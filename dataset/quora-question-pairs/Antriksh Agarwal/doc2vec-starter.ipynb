{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"1ac2855f-d03c-10e8-9fc5-1039d267d99b"},"source":"So, the new popular thing around NLP has been these word embeddings and even though this is a new topic for me, I thought I'd share what I'd learnt and get to know more in doing so.\n\nI am using the gensim library in python which does not seem to have a very good documentation or tutorial series. What I have done below is a compilation from various sources and I think this might work for something I am trying right now.\n\nPlease do write out your views and comment so I can improve."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"181e8d1d-e42a-5ad0-6a16-07e410f3a277"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\nimport nltk\nfrom nltk import word_tokenize\nimport re\n\nfrom sklearn.model_selection import train_test_split as tts\nfrom gensim.models import doc2vec\nimport gensim\nimport json\n\nimport sys\n\nSTOP_WORDS = nltk.corpus.stopwords.words()\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"f1c0fc19-8891-5281-ad78-81ad6ee42444"},"source":"Okay, learning from my previous venture [Cosine Similarity using TFIDF Weighting](https://www.kaggle.com/antriksh5235/quora-question-pairs/cosine-similarity-using-tfidf-weighting) I decided it was best to drop the questions less than a length of 10 and the stop words in sentences in order to avoid a lot of computation.\n\nThe following function was written to take care of all of this."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c5a5f31-2014-515e-fb71-a4f4d57ea3a7"},"outputs":[],"source":"def clean_sentence(sent):\n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', sent).lower()\n    sentence = sentence.split(\" \")\n\n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)\n\n    sentence = \" \".join(sentence)\n    return sentence"},{"cell_type":"markdown","metadata":{"_cell_guid":"ff37b12f-56dd-72a8-67d5-d4b13fd7cb11"},"source":"I am still figuring out how I need to be able to find similarity between two document sets. So, I am keeping an implementation of cosine similarity (between two 1D vectors, just in case.)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e6ae66c-c063-f10e-e5cd-d57d2ea88d40"},"outputs":[],"source":"import math\nimport numpy as np\n\ndef cosine(v1, v2):\n    \"\"\"\n            v1 and v2 are two vectors (can be list of numbers) of the same dimensions. Function returns the cosine distance between those\n            which is the ratio of the dot product of the vectors over their RS.\n    \"\"\"\n    v1 = np.array(v1)\n    v2 = np.array(v2)\n\n    return np.dot(v1, v2) / (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7d267c27-e2ca-a583-eab4-5c83d4dfca53"},"source":"This one is simple enough, just dropping all the nans."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49f484a4-608b-063d-b8b2-28f8bd21eb02"},"outputs":[],"source":"data = pd.read_csv('../input/train.csv')\ndata = data.dropna(how=\"any\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"9e966151-eeea-bf5c-9d60-bda1bc3e1ad0"},"source":"I was first going for merging the two sentence sets into one so that the system is trained over all the words/sentences/document vectors and I would not be able to do it without concatenating both of these."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8253632a-b5a1-aedf-b80f-6e617626320c"},"outputs":[],"source":"def concatenate(data):\n    X_set1 = data['question1']\n    X_set2 = data['question2']\n#    y = data['is_duplicate']\n    X = X_set1.append(X_set2, ignore_index=True)\n    \n    return X"},{"cell_type":"markdown","metadata":{"_cell_guid":"760bc599-5058-9c1c-4d63-d3f2c6803bb9"},"source":"The above method is being run here to clean the sentences one by one."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9dbe03f-76f5-b955-9f2d-4e7e3b6a3295"},"outputs":[],"source":"print('Cleaning data, this might take long')\nfor col in ['question1', 'question2']:\n    data[col] = data[col].apply(clean_sentence)"},{"cell_type":"markdown","metadata":{"_cell_guid":"07e15d27-0aaa-8bdc-c7ae-fd14ea2377d9"},"source":"I am splitting into training and testing set for now. The test given with this competition is very large and I only want to use it once I have tested out implementations."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7d65d0a-5515-aeb0-40a5-d7e9b2eb0153"},"outputs":[],"source":"print('Splitting data to train and test sets.')\ny = data['is_duplicate']\nX_train, X_test, y_train, y_test = tts(data[['id','question1', 'question2']], y, test_size=0.3)\n\nX_train.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"843e07e8-39e0-a3b0-6c0a-f940873896b2"},"source":"Like I said, I am compiling my understanding of gensim from a lot of sources and one of them used multiprocessing, stating that it might be painfully slow doing otherwise."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e13e5ffc-a5f5-542c-c105-a155e864dc13"},"outputs":[],"source":"import multiprocessing\ncores = multiprocessing.cpu_count()\nassert gensim.models.doc2vec.FAST_VERSION > -1"},{"cell_type":"markdown","metadata":{"_cell_guid":"35eabfda-a1e4-2f7e-8168-dfb491b72af7"},"source":"This is where the initial usage of gensim begins. Notice that I am yielding output from the __iter__ method, which is actually why I wrote this modification of the gensim LabeledLineSentence class. Every question is a document and every document has to be tagged, which is where I am using the id. I might as well start using the question Ids once I figure out how I am going to use the or I'll just append a '_q1' and '_q2' for each to know which is which and compare the same set of questions for every ID.\n\nOnce done, I hope this somehow helps in boosting performance. The only reason I went for doc2vec instead of word2vec was it might be able to capture the semantic relations within the sentence/question."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4642d87-b72a-dd62-3bdd-8f288c97c322"},"outputs":[],"source":"from gensim.models.doc2vec import Doc2Vec\nfrom gensim.models import doc2vec\nclass LabeledLineSentence(object):\n\n    def __init__(self, doc_list, labels_list):\n        self.labels_list = labels_list\n        self.doc_list = doc_list\n\n    def __iter__(self):\n        for idx, doc in enumerate(self.doc_list):\n            yield doc2vec.TaggedDocument(words=word_tokenize(doc),\n                                         tags=[self.labels_list[idx]])"},{"cell_type":"markdown","metadata":{"_cell_guid":"8b84edef-cdc4-4ca8-570a-c88ae69ecaee"},"source":"The iterator returns a yield of a TaggedDocument every time the Doc2Vec.build_vocab() function requests it. Had I not given the iterator with the Doc2Vec, I would have to call another model1.build_vocab(it) function just to perform the initialisation. This seemed a quick getaway from writing more lines."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0b47507-d6f7-db3f-017d-bb297ef9c46d"},"outputs":[],"source":"X = concatenate(X_train)\nlabels = []\nfor label in X_train['id'].tolist():\n    labels.append('SENT_%s_1' % label)\nfor label in X_train['id'].tolist():\n    labels.append('SENT_%s_2' % label)\n\ndocs = LabeledLineSentence(X.tolist(), labels)\nit = docs.__iter__()\nmodel1 = Doc2Vec(it, size=12, window=8, min_count=5, workers=4)"},{"cell_type":"markdown","metadata":{"_cell_guid":"dddfe6f4-90df-a2b2-6936-eee2fca51549"},"source":"Okay, the more documents you have, the better. To better measure the similarity of documents, it is undoubtable that your model needs to have a very established vector for each.\n\nAlso, instead of running for the normal 10-20 epochs that people usually have for training Doc2vec models, I tried 100 epochs just in case. Let's see how the results turn up on the test sets I extracted."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c274690-d787-74fb-2814-a80dd9c69fe4"},"outputs":[],"source":"for epoch in range(10):\n    model1.train(it)\n    model1.alpha -= 0.0002  # decrease the learning rate\n    model1.min_alpha = model1.alpha  # fix the learning rate, no deca\n    model1.train(it)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b003895e-e739-86ad-cd6c-8827c05c8da8"},"source":"Now finally for the similarity. I hope it turns out to be some good."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44e543e6-6ac9-9d0b-2316-edf535498794"},"outputs":[],"source":"X_test.index = np.arange(0, X_test['question1'].shape[0])\ny_test.index = np.arange(0, X_test['question1'].shape[0])\n#print(X_test)\ncount = 0\nfor i in range(X_test['question1'].shape[0]):\n    doc1 = word_tokenize(X_test['question1'][i])\n    doc2 = word_tokenize(X_test['question2'][i])\n\n    docvec1 = model1.infer_vector(doc1)\n    docvec2 = model1.infer_vector(doc2)\n\n    #print(docvec1)\n    #print(docvec2)\n\n    print(cosine(docvec1, docvec2), y_test[i])\n    if count>100:\n        break\n    count+=1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7395a6cf-48bb-b6a0-fea4-74f9a2d061dc"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}