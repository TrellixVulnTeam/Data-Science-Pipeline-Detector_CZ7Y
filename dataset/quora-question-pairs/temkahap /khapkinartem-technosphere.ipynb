{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af0e9383-e776-787a-c5e5-9e13c9bc13b2"},"outputs":[],"source":"import time\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\n\nfrom sklearn import model_selection\nfrom sklearn import linear_model\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nmatplotlib.style.use('fivethirtyeight')\n\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline  \n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"efdafe29-e8e8-a723-b3b8-cf451baf42cd"},"outputs":[],"source":"trainDF = pd.read_csv('../input/train.csv')\ntestDF = pd.read_csv('../input/test.csv')\ntrainDF = trainDF.dropna(how=\"any\").reset_index(drop=True)\ntrainDF.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c78c21b-5308-3106-822d-27ed483964fc"},"outputs":[],"source":"featureExtractionStartTime = time.time()\n\n\nmaxNumFeatures = 10000\n\n\nq1_list = np.array(trainDF['question1']).tolist()\nq2_list = np.array(trainDF['question2']).tolist()\n\ncl = TfidfVectorizer(max_df=1000, min_df=1, max_features=maxNumFeatures, \n                                      analyzer='word', ngram_range=(1,4), stop_words = 'english', \n                                      binary=False, lowercase=True)\n\nq1_matrix = cl.fit_transform(q1_list)\nq2_matrix = cl.fit_transform(q2_list)\n\ny = np.array(trainDF.ix[:,'is_duplicate'])\n\nfeatureExtractionDurationInMinutes = (time.time()-featureExtractionStartTime)/60.0\nprint(\"feature extraction took %.2f minutes\" % (featureExtractionDurationInMinutes))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbf93c8a-3546-2f3e-4367-d71f1de1b6d6"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\ncrossValidationStartTime = time.time()\n\nnumCVSplits = 8\nnumSplitsToBreakAfter = 4\n\nX = (q1_matrix != q2_matrix).astype(int) + q1_matrix.multiply(q2_matrix)\n\nlogisticRegressor = linear_model.LogisticRegression(C= 0.1, solver='sag')\n#RFC = RandomForestClassifier(n_estimators = 5)\n#knn = KNeighborsClassifier(n_neighbors=4)\n\n\nlogRegAccuracy = []\nlogRegLogLoss = []\nlogRegAUC = []\n\nprint('---------------------------------------------')\nstratifiedCV = model_selection.StratifiedKFold(n_splits=numCVSplits, random_state=2)\nflag = 0\nfor k, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n    flag+=1\n    print (flag)\n    foldTrainingStartTime = time.time()\n\n    X_train_cv = X[trainInds,:]\n    X_valid_cv = X[validInds,:]\n\n    y_train_cv = y[trainInds]\n    y_valid_cv = y[validInds]\n    \n    logisticRegressor.fit(X_train_cv, y_train_cv)\n   \n    y_train_hat =  logisticRegressor.predict_proba(X_train_cv)[:,1]\n    y_valid_hat =  logisticRegressor.predict_proba(X_valid_cv)[:,1]\n    \n\n    \n    \n    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n    \n    foldTrainingDurationInMinutes = (time.time()-foldTrainingStartTime)/60.0\n    print('fold %d took %.2f minutes: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (k+1,\n             foldTrainingDurationInMinutes, logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1]))\n\n    if (k+1) >= numSplitsToBreakAfter:\n        break\n\n\n    crossValidationDurationInMinutes = (time.time()-crossValidationStartTime)/60.0\n    \n    print('---------------------------------------------')\n    print('cross validation took %.2f minutes' % (crossValidationDurationInMinutes))\n    print('mean CV: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (np.array(logRegAccuracy).mean(),\n                                                                 np.array(logRegLogLoss).mean(),\n                                                                 np.array(logRegAUC).mean()))\n    print('---------------------------------------------')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0bb792f-b3ac-89d2-44a5-65c3fe952ef8"},"outputs":[],"source":"#по аналогии сделали такую штучку))\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10,10)\n\nplt.figure(); \nsns.kdeplot(y_valid_hat[y_valid_cv==0], shade=True, color=\"b\", bw=0.01)\nsns.kdeplot(y_valid_hat[y_valid_cv==1], shade=True, color=\"g\", bw=0.01)\nplt.legend(['non duplicate','duplicate'],fontsize=24)\nplt.title('Validation Accuracy = %.3f, Log Loss = %.4f, AUC = %.3f' %(logRegAccuracy[-1],\n                                                                      logRegLogLoss[-1],\n                                                                      logRegAUC[-1]))\n\nplt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n\nnumFeaturesToShow = 30\n\nsortedCoeffients = np.sort(logisticRegressor.coef_)[0]\nfeatureNames = cl.get_feature_names()\n\nsortedFeatureNames = [featureNames[x] for x in list(np.argsort(logisticRegressor.coef_)[0])]\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10,12)\n\nplt.figure()\nplt.suptitle('Feature Importance',fontsize=24)\nax = plt.subplot(1,2,1); plt.title('top non duplicate predictors'); \nplt.xlabel('minus logistic regression coefficient')\nax.barh(range(numFeaturesToShow), -sortedCoeffients[:numFeaturesToShow][::-1], align='center'); \n\nplt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \nax.set_yticklabels(sortedFeatureNames[:numFeaturesToShow][::-1],fontsize=20)\n\nax = plt.subplot(1,2,2); plt.title('top duplicate predictors'); \nplt.xlabel('logistic regression coefficient')\nax.barh(range(numFeaturesToShow), sortedCoeffients[-numFeaturesToShow:], align='center'); \nplt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \nax.set_yticklabels(sortedFeatureNames[-numFeaturesToShow:],fontsize=20)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a0373f6-2b8d-ca06-2042-d11f0b346a30"},"outputs":[],"source":"logisticRegressor = linear_model.LogisticRegression(C=1, solver='sag', \n                                                    class_weight={1: 0.4, 0: 1.34})\n                                                    \nlogisticRegressor.fit(X, y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f681b863-f218-5bf0-db75-721a37a74470"},"outputs":[],"source":"testPredictionStartTime = time.time()\n\ntestDF.ix[testDF['question1'].isnull(),['question1','question2']] = 'random empty question'\ntestDF.ix[testDF['question2'].isnull(),['question1','question2']] = 'random empty question'\nq1_testmat  = cl.transform(testDF.ix[:,'question1'])   \nq2_testmat  = cl.transform(testDF.ix[:,'question2'])   \n\nX_test = (q1_testmat != q2_testmat).astype(int) + q1_testmat.multiply(q2_testmat)\n\nseperators= [750000,1500000]\ntestPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\ntestPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\ntestPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\ntestPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (9,9)\n\nplt.figure(); \nplt.subplot(2,1,1); sns.kdeplot(y_valid_hat, shade=True, color=\"b\", bw=0.01); \nplt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\nplt.title('mean valid prediction = ' + str(np.mean(y_valid_hat)))\nplt.subplot(2,1,2); sns.kdeplot(testPredictions, shade=True, color=\"b\", bw=0.01);\nplt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\nplt.title('mean test prediction = ' + str(np.mean(testPredictions)))\n\ntestPredictionDurationInMinutes = (time.time()-testPredictionStartTime)/60.0\nprint('predicting on test took %.2f minutes' % (testPredictionDurationInMinutes))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fb8b895-8e8b-f1f6-7e89-34e16e44d274"},"outputs":[],"source":"submissionName = 'shallowBenchmark_'\n\nsubmission = pd.DataFrame()\nsubmission['test_id'] = testDF['test_id']\nsubmission['is_duplicate'] = (testPredictions)# + prev['is_duplicate'])/2\nsubmission.to_csv(submissionName + '.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}