{"nbformat_minor":1,"cells":[{"outputs":[],"execution_count":null,"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import log_loss\nimport re,string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nimport string\nfrom sklearn.cross_validation import train_test_split\nimport xgboost as xgb\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv(\"../input/test.csv\")\n# Any results you write to the current directory are saved as output.","cell_type":"code","metadata":{"_cell_guid":"fe97bcf1-f56e-43d8-b0e6-ebbe01e4084f","_uuid":"641615bd571a34f7b79bf22121a9788b9d00ad17"}},{"outputs":[],"execution_count":null,"source":"train.shape,test.shape","cell_type":"code","metadata":{}},{"outputs":[],"execution_count":null,"source":"train.drop(['id','qid1','qid2'],inplace=True,axis=1)\ntarget = train['is_duplicate']\ntrain.drop('is_duplicate',axis=1,inplace=True)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"def similar(row):\n    try:\n        q1 = set(re.sub(\"[^\\w]\", \" \",  row['question1'].lower()).split())\n        q2 = set(re.sub(\"[^\\w]\", \" \",  row['question2'].lower()).split())\n        return len(q1 & q2)\n    except:\n        return 0","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"def unsimilar(row):\n    try:\n        q1 = set(re.sub(\"[^\\w]\", \" \",  row['question1'].lower()).split())\n        q2 = set(re.sub(\"[^\\w]\", \" \",  row['question2'].lower()).split())\n        o = q1&q2\n        o1 = q1 - o\n        o2 = q2 - o\n        return len(o1) + len(o2)\n    except:\n        return 0","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"def diffLen(row):\n    try:\n        return abs(len(row['question1']) - len(row['question2']))\n    except:\n        return 0","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"def puncCounts(row):\n    try:\n        q1 = len([w for w in row['question1'] if w in string.punctuation])/len(row['question1'])\n        q2 = len([w for w in row['question2'] if w in string.punctuation])/len(row['question2'])\n        return abs(q1-q2)\n    except:\n        return 0\n","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"def digitDiff(row):\n    try:\n        d1 = len([char.isdigit() for char in row['question1']])/len(row['question1'])\n        d2 = len([char.isdigit() for char in row['question2']])/len(row['question2'])\n        return abs(d1-d2)\n    except:\n        return 0\n\n\ndef digit1(row):\n    try:\n        d1 = len([char.isdigit() for char in row['question1']]) > 0\n        return 1 if d1 > 0 else 0\n    except:\n        return 0\ndef digit2(row):\n    try:\n        d2 = len([char.isdigit() for char in row['question2']]) > 0\n        return 1 if d2 > 0 else 0\n    except:\n        return 0","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"ss = set(stopwords.words('english'))\ndef stopWords(row):\n    try:\n        q1 = set(re.sub(\"[^\\w]\", \" \",  row['question1'].lower()).split())\n        q2 = set(re.sub(\"[^\\w]\", \" \",  row['question2'].lower()).split())\n        l1 = len([i for i in q1 if i in ss])\n        l2 = len([i for i in q2 if i in ss])\n        return abs(l1-l2)\n    except:\n        return 0\n","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"train_cp = pd.DataFrame()\ntest_cp = pd.DataFrame()","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"train_cp['stopwordsDiff'] = train.apply(stopWords,axis=1,raw=True)\ntest_cp['stopwordsDiff'] = test.apply(stopWords,axis=1,raw=True)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"train_cp['digitDiff'] = train.apply(digitDiff,axis=1,raw=True)\ntrain_cp['digit1'] = train.apply(digit1,axis=1,raw=True)\ntrain_cp['digit2'] = train.apply(digit2,axis=1,raw=True)\n\ntest_cp['digitDiff'] = test.apply(digitDiff,axis=1,raw=True)\ntest_cp['digit1'] = test.apply(digit1,axis=1,raw=True)\ntest_cp['digit2'] = test.apply(digit2,axis=1,raw=True)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"train_cp['puncCounts'] = train.apply(puncCounts,axis=1,raw=True)\n\ntest_cp['puncCounts'] = test.apply(puncCounts,axis=1,raw=True)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"train_cp['diffLen'] = train.apply(diffLen,axis=1,raw=True)\n\ntest_cp['diffLen'] = test.apply(diffLen,axis=1,raw=True)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"train_cp['similar'] = train.apply(similar,axis=1,raw=True)\ntrain_cp['unsimilar'] = train.apply(unsimilar,axis=1,raw=True)\n\ntest_cp['similar'] = test.apply(similar,axis=1,raw=True)\ntest_cp['unsimilar'] = test.apply(unsimilar,axis=1,raw=True)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"tfIdf = TfidfVectorizer(ngram_range=(1,3),stop_words='english')\ntrain_idf = tfIdf.fit_transform(train['question1'].astype(str)+train['question2'].astype(str))\ntest_idf = tfIdf.transform(test['question1'].astype(str)+test['question2'].astype(str))\nn_comp = 20\nsvd = TruncatedSVD(n_components=n_comp, algorithm='arpack')\ntrain_svd = pd.DataFrame(svd.fit_transform(train_idf))\ntest_svd = pd.DataFrame(svd.transform(test_idf))\n\n#add this train_svd and test_svd to train and test respectively\ntrain_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\ntrain_cp = pd.concat([train_cp, train_svd], axis=1)\ntest_cp = pd.concat([test_cp,test_svd],axis=1)\ntrain_cp.shape,test_cp.shape","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"x_train, x_valid, y_train, y_valid = train_test_split(train_cp, target, test_size=0.2, random_state=4242)\ndtrain = xgb.DMatrix(x_train,y_train)\ndtest = xgb.DMatrix(x_valid)\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 1.0,\n    'colsample_bytree': 0.7,\n    'silent': 1,\n    'objective':'binary:logistic',\n    'eval_metric':'logloss'\n}\nxgbc = xgb.train(xgb_params, dtrain, num_boost_round=1000, verbose_eval=20)\nxpreds = xgbc.predict(dtest)\nlog_loss(y_valid,xpreds)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"dtrain = xgb.DMatrix(train_cp,target)\ndtest = xgb.DMatrix(test_cp)\nxgbc = xgb.train(xgb_params, dtrain, num_boost_round=1000, verbose_eval=20)\nxpreds = xgbc.predict(dtest)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"sub = pd.DataFrame()\nsub['test_id'] = test['test_id']\nsub['is_duplicate'] = xpreds\nsub.to_csv('simple_xgb.csv', index=False)","cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"execution_count":null,"source":"","cell_type":"code","metadata":{"collapsed":true}}],"nbformat":4,"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","name":"python","file_extension":".py","version":"3.6.4"}}}