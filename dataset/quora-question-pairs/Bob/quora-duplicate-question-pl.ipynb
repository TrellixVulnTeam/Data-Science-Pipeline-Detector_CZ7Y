{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Quora Duplicate Questions Detection\n\n- This version is a refactored version of [this](https://www.kaggle.com/sankarshan7/quora-duplicate-question?scriptVersionId=51988650) original kernel\n- The [orignal](https://www.kaggle.com/sankarshan7/quora-duplicate-question?scriptVersionId=51988650) `pytorch` kernel is refactored to integrate with `PyTorchLightning` \n- Some `PytorchLightning` refactoring style has been taken from this kernel: [Lish-moa baseline approach by Adrew Lukyanenko](https://www.kaggle.com/artgor/lish-moa-baseline-approach/notebook#Data-exploration)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn import model_selection","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nDIR = '/kaggle/input'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning and preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lh /kaggle/input/quora-question-pairs/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/quora-question-pairs/sample_submission.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/quora-question-pairs/train.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/quora-question-pairs/test.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.read_csv(\"sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_sub[df_sub.test_id.isin([1046690, 1461432, 379205, 817520, 943911, 1270024,  2345796])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fix `nan` issue in Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ndf_test = df_test.replace(np.nan, 'nan', regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.question1.isna().sum(), df_test.question2.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create validation dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"train.csv\")\ndf['kfold'] = -1\n\ndf = df.sample(frac=1.,random_state=2021).reset_index(drop=True)\n\nkf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X=df, y = df.is_duplicate.values)):\n    print(len(train_idx), len(val_idx))\n    df.loc[val_idx, 'kfold'] = fold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.question1.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.question2.isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fix `nan` issue in `train` data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.question1.isna().sum(), df.question2.isna().sum(), df.question1.isnull().sum(), df.question2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"train_folds.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fold = pd.read_csv(\"train_folds.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Universal Sentence Encode"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_hub as hub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = embed([\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"I am a sentence for which I would like to get its embedding\"])\n\nembeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reproducing same results\nSEED = 2021\n\n#Torch\ntorch.manual_seed(SEED)\n\n#Cuda algorithms\ntorch.backends.cudnn.deterministic = True  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pytorch_lightning as pl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nFOLD_MAPPPING = {\n    0: [1, 2, 3, 4],\n    1: [0, 2, 3, 4],\n    2: [0, 1, 3, 4],\n    3: [0, 1, 2, 4],\n    4: [0, 1, 2, 3]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLD = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = df_fold[df_fold.kfold.isin(FOLD_MAPPPING.get(FOLD))].reset_index(drop=True)\nvalid_df = df_fold[df_fold.kfold==FOLD].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Network Architecture\n\n- Before integrating with the `pytorchlightning`, let's desing the network in vanilla pytorch\n\n- The original architecture idea came from [here](https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur/). But the original architecture is heavily simplified with the use of transfer learning using `Universal Sentence Encoder`\n\n<center>\n<img src='https://raw.githubusercontent.com/msank00/Kaggle_202101_Quora_Duplicate_Questions/main/images/NN_Architecture.jpg' width='400'>    \n</center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class IsDuplicateAdv(nn.Module):\n    def __init__(self, output_dim: int, emb_dim: int, hid_dim=512):\n        \"\"\"Non Linear model\n        \"\"\"\n        super().__init__()\n        #dense layer\n        \n        self.batchnorm1 = nn.BatchNorm1d(emb_dim * 2)\n        self.dropout = nn.Dropout(p=0.2)\n        self.nonlinear = nn.PReLU()\n        \n        self.fc1 = nn.Linear(emb_dim * 2, hid_dim)\n        self.batchnorm2 = nn.BatchNorm1d(hid_dim)\n        self.fc2 = nn.Linear(hid_dim, output_dim)\n        \n        #activation function\n        self.act = nn.Sigmoid()\n        \n    def forward(self, text1:[str], text2:[str]):\n        \"\"\"\n        text1: list of strings from question1, len: batch_size\n        text2: list of strings from question2, len: batch_size\n        \"\"\"\n        \n        emb1 = embed(text1)\n        e1 = torch.from_numpy(emb1.numpy())\n        \n        emb2 = embed(text2)\n        e2 = torch.from_numpy(emb2.numpy())\n        \n        # merged\n        x = torch.cat((e1, e2), dim = 1)\n        x = self.batchnorm1(x)\n        \n        \n        x=self.fc1(x)\n        x = self.nonlinear(x)\n        x = self.dropout(x)\n        x = self.batchnorm2(x)\n        \n        x=self.fc2(x)\n\n        #Final activation function\n        outputs=self.act(x)\n        \n        return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\ncriterion = nn.BCELoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define metric\ndef binary_accuracy(preds, y):\n    #round predictions to the closest integer\n    rounded_preds = torch.argmax(preds, dim=1)\n    \n    correct = (rounded_preds == y).float() \n    acc = correct.sum() / len(correct)\n    return acc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wrap vanila `pytorch` network with `pytorchlightning`"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuoraQPair(pl.LightningModule):\n    def __init__(self, model: IsDuplicateAdv):\n        super().__init__()\n        self.model = model\n        \n    def forward(self, text1:[str], text2:[str]):\n        return self.model(text1, text2)\n    \n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n        return optimizer\n    \n    def training_step(self, batch, batch_idx: int):\n        q1, q2, label = batch['q1'], batch['q2'], batch['label'] \n        label = label.float()\n        predictions = self.model(q1, q2)\n        loss = criterion(predictions[:,1], label) \n        acc = binary_accuracy(predictions, label) \n        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        return {'loss': loss, 'acc': acc}\n\n    \n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n        self.log('avg_train_loss', avg_loss, on_epoch=True, sync_dist=True, prog_bar=False,logger=True,on_step=False)\n        self.log('avg_train_acc', avg_acc, on_epoch=True, sync_dist=True, prog_bar=False,logger=True,on_step=False)\n    \n    def validation_step(self, batch, batch_idx: int):\n        q1, q2, label = batch['q1'], batch['q2'], batch['label'] \n        label = label.float()\n        predictions = self.model(q1, q2)\n        loss = criterion(predictions[:,1], label) \n        acc = binary_accuracy(predictions, label) \n        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('valid_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return {'loss': loss, 'acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n        self.log('avg_val_loss', avg_loss, on_epoch=True, sync_dist=True, prog_bar=False,logger=True,on_step=False)\n        self.log('avg_val_acc', avg_acc, on_epoch=True, sync_dist=True, prog_bar=False,logger=True,on_step=False)\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NOTE**\n\n- Set `on_step=False` for better logging "},{"metadata":{},"cell_type":"markdown","source":"# Data Module\n\n- [pl.DataModule Official Document](https://pytorch-lightning.readthedocs.io/en/stable/datamodules.html)\n- [How to use it in real case - Kaggle MoA Prediction by Andrew Lukyanenko](https://www.kaggle.com/artgor/lish-moa-baseline-approach)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuoraTrainData(Dataset):\n    def __init__(self, df: pd.DataFrame):\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        q1 = self.df.iloc[idx].question1\n        q2 = self.df.iloc[idx].question2\n        label = self.df.iloc[idx].is_duplicate\n        \n        return {\"q1\": q1, \"q2\": q2, \"label\": label}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuoraTestData(Dataset):\n    def __init__(self, df: pd.DataFrame):\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        q1 = self.df.iloc[idx].question1\n        q2 = self.df.iloc[idx].question2\n        \n        return {\"q1\": q1, \"q2\": q2}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuoraQPairDataModule(pl.LightningDataModule):\n    def __init__(self, train_df:pd.DataFrame, valid_df: pd.DataFrame, batch_size:int):\n        super().__init__()\n        self.batch_size = batch_size\n        self.train_df = train_df\n        self.valid_df = valid_df\n        \n    def prepare_data(self):\n        # any data downloading / preprocessing\n        pass\n    \n    def setup(self, stage=None):\n        # setup torch dataset\n        self.train_dataset = QuoraTrainData(self.train_df)\n        self.valid_dataset = QuoraTrainData(self.valid_df)\n    \n    def train_dataloader(self):\n        train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n        return train_loader\n    \n    def val_dataloader(self):\n        valid_loader = DataLoader(self.valid_dataset, batch_size=self.batch_size, num_workers=4)\n        return valid_loader\n    \n    def test_dataloader(self):\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_lightning import Callback\nclass MetricsCallback(Callback):\n    \"\"\"PyTorch Lightning metric callback.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.metrics = {\"train\": [], \"val\": []}\n\n    def on_validation_end(self, trainer, pl_module):\n        self.metrics[\"val\"].append(trainer.logged_metrics)\n    \n    def on_train_end(self, trainer, pl_module):\n        self.metrics[\"train\"].append(trainer.logged_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = IsDuplicateAdv(output_dim=2, emb_dim=512)\nmodel = QuoraQPair(net)\ndm = QuoraQPairDataModule(train_df, valid_df, BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set logger for accessing training history\n\n- [PyTorch CSVLOgger](https://pytorch-lightning.readthedocs.io/en/latest/generated/pytorch_lightning.loggers.CSVLogger.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_lightning.loggers import CSVLogger","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# logger\nimport os\ncsvlogger = CSVLogger(\n    save_dir=os.getcwd(),\n    name=\"exp_logs\"\n)\nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics_callback = MetricsCallback()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer = pl.Trainer(max_epochs=5,\n                     default_root_dir=os.getcwd(),\n                     logger=csvlogger,\n                     deterministic=True) # callbacks = [metrics_callback]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.fit(model, dm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to log metrics properly using PyTorchLightning\n\n- [Why are losses different when logging from '_step' (with on_epoch=True) compared to logging from '_epoch_end'? #5539](https://github.com/PyTorchLightning/pytorch-lightning/issues/5539)\n- [Understanding different values of training/validation loss in callback_metrics dictionary](https://forums.pytorchlightning.ai/t/understanding-different-values-of-training-validation-loss-in-callback-metrics-dictionary/568)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ls -lh exp_logs/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_metrics = pd.read_csv('exp_logs/version_0/metrics.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_metrics_val = df_metrics[[\"avg_val_loss\", \"avg_val_acc\", \"epoch\"]].dropna()\ndf_metrics_train = df_metrics[[\"avg_train_loss\", \"avg_train_acc\", \"epoch\"]].dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_metrics_val.avg_val_loss.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df_metrics_train.avg_train_loss.values, label=\"train\")\nplt.plot(df_metrics_val.avg_val_loss.values, label=\"val\")\nplt.title(\"Loss vs Epoch\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.grid(alpha=0.3)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df_metrics_train.avg_train_acc.values, label=\"train\")\nplt.plot(df_metrics_val.avg_val_acc.values, label=\"val\")\nplt.title(\"Accuracy vs Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.grid(alpha=0.3)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = QuoraTestData(df_test)\ntest_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.zeros(df_test.shape[0])\nmodel_inference = model.model\nmodel_inference.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_iter = iter(test_loader)\ntres = test_iter.next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = model_inference(tres['q1'], tres['q2'])[:,1].detach().cpu().numpy()\ntemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ind, batch in tqdm(enumerate(test_loader), total=len(test_loader)):\n    p = model_inference(batch['q1'], batch['q2'])[:,1].detach().cpu().numpy()\n    predictions[ind * 1024:(ind + 1) * 1024] = p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = pd.DataFrame({'test_id': df_test['test_id'].values, 'is_duplicate': predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#s.shape\n#s[s.test_id.isin([1128118])]\n#df_sub.shape\n#df_sub.head()\n#df_sub[df_sub.test_id.isin([1128118,1128119 ])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}