{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3e92f37f-6100-9e2a-c701-7c3966e2f1f3"},"source":"Yes we can\n----"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4493db04-c6b3-629f-4842-a466650ab30b"},"outputs":[],"source":"import time\nstart = time.clock()\n\n#open data\nimport codecs\nimport nltk #language functions\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\ndatas = pd.read_csv('../input/train.csv')\ndatas = datas.fillna('leeg')\n#print(datas.head())\n\ndef cleantxt(x):    # aangeven sentence\n    x = x.lower()\n    # Pad punctuation with spaces on both sides\n    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n        x = x.replace(char, ' ' + char + ' ')\n    return x.split()\n\ndatas['question1']=datas['question1'].map(cleantxt)\ndatas['question2']=datas['question2'].map(cleantxt)\n\nprint(datas.head())\nend = time.clock()\nprint('open:',end-start)\n\n#datas"},{"cell_type":"markdown","metadata":{"_cell_guid":"f20954d0-0765-45f0-0d2f-8528c0137b39"},"source":"Sentences where the only difference are stopwords are imho to be considered as similar.\n----\n\nyou can discuss about this, but when the question has only the stopwords being different, and as everybody is throwing away the stopwords, you endup with a signal loss in your data...if you think those questions are not similar.\nYou can't even train on it, since you throw away that information you endup with nois imho ?\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92a1cf10-c736-0aba-1ea4-50673665d802"},"outputs":[],"source":" # Import the stop word list\nstoppers=stopwords.words(\"english\") \ndef falsdupl(sent1, sent2,isdup):\n    difq1 = [w for w in sent2 if w not in sent1 if not w in stoppers]\n    difq2 = [w for w in sent1 if w not in sent2 if not w in stoppers]\n    if len(difq1+difq2)==0:\n        falsdup=1\n    else:\n        falsdup=isdup\n        \n    return falsdup\n\nstart = time.clock()\ndatas['fals_dup']=datas[['question1','question2','is_duplicate']].apply(lambda x: falsdupl(*x), axis=1)\n\n    \nend = time.clock()\nprint('all dubious:',400000/(end-start))\n#amazing four times faster this way..."},{"cell_type":"markdown","metadata":{"_cell_guid":"4db24a11-1315-799c-68db-9297a9f12567"},"source":"Find Is_duplicate,is_notduplicate and possible false not duplicate\n---\n\n - we will try to plot the ration duplicate / nr of questions  progressively in the database. \n - the reverse function is the 'non duplicate progressively\n - the final one is the most interesting: the ratio fals duplicate / nr of labeled as duplicate.\n\nI suspect a rampup to the end.\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f66750c6-f612-69aa-e8dc-b55035fe563d"},"outputs":[],"source":"tel_nr_pos = 0\ntel_nr_qu = len(datas)\ntel_nr_neg = 0\ntel_nr_fals = 0\nreeks = pd.DataFrame(columns=('pos','neg','tel','fals'))\nprint(reeks)\nfor xyz in range(0,len(datas)):\n    #q1=datas.iloc[xyz].question1\n    #q2=datas.iloc[xyz].question2\n    #sent1=q1.split()\n    #sent2=q2.split()\n    #equq1 = [w for w in sent1 if w in sent2]\n    #difq1 = [w for w in sent1 if w not in sent2]\n    #difq2 = [w for w in sent2 if w not in sent1]\n    #diftot = difq1+difq2\n    #difton = [w for w in diftot if not w in stopwords.words(\"english\")]\n    dupmem=datas.at[xyz,'is_duplicate']\n    if dupmem==0:\n        tel_nr_neg+=1\n    if dupmem==1:\n        tel_nr_pos+=1\n    if dupmem<datas.at[xyz,'fals_dup']:\n        tel_nr_fals+=1\n    if xyz/100==round(xyz/100) and xyz>1:\n        reeks.loc[xyz/100]= [ tel_nr_pos/xyz,tel_nr_neg/xyz,xyz,tel_nr_fals/tel_nr_pos ]\n        end = time.clock()\n        if end-start>1000:\n            break\n        \nprint(reeks)\nend = time.clock()\nprint('graphing:',end-start)\n\nimport matplotlib.pyplot as plt  \nfrom pandas.tools.plotting import scatter_matrix\nscatter_matrix(reeks, alpha=0.2, figsize=(6, 6), diagonal='kde')"},{"cell_type":"markdown","metadata":{"_cell_guid":"e5406748-6450-df93-c528-6cec279939a0"},"source":"The graphs shows a stable descend in positives, stable rise negatives \n----\n\n - 37% duplicate in training set\n - a negative correlation between pos/neg meaning the ratio descends\n - 2.8% false positives\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2a7b741-279b-1c58-70ac-501f4ce0c8c4"},"outputs":[],"source":"# a 37% positive duplicates diminishing to the end\n# a 4% what i call false negative, or negative with only stopwords"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}