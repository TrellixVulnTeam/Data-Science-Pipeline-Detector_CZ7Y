{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e02e8c7f-532a-e0a0-36e9-93aaa08df4e2"},"source":"source\n\nhttp://nbviewer.jupyter.org/urls/gist.github.com/mjbommar/e2a019e346b879c13d3d/raw/74a206c2629d6e661645e18369f05f6c79d15b65/fuzzy-sentence-matching-python.ipynb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d9b397e8-8468-bd43-6220-c4b16b698237"},"outputs":[],"source":"import pandas as pd\n# timing function\nimport time   \nstart = time.clock() #_________________ measure efficiency timing\n\n# read data\ntest = pd.read_csv('../input/test.csv',encoding='utf8')[:100]\ntrain = pd.read_csv('../input/train.csv',encoding='utf8')[:100]\nprint(train.head(2))\ntrain.fillna(value='leeg',inplace=True)\ntest.fillna(value='leeg',inplace=True)\n\nend = time.clock()\nprint('open:',end-start)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0ebb7b96-3ad3-8939-da9b-350741232483"},"outputs":[],"source":"# Imports\nimport nltk.corpus\nimport nltk.stem.snowball\nfrom nltk.corpus import wordnet\nimport string\n\n# Get default English stopwords and extend with punctuation\nstopwords = nltk.corpus.stopwords.words('english')\n\nstopwords.extend(string.punctuation)\nstopwords.append('')\n\ndef get_wordnet_pos(pos_tag):\n    if pos_tag[1].startswith('J'):\n        return (pos_tag[0], wordnet.ADJ)\n    elif pos_tag[1].startswith('V'):\n        return (pos_tag[0], wordnet.VERB)\n    elif pos_tag[1].startswith('N'):\n        return (pos_tag[0], wordnet.NOUN)\n    elif pos_tag[1].startswith('R'):\n        return (pos_tag[0], wordnet.ADV)\n    else:\n        return (pos_tag[0], wordnet.NOUN)\n\n# Create tokenizer and stemmer\n\nlemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n\ndef is_ci_partial_noun_set_token_stopword_lemma_match(a, b):\n    \"\"\"Check if a and b are matches.\"\"\"\n    \n    pos_a = map(get_wordnet_pos, nltk.pos_tag(a.lower().strip(string.punctuation).split()))\n    pos_b = map(get_wordnet_pos, nltk.pos_tag(b.lower().strip(string.punctuation).split()))\n    lemmae_a = [lemmatizer.lemmatize(token.lower().strip(string.punctuation), pos) for token, pos in pos_a if pos == wordnet.NOUN and token.lower().strip(string.punctuation) not in stopwords]\n    lemmae_b = [lemmatizer.lemmatize(token.lower().strip(string.punctuation), pos) for token, pos in pos_b if pos == wordnet.NOUN and token.lower().strip(string.punctuation) not in stopwords]\n    q1=''.join(lemmae_a).split()\n    q2=''.join(lemmae_b).split()\n    # Calculate Jaccard similarity\n    ratio = len(set(lemmae_a).intersection(lemmae_b)) / float(len(set(lemmae_a).union(lemmae_b))+.001)\n    return (round(ratio,2))\n\nresult=[]\nfor xi in range(0,len(train)):\n    result.append(is_ci_partial_noun_set_token_stopword_lemma_match(train.iloc[xi]['question1'],train.iloc[xi]['question2']))\n\ntrain['jacq']=result\nprint(train)\nend = time.clock()\nprint('open:',end-start)\nprint((end-start)/len(result))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}