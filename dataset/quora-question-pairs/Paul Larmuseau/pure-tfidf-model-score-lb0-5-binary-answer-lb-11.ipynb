{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"11c32b31-3537-112c-0ec4-0934e96d5265"},"source":"The start in his most basic form...\n-----"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c01f66d-b99c-a39d-6c08-c300a4910477"},"outputs":[],"source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntrain = pd.read_csv('../input/train.csv')\nprint(train.head(10))\n\ndef mapfunctie(row):\n    #rint(row)\n    if(row==1):\n        rij='dubbeltje'\n    if(row==0):\n        rij='leegaartje'\n    return rij\n\ntrain['mapp']=train['is_duplicate'].apply(mapfunctie)\n        \ntrain=train.dropna(axis=0, how='any')\ntrain['test']=train['question1']+' '+train['question2']+train['mapp']  # leeg prevents sum of two questions sentence is empty\n\ntraintit=train[train['test']>'']  # remove all empties\n\ncount_vectorizer = CountVectorizer()\ncount_vectorizer.fit_transform(traintit['test'])  #Learn vocabulary and idf, return term-document matrix.\nfreq_term_matrix = count_vectorizer.transform(traintit['test']) #Transform documents to document-term matrix. Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform) This is equivalent to fit followed by transform\n\ntfidf = TfidfTransformer(norm=\"l2\")\ntf_idf_matrix = tfidf.fit_transform(freq_term_matrix)\n\nprint('Questions x Words', tf_idf_matrix.shape)\n#als je similariteit wilt zien...\nprint('Q similarity',tf_idf_matrix[:14].dot(tf_idf_matrix[:14].T).todense().round(2) )\n\ncount_vectorizer.vocabulary_['dubbeltje']\n      "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"330bcf40-26d4-d9a1-2cba-63dcf40b40cc"},"outputs":[],"source":"print('analyse Question 1 : what is the step by step guide to invest in the stockmarket in Japan /Vietnam')\nprint('tfidf value of Q0 of leegaartje',tf_idf_matrix[0,45219])\n\n\nisdup=pd.DataFrame(tf_idf_matrix[:,count_vectorizer.vocabulary_['leegaartje']].todense())\nisdup['dupli']=tf_idf_matrix[:,count_vectorizer.vocabulary_['dubbeltje']].todense()\nprint(isdup.shape)\nprint(tf_idf_matrix.shape)\n\nvietnam=tf_idf_matrix[:,count_vectorizer.vocabulary_['vietnam'] ].todense() # all questions with Vietnam\njapan=tf_idf_matrix[:,count_vectorizer.vocabulary_['japan'] ].todense()\nprint('wordvector shape',vietnam.shape)  #all questions with Japan\nprint('Correlation Vietnam - japan',vietnam.T.dot(japan))\n\ndiffvect=pd.DataFrame(vietnam)\ndiffvect['japan']=japan\nvc=vietnam.T.dot(isdup)\nprint('Vietnam 52% duplicate vrs nondup',vc[0,1]/vc[0,0])\njc=japan.T.dot(isdup)\nprint('Japan 57% dupl vrs nondup',jc[0,1]/jc[0,0])\n\nprint('------------------------------------')\nprint('analyse Question 7 : What should i do to be a great/good geologist')\nprint('print wordvectors is duplicate 0 of leegaartje: is dup',tf_idf_matrix[7,45219])\n\ngood=tf_idf_matrix[:,count_vectorizer.vocabulary_['good'] ].todense() # all questions with Vietnam\ngreat=tf_idf_matrix[:,count_vectorizer.vocabulary_['great'] ].todense() #all questions with Japan\nprint('Correlation good - great very high...',good.T.dot(great))\n\nvg=good.T.dot(isdup)\nvr=great.T.dot(isdup)\nprint('good 80% duplicate versus nondup',vg[0,1]/vg[0,0])\nprint('great 110% duplicate versus nondup',vr[0,1]/vr[0,0])\nprint('remember this is not the real correlation, its indication of similarity' )\nprint(isdup.T.dot(isdup))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11029b1f-9ecb-e09c-fc46-b84a3e5ee359"},"outputs":[],"source":"# Lets redo it but splitted... and use the existing vocabulary\n\ncount1_vectorizer = CountVectorizer(vocabulary=count_vectorizer.vocabulary_)\ncount1_vectorizer.fit_transform(train['question1'])  #Learn vocabulary and idf, return term-document matrix.\nfreq1_term_matrix = count_vectorizer.transform(train['question1'])\ncount2_vectorizer = CountVectorizer(vocabulary=count_vectorizer.vocabulary_)\ncount2_vectorizer.fit_transform(train['question2'])\nfreq2_term_matrix = count_vectorizer.transform(train['question2']) #Transform documents to document-term matrix. Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform) This is equivalent to fit followed by transform\n\n\ntfidf1 = TfidfTransformer(norm=\"l2\")\ntf1_idf_matrix = tfidf1.fit_transform(freq1_term_matrix)\ntfidf2 = TfidfTransformer(norm=\"l2\")\ntf2_idf_matrix = tfidf2.fit_transform(freq2_term_matrix)\n\nprint('Questions1 x Words', tf1_idf_matrix.shape)\nprint('Questions2 x Words', tf2_idf_matrix.shape)\n#als je similariteit wilt zien...\n#print('Q similarity',tf1_idf_matrix[:10].dot(tf2_idf_matrix[:10].T) )\n\nprint(tf1_idf_matrix[:10].dot(tf2_idf_matrix[:10].T).diagonal())\nprint(train[:10].question1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a9421af-68dd-cf36-9aa8-a3495889428d"},"outputs":[],"source":"test = pd.read_csv('../input/test.csv')[:50000]\n#we dont' need the complete training set to do this tfidf comparison !\n\ntest=test.dropna(axis=0, how='any')\ntest['test']=test['question1']+' '+test['question2']  # leeg prevents sum of two questions sentence is empty\ntesttit=test[test['test']>'']  # remove all empties\n\ncount_vectorizer = CountVectorizer()\ncount_vectorizer.fit_transform(testtit['test'])  #Learn vocabulary and idf, return term-document matrix.\nfreq_term_matrix = count_vectorizer.transform(testtit['test']) #Transform documents to document-term matrix. Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform) This is equivalent to fit followed by transform\n\n# Lets redo it but splitted... and use the existing vocabulary\n\ncount3_vectorizer = CountVectorizer(vocabulary=count_vectorizer.vocabulary_)\ncount3_vectorizer.fit_transform(test['question1'])  #Learn vocabulary and idf, return term-document matrix.\nfreq3_term_matrix = count_vectorizer.transform(test['question1'])\ncount4_vectorizer = CountVectorizer(vocabulary=count_vectorizer.vocabulary_)\ncount4_vectorizer.fit_transform(test['question2'])\nfreq4_term_matrix = count_vectorizer.transform(test['question2']) #Transform documents to document-term matrix. Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform) This is equivalent to fit followed by transform\n\n\ntfidf3 = TfidfTransformer(norm=\"l2\")\ntf3_idf_matrix = tfidf3.fit_transform(freq3_term_matrix)\ntfidf4 = TfidfTransformer(norm=\"l2\")\ntf4_idf_matrix = tfidf4.fit_transform(freq4_term_matrix)\n\nprint('Test Questions1 x Words', tf3_idf_matrix.shape)\nprint('Test Questions2 x Words', tf4_idf_matrix.shape)\n#als je similariteit wilt zien...\n#print('Q similarity',tf1_idf_matrix[:10].dot(tf2_idf_matrix[:10].T) )\n\nprint(tf3_idf_matrix.dot(tf4_idf_matrix.T).diagonal().round(2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e5be977-be43-8cdd-8fd1-d42532cb3883"},"outputs":[],"source":"count_vectorizer.vocabulary_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2af29485-12c1-69f4-ddf1-95dcb3c2a340"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\nimport nltk\nfrom nltk import word_tokenize\nimport re\n\nfrom sklearn.model_selection import train_test_split as tts\nfrom gensim.models import doc2vec\nimport gensim\nimport json\n\nimport sys\n\nSTOP_WORDS = nltk.corpus.stopwords.words()\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"423ff90d-a2f2-c82e-ee0a-988e6124d399"},"source":"Okay, learning from my previous venture [Cosine Similarity using TFIDF Weighting](https://www.kaggle.com/antriksh5235/quora-question-pairs/cosine-similarity-using-tfidf-weighting) I decided it was best to drop the questions less than a length of 10 and the stop words in sentences in order to avoid a lot of computation.\n\nThe following function was written to take care of all of this."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48990403-3d04-bdfe-4738-1d800e358575"},"outputs":[],"source":"def clean_sentence(sent):\n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', sent).lower()\n    sentence = sentence.split(\" \")\n\n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)\n\n    sentence = \" \".join(sentence)\n    return sentence"},{"cell_type":"markdown","metadata":{"_cell_guid":"de36e97b-9e56-5a1f-dbe1-e6bc1ff8841f"},"source":"this simplifies abit the calculation, and gives the same result, there are more than ten different similarities calculations"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b86f7b9-3c44-b104-08d2-75e9a8ce3e17"},"outputs":[],"source":"import math\nimport numpy as np\n\ndef cosine(v1, v2):\n    \"\"\"\n            v1 and v2 are two vectors (can be list of numbers) of the same dimensions. Function returns the cosine distance between those\n            which is the ratio of the dot product of the vectors over their RS.\n    \"\"\"\n    v1 = np.array(v1)\n    v2 = np.array(v2)\n\n    return np.dot(v1, v2.T) / np.dot(abs(v1),abs(v2.T))"},{"cell_type":"markdown","metadata":{"_cell_guid":"616d2f6d-f0a7-c220-a438-5b847f55593c"},"source":"This one is simple enough, just dropping all the nans."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb37f664-0de3-3682-57fa-c6c36a660c8b"},"outputs":[],"source":"data = pd.read_csv('../input/train.csv')\ndata = data.dropna(how=\"any\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"770e9baa-7994-cc39-b0a8-394513dfbbff"},"source":"I was first going for merging the two sentence sets into one so that the system is trained over all the words/sentences/document vectors and I would not be able to do it without concatenating both of these."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"872959f4-93e1-a9fc-b7d4-4bc9c0d7f758"},"outputs":[],"source":"def concatenate(data):\n    X_set1 = data['question1']\n    X_set2 = data['question2']\n#    y = data['is_duplicate']\n    X = X_set1.append(X_set2, ignore_index=True)\n    \n    return X"},{"cell_type":"markdown","metadata":{"_cell_guid":"1361451a-019b-c4ac-c7d9-26a1662e9909"},"source":"The above method is being run here to clean the sentences one by one."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71e1bd01-47b1-1f65-7514-7b1d84a25826"},"outputs":[],"source":"print('Cleaning data, this might take long')\nfor col in ['question1', 'question2']:\n    data[col] = data[col].apply(clean_sentence)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f181ca9f-0d88-2249-1bdc-2d4fe44a8dca"},"source":"I am splitting into training and testing set for now. The test given with this competition is very large and I only want to use it once I have tested out implementations."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01f6829c-64a5-16af-708d-deab5f8d6fe9"},"outputs":[],"source":"print('Splitting data to train and test sets.')\ny = data['is_duplicate']\nX_train, X_test, y_train, y_test = tts(data[['id','question1', 'question2']], y, test_size=0.3)\n\nX_train.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ea0cea74-c816-c97c-3914-735239b53987"},"source":"Like I said, I am compiling my understanding of gensim from a lot of sources and one of them used multiprocessing, stating that it might be painfully slow doing otherwise."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"641ffcc6-a532-c879-6ada-04909fd540e7"},"outputs":[],"source":"import multiprocessing\ncores = multiprocessing.cpu_count()\nassert gensim.models.doc2vec.FAST_VERSION > -1\nprint(cores) "},{"cell_type":"markdown","metadata":{"_cell_guid":"cc46a98c-a2b0-da6e-c09e-f8d01180a7b3"},"source":"This is where the initial usage of gensim begins. Notice that I am yielding output from the __iter__ method, which is actually why I wrote this modification of the gensim LabeledLineSentence class. Every question is a document and every document has to be tagged, which is where I am using the id. I might as well start using the question Ids once I figure out how I am going to use the or I'll just append a '_q1' and '_q2' for each to know which is which and compare the same set of questions for every ID.\n\nOnce done, I hope this somehow helps in boosting performance. The only reason I went for doc2vec instead of word2vec was it might be able to capture the semantic relations within the sentence/question."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23e38011-4f5e-5d6f-1fe5-f5301c6f0f03"},"outputs":[],"source":"from gensim.models.doc2vec import Doc2Vec\nfrom gensim.models import doc2vec\nclass LabeledLineSentence(object):\n\n    def __init__(self, doc_list, labels_list):\n        self.labels_list = labels_list\n        self.doc_list = doc_list\n\n    def __iter__(self):\n        for idx, doc in enumerate(self.doc_list):\n            yield doc2vec.TaggedDocument(words=word_tokenize(doc),\n                                         tags=[self.labels_list[idx]])"},{"cell_type":"markdown","metadata":{"_cell_guid":"8b2fbc61-8b0d-c4a9-68d7-fb04e2bc74a8"},"source":"The iterator returns a yield of a TaggedDocument every time the Doc2Vec.build_vocab() function requests it. Had I not given the iterator with the Doc2Vec, I would have to call another model1.build_vocab(it) function just to perform the initialisation. This seemed a quick getaway from writing more lines."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"efb5d33b-7746-84a8-e602-7a23c8f6cec8"},"outputs":[],"source":"X = concatenate(X_train)\nlabels = []\nfor label in X_train['id'].tolist():\n    labels.append('SENT_%s_1' % label)\nfor label in X_train['id'].tolist():\n    labels.append('SENT_%s_2' % label)\n\ndocs = LabeledLineSentence(X.tolist(), labels)\nit = docs.__iter__()\nmodel1 = Doc2Vec(it, size=12, window=8, min_count=5, workers=4)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e6ef8703-311c-ec47-5a4f-9c68174367d7"},"source":"Okay, the more documents you have, the better. To better measure the similarity of documents, it is undoubtable that your model needs to have a very established vector for each.\n\nAlso, instead of running for the normal 10-20 epochs that people usually have for training Doc2vec models, I tried 100 epochs just in case. Let's see how the results turn up on the test sets I extracted."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71276dce-b2a4-ed58-52bb-c773744802bf"},"outputs":[],"source":"for epoch in range(10):\n    model1.train(it, total_examples=model1.corpus_count, epochs=model1.iter)\n    model1.alpha -= 0.0002  # decrease the learning rate\n    model1.min_alpha = model1.alpha  # fix the learning rate, no deca\n    model1.train(it, total_examples=model1.corpus_count, epochs=model1.iter)"},{"cell_type":"markdown","metadata":{"_cell_guid":"dd16fb6a-6e78-3a44-db97-c0395c68192e"},"source":"Now finally for the similarity. I hope it turns out to be some good."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa16d2a3-65ad-ca78-0468-65b8c8d3dad4"},"outputs":[],"source":"X_test.index = np.arange(0, X_test['question1'].shape[0])\ny_test.index = np.arange(0, X_test['question1'].shape[0])\n#print(X_test)\ncount = 0\nfor i in range(X_test['question1'].shape[0]):\n    doc1 = word_tokenize(X_test['question1'][i])\n    doc2 = word_tokenize(X_test['question2'][i])\n    doceq= [w for w in doc1 if w in doc2]\n    docdif1= [w for w in doc1 if w not in doc2]\n    docdif2= [w for w in doc2 if w not in doc1]\n    \n    docvec1 = model1.infer_vector(doc1)\n    docvec2 = model1.infer_vector(doc2)\n    docveced = model1.infer_vector(doceq)\n    docvecdi = model1.infer_vector(docdif1+docdif2)\n\n    #print(docvec1)\n    #print(docvec2)\n\n    print(cosine(docvec1, docvec2), doc1,doc2, y_test[i])\n    print(cosine(docveced, docvecdi), doceq,docdif1,docdif2, y_test[i])\n    print(cosine(docdif1, docdif2), docdif1,docdif2, y_test[i])\n    if count>20:\n        break\n    count+=1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c60b83a4-49f0-bad7-8111-698e4c76aee5"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}