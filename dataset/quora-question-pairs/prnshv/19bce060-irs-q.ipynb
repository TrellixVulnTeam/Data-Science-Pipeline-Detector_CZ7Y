{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<H1> 19BCE060 IRS PRAC3","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nfrom collections import Counter\nfrom nltk import word_tokenize\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T04:30:21.128894Z","iopub.execute_input":"2022-03-10T04:30:21.129214Z","iopub.status.idle":"2022-03-10T04:30:21.134066Z","shell.execute_reply.started":"2022-03-10T04:30:21.129185Z","shell.execute_reply":"2022-03-10T04:30:21.133136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tf","metadata":{}},{"cell_type":"code","source":"def tf(question, word):\n    if word not in question:\n        return 0\n    count = dict(Counter(question))\n    q_len = len(question)\n    return float(count[word]) / float(q_len)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:30:23.581437Z","iopub.execute_input":"2022-03-10T04:30:23.581935Z","iopub.status.idle":"2022-03-10T04:30:23.58797Z","shell.execute_reply.started":"2022-03-10T04:30:23.581877Z","shell.execute_reply":"2022-03-10T04:30:23.586972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def n_containing(qlist, word):\n    return float(qlist[word])\n\ndef idf(qlist, word):\n    return math.log(float(len(qlist.keys())) / (1.0 + n_containing(qlist, word)))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:30:26.653982Z","iopub.execute_input":"2022-03-10T04:30:26.65478Z","iopub.status.idle":"2022-03-10T04:30:26.659847Z","shell.execute_reply.started":"2022-03-10T04:30:26.654739Z","shell.execute_reply":"2022-03-10T04:30:26.658924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tfidf(question, qlist, word):\n    return tf(question, word) * idf(qlist, word)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:30:29.157947Z","iopub.execute_input":"2022-03-10T04:30:29.158388Z","iopub.status.idle":"2022-03-10T04:30:29.162458Z","shell.execute_reply.started":"2022-03-10T04:30:29.158354Z","shell.execute_reply":"2022-03-10T04:30:29.161636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cosine(v1, v2):\n    v1 = np.array(v1)\n    v2 = np.array(v2)\n\n    return np.dot(v1, v2) / (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:30:31.742399Z","iopub.execute_input":"2022-03-10T04:30:31.743503Z","iopub.status.idle":"2022-03-10T04:30:31.749418Z","shell.execute_reply.started":"2022-03-10T04:30:31.743347Z","shell.execute_reply":"2022-03-10T04:30:31.748465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/quora-question-pairs/train.csv.zip')\ntrain_qs = train[['id', 'question1', 'question2', 'is_duplicate']]\nqlist = []\ncount = 0\nfor row in train_qs.itertuples():\n    try:\n        if len(str(row[2])) > 10:\n            q1 = word_tokenize(row[2].lower())\n        if len(str(row[3])) > 10:\n            q2 = word_tokenize(row[3].lower())\n        qlist += q1 + q2\n        count+=1\n        if count%100000 == 0:\n            print('At'+str(count))\n#        qlist.append(q2)\n    except TypeError:\n        pass\nqlist = dict(Counter(qlist))\nimport json\nwith open('qlist.json', 'w') as f:\n    f.write(json.dumps(qlist, indent=2))\nprint('All Questions added to list')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:30:33.607522Z","iopub.execute_input":"2022-03-10T04:30:33.60806Z","iopub.status.idle":"2022-03-10T04:33:15.483407Z","shell.execute_reply.started":"2022-03-10T04:30:33.608025Z","shell.execute_reply":"2022-03-10T04:33:15.482757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('submission.csv', 'a') as f:\n    f.write('id,is_duplicate\\n')\nfor row in train_qs.itertuples():\n    if len(str(row[2])) > 10 and len(str(row[3])) > 10:\n        wordvec1 = word_tokenize(row[2].lower())\n        wordvec2 = word_tokenize(row[3].lower())\n        words = wordvec1 + wordvec2\n        words = list(set([word for word in words if word != '?']))\n\n        # print words\n\n        vec1 = []\n        vec2 = []\n        for word in words:\n            vec1.append(tfidf(wordvec1, qlist, word))\n            vec2.append(tfidf(wordvec2, qlist, word))\n\n        with open('submission.csv', 'a') as f:\n            f.write(str(row[1]) + \",\" + str(cosine(vec1, vec2)) + '\\n')\n    else:\n        with open('submission.csv', 'a') as f:\n            f.write(str(row[1]) + \",\" + '0' + '\\n')\n#    print str(row[1]) + \",\" + str(cosine(vec1, vec2))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:37:31.47545Z","iopub.execute_input":"2022-03-10T04:37:31.475817Z","iopub.status.idle":"2022-03-10T04:42:40.55594Z","shell.execute_reply.started":"2022-03-10T04:37:31.475785Z","shell.execute_reply":"2022-03-10T04:42:40.555086Z"},"trusted":true},"execution_count":null,"outputs":[]}]}