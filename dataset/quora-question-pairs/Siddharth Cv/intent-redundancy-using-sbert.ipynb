{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_colwidth = None\npd.options.display.max_rows = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install -U sentence-transformers\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses, evaluation, util\nfrom torch.utils.data import DataLoader\nimport gc\n\nimport scipy\nfrom sklearn.metrics import accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SentenceTransformer('/kaggle/input/model-weights-sbert-trained-on-these-data/model_mnli/model_mnli/')\n\n#model = SentenceTransformer('/kaggle/input/distilbertbasenlistsbmeantokens/distilbert-base-nli-stsb-mean-tokens/')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.encode(\"hi\").shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/quora-question-pairs/train.csv.zip\")\nprint(train.shape)\n#train['is_duplicate'] = train['is_duplicate'].replace(0,-1)\n\ntrain.head(30)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_train_examples = 121600\nnum_test_examples = 3200\ndistance_metric = \"cosine_distance\"\nnum_epochs = 2\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#help(model.fit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['question1'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = []\nfor row in range(num_train_examples):\n    sample = InputExample(texts=[str(train['question1'][row]), str(train['question2'][row])], \n                          label=int(train['is_duplicate'][row]))\n    train_samples.append(sample)\n\ntrain_dataset = SentencesDataset(train_samples, model=model)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n\ntrain_loss = losses.OnlineContrastiveLoss(model=model, margin=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_samples = num_test_examples\n\nsentences1 = list(train['question1'][-1*test_samples:])\nsentences2 = list(train['question2'][-1*test_samples:])\nscores =  list(train['is_duplicate'][-1*test_samples:].astype('int'))\n\nevaluator1 = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\nevaluator2 = evaluation.BinaryClassificationEvaluator(sentences1, sentences2, scores)\n\n# ... Your other code to load training data\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=50, evaluator=evaluator2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ndef thr_to_accuracy(thr, Y_test, predictions):\n    return -accuracy_score(Y_test, np.array(predictions>thr, dtype=np.int))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COSINE SIM before training\n\n#Compute embedding for both lists\nembeddings1 = model.encode(sentences1, convert_to_tensor=True)\nembeddings2 = model.encode(sentences2, convert_to_tensor=True)\n#Compute cosine-similarits\ncosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n\nprint(pd.DataFrame({\"labels\": scores, 'cosine_sim': np.diag(cosine_scores).tolist()}).groupby(\"labels\").agg({\"cosine_sim\":[\"count\",\"mean\"]}))\n\nbest_thr = scipy.optimize.fmin(thr_to_accuracy, args=(scores, np.diag(cosine_scores)), x0=0.5)\nprint(best_thr)\n\nprint(\"\\n Confusion matrix\")\n# y_pred=np.array(np.diag(cosine_scores) > best_thr).astype(\"int\").tolist()\nprint(confusion_matrix(y_true = scores, y_pred = np.array(np.diag(cosine_scores) > best_thr).astype(\"int\").tolist() ))\n\npred_before = np.array(np.diag(cosine_scores) > best_thr).astype(\"int\").tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train\ngc.collect()\n#np.diag(cosine_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_objectives=[(train_dataloader, train_loss)], epochs= num_epochs, warmup_steps=100, evaluator=evaluator2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COSINE SIM After training\n#Compute embedding for both lists\nembeddings1 = model.encode(sentences1, convert_to_tensor=True)\nembeddings2 = model.encode(sentences2, convert_to_tensor=True)\n#Compute cosine-similarits\ncosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\npd.DataFrame({\"labels\": scores, 'cosine_sim': np.diag(cosine_scores).tolist()}).groupby(\"labels\").agg({\"cosine_sim\":[\"count\",\"mean\"]})\n\nbest_thr = scipy.optimize.fmin(thr_to_accuracy, args=(scores, np.diag(cosine_scores)), x0=0.5)\nprint(best_thr)\nprint(\"\\n Confusion matrix\")\nprint(confusion_matrix(y_true = scores, y_pred = np.array(np.diag(cosine_scores) > best_thr).astype(\"int\").tolist() ))\n\npred_aft = np.array(np.diag(cosine_scores) > best_thr).astype(\"int\").tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_aft","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"log_loss:\", metrics.log_loss(y_true = scores, y_pred = pred_aft, eps=1e-15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred = tf.maximum(pred_aft, 1e-15)\n# # Compute the log loss\n# log_loss = -tf.reduce_sum(y_true * tf.log(y_pred), axis=-1)\n# print(log_loss )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"classification_report:\", metrics.classification_report(y_true = scores, y_pred = np.array(np.diag(cosine_scores) > best_thr).astype(\"int\").tolist() ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Log loss on Test Data using Random Model\",log_loss(scores, np.diag(cosine_scores), eps=1e-15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The test log loss is:\",log_loss(scores, pred_aft, labels=clf.classes_, eps=1e-15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_cm(y_true, y_pred, figsize=(10,10)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm / cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n    \nplot_cm(scores, y_pred = np.array(np.diag(cosine_scores) > best_thr).astype(\"int\").tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Error Analysis\n\npred_df = pd.DataFrame({  \"sentences1\":sentences1,\n                          \"sentences2\":sentences2,\n                          \"y_true\":scores,\n                          \"y_pred_before\":pred_before,\n                          \"y_pred_after\":pred_aft})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pred_df[(pred_df.y_true != pred_df.y_pred_before) & \n              (pred_df.y_true == pred_df.y_pred_after) ].reset_index(drop=True).head(50).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pred_df[(pred_df.y_true != pred_df.y_pred_before) & \n              (pred_df.y_true != pred_df.y_pred_after) ].reset_index(drop=True).head(50).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"which is the best mobile phone under 20000rs\"\nq2=\"which mobile is the best between 10000rs and 20000rs\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1_p=[]\nq1_p.append(q1)\nq2_p=[]\nq2_p.append(q2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_1 = model.encode(q1_p, convert_to_tensor=True)\nembeddings_2 = model.encode(q2_p, convert_to_tensor=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cosine_scores = util.pytorch_cos_sim(embeddings_1, embeddings_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cosine_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"How to toast a bread\"\nq2=\"What is the procedure to make a bread toast\"\nprint(predict(q1,q2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"which is the best mobile phone under 20000rs\"\nq2=\"which is the best phone between 10000rs and 20000rs\"\nprint(predict(q1,q2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"where is the india gate located\"\nq2=\"where is taj mahal located\"\nprint(predict(q1,q2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport nltk\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/train2/train (2).csv', nrows=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting every character to lower case\ndocs=train['question_text'].str.lower()\nprint(docs.head())\nprint('\\n')\n\n#Remove non-alphabets\ndocs.str.replace('[^a-z ]','')\nprint(docs.head())\nprint('\\n')\n\n#Remove commonly used words\nfrom nltk.corpus import stopwords\nstopwords=nltk.corpus.stopwords.words('english')\nstemmer=nltk.stem.PorterStemmer()\nprint(stopwords)\nprint('\\n')\n\ndef clean_sentence(doc):\n    words=doc.split(' ')\n    words_clean=[stemmer.stem(word) for word in words if word not in stopwords]\n    return ' '.join(words_clean)\n    print(words_clean)\n    \ndocs=docs.apply(clean_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\ndtm_vectorizer = CountVectorizer()\n\n\ntrain_x,validate_x, train_y,validate_y = train_test_split(docs, train['target'], test_size = 0.2, random_state = 1)\ndtm_vectorizer.fit(train_x)\ndtm_train = dtm_vectorizer.transform(train_x)\ndtm_validate = dtm_vectorizer.transform(validate_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dtm_train = pd.DataFrame(dtm_train.toarray(),columns=dtm_vectorizer.get_feature_names(),index=train_x.index)\ndf_dtm_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dtm_train.sum().sort_values(ascending=False).head(20).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel2=MultinomialNB().fit(dtm_train,train_y)\ntrain_y_pred=model2.predict(dtm_validate)\n\nfrom sklearn.metrics import accuracy_score,f1_score\nprint(accuracy_score(validate_y,train_y_pred))\nprint(f1_score(validate_y,train_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=[\"How do I marry an American woman for a Green Card? How much do they charge?\"]\nta = dtm_vectorizer.transform(a)\nt=model2.predict(ta)\nif t==1:\n    print(\"Insincere question\")\nelse:\n    print(\"Sincere question\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=[\"if I'm creating an app using multiple programming languages, can I use the same IDE?\"]\nta = dtm_vectorizer.transform(a)\nt=model2.predict(ta)\nif t==1:\n    print(\"Insincere question\")\nelse:\n    print(\"Sincere question\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(q1,q2):\n    q1_p=[]\n    q1_p.append(q1)\n    q2_p=[]\n    q2_p.append(q2)\n    t1=dtm_vectorizer.transform(q1_p)\n    t_1=model2.predict(t1)\n    t2=dtm_vectorizer.transform(q2_p)\n    t_2=model2.predict(t2)\n    if t_1==1:\n        print(\"Question 1 is insincere\")\n    else:\n        print(\"Question 1 is sincere\")\n    if t_2==1:\n        print(\"Question 2 is insincere\")\n    else:\n        print(\"Question 2 is sincere\")\n    embeddings_1 = model.encode(q1_p, convert_to_tensor=True)\n    embeddings_2 = model.encode(q2_p, convert_to_tensor=True)\n    cosine_scores = util.pytorch_cos_sim(embeddings_1, embeddings_2)\n    if(cosine_scores>0.81):\n        return \"Similar Questions\"\n    else:\n        return \"Different Questions\"    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"which is the cheapest flight to chennai \"\nq2=\"which is the cheapest flight to delhi\"\nans=predict(q1,q2)\nprint(ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"How do I marry an American woman for a Green Card? How much do they charge?\"\nq2=\"What are the different ways to get a green card in america?\"\nans=predict(q1,q2)\nprint(ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"which is the best mobile phone under 20000rs\"\nq2=\"which is the best phone between 10000rs and 20000rs\"\nprint(predict(q1,q2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"where is the india gate located\"\nq2=\"where is taj mahal located\"\nprint(predict(q1,q2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1=\"How to toast a bread\"\nq2=\"What is the procedure to make a bread toast\"\nprint(predict(q1,q2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}