{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/quora-question-pairs/train.csv.zip')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:14.76596Z","iopub.execute_input":"2021-09-09T20:10:14.766572Z","iopub.status.idle":"2021-09-09T20:10:17.516235Z","shell.execute_reply.started":"2021-09-09T20:10:14.766457Z","shell.execute_reply":"2021-09-09T20:10:17.515115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.51784Z","iopub.execute_input":"2021-09-09T20:10:17.518264Z","iopub.status.idle":"2021-09-09T20:10:17.546265Z","shell.execute_reply.started":"2021-09-09T20:10:17.518189Z","shell.execute_reply":"2021-09-09T20:10:17.545071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.548712Z","iopub.execute_input":"2021-09-09T20:10:17.549146Z","iopub.status.idle":"2021-09-09T20:10:17.556561Z","shell.execute_reply.started":"2021-09-09T20:10:17.5491Z","shell.execute_reply":"2021-09-09T20:10:17.55525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info() # some values are missing from the 'question2' column","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.558583Z","iopub.execute_input":"2021-09-09T20:10:17.558893Z","iopub.status.idle":"2021-09-09T20:10:17.640913Z","shell.execute_reply.started":"2021-09-09T20:10:17.558844Z","shell.execute_reply":"2021-09-09T20:10:17.639845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.question2.isnull().sum() # since very few values are missing from this column hence it's better to remove both the rows.","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.643928Z","iopub.execute_input":"2021-09-09T20:10:17.644235Z","iopub.status.idle":"2021-09-09T20:10:17.678186Z","shell.execute_reply.started":"2021-09-09T20:10:17.644192Z","shell.execute_reply":"2021-09-09T20:10:17.677036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**let's see if the classes are balanced or not**","metadata":{}},{"cell_type":"code","source":"df['is_duplicate'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.679448Z","iopub.execute_input":"2021-09-09T20:10:17.679797Z","iopub.status.idle":"2021-09-09T20:10:17.697678Z","shell.execute_reply.started":"2021-09-09T20:10:17.679753Z","shell.execute_reply":"2021-09-09T20:10:17.696486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**https://stackoverflow.com/questions/26476668/frequency-plot-in-python-pandas-dataframe**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas\n\nfig, ax = plt.subplots() # plt.subplots() is a function that returns a tuple containing a figure and axes object(s).\n\ndf['is_duplicate'].value_counts().plot(ax=ax, kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.699102Z","iopub.execute_input":"2021-09-09T20:10:17.699442Z","iopub.status.idle":"2021-09-09T20:10:17.874635Z","shell.execute_reply.started":"2021-09-09T20:10:17.699409Z","shell.execute_reply":"2021-09-09T20:10:17.873468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**https://stackoverflow.com/questions/34162443/why-do-many-examples-use-fig-ax-plt-subplots-in-matplotlib-pyplot-python**","metadata":{}},{"cell_type":"code","source":"df.groupby(\"is_duplicate\").count() \n# It will select all the columns present inside df and then it will group accoridng to 'is_duplicate'","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.87602Z","iopub.execute_input":"2021-09-09T20:10:17.876326Z","iopub.status.idle":"2021-09-09T20:10:17.980468Z","shell.execute_reply.started":"2021-09-09T20:10:17.876294Z","shell.execute_reply":"2021-09-09T20:10:17.979701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['id','is_duplicate']].groupby(['is_duplicate']).count()\n# This will first select two columns from df and then will group them according to 'is_duplicate' .","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:17.982351Z","iopub.execute_input":"2021-09-09T20:10:17.98271Z","iopub.status.idle":"2021-09-09T20:10:18.002867Z","shell.execute_reply.started":"2021-09-09T20:10:17.982681Z","shell.execute_reply":"2021-09-09T20:10:18.002002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['id','is_duplicate']].groupby(['is_duplicate']).count().plot.bar() \n# This will first select three columns from df and then will group them according to 'is_duplicate' and then it will plot","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:18.004847Z","iopub.execute_input":"2021-09-09T20:10:18.005135Z","iopub.status.idle":"2021-09-09T20:10:18.150782Z","shell.execute_reply.started":"2021-09-09T20:10:18.005102Z","shell.execute_reply":"2021-09-09T20:10:18.150023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(\"is_duplicate\")['id'].count().plot.bar()\n# selecting all columns from df then grouping them according to 'is_duplicate' and then accordingly counting the 'id' column\n# as 'id' would be unique of every pair","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:18.151776Z","iopub.execute_input":"2021-09-09T20:10:18.152166Z","iopub.status.idle":"2021-09-09T20:10:18.278112Z","shell.execute_reply.started":"2021-09-09T20:10:18.152136Z","shell.execute_reply":"2021-09-09T20:10:18.277403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['id','is_duplicate']].groupby('is_duplicate').count().plot.bar()\n# selecting the column that are required to plot\n# remeber we need numeric data to plot\n# df[[is_duplicate']].groupby('is_duplicate').count().plot.bar() , will result in an error","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:18.279054Z","iopub.execute_input":"2021-09-09T20:10:18.279437Z","iopub.status.idle":"2021-09-09T20:10:18.423541Z","shell.execute_reply.started":"2021-09-09T20:10:18.279408Z","shell.execute_reply":"2021-09-09T20:10:18.422738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.countplot(x = 'is_duplicate',data = df) # This is simplest and elgant","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:18.424557Z","iopub.execute_input":"2021-09-09T20:10:18.424948Z","iopub.status.idle":"2021-09-09T20:10:19.43953Z","shell.execute_reply.started":"2021-09-09T20:10:18.424918Z","shell.execute_reply":"2021-09-09T20:10:19.438461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = df.is_duplicate) # another way since we want to plot only one column so why providing whole data","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:19.442671Z","iopub.execute_input":"2021-09-09T20:10:19.442992Z","iopub.status.idle":"2021-09-09T20:10:19.585776Z","shell.execute_reply.started":"2021-09-09T20:10:19.442961Z","shell.execute_reply":"2021-09-09T20:10:19.584646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\n~> Question pairs are Similar (is_duplicate = 1):\\n   {}%'.format(round(df['is_duplicate'].mean()*100, 2)) )\n# we can use for loop too\nprint('\\n~> Question pairs are Similar (is_duplicate = 1):\\n   {}%'.format(100 - round(df['is_duplicate'].mean()*100, 2)))\n# just subtract from 100 to get the percentage of other class","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:19.587356Z","iopub.execute_input":"2021-09-09T20:10:19.587769Z","iopub.status.idle":"2021-09-09T20:10:19.596039Z","shell.execute_reply.started":"2021-09-09T20:10:19.587726Z","shell.execute_reply":"2021-09-09T20:10:19.594951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Number of Unique Questions**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nqids = pd.Series( df['qid1'].tolist() + df['qid2'].tolist() )\nunique_questions = len(qids.unique())\nprint(\"Total Number of Unique Questions {}\".format(unique_questions))\n\nrepeated_questions = np.sum(qids.value_counts()>1) # value_counts gives the count of every category\nprint(\"Total Number of Unique Questions are {}({})\\n\".format(repeated_questions,repeated_questions/unique_questions*100))\n\nq_vals = qids.value_counts() # contains frequncy of every question\nprint(\"Maximum Number of times one question is repeated is {}\\n\".format(max(q_vals)) )\n\n\n# print(type(q_vals),q_vals.shape) # two columns one containing category other containing it's occurence\n# print(q_vals)\n# q_vals = q_vals.values # Return Series as ndarray or ndarray-like depending on the dtype\n# print(q_vals)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:19.597329Z","iopub.execute_input":"2021-09-09T20:10:19.597601Z","iopub.status.idle":"2021-09-09T20:10:20.057558Z","shell.execute_reply.started":"2021-09-09T20:10:19.597573Z","shell.execute_reply":"2021-09-09T20:10:20.056883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_axis = ['Unique Questions','Repeated Questions']\ny_axis = [unique_questions,repeated_questions]\n\nplt.figure(figsize=(10,6))\nplt.title (\" Plot representing unique and repeated questions  \")\nsns.barplot(x = x_axis,y= y_axis)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:20.058483Z","iopub.execute_input":"2021-09-09T20:10:20.058848Z","iopub.status.idle":"2021-09-09T20:10:20.174948Z","shell.execute_reply.started":"2021-09-09T20:10:20.05882Z","shell.execute_reply":"2021-09-09T20:10:20.1738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking for Duplicates","metadata":{}},{"cell_type":"code","source":"pair_duplicates = df[['qid1','qid2','is_duplicate']].groupby(['qid1','qid2']).count().reset_index()\nprint(pair_duplicates.head())\nprint(\"Number of Duplicate Questions are :- \",df.shape[0] - pair_duplicates.shape[0]) # Finding the Difference in number of rows","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:20.176177Z","iopub.execute_input":"2021-09-09T20:10:20.176475Z","iopub.status.idle":"2021-09-09T20:10:20.47Z","shell.execute_reply.started":"2021-09-09T20:10:20.176446Z","shell.execute_reply":"2021-09-09T20:10:20.468918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of occurrences of each Question","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20,5))\nplt.hist(qids.value_counts()) # If bins is an integer, it defines the number of equal-width bins in the range.by def 10 bins\n\nplt.yscale(\"log\")# setting the y-axis scale to log\n\nplt.title('Log-Histogram of question appearance counts')\n\nplt.xlabel('Number of occurences of question')\n\nplt.ylabel('Number of questions')\n\nprint ('Maximum number of times a single question is repeated: {}\\n'.format(max(qids.value_counts()))) ","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:20.471318Z","iopub.execute_input":"2021-09-09T20:10:20.471589Z","iopub.status.idle":"2021-09-09T20:10:21.465054Z","shell.execute_reply.started":"2021-09-09T20:10:20.471561Z","shell.execute_reply":"2021-09-09T20:10:21.463921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,6))\nplt.hist(qids.value_counts(),bins = 160) \nplt.yscale(\"log\",nonpositive = 'clip')# Any nonpositive value will be clipped to a number very close to 0 or 1\n\nplt.title('Log-Histogram of question appearance counts',fontsize = 15)\n\nplt.xlabel('Number of occurences of Question',fontsize = 15)\n\nplt.ylabel('Number of Questions',fontsize = 15)\n\nprint ('Maximum number of times a single Question is repeated: {}\\n'.format(max(qids.value_counts()))) ","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:21.466477Z","iopub.execute_input":"2021-09-09T20:10:21.466787Z","iopub.status.idle":"2021-09-09T20:10:22.520096Z","shell.execute_reply.started":"2021-09-09T20:10:21.46673Z","shell.execute_reply":"2021-09-09T20:10:22.518971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking for Null Values","metadata":{}},{"cell_type":"code","source":"nan_rows = df[df.isnull().any(axis = 1)] # it will filter row by row instead column by column\nprint (nan_rows)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:22.521443Z","iopub.execute_input":"2021-09-09T20:10:22.521723Z","iopub.status.idle":"2021-09-09T20:10:22.58956Z","shell.execute_reply.started":"2021-09-09T20:10:22.521694Z","shell.execute_reply":"2021-09-09T20:10:22.588357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling the null values with ' '\ndf = df.fillna('')\nnan_rows = df[df.isnull().any(1)] \n#  when the text column is missing, we have to drop those rows.but here we are just filling because only two rows are missing.\nprint (nan_rows)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:22.590706Z","iopub.execute_input":"2021-09-09T20:10:22.59117Z","iopub.status.idle":"2021-09-09T20:10:22.765465Z","shell.execute_reply.started":"2021-09-09T20:10:22.591131Z","shell.execute_reply":"2021-09-09T20:10:22.764736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Basic Feature Extraction (before cleaning) </h2>","metadata":{}},{"cell_type":"markdown","source":"Let us now construct a few features like:\n - **freq_qid1** = Frequency of qid1's\n - ____freq_qid2____ = Frequency of qid2's \n - ____q1len____ = Length of q1 (string length)\n - ____q2len____ = Length of q2\n - ____q1_n_words____ = Number of words in Question 1\n - ____q2_n_words____ = Number of words in Question 2\n - ____word_Common____ = (Number of common unique words in Question 1 and Question 2)\n - ____word_Total____ =(Total num of words in Question 1 + Total num of words in Question 2)\n - ____word_share____ = (word_common)/(word_Total)\n - ____freq_q1+freq_q2____ = sum total of frequency of qid1 and qid2 \n - ____freq_q1-freq_q2____ = absolute difference of frequency of qid1 and qid2 ","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:22.766421Z","iopub.execute_input":"2021-09-09T20:10:22.766803Z","iopub.status.idle":"2021-09-09T20:10:22.777733Z","shell.execute_reply.started":"2021-09-09T20:10:22.766774Z","shell.execute_reply":"2021-09-09T20:10:22.776775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**https://pbpython.com/pandas_transform.html**","metadata":{}},{"cell_type":"code","source":"df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count') # where count is the function that would be applied to each group.\ndf['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count') \n\nprint(df[['freq_qid1','freq_qid2']]) #  here 0th column  is Index of original data Frame","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:22.779403Z","iopub.execute_input":"2021-09-09T20:10:22.779787Z","iopub.status.idle":"2021-09-09T20:10:22.941097Z","shell.execute_reply.started":"2021-09-09T20:10:22.779745Z","shell.execute_reply":"2021-09-09T20:10:22.940137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['q1len'] = df['question1'].str.len() # length of the questions\ndf['q2len'] = df['question2'].str.len()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:22.942324Z","iopub.execute_input":"2021-09-09T20:10:22.942605Z","iopub.status.idle":"2021-09-09T20:10:23.327853Z","shell.execute_reply.started":"2021-09-09T20:10:22.942575Z","shell.execute_reply":"2021-09-09T20:10:23.326748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['q1_n_words'] = df['question1'].apply(lambda row : len(row.split(\" \")) ) # finding the number of words in a question\ndf['q2_n_words'] = df['question2'].apply(lambda row : len(row.split(\" \")) )","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:23.329337Z","iopub.execute_input":"2021-09-09T20:10:23.329756Z","iopub.status.idle":"2021-09-09T20:10:24.12995Z","shell.execute_reply.started":"2021-09-09T20:10:23.329711Z","shell.execute_reply":"2021-09-09T20:10:24.128812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['question1','q1len','freq_qid1','question2','q2len','freq_qid2']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:24.132849Z","iopub.execute_input":"2021-09-09T20:10:24.13318Z","iopub.status.idle":"2021-09-09T20:10:24.184809Z","shell.execute_reply.started":"2021-09-09T20:10:24.133145Z","shell.execute_reply":"2021-09-09T20:10:24.183881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalized_word_Common(row):\n    \n    q1 = set( map ( lambda word : word.lower().strip() , row['question1'].split(\" \") ))\n    q2 = set( map ( lambda word : word.lower().strip() , row['question2'].split(\" \") ))\n    \n#     print(len(q1 and q2 ))\n#     print(len(q1  &  q2 ))        \n#     print(len(q1.intersection(q2)))\n    \n    return 1.0 * len(q1.intersection(q2))\n\ndf['word_Common'] = df.apply(normalized_word_Common,axis = 1) # applying function along column","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:10:24.18609Z","iopub.execute_input":"2021-09-09T20:10:24.186398Z","iopub.status.idle":"2021-09-09T20:10:32.752117Z","shell.execute_reply.started":"2021-09-09T20:10:24.186368Z","shell.execute_reply":"2021-09-09T20:10:32.750847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:12:11.314967Z","iopub.execute_input":"2021-09-09T20:12:11.315349Z","iopub.status.idle":"2021-09-09T20:12:11.333558Z","shell.execute_reply.started":"2021-09-09T20:12:11.315315Z","shell.execute_reply":"2021-09-09T20:12:11.33245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}