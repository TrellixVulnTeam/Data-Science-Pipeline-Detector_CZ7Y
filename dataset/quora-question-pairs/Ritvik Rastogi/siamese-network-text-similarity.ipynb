{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tqdm.auto import tqdm\n\ntqdm.pandas()\npd.options.display.max_colwidth = None\nsns.set_style('darkgrid')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T12:04:16.467316Z","iopub.execute_input":"2021-12-18T12:04:16.467814Z","iopub.status.idle":"2021-12-18T12:04:22.586779Z","shell.execute_reply.started":"2021-12-18T12:04:16.467725Z","shell.execute_reply":"2021-12-18T12:04:22.580018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtrain = pd.read_csv('../input/quora-question-pairs/train.csv.zip')\nprint(dtrain.shape)\ndtrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:04:22.590134Z","iopub.execute_input":"2021-12-18T12:04:22.596646Z","iopub.status.idle":"2021-12-18T12:04:25.056856Z","shell.execute_reply.started":"2021-12-18T12:04:22.596581Z","shell.execute_reply":"2021-12-18T12:04:25.055579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtest = pd.read_csv('../input/quora-question-pairs/test.csv')\nprint(dtest.shape)\ndtest.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:04:25.058717Z","iopub.execute_input":"2021-12-18T12:04:25.059512Z","iopub.status.idle":"2021-12-18T12:04:32.961198Z","shell.execute_reply.started":"2021-12-18T12:04:25.059441Z","shell.execute_reply":"2021-12-18T12:04:32.959886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Cleaning","metadata":{}},{"cell_type":"code","source":"%%time\n\nall_ques = pd.read_csv('../input/qqp-cleaned/quora-ques-pair-all-ques.csv')\nall_ques.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:04:32.96288Z","iopub.execute_input":"2021-12-18T12:04:32.963535Z","iopub.status.idle":"2021-12-18T12:04:45.816174Z","shell.execute_reply.started":"2021-12-18T12:04:32.963479Z","shell.execute_reply":"2021-12-18T12:04:45.814815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntext_map = {x:y for x, y in zip(all_ques['RawText'].values, all_ques['CleanedText'].values)}\n\ndtrain['question1'] = dtrain['question1'].apply(lambda x: text_map[x])\ndtrain['question2'] = dtrain['question2'].apply(lambda x: text_map[x])\n\ndtest['question1'] = dtest['question1'].apply(lambda x: text_map[x])\ndtest['question2'] = dtest['question2'].apply(lambda x: text_map[x])\n\ndel text_map","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:04:45.820467Z","iopub.execute_input":"2021-12-18T12:04:45.820782Z","iopub.status.idle":"2021-12-18T12:04:53.377631Z","shell.execute_reply.started":"2021-12-18T12:04:45.82075Z","shell.execute_reply":"2021-12-18T12:04:53.375359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.01, random_state=19)\ntrain_index, valid_index = list(sss.split(dtrain[['question1', 'question2']].values, dtrain['is_duplicate']))[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:04:53.379908Z","iopub.execute_input":"2021-12-18T12:04:53.38034Z","iopub.status.idle":"2021-12-18T12:04:53.843646Z","shell.execute_reply.started":"2021-12-18T12:04:53.380293Z","shell.execute_reply":"2021-12-18T12:04:53.842659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\ndef evaluate_model(model, x_train, x_valid, y_train, y_valid):\n    print('Train Set:')\n    print()\n    print(classification_report(y_train, model.predict(x_train)))\n    \n    print()\n    print()\n    \n    print('Validation Set:')\n    print()\n    print(classification_report(y_valid, model.predict(x_valid)))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:04:53.846285Z","iopub.execute_input":"2021-12-18T12:04:53.846606Z","iopub.status.idle":"2021-12-18T12:04:53.854076Z","shell.execute_reply.started":"2021-12-18T12:04:53.846575Z","shell.execute_reply":"2021-12-18T12:04:53.852578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vectorization","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(\n    ngram_range=(1, 1),\n    min_df=1,\n    max_df=1.0,\n    sublinear_tf=True\n).fit(all_ques['CleanedText'].fillna('').values)\n\nx_train = dtrain[['question1', 'question2']].iloc[train_index].reset_index(drop=True)\nx_valid = dtrain[['question1', 'question2']].iloc[valid_index].reset_index(drop=True)\n\ny_train = dtrain['is_duplicate'].iloc[train_index].reset_index(drop=True).values\ny_valid = dtrain['is_duplicate'].iloc[valid_index].reset_index(drop=True).values\n\ndel all_ques\n\ny_train.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:04:53.855572Z","iopub.execute_input":"2021-12-18T12:04:53.856053Z","iopub.status.idle":"2021-12-18T12:05:47.081707Z","shell.execute_reply.started":"2021-12-18T12:04:53.855995Z","shell.execute_reply":"2021-12-18T12:05:47.080575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sparse_tensor(X):\n    coo = X.tocoo()\n    indices = np.mat([coo.row, coo.col]).transpose()\n    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:05:47.083357Z","iopub.execute_input":"2021-12-18T12:05:47.083838Z","iopub.status.idle":"2021-12-18T12:05:47.091748Z","shell.execute_reply.started":"2021-12-18T12:05:47.083793Z","shell.execute_reply":"2021-12-18T12:05:47.090332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfrom scipy import sparse\n\nx_train_1 = vectorizer.transform(x_train['question1'].fillna(''))\nx_train_2 = vectorizer.transform(x_train['question2'].fillna(''))\n\nx_valid_1 = vectorizer.transform(x_valid['question1'].fillna(''))\nx_valid_2 = vectorizer.transform(x_valid['question2'].fillna(''))\n\nx_test_1 = vectorizer.transform(dtest['question1'].fillna(''))\nx_test_2 = vectorizer.transform(dtest['question2'].fillna(''))\n\nx_train = [sparse_tensor(x_train_1), sparse_tensor(x_train_2)]\nx_valid = [sparse_tensor(x_valid_1), sparse_tensor(x_valid_2)]\nx_test = [sparse_tensor(x_test_1), sparse_tensor(x_test_2)]\n\nx = [\n    sparse_tensor(sparse.vstack([x_train_1, x_valid_1])), \n    sparse_tensor(sparse.vstack([x_train_2, x_valid_2]))\n]\ny = np.concatenate([y_train, y_valid])\n\ndel x_train_1, x_train_2, x_valid_1, x_valid_2, x_test_1, x_test_2\n\nx_train[0].shape, x_valid[0].shape, x_test[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:05:47.09352Z","iopub.execute_input":"2021-12-18T12:05:47.094044Z","iopub.status.idle":"2021-12-18T12:06:55.719007Z","shell.execute_reply.started":"2021-12-18T12:05:47.093995Z","shell.execute_reply":"2021-12-18T12:06:55.71623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras import layers, utils, callbacks, optimizers, regularizers","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:06:55.720816Z","iopub.execute_input":"2021-12-18T12:06:55.721275Z","iopub.status.idle":"2021-12-18T12:06:55.727558Z","shell.execute_reply.started":"2021-12-18T12:06:55.72123Z","shell.execute_reply":"2021-12-18T12:06:55.726302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def euclidean_distance(vectors):\n    (featsA, featsB) = vectors\n    sumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n\ndef cosine_similarity(vectors):\n    (featsA, featsB) = vectors\n    featsA = K.l2_normalize(featsA, axis=-1)\n    featsB = K.l2_normalize(featsB, axis=-1)\n    return K.mean(featsA * featsB, axis=-1, keepdims=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:06:55.729616Z","iopub.execute_input":"2021-12-18T12:06:55.730173Z","iopub.status.idle":"2021-12-18T12:06:55.740422Z","shell.execute_reply.started":"2021-12-18T12:06:55.730126Z","shell.execute_reply":"2021-12-18T12:06:55.738871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseNetwork(Model):\n    def __init__(self, inputShape, featExtractorConfig):\n        super(SiameseNetwork, self).__init__()\n        \n        inpA = layers.Input(shape=inputShape)\n        inpB = layers.Input(shape=inputShape)\n        featureExtractor = self.build_feature_extractor(inputShape, featExtractorConfig)\n        featsA = featureExtractor(inpA)\n        featsB = featureExtractor(inpB)\n        distance = layers.Concatenate()([featsA, featsB])\n        outputs = layers.Dense(1, activation=\"sigmoid\")(distance)\n        self.model = Model(inputs=[inpA, inpB], outputs=outputs)        \n        \n    def build_feature_extractor(self, inputShape, featExtractorConfig):\n        \n        layers_config = [layers.Input(inputShape)]\n        for i, n_units in enumerate(featExtractorConfig):\n            layers_config.append(layers.Dense(n_units))\n            layers_config.append(layers.Dropout(0.5))\n            layers_config.append(layers.BatchNormalization())\n            layers_config.append(layers.Activation('relu'))\n        \n        model = Sequential(layers_config, name='feature_extractor')\n\n        return model  \n        \n    def call(self, x):\n        return self.model(x)\n\nmodel = SiameseNetwork(inputShape=x_train[0].shape[1], featExtractorConfig=[100])\nmodel.compile(\n    loss=\"binary_crossentropy\", \n    optimizer=optimizers.Adam(learning_rate=0.0001),\n    metrics=[\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:06:55.742505Z","iopub.execute_input":"2021-12-18T12:06:55.74334Z","iopub.status.idle":"2021-12-18T12:06:56.275152Z","shell.execute_reply.started":"2021-12-18T12:06:55.743291Z","shell.execute_reply":"2021-12-18T12:06:56.2737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.model.layers[2].summary()\nmodel.model.summary()\nutils.plot_model(model.model, show_shapes=True, expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:06:56.280956Z","iopub.execute_input":"2021-12-18T12:06:56.281609Z","iopub.status.idle":"2021-12-18T12:06:57.178066Z","shell.execute_reply.started":"2021-12-18T12:06:56.28156Z","shell.execute_reply":"2021-12-18T12:06:57.176558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = callbacks.EarlyStopping(\n    monitor='val_loss', patience=5, verbose=1, restore_best_weights=True\n)\n\nrlp = callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=2, min_lr=1e-10, mode='min', verbose=1\n)\n\nhistory = model.fit(\n    x_train, y_train,\n    validation_data=(x_valid, y_valid),\n    batch_size=32, \n    epochs=100,\n    callbacks=[es, rlp]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:06:57.180256Z","iopub.execute_input":"2021-12-18T12:06:57.180732Z","iopub.status.idle":"2021-12-18T12:21:20.794851Z","shell.execute_reply.started":"2021-12-18T12:06:57.180693Z","shell.execute_reply":"2021-12-18T12:21:20.793542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(20, 8))\ndf = pd.DataFrame(history.history)\ndf[['accuracy', 'val_accuracy']].plot(ax=ax[0])\ndf[['loss', 'val_loss']].plot(ax=ax[1])\nax[0].set_title('Model Accuracy', fontsize=12)\nax[1].set_title('Model Loss', fontsize=12)\nfig.suptitle('Siamese Network: Learning Curve', fontsize=18);","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:21:20.797742Z","iopub.execute_input":"2021-12-18T12:21:20.798429Z","iopub.status.idle":"2021-12-18T12:21:21.777532Z","shell.execute_reply.started":"2021-12-18T12:21:20.798384Z","shell.execute_reply":"2021-12-18T12:21:21.776329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nsubmission = pd.DataFrame({\n    'test_id': dtest.test_id.values,\n    'is_duplicate': np.ravel(model.predict(x_test, batch_size=32))\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:21:21.779208Z","iopub.execute_input":"2021-12-18T12:21:21.779886Z","iopub.status.idle":"2021-12-18T12:23:51.446591Z","shell.execute_reply.started":"2021-12-18T12:21:21.779839Z","shell.execute_reply":"2021-12-18T12:23:51.445283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}