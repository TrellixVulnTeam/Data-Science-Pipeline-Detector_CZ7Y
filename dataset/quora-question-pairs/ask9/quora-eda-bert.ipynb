{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nfrom transformers import *\nfrom transformers import BertTokenizer, BertModel,BertForSequenceClassification,AdamW\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm, trange\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.text import * \n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a93da02c-4974-9116-74ce-3c8c45c3d581","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output\n\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nimport re\nfrom string import punctuation\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\ndf = pd.read_csv(\"../input/quoraquestions/data.csv\").fillna(\"\")\ndf.head() ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f3b994b-f2f3-2847-c635-f28672735666"},"cell_type":"markdown","source":"So we have six columns in total one of which is the label."},{"metadata":{"_cell_guid":"c2bc3874-d7cd-faa8-037f-dccdb4fc8e7c","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8234a5a5-822a-6f9e-f4a4-72464f5c2b33","trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3e4d73e-ee05-ded2-2c86-962164638e58","trusted":true},"cell_type":"code","source":"df.groupby(\"is_duplicate\")['id'].count().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"20befdf0-f412-1df5-071c-4bb0c688a50c","trusted":true},"cell_type":"code","source":"dfs = df[0:2500]\ndfs.groupby(\"is_duplicate\")['id'].count().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n              'Is','If','While','This']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PREPROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_to_wordlist(text, remove_stop_words=True, stem_words=False):\n    # Clean the text, with the option to remove stop_words and to stem words.\n\n    # Clean the text\n    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n    text = re.sub(r\"what's\", \"\", text)\n    text = re.sub(r\"What's\", \"\", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"I'm\", \"I am\", text)\n    text = re.sub(r\" m \", \" am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"60k\", \" 60000 \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e-mail\", \"email\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = re.sub(r\"quikly\", \"quickly\", text)\n    text = re.sub(r\" usa \", \" America \", text)\n    text = re.sub(r\" USA \", \" America \", text)\n    text = re.sub(r\" u s \", \" America \", text)\n    text = re.sub(r\" uk \", \" England \", text)\n    text = re.sub(r\" UK \", \" England \", text)\n    text = re.sub(r\"india\", \"India\", text)\n    text = re.sub(r\"switzerland\", \"Switzerland\", text)\n    text = re.sub(r\"china\", \"China\", text)\n    text = re.sub(r\"chinese\", \"Chinese\", text) \n    text = re.sub(r\"imrovement\", \"improvement\", text)\n    text = re.sub(r\"intially\", \"initially\", text)\n    text = re.sub(r\"quora\", \"Quora\", text)\n    text = re.sub(r\" dms \", \"direct messages \", text)  \n    text = re.sub(r\"demonitization\", \"demonetization\", text) \n    text = re.sub(r\"actived\", \"active\", text)\n    text = re.sub(r\"kms\", \" kilometers \", text)\n    text = re.sub(r\"KMs\", \" kilometers \", text)\n    text = re.sub(r\" cs \", \" computer science \", text) \n    text = re.sub(r\" upvotes \", \" up votes \", text)\n    text = re.sub(r\" iPhone \", \" phone \", text)\n    text = re.sub(r\"\\0rs \", \" rs \", text) \n    text = re.sub(r\"calender\", \"calendar\", text)\n    text = re.sub(r\"ios\", \"operating system\", text)\n    text = re.sub(r\"gps\", \"GPS\", text)\n    text = re.sub(r\"gst\", \"GST\", text)\n    text = re.sub(r\"programing\", \"programming\", text)\n    text = re.sub(r\"bestfriend\", \"best friend\", text)\n    text = re.sub(r\"dna\", \"DNA\", text)\n    text = re.sub(r\"III\", \"3\", text) \n    text = re.sub(r\"the US\", \"America\", text)\n    text = re.sub(r\"Astrology\", \"astrology\", text)\n    text = re.sub(r\"Method\", \"method\", text)\n    text = re.sub(r\"Find\", \"find\", text) \n    text = re.sub(r\"banglore\", \"Banglore\", text)\n    text = re.sub(r\" J K \", \" JK \", text)\n    \n    # Remove punctuation from text\n    text = ''.join([c for c in text if c not in punctuation])\n    \n    # Optionally, remove stop words\n    if remove_stop_words:\n        text = text.split()\n        text = [w for w in text if not w in stop_words]\n        text = \" \".join(text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    # Return a list of words\n    return(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_questions(question_list, questions, question_list_name, dataframe):\n    '''transform questions and display progress'''\n    for question in questions:\n        question_list.append(text_to_wordlist(question))\n        if len(question_list) % 100000 == 0:\n            progress = len(question_list)/len(dataframe) * 100\n            print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = []\nprocess_questions(data1, data, 'train_question1', data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.Series(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_up = df[:20000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_up","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using ULMFIT"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = (TextList.from_df(data_up)\n           #Inputs: all the text files in path\n            .split_by_rand_pct(0.15)\n           #We randomly split and keep 10% for validation\n            .label_for_lm()           \n           #We want to do a language model so we label accordingly\n            .databunch(bs=BATCH_SIZE))\ndata_lm.save('tmp_lm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.show_batch()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\nlearn.fit_one_cycle(1, 1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(1, 1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict(\"what is data\", n_words=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using GPT 2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch-transformers\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":4}