{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['test.csv', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9c6f6f204a1529414917417f63f5e795e0b8901"},"cell_type":"code","source":"train.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   id      ...       is_duplicate\n0   0      ...                  0\n1   1      ...                  0\n2   2      ...                  0\n3   3      ...                  0\n4   4      ...                  0\n\n[5 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"b9028ac029b3c3ad4e31f8f0d91739dfb8989f06"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8be00e253044865af5f5b0a60ccc7207e42a099","_kg_hide-input":false},"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif","execution_count":4,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def punc(df,stri):\n    df[stri] = df[stri].str.lower().str.replace('[^a-z]', ' ')\n    df[stri] = df[stri].str.lower().str.replace('[^\\w\\s]',' ')\n    df[stri] = df[stri].str.lower().str.replace(r'<.*?>',' ')\n    df[stri] = df[stri].str.lower().str.replace(' br ',' ')\n    return df","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=punc(train,\"question1\")\ntrain=punc(train,\"question2\")\n#test=punc(test,\"question2\")\n#test=punc(test,\"question1\")","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.dropna()\ntrain=train.dropna()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n\nstop = stopwords.words('english')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stopi(df,stri): \n    df[stri] = df[stri].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n    return df","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=stopi(train,\"question1\")\ntrain=stopi(train,\"question2\")\n#test=stopi(test,\"question2\")\n#test=stopi(test,\"question1\")","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\n\nps = PorterStemmer()\ndef port(df,stri):\n    df[stri] = df[stri].apply(lambda x: \" \".join(ps.stem(word) for word in x.split()))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=port(train,\"question1\")\ntrain=port(train,\"question2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\ntrain['question1'] = train['question1'].apply(lambda x: \" \".join(wordnet_lemmatizer.lemmatize(word) for word in x.split()))\ntrain['question2'] = train['question2'].apply(lambda x: \" \".join(wordnet_lemmatizer.lemmatize(word) for word in x.split()))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from difflib import SequenceMatcher\nar=[]\nfor index, row in train.iterrows():\n    #print(row['c1'], row['c2'])\n    a=SequenceMatcher(None,row['question1'],row['question2']).ratio()\n    ar.append(a)\n    ","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['simi']=ar","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sim'] = np.where(train['simi']==1.0, 1, 0)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(stop_words ='english', smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word')","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re, math\nfrom collections import Counter\n\nWORD = re.compile(r'\\w+')\n\ndef get_cosine(vec1, vec2):\n    intersection = set(vec1.keys()) & set(vec2.keys())\n    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n    if not denominator:\n        return 0.0\n    else:\n        return float(numerator) / denominator\n\ndef text_to_vector(text):\n    words = WORD.findall(text)\n    return Counter(words)\n\ntext1 = 'This is a foo bar sentence .'\ntext2 = 'This sentence is similar to a foo bar sentence .'\n\nvector1 = text_to_vector(text1)\nvector2 = text_to_vector(text2)\n\ncosine = get_cosine(vector1, vector2)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ar=[]\nfor index, row in train.iterrows():\n    #print(row['c1'], row['c2'])\n    vector1 = text_to_vector(row['question1'])\n    vector2 = text_to_vector(row['question2'])\n    a=get_cosine(vector1, vector2)\n    ar.append(a)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['simi1']=ar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train.ix[:,3:5]","execution_count":16,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train.is_duplicate","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.33, random_state=42)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = X_train[\"question1\"] + \",\" + X_train[\"question2\"]\n\ndef my_tokenizer(s):\n    return s.split(\",\")\n\nvect = CountVectorizer(max_features=1500)\nvect = CountVectorizer(analyzer='word',tokenizer=my_tokenizer, ngram_range=(1, 3), min_df=1) \ntrain1 = vect.fit_transform(sample.values)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = X_test[\"question1\"] + \",\" + X_test[\"question2\"]\n\ntest1 = vect.transform(sample.values)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_tokenizer(s):\n    return s.split(\",\")\n\nvect = TfidfVectorizer(stop_words ='english', smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word',tokenizer=my_tokenizer)\nsample = X_train[\"question1\"] + \",\" + X_train[\"question2\"]\ntrain1 = vect.fit_transform(sample.values)\nsample = X_test[\"question1\"] + \",\" + X_test[\"question2\"]\ntest1 = vect.transform(sample.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(train1, y_train)\npredictions = clf.predict(test1)\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, predictions)\naccuracy\nscore=f1_score(y_test,predictions,average='weighted')\nscore,accuracy","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(0.8095447191560773, 0.816632312708466)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog=LogisticRegression(penalty='l2',C=.00001)\nlog.fit(train1,y_train)\ny_pred = log.predict(test1)\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\naccuracy\nscore=f1_score(y_test,y_pred,average='weighted')\nscore,accuracy","execution_count":22,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n","name":"stderr"},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(0.48901015931694386, 0.6316156354233032)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=626238, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(train1, y_train, epochs=1, batch_size=10,validation_data=(test1, y_test))\ny_pred = model.predict(test1)\nscores = model.evaluate(train1, y_train)","execution_count":26,"outputs":[{"output_type":"stream","text":"Train on 270872 samples, validate on 133415 samples\nEpoch 1/1\n270872/270872 [==============================] - 2781s 10ms/step - loss: 0.5009 - acc: 0.7775 - val_loss: 0.4441 - val_acc: 0.8125\n270872/270872 [==============================] - 1585s 6ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"[0.14439214526680125, 0.977524439587702]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(test1, y_test)","execution_count":30,"outputs":[{"output_type":"stream","text":"133415/133415 [==============================] - 776s 6ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"[0.4441041476742258, 0.8124573698614069]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nmodel=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\nmodel.fit(train1, y_train)\ny_pred = model.predict(test1)\nscore=f1_score(y_test,y_pred,average='weighted')\nscore\naccuracy = accuracy_score(y_test, y_pred)\nscore,accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=4,oob_score=True ,random_state =42, min_samples_split=25)\nrf.fit(train1, y_train)\ny_pred = rf.predict(test1) \nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nscore=f1_score(y_test,y_pred,average='weighted')\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = X_train[['question1','question2']]\nsample = X_train.apply(lambda col: col.str.strip())\nimport scipy.sparse as sp\nvect = CountVectorizer(max_features=1500,ngram_range=(1, 3))\ntrain1 = sp.hstack(sample.apply(lambda col: vect.fit_transform(col)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = X_test[['question1','question2']]\nsample = X_test.apply(lambda col: col.str.strip())\nimport scipy.sparse as sp\ntest1 = sp.hstack(sample.apply(lambda col: vect.transform(col)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog=LogisticRegression(penalty='l2',C=.00001)\nlog.fit(train1,y_train)\ny_pred = log.predict(test1)\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(train1, y_train)\npredictions = clf.predict(test1)\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, predictions)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}