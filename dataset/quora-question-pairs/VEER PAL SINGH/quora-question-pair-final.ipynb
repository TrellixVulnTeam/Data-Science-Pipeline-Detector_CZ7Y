{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-12T13:43:55.982833Z","iopub.execute_input":"2022-03-12T13:43:55.983302Z","iopub.status.idle":"2022-03-12T13:43:55.996342Z","shell.execute_reply.started":"2022-03-12T13:43:55.983243Z","shell.execute_reply":"2022-03-12T13:43:55.995683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport pandas_profiling\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:43:56.000297Z","iopub.execute_input":"2022-03-12T13:43:56.000885Z","iopub.status.idle":"2022-03-12T13:43:57.203447Z","shell.execute_reply.started":"2022-03-12T13:43:56.000855Z","shell.execute_reply":"2022-03-12T13:43:57.20266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/quora-question-pairs/train.csv.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:43:57.204734Z","iopub.execute_input":"2022-03-12T13:43:57.205122Z","iopub.status.idle":"2022-03-12T13:43:59.000897Z","shell.execute_reply.started":"2022-03-12T13:43:57.205074Z","shell.execute_reply":"2022-03-12T13:43:58.999696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:43:59.003662Z","iopub.execute_input":"2022-03-12T13:43:59.004213Z","iopub.status.idle":"2022-03-12T13:43:59.013992Z","shell.execute_reply.started":"2022-03-12T13:43:59.004175Z","shell.execute_reply":"2022-03-12T13:43:59.012596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:43:59.015818Z","iopub.execute_input":"2022-03-12T13:43:59.01632Z","iopub.status.idle":"2022-03-12T13:43:59.041101Z","shell.execute_reply.started":"2022-03-12T13:43:59.016285Z","shell.execute_reply":"2022-03-12T13:43:59.04022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:43:59.042767Z","iopub.execute_input":"2022-03-12T13:43:59.043623Z","iopub.status.idle":"2022-03-12T13:43:59.073409Z","shell.execute_reply.started":"2022-03-12T13:43:59.043546Z","shell.execute_reply":"2022-03-12T13:43:59.072339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:43:59.074718Z","iopub.execute_input":"2022-03-12T13:43:59.07498Z","iopub.status.idle":"2022-03-12T13:43:59.190069Z","shell.execute_reply.started":"2022-03-12T13:43:59.074943Z","shell.execute_reply":"2022-03-12T13:43:59.189107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.profile_report()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:43:59.19345Z","iopub.execute_input":"2022-03-12T13:43:59.193723Z","iopub.status.idle":"2022-03-12T13:44:42.915406Z","shell.execute_reply.started":"2022-03-12T13:43:59.19369Z","shell.execute_reply":"2022-03-12T13:44:42.914442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:42.917033Z","iopub.execute_input":"2022-03-12T13:44:42.917483Z","iopub.status.idle":"2022-03-12T13:44:43.0699Z","shell.execute_reply.started":"2022-03-12T13:44:42.917448Z","shell.execute_reply":"2022-03-12T13:44:43.068917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# duplicate rows\ndf.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:43.07164Z","iopub.execute_input":"2022-03-12T13:44:43.072073Z","iopub.status.idle":"2022-03-12T13:44:43.512941Z","shell.execute_reply.started":"2022-03-12T13:44:43.072035Z","shell.execute_reply":"2022-03-12T13:44:43.511664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of duplicate and non-duplicate questions\n\nprint(df['is_duplicate'].value_counts())\nprint((df['is_duplicate'].value_counts()/df['is_duplicate'].count())*100)\ndf['is_duplicate'].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:43.51467Z","iopub.execute_input":"2022-03-12T13:44:43.514939Z","iopub.status.idle":"2022-03-12T13:44:43.722818Z","shell.execute_reply.started":"2022-03-12T13:44:43.514903Z","shell.execute_reply":"2022-03-12T13:44:43.721817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Repeated questions\n\nqid = pd.Series(df['qid1'].tolist() + df['qid2'].tolist())\nprint('Number of unique questions',np.unique(qid).shape[0])\nx = qid.value_counts()>1\nprint('Number of questions getting repeated',x[x].shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:43.724856Z","iopub.execute_input":"2022-03-12T13:44:43.725554Z","iopub.status.idle":"2022-03-12T13:44:44.28237Z","shell.execute_reply.started":"2022-03-12T13:44:43.725491Z","shell.execute_reply":"2022-03-12T13:44:44.281244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Repeated questions histogram\n\nplt.hist(qid.value_counts().values,bins=160)\nplt.yscale('log')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:44.28758Z","iopub.execute_input":"2022-03-12T13:44:44.287842Z","iopub.status.idle":"2022-03-12T13:44:45.429393Z","shell.execute_reply.started":"2022-03-12T13:44:44.287813Z","shell.execute_reply":"2022-03-12T13:44:45.428529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make data lighter select 30000 out of 400000","metadata":{}},{"cell_type":"code","source":"# df = pd.read_csv('train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:45.4312Z","iopub.execute_input":"2022-03-12T13:44:45.431596Z","iopub.status.idle":"2022-03-12T13:44:45.436573Z","shell.execute_reply.started":"2022-03-12T13:44:45.431549Z","shell.execute_reply":"2022-03-12T13:44:45.435518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = df.sample(30000)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:45.438173Z","iopub.execute_input":"2022-03-12T13:44:45.438549Z","iopub.status.idle":"2022-03-12T13:44:45.475511Z","shell.execute_reply.started":"2022-03-12T13:44:45.438505Z","shell.execute_reply":"2022-03-12T13:44:45.474744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:45.476588Z","iopub.execute_input":"2022-03-12T13:44:45.476894Z","iopub.status.idle":"2022-03-12T13:44:45.498335Z","shell.execute_reply.started":"2022-03-12T13:44:45.476853Z","shell.execute_reply":"2022-03-12T13:44:45.497615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ques_df = new_df[['question1','question2']]\nques_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:45.50054Z","iopub.execute_input":"2022-03-12T13:44:45.500873Z","iopub.status.idle":"2022-03-12T13:44:45.520473Z","shell.execute_reply.started":"2022-03-12T13:44:45.500834Z","shell.execute_reply":"2022-03-12T13:44:45.519441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ques_df = new_df[['question1','question2']]\nques_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:45.522263Z","iopub.execute_input":"2022-03-12T13:44:45.522604Z","iopub.status.idle":"2022-03-12T13:44:45.53803Z","shell.execute_reply.started":"2022-03-12T13:44:45.522562Z","shell.execute_reply":"2022-03-12T13:44:45.536911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n# merge texts\nquestions = list(ques_df['question1']) + list(ques_df['question2'])\n\ncv = CountVectorizer(max_features=3000)\nq1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:45.539955Z","iopub.execute_input":"2022-03-12T13:44:45.540602Z","iopub.status.idle":"2022-03-12T13:44:47.248311Z","shell.execute_reply.started":"2022-03-12T13:44:45.54055Z","shell.execute_reply":"2022-03-12T13:44:47.247437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)\ntemp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)\ntemp_df = pd.concat([temp_df1, temp_df2], axis=1)\ntemp_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:47.24958Z","iopub.execute_input":"2022-03-12T13:44:47.249835Z","iopub.status.idle":"2022-03-12T13:44:50.28923Z","shell.execute_reply.started":"2022-03-12T13:44:47.249805Z","shell.execute_reply":"2022-03-12T13:44:50.288199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:50.290574Z","iopub.execute_input":"2022-03-12T13:44:50.290814Z","iopub.status.idle":"2022-03-12T13:44:50.316913Z","shell.execute_reply.started":"2022-03-12T13:44:50.290786Z","shell.execute_reply":"2022-03-12T13:44:50.315842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df['is_duplicate'] = new_df['is_duplicate']","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:50.31866Z","iopub.execute_input":"2022-03-12T13:44:50.318987Z","iopub.status.idle":"2022-03-12T13:44:50.330832Z","shell.execute_reply.started":"2022-03-12T13:44:50.318928Z","shell.execute_reply":"2022-03-12T13:44:50.329872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:50.332412Z","iopub.execute_input":"2022-03-12T13:44:50.333284Z","iopub.status.idle":"2022-03-12T13:44:50.356844Z","shell.execute_reply.started":"2022-03-12T13:44:50.333223Z","shell.execute_reply":"2022-03-12T13:44:50.355906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(temp_df.iloc[:,0:-1].values,temp_df.iloc[:,-1].values,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:50.357947Z","iopub.execute_input":"2022-03-12T13:44:50.358527Z","iopub.status.idle":"2022-03-12T13:44:54.162401Z","shell.execute_reply.started":"2022-03-12T13:44:50.358487Z","shell.execute_reply":"2022-03-12T13:44:54.161492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred = rf.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:44:54.163808Z","iopub.execute_input":"2022-03-12T13:44:54.164668Z","iopub.status.idle":"2022-03-12T13:46:43.885462Z","shell.execute_reply.started":"2022-03-12T13:44:54.164625Z","shell.execute_reply":"2022-03-12T13:46:43.884458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,y_train)\ny_pred = xgb.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:46:43.887134Z","iopub.execute_input":"2022-03-12T13:46:43.887534Z","iopub.status.idle":"2022-03-12T13:51:12.900563Z","shell.execute_reply.started":"2022-03-12T13:46:43.887498Z","shell.execute_reply":"2022-03-12T13:51:12.899774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of duplicate and non-duplicate questions\n\nprint(new_df['is_duplicate'].value_counts())\nprint((new_df['is_duplicate'].value_counts()/new_df['is_duplicate'].count())*100)\nnew_df['is_duplicate'].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:51:12.904463Z","iopub.execute_input":"2022-03-12T13:51:12.906282Z","iopub.status.idle":"2022-03-12T13:51:13.103607Z","shell.execute_reply.started":"2022-03-12T13:51:12.906238Z","shell.execute_reply":"2022-03-12T13:51:13.102763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Repeated questions\n\nqid = pd.Series(new_df['qid1'].tolist() + new_df['qid2'].tolist())\nprint('Number of unique questions',np.unique(qid).shape[0])\nx = qid.value_counts()>1\nprint('Number of questions getting repeated',x[x].shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:51:13.104986Z","iopub.execute_input":"2022-03-12T13:51:13.105249Z","iopub.status.idle":"2022-03-12T13:51:13.154574Z","shell.execute_reply.started":"2022-03-12T13:51:13.105218Z","shell.execute_reply":"2022-03-12T13:51:13.153473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Repeated questions histogram\n\nplt.hist(qid.value_counts().values,bins=160)\nplt.yscale('log')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:51:13.157251Z","iopub.execute_input":"2022-03-12T13:51:13.157548Z","iopub.status.idle":"2022-03-12T13:51:13.977206Z","shell.execute_reply.started":"2022-03-12T13:51:13.157519Z","shell.execute_reply":"2022-03-12T13:51:13.976411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add new Features to our dataset","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Feature Engineering\n\nnew_df['q1_len'] = new_df['question1'].str.len() \nnew_df['q2_len'] = new_df['question2'].str.len()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:17:09.073975Z","iopub.execute_input":"2022-03-12T14:17:09.07533Z","iopub.status.idle":"2022-03-12T14:17:09.176378Z","shell.execute_reply.started":"2022-03-12T14:17:09.075281Z","shell.execute_reply":"2022-03-12T14:17:09.175499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:17:17.087427Z","iopub.execute_input":"2022-03-12T14:17:17.087964Z","iopub.status.idle":"2022-03-12T14:17:17.102965Z","shell.execute_reply.started":"2022-03-12T14:17:17.087932Z","shell.execute_reply":"2022-03-12T14:17:17.102087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['q1_num_words'] = new_df['question1'].apply(lambda row: len(row.split(\" \")))\nnew_df['q2_num_words'] = new_df['question2'].apply(lambda row: len(row.split(\" \")))\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:17:28.287506Z","iopub.execute_input":"2022-03-12T14:17:28.28781Z","iopub.status.idle":"2022-03-12T14:17:28.400169Z","shell.execute_reply.started":"2022-03-12T14:17:28.287779Z","shell.execute_reply":"2022-03-12T14:17:28.399482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map(lambda word: word.lower().strip(), \"What will be the positive and negative effects.\".split(\" \"))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:23:06.87211Z","iopub.execute_input":"2022-03-12T14:23:06.872638Z","iopub.status.idle":"2022-03-12T14:23:06.880687Z","shell.execute_reply.started":"2022-03-12T14:23:06.872596Z","shell.execute_reply":"2022-03-12T14:23:06.879546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert all words in small letters and stip\n\nlist(map(lambda word: word.lower().strip(), \"What will be the positive and negative effects.\".split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:23:09.681062Z","iopub.execute_input":"2022-03-12T14:23:09.681402Z","iopub.status.idle":"2022-03-12T14:23:09.688288Z","shell.execute_reply.started":"2022-03-12T14:23:09.681344Z","shell.execute_reply":"2022-03-12T14:23:09.687552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace list with set and eliminate duplicate words\n\nset(map(lambda word: word.lower().strip(), \"What will be the positive and negative effects.\".split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:23:13.663754Z","iopub.execute_input":"2022-03-12T14:23:13.664368Z","iopub.status.idle":"2022-03-12T14:23:13.671431Z","shell.execute_reply.started":"2022-03-12T14:23:13.664299Z","shell.execute_reply":"2022-03-12T14:23:13.67072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def common_words(row):\n    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return len(w1 & w2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:25:25.545455Z","iopub.execute_input":"2022-03-12T14:25:25.54583Z","iopub.status.idle":"2022-03-12T14:25:25.552219Z","shell.execute_reply.started":"2022-03-12T14:25:25.545792Z","shell.execute_reply":"2022-03-12T14:25:25.551497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['word_common'] = new_df.apply(common_words, axis=1)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:25:29.318048Z","iopub.execute_input":"2022-03-12T14:25:29.318692Z","iopub.status.idle":"2022-03-12T14:25:30.266414Z","shell.execute_reply.started":"2022-03-12T14:25:29.318644Z","shell.execute_reply":"2022-03-12T14:25:30.265449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def total_words(row):\n    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return (len(w1) + len(w2))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:25:44.771988Z","iopub.execute_input":"2022-03-12T14:25:44.772286Z","iopub.status.idle":"2022-03-12T14:25:44.780118Z","shell.execute_reply.started":"2022-03-12T14:25:44.772255Z","shell.execute_reply":"2022-03-12T14:25:44.778893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['word_total'] = new_df.apply(total_words, axis=1)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:25:58.740803Z","iopub.execute_input":"2022-03-12T14:25:58.741384Z","iopub.status.idle":"2022-03-12T14:25:59.669857Z","shell.execute_reply.started":"2022-03-12T14:25:58.741317Z","shell.execute_reply":"2022-03-12T14:25:59.669023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['word_share'] = round(new_df['word_common']/new_df['word_total'],2)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:26:44.462192Z","iopub.execute_input":"2022-03-12T14:26:44.462625Z","iopub.status.idle":"2022-03-12T14:26:44.483386Z","shell.execute_reply.started":"2022-03-12T14:26:44.462585Z","shell.execute_reply":"2022-03-12T14:26:44.482752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"# Analysis of features\nsns.displot(new_df['q1_len'])\nprint('minimum characters',new_df['q1_len'].min())\nprint('maximum characters',new_df['q1_len'].max())\nprint('average num of characters',int(new_df['q1_len'].mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:27:39.657397Z","iopub.execute_input":"2022-03-12T14:27:39.657763Z","iopub.status.idle":"2022-03-12T14:27:40.381073Z","shell.execute_reply.started":"2022-03-12T14:27:39.657724Z","shell.execute_reply":"2022-03-12T14:27:40.379829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(new_df['q2_len'])\nprint('minimum characters',new_df['q2_len'].min())\nprint('maximum characters',new_df['q2_len'].max())\nprint('average num of characters',int(new_df['q2_len'].mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:27:54.437063Z","iopub.execute_input":"2022-03-12T14:27:54.437562Z","iopub.status.idle":"2022-03-12T14:27:57.275392Z","shell.execute_reply.started":"2022-03-12T14:27:54.437329Z","shell.execute_reply":"2022-03-12T14:27:57.274391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(new_df['q1_num_words'])\nprint('minimum words',new_df['q1_num_words'].min())\nprint('maximum words',new_df['q1_num_words'].max())\nprint('average num of words',int(new_df['q1_num_words'].mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:28:13.446922Z","iopub.execute_input":"2022-03-12T14:28:13.44729Z","iopub.status.idle":"2022-03-12T14:28:14.147406Z","shell.execute_reply.started":"2022-03-12T14:28:13.447251Z","shell.execute_reply":"2022-03-12T14:28:14.146522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(new_df['q2_num_words'])\nprint('minimum words',new_df['q2_num_words'].min())\nprint('maximum words',new_df['q2_num_words'].max())\nprint('average num of words',int(new_df['q2_num_words'].mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:28:24.042412Z","iopub.execute_input":"2022-03-12T14:28:24.042742Z","iopub.status.idle":"2022-03-12T14:28:25.760402Z","shell.execute_reply.started":"2022-03-12T14:28:24.042702Z","shell.execute_reply":"2022-03-12T14:28:25.759638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common words\nsns.distplot(new_df[new_df['is_duplicate'] == 0]['word_common'],label='non duplicate')\nsns.distplot(new_df[new_df['is_duplicate'] == 1]['word_common'],label='duplicate')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:28:34.404553Z","iopub.execute_input":"2022-03-12T14:28:34.405339Z","iopub.status.idle":"2022-03-12T14:28:35.177943Z","shell.execute_reply.started":"2022-03-12T14:28:34.405292Z","shell.execute_reply":"2022-03-12T14:28:35.176915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total words\nsns.distplot(new_df[new_df['is_duplicate'] == 0]['word_total'],label='non duplicate')\nsns.distplot(new_df[new_df['is_duplicate'] == 1]['word_total'],label='duplicate')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:28:58.972541Z","iopub.execute_input":"2022-03-12T14:28:58.973419Z","iopub.status.idle":"2022-03-12T14:28:59.656522Z","shell.execute_reply.started":"2022-03-12T14:28:58.973345Z","shell.execute_reply":"2022-03-12T14:28:59.655705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word share\nsns.distplot(new_df[new_df['is_duplicate'] == 0]['word_share'],label='non duplicate')\nsns.distplot(new_df[new_df['is_duplicate'] == 1]['word_share'],label='duplicate')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:29:47.21197Z","iopub.execute_input":"2022-03-12T14:29:47.212316Z","iopub.status.idle":"2022-03-12T14:29:47.82223Z","shell.execute_reply.started":"2022-03-12T14:29:47.212279Z","shell.execute_reply":"2022-03-12T14:29:47.821183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ques_df = new_df[['question1','question2']]\nques_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:32:05.969629Z","iopub.execute_input":"2022-03-12T14:32:05.969972Z","iopub.status.idle":"2022-03-12T14:32:05.98883Z","shell.execute_reply.started":"2022-03-12T14:32:05.96994Z","shell.execute_reply":"2022-03-12T14:32:05.987935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\nprint(final_df.shape)\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:32:17.265531Z","iopub.execute_input":"2022-03-12T14:32:17.266619Z","iopub.status.idle":"2022-03-12T14:32:17.282843Z","shell.execute_reply.started":"2022-03-12T14:32:17.266573Z","shell.execute_reply":"2022-03-12T14:32:17.282233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n# merge texts\nquestions = list(ques_df['question1']) + list(ques_df['question2'])\n\ncv = CountVectorizer(max_features=3000)\nq1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:32:59.570218Z","iopub.execute_input":"2022-03-12T14:32:59.570616Z","iopub.status.idle":"2022-03-12T14:33:02.304555Z","shell.execute_reply.started":"2022-03-12T14:32:59.570577Z","shell.execute_reply":"2022-03-12T14:33:02.303443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)\ntemp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)\ntemp_df = pd.concat([temp_df1, temp_df2], axis=1)\ntemp_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:33:08.826374Z","iopub.execute_input":"2022-03-12T14:33:08.826734Z","iopub.status.idle":"2022-03-12T14:33:13.084301Z","shell.execute_reply.started":"2022-03-12T14:33:08.826699Z","shell.execute_reply":"2022-03-12T14:33:13.083198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = pd.concat([final_df, temp_df], axis=1)\nprint(final_df.shape)\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:33:29.714218Z","iopub.execute_input":"2022-03-12T14:33:29.714591Z","iopub.status.idle":"2022-03-12T14:33:30.442143Z","shell.execute_reply.started":"2022-03-12T14:33:29.714552Z","shell.execute_reply":"2022-03-12T14:33:30.441276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:33:44.377675Z","iopub.execute_input":"2022-03-12T14:33:44.378486Z","iopub.status.idle":"2022-03-12T14:33:49.220749Z","shell.execute_reply.started":"2022-03-12T14:33:44.378442Z","shell.execute_reply":"2022-03-12T14:33:49.219722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred = rf.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:33:55.473319Z","iopub.execute_input":"2022-03-12T14:33:55.473652Z","iopub.status.idle":"2022-03-12T14:35:11.824276Z","shell.execute_reply.started":"2022-03-12T14:33:55.473616Z","shell.execute_reply":"2022-03-12T14:35:11.823246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,y_train)\ny_pred = xgb.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:35:11.826034Z","iopub.execute_input":"2022-03-12T14:35:11.82628Z","iopub.status.idle":"2022-03-12T14:39:37.248028Z","shell.execute_reply.started":"2022-03-12T14:35:11.826251Z","shell.execute_reply":"2022-03-12T14:39:37.24723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now how to increase further accuracy, lets create some new advanced features\n\n## Advanced Features\n### 1. Token Features\n- cwc_min: This is the ratio of the number of common words to the length of the smaller question\n- cwc_max: This is the ratio of the number of common words to the length of the larger question\n- csc_min: This is the ratio of the number of common stop words to the smaller stop word count among the two questions\n- csc_max: This is the ratio of the number of common stop words to the larger stop word count among the two questions\n- ctc_min: This is the ratio of the number of common tokens to the smaller token count among the two questions\n- ctc_max: This is the ratio of the number of common tokens to the larger token count among the two questions\n- last_word_eq: 1 if the last word in the two questions is same, 0 otherwise\n- first_word_eq: 1 if the first word in the two questions is same, 0 otherwise\n\n### 2. Length Based Features\n- mean_len: Mean of the length of the two questions (number of words)\n- abs_len_diff: Absolute difference between the length of the two questions (number of words)\n- longest_substr_ratio: Ratio of the length of the longest substring among the two questions to the length of the smaller question\n\n### 3. Fuzzy Features\n- fuzz_ratio: fuzz_ratio score from fuzzywuzzy\n- fuzz_partial_ratio: fuzz_partial_ratio from fuzzywuzzy\n- token_sort_ratio: token_sort_ratio from fuzzywuzzy\n- token_set_ratio: token_set_ratio from fuzzywuzzy","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:45:17.156483Z","iopub.execute_input":"2022-03-12T14:45:17.156825Z","iopub.status.idle":"2022-03-12T14:45:17.171034Z","shell.execute_reply.started":"2022-03-12T14:45:17.156793Z","shell.execute_reply":"2022-03-12T14:45:17.170087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = df.sample(30000,random_state=2)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:45:39.573541Z","iopub.execute_input":"2022-03-12T14:45:39.573849Z","iopub.status.idle":"2022-03-12T14:45:39.615188Z","shell.execute_reply.started":"2022-03-12T14:45:39.573817Z","shell.execute_reply":"2022-03-12T14:45:39.614185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(q):\n    \n    q = str(q).lower().strip()\n    \n    # Replace certain special characters with their string equivalents\n    q = q.replace('%', ' percent')\n    q = q.replace('$', ' dollar ')\n    q = q.replace('₹', ' rupee ')\n    q = q.replace('€', ' euro ')\n    q = q.replace('@', ' at ')\n    \n    # The pattern '[math]' appears around 900 times in the whole dataset.\n    q = q.replace('[math]', '')\n    \n    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n    q = q.replace(',000,000,000 ', 'b ')\n    q = q.replace(',000,000 ', 'm ')\n    q = q.replace(',000 ', 'k ')\n    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n    \n    # Decontracting words\n    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n    # https://stackoverflow.com/a/19794953\n    contractions = { \n    \"ain't\": \"am not\",\n    \"aren't\": \"are not\",\n    \"can't\": \"can not\",\n    \"can't've\": \"can not have\",\n    \"'cause\": \"because\",\n    \"could've\": \"could have\",\n    \"couldn't\": \"could not\",\n    \"couldn't've\": \"could not have\",\n    \"didn't\": \"did not\",\n    \"doesn't\": \"does not\",\n    \"don't\": \"do not\",\n    \"hadn't\": \"had not\",\n    \"hadn't've\": \"had not have\",\n    \"hasn't\": \"has not\",\n    \"haven't\": \"have not\",\n    \"he'd\": \"he would\",\n    \"he'd've\": \"he would have\",\n    \"he'll\": \"he will\",\n    \"he'll've\": \"he will have\",\n    \"he's\": \"he is\",\n    \"how'd\": \"how did\",\n    \"how'd'y\": \"how do you\",\n    \"how'll\": \"how will\",\n    \"how's\": \"how is\",\n    \"i'd\": \"i would\",\n    \"i'd've\": \"i would have\",\n    \"i'll\": \"i will\",\n    \"i'll've\": \"i will have\",\n    \"i'm\": \"i am\",\n    \"i've\": \"i have\",\n    \"isn't\": \"is not\",\n    \"it'd\": \"it would\",\n    \"it'd've\": \"it would have\",\n    \"it'll\": \"it will\",\n    \"it'll've\": \"it will have\",\n    \"it's\": \"it is\",\n    \"let's\": \"let us\",\n    \"ma'am\": \"madam\",\n    \"mayn't\": \"may not\",\n    \"might've\": \"might have\",\n    \"mightn't\": \"might not\",\n    \"mightn't've\": \"might not have\",\n    \"must've\": \"must have\",\n    \"mustn't\": \"must not\",\n    \"mustn't've\": \"must not have\",\n    \"needn't\": \"need not\",\n    \"needn't've\": \"need not have\",\n    \"o'clock\": \"of the clock\",\n    \"oughtn't\": \"ought not\",\n    \"oughtn't've\": \"ought not have\",\n    \"shan't\": \"shall not\",\n    \"sha'n't\": \"shall not\",\n    \"shan't've\": \"shall not have\",\n    \"she'd\": \"she would\",\n    \"she'd've\": \"she would have\",\n    \"she'll\": \"she will\",\n    \"she'll've\": \"she will have\",\n    \"she's\": \"she is\",\n    \"should've\": \"should have\",\n    \"shouldn't\": \"should not\",\n    \"shouldn't've\": \"should not have\",\n    \"so've\": \"so have\",\n    \"so's\": \"so as\",\n    \"that'd\": \"that would\",\n    \"that'd've\": \"that would have\",\n    \"that's\": \"that is\",\n    \"there'd\": \"there would\",\n    \"there'd've\": \"there would have\",\n    \"there's\": \"there is\",\n    \"they'd\": \"they would\",\n    \"they'd've\": \"they would have\",\n    \"they'll\": \"they will\",\n    \"they'll've\": \"they will have\",\n    \"they're\": \"they are\",\n    \"they've\": \"they have\",\n    \"to've\": \"to have\",\n    \"wasn't\": \"was not\",\n    \"we'd\": \"we would\",\n    \"we'd've\": \"we would have\",\n    \"we'll\": \"we will\",\n    \"we'll've\": \"we will have\",\n    \"we're\": \"we are\",\n    \"we've\": \"we have\",\n    \"weren't\": \"were not\",\n    \"what'll\": \"what will\",\n    \"what'll've\": \"what will have\",\n    \"what're\": \"what are\",\n    \"what's\": \"what is\",\n    \"what've\": \"what have\",\n    \"when's\": \"when is\",\n    \"when've\": \"when have\",\n    \"where'd\": \"where did\",\n    \"where's\": \"where is\",\n    \"where've\": \"where have\",\n    \"who'll\": \"who will\",\n    \"who'll've\": \"who will have\",\n    \"who's\": \"who is\",\n    \"who've\": \"who have\",\n    \"why's\": \"why is\",\n    \"why've\": \"why have\",\n    \"will've\": \"will have\",\n    \"won't\": \"will not\",\n    \"won't've\": \"will not have\",\n    \"would've\": \"would have\",\n    \"wouldn't\": \"would not\",\n    \"wouldn't've\": \"would not have\",\n    \"y'all\": \"you all\",\n    \"y'all'd\": \"you all would\",\n    \"y'all'd've\": \"you all would have\",\n    \"y'all're\": \"you all are\",\n    \"y'all've\": \"you all have\",\n    \"you'd\": \"you would\",\n    \"you'd've\": \"you would have\",\n    \"you'll\": \"you will\",\n    \"you'll've\": \"you will have\",\n    \"you're\": \"you are\",\n    \"you've\": \"you have\"\n    }\n\n    q_decontracted = []\n\n    for word in q.split():\n        if word in contractions:\n            word = contractions[word]\n\n        q_decontracted.append(word)\n\n    q = ' '.join(q_decontracted)\n    q = q.replace(\"'ve\", \" have\")\n    q = q.replace(\"n't\", \" not\")\n    q = q.replace(\"'re\", \" are\")\n    q = q.replace(\"'ll\", \" will\")\n    \n    # Removing HTML tags\n    q = BeautifulSoup(q)\n    q = q.get_text()\n    \n    # Remove punctuations\n    pattern = re.compile('\\W')\n    q = re.sub(pattern, ' ', q).strip()\n\n    \n    return q","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:46:09.552288Z","iopub.execute_input":"2022-03-12T14:46:09.553441Z","iopub.status.idle":"2022-03-12T14:46:09.579029Z","shell.execute_reply.started":"2022-03-12T14:46:09.553395Z","shell.execute_reply":"2022-03-12T14:46:09.577997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:48:07.475846Z","iopub.execute_input":"2022-03-12T14:48:07.476138Z","iopub.status.idle":"2022-03-12T14:48:07.714777Z","shell.execute_reply.started":"2022-03-12T14:48:07.476108Z","shell.execute_reply":"2022-03-12T14:48:07.713747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess(\"I've already! wasn't <b>done</b>?\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:48:10.18366Z","iopub.execute_input":"2022-03-12T14:48:10.184113Z","iopub.status.idle":"2022-03-12T14:48:10.194368Z","shell.execute_reply.started":"2022-03-12T14:48:10.184061Z","shell.execute_reply":"2022-03-12T14:48:10.193298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['question1'] = new_df['question1'].apply(preprocess)\nnew_df['question2'] = new_df['question2'].apply(preprocess)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:48:24.246721Z","iopub.execute_input":"2022-03-12T14:48:24.247342Z","iopub.status.idle":"2022-03-12T14:48:42.006971Z","shell.execute_reply.started":"2022-03-12T14:48:24.24729Z","shell.execute_reply":"2022-03-12T14:48:42.005869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:48:42.009054Z","iopub.execute_input":"2022-03-12T14:48:42.009373Z","iopub.status.idle":"2022-03-12T14:48:42.026483Z","shell.execute_reply.started":"2022-03-12T14:48:42.009315Z","shell.execute_reply":"2022-03-12T14:48:42.025183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['q1_len'] = new_df['question1'].str.len() \nnew_df['q2_len'] = new_df['question2'].str.len()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:49:09.661593Z","iopub.execute_input":"2022-03-12T14:49:09.661876Z","iopub.status.idle":"2022-03-12T14:49:09.724373Z","shell.execute_reply.started":"2022-03-12T14:49:09.661847Z","shell.execute_reply":"2022-03-12T14:49:09.723479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['q1_num_words'] = new_df['question1'].apply(lambda row: len(row.split(\" \")))\nnew_df['q2_num_words'] = new_df['question2'].apply(lambda row: len(row.split(\" \")))\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:49:16.244513Z","iopub.execute_input":"2022-03-12T14:49:16.245069Z","iopub.status.idle":"2022-03-12T14:49:16.347615Z","shell.execute_reply.started":"2022-03-12T14:49:16.244977Z","shell.execute_reply":"2022-03-12T14:49:16.346465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def common_words(row):\n    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return len(w1 & w2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:49:26.876175Z","iopub.execute_input":"2022-03-12T14:49:26.876563Z","iopub.status.idle":"2022-03-12T14:49:26.88569Z","shell.execute_reply.started":"2022-03-12T14:49:26.876523Z","shell.execute_reply":"2022-03-12T14:49:26.884619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['word_common'] = new_df.apply(common_words, axis=1)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:49:33.298959Z","iopub.execute_input":"2022-03-12T14:49:33.299476Z","iopub.status.idle":"2022-03-12T14:49:34.258491Z","shell.execute_reply.started":"2022-03-12T14:49:33.299432Z","shell.execute_reply":"2022-03-12T14:49:34.257532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def total_words(row):\n    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return (len(w1) + len(w2))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:49:42.420949Z","iopub.execute_input":"2022-03-12T14:49:42.421416Z","iopub.status.idle":"2022-03-12T14:49:42.428762Z","shell.execute_reply.started":"2022-03-12T14:49:42.421383Z","shell.execute_reply":"2022-03-12T14:49:42.427347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['word_total'] = new_df.apply(total_words, axis=1)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:49:49.316793Z","iopub.execute_input":"2022-03-12T14:49:49.31781Z","iopub.status.idle":"2022-03-12T14:49:50.237526Z","shell.execute_reply.started":"2022-03-12T14:49:49.317759Z","shell.execute_reply":"2022-03-12T14:49:50.236645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['word_share'] = round(new_df['word_common']/new_df['word_total'],2)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:49:57.572568Z","iopub.execute_input":"2022-03-12T14:49:57.573416Z","iopub.status.idle":"2022-03-12T14:49:57.59162Z","shell.execute_reply.started":"2022-03-12T14:49:57.573376Z","shell.execute_reply":"2022-03-12T14:49:57.590772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Advanced Features\nfrom nltk.corpus import stopwords\n\ndef fetch_token_features(row):\n    \n    q1 = row['question1']\n    q2 = row['question2']\n    \n    SAFE_DIV = 0.0001 \n\n    STOP_WORDS = stopwords.words(\"english\")\n    \n    token_features = [0.0]*8\n    \n    # Converting the Sentence into Tokens: \n    q1_tokens = q1.split()\n    q2_tokens = q2.split()\n    \n    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n        return token_features\n\n    # Get the non-stopwords in Questions\n    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n    \n    #Get the stopwords in Questions\n    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n    \n    # Get the common non-stopwords from Question pair\n    common_word_count = len(q1_words.intersection(q2_words))\n    \n    # Get the common stopwords from Question pair\n    common_stop_count = len(q1_stops.intersection(q2_stops))\n    \n    # Get the common Tokens from Question pair\n    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n    \n    \n    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n    \n    # Last word of both question is same or not\n    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n    \n    # First word of both question is same or not\n    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n    \n    return token_features","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:50:10.773403Z","iopub.execute_input":"2022-03-12T14:50:10.774057Z","iopub.status.idle":"2022-03-12T14:50:11.660034Z","shell.execute_reply.started":"2022-03-12T14:50:10.774007Z","shell.execute_reply":"2022-03-12T14:50:11.658987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token_features = new_df.apply(fetch_token_features, axis=1)\n\nnew_df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\nnew_df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\nnew_df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\nnew_df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\nnew_df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\nnew_df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\nnew_df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\nnew_df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:50:22.26025Z","iopub.execute_input":"2022-03-12T14:50:22.260602Z","iopub.status.idle":"2022-03-12T14:50:30.636878Z","shell.execute_reply.started":"2022-03-12T14:50:22.26057Z","shell.execute_reply":"2022-03-12T14:50:30.635647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:50:30.638786Z","iopub.execute_input":"2022-03-12T14:50:30.639558Z","iopub.status.idle":"2022-03-12T14:50:30.667477Z","shell.execute_reply.started":"2022-03-12T14:50:30.639514Z","shell.execute_reply":"2022-03-12T14:50:30.666676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install Distance","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:55:37.867465Z","iopub.execute_input":"2022-03-12T14:55:37.867791Z","iopub.status.idle":"2022-03-12T14:55:51.321214Z","shell.execute_reply.started":"2022-03-12T14:55:37.86776Z","shell.execute_reply":"2022-03-12T14:55:51.319878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import distance\n\ndef fetch_length_features(row):\n    \n    q1 = row['question1']\n    q2 = row['question2']\n    \n    length_features = [0.0]*3\n    \n    # Converting the Sentence into Tokens: \n    q1_tokens = q1.split()\n    q2_tokens = q2.split()\n    \n    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n        return length_features\n    \n    # Absolute length features\n    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n    \n    #Average Token Length of both Questions\n    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n    \n    strs = list(distance.lcsubstrings(q1, q2))\n    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n    \n    return length_features","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:56:05.835803Z","iopub.execute_input":"2022-03-12T14:56:05.836273Z","iopub.status.idle":"2022-03-12T14:56:05.853486Z","shell.execute_reply.started":"2022-03-12T14:56:05.836225Z","shell.execute_reply":"2022-03-12T14:56:05.852437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length_features = new_df.apply(fetch_length_features, axis=1)\n\nnew_df['abs_len_diff'] = list(map(lambda x: x[0], length_features))\nnew_df['mean_len'] = list(map(lambda x: x[1], length_features))\nnew_df['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:56:20.234756Z","iopub.execute_input":"2022-03-12T14:56:20.235648Z","iopub.status.idle":"2022-03-12T14:57:05.599161Z","shell.execute_reply.started":"2022-03-12T14:56:20.235596Z","shell.execute_reply":"2022-03-12T14:57:05.597951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:57:05.600928Z","iopub.execute_input":"2022-03-12T14:57:05.601188Z","iopub.status.idle":"2022-03-12T14:57:05.631006Z","shell.execute_reply.started":"2022-03-12T14:57:05.601159Z","shell.execute_reply":"2022-03-12T14:57:05.630188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fuzzy Features\nfrom fuzzywuzzy import fuzz\n\ndef fetch_fuzzy_features(row):\n    \n    q1 = row['question1']\n    q2 = row['question2']\n    \n    fuzzy_features = [0.0]*4\n    \n    # fuzz_ratio\n    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n\n    # fuzz_partial_ratio\n    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n\n    # token_sort_ratio\n    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n\n    # token_set_ratio\n    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n\n    return fuzzy_features","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:57:05.632249Z","iopub.execute_input":"2022-03-12T14:57:05.632982Z","iopub.status.idle":"2022-03-12T14:57:05.657461Z","shell.execute_reply.started":"2022-03-12T14:57:05.632942Z","shell.execute_reply":"2022-03-12T14:57:05.656707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fuzzy_features = new_df.apply(fetch_fuzzy_features, axis=1)\n\n# Creating new feature columns for fuzzy features\nnew_df['fuzz_ratio'] = list(map(lambda x: x[0], fuzzy_features))\nnew_df['fuzz_partial_ratio'] = list(map(lambda x: x[1], fuzzy_features))\nnew_df['token_sort_ratio'] = list(map(lambda x: x[2], fuzzy_features))\nnew_df['token_set_ratio'] = list(map(lambda x: x[3], fuzzy_features))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:57:17.178272Z","iopub.execute_input":"2022-03-12T14:57:17.178872Z","iopub.status.idle":"2022-03-12T14:57:25.089548Z","shell.execute_reply.started":"2022-03-12T14:57:17.17883Z","shell.execute_reply":"2022-03-12T14:57:25.088454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(new_df.shape)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:57:25.091543Z","iopub.execute_input":"2022-03-12T14:57:25.091998Z","iopub.status.idle":"2022-03-12T14:57:25.123071Z","shell.execute_reply.started":"2022-03-12T14:57:25.091945Z","shell.execute_reply":"2022-03-12T14:57:25.122025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(new_df[['ctc_min', 'cwc_min', 'csc_min', 'is_duplicate']],hue='is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:57:36.585513Z","iopub.execute_input":"2022-03-12T14:57:36.585828Z","iopub.status.idle":"2022-03-12T14:57:53.336471Z","shell.execute_reply.started":"2022-03-12T14:57:36.585797Z","shell.execute_reply":"2022-03-12T14:57:53.335477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(new_df[['ctc_max', 'cwc_max', 'csc_max', 'is_duplicate']],hue='is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:06.113237Z","iopub.execute_input":"2022-03-12T14:58:06.113563Z","iopub.status.idle":"2022-03-12T14:58:22.478433Z","shell.execute_reply.started":"2022-03-12T14:58:06.113527Z","shell.execute_reply":"2022-03-12T14:58:22.477409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(new_df[['last_word_eq', 'first_word_eq', 'is_duplicate']],hue='is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:50.338582Z","iopub.execute_input":"2022-03-12T14:58:50.338915Z","iopub.status.idle":"2022-03-12T14:58:56.032271Z","shell.execute_reply.started":"2022-03-12T14:58:50.33888Z","shell.execute_reply":"2022-03-12T14:58:56.029734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(new_df[['mean_len', 'abs_len_diff','longest_substr_ratio', 'is_duplicate']],hue='is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:59:12.675178Z","iopub.execute_input":"2022-03-12T14:59:12.676125Z","iopub.status.idle":"2022-03-12T14:59:29.291681Z","shell.execute_reply.started":"2022-03-12T14:59:12.676073Z","shell.execute_reply":"2022-03-12T14:59:29.290415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(new_df[['fuzz_ratio', 'fuzz_partial_ratio','token_sort_ratio','token_set_ratio', 'is_duplicate']],hue='is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:59:29.426478Z","iopub.execute_input":"2022-03-12T14:59:29.427443Z","iopub.status.idle":"2022-03-12T15:00:01.917279Z","shell.execute_reply.started":"2022-03-12T14:59:29.427401Z","shell.execute_reply":"2022-03-12T15:00:01.915515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using TSNE for Dimentionality reduction for 15 Features(Generated after cleaning the data) to 3 dimention\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nX = MinMaxScaler().fit_transform(new_df[['cwc_min', 'cwc_max', 'csc_min', 'csc_max' , 'ctc_min' , 'ctc_max' , 'last_word_eq', 'first_word_eq' , 'abs_len_diff' , 'mean_len' , 'token_set_ratio' , 'token_sort_ratio' ,  'fuzz_ratio' , 'fuzz_partial_ratio' , 'longest_substr_ratio']])\ny = new_df['is_duplicate'].values","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:00:01.920928Z","iopub.execute_input":"2022-03-12T15:00:01.922933Z","iopub.status.idle":"2022-03-12T15:00:01.959385Z","shell.execute_reply.started":"2022-03-12T15:00:01.922845Z","shell.execute_reply":"2022-03-12T15:00:01.957483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n\ntsne2d = TSNE(\n    n_components=2,\n    init='random', # pca\n    random_state=101,\n    method='barnes_hut',\n    n_iter=1000,\n    verbose=2,\n    angle=0.5\n).fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:00:08.594771Z","iopub.execute_input":"2022-03-12T15:00:08.595677Z","iopub.status.idle":"2022-03-12T15:03:38.028734Z","shell.execute_reply.started":"2022-03-12T15:00:08.595628Z","shell.execute_reply":"2022-03-12T15:03:38.027904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_df = pd.DataFrame({'x':tsne2d[:,0], 'y':tsne2d[:,1] ,'label':y})\n\n# draw the plot in appropriate place in the grid\nsns.lmplot(data=x_df, x='x', y='y', hue='label', fit_reg=False, size=8,palette=\"Set1\",markers=['s','o'])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:03:38.030953Z","iopub.execute_input":"2022-03-12T15:03:38.031639Z","iopub.status.idle":"2022-03-12T15:03:38.908396Z","shell.execute_reply.started":"2022-03-12T15:03:38.031589Z","shell.execute_reply":"2022-03-12T15:03:38.907723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsne3d = TSNE(\n    n_components=3,\n    init='random', # pca\n    random_state=101,\n    method='barnes_hut',\n    n_iter=1000,\n    verbose=2,\n    angle=0.5\n).fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:03:38.909396Z","iopub.execute_input":"2022-03-12T15:03:38.909907Z","iopub.status.idle":"2022-03-12T15:12:31.038816Z","shell.execute_reply.started":"2022-03-12T15:03:38.909866Z","shell.execute_reply":"2022-03-12T15:12:31.037972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\n\ntrace1 = go.Scatter3d(\n    x=tsne3d[:,0],\n    y=tsne3d[:,1],\n    z=tsne3d[:,2],\n    mode='markers',\n    marker=dict(\n        sizemode='diameter',\n        color = y,\n        colorscale = 'Portland',\n        colorbar = dict(title = 'duplicate'),\n        line=dict(color='rgb(255, 255, 255)'),\n        opacity=0.75\n    )\n)\n\ndata=[trace1]\nlayout=dict(height=800, width=800, title='3d embedding with engineered features')\nfig=dict(data=data, layout=layout)\npy.iplot(fig, filename='3DBubble')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:12:31.043335Z","iopub.execute_input":"2022-03-12T15:12:31.045481Z","iopub.status.idle":"2022-03-12T15:12:32.314128Z","shell.execute_reply.started":"2022-03-12T15:12:31.045431Z","shell.execute_reply":"2022-03-12T15:12:32.311755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ques_df = new_df[['question1','question2']]\nques_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:12:32.315514Z","iopub.execute_input":"2022-03-12T15:12:32.315857Z","iopub.status.idle":"2022-03-12T15:12:32.329176Z","shell.execute_reply.started":"2022-03-12T15:12:32.315819Z","shell.execute_reply":"2022-03-12T15:12:32.328519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\nprint(final_df.shape)\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:12:32.330344Z","iopub.execute_input":"2022-03-12T15:12:32.330925Z","iopub.status.idle":"2022-03-12T15:12:32.369848Z","shell.execute_reply.started":"2022-03-12T15:12:32.330892Z","shell.execute_reply":"2022-03-12T15:12:32.369153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n# merge texts\nquestions = list(ques_df['question1']) + list(ques_df['question2'])\n\ncv = CountVectorizer(max_features=3000)\nq1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:12:32.371021Z","iopub.execute_input":"2022-03-12T15:12:32.371263Z","iopub.status.idle":"2022-03-12T15:12:34.616874Z","shell.execute_reply.started":"2022-03-12T15:12:32.371234Z","shell.execute_reply":"2022-03-12T15:12:34.615718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)\ntemp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)\ntemp_df = pd.concat([temp_df1, temp_df2], axis=1)\ntemp_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:41.925832Z","iopub.execute_input":"2022-03-12T15:14:41.926208Z","iopub.status.idle":"2022-03-12T15:14:45.631678Z","shell.execute_reply.started":"2022-03-12T15:14:41.926171Z","shell.execute_reply":"2022-03-12T15:14:45.630553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = pd.concat([final_df, temp_df], axis=1)\nprint(final_df.shape)\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:49.434538Z","iopub.execute_input":"2022-03-12T15:14:49.435229Z","iopub.status.idle":"2022-03-12T15:14:50.029673Z","shell.execute_reply.started":"2022-03-12T15:14:49.435189Z","shell.execute_reply":"2022-03-12T15:14:50.028925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:59.530661Z","iopub.execute_input":"2022-03-12T15:14:59.531194Z","iopub.status.idle":"2022-03-12T15:15:04.296659Z","shell.execute_reply.started":"2022-03-12T15:14:59.531157Z","shell.execute_reply":"2022-03-12T15:15:04.295634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred = rf.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:15:20.578423Z","iopub.execute_input":"2022-03-12T15:15:20.578755Z","iopub.status.idle":"2022-03-12T15:16:14.161342Z","shell.execute_reply.started":"2022-03-12T15:15:20.578722Z","shell.execute_reply":"2022-03-12T15:16:14.160411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,y_train)\ny_pred1 = xgb.predict(X_test)\naccuracy_score(y_test,y_pred1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:16:14.163151Z","iopub.execute_input":"2022-03-12T15:16:14.163428Z","iopub.status.idle":"2022-03-12T15:20:40.125918Z","shell.execute_reply.started":"2022-03-12T15:16:14.163397Z","shell.execute_reply":"2022-03-12T15:20:40.124955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:20:40.130264Z","iopub.execute_input":"2022-03-12T15:20:40.130974Z","iopub.status.idle":"2022-03-12T15:20:40.13527Z","shell.execute_reply.started":"2022-03-12T15:20:40.130924Z","shell.execute_reply":"2022-03-12T15:20:40.134457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for random forest model\nconfusion_matrix(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:43:52.942068Z","iopub.execute_input":"2022-03-12T15:43:52.942586Z","iopub.status.idle":"2022-03-12T15:43:52.955105Z","shell.execute_reply.started":"2022-03-12T15:43:52.942516Z","shell.execute_reply":"2022-03-12T15:43:52.953797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for xgboost model\nconfusion_matrix(y_test,y_pred1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:43:58.381773Z","iopub.execute_input":"2022-03-12T15:43:58.382053Z","iopub.status.idle":"2022-03-12T15:43:58.390717Z","shell.execute_reply.started":"2022-03-12T15:43:58.382024Z","shell.execute_reply":"2022-03-12T15:43:58.389695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_common_words(q1,q2):\n    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n    return len(w1 & w2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:33:55.355157Z","iopub.execute_input":"2022-03-12T15:33:55.356008Z","iopub.status.idle":"2022-03-12T15:33:55.362773Z","shell.execute_reply.started":"2022-03-12T15:33:55.355955Z","shell.execute_reply":"2022-03-12T15:33:55.361777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_total_words(q1,q2):\n    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n    return (len(w1) + len(w2))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:34:05.309805Z","iopub.execute_input":"2022-03-12T15:34:05.310986Z","iopub.status.idle":"2022-03-12T15:34:05.316842Z","shell.execute_reply.started":"2022-03-12T15:34:05.310939Z","shell.execute_reply":"2022-03-12T15:34:05.315898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fetch_token_features(q1,q2):\n    \n    SAFE_DIV = 0.0001 \n\n    STOP_WORDS = stopwords.words(\"english\")\n    \n    token_features = [0.0]*8\n    \n    # Converting the Sentence into Tokens: \n    q1_tokens = q1.split()\n    q2_tokens = q2.split()\n    \n    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n        return token_features\n\n    # Get the non-stopwords in Questions\n    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n    \n    #Get the stopwords in Questions\n    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n    \n    # Get the common non-stopwords from Question pair\n    common_word_count = len(q1_words.intersection(q2_words))\n    \n    # Get the common stopwords from Question pair\n    common_stop_count = len(q1_stops.intersection(q2_stops))\n    \n    # Get the common Tokens from Question pair\n    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n    \n    \n    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n    \n    # Last word of both question is same or not\n    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n    \n    # First word of both question is same or not\n    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n    \n    return token_features","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:34:19.719118Z","iopub.execute_input":"2022-03-12T15:34:19.719652Z","iopub.status.idle":"2022-03-12T15:34:19.736062Z","shell.execute_reply.started":"2022-03-12T15:34:19.719607Z","shell.execute_reply":"2022-03-12T15:34:19.735275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fetch_length_features(q1,q2):\n    \n    length_features = [0.0]*3\n    \n    # Converting the Sentence into Tokens: \n    q1_tokens = q1.split()\n    q2_tokens = q2.split()\n    \n    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n        return length_features\n    \n    # Absolute length features\n    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n    \n    #Average Token Length of both Questions\n    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n    \n    strs = list(distance.lcsubstrings(q1, q2))\n    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n    \n    return length_features","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:34:32.496197Z","iopub.execute_input":"2022-03-12T15:34:32.496672Z","iopub.status.idle":"2022-03-12T15:34:32.506264Z","shell.execute_reply.started":"2022-03-12T15:34:32.496637Z","shell.execute_reply":"2022-03-12T15:34:32.505142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fetch_fuzzy_features(q1,q2):\n    \n    fuzzy_features = [0.0]*4\n    \n    # fuzz_ratio\n    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n\n    # fuzz_partial_ratio\n    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n\n    # token_sort_ratio\n    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n\n    # token_set_ratio\n    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n\n    return fuzzy_features","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:34:41.477699Z","iopub.execute_input":"2022-03-12T15:34:41.478259Z","iopub.status.idle":"2022-03-12T15:34:41.484751Z","shell.execute_reply.started":"2022-03-12T15:34:41.478214Z","shell.execute_reply":"2022-03-12T15:34:41.483746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def query_point_creator(q1,q2):\n    \n    input_query = []\n    \n    # preprocess\n    q1 = preprocess(q1)\n    q2 = preprocess(q2)\n    \n    # fetch basic features\n    input_query.append(len(q1))\n    input_query.append(len(q2))\n    \n    input_query.append(len(q1.split(\" \")))\n    input_query.append(len(q2.split(\" \")))\n    \n    input_query.append(test_common_words(q1,q2))\n    input_query.append(test_total_words(q1,q2))\n    input_query.append(round(test_common_words(q1,q2)/test_total_words(q1,q2),2))\n    \n    # fetch token features\n    token_features = test_fetch_token_features(q1,q2)\n    input_query.extend(token_features)\n    \n    # fetch length based features\n    length_features = test_fetch_length_features(q1,q2)\n    input_query.extend(length_features)\n    \n    # fetch fuzzy features\n    fuzzy_features = test_fetch_fuzzy_features(q1,q2)\n    input_query.extend(fuzzy_features)\n    \n    # bow feature for q1\n    q1_bow = cv.transform([q1]).toarray()\n    \n    # bow feature for q2\n    q2_bow = cv.transform([q2]).toarray()\n    \n    \n    \n    return np.hstack((np.array(input_query).reshape(1,22),q1_bow,q2_bow))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:34:57.012095Z","iopub.execute_input":"2022-03-12T15:34:57.012616Z","iopub.status.idle":"2022-03-12T15:34:57.02506Z","shell.execute_reply.started":"2022-03-12T15:34:57.012562Z","shell.execute_reply":"2022-03-12T15:34:57.023953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q1 = 'Where is the capital of India?'\nq2 = 'What is the current capital of Pakistan?'\nq3 = 'Which city serves as the capital of India?'\nq4 = 'What is the business capital of India?'","metadata":{"execution":{"iopub.status.busy":"2022-03-12T16:11:00.050995Z","iopub.execute_input":"2022-03-12T16:11:00.051533Z","iopub.status.idle":"2022-03-12T16:11:00.056219Z","shell.execute_reply.started":"2022-03-12T16:11:00.051489Z","shell.execute_reply":"2022-03-12T16:11:00.055246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_point_creator(q1,q2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T16:08:08.504652Z","iopub.execute_input":"2022-03-12T16:08:08.505385Z","iopub.status.idle":"2022-03-12T16:08:08.516605Z","shell.execute_reply.started":"2022-03-12T16:08:08.505322Z","shell.execute_reply":"2022-03-12T16:08:08.515947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_point_creator(q1,q2).shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T16:08:27.993038Z","iopub.execute_input":"2022-03-12T16:08:27.993776Z","iopub.status.idle":"2022-03-12T16:08:28.00402Z","shell.execute_reply.started":"2022-03-12T16:08:27.993739Z","shell.execute_reply":"2022-03-12T16:08:28.002884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.predict(query_point_creator(q1,q4))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T16:11:02.662227Z","iopub.execute_input":"2022-03-12T16:11:02.663189Z","iopub.status.idle":"2022-03-12T16:11:02.683253Z","shell.execute_reply.started":"2022-03-12T16:11:02.66314Z","shell.execute_reply":"2022-03-12T16:11:02.682617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.predict(query_point_creator(q1,q2))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T16:11:30.404828Z","iopub.execute_input":"2022-03-12T16:11:30.405611Z","iopub.status.idle":"2022-03-12T16:11:30.429177Z","shell.execute_reply.started":"2022-03-12T16:11:30.405559Z","shell.execute_reply":"2022-03-12T16:11:30.428212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv","metadata":{"execution":{"iopub.status.busy":"2022-03-12T16:11:43.706222Z","iopub.execute_input":"2022-03-12T16:11:43.706589Z","iopub.status.idle":"2022-03-12T16:11:43.713975Z","shell.execute_reply.started":"2022-03-12T16:11:43.706551Z","shell.execute_reply":"2022-03-12T16:11:43.71286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\npickle.dump(rf,open('model.pkl','wb'))\npickle.dump(cv,open('cv.pkl','wb'))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T16:11:48.378259Z","iopub.execute_input":"2022-03-12T16:11:48.378566Z","iopub.status.idle":"2022-03-12T16:11:48.687142Z","shell.execute_reply.started":"2022-03-12T16:11:48.378534Z","shell.execute_reply":"2022-03-12T16:11:48.685784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}