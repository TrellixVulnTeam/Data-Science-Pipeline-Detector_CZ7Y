{"cells":[{"metadata":{},"cell_type":"markdown","source":"本篇借鉴了[Zhu Kai](https://www.kaggle.com/benjaminkz) 的 [Quora Question Pairs: XGBoost](https://www.kaggle.com/benjaminkz/quora-question-pairs-xgboost)\n\n可以作为XGBoost的入门案例，其中的文本特征分析方法也比较经典易操作！\n\n---"},{"metadata":{"id":"lcURWYCk9bTM","colab_type":"code","outputId":"46004208-c17d-4acb-d17b-58b531ef6afd","colab":{"base_uri":"https://localhost:8080/","height":305},"trusted":true},"cell_type":"code","source":"#Colab中文字体解决办法，https://blog.csdn.net/xieyan0811/article/details/80371201\n!wget -O /usr/share/fonts/truetype/liberation/simhei.ttf https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf","execution_count":null,"outputs":[]},{"metadata":{"id":"08tFaREOkHUm","colab_type":"text"},"cell_type":"markdown","source":"Public和Private榜上的得分也可以在[Quora Question Pairs: XGBoost](https://www.kaggle.com/benjaminkz/quora-question-pairs-xgboost)上查看。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"id":"isoxNJd1j6c3","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom string import punctuation","execution_count":null,"outputs":[]},{"metadata":{"id":"tZB-bpqf5Lzi","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nmatplotlib.rcParams['font.family']='simhei'#修改了全局变量\nmatplotlib.rcParams['font.size']=20\n\nzhfont = matplotlib.font_manager.FontProperties(fname='/usr/share/fonts/truetype/liberation/simhei.ttf')\nplt.rcParams['axes.unicode_minus'] = False # 用来正常显示负号","execution_count":null,"outputs":[]},{"metadata":{"id":"xom3icKnmxmq","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/quora-question-pairs/'\ncsv_train = path+\"train.csv\"\ncsv_test = path+\"test.csv\"\ntrain_orig = pd.read_csv(csv_train)\ntest_orig = pd.read_csv(csv_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"NiucedQ510VY","colab_type":"code","outputId":"a84fcfdc-081b-47a5-e4f5-21eba9bd32a4","colab":{"base_uri":"https://localhost:8080/","height":499},"trusted":true},"cell_type":"code","source":"display(train_orig.shape)\ndisplay(train_orig.head())\ndisplay(test_orig.shape)\ndisplay(test_orig.head())\n\nprint('潜在相似问题对数量: {}'.format(train_orig.shape[0]))\nprint('\\'is_duplicate\\' 正例比例: {}%'.format(round(train_orig['is_duplicate'].mean()*100, 2)))\nqids = pd.Series(train_orig['qid1'].tolist() + train_orig['qid2'].tolist())\nprint('总问题数量: {}'.format(len(np.unique(qids))))\nprint('\"重复问题\" 出现次数: {}'.format(np.sum(qids.value_counts() > 1)))","execution_count":null,"outputs":[]},{"metadata":{"id":"jykgrIli1V3l","colab_type":"code","outputId":"e385bc10-58bf-46dd-a694-0a57838562ac","colab":{"base_uri":"https://localhost:8080/","height":392},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.hist(qids.value_counts(), bins=50)\nplt.yscale('log', nonposy='clip')\nplt.title('问题出现次数的对数直方图', fontproperties=zhfont)\nplt.xlabel('问题出现的频数', fontproperties=zhfont)\nplt.ylabel('频数计数', fontproperties=zhfont)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"AR9qK8OQkldk","colab_type":"text"},"cell_type":"markdown","source":"# 1 数据清洗\n\n本次任务的数据清洗工作较为繁重，为了照顾到后续特征提取的不同需要，本文生成了以下多个版本的训练集和测试集：\n\n<table>\n<tr><td>train_orig.csv、test_orig.csv</td><td>在原始数据集的基础上，处理缺失，转换同义词，转义标点符号</td></tr>\n<tr><td>train_stop.csv、test_stop.csv</td><td>在train_orig/test_orig的基础上，去除停用词</td></tr>\n<tr><td>train_stem.csv、test_stem.csv</td><td>在train_stop/test_stop的基础上，提取单词词根</td></tr>\n<tr><td>train_lem.csv、test_lem.csv</td><td>在train_stop/test_stop的基础上，还原单词的原型</td></tr>\n</table>"},{"metadata":{"id":"g-XbMiimmlHb","colab_type":"text"},"cell_type":"markdown","source":"## 处理缺失，转换同义词，转义标点符号"},{"metadata":{"id":"tfm78KWeoYCK","colab_type":"text"},"cell_type":"markdown","source":"### 处理空值\n\n填补空值，这里不能丢弃空值"},{"metadata":{"id":"x1ATrqaomkjd","colab_type":"code","outputId":"a4e8ac63-68da-4350-bb41-23c9977c2991","colab":{"base_uri":"https://localhost:8080/","height":215},"trusted":true},"cell_type":"code","source":"print(train_orig.isnull().sum())\nprint(test_orig.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"id":"uNg32W48o2wU","colab_type":"code","outputId":"6176b60a-eac4-4842-eb48-e22a8d1275b3","colab":{"base_uri":"https://localhost:8080/","height":360},"trusted":true},"cell_type":"code","source":"display(train_orig[train_orig.isnull().values==True])\ndisplay(test_orig[test_orig.isnull().values==True])","execution_count":null,"outputs":[]},{"metadata":{"id":"0PshSryUqx9L","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_orig = train_orig.fillna(\" \")\ntest_orig = test_orig.fillna(\" \")","execution_count":null,"outputs":[]},{"metadata":{"id":"wTYsSzJKssk4","colab_type":"text"},"cell_type":"markdown","source":"原始数据集中存在许多同义表述，以及标点符号和杂乱的特殊符号。本文首先将所有文本转换为小写，其次把常见缩写替换成没有缩写的形式，再次去除标点符号和特殊符号，最后是从其他kernel上收集到的单词替换。定义common_words_transformation_remove_punctuation函数来完成以上过程，得到第一层样本train_orig/test_orig。"},{"metadata":{"id":"T_bfZ9YwtPbB","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#apply显示进度条\nfrom tqdm import tqdm\ntqdm.pandas(desc=\"my bar!\")","execution_count":null,"outputs":[]},{"metadata":{"id":"acEo_OgvtP9B","colab_type":"code","outputId":"36a76f85-70db-4582-ec56-cc172a33b0e2","colab":{"base_uri":"https://localhost:8080/","height":276},"trusted":true},"cell_type":"code","source":"def common_words_transformation_remove_punctuation(text):\n    #转换为小写\n    text = text.lower()\n\n    #清理字符\n    text = re.sub(r\"what's\", \"what is\", text)\n    text = re.sub(r\"who's\", \"who is\", text)\n    text = re.sub(r\"where's\", \"where is\", text)\n    text = re.sub(r\"when's\", \"when is\", text)\n    text = re.sub(r\"how's\", \"how is\", text)\n    text = re.sub(r\"it's\", \"it is\", text)\n    text = re.sub(r\"he's\", \"he is\", text)\n    text = re.sub(r\"she's\", \"she is\", text)\n    text = re.sub(r\"that's\", \"that is\", text)\n    text = re.sub(r\"there's\", \"there is\", text)\n\n    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n    text = re.sub(r\"\\'s\", \" \", text)  # 除了上面的特殊情况外，“\\'s”只能表示所有格，应替换成“ ”\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"can not \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am\", text)\n    text = re.sub(r\" m \", \" am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"60k\", \" 60000 \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e-mail\", \"email\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = re.sub(r\"quikly\", \"quickly\", text)\n    text = re.sub(r\" usa \", \" america \", text)\n    text = re.sub(r\" u s \", \" america \", text)\n    text = re.sub(r\" uk \", \" england \", text)\n    text = re.sub(r\"imrovement\", \"improvement\", text)\n    text = re.sub(r\"intially\", \"initially\", text)\n    text = re.sub(r\" dms \", \"direct messages \", text)  \n    text = re.sub(r\"demonitization\", \"demonetization\", text) \n    text = re.sub(r\"actived\", \"active\", text)\n    text = re.sub(r\"kms\", \" kilometers \", text)\n    text = re.sub(r\" cs \", \" computer science \", text)\n    text = re.sub(r\" ds \", \" data science \", text)\n    text = re.sub(r\" ee \", \" electronic engineering \", text)\n    text = re.sub(r\" upvotes \", \" up votes \", text)\n    text = re.sub(r\" iphone \", \" phone \", text)\n    text = re.sub(r\"\\0rs \", \" rs \", text) \n    text = re.sub(r\"calender\", \"calendar\", text)\n    text = re.sub(r\"ios\", \"operating system\", text)\n    text = re.sub(r\"programing\", \"programming\", text)\n    text = re.sub(r\"bestfriend\", \"best friend\", text)\n    text = re.sub(r\"III\", \"3\", text) \n    text = re.sub(r\"the us\", \"america\", text)\n    text = re.sub(r\",\", \" \", text)\n    text = re.sub(r\"\\.\", \" \", text)\n    text = re.sub(r\"!\", \" \", text)\n    text = re.sub(r\"\\/\", \" \", text)\n    text = re.sub(r\"\\^\", \" \", text)\n    text = re.sub(r\"\\+\", \" \", text)\n    text = re.sub(r\"\\-\", \" \", text)\n    text = re.sub(r\"\\=\", \" \", text)\n    text = re.sub(r\"'\", \" \", text)\n    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n    text = re.sub(r\":\", \" \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    \n    text = \"\".join([c for c in text if c not in punctuation])\n        \n    return text\n\n\n#train_orig[\"question1\"] = train_orig[\"question1\"].apply(common_words_transformation_remove_punctuation)\n#train_orig[\"question2\"] = train_orig[\"question2\"].apply(common_words_transformation_remove_punctuation)\n#test_orig[\"question1\"] = test_orig[\"question1\"].apply(common_words_transformation_remove_punctuation)\n#test_orig[\"question2\"] = test_orig[\"question2\"].apply(common_words_transformation_remove_punctuation)\n\ntrain_orig[\"question1\"] = train_orig[\"question1\"].progress_apply(common_words_transformation_remove_punctuation)\ntrain_orig[\"question2\"] = train_orig[\"question2\"].progress_apply(common_words_transformation_remove_punctuation)\ntest_orig[\"question1\"] = test_orig[\"question1\"].progress_apply(common_words_transformation_remove_punctuation)\ntest_orig[\"question2\"] = test_orig[\"question2\"].progress_apply(common_words_transformation_remove_punctuation)\n\n#保存为文件\ntrain_orig.to_csv(\"train_orig_trans.csv\", index = False)\ntest_orig.to_csv(\"test_orig_trans.csv\", index = False)\n\ntrain_orig.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"oIfUvCXevF_a","colab_type":"text"},"cell_type":"markdown","source":"### 去除停用词"},{"metadata":{"id":"kS-10PuHvHD3","colab_type":"text"},"cell_type":"markdown","source":"用NLTK中的stopwords清理停用词\n"},{"metadata":{"id":"dui3xAjlvWQe","colab_type":"code","outputId":"9ae2756b-52e9-44e6-f9e5-2f7151cefb9c","colab":{"base_uri":"https://localhost:8080/","height":107},"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')\nstopwords.words(\"english\")\n\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"id":"18AKa0O_vZ5v","colab_type":"code","outputId":"352ed6b9-070d-48bf-eddd-33a9117e63ed","colab":{"base_uri":"https://localhost:8080/","height":276},"trusted":true},"cell_type":"code","source":"def remove_stopwords(text):\n    stops = set(stopwords.words(\"english\"))\n    text = word_tokenize(text)\n    text = [w for w in text if not w in stops]\n    text = \" \".join(text)\n    return text\n\ntrain_stop, test_stop = train_orig.copy(deep = True), test_orig.copy(deep = True)\n\n#train_stop[\"question1\"] = train_stop[\"question1\"].apply(remove_stopwords)\n#train_stop[\"question2\"] = train_stop[\"question2\"].apply(remove_stopwords)\n#test_stop[\"question1\"] = test_stop[\"question1\"].apply(remove_stopwords)\n#test_stop[\"question2\"] = test_stop[\"question2\"].apply(remove_stopwords)\n\ntrain_stop[\"question1\"] = train_stop[\"question1\"].progress_apply(remove_stopwords)\ntrain_stop[\"question2\"] = train_stop[\"question2\"].progress_apply(remove_stopwords)\ntest_stop[\"question1\"] = test_stop[\"question1\"].progress_apply(remove_stopwords)\ntest_stop[\"question2\"] = test_stop[\"question2\"].progress_apply(remove_stopwords)\n\n#保存为文件\ntrain_stop.to_csv(\"train_stop.csv\", index = False)\ntest_stop.to_csv(\"test_stop.csv\", index = False)\n\ntrain_stop.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"J9dteRjKx63Y","colab_type":"text"},"cell_type":"markdown","source":"### 提取单词词根"},{"metadata":{"id":"v9SU51ryx9sW","colab_type":"text"},"cell_type":"markdown","source":"使用NLTK库中的SnowballStemmer提取词根"},{"metadata":{"id":"rfUdKcnUx772","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":276},"outputId":"3ab05b62-128c-4b8d-86c2-a80af6f00061","trusted":true},"cell_type":"code","source":"def stem_words(text):\n    text = word_tokenize(text)\n    stemmer = SnowballStemmer(\"english\")\n    stemmed_words = [stemmer.stem(word) for word in text]\n    text = \" \".join(stemmed_words)\n    return text\n\ntrain_stem, test_stem = train_stop.copy(deep = True), test_stop.copy(deep = True)\n\n#train_stem[\"question1\"] = train_stem[\"question1\"].progress_apply(stem_words)\n#train_stem[\"question2\"] = train_stem[\"question2\"].progress_apply(stem_words)\n#test_stem[\"question1\"] = test_stem[\"question1\"].progress_apply(stem_words)\n#test_stem[\"question2\"] = test_stem[\"question2\"].progress_apply(stem_words)\n\ntrain_stem[\"question1\"] = train_stem[\"question1\"].progress_apply(stem_words)\ntrain_stem[\"question2\"] = train_stem[\"question2\"].progress_apply(stem_words)\ntest_stem[\"question1\"] = test_stem[\"question1\"].progress_apply(stem_words)\ntest_stem[\"question2\"] = test_stem[\"question2\"].progress_apply(stem_words)\n\n#保存为文件\ntrain_stem.to_csv(\"train_stem.csv\", index = False)\ntest_stem.to_csv(\"test_stem.csv\", index = False)\n\ntrain_stem.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"iexxJ006yWAh","colab_type":"text"},"cell_type":"markdown","source":"### 还原单词的原型"},{"metadata":{"id":"z9LNFOiLyW3N","colab_type":"text"},"cell_type":"markdown","source":"使用NLTK中的WordNetLemmatizer还原词的原型"},{"metadata":{"id":"18805jjtyZof","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"9c6fcc5a-f4c3-4b68-ca7f-e678b352c91f","trusted":true},"cell_type":"code","source":"nltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{"id":"bY5gHOXhybnt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":276},"outputId":"e255e1fb-eaab-43a4-d301-f96c8451c2c3","trusted":true},"cell_type":"code","source":"def lemmatize_words(text):\n    text = word_tokenize(text)\n    wordnet_lemmatizer = WordNetLemmatizer()\n    lammatized_words = [wordnet_lemmatizer.lemmatize(word) for word in text]\n    text = \" \".join(lammatized_words)\n    return text\n\ntrain_lem, test_lem = train_stop.copy(deep = True), test_stop.copy(deep = True)\n\n#train_lem[\"question1\"] = train_lem[\"question1\"].apply(lemmatize_words)\n#train_lem[\"question2\"] = train_lem[\"question2\"].apply(lemmatize_words)\n#test_lem[\"question1\"] = test_lem[\"question1\"].apply(lemmatize_words)\n#test_lem[\"question2\"] = test_lem[\"question2\"].apply(lemmatize_words)\n\ntrain_lem[\"question1\"] = train_lem[\"question1\"].progress_apply(lemmatize_words)\ntrain_lem[\"question2\"] = train_lem[\"question2\"].progress_apply(lemmatize_words)\ntest_lem[\"question1\"] = test_lem[\"question1\"].progress_apply(lemmatize_words)\ntest_lem[\"question2\"] = test_lem[\"question2\"].progress_apply(lemmatize_words)\n\ntrain_lem.to_csv(\"train_lem.csv\", index = False)\ntest_lem.to_csv(\"test_lem.csv\", index = False)\n\ntrain_lem.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"V8GwCS9ozNv1","colab_type":"text"},"cell_type":"markdown","source":""},{"metadata":{"id":"QTssiZDIzM_Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":517},"outputId":"9bf3b445-e58f-42c3-8658-e85286dc147a","trusted":true},"cell_type":"code","source":"display(train_orig.head(3)) #符号转义和清除\ndisplay(train_stop.head(3)) #去除停用词\ndisplay(train_stem.head(3)) #提取单词词根\ndisplay(train_lem.head(3)) #还原单词的原型","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**词云**"},{"metadata":{"id":"aGshr35JaxwO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":897},"outputId":"d92ae845-f9c1-47bd-caed-a89dde49d8a2","trusted":true},"cell_type":"code","source":"#train_orig = pd.read_csv('train_orig_trans.csv')\n\ntrain_qs = pd.Series(train_orig['question1'].tolist() + train_orig['question2'].tolist()).astype(str)\n\nfrom wordcloud import WordCloud\ncloud_train = WordCloud(width=1440, height=1080).generate(\" \".join(train_qs.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud_train)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_orig = pd.read_csv('test_orig_trans.csv')\n\ntest_qs = pd.Series(test_orig['question1'].tolist() + test_orig['question2'].tolist()).astype(str)\n\nfrom wordcloud import WordCloud\ncloud_test = WordCloud(width=1440, height=1080).generate(\" \".join(test_qs.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud_test)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"K1LdjnsizTM_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"13b0251d-539b-440c-9651-e3f15b02598d","trusted":true},"cell_type":"code","source":"!ls -lh ","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"clean_and_feature.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}