{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ntrain=pd.read_csv('/kaggle/input/quora-question-pairs/train.csv.zip')\ntrain.head()\ntest=pd.read_csv('/kaggle/input/quora-question-pairs/test.csv.zip')\ntest=test[1:20000]\ntest1=test.copy()\ntrain=train[1:40000]\ntrain['is_duplicate'].value_counts()\n#We can see there is an imbalance in predicted class set.\n#Lets remove the imbalance by upsampling/downsampling the class variables\n#Upsampling\nfrom sklearn.utils import resample\nduplicate_ids=train[train['is_duplicate']==1]\nduplicate_ids\nnot_duplicate_ids=train[train['is_duplicate']==0]\nduplicate_upsampled=resample(duplicate_ids,replace=True,n_samples=len(not_duplicate_ids),random_state=27)\nupsampled=pd.concat([not_duplicate_ids,duplicate_upsampled])\nupsampled['is_duplicate'].value_counts()\nupsampled['question1']=upsampled['question1'].astype(str)\nupsampled['question2']=upsampled['question2'].astype(str)\n#Lets clean up the texts\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps=PorterStemmer()\ndef clean_text(text):\n    text=text.lower()\n    text=re.sub('[^a-zA-Z0-9\\s]','',text)\n    text=text.split()\n    text=[ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n    reviews=' '.join(text)\n    return reviews\nupsampled['question1']=upsampled['question1'].apply(lambda x:clean_text(x))\nupsampled['question1']\nupsampled['question2']=upsampled['question2'].apply(lambda x:clean_text(x))\ntest1['question1']=test1['question1'].apply(lambda x:clean_text(x))\ntest1['question2']=test1['question2'].apply(lambda x:clean_text(x))\n#TF-IDF vectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf=TfidfVectorizer(analyzer='word',max_features=300,norm='l1')\ntfidf_question1=tfidf.fit_transform(upsampled['question1'])\ntfidf_question2=tfidf.fit_transform(upsampled['question2'])\ntest_tfidf_question1=tfidf.fit_transform(test['question1'])\ntest_tfidf_question2=tfidf.fit_transform(test['question2'])\n#Finding the difference of the vocabulary matrix\ntrain_x=abs(tfidf_question1- tfidf_question2)\ntrain_x.shape\ntest_x1=abs(test_tfidf_question1-test_tfidf_question2)\ntest_x1.shape\nY=upsampled['is_duplicate']\nY.shape\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\ntrain_x,test_x,train_y,test_y=train_test_split(train_x,Y,test_size=0.2,random_state=10)\ntrain_x.shape\ntrain_y.shape\ntest_y.shape\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy.stats import randint as sp_randint\nrf=RandomForestClassifier(n_estimators=150,n_jobs=-1)\nmodel=rf.fit(train_x,train_y)\npred=model.predict(test_x)\npred\nfrom sklearn.metrics import accuracy_score,f1_score,recall_score\naccuracy_score(test_y,pred)\nf1_score(test_y,pred)\nrecall_score(test_y,pred)\n#recall_score(test,y_pred)\n#recall_score-0.79\n#f1_score-0.78\npred1=rf.predict(test_x1)\nsubmission = pd.DataFrame({'Question1':test['question1'],'Question2':test['question2'],'is_duplicate':pred1})\nsubmission.head()\nsubmission[submission['is_duplicate']==1]\ntype(train_y)\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nparams={'objective':'binary:logistic',\n        'eval_metric':'auc',\n        'eta':0.01,\n        'max_depth':100,\n        'subsample':0.6,\n        'alpha':0.01,\n        'random_state':10,\n        'device':'gpu'\n       }\ntr_x=xgb.DMatrix(train_x,train_y)\ntr_x\nts_x=xgb.DMatrix(test_x)\nts_x1=xgb.DMatrix(test_x1)\nmodel=xgb.train(params,tr_x,2000)\npred_xg=model.predict(ts_x)\npred_xg\nfor i in range(0,10044):\n    if pred_xg[i]>0.5:\n        pred_xg[i]=1\n    else:\n        pred_xg[i]=0\naccuracy_score(test_y,pred_xg)\nf1_score(test_y,pred_xg)\nrecall_score(test_y,pred_xg)\npred_xg1=model.predict(ts_x1)\nfor i in range(0,19999):\n    if pred_xg1[i]>0.5:\n        pred_xg1[i]=1\n    else:\n        pred_xg1[i]=0\n\nsubmission = pd.DataFrame({'Question1':test['question1'],'Question2':test['question2'],'is_duplicate':pred_xg1})\nsubmission.head()\nsubmission[submission['is_duplicate']==1]\n#Recall Score-0.85\n#F-Score-0.80\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nos.listdir('../input')\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}