{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport warnings\nfrom warnings import simplefilter\nsimplefilter(action = 'ignore',category = FutureWarning)\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, logging\nlogging.set_verbosity_error()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T13:53:06.352431Z","iopub.execute_input":"2022-04-13T13:53:06.352756Z","iopub.status.idle":"2022-04-13T13:53:12.652408Z","shell.execute_reply.started":"2022-04-13T13:53:06.352677Z","shell.execute_reply":"2022-04-13T13:53:12.651638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(torch.__version__)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:12.654112Z","iopub.execute_input":"2022-04-13T13:53:12.65436Z","iopub.status.idle":"2022-04-13T13:53:12.714964Z","shell.execute_reply.started":"2022-04-13T13:53:12.654328Z","shell.execute_reply":"2022-04-13T13:53:12.713819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 2345\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:12.716469Z","iopub.execute_input":"2022-04-13T13:53:12.717362Z","iopub.status.idle":"2022-04-13T13:53:12.726057Z","shell.execute_reply.started":"2022-04-13T13:53:12.717185Z","shell.execute_reply":"2022-04-13T13:53:12.725314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/quora-question-pairs/train.csv.zip\")\ntrain_df.dropna(inplace=True)\ntrain_sentences_lens = train_df['question1'].apply(lambda x: len(x.split(' '))).tolist()\ntrain_sentences_lens.extend(train_df['question2'].apply(lambda x: len(x.split(' '))).tolist())\nsns.distplot(train_sentences_lens)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:12.728284Z","iopub.execute_input":"2022-04-13T13:53:12.728745Z","iopub.status.idle":"2022-04-13T13:53:18.622599Z","shell.execute_reply.started":"2022-04-13T13:53:12.728708Z","shell.execute_reply":"2022-04-13T13:53:18.621928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 40","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:18.623865Z","iopub.execute_input":"2022-04-13T13:53:18.624147Z","iopub.status.idle":"2022-04-13T13:53:18.628136Z","shell.execute_reply.started":"2022-04-13T13:53:18.624112Z","shell.execute_reply":"2022-04-13T13:53:18.627403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pie_chart(similar_questions_num, different_questions_num, set_type):\n    labels = 'Similiar', 'Different'\n    sizes = [similar_questions_num, different_questions_num]\n\n    fig1, ax1 = plt.subplots()\n    ax1.set_title(set_type)\n    ax1.pie(sizes, labels=labels, autopct='%1.2f%%', shadow=True, startangle=90)\n\n    plt.show()\n\nsimilar_samples_num = sum(train_df['is_duplicate'].values)\npie_chart(similar_samples_num, len(train_df['is_duplicate']) - similar_samples_num, 'train set')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:18.629399Z","iopub.execute_input":"2022-04-13T13:53:18.62994Z","iopub.status.idle":"2022-04-13T13:53:18.809085Z","shell.execute_reply.started":"2022-04-13T13:53:18.629903Z","shell.execute_reply":"2022-04-13T13:53:18.808329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qids = pd.Series(list(train_df['qid1']) + list(train_df['qid2']))\n\nprint ('Unique Questions number: {}\\n'.format(len(np.unique(qids))))\n\nq_vals=qids.value_counts()[0:5]\nprint ('Top 5 most frequently asked questions: ')\n\nfor pair in q_vals.iteritems():\n    print(train_df.loc[train_df['qid2']==pair[0]]['question1'].head(1).values + \" count: \" + str(pair[1]))\n\nq_vals=q_vals.values","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:18.81036Z","iopub.execute_input":"2022-04-13T13:53:18.811074Z","iopub.status.idle":"2022-04-13T13:53:19.431274Z","shell.execute_reply.started":"2022-04-13T13:53:18.811025Z","shell.execute_reply":"2022-04-13T13:53:19.430563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicate_rows = train_df[train_df.duplicated(['qid1','qid2'])]\nprint (\"Number of duplicate questions : \", len(duplicate_rows))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:19.432504Z","iopub.execute_input":"2022-04-13T13:53:19.43279Z","iopub.status.idle":"2022-04-13T13:53:19.482835Z","shell.execute_reply.started":"2022-04-13T13:53:19.432756Z","shell.execute_reply":"2022-04-13T13:53:19.481959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = [\"Unique\" , \"Repeated\"]\ny =  [len(np.unique(qids)), np.sum(qids.value_counts() > 1)]\n\nplt.figure(figsize=(10, 8))\nplt.title (\"Unique and Repeated questions counts\")\nsns.barplot(x,y)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:19.484378Z","iopub.execute_input":"2022-04-13T13:53:19.484648Z","iopub.status.idle":"2022-04-13T13:53:19.759135Z","shell.execute_reply.started":"2022-04-13T13:53:19.484612Z","shell.execute_reply":"2022-04-13T13:53:19.75817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def common_words(row):\n    q1_word_set = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    q2_word_set = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return 1.0 * len(q1_word_set & q2_word_set)\n\ntrain_df['common_words'] = train_df.apply(common_words, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:19.762501Z","iopub.execute_input":"2022-04-13T13:53:19.762743Z","iopub.status.idle":"2022-04-13T13:53:30.449618Z","shell.execute_reply.started":"2022-04-13T13:53:19.762713Z","shell.execute_reply":"2022-04-13T13:53:30.448878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nplt.subplot(1,2,2)\nsns.distplot(train_df[train_df['is_duplicate'] == 1]['common_words'][0:] , label = \"1\", color = 'red')\nsns.distplot(train_df[train_df['is_duplicate'] == 0]['common_words'][0:] , label = \"0\" , color = 'blue' )\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y = 'common_words', data = train_df[0:])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:30.450763Z","iopub.execute_input":"2022-04-13T13:53:30.451065Z","iopub.status.idle":"2022-04-13T13:53:33.172625Z","shell.execute_reply.started":"2022-04-13T13:53:30.451021Z","shell.execute_reply":"2022-04-13T13:53:33.171951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of common words between question1 and question2 divided by total words between both of them\ndef shared_words(row):\n    q1_word_set = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    q2_word_set = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n    return 1.0 * len(q1_word_set & q2_word_set) / (len(q1_word_set) + len(q2_word_set))    \n\ntrain_df['shared_words'] = train_df.apply(shared_words, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:33.17365Z","iopub.execute_input":"2022-04-13T13:53:33.173875Z","iopub.status.idle":"2022-04-13T13:53:44.256595Z","shell.execute_reply.started":"2022-04-13T13:53:33.173843Z","shell.execute_reply":"2022-04-13T13:53:44.255867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nplt.subplot(1,2,2)\nsns.distplot(train_df[train_df['is_duplicate'] == 1]['shared_words'][0:] , label = \"1\", color = 'red')\nsns.distplot(train_df[train_df['is_duplicate'] == 0]['shared_words'][0:] , label = \"0\" , color = 'green' )\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y = 'shared_words', data = train_df[0:])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:44.257926Z","iopub.execute_input":"2022-04-13T13:53:44.258185Z","iopub.status.idle":"2022-04-13T13:53:47.135635Z","shell.execute_reply.started":"2022-04-13T13:53:44.258149Z","shell.execute_reply":"2022-04-13T13:53:47.134875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BERT_VERSION = 'bert-base-uncased'\nPOOLED_OUTPUT_DIM = 768 \ntokenizer = BertTokenizer.from_pretrained(BERT_VERSION)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:53:47.137013Z","iopub.execute_input":"2022-04-13T13:53:47.137395Z","iopub.status.idle":"2022-04-13T13:54:00.376126Z","shell.execute_reply.started":"2022-04-13T13:53:47.137359Z","shell.execute_reply":"2022-04-13T13:54:00.375391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split data to train and validation sets\ntrain_df, val_df = train_test_split(train_df, test_size=0.1)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:00.377371Z","iopub.execute_input":"2022-04-13T13:54:00.377649Z","iopub.status.idle":"2022-04-13T13:54:00.571813Z","shell.execute_reply.started":"2022-04-13T13:54:00.37761Z","shell.execute_reply":"2022-04-13T13:54:00.571095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertDataSet:\n    def __init__(self, first_questions, second_questions, targets, tokenizer):\n        self.first_questions = first_questions\n        self.second_questions = second_questions\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.length = len(first_questions)\n        \n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, item):\n        first_question = str(self.first_questions[item])\n        second_question = str(self.second_questions[item])\n\n        # removes extra white spaces from questions\n        first_question = \" \".join(first_question.split())\n        second_question = \" \".join(second_question.split())\n        \n        ### [CLS] question1 [SEP] questions2 [SEP] ... [PAD]\n        inputs = self.tokenizer.encode_plus(\n            first_question,\n            second_question,\n            add_special_tokens=True,\n            padding='max_length',\n            max_length=2 * MAX_LEN + 3, # max length of 2 questions and 3 special tokens\n            truncation=True   \n        )\n        \n        # return targets 0, when using data set in testing and targets are none\n        return {\n            \"ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n            \"mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n            \"token_type_ids\": torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n            \"targets\": torch.tensor(int(self.targets[item]), dtype=torch.long) if self.targets is not None else 0\n        }\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:00.573212Z","iopub.execute_input":"2022-04-13T13:54:00.573758Z","iopub.status.idle":"2022-04-13T13:54:00.584652Z","shell.execute_reply.started":"2022-04-13T13:54:00.57371Z","shell.execute_reply":"2022-04-13T13:54:00.583686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creates dataset and returns dataloader of it\ndef get_data_loader(df, targets, batch_size, shuffle, tokenizer):\n    dataset = BertDataSet(\n        first_questions=df[\"question1\"].values,\n        second_questions=df[\"question2\"].values,\n        targets=targets,\n        tokenizer=tokenizer\n    )\n    \n    data_loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size = batch_size,\n        shuffle=shuffle\n    )\n    \n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:00.586205Z","iopub.execute_input":"2022-04-13T13:54:00.586649Z","iopub.status.idle":"2022-04-13T13:54:00.596643Z","shell.execute_reply.started":"2022-04-13T13:54:00.586608Z","shell.execute_reply":"2022-04-13T13:54:00.595771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training batch size we gonna use throughout this notebook.\nBS = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:00.597763Z","iopub.execute_input":"2022-04-13T13:54:00.598453Z","iopub.status.idle":"2022-04-13T13:54:00.609073Z","shell.execute_reply.started":"2022-04-13T13:54:00.598407Z","shell.execute_reply":"2022-04-13T13:54:00.608269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create data loaders of training and validation data.\ntrain_data_loader = get_data_loader(\n    df=train_df,\n    targets=train_df[\"is_duplicate\"].values,\n    batch_size=BS,\n    shuffle=True,\n    tokenizer=tokenizer\n)\n\nval_data_loader = get_data_loader(\n    df=val_df,\n    targets=val_df[\"is_duplicate\"].values,\n    batch_size=4 * BS,\n    shuffle=True,\n    tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:00.612766Z","iopub.execute_input":"2022-04-13T13:54:00.613479Z","iopub.status.idle":"2022-04-13T13:54:00.621927Z","shell.execute_reply.started":"2022-04-13T13:54:00.613433Z","shell.execute_reply":"2022-04-13T13:54:00.62112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertModel(nn.Module):\n    def __init__(self, bert_path):\n        super(BertModel, self).__init__()\n        self.bert_path = bert_path\n        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n        self.dropout = nn.Dropout(0.3)\n        self.out = nn.Linear(POOLED_OUTPUT_DIM, 1)\n\n    def forward(self, ids, mask, token_type_ids):\n        _, pooled = self.bert(ids, attention_mask=mask,token_type_ids=token_type_ids,return_dict = False)\n        \n        # add dropout to prevent overfitting.\n        pooled = self.dropout(pooled) \n        return self.out(pooled)\n\nmodel = BertModel(BERT_VERSION).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:00.623464Z","iopub.execute_input":"2022-04-13T13:54:00.624359Z","iopub.status.idle":"2022-04-13T13:54:31.044051Z","shell.execute_reply.started":"2022-04-13T13:54:00.624316Z","shell.execute_reply":"2022-04-13T13:54:31.043157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss function is simple binary cross entropy loss\n# need sigmoid to put probabilities in [0,1] interval\ndef loss_fn(outputs, targets):\n    outputs = torch.squeeze(outputs)\n    return nn.BCELoss()(nn.Sigmoid()(outputs), targets)\n\n# computes perplexity on validation data\ndef calculate_perplexity(data_loader, model, device):\n    model.eval()\n    \n    # tells Pytorch not to store values of intermediate computations for backward pass because we not gonna need gradients.\n    with torch.no_grad():\n        total_loss = 0\n        for batch in data_loader:\n            ids = batch[\"ids\"].to(device, dtype=torch.long)\n            mask = batch[\"mask\"].to(device, dtype=torch.long)\n            token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n            targets = batch[\"targets\"].to(device, dtype=torch.float)\n\n            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n            total_loss += loss_fn(outputs, targets).item()\n            \n    model.train()\n\n    return np.exp(total_loss / len(data_loader))\n\ndef train_loop(epochs, train_data_loader, val_data_loader, model, optimizer, device, scheduler=None):\n    it = 1\n    total_loss = 0\n    curr_perplexity = None\n    perplexity = None\n    \n    model.train()\n    for epoch in range(epochs):\n        print('Epoch: ', epoch + 1)\n        for batch in train_data_loader:\n            ids = batch[\"ids\"].to(device, dtype=torch.long)\n            mask = batch[\"mask\"].to(device, dtype=torch.long)\n            token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n            targets = batch[\"targets\"].to(device, dtype=torch.float)\n\n            optimizer.zero_grad()\n            \n            # do forward pass, will save intermediate computations of the graph for later backprop use.\n            outputs = model(ids, mask=mask, token_type_ids=token_type_ids)\n            \n            loss = loss_fn(outputs, targets)\n            total_loss += loss.item()\n            \n            # running backprop.\n            loss.backward()\n            \n            # doing gradient descent step.\n            optimizer.step()\n            \n            # we are logging current loss/perplexity in every 100 iteration\n            if it % 100 == 0:\n                \n                # computing validation set perplexity in every 500 iteration.\n                if it % 500 == 0:\n                    curr_perplexity = calculate_perplexity(val_data_loader, model, device)\n                    \n                    if scheduler is not None:\n                        scheduler.step()\n\n                    # making checkpoint of best model weights.\n                    if not perplexity or curr_perplexity < perplexity:\n                        torch.save(model.state_dict(), 'saved_model')\n                        perplexity = curr_perplexity\n\n                print('| Iter', it, '| Avg Train Loss', total_loss / 100, '| Dev Perplexity', curr_perplexity)\n                total_loss = 0\n\n            it += 1\n\ndef run(model, train_df, device, train_data_loader, val_data_loader):\n    EPOCHS = 1\n    \n    lr = 3e-5\n    num_training_steps = int(len(train_data_loader) * EPOCHS)\n    optimizer = AdamW(model.parameters(), lr=lr)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=0,\n        num_training_steps=num_training_steps\n    )\n    \n    \n    train_loop(EPOCHS, train_data_loader, val_data_loader,  model, optimizer, device, scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:31.046339Z","iopub.execute_input":"2022-04-13T13:54:31.046802Z","iopub.status.idle":"2022-04-13T13:54:31.06855Z","shell.execute_reply.started":"2022-04-13T13:54:31.046755Z","shell.execute_reply":"2022-04-13T13:54:31.06724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run(model, train_df, device, train_data_loader, val_data_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:54:31.070076Z","iopub.execute_input":"2022-04-13T13:54:31.070614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/quora-question-pairs/test.csv\")\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, test_df, device):\n    predictions = torch.empty(0).to(device, dtype=torch.float)\n    \n    test_dataset = BertDataSet(\n        first_questions=test_df[\"question1\"].values,\n        second_questions=test_df[\"question2\"].values,\n        targets=None,\n        tokenizer=tokenizer\n    )\n    \n    test_data_loader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=512\n    )\n    \n    with torch.no_grad():\n        model.eval()\n        for batch in tqdm(test_data_loader):\n            ids = batch[\"ids\"]\n            mask = batch[\"mask\"]\n            token_type_ids = batch[\"token_type_ids\"]\n\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n\n            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n            predictions = torch.cat((predictions, nn.Sigmoid()(outputs)))\n    \n    return predictions.cpu().numpy().squeeze()\n\npredictions = test(model, test_df, device)\nlen(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['is_duplicate'] = predictions\ntest_df[['test_id', 'is_duplicate']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval(model, tokenizer, first_question, second_question, device):\n    inputs = tokenizer.encode_plus(\n        first_question,\n        second_question,\n        add_special_tokens=True,\n    )\n\n    ids = torch.tensor([inputs[\"input_ids\"]], dtype=torch.long).to(device, dtype=torch.long)\n    mask = torch.tensor([inputs[\"attention_mask\"]], dtype=torch.long).to(device, dtype=torch.long)\n    token_type_ids = torch.tensor([inputs[\"token_type_ids\"]], dtype=torch.long).to(device, dtype=torch.long)\n\n    with torch.no_grad():\n        model.eval()\n        output = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n        prob = nn.Sigmoid()(output).item()\n\n        print(\"questions [{}] and [{}] are {} with score {}\".format(first_question, second_question, 'similar' if prob > 0.5 else 'not similar', prob))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change questions to test model\nfirst_question = \"how to register on hackerrank with google account?\"\nsecond_question = \"Can I sign using google account on hackerrank?\"\n\neval(model, tokenizer, first_question, second_question, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}