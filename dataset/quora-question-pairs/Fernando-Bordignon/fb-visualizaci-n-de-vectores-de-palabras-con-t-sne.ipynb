{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Visualización de vectores de palabras con t-SNE\n\nTSNE es una técnica útil a aplicar cuando se trata de visualizar la similitud entre objetos. Funciona tomando un grupo de vectores de características de palabras de vocabulario de alta dimensión (100 dimensiones a través de Word2Vec), y luego los comprime a pares de coordenadas x,y de 2 dimensiones. La idea es mantener las palabras similares cerca en el plano, mientras se maximiza la distancia entre las palabras no similares.\n\nPasos\n* Limpiar los datos\n* Construir un corpus\n* Entrenar un modelo Word2Vec\n* Visualizar las representaciones t-SNE de las palabras más comunes\n\nOriginal y crédito: https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne y \nhttps://github.com/rouseguy/DeepLearning-NLP\n\nEl corpus a usar es Quora Question Pairs (Pares de preguntas de Quora)\n\nPerteneció a un concurso bajo la pregunta ¿Puedes identificar los pares de preguntas que tienen la misma intención?. El objetivo de este concurso fue predecir cuáles de los pares de preguntas proporcionados contienen dos preguntas con el mismo significado. La verdad básica es el conjunto de etiquetas que han sido suministradas por expertos humanos. Las etiquetas de la verdad básica son intrínsecamente subjetivas, ya que el verdadero significado de las frases nunca puede conocerse con certeza. Además, el etiquetado humano es un proceso \"ruidoso\" y las personas razonables pueden discrepar. Por lo tanto, las etiquetas de la verdad sobre el terreno en este conjunto de datos deben considerarse \"informadas\", pero no 100% exactas, y pueden incluir un etiquetado incorrecto. Creemos que las etiquetas, en general, representan un consenso razonable, pero a menudo esto puede no ser cierto en cada caso para los elementos individuales en el conjunto de datos.\n\nEstructura  de datos\n* id - el id de un par de preguntas del conjunto de entrenamiento\n* qid1, qid2 - identificadores únicos de cada pregunta (sólo disponibles en train.csv)\n* question1, question2 - el texto completo de cada pregunta\n* is_duplicate - la variable de destino, establecida en 1 si la pregunta1 y la pregunta2 tienen esencialmente el mismo significado, y 0 en caso contrario.\n","metadata":{}},{"cell_type":"code","source":"# Carga de librerías\n\nimport pandas as pd\npd.options.mode.chained_assignment = None \nimport numpy as np\nimport re\nimport nltk\n\nfrom gensim.models import word2vec\n\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Carga del conjunto de datos en un dataframe\ndata = pd.read_csv('../input/quora-question-pairs/train.csv.zip').sample(50000, random_state=23)\n\n# carga de conjunto de datos de palabra vacías\nSTOP_WORDS = nltk.corpus.stopwords.words()\n\n# Procedimiento para eliminar los caracteres que no son letras o números, reducir las mayúsculas, \n# y luego eliminar las palabras vacías\n\ndef clean_sentence(val): \n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', val).lower()\n    sentence = sentence.split(\" \")\n    \n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)  \n            \n    sentence = \" \".join(sentence)\n    return sentence\n\n# Procedimiento para borrar nans, luego aplicar la función 'clean_sentence' a la pregunta1 y 2\"\n\ndef clean_dataframe(data):\n    data = data.dropna(how=\"any\")\n    \n    for col in ['question1', 'question2']:\n        data[col] = data[col].apply(clean_sentence)\n    \n    return data\n\ndata = clean_dataframe(data)\n\ndata.head(5) # mostrar daatos limpios","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-27T21:38:32.751274Z","iopub.execute_input":"2022-01-27T21:38:32.751644Z","iopub.status.idle":"2022-01-27T21:39:42.262852Z","shell.execute_reply.started":"2022-01-27T21:38:32.751557Z","shell.execute_reply":"2022-01-27T21:39:42.261782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_corpus(data): #  Crea una lista de listas con palabras de cada pregunta q\n    corpus = []\n    for col in ['question1', 'question2']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(data)        \n\nprint(len(corpus)) # Cantidad de elementos en la lista armada\nprint(corpus[0:4]) # Se muestran los primeros 4 elementos de la lista\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T21:43:04.245095Z","iopub.execute_input":"2022-01-27T21:43:04.24563Z","iopub.status.idle":"2022-01-27T21:43:04.622134Z","shell.execute_reply.started":"2022-01-27T21:43:04.24558Z","shell.execute_reply":"2022-01-27T21:43:04.621285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# la técnica Word2Vec produce un vocabulario en el que cada palabra está representada por una \n# matriz numpy n-dimensional (100 valores en este ejemplo)\n\nmodel = word2vec.Word2Vec(corpus, vector_size=100, window=20, min_count=200, workers=4)\n\nmodel.wv['trump']","metadata":{"execution":{"iopub.status.busy":"2022-01-27T21:47:05.170533Z","iopub.execute_input":"2022-01-27T21:47:05.171239Z","iopub.status.idle":"2022-01-27T21:47:07.357899Z","shell.execute_reply.started":"2022-01-27T21:47:05.171198Z","shell.execute_reply":"2022-01-27T21:47:07.356802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se aplica la técnica TSNE para visualizar datos y sus relaciones\n\ndef tsne_plot(model): # Se crea un modelo tsne y se grafican los datos\n    \n    labels = []\n    tokens = []\n\n    for word in list(model.wv.key_to_index):\n        tokens.append(model.wv[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 30)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()\n\ntsne_plot(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T21:54:35.802966Z","iopub.execute_input":"2022-01-27T21:54:35.803633Z","iopub.status.idle":"2022-01-27T21:54:49.780474Z","shell.execute_reply.started":"2022-01-27T21:54:35.803595Z","shell.execute_reply":"2022-01-27T21:54:49.779924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Un modelo más selectivo, tiene en cuenta las palabras que al menos tienen 500 repeticiones en el corpus\n\nmodel = word2vec.Word2Vec(corpus, vector_size=100, window=20, min_count=500, workers=4)\n\ntsne_plot(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T21:56:14.014943Z","iopub.execute_input":"2022-01-27T21:56:14.015738Z","iopub.status.idle":"2022-01-27T21:56:19.64615Z","shell.execute_reply.started":"2022-01-27T21:56:14.015693Z","shell.execute_reply":"2022-01-27T21:56:19.645551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Con un conjunto de datos tan grande, es difícil hacer una visualización de TSNE fácil de leer. Lo que se puede \n# hacer es utilizar el modelo para buscar las palabras más parecidas a partir de un punto determinado.\n\nmodel.wv.most_similar('trump')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T21:59:00.434964Z","iopub.execute_input":"2022-01-27T21:59:00.435323Z","iopub.status.idle":"2022-01-27T21:59:00.45165Z","shell.execute_reply.started":"2022-01-27T21:59:00.435287Z","shell.execute_reply":"2022-01-27T21:59:00.450672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.wv.most_similar('university')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T22:00:46.096611Z","iopub.execute_input":"2022-01-27T22:00:46.096962Z","iopub.status.idle":"2022-01-27T22:00:46.107287Z","shell.execute_reply.started":"2022-01-27T22:00:46.096927Z","shell.execute_reply":"2022-01-27T22:00:46.106396Z"},"trusted":true},"execution_count":null,"outputs":[]}]}