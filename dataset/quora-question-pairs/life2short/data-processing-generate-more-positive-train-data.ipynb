{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"dc5eaed1-c93e-2d4f-d716-e7e71147cb2a"},"source":"# Just like the old saying:\n### *All happy families resemble each other, while unhappy ones each have their own problems.*\n# So we can assume:\n### Duplicated questions resemble each other, while unduplicated questions have their own differences."},{"cell_type":"markdown","metadata":{"_cell_guid":"d375e0ea-47af-1e89-a525-71d31a718960"},"source":"Suppose  if A=B and B=C, we assume that A=C\n\nFor example:  if we have this kind of data, and they are duplicated\n\n    [qid1,qid2]\n    [1,2]\n    [1,3]\n    [11,2]\n    [12,2]\n\nso we can get [1,2,3,11,12] are duplicated questions, \nso we can generate more positive training data:\n\n    [1,2]\n    [1,3]\n    [1,11]\n    [1,12]\n    [2,3]\n    [2,11]\n    [2,12]\n    [3,11]\n    [3,12]\n    [11,12]"},{"cell_type":"markdown","metadata":{"_cell_guid":"ce2c0eea-286a-6a52-cc3d-e25e9ef94109"},"source":"Let's do it"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"13d3633c-304b-73b6-42ed-095405821ce4"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom IPython.display import  display\nfrom collections import defaultdict\nfrom itertools import combinations\npd.set_option('display.max_colwidth',-1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c61360cf-cdf8-2488-6e0f-dad353596d8d"},"outputs":[],"source":"train_df=pd.read_csv('../input/train.csv')\ntrain_df.head(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51beebec-1c45-8174-3d67-a8fffb07891d"},"outputs":[],"source":"# only duplicated questions\nddf=train_df[train_df.is_duplicate==1]\nprint('Duplicated questions shape:',ddf.shape)\nddf.head(2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ed9e9815-7eef-f0bb-78f9-d6332b0ba889"},"source":"There are 149263 pairs duplicated questions"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d04940a-16aa-87ea-228e-f7e8321356d9"},"outputs":[],"source":"# get all duplicated questions\nclean_ddf1=ddf[['qid1','question1']].drop_duplicates()\nclean_ddf1.columns=['qid','question']\nclean_ddf2=ddf[['qid2','question2']].drop_duplicates()\nclean_ddf2.columns=['qid','question']\nall_dqdf=clean_ddf1.append(clean_ddf2,ignore_index=True)\nprint(all_dqdf.shape)\nall_dqdf.head(2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b4fa7073-2191-6137-babc-b5326070c07c"},"source":"There are 172286 questions in the above df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c624518-fcae-99c8-3681-f9b17c27d864"},"outputs":[],"source":"# groupby qid1, and then we get all the combinations of id in each group\ndqids12=ddf[['qid1','qid2']]\ndf12list=dqids12.groupby('qid1', as_index=False)['qid2'].agg({'dlist':(lambda x: list(x))})\nprint(len(df12list))\nd12list=df12list.values\nd12list=[[i]+j for i,j in d12list]\n# get all the combinations of id, like (id1,id2)...\nd12ids=set()\nfor ids in d12list:\n    ids_len=len(ids)\n    for i in range(ids_len):\n        for j in range(i+1,ids_len):\n            d12ids.add((ids[i],ids[j]))\nprint(len(d12ids))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3352efc5-b2eb-3a6b-8b68-17e23070ae98"},"outputs":[],"source":"# the same operation of qid2\ndqids21=ddf[['qid2','qid1']]\ndisplay(dqids21.head(2))\ndf21list=dqids21.groupby('qid2', as_index=False)['qid1'].agg({'dlist':(lambda x: list(x))})\nprint(len(df21list))\nids2=df21list.qid2.values\nd21list=df21list.values\nd21list=[[i]+j for i,j in d21list]\nd21ids=set()\nfor ids in d21list:\n    ids_len=len(ids)\n    for i in range(ids_len):\n        for j in range(i+1,ids_len):\n            d21ids.add((ids[i],ids[j]))\nlen(d21ids)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c5b25200-a6bd-1f2c-8eb9-15f1d1402581"},"outputs":[],"source":"# merge two set\ndids=list(d12ids | d21ids)\nlen(dids)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9536a7c-d257-f015-b53b-da52114e6018"},"outputs":[],"source":"# let's define union-find function\ndef indices_dict(lis):\n    d = defaultdict(list)\n    for i,(a,b) in enumerate(lis):\n        d[a].append(i)\n        d[b].append(i)\n    return d\n\ndef disjoint_indices(lis):\n    d = indices_dict(lis)\n    sets = []\n    while len(d):\n        que = set(d.popitem()[1])\n        ind = set()\n        while len(que):\n            ind |= que \n            que = set([y for i in que \n                         for x in lis[i] \n                         for y in d.pop(x, [])]) - ind\n        sets += [ind]\n    return sets\n\ndef disjoint_sets(lis):\n    return [set([x for i in s for x in lis[i]]) for s in disjoint_indices(lis)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cba2337c-bd72-a19b-a04c-0b8d39aafb68"},"outputs":[],"source":"# split data into groups, so that each question in each group are duplicated\ndid_u=disjoint_sets(dids)\nnew_dids=[]\nfor u in did_u:\n    new_dids.extend(list(combinations(u,2)))\nlen(new_dids)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8c8b48e-b691-13e4-357b-27a7d3b746c0"},"outputs":[],"source":"new_ddf=pd.DataFrame(new_dids,columns=['qid1','qid2'])\nprint('New duplicated shape:',new_ddf.shape)\ndisplay(new_ddf.head(2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31c41a69-7ada-6514-d243-291d0eb08a44"},"outputs":[],"source":"# merge with all_dqdf to get question1 description\nnew_ddf=new_ddf.merge(all_dqdf,left_on='qid1',right_on='qid',how='left')\nnew_ddf.drop('qid',inplace=True,axis=1)\nnew_ddf.columns=['qid1','qid2','question1']\nnew_ddf.drop_duplicates(inplace=True)\nprint(new_ddf.shape)\nnew_ddf.head(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2d905bf-5533-f07a-9185-d35ad74e332a"},"outputs":[],"source":"# the same operation with qid2\nnew_ddf=new_ddf.merge(all_dqdf,left_on='qid2',right_on='qid',how='left')\nnew_ddf.drop('qid',inplace=True,axis=1)\nnew_ddf.columns=['qid1','qid2','question1','question2']\nnew_ddf.drop_duplicates(inplace=True)\nprint(new_ddf.shape)\nnew_ddf.head(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18bb50b2-c2a5-6f22-90d2-4df068605615"},"outputs":[],"source":"# is_duplicate flag\nnew_ddf['is_duplicate']=1\nnew_ddf.head(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"923b6a6a-cc69-e031-0953-e4036736c5a4"},"outputs":[],"source":"# let random select 10 rows to check the result\nnew_ddf.sample(10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"95a98fef-27bf-e793-80d1-60ee5c57593b"},"source":"### It seemed quite make sense"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f5304db-f8fc-d837-52fb-e29d9da3b7d4"},"outputs":[],"source":"# the orininal duplicated pairs count:\nprint(len(all_dqdf))\n# after we generate more data, then the duplicated pairs count:\nprint(len(new_ddf))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fb69067-33c5-8dab-6ec4-db38599b0959"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}