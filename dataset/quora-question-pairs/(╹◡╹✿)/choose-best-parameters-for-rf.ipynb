{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ff5929a351a951cd5537b6d49d9de0d313a50de1","collapsed":true,"_cell_guid":"ca59c2a6-e5bf-403d-9513-1a32a05a03ef"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom IPython.display import display\nfrom collections import Counter\nfrom sklearn import metrics\nfrom sklearn.metrics import log_loss\nimport matplotlib.pyplot as plt\n\nfrom time import time\nfrom scipy.stats import randint as sp_randint\nfrom sklearn.model_selection import RandomizedSearchCV"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"df = pd.read_csv('../input/train.csv', low_memory=False)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"df.head()"},{"cell_type":"markdown","metadata":{},"source":"# **Feature Engineering**"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"def countword(q):\n    text = q.split(' ')\n    count = Counter(text)\n    return count"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"df['question1'] = df['question1'].astype('str')\ndf['question2'] = df['question2'].astype('str')\ndf['counter1'] = df['question1'].apply(lambda x:countword(x))\ndf['counter2'] = df['question2'].apply(lambda x:countword(x))\ndf['len1'] = df['question1'].apply(len)\ndf['len2'] = df['question2'].apply(len)\ndf['wordnum1'] = df['counter1'].apply(len)\ndf['wordnum2']= df['counter2'].apply(len)\ndf['sameWordNum'] = df.apply(lambda x:len(x['counter1'] & x['counter2']),axis=1)\ndf['len_diff'] = df.apply(lambda x:abs(x['len1']-x['len2']), axis=1)\ndf['word_num_diff'] = df.apply(lambda x:abs(x['wordnum1']-x['len2']), axis=1)\ndf['same_word_perc'] = df.apply(lambda x:abs(2.0*x['sameWordNum']/(x['len1']+x['len2'])), axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":"df.columns"},{"cell_type":"markdown","metadata":{},"source":"# **Train the Model**"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"feature = df.drop(['id','qid1','qid2','question1','question2', 'is_duplicate','counter1',\n                    'counter2'],1).columns"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"train_size = int(len(df)*0.8)\ntrind = np.random.permutation(len(df))[:train_size]\nteind = np.random.permutation(len(df))[train_size:]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"Xtrain = df.loc[trind, feature].copy().values\nYtrain = df.loc[trind, 'is_duplicate'].copy().values\nXval = df.loc[teind, feature].copy().values\nYval = df.loc[teind, 'is_duplicate'].copy().values"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"Xval.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"rf = RandomForestClassifier(n_jobs=-1, criterion = 'entropy')\nrf.fit(Xtrain, Ytrain)"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":"# accurary\nrf.score(Xtrain, Ytrain), rf.score(Xval, Yval)"},{"cell_type":"markdown","metadata":{},"source":"# **Choose Parameter**"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"tree_num = [10,20,30,40,50]\nll = []\nfor i, num in enumerate(tree_num):\n    rf = RandomForestClassifier(n_estimators=num, n_jobs=-1, criterion = 'entropy')\n    rf.fit(Xtrain, Ytrain)\n    Yfit= rf.predict(Xval)\n    ll.append(log_loss(Yfit, Yval))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"plt.plot(tree_num,ll)\nplt.xlabel('Tree Number')\nplt.ylabel('Log Loss')\nplt.title('Tree number VS Loss')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"min_sample_leaf = [1,3,5,10,25,100]\nll = []\nfor i, num in enumerate(min_sample_leaf):\n    rf = RandomForestClassifier(n_estimators=30, min_samples_leaf = num, n_jobs=-1, criterion = 'entropy')\n    rf.fit(Xtrain, Ytrain)\n    Yfit= rf.predict(Xval)\n    ll.append(log_loss(Yfit, Yval))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"plt.plot(min_sample_leaf,ll)\nplt.xlabel('Min sample per leaf')\nplt.ylabel('Log Loss')\nplt.title('Min sample per leaf VS Loss')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"max_feature = [0.1,0.3,0.5,0.7,0.9]\nll = []\nfor i, num in enumerate(max_feature):\n    rf = RandomForestClassifier(n_estimators=30, max_features = num, n_jobs=-1, criterion = 'entropy')\n    rf.fit(Xtrain, Ytrain)\n    Yfit= rf.predict(Xval)\n    ll.append(log_loss(Yfit, Yval))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"plt.plot(max_feature,ll)\nplt.xlabel('Min sample per leaf')\nplt.ylabel('Log Loss')\nplt.title('Min sample per leaf VS Loss')"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"param_dist = {\"max_features\": [0.1,0.3,0.5,0.7,0.9],\n             \"min_samples_leaf\": [1,3,5,10,25,100],\n             \"n_estimators\": [10,20,30,40,50]}\n\n# run randomized search\nn_iter_search = 10 \nrf = RandomForestClassifier()\nrandom_search = RandomizedSearchCV(rf, param_distributions=param_dist,\n                                   n_iter=n_iter_search)\nstart = time()\nrandom_search.fit(Xtrain, Ytrain)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\nreport(random_search.cv_results_)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"# Best Parameters: 'n_estimators': 40, 'min_samples_leaf': 25, 'max_features': 0.1"}],"nbformat_minor":1,"metadata":{"language_info":{"file_extension":".py","name":"python","pygments_lexer":"ipython3","version":"3.6.3","mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4}