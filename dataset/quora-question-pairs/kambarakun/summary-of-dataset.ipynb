{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"07b718bd-2079-60b1-94d9-9d358672b2af"},"source":"# Load Dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d5289134-191c-d644-2567-4ab19df81245"},"outputs":[],"source":"import pandas as pd\n\n\ndf_train = pd.read_csv('../input/train.csv')\ndf_test  = pd.read_csv('../input/test.csv')"},{"cell_type":"markdown","metadata":{"_cell_guid":"2574e0d0-9132-4c3a-ac96-b20f4a67cb0b"},"source":"# Length (Rows) of Dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa8efb64-e3fd-6aa5-af1d-2fc0a8a8baa6"},"outputs":[],"source":"pd_columns = ['length']\npd_index   = ['train', 'test']\npd_data    = [len(df_train), len(df_test)]\n\npd.DataFrame(pd_data, index = pd_index, columns = pd_columns)"},{"cell_type":"markdown","metadata":{"_cell_guid":"14ee6c2b-991a-3a9c-ba24-39964c667e3f"},"source":"# Words of Dataset (simply split by space)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07f5a1f2-95a8-482d-ee2b-cb27513fa639"},"outputs":[],"source":"pd_columns = ['question1', 'question2']\npd_index   = ['train', 'test']\npd_data    = [\n    [\n        max([len(str(x).split(' ')) for x in df_train.question1.tolist()]),\n        max([len(str(x).split(' ')) for x in df_train.question2.tolist()])\n    ],\n    [\n        max([len(str(x).split(' ')) for x in df_test.question1.tolist()]),\n        max([len(str(x).split(' ')) for x in df_test.question2.tolist()])\n    ]]\n\npd.DataFrame(pd_data, index = pd_index, columns = pd_columns)"},{"cell_type":"markdown","metadata":{"_cell_guid":"878eb347-5373-d5c5-6886-29afae9f3c12"},"source":"# Ratio of duplication (train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f083e80-aa6c-5862-4cac-e0558d152071"},"outputs":[],"source":"pd_columns = ['duplicate', 'not duplicate', 'total', '%duplication']\npd_index   = ['train']\npd_data    = [len(df_train), len(df_test)]\n\npd_data    = [\n    [\n        df_train.is_duplicate.sum(),\n        len(df_train) - df_train.is_duplicate.sum(),\n        len(df_train),\n        df_train.is_duplicate.sum() / len(df_train) * 100\n    ]]\n\npd.DataFrame(pd_data, index = pd_index, columns = pd_columns)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}