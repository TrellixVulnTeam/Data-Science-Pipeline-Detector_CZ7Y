{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73b2b9bd-bd22-5390-de1c-22c3b7edfb1a"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/quora-question-pairs\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb8d384d-6a89-eede-0998-67ed6bf69532"},"outputs":[],"source":"from nltk.corpus import stopwords\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn import svm\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c031af2c-89e6-e55d-a1f3-80aebb65f1cd"},"outputs":[],"source":"data = pd.read_csv('../input/quora-question-pairs/train.csv')\ntrain_data = data.drop('is_duplicate', axis=1)\nlabel_data = data['is_duplicate']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7acee047-1783-131b-61ec-6c785f3bd971"},"outputs":[],"source":"stops = set(stopwords.words(\"english\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1e8a44e-4b32-6c70-b385-ae1c661ebd3a"},"outputs":[],"source":"full_stop = [',','.','?','!',';']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a5502fae-b134-02ed-2497-e1682e289d45"},"outputs":[],"source":"label_data.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12278dfb-c927-80ac-e49b-0e70f3eae806"},"outputs":[],"source":"def sent_to_word(row):\n    sen_split = row.split(' ')\n    return [x.lower() for x in sen_split if ]\ndef sent_len(row):\n    return len(sent_to_word(row))\ndef overlap_words(row):\n    inter_set = set(row.word_list1).intersection(set(row.word_list2))\n    stops = set(stopwords.words(\"english\"))\n    filtered_set = [word for word in inter_set if word not in stops]\n    return filtered_set"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5b79615-6748-b5dc-c980-62fe70fb0fe6"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74eebf04-6f49-294c-cfbd-c5af478f8399"},"outputs":[],"source":"def make_input(train_data):\n    train_data['sent_diff'] = train_data.question1.astype(str).apply(sent_len) - train_data.question2.astype(str).apply(sent_len)\n    train_data['word_list1'] = train_data.question1.apply(sent_to_word)\n    train_data['word_list2'] = train_data.question2.astype(str).apply(sent_to_word)\n    train_data['overlap'] = train_data.apply(overlap_words, axis=1)\n    train_data['len_overlap'] = train_data['overlap'].apply(len)\n    train_data['len_over_ratio'] = train_data['len_overlap']/(train_data['word_list1'].apply(len)+train_data['word_list2'].apply(len))\n    train_data['words'] = train_data['word_list1'] + train_data['word_list2']\n    return train_data\n\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09ed9b2f-1c35-5da2-ab41-70ab31762b2f"},"outputs":[],"source":"train_data = make_input(train_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cfddff53-212c-e8d6-04fc-f141d10c3f46"},"outputs":[],"source":"from sklearn.base import BaseEstimator, TransformerMixin\nclass Make_input(BaseEstimator, TransformerMixin):\n    def __init__(self, words_pool={}):\n        self.words_pool = words_pool\n   \n    def fit(self, train_data, y=None):\n    \n        def weight(row):\n            w = 0\n            for word in row:\n                w += 1/self.words_pool[word]\n            return w\n        \n        for i in range(train_data.shape[0]):\n            for word in train_data.loc[i, 'words']:\n                if word not in stops:\n                    if word not in self.words_pool.keys():\n                        self.words_pool[word] = 1\n                    else:\n                        self.words_pool[word] += 1\n        train_data['weight'] = train_data['overlap'].apply(weight)\n        train_data = train_data.ix[:,['sent_diff','len_over_ratio','weight']]\n        return self\n    \n    def transform(self, valid_data):\n        \n        def weight_transform(row):\n            w = 0\n            for word in row:\n                if word in self.words_pool.keys():\n                    w += 1/self.words_pool[word]\n                else:\n                    self.words_pool[word] = 1\n            return w\n        \n        valid_data['weight'] = valid_data['overlap'].apply(weight_transform)\n        valid_data = valid_data.ix[:,['sent_diff','len_over_ratio','weight']]\n        return valid_data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43a2dcaf-2eb3-4b1d-863d-de9e821577f5"},"outputs":[],"source":"from sklearn.metrics import log_loss\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e82716f5-3bf5-0057-6f51-bafd82281256"},"outputs":[],"source":"X_train, y_train, X_test, y_test = train_data.loc[:35000,:], label_data[:35001], train_data.loc[35001:,:], label_data[35001:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4641c716-ac63-3274-2e00-e3bcf0e9efc1"},"outputs":[],"source":"prework = Make_input()\nX_train = prework.fit_transform(X_train)\nX_test = prework.transform(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b9fad3e-751f-23a9-cb25-0559b54a0c59"},"outputs":[],"source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7bfe11c-07c9-cd78-8d7b-8ecfa827420c"},"outputs":[],"source":"svm_classifier = svm.SVC(C=1, probability=True)\nsvm_classifier.fit(X_train, y_train)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"579abff2-b794-add8-0f3c-0a7d2eccbe20"},"outputs":[],"source":"pred = svm_classifier.predict_proba(X_test)\nmetric_1 = log_loss(y_test, pred)\nprint (metric_1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52e40f43-5ee7-085b-eccd-8d4317bd8baa"},"outputs":[],"source":"y_train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1f799d1-e4a5-96f8-481f-4322a02c036b"},"outputs":[],"source":"clf = make_pipeline(Make_input(), StandardScaler())\nX_train = clf.fit_transform(X_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f95ecfa-ae3f-a16f-b3ba-641540fa16a9"},"outputs":[],"source":"estimator = Make_input()\ntrai = estimator.fit_transform(train_data)\n#vali = estimator.transform(train_data.loc[20:40,:])\n#print (trai, vali)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d548fba5-196a-e6b9-9e40-c1a6092a7f11"},"outputs":[],"source":"scaler = StandardScaler()\ntrai = scaler.fit_transform(trai)\nvali = scaler.transform(vali)\nprint (trai, vali)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ed2eeaa-642d-1a88-cb35-75ed09b5b235"},"outputs":[],"source":"svm_classifier = svm.SVC(C=1, probability=True)\nsvm_classifier.fit(trai, label_data[:21])\npred = svm_classifier.predict_proba(vali)\nprint (pred)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83bb3c69-4921-9091-7753-930d9245af46"},"outputs":[],"source":"cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\ncross_val_score(estimator, train_data.loc[:20,:], scoring='neg_log_loss', cv=cv)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7cc1b05c-72cb-217f-9cee-214d88eb995c"},"outputs":[],"source":"label_data[:19].shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"231aa1ba-3e2e-d0f5-641a-cd39736782dc"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee83f6f3-5dca-18c9-a51c-fa6e5551156c"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94a72c1b-2c0c-4f77-cd32-5af805bae6dc"},"outputs":[],"source":"train_data['len_overlap'] = train_data['overlap'].apply(len)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d25b022f-3eaa-d9fe-d222-07a8317205f2"},"outputs":[],"source":"train_data['len_over_ratio'] = train_data['len_overlap']/(train_data['word_list1'].apply(len)+train_data['word_list2'].apply(len))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"949de35d-3342-af67-0d25-944b9dc731a6"},"outputs":[],"source":"train_data['words'] = train_data['word_list1'] + train_data['word_list2']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1c090e9-b51c-b921-9ada-cbe73123b365"},"outputs":[],"source":"train_data['words'] = train_data['word_list1'] + train_data['word_list2']\nwords_pool = {}\nfor i in range(train_data.shape[0]):\n    for word in train_data.loc[i, 'words']:\n        if word not in stops:\n            if word not in words_pool.keys():\n                words_pool[word] = 0\n            else:\n                words_pool[word] += 1\ntrain_data['weight'] = train_data['overlap'].apply(weight)\nmodel_input = train_data.ix[:,['sent_diff','len_over_ratio','weight']]\nmodel_label = train_data.ix[:,'is_duplicate']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37250eee-8b57-0c0a-c726-0b6ed040db6d"},"outputs":[],"source":"train_data['weight'] = train_data['overlap'].apply(weight)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d243f8a4-c1db-5633-d4d0-405830a9d376"},"outputs":[],"source":"model_input = train_data.ix[:,['sent_diff','len_over_ratio','weight']]\nmodel_label = train_data.ix[:,'is_duplicate']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"360ca225-3214-b44d-2754-abed4b75817d"},"outputs":[],"source":"input_scaler = StandardScaler()\nstand_input = input_scaler.fit_transform(model_input)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}