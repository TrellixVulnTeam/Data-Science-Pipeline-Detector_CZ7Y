{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6d7fe028-b82d-5df2-6e1c-b31ee6936f08"},"source":"Various feature engineering in the quora set\nSome features are from Abhishek Thakur"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f2fccee-3e41-b7ea-e597-f80f08b97ac9"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport gensim\nfrom fuzzywuzzy import fuzz\nfrom nltk.corpus import stopwords\nfrom tqdm import tqdm\nfrom scipy.stats import skew, kurtosis\nfrom scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\nfrom nltk import word_tokenize\nstop_words = stopwords.words('english')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"792ae323-5ecc-9b54-b6e6-1e969e9134ab"},"outputs":[],"source":"\ndef wmd(s1, s2):\n    s1 = str(s1).lower().split()\n    s2 = str(s2).lower().split()\n    stop_words = stopwords.words('english')\n    s1 = [w for w in s1 if w not in stop_words]\n    s2 = [w for w in s2 if w not in stop_words]\n    return model.wmdistance(s1, s2)\n\n\ndef norm_wmd(s1, s2):\n    s1 = str(s1).lower().split()\n    s2 = str(s2).lower().split()\n    stop_words = stopwords.words('english')\n    s1 = [w for w in s1 if w not in stop_words]\n    s2 = [w for w in s2 if w not in stop_words]\n    return norm_model.wmdistance(s1, s2)\n\n\ndef sent2vec(s):\n    words = str(s).lower().decode('utf-8')\n    words = word_tokenize(words)\n    words = [w for w in words if not w in stop_words]\n    words = [w for w in words if w.isalpha()]\n    M = []\n    for w in words:\n        try:\n            M.append(model[w])\n        except:\n            continue\n    M = np.array(M)\n    v = M.sum(axis=0)\n    return v / np.sqrt((v ** 2).sum())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4cfde19a-7be8-a69e-f005-073562253fd4"},"outputs":[],"source":"\n\ndata = pd.read_csv('../input/train.csv')\ndata = data.drop(['id', 'qid1', 'qid2'], axis=1)\n\n\ndata['len_q1'] = data.question1.apply(lambda x: len(str(x)))\ndata['len_q2'] = data.question2.apply(lambda x: len(str(x)))\ndata['diff_len'] = data.len_q1 - data.len_q2\ndata['len_char_q1'] = data.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\ndata['len_char_q2'] = data.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\ndata['len_word_q1'] = data.question1.apply(lambda x: len(str(x).split()))\ndata['len_word_q2'] = data.question2.apply(lambda x: len(str(x).split()))\ndata['common_words'] = data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\ndata['fuzz_qratio'] = data.apply(lambda x: fuzz.QRatio(str(x['question1']), str(x['question2'])), axis=1)\ndata['fuzz_WRatio'] = data.apply(lambda x: fuzz.WRatio(str(x['question1']), str(x['question2'])), axis=1)\ndata['fuzz_partial_ratio'] = data.apply(lambda x: fuzz.partial_ratio(str(x['question1']), str(x['question2'])), axis=1)\ndata['fuzz_partial_token_set_ratio'] = data.apply(lambda x: fuzz.partial_token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\ndata['fuzz_partial_token_sort_ratio'] = data.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\ndata['fuzz_token_set_ratio'] = data.apply(lambda x: fuzz.token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\ndata['fuzz_token_sort_ratio'] = data.apply(lambda x: fuzz.token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbe4d483-5cbc-ea93-7a7b-dc337fe7f860"},"outputs":[],"source":"\n\nmodel = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\ndata['wmd'] = data.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)\n\n\nnorm_model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\nnorm_model.init_sims(replace=True)\ndata['norm_wmd'] = data.apply(lambda x: norm_wmd(x['question1'], x['question2']), axis=1)\n\nquestion1_vectors = np.zeros((data.shape[0], 300))\nerror_count = 0\n\nfor i, q in tqdm(enumerate(data.question1.values)):\n    question1_vectors[i, :] = sent2vec(q)\n\nquestion2_vectors  = np.zeros((data.shape[0], 300))\nfor i, q in tqdm(enumerate(data.question2.values)):\n    question2_vectors[i, :] = sent2vec(q)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3803e89a-5089-aa64-760a-e8bf5eb77875"},"outputs":[],"source":"\ndata['cosine_distance'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),\n                                                          np.nan_to_num(question2_vectors))]\n\ndata['cityblock_distance'] = [cityblock(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),\n                                                          np.nan_to_num(question2_vectors))]\n\ndata['jaccard_distance'] = [jaccard(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),\n                                                          np.nan_to_num(question2_vectors))]\n\ndata['canberra_distance'] = [canberra(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),\n                                                          np.nan_to_num(question2_vectors))]\n\ndata['euclidean_distance'] = [euclidean(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),\n                                                          np.nan_to_num(question2_vectors))]\n\ndata['minkowski_distance'] = [minkowski(x, y, 3) for (x, y) in zip(np.nan_to_num(question1_vectors),\n                                                          np.nan_to_num(question2_vectors))]\n\ndata['braycurtis_distance'] = [braycurtis(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),\n                                                          np.nan_to_num(question2_vectors))]\n\ndata['skew_q1vec'] = [skew(x) for x in np.nan_to_num(question1_vectors)]\ndata['skew_q2vec'] = [skew(x) for x in np.nan_to_num(question2_vectors)]\ndata['kur_q1vec'] = [kurtosis(x) for x in np.nan_to_num(question1_vectors)]\ndata['kur_q2vec'] = [kurtosis(x) for x in np.nan_to_num(question2_vectors)]"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}