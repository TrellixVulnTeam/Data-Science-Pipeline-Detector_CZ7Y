{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Challenges in Representation Learning: Facial Expression Recognition Challenge\n\nhttps://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.preprocessing import image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import applications as keras_applications","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install keras_applications\n!pip install git+https://github.com/rcmalli/keras-vggface.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_vggface.vggface import VGGFace\nfrom keras_vggface import utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system('tar -xf /kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013.tar.gz');\ndata = pd.read_csv('fer2013/fer2013.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Usage.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = data[data.Usage=='Training']\nval_data = data[data.Usage=='PublicTest']\ntest_data = data[data.Usage=='PrivateTest']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape, val_data.shape, test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\nimport imblearn\noversampler = imblearn.over_sampling.RandomOverSampler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collections.Counter(train_data.emotion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\nx_train, y_train = oversampler.fit_resample(train_data.pixels.values.reshape(-1,1),train_data.emotion.values)\n\n# x_train = train_data.pixels.values.reshape(-1,1)\n# y_train = train_data.emotion.values\n\nx_val = val_data.pixels.values.reshape(-1,1)\ny_val = val_data.emotion.values\n\nx_test = test_data.pixels.values.reshape(-1,1)\ny_test = test_data.emotion.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collections.Counter(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = list(x_train)\nx_val   = list(x_val)\nx_test  = list(x_test)\n\nfor i,item in enumerate(x_train):\n    x_train[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\nfor i,item in enumerate(x_val):\n    x_val[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\nfor i,item in enumerate(x_test):\n    x_test[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\n    \nx_train = np.vstack(x_train).reshape(-1,48,48,1)\nx_val = np.vstack(x_val).reshape(-1,48,48,1)\nx_test = np.vstack(x_test).reshape(-1,48,48,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = to_categorical(y_train,num_classes=7)\ny_val   = to_categorical(y_val  ,num_classes=7)\ny_test  = to_categorical(y_test ,num_classes=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from copy import deepcopy as copy\n\ndef smooth_labels(y, smooth_factor):\n    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\n\n    # Arguments\n        y: matrix of one-hot row-vector labels to be smoothed\n        smooth_factor: label smoothing factor (between 0 and 1)\n\n    # Returns\n        A matrix of smoothed labels.\n    '''\n    assert len(y.shape) == 2, 'input should be a batch of one-hot-encoded data'\n    y2 = copy(y)\n    if 0 <= smooth_factor <= 1:\n        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\n        y2 *= 1 - smooth_factor\n        y2 += smooth_factor / y.shape[1]\n    else:\n        raise Exception(\n            'Invalid label smoothing factor: ' + str(smooth_factor))\n    return y2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import Sequence\nfrom keras.utils import to_categorical\nimport cv2\nfrom math import floor\n\nclass data_sequence(Sequence):\n    '''\n      yield sequence of data\n      features -- list of features\n      labels -- list of labels\n      target_channels {int} -- 1 (gray) or 3(RGB)\n    '''\n    def __init__(self, features, labels, batch_size=128, target_dim=(224,224), \n                 n_classes=7, shuffle=True, smooth=0.0):\n        'Initialization'\n        assert len(features)==len(labels), 'number of feature and labels not consistent'\n        self.features = features\n        self.labels = labels\n        self.batch_size = batch_size\n        self.target_dim = target_dim\n        self.target_channels = 3\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.smooth = smooth\n        self.sample_count = len(labels)\n        self.indexes = np.arange(self.sample_count)\n        self.on_epoch_end()\n#         self.verbose = verbose\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return floor(self.sample_count / self.batch_size)\n\n    def __gray2RGB__(self,x):\n      if len(x.shape)==2:\n        return np.stack((x,x,x),-1)\n      else:\n        assert len(x.shape)==3\n        if len(x[0,0,:]) == 1:\n          return np.stack((x[:,:,0],x[:,:,0],x[:,:,0]),-1)\n        else:\n          assert len(x[0,0,:])==self.target_channels\n      return x\n\n\n    def __getitem__(self, idx):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n        X = np.empty((self.batch_size, *self.target_dim, self.target_channels))\n        Y = np.empty((self.batch_size, self.n_classes))\n        for i,ind in enumerate(indexes):\n          x = self.features[ind]\n          # resize image to the target size \n          x = cv2.resize(x,self.target_dim,interpolation=cv2.INTER_CUBIC)\n          x = self.__gray2RGB__(x)\n          X[i] = utils.preprocess_input(x, version=2) # or version=2 for VGGFace2 ResNet50  \n          y = self.labels[ind]\n          if isinstance(y,int):\n            Y[i]=to_categorical(y,7)\n          else:\n            assert len(y)==self.n_classes\n            Y[i]=y\n        X = np.array(X)\n        Y = np.array(Y)\n        if self.smooth > 0.0:\n          smooth_labels(Y, self.smooth)\n        return X,Y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sequence = data_sequence(x_train,y_train,batch_size=16,target_dim=(224,224),n_classes=7,shuffle=False)\nfeature,lable = train_sequence.__getitem__(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_dict = {0: 'Angry', 1:'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6:'Neutral'}\n\nimport matplotlib.pyplot as plt\nplt.imshow(feature[0,:,:,:])\nplt.title(emotion_dict[np.argmax(lable[0])]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"vggface = VGGFace(model='resnet50', include_top=False, input_shape = (224,224,3))\nvggface.trainable = False\nvggface.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\n\n# model = Sequential([vggface,\n#                     Flatten(),\n#                     Dropout(0.5),\n#                     BatchNormalization(),\n#                     Dense(128, activation='relu'),\n#                     Dropout(0.5),\n#                     BatchNormalization(),\n#                     Dense(len(emotion_dict), activation='softmax', name = 'classifer')])\nmodel = Sequential([vggface,\n                    Flatten(),\n                    Dropout(0.25),\n                    Dense(2048, activation='relu'),\n                    Dropout(0.25),\n                    Dense(1024, activation='relu'),\n                    Dense(7, activation='softmax', name = 'classifer')])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sequence = data_sequence(x_train,y_train,batch_size=64,target_dim=(224,224),n_classes=7,shuffle=True,smooth=0.07)\nval_sequence   = data_sequence(x_val,  y_val,  batch_size=64,target_dim=(224,224),n_classes=7,shuffle=True,smooth=0.0)\ntest_sequence  = data_sequence(x_test, y_test, batch_size=64,target_dim=(224,224),n_classes=7,shuffle=True,smooth=0.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train only top layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\nhist = model.fit_generator(generator = train_sequence,\n                           validation_data = val_sequence,\n                           epochs = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\nplt.subplot(1,2,1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.subplot(1,2,2)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### finetune all layer, lr=1e-4"},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers[0].layers:\n    if 'bn' not in layer.name:\n        layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = keras.optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\nhist2 = model.fit_generator(generator = train_sequence,\n                            validation_data = val_sequence,\n                            epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in ['accuracy','val_accuracy','loss','val_loss']:\n    hist.history[key] = hist.history[key] + hist2.history[key]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\nplt.subplot(1,2,1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.subplot(1,2,2)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### finetune further all, lr=1e-5"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\ncheck_point = ModelCheckpoint('VGGfaceTransfer_dropout_smoothing_keras_model', \n                              monitor='val_acc', verbose=0, save_best_only=True,\n                              save_weights_only=False, mode='auto', period=1)\n\n\nmodel.compile(optimizer = keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\nhist3 = model.fit_generator(generator = train_sequence,\n                            validation_data = val_sequence,\n                            epochs = 10,\n                            callbacks=[check_point])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in ['accuracy','val_accuracy','loss','val_loss']:\n    hist.history[key] = hist.history[key] + hist3.history[key]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\nplt.subplot(1,2,1)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.subplot(1,2,2)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# model test"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_sequence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('VGGfaceTransfer_dropout_smoothing_keras_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar -czvf VGGfaceTransfer_dropout_smoothing_keras_model.tar.gz VGGfaceTransfer_dropout_smoothing_keras_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'VGGfaceTransfer_dropout_smoothing_keras_model.tar.gz')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ny_pred = []\ny_true = []\nfor x,y in test_sequence:\n    y_pred = y_pred + list(model.predict_classes(x))\n    y_true = y_true + list(np.argmax(y,axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_dict.values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\nconfusion_matrix = np.around(confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis], decimals=2)\n\nconfusion_matrix = pd.DataFrame(confusion_matrix,\n                                index = emotion_dict.values(), \n                                columns = emotion_dict.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfigure = plt.figure(figsize=(8, 8))\nsns.heatmap(confusion_matrix, annot=True,cmap=plt.cm.Blues)\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}