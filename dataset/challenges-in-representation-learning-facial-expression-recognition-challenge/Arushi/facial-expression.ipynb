{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport random\n\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nimport seaborn as sns\nfrom scipy.sparse.linalg import eigs\n\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:19.937324Z","iopub.execute_input":"2022-04-17T21:06:19.937966Z","iopub.status.idle":"2022-04-17T21:06:27.073794Z","shell.execute_reply.started":"2022-04-17T21:06:19.937864Z","shell.execute_reply":"2022-04-17T21:06:27.072775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'\nos.listdir(path)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:27.075232Z","iopub.execute_input":"2022-04-17T21:06:27.075466Z","iopub.status.idle":"2022-04-17T21:06:27.082728Z","shell.execute_reply.started":"2022-04-17T21:06:27.07544Z","shell.execute_reply":"2022-04-17T21:06:27.082169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(path+'icml_face_data.csv')\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:27.083629Z","iopub.execute_input":"2022-04-17T21:06:27.084272Z","iopub.status.idle":"2022-04-17T21:06:33.974654Z","shell.execute_reply.started":"2022-04-17T21:06:27.08424Z","shell.execute_reply":"2022-04-17T21:06:33.973793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[' Usage'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:33.977341Z","iopub.execute_input":"2022-04-17T21:06:33.977866Z","iopub.status.idle":"2022-04-17T21:06:33.992124Z","shell.execute_reply.started":"2022-04-17T21:06:33.977818Z","shell.execute_reply":"2022-04-17T21:06:33.991122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(data):\n    \"\"\" Prepare data for modeling \n        input: data frame with labels und pixel data\n        output: image and label array \"\"\"\n    \n    image_array = np.zeros(shape=(len(data), 48, 48))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        image_array[i] = image\n        \n    return image_array, image_label\n","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:33.993903Z","iopub.execute_input":"2022-04-17T21:06:33.994256Z","iopub.status.idle":"2022-04-17T21:06:34.005196Z","shell.execute_reply.started":"2022-04-17T21:06:33.994215Z","shell.execute_reply":"2022-04-17T21:06:34.004244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n\ntrain_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\nval_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\ntest_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:34.006726Z","iopub.execute_input":"2022-04-17T21:06:34.006962Z","iopub.status.idle":"2022-04-17T21:06:37.207208Z","shell.execute_reply.started":"2022-04-17T21:06:34.006935Z","shell.execute_reply":"2022-04-17T21:06:37.206156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_image_array.reshape((train_image_array.shape[0], 1, 48, 48))\ntrain_images = train_images.astype('float32')/255\nval_images = val_image_array.reshape((val_image_array.shape[0], 1, 48, 48))\nval_images = val_images.astype('float32')/255\ntest_images = test_image_array.reshape((test_image_array.shape[0], 1, 48, 48))\ntest_images = test_images.astype('float32')/255\n\ntrain_labels = to_categorical(train_image_label)\nval_labels = to_categorical(val_image_label)\ntest_labels = to_categorical(test_image_label)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:37.208981Z","iopub.execute_input":"2022-04-17T21:06:37.209299Z","iopub.status.idle":"2022-04-17T21:06:37.389243Z","shell.execute_reply.started":"2022-04-17T21:06:37.209256Z","shell.execute_reply":"2022-04-17T21:06:37.388247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = to_categorical(train_image_label)\nval_labels = to_categorical(val_image_label)\ntest_labels = to_categorical(test_image_label)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:37.390632Z","iopub.execute_input":"2022-04-17T21:06:37.390845Z","iopub.status.idle":"2022-04-17T21:06:37.395455Z","shell.execute_reply.started":"2022-04-17T21:06:37.39082Z","shell.execute_reply":"2022-04-17T21:06:37.394574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[' Usage'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:37.39662Z","iopub.execute_input":"2022-04-17T21:06:37.396897Z","iopub.status.idle":"2022-04-17T21:06:37.417784Z","shell.execute_reply.started":"2022-04-17T21:06:37.396866Z","shell.execute_reply":"2022-04-17T21:06:37.416791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"((data[data[' Usage']=='Training']['emotion'].value_counts()).sort_index())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:37.420087Z","iopub.execute_input":"2022-04-17T21:06:37.420691Z","iopub.status.idle":"2022-04-17T21:06:37.44252Z","shell.execute_reply.started":"2022-04-17T21:06:37.420651Z","shell.execute_reply":"2022-04-17T21:06:37.441647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating the percentage into each category in the training dataset\npercentage = (((data[data[' Usage']=='Training']['emotion'].value_counts()).sort_index()) * 100 /len(data[data[' Usage']=='Training']['emotion']))\n\nclass_weight = dict(zip(range(0, 7), percentage.tolist()))\nclass_weight","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:37.444055Z","iopub.execute_input":"2022-04-17T21:06:37.444746Z","iopub.status.idle":"2022-04-17T21:06:37.468Z","shell.execute_reply.started":"2022-04-17T21:06:37.444714Z","shell.execute_reply":"2022-04-17T21:06:37.467121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(data = data[data[' Usage']=='Training'], x='emotion', ax=ax1).set_title('Training')\nax1.set_xticklabels(emotions.values())\nsns.countplot(data = data[data[' Usage']=='PublicTest'], x='emotion', ax=ax2).set_title('Testing')\nax2.set_xticklabels(emotions.values())\nsns.countplot(data = data[data[' Usage']=='PrivateTest'], x='emotion', ax=ax3).set_title('Validation')\nax3.set_xticklabels(emotions.values())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:37.469361Z","iopub.execute_input":"2022-04-17T21:06:37.469826Z","iopub.status.idle":"2022-04-17T21:06:37.97874Z","shell.execute_reply.started":"2022-04-17T21:06:37.469783Z","shell.execute_reply":"2022-04-17T21:06:37.978078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Randomly plotting 20 images from the dataset\n\ndef sample_plot(x,y=None):\n    #x, y are numpy arrays\n    n = 20\n    samples = random.sample(range(x.shape[0]),n)\n    \n    fig, axs = plt.subplots(2,10, figsize=(25,5), sharex=True, sharey=True)\n    ax = axs.ravel()\n    for i in range(n):\n        ax[i].imshow(x[samples[i],:,:], cmap=plt.get_cmap('gray'))\n        ax[i].set_xticks([])\n        ax[i].set_yticks([])\n        if y is not None:\n            ax[i].set_title(emotions[y[samples[i]]])\n            \nsample_plot(train_image_array, train_image_label)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:37.979851Z","iopub.execute_input":"2022-04-17T21:06:37.98017Z","iopub.status.idle":"2022-04-17T21:06:39.02591Z","shell.execute_reply.started":"2022-04-17T21:06:37.980143Z","shell.execute_reply":"2022-04-17T21:06:39.025225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_image_vector(image_list, new_size):\n    D = np.empty([len(image_list), new_size])\n    i = 0\n    for image in image_list:\n        D[i, :] = image\n        i += 1\n    return D\n\ndef avgfaces_by_emotion(df):\n    \n    avgfaces = []\n    for emotion in sorted(df['emotion'].unique()):\n        sub_df = df[df['emotion']==emotion]    \n        avg_pixels = np.mean(sub_df['pixels'].values)\n        avgfaces.append((avg_pixels, emotion))\n        \n    return avgfaces\n\ndef eigenfaces_by_emotion(df, k=1):\n    \n    variance_arr = []\n    eigenfaces = []\n    for emotion in sorted(df['emotion'].unique()):\n        sub_df = df[df['emotion'] == emotion]\n        \n        pixels = list(sub_df['pixels'].values)\n        D = make_image_vector(pixels, 48*48)\n        A = np.dot(D.T, D)\n        \n        # Find k largest magnitude (LM) eigenvectors\n        vals, vecs = eigs(A, k, which = 'LM')\n        variance = vals\n        \n        eigenfaces.extend([(vec.reshape(48, 48).astype(float), emotion) for vec in vecs.T])\n        variance_arr.extend([variance])\n        \n    return variance_arr, eigenfaces","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:39.027011Z","iopub.execute_input":"2022-04-17T21:06:39.027645Z","iopub.status.idle":"2022-04-17T21:06:39.035533Z","shell.execute_reply.started":"2022-04-17T21:06:39.027612Z","shell.execute_reply":"2022-04-17T21:06:39.034985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\ndf['pixels'] = df[' pixels'].apply(lambda x: np.array(x.split(), dtype=np.float))\navgfaces = avgfaces_by_emotion(df)\n\nvar, eigenfaces = eigenfaces_by_emotion(df, 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:39.036698Z","iopub.execute_input":"2022-04-17T21:06:39.036916Z","iopub.status.idle":"2022-04-17T21:06:55.602921Z","shell.execute_reply.started":"2022-04-17T21:06:39.036889Z","shell.execute_reply":"2022-04-17T21:06:55.601822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot faces and show emotion label\ndef plot_face_and_emotion(plot_nrow, plot_ncol, face_list):\n    fig, axes = plt.subplots(plot_nrow, plot_ncol, figsize=(15, 15))\n    for i, (face, emotion) in enumerate(face_list):\n        ax = axes.ravel()[i]\n        ax.imshow(face.reshape(48, 48), cmap='gray')\n        # Turn off tick labels\n        ax.set_xlabel(emotions[emotion])\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:55.605407Z","iopub.execute_input":"2022-04-17T21:06:55.607121Z","iopub.status.idle":"2022-04-17T21:06:55.620676Z","shell.execute_reply.started":"2022-04-17T21:06:55.607071Z","shell.execute_reply":"2022-04-17T21:06:55.61975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg = []\navg_pixels = np.mean(df['pixels'].values)\navg.append((avg_pixels, '1'))\n\nfig, axes = plt.subplots(1, 1, figsize=(5, 5))\nfor i, (face, emotion) in enumerate(avg):\n    ax = axes\n    ax.imshow(face.reshape(48, 48), cmap='gray')\n    # Turn off tick labels","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:55.623297Z","iopub.execute_input":"2022-04-17T21:06:55.624963Z","iopub.status.idle":"2022-04-17T21:06:56.121145Z","shell.execute_reply.started":"2022-04-17T21:06:55.624914Z","shell.execute_reply":"2022-04-17T21:06:56.120612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_face_and_emotion(1, 7, avgfaces)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:56.123175Z","iopub.execute_input":"2022-04-17T21:06:56.123898Z","iopub.status.idle":"2022-04-17T21:06:56.74278Z","shell.execute_reply.started":"2022-04-17T21:06:56.123843Z","shell.execute_reply":"2022-04-17T21:06:56.74192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_face_and_emotion(1, 7, eigenfaces)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:56.743875Z","iopub.execute_input":"2022-04-17T21:06:56.744104Z","iopub.status.idle":"2022-04-17T21:06:57.367083Z","shell.execute_reply.started":"2022-04-17T21:06:56.744076Z","shell.execute_reply":"2022-04-17T21:06:57.366258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import models\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.metrics import TopKCategoricalAccuracy","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:57.368468Z","iopub.execute_input":"2022-04-17T21:06:57.368981Z","iopub.status.idle":"2022-04-17T21:06:57.374839Z","shell.execute_reply.started":"2022-04-17T21:06:57.368939Z","shell.execute_reply":"2022-04-17T21:06:57.373904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\ntrain_images = train_images.astype('float32')/255\nval_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\nval_images = val_images.astype('float32')/255\ntest_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\ntest_images = test_images.astype('float32')/255\n\ntrain_labels = to_categorical(train_image_label)\nval_labels = to_categorical(val_image_label)\ntest_labels = to_categorical(test_image_label)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:57.375949Z","iopub.execute_input":"2022-04-17T21:06:57.37617Z","iopub.status.idle":"2022-04-17T21:06:57.56488Z","shell.execute_reply.started":"2022-04-17T21:06:57.376142Z","shell.execute_reply":"2022-04-17T21:06:57.563921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model =  models.Sequential([\n                        Conv2D(128, (3,3), activation = 'relu', strides = 1, padding = 'same', input_shape = (48, 48, 1)),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        Conv2D(128, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                               \n                        Conv2D(64, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        Conv2D(64, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n    \n                        Conv2D(32, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        Conv2D(32, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        \n                        Flatten(),\n                        Dense(128, 'relu'),\n                        Dense(7,'softmax'),\n                ])","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:57.566146Z","iopub.execute_input":"2022-04-17T21:06:57.566413Z","iopub.status.idle":"2022-04-17T21:06:57.759545Z","shell.execute_reply.started":"2022-04-17T21:06:57.566383Z","shell.execute_reply":"2022-04-17T21:06:57.758674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model.compile(optimizer = Adam(lr=1e-3), loss = 'categorical_crossentropy', metrics = ['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)])\ncnn_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:57.761006Z","iopub.execute_input":"2022-04-17T21:06:57.761326Z","iopub.status.idle":"2022-04-17T21:06:57.787415Z","shell.execute_reply.started":"2022-04-17T21:06:57.761282Z","shell.execute_reply":"2022-04-17T21:06:57.786645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 5\ntrained_model_conv = cnn_model.fit(train_images, \n                               train_labels, \n                               epochs = epochs, \n                               batch_size = 32, \n                               class_weight = class_weight,\n                               validation_data = (val_images, val_labels))","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:06:57.788611Z","iopub.execute_input":"2022-04-17T21:06:57.789404Z","iopub.status.idle":"2022-04-17T21:21:20.959609Z","shell.execute_reply.started":"2022-04-17T21:06:57.78937Z","shell.execute_reply":"2022-04-17T21:21:20.958598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(trained_model_conv.history['accuracy'], label = 'Train Accuracy')\nplt.plot(trained_model_conv.history['val_accuracy'], label = 'Val Accuracy')\nplt.xlabel('Ephocs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:42:38.897453Z","iopub.execute_input":"2022-04-17T21:42:38.898165Z","iopub.status.idle":"2022-04-17T21:42:39.101484Z","shell.execute_reply.started":"2022-04-17T21:42:38.898116Z","shell.execute_reply":"2022-04-17T21:42:39.100603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(trained_model_conv.history['top_k_categorical_accuracy'], label = 'Train Accuracy Top 3')\nplt.plot(trained_model_conv.history['val_top_k_categorical_accuracy'], label = 'Val Accuracy Top 3')\nplt.xlabel('Ephocs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:43:04.774161Z","iopub.execute_input":"2022-04-17T21:43:04.775069Z","iopub.status.idle":"2022-04-17T21:43:04.948065Z","shell.execute_reply.started":"2022-04-17T21:43:04.77502Z","shell.execute_reply":"2022-04-17T21:43:04.947188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc, top_k_acc = cnn_model.evaluate(test_images, test_labels)\nprint('test accuracy :', test_acc)\nprint('test accuracy top 3:', top_k_acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:21:21.177532Z","iopub.execute_input":"2022-04-17T21:21:21.177773Z","iopub.status.idle":"2022-04-17T21:21:27.618929Z","shell.execute_reply.started":"2022-04-17T21:21:21.177745Z","shell.execute_reply":"2022-04-17T21:21:27.617915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Augmentation","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center = False,  # set input mean to 0 over the dataset\n        samplewise_center = False,  # set each sample mean to 0\n        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n        samplewise_std_normalization = False,  # divide each input by its std\n        zca_whitening = False,  # apply ZCA whitening\n        rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = False,  # randomly flip images\n        vertical_flip = False)  # randomly flip images","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:21:27.620006Z","iopub.execute_input":"2022-04-17T21:21:27.62024Z","iopub.status.idle":"2022-04-17T21:21:27.626804Z","shell.execute_reply.started":"2022-04-17T21:21:27.620205Z","shell.execute_reply":"2022-04-17T21:21:27.625798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augment over all data\ndatagen.fit(train_images)\n\nfor X_batch, y_batch in datagen.flow(train_images, train_labels, batch_size = 9):\n    fig, axes = plt.subplots(3, 3, figsize = (8, 8))\n    for i in range(0, 9):\n        ax = axes.ravel()[i]\n        ax.imshow(X_batch[i].reshape(48, 48, 1))\n        ax.set_xlabel(y_batch[i])\n    break\n\nemotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:21:27.631353Z","iopub.execute_input":"2022-04-17T21:21:27.631956Z","iopub.status.idle":"2022-04-17T21:21:28.83819Z","shell.execute_reply.started":"2022-04-17T21:21:27.63191Z","shell.execute_reply":"2022-04-17T21:21:28.837301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_model = cnn_model.fit(\n                 datagen.flow(train_images, train_labels, batch_size = 32),\n                 validation_data = (val_images, val_labels),\n                 steps_per_epoch = len(train_images) / 32, \n                 epochs = 5)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:27:02.788405Z","iopub.execute_input":"2022-04-17T21:27:02.788762Z","iopub.status.idle":"2022-04-17T21:42:01.397564Z","shell.execute_reply.started":"2022-04-17T21:27:02.788722Z","shell.execute_reply":"2022-04-17T21:42:01.396583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc, top_k_acc = aug_model.evaluate(test_images, test_labels)\nprint('test accuracy :', test_acc)\nprint('test accuracy top 3:', top_k_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(aug_model.history['accuracy'], label = 'Train Accuracy')\nplt.plot(aug_model.history['val_accuracy'], label = 'Val Accuracy')\nplt.xlabel('Ephocs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:44:08.724165Z","iopub.execute_input":"2022-04-17T21:44:08.724468Z","iopub.status.idle":"2022-04-17T21:44:08.927571Z","shell.execute_reply.started":"2022-04-17T21:44:08.724435Z","shell.execute_reply":"2022-04-17T21:44:08.926741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(aug_model.history['top_k_categorical_accuracy'], label = 'Train Accuracy Top 3')\nplt.plot(aug_model.history['val_top_k_categorical_accuracy'], label = 'Val Accuracy Top 3')\nplt.xlabel('Ephocs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:44:15.674285Z","iopub.execute_input":"2022-04-17T21:44:15.67457Z","iopub.status.idle":"2022-04-17T21:44:15.889846Z","shell.execute_reply.started":"2022-04-17T21:44:15.67454Z","shell.execute_reply":"2022-04-17T21:44:15.888899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augment just disgust images\n\nindices = np.argwhere(train_image_label == 1)\nindices = indices.reshape(indices.shape[0],)\n\ndatagen.fit(train_images[indices])\n\nfor X_batch, y_batch in datagen.flow(train_images[indices], train_labels[indices], batch_size = 9):\n    fig, axes = plt.subplots(3, 3, figsize = (8, 8))\n    for i in range(0, 9):\n        ax = axes.ravel()[i]\n        ax.imshow(X_batch[i].reshape(48, 48, 1))\n        ax.set_xlabel(y_batch[i])\n    break\n","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:46:11.722781Z","iopub.execute_input":"2022-04-17T21:46:11.723346Z","iopub.status.idle":"2022-04-17T21:46:12.723597Z","shell.execute_reply.started":"2022-04-17T21:46:11.723307Z","shell.execute_reply":"2022-04-17T21:46:12.723034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model2 =  models.Sequential([\n                        Conv2D(128, (3,3), activation = 'relu', strides = 1, padding = 'same', input_shape = (48, 48, 1)),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        Conv2D(128, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                               \n                        Conv2D(64, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        Conv2D(64, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n    \n                        Conv2D(32, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        Conv2D(32, (3,3), activation = 'relu', strides = 1, padding = 'same'),\n                        MaxPool2D((2,2), strides = 2 , padding = 'same'),\n                        \n                        Flatten(),\n                        Dense(128, 'relu'),\n                        Dense(7,'softmax'),\n                ])\n\ncnn_model2.compile(optimizer = Adam(lr=1e-3), loss = 'categorical_crossentropy', metrics = ['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)])","metadata":{"execution":{"iopub.status.busy":"2022-04-17T21:48:11.503729Z","iopub.execute_input":"2022-04-17T21:48:11.504554Z","iopub.status.idle":"2022-04-17T21:48:11.604137Z","shell.execute_reply.started":"2022-04-17T21:48:11.504504Z","shell.execute_reply":"2022-04-17T21:48:11.603341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 5\nfor e in range(epochs):\n    print('Epoch', e)\n    batches = 0\n    for x_batch, y_batch in datagen.flow(train_images[indices], train_labels[indices], batch_size = 128):\n        \n        train_images_new = np.concatenate((train_images, x_batch), axis = 0)\n        train_labels_new = np.concatenate((train_labels, y_batch), axis = 0)\n        \n        cnn_model2.fit(train_images_new, train_labels_new, validation_data = (val_images, val_labels))\n        batches += 1\n        \n        if batches >= 2:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break\n","metadata":{"execution":{"iopub.status.busy":"2022-04-17T22:30:06.295845Z","iopub.execute_input":"2022-04-17T22:30:06.296406Z","iopub.status.idle":"2022-04-17T22:59:10.688601Z","shell.execute_reply.started":"2022-04-17T22:30:06.296351Z","shell.execute_reply":"2022-04-17T22:59:10.687691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc, top_k_acc = cnn_model2.evaluate(test_images, test_labels)\nprint('test accuracy :', test_acc)\nprint('test accuracy top 3:', top_k_acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T22:59:49.626993Z","iopub.execute_input":"2022-04-17T22:59:49.627743Z","iopub.status.idle":"2022-04-17T22:59:56.081913Z","shell.execute_reply.started":"2022-04-17T22:59:49.627702Z","shell.execute_reply":"2022-04-17T22:59:56.080975Z"},"trusted":true},"execution_count":null,"outputs":[]}]}