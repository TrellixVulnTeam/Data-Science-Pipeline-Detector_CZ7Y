{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import models, layers\nimport tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom keras.applications.xception import Xception\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet import ResNet50\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, GlobalAveragePooling2D\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-30T12:26:33.283837Z","iopub.execute_input":"2022-04-30T12:26:33.28418Z","iopub.status.idle":"2022-04-30T12:26:38.835497Z","shell.execute_reply.started":"2022-04-30T12:26:33.284106Z","shell.execute_reply":"2022-04-30T12:26:38.834747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge\"\n\ndata = pd.read_csv(os.path.join(PATH, \"icml_face_data.csv\"))\n\nemotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:26:43.275241Z","iopub.execute_input":"2022-04-30T12:26:43.275519Z","iopub.status.idle":"2022-04-30T12:26:48.165887Z","shell.execute_reply.started":"2022-04-30T12:26:43.27549Z","shell.execute_reply":"2022-04-30T12:26:48.165162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:26:50.726849Z","iopub.execute_input":"2022-04-30T12:26:50.727113Z","iopub.status.idle":"2022-04-30T12:26:50.748919Z","shell.execute_reply.started":"2022-04-30T12:26:50.727085Z","shell.execute_reply":"2022-04-30T12:26:50.748286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to parse data into right format\n# Output: Image in right shaped and normalized + labels\ndef parse_data(data):\n    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48, 1))\n        image_array[i] = image\n        \n    return image_array, image_label\n\n# Splitting the data into train, validation and testing set thanks to Usage column\ntrain_imgs, train_lbls = parse_data(data[data[\" Usage\"] == \"Training\"])\nval_imgs, val_lbls = parse_data(data[data[\" Usage\"] == \"PrivateTest\"])\ntest_imgs, test_lbls = parse_data(data[data[\" Usage\"] == \"PublicTest\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:45:34.980637Z","iopub.execute_input":"2022-04-30T12:45:34.981512Z","iopub.status.idle":"2022-04-30T12:45:38.587176Z","shell.execute_reply.started":"2022-04-30T12:45:34.981461Z","shell.execute_reply":"2022-04-30T12:45:38.586469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train shape\", np.shape(train_imgs))\nprint(\"validation shape\", np.shape(val_imgs))\nprint(\"validatio shape\", np.shape(test_imgs))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:45:43.095714Z","iopub.execute_input":"2022-04-30T12:45:43.09632Z","iopub.status.idle":"2022-04-30T12:45:43.102939Z","shell.execute_reply.started":"2022-04-30T12:45:43.096283Z","shell.execute_reply":"2022-04-30T12:45:43.101881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_imgs_new = train_imgs / 255\nval_imgs_new = val_imgs / 255","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:45:48.797148Z","iopub.execute_input":"2022-04-30T12:45:48.797404Z","iopub.status.idle":"2022-04-30T12:45:48.977192Z","shell.execute_reply.started":"2022-04-30T12:45:48.797375Z","shell.execute_reply":"2022-04-30T12:45:48.976465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an image generator for augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 30,\n    width_shift_range = 0.2, \n    height_shift_range = 0.2, \n    zoom_range = 0.2, \n    horizontal_flip = True, \n    fill_mode = 'nearest'\n)\n\ntrain_loader = train_datagen.flow(train_imgs_new, train_lbls, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:45:52.998817Z","iopub.execute_input":"2022-04-30T12:45:52.999524Z","iopub.status.idle":"2022-04-30T12:45:53.10776Z","shell.execute_reply.started":"2022-04-30T12:45:52.999489Z","shell.execute_reply":"2022-04-30T12:45:53.106997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def entry_flow(inputs):\n\n    x = layers.Conv2D(32, 3, strides=2, padding='same')(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n\n    x = layers.Conv2D(64, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n\n    previous_block_activation = x  # Set aside residual\n  \n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for size in [128, 256, 728]:\n        x = layers.Activation('relu')(x)\n        x = layers.SeparableConv2D(size, 3, padding='same')(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation('relu')(x)\n        x = layers.SeparableConv2D(size, 3, padding='same')(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n    \n        residual = layers.Conv2D(size, 1, strides=2, padding='same')(previous_block_activation)           \n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    return x\n\n\ndef middle_flow(x, num_blocks=8):\n  \n    previous_block_activation = x\n\n    for _ in range(num_blocks):\n        x = layers.Activation('relu')(x)\n        x = layers.SeparableConv2D(728, 3, padding='same')(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation('relu')(x)\n        x = layers.SeparableConv2D(728, 3, padding='same')(x)\n        x = layers.BatchNormalization()(x)\n    \n        x = layers.Activation('relu')(x)\n        x = layers.SeparableConv2D(728, 3, padding='same')(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.add([x, previous_block_activation])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n    \n    return x\n\n\ndef exit_flow(x, num_classes=7):\n  \n    previous_block_activation = x\n\n    x = layers.Activation('relu')(x)\n    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Activation('relu')(x)\n    x = layers.SeparableConv2D(1024, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n  \n    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n\n    residual = layers.Conv2D(1024, 1, strides=2, padding='same')(previous_block_activation)\n    x = layers.add([x, residual])  # Add back residual\n  \n    x = layers.SeparableConv2D(1536, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n  \n    x = layers.SeparableConv2D(2048, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n  \n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 1:\n        activation = 'sigmoid'\n    else:\n        activation = 'softmax'\n    return layers.Dense(num_classes, activation=activation)(x)\n\ninputs = keras.Input(shape=(48, 48, 1))  # Variable-size image inputs.\noutputs = exit_flow(middle_flow(entry_flow(inputs)))\nxception = keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:45:56.578568Z","iopub.execute_input":"2022-04-30T12:45:56.579029Z","iopub.status.idle":"2022-04-30T12:45:57.298224Z","shell.execute_reply.started":"2022-04-30T12:45:56.578994Z","shell.execute_reply":"2022-04-30T12:45:57.297488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = xception\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:46:02.5116Z","iopub.execute_input":"2022-04-30T12:46:02.512573Z","iopub.status.idle":"2022-04-30T12:46:02.57355Z","shell.execute_reply.started":"2022-04-30T12:46:02.51252Z","shell.execute_reply":"2022-04-30T12:46:02.572851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.compile(loss='sparse_categorical_crossentropy', \n            optimizer=keras.optimizers.Adam(0.001), \n            metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:46:23.230655Z","iopub.execute_input":"2022-04-30T12:46:23.231099Z","iopub.status.idle":"2022-04-30T12:46:23.249846Z","shell.execute_reply.started":"2022-04-30T12:46:23.231063Z","shell.execute_reply":"2022-04-30T12:46:23.249219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h1 = cnn.fit(train_loader, \n             batch_size=64, \n             epochs=50, \n             validation_data=(val_imgs_new, val_lbls), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:46:30.667523Z","iopub.execute_input":"2022-04-30T12:46:30.668363Z","iopub.status.idle":"2022-04-30T12:50:55.376064Z","shell.execute_reply.started":"2022-04-30T12:46:30.668321Z","shell.execute_reply":"2022-04-30T12:50:55.375393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = h1.history\nn_epochs = len(history['loss'])\n\nplt.figure(figsize=[10,4])\nplt.subplot(1,2,1)\nplt.plot(range(1, n_epochs+1), history['loss'], label='Training')\nplt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')\nplt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:51:57.376812Z","iopub.execute_input":"2022-04-30T12:51:57.37729Z","iopub.status.idle":"2022-04-30T12:51:57.858965Z","shell.execute_reply.started":"2022-04-30T12:51:57.377243Z","shell.execute_reply":"2022-04-30T12:51:57.858262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Update the learning rate\ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:52:44.153837Z","iopub.execute_input":"2022-04-30T12:52:44.154092Z","iopub.status.idle":"2022-04-30T12:52:44.160877Z","shell.execute_reply.started":"2022-04-30T12:52:44.154063Z","shell.execute_reply":"2022-04-30T12:52:44.158909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2 = cnn.fit(train_loader, \n             batch_size=64, \n             epochs=50, \n             validation_data=(val_imgs_new, val_lbls), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:53:02.351856Z","iopub.execute_input":"2022-04-30T12:53:02.352109Z","iopub.status.idle":"2022-04-30T12:59:26.306094Z","shell.execute_reply.started":"2022-04-30T12:53:02.352081Z","shell.execute_reply":"2022-04-30T12:59:26.305341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:59:31.704722Z","iopub.execute_input":"2022-04-30T12:59:31.705021Z","iopub.status.idle":"2022-04-30T12:59:31.981136Z","shell.execute_reply.started":"2022-04-30T12:59:31.704989Z","shell.execute_reply":"2022-04-30T12:59:31.980483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Update the learning rate\ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.00001)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h3 = cnn.fit(train_loader, \n             batch_size=64, \n             epochs=10, \n             validation_data=(val_imgs_new, val_lbls), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:59:49.905953Z","iopub.execute_input":"2022-04-30T12:59:49.906209Z","iopub.status.idle":"2022-04-30T13:06:12.561009Z","shell.execute_reply.started":"2022-04-30T12:59:49.90618Z","shell.execute_reply":"2022-04-30T13:06:12.560272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in history.keys():\n    history[k] += h3.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:06:20.366806Z","iopub.execute_input":"2022-04-30T13:06:20.367371Z","iopub.status.idle":"2022-04-30T13:06:20.841045Z","shell.execute_reply.started":"2022-04-30T13:06:20.36732Z","shell.execute_reply":"2022-04-30T13:06:20.840308Z"},"trusted":true},"execution_count":null,"outputs":[]}]}