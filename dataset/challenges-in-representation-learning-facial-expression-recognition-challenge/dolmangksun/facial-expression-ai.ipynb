{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">Libraries</span> "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data handling\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AI modeling\nfrom keras import models\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image handling\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">Path</span> "},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">Load Data</span> "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(path+'icml_face_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = '/kaggle/input/facial-expression-sample/'\nimglist = ['sample_01.jpg', 'sample_02.jpg', 'sample_03.jpg', 'sample_04.jpg', 'sample_05.jpg', 'sample_06.jpg', 'sample_07.jpg', 'sample_08.jpg', 'sample_09.jpg', 'sample_10.jpg']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">Functions</span> "},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_img(pic):\n    \"\"\" input : 이미지 주소\n        output : 48*48 흑백으로 변환된 픽셀 데이터 \"\"\"\n    im = Image.open(pic)\n\n    pix = np.array(im)\n    ysize=im.size[0]\n    xsize=im.size[1]\n    graypix=np.zeros(shape=(xsize,ysize))\n    if pix.ndim == 3:\n        for i in range(xsize):\n            for j in range(ysize):\n                p=int((0.2126*pix[i][j][0])+(0.7152*pix[i][j][1])+(0.0722*pix[i][j][2]))\n                graypix[i][j]=p\n    else:\n        for i in range(xsize):\n            for j in range(ysize):\n                graypix[i][j] = pix[i][j]\n\n    sizecheck=[[0],[0]]\n    resized=str()\n    for i in range(48):\n        a=int(xsize*(i+1)/48)\n        sizecheck[0].append(a)\n    for j in range(48):        \n        b=int(ysize*(j+1)/48)\n        sizecheck[1].append(b)\n\n    for i in range(48):\n        for j in range(48):\n            a=sizecheck[0][i+1]-sizecheck[0][i]\n            b=sizecheck[1][i+1]-sizecheck[1][i]\n            new=0\n            for k in range(a):\n                for l in range(b):\n                    new+=graypix[sizecheck[0][i]+k][sizecheck[1][j]+l]\n            new=str(int(new/(a*b)))\n            if resized=='':\n                resized=new\n            else:\n                resized=resized+' '+new\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(data):\n    \"\"\" input: 레이블과 픽셀 데이터(48*48)\n        output: 레이블과 행렬 형태의 이미지 \"\"\"\n    \n    image_array = np.zeros(shape=(len(data), 48, 48))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        image_array[i] = image\n        \n    return image_array, image_label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">불러온 이미지 데이터의 형태 변경</span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_data = []\nfor i in imglist:\n    img_data.append(prepare_img(test_imgs+i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_array = np.zeros(shape=(len(imglist), 48, 48))\nfor i in range(len(imglist)):\n        image = np.fromstring(img_data[i], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        test_image_array[i] = image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">데이터 정리</span> "},{"metadata":{"trusted":true},"cell_type":"code","source":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 학습용, 테스트용 데이터 분리"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\nval_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 픽셀 데이터를 48x48의 행렬로 변환"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\ntrain_images = train_images.astype('float32')/255\nval_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\nval_images = val_images.astype('float32')/255\ntest_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\ntest_images = test_images.astype('float32')/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = to_categorical(train_image_label)\nval_labels = to_categorical(val_image_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">Model</span> \nCNN 모델 정의"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(7, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 학습\nhistory = model.fit(train_images, train_labels,\n                    validation_data=(val_images, val_labels),\n                    epochs=15,\n                    batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 예측"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_labels = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color: royalblue;\">분석 결과</span> "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_image_and_emotion(test_image_array, pred_test_labels, image_number):\n    \"\"\"표에 이미지와 분석 결과를 나타내는 함수\"\"\"\n    \n    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n    \n    bar_label = emotions.values()\n    \n    axs[0].imshow(test_image_array[image_number], 'gray')\n    axs[0].set_title('Picture')\n    \n    axs[1].bar(bar_label, pred_test_labels[image_number])\n    axs[1].grid()\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_image_and_emotion(test_image_array, pred_test_labels, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(imglist)):\n    plot_image_and_emotion(test_image_array, pred_test_labels, i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}