{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport os \nimport pandas as pd\nimport tensorflow\ndir_path = './input'\n\ntrain_dir = os.path.join(dir_path,'train.csv')\ntest_dir = os.path.join(dir_path,'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv(train_dir)\ntest_csv = pd.read_csv(test_dir)\ntrain_csv.head()\ntrain_csv.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"split_df = pd.DataFrame([train_csv['pixels'][i].split() for i in range(train_csv.shape[0])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_joined = train_csv.join(split_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_joined.drop('pixels',axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Y_train = train_joined['emotion']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = train_joined.iloc[:,1:2305]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt \n\nx_train_raw = X_train.to_numpy()\ny_train_raw = Y_train.to_numpy()\n\nx_train = x_train_raw.astype(np.float64)\ny_train = y_train_raw.astype(np.int)\n\nx_train/=255","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Showing a couple of images taken from the train data set\nfig = plt.figure()\nax1 = fig.add_subplot(221)\nax1.imshow(x_train[0].reshape((48,48)))\nax2 = fig.add_subplot(222)\nax2.imshow(x_train[1].reshape((48,48)))\nax3 = fig.add_subplot(223)\nax3.imshow(x_train[2].reshape((48,48)))\nax4 = fig.add_subplot(224)\nax4.imshow(x_train[3].reshape((48,48)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Looking at the histogram of the emotions \n#plt.hist(range(len(np.unique(y_train))),y_train)\n\nplt.hist(y_train_raw,range(6))\n\n# Emotion nb 1 seems to be very underrepresented, \n# with that lack of data it is most likely we will perform poorly on recognizing those","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(x_train_raw.shape)\nprint(y_train_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# We build a train/test data set\n# We have a lot of data (overall) so we can afford to take a relatively large validation set\nfrom sklearn.model_selection import train_test_split\n\nx_train,x_val, y_train,y_val = train_test_split(x_train,y_train,test_size = 0.2,stratify = y_train_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.hist(y_val,range(6),label='histogram of the validation set')\nplt.hist(y_train,range(6),fc= (0,0,1,0.5),label='histogram of the training set')\nplt.legend()\nplt.xlabel('Classes')\nplt.ylabel('Instances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pred = rf.predict(x_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nscore = accuracy_score(pred,y_val)\n# 44 % Accuracy\nprint('Accuracy of the random forest classifier :',score)\n\n# We have managed to get better than a random classifier (around 1/7)\n# This is a good baseline model\n\n# We use it to show the importance of the pixels \n\nfi = rf.feature_importances_\nplt.imshow(np.reshape(fi,(48,48)))\nplt.show()\n\n# Showing a couple of images taken from the train data set\nfig = plt.figure()\nax1 = fig.add_subplot(221)\nax1.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nax2 = fig.add_subplot(222)\nax2.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nax3 = fig.add_subplot(223)\nax3.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nax4 = fig.add_subplot(224)\nax4.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting fact, the model seems to look for clues mainly around the mouth, gives importance to the cheeks, and also a bit to the forehead. Pretty much what we do as humans ! "},{"metadata":{"trusted":false},"cell_type":"code","source":"# We will now train a convnet (duh) to tacke the problem\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train = np.reshape(x_train,(x_train.shape[0],48,48,1))\nx_val = np.reshape(x_val,(x_val.shape[0],48,48,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train = to_categorical(y_train)\ny_val = to_categorical(y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL 1"},{"metadata":{"trusted":false},"cell_type":"code","source":"import tensorflow\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation = 'relu', padding = 'same',input_shape = (48,48,1)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(64,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(7,activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(x_train,y_train,validation_data = (x_val,y_val),epochs = 50, batch_size = 128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# First model, only a bit better than the random forest \n# Lets see what's wrong with it\n\n# A first obvious thing is the fact that is not complex enough to learn the training set\n# We are quite obviously under fitting\n\n# Lets try to make the model a bit more complex to make the hypothesis space larger ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(1,len(loss)+1)\n\nplt.plot(epochs,loss,'bo',label='training loss')\nplt.plot(epochs,val_loss,'b',label='val loss')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('losses')\nplt.show()\n\nplt.plot(epochs,acc,'bo',label='training acc')\nplt.plot(epochs,val_acc,'b',label='val acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('accuracies')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL 2 "},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"model_2 = Sequential()\n\nmodel_2.add(Conv2D(256,(3,3),activation = 'relu', padding = 'same',input_shape = (48,48,1)))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Conv2D(256,(5,5),activation = 'relu', padding = 'same'))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Conv2D(256,(5,5),activation = 'relu', padding = 'same'))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Conv2D(256,(5,5),activation = 'relu', padding = 'same'))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Flatten())\nmodel_2.add(Dense(256,activation='relu'))\nmodel_2.add(Dense(256,activation='relu'))\nmodel_2.add(Dense(7,activation='softmax'))\nmodel_2.summary()\n\nmodel_2.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model_2.fit(x_train,y_train,validation_data = (x_val,y_val),epochs = 20, batch_size = 128,verbose=1)\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(1,len(loss)+1)\n\nplt.plot(epochs[1:],loss[1:],'bo',label='training loss')\nplt.plot(epochs[1:],val_loss[1:],'b',label='val loss')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('losses')\nplt.show()\n\nplt.plot(epochs,acc,'bo',label='training acc')\nplt.plot(epochs,val_acc,'b',label='val acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('accuracies')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# The model is severely over fitting, so we'll try to tune the first one a bit \n\n# We now use a pretrained model, facenet","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"m_pre = Sequential()\nfrom tensorflow.keras.applications import InceptionResNetV2\n\n# Since ResNetV2 expects 3 input channels we repeat the image\n\nx_train_3c = x_train[:,:,:,:,np.newaxis]\nx_train_3c.shape\nx_train_rgb = np.repeat(x_train, 3, -1)\n\nplt.imshow(x_train_rgb[0,:,:,0].reshape(48,48))\nplt.show()\nplt.imshow(x_train_rgb[0,:,:,1].reshape(48,48))\nplt.show()\nplt.imshow(x_train_rgb[0,:,:,2].reshape(48,48))\nplt.show()\n\nx_val_rgb = np.repeat(x_val,3,-1)\n\n# It worked","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(x_val_rgb.shape)\nprint(x_train_rgb.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"conv_base = InceptionResNetV2(include_top = False,weights ='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"conv_base.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(tensorflow.keras.layers.ZeroPadding2D((75,75), input_shape = (48,48,3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(128, activation ='relu'))\nmodel.add(Dense(7,activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop',metrics = ['accuracy'],loss='categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"history = model.fit(x_train_rgb,y_train, validation_data = (x_val_rgb,y_val), epochs = 20, batch_size = 256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# the model is very, very long to train, and I don't have the ressources to experiment on it, so we'll keep the handmade one","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# We train the model on the validation + training data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train_full = np.concatenate((x_train,x_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_full = np.concatenate((y_train,y_val))\ny_train_full.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"full = os.path.join(dir_path, 'icml_face_data.csv')\n\nfull_csv = pd.read_csv(full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cop[full_csv['Usage'] != 'Training']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"testing_csv = full_csv[full_csv['Usage'] == 'PublicTest']\nprivate_csv = full_csv[full_csv['Usage'] == 'PrivateTest']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"testing_csv.drop('Usage',axis=1,inplace=True)\nprivate_csv.drop('Usage',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"testing_csv.reset_index(inplace=True)\nprivate_csv.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def convert_tests(df):\n    \n    # We plit the data set \n    split_df_test = pd.DataFrame([df['pixels'][i].split() for i in range(df.shape[0])])\n    temp_joined = df.join(split_df_test)\n    \n    # We drop the pixels column\n    temp_joined.drop('pixels',axis = 1,inplace = True)\n    \n    # We get the X : pixels \n    X = temp_joined.iloc[:,1:2305]\n    x_raw = X.to_numpy()\n    x = x_raw.astype(np.float64)\n    x/=255\n\n    # We get the Y : labels\n    Y = temp_joined['emotion']\n    y_raw = Y.to_numpy()\n    y = y_raw.astype(np.int)\n    y = to_categorical(y)\n\n    x = np.reshape(x,(x.shape[0],48,48,1))\n    \n    print('Shape of attributes matrix',x.shape)\n    print('Shape of label matrix',y.shape)\n    \n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_public, y_public = convert_tests(testing_csv)\nx_private,y_private = convert_tests(private_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.imshow(x_public[2].reshape(48,48))\nplt.show()\ny_public[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import tensorflow\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation = 'relu', padding = 'same',input_shape = (48,48,1)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(64,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(7,activation='softmax'))\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n\nhistory = model.fit(x_train_full,y_train_full,epochs = 150, batch_size = 128)\n\nloss = history.history['loss']\n\nacc = history.history['accuracy']\n\nepochs = range(1,len(loss)+1)\n\nplt.plot(epochs,loss,'bo',label='training loss')\nplt.plot(epochs,acc,'b',label='training acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('losses')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.evaluate(x_private,y_private)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# My Model Accuracy : 62.41 % (10/58)"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.save('model_facial_recognition.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}