{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import and preprocess data\n\nDatasets:\n\n- fer2013"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Constants for FER2013 dataset\nFER2013_PATH = \"/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013/fer2013.csv\"\nFER2013_WIDTH = 48\nFER2013_HEIGHT = 48","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(FER2013_PATH)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Usage\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate training and public/private test data\ndata_publ_test = data[data.Usage==\"PublicTest\"]\ndata_priv_test = data[data.Usage==\"PrivateTest\"]\ndata = data[data.Usage==\"Training\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]  # indices 0 to 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"emotion\"].value_counts(sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fer2013_show_instance(index):\n    \"\"\"Shows the image and the emotion label of the index's instance.\"\"\"\n    image = np.reshape(data.at[index, \"pixels\"].split(\" \"), (FER2013_WIDTH, FER2013_HEIGHT)).astype(\"float\")\n    image -= np.mean(image)\n    image /= np.std(image)\n    print(Emotions[data.at[index, \"emotion\"]])\n    plt.imshow(image, cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fer2013_show_instance(np.random.randint(0,len(data)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fer2013_to_X():\n    \"\"\"Transforms the (blank separated) pixel strings in the DataFrame to an 3-dimensional array \n    (1st dim: instances, 2nd and 3rd dims represent 2D image).\"\"\"\n    \n    X = []\n    pixels_list = data[\"pixels\"].values\n    \n    for pixels in pixels_list:\n        single_image = np.reshape(pixels.split(\" \"), (FER2013_WIDTH, FER2013_HEIGHT)).astype(\"float\")\n        X.append(single_image)\n        \n    # Convert list to 4D array:\n    X = np.expand_dims(np.array(X), -1)\n    \n    # Normalize image data:\n    X -= np.mean(X, axis=0)\n    X /= np.std(X, axis=0)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get features (image data)\nX = fer2013_to_X()\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get labels (one-hot encoded)\ny = pd.get_dummies(data['emotion']).values\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save data\nnp.save(\"fer2013_X\", X)\nnp.save(\"fer2013_y\", y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"bsc_cnn_emotion_rpi_matthias_wolf","language":"python","name":"bsc_cnn_emotion_rpi_matthias_wolf"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}