{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import models, layers\nimport tqdm\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom sklearn import svm\nfrom sklearn.model_selection import KFold\nimport os\nimport os, shutil \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'\ndata = pd.read_csv(path+'icml_face_data.csv')\nemotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\nclasses = dict(zip(range(0, 7), (((data[data[' Usage']=='Training']['emotion'].value_counts()).sort_index())/len(data[data[' Usage']=='Training']['emotion'])).tolist()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.emotion\nkf = KFold(n_splits=6)\nfor train, test in kf.split(X):\n    print(\"%s %s\" % (train, test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to parse data into right format\n# Output: Image in right shaped and normalized + labels\ndef parse_data(data):\n    image_array = np.zeros(shape=(len(data), 48, 48)) # 1\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48)) # 1\n        image_array[i] = image\n        \n    return image_array, image_label\n\n# Splitting the data into train, validation and testing set thanks to Usage column\ntrain_imgs, train_lbls = parse_data(data[data[\" Usage\"] == \"Training\"])\nval_imgs, val_lbls = parse_data(data[data[\" Usage\"] == \"PrivateTest\"])\ntest_imgs, test_lbls = parse_data(data[data[\" Usage\"] == \"PublicTest\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_imgs.reshape((train_imgs.shape[0], 48, 48, 1))\ntrain_images = train_images.astype('float32')/255\nval_images = val_imgs.reshape((val_imgs.shape[0], 48, 48, 1))\nval_images = val_images.astype('float32')/255\ntest_images = test_imgs.reshape((test_imgs.shape[0], 48, 48, 1))\ntest_images = test_images.astype('float32')/255\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train shape\", np.shape(train_imgs))\nprint(\"validation shape\", np.shape(val_imgs))\nprint(\"validatio shape\", np.shape(val_imgs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_imgs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MLP model","metadata":{}},{"cell_type":"code","source":"# Building a MLP model based on LeNet architecture \nmodel_mlp = keras.Sequential()\nmodel_mlp.add(layers.Flatten(input_shape=(48, 48, 1)))\nmodel_mlp.add(layers.Dense(units=120, activation='relu'))\nmodel_mlp.add(layers.Dense(units=84, activation='relu'))\nmodel_mlp.add(layers.Dense(units=7, activation = 'softmax'))\nmodel_mlp.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(lr=1e-3), metrics=['accuracy'])\nmodel_mlp.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model, and validating\nmodel_mlp.fit(train_imgs, train_lbls, \n          epochs=10, batch_size=32, \n          validation_data=(val_imgs, val_lbls), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\ntrain_labels = to_categorical(train_lbls)\nval_labels = to_categorical(val_lbls)\ntest_labels = to_categorical(test_lbls)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN model","metadata":{}},{"cell_type":"code","source":"model_cnn = models.Sequential()\nmodel_cnn.add(layers.Conv2D(128, (3, 3), activation='selu', input_shape=(48, 48, 1)))\nmodel_cnn.add(layers.MaxPool2D((2, 2)))\nmodel_cnn.add(layers.Conv2D(128, (3, 3), activation='selu'))\nmodel_cnn.add(layers.MaxPool2D((2, 2)))\nmodel_cnn.add(layers.Conv2D(64, (3, 3), activation='elu'))\nmodel_cnn.add(layers.MaxPool2D((2, 2)))\nmodel_cnn.add(layers.Conv2D(64, (3, 3), activation='elu'))\nmodel_cnn.add(layers.Flatten())\nmodel_cnn.add(layers.Dense(64, activation='relu'))\nmodel_cnn.add(layers.Dense(7, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_cnn.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_cnn.fit(train_images, train_labels,\n                    validation_data=(val_images, val_labels),\n                    class_weight = classes,\n                    epochs=12,\n                    batch_size=512)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train accuracy and validation accuracy vs epoch graph\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, label='Training loss')\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prob = model_cnn.predict(test_images)\ntest_pred = np.argmax(test_prob, axis=1)\ntest_accuracy = np.mean(test_pred == test_lbls)\n\nprint(test_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_mat = confusion_matrix(test_lbls, test_pred)\npd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. У чому призначення різних типів шарів згорткових нейромереж?<br>\nЗгортковий шар є основним будівельним блоком СНС.\nАгрегуючий шар служить для поступового скорочення просторового розміру уявлення для зменшення кількості параметрів і обсягу обчислень в мережі, а тому ще й для контролю перенавчання.\nШар зрізаних лінійних вузлів підсилює нелінійні властивості функції прийняття рішення і мережі в цілому, зачіпаючи рецептивні поля сверточного шару.\nНейрони в  шарі мають сполучення з усіма возбуждениями попереднього шару, як це можна бачити в звичайних нейронних мережах. Їх порушення потім може бути обчислено матричних множенням, за яким слід зміщення упередженості.\nШар втрат визначає, як тренування штрафує відхилення між передбачуваними і справжніми знаками, і є, як правило, завершальним шаром. Для різних завдань в ньому можуть використовувати різні функції втрат (найчастіше це softmax і sigmoid).\n2. Які основні етапи типового проекту машинного навчання?<br>\nБізнес-аналіз, аналіз і підготовка даних, моделювання, оцінка рішення, впровадження.","metadata":{}}]}