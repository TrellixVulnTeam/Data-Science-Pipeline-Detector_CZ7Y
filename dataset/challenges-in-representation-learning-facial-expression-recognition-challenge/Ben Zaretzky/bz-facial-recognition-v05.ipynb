{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Statements","metadata":{}},{"cell_type":"code","source":"# Import packages\n%config Completer.use_jedi = False\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle\n\nfrom sklearn.model_selection import train_test_split \n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:24:46.257855Z","iopub.execute_input":"2021-12-07T21:24:46.258178Z","iopub.status.idle":"2021-12-07T21:24:51.858438Z","shell.execute_reply.started":"2021-12-07T21:24:46.2581Z","shell.execute_reply":"2021-12-07T21:24:51.857708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# Load the training data and view the shape\ntrain = pd.read_csv('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv')\n\nprint('Training Set Size:', train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:24:57.272384Z","iopub.execute_input":"2021-12-07T21:24:57.273082Z","iopub.status.idle":"2021-12-07T21:25:01.236045Z","shell.execute_reply.started":"2021-12-07T21:24:57.273043Z","shell.execute_reply":"2021-12-07T21:25:01.234281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:02.943049Z","iopub.execute_input":"2021-12-07T21:25:02.943717Z","iopub.status.idle":"2021-12-07T21:25:02.96279Z","shell.execute_reply.started":"2021-12-07T21:25:02.943681Z","shell.execute_reply":"2021-12-07T21:25:02.961981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the string of pixels to an array\ntrain['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48,1) for x in train['pixels']]","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:05.176909Z","iopub.execute_input":"2021-12-07T21:25:05.177168Z","iopub.status.idle":"2021-12-07T21:25:07.882356Z","shell.execute_reply.started":"2021-12-07T21:25:05.17714Z","shell.execute_reply":"2021-12-07T21:25:07.881572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store pixels and labels in an array\npixels = np.concatenate(train['pixels'])\nlabels = train.emotion.values\n\n# Print the shape of both arrays\nprint(pixels.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:14.982466Z","iopub.execute_input":"2021-12-07T21:25:14.98278Z","iopub.status.idle":"2021-12-07T21:25:15.266793Z","shell.execute_reply.started":"2021-12-07T21:25:14.982743Z","shell.execute_reply":"2021-12-07T21:25:15.266042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split, Reshape, and Scale Datasets","metadata":{}},{"cell_type":"code","source":"# Split the data into a training and validation set\nX_train, X_valid, y_train, y_valid = train_test_split(\n    pixels, labels, test_size=0.2, stratify=labels, random_state=1\n)\n\n\n# View the shapes of the data sets\nprint('X_train Shape:', X_train.shape)\nprint('y_train Shape:', y_train.shape)\nprint()\nprint('X_valid Shape:', X_valid.shape)\nprint('y_valid Shape:', y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:17.989236Z","iopub.execute_input":"2021-12-07T21:25:17.989521Z","iopub.status.idle":"2021-12-07T21:25:18.16848Z","shell.execute_reply.started":"2021-12-07T21:25:17.98949Z","shell.execute_reply":"2021-12-07T21:25:18.167719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize the pixel values between 0 and 1\nXs_train = X_train / 255\nXs_valid = X_valid / 255","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:20.105627Z","iopub.execute_input":"2021-12-07T21:25:20.106192Z","iopub.status.idle":"2021-12-07T21:25:20.311584Z","shell.execute_reply.started":"2021-12-07T21:25:20.106155Z","shell.execute_reply":"2021-12-07T21:25:20.310774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Augmentation","metadata":{}},{"cell_type":"code","source":"# Create an image generator for augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 30,\n    width_shift_range = 0.2, \n    height_shift_range = 0.2, \n    zoom_range = 0.2, \n    horizontal_flip = True, \n    fill_mode = 'nearest'\n)\n\ntrain_loader = train_datagen.flow(Xs_train, y_train, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:21.402198Z","iopub.execute_input":"2021-12-07T21:25:21.402475Z","iopub.status.idle":"2021-12-07T21:25:21.491166Z","shell.execute_reply.started":"2021-12-07T21:25:21.402432Z","shell.execute_reply":"2021-12-07T21:25:21.490392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Xception Model\nThe code for the Xecption model is taken from https://colab.research.google.com/github/mavenzer/Autism-Detection-Using_YOLO/blob/master/Tutorial_implementing_Xception_in_TensorFlow_2_0_using_the_Functional_API.ipynb#scrollTo=uy3q-iLm3VV2 since the TensorFlow package requires an image size of at least 71x71.","metadata":{}},{"cell_type":"code","source":"def entry_flow(inputs):\n\n  x = layers.Conv2D(32, 3, strides=2, padding='same')(inputs)\n  x = layers.BatchNormalization()(x)\n  x = layers.Activation('relu')(x)\n\n  x = layers.Conv2D(64, 3, padding='same')(x)\n  x = layers.BatchNormalization()(x)\n  x = layers.Activation('relu')(x)\n\n  previous_block_activation = x  # Set aside residual\n  \n  # Blocks 1, 2, 3 are identical apart from the feature depth.\n  for size in [128, 256, 728]:\n    x = layers.Activation('relu')(x)\n    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Activation('relu')(x)\n    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n    \n    residual = layers.Conv2D(  # Project residual\n        size, 1, strides=2, padding='same')(previous_block_activation)           \n    x = layers.add([x, residual])  # Add back residual\n    previous_block_activation = x  # Set aside next residual\n\n  return x\n\n\ndef middle_flow(x, num_blocks=8):\n  \n  previous_block_activation = x\n\n  for _ in range(num_blocks):\n    x = layers.Activation('relu')(x)\n    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Activation('relu')(x)\n    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Activation('relu')(x)\n    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.add([x, previous_block_activation])  # Add back residual\n    previous_block_activation = x  # Set aside next residual\n    \n  return x\n\n\ndef exit_flow(x, num_classes=7):\n  \n  previous_block_activation = x\n\n  x = layers.Activation('relu')(x)\n  x = layers.SeparableConv2D(728, 3, padding='same')(x)\n  x = layers.BatchNormalization()(x)\n\n  x = layers.Activation('relu')(x)\n  x = layers.SeparableConv2D(1024, 3, padding='same')(x)\n  x = layers.BatchNormalization()(x)\n  \n  x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n\n  residual = layers.Conv2D(  # Project residual\n      1024, 1, strides=2, padding='same')(previous_block_activation)\n  x = layers.add([x, residual])  # Add back residual\n  \n  x = layers.SeparableConv2D(1536, 3, padding='same')(x)\n  x = layers.BatchNormalization()(x)\n  x = layers.Activation('relu')(x)\n  \n  x = layers.SeparableConv2D(2048, 3, padding='same')(x)\n  x = layers.BatchNormalization()(x)\n  x = layers.Activation('relu')(x)\n  \n  x = layers.GlobalAveragePooling2D()(x)\n  if num_classes == 1:\n    activation = 'sigmoid'\n  else:\n    activation = 'softmax'\n  return layers.Dense(num_classes, activation=activation)(x)\n\ninputs = keras.Input(shape=(48, 48, 1))  # Variable-size image inputs.\noutputs = exit_flow(middle_flow(entry_flow(inputs)))\nxception = keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:27.149112Z","iopub.execute_input":"2021-12-07T21:25:27.149447Z","iopub.status.idle":"2021-12-07T21:25:30.476025Z","shell.execute_reply.started":"2021-12-07T21:25:27.149414Z","shell.execute_reply":"2021-12-07T21:25:30.475252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = xception\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:43.266002Z","iopub.execute_input":"2021-12-07T21:25:43.266262Z","iopub.status.idle":"2021-12-07T21:25:43.332664Z","shell.execute_reply.started":"2021-12-07T21:25:43.26623Z","shell.execute_reply":"2021-12-07T21:25:43.331914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Run 1","metadata":{}},{"cell_type":"code","source":"# Set up the optimizer\nopt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:56.808243Z","iopub.execute_input":"2021-12-07T21:25:56.808528Z","iopub.status.idle":"2021-12-07T21:25:56.828347Z","shell.execute_reply.started":"2021-12-07T21:25:56.808498Z","shell.execute_reply":"2021-12-07T21:25:56.827672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Training Run #1\nh1 = cnn.fit(train_loader, \n             batch_size=64, \n             epochs=50, \n             validation_data=(Xs_valid, y_valid), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:25:59.506982Z","iopub.execute_input":"2021-12-07T21:25:59.507346Z","iopub.status.idle":"2021-12-07T21:44:23.948415Z","shell.execute_reply.started":"2021-12-07T21:25:59.507293Z","shell.execute_reply":"2021-12-07T21:44:23.94774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save history and view plots of loss and accuracy\nhistory = h1.history\nn_epochs = len(history['loss'])\n\nplt.figure(figsize=[10,4])\nplt.subplot(1,2,1)\nplt.plot(range(1, n_epochs+1), history['loss'], label='Training')\nplt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')\nplt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:44:30.726198Z","iopub.execute_input":"2021-12-07T21:44:30.726478Z","iopub.status.idle":"2021-12-07T21:44:31.245998Z","shell.execute_reply.started":"2021-12-07T21:44:30.726433Z","shell.execute_reply":"2021-12-07T21:44:31.245324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice that the graphs for the accuracy and loss are not very smooth. This indicates that we need to reduce the learning rate. The purpose of decreasing the learning rate is to allow our model to approach the optimal solution. When the learning rate is too large, the model tends to quickly converge on a suboptimal solution.","metadata":{}},{"cell_type":"markdown","source":"# Training Run 2","metadata":{}},{"cell_type":"code","source":"# Update the learning rate\ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:44:35.685311Z","iopub.execute_input":"2021-12-07T21:44:35.685685Z","iopub.status.idle":"2021-12-07T21:44:35.693444Z","shell.execute_reply.started":"2021-12-07T21:44:35.685653Z","shell.execute_reply":"2021-12-07T21:44:35.692651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Training Run #2\nh2 = cnn.fit(train_loader, \n             batch_size=64, \n             epochs=50, \n             validation_data=(Xs_valid, y_valid), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:44:38.42937Z","iopub.execute_input":"2021-12-07T21:44:38.430084Z","iopub.status.idle":"2021-12-07T22:03:21.33602Z","shell.execute_reply.started":"2021-12-07T21:44:38.430047Z","shell.execute_reply":"2021-12-07T22:03:21.335175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save history and view plots of loss and accuracy\nfor k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:03:23.57826Z","iopub.execute_input":"2021-12-07T22:03:23.578744Z","iopub.status.idle":"2021-12-07T22:03:23.990053Z","shell.execute_reply.started":"2021-12-07T22:03:23.578706Z","shell.execute_reply":"2021-12-07T22:03:23.989341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The validation loss and accuracy stabilzed after reducing the learning rate. We will reduce the learning rate a final time to see if we can improve the accuracy any more. This time we will only run 10 epochs since the training accuracy is increasing more than validation accuracy.","metadata":{}},{"cell_type":"markdown","source":"# Training Run 3","metadata":{}},{"cell_type":"code","source":"# Update the learning rate\ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.00001)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:03:38.398452Z","iopub.execute_input":"2021-12-07T22:03:38.399156Z","iopub.status.idle":"2021-12-07T22:03:38.404025Z","shell.execute_reply.started":"2021-12-07T22:03:38.399123Z","shell.execute_reply":"2021-12-07T22:03:38.403149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Training Run #3\nh3 = cnn.fit(train_loader, \n             batch_size=64, \n             epochs=10, \n             validation_data=(Xs_valid, y_valid), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:03:41.048218Z","iopub.execute_input":"2021-12-07T22:03:41.048502Z","iopub.status.idle":"2021-12-07T22:07:34.59407Z","shell.execute_reply.started":"2021-12-07T22:03:41.048449Z","shell.execute_reply":"2021-12-07T22:07:34.593288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save history and view plots of loss and accuracy\nfor k in history.keys():\n    history[k] += h3.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:08:03.282263Z","iopub.execute_input":"2021-12-07T22:08:03.282556Z","iopub.status.idle":"2021-12-07T22:08:03.689974Z","shell.execute_reply.started":"2021-12-07T22:08:03.282525Z","shell.execute_reply":"2021-12-07T22:08:03.689305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"# Save the model\ncnn.save('fer_v05_BZ.h5')\npickle.dump(history, open(f'fer_v05_BZ.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:08:06.548969Z","iopub.execute_input":"2021-12-07T22:08:06.549522Z","iopub.status.idle":"2021-12-07T22:08:07.445776Z","shell.execute_reply.started":"2021-12-07T22:08:06.549474Z","shell.execute_reply":"2021-12-07T22:08:07.445046Z"},"trusted":true},"execution_count":null,"outputs":[]}]}