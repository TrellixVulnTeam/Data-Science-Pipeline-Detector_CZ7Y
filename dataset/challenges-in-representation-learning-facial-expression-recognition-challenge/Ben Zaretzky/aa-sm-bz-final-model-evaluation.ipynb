{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Statements","metadata":{}},{"cell_type":"code","source":"%%capture\n\n!pip install --upgrade scikit-learn","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:18.350191Z","iopub.execute_input":"2021-12-13T01:10:18.351093Z","iopub.status.idle":"2021-12-13T01:10:26.369047Z","shell.execute_reply.started":"2021-12-13T01:10:18.351035Z","shell.execute_reply":"2021-12-13T01:10:26.367614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scikitplot\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nfrom tensorflow import keras\nfrom sklearn.metrics import classification_report, top_k_accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:26.371377Z","iopub.execute_input":"2021-12-13T01:10:26.371674Z","iopub.status.idle":"2021-12-13T01:10:26.377652Z","shell.execute_reply.started":"2021-12-13T01:10:26.371638Z","shell.execute_reply":"2021-12-13T01:10:26.376875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since this competition is closed, we have access to the full dataset. Therefore, we will combine the private and public test data sets together. ","metadata":{}},{"cell_type":"markdown","source":"# Read in Full Data Set","metadata":{}},{"cell_type":"code","source":"# Read in full data set\ndata = pd.read_csv('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv')\ndata.columns = ['emotion', 'Usage', 'pixels']\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:26.379154Z","iopub.execute_input":"2021-12-13T01:10:26.379656Z","iopub.status.idle":"2021-12-13T01:10:29.337311Z","shell.execute_reply.started":"2021-12-13T01:10:26.379608Z","shell.execute_reply":"2021-12-13T01:10:29.336588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View first five rows\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:29.338555Z","iopub.execute_input":"2021-12-13T01:10:29.339036Z","iopub.status.idle":"2021-12-13T01:10:29.34991Z","shell.execute_reply.started":"2021-12-13T01:10:29.33899Z","shell.execute_reply":"2021-12-13T01:10:29.348938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Select Only Data in Test Sets","metadata":{}},{"cell_type":"code","source":"# Select only rows that are in the public or private test set\ntest = data.loc[data[\"Usage\"] != 'Training',['emotion','pixels']]\n#test.drop(columns='Usage', inplace=True)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:29.352422Z","iopub.execute_input":"2021-12-13T01:10:29.352696Z","iopub.status.idle":"2021-12-13T01:10:29.379705Z","shell.execute_reply.started":"2021-12-13T01:10:29.352665Z","shell.execute_reply":"2021-12-13T01:10:29.378245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reshape Pixels","metadata":{}},{"cell_type":"code","source":"# Reshape the pixels\ntest['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48,1) for x in test['pixels']]","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:29.381958Z","iopub.execute_input":"2021-12-13T01:10:29.382356Z","iopub.status.idle":"2021-12-13T01:10:29.975176Z","shell.execute_reply.started":"2021-12-13T01:10:29.38231Z","shell.execute_reply":"2021-12-13T01:10:29.973811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine pixels into single array\npixels = np.concatenate(test['pixels'].values)\n\nprint(pixels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:29.977372Z","iopub.execute_input":"2021-12-13T01:10:29.977645Z","iopub.status.idle":"2021-12-13T01:10:30.030635Z","shell.execute_reply.started":"2021-12-13T01:10:29.977617Z","shell.execute_reply":"2021-12-13T01:10:30.029681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize the pixels values between 0 and 1\npixels = pixels / 255","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:30.031864Z","iopub.execute_input":"2021-12-13T01:10:30.03211Z","iopub.status.idle":"2021-12-13T01:10:30.090319Z","shell.execute_reply.started":"2021-12-13T01:10:30.032081Z","shell.execute_reply":"2021-12-13T01:10:30.089287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Trained Model","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel = keras.models.load_model('../input/models/Facial Recognition Models/fer_v05_BZ.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:30.091544Z","iopub.execute_input":"2021-12-13T01:10:30.091768Z","iopub.status.idle":"2021-12-13T01:10:35.819885Z","shell.execute_reply.started":"2021-12-13T01:10:30.091739Z","shell.execute_reply":"2021-12-13T01:10:35.818936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Prediction Probabilities","metadata":{}},{"cell_type":"code","source":"# Compute probabilities\ntest_probs = model.predict(pixels)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:10:35.822346Z","iopub.execute_input":"2021-12-13T01:10:35.822671Z","iopub.status.idle":"2021-12-13T01:11:12.032197Z","shell.execute_reply.started":"2021-12-13T01:10:35.822632Z","shell.execute_reply":"2021-12-13T01:11:12.031342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assign Each Sample a Predicted Label","metadata":{}},{"cell_type":"code","source":"final_pred = np.argmax(test_probs, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:12.034995Z","iopub.execute_input":"2021-12-13T01:11:12.035424Z","iopub.status.idle":"2021-12-13T01:11:12.040176Z","shell.execute_reply.started":"2021-12-13T01:11:12.035388Z","shell.execute_reply":"2021-12-13T01:11:12.039454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine Predicted Labels and Actual Labels","metadata":{}},{"cell_type":"code","source":"test['predictions'] = np.round(final_pred,0)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:12.041402Z","iopub.execute_input":"2021-12-13T01:11:12.041832Z","iopub.status.idle":"2021-12-13T01:11:12.972619Z","shell.execute_reply.started":"2021-12-13T01:11:12.041802Z","shell.execute_reply":"2021-12-13T01:11:12.971751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_cat = {0:'Anger', 1:'Disgust', 2:'Fear', 3:'Happiness', 4: 'Sadness', 5: 'Surprise', 6: 'Neutral'}\ntest['emotion'] = test['emotion'].apply(lambda x: emotion_cat[x])\ntest['predictions'] = test['predictions'].apply(lambda x: emotion_cat[x])","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:12.97375Z","iopub.execute_input":"2021-12-13T01:11:12.973974Z","iopub.status.idle":"2021-12-13T01:11:12.983325Z","shell.execute_reply.started":"2021-12-13T01:11:12.973946Z","shell.execute_reply":"2021-12-13T01:11:12.982455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification Report","metadata":{}},{"cell_type":"code","source":"my_classification_report = classification_report(test['emotion'], test['predictions'])\nprint(my_classification_report)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:12.985776Z","iopub.execute_input":"2021-12-13T01:11:12.986001Z","iopub.status.idle":"2021-12-13T01:11:13.171939Z","shell.execute_reply.started":"2021-12-13T01:11:12.985974Z","shell.execute_reply":"2021-12-13T01:11:13.169978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our CNN model using the Xception architecure had a 66% accuracy. Since the competition has closed, we cannot submit our predictions or be placed on the leaderboard. Based on the submissions while the competition was still active, we would have placed in the top five teams. The model was able to predict images with happiness better than the other emotions, and struggled with classifying fear and disgust. For example, disgust had a precision of 61% and a recall of 38%. This means of the images our model classified the emotion as disgust, 61% of these images true emotion was digust. However, the model correctly indentified only 38% of all of the images with disgust as the emotion. Below, we will look at the confustion matrix to see what emotions our model thought these images were.","metadata":{}},{"cell_type":"markdown","source":"# Number of Misclassified Samples","metadata":{}},{"cell_type":"code","source":"print('Total Wrong Predictions:', np.sum(test['emotion'] != test['predictions']))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:13.173289Z","iopub.execute_input":"2021-12-13T01:11:13.173506Z","iopub.status.idle":"2021-12-13T01:11:13.179845Z","shell.execute_reply.started":"2021-12-13T01:11:13.173481Z","shell.execute_reply":"2021-12-13T01:11:13.17899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"scikitplot.metrics.plot_confusion_matrix(test['emotion'], test['predictions'], figsize=(7,7))    ","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:13.180926Z","iopub.execute_input":"2021-12-13T01:11:13.181177Z","iopub.status.idle":"2021-12-13T01:11:13.748564Z","shell.execute_reply.started":"2021-12-13T01:11:13.181149Z","shell.execute_reply":"2021-12-13T01:11:13.747745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confustion matrix allows us to see a breakdown of the predicted labels and the true labels. As mentioned previously, our model had a hard time classifying images with disgust. We can see that our model correctly predicted 42 images where the true emotion was disgust. However, it predicted that the emotion was anger when it was actually disgust 43 times. In the future, we may decide to combine the anger and digust classes since they are very similar emotions. We also see that our model had a tough time distinguishing between neutral and sadness.","metadata":{}},{"cell_type":"markdown","source":"# Top-K Accuracy","metadata":{}},{"cell_type":"code","source":"# Compute Top-K accuracy for each class\nfor k in range(0, 7):\n    print(f\"{emotion_cat[k]} top accuracy: {round(top_k_accuracy_score(test['emotion'], test_probs, k=k), 2)}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:13.749652Z","iopub.execute_input":"2021-12-13T01:11:13.749859Z","iopub.status.idle":"2021-12-13T01:11:13.801313Z","shell.execute_reply.started":"2021-12-13T01:11:13.749833Z","shell.execute_reply":"2021-12-13T01:11:13.800455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View Correctly and Incorrectly Classified Samples","metadata":{}},{"cell_type":"markdown","source":"## Correctly Classified","metadata":{}},{"cell_type":"markdown","source":"Below is a plot of correctly classified images. The blue text next to each image is the observed emotion and the red text is the predicted emotion.","metadata":{}},{"cell_type":"code","source":"plt.close()\nplt.rcParams[\"figure.figsize\"] = [16,16]\n\nrow = 0\nfor emotion in np.unique(test['emotion'].values):\n    all_emotion_images = test[(test['emotion'] == emotion) & (test['predictions'] == emotion)]\n    for i in range(5):\n        \n        img = all_emotion_images.iloc[i,].pixels.reshape(48,48)\n        actual_lab = emotion\n        predicted_lab = all_emotion_images.iloc[i,].predictions\n\n        plt.subplot(7,5,row+i+1)\n        plt.imshow(img, cmap='binary_r')\n        plt.text(-30, 5, s = str(actual_lab), fontsize=10, color='b')\n        plt.text(-30, 10, s = str(predicted_lab), fontsize=10, color='r')\n        plt.axis('off')\n    row += 5\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:13.802493Z","iopub.execute_input":"2021-12-13T01:11:13.802785Z","iopub.status.idle":"2021-12-13T01:11:16.071048Z","shell.execute_reply.started":"2021-12-13T01:11:13.802751Z","shell.execute_reply":"2021-12-13T01:11:16.070123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Incorrectly Classified","metadata":{}},{"cell_type":"markdown","source":"Below is a plot of misclassified images. The blue text next to each image is the observed emotion and the red text is the predicted emotion.","metadata":{}},{"cell_type":"code","source":"plt.close()\nplt.rcParams[\"figure.figsize\"] = [16,16]\n\nrow = 0\nfor emotion in np.unique(test['emotion'].values):\n    all_emotion_images = test[(test['emotion'] == emotion) & (test['predictions'] != emotion)]\n    for i in range(5):\n        \n        img = all_emotion_images.iloc[i,].pixels.reshape(48,48)\n        actual_lab = emotion\n        predicted_lab = all_emotion_images.iloc[i,].predictions\n\n        plt.subplot(7,5,row+i+1)\n        plt.imshow(img, cmap='binary_r')\n        plt.text(-30, 5, s = str(actual_lab), fontsize=10, color='b')\n        plt.text(-30, 10, s = str(predicted_lab), fontsize=10, color='r')\n        plt.axis('off')\n    row += 5\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T01:11:16.072838Z","iopub.execute_input":"2021-12-13T01:11:16.073244Z","iopub.status.idle":"2021-12-13T01:11:17.894582Z","shell.execute_reply.started":"2021-12-13T01:11:16.07321Z","shell.execute_reply":"2021-12-13T01:11:17.893969Z"},"trusted":true},"execution_count":null,"outputs":[]}]}