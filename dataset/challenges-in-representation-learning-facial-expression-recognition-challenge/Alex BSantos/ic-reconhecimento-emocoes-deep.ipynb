{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom tensorflow.keras.layers import BatchNormalization\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import array_to_img\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file='../input/challenges-in-representation-learning-facial-expression-recognition-challenge/test.csv'\ntrain_file='../input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames_train=['emotion','pixels']\nnames_test=['pixels']\ndf_test=pd.read_csv('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/test.csv',names=names_test, na_filter=False)\n#im=df['pixels']\ndf_test=df_test.drop([0],axis=0)\ndf_test.head(10)\ndf_train=pd.read_csv('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv',names=names_train, na_filter=False)\n#im=df['pixels']\ndf_train=df_train.drop([0],axis=0)\ndf_train.head(10)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gray_to_rgb(im):\n  '''\n  converts images from single channel images to 3 channels\n  '''\n\n  w, h = im.shape\n  ret = np.empty((w, h, 3), dtype=np.uint8)\n  ret[:, :, 2] =  ret[:, :, 1] =  ret[:, :, 0] =  im\n  return ret\n\ndef convert_to_image(pixels, mode=\"save\", t=\"gray\"):\n\n  if type(pixels) == str:\n      pixels = np.array([int(i) for i in pixels.split()])\n  if mode == \"show\":\n    if t == \"gray\":\n      return pixels.reshape(48,48)\n    else:\n      return gray_to_rgb(pixels.reshape(48,48))\n  else:\n      return pixels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"pixels\"] = df_train[\"pixels\"].apply(lambda x : convert_to_image(x, mode=\"show\", t=\"gray\"))\ndf_test[\"pixels\"] = df_test[\"pixels\"].apply(lambda x : convert_to_image(x, mode=\"show\", t=\"gray\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(df_train[\"pixels\"],  df_train[\"emotion\"], test_size=0.2, random_state=1)\n\nX_train = np.array(list(X_train[:]), dtype=np.float)\nX_val = np.array(list(X_val[:]), dtype=np.float)\n\ny_train = np.array(list(y_train[:]), dtype=np.float)\ny_val = np.array(list(y_val[:]), dtype=np.float)\n\nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1) \nX_val = X_val.reshape(X_val.shape[0], 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=np.array(list(df_test['pixels']), dtype=np.float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE=48","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n                 input_shape=(IMG_SIZE,IMG_SIZE,1)))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='softmax'))\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom=model.fit(X_train,y_train,epochs=50,batch_size=64,validation_data=(X_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(custom.history['loss'])\nplt.plot(custom.history['val_loss'])\nplt.title(\"Model Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(custom.history['accuracy'])\nplt.plot(custom.history['val_accuracy'])\nplt.title(\"Model Accuracy\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}