{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.models import Model\nimport keras\nimport csv\nfrom PIL import Image    \nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D,BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tqdm import tqdm\nimport numpy as np # linear algebra\nfrom numpy import asarray\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import RandomOverSampler\nimport collections\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.layers import Dropout\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# from tensorflow.keras.utils import plot_model\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        print(os.listdir(\"../input\"))\n        \n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_set = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv')\nexamples = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/test.csv')\nicml_face_data = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = np.array(data_set.emotion)\ncollections.Counter(ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversample = RandomOverSampler(sampling_strategy='auto')\n# fit and apply the transform\nX_over, y_over = oversample.fit_resample((data_set.pixels).values.reshape(-1, 1), data_set.emotion)\n\n\na = np.array(y_over)\ncollections.Counter(a)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_over = pd.Series(y_over)\ny_over= y_over.values.reshape(len(y_over),1)\n\nX_train,X_test,Y_train,Y_test = train_test_split(X_over,y_over, test_size=0.2)\n#print(X_train[11])\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(pixels):\n    a = []\n    \n    for i in range(len(pixels)):\n            image_string = (pixels)[i].split(' ') \n            image_data = np.asarray(image_string, dtype=np.uint8).reshape(48,48,1)\n            a.append(image_data)\n\n    return a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\na= []\n\nX_train = pd.Series(X_train.flatten())\nX_train_resnet50 =X_train\na = preprocessing(X_train)\n\n\n\nX_train = np.array(a)\n#X_test =test\n# Y_train = y_over\n\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ResNet50\na = []\nfor i in range(len(X_train_resnet50)):\n            image_string = (X_train_resnet50)[i].split(' ') \n            image_data = np.asarray(image_string, dtype=np.uint8).reshape(48,48)\n            a.append(image_data)\n\nX_train_resnet50 = np.array(a)\nrgb_X_train = np.repeat(X_train_resnet50[..., np.newaxis], 3, -1)\nprint(rgb_X_train.shape)  # (size, 48, 48, 3)\n\nmodel1 = ResNet50(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n\nx = model1.output\nx= Flatten()(x)\nx = Dense(7, activation='softmax')(x)\nmodel50 = Model(inputs=model1.input, outputs=x)\n\n\nmodel50.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel50.fit(rgb_X_train, Y_train, batch_size=64, epochs=40, steps_per_epoch=len(X_train)/128, validation_split = 0.25)\nmodel50.save('CNNmodel')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Expressions = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"]\na= []\nprint (\"X_test shape: \" + str(X_test.shape))\nX_test50 = pd.Series(X_test.flatten())\na = []\nfor i in range(len(X_test50)):\n            image_string = (X_test50)[i].split(' ') \n            image_data = np.asarray(image_string, dtype=np.uint8).reshape(48,48)\n            a.append(image_data)\n\n\nX_testing_array = np.array(a)\nprint(X_testing_array.shape)  # (size, 48, 48)\nrgb_X_test = np.repeat(X_testing_array[..., np.newaxis], 3, -1)\n# print(rgb_X_test.shape)  # (size, 48, 48, 3)\n\nprediction = model50.predict(rgb_X_test)\nmodel50.evaluate(rgb_X_test,Y_test)\n    \nresults = Expressions[np.argmax(prediction[100])]\nprint(results)\n\nimage_string = X_test50[100].split(' ') \nimage_data = np.asarray(image_string, dtype=np.uint8).reshape(48,48)\nplt.imshow(image_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, (1, 1), padding='same', activation='relu', input_shape=(48, 48, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(layers.Conv2D(128, (3, 3),padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(layers.Conv2D(256, (5, 5),padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2),padding=\"same\"))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(128))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(layers.Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(layers.Dense(7, activation='softmax'))\nmodel.summary()\n\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n# model.fit(X_train, Y_train, batch_size=64, epochs=40, steps_per_epoch=(len(X_train)/128))\n\n\nmodel.fit(X_train, Y_train, batch_size=64, epochs=40, steps_per_epoch=len(X_train)/128, validation_split = 0.25)\n\nmodel.save('CNNmodel')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Expressions = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"]\na= []\nprint (\"X_test shape: \" + str(X_test.shape))\nX_test = pd.Series(X_test.flatten())\n\na = preprocessing(X_test)\nX_testing_array = np.array(a)\n\n\nprint (\"number of Test examples = \" + str(X_testing_array.shape[0]))\nprint (\"X_test shape: \" + str(X_testing_array.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))\n\nprediction = model.predict(X_testing_array)\nmodel.evaluate(X_testing_array,Y_test)\n\nresults = Expressions[np.argmax(prediction[100])]\nprint(results)\nimage_string = X_test[100].split(' ') \nimage_data = np.asarray(image_string, dtype=np.uint8).reshape(48,48)\nplt.imshow(image_data)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}