{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-02T15:16:26.706317Z","iopub.execute_input":"2021-09-02T15:16:26.706855Z","iopub.status.idle":"2021-09-02T15:16:26.720296Z","shell.execute_reply.started":"2021-09-02T15:16:26.706804Z","shell.execute_reply":"2021-09-02T15:16:26.718975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nfrom tqdm import tqdm\nimport copy\nimport matplotlib.pyplot as plt\nimport time\nimport timeit\n\nimport torch, torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Dataset  \nfrom torch.utils.data import TensorDataset","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:26.722153Z","iopub.execute_input":"2021-09-02T15:16:26.722599Z","iopub.status.idle":"2021-09-02T15:16:26.730457Z","shell.execute_reply.started":"2021-09-02T15:16:26.722507Z","shell.execute_reply":"2021-09-02T15:16:26.729621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = {\n    \"batch_size\" : 64,\n    \"num_clients\": 2,\n    \"frac\": 1,\n    \"ep_local\": 2,\n    \"bs_local\": 10,\n    \"epochs\": 2,\n    \"dataset\": \"CIFAR10\",\n    \"model\": \"CNN\",\n    \"iid\": \"iid\",\n    \n    # Unlearning params\n    \"unlearned_clients\": [0], \n    \"t\": 2, # calibration_interval,\n    \"r\": 0.5 # local_calibration_epoch_ratio r = Ecali/Eloc\n    \n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:21:01.079648Z","iopub.execute_input":"2021-09-02T15:21:01.080283Z","iopub.status.idle":"2021-09-02T15:21:01.08649Z","shell.execute_reply.started":"2021-09-02T15:21:01.08023Z","shell.execute_reply":"2021-09-02T15:21:01.085676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'\nos.listdir(path)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:26.732606Z","iopub.execute_input":"2021-09-02T15:16:26.732915Z","iopub.status.idle":"2021-09-02T15:16:26.752568Z","shell.execute_reply.started":"2021-09-02T15:16:26.732883Z","shell.execute_reply":"2021-09-02T15:16:26.75166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(path+'icml_face_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:26.754363Z","iopub.execute_input":"2021-09-02T15:16:26.755031Z","iopub.status.idle":"2021-09-02T15:16:29.721232Z","shell.execute_reply.started":"2021-09-02T15:16:26.75498Z","shell.execute_reply":"2021-09-02T15:16:29.719898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:29.722851Z","iopub.execute_input":"2021-09-02T15:16:29.723149Z","iopub.status.idle":"2021-09-02T15:16:29.736645Z","shell.execute_reply.started":"2021-09-02T15:16:29.723121Z","shell.execute_reply":"2021-09-02T15:16:29.735116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(data):\n    \"\"\" Prepare data for modeling \n        input: data frame with labels und pixel data\n        output: image and label array \"\"\"\n    \n    image_array = np.zeros(shape=(len(data), 48, 48))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        image_array[i] = image\n        \n    return image_array, image_label","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:29.738154Z","iopub.execute_input":"2021-09-02T15:16:29.738448Z","iopub.status.idle":"2021-09-02T15:16:29.751598Z","shell.execute_reply.started":"2021-09-02T15:16:29.73842Z","shell.execute_reply":"2021-09-02T15:16:29.750407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[' Usage'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:29.753632Z","iopub.execute_input":"2021-09-02T15:16:29.754075Z","iopub.status.idle":"2021-09-02T15:16:29.783872Z","shell.execute_reply.started":"2021-09-02T15:16:29.754029Z","shell.execute_reply":"2021-09-02T15:16:29.782465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:29.785817Z","iopub.execute_input":"2021-09-02T15:16:29.786326Z","iopub.status.idle":"2021-09-02T15:16:29.795221Z","shell.execute_reply.started":"2021-09-02T15:16:29.786252Z","shell.execute_reply":"2021-09-02T15:16:29.793924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\nval_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\ntest_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:29.798139Z","iopub.execute_input":"2021-09-02T15:16:29.798523Z","iopub.status.idle":"2021-09-02T15:16:34.534772Z","shell.execute_reply.started":"2021-09-02T15:16:29.798475Z","shell.execute_reply":"2021-09-02T15:16:34.533627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(train_image_array))\ntrain_image_array.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:34.536502Z","iopub.execute_input":"2021-09-02T15:16:34.536866Z","iopub.status.idle":"2021-09-02T15:16:34.546123Z","shell.execute_reply.started":"2021-09-02T15:16:34.536832Z","shell.execute_reply":"2021-09-02T15:16:34.544548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reshape and scale\ntrain_images = train_image_array.reshape((train_image_array.shape[0], 1, 48, 48))\ntrain_images = train_images.astype('float32')/255\nval_images = val_image_array.reshape((val_image_array.shape[0], 1, 48, 48))\nval_images = val_images.astype('float32')/255\ntest_images = test_image_array.reshape((test_image_array.shape[0], 1, 48, 48))\ntest_images = test_images.astype('float32')/255","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:34.548066Z","iopub.execute_input":"2021-09-02T15:16:34.548399Z","iopub.status.idle":"2021-09-02T15:16:34.807447Z","shell.execute_reply.started":"2021-09-02T15:16:34.548369Z","shell.execute_reply":"2021-09-02T15:16:34.806073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(train_images))\ntrain_images.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:34.809225Z","iopub.execute_input":"2021-09-02T15:16:34.809747Z","iopub.status.idle":"2021-09-02T15:16:34.81917Z","shell.execute_reply.started":"2021-09-02T15:16:34.809667Z","shell.execute_reply":"2021-09-02T15:16:34.817775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = train_image_label\nval_labels = val_image_label\ntest_labels = test_image_label","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:34.820953Z","iopub.execute_input":"2021-09-02T15:16:34.821294Z","iopub.status.idle":"2021-09-02T15:16:34.829982Z","shell.execute_reply.started":"2021-09-02T15:16:34.821265Z","shell.execute_reply":"2021-09-02T15:16:34.828713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert to tensor\ntrain_images = torch.from_numpy(train_images)\ntrain_labels = torch.from_numpy(train_labels)\nval_images = torch.from_numpy(val_images)\nval_labels = torch.from_numpy(val_labels)\ntest_images = torch.from_numpy(test_images)\ntest_labels = torch.from_numpy(test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:34.831243Z","iopub.execute_input":"2021-09-02T15:16:34.831635Z","iopub.status.idle":"2021-09-02T15:16:34.844805Z","shell.execute_reply.started":"2021-09-02T15:16:34.8316Z","shell.execute_reply":"2021-09-02T15:16:34.843328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(train_labels)\ntrain_labels[1]","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:34.84648Z","iopub.execute_input":"2021-09-02T15:16:34.846889Z","iopub.status.idle":"2021-09-02T15:16:34.862147Z","shell.execute_reply.started":"2021-09-02T15:16:34.846855Z","shell.execute_reply":"2021-09-02T15:16:34.860756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to dataset\ndataset_train = TensorDataset(train_images, train_labels)\ndataset_val = TensorDataset(val_images, val_labels)\ndataset_test = TensorDataset(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:34.864184Z","iopub.execute_input":"2021-09-02T15:16:34.864587Z","iopub.status.idle":"2021-09-02T15:16:34.873632Z","shell.execute_reply.started":"2021-09-02T15:16:34.864551Z","shell.execute_reply":"2021-09-02T15:16:34.872101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(dataset_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:16:44.797856Z","iopub.execute_input":"2021-09-02T15:16:44.798268Z","iopub.status.idle":"2021-09-02T15:16:44.805338Z","shell.execute_reply.started":"2021-09-02T15:16:44.798232Z","shell.execute_reply":"2021-09-02T15:16:44.804337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=args[\"batch_size\"], shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=args[\"batch_size\"], shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset_val, batch_size=args[\"batch_size\"], shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:18:18.427328Z","iopub.execute_input":"2021-09-02T15:18:18.427704Z","iopub.status.idle":"2021-09-02T15:18:18.433401Z","shell.execute_reply.started":"2021-09-02T15:18:18.427673Z","shell.execute_reply":"2021-09-02T15:18:18.43231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in val_loader:\n    print(x.shape, y.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:18:31.317734Z","iopub.execute_input":"2021-09-02T15:18:31.318138Z","iopub.status.idle":"2021-09-02T15:18:31.353098Z","shell.execute_reply.started":"2021-09-02T15:18:31.318105Z","shell.execute_reply":"2021-09-02T15:18:31.35179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.fc1 = nn.Linear(64*10*10, 64)\n        self.fc2 = nn.Linear(64, 7)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:18:49.621007Z","iopub.execute_input":"2021-09-02T15:18:49.621393Z","iopub.status.idle":"2021-09-02T15:18:49.631901Z","shell.execute_reply.started":"2021-09-02T15:18:49.621363Z","shell.execute_reply":"2021-09-02T15:18:49.630165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for images, y in val_loader:\n    print(x.shape, y.shape)\n    break\nconv1 = nn.Conv2d(1, 32, 3)\nconv2 = nn.Conv2d(32, 64, 3)\npool = nn.MaxPool2d(2, 2)\nprint(images.shape)\nx = conv1(images)\nprint(x.shape)\nx = pool(x)\nx = conv2(x)\nprint(x.shape)\nx = pool(x)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:21:28.14854Z","iopub.execute_input":"2021-09-02T15:21:28.149151Z","iopub.status.idle":"2021-09-02T15:21:28.214197Z","shell.execute_reply.started":"2021-09-02T15:21:28.149102Z","shell.execute_reply":"2021-09-02T15:21:28.213097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetSplit(Dataset):\n    def __init__(self, dataset_train, idxs):\n        self.dataset_train = dataset_train\n        self.idxs = list(idxs)\n\n    def __len__(self):\n        return len(self.idxs)\n\n    def __getitem__(self, item):\n        image, label = self.dataset_train[self.idxs[item]]\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:21:32.627936Z","iopub.execute_input":"2021-09-02T15:21:32.62858Z","iopub.status.idle":"2021-09-02T15:21:32.634641Z","shell.execute_reply.started":"2021-09-02T15:21:32.628509Z","shell.execute_reply":"2021-09-02T15:21:32.633658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribute data - IID\nnum_items = int(len(dataset_train)/args[\"num_clients\"])\ndict_users, all_idxs = {}, [i for i in range(len(dataset_train))]\nfor i in range(args[\"num_clients\"]):\n    dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n    all_idxs = list(set(all_idxs) - dict_users[i])\n\nlocal_datasets = []\nfor i in range(args[\"num_clients\"]):\n    local_datasets.append(DataLoader(DatasetSplit(dataset_train, dict_users[i]),\n                                 batch_size=args[\"bs_local\"], shuffle=True))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:22:45.902566Z","iopub.execute_input":"2021-09-02T15:22:45.903151Z","iopub.status.idle":"2021-09-02T15:22:45.948979Z","shell.execute_reply.started":"2021-09-02T15:22:45.903103Z","shell.execute_reply":"2021-09-02T15:22:45.948142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(local_datasets[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:24:12.992412Z","iopub.execute_input":"2021-09-02T15:24:12.993073Z","iopub.status.idle":"2021-09-02T15:24:13.000427Z","shell.execute_reply.started":"2021-09-02T15:24:12.993036Z","shell.execute_reply":"2021-09-02T15:24:12.999123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Client:\n    num_clients = 0\n    def __init__(self, data):\n        self.id = Client.num_clients\n        self.dataloader = data\n        self.__model = None\n        self.model_record = []\n        self.device = device\n        self.unlearned = False\n        Client.num_clients += 1\n        \n        \n    def setup(self, args):\n        self.local_epoch = args[\"ep_local\"]\n        \n        \n    @property\n    def unlearned(self):\n        return self.__unlearned\n    \n    \n    @unlearned.setter\n    def unlearned(self, unlearned):\n        self.__unlearned = unlearned\n        \n        \n    @property\n    def model(self):\n        return self.__model\n    \n    \n    @model.setter\n    def model(self, model):\n        self.__model = model\n        \n        \n    def client_update(self):\n        self.model.train()\n        self.model.to(self.device)\n\n        optimizer = optim.SGD(self.model.parameters(), lr=0.01)\n        epoch_loss = []\n        \n        for epoch in range(self.local_epoch):\n            batch_loss = []\n            \n            for batch_idx, (data, labels) in enumerate(self.dataloader):\n                data, labels = data.to(self.device), labels.long().to(self.device)\n                 \n                self.model.zero_grad()\n                outputs = self.model(data)\n                loss = F.nll_loss(outputs, labels)\n\n                loss.backward()\n                optimizer.step() \n\n                batch_loss.append(loss.item())\n            \n            #print(f\"Train Epoch: {epoch} \\tLoss: {loss.item():.6f}\")\n            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n\n        #return self.model.state_dict(), sum(epoch_loss) / len(epoch_loss)\n        return self.model, sum(epoch_loss) / len(epoch_loss)\n    \n    \n    def client_test(self):\n        self.model.eval()\n        self.model.to(self.device)\n        test_loss, correct = 0, 0\n        with torch.no_grad():\n            for data, labels in self.dataloader:\n                data, labels = data.to(self.device), labels.to(self.device)\n                outputs = self.model(data)\n                test_loss += F.nll_loss(outputs, labels, reduction='sum').item()\n                predicted = outputs.argmax(dim=1, keepdim=True)\n                correct += predicted.eq(labels.data.view_as(predicted)).long().cpu().sum()\n\n\n        test_loss /= len(self.dataloader.dataset)\n        test_accuracy = correct / len(self.dataloader.dataset)\n\n        print(f\"Average loss: {test_loss:.4f}, Accuracy: {100. * test_accuracy:.2f}%\")\n\n        return test_accuracy, test_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:24:38.067222Z","iopub.execute_input":"2021-09-02T15:24:38.067792Z","iopub.status.idle":"2021-09-02T15:24:38.094237Z","shell.execute_reply.started":"2021-09-02T15:24:38.067755Z","shell.execute_reply":"2021-09-02T15:24:38.092915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Server:\n    def __init__(self):\n        self.round = 0\n        self.model = Net().to(device)\n        self.w_glob = None\n        self.device = device\n        \n        self.history = {\n            \"train_loss\": [], \n            \"test_loss\": [], \n            \"train_acc\": [],\n            \"test_acc\": []\n        }\n        \n        \n    def setup(self, args):\n        self.train_loader = train_loader\n        self.test_loader = test_loader\n        \n        self.num_clients = args[\"num_clients\"]\n        self.num_rounds = args[\"epochs\"]\n        self.local_epochs = args[\"ep_local\"]\n        self.batch_size = args[\"batch_size\"]\n        self.clients = args[\"clients\"]\n        self.unlearned_clients = args[\"unlearned_clients\"]\n        \n        self.local_model_record = [[] for i in range(self.num_clients)]\n        self.global_model_record = []\n        \n        \n    def fedAvg(self, w):\n        w_avg = copy.deepcopy(w[0])\n        for k in w_avg.keys():\n            for i in range(1, len(w)):\n                w_avg[k] += w[i][k]\n            w_avg[k] = torch.div(w_avg[k], len(w))\n        self.model\n        return w_avg\n    \n    \n    def send_global_model(self):\n        for client in self.clients:\n            #client.w_local = copy.deepcopy(self.w_glob)\n            client.model = copy.deepcopy(self.model)\n            client.model_record.append(client.model)\n        \n        \n    def train_global_model(self):\n        w_locals = [self.w_glob for i in range(self.num_clients)]\n        loss_locals = [0 for i in range(self.num_clients)]\n        \n        # Send global model to clients\n        self.send_global_model()\n        print(\"Send global model to all clients...\")\n        \n        # Train local model\n        acc_test_clients, loss_test_clients = [], []\n        for id, client in enumerate(self.clients):\n            print(f\"\\nUpdating client {id}...\")\n            local_model, loss_train_client = client.client_update()\n            \n            # Save local models\n            self.local_model_record[id].append(local_model)\n            w_locals.append(local_model.state_dict())\n            #print(w_locals)\n            loss_locals.append(loss_train_client)\n            \n            print(f\"Evaluating client {id}...\")\n            acc_test_client, loss_test_client = client.client_test()\n            acc_test_clients.append(acc_test_client)\n            loss_test_clients.append(loss_test_client)\n            \n            \n        # Fed Aggregation\n        w_glob = self.fedAvg(w_locals)\n            \n        # Update global model\n        self.model.load_state_dict(w_glob)\n            \n        return acc_test_clients, loss_locals\n    \n    \n    def federated_learning(self):\n        self.model.train()\n        self.w_glob = self.model.state_dict()\n        \n        print(\"\\tFederated Learning:\")\n        for round in tqdm(range(self.num_rounds)):\n            self.round = round + 1\n            print(f\"\\nRound {self.round}/{self.num_rounds}: Starting...\")\n            acc_train_clients, loss_train_clients = self.train_global_model()\n            self.history[\"train_acc\"].append(100*sum(acc_train_clients)/len(acc_train_clients))\n            self.history[\"train_loss\"].append(sum(loss_train_clients)/len(loss_train_clients))\n            \n            print(f\"\\nRound {self.round}: Evaluating...\")\n            # Save test accuracy and loss\n            acc_test_server, loss_test_server = self.test_global_model()\n            self.history[\"test_acc\"].append(acc_test_server)\n            self.history[\"test_loss\"].append(loss_test_server)\n            \n            print(f\"|---- Average Clients Loss: {sum(loss_train_clients) / len(loss_train_clients)}\")\n            print(f\"|---- Average Clients Accuracy: {100*sum(acc_train_clients)/len(acc_train_clients):.2f}%\")\n            print(f\"|---- Server Testing Accuracy: {acc_test_server:.2f}%\")\n            \n            print(f\"\\nRound {self.round}: Finished!\\n\")\n            print(f\"---------------------------------\")\n            \n        self.show_result()\n        self.plot(self.history)\n        \n        \n    def show_result(self):\n        # Testing data\n        acc_test_server, loss_test_server = self.test_global_model()\n        print(f' \\n Results after {self.num_rounds} global rounds of training:')\n        print(f\"|---- Testing Accuracy: {acc_test_server:.2f}%\")\n\n        # Unlearned client\n        print(f\"\\nUnlearned Clients:\")\n        for i in self.unlearned_clients:\n            acc_test, loss_test = self.clients[i].client_test()\n            print(f\"|---- Unlearned Client - {i} Accuracy: {100*acc_test:.2f}%\")\n            \n            \n    def plot(self, history):\n        fig, axs = plt.subplots(2, 1)\n        axs[0].plot(history[\"train_loss\"], color=\"b\", label=\"Training Loss\")\n        axs[0].plot(history[\"test_loss\"], color='r', label=\"Testing Loss\")\n        legend = axs[0].legend(loc=\"best\", shadow=True)\n        axs[0].set_xlabel(\"Communication Rounds\")\n        axs[0].set_ylabel(\"Loss\")\n        \n        axs[1].plot(history[\"train_acc\"], color=\"b\", label=\"Training Accuracy\")\n        axs[1].plot(history[\"test_acc\"], color='r', label=\"Testing Accuracy\")\n        legend = axs[1].legend(loc=\"best\", shadow=True)\n        axs[1].set_xlabel(\"Communication Rounds\")\n        axs[1].set_ylabel(\"Accuracy\")\n        \n        \n    def test_global_model(self):\n        self.model.eval()\n        \n        test_loss = 0\n        correct = 0\n        with torch.no_grad():\n            for data, labels in self.test_loader:\n                data, labels = data.to(self.device), labels.to(self.device)\n                output = self.model(data)\n                test_loss += F.nll_loss(output, labels, reduction='sum').item()  \n                pred = output.argmax(dim=1, keepdim=True)  \n                #correct += pred.eq(target.view_as(pred)).sum().item()\n                correct += pred.eq(labels.data.view_as(pred)).long().cpu().sum()\n\n\n        test_loss /= len(self.test_loader.dataset)\n        accuracy = 100. * correct / len(self.test_loader.dataset)\n\n        print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({ 100. * correct / len(test_loader.dataset):.2f}%)\\n')\n\n        return accuracy, test_loss\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:25:04.021263Z","iopub.execute_input":"2021-09-02T15:25:04.021929Z","iopub.status.idle":"2021-09-02T15:25:04.056709Z","shell.execute_reply.started":"2021-09-02T15:25:04.021874Z","shell.execute_reply":"2021-09-02T15:25:04.055184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create clients and distribute the dataset \n# All clients are stored in list clients\nargs[\"clients\"] = []\nfor i in range(args[\"num_clients\"]):\n    client = Client(local_datasets[i])\n    client.setup(args)\n    args[\"clients\"].append(client)\n    \nfor unlearned in args[\"unlearned_clients\"]:\n    args[\"clients\"][unlearned].unlearned = True","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:25:05.973464Z","iopub.execute_input":"2021-09-02T15:25:05.973897Z","iopub.status.idle":"2021-09-02T15:25:05.980991Z","shell.execute_reply.started":"2021-09-02T15:25:05.973861Z","shell.execute_reply":"2021-09-02T15:25:05.979428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a server\nserver = Server()\nserver.setup(args)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:25:15.023976Z","iopub.execute_input":"2021-09-02T15:25:15.024348Z","iopub.status.idle":"2021-09-02T15:25:15.040815Z","shell.execute_reply.started":"2021-09-02T15:25:15.024317Z","shell.execute_reply":"2021-09-02T15:25:15.039396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"server.federated_learning()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:25:21.560268Z","iopub.execute_input":"2021-09-02T15:25:21.560718Z","iopub.status.idle":"2021-09-02T15:29:29.867293Z","shell.execute_reply.started":"2021-09-02T15:25:21.560683Z","shell.execute_reply":"2021-09-02T15:29:29.865998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}