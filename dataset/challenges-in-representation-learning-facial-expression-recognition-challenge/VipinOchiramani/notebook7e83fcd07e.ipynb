{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom keras import models\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'\ndata=pd.read_csv(path+'icml_face_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[' Usage'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['emotion'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotions={0:'Angry' , 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise',6: 'Neutral'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(data):\n    \"\"\" Prepare data for modeling \n        input: data frame with labels und pixel data\n        output: image and label array \"\"\"\n    \n    image_array = np.zeros(shape=(len(data), 48, 48))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        image_array[i] = image\n        \n    return image_array, image_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\nval_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\ntest_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\ntrain_images = train_images.astype('float32')/255\nval_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\nval_images = val_images.astype('float32')/255\ntest_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\ntest_images = test_images.astype('float32')/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = to_categorical(train_image_label)\nval_labels = to_categorical(val_image_label)\ntest_labels = to_categorical(test_image_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_examples(label=0):\n    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(5):\n        idx = data[data['emotion']==label].index[i]\n        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n        axs[i].set_title(emotions[train_labels[idx].argmax()])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n        \ndef plot_all_emotions():\n    fig, axs = plt.subplots(1, 7, figsize=(80, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(7):\n        idx = data[data['emotion']==i].index[i]\n        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n        axs[i].set_title(emotions[train_labels[idx].argmax()])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, image_number):\n    \"\"\" Function to plot the image and compare the prediction results with the label \"\"\"\n    \n    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n    \n    bar_label = emotions.values()\n    \n    axs[0].imshow(test_image_array[image_number], 'gray')\n    axs[0].set_title(emotions[test_image_label[image_number]])\n    \n    axs[1].bar(bar_label, pred_test_labels[image_number])\n    axs[1].grid()\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_compare_distributions(array1, array2, title1='', title2=''):\n    df_array1 = pd.DataFrame()\n    df_array2 = pd.DataFrame()\n    df_array1['emotion'] = array1.argmax(axis=1)\n    df_array2['emotion'] = array2.argmax(axis=1)\n    \n    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n    x = emotions.values()\n    \n    y = df_array1['emotion'].value_counts()\n    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n    for key_missed in keys_missed:\n        y[key_missed] = 0\n    axs[0].bar(x, y.sort_index())\n    axs[0].set_title(title1)\n    axs[0].grid()\n    \n    y = df_array2['emotion'].value_counts()\n    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n    for key_missed in keys_missed:\n        y[key_missed] = 0\n    axs[1].bar(x, y.sort_index())\n    axs[1].set_title(title2)\n    axs[1].grid()\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_all_emotions()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_examples(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_compare_distributions(train_labels, val_labels, title1='train labels', title2='val labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = dict(zip(range(0, 7), (((data[data[' Usage']=='Training']['emotion'].value_counts()).sort_index())/len(data[data[' Usage']=='Training']['emotion'])).tolist()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#model=models.Sequential()\n#model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\",input_shape=(48, 48, 1)))\n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Conv2D(128, (5, 5), padding=\"same\", activation=\"relu\"))\n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n#model.add(Flatten())\n#model.add(Dense(64, activation='relu'))\n#model.add(Dense(7, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=models.Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 256, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(7, activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_images, train_labels,\n                    validation_data=(val_images, val_labels),\n                    class_weight = class_weight,\n                    epochs=30,\n                    batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_images, test_labels)\nprint('test caccuracy:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_labels = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, loss, 'bo', label='loss_train')\nplt.plot(epochs, loss_val, 'b', label='loss_val')\nplt.title('value of the loss function')\nplt.xlabel('epochs')\nplt.ylabel('value of the loss function')\nplt.legend()\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nacc_val = history.history['val_accuracy']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, acc, 'bo', label='accuracy_train')\nplt.plot(epochs, acc_val, 'b', label='accuracy_val')\nplt.title('accuracy')\nplt.xlabel('epochs')\nplt.ylabel('value of accuracy')\nplt.legend()\nplt.grid()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, 106)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, 69)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_compare_distributions(test_labels, pred_test_labels, title1='test labels', title2='predict labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_compare = pd.DataFrame()\ndf_compare['real'] = test_labels.argmax(axis=1)\ndf_compare['pred'] = pred_test_labels.argmax(axis=1)\ndf_compare['wrong'] = np.where(df_compare['real']!=df_compare['pred'], 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_mat = confusion_matrix(test_labels.argmax(axis=1), pred_test_labels.argmax(axis=1))\n\nfig, ax = plot_confusion_matrix(conf_mat=conf_mat,\n                                show_normed=True,\n                                show_absolute=False,\n                                class_names=emotions.values(),\n                                figsize=(8, 8))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(path+'example_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_output=pd.read_csv(path+'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_output_image_array = np.zeros(shape=(len(test_data_output), 48, 48))\n\n    \nfor i, row in enumerate(test_data_output.index):\n    image = np.fromstring(test_data_output.loc[row, 'pixels'], dtype=int, sep=' ')\n    image = np.reshape(image, (48, 48))\n    test_output_image_array[i] = image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_output_image = test_output_image_array.reshape((test_output_image_array.shape[0], 48, 48, 1))\ntest_output_image = test_output_image.astype('float32')/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_output_image_array.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict results\nresults = model.predict(test_output_image)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"3\")\n\n\nresults.to_csv(\"challenges-in-representation-learning-facial-expression-recognition-challenge_submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}