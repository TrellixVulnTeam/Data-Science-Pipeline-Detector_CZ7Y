{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-24T06:05:51.835042Z","iopub.execute_input":"2021-07-24T06:05:51.835411Z","iopub.status.idle":"2021-07-24T06:05:51.854631Z","shell.execute_reply.started":"2021-07-24T06:05:51.835337Z","shell.execute_reply":"2021-07-24T06:05:51.853185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.models import Sequential\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:05:51.856822Z","iopub.execute_input":"2021-07-24T06:05:51.857113Z","iopub.status.idle":"2021-07-24T06:05:56.297614Z","shell.execute_reply.started":"2021-07-24T06:05:51.857089Z","shell.execute_reply":"2021-07-24T06:05:56.296739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'\nos.listdir(path)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:05:56.299581Z","iopub.execute_input":"2021-07-24T06:05:56.299921Z","iopub.status.idle":"2021-07-24T06:05:56.310542Z","shell.execute_reply.started":"2021-07-24T06:05:56.299886Z","shell.execute_reply":"2021-07-24T06:05:56.309745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndata = pd.read_csv(path+'icml_face_data.csv')\ndata\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:05:56.313319Z","iopub.execute_input":"2021-07-24T06:05:56.313555Z","iopub.status.idle":"2021-07-24T06:06:01.199533Z","shell.execute_reply.started":"2021-07-24T06:05:56.313532Z","shell.execute_reply":"2021-07-24T06:06:01.19864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:01.200896Z","iopub.execute_input":"2021-07-24T06:06:01.201307Z","iopub.status.idle":"2021-07-24T06:06:01.205987Z","shell.execute_reply.started":"2021-07-24T06:06:01.201265Z","shell.execute_reply":"2021-07-24T06:06:01.205157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(data = data[data[' Usage']=='Training'], x='emotion', ax=ax1).set_title('Training')\nax1.set_xticklabels(emotions.values())\nsns.countplot(data = data[data[' Usage']=='PublicTest'], x='emotion', ax=ax2).set_title('Testing')\nax2.set_xticklabels(emotions.values())\nsns.countplot(data = data[data[' Usage']=='PrivateTest'], x='emotion', ax=ax3).set_title('Validation')\nax3.set_xticklabels(emotions.values())","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:01.207274Z","iopub.execute_input":"2021-07-24T06:06:01.207878Z","iopub.status.idle":"2021-07-24T06:06:01.712265Z","shell.execute_reply.started":"2021-07-24T06:06:01.207836Z","shell.execute_reply":"2021-07-24T06:06:01.711263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(data):\n    \"\"\" Prepare data for modeling \n        input: data frame with labels und pixel data\n        output: image and label array \"\"\"\n    \n    image_array = np.zeros(shape=(len(data), 48, 48))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        image_array[i] = image\n        \n    return image_array, image_label\n\n  \ndef sample_plot(x,y=None):\n    #x, y are numpy arrays\n    n = 20\n    samples = random.sample(range(x.shape[0]),n)\n    \n    fig, axs = plt.subplots(2,10, figsize=(25,5), sharex=True, sharey=True)\n    ax = axs.ravel()\n    for i in range(n):\n        ax[i].imshow(x[samples[i],:,:], cmap=plt.get_cmap('gray'))\n        ax[i].set_xticks([])\n        ax[i].set_yticks([])\n        if y is not None:\n            ax[i].set_title(emotions[y[samples[i]]])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:01.713745Z","iopub.execute_input":"2021-07-24T06:06:01.71412Z","iopub.status.idle":"2021-07-24T06:06:01.724531Z","shell.execute_reply.started":"2021-07-24T06:06:01.714073Z","shell.execute_reply":"2021-07-24T06:06:01.72363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\nval_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\ntest_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:01.727306Z","iopub.execute_input":"2021-07-24T06:06:01.727655Z","iopub.status.idle":"2021-07-24T06:06:06.388732Z","shell.execute_reply.started":"2021-07-24T06:06:01.727616Z","shell.execute_reply":"2021-07-24T06:06:06.387834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\ntrain_images = train_images.astype('float32')/255\nval_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\nval_images = val_images.astype('float32')/255\ntest_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\ntest_images = test_images.astype('float32')/255","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:06.390944Z","iopub.execute_input":"2021-07-24T06:06:06.391316Z","iopub.status.idle":"2021-07-24T06:06:06.56289Z","shell.execute_reply.started":"2021-07-24T06:06:06.391279Z","shell.execute_reply":"2021-07-24T06:06:06.561953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[' Usage'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:06.56435Z","iopub.execute_input":"2021-07-24T06:06:06.564784Z","iopub.status.idle":"2021-07-24T06:06:06.582023Z","shell.execute_reply.started":"2021-07-24T06:06:06.56474Z","shell.execute_reply":"2021-07-24T06:06:06.580999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = to_categorical(train_image_label)\nval_labels = to_categorical(val_image_label)\ntest_labels = to_categorical(test_image_label)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:06.583462Z","iopub.execute_input":"2021-07-24T06:06:06.583819Z","iopub.status.idle":"2021-07-24T06:06:06.59139Z","shell.execute_reply.started":"2021-07-24T06:06:06.583782Z","shell.execute_reply":"2021-07-24T06:06:06.590425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_all_emotions():\n    fig, axs = plt.subplots(1, 7, figsize=(30, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(7):\n        idx = data[data['emotion']==i].index[i]\n        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n        axs[i].set_title(emotions[train_labels[idx].argmax()])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:06.592668Z","iopub.execute_input":"2021-07-24T06:06:06.593161Z","iopub.status.idle":"2021-07-24T06:06:06.601374Z","shell.execute_reply.started":"2021-07-24T06:06:06.593127Z","shell.execute_reply":"2021-07-24T06:06:06.600545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_all_emotions()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:06.602867Z","iopub.execute_input":"2021-07-24T06:06:06.603512Z","iopub.status.idle":"2021-07-24T06:06:07.913592Z","shell.execute_reply.started":"2021-07-24T06:06:06.603474Z","shell.execute_reply":"2021-07-24T06:06:07.912657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convolutional Neural Network (CNN)\n\n# Se crea un modelo secuencial y se agregan capas a la red neuronal\n\nfrom keras import models\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n\nmodel = models.Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(7, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:07.915026Z","iopub.execute_input":"2021-07-24T06:06:07.915738Z","iopub.status.idle":"2021-07-24T06:06:09.789334Z","shell.execute_reply.started":"2021-07-24T06:06:07.915692Z","shell.execute_reply":"2021-07-24T06:06:09.788394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:09.790599Z","iopub.execute_input":"2021-07-24T06:06:09.791001Z","iopub.status.idle":"2021-07-24T06:06:09.808272Z","shell.execute_reply.started":"2021-07-24T06:06:09.790925Z","shell.execute_reply":"2021-07-24T06:06:09.807533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#50 epochs\n\nhistory = model.fit(train_images, train_labels,\n                    validation_data=(test_images, test_labels),  epochs=50, batch_size=32)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:06:09.809523Z","iopub.execute_input":"2021-07-24T06:06:09.810124Z","iopub.status.idle":"2021-07-24T06:09:22.625397Z","shell.execute_reply.started":"2021-07-24T06:06:09.810076Z","shell.execute_reply":"2021-07-24T06:09:22.624468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test_labels = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:09:22.627145Z","iopub.execute_input":"2021-07-24T06:09:22.627552Z","iopub.status.idle":"2021-07-24T06:09:22.903845Z","shell.execute_reply.started":"2021-07-24T06:09:22.627507Z","shell.execute_reply":"2021-07-24T06:09:22.902819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image \nimport PIL \nfrom six.moves import urllib\n\nurllib.request.urlretrieve(\"https://imgc.artprintimages.com/img/print/the-godfather-marlon-brando-1972_u-l-q12pfjf0.jpg?h=550&p=0&w=550\", \"godfather.png\")\nurllib.request.urlretrieve(\"https://www.pilotonline.com/resizer/s81d-dFjGylRCkOBJJmMPuA8_s0=/415x560/top/arc-anglerfish-arc2-prod-tronc.s3.amazonaws.com/public/HNMTBLBEZNFAZOOPRLZWMI6CMY.jpg\", \"bob.png\")\nurllib.request.urlretrieve(\"https://pbs.twimg.com/profile_images/1140172161602195457/czwGGE5y.png\", \"bready.png\")\n\nimg = PIL.Image.open(\"godfather.png\")\n\nimg","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:01.332569Z","iopub.execute_input":"2021-07-24T06:25:01.332975Z","iopub.status.idle":"2021-07-24T06:25:02.561753Z","shell.execute_reply.started":"2021-07-24T06:25:01.332925Z","shell.execute_reply":"2021-07-24T06:25:02.560912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import image\nimport cv2\nimport os\n\n#\"/data/haarcascades/haarcascade_frontalface_default.xml\"\n\nface_haar_cascade = cv2.CascadeClassifier(\"/content/haarcascade_frontalface_default.xml\")","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:03.617011Z","iopub.execute_input":"2021-07-24T06:25:03.617323Z","iopub.status.idle":"2021-07-24T06:25:03.62157Z","shell.execute_reply.started":"2021-07-24T06:25:03.617296Z","shell.execute_reply":"2021-07-24T06:25:03.620742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab.patches import cv2_imshow\n\ntest_image1 = cv2.imread('/kaggle/working/godfather.png')\ntest_image2 = cv2.imread('/kaggle/working/bob.png')\ntest_image3 = cv2.imread('/kaggle/working/bready.png')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:03.994473Z","iopub.execute_input":"2021-07-24T06:25:03.99479Z","iopub.status.idle":"2021-07-24T06:25:04.017096Z","shell.execute_reply.started":"2021-07-24T06:25:03.994762Z","shell.execute_reply":"2021-07-24T06:25:04.016224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gray_image1 = cv2.cvtColor(test_image1, cv2.COLOR_BGR2GRAY)\ngray_image2 = cv2.cvtColor(test_image2, cv2.COLOR_BGR2GRAY)\ngray_image3 = cv2.cvtColor(test_image3, cv2.COLOR_BGR2GRAY)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:04.221986Z","iopub.execute_input":"2021-07-24T06:25:04.222337Z","iopub.status.idle":"2021-07-24T06:25:04.23059Z","shell.execute_reply.started":"2021-07-24T06:25:04.222308Z","shell.execute_reply":"2021-07-24T06:25:04.229897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\nfrom keras.preprocessing.image import img_to_array","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:04.399133Z","iopub.execute_input":"2021-07-24T06:25:04.399476Z","iopub.status.idle":"2021-07-24T06:25:04.433613Z","shell.execute_reply.started":"2021-07-24T06:25:04.399445Z","shell.execute_reply":"2021-07-24T06:25:04.432723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"faces = face_cascade.detectMultiScale(gray_image1,1.1,4)\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(test_image1,(x,y),(x+w,y+h),(255,0,0))\n    roi_gray = gray_image1[y:y+w,x:x+h]\n    roi_gray =cv2.resize(roi_gray,(48,48))\n    image_pixels = img_to_array(roi_gray)\n    image_pixels = np.expand_dims(image_pixels, axis = 0)\n    image_pixels /= 255\n    predictions = model.predict(image_pixels)\n    max_index = np.argmax(predictions[0])\n    emotion_detection = ( 'Angry','Disgust','Fear','Happy', 'Sad','Surprise', 'Neutral')\n    emotion_prediction = emotion_detection[max_index]\n    print(emotion_prediction)\n    \n    font =cv2.FONT_HERSHEY_SIMPLEX\n    org = (50,50)\n    fontScale = 1\n    color = (0, 253, 0)\n    thickness = 2\n    image = cv2.putText(test_image1,emotion_prediction, org, font, \n                        fontScale, color, thickness, cv2.LINE_AA)\n    cv2_imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:04.535307Z","iopub.execute_input":"2021-07-24T06:25:04.535614Z","iopub.status.idle":"2021-07-24T06:25:04.757444Z","shell.execute_reply.started":"2021-07-24T06:25:04.535585Z","shell.execute_reply":"2021-07-24T06:25:04.756639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"faces = face_cascade.detectMultiScale(gray_image2,1.1,4)\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(test_image2,(x,y),(x+w,y+h),(255,0,0))\n    roi_gray = gray_image2[y:y+w,x:x+h]\n    roi_gray =cv2.resize(roi_gray,(48,48))\n    image_pixels = img_to_array(roi_gray)\n    image_pixels = np.expand_dims(image_pixels, axis = 0)\n    image_pixels /= 255\n    predictions = model.predict(image_pixels)\n    max_index = np.argmax(predictions[0])\n    emotion_detection = ( 'Angry','Disgust','Fear','Happy', 'Sad','Surprise', 'Neutral')\n    emotion_prediction = emotion_detection[max_index]\n    print(emotion_prediction)\n    \n    font =cv2.FONT_HERSHEY_SIMPLEX\n    org = (50,50)\n    fontScale = 1\n    color = (0, 253, 0)\n    thickness = 2\n    image = cv2.putText(test_image2,emotion_prediction, org, font, \n                        fontScale, color, thickness, cv2.LINE_AA)\n    cv2_imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:04.793727Z","iopub.execute_input":"2021-07-24T06:25:04.794014Z","iopub.status.idle":"2021-07-24T06:25:05.004684Z","shell.execute_reply.started":"2021-07-24T06:25:04.793987Z","shell.execute_reply":"2021-07-24T06:25:05.003862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"faces = face_cascade.detectMultiScale(gray_image3,1.1,4)\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(test_image3,(x,y),(x+w,y+h),(255,0,0))\n    roi_gray = gray_image3[y:y+w,x:x+h]\n    roi_gray =cv2.resize(roi_gray,(48,48))\n    image_pixels = img_to_array(roi_gray)\n    image_pixels = np.expand_dims(image_pixels, axis = 0)\n    image_pixels /= 255\n    predictions = model.predict(image_pixels)\n    max_index = np.argmax(predictions[0])\n    emotion_detection = ( 'Angry','Disgust','Fear','Happy', 'Sad','Surprise', 'Neutral')\n    emotion_prediction = emotion_detection[max_index]\n    print(emotion_prediction)\n    \n    font =cv2.FONT_HERSHEY_SIMPLEX\n    org = (50,50)\n    fontScale = 1\n    color = (0, 253, 0)\n    thickness = 2\n    image = cv2.putText(test_image3,emotion_prediction, org, font, \n                        fontScale, color, thickness, cv2.LINE_AA)\n    cv2_imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:06.059552Z","iopub.execute_input":"2021-07-24T06:25:06.059859Z","iopub.status.idle":"2021-07-24T06:25:06.314775Z","shell.execute_reply.started":"2021-07-24T06:25:06.059832Z","shell.execute_reply":"2021-07-24T06:25:06.313848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nconf_mat = confusion_matrix(test_labels.argmax(axis=1), pred_test_labels.argmax(axis=1))\n\nfig, ax = plot_confusion_matrix(conf_mat=conf_mat,\n                                show_normed=True,\n                                show_absolute=False,\n                                class_names=emotions.values(),\n                                figsize=(8, 8))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:25:27.370906Z","iopub.execute_input":"2021-07-24T06:25:27.371303Z","iopub.status.idle":"2021-07-24T06:25:27.772168Z","shell.execute_reply.started":"2021-07-24T06:25:27.37127Z","shell.execute_reply":"2021-07-24T06:25:27.771064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install google-colab","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:09:37.380105Z","iopub.execute_input":"2021-07-24T06:09:37.380422Z","iopub.status.idle":"2021-07-24T06:10:19.54357Z","shell.execute_reply.started":"2021-07-24T06:09:37.380392Z","shell.execute_reply":"2021-07-24T06:10:19.542581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}