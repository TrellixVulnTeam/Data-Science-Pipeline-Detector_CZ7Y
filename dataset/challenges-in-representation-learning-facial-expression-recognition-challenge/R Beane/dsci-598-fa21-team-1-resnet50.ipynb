{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Facial Expression Recognition Training Notebook**\n## **Week 6**\n### Sara Manrriquez","metadata":{}},{"cell_type":"markdown","source":"In this notebook we will explore the effects of the pretrained model ResNet50 on the facial expression recognition data. ResNet50 is a transfer learning model that was trained on ImageNet, a large dataset of annotated photographs. The benefits of ResNet50 include accelerated training and help with the vanishing gradient problem.","metadata":{}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"markdown","source":"We import all necessary packages.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:32.661874Z","iopub.execute_input":"2021-11-28T16:57:32.662201Z","iopub.status.idle":"2021-11-28T16:57:32.669391Z","shell.execute_reply.started":"2021-11-28T16:57:32.66216Z","shell.execute_reply":"2021-11-28T16:57:32.668256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Training DataFrame","metadata":{}},{"cell_type":"markdown","source":"We load the training data and view the first 5 rows.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv')\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:32.671388Z","iopub.execute_input":"2021-11-28T16:57:32.671965Z","iopub.status.idle":"2021-11-28T16:57:34.714976Z","shell.execute_reply.started":"2021-11-28T16:57:32.671923Z","shell.execute_reply":"2021-11-28T16:57:34.714108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:34.716908Z","iopub.execute_input":"2021-11-28T16:57:34.71739Z","iopub.status.idle":"2021-11-28T16:57:34.728151Z","shell.execute_reply.started":"2021-11-28T16:57:34.717351Z","shell.execute_reply":"2021-11-28T16:57:34.727188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Data","metadata":{}},{"cell_type":"markdown","source":"The images for this training set are stored as a string. In order to train the model and visualize the images we need to process these strings into a 4D array of pixel values.","metadata":{}},{"cell_type":"code","source":"train['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48) for x in train['pixels']]","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:34.729668Z","iopub.execute_input":"2021-11-28T16:57:34.729963Z","iopub.status.idle":"2021-11-28T16:57:37.34471Z","shell.execute_reply.started":"2021-11-28T16:57:34.729923Z","shell.execute_reply":"2021-11-28T16:57:37.343843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixels = np.concatenate(train['pixels'])\nlabels = train.emotion.values\n\nprint(pixels.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:37.346695Z","iopub.execute_input":"2021-11-28T16:57:37.347039Z","iopub.status.idle":"2021-11-28T16:57:37.628437Z","shell.execute_reply.started":"2021-11-28T16:57:37.346999Z","shell.execute_reply":"2021-11-28T16:57:37.62755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Distribution","metadata":{}},{"cell_type":"markdown","source":"Let's view the distribution of labels.","metadata":{}},{"cell_type":"code","source":"emotion_prop = (train.emotion.value_counts() / len(train)).to_frame().sort_index(ascending=True)\n\nemotion_prop","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:37.629621Z","iopub.execute_input":"2021-11-28T16:57:37.630243Z","iopub.status.idle":"2021-11-28T16:57:37.641761Z","shell.execute_reply.started":"2021-11-28T16:57:37.630202Z","shell.execute_reply":"2021-11-28T16:57:37.640825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:37.643001Z","iopub.execute_input":"2021-11-28T16:57:37.643374Z","iopub.status.idle":"2021-11-28T16:57:37.651014Z","shell.execute_reply.started":"2021-11-28T16:57:37.643339Z","shell.execute_reply":"2021-11-28T16:57:37.650308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palette = ['orchid', 'lightcoral', 'orange', 'gold', 'lightgreen', 'deepskyblue', 'cornflowerblue']\n\nplt.figure(figsize=[12,6])\n\nplt.bar(x=emotions, height=emotion_prop['emotion'], color=palette, edgecolor='black')\n    \nplt.xlabel('Emotion')\nplt.ylabel('Proportion')\nplt.title('Emotion Label Proportions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:37.651971Z","iopub.execute_input":"2021-11-28T16:57:37.65216Z","iopub.status.idle":"2021-11-28T16:57:37.850454Z","shell.execute_reply.started":"2021-11-28T16:57:37.652131Z","shell.execute_reply":"2021-11-28T16:57:37.849681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the distribution of labels, there is a class imbalance within this training set: the emotion happy accounts for about 25% of the data.","metadata":{}},{"cell_type":"markdown","source":"## View Sample of Images","metadata":{}},{"cell_type":"markdown","source":"We view a sample of images for each emotion: angry, disgust, fear, happy, sad, surprise, and neutral.","metadata":{}},{"cell_type":"code","source":"plt.close()\nplt.rcParams[\"figure.figsize\"] = [16,16]\n\nrow = 0\nfor emotion in np.unique(labels):\n\n    all_emotion_images = train[train['emotion'] == emotion]\n    for i in range(5):\n        \n        img = all_emotion_images.iloc[i,].pixels.reshape(48,48)\n        lab = emotions[emotion]\n\n        plt.subplot(7,5,row+i+1)\n        plt.imshow(img, cmap='binary_r')\n        plt.text(-30, 5, s = str(lab), fontsize=10, color='b')\n        plt.axis('off')\n    row += 5\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:37.85176Z","iopub.execute_input":"2021-11-28T16:57:37.851997Z","iopub.status.idle":"2021-11-28T16:57:39.515207Z","shell.execute_reply.started":"2021-11-28T16:57:37.851965Z","shell.execute_reply":"2021-11-28T16:57:39.514574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split, Reshape, and Scale Datasets","metadata":{}},{"cell_type":"markdown","source":"We split the data into training and validation sets using a stratified fashion.","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(\n    pixels, labels, test_size=0.2, stratify=labels, random_state=1\n)\n\n\nprint('X_train Shape:', X_train.shape)\nprint('y_train Shape:', y_train.shape)\nprint()\nprint('X_valid Shape:', X_valid.shape)\nprint('y_valid Shape:', y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:39.516205Z","iopub.execute_input":"2021-11-28T16:57:39.516556Z","iopub.status.idle":"2021-11-28T16:57:39.69133Z","shell.execute_reply.started":"2021-11-28T16:57:39.516524Z","shell.execute_reply":"2021-11-28T16:57:39.690465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ResNet50 was trained with RGB images, and our data is in grayscale. In order to use the pretrained weights of the ResNet50 model we need to convert the single grayscale channel of our images into 3 channels (RGB).","metadata":{}},{"cell_type":"code","source":"rgb_X_train = np.repeat(X_train[..., np.newaxis], 3, -1)\nprint(rgb_X_train.shape)\n\nrgb_X_valid = np.repeat(X_valid[..., np.newaxis], 3, -1)\nprint(rgb_X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:39.6947Z","iopub.execute_input":"2021-11-28T16:57:39.695027Z","iopub.status.idle":"2021-11-28T16:57:41.024992Z","shell.execute_reply.started":"2021-11-28T16:57:39.694989Z","shell.execute_reply":"2021-11-28T16:57:41.024098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Augmentation","metadata":{}},{"cell_type":"markdown","source":"In an effort to prevent overfitting, we use image augmentation to create additional training observations.","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range = 40,\n    width_shift_range = 0.3, \n    height_shift_range = 0.3, \n    zoom_range = 0.3, \n    horizontal_flip = True, \n    fill_mode = 'reflect'\n)\n\ntrain_loader = train_datagen.flow(rgb_X_train, y_train, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:41.026329Z","iopub.execute_input":"2021-11-28T16:57:41.02671Z","iopub.status.idle":"2021-11-28T16:57:41.299734Z","shell.execute_reply.started":"2021-11-28T16:57:41.026674Z","shell.execute_reply":"2021-11-28T16:57:41.29892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Learning with ResNet50","metadata":{}},{"cell_type":"markdown","source":"We load the pretrained ResNet50 model and set trainable to false. ","metadata":{}},{"cell_type":"code","source":"resnet_model = tf.keras.applications.resnet50.ResNet50(\n    include_top=False, weights='imagenet', input_shape=(48,48,3))\n\nresnet_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:41.300895Z","iopub.execute_input":"2021-11-28T16:57:41.301558Z","iopub.status.idle":"2021-11-28T16:57:42.701199Z","shell.execute_reply.started":"2021-11-28T16:57:41.301516Z","shell.execute_reply":"2021-11-28T16:57:42.700179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We view the model summary and plot the model's architecture. ","metadata":{}},{"cell_type":"code","source":"resnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:42.702615Z","iopub.execute_input":"2021-11-28T16:57:42.702977Z","iopub.status.idle":"2021-11-28T16:57:42.810994Z","shell.execute_reply.started":"2021-11-28T16:57:42.702941Z","shell.execute_reply":"2021-11-28T16:57:42.810336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(resnet_model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:42.81246Z","iopub.execute_input":"2021-11-28T16:57:42.812934Z","iopub.status.idle":"2021-11-28T16:57:45.438609Z","shell.execute_reply.started":"2021-11-28T16:57:42.812894Z","shell.execute_reply":"2021-11-28T16:57:45.437783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configure Model","metadata":{}},{"cell_type":"markdown","source":"To the ResNet50 model we add densely-connected layers, incorporating dropout and batch normalization.","metadata":{}},{"cell_type":"code","source":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    resnet_model,\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.7),\n    \n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.7),\n    \n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    \n    Dense(7, activation='softmax')\n])\n\ncnn.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:45.440647Z","iopub.execute_input":"2021-11-28T16:57:45.441153Z","iopub.status.idle":"2021-11-28T16:57:46.02081Z","shell.execute_reply.started":"2021-11-28T16:57:45.441113Z","shell.execute_reply":"2021-11-28T16:57:46.020081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"markdown","source":"We train the model using the Adam optimizer, a learning rate of 0.0001, and sparse categorical crossentropy loss.","metadata":{}},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(0.0001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:46.02222Z","iopub.execute_input":"2021-11-28T16:57:46.022491Z","iopub.status.idle":"2021-11-28T16:57:46.03487Z","shell.execute_reply.started":"2021-11-28T16:57:46.022456Z","shell.execute_reply":"2021-11-28T16:57:46.034039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We train the model for 30 epochs. ","metadata":{}},{"cell_type":"code","source":"%%time \n\nh1 = cnn.fit(\n    train_loader, \n    batch_size=32,\n    epochs = 30,\n    verbose = 1,\n    validation_data = (rgb_X_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:46.036239Z","iopub.execute_input":"2021-11-28T16:57:46.036569Z","iopub.status.idle":"2021-11-28T17:10:00.860998Z","shell.execute_reply.started":"2021-11-28T16:57:46.036535Z","shell.execute_reply":"2021-11-28T17:10:00.860093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = h1.history\nprint(history.keys())","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:10:00.862518Z","iopub.execute_input":"2021-11-28T17:10:00.862879Z","iopub.status.idle":"2021-11-28T17:10:00.868542Z","shell.execute_reply.started":"2021-11-28T17:10:00.862833Z","shell.execute_reply":"2021-11-28T17:10:00.867777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:10:00.869942Z","iopub.execute_input":"2021-11-28T17:10:00.870601Z","iopub.status.idle":"2021-11-28T17:10:01.278612Z","shell.execute_reply.started":"2021-11-28T17:10:00.870565Z","shell.execute_reply":"2021-11-28T17:10:01.277925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the learning curves we can see there is slight overfitting, and the model could benefit from additional epochs.","metadata":{}},{"cell_type":"markdown","source":"## Fine-Tune Model","metadata":{}},{"cell_type":"markdown","source":"In an effort to enhance our model's performance, we will allow the ResNet50 model to retrain.","metadata":{}},{"cell_type":"code","source":"resnet_model.trainable = True\ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.00001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:10:01.279933Z","iopub.execute_input":"2021-11-28T17:10:01.280179Z","iopub.status.idle":"2021-11-28T17:10:01.30091Z","shell.execute_reply.started":"2021-11-28T17:10:01.280146Z","shell.execute_reply":"2021-11-28T17:10:01.300176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:10:01.30243Z","iopub.execute_input":"2021-11-28T17:10:01.30309Z","iopub.status.idle":"2021-11-28T17:10:01.327302Z","shell.execute_reply.started":"2021-11-28T17:10:01.303056Z","shell.execute_reply":"2021-11-28T17:10:01.326596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We train the model for 30 epochs. ","metadata":{}},{"cell_type":"code","source":"%%time \n\nh2 = cnn.fit(\n    train_loader, \n    batch_size=32,\n    epochs = 30,\n    verbose = 1,\n    validation_data = (rgb_X_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:10:01.328459Z","iopub.execute_input":"2021-11-28T17:10:01.328692Z","iopub.status.idle":"2021-11-28T17:24:54.131469Z","shell.execute_reply.started":"2021-11-28T17:10:01.328662Z","shell.execute_reply":"2021-11-28T17:24:54.130651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:24:54.13318Z","iopub.execute_input":"2021-11-28T17:24:54.133626Z","iopub.status.idle":"2021-11-28T17:24:54.530012Z","shell.execute_reply.started":"2021-11-28T17:24:54.133589Z","shell.execute_reply":"2021-11-28T17:24:54.529245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the learning curves we can see retraining the model increase the accuracy from ~30% to ~44%; however, there is still unerfitting present. ","metadata":{}},{"cell_type":"markdown","source":"## Train Final Convolutional Layers","metadata":{}},{"cell_type":"markdown","source":"In an effort to enhance the model's performance, we will retrain the top convolutional layers of the ResNet50 model. ","metadata":{}},{"cell_type":"code","source":"resnet_model = tf.keras.applications.resnet50.ResNet50(\n    include_top=False, weights='imagenet', input_shape=(48,48,3))\n\nresnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:24:54.53111Z","iopub.execute_input":"2021-11-28T17:24:54.531344Z","iopub.status.idle":"2021-11-28T17:24:55.946481Z","shell.execute_reply.started":"2021-11-28T17:24:54.53131Z","shell.execute_reply":"2021-11-28T17:24:55.945766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of layers in base model:', len(resnet_model.layers), '\\n')\n\nprint('Names of last ten layers:')\nfor layer in resnet_model.layers[-10:]:\n    print(layer.name)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:24:55.947843Z","iopub.execute_input":"2021-11-28T17:24:55.948084Z","iopub.status.idle":"2021-11-28T17:24:55.954976Z","shell.execute_reply.started":"2021-11-28T17:24:55.94805Z","shell.execute_reply":"2021-11-28T17:24:55.954287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_model.trainable = True\n\nfor layer in resnet_model.layers[:-10]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:24:55.956196Z","iopub.execute_input":"2021-11-28T17:24:55.956447Z","iopub.status.idle":"2021-11-28T17:24:55.970578Z","shell.execute_reply.started":"2021-11-28T17:24:55.956416Z","shell.execute_reply":"2021-11-28T17:24:55.969787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To the ResNet50 model we add densely-connected layers, incorporating dropout and batch normalization.","metadata":{}},{"cell_type":"code","source":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    resnet_model,\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.7),\n    \n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.7),\n    \n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    \n    Dense(7, activation='softmax')\n])\n\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:24:55.971619Z","iopub.execute_input":"2021-11-28T17:24:55.972285Z","iopub.status.idle":"2021-11-28T17:24:56.517784Z","shell.execute_reply.started":"2021-11-28T17:24:55.972248Z","shell.execute_reply":"2021-11-28T17:24:56.517071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Run 1","metadata":{}},{"cell_type":"markdown","source":"We train the model using the Adam optimizer, a learning rate of 0.0001, and sparse categorical crossentropy loss.","metadata":{}},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(0.0001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:24:56.521501Z","iopub.execute_input":"2021-11-28T17:24:56.521904Z","iopub.status.idle":"2021-11-28T17:24:56.534182Z","shell.execute_reply.started":"2021-11-28T17:24:56.521866Z","shell.execute_reply":"2021-11-28T17:24:56.533402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We train for 30 epochs for the first training run.","metadata":{}},{"cell_type":"code","source":"%%time \n\nh1 = cnn.fit(\n    train_loader, \n    batch_size=32,\n    epochs = 30,\n    verbose = 1,\n    validation_data = (rgb_X_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:24:56.536115Z","iopub.execute_input":"2021-11-28T17:24:56.536443Z","iopub.status.idle":"2021-11-28T17:40:04.453902Z","shell.execute_reply.started":"2021-11-28T17:24:56.536383Z","shell.execute_reply":"2021-11-28T17:40:04.453083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = h1.history\nprint(history.keys())","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:40:04.455243Z","iopub.execute_input":"2021-11-28T17:40:04.455702Z","iopub.status.idle":"2021-11-28T17:40:04.46286Z","shell.execute_reply.started":"2021-11-28T17:40:04.455663Z","shell.execute_reply":"2021-11-28T17:40:04.462059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:40:04.464199Z","iopub.execute_input":"2021-11-28T17:40:04.464957Z","iopub.status.idle":"2021-11-28T17:40:04.842107Z","shell.execute_reply.started":"2021-11-28T17:40:04.464919Z","shell.execute_reply":"2021-11-28T17:40:04.841284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the learning curves we can see there is slight overfitting, and the model could benefit from additional epochs.","metadata":{}},{"cell_type":"markdown","source":"### Training Run 2","metadata":{}},{"cell_type":"markdown","source":"In order to enhance the performance of the model, we will increase the learning rate to 0.00001.","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.00001)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:40:04.843372Z","iopub.execute_input":"2021-11-28T17:40:04.843657Z","iopub.status.idle":"2021-11-28T17:40:04.849259Z","shell.execute_reply.started":"2021-11-28T17:40:04.843623Z","shell.execute_reply":"2021-11-28T17:40:04.848179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We train for another 30 epochs for the second training run.","metadata":{}},{"cell_type":"code","source":"%%time \n\nh2 = cnn.fit(\n    train_loader, \n    batch_size=32,\n    epochs = 30,\n    verbose = 1,\n    validation_data = (rgb_X_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:40:04.850857Z","iopub.execute_input":"2021-11-28T17:40:04.851121Z","iopub.status.idle":"2021-11-28T17:54:40.829741Z","shell.execute_reply.started":"2021-11-28T17:40:04.851087Z","shell.execute_reply":"2021-11-28T17:54:40.829062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:54:40.831283Z","iopub.execute_input":"2021-11-28T17:54:40.831573Z","iopub.status.idle":"2021-11-28T17:54:41.232139Z","shell.execute_reply.started":"2021-11-28T17:54:40.831538Z","shell.execute_reply":"2021-11-28T17:54:41.231456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the model we can see the accuracy improved from ~35% to ~37%; however, there is still underfitting present. ","metadata":{}},{"cell_type":"markdown","source":"## Save Model and History","metadata":{}},{"cell_type":"markdown","source":"We save the model and training history for future reference.","metadata":{}},{"cell_type":"code","source":"cnn.save('fer_model_v06.h5')\npickle.dump(history, open(f'fer_v06.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:57:26.056367Z","iopub.status.idle":"2021-11-28T17:57:26.058932Z","shell.execute_reply.started":"2021-11-28T17:57:26.058713Z","shell.execute_reply":"2021-11-28T17:57:26.058736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary","metadata":{}},{"cell_type":"markdown","source":"Overall, the ResNet50 did not perform well on the facial expression recognition data. The top accuracy was ~44%. This dataset may benefit from another transfer learning model or simple architecture with the addition of image augmentation. ","metadata":{}},{"cell_type":"markdown","source":"## Resources","metadata":{}},{"cell_type":"markdown","source":"[A Comparison of 4 Popular Transfer Learning Models](https://analyticsindiamag.com/a-comparison-of-4-popular-transfer-learning-models/)<br/>\n[Facial Expression Detection 2](https://www.kaggle.com/haneenabdelmaguid/facial-expression-detection-2)<br/>\n[How can I use a pre-trained neural network with grayscale images?](https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images)<br/>\n[Transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/#do-a-round-of-finetuning-of-the-entire-model)<br/>\n[Transfer Learning Tutorial (CIFAR 10)](https://www.kaggle.com/drbeane/transfer-learning-tutorial-cifar-10)","metadata":{}}]}