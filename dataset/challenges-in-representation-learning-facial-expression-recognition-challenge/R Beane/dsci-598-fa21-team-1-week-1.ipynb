{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Facial Expression Recognition**\n## **Week 1 Training Notebook**\n### Alejandro Alemany, Sara Manrriquez, and Benjamin Zaretzky","metadata":{}},{"cell_type":"markdown","source":"In this notebook we will build an image classification model to identify the emotion being expressed in the images of human faces.","metadata":{}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"markdown","source":"We import all necessary packages. ","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KMP_SETTINGS\"] = \"false\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:09.100803Z","iopub.execute_input":"2021-12-14T22:49:09.101344Z","iopub.status.idle":"2021-12-14T22:49:14.844238Z","shell.execute_reply.started":"2021-12-14T22:49:09.101243Z","shell.execute_reply":"2021-12-14T22:49:14.843331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Training DataFrame","metadata":{}},{"cell_type":"markdown","source":"We load the training data and view the first 5 rows. ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv')\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:14.845913Z","iopub.execute_input":"2021-12-14T22:49:14.846147Z","iopub.status.idle":"2021-12-14T22:49:19.202601Z","shell.execute_reply.started":"2021-12-14T22:49:14.8461Z","shell.execute_reply":"2021-12-14T22:49:19.201886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:19.204006Z","iopub.execute_input":"2021-12-14T22:49:19.204443Z","iopub.status.idle":"2021-12-14T22:49:19.22553Z","shell.execute_reply.started":"2021-12-14T22:49:19.204403Z","shell.execute_reply":"2021-12-14T22:49:19.224795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Data","metadata":{}},{"cell_type":"markdown","source":"The images for this training set are stored as a string. In order to train the model and visualize the images we need to process these strings into a 4D array of pixel values.","metadata":{}},{"cell_type":"code","source":"train['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48,1) for x in train['pixels']]","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:19.228006Z","iopub.execute_input":"2021-12-14T22:49:19.228398Z","iopub.status.idle":"2021-12-14T22:49:22.025791Z","shell.execute_reply.started":"2021-12-14T22:49:19.22836Z","shell.execute_reply":"2021-12-14T22:49:22.025045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixels = np.concatenate(train['pixels'])\nlabels = train.emotion.values\n\nprint(pixels.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:22.027247Z","iopub.execute_input":"2021-12-14T22:49:22.027499Z","iopub.status.idle":"2021-12-14T22:49:22.31991Z","shell.execute_reply.started":"2021-12-14T22:49:22.027466Z","shell.execute_reply":"2021-12-14T22:49:22.319145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Distribution","metadata":{}},{"cell_type":"markdown","source":"Let's view the distribution of labels. ","metadata":{}},{"cell_type":"code","source":"emotion_prop = (train.emotion.value_counts() / len(train)).to_frame().sort_index(ascending=True)\n\nemotion_prop","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:22.321088Z","iopub.execute_input":"2021-12-14T22:49:22.321763Z","iopub.status.idle":"2021-12-14T22:49:22.336655Z","shell.execute_reply.started":"2021-12-14T22:49:22.321723Z","shell.execute_reply":"2021-12-14T22:49:22.335838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:22.338223Z","iopub.execute_input":"2021-12-14T22:49:22.338723Z","iopub.status.idle":"2021-12-14T22:49:22.344744Z","shell.execute_reply.started":"2021-12-14T22:49:22.338682Z","shell.execute_reply":"2021-12-14T22:49:22.343811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palette = ['orchid', 'lightcoral', 'orange', 'gold', 'lightgreen', 'deepskyblue', 'cornflowerblue']\n\nplt.figure(figsize=[12,6])\n\nplt.bar(x=emotions, height=emotion_prop['emotion'], color=palette, edgecolor='black')\n    \nplt.xlabel('Emotion')\nplt.ylabel('Proportion')\nplt.title('Emotion Label Proportions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:22.346435Z","iopub.execute_input":"2021-12-14T22:49:22.346925Z","iopub.status.idle":"2021-12-14T22:49:22.721879Z","shell.execute_reply.started":"2021-12-14T22:49:22.346886Z","shell.execute_reply":"2021-12-14T22:49:22.721223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the distribution of labels, there is a class imbalance within this training set: the emotion happy accounts for about 25% of the data. ","metadata":{}},{"cell_type":"markdown","source":"## View Sample of Images","metadata":{}},{"cell_type":"markdown","source":"We view a sample of images for each emotion: angry, disgust, fear, happy, sad, surprise, and neutral.","metadata":{}},{"cell_type":"code","source":"plt.close()\nplt.rcParams[\"figure.figsize\"] = [16,16]\n\nrow = 0\nfor emotion in np.unique(labels):\n\n    all_emotion_images = train[train['emotion'] == emotion]\n    for i in range(5):\n        \n        img = all_emotion_images.iloc[i,].pixels.reshape(48,48)\n        lab = emotions[emotion]\n\n        plt.subplot(7,5,row+i+1)\n        plt.imshow(img, cmap='binary_r')\n        plt.text(-30, 5, s = str(lab), fontsize=10, color='b')\n        plt.axis('off')\n    row += 5\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:22.723084Z","iopub.execute_input":"2021-12-14T22:49:22.723841Z","iopub.status.idle":"2021-12-14T22:49:25.30421Z","shell.execute_reply.started":"2021-12-14T22:49:22.723794Z","shell.execute_reply":"2021-12-14T22:49:25.302231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split, Reshape, and Scale Datasets","metadata":{}},{"cell_type":"markdown","source":"We split the data into training and validation sets using a stratified fashion, and scale the pixels values between 0 and 1. ","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(\n    pixels, labels, test_size=0.2, stratify=labels, random_state=1\n)\n\n\nprint('X_train Shape:', X_train.shape)\nprint('y_train Shape:', y_train.shape)\nprint()\nprint('X_valid Shape:', X_valid.shape)\nprint('y_valid Shape:', y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:25.308314Z","iopub.execute_input":"2021-12-14T22:49:25.308805Z","iopub.status.idle":"2021-12-14T22:49:25.500806Z","shell.execute_reply.started":"2021-12-14T22:49:25.30877Z","shell.execute_reply":"2021-12-14T22:49:25.499791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xs_train = X_train / 255\nXs_valid = X_valid / 255","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:25.502326Z","iopub.execute_input":"2021-12-14T22:49:25.502676Z","iopub.status.idle":"2021-12-14T22:49:25.713514Z","shell.execute_reply.started":"2021-12-14T22:49:25.502637Z","shell.execute_reply":"2021-12-14T22:49:25.712484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Network","metadata":{}},{"cell_type":"markdown","source":"We set the seed in order to produce the same results each training run. We build the convolutional neural network using a series of 2D convolution layers followed by densely-connected layers. Additionally, we incorporate max pooling, dropout, and batch normalization. ","metadata":{}},{"cell_type":"code","source":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same', input_shape=(48,48,1)),\n    Conv2D(64, (5,5), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n    \n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    BatchNormalization(),\n    Dense(7, activation='softmax')\n])\n\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:25.717507Z","iopub.execute_input":"2021-12-14T22:49:25.717818Z","iopub.status.idle":"2021-12-14T22:49:28.453048Z","shell.execute_reply.started":"2021-12-14T22:49:25.717785Z","shell.execute_reply":"2021-12-14T22:49:28.452306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Network","metadata":{}},{"cell_type":"markdown","source":"We train the model using the Adam optimizer, a learning rate of 0.001, and sparse categorical crossentropy loss. ","metadata":{}},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:28.454356Z","iopub.execute_input":"2021-12-14T22:49:28.454609Z","iopub.status.idle":"2021-12-14T22:49:28.469704Z","shell.execute_reply.started":"2021-12-14T22:49:28.454574Z","shell.execute_reply":"2021-12-14T22:49:28.468919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Run 1","metadata":{}},{"cell_type":"markdown","source":"We train for 20 epochs for the first training run. ","metadata":{}},{"cell_type":"code","source":"%%time \n\nh1 = cnn.fit(\n    Xs_train, y_train, \n    batch_size=256,\n    epochs = 20,\n    verbose = 1,\n    validation_data = (Xs_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:49:28.471453Z","iopub.execute_input":"2021-12-14T22:49:28.471636Z","iopub.status.idle":"2021-12-14T22:51:16.604634Z","shell.execute_reply.started":"2021-12-14T22:49:28.471613Z","shell.execute_reply":"2021-12-14T22:51:16.603783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = h1.history\nprint(history.keys())","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:51:16.606309Z","iopub.execute_input":"2021-12-14T22:51:16.606731Z","iopub.status.idle":"2021-12-14T22:51:16.61148Z","shell.execute_reply.started":"2021-12-14T22:51:16.606692Z","shell.execute_reply":"2021-12-14T22:51:16.610488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:51:16.612936Z","iopub.execute_input":"2021-12-14T22:51:16.613444Z","iopub.status.idle":"2021-12-14T22:51:17.034719Z","shell.execute_reply.started":"2021-12-14T22:51:16.613326Z","shell.execute_reply":"2021-12-14T22:51:17.033966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the leaning curves we can conclude the model is training well, between 55-60%; however, there is room for improvement. There is slight overfitting, and the model could benefit from additional epochs. ","metadata":{}},{"cell_type":"markdown","source":"### Training Run 2","metadata":{}},{"cell_type":"markdown","source":"In order to enhance the performance of the model, we will increase the learning rate to 0.0001. ","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:51:17.036281Z","iopub.execute_input":"2021-12-14T22:51:17.036777Z","iopub.status.idle":"2021-12-14T22:51:17.042432Z","shell.execute_reply.started":"2021-12-14T22:51:17.036739Z","shell.execute_reply":"2021-12-14T22:51:17.041367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We train for another 20 epochs for the second training run. ","metadata":{}},{"cell_type":"code","source":"%%time \n\nh2 = cnn.fit(\n    Xs_train, y_train, \n    batch_size=256,\n    epochs = 20,\n    verbose = 1,\n    validation_data = (Xs_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:51:17.044088Z","iopub.execute_input":"2021-12-14T22:51:17.044414Z","iopub.status.idle":"2021-12-14T22:52:55.80271Z","shell.execute_reply.started":"2021-12-14T22:51:17.044376Z","shell.execute_reply":"2021-12-14T22:52:55.801991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:52:55.806051Z","iopub.execute_input":"2021-12-14T22:52:55.806276Z","iopub.status.idle":"2021-12-14T22:52:56.2912Z","shell.execute_reply.started":"2021-12-14T22:52:55.80625Z","shell.execute_reply":"2021-12-14T22:52:56.290487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the learning curves we can conclude the increased learning rate caused significant overfitting. The training accuracy is ~70%, while the validation accuracy is ~57%. In order to enhance performance, this model may benefit from image augmentation. ","metadata":{}},{"cell_type":"markdown","source":"## Save Model and History","metadata":{}},{"cell_type":"markdown","source":"We save the model and training history for future reference. ","metadata":{}},{"cell_type":"code","source":"cnn.save('fer_model_v02.h5')\npickle.dump(history, open(f'fer_v02.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:52:56.29248Z","iopub.execute_input":"2021-12-14T22:52:56.292917Z","iopub.status.idle":"2021-12-14T22:52:56.412519Z","shell.execute_reply.started":"2021-12-14T22:52:56.292873Z","shell.execute_reply":"2021-12-14T22:52:56.411763Z"},"trusted":true},"execution_count":null,"outputs":[]}]}