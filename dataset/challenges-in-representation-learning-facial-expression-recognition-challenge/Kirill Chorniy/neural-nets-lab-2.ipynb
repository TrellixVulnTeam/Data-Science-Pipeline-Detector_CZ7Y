{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import models, layers\nimport tqdm\nfrom PIL import Image\n\nimport os, shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge\"\n\nraw_data = pd.read_csv(os.path.join(PATH, \"icml_face_data.csv\"))\n\nemotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.system('rm -rf /kaggle/working')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hot_emotions = pd.get_dummies(raw_data['emotion'])\nclear_hot_emotions = pd.DataFrame({\"hot_emotions\":[]})\nfor inx in range(hot_emotions.shape[0]):\n    hot_em = [list(hot_emotions.loc[inx])]\n    tmp = pd.DataFrame({'hot_emotions':hot_em})\n    clear_hot_emotions = clear_hot_emotions.append(tmp, ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data = pd.concat([raw_data, clear_hot_emotions], axis=1).drop('emotion', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_data(data):\n    dt = np.zeros(shape=(len(data), 48, 48, 1))\n    lb = np.array(list(map(list, data['hot_emotions'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48, 1))\n        dt[i] = image\n        \n    return dt, lb\n\ntrain_data, train_lab = parse_data(raw_data[raw_data[\" Usage\"] == \"Training\"])\ntest_data, test_lab = parse_data(raw_data[raw_data[\" Usage\"] == \"PublicTest\"])\nval_data, val_lab = parse_data(raw_data[raw_data[\" Usage\"] == \"PrivateTest\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape, test_data.shape, val_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_lab.shape, test_lab.shape, val_lab.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.system('mkdir -p /kaggle/working/imgs/train /kaggle/working/imgs/test /kaggle/working/imgs/val')\n\n# for inx, px_map in enumerate(np.array(train_imgs[:])):\n#     px_map = np.reshape(px_map, (48, 48))\n#     image = Image.fromarray(px_map)\n#     image = image.convert('RGB')\n#     image.save('/kaggle/working/imgs/train/'+str(inx)+'.bmp')\n\n# for inx, px_map in enumerate(np.array(test_imgs[:])):\n#     px_map = np.reshape(px_map, (48, 48))\n#     image = Image.fromarray(px_map)\n#     image = image.convert('RGB')\n#     image.save('/kaggle/working/imgs/test/'+str(inx)+'.bmp')\n\n# for inx, px_map in enumerate(np.array(val_imgs[:])):\n#     px_map = np.reshape(px_map, (48, 48))\n#     image = Image.fromarray(px_map)\n#     image = image.convert('RGB')\n#     image.save('/kaggle/working/imgs/val/'+str(inx)+'.bmp')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn = keras.Sequential()\n\nmodel_cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)))\nmodel_cnn.add(layers.MaxPool2D(2))\n\nmodel_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel_cnn.add(layers.MaxPool2D(2))\n\nmodel_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\n\nmodel_cnn.add(layers.Flatten())\n\nmodel_cnn.add(layers.Dense(64, activation='relu'))\nmodel_cnn.add(layers.Dense(len(emotions.keys()), activation='softmax'))\n\nmodel_cnn.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.03), metrics=['accuracy'])\n\nmodel_cnn.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.fit(train_data, train_lab, epochs=6, batch_size=64, validation_data=(val_data, val_lab), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.evaluate(test_data, test_lab)[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn = keras.Sequential()\n\nmodel_cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)))\nmodel_cnn.add(layers.MaxPool2D(2))\n\nmodel_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\n\nmodel_cnn.add(layers.Flatten())\n\nmodel_cnn.add(layers.Dense(64, activation='relu'))\nmodel_cnn.add(layers.Dense(len(emotions.keys()), activation='softmax'))\n\nmodel_cnn.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.03), metrics=['accuracy'])\n\nmodel_cnn.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.fit(train_data, train_lab, epochs=6, batch_size=64, validation_data=(val_data, val_lab), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.evaluate(test_data, test_lab)[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn = keras.Sequential()\n\nmodel_cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)))\nmodel_cnn.add(layers.MaxPool2D(2))\n\nmodel_cnn.add(layers.Flatten())\n\nmodel_cnn.add(layers.Dense(64, activation='relu'))\nmodel_cnn.add(layers.Dense(len(emotions.keys()), activation='softmax'))\n\nmodel_cnn.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.03), metrics=['accuracy'])\n\nmodel_cnn.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.fit(train_data, train_lab, epochs=6, batch_size=64, validation_data=(val_data, val_lab), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.evaluate(test_data, test_lab)[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn = keras.Sequential()\n\nmodel_cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)))\nmodel_cnn.add(layers.MaxPool2D(2))\n\nmodel_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel_cnn.add(layers.MaxPool2D(2))\n\nmodel_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\n\nmodel_cnn.add(layers.Flatten())\n\nmodel_cnn.add(layers.Dense(64, activation='relu'))\nmodel_cnn.add(layers.Dense(len(emotions.keys()), activation='softmax'))\n\nmodel_cnn.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.003), metrics=['accuracy'])\n\nmodel_cnn.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.fit(train_data, train_lab, epochs=64, batch_size=4096, validation_data=(val_data, val_lab), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cnn.evaluate(test_data, test_lab)[1]","metadata":{},"execution_count":null,"outputs":[]}]}