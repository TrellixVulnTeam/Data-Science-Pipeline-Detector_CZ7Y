{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-23T08:18:28.046503Z","iopub.execute_input":"2022-04-23T08:18:28.047335Z","iopub.status.idle":"2022-04-23T08:18:28.07835Z","shell.execute_reply.started":"2022-04-23T08:18:28.047227Z","shell.execute_reply":"2022-04-23T08:18:28.07746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOAD DATA**","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv\")\ntrain_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:28.080037Z","iopub.execute_input":"2022-04-23T08:18:28.080362Z","iopub.status.idle":"2022-04-23T08:18:32.042421Z","shell.execute_reply.started":"2022-04-23T08:18:28.080326Z","shell.execute_reply":"2022-04-23T08:18:32.041627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[\"emotion\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:32.044366Z","iopub.execute_input":"2022-04-23T08:18:32.044796Z","iopub.status.idle":"2022-04-23T08:18:32.057553Z","shell.execute_reply.started":"2022-04-23T08:18:32.044758Z","shell.execute_reply":"2022-04-23T08:18:32.056832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/test.csv\")\ntest_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:32:51.885602Z","iopub.execute_input":"2022-04-23T09:32:51.886337Z","iopub.status.idle":"2022-04-23T09:32:52.400403Z","shell.execute_reply.started":"2022-04-23T09:32:51.886297Z","shell.execute_reply":"2022-04-23T09:32:52.3995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facialexpression_df = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:33.095489Z","iopub.execute_input":"2022-04-23T08:18:33.095801Z","iopub.status.idle":"2022-04-23T08:18:38.055935Z","shell.execute_reply.started":"2022-04-23T08:18:33.095763Z","shell.execute_reply":"2022-04-23T08:18:38.055101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facialexpression_df","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:38.057632Z","iopub.execute_input":"2022-04-23T08:18:38.057921Z","iopub.status.idle":"2022-04-23T08:18:38.07201Z","shell.execute_reply.started":"2022-04-23T08:18:38.057885Z","shell.execute_reply":"2022-04-23T08:18:38.070989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facialexpression_df[' pixels'][0]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:38.073897Z","iopub.execute_input":"2022-04-23T08:18:38.074212Z","iopub.status.idle":"2022-04-23T08:18:38.081619Z","shell.execute_reply.started":"2022-04-23T08:18:38.074124Z","shell.execute_reply":"2022-04-23T08:18:38.080749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> HERE WE SEE THAT PIXELS ARE IN STRING FORMET WE HAVE TO CONVERT THEM INTO ARRAY FORMET","metadata":{}},{"cell_type":"code","source":"def string2array(x):\n  return np.array(x.split(' ')).reshape(48, 48, 1).astype('float32')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:38.083076Z","iopub.execute_input":"2022-04-23T08:18:38.083539Z","iopub.status.idle":"2022-04-23T08:18:38.088543Z","shell.execute_reply.started":"2022-04-23T08:18:38.083504Z","shell.execute_reply":"2022-04-23T08:18:38.087825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> HERE WE CONVERT 48x48 Image To 96x96 Image","metadata":{}},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:38.089949Z","iopub.execute_input":"2022-04-23T08:18:38.090468Z","iopub.status.idle":"2022-04-23T08:18:38.351079Z","shell.execute_reply.started":"2022-04-23T08:18:38.090431Z","shell.execute_reply":"2022-04-23T08:18:38.350232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize(x):\n  \n  img = x.reshape(48, 48)\n  return cv2.resize(img, dsize=(96, 96), interpolation = cv2.INTER_CUBIC)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:38.352523Z","iopub.execute_input":"2022-04-23T08:18:38.352811Z","iopub.status.idle":"2022-04-23T08:18:38.357758Z","shell.execute_reply.started":"2022-04-23T08:18:38.352774Z","shell.execute_reply":"2022-04-23T08:18:38.356892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facialexpression_df[' pixels'] = facialexpression_df[' pixels'].apply(lambda x: string2array(x)) # Converted To Array\nfacialexpression_df[' pixels'] = facialexpression_df[' pixels'].apply(lambda x: resize(x)) # Resize To 96x96","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:18:38.361675Z","iopub.execute_input":"2022-04-23T08:18:38.36202Z","iopub.status.idle":"2022-04-23T08:19:48.980408Z","shell.execute_reply.started":"2022-04-23T08:18:38.361982Z","shell.execute_reply":"2022-04-23T08:19:48.979643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facialexpression_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:48.981916Z","iopub.execute_input":"2022-04-23T08:19:48.982173Z","iopub.status.idle":"2022-04-23T08:19:49.483192Z","shell.execute_reply.started":"2022-04-23T08:19:48.982137Z","shell.execute_reply":"2022-04-23T08:19:49.482471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Check For Null Data","metadata":{}},{"cell_type":"code","source":"facialexpression_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:49.484459Z","iopub.execute_input":"2022-04-23T08:19:49.48476Z","iopub.status.idle":"2022-04-23T08:19:49.501427Z","shell.execute_reply.started":"2022-04-23T08:19:49.48472Z","shell.execute_reply":"2022-04-23T08:19:49.500553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Just Visualize One Image","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:49.502972Z","iopub.execute_input":"2022-04-23T08:19:49.503826Z","iopub.status.idle":"2022-04-23T08:19:49.509269Z","shell.execute_reply.started":"2022-04-23T08:19:49.503786Z","shell.execute_reply":"2022-04-23T08:19:49.508474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(facialexpression_df[' pixels'][6], cmap = 'gray')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:49.510393Z","iopub.execute_input":"2022-04-23T08:19:49.510679Z","iopub.status.idle":"2022-04-23T08:19:49.813997Z","shell.execute_reply.started":"2022-04-23T08:19:49.510643Z","shell.execute_reply":"2022-04-23T08:19:49.81333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Count How Many Emotions ","metadata":{}},{"cell_type":"code","source":"facialexpression_df.emotion.value_counts().index","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:49.815242Z","iopub.execute_input":"2022-04-23T08:19:49.815897Z","iopub.status.idle":"2022-04-23T08:19:49.824069Z","shell.execute_reply.started":"2022-04-23T08:19:49.815857Z","shell.execute_reply":"2022-04-23T08:19:49.823122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facialexpression_df.emotion.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:49.82584Z","iopub.execute_input":"2022-04-23T08:19:49.826168Z","iopub.status.idle":"2022-04-23T08:19:49.834335Z","shell.execute_reply.started":"2022-04-23T08:19:49.826105Z","shell.execute_reply":"2022-04-23T08:19:49.833489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:49.835692Z","iopub.execute_input":"2022-04-23T08:19:49.835982Z","iopub.status.idle":"2022-04-23T08:19:50.578278Z","shell.execute_reply.started":"2022-04-23T08:19:49.835942Z","shell.execute_reply":"2022-04-23T08:19:50.577469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.barplot(x = facialexpression_df.emotion.value_counts().index, y = facialexpression_df.emotion.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:50.579734Z","iopub.execute_input":"2022-04-23T08:19:50.579985Z","iopub.status.idle":"2022-04-23T08:19:50.793675Z","shell.execute_reply.started":"2022-04-23T08:19:50.579949Z","shell.execute_reply":"2022-04-23T08:19:50.792863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nX = facialexpression_df[' pixels']\ny = tf.keras.utils.to_categorical(facialexpression_df['emotion'])# Convert Into Categorical Because OF CNN Output","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:50.794958Z","iopub.execute_input":"2022-04-23T08:19:50.795211Z","iopub.status.idle":"2022-04-23T08:19:54.949871Z","shell.execute_reply.started":"2022-04-23T08:19:50.795175Z","shell.execute_reply":"2022-04-23T08:19:54.948949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> X's Value In Pixels And Image","metadata":{}},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:54.951624Z","iopub.execute_input":"2022-04-23T08:19:54.95216Z","iopub.status.idle":"2022-04-23T08:19:54.961121Z","shell.execute_reply.started":"2022-04-23T08:19:54.952121Z","shell.execute_reply":"2022-04-23T08:19:54.960207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X[0], cmap = 'gray')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:54.962479Z","iopub.execute_input":"2022-04-23T08:19:54.962834Z","iopub.status.idle":"2022-04-23T08:19:55.169097Z","shell.execute_reply.started":"2022-04-23T08:19:54.962795Z","shell.execute_reply":"2022-04-23T08:19:55.168393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> y's Value","metadata":{}},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:55.1704Z","iopub.execute_input":"2022-04-23T08:19:55.170877Z","iopub.status.idle":"2022-04-23T08:19:55.17899Z","shell.execute_reply.started":"2022-04-23T08:19:55.170822Z","shell.execute_reply":"2022-04-23T08:19:55.178313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.stack(X, axis = 0)\nX = X.reshape(35887, 96, 96,1)# 35887 Because Of 35887 No. Of Images\n\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:55.180525Z","iopub.execute_input":"2022-04-23T08:19:55.181413Z","iopub.status.idle":"2022-04-23T08:19:55.639642Z","shell.execute_reply.started":"2022-04-23T08:19:55.181372Z","shell.execute_reply":"2022-04-23T08:19:55.638081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X = np.repeat(X[..., np.newaxis], 3, -1)# For Gray-Scale To RGB Convert(1 Channel To 3 Channel Convert)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:55.640908Z","iopub.execute_input":"2022-04-23T08:19:55.641159Z","iopub.status.idle":"2022-04-23T08:19:55.646472Z","shell.execute_reply.started":"2022-04-23T08:19:55.641123Z","shell.execute_reply":"2022-04-23T08:19:55.644886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Split X-y In To Train-Test And Validation Data","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_Test, y_train, y_Test = train_test_split(X, y, test_size = 0.1, shuffle = True)\nX_val, X_Test, y_val, y_Test = train_test_split(X_Test, y_Test, test_size = 0.5, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:55.647903Z","iopub.execute_input":"2022-04-23T08:19:55.648098Z","iopub.status.idle":"2022-04-23T08:19:56.206196Z","shell.execute_reply.started":"2022-04-23T08:19:55.648075Z","shell.execute_reply":"2022-04-23T08:19:56.205361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Normalize","metadata":{}},{"cell_type":"code","source":"X_train = X_train-127.5/127.5\nX_val   = X_val-127.5 /127.5\nX_Test  = X_Test-127.5/127.5","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:56.207564Z","iopub.execute_input":"2022-04-23T08:19:56.20787Z","iopub.status.idle":"2022-04-23T08:19:56.592379Z","shell.execute_reply.started":"2022-04-23T08:19:56.207832Z","shell.execute_reply":"2022-04-23T08:19:56.5916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train[0],X_val[0],X_Test[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:56.593711Z","iopub.execute_input":"2022-04-23T08:19:56.594062Z","iopub.status.idle":"2022-04-23T08:19:56.602471Z","shell.execute_reply.started":"2022-04-23T08:19:56.594023Z","shell.execute_reply":"2022-04-23T08:19:56.601739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom IPython.display import display\nfrom tensorflow.python.keras import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:35:03.923129Z","iopub.execute_input":"2022-04-23T08:35:03.923497Z","iopub.status.idle":"2022-04-23T08:35:03.941466Z","shell.execute_reply.started":"2022-04-23T08:35:03.923454Z","shell.execute_reply":"2022-04-23T08:35:03.940816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Create Training Data-Genrator","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range = 15,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    shear_range = 0.1,\n    zoom_range = 0.1,\n    horizontal_flip = True,\n    fill_mode = \"nearest\")","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:19:56.614189Z","iopub.execute_input":"2022-04-23T08:19:56.614665Z","iopub.status.idle":"2022-04-23T08:19:56.621174Z","shell.execute_reply.started":"2022-04-23T08:19:56.614629Z","shell.execute_reply":"2022-04-23T08:19:56.620467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We Want To Use Xception Model For Transfer Lerning In This Compition But The Data Given Is Only in 1 Channel We Converted It Into 3 Channel And Start Trainng But The Acc. Is Low And The Memory Limit Is Exided So We Desided To Build The Model","metadata":{}},{"cell_type":"code","source":"'''\n\nxception_model = Sequential()\n\npretrained_model= tf.keras.applications.Xception(include_top=False,\n                   input_shape=(96,96,3),#Usally Is 299x299 But We Give It 96x96\n                   pooling='avg',\n                   weights='imagenet')\nfor layer in pretrained_model.layers:\n        layer.trainable=False\n\nxception_model.add(pretrained_model)\nxception_model.add(Flatten())\nxception_model.add(BatchNormalization())\nxception_model.add(Dense(7, activation='softmax'))# For 7 Classes\nxception_model.compile(loss'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n'''","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:25:13.106847Z","iopub.execute_input":"2022-04-23T08:25:13.10717Z","iopub.status.idle":"2022-04-23T08:25:13.113784Z","shell.execute_reply.started":"2022-04-23T08:25:13.107125Z","shell.execute_reply":"2022-04-23T08:25:13.112492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We Use Residual Blocks Here Like Resnet ","metadata":{}},{"cell_type":"code","source":"def res_block(X, filter):\n\n  # Convolutional_block\n  X_copy = X\n\n  f1 , f2, f3 = filter\n\n  # Main Path\n  X = Conv2D(f1, (1,1),strides = (1,1), kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = MaxPool2D((2,2))(X)\n  X = BatchNormalization(axis =3,)(X)\n  X = Activation('relu')(X) \n\n  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n  X = Activation('relu')(X) \n\n  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n\n\n  # Short path\n  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1), kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n  X_copy = MaxPool2D((2,2))(X_copy)\n  X_copy = BatchNormalization(axis =3)(X_copy)\n\n  # ADD\n  X = Add()([X,X_copy])\n  X = Activation('relu')(X)\n\n  # Identity Block 1\n  X_copy = X\n\n\n  # Main Path\n  X = Conv2D(f1, (1,1),strides = (1,1), kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n  X = Activation('relu')(X) \n\n  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n  X = Activation('relu')(X) \n\n  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1), kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n\n  # ADD\n  X = Add()([X,X_copy])\n  X = Activation('relu')(X)\n\n  # Identity Block 2\n  X_copy = X\n\n\n  # Main Path\n  X = Conv2D(f1, (1,1),strides = (1,1), kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n  X = Activation('relu')(X) \n\n  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n  X = Activation('relu')(X) \n\n  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1), kernel_initializer= glorot_uniform(seed = 0))(X)\n  X = BatchNormalization(axis =3)(X)\n\n  # ADD\n  X = Add()([X,X_copy])\n  X = Activation('relu')(X)\n\n  return X","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:46:26.08811Z","iopub.execute_input":"2022-04-23T08:46:26.088408Z","iopub.status.idle":"2022-04-23T08:46:26.118017Z","shell.execute_reply.started":"2022-04-23T08:46:26.088376Z","shell.execute_reply":"2022-04-23T08:46:26.11718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (96, 96, 1)\n\nX_input = Input(input_shape)\n\nX = ZeroPadding2D((3, 3))(X_input)\n\nX = Conv2D(64, (7, 7), strides= (2, 2), kernel_initializer= glorot_uniform(seed = 0))(X)\nX = BatchNormalization(axis =3)(X)\nX = Activation('relu')(X)\nX = MaxPooling2D((3, 3), strides= (2, 2))(X)\n\nX = res_block(X, filter= [64, 64, 256])\n\nX = res_block(X, filter= [128, 128, 512])\n\nX = AveragePooling2D((4, 4))(X)\n\nX = Flatten()(X)\nX = Dense(7, activation = 'softmax',kernel_initializer= glorot_uniform(seed=0))(X)\n\nmodel = Model( inputs= X_input, outputs = X)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:46:51.646251Z","iopub.execute_input":"2022-04-23T08:46:51.646899Z","iopub.status.idle":"2022-04-23T08:46:52.053743Z","shell.execute_reply.started":"2022-04-23T08:46:51.646858Z","shell.execute_reply":"2022-04-23T08:46:52.052989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:47:24.080632Z","iopub.execute_input":"2022-04-23T08:47:24.08135Z","iopub.status.idle":"2022-04-23T08:47:24.096733Z","shell.execute_reply.started":"2022-04-23T08:47:24.081313Z","shell.execute_reply":"2022-04-23T08:47:24.095847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save = model.fit(train_datagen.flow(X_train, y_train, batch_size=100),\n    validation_data=(X_val, y_val), steps_per_epoch=len(X_train) // 100,\n    epochs= 20)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T08:50:56.084817Z","iopub.execute_input":"2022-04-23T08:50:56.08555Z","iopub.status.idle":"2022-04-23T09:00:59.029829Z","shell.execute_reply.started":"2022-04-23T08:50:56.085502Z","shell.execute_reply":"2022-04-23T09:00:59.029018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_Test, y_Test)\nprint('Test Accuracy: {}'.format(score[1]))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:01:29.165844Z","iopub.execute_input":"2022-04-23T09:01:29.166228Z","iopub.status.idle":"2022-04-23T09:01:29.952022Z","shell.execute_reply.started":"2022-04-23T09:01:29.166194Z","shell.execute_reply":"2022-04-23T09:01:29.95126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Now This Is All For icml_face Data Now We Will Acctually Train For Train Data And Pridict For Test Data","metadata":{}},{"cell_type":"code","source":"train_data['pixels'] = train_data['pixels'].apply(lambda x: string2array(x)) # Converted To Array\ntrain_data['pixels'] = train_data['pixels'].apply(lambda x: resize(x)) # Resize To 96x96","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:05:18.330201Z","iopub.execute_input":"2022-04-23T09:05:18.330969Z","iopub.status.idle":"2022-04-23T09:06:16.205438Z","shell.execute_reply.started":"2022-04-23T09:05:18.330927Z","shell.execute_reply":"2022-04-23T09:06:16.204637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:06:25.049841Z","iopub.execute_input":"2022-04-23T09:06:25.050353Z","iopub.status.idle":"2022-04-23T09:06:25.809266Z","shell.execute_reply.started":"2022-04-23T09:06:25.050311Z","shell.execute_reply":"2022-04-23T09:06:25.808523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()#check For Null","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:06:59.765518Z","iopub.execute_input":"2022-04-23T09:06:59.766216Z","iopub.status.idle":"2022-04-23T09:06:59.778443Z","shell.execute_reply.started":"2022-04-23T09:06:59.766156Z","shell.execute_reply":"2022-04-23T09:06:59.777612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.barplot(x = train_data.emotion.value_counts().index, y = train_data.emotion.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:08:15.167533Z","iopub.execute_input":"2022-04-23T09:08:15.167966Z","iopub.status.idle":"2022-04-23T09:08:15.506629Z","shell.execute_reply.started":"2022-04-23T09:08:15.167912Z","shell.execute_reply":"2022-04-23T09:08:15.505833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_data['pixels']\ny = tf.keras.utils.to_categorical(train_data['emotion'])# Convert Into Categorical Because OF CNN Output","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:09:03.0104Z","iopub.execute_input":"2022-04-23T09:09:03.011288Z","iopub.status.idle":"2022-04-23T09:09:03.017292Z","shell.execute_reply.started":"2022-04-23T09:09:03.011233Z","shell.execute_reply":"2022-04-23T09:09:03.016485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:09:41.215858Z","iopub.execute_input":"2022-04-23T09:09:41.216416Z","iopub.status.idle":"2022-04-23T09:09:41.2221Z","shell.execute_reply.started":"2022-04-23T09:09:41.216377Z","shell.execute_reply":"2022-04-23T09:09:41.22138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.stack(X, axis = 0)\nX = X.reshape(28709, 96, 96,1)# 28709 Because Of 28709 No. Of Images\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:10:00.330602Z","iopub.execute_input":"2022-04-23T09:10:00.33087Z","iopub.status.idle":"2022-04-23T09:10:00.704065Z","shell.execute_reply.started":"2022-04-23T09:10:00.330841Z","shell.execute_reply":"2022-04-23T09:10:00.702313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:11:26.004559Z","iopub.execute_input":"2022-04-23T09:11:26.005107Z","iopub.status.idle":"2022-04-23T09:11:26.300544Z","shell.execute_reply.started":"2022-04-23T09:11:26.005065Z","shell.execute_reply":"2022-04-23T09:11:26.299733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train-127.5/127.5\nX_val   = X_val-127.5 /127.5","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:12:54.244468Z","iopub.execute_input":"2022-04-23T09:12:54.245102Z","iopub.status.idle":"2022-04-23T09:12:54.548717Z","shell.execute_reply.started":"2022-04-23T09:12:54.245056Z","shell.execute_reply":"2022-04-23T09:12:54.547906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save = model.fit(train_datagen.flow(X_train, y_train, batch_size=100),\n    validation_data=(X_val, y_val), steps_per_epoch=len(X_train) // 100,\n    epochs= 20)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:13:39.20584Z","iopub.execute_input":"2022-04-23T09:13:39.20614Z","iopub.status.idle":"2022-04-23T09:22:01.229074Z","shell.execute_reply.started":"2022-04-23T09:13:39.206099Z","shell.execute_reply":"2022-04-23T09:22:01.228117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"weights.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:24:47.925472Z","iopub.execute_input":"2022-04-23T09:24:47.926165Z","iopub.status.idle":"2022-04-23T09:24:47.934156Z","shell.execute_reply.started":"2022-04-23T09:24:47.92612Z","shell.execute_reply":"2022-04-23T09:24:47.933399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['pixels'] = test_data['pixels'].apply(lambda x: string2array(x)) # Converted To Array\ntest_data['pixels'] = test_data['pixels'].apply(lambda x: resize(x)) # Resize To 96x96","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:36:46.315098Z","iopub.execute_input":"2022-04-23T09:36:46.315377Z","iopub.status.idle":"2022-04-23T09:37:00.242078Z","shell.execute_reply.started":"2022-04-23T09:36:46.315348Z","shell.execute_reply":"2022-04-23T09:37:00.241305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=test_data['pixels']","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:37:08.255238Z","iopub.execute_input":"2022-04-23T09:37:08.255505Z","iopub.status.idle":"2022-04-23T09:37:08.259845Z","shell.execute_reply.started":"2022-04-23T09:37:08.255474Z","shell.execute_reply":"2022-04-23T09:37:08.258756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.stack(X, axis = 0)\nX = X.reshape(7178, 96, 96,1)# 28709 Because Of 28709 No. Of Images\nprint(test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:37:10.499336Z","iopub.execute_input":"2022-04-23T09:37:10.500073Z","iopub.status.idle":"2022-04-23T09:37:10.598203Z","shell.execute_reply.started":"2022-04-23T09:37:10.500031Z","shell.execute_reply":"2022-04-23T09:37:10.597321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted=model.predict(X)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:39:45.566325Z","iopub.execute_input":"2022-04-23T09:39:45.566617Z","iopub.status.idle":"2022-04-23T09:39:47.158657Z","shell.execute_reply.started":"2022-04-23T09:39:45.566568Z","shell.execute_reply":"2022-04-23T09:39:47.156685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted_labels = [np.argmax(i) for i in y_predicted]\nprint(y_predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:40:29.065572Z","iopub.execute_input":"2022-04-23T09:40:29.066466Z","iopub.status.idle":"2022-04-23T09:40:29.096365Z","shell.execute_reply.started":"2022-04-23T09:40:29.066429Z","shell.execute_reply":"2022-04-23T09:40:29.095643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions=pd.DataFrame({\"\": y_predicted_labels})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:46:59.190041Z","iopub.execute_input":"2022-04-23T09:46:59.190539Z","iopub.status.idle":"2022-04-23T09:46:59.210384Z","shell.execute_reply.started":"2022-04-23T09:46:59.190502Z","shell.execute_reply":"2022-04-23T09:46:59.209565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Graphs And Etc At Last.","metadata":{}},{"cell_type":"code","source":"accuracy = save.history['accuracy']\nval_accuracy = save.history['val_accuracy']\nloss = save.history['loss']\nval_loss = save.history['val_loss']","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:50:49.17642Z","iopub.execute_input":"2022-04-23T09:50:49.176996Z","iopub.status.idle":"2022-04-23T09:50:49.18131Z","shell.execute_reply.started":"2022-04-23T09:50:49.176955Z","shell.execute_reply":"2022-04-23T09:50:49.180597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> For Training & Validation","metadata":{}},{"cell_type":"code","source":"epochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\nplt.title('Training & Validation Accuracy')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:51:26.775168Z","iopub.execute_input":"2022-04-23T09:51:26.775444Z","iopub.status.idle":"2022-04-23T09:51:27.015388Z","shell.execute_reply.started":"2022-04-23T09:51:26.775411Z","shell.execute_reply":"2022-04-23T09:51:27.014491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> For Loss","metadata":{}},{"cell_type":"code","source":"plt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training & Validation loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T09:52:50.82052Z","iopub.execute_input":"2022-04-23T09:52:50.821108Z","iopub.status.idle":"2022-04-23T09:52:51.048695Z","shell.execute_reply.started":"2022-04-23T09:52:50.821069Z","shell.execute_reply":"2022-04-23T09:52:51.047985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# THE END","metadata":{}}]}