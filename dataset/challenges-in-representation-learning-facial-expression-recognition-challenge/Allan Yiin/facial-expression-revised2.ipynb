{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#這是jupyter notebook的magic word˙\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom IPython import display","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-23T12:04:59.241878Z","iopub.execute_input":"2021-10-23T12:04:59.2423Z","iopub.status.idle":"2021-10-23T12:04:59.348494Z","shell.execute_reply.started":"2021-10-23T12:04:59.242193Z","shell.execute_reply":"2021-10-23T12:04:59.347776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n#判斷是否在jupyter notebook上\ndef is_in_ipython():\n    \"Is the code running in the ipython environment (jupyter including)\"\n    program_name = os.path.basename(os.getenv('_', ''))\n\n    if ('jupyter-notebook' in program_name or # jupyter-notebook\n        'ipython'          in program_name or # ipython\n        'jupyter' in program_name or  # jupyter\n        'JPY_PARENT_PID'   in os.environ):    # ipython-notebook\n        return True\n    else:\n        return False\n\n\n#判斷是否在colab上\ndef is_in_colab():\n    if not is_in_ipython(): return False\n    try:\n        from google import colab\n        return True\n    except: return False\n\n#判斷是否在kaggke_kernal上\ndef is_in_kaggle_kernal():\n    if 'kaggle' in os.environ['PYTHONPATH']:\n        return True\n    else:\n        return False\n\nif is_in_colab():\n    from google.colab import drive\n    drive.mount('/content/gdrive')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:04:59.35017Z","iopub.execute_input":"2021-10-23T12:04:59.350517Z","iopub.status.idle":"2021-10-23T12:04:59.360569Z","shell.execute_reply.started":"2021-10-23T12:04:59.35048Z","shell.execute_reply":"2021-10-23T12:04:59.359798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ['TRIDENT_BACKEND'] = 'pytorch'\n\nif is_in_kaggle_kernal():\n    os.environ['TRIDENT_HOME'] = './trident'\n    \nelif is_in_colab():\n    os.environ['TRIDENT_HOME'] = '/content/gdrive/My Drive/trident'\n\n#為確保安裝最新版 \n\n!pip uninstall tridentx -y\n!pip install ../input/trident/tridentx-0.7.3.21-py3-none-any.whl --upgrade\n#!pip install cupy\n\nimport json\nimport copy\nimport numpy as np\n#調用trident api\nimport trident as T\nfrom trident import *\n\nfrom trident.layers.pytorch_initializers import orthogonal\nimport random\nfrom tqdm import tqdm\nimport glob\nimport scipy\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:04:59.362843Z","iopub.execute_input":"2021-10-23T12:04:59.365541Z","iopub.status.idle":"2021-10-23T12:05:22.49964Z","shell.execute_reply.started":"2021-10-23T12:04:59.365513Z","shell.execute_reply":"2021-10-23T12:05:22.498806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"這比賽是基於\n0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:05:22.501243Z","iopub.execute_input":"2021-10-23T12:05:22.501502Z","iopub.status.idle":"2021-10-23T12:05:29.444309Z","shell.execute_reply.started":"2021-10-23T12:05:22.501462Z","shell.execute_reply":"2021-10-23T12:05:29.443583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts = train_df['emotion'].value_counts().to_dict()\nprint(counts)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:05:29.446719Z","iopub.execute_input":"2021-10-23T12:05:29.447136Z","iopub.status.idle":"2021-10-23T12:05:29.455512Z","shell.execute_reply.started":"2021-10-23T12:05:29.447101Z","shell.execute_reply":"2021-10-23T12:05:29.454578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df\n\n\ndata=open('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv','r',encoding='utf-8-sig').readlines()\nprint(len(data))\narray2image(np.array(eval('['+data[1].split(',')[-1].replace(' ',', ')+']')).reshape((48,48)))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:05:29.457217Z","iopub.execute_input":"2021-10-23T12:05:29.457502Z","iopub.status.idle":"2021-10-23T12:05:29.940829Z","shell.execute_reply.started":"2021-10-23T12:05:29.457469Z","shell.execute_reply":"2021-10-23T12:05:29.939905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions=[]\nimages=[]\ntest_emotions=[]\ntest_images=[]\nfor i in tqdm(range(len(data)-1)):\n    row=data[i+1]\n    cols=row.split(',')\n    if cols[1]=='Training':\n        emotions.append(int(cols[0]))\n        images.append(np.array(eval('['+cols[-1].replace(' ',', ')+']')).reshape((48,48,1)).astype(np.float32))\n    else:\n        test_emotions.append(int(cols[0]))\n        test_images.append(np.array(eval('['+cols[-1].replace(' ',', ')+']')).reshape((48,48,1)).astype(np.float32))\n        \n\nprint(len(emotions))\nprint(len(images))\nprint(len(test_emotions))\nprint(len(test_images))\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:05:29.942204Z","iopub.execute_input":"2021-10-23T12:05:29.942561Z","iopub.status.idle":"2021-10-23T12:07:37.769839Z","shell.execute_reply.started":"2021-10-23T12:05:29.94252Z","shell.execute_reply":"2021-10-23T12:07:37.768947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在上一版分析中發現，disgust(1)這種表情因為數量過少，因此決策邊界不明確而成為效度提升的最大問題點，因此在這版中我刻意把disgust案例挑選出來，並且增量5後被放入樣本(只放訓練集，測試集不動)，希望能透過樣本數增加來強化它的決策邊界。","metadata":{}},{"cell_type":"code","source":"label_dict=OrderedDict()\ntest_label_dict=OrderedDict()\ndisgust_images1=[]\ndisgust_emotions1=[]\nfor lab,img in zip(emotions,images):\n    if lab not in label_dict:\n        label_dict[lab]=1\n    else:\n        label_dict[lab]+=1\n    if lab==1:\n        disgust_images1.append(img)\n        disgust_emotions1.append(lab)\ntest_disgust_images1=[]\ntest_disgust_emotions1=[]        \nfor lab,img in zip(test_emotions,test_images):\n    if lab not in test_label_dict:\n        test_label_dict[lab]=1\n    else:\n        test_label_dict[lab]+=1\n    if lab==1:\n        test_disgust_images1.append(img)\n        test_disgust_emotions1.append(lab)\nprint(len(disgust_images1))\nprint(label_dict)\nprint(test_label_dict)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:37.771243Z","iopub.execute_input":"2021-10-23T12:07:37.771698Z","iopub.status.idle":"2021-10-23T12:07:37.798171Z","shell.execute_reply.started":"2021-10-23T12:07:37.771644Z","shell.execute_reply":"2021-10-23T12:07:37.797305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在數據增強部分，像教於上一個案例，我們加入了仿設轉換，以及CLAHE(限制對比度自適應直方圖均衡化)，後者可以強化圖片的對比均衡，能夠將細微的肌肉線條更為凸顯，以便獲取五官以外的肌肉紋理特徵。","metadata":{}},{"cell_type":"code","source":"ds1=ImageDataset(images+5*disgust_images1,symbol='images')\nds2=LabelDataset(emotions+5*disgust_emotions1,symbol='emotions_label')\nds2.class_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ntest_ds1=ImageDataset(test_images,symbol='images')\ntest_ds2=LabelDataset(test_emotions,symbol='emotions_label')\ntest_ds2.class_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndata_provider=DataProvider(traindata=Iterator(data=ds1,label=ds2),testdata=Iterator(data=test_ds1,label=test_ds2))\n\n\ndata_provider.traindata.data.image_transform_funcs=[\n    ToRGB(),\n    Resize(output_size=(112,112)),\n    CLAHE(),\n    RandomTransform(rotation_range=25,zoom_range=0.1, shift_range=0.05,  shear_range= 0.1,random_flip= 0.3),\n    RandomAdjustGamma(gamma_range=(0.6,1.4)),\n    RandomAdjustContrast(value_range=(0.6,1.4)),\n    RandomAdjustHue(value_range=(-0.3,0.3)),#調整色相\n    RandomAdjustSaturation(value_range=(0.6,1.4)),#調整飽和度\n    RandomBlur(ksize_range=(3,7)),#隨機模糊\n    SaltPepperNoise(prob=0.001),#椒鹽噪音\n    RandomErasing(size_range=(0.08,0.2),transparency_range=(0.4,0.6),transparancy_ratio=0.8),\n    Normalize(127.5,127.5)]\n\n\ndata_provider.testdata.data.image_transform_funcs=[\n    ToRGB(),\n    Resize(output_size=(112,112)),\n    CLAHE(),\n    Normalize(127.5,127.5)]","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:37.799839Z","iopub.execute_input":"2021-10-23T12:07:37.800145Z","iopub.status.idle":"2021-10-23T12:07:37.823731Z","shell.execute_reply.started":"2021-10-23T12:07:37.800111Z","shell.execute_reply":"2021-10-23T12:07:37.822896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_data,emotion_data=data_provider.next()\nprint(img_data.shape,img_data.mean())\nprint(emotion_data.shape)\ntest_img_data,test_emotion_data=data_provider.next_test()\nprint(test_img_data.shape,test_img_data.mean())\ndata_provider.preview_images()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:37.825261Z","iopub.execute_input":"2021-10-23T12:07:37.82551Z","iopub.status.idle":"2021-10-23T12:07:38.106838Z","shell.execute_reply.started":"2021-10-23T12:07:37.825479Z","shell.execute_reply":"2021-10-23T12:07:38.106122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"這次的骨幹是基於「口罩人臉識別」實作的成果，等於是arcFace再加上理解特徵點幾何位置的能力，以及復原臉部的腦捕能力的骨幹。由於表情與特徵點息息相關，因此使用這個骨幹效果會比一般骨幹來的更好。首先建構與「口罩人臉識別」相同的模型結構，並且載入訓練權重。","metadata":{}},{"cell_type":"code","source":"from trident.models import arcfacenet\nnum_faces=10575\n#標準生成結構\n#不包含原有分類器\nse_resnet50 =arcfacenet.SEResNet_IR_50_512(include_top=False,\n             pretrained=True,\n             freeze_features=True,\n             input_shape=(3,112,112))\n\nse_resnet50.model.trainable=False\nse_resnet50.model.add_module('last_conv',Conv2d((1,1),7,strides=1,auto_pad=True,use_bias=False,activation=None))\nse_resnet50.model.add_module('pool',GlobalAvgPool2d())\nse_resnet50.model.add_module('fc',Dense(7))\nse_resnet50.model.add_module('softmax',SoftMax(-1,add_noise=True,noise_intensity=0.08))\n\nse_resnet50.model.pool.keep_output=True\n\nis_resume=False\nif is_resume and os.path.exists('./Models/emotions_dtection.pth'):\n    se_resnet50.load_model('./Models/emotions_dtection.pth')\n    print('./Models/emotions_dtection.pth loaded')\nelse:\n    if os.path.exists('../input/facial-expression/Models/emotions_dtection.pth'):\n        se_resnet50.load_model('../input/facial-expression/Models/emotions_dtection.pth')\nse_resnet50.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:38.10824Z","iopub.execute_input":"2021-10-23T12:07:38.108541Z","iopub.status.idle":"2021-10-23T12:07:48.688454Z","shell.execute_reply.started":"2021-10-23T12:07:38.108503Z","shell.execute_reply":"2021-10-23T12:07:48.687744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"將整個模型設定為不可訓練，移除掉最後一層的head，然後依序加入一層通道數為7的卷積層，再透過GlobalAvgPool2d移除掉空間維度，再加上全連接層以及SoftMax即可完成第一個fintune的模型。","metadata":{}},{"cell_type":"markdown","source":"為了能夠有效的比較各種技巧對於模型效果的差異，我在此又建構了第二個finetune model","metadata":{}},{"cell_type":"code","source":"#標準生成結構\n#不包含原有分類器\nse_resnet50_2 =arcfacenet.SEResNet_IR_50_512(include_top=False,\n             pretrained=True,\n             freeze_features=True,\n             input_shape=(3,112,112))\n\nse_resnet50_2.model.trainable=False\n\n\n\n\n\nis_resume=False\nif is_resume and os.path.exists('./Models/emotions_dtection2.pth'):\n    se_resnet50_2.load_model('./Models/emotions_dtection2.pth')\n    print('./Models/emotions_dtection2.pth loaded')\nelse:\n    if os.path.exists('../input/facial-expression/Models/emotions_dtection.pth'):\n        se_resnet50_2.load_model('../input/facial-expression/Models/emotions_dtection.pth')\n\n        \nse_resnet50_2.model.add_module('last_conv',Conv2d((1,1),512,strides=1,auto_pad=True,use_bias=False,activation=None))\nse_resnet50_2.model.add_module('pool',GlobalAvgPool2d())\nse_resnet50_2.model.pool.keep_output=True\n\nclassifier=Sequential(\n    Dense(7,name='fc'),\n    SoftMax(-1,add_noise=True,noise_intensity=0.08,name='softmax'))\n\nhead=ModuleDict({'classifier':classifier,\n                    'features':Identity()\n                    },is_multicasting=True)\n\nse_resnet50_2.model.add_module('head',head)\n\n\nif is_resume and os.path.exists('./Models/emotions_dtection2.pth'):\n    se_resnet50_2.load_model('./Models/emotions_dtection2.pth')\n    print('./Models/emotions_dtection2.pth loaded')\n    \nse_resnet50_2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:48.689937Z","iopub.execute_input":"2021-10-23T12:07:48.690207Z","iopub.status.idle":"2021-10-23T12:07:50.473631Z","shell.execute_reply.started":"2021-10-23T12:07:48.690173Z","shell.execute_reply":"2021-10-23T12:07:50.472954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"其中最大的差異在於加入了類別活化映射模組(Class Activation Mapping, CAM)，基本上這等於是特徵內的注意力機制，我們首先透過一個卷積層將通道數降為7(等於分類類別數)，然後再將輸出複製一份，透過GlobalAvgPool2d將它去重空間維度後，再透過1x1卷積再變為二為空間結構，再與原來的輸出進行點乘後，透過Sigmoid將其數值確保介於0\\~1之間，這樣的結構可以強化通道與類別的偶和強度，來獲得更好的分類效果。","metadata":{}},{"cell_type":"markdown","source":"透過撰寫以training_context為引數的函數，搭配模型的trigger_when，就可以輕鬆地在學習階段與指定時點，執行指定的任務，我們在與預計在第5,10個epoch開始，開放兩層網路的權重供其訓練。","metadata":{}},{"cell_type":"code","source":"def unfreeze(training_context):\n    if training_context['steps']==0:\n        training_context['current_model'].body[23].trainable=True\n        training_context['current_model'].body[22].trainable=True","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:50.476269Z","iopub.execute_input":"2021-10-23T12:07:50.476478Z","iopub.status.idle":"2021-10-23T12:07:50.482834Z","shell.execute_reply.started":"2021-10-23T12:07:50.476453Z","shell.execute_reply":"2021-10-23T12:07:50.482088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom trident.callbacks.lr_schedulers import AdjustLRCallbackBase\n\nclass PolyLR(AdjustLRCallbackBase):\n    def __init__(self,max_lr=1e-3,  max_iter=10000):\n        super().__init__()\n        self.max_lr = max_lr\n        self.max_iter=max_iter\n    def on_batch_end(self, training_context):\n        current_step =training_context['steps']\n        lr = self.max_lr * (1 - (current_step/ self.max_iter)) * (1 - (current_step / self.max_iter))\n        if (lr < 1.0e-7):\n            lr = 1.0e-7\n        self.adjust_learning_rate(training_context, lr, verbose=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:50.486763Z","iopub.execute_input":"2021-10-23T12:07:50.486999Z","iopub.status.idle":"2021-10-23T12:07:50.495156Z","shell.execute_reply.started":"2021-10-23T12:07:50.486974Z","shell.execute_reply":"2021-10-23T12:07:50.494303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nse_resnet50.with_optimizer(optimizer=DiffGrad, lr=5e-4, betas=(0.9, 0.999),gradient_centralization='all') \\\n    .with_loss(CrossEntropyLoss(label_smooth=True)) \\\n    .with_metric(accuracy, name='accuracy') \\\n    .with_regularizer('l2',reg_weight=1e-5) \\\n    .with_accumulate_grads(10)\\\n    .with_model_save_path('./Models/emotions_dtection.pth')\\\n    .trigger_when(when='on_batch_end',frequency=1,unit='batch',action=unfreeze)\\\n    .with_automatic_mixed_precision_training()\\\n    .with_learning_rate_scheduler(PolyLR(max_lr=5e-4,max_iter=3000))\\\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:50.496617Z","iopub.execute_input":"2021-10-23T12:07:50.496914Z","iopub.status.idle":"2021-10-23T12:07:50.51932Z","shell.execute_reply.started":"2021-10-23T12:07:50.496879Z","shell.execute_reply":"2021-10-23T12:07:50.518448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在第二個finetune模型中，我還加入了center_loss，它有助於將決策邊界變得更清晰。","metadata":{}},{"cell_type":"code","source":"\ndef class_accuracy(classifier,target):\n    return accuracy(classifier,target)\n\ncenter_loss=CenterLoss(num_classes=7, feat_dim=512)\n    \nse_resnet50_2.with_optimizer(optimizer=AdaBelief, lr=1e-3, betas=(0.9, 0.999),gradient_centralization='all') \\\n    .with_loss(CrossEntropyLoss(auto_balance=True,input_names=['classifier','target'])) \\\n    .with_loss(center_loss, loss_weight=0.2) \\\n    .with_metric(class_accuracy, name='accuracy') \\\n    .with_regularizer('l2',reg_weight=1e-5) \\\n    .with_accumulate_grads(10)\\\n    .with_model_save_path('./Models/emotions_dtection2.pth')\\\n    .with_learning_rate_scheduler(PolyLR(max_lr=1e-3,max_iter=3000))\\\n    .trigger_when(when='on_batch_end',frequency=1,unit='batch',action=unfreeze)\\\n\n\n#把center loss的中心點權重納入優化器\nse_resnet50_2.optimizer.param_groups[0]['params'].append(center_loss.centers)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:50.520654Z","iopub.execute_input":"2021-10-23T12:07:50.520984Z","iopub.status.idle":"2021-10-23T12:07:50.546217Z","shell.execute_reply.started":"2021-10-23T12:07:50.520946Z","shell.execute_reply":"2021-10-23T12:07:50.545191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\nplan=TrainingPlan()\\\n    .add_training_item(se_resnet50, name='arcface')\\\n    .add_training_item(se_resnet50_2, name='arcface2')\\\n    .with_data_loader(data_provider)\\\n    .repeat_epochs(15)\\\n    .with_batch_size(64)\\\n    .print_progress_scheduling(10,unit='batch')\\\n    .out_sample_evaluation_scheduling(100,unit='batch')\\\n    .display_loss_metric_curve_scheduling(200,unit='batch',imshow=True)\\\n    .save_model_scheduling(50,unit='batch')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:50.54903Z","iopub.execute_input":"2021-10-23T12:07:50.549233Z","iopub.status.idle":"2021-10-23T12:07:50.555354Z","shell.execute_reply.started":"2021-10-23T12:07:50.549211Z","shell.execute_reply":"2021-10-23T12:07:50.55457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plan.start_now()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:07:50.557062Z","iopub.execute_input":"2021-10-23T12:07:50.557603Z","iopub.status.idle":"2021-10-23T13:44:51.881218Z","shell.execute_reply.started":"2021-10-23T12:07:50.557563Z","shell.execute_reply":"2021-10-23T13:44:51.880324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import manifold\ncolors = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff',\n         '#ff00ff', '#990000', '#999900', '#009900', '#009999']\n\nemotions_legend=['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']\n\nfeatures=[]\nfeatures2=[]\nemotion_data=[]\nfor n in range(10):\n    img_data2,emotion_data2=data_provider.next()\n    se_resnet50.model.eval()\n    se_resnet50_2.model.eval()\n    out=se_resnet50.model(to_tensor(img_data2))\n    out2=se_resnet50_2.model(to_tensor(img_data2))\n    emotion_data.append(to_numpy(emotion_data2))\n    features.append(to_numpy(se_resnet50.model.pool.output))\n    features2.append(to_numpy(se_resnet50_2.model.pool.output))\nemotion_data=np.concatenate(emotion_data,axis=0)\nfeatures=np.concatenate(features,axis=0)\nfeatures2=np.concatenate(features2,axis=0)\n\ntsne = manifold.TSNE(n_components=2, init='random',metric='cosine', random_state=0)  # 利用t-sne將512特徵向量降維至2\nfeatures_tsne = tsne.fit_transform(features)\nfeatures_tsne=l2_normalize(features_tsne)\n\ntsne2 = manifold.TSNE(n_components=2, init='random',metric='cosine', random_state=0)  # 利用t-sne將512特徵向量降維至2\nfeatures_tsne2 = tsne2.fit_transform(features2)\nfeatures_tsne2=l2_normalize(features_tsne2)\n\nfig = plt.figure(figsize=(18,8))\n    \nax1= fig.add_subplot(1, 2, 1)\nfor i in range(7):\n    x_i = features_tsne[:,0][emotion_data==i]\n    y_i = features_tsne[:,1][emotion_data==i]\n    ax1.scatter(x_i,y_i,s=100,marker='o',c=colors[i])\n\nax2= fig.add_subplot(1, 2, 2)\nfor i in range(7):\n    x_i = features_tsne2[:,0][emotion_data==i]\n    y_i = features_tsne2[:,1][emotion_data==i]\n    ax2.scatter(x_i,y_i,s=100,marker='o',c=colors[i])\n    \nplt.legend(emotions_legend, loc ='lower left')\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:44:51.882971Z","iopub.execute_input":"2021-10-23T13:44:51.883272Z","iopub.status.idle":"2021-10-23T13:45:06.190591Z","shell.execute_reply.started":"2021-10-23T13:44:51.883236Z","shell.execute_reply":"2021-10-23T13:45:06.189868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"我們看一下基於前面版本所繪製出來的決策邊界圖如下，很明顯的Disgust出現的比例少而且被淹沒在其他情緒中。這很明顯是個不均衡的分布。\n\n<img src='https://docs.google.com/uc?export=download&id=1dPOpAlV06PwncZtYl_pRKKq_-QYSbqyT'/>","metadata":{}}]}