{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#這是jupyter notebook的magic word˙\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom IPython import display","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-17T13:16:04.900023Z","iopub.execute_input":"2021-10-17T13:16:04.900653Z","iopub.status.idle":"2021-10-17T13:16:05.001275Z","shell.execute_reply.started":"2021-10-17T13:16:04.900561Z","shell.execute_reply":"2021-10-17T13:16:05.000646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n#判斷是否在jupyter notebook上\ndef is_in_ipython():\n    \"Is the code running in the ipython environment (jupyter including)\"\n    program_name = os.path.basename(os.getenv('_', ''))\n\n    if ('jupyter-notebook' in program_name or # jupyter-notebook\n        'ipython'          in program_name or # ipython\n        'jupyter' in program_name or  # jupyter\n        'JPY_PARENT_PID'   in os.environ):    # ipython-notebook\n        return True\n    else:\n        return False\n\n\n#判斷是否在colab上\ndef is_in_colab():\n    if not is_in_ipython(): return False\n    try:\n        from google import colab\n        return True\n    except: return False\n\n#判斷是否在kaggke_kernal上\ndef is_in_kaggle_kernal():\n    if 'kaggle' in os.environ['PYTHONPATH']:\n        return True\n    else:\n        return False\n\nif is_in_colab():\n    from google.colab import drive\n    drive.mount('/content/gdrive')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:16:05.002958Z","iopub.execute_input":"2021-10-17T13:16:05.003222Z","iopub.status.idle":"2021-10-17T13:16:05.011275Z","shell.execute_reply.started":"2021-10-17T13:16:05.003189Z","shell.execute_reply":"2021-10-17T13:16:05.010515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ['TRIDENT_BACKEND'] = 'pytorch'\n\nif is_in_kaggle_kernal():\n    os.environ['TRIDENT_HOME'] = './trident'\n    \nelif is_in_colab():\n    os.environ['TRIDENT_HOME'] = '/content/gdrive/My Drive/trident'\n\n#為確保安裝最新版 \n\n!pip uninstall tridentx -y\n!pip install ../input/trident/tridentx-0.7.3.21-py3-none-any.whl --upgrade\n#!pip install cupy\n\nimport json\nimport copy\nimport numpy as np\n#調用trident api\nimport trident as T\nfrom trident import *\n\nfrom trident.layers.pytorch_initializers import orthogonal\nimport random\nfrom tqdm import tqdm\nimport glob\nimport scipy\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:16:05.012687Z","iopub.execute_input":"2021-10-17T13:16:05.013116Z","iopub.status.idle":"2021-10-17T13:16:27.551069Z","shell.execute_reply.started":"2021-10-17T13:16:05.013083Z","shell.execute_reply":"2021-10-17T13:16:27.550308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"這比賽是基於\n0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:16:27.553378Z","iopub.execute_input":"2021-10-17T13:16:27.553654Z","iopub.status.idle":"2021-10-17T13:16:33.441738Z","shell.execute_reply.started":"2021-10-17T13:16:27.553618Z","shell.execute_reply":"2021-10-17T13:16:33.440961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df\n\n\ndata=open('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv','r',encoding='utf-8-sig').readlines()\nprint(len(data))\narray2image(np.array(eval('['+data[1].split(',')[-1].replace(' ',', ')+']')).reshape((48,48)))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:16:33.443172Z","iopub.execute_input":"2021-10-17T13:16:33.443448Z","iopub.status.idle":"2021-10-17T13:16:33.879049Z","shell.execute_reply.started":"2021-10-17T13:16:33.443417Z","shell.execute_reply":"2021-10-17T13:16:33.878154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions=[]\nimages=[]\ntest_emotions=[]\ntest_images=[]\nfor i in tqdm(range(len(data)-1)):\n    row=data[i+1]\n    cols=row.split(',')\n    if cols[1]=='Training':\n        emotions.append(int(cols[0]))\n        images.append(np.array(eval('['+cols[-1].replace(' ',', ')+']')).reshape((48,48,1)).astype(np.float32))\n    else:\n        test_emotions.append(int(cols[0]))\n        test_images.append(np.array(eval('['+cols[-1].replace(' ',', ')+']')).reshape((48,48,1)).astype(np.float32))\n        \n\nprint(len(emotions))\nprint(len(images))\nprint(len(test_emotions))\nprint(len(test_images))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:16:33.880527Z","iopub.execute_input":"2021-10-17T13:16:33.880837Z","iopub.status.idle":"2021-10-17T13:18:39.893359Z","shell.execute_reply.started":"2021-10-17T13:16:33.880787Z","shell.execute_reply":"2021-10-17T13:18:39.892522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在數據增強部分，像教於上一個案例，我們加入了仿設轉換，以及CLAHE(限制對比度自適應直方圖均衡化)，後者可以強化圖片的對比均衡，能夠將細微的肌肉線條更為凸顯，以便獲取五官以外的肌肉紋理特徵。","metadata":{}},{"cell_type":"code","source":"ds1=ImageDataset(images,symbol='images')\nds2=LabelDataset(emotions,symbol='emotions_label')\nds2.class_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ntest_ds1=ImageDataset(test_images,symbol='images')\ntest_ds2=LabelDataset(test_emotions,symbol='emotions_label')\ntest_ds2.class_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndata_provider=DataProvider(traindata=Iterator(data=ds1,label=ds2),testdata=Iterator(data=test_ds1,label=test_ds2))\n\n\ndata_provider.image_transform_funcs=[\n    ToRGB(),\n    Resize(output_size=(112,112)),\n    CLAHE(),\n    RandomTransform(rotation_range=15,zoom_range=0.1, shift_range=0.05,  shear_range= 0.1,random_flip= 0.3),\n    RandomAdjustGamma(gamma_range=(0.6,1.4)),\n    RandomAdjustContrast(value_range=(0.6,1.4)),\n    RandomAdjustHue(scale=(-0.3,0.3)),#調整色相\n    RandomAdjustSaturation(scale=(0.6,1.4)),#調整飽和度\n    RandomBlur(scale=(3,7)),#隨機模糊\n    SaltPepperNoise(prob=0.001),#椒鹽噪音\n    RandomErasing(size_range=(0.08,0.2),transparency_range=(0.4,0.6),transparancy_ratio=0.8),\n    Normalize(127.5,127.5)]\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:18:39.89464Z","iopub.execute_input":"2021-10-17T13:18:39.894903Z","iopub.status.idle":"2021-10-17T13:18:39.912608Z","shell.execute_reply.started":"2021-10-17T13:18:39.894872Z","shell.execute_reply":"2021-10-17T13:18:39.911866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_data,emotion_data=data_provider.next()\nprint(img_data.shape)\nprint(emotion_data.shape)\n\ndata_provider.preview_images()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:18:39.913876Z","iopub.execute_input":"2021-10-17T13:18:39.914191Z","iopub.status.idle":"2021-10-17T13:18:40.229113Z","shell.execute_reply.started":"2021-10-17T13:18:39.914143Z","shell.execute_reply":"2021-10-17T13:18:40.228448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"這次的骨幹是基於「口罩人臉識別」實作的成果，等於是arcFace再加上理解特徵點幾何位置的能力，以及復原臉部的腦捕能力的骨幹。由於表情與特徵點息息相關，因此使用這個骨幹效果會比一般骨幹來的更好。首先建構與「口罩人臉識別」相同的模型結構，並且載入訓練權重。","metadata":{}},{"cell_type":"code","source":"from trident.models import arcfacenet\nnum_faces=10575\n#標準生成結構\n#不包含原有分類器\nse_resnet50 =arcfacenet.SEResNet_IR_50_512(include_top=False,\n             pretrained=True,\n             freeze_features=True,\n             input_shape=(3,112,112))\n\n#加入output_layer\nse_resnet50.model.add_module('output_layer', \n    Sequential(\n        Dropout(dropout_rate=0.4),\n        Flatten(),\n        Dense((512),use_bias=False,keep_output=True),\n    ))\n\n#se_resnet50.model.output_layer[0].inplace = False\nse_resnet50.model.add_module('l2norm',L2Norm())\nse_resnet50.model.add_module('fc',Dense((num_faces),use_bias=False,weights_norm='l2'))\n\n\n#fc_weight=se_resnet50.model[-1].weight.data        \nface_head=Sequential(se_resnet50.model[-3:])\n\nlandmark_head=Sequential(\n    Conv2d((3,3),68*2,strides=1,auto_pad=True,activation='sigmoid',use_bias=False),\n    GlobalAvgPool2d()\n        )\n\ndecoder=Sequential(\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False) ,#((128,7,7))\n        Upsampling2d(scale_factor=2,mode='pixel_shuffle'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False),#(128,14,14)\n        Upsampling2d(scale_factor=2,mode='pixel_shuffle'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False,dropout_rate=0.2),#(128,28,28)\n        Upsampling2d(scale_factor=2,mode='pixel_shuffle'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False),#(128,56,56)\n        Upsampling2d(scale_factor=2,mode='bicubic'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False),#(128,112,112)\n        Conv2d((1,1),3,strides=1,auto_pad=True,activation='tanh',use_bias=False)\n    )\n\n\nhead=ModuleDict({'class_pred':face_head,\n                    'landmark_pred':landmark_head,\n                    'face_restructure':decoder\n                    },is_multicasting=True)\nse_resnet50.model.remove_at(-1)\nse_resnet50.model.remove_at(-1)\nse_resnet50.model.remove_at(-1)\nse_resnet50.model.add_module('head',head)\n\nis_resume=False\nif is_resume and os.path.exists('./Models/arcface_with_mask.pth'):\n    se_resnet50.load_model('./Models/arcface_with_mask.pth')\n    print('./Models/arcface_with_mask.pth loaded')\nelse:\n    if os.path.exists('../input/face-recognition-with-mask/Models/arcface_with_mask.pth'):\n        se_resnet50.load_model('../input/face-recognition-with-mask/Models/arcface_with_mask.pth')\nse_resnet50.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:41.134699Z","iopub.execute_input":"2021-10-17T14:54:41.135082Z","iopub.status.idle":"2021-10-17T14:54:43.110929Z","shell.execute_reply.started":"2021-10-17T14:54:41.135039Z","shell.execute_reply":"2021-10-17T14:54:43.110088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"將整個模型設定為不可訓練，移除掉最後一層的head，然後依序加入一層通道數為7的卷積層，再透過GlobalAvgPool2d移除掉空間維度，再加上全連接層以及SoftMax即可完成第一個fintune的模型。","metadata":{}},{"cell_type":"code","source":"se_resnet50.model.trainable=False\nse_resnet50.model.remove_at(-1)\nse_resnet50.model.add_module('last_conv',Conv2d((1,1),7,strides=1,auto_pad=True,use_bias=False,activation=None))\nse_resnet50.model.add_module('pool',GlobalAvgPool2d())\nse_resnet50.model.add_module('fc',Dense(7))\nse_resnet50.model.add_module('softmax',SoftMax(-1,add_noise=True,noise_intensity=0.08))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:43.114183Z","iopub.execute_input":"2021-10-17T14:54:43.114414Z","iopub.status.idle":"2021-10-17T14:54:43.138927Z","shell.execute_reply.started":"2021-10-17T14:54:43.114389Z","shell.execute_reply":"2021-10-17T14:54:43.137968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"se_resnet50.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:43.141676Z","iopub.execute_input":"2021-10-17T14:54:43.142949Z","iopub.status.idle":"2021-10-17T14:54:43.290034Z","shell.execute_reply.started":"2021-10-17T14:54:43.142911Z","shell.execute_reply":"2021-10-17T14:54:43.289406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"為了能夠有效的比較各種技巧對於模型效果的差異，我在此又建構了第二個finetune model","metadata":{}},{"cell_type":"code","source":"#標準生成結構\n#不包含原有分類器\nse_resnet50_2 =arcfacenet.SEResNet_IR_50_512(include_top=False,\n             pretrained=True,\n             freeze_features=True,\n             input_shape=(3,112,112))\n\n#加入output_layer\nse_resnet50_2.model.add_module('output_layer', \n    Sequential(\n        Dropout(dropout_rate=0.4),\n        Flatten(),\n        Dense((512),use_bias=False,keep_output=True),\n    ))\n\n#se_resnet50.model.output_layer[0].inplace = False\nse_resnet50_2.model.add_module('l2norm',L2Norm())\nse_resnet50_2.model.add_module('fc',Dense((num_faces),use_bias=False,weights_norm='l2'))\n\n\n#fc_weight=se_resnet50.model[-1].weight.data        \nface_head2=Sequential(se_resnet50_2.model[-3:])\n\nlandmark_head2=Sequential(\n    Conv2d((3,3),68*2,strides=1,auto_pad=True,activation='sigmoid',use_bias=False),\n    GlobalAvgPool2d()\n        )\n\ndecoder2=Sequential(\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False) ,#((128,7,7))\n        Upsampling2d(scale_factor=2,mode='pixel_shuffle'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False),#(128,14,14)\n        Upsampling2d(scale_factor=2,mode='pixel_shuffle'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False,dropout_rate=0.2),#(128,28,28)\n        Upsampling2d(scale_factor=2,mode='pixel_shuffle'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False),#(128,56,56)\n        Upsampling2d(scale_factor=2,mode='bicubic'),\n        Conv2d_Block((3,3),128,strides=1,auto_pad=True,activation='leaky_relu',normalization='batch',use_bias=False),#(128,112,112)\n        Conv2d((1,1),3,strides=1,auto_pad=True,activation='tanh',use_bias=False)\n    )\n\n\nhead2=ModuleDict({'class_pred':face_head2,\n                    'landmark_pred':landmark_head2,\n                    'face_restructure':decoder2\n                    },is_multicasting=True)\nse_resnet50_2.model.remove_at(-1)\nse_resnet50_2.model.remove_at(-1)\nse_resnet50_2.model.remove_at(-1)\nse_resnet50_2.model.add_module('head',head2)\n\nis_resume=False\nif is_resume and os.path.exists('./Models/arcface_with_mask.pth'):\n    se_resnet50_2.load_model('./Models/arcface_with_mask.pth')\n    print('./Models/arcface_with_mask.pth loaded')\nelse:\n    if os.path.exists('../input/face-recognition-with-mask/Models/arcface_with_mask.pth'):\n        se_resnet50_2.load_model('../input/face-recognition-with-mask/Models/arcface_with_mask.pth')\nse_resnet50_2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:43.29316Z","iopub.execute_input":"2021-10-17T14:54:43.293357Z","iopub.status.idle":"2021-10-17T14:54:45.8334Z","shell.execute_reply.started":"2021-10-17T14:54:43.293329Z","shell.execute_reply":"2021-10-17T14:54:45.832749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"其中最大的差異在於加入了類別活化映射模組(Class Activation Mapping, CAM)，基本上這等於是特徵內的注意力機制，我們首先透過一個卷積層將通道數降為7(等於分類類別數)，然後再將輸出複製一份，透過GlobalAvgPool2d將它去重空間維度後，再透過1x1卷積再變為二為空間結構，再與原來的輸出進行點乘後，透過Sigmoid將其數值確保介於0\\~1之間，這樣的結構可以強化通道與類別的偶和強度，來獲得更好的分類效果。","metadata":{}},{"cell_type":"code","source":"se_resnet50_2.model.trainable=False\nse_resnet50_2.model.remove_at(-1)\nse_resnet50_2.model.add_module('last_conv',Conv2d_Block((3,3),num_filters=7,use_bias=False,activation=None, normalization='l2'))\nse_resnet50_2.model.add_module('dropout',Dropout(0.2))\ncam=ShortCut(\n    Identity(),\n    Sequential(\n    GlobalAvgPool2d(),\n    Reshape((7,1,1)),\n    Conv2d((1,1),num_filters=7,use_bias=False,activation=None)\n    )\n,mode='dot'\n)\n\nse_resnet50_2.model.add_module('cam',cam)\nse_resnet50_2.model.add_module('aggregate',Aggregation('sum',axis=[2,3]))\nse_resnet50_2.model.add_module('reshape',Reshape((7)))\nse_resnet50_2.model.add_module('sigmoid',Sigmoid())\nse_resnet50_2.model.add_module('fc',Dense((7)))\nse_resnet50_2.model.add_module('softmax',SoftMax(axis=-1,add_noise=True,noise_intensity=0.08))\nse_resnet50_2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:45.834591Z","iopub.execute_input":"2021-10-17T14:54:45.834964Z","iopub.status.idle":"2021-10-17T14:54:46.008916Z","shell.execute_reply.started":"2021-10-17T14:54:45.834928Z","shell.execute_reply":"2021-10-17T14:54:46.008269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"透過撰寫以training_context為引數的函數，搭配模型的trigger_when，就可以輕鬆地在學習階段與指定時點，執行指定的任務，我們在與預計在第5,10個epoch開始，開放兩層網路的權重供其訓練。","metadata":{}},{"cell_type":"code","source":"def unfreeze(training_context):\n    \n    if training_context['steps']==450*5:\n        training_context['current_model'].body[23].trainable=True\n    if training_context['steps']==450*10:\n        training_context['current_model'].body[22].trainable=True","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:46.009938Z","iopub.execute_input":"2021-10-17T14:54:46.010191Z","iopub.status.idle":"2021-10-17T14:54:46.017741Z","shell.execute_reply.started":"2021-10-17T14:54:46.010157Z","shell.execute_reply":"2021-10-17T14:54:46.017034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nse_resnet50.with_optimizer(optimizer=DiffGrad, lr=1e-3, betas=(0.9, 0.999),gradient_centralization='all') \\\n    .with_loss(CrossEntropyLoss(label_smooth=True)) \\\n    .with_metric(accuracy, name='accuracy') \\\n    .with_regularizer('l2',reg_weight=1e-5) \\\n    .with_accumulate_grads(10)\\\n    .with_model_save_path('./Models/emotions_dtection.pth')\\\n    .with_callbacks(PrintGradientsCallback(frequency=500)) \\\n    .trigger_when(when='on_batch_end',frequency=1,unit='batch',action=unfreeze)\\\n    .with_automatic_mixed_precision_training()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:46.020991Z","iopub.execute_input":"2021-10-17T14:54:46.021227Z","iopub.status.idle":"2021-10-17T14:54:46.040037Z","shell.execute_reply.started":"2021-10-17T14:54:46.021203Z","shell.execute_reply":"2021-10-17T14:54:46.039131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在第二個finetune模型中，我還加入了Mixup機制，也就是一次將兩張圖積於透明度混合，而最後標籤則是由兩張圖均分。這技術有助於緩解softmax的缺陷，","metadata":{}},{"cell_type":"code","source":"\nse_resnet50_2.with_optimizer(optimizer=DiffGrad, lr=1e-3, betas=(0.9, 0.999),gradient_centralization='all') \\\n    .with_loss(CrossEntropyLoss(label_smooth=True)) \\\n    .with_metric(accuracy, name='accuracy') \\\n    .with_regularizer('l2',reg_weight=1e-5) \\\n    .with_accumulate_grads(10)\\\n    .with_model_save_path('./Models/emotions_dtection2.pth')\\\n    .with_callbacks(PrintGradientsCallback(frequency=500)) \\\n    .with_callbacks(MixupCallback(alpha= 1,loss_criterion=CrossEntropyLoss,loss_weight=0.5))\\\n    .trigger_when(when='on_batch_end',frequency=1,unit='batch',action=unfreeze)\\\n    .with_automatic_mixed_precision_training()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:46.041323Z","iopub.execute_input":"2021-10-17T14:54:46.04158Z","iopub.status.idle":"2021-10-17T14:54:46.057815Z","shell.execute_reply.started":"2021-10-17T14:54:46.041549Z","shell.execute_reply":"2021-10-17T14:54:46.057042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\nplan=TrainingPlan()\\\n    .add_training_item(se_resnet50, name='arcface')\\\n    .add_training_item(se_resnet50_2, name='arcface2')\\\n    .with_data_loader(data_provider)\\\n    .repeat_epochs(300)\\\n    .with_batch_size(64)\\\n    .print_progress_scheduling(10,unit='batch')\\\n    .out_sample_evaluation_scheduling(100,unit='batch')\\\n    .display_loss_metric_curve_scheduling(200,unit='batch',imshow=True)\\\n    .save_model_scheduling(50,unit='batch')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:46.059158Z","iopub.execute_input":"2021-10-17T14:54:46.059401Z","iopub.status.idle":"2021-10-17T14:54:46.066879Z","shell.execute_reply.started":"2021-10-17T14:54:46.059371Z","shell.execute_reply":"2021-10-17T14:54:46.065985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"第二個finetune模型因為有加入dropout以及mixup，初期訓練的效度會比較差，但是隨著訓練到後期，則效果會越來越好，切換回eval模式時，由於不再有dropout，效度還會再次提升。","metadata":{}},{"cell_type":"code","source":"plan.start_now()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T14:54:46.069307Z","iopub.execute_input":"2021-10-17T14:54:46.069589Z"},"trusted":true},"execution_count":null,"outputs":[]}]}