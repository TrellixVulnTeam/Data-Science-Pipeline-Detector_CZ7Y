{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Facial Expression Recognition**\n## **Week 1 Training Notebook**\n### Alejandro Alemany, Sara Manrriquez, and Benjamin Zaretzky","metadata":{}},{"cell_type":"markdown","source":"In this notebook we will build an image classification model to identify the emotion being expressed in the images of human faces.","metadata":{}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"markdown","source":"We import all necessary packages. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:33.103102Z","iopub.execute_input":"2021-12-08T21:56:33.103596Z","iopub.status.idle":"2021-12-08T21:56:34.862987Z","shell.execute_reply.started":"2021-12-08T21:56:33.103536Z","shell.execute_reply":"2021-12-08T21:56:34.862125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Training DataFrame","metadata":{}},{"cell_type":"markdown","source":"We load the training data and view the first 5 rows. ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv')\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:34.867762Z","iopub.execute_input":"2021-12-08T21:56:34.868252Z","iopub.status.idle":"2021-12-08T21:56:36.868533Z","shell.execute_reply.started":"2021-12-08T21:56:34.868203Z","shell.execute_reply":"2021-12-08T21:56:36.867554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:36.870266Z","iopub.execute_input":"2021-12-08T21:56:36.870649Z","iopub.status.idle":"2021-12-08T21:56:36.886477Z","shell.execute_reply.started":"2021-12-08T21:56:36.870604Z","shell.execute_reply":"2021-12-08T21:56:36.885748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Data","metadata":{}},{"cell_type":"markdown","source":"The images for this training set are stored as a string. In order to train the model and visualize the images we need to process these strings into a 4D array of pixel values.","metadata":{}},{"cell_type":"code","source":"train['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48,1) for x in train['pixels']]","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:36.890103Z","iopub.execute_input":"2021-12-08T21:56:36.890403Z","iopub.status.idle":"2021-12-08T21:56:39.738966Z","shell.execute_reply.started":"2021-12-08T21:56:36.890364Z","shell.execute_reply":"2021-12-08T21:56:39.738128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixels = np.concatenate(train['pixels'])\nlabels = train.emotion.values\n\nprint(pixels.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:39.740491Z","iopub.execute_input":"2021-12-08T21:56:39.740771Z","iopub.status.idle":"2021-12-08T21:56:40.020583Z","shell.execute_reply.started":"2021-12-08T21:56:39.740733Z","shell.execute_reply":"2021-12-08T21:56:40.019697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Distribution","metadata":{}},{"cell_type":"markdown","source":"Let's view the distribution of labels. ","metadata":{}},{"cell_type":"code","source":"emotion_prop = (train.emotion.value_counts() / len(train)).to_frame().sort_index(ascending=True)\n\nemotion_prop","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:40.022129Z","iopub.execute_input":"2021-12-08T21:56:40.022597Z","iopub.status.idle":"2021-12-08T21:56:40.034025Z","shell.execute_reply.started":"2021-12-08T21:56:40.022558Z","shell.execute_reply":"2021-12-08T21:56:40.033267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:40.035675Z","iopub.execute_input":"2021-12-08T21:56:40.036171Z","iopub.status.idle":"2021-12-08T21:56:40.044496Z","shell.execute_reply.started":"2021-12-08T21:56:40.036104Z","shell.execute_reply":"2021-12-08T21:56:40.04379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palette = ['orchid', 'lightcoral', 'orange', 'gold', 'lightgreen', 'deepskyblue', 'cornflowerblue']\n\nplt.figure(figsize=[12,6])\n\nplt.bar(x=emotions, height=emotion_prop['emotion'], color=palette, edgecolor='black')\n    \nplt.xlabel('Emotion')\nplt.ylabel('Proportion')\nplt.title('Emotion Label Proportions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:40.046236Z","iopub.execute_input":"2021-12-08T21:56:40.046786Z","iopub.status.idle":"2021-12-08T21:56:40.396773Z","shell.execute_reply.started":"2021-12-08T21:56:40.046747Z","shell.execute_reply":"2021-12-08T21:56:40.396042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the distribution of labels, there is a class imbalance within this training set: the emotion happy accounts for about 25% of the data. ","metadata":{}},{"cell_type":"markdown","source":"## View Sample of Images","metadata":{}},{"cell_type":"markdown","source":"We view a sample of images for each emotion: angry, disgust, fear, happy, sad, surprise, and neutral.","metadata":{}},{"cell_type":"code","source":"plt.close()\nplt.rcParams[\"figure.figsize\"] = [16,16]\n\nrow = 0\nfor emotion in np.unique(labels):\n\n    all_emotion_images = train[train['emotion'] == emotion]\n    for i in range(5):\n        \n        img = all_emotion_images.iloc[i,].pixels.reshape(48,48)\n        lab = emotions[emotion]\n\n        plt.subplot(7,5,row+i+1)\n        plt.imshow(img, cmap='binary_r')\n        plt.text(-30, 5, s = str(lab), fontsize=10, color='b')\n        plt.axis('off')\n    row += 5\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:40.398309Z","iopub.execute_input":"2021-12-08T21:56:40.39883Z","iopub.status.idle":"2021-12-08T21:56:42.083747Z","shell.execute_reply.started":"2021-12-08T21:56:40.398791Z","shell.execute_reply":"2021-12-08T21:56:42.083043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split, Reshape, and Scale Datasets","metadata":{}},{"cell_type":"markdown","source":"We split the data into training and validation sets using a stratified fashion, and scale the pixels values between 0 and 1. ","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(\n    pixels, labels, test_size=0.2, stratify=labels, random_state=1\n)\n\n\nprint('X_train Shape:', X_train.shape)\nprint('y_train Shape:', y_train.shape)\nprint()\nprint('X_valid Shape:', X_valid.shape)\nprint('y_valid Shape:', y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:42.084685Z","iopub.execute_input":"2021-12-08T21:56:42.084906Z","iopub.status.idle":"2021-12-08T21:56:42.26314Z","shell.execute_reply.started":"2021-12-08T21:56:42.084877Z","shell.execute_reply":"2021-12-08T21:56:42.26225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xs_train = X_train / 255\nXs_valid = X_valid / 255","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:42.264582Z","iopub.execute_input":"2021-12-08T21:56:42.264938Z","iopub.status.idle":"2021-12-08T21:56:42.468741Z","shell.execute_reply.started":"2021-12-08T21:56:42.264899Z","shell.execute_reply":"2021-12-08T21:56:42.467944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Network","metadata":{}},{"cell_type":"markdown","source":"We set the seed in order to produce the same results each training run. We build the convolutional neural network using a series of 2D convolution layers followed by densely-connected layers. Additionally, we incorporate max pooling, dropout, and batch normalization. ","metadata":{}},{"cell_type":"code","source":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same', input_shape=(48,48,1)),\n    Conv2D(64, (5,5), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n    \n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    BatchNormalization(),\n    Dense(7, activation='softmax')\n])\n\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:42.470137Z","iopub.execute_input":"2021-12-08T21:56:42.470524Z","iopub.status.idle":"2021-12-08T21:56:43.696841Z","shell.execute_reply.started":"2021-12-08T21:56:42.470483Z","shell.execute_reply":"2021-12-08T21:56:43.696059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Network","metadata":{}},{"cell_type":"markdown","source":"We train the model using the Adam optimizer, a learning rate of 0.001, and sparse categorical crossentropy loss. ","metadata":{}},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:43.699982Z","iopub.execute_input":"2021-12-08T21:56:43.700205Z","iopub.status.idle":"2021-12-08T21:56:43.714076Z","shell.execute_reply.started":"2021-12-08T21:56:43.700178Z","shell.execute_reply":"2021-12-08T21:56:43.71314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Run 1","metadata":{}},{"cell_type":"markdown","source":"We train for 20 epochs for the first training run. ","metadata":{}},{"cell_type":"code","source":"%%time \n\nh1 = cnn.fit(\n    Xs_train, y_train, \n    batch_size=256,\n    epochs = 20,\n    verbose = 1,\n    validation_data = (Xs_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:56:43.715411Z","iopub.execute_input":"2021-12-08T21:56:43.716061Z","iopub.status.idle":"2021-12-08T21:58:23.051373Z","shell.execute_reply.started":"2021-12-08T21:56:43.716021Z","shell.execute_reply":"2021-12-08T21:58:23.050457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = h1.history\nprint(history.keys())","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:58:23.052815Z","iopub.execute_input":"2021-12-08T21:58:23.053179Z","iopub.status.idle":"2021-12-08T21:58:23.060507Z","shell.execute_reply.started":"2021-12-08T21:58:23.053137Z","shell.execute_reply":"2021-12-08T21:58:23.059311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:58:23.062205Z","iopub.execute_input":"2021-12-08T21:58:23.062491Z","iopub.status.idle":"2021-12-08T21:58:23.473757Z","shell.execute_reply.started":"2021-12-08T21:58:23.062455Z","shell.execute_reply":"2021-12-08T21:58:23.472896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the leaning curves we can conclude the model is training well, between 55-60%; however, there is room for improvement. There is slight overfitting, and the model could benefit from additional epochs. ","metadata":{}},{"cell_type":"markdown","source":"### Training Run 2","metadata":{}},{"cell_type":"markdown","source":"In order to enhance the performance of the model, we will increase the learning rate to 0.0001. ","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:58:23.475096Z","iopub.execute_input":"2021-12-08T21:58:23.475395Z","iopub.status.idle":"2021-12-08T21:58:23.481535Z","shell.execute_reply.started":"2021-12-08T21:58:23.475357Z","shell.execute_reply":"2021-12-08T21:58:23.480475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We train for another 20 epochs for the second training run. ","metadata":{}},{"cell_type":"code","source":"%%time \n\nh2 = cnn.fit(\n    Xs_train, y_train, \n    batch_size=256,\n    epochs = 20,\n    verbose = 1,\n    validation_data = (Xs_valid, y_valid)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:58:23.482873Z","iopub.execute_input":"2021-12-08T21:58:23.483389Z","iopub.status.idle":"2021-12-08T21:59:58.891657Z","shell.execute_reply.started":"2021-12-08T21:58:23.48335Z","shell.execute_reply":"2021-12-08T21:59:58.890909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:59:58.894451Z","iopub.execute_input":"2021-12-08T21:59:58.894688Z","iopub.status.idle":"2021-12-08T21:59:59.318123Z","shell.execute_reply.started":"2021-12-08T21:59:58.894655Z","shell.execute_reply":"2021-12-08T21:59:59.317428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the learning curves we can conclude the increased learning rate caused significant overfitting. The training accuracy is ~70%, while the validation accuracy is ~57%. In order to enhance performance, this model may benefit from image augmentation. ","metadata":{}},{"cell_type":"markdown","source":"## Save Model and History","metadata":{}},{"cell_type":"markdown","source":"We save the model and training history for future reference. ","metadata":{}},{"cell_type":"code","source":"cnn.save('fer_model_v02.h5')\npickle.dump(history, open(f'fer_v02.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-12-08T21:59:59.319443Z","iopub.execute_input":"2021-12-08T21:59:59.319858Z","iopub.status.idle":"2021-12-08T21:59:59.434779Z","shell.execute_reply.started":"2021-12-08T21:59:59.31982Z","shell.execute_reply":"2021-12-08T21:59:59.433994Z"},"trusted":true},"execution_count":null,"outputs":[]}]}