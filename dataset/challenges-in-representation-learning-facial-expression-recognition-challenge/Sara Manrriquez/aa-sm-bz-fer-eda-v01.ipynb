{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Facial Expression Recognition**\n## **Exploratory Data Analysis**\n### Alejandro Alemany, Sara Manrriquez, and Ben Zaretzky\n<br/>\nIn this notebook we explore the facial expression recognition dataset.","metadata":{}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:25.967414Z","iopub.execute_input":"2021-11-28T23:29:25.968034Z","iopub.status.idle":"2021-11-28T23:29:26.000792Z","shell.execute_reply.started":"2021-11-28T23:29:25.967901Z","shell.execute_reply":"2021-11-28T23:29:25.999983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Training Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv')\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:26.015345Z","iopub.execute_input":"2021-11-28T23:29:26.015874Z","iopub.status.idle":"2021-11-28T23:29:30.63906Z","shell.execute_reply.started":"2021-11-28T23:29:26.015838Z","shell.execute_reply":"2021-11-28T23:29:30.637959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:30.64118Z","iopub.execute_input":"2021-11-28T23:29:30.641655Z","iopub.status.idle":"2021-11-28T23:29:30.664939Z","shell.execute_reply.started":"2021-11-28T23:29:30.641597Z","shell.execute_reply":"2021-11-28T23:29:30.664205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Data","metadata":{}},{"cell_type":"code","source":"train['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48) for x in train['pixels']]","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:30.666489Z","iopub.execute_input":"2021-11-28T23:29:30.66698Z","iopub.status.idle":"2021-11-28T23:29:33.952153Z","shell.execute_reply.started":"2021-11-28T23:29:30.666934Z","shell.execute_reply":"2021-11-28T23:29:33.951121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixels = np.concatenate(train['pixels'])\nlabels = train.emotion.values\n\nprint(pixels.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:33.9542Z","iopub.execute_input":"2021-11-28T23:29:33.954474Z","iopub.status.idle":"2021-11-28T23:29:34.431951Z","shell.execute_reply.started":"2021-11-28T23:29:33.954442Z","shell.execute_reply":"2021-11-28T23:29:34.431296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Distribution","metadata":{}},{"cell_type":"code","source":"emotion_prop = (train.emotion.value_counts() / len(train)).to_frame().sort_index(ascending=True)\n\nemotion_prop","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:34.432971Z","iopub.execute_input":"2021-11-28T23:29:34.433602Z","iopub.status.idle":"2021-11-28T23:29:34.454836Z","shell.execute_reply.started":"2021-11-28T23:29:34.433564Z","shell.execute_reply":"2021-11-28T23:29:34.453663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:34.456489Z","iopub.execute_input":"2021-11-28T23:29:34.456944Z","iopub.status.idle":"2021-11-28T23:29:34.465688Z","shell.execute_reply.started":"2021-11-28T23:29:34.456896Z","shell.execute_reply":"2021-11-28T23:29:34.464763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palette = ['orchid', 'lightcoral', 'orange', 'gold', 'lightgreen', 'deepskyblue', 'cornflowerblue']\n\nplt.figure(figsize=[12,6])\n\nplt.bar(x=emotions, height=emotion_prop['emotion'], color=palette, edgecolor='black')\n    \nplt.xlabel('Emotion')\nplt.ylabel('Proportion')\nplt.title('Emotion Label Proportions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:34.467054Z","iopub.execute_input":"2021-11-28T23:29:34.467488Z","iopub.status.idle":"2021-11-28T23:29:34.723191Z","shell.execute_reply.started":"2021-11-28T23:29:34.467452Z","shell.execute_reply":"2021-11-28T23:29:34.722286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## View Sample of Images","metadata":{}},{"cell_type":"code","source":"plt.close()\nplt.rcParams[\"figure.figsize\"] = [16,16]\n\nrow = 0\nfor emotion in np.unique(labels):\n\n    all_emotion_images = train[train['emotion'] == emotion]\n    for i in range(5):\n        \n        img = all_emotion_images.iloc[i,].pixels.reshape(48,48)\n        lab = emotions[emotion]\n\n        plt.subplot(7,5,row+i+1)\n        plt.imshow(img, cmap='binary_r')\n        plt.text(-30, 5, s = str(lab), fontsize=10, color='b')\n        plt.axis('off')\n    row += 5\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:29:34.7246Z","iopub.execute_input":"2021-11-28T23:29:34.725478Z","iopub.status.idle":"2021-11-28T23:29:36.971746Z","shell.execute_reply.started":"2021-11-28T23:29:34.725426Z","shell.execute_reply":"2021-11-28T23:29:36.970682Z"},"trusted":true},"execution_count":null,"outputs":[]}]}