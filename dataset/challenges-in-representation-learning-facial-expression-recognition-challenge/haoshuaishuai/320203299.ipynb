{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# 样本文件路径\nSAMPLE_FILE_PATH = \"../input/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv\"\n\n# 分类数量\nNUM_CLASSES = 7\n\n# 训练、校验、测试数据集HDF5文件的输出路径\nTRAIN_HDF5 = \"./train.hdf5\"\nVAL_HDF5 = \"./val.hdf5\"\nTEST_HDF5 = \"./test.hdf5\"\n\n# 每批次样本数量\nBATCH_SIZE = 128\n\n# 项目输出文件保存目录\nOUTPUT_PATH = \"./\"\n\n# 数据集样本RGB平均值存位置及文件名称\nDATASET_MEAN_FILE = OUTPUT_PATH + \"/rgb_mean.json\"\n\n# 模型保存位置及文件名称\nMODEL_FILE = OUTPUT_PATH + \"/model.h5\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 导入必要包\nfrom tensorflow.keras.callbacks import Callback\nimport os\n\n\n\nclass EpochCheckpoint(Callback):\n    def __init__(self, output_path, every=5, start_at=0):\n        super(Callback, self).__init__()\n        self.output_path = output_path\n        self.every = every\n        self.start_epoch = start_at\n\n    def on_epoch_end(self, epoch, logs={}):\n        if (self.start_epoch + 1) % self.every == 0:\n            p = os.path.sep.join([self.output_path,\n                                  \"epoch_{}.hdf5\".format(self.start_epoch + 1)])\n            self.model.save(p, overwrite=True)\n        self.start_epoch += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport h5py\nfrom tensorflow.python.keras.utils import np_utils\n\n\nclass HDF5DatasetGenerator:\n    def __init__(self, db_file, batch_size, preprocessors=None,\n                 aug=None, binarize=True, classes=2):\n        self.batchSize = batch_size\n        self.preprocessors = preprocessors\n        self.aug = aug\n        self.binarize = binarize\n        self.classes = classes\n        self.db = h5py.File(db_file)\n        self.numImages = self.db[\"labels\"].shape[0]\n\n    def generator(self, passes=np.inf):\n        epochs = 0\n        while epochs < passes:\n            for i in np.arange(0, self.numImages, self.batchSize):\n                images = self.db[\"images\"][i:i + self.batchSize]\n                labels = self.db[\"labels\"][i:i + self.batchSize]\n\n                if self.binarize:\n                    labels = np_utils.to_categorical(labels, self.classes)\n\n                if self.preprocessors is not None:\n                    processed_images = []\n                    for image in images:\n                        for p in self.preprocessors:\n                            image = p.preprocess(image)\n                        processed_images.append(image)\n                    images = np.array(processed_images)\n\n                if self.aug is not None:\n                    (images, labels) = next(self.aug.flow(images, labels,\n                                                          batch_size=self.batchSize))\n                yield images, labels\n            epochs += 1\n\n    def close(self):\n        self.db.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport h5py\n\n\nclass HDF5DatasetWriter:\n    def __init__(self, dims, output_path, data_key=\"images\", buf_size=1000):\n        if os.path.exists(output_path):\n            raise ValueError('你提供的输出文件{}已经存在，请先手工输出'.format(output_path))\n        self.db = h5py.File(output_path, 'w')\n        self.data = self.db.create_dataset(data_key, dims, dtype=\"float\")\n        self.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n\n\n        self.buf_size = buf_size\n        self.buffer = {\"data\": [], \"labels\": []}\n        self.idx = 0\n\n    def add(self, raw, label):\n        self.buffer[\"data\"].extend(raw)\n        self.buffer[\"labels\"].extend(label)\n        if len(self.buffer[\"data\"]) >= self.buf_size:\n            self.flush()\n\n    def flush(self):\n        i = self.idx + len(self.buffer[\"data\"])\n        self.data[self.idx:i] = self.buffer[\"data\"]\n        self.labels[self.idx:i] = self.buffer[\"labels\"]\n        self.idx = i\n        self.buffer = {\"data\": [], \"labels\": []}\n\n    def store_class_labels(self, class_labels):\n        dt = h5py.special_dtype(vlen=str)\n        label_dim = (len(class_labels),)\n        label_set = self.db.create_dataset(\"label_names\", label_dim, dtype=dt)\n        label_set[:] = class_labels\n\n    def close(self):\n        if len(self.buffer[\"data\"]) > 0:\n            self.flush()\n        self.db.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import img_to_array\n\n\n# 定义ImageToArrayPreprocessor类\nclass ImageToArrayPreprocessor:\n    def __init__(self, data_format=None):\n        # 保存数据图像的格式\n        self.data_format = data_format\n\n    def preprocess(self, image):\n        # 重置图像维度,调用keras中的img_to_array的方法\n        return img_to_array(image, data_format=self.data_format)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import BaseLogger\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport json\nimport os\n\n\n\nclass TrainingMonitor(BaseLogger):\n    def __init__(self, fig_path, json_path=None, start_at=0):\n        super(TrainingMonitor, self).__init__()\n        self.history = {}\n        self.fig_path = fig_path\n        self.json_path = json_path\n        self.start_at = start_at\n\n    def on_train_begin(self, logs={}):\n        if self.json_path is not None:\n            if os.path.exists(self.json_path):\n                self.history = json.loads(open(self.json_path).read())\n                if self.start_at > 0:\n                    for k in self.history.keys():\n                        self.history[k] = self.history[k][:self.start_at]\n\n    def on_epoch_end(self, epoch, logs={}):\n        for (k, v) in logs.items():\n            log = self.history.get(k, [])\n            log.append(v)\n            self.history[k] = log\n\n        if self.json_path is not None:\n            f = open(self.json_path, \"w\")\n            f.write(json.dumps(self.history))\n            f.close()\n\n        if len(self.history[\"loss\"])>1:\n            N=np.arange(0,len(self.history[\"loss\"]))\n            plt.style.use(\"ggplot\")\n            plt.figure()\n            plt.plot(N,self.history[\"loss\"],label=\"train_loss\")\n            plt.plot(N,self.history[\"val_loss\"],label=\"val_loss\")\n            plt.plot(N,self.history[\"accuracy\"],label=\"train_acc\")\n            plt.plot(N,self.history[\"val_accuracy\"],label=\"val_acc\")\n            epochs=len(self.history[\"loss\"])\n            plt.title(\"Training Loss & Accuracy [Epoch{}]\".format(epochs))\n            plt.xlabel(\"Epoch #\")\n            plt.ylabel(\"Loss/Accuracy\")\n            plt.legend()\n            plt.savefig(self.fig_path)\n            plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 导包\nimport numpy as np\n\nprint(\"[信息]加载csv格式数据集文件...\")\nfile = open(SAMPLE_FILE_PATH)\n\n# 跳过第一行(表头)\nfile.__next__()\n\n(train_images, train_labels) = ([], [])\n(val_images, val_labels) = ([], [])\n(test_images, test_labels) = ([], [])\n\n\ncount_by_label_train = {}\ncount_by_label_val = {}\ncount_by_label_test = {}\n\n\nfor row in file:\n    # 提取每一行的标签，用途和图像\n    (label, usage, image) = row.strip().split(\",\")\n    # 标签转整数\n    label = int(label)\n    # 将一组像素列表编程48*48灰度图像\n    image = np.array(image.split(\" \"), dtype=\"uint8\")\n    image = image.reshape((48, 48))\n\n    if usage == \"Training\":\n        train_images.append(image)\n        train_labels.append(label)\n        count = count_by_label_train.get(label, 0)\n        count_by_label_train[label] = count + 1\n\n    elif usage == 'PublicTest':\n        val_images.append(image)\n        val_labels.append(label)\n        count = count_by_label_val.get(label, 0)\n        count_by_label_val[label] = count + 1\n\n    elif usage == \"PrivateTest\":\n        test_images.append(image)\n        test_labels.append(label)\n        count = count_by_label_test.get(label, 0)\n        count_by_label_test[label] = count + 1\n\nfile.close()\n\nprint(\"[信息]训练样本数量：{}\".format(len(train_images)))\nprint(\"[信息]校验样本数量：{}\".format(len(val_images)))\nprint(\"[信息]测试样本数量：{}\".format(len(test_images)))\n\nprint(count_by_label_train)\nprint(\"[信息]校验样本分布：\")\nprint(count_by_label_val)\nprint(\"[信息]测试样本分布：\")\nprint(count_by_label_test)\n\ndatasets = [(train_images, train_labels, TRAIN_HDF5),\n            (val_images, val_labels, VAL_HDF5),\n            (test_images, test_labels, TEST_HDF5)]\n\nfor (images, labels, outputPath) in datasets:\n    print(\"[信息构建]{}...\".format(outputPath))\n    writer = HDF5DatasetWriter((len(images), 48, 48), outputPath)\n    for (image, label) in zip(images, labels):\n        writer.add([image], [label])\n\n    writer.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.regularizers import l1, l2\nfrom tensorflow.keras import backend\n\n\n# 定义VGG11类\nclass MiniVGG11:\n    @staticmethod\n    def build(width, height, channel, classes, reg=0.0002):\n        model = Sequential(name=\"VGG11\")\n        shape = (height, width, channel)\n        channel_dimension = -1\n\n        if backend.image_data_format() == \"channels_first\":\n            shape = (channel, height, width)\n            channel_dimension = 1\n\n        model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", strides=(1, 1)))\n\n        model.add(Flatten())\n        model.add(Dense(256, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n\n        model.add(Dense(128, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n\n        model.add(Dense(classes, kernel_regularizer=l1(reg)))\n        model.add(Activation(\"softmax\"))\n\n        return model\n\n\nif __name__ == \"__main__\":\n    my_model = MiniVGG11.build(width=48, height=48, channel=1, classes=7, reg=0.0002)\n    print(my_model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\nimport tensorflow.keras.backend as K\nimport argparse\nimport os\n\n\nmatplotlib.use(\"Agg\")\n\ntrain_aug = ImageDataGenerator(rotation_range=10,\n                   zoom_range = 0.1,\n                   rescale=1 / 255.0,\n                   fill_mode=\"nearest\")\nval_aug = ImageDataGenerator(rescale=1/255.0)\n\niap = ImageToArrayPreprocessor()\n\ntrain_gen = HDF5DatasetGenerator(TRAIN_HDF5,\n                                 BATCH_SIZE,\n                                 aug=train_aug,\n                                 preprocessors=[iap],\n                                 classes=NUM_CLASSES)\nval_gen = HDF5DatasetGenerator(VAL_HDF5,\n                                 BATCH_SIZE,\n                                 aug=val_aug,\n                                 preprocessors = [iap],\n                                 classes=NUM_CLASSES)\n\nopt = Adam(lr = 1e-3)\nmodel = MiniVGG11.build(width=48,height=48,channel=1,classes=NUM_CLASSES)\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\nfig_path = os.path.sep.join([OUTPUT_PATH, \"{}.png\".format(os.getpid())])\ncallbacks = [TrainingMonitor(fig_path=fig_path)]\nmodel.fit_generator(train_gen.generator(),\n                    steps_per_epoch=train_gen.numImages//BATCH_SIZE,\n                    validation_data=val_gen.generator(),\n                    validation_steps=val_gen.numImages // BATCH_SIZE,\n                    epochs=50,\n                    max_queue_size=BATCH_SIZE*2,\n                    callbacks=callbacks,\n                    verbose=1)\nprint(\"[信息] 保存模型...\")\nmodel.save(MODEL_FILE,overwrite=True)\ntrain_gen.close()\nval_gen.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\n\ntestAug = ImageDataGenerator(rescale=1 / 255.0)\niap = ImageToArrayPreprocessor()\n\ntestGen = HDF5DatasetGenerator(TEST_HDF5,\n                               BATCH_SIZE,\n                               aug=testAug,\n                               preprocessors=[iap],\n                               classes=NUM_CLASSES)\n\nprint(\"[信息]加载网络模型\")\nmodel = load_model(MODEL_FILE)\n\n(loss, acc) = model.evaluate_generator(testGen.generator(),\n                                       steps=testGen.numImages // BATCH_SIZE,\n                                       max_queue_size=BATCH_SIZE * 2)\nprint(\"[信息]测试集准确率：{:.2f}%\".format(acc * 100))\n\ntestGen.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\n\ndef convert(model_file):\n    '''\n\n    :param model_file:模型文件\n    :return: 无\n    '''\n    model = load_model(model_file)\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n    tflite_float_model = converter.convert()\n    model_lite_float_file = 'VGG_float.tflite'\n    open(model_lite_float_file, 'wb').write(tflite_float_model)\n    '''\n    TF格式\n    量化\n\n    '''\n    model_lite_quantized_file = 'VGG_quantized.tflite'\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n    tflite_quantized_model = converter.convert()\n    open(model_lite_quantized_file, 'wb').write(tflite_quantized_model)\n\n\nif __name__ == \"__main__\":\n    convert('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}