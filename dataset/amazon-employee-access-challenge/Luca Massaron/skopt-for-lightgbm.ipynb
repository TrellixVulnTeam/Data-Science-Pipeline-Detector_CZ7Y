{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing core libraries\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport pprint\nimport joblib\n\n# Suppressing warnings because of skopt verbosity\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Classifiers\nimport lightgbm as lgb\n\n# Model selection\nfrom sklearn.model_selection import StratifiedKFold\n\n# Metrics\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer\n\n# Skopt functions\nfrom skopt import BayesSearchCV\nfrom skopt.callbacks import DeadlineStopper, DeltaYStopper\nfrom skopt.space import Real, Categorical, Integer\n\n# Plotting functions\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n#sns.set(style='whitegrid')","metadata":{"papermill":{"duration":2.832919,"end_time":"2021-08-06T13:40:58.107321","exception":false,"start_time":"2021-08-06T13:40:55.274402","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:20:03.641584Z","iopub.execute_input":"2021-08-08T10:20:03.642289Z","iopub.status.idle":"2021-08-08T10:20:06.158666Z","shell.execute_reply.started":"2021-08-08T10:20:03.642192Z","shell.execute_reply":"2021-08-08T10:20:06.157789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. First steps","metadata":{"papermill":{"duration":0.021573,"end_time":"2021-08-06T13:40:58.152206","exception":false,"start_time":"2021-08-06T13:40:58.130633","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"As first steps: \n* we load the train and test data from disk\n* we separate the target from the training data\n* we separate the ids from the test data (thus train and test data have the same structure)\n* we convert integer variables to categories (thus our machine learning algorithm can pick them as categorical variables and not standard numeric one)","metadata":{"papermill":{"duration":0.021608,"end_time":"2021-08-06T13:40:58.195903","exception":false,"start_time":"2021-08-06T13:40:58.174295","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Loading data \nX = pd.read_csv(\"../input/amazon-employee-access-challenge/train.csv\")\nX_test = pd.read_csv(\"../input/amazon-employee-access-challenge/test.csv\")\n\n# Separating the target from the predictors\ny = X[\"ACTION\"]\nX.drop([\"ACTION\"], axis=\"columns\", inplace=True)\n\n# Separating the identifier from the test data\nids = X_test[\"id\"]\nX_test.drop(\"id\", axis=\"columns\", inplace=True)\n\n# Converting all integer variables to categorical\ninteger_cols = X.select_dtypes(include=['int']).columns\nX[integer_cols] = X[integer_cols].astype('category', copy=False)\nX_test[integer_cols] = X_test[integer_cols].astype('category', copy=False)","metadata":{"papermill":{"duration":0.304447,"end_time":"2021-08-06T13:40:58.522582","exception":false,"start_time":"2021-08-06T13:40:58.218135","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:20:06.159848Z","iopub.execute_input":"2021-08-08T10:20:06.16009Z","iopub.status.idle":"2021-08-08T10:20:06.430148Z","shell.execute_reply.started":"2021-08-08T10:20:06.160066Z","shell.execute_reply":"2021-08-08T10:20:06.429189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA","metadata":{"papermill":{"duration":0.021905,"end_time":"2021-08-06T13:40:58.56767","exception":false,"start_time":"2021-08-06T13:40:58.545765","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"At this point we have a look at the training and test data in order to figure out how we can process the data.","metadata":{"papermill":{"duration":0.022227,"end_time":"2021-08-06T13:40:58.611924","exception":false,"start_time":"2021-08-06T13:40:58.589697","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"Unique values\")\n(pd.concat([X.apply(lambda x: len(x.unique())), \n            X_test.apply(lambda x: len(x.unique()))\n           ], axis=\"columns\")\n .rename(columns={0: \"train\", 1:\"test\"}))","metadata":{"papermill":{"duration":0.067594,"end_time":"2021-08-06T13:40:58.701791","exception":false,"start_time":"2021-08-06T13:40:58.634197","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:20:14.675221Z","iopub.execute_input":"2021-08-08T10:20:14.675617Z","iopub.status.idle":"2021-08-08T10:20:14.714831Z","shell.execute_reply.started":"2021-08-08T10:20:14.675582Z","shell.execute_reply":"2021-08-08T10:20:14.713866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Values in test but not in train\")\nfor col in integer_cols:\n    mismatched_codes = len(np.setdiff1d(X[col].unique(), X_test[col].unique()))\n    print(f\"{col:20} {mismatched_codes:4}\")","metadata":{"papermill":{"duration":0.0613,"end_time":"2021-08-06T13:40:58.7875","exception":false,"start_time":"2021-08-06T13:40:58.7262","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:20:15.772091Z","iopub.execute_input":"2021-08-08T10:20:15.772625Z","iopub.status.idle":"2021-08-08T10:20:15.806505Z","shell.execute_reply.started":"2021-08-08T10:20:15.772583Z","shell.execute_reply":"2021-08-08T10:20:15.805571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Missing cases\")\n(pd.concat([X.isna().sum(), \n           X_test.isna().sum()\n           ], axis=\"columns\")\n .rename(columns={0: \"train\", 1:\"test\"}))","metadata":{"papermill":{"duration":0.045522,"end_time":"2021-08-06T13:40:58.857173","exception":false,"start_time":"2021-08-06T13:40:58.811651","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:20:16.733059Z","iopub.execute_input":"2021-08-08T10:20:16.733466Z","iopub.status.idle":"2021-08-08T10:20:16.75588Z","shell.execute_reply.started":"2021-08-08T10:20:16.733412Z","shell.execute_reply":"2021-08-08T10:20:16.754896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label distribution\nfig, ax = plt.subplots(1, 1, figsize=(10, 6))\nsns.histplot(y, ax=ax)\nplt.show()","metadata":{"papermill":{"duration":0.275056,"end_time":"2021-08-06T13:40:59.156313","exception":false,"start_time":"2021-08-06T13:40:58.881257","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:20:17.603196Z","iopub.execute_input":"2021-08-08T10:20:17.603604Z","iopub.status.idle":"2021-08-08T10:20:17.845543Z","shell.execute_reply.started":"2021-08-08T10:20:17.603569Z","shell.execute_reply":"2021-08-08T10:20:17.844634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of values of variables\n_ = X.astype(int).hist(bins='auto', figsize=(24, 22), layout=(5, 2))","metadata":{"papermill":{"duration":46.825366,"end_time":"2021-08-06T13:41:46.006767","exception":false,"start_time":"2021-08-06T13:40:59.181401","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:20:18.806327Z","iopub.execute_input":"2021-08-08T10:20:18.806783Z","iopub.status.idle":"2021-08-08T10:21:05.512316Z","shell.execute_reply.started":"2021-08-08T10:20:18.806747Z","shell.execute_reply":"2021-08-08T10:21:05.511632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the EDA we can get a few hints about what to do:\n* the target classes are unbalanced, we should consider re-balancing the data\n* all the categorical features have a different number of values ranging from 70 to up to over 7000 (high cardinality features)\n* there are no missing values but many categorical values appear just in test, not in train (this especially affects the RESOURCE feature)\n* the categorical values are sparse","metadata":{"papermill":{"duration":0.026445,"end_time":"2021-08-06T13:41:46.060057","exception":false,"start_time":"2021-08-06T13:41:46.033612","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 3. Feature engineering","metadata":{"papermill":{"duration":0.027123,"end_time":"2021-08-06T13:41:46.113948","exception":false,"start_time":"2021-08-06T13:41:46.086825","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"As the categorical features are sparsed and mismatched, we replace the original values with contiguous values, substituing with the value -1 in the test set for values that are not present in the train set. This operation should permit the LightGBM ","metadata":{"papermill":{"duration":0.026585,"end_time":"2021-08-06T13:41:46.16762","exception":false,"start_time":"2021-08-06T13:41:46.141035","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for col in integer_cols:\n    unique_values = sorted(X[col].unique())\n    print(col, \":\", unique_values[:5],'...', unique_values[-5:])\n    conversion_dict = dict(zip(unique_values, range(len(unique_values))))\n    # When working with the Categoricalâ€™s codes, missing values will always have a code of -1.\n    X[col] = X[col].map(conversion_dict, na_action=-1).astype('category', copy=False)\n    X_test[col] = X_test[col].map(conversion_dict, na_action=-1).astype('category', copy=False)","metadata":{"papermill":{"duration":0.126833,"end_time":"2021-08-06T13:41:46.321366","exception":false,"start_time":"2021-08-06T13:41:46.194533","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:21:46.178518Z","iopub.execute_input":"2021-08-08T10:21:46.179073Z","iopub.status.idle":"2021-08-08T10:21:46.271203Z","shell.execute_reply.started":"2021-08-08T10:21:46.179024Z","shell.execute_reply":"2021-08-08T10:21:46.270255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Missing cases\")\npd.concat([X.isna().sum(), X_test.isna().sum()], axis=\"columns\").rename(columns={0: \"train\", 1:\"test\"})","metadata":{"papermill":{"duration":0.049707,"end_time":"2021-08-06T13:41:46.399287","exception":false,"start_time":"2021-08-06T13:41:46.34958","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-08T10:21:47.212748Z","iopub.execute_input":"2021-08-08T10:21:47.213127Z","iopub.status.idle":"2021-08-08T10:21:47.234901Z","shell.execute_reply.started":"2021-08-08T10:21:47.213098Z","shell.execute_reply":"2021-08-08T10:21:47.233829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Setting up optimization","metadata":{"papermill":{"duration":0.027602,"end_time":"2021-08-06T13:41:46.454749","exception":false,"start_time":"2021-08-06T13:41:46.427147","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"First, we create a wrapper function to deal with running the optimizer and reporting back its best results.","metadata":{}},{"cell_type":"code","source":"# Reporting util for different optimizers\ndef report_perf(optimizer, X, y, title=\"model\", callbacks=None):\n    \"\"\"\n    A wrapper for measuring time and performances of different optmizers\n    \n    optimizer = a sklearn or a skopt optimizer\n    X = the training set \n    y = our target\n    title = a string label for the experiment\n    \"\"\"\n    start = time()\n    \n    if callbacks is not None:\n        optimizer.fit(X, y, callback=callbacks)\n    else:\n        optimizer.fit(X, y)\n        \n    d=pd.DataFrame(optimizer.cv_results_)\n    best_score = optimizer.best_score_\n    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n    best_params = optimizer.best_params_\n    \n    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n           + u\"\\u00B1\"+\" %.3f\") % (time() - start, \n                                   len(optimizer.cv_results_['params']),\n                                   best_score,\n                                   best_score_std))    \n    print('Best parameters:')\n    pprint.pprint(best_params)\n    print()\n    return best_params","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:41:46.574669Z","iopub.status.busy":"2021-08-06T13:41:46.573964Z","iopub.status.idle":"2021-08-06T13:41:46.575957Z","shell.execute_reply":"2021-08-06T13:41:46.576428Z","shell.execute_reply.started":"2021-08-06T13:18:42.320205Z"},"papermill":{"duration":0.038681,"end_time":"2021-08-06T13:41:46.576615","exception":false,"start_time":"2021-08-06T13:41:46.537934","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We then define the evaluation metric, using the Scikit-learn function make_scorer allows us to convert the optimization into a minimization problem, as required by Scikit-optimize","metadata":{}},{"cell_type":"code","source":"# Converting average precision score into a scorer suitable for model selection\nroc_auc = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:41:46.635768Z","iopub.status.busy":"2021-08-06T13:41:46.635092Z","iopub.status.idle":"2021-08-06T13:41:46.640073Z","shell.execute_reply":"2021-08-06T13:41:46.639545Z","shell.execute_reply.started":"2021-08-06T13:18:42.333385Z"},"papermill":{"duration":0.035434,"end_time":"2021-08-06T13:41:46.640221","exception":false,"start_time":"2021-08-06T13:41:46.604787","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We set up a stratified 5-fold cross validation: stratification helps us to obtain representative folds of the data and the target, though the target is unbalanced","metadata":{}},{"cell_type":"code","source":"# Setting a 5-fold stratified cross-validation (note: shuffle=True)\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:41:46.701913Z","iopub.status.busy":"2021-08-06T13:41:46.701252Z","iopub.status.idle":"2021-08-06T13:41:46.703224Z","shell.execute_reply":"2021-08-06T13:41:46.703734Z","shell.execute_reply.started":"2021-08-06T13:18:42.344906Z"},"papermill":{"duration":0.03441,"end_time":"2021-08-06T13:41:46.703898","exception":false,"start_time":"2021-08-06T13:41:46.669488","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We set up a generic LightGBM classifier","metadata":{}},{"cell_type":"code","source":"clf = lgb.LGBMClassifier(boosting_type='gbdt',\n                         metric='auc',\n                         objective='binary',\n                         n_jobs=1, \n                         verbose=-1,\n                         random_state=0)","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:41:46.763373Z","iopub.status.busy":"2021-08-06T13:41:46.762708Z","iopub.status.idle":"2021-08-06T13:41:46.766789Z","shell.execute_reply":"2021-08-06T13:41:46.767299Z","shell.execute_reply.started":"2021-08-06T13:18:42.358319Z"},"papermill":{"duration":0.035503,"end_time":"2021-08-06T13:41:46.767503","exception":false,"start_time":"2021-08-06T13:41:46.732","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We define a search space, expliciting the key hyper-parameters to optimize and the range where to look for the best values","metadata":{}},{"cell_type":"code","source":"search_spaces = {\n    'learning_rate': Real(0.01, 1.0, 'log-uniform'),     # Boosting learning rate\n    'n_estimators': Integer(30, 5000),                   # Number of boosted trees to fit\n    'num_leaves': Integer(2, 512),                       # Maximum tree leaves for base learners\n    'max_depth': Integer(-1, 256),                       # Maximum tree depth for base learners, <=0 means no limit\n    'min_child_samples': Integer(1, 256),                # Minimal number of data in one leaf\n    'max_bin': Integer(100, 1000),                       # Max number of bins that feature values will be bucketed\n    'subsample': Real(0.01, 1.0, 'uniform'),             # Subsample ratio of the training instance\n    'subsample_freq': Integer(0, 10),                    # Frequency of subsample, <=0 means no enable\n    'colsample_bytree': Real(0.01, 1.0, 'uniform'),      # Subsample ratio of columns when constructing each tree\n    'min_child_weight': Real(0.01, 10.0, 'uniform'),     # Minimum sum of instance weight (hessian) needed in a child (leaf)\n    'reg_lambda': Real(1e-9, 100.0, 'log-uniform'),      # L2 regularization\n    'reg_alpha': Real(1e-9, 100.0, 'log-uniform'),       # L1 regularization\n    'scale_pos_weight': Real(1.0, 500.0, 'uniform'),     # Weighting of the minority class (Only for binary classification)\n        }","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:41:46.827012Z","iopub.status.busy":"2021-08-06T13:41:46.826362Z","iopub.status.idle":"2021-08-06T13:41:46.843539Z","shell.execute_reply":"2021-08-06T13:41:46.844059Z","shell.execute_reply.started":"2021-08-06T13:18:42.371004Z"},"papermill":{"duration":0.048606,"end_time":"2021-08-06T13:41:46.844247","exception":false,"start_time":"2021-08-06T13:41:46.795641","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We then define the Bayesian optimization engine, providing to it our LightGBM, the search spaces, the evaluation metric, the cross-validation. We set a large number of possible experiments and some parallelism in the search operations. ","metadata":{}},{"cell_type":"code","source":"opt = BayesSearchCV(estimator=clf,                                    \n                    search_spaces=search_spaces,                      \n                    scoring=roc_auc,                                  \n                    cv=skf,                                           \n                    n_iter=3000,                                      # max number of trials\n                    n_points=3,                                       # number of hyperparameter sets evaluated at the same time\n                    n_jobs=-1,                                        # number of jobs\n                    iid=False,                                        # if not iid it optimizes on the cv score\n                    return_train_score=False,                         \n                    refit=False,                                      \n                    optimizer_kwargs={'base_estimator': 'GP'},        # optmizer parameters: we use Gaussian Process (GP)\n                    random_state=0)                                   # random state for replicability","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:41:46.903326Z","iopub.status.busy":"2021-08-06T13:41:46.902599Z","iopub.status.idle":"2021-08-06T13:41:46.9087Z","shell.execute_reply":"2021-08-06T13:41:46.908022Z","shell.execute_reply.started":"2021-08-06T13:18:42.39355Z"},"papermill":{"duration":0.036572,"end_time":"2021-08-06T13:41:46.908841","exception":false,"start_time":"2021-08-06T13:41:46.872269","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally we runt the optimizer and wait for the results. We have set some limits to its operations: we required it to stop if it cannot get consistent improvements from the search (DeltaYStopper) and time dealine set in seconds (we decided for 45 minutes).","metadata":{}},{"cell_type":"code","source":"overdone_control = DeltaYStopper(delta=0.0001)               # We stop if the gain of the optimization becomes too small\ntime_limit_control = DeadlineStopper(total_time=60 * 45)     # We impose a time limit (45 minutes)\n\nbest_params = report_perf(opt, X, y,'LightGBM', \n                          callbacks=[overdone_control, time_limit_control])","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:41:46.996401Z","iopub.status.busy":"2021-08-06T13:41:46.990296Z","iopub.status.idle":"2021-08-06T13:55:54.581266Z","shell.execute_reply":"2021-08-06T13:55:54.581773Z","shell.execute_reply.started":"2021-08-06T13:18:42.412421Z"},"papermill":{"duration":847.645144,"end_time":"2021-08-06T13:55:54.581956","exception":false,"start_time":"2021-08-06T13:41:46.936812","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Prediction on test data","metadata":{"papermill":{"duration":0.028022,"end_time":"2021-08-06T13:55:54.638748","exception":false,"start_time":"2021-08-06T13:55:54.610726","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Having got the best hyperparameters for the data at hand, we instantiate a lightGBM using such values and train our model on all the available examples.\n<P>After having trained the model, we predict on the test set and we save the results on a csv file.","metadata":{"papermill":{"duration":0.027934,"end_time":"2021-08-06T13:55:54.695341","exception":false,"start_time":"2021-08-06T13:55:54.667407","status":"completed"},"tags":[]}},{"cell_type":"code","source":"clf = lgb.LGBMClassifier(boosting_type='gbdt',\n                         metric='auc',\n                         objective='binary',\n                         n_jobs=1, \n                         verbose=-1,\n                         random_state=0,\n                         **best_params\n                        )","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:55:54.758305Z","iopub.status.busy":"2021-08-06T13:55:54.757645Z","iopub.status.idle":"2021-08-06T13:55:54.760944Z","shell.execute_reply":"2021-08-06T13:55:54.760346Z","shell.execute_reply.started":"2021-08-06T13:34:18.942198Z"},"papermill":{"duration":0.037467,"end_time":"2021-08-06T13:55:54.761091","exception":false,"start_time":"2021-08-06T13:55:54.723624","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X, y)","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:55:54.821015Z","iopub.status.busy":"2021-08-06T13:55:54.820353Z","iopub.status.idle":"2021-08-06T13:56:28.232051Z","shell.execute_reply":"2021-08-06T13:56:28.232567Z","shell.execute_reply.started":"2021-08-06T13:34:18.951572Z"},"papermill":{"duration":33.443183,"end_time":"2021-08-06T13:56:28.232742","exception":false,"start_time":"2021-08-06T13:55:54.789559","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'Id':ids, 'ACTION': clf.predict_proba(X_test)[:, 1].ravel()})\nsubmission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.execute_input":"2021-08-06T13:56:28.294369Z","iopub.status.busy":"2021-08-06T13:56:28.293705Z","iopub.status.idle":"2021-08-06T13:57:20.943703Z","shell.execute_reply":"2021-08-06T13:57:20.944247Z","shell.execute_reply.started":"2021-08-06T13:34:40.198866Z"},"papermill":{"duration":52.682586,"end_time":"2021-08-06T13:57:20.944451","exception":false,"start_time":"2021-08-06T13:56:28.261865","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}