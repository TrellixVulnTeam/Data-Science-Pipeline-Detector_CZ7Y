{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Solving classification problems with CatBoost"},{"metadata":{},"cell_type":"markdown","source":"In this tutorial we will use dataset Amazon Employee Access Challenge from [Kaggle](https://www.kaggle.com) competition for our experiments. Data can be downloaded [here](https://www.kaggle.com/c/amazon-employee-access-challenge/data)."},{"metadata":{},"cell_type":"markdown","source":"https://www.youtube.com/watch?v=xl1fwCza9C8&t=673s"},{"metadata":{},"cell_type":"markdown","source":"## Libraries installation"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --user --upgrade catboost\n!pip install --user --upgrade ipywidgets\n!pip install shap\n!pip install sklearn\n!pip install --upgrade numpy\n!jupyter nbextension enable --py widgetsnbextension","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import catboost\nprint(catboost.__version__)\n!python --version","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nnp.set_printoptions(precision=4)\nimport catboost\nfrom catboost import *\nfrom catboost import datasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(('/kaggle/input/amazon-employee-access-challenge/train.csv'))\ntest_df = pd.read_csv(('/kaggle/input/amazon-employee-access-challenge/test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing your data"},{"metadata":{},"cell_type":"markdown","source":"Label values extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_df.ACTION\nX = train_df.drop('ACTION', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical features declaration"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = list(range(0, X.shape[1]))\nprint(cat_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking on label balance in dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Labels: {}'.format(set(y)))\nprint('Zero count = {}, One count = {}'.format(len(y) - sum(y), sum(y)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ways to create Pool class"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dir = './amazon'\nif not os.path.exists(dataset_dir):\n    os.makedirs(dataset_dir)\n\n# We will be able to work with files with/without header and\n# with different separators.\ntrain_df.to_csv(\n    os.path.join(dataset_dir, 'train.tsv'),\n    index=False, sep='\\t', header=False\n)\ntest_df.to_csv(\n    os.path.join(dataset_dir, 'test.tsv'),\n    index=False, sep='\\t', header=False\n)\n\ntrain_df.to_csv(\n    os.path.join(dataset_dir, 'train.csv'),\n    index=False, sep=',', header=True\n)\ntest_df.to_csv(\n    os.path.join(dataset_dir, 'test.csv'),\n    index=False, sep=',', header=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head amazon/train.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost.utils import create_cd\nfeature_names = dict()\nfor column, name in enumerate(train_df):\n    if column == 0:\n        continue\n    feature_names[column - 1] = name\n    \ncreate_cd(\n    label=0, \n    cat_features=list(range(1, train_df.columns.shape[0])),\n    feature_names=feature_names,\n    output_path=os.path.join(dataset_dir, 'train.cd')\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cat amazon/train.cd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pool1 = Pool(data=X, label=y, cat_features=cat_features)\npool2 = Pool(\n    data=os.path.join(dataset_dir, 'train.csv'), \n    delimiter=',', \n    column_description=os.path.join(dataset_dir, 'train.cd'),\n    has_header=True\n)\npool3 = Pool(data=X, cat_features=cat_features)\n\n# Fastest way to create a Pool is to create it from numpy matrix.\n# This way should be used if you want fast predictions\n# or fastest way to load the data in python.\n\nX_prepared = X.values.astype(str).astype(object)\n# For FeaturesData class categorial features must have type str\n\npool4 = Pool(\n    data=FeaturesData(\n        cat_feature_data=X_prepared,\n        cat_feature_names=list(X)\n    ),\n    label=y.values\n)\n\nprint('Dataset shape')\nprint('dataset 1:' + str(pool1.shape) +\n      '\\ndataset 2:' + str(pool2.shape) + \n      '\\ndataset 3:' + str(pool3.shape) +\n      '\\ndataset 4: ' + str(pool4.shape))\n\nprint('\\n')\nprint('Column names')\nprint('dataset 1:')\nprint(pool1.get_feature_names()) \nprint('\\ndataset 2:')\nprint(pool2.get_feature_names())\nprint('\\ndataset 3:')\nprint(pool3.get_feature_names())\nprint('\\ndataset 4:')\nprint(pool4.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split your data into train and validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=1234)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting the objective function"},{"metadata":{},"cell_type":"markdown","source":"Possible options for binary classification:\n\n`Logloss`\n\n`CrossEntropy` for probabilities in target"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=5,\n    learning_rate=0.1,\n    # loss_function='CrossEntropy'\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    eval_set=(X_validation, y_validation),\n    verbose=False\n)\nprint('Model is fitted: ' + str(model.is_fitted()))\nprint('Model params:')\nprint(model.get_params())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stdout of the training"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=30,\n#     verbose=5,\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    eval_set=(X_validation, y_validation),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metrics calculation and graph plotting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=200,\n    random_seed=63,\n    learning_rate=0.5,\n    custom_loss=['AUC', 'Accuracy']\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    eval_set=(X_validation, y_validation),\n    verbose=False,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = CatBoostClassifier(\n    learning_rate=0.7,\n    iterations=100,\n    random_seed=0,\n    train_dir='learing_rate_0.7'\n)\n\nmodel2 = CatBoostClassifier(\n    learning_rate=0.01,\n    iterations=100,\n    random_seed=0,\n    train_dir='learing_rate_0.01'\n)\nmodel1.fit(\n    X_train, y_train,\n    eval_set=(X_validation, y_validation),\n    cat_features=cat_features,\n    verbose=False\n)\nmodel2.fit(\n    X_train, y_train,\n    eval_set=(X_validation, y_validation),\n    cat_features=cat_features,\n    verbose=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import MetricVisualizer\nMetricVisualizer(['learing_rate_0.01', 'learing_rate_0.7']).start()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Best iteration"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=100,\n    random_seed=63,\n    learning_rate=0.5,\n#     use_best_model=False\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    eval_set=(X_validation, y_validation),\n    verbose=False,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Tree count: ' + str(model.tree_count_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cross-validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import cv\n\nparams = {}\nparams['loss_function'] = 'Logloss'\nparams['iterations'] = 80\nparams['custom_loss'] = 'AUC'\nparams['random_seed'] = 63\nparams['learning_rate'] = 0.5\n\ncv_data = cv(\n    params = params,\n    pool = Pool(X, label=y, cat_features=cat_features),\n    fold_count=10,\n    shuffle=True,\n    partition_random_seed=0,\n    plot=True,\n    stratified=False,\n    verbose=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_value = np.min(cv_data['test-Logloss-mean'])\nbest_iter = np.argmin(cv_data['test-Logloss-mean'])\n\nprint('Best validation Logloss score, not stratified: {:.4f}±{:.4f} on step {}'.format(\n    best_value,\n    cv_data['test-Logloss-std'][best_iter],\n    best_iter)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_data = cv(\n    params = params,\n    pool = Pool(X, label=y, cat_features=cat_features),\n    fold_count=5,\n    inverted=False,\n    shuffle=True,\n    partition_random_seed=0,\n    plot=True,\n    stratified=True,\n    verbose=False\n)\n\nbest_value = np.min(cv_data['test-Logloss-mean'])\nbest_iter = np.argmin(cv_data['test-Logloss-mean'])\n\nprint('Best validation Logloss score, stratified: {:.4f}±{:.4f} on step {}'.format(\n    best_value,\n    cv_data['test-Logloss-std'][best_iter],\n    best_iter)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overfitting detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_with_early_stop = CatBoostClassifier(\n    iterations=200,\n    random_seed=63,\n    learning_rate=0.5,\n    early_stopping_rounds=20\n)\nmodel_with_early_stop.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    eval_set=(X_validation, y_validation),\n    verbose=False,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model_with_early_stop.tree_count_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_with_early_stop = CatBoostClassifier(\n    eval_metric='AUC',\n    iterations=200,\n    random_seed=63,\n    learning_rate=0.5,\n    early_stopping_rounds=20\n)\nmodel_with_early_stop.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    eval_set=(X_validation, y_validation),\n    verbose=False,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model_with_early_stop.tree_count_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Select decision boundary"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(\n    random_seed=63,\n    iterations=200,\n    learning_rate=0.03,\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    verbose=False,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://habrastorage.org/webt/y4/1q/yq/y41qyqfm9mcerp2ziys48phpjia.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost.utils import get_roc_curve\nimport sklearn\nfrom sklearn import metrics\n\neval_pool = Pool(X_validation, y_validation, cat_features=cat_features)\ncurve = get_roc_curve(model, eval_pool)\n(fpr, tpr, thresholds) = curve\nroc_auc = sklearn.metrics.auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(16, 8))\nlw = 2\n\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)\n\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', alpha=0.5)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.grid(True)\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('Receiver operating characteristic', fontsize=20)\nplt.legend(loc=\"lower right\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost.utils import get_fpr_curve\nfrom catboost.utils import get_fnr_curve\n\n(thresholds, fpr) = get_fpr_curve(curve=curve)\n(thresholds, fnr) = get_fnr_curve(curve=curve)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nlw = 2\n\nplt.plot(thresholds, fpr, color='blue', lw=lw, label='FPR', alpha=0.5)\nplt.plot(thresholds, fnr, color='green', lw=lw, label='FNR', alpha=0.5)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.grid(True)\nplt.xlabel('Threshold', fontsize=16)\nplt.ylabel('Error Rate', fontsize=16)\nplt.title('FPR-FNR curves', fontsize=20)\nplt.legend(loc=\"lower left\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost.utils import select_threshold\n\nprint(select_threshold(model=model, data=eval_pool, FNR=0.01))\nprint(select_threshold(model=model, data=eval_pool, FPR=0.01))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Snapshotting"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# !rm 'catboost_info/snapshot.bkp'\nfrom catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=100,\n    save_snapshot=True,\n    snapshot_file='snapshot.bkp',\n    snapshot_interval=1,\n    random_seed=43\n)\nmodel.fit(\n    X_train, y_train,\n    eval_set=(X_validation, y_validation),\n    cat_features=cat_features,\n    verbose=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.predict_proba(data=X_validation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.predict(data=X_validation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_pred = model.predict(\n    data=X_validation,\n    prediction_type='RawFormulaVal'\n)\nprint(raw_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import exp\n\nsigmoid = lambda x: 1 / (1 + exp(-x))\n\nprobabilities = sigmoid(raw_pred)\n\nprint(probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_prepared = X_validation.values.astype(str).astype(object)\n# For FeaturesData class categorial features must have type str\n\nfast_predictions = model.predict_proba(\n    data=FeaturesData(\n        cat_feature_data=X_prepared,\n        cat_feature_names=list(X_validation)\n    )\n)\nprint(fast_predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Staged prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_gen = model.staged_predict_proba(\n    data=X_validation,\n    ntree_start=0, \n    ntree_end=5, \n    eval_period=1\n)\ntry:\n    for iteration, predictions in enumerate(predictions_gen):\n        print('Iteration ' + str(iteration) + ', predictions:')\n        print(predictions)\nexcept Exception:\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Solving MultiClassification problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=50,\n    random_seed=43,\n    loss_function='MultiClass'\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    eval_set=(X_validation, y_validation),\n    verbose=False,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metric evaluation on a new dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(\n    random_seed=63,\n    iterations=200,\n    learning_rate=0.03,\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    verbose=50\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics = model.eval_metrics(\n    data=pool1,\n    metrics=['Logloss','AUC'],\n    ntree_start=0,\n    ntree_end=0,\n    eval_period=1,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('AUC values:')\nprint(np.array(metrics['AUC']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Feature importances"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_feature_importance(prettified=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shap values"},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values = model.get_feature_importance(pool1, fstr_type='ShapValues')\nprint(shap_values.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(Pool(X, y, cat_features=cat_features))\n\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[3,:], X.iloc[3,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[91,:], X.iloc[91,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_small = X.iloc[0:200]\nshap_small = shap_values[:200]\nshap.force_plot(explainer.expected_value, shap_small, X_small)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature evaluation"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from catboost.eval.catboost_evaluation import *\nlearn_params = {'iterations': 20, # 2000\n                'learning_rate': 0.5, # we set big learning_rate,\n                                      # because we have small\n                                      # #iterations\n                'random_seed': 0,\n                'verbose': False,\n                'loss_function' : 'Logloss',\n                'boosting_type': 'Plain'}\nevaluator = CatboostEvaluation('amazon/train.tsv',\n                               fold_size=10000, # <= 50% of dataset\n                               fold_count=20,\n                               column_description='amazon/train.cd',\n                               partition_random_seed=0,\n                               #working_dir=... \n)\nresult = evaluator.eval_features(learn_config=learn_params,\n                                 eval_metrics=['Logloss', 'Accuracy'],\n                                 features_to_eval=[6, 7, 8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost.eval.evaluation_result import *\nlogloss_result = result.get_metric_results('Logloss')\nlogloss_result.get_baseline_comparison(\n    ScoreConfig(ScoreType.Rel, overfit_iterations_info=False)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Saving the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_best_model = CatBoostClassifier(iterations=10)\nmy_best_model.fit(\n    X_train, y_train,\n    eval_set=(X_validation, y_validation),\n    cat_features=cat_features,\n    verbose=False\n)\nmy_best_model.save_model('catboost_model.bin')\nmy_best_model.save_model('catboost_model.json', format='json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_best_model.load_model('catboost_model.bin')\nprint(my_best_model.get_params())\nprint(my_best_model.random_seed_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter tunning"},{"metadata":{},"cell_type":"markdown","source":"### Training speed"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoost\nfast_model = CatBoostClassifier(\n    random_seed=63,\n    iterations=150,\n    learning_rate=0.01,\n    boosting_type='Plain',\n    bootstrap_type='Bernoulli',\n    subsample=0.5,\n    one_hot_max_size=20,\n    rsm=0.5,\n    leaf_estimation_iterations=5,\n    max_ctr_complexity=1)\n\nfast_model.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    verbose=False,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy"},{"metadata":{"trusted":false},"cell_type":"code","source":"tunned_model = CatBoostClassifier(\n    random_seed=63,\n    iterations=1000,\n    learning_rate=0.03,\n    l2_leaf_reg=3,\n    bagging_temperature=1,\n    random_strength=1,\n    one_hot_max_size=2,\n    leaf_estimation_method='Newton'\n)\ntunned_model.fit(\n    X_train, y_train,\n    cat_features=cat_features,\n    verbose=False,\n    eval_set=(X_validation, y_validation),\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model after parameter tunning"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_model = CatBoostClassifier(\n    random_seed=63,\n    iterations=int(tunned_model.tree_count_ * 1.2),\n)\nbest_model.fit(\n    X, y,\n    cat_features=cat_features,\n    verbose=100\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate predictions for the contest"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test = test_df.drop('id', axis=1)\ntest_pool = Pool(data=X_test, cat_features=cat_features)\ncontest_predictions = best_model.predict_proba(test_pool)\nprint('Predictoins:')\nprint(contest_predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare the submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"f = open('submit.csv', 'w')\nf.write('Id,Action\\n')\nfor idx in range(len(contest_predictions)):\n    line = str(test_df['id'][idx]) + ',' + str(contest_predictions[idx][1]) + '\\n'\n    f.write(line)\nf.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submit your solution [here](https://www.kaggle.com/c/amazon-employee-access-challenge/submit).\nGood luck!!!"},{"metadata":{},"cell_type":"markdown","source":"## Bonus\n### Solving MultiClassification problem via Ranking"},{"metadata":{},"cell_type":"markdown","source":"For multiclass problems with many classes sometimes it's better to solve classification problem using ranking.\nTo do that we will build a dataset with groups.\nEvery group will represent one object from our initial dataset.\nBut it will have one additional categorical feature - possible class value.\nTarget values will be equal to 1 if the class value is equal to the correct class, and 0 otherwise.\nThus each group will have exactly one 1 in labels, and some zeros.\nYou can put all possible class values in the group or you can try setting only hard negatives if there are too many labels.\nWe'll show this approach on an example of binary classification problem."},{"metadata":{"trusted":false},"cell_type":"code","source":"from copy import deepcopy\ndef build_multiclass_ranking_dataset(X, y, cat_features, label_values=[0,1], start_group_id=0):\n    ranking_matrix = []\n    ranking_labels = []\n    group_ids = []\n\n    X_train_matrix = X.values\n    y_train_vector = y.values\n\n    for obj_idx in range(X.shape[0]):\n        obj = list(X_train_matrix[obj_idx])\n\n        for label in label_values:\n            obj_of_given_class = deepcopy(obj)\n            obj_of_given_class.append(label)\n            ranking_matrix.append(obj_of_given_class)\n            ranking_labels.append(float(y_train_vector[obj_idx] == label)) \n            group_ids.append(start_group_id + obj_idx)\n        \n    final_cat_features = deepcopy(cat_features)\n    final_cat_features.append(X.shape[1]) # new feature that we are adding should be categorical.\n    return Pool(ranking_matrix, ranking_labels, cat_features=final_cat_features, group_id = group_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from catboost import CatBoost\nparams = {'iterations':150, 'learning_rate':0.01, 'l2_leaf_reg':30, 'random_seed':0, 'loss_function':'QuerySoftMax'}\n\ngroupwise_train_pool = build_multiclass_ranking_dataset(X_train, y_train, cat_features, [0,1])\ngroupwise_eval_pool = build_multiclass_ranking_dataset(X_validation, y_validation, cat_features, [0,1], X_train.shape[0])\n\nmodel = CatBoost(params)\nmodel.fit(\n    X=groupwise_train_pool,\n    verbose=False,\n    eval_set=groupwise_eval_pool,\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Doing predictions with ranking mode"},{"metadata":{"trusted":false},"cell_type":"code","source":"import math\n\nobj = list(X_validation.values[0])\nratings = []\nfor label in [0,1]:\n    obj_with_label = deepcopy(obj)\n    obj_with_label.append(label)\n    rating = model.predict([obj_with_label])[0]\n    ratings.append(rating)\nprint('Raw values:', np.array(ratings))\n\ndef soft_max(values):\n    return [math.exp(val) / sum([math.exp(val) for val in values]) for val in values]\n\nprint('Probabilities', np.array(soft_max(ratings)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"widgets":{"state":{"1057714ebc614324aa3ba2cf69408966":{"views":[{"cell_index":17}]},"8381e9eed05f4a03905ae8a56d7ab4ea":{"views":[{"cell_index":48}]},"f49684e8c5c44241bfe2c7f577f5cb41":{"views":[{"cell_index":53}]}},"version":"1.2.0"}},"nbformat":4,"nbformat_minor":4}