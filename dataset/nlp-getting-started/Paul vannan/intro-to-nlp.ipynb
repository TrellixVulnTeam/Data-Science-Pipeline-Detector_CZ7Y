{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Data Loading and Preview\n\ntrain = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n\nprint(train.shape)\nprint(train.columns)\nprint(train[['text','target']].sample(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Investigating Data Properties\nprint(len(train['keyword'].unique()))\nprint(len(train['location'].unique()))\nprint(train['target'].value_counts())\nprint(train['target'].value_counts(normalize = True))\n\nprint(train[train.target == 1]['text'].sample(5).values)\nprint(train[train.target == 0]['text'].sample(5).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train['text'].apply(lambda x: 1 if 'dead' in x.lower() or 'kill' in x.lower() else 0), train['target'])\npd.crosstab(train['text'].apply(lambda x: 1 if 'http' in x.lower() else 0), train['target'], normalize = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#counting words in each tweet\ncount_vectorizer = feature_extraction.text.CountVectorizer()\ntrain_vectors = count_vectorizer.fit_transform(train['text'])\nprint(train_vectors.shape)\nprint(count_vectorizer.get_feature_names()[:20])\n\ntest_vectors = count_vectorizer.transform(test['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_corpus_non_stand = pd.DataFrame(train_vectors.todense())\ntrain_corpus_non_stand.columns = count_vectorizer.get_feature_names()\ntrain_corpus_non_stand.head()\n\ntest_corpus_non_stand = pd.DataFrame(test_vectors.todense())\ntest_corpus_non_stand.columns = count_vectorizer.get_feature_names()\ntest_corpus_non_stand","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_corpus_non_stand.sum().sort_values(ascending = False).head(20)\n\n#too many stopword in our vector list. removing them using nltk\nimport nltk\nfrom nltk.corpus import stopwords\nprint(len(stopwords.words('english')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_normalized_values(train_idv,test_idv):\n    mean,sd,train_idv,test_idv=get_mean_sd(train_idv,test_idv)\n    idvs=list(train_idv.columns)\n    train_x=pd.DataFrame()\n    test_x=pd.DataFrame()\n    for idv in idvs:\n        train_x[idv]=train_idv[idv].apply(lambda m: (m-mean[idv])/sd[idv])\n        test_x[idv]=test_idv[idv].apply(lambda n: (n-mean[idv])/sd[idv])\n    return train_x,test_x\n\ndef get_mean_sd(train_idv,test_idv):\n    mean=np.mean(train_idv)\n    sd=np.std(train_idv)\n    idvs=list(mean.index)\n    for idv in idvs:\n        if sd[idv]==0:\n            train_idv.drop([idv],axis=1,inplace=True)\n            test_idv.drop([idv],axis=1,inplace=True)\n        else:\n            train_idv[idv].fillna(mean[idv],inplace=True)\n            test_idv[idv].fillna(mean[idv],inplace=True)\n    return mean,sd,train_idv,test_idv\n\n#train_stand, test_stand = get_normalized_values(train_corpus_non_stand, test_corpus_non_stand)\ntrain_stand = (train_corpus_non_stand - train_corpus_non_stand.mean())/train_corpus_non_stand.std()\ntest_stand = (test_corpus_non_stand - test_corpus_non_stand.mean())/train_corpus_non_stand.std()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = linear_model.LogisticRegression\nc_values = [0.001, 0.01, 0.1, 1]\nc_values = [0.1]\n\nfor c_value in c_values:\n    model=LR(penalty='l2',C=c_value, solver = 'liblinear')\n    model.fit(train_stand,train['target'].values)\n    scores = model_selection.cross_val_score(model, train_vectors, train[\"target\"], cv=3, scoring=\"f1\")\n    print(scores)\n    print(\"for c_value = \", c_value, \"scores = \", scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RC = linear_model.RidgeClassifier\n\nmodel=RC()\nscores = model_selection.cross_val_score(model, train_vectors, train[\"target\"], cv=3, scoring=\"f1\")\nprint(scores)\nprint(\"for c_value = \", c_value, \"scores = \", scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"] = model.predict(test_vectors)\nsample_submission.to_csv(\"RF_submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}