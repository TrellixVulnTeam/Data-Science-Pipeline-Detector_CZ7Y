{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-10T07:11:05.121066Z","iopub.execute_input":"2021-11-10T07:11:05.121361Z","iopub.status.idle":"2021-11-10T07:11:05.129711Z","shell.execute_reply.started":"2021-11-10T07:11:05.121329Z","shell.execute_reply":"2021-11-10T07:11:05.128283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(r'../input/nlp-getting-started/train.csv')\ntest_data = pd.read_csv(r'../input/nlp-getting-started/test.csv')\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:06.669508Z","iopub.execute_input":"2021-11-10T07:11:06.669752Z","iopub.status.idle":"2021-11-10T07:11:06.713573Z","shell.execute_reply.started":"2021-11-10T07:11:06.669729Z","shell.execute_reply":"2021-11-10T07:11:06.712329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:08.431311Z","iopub.execute_input":"2021-11-10T07:11:08.431554Z","iopub.status.idle":"2021-11-10T07:11:08.442203Z","shell.execute_reply.started":"2021-11-10T07:11:08.43153Z","shell.execute_reply":"2021-11-10T07:11:08.441439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Table of Contents :** \n\n*      <a href=\"#1\">1. Tweets Length Analysis </a>\n\n*      <a href=\"#2\">2. Word Length Analysis </a>\n\n*      <a href=\"#3\">3. Top 10 Stopwords in Corpus </a>\n\n*      <a href=\"#4\">4. Bigrams </a>\n\n*      <a href=\"#5\">5. Trigrams </a>\n\n*      <a href=\"#6\">6. Hastags from Tweets </a>\n\n*      <a href=\"#7\">7. Wordcloud </a>\n\n*      <a href=\"#8\">8. Sentiment Analysis </a>\n","metadata":{}},{"cell_type":"markdown","source":"##  <a id = '1' > Tweets Length Analysis</a>","metadata":{}},{"cell_type":"code","source":"#   Sentence length in \ntext = train_data['text']\ntext.str.len().hist()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:20.691513Z","iopub.execute_input":"2021-11-10T07:11:20.691726Z","iopub.status.idle":"2021-11-10T07:11:20.886241Z","shell.execute_reply.started":"2021-11-10T07:11:20.691703Z","shell.execute_reply":"2021-11-10T07:11:20.884872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id= '2' >Word Length Analysis </a>","metadata":{}},{"cell_type":"code","source":"# Word length Analysis\nimport matplotlib.pyplot as plt\narr = [ ]\nfor i in text:\n    \n    tmp = i.split(' ')\n    arr.append(len(tmp))\nplt.grid()\nplt.hist(arr)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:21.862179Z","iopub.execute_input":"2021-11-10T07:11:21.862398Z","iopub.status.idle":"2021-11-10T07:11:22.097381Z","shell.execute_reply.started":"2021-11-10T07:11:21.862376Z","shell.execute_reply":"2021-11-10T07:11:22.096388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install nltk\nimport nltk \nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstop = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:22.284266Z","iopub.execute_input":"2021-11-10T07:11:22.284623Z","iopub.status.idle":"2021-11-10T07:11:28.87737Z","shell.execute_reply.started":"2021-11-10T07:11:22.284598Z","shell.execute_reply":"2021-11-10T07:11:28.876423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id ='3' >Top 10 Stopwords in Corpus </a>","metadata":{}},{"cell_type":"code","source":"import numpy as np\ncorpus = []\ntmp = []\nfor i in text : \n    tmp.append(i.split())\n    \nfor i in tmp:\n    for words in i :\n        corpus.append(words)\nfrom collections import defaultdict\ndic = defaultdict(int)\nfor i in corpus: \n    if i in stop :\n        dic[i] = dic[i] + 1\nval = dic.values()\nval = sorted(val,reverse = True)\nval = val[0:11]\nd = {}\nfor i in list(dic.keys()):\n    if dic[i] in val: \n        d[i] = dic[i]\n# Top 10 Stopwords in corpus\nplt.bar(list(d.keys()), list(d.values()))","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:28.881142Z","iopub.execute_input":"2021-11-10T07:11:28.881366Z","iopub.status.idle":"2021-11-10T07:11:29.245799Z","shell.execute_reply.started":"2021-11-10T07:11:28.881342Z","shell.execute_reply":"2021-11-10T07:11:29.245224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bigrams, trigrams\nfrom nltk.util import ngrams\nimport collections\ntex = ''\n#word_tokenize = nltk.download('word_tokenize')\nfor i in text : \n    tex = tex + str(i.strip('[]'))\ntok = tex.split()\nb_grams = ngrams(tok, 2) \nt_grams = ngrams(tok,3)\nbigrams = collections.Counter(b_grams)\ntrigrams = collections.Counter(t_grams)\nbi= bigrams.most_common(10)\nti= trigrams.most_common(10)\n#biti\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:29.247032Z","iopub.execute_input":"2021-11-10T07:11:29.247437Z","iopub.status.idle":"2021-11-10T07:11:29.398566Z","shell.execute_reply.started":"2021-11-10T07:11:29.247404Z","shell.execute_reply":"2021-11-10T07:11:29.397815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id = '4'> Bigrams </a>","metadata":{}},{"cell_type":"code","source":"def plot_ngrams(bi):\n    word = []\n    idx = []\n    for i in range(len(bi)):\n        word.append(str(bi[i][0]))\n        idx.append(bi[i][1])\n    plt.figure(figsize = (10,8))\n    plt.bar(word,idx)\n    plt.xticks(word, word, rotation = 'vertical')\n    plt.xlabel('Ngrams')\n    plt.ylabel('Frequency')\n    plt.title('Ngram with Frequency')\n    plt.show()\nplot_ngrams(bi)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:29.399997Z","iopub.execute_input":"2021-11-10T07:11:29.40022Z","iopub.status.idle":"2021-11-10T07:11:29.597006Z","shell.execute_reply.started":"2021-11-10T07:11:29.40019Z","shell.execute_reply":"2021-11-10T07:11:29.595892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='5' >Trigrams </a>","metadata":{}},{"cell_type":"code","source":"plot_ngrams(ti)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:11:29.598677Z","iopub.execute_input":"2021-11-10T07:11:29.599201Z","iopub.status.idle":"2021-11-10T07:11:29.824868Z","shell.execute_reply.started":"2021-11-10T07:11:29.599174Z","shell.execute_reply":"2021-11-10T07:11:29.823996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id = '6'> Hastags from Tweets </a>","metadata":{}},{"cell_type":"code","source":"# Hastags from Tweets \nimport re  \na = ''\nfor i in range(len(text)):\n    tmp = re.search(r'#[a-zA-Z0-9]*', text[i])\n    #print(tmp)\n    if tmp is not None :  \n        tm = re.sub(r'#','' ,tmp.group())\n        a = a + str(tm)+ ' '\n    else: \n        a = a + ''\nfrom wordcloud import WordCloud, STOPWORDS\nstopwords = train_data['keyword'].unique()\nwordcloud = WordCloud()\nwordcloud=wordcloud.generate(a)\n\nfig = plt.figure(1, figsize=(12, 12))\nplt.axis('off')\n\nplt.imshow(wordcloud)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:10:16.83907Z","iopub.execute_input":"2021-11-10T07:10:16.839326Z","iopub.status.idle":"2021-11-10T07:10:17.506371Z","shell.execute_reply.started":"2021-11-10T07:10:16.839266Z","shell.execute_reply":"2021-11-10T07:10:17.505352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='8'> Sentiment Analysis </a>","metadata":{}},{"cell_type":"code","source":"from textblob import TextBlob\npo = []\nfor i in text : \n    analysis = TextBlob(i)\n    po.append(analysis.sentiment.polarity)\ndic = { 'polarity': po, 'Tweets': text }\nplt.plot(po[:20])","metadata":{"execution":{"iopub.status.busy":"2021-11-10T07:26:52.239526Z","iopub.execute_input":"2021-11-10T07:26:52.239771Z","iopub.status.idle":"2021-11-10T07:26:53.870412Z","shell.execute_reply.started":"2021-11-10T07:26:52.239748Z","shell.execute_reply":"2021-11-10T07:26:53.869644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}