{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom fastai.text.all import *\nimport re","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:34.86871Z","iopub.execute_input":"2021-06-11T07:52:34.869228Z","iopub.status.idle":"2021-06-11T07:52:39.631629Z","shell.execute_reply.started":"2021-06-11T07:52:34.869073Z","shell.execute_reply":"2021-06-11T07:52:39.630517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import the data and clean it","metadata":{}},{"cell_type":"code","source":"dir_path = \"/kaggle/input/nlp-getting-started/\"\ntrain_df = pd.read_csv(dir_path + \"train.csv\")\ntest_df = pd.read_csv(dir_path + \"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:39.635457Z","iopub.execute_input":"2021-06-11T07:52:39.635767Z","iopub.status.idle":"2021-06-11T07:52:39.724786Z","shell.execute_reply.started":"2021-06-11T07:52:39.635735Z","shell.execute_reply":"2021-06-11T07:52:39.723827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:39.72689Z","iopub.execute_input":"2021-06-11T07:52:39.727397Z","iopub.status.idle":"2021-06-11T07:52:39.759407Z","shell.execute_reply.started":"2021-06-11T07:52:39.727355Z","shell.execute_reply":"2021-06-11T07:52:39.758299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(columns=[\"id\", \"keyword\", \"location\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:39.763197Z","iopub.execute_input":"2021-06-11T07:52:39.763526Z","iopub.status.idle":"2021-06-11T07:52:39.771658Z","shell.execute_reply.started":"2021-06-11T07:52:39.763498Z","shell.execute_reply":"2021-06-11T07:52:39.770496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:39.775198Z","iopub.execute_input":"2021-06-11T07:52:39.775528Z","iopub.status.idle":"2021-06-11T07:52:39.787498Z","shell.execute_reply.started":"2021-06-11T07:52:39.7755Z","shell.execute_reply":"2021-06-11T07:52:39.786387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ntrain_df[\"text\"] = train_df[\"text\"].apply(remove_URL)\ntest_df[\"text\"] = test_df[\"text\"].apply(remove_URL)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:39.790287Z","iopub.execute_input":"2021-06-11T07:52:39.790604Z","iopub.status.idle":"2021-06-11T07:52:39.847337Z","shell.execute_reply.started":"2021-06-11T07:52:39.790577Z","shell.execute_reply":"2021-06-11T07:52:39.846249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ntrain_df[\"text\"] = train_df[\"text\"].apply(remove_html)\ntest_df[\"text\"] = test_df[\"text\"].apply(remove_html)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:39.851205Z","iopub.execute_input":"2021-06-11T07:52:39.851608Z","iopub.status.idle":"2021-06-11T07:52:39.88343Z","shell.execute_reply.started":"2021-06-11T07:52:39.851579Z","shell.execute_reply":"2021-06-11T07:52:39.879868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ntrain_df[\"text\"] = train_df[\"text\"].apply(remove_emoji)\ntest_df[\"text\"] = test_df[\"text\"].apply(remove_emoji)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:39.890658Z","iopub.execute_input":"2021-06-11T07:52:39.891422Z","iopub.status.idle":"2021-06-11T07:52:40.044213Z","shell.execute_reply.started":"2021-06-11T07:52:39.891372Z","shell.execute_reply":"2021-06-11T07:52:40.043132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:40.046152Z","iopub.execute_input":"2021-06-11T07:52:40.046828Z","iopub.status.idle":"2021-06-11T07:52:40.066608Z","shell.execute_reply.started":"2021-06-11T07:52:40.046782Z","shell.execute_reply":"2021-06-11T07:52:40.065345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"text\"].apply(lambda x:len(x.split())).plot(kind=\"hist\");","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:40.068151Z","iopub.execute_input":"2021-06-11T07:52:40.068919Z","iopub.status.idle":"2021-06-11T07:52:40.507263Z","shell.execute_reply.started":"2021-06-11T07:52:40.068858Z","shell.execute_reply":"2021-06-11T07:52:40.505628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get tokens for the transformer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:40.512448Z","iopub.execute_input":"2021-06-11T07:52:40.512876Z","iopub.status.idle":"2021-06-11T07:52:41.314733Z","shell.execute_reply.started":"2021-06-11T07:52:40.512833Z","shell.execute_reply":"2021-06-11T07:52:41.313578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:41.317283Z","iopub.execute_input":"2021-06-11T07:52:41.31791Z","iopub.status.idle":"2021-06-11T07:52:47.324383Z","shell.execute_reply.started":"2021-06-11T07:52:41.317849Z","shell.execute_reply":"2021-06-11T07:52:47.323246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the graph above, we can know that the longest tweet has 30 words, so I set the `max_length` to 30.","metadata":{}},{"cell_type":"code","source":"train_tensor = tokenizer(list(train_df[\"text\"]), padding=\"max_length\",\n                        truncation=True, max_length=30,\n                        return_tensors=\"pt\")[\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:47.32577Z","iopub.execute_input":"2021-06-11T07:52:47.326228Z","iopub.status.idle":"2021-06-11T07:52:48.248254Z","shell.execute_reply.started":"2021-06-11T07:52:47.326164Z","shell.execute_reply":"2021-06-11T07:52:48.247058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing datasets and dataloaders","metadata":{}},{"cell_type":"code","source":"class TweetDataset:\n    def __init__(self, tensors, targ, ids):\n        self.text = tensors[ids, :]\n        self.targ = targ[ids].reset_index(drop=True)\n    \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        \n        t = self.text[idx]\n        y = self.targ[idx]\n        \n        return t, tensor(y)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:48.250206Z","iopub.execute_input":"2021-06-11T07:52:48.250626Z","iopub.status.idle":"2021-06-11T07:52:48.258611Z","shell.execute_reply.started":"2021-06-11T07:52:48.250585Z","shell.execute_reply":"2021-06-11T07:52:48.257178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids, valid_ids = RandomSplitter()(train_df)\n\n\ntarget = train_df[\"target\"]\n\ntrain_ds = TweetDataset(train_tensor, target, train_ids)\nvalid_ds = TweetDataset(train_tensor, target, valid_ids)\n\ntrain_dl = DataLoader(train_ds, bs=64)\nvalid_dl = DataLoader(valid_ds, bs=512)\ndls = DataLoaders(train_dl, valid_dl).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:48.26039Z","iopub.execute_input":"2021-06-11T07:52:48.26101Z","iopub.status.idle":"2021-06-11T07:52:48.316658Z","shell.execute_reply.started":"2021-06-11T07:52:48.260952Z","shell.execute_reply":"2021-06-11T07:52:48.315689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get the model","metadata":{}},{"cell_type":"code","source":"bert = AutoModelForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=2).train().to(\"cuda\")\n\nclass BertClassifier(Module):\n    def __init__(self, bert):\n        self.bert = bert\n    def forward(self, x):\n        return self.bert(x).logits\n\nmodel = BertClassifier(bert)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:52:48.318003Z","iopub.execute_input":"2021-06-11T07:52:48.318489Z","iopub.status.idle":"2021-06-11T07:54:00.333482Z","shell.execute_reply.started":"2021-06-11T07:52:48.31845Z","shell.execute_reply":"2021-06-11T07:54:00.332295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start training","metadata":{}},{"cell_type":"code","source":"learn = Learner(dls, model, metrics=[accuracy, F1Score()]).to_fp16()\nlearn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:54:14.214835Z","iopub.execute_input":"2021-06-11T07:54:14.215238Z","iopub.status.idle":"2021-06-11T07:55:32.680186Z","shell.execute_reply.started":"2021-06-11T07:54:14.215205Z","shell.execute_reply":"2021-06-11T07:55:32.679086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fit_one_cycle(3, lr_max=1e-5)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:55:35.487413Z","iopub.execute_input":"2021-06-11T07:55:35.487798Z","iopub.status.idle":"2021-06-11T07:59:27.439196Z","shell.execute_reply.started":"2021-06-11T07:55:35.487752Z","shell.execute_reply":"2021-06-11T07:59:27.437834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find the best threshold for f1 score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\npreds, targs = learn.get_preds()\n\nmin_threshold = None\nmax_f1 = -float(\"inf\")\nthresholds = np.linspace(0.3, 0.7, 50)\nfor threshold in thresholds:\n    f1 = f1_score(targs, F.softmax(preds, dim=1)[:, 1]>threshold)\n    if f1 > max_f1:\n        min_threshold = threshold\n        min_f1 = f1\n    print(f\"threshold:{threshold:.4f} - f1:{f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:59:33.817456Z","iopub.execute_input":"2021-06-11T07:59:33.81782Z","iopub.status.idle":"2021-06-11T07:59:38.754664Z","shell.execute_reply.started":"2021-06-11T07:59:33.817789Z","shell.execute_reply":"2021-06-11T07:59:38.753551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make prediction on the test set and submit the prediction","metadata":{}},{"cell_type":"code","source":"test_tensor = tokenizer(list(test_df[\"text\"]),\n                        padding=\"max_length\",\n                        truncation=True,\n                        max_length=30,\n                        return_tensors=\"pt\")[\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:59:38.757446Z","iopub.execute_input":"2021-06-11T07:59:38.757858Z","iopub.status.idle":"2021-06-11T07:59:39.25662Z","shell.execute_reply.started":"2021-06-11T07:59:38.757814Z","shell.execute_reply":"2021-06-11T07:59:39.255432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDS:\n    def __init__(self, tensors):\n        self.tensors = tensors\n    \n    def __len__(self):\n        return len(self.tensors)\n    \n    def __getitem__(self, idx):\n        t = self.tensors[idx]\n        return t, tensor(0)\n\ntest_dl = DataLoader(TestDS(test_tensor), bs=128)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:59:39.258743Z","iopub.execute_input":"2021-06-11T07:59:39.259165Z","iopub.status.idle":"2021-06-11T07:59:39.268877Z","shell.execute_reply.started":"2021-06-11T07:59:39.259118Z","shell.execute_reply":"2021-06-11T07:59:39.266127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = learn.get_preds(dl=test_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:59:39.270866Z","iopub.execute_input":"2021-06-11T07:59:39.271392Z","iopub.status.idle":"2021-06-11T07:59:50.071598Z","shell.execute_reply.started":"2021-06-11T07:59:39.271331Z","shell.execute_reply":"2021-06-11T07:59:50.070513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(dir_path + \"sample_submission.csv\")\nprediction = (F.softmax(test_preds[0], dim=1)[:, 1]>min_threshold).int()\nsub = pd.read_csv(dir_path + \"sample_submission.csv\")\nsub[\"target\"] = prediction\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T07:59:50.073342Z","iopub.execute_input":"2021-06-11T07:59:50.073826Z","iopub.status.idle":"2021-06-11T07:59:50.290133Z","shell.execute_reply.started":"2021-06-11T07:59:50.073781Z","shell.execute_reply":"2021-06-11T07:59:50.288816Z"},"trusted":true},"execution_count":null,"outputs":[]}]}