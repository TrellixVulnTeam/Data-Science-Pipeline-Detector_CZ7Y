{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Competition description\n\nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n\nBut, it’s not always clear whether a person’s words are actually announcing a disaster.\n\nAcknowledgments\n\nThis dataset was created by the company figure-eight and originally shared on their ‘Data For Everyone’ website here.","metadata":{}},{"cell_type":"markdown","source":"Import libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:01.803266Z","iopub.execute_input":"2022-06-28T14:11:01.803672Z","iopub.status.idle":"2022-06-28T14:11:01.811769Z","shell.execute_reply.started":"2022-06-28T14:11:01.803635Z","shell.execute_reply":"2022-06-28T14:11:01.810703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loads train, test, and sample files","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-28T14:11:01.817616Z","iopub.execute_input":"2022-06-28T14:11:01.81798Z","iopub.status.idle":"2022-06-28T14:11:01.880515Z","shell.execute_reply.started":"2022-06-28T14:11:01.817951Z","shell.execute_reply":"2022-06-28T14:11:01.879365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read","metadata":{}},{"cell_type":"code","source":"train  = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsubmission = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-06-28T14:11:01.882239Z","iopub.execute_input":"2022-06-28T14:11:01.882641Z","iopub.status.idle":"2022-06-28T14:11:01.922948Z","shell.execute_reply.started":"2022-06-28T14:11:01.882601Z","shell.execute_reply":"2022-06-28T14:11:01.921998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:01.924196Z","iopub.execute_input":"2022-06-28T14:11:01.924501Z","iopub.status.idle":"2022-06-28T14:11:01.943698Z","shell.execute_reply.started":"2022-06-28T14:11:01.924469Z","shell.execute_reply":"2022-06-28T14:11:01.9424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:01.945553Z","iopub.execute_input":"2022-06-28T14:11:01.94623Z","iopub.status.idle":"2022-06-28T14:11:01.963732Z","shell.execute_reply.started":"2022-06-28T14:11:01.94618Z","shell.execute_reply":"2022-06-28T14:11:01.962865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:01.965625Z","iopub.execute_input":"2022-06-28T14:11:01.966062Z","iopub.status.idle":"2022-06-28T14:11:01.97659Z","shell.execute_reply.started":"2022-06-28T14:11:01.966032Z","shell.execute_reply":"2022-06-28T14:11:01.975706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Combine train and test","metadata":{}},{"cell_type":"code","source":"target = train.target\ntrain.drop('target', axis=1, inplace=True)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:01.97872Z","iopub.execute_input":"2022-06-28T14:11:01.979108Z","iopub.status.idle":"2022-06-28T14:11:01.997518Z","shell.execute_reply.started":"2022-06-28T14:11:01.979078Z","shell.execute_reply":"2022-06-28T14:11:01.996695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combi = train.append(test)\ncombi","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:01.998618Z","iopub.execute_input":"2022-06-28T14:11:01.999003Z","iopub.status.idle":"2022-06-28T14:11:02.018749Z","shell.execute_reply.started":"2022-06-28T14:11:01.998975Z","shell.execute_reply":"2022-06-28T14:11:02.01776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Impute any null values","metadata":{}},{"cell_type":"code","source":"combi.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.020839Z","iopub.execute_input":"2022-06-28T14:11:02.021312Z","iopub.status.idle":"2022-06-28T14:11:02.034773Z","shell.execute_reply.started":"2022-06-28T14:11:02.021252Z","shell.execute_reply":"2022-06-28T14:11:02.033625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# substitue NaN value here with mode\n\ncombi['location'] = combi['location'].fillna(\"not listed\")\ncombi['keyword'] = combi['keyword'].fillna(\"not listed\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.036249Z","iopub.execute_input":"2022-06-28T14:11:02.036889Z","iopub.status.idle":"2022-06-28T14:11:02.045349Z","shell.execute_reply.started":"2022-06-28T14:11:02.036856Z","shell.execute_reply":"2022-06-28T14:11:02.04425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combi.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.04672Z","iopub.execute_input":"2022-06-28T14:11:02.047257Z","iopub.status.idle":"2022-06-28T14:11:02.062947Z","shell.execute_reply.started":"2022-06-28T14:11:02.047211Z","shell.execute_reply":"2022-06-28T14:11:02.062003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare tweets in train and test file","metadata":{}},{"cell_type":"code","source":"#compare tweets in train and test file\nlength_train=train['text'].str.len()\nlength_test=test['text'].str.len()\nplt.hist(length_train, bins=20, label=\"train_tweets\")\nplt.hist(length_test, bins=20, label=\"test_tweets\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.064794Z","iopub.execute_input":"2022-06-28T14:11:02.065234Z","iopub.status.idle":"2022-06-28T14:11:02.32555Z","shell.execute_reply.started":"2022-06-28T14:11:02.06519Z","shell.execute_reply":"2022-06-28T14:11:02.324577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Identify percentage of disaster tweets","metadata":{}},{"cell_type":"code","source":"target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.327138Z","iopub.execute_input":"2022-06-28T14:11:02.327483Z","iopub.status.idle":"2022-06-28T14:11:02.336194Z","shell.execute_reply.started":"2022-06-28T14:11:02.327443Z","shell.execute_reply":"2022-06-28T14:11:02.335072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentage_disaster=(target.value_counts() / len(train)) * 100\npercentage_disaster","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.337725Z","iopub.execute_input":"2022-06-28T14:11:02.338048Z","iopub.status.idle":"2022-06-28T14:11:02.354239Z","shell.execute_reply.started":"2022-06-28T14:11:02.338016Z","shell.execute_reply":"2022-06-28T14:11:02.353198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(target)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.355918Z","iopub.execute_input":"2022-06-28T14:11:02.356412Z","iopub.status.idle":"2022-06-28T14:11:02.528088Z","shell.execute_reply.started":"2022-06-28T14:11:02.356364Z","shell.execute_reply":"2022-06-28T14:11:02.527268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing raw text and getting it ready for machine learning","metadata":{}},{"cell_type":"code","source":"tweets = combi['text']\n\ncount_words = tweets.str.findall(r'(\\w+)').str.len()\nprint(count_words.sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.530821Z","iopub.execute_input":"2022-06-28T14:11:02.531288Z","iopub.status.idle":"2022-06-28T14:11:02.618185Z","shell.execute_reply.started":"2022-06-28T14:11:02.531254Z","shell.execute_reply":"2022-06-28T14:11:02.617066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\n\nstopwords = set(stopwords.words(\"english\"))\nstemmer = PorterStemmer()\nlemmatizer = WordNetLemmatizer()\n\n\"\"\" Cleaning Tweets \"\"\"\ntweets = tweets.str.lower()\n\n#stem the text\ntweets = tweets.apply(lambda x: \" \".join([stemmer.stem(i)\nfor i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in stopwords]).lower())\n\n#lemmatize the text\ntweets = tweets.apply(lambda x: \" \".join([lemmatizer.lemmatize(i)\nfor i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in stopwords]).lower())\n\n# removing special characters and numbers\ntweets = tweets.apply(lambda x : re.sub(\"[^a-z]\\s\",\"\",x) )\n\n# remove hash tags\ntweets = tweets.str.replace(\"#\", \"\")\n\n#remove words less than 3 character and greater than 7\ntweets = tweets.apply(lambda x: ' '.join([w for w in x.split() if len(w)>2 and len(w)<8]))\n\n# removing stopwords\ntweets = tweets.apply(lambda x : \" \".join(word for word in x.split() if word not in stopwords ))\n\ncount_words = tweets.str.findall(r'(\\w+)').str.len()\nprint(count_words.sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:02.620813Z","iopub.execute_input":"2022-06-28T14:11:02.621394Z","iopub.status.idle":"2022-06-28T14:11:05.743753Z","shell.execute_reply.started":"2022-06-28T14:11:02.621345Z","shell.execute_reply":"2022-06-28T14:11:05.742924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_words = tweets.str.findall(r'(\\w+)').str.len()\nprint(count_words.sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:05.74475Z","iopub.execute_input":"2022-06-28T14:11:05.745144Z","iopub.status.idle":"2022-06-28T14:11:05.790727Z","shell.execute_reply.started":"2022-06-28T14:11:05.745114Z","shell.execute_reply":"2022-06-28T14:11:05.789964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove frequently used words","metadata":{}},{"cell_type":"code","source":"most_freq_words = pd.Series(' '.join(tweets).lower().split()).value_counts()[:25]\ntweets = tweets.apply(lambda x : \" \".join(word for word in x.split() if word not in most_freq_words ))\nprint(most_freq_words)\n\ncount_words = tweets.str.findall(r'(\\w+)').str.len()\nprint(count_words.sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:05.79173Z","iopub.execute_input":"2022-06-28T14:11:05.792141Z","iopub.status.idle":"2022-06-28T14:11:06.003687Z","shell.execute_reply.started":"2022-06-28T14:11:05.792112Z","shell.execute_reply":"2022-06-28T14:11:06.002768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove rare words","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom itertools import chain\n\n# split words into lists\nv = tweets.str.split().tolist() \n# compute global word frequency\nc = Counter(chain.from_iterable(v))\n# filter, join, and re-assign\ntweets = [' '.join([j for j in i if c[j] > 1]) for i in v]\n\ntotal_word = 0\nfor x,word in enumerate(tweets):\n    num_word = len(word.split())\n    #print(num_word)\n    total_word = total_word + num_word\nprint(total_word)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:06.004963Z","iopub.execute_input":"2022-06-28T14:11:06.005248Z","iopub.status.idle":"2022-06-28T14:11:06.079124Z","shell.execute_reply.started":"2022-06-28T14:11:06.00522Z","shell.execute_reply":"2022-06-28T14:11:06.078268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create tokens in spacy","metadata":{}},{"cell_type":"code","source":"import spacy\nimport spacy.cli\nspacy.cli.download(\"en_vectors_web_lg\")\nnlp = spacy.load('en_vectors_web_lg')","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:06.080531Z","iopub.execute_input":"2022-06-28T14:11:06.08083Z","iopub.status.idle":"2022-06-28T14:11:23.454665Z","shell.execute_reply.started":"2022-06-28T14:11:06.0808Z","shell.execute_reply":"2022-06-28T14:11:23.45282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nimport en_vectors_web_lg\n\nnlp = en_vectors_web_lg.load()\ndocument = nlp(tweets[0])\nprint(\"Document : \",document)\nprint(\"Tokens : \")\nfor token in document:\n       print(token.text)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:23.456929Z","iopub.execute_input":"2022-06-28T14:11:23.457349Z","iopub.status.idle":"2022-06-28T14:11:35.669068Z","shell.execute_reply.started":"2022-06-28T14:11:23.4573Z","shell.execute_reply":"2022-06-28T14:11:35.66795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Token to vector","metadata":{}},{"cell_type":"code","source":"document = nlp(tweets[0])\nprint(document)\nfor token in document:\n    print(token.text, token.vector.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:35.670477Z","iopub.execute_input":"2022-06-28T14:11:35.671092Z","iopub.status.idle":"2022-06-28T14:11:35.679277Z","shell.execute_reply.started":"2022-06-28T14:11:35.671044Z","shell.execute_reply":"2022-06-28T14:11:35.67816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sentence to vector using pipe","metadata":{}},{"cell_type":"code","source":"document = nlp.pipe(tweets)\ntweets_vector = np.array([tweet.vector for tweet in document])\nprint(tweets_vector.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:35.680952Z","iopub.execute_input":"2022-06-28T14:11:35.681305Z","iopub.status.idle":"2022-06-28T14:11:36.691576Z","shell.execute_reply.started":"2022-06-28T14:11:35.681274Z","shell.execute_reply":"2022-06-28T14:11:36.690333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define X, y and X_test","metadata":{}},{"cell_type":"code","source":"#define x, y and t_test\ny = target\nX=tweets_vector[: len(train)]\nX_test=tweets_vector[len(train) :]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:36.693188Z","iopub.execute_input":"2022-06-28T14:11:36.693494Z","iopub.status.idle":"2022-06-28T14:11:36.69788Z","shell.execute_reply.started":"2022-06-28T14:11:36.693462Z","shell.execute_reply":"2022-06-28T14:11:36.697056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split train set for training and testing","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.10, random_state=42, shuffle=True)\nX_train.shape, X_val.shape, y_train.shape,y_val.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:36.699317Z","iopub.execute_input":"2022-06-28T14:11:36.699631Z","iopub.status.idle":"2022-06-28T14:11:36.724961Z","shell.execute_reply.started":"2022-06-28T14:11:36.699603Z","shell.execute_reply":"2022-06-28T14:11:36.72395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define and train the model","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(C=10,max_iter=1000).fit(X_train, y_train)\nprint(model.score(X_train, y_train))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:36.726717Z","iopub.execute_input":"2022-06-28T14:11:36.727083Z","iopub.status.idle":"2022-06-28T14:11:37.146149Z","shell.execute_reply.started":"2022-06-28T14:11:36.727054Z","shell.execute_reply":"2022-06-28T14:11:37.145104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict on validation set","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_val)\nprint(model.score(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:37.147758Z","iopub.execute_input":"2022-06-28T14:11:37.148274Z","iopub.status.idle":"2022-06-28T14:11:37.159189Z","shell.execute_reply.started":"2022-06-28T14:11:37.148228Z","shell.execute_reply":"2022-06-28T14:11:37.158097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_val, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:37.161023Z","iopub.execute_input":"2022-06-28T14:11:37.161861Z","iopub.status.idle":"2022-06-28T14:11:37.173357Z","shell.execute_reply.started":"2022-06-28T14:11:37.161813Z","shell.execute_reply":"2022-06-28T14:11:37.172397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame({'Actual': y_val, 'Predicted':y_pred})\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:37.174876Z","iopub.execute_input":"2022-06-28T14:11:37.175503Z","iopub.status.idle":"2022-06-28T14:11:37.189959Z","shell.execute_reply.started":"2022-06-28T14:11:37.175459Z","shell.execute_reply":"2022-06-28T14:11:37.189201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict on test set","metadata":{}},{"cell_type":"code","source":"test_pred = model.predict(X_test)\ntest_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:37.191071Z","iopub.execute_input":"2022-06-28T14:11:37.191575Z","iopub.status.idle":"2022-06-28T14:11:37.200367Z","shell.execute_reply.started":"2022-06-28T14:11:37.191541Z","shell.execute_reply":"2022-06-28T14:11:37.199627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission","metadata":{}},{"cell_type":"code","source":"submission['target'] = test_pred\nsubmission.to_csv('submission.csv',index=False) # writing data to a CSV file\nsubmission = pd.read_csv(\"submission.csv\")\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:11:37.201832Z","iopub.execute_input":"2022-06-28T14:11:37.20246Z","iopub.status.idle":"2022-06-28T14:11:37.535978Z","shell.execute_reply.started":"2022-06-28T14:11:37.202399Z","shell.execute_reply":"2022-06-28T14:11:37.535133Z"},"trusted":true},"execution_count":null,"outputs":[]}]}