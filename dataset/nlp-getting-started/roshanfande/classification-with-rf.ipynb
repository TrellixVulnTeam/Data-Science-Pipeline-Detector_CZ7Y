{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-----Importing Required Libraries-----#\nimport re\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom textblob import Word\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T11:26:47.894741Z","iopub.execute_input":"2021-07-14T11:26:47.895082Z","iopub.status.idle":"2021-07-14T11:26:49.792093Z","shell.execute_reply.started":"2021-07-14T11:26:47.895055Z","shell.execute_reply":"2021-07-14T11:26:49.790961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---Text Preprocessing-----------#\n\ndef clean_str(string):\n    \"\"\"\n    Tokenization/string cleaning for datasets.\n    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n    \"\"\"\n    string = re.sub(r\"\\'s\", \"\", string)\n    string = re.sub(r\"\\'ve\", \"\", string)\n    string = re.sub(r\"n\\'t\", \"\", string)\n    string = re.sub(r\"\\'re\", \"\", string)\n    string = re.sub(r\"\\'d\", \"\", string)\n    string = re.sub(r\"\\'ll\", \"\", string)\n    string = re.sub(r\",\", \"\", string)\n    string = re.sub(r\"!\", \" ! \", string)\n    string = re.sub(r\"\\(\", \"\", string)\n    string = re.sub(r\"\\)\", \"\", string)\n    string = re.sub(r\"\\?\", \"\", string)\n    string = re.sub(r\"'\", \"\", string)\n    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n    string = re.sub(r\"[0-9]\\w+|[0-9]\",\"\", string)\n    string = re.sub(r\"\\s{2,}\", \" \", string)\n    return string.strip().lower()\n\ndata = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\nx = data['text'].tolist()\ny = data['target'].tolist()\n\nfor index,value in enumerate(x):\n    print(\"processing data:\",index)\n    x[index] = ' '.join([Word(word).lemmatize(\"v\") for word in clean_str(value).split()])\n\nvect = TfidfVectorizer(stop_words='english',min_df=2)\nX = vect.fit_transform(x)\nY = np.array(y)\nprint(\"no of features extracted:\",X.shape[1])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T11:26:53.952571Z","iopub.execute_input":"2021-07-14T11:26:53.952944Z","iopub.status.idle":"2021-07-14T11:26:59.652456Z","shell.execute_reply.started":"2021-07-14T11:26:53.952907Z","shell.execute_reply":"2021-07-14T11:26:59.651743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------Splitting data into Train-Test----------#\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n\nprint(\"train size:\", X_train.shape)\nprint(\"test size:\", X_test.shape)\n\n#-------Building Model--------------------------#\n\nmodel = RandomForestClassifier(n_estimators=300, max_depth=150,n_jobs=1)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nc_mat = confusion_matrix(y_test,y_pred)\ncls_report=classification_report(y_test,y_pred)\nprint(cls_report)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T11:27:09.539349Z","iopub.execute_input":"2021-07-14T11:27:09.539853Z","iopub.status.idle":"2021-07-14T11:27:24.31493Z","shell.execute_reply.started":"2021-07-14T11:27:09.539821Z","shell.execute_reply":"2021-07-14T11:27:24.313913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------Feteching prediction using built model-------------#\ntest_data=pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntest_text=test_data['text']\ntest_text_vect = vect.transform(test_text)\ntest_prediction=model.predict(test_text_vect)\nfinal_prediction=pd.DataFrame(test_prediction)\nResult=pd.concat([test_data['id'],final_prediction],axis=1)\nResult.to_csv('prediction.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T11:27:26.853299Z","iopub.execute_input":"2021-07-14T11:27:26.853811Z","iopub.status.idle":"2021-07-14T11:27:27.44593Z","shell.execute_reply.started":"2021-07-14T11:27:26.85378Z","shell.execute_reply":"2021-07-14T11:27:27.445159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}