{"cells":[{"metadata":{},"cell_type":"markdown","source":"# importing the libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn import linear_model\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## given datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"ls ../input/nlp-getting-started/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# importing the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-Fold"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\ndef fold(df):\n    df['kfold'] = -1\n    df = df.sample(frac=0.1).reset_index(drop=True)\n    y = df.target.values\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    for f_,(t_,v_) in enumerate(kf.split(X=df, y=y)):\n        df.loc[v_, 'kfold'] = f_\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = fold(train_df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(fold):\n    \n    # splitting the dataset into training and validation dataset\n    train_df = df[df.kfold != fold].reset_index(drop=True)\n    valid_df = df[df.kfold == fold].reset_index(drop=True)\n    \n    # Initializing count vectorizer with word_tokenize as a tokenizer\n    cv = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n    cv.fit(train_df.text)\n    \n    # trainforming training and validation dataset\n    x_train = cv.transform(train_df.text)\n    x_valid = cv.transform(valid_df.text)\n\n    # initializing logistic regression\n    model = linear_model.LogisticRegression()\n    \n    # fitting the modelo\n    model.fit(x_train, train_df.target)\n    \n    #prediction on validation set\n    preds = model.predict(x_valid)\n    \n    # Accuracy score\n    accuracy = metrics.accuracy_score(preds, valid_df.target)\n    \n    print(f\"Accuracy:{accuracy}\")\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold in range(5):\n    train(fold)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Neive Baise"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import naive_bayes\n\ndef train(fold):\n    \n    # splitting the dataset into training and validation dataset\n    train_df = df[df.kfold != fold].reset_index(drop=True)\n    valid_df = df[df.kfold == fold].reset_index(drop=True)\n    \n    # Initializing count vectorizer with word_tokenize as a tokenizer\n    cv = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n    cv.fit(train_df.text)\n    \n    # trainforming training and validation dataset\n    x_train = cv.transform(train_df.text)\n    x_valid = cv.transform(valid_df.text)\n\n    # initializing logistic regression\n    model = naive_bayes.MultinomialNB()\n    \n    # fitting the modelo\n    model.fit(x_train, train_df.target)\n    \n    #prediction on validation set\n    preds = model.predict(x_valid)\n    \n    # Accuracy score\n    accuracy = metrics.accuracy_score(preds, valid_df.target)\n    \n    print(f\"Accuracy:{accuracy}\")\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold in range(5):\n    train(fold)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regressin with TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(fold):\n    \n    # splitting the dataset into training and validation dataset\n    train_df = df[df.kfold != fold].reset_index(drop=True)\n    valid_df = df[df.kfold == fold].reset_index(drop=True)\n    \n    # Initializing count vectorizer with word_tokenize as a tokenizer\n    cv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None, ngram_range=(1, 4))\n    cv.fit(train_df.text)\n    \n    # trainforming training and validation dataset\n    x_train = cv.transform(train_df.text)\n    x_valid = cv.transform(valid_df.text)\n\n    # initializing logistic regression\n    model = linear_model.LogisticRegression()\n    \n    # fitting the modelo\n    model.fit(x_train, train_df.target)\n    \n    #prediction on validation set\n    preds = model.predict(x_valid)\n    \n    # Accuracy score\n    accuracy = metrics.accuracy_score(preds, valid_df.target)\n    \n    print(f\"Accuracy:{accuracy}\")\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold in range(5):\n    train(fold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}