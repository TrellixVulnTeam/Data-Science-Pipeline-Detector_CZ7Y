{"cells":[{"metadata":{},"cell_type":"markdown","source":"＊＊つい先日RNNの勉強を始めたので、そこまで難しいことをしていない方のノートブックをコピーして一部編集しています。\nなるべく、知らないことがあったら説明やリンクを乗っけるようにしてます、"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras as keras\nfrom keras.models import Sequential, load_model\nfrom keras.layers import LSTM, GRU,SimpleRNN\nfrom keras.layers import Dense, Embedding, Bidirectional, Dropout, Flatten\nfrom keras.optimizers import Adam, SGD\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\nearly_stop=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dataset Load**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Dataset contain {} samples'.format(train.shape[0]))\nprint('Testing Dataset contain {} samples'.format(test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop 'id', 'keyword' and 'location columns as we are going to train an RNN only on text data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['id', 'keyword', 'location'], axis=1)\ntest = test.drop(['id', 'keyword', 'location'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train =  train['target'].values\nX_train = train.drop(['target'], axis=1).values.reshape(len(train),)\nX_test = test['text'].values.reshape(len(test),)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train)\nprint(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets = np.concatenate((X_train, X_test))\nprint('Total tweets : ', len(total_tweets))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"numpy.concatenate()の基本的な使い方\n\n結合する配列ndarrayのリストを指定\n\n結合する軸（次元）を指定: 引数axis\n\nnumpy.stack()で新たな軸（次元）に沿って結合\n\nnumpy.block()で配置を指定して結合\n\nnumpy.vstack()で縦に結合\n\nnumpy.hstack()で横に結合\n\nnumpy.dstack()で深さ方向に結合"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"単語の文字列のindexを構築"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(total_tweets)\n\n# Vocbvulary Size\n#　trian、testのツイートの総単語数（単語の次元数）を取得\nvocab_size = len(tokenizer.word_index) + 1\nprint('Size of Vocabulary : ', vocab_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## [tokenizerの使いかたまとめ](https://weblabo.oscasierra.net/python/keras-tokenizer.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Maximum length for padding sequence\nmaxlen = max(len(x.split()) for x in total_tweets)\nprint('Maximum length of tweet : ', maxlen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"文字列を整数のインデックスのリストに変換"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_token = tokenizer.texts_to_sequences(X_train)\nX_test_token = tokenizer.texts_to_sequences(X_test)\n\nprint('Text before tokenized')\nprint(X_train[0])\nprint('\\nText after tokenized')\nprint(X_train_token[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n要素の合わない配列に対して、0 で埋めるなどして配列のサイズを一致させる。\n[参考記事](https://qiita.com/9ryuuuuu/items/2830fee559a41d00aa2b)\n\n\n一番長いtweetの単語数に合わせる\npaddding='post’\nにすると後ろに0が追加される\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pad = pad_sequences(X_train_token, maxlen=maxlen, padding='post')\nX_test_pad = pad_sequences(X_test_token, maxlen=maxlen, padding='post')\n\nprint('Tokenized text before padding')\nprint(X_train_token[0])\nprint('\\nTokenized text after padding')\nprint(X_train_pad[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## モデルを作成していく\n元ネタの方はBidirectional　LSTMで学習されていたのですが、いろいろと試してみたかったので下記の四つのモデルを作成して精度を比較しました\n\nBidirectionalって？？\n普通のRNNだと前から順に次の文字を予想していくが、Bidirectionalをつけると前と後ろから読んで次に出てくる文字を予想できる。→精度がよくなるらしい\n\n[参考記事](https://sleepless-se.net/2019/03/21/%E3%80%90python%E3%80%91bidirectionalrnn-create-sentence/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nembed_units=100\nhidden_units=128\n\nmodel=Sequential()\nmodel.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel.add(SimpleRNN(hidden_units))\nmodel.add(Dropout(0.2))\n#model.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.0001\n\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size_1= 150\nbatch_size_2= 300\nbatch_size_3= 700\nnum_itr = 5\nes_cb=keras.callbacks.EarlyStopping( patience=0, verbose=0)\nmodel_history = model.fit(X_train_pad, y_train, \n                          batch_size=batch_size_1, \n                          epochs=num_itr, \n                          validation_split=0.3,\n                          callbacks=[es_cb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bidirectional　SimpleRNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nmodel_BRNN=Sequential()\nmodel_BRNN.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel_BRNN.add(Bidirectional(SimpleRNN(hidden_units)))\nmodel_BRNN.add(Dropout(0.2))\n#model.add(Flatten())\nmodel_BRNN.add(Dense(256, activation='relu'))\nmodel_BRNN.add(Dropout(0.2))\nmodel_BRNN.add(Dense(1, activation='sigmoid'))\n\nmodel_BRNN.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.0001\n\nmodel_BRNN.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_BRNN_history = model_BRNN.fit(X_train_pad, y_train, \n                          batch_size=batch_size_3, \n                          epochs=num_itr, \n                          validation_split=0.2,\n                          callbacks=[es_cb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nmodel_LS = Sequential()\nmodel_LS.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel_LS.add(Bidirectional(LSTM(hidden_units)))\nmodel_LS.add(Dropout(0.2))\n#model.add(Flatten())\nmodel_LS.add(Dense(256, activation='relu'))\nmodel_LS.add(Dropout(0.2))\nmodel_LS.add(Dense(1, activation='sigmoid'))\n\nmodel_LS.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.0001\n\nmodel_LS.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_LS_history = model_LS.fit(X_train_pad, y_train, \n                          batch_size=batch_size_3, \n                          epochs=num_itr, \n                          validation_split=0.4,\n                          callbacks=[es_cb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"いろいろいじってみた結果\nvalidation-splitを極端に上げるとたまにいい数字を出す、（よくわからん）\nvalidation-splitを0.4ぐらいにして、バッチサイズをいじってみたがそんなに変わらない"},{"metadata":{},"cell_type":"markdown","source":"# Bidirectional LSTM "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_BLS=Sequential()\nmodel_BLS.add(Embedding(vocab_size, embed_units, input_length = maxlen))\nmodel_BLS.add(Bidirectional(LSTM(hidden_units)))\nmodel_BLS.add(Dropout(0.2))\n#model.add(Flatten())\nmodel_BLS.add(Dense(256, activation='relu'))\nmodel_BLS.add(Dropout(0.2))\nmodel_BLS.add(Dense(1, activation='sigmoid'))\n\nmodel_BLS.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.0001\n\nmodel_BLS.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_BLS_history = model_LS.fit(X_train_pad, y_train, \n                          batch_size=batch_size_3, \n                          epochs=num_itr, \n                          validation_split=0.9,\n                          callbacks=[es_cb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"いろいろいじってみた結果、\nvalidation-splitを極端に挙げているのに、なかなか良い値を安定して出し続けている（なぜかはわからん）"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model_LS.predict(X_test_pad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsub[\"target\"] = pred\nsub[\"target\"] = sub[\"target\"].apply(lambda x : 0 if x<=.5 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submit_5.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 疑問点\nvalidation-splitをを極端に上げるとval―accuracyが以上によくなる原因（所詮二値分類だから確率の問題？）\nパラメータいじってもfitし直すごとにだいぶ値がかわるのでどのようにパラメータを調整すればいいのかわからない"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 分かったこと\n自然言語処理の前処理の仕方\nBidirectional LSTM が（理由ははからないが）一番いいスコアを出すってこと\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}