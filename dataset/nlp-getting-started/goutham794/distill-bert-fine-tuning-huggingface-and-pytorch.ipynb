{"cells":[{"metadata":{"_uuid":"0ee96682-f081-4b1c-bdd5-2ad1e937d970","_cell_guid":"d5244981-f1db-4ba5-a37e-364360314ae9","trusted":true},"cell_type":"markdown","source":"In this notebook I use distill-bert-uncased from huggingface and use pytorch to fine-tune it to the classification task at hand.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Importing requirements","execution_count":null},{"metadata":{"_uuid":"65968c2b-6aff-41eb-a0c7-0c60069a7038","_cell_guid":"cb66dccf-f288-4344-a4a7-2d5474f5c0bd","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport torch\nimport transformers\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom transformers import DistilBertModel, DistilBertTokenizer\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport numpy as np\nimport re","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5756f350-a8cf-4200-a9bd-8ce8f3177020","_cell_guid":"33db69ee-e322-4324-ab31-ee61c3dacb83","trusted":true},"cell_type":"code","source":"# Setting up the device for GPU usage\n\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00f70cf6-aeba-4f87-a650-455eeac33e54","_cell_guid":"cc9e1dce-52ef-4191-9c2f-f1692f320e1e","trusted":true},"cell_type":"markdown","source":"Reading in the train dataframe","execution_count":null},{"metadata":{"_uuid":"03640e33-2f7a-4252-a591-8ba55ef0efe0","_cell_guid":"513b82f4-8742-4708-97c4-0bdc6c7e52c2","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")[[\"text\",\"target\"]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ca12726-9200-4b42-9dbc-4c18be18a1c9","_cell_guid":"7cccd5c5-bb51-4ce6-ba99-062619dd02ef","trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pre-processing / Cleaning functions","execution_count":null},{"metadata":{"_uuid":"c3ad6949-7386-47ab-b230-de58ded71cda","_cell_guid":"69556f76-40ad-4a3e-8b57-6260b573a610","trusted":true},"cell_type":"markdown","source":"A few pre-processing functions that will be used to clean up the tweets while we create the PyTorch dataset object.","execution_count":null},{"metadata":{"_uuid":"b42d65dc-5fb8-4374-9ec8-739b3a370d59","_cell_guid":"d64921bd-d50a-490b-8365-0ff71c578413","trusted":true},"cell_type":"code","source":"def remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ndef remove_numbers(text):\n    text = ''.join([i for i in text if not i.isdigit()])         \n    return text\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ndef remove_username(text):\n    url = re.compile(r'@[A-Za-z0-9_]+')\n    return url.sub(r'',text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51cb71e1-3ca1-4913-8bba-84580d1d5f0e","_cell_guid":"fbc1096e-bb74-48cd-bd15-560004e788ae","trusted":true},"cell_type":"code","source":"def pre_process_text(text):\n    text = remove_URL(text)\n    text = remove_numbers(text)\n    text = remove_html(text)\n    text = remove_username(text)\n    return \" \".join(text.split())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05be6ee5-7942-450c-86f9-552d83539330","_cell_guid":"f72586af-1720-491b-8ee1-67ad4c8c601c","trusted":true},"cell_type":"markdown","source":"An example of how a tweet gets cleaned","execution_count":null},{"metadata":{"_uuid":"e67be580-85a9-4f83-b709-136d44f15173","_cell_guid":"98abddd4-9e56-4658-a429-8678511f47d0","trusted":true},"cell_type":"code","source":"pre_process_text(\"Why can't gay men donate blood? http://t.co/v2Etl8P9eQ http://t.co/NLnyzeljbw\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0595490-6ff6-40fb-b340-687778487b26","_cell_guid":"7fb9793f-7842-40ec-8cdd-49d6f64e7bd4","trusted":true},"cell_type":"markdown","source":"The longest tweet is 157, for the bert input length we'll take that into consideration.","execution_count":null},{"metadata":{"_uuid":"bd42d656-61df-43b4-aafd-733f644860b6","_cell_guid":"aa646cab-5b40-4eab-90f5-8311e6474ec8","trusted":true},"cell_type":"code","source":"# longest tweet length\nmax(df_train['text'].apply(len))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78c562f6-4d59-4758-83b4-fe706aa1ab98","_cell_guid":"a6dae399-a6ed-490c-b99e-684afec01fa0","trusted":true},"cell_type":"code","source":"# Defining some key variables that will be used later on in the training\nMAX_LEN = 160\nBATCH_SIZE = 16\nEPOCHS = 1\nLEARNING_RATE = 1e-05\n\nBERT_PATH = '/kaggle/input/distillbert-huggingface-model/'\nMODEL_PATH = \"distilbert-base-uncased-pytorch_model.bin\"\ntokenizer = DistilBertTokenizer.from_pretrained(\n    BERT_PATH,\n    do_lower_case=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class for creating the dataset.","execution_count":null},{"metadata":{"_uuid":"ae2feb41-c803-406f-a559-0c76aaf362b1","_cell_guid":"4839d167-9997-4aa6-8893-fef36aeef1d3","trusted":true},"cell_type":"code","source":"class tweet_Dataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __getitem__(self, index):\n        tweet = str(self.data.text[index])\n        tweet = pre_process_text(tweet)\n        inputs = self.tokenizer.encode_plus(\n            tweet,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'targets': torch.tensor(self.data.target[index], dtype=torch.float)\n        }\n        \n    def __len__(self):\n        return len(self.data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6229be7d-d162-4e20-91c7-61cf15e4c299","_cell_guid":"cd58a92b-6b0d-4853-b22a-d8ea4475549f","trusted":true},"cell_type":"code","source":"# Creating the dataset and dataloader for the neural network\n\ntrain_size = 0.85\ntrain_dataset=df_train.sample(frac=train_size,random_state=200).reset_index(drop=True)\nvalid_dataset=df_train.drop(train_dataset.index).reset_index(drop=True)\n\n\nprint(\"FULL Dataset: {}\".format(df_train.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"VALID Dataset: {}\".format(valid_dataset.shape))\n\ntraining_set = tweet_Dataset(train_dataset, tokenizer, MAX_LEN)\nvalidation_set = tweet_Dataset(valid_dataset, tokenizer, MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a0029fc-c3a0-49f8-98b5-eddc98352225","_cell_guid":"713ea657-7a53-4cad-9e3e-207ead39f71b","trusted":true},"cell_type":"code","source":"training_set[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48b45687-7225-4e66-9d65-8b3a83765893","_cell_guid":"d44e65e2-83a0-4204-95a0-abc46c1721b6","trusted":true},"cell_type":"code","source":"train_params = {'batch_size': BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\nvalid_params = {'batch_size': BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntrain_dl = DataLoader(training_set, **train_params)\nvalid_dl = DataLoader(validation_set, **valid_params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pytorch module class for our model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Bert Encoder(pooled output) -> Dropout -> Linear layer -> Final Output","execution_count":null},{"metadata":{"_uuid":"ff9d1d68-5524-4b12-b116-93376e76f679","_cell_guid":"da14b7e1-95c0-424f-866e-e1dcee2a8e81","trusted":true},"cell_type":"code","source":"class DistillBERTClass(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.distill_bert = transformers.DistilBertModel.from_pretrained(BERT_PATH)\n        self.drop = torch.nn.Dropout(0.3)\n        self.out = torch.nn.Linear(768, 1)\n    \n    def forward(self, ids, mask):\n        distilbert_output = self.distill_bert(ids, mask)\n        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n        pooled_output = hidden_state[:, 0]  # (bs, dim)\n        output_1 = self.drop(pooled_output)\n        output = self.out(output_1)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5543dd50-224b-478d-8ccc-1b9c81bc8d72","_cell_guid":"f2d945eb-2c20-451e-9e7b-ab0660e4be67","trusted":true},"cell_type":"code","source":"model = DistillBERTClass()\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40187eed-ad91-4a17-a328-30ce9c6e918d","_cell_guid":"9a6e9d3d-dbba-4774-b720-d5c9e7834178","trusted":true},"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return nn.BCEWithLogitsLoss()(outputs, targets)\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation function","execution_count":null},{"metadata":{"_uuid":"0c55b56d-80bd-4692-8428-561af27eafb0","_cell_guid":"ca74bcd5-beb9-409a-b732-8ac28d8a8423","trusted":true},"cell_type":"code","source":"def eval_fn(data_loader, model):\n    model.eval()\n    fin_targets = []\n    fin_outputs = []\n    with torch.no_grad():\n        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n            ids = d[\"ids\"]\n            mask = d[\"mask\"]\n            targets = d[\"targets\"]\n\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            targets = targets.to(device, dtype=torch.float)\n\n            outputs = model(ids=ids, mask=mask)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n        fin_outputs = np.array(fin_outputs) >= 0.5\n        f1 = metrics.f1_score(fin_targets, fin_outputs)\n    return f1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training function","execution_count":null},{"metadata":{"_uuid":"8b6647e0-0ff1-4f14-8943-df5bd883c9d1","_cell_guid":"6fcd7f7b-5465-4386-bd39-7bb12d313afc","trusted":true},"cell_type":"code","source":"def fit(num_epochs, model, loss_fn, opt, train_dl, valid_dl):\n    \n    for epoch in range(num_epochs):\n        model.train()\n        for _,data in enumerate(train_dl, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask).squeeze()\n            loss = loss_fn(outputs, targets)\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n\n        valid_acc = eval_fn(valid_dl, model)\n        print('Epoch [{}/{}], Train Loss: {:.4f} and Validation f1 {:.4f}'.format(epoch+1, num_epochs, loss.item(),valid_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training for 7 epochs.","execution_count":null},{"metadata":{"_uuid":"4da6f91a-b75e-4729-b444-92ae93e2a815","_cell_guid":"200ab7fd-d6a2-474f-aacc-db34af0f5cdf","trusted":true},"cell_type":"code","source":"fit(7, model, loss_fn, optimizer, train_dl,valid_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to predict on a new tweet","execution_count":null},{"metadata":{"_uuid":"7c31aa34-d31a-43d4-9876-f3c7c90899a1","_cell_guid":"fb696e34-30f5-4def-bb4e-e44ab13f1023","trusted":true},"cell_type":"code","source":"def sentence_prediction(sentence):\n    max_len = MAX_LEN\n    tweet = str(sentence)\n    tweet = \" \".join(tweet.split())\n    inputs = tokenizer.encode_plus(\n            tweet,\n            None,\n            add_special_tokens=True,\n            max_length=max_len,\n            pad_to_max_length=True,\n        )\n\n    ids = inputs[\"input_ids\"]\n    mask = inputs[\"attention_mask\"]\n\n\n    ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n    mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n\n    ids = ids.to(device, dtype=torch.long)\n    mask = mask.to(device, dtype=torch.long)\n\n    outputs = model(ids=ids, mask=mask)\n\n    outputs = torch.sigmoid(outputs).cpu().detach().numpy()\n    return outputs[0][0] > 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_prediction(\"We are experiencing slight tremors in London right now\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_prediction(\"Lol this movie is an absolute disaster!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading in test set","execution_count":null},{"metadata":{"_uuid":"a9e6e09a-ba7f-4181-97cf-c5e6669768ec","_cell_guid":"418bb0b6-0572-42ac-9be5-c19d8b52b3bb","trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")[[\"id\",\"text\"]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa473671-c91a-4bcb-883e-69fb3dbe213b","_cell_guid":"f747aa42-361d-499d-a50f-83003c4a4266","trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction on test set","execution_count":null},{"metadata":{"_uuid":"5ee244fc-25b6-435b-be2d-7821295b6589","_cell_guid":"1fb5164f-d48b-417d-bb2b-13cbb122f233","trusted":true},"cell_type":"code","source":"df_test['target'] = df_test['text'].apply(sentence_prediction)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87e3c9ca-fdc6-4e52-aeed-2fce2bbbd00c","_cell_guid":"928a2d38-af7e-49fd-8ecf-dbbca71309b3","trusted":true},"cell_type":"code","source":"df_test['target'] = df_test['target'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a9854dd-9db1-4605-8557-b0710c344000","_cell_guid":"2adb6438-b9ab-4c4d-8d67-337e01eab63f","trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving submission file","execution_count":null},{"metadata":{"_uuid":"7823dd89-6855-43ec-9a85-64bf647c5526","_cell_guid":"2ab595f4-ffea-40c1-9ed2-42533f9cfd5e","trusted":true},"cell_type":"code","source":"# submission\ndf_test.to_csv(\"submission.csv\", columns = ['id','target'], index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}