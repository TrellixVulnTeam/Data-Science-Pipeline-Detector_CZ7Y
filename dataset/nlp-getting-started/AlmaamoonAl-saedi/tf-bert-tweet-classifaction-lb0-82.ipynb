{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **import lib** # \n\nthe main part for bert is in transformers\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\nfrom transformers import TFAutoModel, AutoTokenizer\nimport matplotlib.pyplot as plt\nimport math, re, os\nimport string\n\n# Set seed for experiment reproducibility\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-01T18:14:02.378089Z","iopub.execute_input":"2021-09-01T18:14:02.378437Z","iopub.status.idle":"2021-09-01T18:14:08.955359Z","shell.execute_reply.started":"2021-09-01T18:14:02.378364Z","shell.execute_reply":"2021-09-01T18:14:08.954446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# define paths for data and  the offline load of transformers lib","metadata":{}},{"cell_type":"code","source":"train_loc = '../input/nlp-getting-started/train.csv'\ntest_loc = '../input/nlp-getting-started/test.csv'\nfile_path = '/kaggle/input/huggingface-bert/'\nMODEL_NAME = \"bert-large-uncased\"\nbatch_size = 16\nepochs = 6","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:08.956811Z","iopub.execute_input":"2021-09-01T18:14:08.957151Z","iopub.status.idle":"2021-09-01T18:14:08.960863Z","shell.execute_reply.started":"2021-09-01T18:14:08.957114Z","shell.execute_reply":"2021-09-01T18:14:08.960094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Read","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(train_loc)\ntest_df = pd.read_csv(test_loc)\nprint('training items ' + str(train_df.shape[0]) )\nprint('test items ' + str(test_df.shape[0]) )","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:08.963045Z","iopub.execute_input":"2021-09-01T18:14:08.963377Z","iopub.status.idle":"2021-09-01T18:14:09.049586Z","shell.execute_reply.started":"2021-09-01T18:14:08.963344Z","shell.execute_reply":"2021-09-01T18:14:09.048805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:11.030284Z","iopub.execute_input":"2021-09-01T18:14:11.030612Z","iopub.status.idle":"2021-09-01T18:14:11.058099Z","shell.execute_reply.started":"2021-09-01T18:14:11.030584Z","shell.execute_reply":"2021-09-01T18:14:11.057375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlenght = train_df.text.map(len).max()\nmaxlenght_test = test_df.text.map(len).max()\n\nprint(f'maxmum str lenght in training  is : {maxlenght}\\n   max str lunght in test is : {maxlenght_test}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:11.874536Z","iopub.execute_input":"2021-09-01T18:14:11.874842Z","iopub.status.idle":"2021-09-01T18:14:11.890395Z","shell.execute_reply.started":"2021-09-01T18:14:11.874813Z","shell.execute_reply":"2021-09-01T18:14:11.889546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# very simple cleaning  function","metadata":{}},{"cell_type":"code","source":"def clean(title):\n\n    title = re.sub(r\"\\-\",\" \",title)\n    title = re.sub(r\"\\+\",\" \",title)\n    title = re.sub (r\"&\",\"and\",title)\n    title = re.sub(r\"\\|\",\" \",title)\n    title = re.sub(r\"\\\\\",\" \",title)\n    title = re.sub(r\"\\W\",\" \",title)\n    title = title.lower()\n    for p in string.punctuation :\n        title = re.sub(r\"f{p}\",\" \",title)\n    \n    title = re.sub(r\"\\s+\",\" \",title)\n    \n    return title","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:13.773772Z","iopub.execute_input":"2021-09-01T18:14:13.774131Z","iopub.status.idle":"2021-09-01T18:14:13.780754Z","shell.execute_reply.started":"2021-09-01T18:14:13.774098Z","shell.execute_reply":"2021-09-01T18:14:13.779948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"text\"] = train_df[\"text\"].map(clean)\ntest_df[\"text\"] = test_df[\"text\"].map(clean)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:14.769814Z","iopub.execute_input":"2021-09-01T18:14:14.770149Z","iopub.status.idle":"2021-09-01T18:14:15.394774Z","shell.execute_reply.started":"2021-09-01T18:14:14.770119Z","shell.execute_reply":"2021-09-01T18:14:15.393849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**function to do tokenize and padd or truncation on the data **","metadata":{}},{"cell_type":"code","source":"def tokeniz_dataset(tokenizer,max_len):\n\n    return {\n        \"train\": {\n            \"data\": tokenizer(list(train_df[\"text\"].values), padding = \"max_length\", max_length = max_len, truncation = True, return_tensors = \"tf\").data,\n            \"labels\": train_df[\"target\"].values,\n        },\n        \"test\": {\n            \"data\": tokenizer(list(test_df[\"text\"].values), padding = \"max_length\", max_length = max_len, truncation = True, return_tensors = \"tf\").data\n        }\n    }","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:16.365082Z","iopub.execute_input":"2021-09-01T18:14:16.365484Z","iopub.status.idle":"2021-09-01T18:14:16.371453Z","shell.execute_reply.started":"2021-09-01T18:14:16.365451Z","shell.execute_reply":"2021-09-01T18:14:16.370338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define the model \n\n**bert + our own linear layers**","metadata":{}},{"cell_type":"code","source":"class ClassifModel(tf.keras.Model):\n\n    def __init__(self, checkpoint):\n        super(ClassifModel, self).__init__()\n        \n        self.base_model = TFAutoModel.from_pretrained(checkpoint)\n        self.flatten = layers.Flatten()\n        \n        self.dropout1 = layers.Dropout(rate = 0.2)\n        self.linear1 = layers.Dense(units = 1024, kernel_regularizer = \"l1_l2\")\n        self.batchNorm1 = layers.BatchNormalization()\n        self.activation1 = layers.Activation(\"relu\")\n        \n        self.out = layers.Dense(units = 1, activation = \"sigmoid\")\n\n    def call(self, inputs, training = False):\n        x = self.base_model(inputs).last_hidden_state\n        x = self.flatten(x)\n        \n        x = self.dropout1(x) if training else x\n        x = self.linear1(x)\n        x = self.batchNorm1(x)\n        x = self.activation1(x)\n\n        x = self.out(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:17.82359Z","iopub.execute_input":"2021-09-01T18:14:17.823923Z","iopub.status.idle":"2021-09-01T18:14:17.831913Z","shell.execute_reply.started":"2021-09-01T18:14:17.823892Z","shell.execute_reply":"2021-09-01T18:14:17.830719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**f1 score for the compution porpuse **","metadata":{}},{"cell_type":"code","source":"class F1_score(tf.keras.metrics.Metric):\n\n    def __init__(self, name = \"f1_score\", **kwargs):\n        super(F1_score, self).__init__(name = name, **kwargs)\n        \n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n        \n    def update_state(self, y_true, y_pred, sample_weight = None):\n        self.precision.update_state(y_true, y_pred, sample_weight)\n        self.recall.update_state(y_true, y_pred, sample_weight)\n        \n    def reset_states(self):\n        self.precision.reset_states()\n        self.recall.reset_states()\n        \n    def result(self):\n        return 2 / ((1 / self.precision.result()) + (1 / self.recall.result()))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:19.686413Z","iopub.execute_input":"2021-09-01T18:14:19.686745Z","iopub.status.idle":"2021-09-01T18:14:19.695773Z","shell.execute_reply.started":"2021-09-01T18:14:19.686715Z","shell.execute_reply":"2021-09-01T18:14:19.693045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# learning rate schudler ","metadata":{}},{"cell_type":"code","source":"def lrfn(epoch, bs=batch_size, epochs=epochs):\n    # Config\n    LR_START = 1e-5\n    LR_MAX = 2e-3\n    LR_FINAL = 1e-5\n    LR_RAMPUP_EPOCHS = 4\n    LR_SUSTAIN_EPOCHS = 0\n    DECAY_EPOCHS = epochs  - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n    LR_EXP_DECAY = (LR_FINAL / LR_MAX) ** (1 / (epochs - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1))\n\n    if epoch < LR_RAMPUP_EPOCHS: # exponential warmup\n        lr = LR_START + (LR_MAX + LR_START) * (epoch / LR_RAMPUP_EPOCHS) ** 2.5\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS: # sustain lr\n        lr = LR_MAX\n    else: # cosine decay\n        epoch_diff = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        decay_factor = (epoch_diff / DECAY_EPOCHS) * math.pi\n        decay_factor= (tf.math.cos(decay_factor).numpy() + 1) / 2        \n        lr = LR_FINAL + (LR_MAX - LR_FINAL) * decay_factor\n\n    return lr\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:39.377583Z","iopub.execute_input":"2021-09-01T18:14:39.377903Z","iopub.status.idle":"2021-09-01T18:14:39.384284Z","shell.execute_reply.started":"2021-09-01T18:14:39.377874Z","shell.execute_reply":"2021-09-01T18:14:39.383449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plots the learning rate schedule\ndef show_lr_schedule(bs=batch_size, epochs=epochs):\n    rng = [i for i in range(epochs)]\n    y = [lrfn(x, bs=bs, epochs=epochs) for x in rng]\n    x = np.arange(epochs)\n    x_axis_labels = list(map(str, np.arange(1, epochs+1)))\n    print('init lr {:.1e} to {:.1e} final {:.1e}'.format(y[0], max(y), y[-1]))\n    \n    plt.figure(figsize=(30, 10))\n    plt.xticks(x, x_axis_labels, fontsize=16) # set tick step to 1 and let x axis start at 1\n    plt.yticks(fontsize=16)\n    plt.plot(rng, y)\n    plt.grid()\n    plt.show()\n    \nshow_lr_schedule()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:40.26326Z","iopub.execute_input":"2021-09-01T18:14:40.263591Z","iopub.status.idle":"2021-09-01T18:14:46.598719Z","shell.execute_reply.started":"2021-09-01T18:14:40.263562Z","shell.execute_reply":"2021-09-01T18:14:46.597931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# init tokenizer and model ","metadata":{}},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained('../input/huggingface-bert/bert-large-uncased' )\nmodel = ClassifModel('../input/huggingface-bert/bert-large-uncased')\nloss = BinaryCrossentropy()\nmodel.compile(loss = loss, optimizer = tf.keras.optimizers.Adam(), metrics = [\"accuracy\", F1_score()])\ntokenized_dataset = tokeniz_dataset(tokenizer,65)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:14:48.867881Z","iopub.execute_input":"2021-09-01T18:14:48.868277Z","iopub.status.idle":"2021-09-01T18:15:11.934269Z","shell.execute_reply.started":"2021-09-01T18:14:48.868246Z","shell.execute_reply":"2021-09-01T18:15:11.933319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start training ","metadata":{}},{"cell_type":"code","source":"checkpoint_filepath = './modebest-stlr.h5'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_f1_score',\n    mode='max',\n    save_best_only=True)\nearlystop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_f1_score', patience=3,  \n    mode='max' \n)\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch, epochs=epochs), verbose=1)\nhistory = model.fit(\n    x = tokenized_dataset[\"train\"][\"data\"],\n    y = tokenized_dataset[\"train\"][\"labels\"],\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_split = 0.2, callbacks=[model_checkpoint_callback , earlystop , lr_callback]\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:15:11.936011Z","iopub.execute_input":"2021-09-01T18:15:11.936372Z","iopub.status.idle":"2021-09-01T18:29:02.952695Z","shell.execute_reply.started":"2021-09-01T18:15:11.936335Z","shell.execute_reply":"2021-09-01T18:29:02.951789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize = (14, 14))\n\n\nplt.plot(history.history[\"f1_score\"], label = \"f1_score\")\nplt.plot(history.history[\"val_f1_score\"], label = \"val_f1_score\")\nplt.title(\"F1 Score\")\nplt.ylabel(\"F1 Score\")\nplt.xlabel(\"Epoch\")\nplt.legend(loc = \"best\")","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:29:02.954894Z","iopub.execute_input":"2021-09-01T18:29:02.955284Z","iopub.status.idle":"2021-09-01T18:29:03.176497Z","shell.execute_reply.started":"2021-09-01T18:29:02.955244Z","shell.execute_reply":"2021-09-01T18:29:03.17555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# load best model and make prediactions","metadata":{}},{"cell_type":"code","source":"model.load_weights(checkpoint_filepath)\n\npredictions = model.predict(tokenized_dataset[\"test\"][\"data\"], verbose = True)\npredictions = np.where(predictions >= 0.5, 1, 0)\npredictions","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:29:03.177951Z","iopub.execute_input":"2021-09-01T18:29:03.178314Z","iopub.status.idle":"2021-09-01T18:29:39.891917Z","shell.execute_reply.started":"2021-09-01T18:29:03.178276Z","shell.execute_reply":"2021-09-01T18:29:39.891101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions = test_df.drop(labels = [\"keyword\", \"location\", \"text\"], axis = 1)\nsubmissions[\"target\"] = predictions\nsubmissions.to_csv(\"submissions.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:29:39.897417Z","iopub.execute_input":"2021-09-01T18:29:39.899394Z","iopub.status.idle":"2021-09-01T18:29:39.925279Z","shell.execute_reply.started":"2021-09-01T18:29:39.899352Z","shell.execute_reply":"2021-09-01T18:29:39.924329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}