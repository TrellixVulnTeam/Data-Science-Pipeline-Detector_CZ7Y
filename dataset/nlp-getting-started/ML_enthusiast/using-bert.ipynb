{"cells":[{"metadata":{},"cell_type":"markdown","source":"> Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ktrain # for BERT model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport spacy\nimport ktrain\nimport re\nimport string\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport unicodedata\nfrom wordcloud import WordCloud\nfrom textblob import TextBlob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.lang.en.stop_words import STOP_WORDS as stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv('../input/nlp-getting-started/train.csv')\ntrain_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('../input/nlp-getting-started/test.csv')\ntest_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g=sns.countplot(x='target',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Convert to lowercase"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: str(x).lower())\ntest_df['text'] = test_df['text'].apply(lambda x: str(x).lower())\ntrain_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Contraction to Extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how does\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\" u \": \" you \",\n\" ur \": \" your \",\n\" n \": \" and \",\n\"won't\": \"would not\",\n'dis': 'this',\n'bak': 'back',\n'brng': 'bring'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Expansion "},{"metadata":{"trusted":true},"cell_type":"code","source":"def cont_to_exp(x):\n    if type(x) is str:\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key, value)\n        return x\n    else:\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: cont_to_exp(x))\ntest_df['text'] = test_df['text'].apply(lambda x: cont_to_exp(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Count number of words, characters, hashtags, mentions and emails"},{"metadata":{"trusted":true},"cell_type":"code","source":"def wordcount(x):\n    length = len(str(x).split())\n    return length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def charcount(x):\n    s = x.split()\n    x = ''.join(s)\n    return len(x)\n\ndef hashtag_count(x):\n    l = len([t for t in x.split() if t.startswith('#')])\n    return l\n\ndef mentions_count(x):\n    l = len([t for t in x.split() if t.startswith('@')])\n    return l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['char_count'] = train_df['text'].apply(lambda x: charcount(x))\ntrain_df['word_count'] = train_df['text'].apply(lambda x: wordcount(x))\ntrain_df['hashtag_count'] = train_df['text'].apply(lambda x: hashtag_count(x))\ntrain_df['mention_count'] = train_df['text'].apply(lambda x: mentions_count(x))\ntrain_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,4))\nplt.subplot(1,3,1)\nsns.barplot(y='char_count',x='target',data=train_df)\nplt.subplot(1,3,2)\nsns.barplot(y='word_count',x='target',data=train_df)\nplt.subplot(1,3,3)\ng=sns.barplot(y='hashtag_count',x='target',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['char_count'] = test_df['text'].apply(lambda x: charcount(x))\ntest_df['word_count'] = test_df['text'].apply(lambda x: wordcount(x))\ntest_df['hashtag_count'] = test_df['text'].apply(lambda x: hashtag_count(x))\ntest_df['mention_count'] = test_df['text'].apply(lambda x: mentions_count(x))\ntest_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Remove hashtags, mentions and emails"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_emails(x):\n     return re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", x)\n\n\ndef remove_urls(x):\n    return re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , x)\n\ndef remove_rt(x):\n    return re.sub(r'\\brt\\b', '', x).strip()\n\ndef remove_special_chars(x):\n    x = re.sub(r'[^\\w ]+', \"\", x)\n    x = ' '.join(x.split())\n    return x\n\n\ndef remove_accented_chars(x):\n    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return x\n\ndef remove_stopwords(x):\n    return ' '.join([t for t in x.split() if t not in stopwords])\t\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: remove_emails(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_urls(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_rt(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_special_chars(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_accented_chars(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_stopwords(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['text'] = test_df['text'].apply(lambda x: remove_emails(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_urls(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_rt(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_special_chars(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_accented_chars(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_stopwords(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Wordcloud Visualization "},{"metadata":{"trusted":true},"cell_type":"code","source":"text = ' '.join(train_df[train_df.target==1]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.title('Disaster tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = ' '.join(train_df[train_df.target==0]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.title('Not Disaster tweets')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> After removing frequent words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_value_counts(df, col):\n    text = ' '.join(df[col])\n    text = text.split()\n    freq = pd.Series(text).value_counts()\n    return freq\n\ndef remove_common_words(x, freq, n=20):\n    fn = freq[:n]\n    x = ' '.join([t for t in x.split() if t not in fn])\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq=get_value_counts(train_df,'text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: remove_common_words(x,freq,100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = ' '.join(train_df[train_df.target==1]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.title('Disaster tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = ' '.join(train_df[train_df.target==0]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.title('Not Disaster tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"from ktrain import text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df=train_df, text_column='text', label_columns='target', maxlen=50, preprocess_mode='bert')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = text.text_classifier(name='bert', train_data=(X_train, y_train), preproc=preproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner = ktrain.get_learner(model=model, train_data=(X_train, y_train), val_data=(X_test, y_test), batch_size=32)\nlearner.fit_onecycle(lr = 2e-4, epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor = ktrain.get_predictor(learner.model, preproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=predictor.get_classes()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame(columns=['id','target'])\nfor index, row in test_df.iterrows(): \n    y_pred,p= predictor.predict(row['text'],return_proba=True)\n    pred=classes.index(y_pred)\n    output1 = pd.DataFrame({'id': row['id'], 'target': pred},index=[0])\n    output=output.append(output1)\n    \noutput = output.astype({'target': 'int32'})\noutput.to_csv('submission_bert.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}