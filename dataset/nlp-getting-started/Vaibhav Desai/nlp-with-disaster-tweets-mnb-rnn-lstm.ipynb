{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_id = train['id']\ntest_id = test['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(columns = ['id'], inplace = True)\ntest.drop(columns = ['id'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Location column has a lot of missing values and keyword column contains information that is present in the text column and we will be exracting that information down the line from the text column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(columns = ['keyword','location'], inplace = True)\ntest.drop(columns = ['keyword','location'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting all text to lowercase\ntrain['text'] = [t.lower() for t in train['text']]\ntest['text'] = [t.lower() for t in test['text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing punctuations\nimport re\nimport string\ntrain['text'] = [re.sub('[%s]' % re.escape(string.punctuation), '', i) for i in train['text']]\ntest['text'] = [re.sub('[%s]' % re.escape(string.punctuation), '', i) for i in test['text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing numeric characters\ntrain['text'] = [re.sub('\\d','',n) for n in train['text']]\ntest['text'] = [re.sub('\\d','',n) for n in test['text']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing Text Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Tokenization and Stop Words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Word Tokenization\n\ntrain['text'] = [word_tokenize(i) for i in train['text']]\ntest['text'] = [word_tokenize(i) for i in test['text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stop Words Removal\n\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\ntrain['text'] = [[i for i in j if not i in stop_words] for j in train['text']]\ntest['text'] = [[i for i in j if not i in stop_words] for j in test['text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lemmatization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom nltk.tag import pos_tag\nfrom nltk.corpus import wordnet as wn\n\ntag_map = defaultdict(lambda : wn.NOUN)\ntag_map['J'] = wn.ADJ\ntag_map['V'] = wn.VERB\ntag_map['R'] = wn.ADV\n\ntag_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\ntrain['text'] = [[lemmatizer.lemmatize(word, tag_map[tag[0]]) for word, tag in pos_tag(i)] for i in train['text']]\ntest['text'] = [[lemmatizer.lemmatize(word, tag_map[tag[0]]) for word, tag in pos_tag(i)] for i in test['text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['lemmatized_text'] = train['text'].apply(lambda x : ' '.join(x))\ntest['lemmatized_text'] = test['text'].apply(lambda x : ' '.join(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(columns = ['text'], inplace = True)\ntest.drop(columns = ['text'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Word Embedding using TF_IDF Vectorizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(max_features = 5000)\n\ntrain_emb = tfidf.fit_transform(train['lemmatized_text']).toarray()\ntest_emb = tfidf.fit_transform(test['lemmatized_text']).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_emb.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MNB = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the train set in train and validation set to see how good is Naive Bayes for our data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_valid,y_train,y_valid = train_test_split(train_emb,y,test_size = 0.3, random_state = 100) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MNB.fit(x_train,y_train)\npred_MNB = MNB.predict(x_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy score : {:.2f}\".format(accuracy_score(y_valid, pred_MNB)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ROC-AUC score : {:.2f}\".format(roc_auc_score(y_valid, pred_MNB)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_valid, pred_MNB))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"MNB.fit(train_emb,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MNB_predictions = MNB.predict(test_emb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Prediction_results = pd.DataFrame({\"target\": MNB_predictions}, index = test_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission_file = Prediction_results.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Multinomial Naive Bayes got a 0.515 score which is decent but can be significantly improved.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machines","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nSVC = svm.SVC()\n#SVC.fit(x_train,y_train)\n#pred_SVC = SVC.predict(x_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(\"Accuracy score : {:.2f}\".format(accuracy_score(y_valid, pred_SVC)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(\"ROC-AUC score : {:.2f}\".format(roc_auc_score(y_valid, pred_SVC)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Alternative Approach using Sequencing, Padding, and LSTM","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Sequencing and Sentence Padding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\n# Finding the number of unique word in the corpus\ndef word_counter(text):\n    count = Counter()\n    for i in text.values:\n        for word in i.split():\n            count[word] += 1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text = train.lemmatized_text\ncounter = word_counter(train_text)\ncounter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of unique words in the corpus : {:.2f}\".format(len(counter)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = len(counter)\n# maximum number of words in a sequence\nmax_length = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sent = train['lemmatized_text']\ntrain_labels = train['target']\ntest_sent = test['lemmatized_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=words)\ntokenizer.fit_on_texts(train_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_index = tokenizer.word_index\nword_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sequence = tokenizer.texts_to_sequences(train_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sequence[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequence = tokenizer.texts_to_sequences(test_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequence","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sequence Padding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\ntrain_padded = pad_sequences(train_sequence, maxlen = max_length, padding = \"post\", truncating = \"post\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_padded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_padded = pad_sequences(test_sequence, maxlen = max_length, padding = \"post\", truncating = \"post\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_padded","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Building using LSTM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.initializers import Constant\nfrom keras.optimizers import Adam\nimport tensorflow as tf\n\ndef leaky_relu(z, name = None):\n    return tf.maximum(0.01*z,z, name = name)\n\nmodel = Sequential()\n\nmodel.add(Embedding(words,32,input_length = max_length))\n#model.add(LSTM(128, return_sequences = True, dropout = 0.1))\nmodel.add(LSTM(64, dropout = 0.1))\nmodel.add(Dense(units = 32 , activation = leaky_relu))\nmodel.add(Dense(1, activation = tf.nn.elu))\n\noptimizer = Adam(learning_rate = 3e-4)\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_padded, train_labels, epochs = 40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h5py\n#model.save('baseline_lstm_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\n#model = load_model('baseline_lstm_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_base_pred = model.predict_classes(test_padded, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_base_pred = lstm_base_pred.reshape(-1,1).ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(lstm_base_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Prediction_results_lstm = pd.DataFrame({\"target\":lstm_base_pred}, index = test_id)\nPrediction_results_lstm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission_lstm_elu_leaky_relu = Prediction_results_lstm.to_csv('submission_lstm_elu_leaky_relu.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}