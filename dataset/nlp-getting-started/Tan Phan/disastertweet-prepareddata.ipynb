{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-03T07:30:37.194405Z","iopub.execute_input":"2021-11-03T07:30:37.194785Z","iopub.status.idle":"2021-11-03T07:30:37.224243Z","shell.execute_reply.started":"2021-11-03T07:30:37.194675Z","shell.execute_reply":"2021-11-03T07:30:37.223512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install dataprep\n!pip install pyspellchecker","metadata":{"execution":{"iopub.status.busy":"2021-11-03T09:22:24.032258Z","iopub.execute_input":"2021-11-03T09:22:24.032567Z","iopub.status.idle":"2021-11-03T09:22:33.598599Z","shell.execute_reply.started":"2021-11-03T09:22:24.032536Z","shell.execute_reply":"2021-11-03T09:22:33.597503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spellchecker import SpellChecker\nfrom dataprep.clean import clean_text\nimport pandas as pd\nfrom nltk import SnowballStemmer\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-11-03T08:59:16.063172Z","iopub.execute_input":"2021-11-03T08:59:16.063764Z","iopub.status.idle":"2021-11-03T08:59:16.149258Z","shell.execute_reply.started":"2021-11-03T08:59:16.063718Z","shell.execute_reply":"2021-11-03T08:59:16.147778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=0></a>\n## <p style=\"background-color:lightblue; font-family:newtimeroman; font-size:120%; text-align:left; border-radius: 15px 50px;\">Table of Content</p>\n* [1. Loading Data ðŸ’Ž](#1)\n* [2. Data Preprocessing](#2)\n    * [2.1 Remove 92 duplicated rows](#2.1)\n    * [2.2 Cleaning text](#2.2)\n    * [2.3 Spelling Checker](#2.3)\n    * [2.4 Remove Stemming](#2.4)\n* [3. Saving Data](#3)","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">1. Loading Data ðŸ’Ž</p>\n\nJust load the dataset and global variables for colors and so on.\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"train_full = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_full = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\nprint('Training Set Shape = {}'.format(train_full.shape))\nprint('Training Set Memory Usage = {:.2f}MB'.format(train_full.memory_usage().sum()/2**20))\n\nprint('Test Set Shape = {}'.format(test_full.shape))\nprint('Test Set Memory Usage = {:.2f}MB'.format(test_full.memory_usage().sum()/2**20))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:31:16.046196Z","iopub.execute_input":"2021-11-03T07:31:16.046432Z","iopub.status.idle":"2021-11-03T07:31:16.11789Z","shell.execute_reply.started":"2021-11-03T07:31:16.0464Z","shell.execute_reply":"2021-11-03T07:31:16.117271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">2. Data Pre-processing </p>\n\nNow we are going to engineering the data to make it easier for the model to clasiffy.\n\nThis section is very important to reduce the dimensions of the problem.\n\n\n\n\n[Content](#0)","metadata":{}},{"cell_type":"markdown","source":"<a id=2.1 ></a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 15px 50px;\">2.1 Remove 92 duplicated Rows</p>\n\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"duplicate_data = train_full[train_full.duplicated(['text','target'], keep=False)]","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:31:16.119193Z","iopub.execute_input":"2021-11-03T07:31:16.11943Z","iopub.status.idle":"2021-11-03T07:31:16.133374Z","shell.execute_reply.started":"2021-11-03T07:31:16.119397Z","shell.execute_reply":"2021-11-03T07:31:16.132508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_full.drop_duplicates(['text','target'], inplace=True, ignore_index=True)\ntrain_full.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:31:16.134575Z","iopub.execute_input":"2021-11-03T07:31:16.135918Z","iopub.status.idle":"2021-11-03T07:31:16.147367Z","shell.execute_reply.started":"2021-11-03T07:31:16.135877Z","shell.execute_reply":"2021-11-03T07:31:16.146713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=2.2 ></a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 15px 50px;\">2.2 Cleaning text</p>\n\n\n[Content](#0)","metadata":{}},{"cell_type":"markdown","source":"# In this kernel, I use **dataprep** library to clean data productively. \n    1. fillna: Replace all null values with NaN.\n\n    2. lowercase: Convert all characters to lowercase.\n\n    3. remove_digits: Remove numbers.\n\n    4. remove_html Remove HTML tags.\n\n    5. remove_urls: Remove URLs.\n\n    6. remove_punctuation: Remove punctuation marks. (do not use)\n\n    7. remove_accents: Remove accent marks. \n\n    8. remove_stopwords: Remove stopwords. (do not use)\n\n    9. remove_whitespace: Remove extra spaces, and tabs and newlines.","metadata":{}},{"cell_type":"code","source":"custom_pipeline = [\n    {\"operator\": \"fillna\", \"parameters\":{\"value\":\"\"}},\n    {\"operator\": \"lowercase\"},\n    {\"operator\": \"remove_digits\"},\n    {\"operator\": \"remove_html\"},\n    {\"operator\": \"remove_urls\"},\n    {\"operator\": \"remove_accents\"},\n    {\"operator\": \"remove_whitespace\"},\n]","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:31:16.149616Z","iopub.execute_input":"2021-11-03T07:31:16.150215Z","iopub.status.idle":"2021-11-03T07:31:16.155117Z","shell.execute_reply.started":"2021-11-03T07:31:16.150178Z","shell.execute_reply":"2021-11-03T07:31:16.154023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = clean_text(train_full, \"text\", pipeline = custom_pipeline)\ndf_test = clean_text(test_full, \"text\", pipeline= custom_pipeline)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:31:16.156689Z","iopub.execute_input":"2021-11-03T07:31:16.157155Z","iopub.status.idle":"2021-11-03T07:31:16.577542Z","shell.execute_reply.started":"2021-11-03T07:31:16.157116Z","shell.execute_reply":"2021-11-03T07:31:16.576812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=2.3 ></a>\n   ## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">2.3 Spelling Checker</p>\n   \nSpend so much time to apply Spelling Checker.\n\nSo I will use commited-dataset (df_train/df_test) applied and saved in the last time) to save time.\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"spell = SpellChecker()\ndef correct_spelling(text):    \n    misspelled_words = spell.unknown(text.split())\n    corrected_text = [spell.correction(w) if w in misspelled_words else w for w in text.split()] \n    return \" \".join(corrected_text)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:32:54.825878Z","iopub.execute_input":"2021-11-03T07:32:54.826747Z","iopub.status.idle":"2021-11-03T07:32:54.95351Z","shell.execute_reply.started":"2021-11-03T07:32:54.8267Z","shell.execute_reply":"2021-11-03T07:32:54.952791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We lost arround 1hour to run SpellChecker for Training Data","metadata":{}},{"cell_type":"code","source":"t1 = time.time()\ndf_train.text = df_train.text.apply(correct_spelling)\ndeltaT1 = time.time() - t1","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:32:58.757317Z","iopub.execute_input":"2021-11-03T07:32:58.757884Z","iopub.status.idle":"2021-11-03T08:29:29.124375Z","shell.execute_reply.started":"2021-11-03T07:32:58.757844Z","shell.execute_reply":"2021-11-03T08:29:29.123521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t2 = time.time()\ndf_test.text = df_test.text.apply(correct_spelling)\ndeltaT2 = time.time() - t2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=2.4 ></a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 15px 50px;\">2.4 Stemming</p>\n\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"stemmer = SnowballStemmer(\"english\")\n\ndef stemming_text(text):\n    return ' '.join(stemmer.stem(w) for w in text.split(' '))\n\ndf_train.text = df_train.text.apply(stemming_text)\ndf_test.text = df_test.text.apply(stemming_text)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T08:32:11.016988Z","iopub.execute_input":"2021-11-03T08:32:11.017261Z","iopub.status.idle":"2021-11-03T08:32:12.967663Z","shell.execute_reply.started":"2021-11-03T08:32:11.017231Z","shell.execute_reply":"2021-11-03T08:32:12.966888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">3. Saving Data ðŸ’Ž</p>","metadata":{}},{"cell_type":"code","source":"df_train[['text','target']].to_csv('train_prepared.csv', index=False)\ndf_test.text.to_csv('test_prepared.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T08:52:38.68291Z","iopub.execute_input":"2021-11-03T08:52:38.683653Z","iopub.status.idle":"2021-11-03T08:52:38.737941Z","shell.execute_reply.started":"2021-11-03T08:52:38.683608Z","shell.execute_reply":"2021-11-03T08:52:38.737232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('train_prepared.csv') , pd.read_csv('test_prepared.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T08:52:42.214275Z","iopub.execute_input":"2021-11-03T08:52:42.214519Z","iopub.status.idle":"2021-11-03T08:52:42.241301Z","shell.execute_reply.started":"2021-11-03T08:52:42.214491Z","shell.execute_reply":"2021-11-03T08:52:42.240636Z"},"trusted":true},"execution_count":null,"outputs":[]}]}