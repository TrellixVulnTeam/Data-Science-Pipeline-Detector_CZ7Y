{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Visualization\n!pip install dataprep | grep -v 'already satisfied'\nfrom dataprep.eda import plot, plot_diff, create_report\n\n#Preprocessing and Modelling\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Fine-tuning\n!pip install -q -U keras-tuner\nimport keras_tuner as kt\n\n# Warning\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:10:50.668579Z","iopub.execute_input":"2021-11-17T02:10:50.66901Z","iopub.status.idle":"2021-11-17T02:11:34.406025Z","shell.execute_reply.started":"2021-11-17T02:10:50.668917Z","shell.execute_reply":"2021-11-17T02:11:34.404673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=0></a>\n## <p style=\"background-color:lightblue; font-family:newtimeroman; font-size:120%; text-align:left; border-radius: 15px 50px;\">Table of Content</p>\n* [0. What are updated in the last version?](#0)\n* [1. Loading Data](#1)\n* [2. EDA ](#2)\n* [3. Data Preprocessing](#3)\n* [4. Vectorization](#4)\n    * [4.1 Common Vectorizer Usage](#4.1)\n    * [4.2 If-Idf Term Weightings](#4.2)\n\n* [5. BERT model](#5)\n    * [5.1 Preprocessing Data](#5.1)\n    * [5.2 DistilBERT model with Fine-tuning using Keras](#5.2)\n* [6. Make a Submission](#6)\n* [7. References](#7)","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">0. What are updated in the last version?</p>\n\n## Current Version\n\n   1. Upload syntax for pip install dataprep\n   \n   2. Using *val_accuracy* monitor in EarlyStopping because it make the better result.\n   \n   \n# Older Versions\n\n## Current Version\n\n   1. Update References\n   \n   2. Using again data at [this dataset](https://www.kaggle.com/phanttan/disastertweet-prepared2) \n\n## Version 6\n\n   1. Add 4e-5 into learning_rate for Tunning\n   \n   2. Using data at [this dataset](https://www.kaggle.com/phanttan/disastertweets-prepared) \n   \n## Version 5\n\n   1. Find the maximum length to create smaller data to model (from 256 -> 149)\n\n[Content](#0)","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">1. Loading Data ðŸ’Ž</p>\n\nJust load the dataset and global variables for colors and so on.\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"train_full = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_full = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n\nprint('Training Set Shape = {}'.format(train_full.shape))\nprint('Training Set Memory Usage = {:.2f}MB'.format(train_full.memory_usage().sum()/2**20))\n\nprint('Test Set Shape = {}'.format(test_full.shape))\nprint('Test Set Memory Usage = {:.2f}MB'.format(test_full.memory_usage().sum()/2**20))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:34.4083Z","iopub.execute_input":"2021-11-17T02:11:34.408742Z","iopub.status.idle":"2021-11-17T02:11:34.499334Z","shell.execute_reply.started":"2021-11-17T02:11:34.408694Z","shell.execute_reply":"2021-11-17T02:11:34.498206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">2. EDA ðŸ“Š</p>\n\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"plot(train_full)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:34.501999Z","iopub.execute_input":"2021-11-17T02:11:34.502443Z","iopub.status.idle":"2021-11-17T02:11:35.665338Z","shell.execute_reply.started":"2021-11-17T02:11:34.502399Z","shell.execute_reply":"2021-11-17T02:11:35.66422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_report(train_full)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:35.667235Z","iopub.execute_input":"2021-11-17T02:11:35.667803Z","iopub.status.idle":"2021-11-17T02:11:40.350904Z","shell.execute_reply.started":"2021-11-17T02:11:35.667762Z","shell.execute_reply":"2021-11-17T02:11:40.349485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Range from 120 to 140 characters is the most common in tweet.","metadata":{}},{"cell_type":"markdown","source":"<a id='3'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">3. Data Pre-processing </p>\n\nNow we are going to engineering the data to make it easier for the model to clasiffy.\n\nThis section is very important to reduce the dimensions of the problem.\n\n\n[Content](#0)","metadata":{}},{"cell_type":"markdown","source":"# Main technics I used in this data\n    * [3.1] Remove 92 duplicated rows\n    * [3.2] Cleaning text\n    * [3.3] Spelling Checker\n    * [3.4] Remove Stemming\n #### Step 3.3 spends a lot time (around 4000s in 4536s in total). \n #### So, I splits Data Preprocessing into [another kernel](http://https://www.kaggle.com/phanttan/disastertweet-prepareddata). \n #### And the prepared data to save in to [new dataset](http://https://www.kaggle.com/phanttan/disastertweet-prepared2)\n #### I am so appreciate to you for using/upvoting it.\n","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/disastertweet-prepared2/train_prepared.csv')\ndf_test = pd.read_csv('/kaggle/input/disastertweet-prepared2/test_prepared.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:40.35273Z","iopub.execute_input":"2021-11-17T02:11:40.353411Z","iopub.status.idle":"2021-11-17T02:11:40.417807Z","shell.execute_reply.started":"2021-11-17T02:11:40.353366Z","shell.execute_reply":"2021-11-17T02:11:40.416504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=4 ></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">4. Vectorization</p>\n\nThree steps using the Bag-of-words (BOW) model:\n1. Term frequency : count occurrences of word in sentence\n2. Inverse document frequency: \n3. L2 Norm\nReference : https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n\n[Content](#0)","metadata":{}},{"cell_type":"markdown","source":"<a id=4.1 ></a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">4.1 Common Vectorizer Usage</p>\nReference: https://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"# Instantiate the Vectorizer\nvect = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0, max_df=0.9, max_features=100)\ndf_dtm = vect.fit_transform(df_train)\ndf_dtm.toarray()[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:40.419853Z","iopub.execute_input":"2021-11-17T02:11:40.420644Z","iopub.status.idle":"2021-11-17T02:11:40.434921Z","shell.execute_reply.started":"2021-11-17T02:11:40.420594Z","shell.execute_reply":"2021-11-17T02:11:40.433569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=4.2 ></a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">4.2 TF-IDF</p>\nReference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=0, max_df=0.98, max_features=100)\ndf_ifidf= tfidf_vect.fit_transform(df_train)\ndf_ifidf.toarray()[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:40.437044Z","iopub.execute_input":"2021-11-17T02:11:40.437776Z","iopub.status.idle":"2021-11-17T02:11:40.456083Z","shell.execute_reply.started":"2021-11-17T02:11:40.437733Z","shell.execute_reply":"2021-11-17T02:11:40.454952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=5 ></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5 BERT model</p>\n\n[Content](#0)","metadata":{}},{"cell_type":"markdown","source":"BERT(*Bi-directional Encoder Representations from Transformers*)\n\n    - GLUE Score to 80.5%\n    - MultiNLI accuracy to 86.7%\n    - SQuAD v1.1 question answering Test F1 to 93.3\n    - SQuAD v2.0 Test F1 to 83.1","metadata":{}},{"cell_type":"markdown","source":"<a id=5.1 ></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.1 Preprocessing Data</p>\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"df_test.text","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:40.458249Z","iopub.execute_input":"2021-11-17T02:11:40.459224Z","iopub.status.idle":"2021-11-17T02:11:40.472224Z","shell.execute_reply.started":"2021-11-17T02:11:40.459091Z","shell.execute_reply":"2021-11-17T02:11:40.471255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 0\n# Find the longest sentence \nfor sentence in pd.concat([df_train.text, df_test.text]):\n    if len(sentence) > max_len: # number of word in a sentence tokenizer is greater max_len\n        max_len = len(sentence)\nmax_len","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:40.476028Z","iopub.execute_input":"2021-11-17T02:11:40.476839Z","iopub.status.idle":"2021-11-17T02:11:40.497133Z","shell.execute_reply.started":"2021-11-17T02:11:40.476792Z","shell.execute_reply":"2021-11-17T02:11:40.495823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\ntrain_x = tokenizer.batch_encode_plus(df_train.text.tolist(), max_length=max_len, padding='max_length',return_tensors='tf')\ntest_x = tokenizer.batch_encode_plus(df_test.text.tolist(), max_length=max_len, padding='max_length', return_tensors='tf')\ntrain_y = df_train.target","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:40.499813Z","iopub.execute_input":"2021-11-17T02:11:40.500656Z","iopub.status.idle":"2021-11-17T02:11:56.078696Z","shell.execute_reply.started":"2021-11-17T02:11:40.500612Z","shell.execute_reply":"2021-11-17T02:11:56.077488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:56.080314Z","iopub.execute_input":"2021-11-17T02:11:56.080773Z","iopub.status.idle":"2021-11-17T02:11:56.093928Z","shell.execute_reply.started":"2021-11-17T02:11:56.080701Z","shell.execute_reply":"2021-11-17T02:11:56.092632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=5.2 ></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.2 DistilBERT model with Fine-tuning using Keras </p>\n\n[Content](#0)\n\nThe DistilBERT model was proposed in the blog post Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT","metadata":{}},{"cell_type":"code","source":"from transformers import TFAutoModelForSequenceClassification\n\ndef distilBERT_tuner(hp):\n    model = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased')\n    # Using learning_rate values are recommendated from paper BERT: Pre-training of Deep Bidirectional Transformers forLanguage Understanding\n    hp_learning_rate = hp.Choice('learning_rate', values=[5e-5, 4e-5 , 3e-5, 2e-5])\n    optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate)\n    model.compile(optimizer=optimizer,\n                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                 metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:56.095652Z","iopub.execute_input":"2021-11-17T02:11:56.0964Z","iopub.status.idle":"2021-11-17T02:11:56.243512Z","shell.execute_reply.started":"2021-11-17T02:11:56.09635Z","shell.execute_reply":"2021-11-17T02:11:56.242446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Instantiate the tuner and perform hypertuning","metadata":{}},{"cell_type":"code","source":"tuner = kt.Hyperband(distilBERT_tuner,\n                    objective='val_accuracy',\n                    max_epochs=4,\n                    factor=3,\n                    directory='my_dir',\n                    project_name='DistilBERT_to_kt')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:56.24511Z","iopub.execute_input":"2021-11-17T02:11:56.246679Z","iopub.status.idle":"2021-11-17T02:12:32.548181Z","shell.execute_reply.started":"2021-11-17T02:11:56.246628Z","shell.execute_reply":"2021-11-17T02:12:32.546962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_early = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:12:32.553528Z","iopub.execute_input":"2021-11-17T02:12:32.556209Z","iopub.status.idle":"2021-11-17T02:12:32.563501Z","shell.execute_reply.started":"2021-11-17T02:12:32.556154Z","shell.execute_reply":"2021-11-17T02:12:32.562297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(train_x['input_ids'], \n             train_y, \n             epochs=4, \n             validation_split=0.2, \n             callbacks=[stop_early])\n\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\nprint(f\"\"\"The hyperparameter search is complete. The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:12:32.568387Z","iopub.execute_input":"2021-11-17T02:12:32.571222Z","iopub.status.idle":"2021-11-17T02:21:13.499364Z","shell.execute_reply.started":"2021-11-17T02:12:32.571172Z","shell.execute_reply":"2021-11-17T02:21:13.497605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model","metadata":{}},{"cell_type":"code","source":"# Build the model with the optimal hyperparameters and train it on the data for 4 epochs\nmodel = tuner.hypermodel.build(best_hps)\nhistory = model.fit(train_x['input_ids'], \n                    train_y, \n                    epochs=4, \n                    validation_split=0.2)\n\nval_acc_per_epoch = history.history['val_accuracy']\nbest_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\nprint('Best epoch: %d' % (best_epoch,))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:21:13.50117Z","iopub.execute_input":"2021-11-17T02:21:13.501655Z","iopub.status.idle":"2021-11-17T02:25:12.74237Z","shell.execute_reply.started":"2021-11-17T02:21:13.501608Z","shell.execute_reply":"2021-11-17T02:25:12.741258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Re-instantiate the hypermodel and train it with the optimal number of epochs from above","metadata":{}},{"cell_type":"code","source":"hypermodel = tuner.hypermodel.build(best_hps)\n\n# Retrain the model\nhypermodel.fit(train_x['input_ids'], \n               train_y, \n               epochs=best_epoch, \n               validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:25:12.745976Z","iopub.execute_input":"2021-11-17T02:25:12.746332Z","iopub.status.idle":"2021-11-17T02:28:13.868385Z","shell.execute_reply.started":"2021-11-17T02:25:12.746286Z","shell.execute_reply":"2021-11-17T02:28:13.867239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=6 ></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">6. Make a Submission</p>\n\n[Content](#0)","metadata":{}},{"cell_type":"code","source":"def submission_transformer(model, test):\n    \"\"\"For Bert\"\"\"\n    sample_sub = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n    predictions =  model.predict(test['input_ids'])\n    y_preds = [ np.argmax(x) for x in predictions[0]]\n    sub = pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':y_preds})\n    sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:28:13.870664Z","iopub.execute_input":"2021-11-17T02:28:13.871463Z","iopub.status.idle":"2021-11-17T02:28:13.87912Z","shell.execute_reply.started":"2021-11-17T02:28:13.871417Z","shell.execute_reply":"2021-11-17T02:28:13.877985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_transformer(hypermodel, test_x)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:28:13.880928Z","iopub.execute_input":"2021-11-17T02:28:13.881617Z","iopub.status.idle":"2021-11-17T02:28:26.059446Z","shell.execute_reply.started":"2021-11-17T02:28:13.881571Z","shell.execute_reply":"2021-11-17T02:28:26.058315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:28:26.06114Z","iopub.execute_input":"2021-11-17T02:28:26.061751Z","iopub.status.idle":"2021-11-17T02:28:26.085154Z","shell.execute_reply.started":"2021-11-17T02:28:26.061691Z","shell.execute_reply":"2021-11-17T02:28:26.084037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=7 ></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">7. References</p>\n[Content](#0)","metadata":{}},{"cell_type":"markdown","source":"[Keras Tuner](https://keras.io/keras_tuner)\n\n[Distil Bert](https://huggingface.co/transformers/model_doc/distilbert.html)","metadata":{}},{"cell_type":"markdown","source":"# If you like this kernel, please upvote and tell me your thought. Thank you @@","metadata":{}}]}