{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T09:04:22.033491Z","iopub.execute_input":"2022-05-19T09:04:22.033797Z","iopub.status.idle":"2022-05-19T09:04:22.044166Z","shell.execute_reply.started":"2022-05-19T09:04:22.033763Z","shell.execute_reply":"2022-05-19T09:04:22.043389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom torch.nn import *\nfrom sklearn.naive_bayes import MultinomialNB\nfrom torch.optim import *\nfrom torchvision.models import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import f1_score,accuracy_score,precision_score\nimport wandb\nimport nltk\nfrom nltk.stem.porter import *\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import f1_score\nfrom sklearn import svm\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nimport warnings\nimport os\nwarnings.filterwarnings(\"ignore\")\nPROJECT_NAME = \"Natural-Language-Processing-with-Disaster-Tweets\"\nnp.random.seed(55)\nstemmer = PorterStemmer()\ndevice = \"cuda\"\nos.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\nprint(\"Version: \", tf.__version__)\nprint(\"Eager mode: \", tf.executing_eagerly())\nprint(\"Hub version: \", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:04:22.192625Z","iopub.execute_input":"2022-05-19T09:04:22.193272Z","iopub.status.idle":"2022-05-19T09:04:22.204896Z","shell.execute_reply.started":"2022-05-19T09:04:22.193237Z","shell.execute_reply":"2022-05-19T09:04:22.204099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Sklearn_Data_Loader:\n    def __init__(\n        self,\n        data: pd.DataFrame = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\"),\n        test: pd.DataFrame = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\"),\n        all_words: list = [],\n        tags: list = [],\n    ):\n        self.data = data\n        self.data = self.data.sample(frac=1)\n        self.test = test\n        self.X = self.data[\"text\"]\n        self.y = self.data[\"target\"]\n        # self.y = np.array(self.y.tolist())\n        # self.y = self.y.reshape(-1, 1)\n        self.all_words = all_words\n\n    def create(self, count_vectorizer=False):\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            self.X, self.y, test_size=0.0625, shuffle=True\n        )\n        if count_vectorizer:\n            self.vectorizer = CountVectorizer(binary=1)\n        else:\n            self.vectorizer = TfidfVectorizer()\n        self.X_train = self.vectorizer.fit_transform(self.X_train)\n        self.X_test = self.vectorizer.transform(self.X_test)\n        # self.X_train = np.array(self.X_train)\n        # self.y_train = np.array(self.y_train)\n        # self.X_test = np.array(self.X_test)\n        # self.y_test = np.array(self.y_test)\n        return self.X_train, self.X_test, self.y_train, self.y_test, self.vectorizer\n\n    def create_test(self):\n        return self.vectorizer.transform(self.test[\"text\"])\n\n    def create_submission(self, model):\n        preds = model.predict(self.create_test())\n        print(preds)\n        ids = self.test[\"id\"]\n        submission = {\"id\": [], \"target\": []}\n        for pred, id in tqdm(zip(preds, ids)):\n            submission[\"id\"].append(id)\n            submission[\"target\"].append(int(pred))\n        submission = pd.DataFrame(submission)\n        return submission\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:04:22.354514Z","iopub.execute_input":"2022-05-19T09:04:22.354826Z","iopub.status.idle":"2022-05-19T09:04:22.403123Z","shell.execute_reply.started":"2022-05-19T09:04:22.354795Z","shell.execute_reply":"2022-05-19T09:04:22.402328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Sklearn_Modelling:\n    def train(self, model, X_train, y_train, X_test, y_test, name):\n#         wandb.init(project=PROJECT_NAME, name=name)\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n#         preds_prob = model.predict_proba(X_test)\n        labels = sorted(set(list(y_test)))\n#         wandb.log(\n#             {\n#                 \"Accuracy\": accuracy_score(preds, y_test),\n#                 \"F1 Score\": f1_score(preds, y_test),\n#                 \"Precisions\": precision_score(preds, y_test),\n#             }\n#         )\n        print(\n            {\n                \"Accuracy\": accuracy_score(preds, y_test),\n                \"F1 Score\": f1_score(preds, y_test),\n                \"Precisions\": precision_score(preds, y_test),\n            }\n        )\n#         wandb.sklearn.plot_confusion_matrix(y_test, preds, labels)\n        # wandb.sklearn.plot_classifier(model, X_train, X_test, y_train, y_test, preds, preds_prob, {0:0,1:1},\n        #                                                  model_name=f'{model}')\n#         wandb.sklearn.plot_roc(y_test, preds_prob, labels)\n#         wandb.sklearn.plot_precision_recall(y_test, preds_prob, labels)\n#         wandb.sklearn.plot_confusion_matrix(y_test, preds, labels)\n#         wandb.finish()\n        return model, preds","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:04:22.467576Z","iopub.execute_input":"2022-05-19T09:04:22.467881Z","iopub.status.idle":"2022-05-19T09:04:22.475767Z","shell.execute_reply.started":"2022-05-19T09:04:22.467848Z","shell.execute_reply":"2022-05-19T09:04:22.474996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdl = Sklearn_Data_Loader()\nX_train, X_test, y_train, y_test, vectorizer = sdl.create()\nsm = Sklearn_Modelling()\nmodel = svm.SVC()\nmodel.fit(X_train, y_train)\nmodel.fit(X_train, y_train)\nmodel, preds = sm.train(model, X_train, y_train, X_test, y_test, \"name\")\nsubmission = sdl.create_submission(model)\nsubmission.to_csv(\"./Sklearn-1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:04:47.682649Z","iopub.execute_input":"2022-05-19T09:04:47.682961Z","iopub.status.idle":"2022-05-19T09:05:20.755595Z","shell.execute_reply.started":"2022-05-19T09:04:47.682915Z","shell.execute_reply":"2022-05-19T09:05:20.754669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}