{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T13:33:16.160421Z","iopub.execute_input":"2022-05-19T13:33:16.161362Z","iopub.status.idle":"2022-05-19T13:33:16.175251Z","shell.execute_reply.started":"2022-05-19T13:33:16.16124Z","shell.execute_reply":"2022-05-19T13:33:16.174374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:33:18.959575Z","iopub.execute_input":"2022-05-19T13:33:18.960326Z","iopub.status.idle":"2022-05-19T13:33:19.698891Z","shell.execute_reply.started":"2022-05-19T13:33:18.960289Z","shell.execute_reply":"2022-05-19T13:33:19.697849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom torch.nn import *\nfrom torch.optim import *\nfrom torchvision.models import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import f1_score,accuracy_score,precision_score\nimport wandb\nimport nltk\nfrom nltk.stem.porter import *\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import f1_score\nfrom sklearn import svm\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nimport warnings\nimport os\nwarnings.filterwarnings(\"ignore\")\nPROJECT_NAME = \"Natural-Language-Processing-with-Disaster-Tweets\"\nnp.random.seed(55)\nstemmer = PorterStemmer()\ndevice = \"cpu\"\nos.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\nprint(\"Version: \", tf.__version__)\nprint(\"Eager mode: \", tf.executing_eagerly())\nprint(\"Hub version: \", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:16:42.220815Z","iopub.execute_input":"2022-05-19T12:16:42.221597Z","iopub.status.idle":"2022-05-19T12:16:42.23409Z","shell.execute_reply.started":"2022-05-19T12:16:42.221546Z","shell.execute_reply":"2022-05-19T12:16:42.233279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Pytorch_Data_Loader:\n    def __init__(\n        self,\n        data: pd.DataFrame = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\"),\n        test: pd.DataFrame = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\"),\n        all_words: list = [],\n        tags: list = [],\n    ):\n        self.data = data\n        self.data = self.data.sample(frac=1)\n        self.test = test\n        self.X = self.data[\"text\"]\n        self.y = self.data[\"target\"]\n        self.all_words = all_words\n        self.tags = tags\n\n    def tokenize(self, sentence):\n        return nltk.word_tokenize(sentence.lower())\n\n    def stem(self, word):\n        return stemmer.stem(word.lower())\n\n    def words_to_int(self, words, all_words):\n        new_words = []\n        for word in words:\n            new_words.append(self.stem(word))\n        list_of_os = np.zeros(len(all_words))\n        for i in range(len(all_words)):\n            if all_words[i] in new_words:\n                list_of_os[i] = 1.0\n        return list_of_os\n\n    def create_all_words(self):\n        for x_iter, y_iter in tqdm(zip(self.X, self.y)):\n            x_iter = self.tokenize(x_iter)\n            new_x_iter = []\n            for x_iter_i in x_iter:\n                new_x_iter.append(self.stem(x_iter_i))\n            self.all_words.extend(new_x_iter)\n            self.tags.append(y_iter)\n        np.random.shuffle(self.all_words)\n        self.all_words = sorted(set(self.all_words))\n        self.tags = sorted(set(self.tags))\n        return self.all_words, self.tags\n\n    def create(self, test_size=0.0625, shuffle=True):\n        self.create_all_words()\n        self.new_X = []\n        self.new_y = []\n        for X_iter, y_iter in tqdm(zip(self.X, self.y)):\n            self.new_X.append(self.words_to_int(X_iter, self.all_words))\n            self.new_y.append(self.tags.index(y_iter))\n        self.X = np.array(self.new_X)\n        self.y = np.array(self.new_y)\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            self.X, self.y, test_size=test_size, shuffle=shuffle\n        )\n        self.X_train = torch.from_numpy(self.X_train).to(device)\n        self.y_train = torch.from_numpy(self.y_train).to(device)\n        self.X_test = torch.from_numpy(self.X_test).to(device)\n        self.y_test = torch.from_numpy(self.y_test).to(device)\n        return (\n            self.new_X,\n            self.new_y,\n            self.X,\n            self.y,\n            self.X_train,\n            self.X_test,\n            self.y_train,\n            self.y_test,\n            self.all_words\n        )\n\n    def create_test(self):\n        new_test = []\n        for X_iter in tqdm(self.test[\"text\"]):\n            new_test.append(self.words_to_int(X_iter, self.all_words))\n        new_test = torch.from_numpy(np.array(new_test)).to(\"cpu\")\n        return new_test\n\n    def create_submission(self, model):\n        model.to(\"cpu\")\n        preds = model(self.create_test().float())\n        ids = self.test[\"id\"]\n        submission = {\"id\": [], \"target\": []}\n        for pred, id in tqdm(zip(preds, ids)):\n            submission[\"id\"].append(id)\n            submission[\"target\"].append(int(torch.argmax(pred)))\n        submission = pd.DataFrame(submission)\n        return submission","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:16:42.397348Z","iopub.execute_input":"2022-05-19T12:16:42.397654Z","iopub.status.idle":"2022-05-19T12:16:42.455126Z","shell.execute_reply.started":"2022-05-19T12:16:42.397619Z","shell.execute_reply":"2022-05-19T12:16:42.454501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef accuracy(model, X, y):\n    correct = 0\n    total = 0\n    preds = model(X.float())\n    for pred, y_batch in zip(preds, y):\n        pred = int(torch.argmax(pred))\n        y_batch = int(y_batch)\n        if pred == y_batch:\n            correct += 1\n        total += 1\n    acc = round(correct / total, 3) * 100\n    return acc\ndef g_loss(model,X,y,criterion):\n    preds = model(X.float())\n    loss = criterion(preds.float(), y.long())\n    return loss.item()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:16:42.530874Z","iopub.execute_input":"2022-05-19T12:16:42.531281Z","iopub.status.idle":"2022-05-19T12:16:42.538Z","shell.execute_reply.started":"2022-05-19T12:16:42.531251Z","shell.execute_reply":"2022-05-19T12:16:42.537072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(Module):\n    def __init__(self, input_size, hidden_size=512, num_classes=2):\n        super(Model, self).__init__()\n        self.l1 = Linear(input_size, hidden_size)\n        self.l2 = Linear(hidden_size, hidden_size*2)\n        self.l3 = Linear(hidden_size*2, hidden_size*4)\n        self.l4 = Linear(hidden_size*4, hidden_size*2)\n        self.l5 = Linear(hidden_size*2, num_classes)\n        self.relu = ReLU()\n\n    def forward(self, x):\n        preds = self.l1(x)\n        preds = self.relu(preds)\n        preds = self.l2(preds)\n        preds = self.relu(preds)\n        preds = self.l3(preds)\n        preds = self.relu(preds)\n        preds = self.l4(preds)\n        preds = self.relu(preds)\n        preds = self.l5(preds)\n        return preds\n\n\nclass Pytorch_Modelling:\n    def train(\n        self,\n        X_train,\n        X_test,\n        y_train,\n        y_test,\n        all_words,\n        model=Model,\n        criterion=CrossEntropyLoss(),  # TODO \n        optimizer=Adam,\n        epochs=100,\n        batch_size=32,\n        name=\"BaseLine\",\n    ):\n        model = Model(input_size=len(all_words)).to(device)\n        optimizer = optimizer(model.parameters(), lr=0.001)\n        #wandb.init(project=PROJECT_NAME, name=name)\n        #wandb.watch(model, log_freq=10)\n        torch.cuda.empty_cache()\n        for _ in tqdm(range(epochs)):\n            torch.cuda.empty_cache()\n            for i in range(0, len(X_train), batch_size):\n                torch.cuda.empty_cache()\n                try:\n                    X_batch = X_train[i : i + batch_size]\n                    y_batch = y_train[i : i + batch_size]\n                    preds = model(X_batch.float())\n                    loss = criterion(preds.float(), y_batch.long())\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n                except Exception as e:\n                    print(e)\n            model.eval()\n            #wandb.log(\n            #    {\n            #        \"Val Accuracy\": accuracy(model, X_test, y_test),\n            #        \"Val Loss\": g_loss(model, X_test, y_test.long(),criterion),\n            #        \"Accuracy\": accuracy(model, X_train, y_train),\n            #        \"Loss\": g_loss(model, X_train, y_train.long(),criterion),\n            #    }\n            #)\n            model.train()\n        # wandb.finish()\n        return model","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:16:42.727076Z","iopub.execute_input":"2022-05-19T12:16:42.727399Z","iopub.status.idle":"2022-05-19T12:16:42.744244Z","shell.execute_reply.started":"2022-05-19T12:16:42.727365Z","shell.execute_reply":"2022-05-19T12:16:42.743368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdl = Pytorch_Data_Loader()\nnew_X,new_y,X,y,X_train,X_test,y_train,y_test,all_words = sdl.create()\nsm = Pytorch_Modelling()\nmodel = sm.train(X_train,X_test,y_train,y_test,all_words, \"name\")\nsubmission = sdl.create_submission(model)\nsubmission.to_csv(\"./Pytorch-1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:16:42.900963Z","iopub.execute_input":"2022-05-19T12:16:42.901364Z","iopub.status.idle":"2022-05-19T13:13:33.383777Z","shell.execute_reply.started":"2022-05-19T12:16:42.901334Z","shell.execute_reply":"2022-05-19T13:13:33.382918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}