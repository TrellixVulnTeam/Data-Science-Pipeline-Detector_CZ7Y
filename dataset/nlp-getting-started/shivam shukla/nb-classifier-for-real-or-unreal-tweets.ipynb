{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"print('Tweets Real / Fake Classification......')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Import All required libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nlv_path = r'../input/nlp-getting-started/'\nprint(os.listdir(lv_path))\nimport numpy as np\nimport pandas as pd\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(r'../input/nlp-getting-started/train.csv')\ntrain_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('training data shape: ', train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(r'../input/nlp-getting-started/sample_submission.csv')\nsub_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/nlp-getting-started/test.csv')\ntest_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.barplot(train_df['target'].value_counts().index,train_df['target'].value_counts(),palette='rocket')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A disaster tweet\ndisaster_tweets = train_df[train_df['target']==1]['text']\ndisaster_tweets.values[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#not a disaster tweet\nnon_disaster_tweets = train_df[train_df['target']==0]['text']\nnon_disaster_tweets.values[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['text'].str.contains('disaster', na=False, case=False)].target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A quick glance over the existing data\ntrain_df['text'][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nprint(train_df.text[3])\nre.sub(\"RT @[\\w]*:\", \"\" , train_df.text[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_data(tweet):\n    tweet = re.sub(\"RT @[\\w]*:\", \"\", tweet)\n    tweet = re.sub(\"@[\\w]*\", \"\", tweet)\n    tweet = re.sub(\"https://[A-Za-z0-9./]\", \"\", tweet)\n    tweet = re.sub(\"\\n\", \"\", tweet)\n    tweet = re.sub(\"&amp\", \"\", tweet)\n    tweet = re.sub(\"#\", \"\", tweet)\n    tweet = re.sub(r\"[^\\w]\", ' ', tweet )\n    return tweet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: clean_data(x))\ntest_df['text'] = test_df['text'].apply(lambda x: clean_data(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: x.lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\ntrain_df['text'] = train_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfake_data = train_df[train_df[\"target\"] == 0]\nall_words = ' '.join([text for text in fake_data.text])\nwordcloud = WordCloud(width= 800, height= 500,\n                          max_font_size = 110,\n                          collocations = False).generate(all_words)\nplt.figure(figsize=(10,7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nfake_data = train_df[train_df[\"target\"] == 1]\nall_words = ' '.join([text for text in fake_data.text])\nwordcloud = WordCloud(width= 800, height= 500,\n                          max_font_size = 110,\n                          collocations = False).generate(all_words)\nplt.figure(figsize=(10,7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = train_df['text'], train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #DataFlair - Split the dataset\n# x_train,x_test,y_train,y_test=train_test_split(train_df['target'], labels, test_size=0.2, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vect = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_df = count_vect.fit_transform(X)\n# x_train_tr = count_vect.fit_transform(train_df.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_df.shape, train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfTransformer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_traintf = tfidf.fit_transform(x_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_traintf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels = train_df.target\n# labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MultinomialNB().fit(x_traintf, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_in = [\n#     'deeds reason earthquake may allah forgive us',\n#     'summer lovely',\n#     'damage school bus 80 multi car crash breaking',\n#     'man'\n'The U.S. Army released new guidelines for optimal soldier performance â€” and they include strategic and aggressive napping']\nX_test_in = count_vect.transform(test_df.text) #(test_in)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_tf = tfidf.transform(X_test_in)\nx_test_tf","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"pred = clf.predict(x_test_tf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Dataset "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['target'] = pred.round().astype(int)\nsub_df.to_csv(r'Your System Path', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}