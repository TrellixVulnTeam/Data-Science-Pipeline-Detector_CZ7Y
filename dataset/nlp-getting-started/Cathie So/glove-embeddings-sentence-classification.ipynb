{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Embedding\nfrom keras import layers\nfrom keras.utils import to_categorical\nfrom keras.regularizers import l2\nfrom keras import Model, Input\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport keras\nimport regex as re","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = [str(train.iloc[i].keyword)+\" \"+str(train.iloc[i].location)+\" \"+train.iloc[i].text for i in range(len(train))]\n#X = [train.iloc[i].text for i in range(len(train))]\nX = [re.sub(r'[^a-zA-Z\\ ]', '', s).lower() for s in X]\nX = np.array(X)\ny = [train.iloc[i].target for i in range(len(train))]\ny = np.array(y)\nprint(np.unique(y, return_counts=True))\n#y = to_categorical(y)\nX.shape, y.shape, X[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = [str(test.iloc[i].keyword)+\" \"+str(test.iloc[i].location)+\" \"+test.iloc[i].text for i in range(len(test))]\n#X_test = [test.iloc[i].text for i in range(len(test))]\nX_test = [re.sub(r'[^a-zA-Z\\ ]', '', s).lower() for s in X_test]\nX_test = np.array(X_test)\nX_test.shape, X_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, counts = np.unique(y_train, return_counts=True)\nclass_weight = [np.size(y_train)/c for c in counts]\ncounts, class_weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n\nvectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\ntext_ds = tf.data.Dataset.from_tensor_slices(X_train).batch(128)\nvectorizer.adapt(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer.get_vocabulary()[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = vectorizer(np.array([[\"the cat sat on the\"]]))\noutput.numpy()[0, :5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voc = vectorizer.get_vocabulary()\nword_index = dict(zip(voc, range(2, len(voc))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = [b\"the\", b\"cat\", b\"sat\", b\"on\", b\"the\"]\n[word_index[w] for w in test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_to_glove_file = \"/kaggle/input/glove6b/glove.6B.100d.txt\"\n\nembeddings_index = {}\nwith open(path_to_glove_file) as f:\n    for line in f:\n        word, coefs = line.split(maxsplit=1)\n        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n        embeddings_index[word] = coefs\n\nprint(\"Found %s word vectors.\" % len(embeddings_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_tokens = len(voc) + 2\nembedding_dim = 100\nhits = 0\nmisses = 0\n\n# Prepare embedding matrix\nembedding_matrix = np.zeros((num_tokens, embedding_dim))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word.decode(\"utf-8\"))\n    if embedding_vector is not None:\n        # Words not found in embedding index will be all-zeros.\n        # This includes the representation for \"padding\" and \"OOV\"\n        embedding_matrix[i] = embedding_vector\n        hits += 1\n    else:\n        misses += 1\nprint(\"Converted %d words (%d misses)\" % (hits, misses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = vectorizer(np.array([[s] for s in X_train])).numpy()\nX_val = vectorizer(np.array([[s] for s in X_val])).numpy()\nX_test = vectorizer(np.array([[s] for s in X_test])).numpy()\nX_train.shape, X_val.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_layer = Embedding(\n    num_tokens,\n    embedding_dim,\n    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n    trainable=False,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropout_rate = 0.5\nl2_rate = 1.e-6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\nembedded_sequences = embedding_layer(int_sequences_input)\nx = layers.Conv1D(128, 5, activation=\"relu\", kernel_regularizer=l2(l2_rate))(embedded_sequences)\nx = layers.MaxPooling1D(5)(x)\nx = layers.Dropout(dropout_rate)(x)\nx = layers.Conv1D(128, 5, activation=\"relu\", kernel_regularizer=l2(l2_rate))(x)\nx = layers.MaxPooling1D(5)(x)\nx = layers.Dropout(dropout_rate)(x)\nx = layers.Conv1D(128, 5, activation=\"relu\", kernel_regularizer=l2(l2_rate))(x)\nx = layers.GlobalMaxPooling1D()(x)\nx = layers.Dropout(dropout_rate)(x)\nx = layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(l2_rate))(x)\nx = layers.Dropout(dropout_rate)(x)\npreds = layers.Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(l2_rate))(x)\nmodel = keras.Model(int_sequences_input, preds)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(patience=10, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n\nmodel.fit(X_train, y_train, batch_size=128, epochs=100, validation_data=(X_val, y_val), \n              class_weight={0: class_weight[0], 1: class_weight[1]}, \n              callbacks=[early_stopping, model_checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = load_model(\"best_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = best_model.predict(X_test, verbose=1, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.round(y_pred)\nnp.unique(y_pred, return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(y_pred)):\n    sub.iloc[i].target = y_pred[i]\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}