{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk import pos_tag\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom gensim.models import Word2Vec, KeyedVectors\nimport string\nimport matplotlib.pyplot as plt\nimport math\nimport re\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-10T17:58:36.760632Z","iopub.execute_input":"2021-07-10T17:58:36.76118Z","iopub.status.idle":"2021-07-10T17:58:37.770627Z","shell.execute_reply.started":"2021-07-10T17:58:36.761069Z","shell.execute_reply":"2021-07-10T17:58:37.769771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"sentence_size = 128\nword_vector_size = 128\nword_vector_window = 5\nepochs = 10\nlearning_rate = 0.000035 \nbatch_size = 32\nhidden_size =512\nn_layers=3","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:09:53.731444Z","iopub.execute_input":"2021-07-10T18:09:53.731775Z","iopub.status.idle":"2021-07-10T18:09:53.736902Z","shell.execute_reply.started":"2021-07-10T18:09:53.731742Z","shell.execute_reply":"2021-07-10T18:09:53.736067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Device","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.781472Z","iopub.execute_input":"2021-07-10T17:58:37.781901Z","iopub.status.idle":"2021-07-10T17:58:37.809072Z","shell.execute_reply.started":"2021-07-10T17:58:37.781857Z","shell.execute_reply":"2021-07-10T17:58:37.808035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/nlp-getting-started/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.810733Z","iopub.execute_input":"2021-07-10T17:58:37.811164Z","iopub.status.idle":"2021-07-10T17:58:37.854281Z","shell.execute_reply.started":"2021-07-10T17:58:37.811126Z","shell.execute_reply":"2021-07-10T17:58:37.853348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/nlp-getting-started/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.855676Z","iopub.execute_input":"2021-07-10T17:58:37.856025Z","iopub.status.idle":"2021-07-10T17:58:37.879289Z","shell.execute_reply.started":"2021-07-10T17:58:37.85599Z","shell.execute_reply":"2021-07-10T17:58:37.87829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(['id','keyword','location'],axis=1, inplace = True)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.880722Z","iopub.execute_input":"2021-07-10T17:58:37.881089Z","iopub.status.idle":"2021-07-10T17:58:37.891506Z","shell.execute_reply.started":"2021-07-10T17:58:37.881054Z","shell.execute_reply":"2021-07-10T17:58:37.890463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.drop(['keyword','location'],axis=1, inplace = True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.89307Z","iopub.execute_input":"2021-07-10T17:58:37.893435Z","iopub.status.idle":"2021-07-10T17:58:37.906756Z","shell.execute_reply.started":"2021-07-10T17:58:37.893397Z","shell.execute_reply":"2021-07-10T17:58:37.905761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"train_raw_x = train_df['text']\ntest_raw_x = test_df['text']","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.908517Z","iopub.execute_input":"2021-07-10T17:58:37.908912Z","iopub.status.idle":"2021-07-10T17:58:37.915918Z","shell.execute_reply.started":"2021-07-10T17:58:37.908874Z","shell.execute_reply":"2021-07-10T17:58:37.915044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def processText(text, target_length=None):\n    \n    start_token='<start>'\n    end_token = '<end>'\n    \n    #text = ''.join(char for char in text.lower() if char not in string.punctuation)   #Make all lower case and remove punctuations\n    text = text.lower()\n    \n    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n    text = re.sub(\" \\d+\", \" \", text) # remove pure number strings\n    text = re.sub(r'http\\S+','', text)\n    \n    \n    tokens = word_tokenize(text)\n    \n    stopword =  stopwords.words('english')\n    \n    tokens =  [token for token in tokens if token not in stopword]\n    \n    lemmatizer = WordNetLemmatizer()\n    lemmatized_tokens =  [lemmatizer.lemmatize(token) for token in tokens]\n    \n    lemmatized_tokens.insert(0,start_token)\n    lemmatized_tokens.append(end_token)\n    \n    if target_length == None:\n        return lemmatized_tokens\n    \n    while len(lemmatized_tokens) < target_length:\n        lemmatized_tokens.extend(lemmatized_tokens)\n    \n    return lemmatized_tokens[0:target_length]","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.919725Z","iopub.execute_input":"2021-07-10T17:58:37.920062Z","iopub.status.idle":"2021-07-10T17:58:37.929229Z","shell.execute_reply.started":"2021-07-10T17:58:37.920037Z","shell.execute_reply":"2021-07-10T17:58:37.928261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_trained_x = [processText(sentence,sentence_size) for sentence in train_raw_x]\nprocessed_test_x = [processText(sentence,sentence_size) for sentence in test_raw_x]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:37.93118Z","iopub.execute_input":"2021-07-10T17:58:37.931578Z","iopub.status.idle":"2021-07-10T17:58:44.615803Z","shell.execute_reply.started":"2021-07-10T17:58:37.931539Z","shell.execute_reply":"2021-07-10T17:58:44.614771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forming word vectors using Word2Vec","metadata":{}},{"cell_type":"code","source":"all_x =processed_trained_x + processed_test_x","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:44.61721Z","iopub.execute_input":"2021-07-10T17:58:44.617566Z","iopub.status.idle":"2021-07-10T17:58:44.622864Z","shell.execute_reply.started":"2021-07-10T17:58:44.617529Z","shell.execute_reply":"2021-07-10T17:58:44.621917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector_model = Word2Vec(all_x,min_count=1,vector_size=word_vector_size,window=word_vector_window)\nvector =  vector_model.wv","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:44.624332Z","iopub.execute_input":"2021-07-10T17:58:44.624713Z","iopub.status.idle":"2021-07-10T17:58:54.788123Z","shell.execute_reply.started":"2021-07-10T17:58:44.624669Z","shell.execute_reply":"2021-07-10T17:58:54.78726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector_train_x = []\nfor sentence in processed_trained_x:\n    vector_train_x.append([vector[token].tolist() for token in sentence])","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:58:54.789492Z","iopub.execute_input":"2021-07-10T17:58:54.78987Z","iopub.status.idle":"2021-07-10T17:59:07.641473Z","shell.execute_reply.started":"2021-07-10T17:58:54.789835Z","shell.execute_reply":"2021-07-10T17:59:07.640441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector_test_x = []\nfor sentence in processed_test_x:\n    vector_test_x.append([vector[token].tolist() for token in sentence])","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:59:07.642837Z","iopub.execute_input":"2021-07-10T17:59:07.643219Z","iopub.status.idle":"2021-07-10T17:59:13.372737Z","shell.execute_reply.started":"2021-07-10T17:59:07.643183Z","shell.execute_reply":"2021-07-10T17:59:13.371716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test/Validation split","metadata":{}},{"cell_type":"code","source":"#x_train, x_validation, y_train ,y_validation = train_test_split(vector_train_x, train_df['target'],test_size = .2)\nx_train , y_train = vector_train_x , train_df['target']","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:59:13.374138Z","iopub.execute_input":"2021-07-10T17:59:13.374499Z","iopub.status.idle":"2021-07-10T17:59:13.387646Z","shell.execute_reply.started":"2021-07-10T17:59:13.37446Z","shell.execute_reply":"2021-07-10T17:59:13.384687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset and Data","metadata":{}},{"cell_type":"code","source":"class NLPData(Dataset):\n    def __init__(self):\n        self.x_data = torch.tensor(x_train ) #vector_train_x)\n        self.y_data = torch.tensor(list(y_train),dtype=torch.float32)\n        self.n_samples =  len(self.y_data)\n    \n    def __getitem__(self,idx):\n        return self.x_data[idx] , self.y_data[idx]\n    \n    def __len__(self):\n        return self.n_samples\ndataset = NLPData()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:59:13.389473Z","iopub.execute_input":"2021-07-10T17:59:13.390063Z","iopub.status.idle":"2021-07-10T17:59:21.982501Z","shell.execute_reply.started":"2021-07-10T17:59:13.390024Z","shell.execute_reply":"2021-07-10T17:59:21.981483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle = True )","metadata":{"execution":{"iopub.status.busy":"2021-07-10T17:59:21.986219Z","iopub.execute_input":"2021-07-10T17:59:21.986494Z","iopub.status.idle":"2021-07-10T17:59:21.997488Z","shell.execute_reply.started":"2021-07-10T17:59:21.986467Z","shell.execute_reply":"2021-07-10T17:59:21.996731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model, loss and optimizer","metadata":{}},{"cell_type":"code","source":"class LSTMNN(nn.Module):\n    def __init__(self):\n        super(LSTMNN,self).__init__()\n        \n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        \n        self.lstm = nn.LSTM(word_vector_size,hidden_size,n_layers,batch_first=True)\n        self.fc1 = nn.Linear(hidden_size,hidden_size)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(hidden_size,hidden_size)\n        self.fc3 = nn.Linear(hidden_size,1)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self,x):\n        h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device)\n        c0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device)\n        \n        out, _ = self.lstm(x, (h0,c0))\n        out = out[:,-1,:]\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc3(out)\n        out = self.sigmoid(out)\n        \n        return out\n\nmodel = LSTMNN().to(device)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:09:59.415745Z","iopub.execute_input":"2021-07-10T18:09:59.416094Z","iopub.status.idle":"2021-07-10T18:09:59.475116Z","shell.execute_reply.started":"2021-07-10T18:09:59.41606Z","shell.execute_reply":"2021-07-10T18:09:59.474285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCELoss()\noptimizer = torch.optim.RMSprop(model.parameters(),lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:09:59.784974Z","iopub.execute_input":"2021-07-10T18:09:59.785282Z","iopub.status.idle":"2021-07-10T18:09:59.790405Z","shell.execute_reply.started":"2021-07-10T18:09:59.785253Z","shell.execute_reply":"2021-07-10T18:09:59.789133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"all_loss =[]\nfor epoch in range(epochs):\n    for x,y in train_loader:\n        x,y = x.to(device), y.to(device).view(-1,1) \n        \n        y_hat =  model(x)\n        \n        loss = criterion(y_hat,y)\n        \n        if(loss.item()<0.2): \n            break\n        all_loss.append(loss.item())\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    print(f'Epoch: {epoch+1} Loss: {loss.item()}')\n    if(loss.item()<0.2): \n            break","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:10:01.51667Z","iopub.execute_input":"2021-07-10T18:10:01.517032Z","iopub.status.idle":"2021-07-10T18:10:57.182373Z","shell.execute_reply.started":"2021-07-10T18:10:01.516995Z","shell.execute_reply":"2021-07-10T18:10:57.181391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(24,6))\nplt.plot(all_loss)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:11:02.578947Z","iopub.execute_input":"2021-07-10T18:11:02.579317Z","iopub.status.idle":"2021-07-10T18:11:02.801029Z","shell.execute_reply.started":"2021-07-10T18:11:02.579283Z","shell.execute_reply":"2021-07-10T18:11:02.800034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:11:05.546729Z","iopub.execute_input":"2021-07-10T18:11:05.547085Z","iopub.status.idle":"2021-07-10T18:11:05.553292Z","shell.execute_reply.started":"2021-07-10T18:11:05.547046Z","shell.execute_reply":"2021-07-10T18:11:05.552263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = torch.tensor(vector_test_x).to(device)\n#x_validation = torch.tensor(x_validation).to(device)\n#y_pred = model(x_validation)\ny_pred = model(x_test)\nwith torch.no_grad():\n    y_pred =  np.round(y_pred.to('cpu').numpy()).astype(np.int32)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:12:06.239211Z","iopub.execute_input":"2021-07-10T18:12:06.23959Z","iopub.status.idle":"2021-07-10T18:12:11.405289Z","shell.execute_reply.started":"2021-07-10T18:12:06.239558Z","shell.execute_reply":"2021-07-10T18:12:11.404366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.drop(['text'],axis=1,inplace=True)\ntest_df['target']=y_pred\ntest_df.to_csv('output.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:12:13.899491Z","iopub.execute_input":"2021-07-10T18:12:13.899816Z","iopub.status.idle":"2021-07-10T18:12:13.917724Z","shell.execute_reply.started":"2021-07-10T18:12:13.899784Z","shell.execute_reply":"2021-07-10T18:12:13.916938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = y_pred.reshape(-1)\n#(y_pred == y_validation).sum()/len(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T18:11:09.45208Z","iopub.execute_input":"2021-07-10T18:11:09.452524Z","iopub.status.idle":"2021-07-10T18:11:09.466272Z","shell.execute_reply.started":"2021-07-10T18:11:09.452483Z","shell.execute_reply":"2021-07-10T18:11:09.465089Z"},"trusted":true},"execution_count":null,"outputs":[]}]}