{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split as TTS\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport nltk\n# nltk.download('stopwords')\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\nsample_df = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1 is disaster, while 0 is not**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df[\"text\"].values\nX_val = test_df[\"text\"].values\ny_train = train_df[\"target\"].values\n# y_val = test_df[\"target\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nREPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\[@,;]]')\nBAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\nSTOPWORDS = set(stopwords.words(\"english\"))\n\ndef process(text):\n    \n    text = text.lower()\n    text = REPLACE_BY_SPACE_RE.sub('',text)\n    text = BAD_SYMBOLS_RE.sub('',text)\n    \n    text = ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = [process(x) for x in X_train]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 1000\ntrunc='post'\nmax_length = 150\ntokenizer = Tokenizer(num_words=vocab_size,oov_token='<OOV>')\ntokenizer.fit_on_texts(X_train)\n\nword_index = tokenizer.word_index\n\nsequences = tokenizer.texts_to_sequences(X_train)\npadded = pad_sequences(sequences,maxlen=max_length,truncating=trunc,padding='post')\n\nval_sequences = tokenizer.texts_to_sequences(X_val)\nval_padded = pad_sequences(val_sequences,maxlen=max_length,truncating=trunc,padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, Dense, GlobalAveragePooling1D, Bidirectional, LSTM, Conv1D, Dropout, Activation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Embedding(vocab_size,20,input_length=max_length))\nmodel.add(Bidirectional(LSTM(64)))\n\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nhistory = model.fit(padded,y_train,epochs=20,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_history(history):\n    fig,ax = plt.subplots(1,2,figsize=(15,5))\n    \n    ax[0].plot(history.history['loss'])\n    ax[1].plot(history.history['accuracy'])\n    \n    ax[0].set_title(\"Loss\")\n    ax[0].set_title(\"Accuracy\")\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_and_save(test,model,name):\n    \n    test = [process(x) for x in test]\n    test = np.array(test)\n    test_sequences = tokenizer.texts_to_sequences(test)\n    test_padded = pad_sequences(test_sequences,maxlen=max_length,truncating=trunc,padding='post')\n    \n    pred = model.predict(test_padded)\n    pred = np.argmax(pred,axis=1)\n    pred = np.array(pred)\n    sample_df.target = pred\n    sample_df.to_csv(name,index=False)\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_save(X_val,model,\"model_lstm.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}