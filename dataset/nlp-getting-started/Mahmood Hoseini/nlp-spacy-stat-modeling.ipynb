{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"#!python -m spacy download en_core_web_lg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nimport random\nimport seaborn\nimport re\nimport string\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom spacy.lang.en import English\nfrom sklearn import metrics\nfrom sklearn.base import TransformerMixin\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/nlp-getting-started/train.csv')\ntrain_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_url(txt):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',txt)\n\ntrain_df.text = train_df.text.apply(lambda x: remove_url(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_df.text.tolist(),\n                                                      train_df.target.tolist(),\n                                                      test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_lg')\nnlp.pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DATA = [('OMG! Earthquake in Tehran!', {'cats': {'POSITIVE': 1}}),\n              ('Has an accident changed your life?', {'cats': {'POSITIVE': 0}})]\n\ndef parse_train_data(docs, labels) :    \n    train_data = []\n    for doc, label in zip(docs, labels) :\n        S = {'cats': {'POSITIVE': label}}\n        train_data.append((doc.text, S))\n        \n    return train_data\n\ndocs = [doc for doc in nlp.pipe(X_train)]\ntrain_data = parse_train_data(docs, y_train)\n\nrandom.choices(train_data, k=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'textcat' not in nlp.pipe_names:\n    textcat = nlp.create_pipe(\"textcat\")\n    nlp.add_pipe(textcat, last=True) \nelse:\n    textcat = nlp.get_pipe(\"textcat\")\n\ntextcat.add_label('POSITIVE')\n\nnlp.pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fixed_pipes = [pipe for pipe in nlp.pipe_names if pipe!='textcat']\nfixed_pipes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## https://spacy.io/usage/training#textcat\nimport datetime as dt\nfrom spacy.util import minibatch, compounding\n\ndef evaluate(tokenizer, textcat, texts, cats):\n    docs = (tokenizer(text) for text in texts)\n    tp = 0.0  # True positives\n    fp = 1e-8  # False positives\n    fn = 1e-8  # False negatives\n    tn = 0.0  # True negatives\n    for ii, doc in enumerate(docs):\n        score, _ = textcat.predict([doc])\n        if score[0][0] >= 0.5 and cats[ii] == 1:\n            tp += 1.0\n        elif score[0][0] >= 0.5 and cats[ii] == 0:\n            fp += 1.0\n        elif score[0][0] < 0.5 and cats[ii] == 0:\n            tn += 1\n        elif score[0][0] < 0.5 and cats[ii] == 1:\n            fn += 1\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    if (precision + recall) == 0:\n        f_score = 0.0\n    else:\n        f_score = 2 * (precision * recall) / (precision + recall)\n    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n\n\n## Only train the textcat pipe\nprint(\"Loss \\t P\\t R\\t F1\")\nwith nlp.disable_pipes(*fixed_pipes):\n    optimizer = nlp.begin_training()\n    batch_sizes = compounding(128, 256, 512)\n    for itn in range(50) :\n        random.shuffle(train_data)\n        losses = {}\n        minibatches = minibatch(train_data, size=batch_sizes)\n        for batch in minibatches :\n            txts, annotations = zip(*batch)\n            nlp.update(txts, \n                       annotations, \n                       sgd=optimizer, \n                       drop=0.1,\n                       losses=losses)\n        with textcat.model.use_params(optimizer.averages):\n            # evaluate on the valid data split off in load_data()\n            scores = evaluate(nlp.tokenizer, textcat, X_valid, y_valid)\n        print(\"{0:.5f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(\n                    losses[\"textcat\"],\n                    scores[\"textcat_p\"],\n                    scores[\"textcat_r\"],\n                    scores[\"textcat_f\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print mislabelled examples\ndocs = [nlp.tokenizer(text) for text in X_valid]        \nfor ii in range(50):\n    score, _ = textcat.predict([docs[ii]])\n    if ((score[0][0] >= 0.5 and y_valid[ii] == 0) or\n        (score[0][0] < 0.5 and y_valid[ii] == 1)) :\n        print('pred: ' + str(score[0][0]) + \n              ', true: ' + str(y_valid[ii]) + \n               ' --> ', X_valid[ii] + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## 4\ntest_df = pd.read_csv('../input/nlp-getting-started/test.csv')\ntest_df.text = test_df.text.apply(lambda x: remove_url(x))\ntest_df['target'] = np.nan\n\nX_test = test_df.text.tolist()\ndocs = [nlp.tokenizer(text) for text in X_test]        \nfor ii, doc in enumerate(docs[:10]) :\n    score, _ = textcat.predict([docs[ii]])\n    test_df.target[ii] = (0 if score[0][0] < 0.5 else 1)\n\ntest_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\nsub_df.target = test_df.target\nsub_df.head()\nsub_df.to_csv(\"sub-spacy.csv\", index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}