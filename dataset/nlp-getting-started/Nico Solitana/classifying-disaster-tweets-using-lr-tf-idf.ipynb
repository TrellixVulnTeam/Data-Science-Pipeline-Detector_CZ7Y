{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install preprocessor\n!pip install tweet-preprocessor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-08T03:25:05.940642Z","iopub.execute_input":"2021-06-08T03:25:05.940958Z","iopub.status.idle":"2021-06-08T03:25:15.984469Z","shell.execute_reply.started":"2021-06-08T03:25:05.940933Z","shell.execute_reply":"2021-06-08T03:25:15.982845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:24.031301Z","iopub.execute_input":"2021-06-08T03:25:24.031643Z","iopub.status.idle":"2021-06-08T03:25:24.036529Z","shell.execute_reply.started":"2021-06-08T03:25:24.031597Z","shell.execute_reply":"2021-06-08T03:25:24.035193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Cleaning\nimport nltk\nfrom nltk.tokenize import TweetTokenizer\n\nimport preprocessor as tweet_preprocess\nimport re\nimport string\n\ndef download_necessary_functions():\n    global stopwords, wn, wcorp, tweet_tokenizer\n    stopwords = nltk.corpus.stopwords.words('english')\n    wn = nltk.WordNetLemmatizer()\n    wcorp = set(nltk.corpus.words.words())\n    tweet_preprocess.set_options(\n        tweet_preprocess.OPT.URL,\n        tweet_preprocess.OPT.MENTION,\n        tweet_preprocess.OPT.NUMBER)\n    tweet_tokenizer = TweetTokenizer()\n\ndef hashtag_segmentation(word):\n    if(word.startswith('#')):\n        word = word.replace('#', '')\n    word = re.sub('([A-Z][a-z]+)', r' \\1',\n                  re.sub('([A-Z]+)', r' \\1', word)).split()\n    return word\n\ndef remove_number(word):\n    res = any(map(str.isdigit, word))\n    if res:\n        return ''\n    else:\n        return word\n\ndef lemmatize_english_words(word):\n    if word in wcorp:\n        return wn.lemmatize(word)\n    else:\n        return word\n\ndef remove_short_words(word):\n    if len(word) > 3:\n        return word\n    \n    regex = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')\n    if(regex.search(word) != None):\n        return word\n    return ''\n\ndef split_by_dot(word):\n    return word.split(\".\")\n\ndef clean_text(text):\n    text = tweet_preprocess.clean(text)\n    tokens = np.array(tweet_tokenizer.tokenize(text))\n    tokens = [hashtag_segmentation(word) for word in tokens]\n    tokens = np.hstack(np.array(tokens, dtype=object))\n    tokens = [split_by_dot(word) for word in tokens]\n    tokens = np.hstack(np.array(tokens, dtype=object))\n    tokens = [remove_number(word) for word in tokens]\n    tokens = [lemmatize_english_words(word) for word in tokens]\n    tokens = [remove_short_words(word) for word in tokens]\n    tokens = [word for word in tokens if word not in stopwords]\n    tokens = [word for word in tokens if word not in string.punctuation]\n    tokens = [word for word in tokens if not(word.isdigit())]\n    tokens = list(filter(None, tokens))\n    return list(map(str.lower, tokens))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:26.686103Z","iopub.execute_input":"2021-06-08T03:25:26.686378Z","iopub.status.idle":"2021-06-08T03:25:26.697984Z","shell.execute_reply.started":"2021-06-08T03:25:26.686354Z","shell.execute_reply":"2021-06-08T03:25:26.697422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training & Testing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, multilabel_confusion_matrix, accuracy_score\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.multiclass import OneVsRestClassifier\nimport scikitplot as skplt\n\ndef set_train_test(xtrain, xtest, ytrain, ytest):\n    global X_train, X_test, y_train, y_test\n    X_train = xtrain\n    X_test = xtest\n    y_train = ytrain\n    y_test = ytest\n\n\ndef train_test_model(classifier):\n    global y_pred\n    k_fold = KFold(n_splits=5)\n    cls = classifier()\n    print(cross_val_score(cls, X_train, y_train,\n                          cv=k_fold, scoring='accuracy', n_jobs=-1))\n\n    model = cls.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    return model\n\n\ndef get_model_performance():\n    accuracy = round((y_pred == y_test).sum()/len(y_pred), 3)\n    cf_matrix = confusion_matrix(y_test, y_pred)\n    precision = round(precision_score(\n        y_test, y_pred, pos_label=0, average='binary'), 3)\n    recall = round(recall_score(\n        y_test, y_pred, pos_label=0, average='binary'), 3)\n    return accuracy, cf_matrix, precision, recall","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:30.863668Z","iopub.execute_input":"2021-06-08T03:25:30.864127Z","iopub.status.idle":"2021-06-08T03:25:30.871929Z","shell.execute_reply.started":"2021-06-08T03:25:30.864088Z","shell.execute_reply":"2021-06-08T03:25:30.871019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converts tokens into vectors\ndef convert_to_tfidf_vector(df):\n    tfidf_vec = TfidfVectorizer(analyzer=clean_text)\n    xtfidf_fit = tfidf_vec.fit(df['merge'])\n    xtfidf = xtfidf_fit.fit_transform(df['merge'])\n    X = pd.DataFrame(xtfidf.toarray())\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:33.915192Z","iopub.execute_input":"2021-06-08T03:25:33.915653Z","iopub.status.idle":"2021-06-08T03:25:33.921181Z","shell.execute_reply.started":"2021-06-08T03:25:33.915595Z","shell.execute_reply":"2021-06-08T03:25:33.91965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Dataset\ntrain = pd.read_csv('../input/nlp-getting-started/train.csv', \n                   encoding='latin-1')\ntest = pd.read_csv('../input/nlp-getting-started/test.csv', \n                   encoding='latin-1')\n\n# Drop unnecessary columns/features\ntrain.drop (columns = ['keyword'], inplace = True)\n\n# Drop unnecessary columns/features\ntest.drop (columns = ['keyword'], inplace = True)\n\ndata = train.append(test, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:36.16984Z","iopub.execute_input":"2021-06-08T03:25:36.170137Z","iopub.status.idle":"2021-06-08T03:25:36.216362Z","shell.execute_reply.started":"2021-06-08T03:25:36.170113Z","shell.execute_reply":"2021-06-08T03:25:36.214911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Engineering using TF-IDF\ndownload_necessary_functions()\ndata['merge'] = data['text'] \nX_data = convert_to_tfidf_vector(data)\ndata_vec = pd.DataFrame(X_data)\ndata_vec['target'] = data['target'] \n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:39.302289Z","iopub.execute_input":"2021-06-08T03:25:39.302701Z","iopub.status.idle":"2021-06-08T03:25:50.220143Z","shell.execute_reply.started":"2021-06-08T03:25:39.302667Z","shell.execute_reply":"2021-06-08T03:25:50.219577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separating training data\ntrain_vec = data_vec\ntrain_vec = train_vec[train_vec['target'].notna()]\nX_train_vec = train_vec.copy()\nX_train_vec.drop (columns = ['target'], inplace = True)\nX_train_vec","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:57.626561Z","iopub.execute_input":"2021-06-08T03:25:57.627008Z","iopub.status.idle":"2021-06-08T03:25:59.561278Z","shell.execute_reply.started":"2021-06-08T03:25:57.626982Z","shell.execute_reply":"2021-06-08T03:25:59.559867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Divide training data into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X_train_vec, train_vec['target'], test_size=0.2)\n\n# Handle Data imbalance using SMOTE Tomek\nfrom imblearn.combine import SMOTETomek\nSMOTE = SMOTETomek(random_state=139)\nX_train, y_train = SMOTE.fit_resample(X_train, y_train)\nX_test, y_test = SMOTE.fit_resample(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:26:03.713775Z","iopub.execute_input":"2021-06-08T03:26:03.714154Z","iopub.status.idle":"2021-06-08T03:26:26.084067Z","shell.execute_reply.started":"2021-06-08T03:26:03.714122Z","shell.execute_reply":"2021-06-08T03:26:26.08278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOGISTIC REGRESSION\n# Model Building, Cross Validation and Prediction\nset_train_test(X_train, X_test, y_train, y_test)\nmodel = train_test_model(lambda: LogisticRegression(solver='lbfgs',max_iter=500))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:02.964349Z","iopub.status.idle":"2021-06-08T03:25:02.964857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Model Performance\naccuracy, cf_matrix, precision, recall = get_model_performance()\nprint('Accuracy: {} Precision: {} Recall: {}'.format(accuracy, precision, recall))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:02.965937Z","iopub.status.idle":"2021-06-08T03:25:02.966419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict data based on test data\ntest_vec = data_vec\ntest_vec = test_vec[test_vec['target'].isna()]\nX_test_vec = test_vec.copy()\nX_test_vec.drop (columns = ['target'], inplace = True)\nX_test_vec\n\ny_test_pred = model.predict(X_test_vec)\ntmp = data[data['target'].isna()]\ntest_res = pd.DataFrame(tmp['id'], columns=['id'])\ntest_res['target'] = y_test_pred\ntest_res.to_csv(r'./Submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:25:02.967349Z","iopub.status.idle":"2021-06-08T03:25:02.967849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef IsDataBalance(ydata, title):\n    arr = []\n    arr.append([len(ydata[ydata['target'] == 0]), 0])\n    arr.append([len(ydata[ydata['target'] == 1]), 1])\n    df = pd.DataFrame(arr, columns=['count', 'target'])\n    \n    sns.barplot(x = 'target',\n                y = 'count',\n                data = df, \n                palette='YlGn').set(title=title)\n    plt.show()\n    \ndef make_confusion_matrix(cf_matrix):\n    labels = ['True Negative','False Positive','False Negative','True Positive']\n    categories = ['0', '1']\n    group_names = labels\n    group_counts = [\"{0:0.0f}\".format(value) for value in\n                    cf_matrix.flatten()]\n    group_percentages = [\"{0:.2%}\".format(value) for value in\n                        cf_matrix.flatten()/np.sum(cf_matrix)]\n    categories = categories\n    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n            zip(group_names,group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n    ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='YlGn') \n    ax.set_xticklabels(categories) \n    ax.set_yticklabels(categories)\n    ax.set(ylabel=\"True\", xlabel=\"Predicted\")\n    ax.set(title=\"Consfusion Matrix\")\n    \nmake_confusion_matrix(cf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:40:15.798075Z","iopub.execute_input":"2021-06-08T03:40:15.798378Z","iopub.status.idle":"2021-06-08T03:40:16.006162Z","shell.execute_reply.started":"2021-06-08T03:40:15.798352Z","shell.execute_reply":"2021-06-08T03:40:16.00411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ydata = pd.DataFrame(y_train, columns=['target'])\nIsDataBalance(ydata, \"Training Data\")\n\nydata = pd.DataFrame(y_test, columns=['target'])\nIsDataBalance(ydata, \"Testing Data\")","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:40:22.266521Z","iopub.execute_input":"2021-06-08T03:40:22.266834Z","iopub.status.idle":"2021-06-08T03:40:22.45311Z","shell.execute_reply.started":"2021-06-08T03:40:22.266809Z","shell.execute_reply":"2021-06-08T03:40:22.452189Z"},"trusted":true},"execution_count":null,"outputs":[]}]}