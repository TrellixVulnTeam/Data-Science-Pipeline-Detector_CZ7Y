{"cells":[{"metadata":{"id":"LWFFLdrJZbNq","colab_type":"code","outputId":"631e58d3-492a-4e0d-8faa-a9ba268d56ac","colab":{"base_uri":"https://localhost:8080/","height":104},"trusted":true},"cell_type":"code","source":"! pip install transformers -q","execution_count":null,"outputs":[]},{"metadata":{"id":"9W8iuy5iZbN0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import csv\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.cm as cm\nfrom fastai import *\nfrom fastai.text import *\nfrom fastai.callbacks import *\nfrom fastai.metrics import *\nimport numpy as np\nimport pandas as pd\n\nfrom pathlib import Path\nfrom typing import *\n\nimport torch\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"id":"bDcJAbWQmWmW","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"seed = 42\n\nimport random\nrandom.seed(seed)\n\nimport torch\ntorch.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\nif torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n\nimport numpy as np\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"id":"17X4qG7RZbN-","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class Config(dict):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n    \n    def set(self, key, val):\n        self[key] = val\n        setattr(self, key, val)\n\n\nconfig = Config(\n    testing=False,\n    model_name=\"bert-base-cased\",\n    max_lr=3e-5,\n    epochs=4,\n    use_fp16=True,\n    bs=64,\n    discriminative=False,\n    max_seq_len=64,\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"8TBbnX8TZbOF","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer\ntok = BertTokenizer.from_pretrained(config.model_name,)","execution_count":null,"outputs":[]},{"metadata":{"id":"6H6CsnEeZbOL","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class FastAiTokenizer(BaseTokenizer):\n    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n        self._pretrained_tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n\n    def __call__(self, *args, **kwargs):\n        return self\n\n    def tokenizer(self, t:str) -> List[str]:\n        \"\"\"Limits the maximum sequence length\"\"\"\n        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"qUnzuTauZbOQ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"fastai_tokenizer = Tokenizer(tok_func=FastAiTokenizer(tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])","execution_count":null,"outputs":[]},{"metadata":{"id":"WbNGhNSrZbOU","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"fastai_vocab = Vocab(list(tok.vocab.keys()))","execution_count":null,"outputs":[]},{"metadata":{"id":"TegWEXryZbOY","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import TweetTokenizer\ntwt = TweetTokenizer(strip_handles=True)\ndef tweets(r):\n    s = ' '.join(twt.tokenize(r['text']))\n    s = re.sub(r'http\\S+', '', s)\n    s = re.sub(r'https\\S+', '', s)    \n    return s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ptext'] = train.apply(tweets, axis=1)\ntest['ptext'] = test.apply(tweets, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"SLBkrbyeZbOp","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"label_cols = list(set(train['target']))","execution_count":null,"outputs":[]},{"metadata":{"id":"c_Le382SZbO3","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class AutoTokenizeProcessor(TokenizeProcessor):\n    def __init__(self, tokenizer):\n        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n\nclass AutoNumericalizeProcessor(NumericalizeProcessor):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n\ndef get_auto_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n    \"\"\"\n    Constructing preprocessors for BERT\n    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n    We also use a custom vocabulary to match the numericalization with the original BERT model.\n    \"\"\"\n    return [AutoTokenizeProcessor(tokenizer=tokenizer),\n            NumericalizeProcessor(vocab=vocab)]","execution_count":null,"outputs":[]},{"metadata":{"id":"gCtPGe-rZbO7","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class AutoDataBunch(TextDataBunch):\n    @classmethod\n    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n                label_cols:IntsOrStrs=0, label_delim:str=None, **kwargs) -> DataBunch:\n        \"Create a `TextDataBunch` from DataFrames.\"\n        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_auto_processor)\n        # use our custom processors while taking tokenizer and vocab as kwargs\n        processor = get_auto_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n        if classes is None and is_listy(label_cols) and len(label_cols) > 1: \n          classes = label_cols\n        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor), TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n\n        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n\n        if test_df is not None: \n          src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n        return src.databunch(**kwargs)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ib4nSNu-ZbO0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val = train_test_split(train,test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"id":"9G_vYAPiZbPA","colab_type":"code","outputId":"8835fb25-e962-4e23-8f3f-cb4723286c46","colab":{"base_uri":"https://localhost:8080/","height":17},"trusted":true},"cell_type":"code","source":"databunch = AutoDataBunch.from_df(\".\", \n                    train_df = X_train, \n                    valid_df = X_val,\n                    test_df = test,\n                  tokenizer=fastai_tokenizer,\n                  vocab=fastai_vocab,\n                  text_cols=\"ptext\",\n                  label_cols='target',\n                  bs=config.bs,\n                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n             )\n","execution_count":null,"outputs":[]},{"metadata":{"id":"3ktiH4R5aO1Z","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import torch\ndef softmax(v):\n  e = torch.exp(v)\n  s = torch.sum(e, dim=0)\n  return e/s","execution_count":null,"outputs":[]},{"metadata":{"id":"clagBsqyY4qX","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from transformers import BertPreTrainedModel, BertModel\nclass BertForSequenceClassification(BertPreTrainedModel):\n    r\"\"\"\n        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n            Labels for computing the sequence classification/regression loss.\n            Indices should be in ``[0, ..., config.num_labels - 1]``.\n            If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n\n    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n            Classification (or regression if config.num_labels==1) loss.\n        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n            of shape ``(batch_size, sequence_length, hidden_size)``:\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n\n    Examples::\n\n        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids, labels=labels)\n        loss, logits = outputs[:2]\n\n    \"\"\"\n    def __init__(self, config):\n        super(BertForSequenceClassification, self).__init__(config)\n        self.num_labels = config.num_labels\n\n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n\n        self.init_weights()\n\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n                position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n\n        outputs = self.bert(input_ids,\n                            attention_mask=attention_mask,\n                            token_type_ids=token_type_ids,\n                            position_ids=position_ids,\n                            head_mask=head_mask,\n                            inputs_embeds=inputs_embeds)\n\n        pooled_output = outputs[1]\n\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n\n        if labels is not None:\n            if self.num_labels == 1:\n                #  We are doing regression\n                loss_fct = MSELoss()\n                loss = loss_fct(logits.view(-1), labels.view(-1))\n            else:\n                loss_fct = CrossEntropyLoss()\n                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n            outputs = (loss,) + outputs\n\n        return softmax(outputs[0])  # (loss), logits, (hidden_states), (attentions)","execution_count":null,"outputs":[]},{"metadata":{"id":"ISQ4dFvoZbPD","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"auto_model = BertForSequenceClassification.from_pretrained(config.model_name, num_labels=len(set(train['target'])))","execution_count":null,"outputs":[]},{"metadata":{"id":"f1gKmMQzZbPI","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"learner = Learner(\n    databunch, auto_model,\n    metrics=[accuracy,error_rate]\n)\nlearner.callbacks.append(ShowGraph(learner))","execution_count":null,"outputs":[]},{"metadata":{"id":"sbB2BbU7ZbPL","colab_type":"code","outputId":"93573320-5d8e-4b24-d29f-69f4145bb7f4","colab":{"base_uri":"https://localhost:8080/","height":335},"trusted":true},"cell_type":"code","source":"learner.lr_find()\nlearner.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"BB4_UT-oZbPR","colab_type":"code","outputId":"a3718e80-6103-4cdb-de2b-330a4becaacb","colab":{"base_uri":"https://localhost:8080/","height":360},"trusted":true},"cell_type":"code","source":"learner.fit_one_cycle(2, slice(1e-4))","execution_count":null,"outputs":[]},{"metadata":{"id":"YUzdLQQtktsz","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"learner.save('bert')","execution_count":null,"outputs":[]},{"metadata":{"id":"GHgpUNscdefn","colab_type":"code","outputId":"35f8e259-798d-4559-d621-20f6d6514560","colab":{"base_uri":"https://localhost:8080/","height":331},"trusted":true},"cell_type":"code","source":"learner.unfreeze()\nlearner.lr_find()\nlearner.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"jODwUsg5eE0G","colab_type":"code","outputId":"53f408b3-8984-4726-d065-380246b400a3","colab":{"base_uri":"https://localhost:8080/","height":360},"trusted":true},"cell_type":"code","source":"learner.fit_one_cycle(3, slice(1e-6))","execution_count":null,"outputs":[]},{"metadata":{"id":"sodVaTITgoji","colab_type":"code","outputId":"7509f509-744a-4d0e-8583-a31ee15c5a77","colab":{"base_uri":"https://localhost:8080/","height":458},"trusted":false},"cell_type":"code","source":"# learner.fit_one_cycle(5, slice(5e-8))","execution_count":0,"outputs":[]},{"metadata":{"id":"T6VtunhLMtSO","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"# learner.load('model')","execution_count":0,"outputs":[]},{"metadata":{"id":"m9GIUD4XZbPV","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_preds_as_nparray(ds_type) -> np.ndarray:\n    \"\"\"\n    the get_preds method does not yield the elements in order by default\n    we borrow the code from the RNNLearner to resort the elements into their correct order\n    \"\"\"\n    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n    sampler = [i for i in databunch.dl(ds_type).sampler]\n    reverse_sampler = np.argsort(sampler)\n    return preds[reverse_sampler, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_preds = get_preds_as_nparray(DatasetType.Valid)","execution_count":null,"outputs":[]},{"metadata":{"id":"hF_3siguZbPZ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"test_preds = get_preds_as_nparray(DatasetType.Test)\npreds = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vpreds = []\nfor i in val_preds:\n    vpreds.append(np.argmax(i))","execution_count":null,"outputs":[]},{"metadata":{"id":"58bN129IZbPh","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"for i in test_preds:\n    preds.append(np.argmax(i))","execution_count":null,"outputs":[]},{"metadata":{"id":"QuHDNVFijRVS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, f1_score , recall_score, precision_score","execution_count":null,"outputs":[]},{"metadata":{"id":"M_Xx8CXoZbP7","colab_type":"code","outputId":"4d212337-3b4a-4c7e-f0d3-110d7c118682","colab":{"base_uri":"https://localhost:8080/","height":173},"trusted":true},"cell_type":"code","source":"print(classification_report(X_val['target'], vpreds))","execution_count":null,"outputs":[]},{"metadata":{"id":"fm062izrlH71","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsub.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds\nsub.to_csv('submission.csv', index=False)\nsub.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"BERT_fastai.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}