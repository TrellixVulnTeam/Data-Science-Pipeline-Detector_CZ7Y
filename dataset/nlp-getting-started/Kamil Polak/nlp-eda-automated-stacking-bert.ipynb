{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook wouldn't have been possible without these resources. Most of the solutions used in this notebooks are taken from the below mentioned resources, combining everything into one\n\n*     https://www.kaggle.com/vbmokin/nlp-eda-bag-of-words-tf-idf-glove-bert\n*     https://www.kaggle.com/ratan123/start-from-here-disaster-tweets-eda-basic-model\n*     https://www.kaggle.com/shahules/basic-eda-cleaning-and-glove\n*     https://www.kaggle.com/szelee/simpletransformers-hyperparam-tuning-k-fold-cv\n*     https://www.kaggle.com/basu369victor/learning-bert-for-the-first-time\n*     https://www.kaggle.com/slatawa/tfidf-implementation-to-get-80-accuracy\n*     https://www.kaggle.com/user123454321/bert-starter-inference\n*     https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n"},{"metadata":{},"cell_type":"markdown","source":"Table of content\n\n1. Import libraries\n2. Download data\n3. EDA\n4. Data Cleaning\n5. Baseline models\n6. Automated stacking\n7. BERT\n"},{"metadata":{},"cell_type":"markdown","source":"**1. Import libraries**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport pandas as pd\nimport numpy as np\nimport os\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\nfrom plotly import tools\nimport plotly.offline as py\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\n\nfrom wordcloud import WordCloud\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.metrics import classification_report,confusion_matrix, f1_score\n\nfrom collections import defaultdict\nfrom collections import Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\n\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\n\nfrom tqdm import tqdm\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\nfrom keras.optimizers import Adam\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Download data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsub = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the size of the train and test datasets.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} rows and {} columns in train'.format(train.shape[0],train.shape[1]))\nprint('There are {} rows and {} columns in test'.format(test.shape[0],test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nColumns\n\n*     id - a unique identifier for each tweet\n*     text - the text of the tweet\n*     location - the location the tweet was sent from (may be blank)\n*     keyword - a particular keyword from the tweet (may be blank)\n*     target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)\n\n"},{"metadata":{},"cell_type":"markdown","source":"**3. EDA**\n"},{"metadata":{},"cell_type":"markdown","source":"3.1 Class distribution\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train.target.value_counts()\nsns.barplot(x.index,x)\nplt.gca().set_ylabel('Number of samples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.2 Number of characters in tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train[train['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster tweets')\ntweet_len=train[train['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Characters in tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.3 Number of words in a tweet\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train[train['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster tweets')\ntweet_len=train[train['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Words in a tweet')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.4 Average word length in a tweet\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword=train[train['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\nax1.set_title('disaster')\nword=train[train['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\nax2.set_title('Not disaster')\nfig.suptitle('Average word length in each tweet')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.5 Number of tweets in dataset according to location\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_ = train['location'].value_counts()\ncnt_.reset_index()\ncnt_ = cnt_[:20,]\ntrace1 = go.Bar(\n                x = cnt_.index,\n                y = cnt_.values,\n                name = \"Number of tweets in dataset according to location\",\n                marker = dict(color = 'rgba(200, 74, 55, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                )\n\ndata = [trace1]\nlayout = go.Layout(barmode = \"group\",title = 'Number of tweets depending on location')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.6 Number of tweets depending on location per class\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train1_df = train[train[\"target\"]==1]\ntrain0_df = train[train[\"target\"]==0]\ncnt_1 = train1_df['location'].value_counts()\ncnt_1.reset_index()\ncnt_1 = cnt_1[:20,]\n\ncnt_0 = train0_df['location'].value_counts()\ncnt_0.reset_index()\ncnt_0 = cnt_0[:20,]\n\ntrace1 = go.Bar(\n                x = cnt_1.index,\n                y = cnt_1.values,\n                name = \"Number of real disaster tweets\",\n                marker = dict(color = 'rgba(255, 74, 55, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                )\ntrace0 = go.Bar(\n                x = cnt_0.index,\n                y = cnt_0.values,\n                name = \"Number of unreal disaster tweets\",\n                marker = dict(color = 'rgba(79, 82, 97, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                )\n\n\ndata = [trace0,trace1]\nlayout = go.Layout(barmode = 'stack',title = 'Number of tweets depending on location per class')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.7 WordCloud\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train[train[\"target\"]==1], title=\"Word Cloud of real disaster tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_wordcloud(train[train[\"target\"]==0], title=\"Word Cloud of unreal disaster tweets\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.8 Common stopwords\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_corpus(target):\n    corpus=[]\n    \n    for x in train[train['target']==target]['text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CLass 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus=create_corpus(0)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n        \ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10]\n\n\n\nplt.rcParams['figure.figsize'] = (18.0, 6.0)\nx,y=zip(*top)\nplt.bar(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Class 1"},{"metadata":{},"cell_type":"markdown","source":"**4. Data cleaning**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    import re\n    text = text.lower()\n    text = re.sub(r\"i'm\", \"i am\", text)\n    text = re.sub(r\"you'll\", \"you will\", text)\n    text = re.sub(r\"i'll\", \"i will\", text)\n    text = re.sub(r\"she'll\", \"she will\", text)\n    text = re.sub(r\"he'll\", \"he will\", text)\n    text = re.sub(r\"he's\", \"he is\", text)\n    text = re.sub(r\"she's\", \"she is\", text)\n    text = re.sub(r\"that's\", \"that is\", text)\n    text = re.sub(r\"what's\", \"what is\", text)\n    text = re.sub(r\"where's\", \"where is\", text)\n    text = re.sub(r\"there's\", \"there is\", text)\n    text = re.sub(r\"here's\", \"here is\", text)\n    text = re.sub(r\"who's\", \"who is\", text)\n    text = re.sub(r\"how's\", \"how is\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"can't\", \"cannot\", text)\n    text = re.sub(r\"won't\", \"will not\", text)\n    text = re.sub(r\"don't\", \"do not\", text)\n    text = re.sub(r\"shouldn't\", \"should not\", text)\n    text = re.sub(r\"n't\", \" not\", text)\n    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n    return text\n\n\ntrain['clean_text'] = train['text'].apply(clean_text)\ntest['clean_text'] = test['text'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def massage_text(text):\n    import re\n    from nltk.corpus import stopwords\n    ## remove anything other then characters and put everything in lowercase\n    tweet = re.sub(\"[^a-zA-Z]\", ' ', text)\n    tweet = tweet.lower()\n    tweet = tweet.split()\n\n    from nltk.stem import WordNetLemmatizer\n    lem = WordNetLemmatizer()\n    tweet = [lem.lemmatize(word) for word in tweet\n             if word not in set(stopwords.words('english'))]\n    tweet = ' '.join(tweet)\n    return tweet\n    print('--here goes nothing')\n    print(text)\n    print(tweet)\n\ntrain['clean_text'] = train['text'].apply(massage_text)\ntest['clean_text'] = test['text'].apply(massage_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preview of cleaned text\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.iloc[0:10][['text','clean_text']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. Baseline models**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nX_train,X_test,y_train,y_test = train_test_split(train['clean_text'],train['target'])\n\ntfidf = TfidfVectorizer()\n\ntrain_vector = tfidf.fit_transform(X_train)\ntest_vector = tfidf.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = (xgb.XGBClassifier(random_state = 1),\n         RandomForestClassifier(random_state = 1),\n         GradientBoostingClassifier(random_state = 1),\n         lgb.LGBMClassifier(random_state = 1),\n         LogisticRegression(random_state = 1))\n\nfor model in models:\n    model.fit(train_vector, y_train)\n    predict = model.predict(test_vector)\n    print(f1_score(y_test,predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6. Automated stacking**"},{"metadata":{},"cell_type":"markdown","source":"In order to automate stacking I'll use vecstack package."},{"metadata":{"trusted":true},"cell_type":"code","source":"from vecstack import stacking\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S_train, S_test = stacking(models,                   \n                           train_vector, y_train, test_vector,   \n                           regression=False, \n     \n                           mode='oof_pred_bag', \n       \n                           needs_proba=False,\n         \n                           save_dir=None, \n            \n                           metric=f1_score, \n    \n                           n_folds=4, \n                 \n                           stratified=True,\n            \n                           shuffle=True,  \n            \n                           random_state=0,    \n         \n                           verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=0)\n    \nmodel = model.fit(S_train, y_train)\n\ny_pred = model.predict(S_test)\n\nprint(f1_score(y_test,predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F1 score is 74%, not bad, but I will try to use BERT model."},{"metadata":{},"cell_type":"markdown","source":"**7. BERT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use the official tokenization script created by the Google team\n!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_hub as hub\n\nimport tokenization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def build_model(bert_layer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(clf_output)\n    \n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load and Preprocess\n\n- Load BERT from the Tensorflow Hub\n- Load CSV files containing training data\n- Load tokenizer from the bert layer\n- Encode the text into tokens, masks, and segment flags"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodule_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\nbert_layer = hub.KerasLayer(module_url, trainable=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_input = bert_encode(train.text.values, tokenizer, max_len=160)\ntest_input = bert_encode(test.text.values, tokenizer, max_len=160)\ntrain_labels = train.target.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model: Build, Train, Predict, Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(bert_layer, max_len=160)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n\ntrain_history = model.fit(\n    train_input, train_labels,\n    validation_split=0.2,\n    epochs=3,\n    callbacks=[checkpoint],\n    batch_size=16\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model.h5')\ntest_pred = model.predict(test_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target'] = test_pred.round().astype(int)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If you like this kernel, please upvote.**\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}