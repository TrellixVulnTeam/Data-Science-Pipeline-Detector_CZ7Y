{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h2 style='color:red'>NLP: The Simplest Way<br><span>By Kassem@elcaiseri</span></h2></center>\n<h3>NLP with Disaster Tweets (NLTK + Sklearn)</h3>\n* **1. Introduction**\n* **2. Data Preparation**\n* **3. Text Processing**\n* **4. Machine learning**\n* **5. Evaluate the model**\n* **5. Prediction and Submition**\n* **6. References**\n<hr>\n\n* Update: using **word_tokenize()** rather than **text.split()**","metadata":{}},{"cell_type":"markdown","source":"# 1. Introduction\nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency theyâ€™re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).<br>\n**Goal** .. Predict which Tweets are about real disasters and which ones are not","metadata":{}},{"cell_type":"markdown","source":"# 2. Data preparation","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-10-03T15:35:13.689736Z","iopub.execute_input":"2021-10-03T15:35:13.690128Z","iopub.status.idle":"2021-10-03T15:35:14.413823Z","shell.execute_reply.started":"2021-10-03T15:35:13.690069Z","shell.execute_reply":"2021-10-03T15:35:14.412828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-10-03T15:35:14.416168Z","iopub.execute_input":"2021-10-03T15:35:14.416477Z","iopub.status.idle":"2021-10-03T15:35:14.424227Z","shell.execute_reply.started":"2021-10-03T15:35:14.416415Z","shell.execute_reply":"2021-10-03T15:35:14.42307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE = \"/kaggle/input/nlp-getting-started/\"\ntrain = pd.read_csv(BASE + \"train.csv\")\ntest = pd.read_csv(BASE + \"test.csv\")\nsub = pd.read_csv(BASE + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:14.426483Z","iopub.execute_input":"2021-10-03T15:35:14.426854Z","iopub.status.idle":"2021-10-03T15:35:14.50326Z","shell.execute_reply.started":"2021-10-03T15:35:14.426799Z","shell.execute_reply":"2021-10-03T15:35:14.502194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets = train[['text', 'target']]\ntweets.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:14.504607Z","iopub.execute_input":"2021-10-03T15:35:14.504955Z","iopub.status.idle":"2021-10-03T15:35:14.538062Z","shell.execute_reply.started":"2021-10-03T15:35:14.504881Z","shell.execute_reply":"2021-10-03T15:35:14.537044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:14.541062Z","iopub.execute_input":"2021-10-03T15:35:14.541501Z","iopub.status.idle":"2021-10-03T15:35:14.550322Z","shell.execute_reply.started":"2021-10-03T15:35:14.541445Z","shell.execute_reply":"2021-10-03T15:35:14.549469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:14.55241Z","iopub.execute_input":"2021-10-03T15:35:14.552917Z","iopub.status.idle":"2021-10-03T15:35:14.56307Z","shell.execute_reply.started":"2021-10-03T15:35:14.552797Z","shell.execute_reply":"2021-10-03T15:35:14.562213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Text Processing\n","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:14.565347Z","iopub.execute_input":"2021-10-03T15:35:14.565873Z","iopub.status.idle":"2021-10-03T15:35:17.520496Z","shell.execute_reply.started":"2021-10-03T15:35:14.565811Z","shell.execute_reply":"2021-10-03T15:35:17.519581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove Punctuation","metadata":{}},{"cell_type":"code","source":"def remove_punctuation(text):\n    '''a function for removing punctuation'''\n    import string\n    # replacing the punctuations with no space, \n    # which in effect deletes the punctuation marks \n    translator = str.maketrans('', '', string.punctuation)\n    # return the text stripped of punctuation marks\n    return text.translate(translator)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:17.521974Z","iopub.execute_input":"2021-10-03T15:35:17.522474Z","iopub.status.idle":"2021-10-03T15:35:17.538326Z","shell.execute_reply.started":"2021-10-03T15:35:17.522429Z","shell.execute_reply":"2021-10-03T15:35:17.536989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets['text'] = tweets['text'].apply(remove_punctuation)\ntweets.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:17.540021Z","iopub.execute_input":"2021-10-03T15:35:17.540321Z","iopub.status.idle":"2021-10-03T15:35:17.621794Z","shell.execute_reply.started":"2021-10-03T15:35:17.540266Z","shell.execute_reply":"2021-10-03T15:35:17.620853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove Stopwords","metadata":{}},{"cell_type":"code","source":"# extracting the stopwords from nltk library\nsw = stopwords.words('english')\n# displaying the stopwords\nnp.array(sw);","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:17.623318Z","iopub.execute_input":"2021-10-03T15:35:17.623843Z","iopub.status.idle":"2021-10-03T15:35:17.637342Z","shell.execute_reply.started":"2021-10-03T15:35:17.623784Z","shell.execute_reply":"2021-10-03T15:35:17.636473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stopwords(text):\n    '''a function for removing the stopword'''\n    # removing the stop words and lowercasing the selected words\n    text = [word.lower() for word in word_tokenize(text) if word.lower() not in sw]\n    # joining the list of words with space separator\n    return \" \".join(text)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:17.638865Z","iopub.execute_input":"2021-10-03T15:35:17.639188Z","iopub.status.idle":"2021-10-03T15:35:17.644953Z","shell.execute_reply.started":"2021-10-03T15:35:17.639086Z","shell.execute_reply":"2021-10-03T15:35:17.643917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets['text'] = tweets['text'].apply(stopwords)\ntweets.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:17.646007Z","iopub.execute_input":"2021-10-03T15:35:17.646319Z","iopub.status.idle":"2021-10-03T15:35:19.865183Z","shell.execute_reply.started":"2021-10-03T15:35:17.646275Z","shell.execute_reply":"2021-10-03T15:35:19.864164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stemming operations\nStemming operation bundles together words of same root. E.g. stem operation bundles \"response\" and \"respond\" into a common \"respon","metadata":{}},{"cell_type":"code","source":"# create an object of stemming function\nstemmer = PorterStemmer()\n\ndef stemming(text):    \n    '''a function which stems each word in the given text'''\n    text = [stemmer.stem(word) for word in word_tokenize(text)]\n    return \" \".join(text) ","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:19.866502Z","iopub.execute_input":"2021-10-03T15:35:19.866815Z","iopub.status.idle":"2021-10-03T15:35:19.872066Z","shell.execute_reply.started":"2021-10-03T15:35:19.866767Z","shell.execute_reply":"2021-10-03T15:35:19.871071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets['text'] = tweets['text'].apply(stemming)\ntweets.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:19.873648Z","iopub.execute_input":"2021-10-03T15:35:19.874Z","iopub.status.idle":"2021-10-03T15:35:24.039883Z","shell.execute_reply.started":"2021-10-03T15:35:19.873947Z","shell.execute_reply":"2021-10-03T15:35:24.038993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer(analyzer='word', binary=True, stop_words='english')\nvectorizer.fit(tweets['text'])","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:38:13.011939Z","iopub.execute_input":"2021-10-03T15:38:13.012254Z","iopub.status.idle":"2021-10-03T15:38:13.239016Z","shell.execute_reply.started":"2021-10-03T15:38:13.012205Z","shell.execute_reply":"2021-10-03T15:38:13.238325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = vectorizer.transform(tweets['text']).todense()\ny = tweets['target'].values\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:38:13.662687Z","iopub.execute_input":"2021-10-03T15:38:13.663025Z","iopub.status.idle":"2021-10-03T15:38:14.011085Z","shell.execute_reply.started":"2021-10-03T15:38:13.662975Z","shell.execute_reply":"2021-10-03T15:38:14.010232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Machine learning","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:40:11.7936Z","iopub.execute_input":"2021-10-03T15:40:11.793923Z","iopub.status.idle":"2021-10-03T15:40:11.799314Z","shell.execute_reply.started":"2021-10-03T15:40:11.79388Z","shell.execute_reply":"2021-10-03T15:40:11.797822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:40:11.95036Z","iopub.execute_input":"2021-10-03T15:40:11.950922Z","iopub.status.idle":"2021-10-03T15:40:12.466145Z","shell.execute_reply.started":"2021-10-03T15:40:11.95087Z","shell.execute_reply":"2021-10-03T15:40:12.464896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LogisticRegression(C=1.0, random_state=111)\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:40:12.468373Z","iopub.execute_input":"2021-10-03T15:40:12.468764Z","iopub.status.idle":"2021-10-03T15:40:13.341091Z","shell.execute_reply.started":"2021-10-03T15:40:12.468666Z","shell.execute_reply":"2021-10-03T15:40:13.33977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Evaluate the model","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)\n\nf1score = f1_score(y_test, y_pred)\nprint(f\"Model Score: {f1score * 100:.2f} %\")","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:40:13.343521Z","iopub.execute_input":"2021-10-03T15:40:13.344179Z","iopub.status.idle":"2021-10-03T15:40:13.516859Z","shell.execute_reply.started":"2021-10-03T15:40:13.344116Z","shell.execute_reply":"2021-10-03T15:40:13.514139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see score imporved from 75% in last version to 77% with simple preprocessing change.","metadata":{}},{"cell_type":"markdown","source":"# 5. Prediction and Submition","metadata":{}},{"cell_type":"code","source":"tweets_test = test['text']\ntest_X = vectorizer.transform(tweets_test).todense()\ntest_X.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:26.542413Z","iopub.execute_input":"2021-10-03T15:35:26.542797Z","iopub.status.idle":"2021-10-03T15:35:26.729201Z","shell.execute_reply.started":"2021-10-03T15:35:26.542741Z","shell.execute_reply":"2021-10-03T15:35:26.728202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_pred = model.predict(test_X)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:26.730687Z","iopub.execute_input":"2021-10-03T15:35:26.731334Z","iopub.status.idle":"2021-10-03T15:35:27.157483Z","shell.execute_reply.started":"2021-10-03T15:35:26.731274Z","shell.execute_reply":"2021-10-03T15:35:27.156097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['target'] = lr_pred\nsub.to_csv(\"submission.csv\", index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T15:35:27.164278Z","iopub.execute_input":"2021-10-03T15:35:27.165003Z","iopub.status.idle":"2021-10-03T15:35:27.748652Z","shell.execute_reply.started":"2021-10-03T15:35:27.164683Z","shell.execute_reply":"2021-10-03T15:35:27.747559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. References\n* https://www.kaggle.com/elcaiseri/toxicity-bias-logistic-regression-tfidfvectorizer\n* http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n* https://www.kaggle.com/itratrahman/nlp-tutorial-using-python/notebook","metadata":{}},{"cell_type":"markdown","source":"<h3>Thanks For Being Here. <span style='color:red'>UPVOTE</span> If Interested .. Feel Free In Comments</h3>","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}