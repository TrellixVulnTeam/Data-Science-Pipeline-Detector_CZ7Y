{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is this competition about?\n\n#### We are asked to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. For support we have access to a dataset of 10,000 tweets that were hand classified."},{"metadata":{},"cell_type":"markdown","source":"# The Evaluation\n\nSubmissions are evaluated using F1 between the predicted and expected answers.\n\nHere's more about that and the submission format [Link](https://www.kaggle.com/c/nlp-getting-started/overview/evaluation)"},{"metadata":{},"cell_type":"markdown","source":"# Explorers Out!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nimport time \nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display, HTML\nimport plotly.graph_objects as go\nimport re\n# Natural Language Tool Kit \nimport nltk  \nnltk.download('stopwords') \nfrom nltk.corpus import stopwords \nfrom nltk.stem.porter import PorterStemmer ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\", index_col= 'id')\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\", index_col= 'id')\nsubmission =  pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\", index_col= 'id')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Location Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.location.unique()[-10:-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion 1"},{"metadata":{},"cell_type":"markdown","source":"In the Location column:-\n\n1. Remove spaces from start and end of words.\n2. Make a flag for the words that contain '#' in it.\n3. Replace all special characters with space in the words.\n4. Make all characters lowercase."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['location_has_hash'] = train.location.apply(lambda x: 1 if '#'in str(x) else 0 )\ntest['location_has_hash'] = test.location.apply(lambda x: 1 if '#'in str(x) else 0 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['location_treated'] = train.location.str.lower().str.replace(r\"[^A-Z|a-z|0-9]\",\" \").str.strip()\ntest['location_treated'] = test.location.str.lower().str.replace(r\"[^A-Z|a-z|0-9]\",\" \").str.strip()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keyword Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.keyword.unique()[-10:-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion 2"},{"metadata":{},"cell_type":"markdown","source":"In the Keyword column:-\n\n1. Remove spaces from start and end of words.\n2. Make a flag for the words that contain '%20' in it.\n3. Replace all special characters with space in the words.\n4. Make all characters lowercase."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['keyword_has_hash'] = train.keyword.apply(lambda x: 1 if '%20'in str(x) else 0 )\ntrain['keyword'] = train.keyword.str.replace(r\"%20\",\" \")\n\ntest['keyword_has_hash'] = test.keyword.apply(lambda x: 1 if '%20'in str(x) else 0 )\ntest['keyword'] = test.keyword.str.replace(r\"%20\",\" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['keyword_treated'] = train.keyword.str.lower().str.replace(r\"[^A-Z|a-z|0-9]\",\" \").str.strip()\ntest['keyword_treated'] = test.keyword.str.lower().str.replace(r\"[^A-Z|a-z|0-9]\",\" \").str.strip()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'] = train.text.str.lower().str.strip()\ntest['text'] = test.text.str.lower().str.strip()\n\ntrain['text_has_mentions'] = train.text.apply(lambda x: 1 if '@'in str(x) else 0 )\ntest['text_has_mentions'] = test.text.apply(lambda x: 1 if '@'in str(x) else 0 )\n\ntrain['text_mentions_count'] = train.text.apply(lambda x: str(x).count(\"@\"))\ntest['text_mentions_count'] = test.text.apply(lambda x: str(x).count(\"@\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x = 'target', data = train )\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.0f}\\n({p.get_height() / (train.target.count()) * 100:.1f}%)', \n                xy=(p.get_x() + p.get_width()/2., p.get_height()), ha='center', xytext=(0,5), textcoords='offset points')\nax.set_ylim(0, 2*train.target.sum())\n_ = plt.title('Target Analysis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keyword Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target_mean'] = train.groupby('keyword_treated')['target'].transform('mean')\n\nfig = plt.figure(figsize=(8, 72), dpi=100)\n\nsns.countplot(y=train.sort_values(by='target_mean', ascending=False)['keyword_treated'],\n              hue=train.sort_values(by='target_mean', ascending=False)['target'])\n\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=12)\nplt.legend(loc=1)\nplt.title('Target Distribution in Keywords')\n\nplt.show()\n\ntrain.drop(columns=['target_mean'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Location data has many unique values and the location data is not very structured as one can manually type the address too."},{"metadata":{},"cell_type":"markdown","source":"# Target based Text Column WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper refer https://www.kaggle.com/marcovasquez/basic-nlp-with-tensorflow-and-wordcloud\n\nSTOPWORDS.add('https')  # remove htps to the world Cloud\n\ndef plot_world(text, bg_color):\n    \n    comment_words = ' '\n    stopwords = set(STOPWORDS) \n    \n    for val in text: \n\n        # typecaste each val to string \n        val = str(val) \n\n        # split the value \n        tokens = val.split() \n\n#         # Converts each token into lowercase \n#         for i in range(len(tokens)): \n#             tokens[i] = tokens[i].lower() \n\n        for words in tokens: \n            comment_words = comment_words + words + ' '\n\n\n    wordcloud = WordCloud(width = 5000, height = 4000, \n                    background_color =bg_color, \n                    stopwords = stopwords, \n                    min_font_size = 10).generate(comment_words) \n\n    # plot the WordCloud image                        \n    plt.figure(figsize = (12, 12), facecolor = 'k', edgecolor = 'k' ) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# WordCloud with target 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_1 = train[train.target==1].text.values\nplot_world(text_1, 'green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# WordCloud with target 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_0 = train[train.target==0].text.values\nplot_world(text_0, 'red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target based Keyword Column WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_1 = train[train.target==1].keyword_treated.fillna(\"\").values\nplot_world(text_1, 'green')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_0 = train[train.target==0].keyword_treated.fillna(\"\").values\nplot_world(text_0, 'red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Length of Text, Keyword and Location"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text_length'] = train['text'].fillna(\"\").apply(len)\ntest['text_length'] = test['text'].fillna(\"\").apply(len)\n\ntrain['keyword_length'] = train['keyword_treated'].fillna(\"\").apply(str).apply(len)\ntest['keyword_length'] = test['keyword_treated'].fillna(\"\").apply(str).apply(len)\n\ntrain['location_length'] = train['location'].fillna(\"\").apply(str).apply(len)\ntest['location_length'] = test['location'].fillna(\"\").apply(str).apply(len)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Length Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(y = 'text_length', x = 'target', data = train, kind = 'box')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(x = 'text_length', y = None, data = train, kind = 'count', aspect = 2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(x = 'text_length', y = None, data = test, kind = 'count', aspect = 2.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keyword Length Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(y = 'keyword_length', x = 'target', data = train, kind = 'box')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(x = 'keyword_length', y = None, data = train, kind = 'count', aspect = 2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(x = 'keyword_length', y = None, data = test, kind = 'count', aspect = 2.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Location Length Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(y = 'location_length', x = 'target', data = train, kind = 'box')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(x = 'location_length', y = None, data = train, kind = 'count', aspect = 2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.factorplot(x = 'location_length', y = None, data = test, kind = 'count', aspect = 2.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check if all test locations are there in train"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(str(100*test.location_treated.isin(train.location_treated).sum()/test.location_treated.isin(train.location_treated).count())+\" % of unique test locations are from train\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Location data was pretty rough already. Now there's unseen too."},{"metadata":{},"cell_type":"markdown","source":"# Check if all test keywords are there in train"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(str(test.keyword_treated.isin(train.keyword_treated).sum()*100/test.keyword_treated.isin(train.keyword_treated).count())+\" % of unique test keywords are from train\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion - The number of unique keywords and locations seem high enough to not one hot encode them all to get high dimensionality already before touching the text column."},{"metadata":{},"cell_type":"markdown","source":"# Updates Coming Soon"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}