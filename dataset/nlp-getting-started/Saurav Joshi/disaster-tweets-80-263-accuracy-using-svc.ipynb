{"cells":[{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Data-Cleaning-for-both-train-and-test-data\" data-toc-modified-id=\"Data-Cleaning-for-both-train-and-test-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Cleaning for both train and test data</a></span></li><li><span><a href=\"#Saving-Cleaned-data\" data-toc-modified-id=\"Saving-Cleaned-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Saving Cleaned data</a></span></li><li><span><a href=\"#Loading-Cleaned-data\" data-toc-modified-id=\"Loading-Cleaned-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Loading Cleaned data</a></span></li><li><span><a href=\"#Feature-Vectorization-using-TFIDF\" data-toc-modified-id=\"Feature-Vectorization-using-TFIDF-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Feature Vectorization using TFIDF</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Test-Data\" data-toc-modified-id=\"Test-Data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Test Data</a></span></li><li><span><a href=\"#Clean-test-data-from-above-code\" data-toc-modified-id=\"Clean-test-data-from-above-code-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Clean test data from above code</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Submission</a></span></li><li><span><a href=\"#Accuracy(SVC):-80.263%\" data-toc-modified-id=\"Accuracy(SVC):-80.263%-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Accuracy(SVC): 80.263%</a></span></li></ul></div>"},{"metadata":{},"cell_type":"markdown","source":"**This notebook is to share my knowledge to the beginners as to how to go about writing code in a competition and I have particularly used SVC to solve the problem and got a decent accuracy and I am currently working on a different approach to get a higher score.**"},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(r\"../input/nlp-getting-started/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning for both train and test data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"text = list(df['text'])\n#text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lower\nlist1 = []\nfor doc in text:\n    doc = doc.lower()\n    list1.append(doc)\ntext = list1\n\n#print(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#word tokenize\nlist1 = []\nfor doc in text:\n    doc = word_tokenize(doc)\n    list1.append(doc)\ntext = list1\n\n#print(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove punctuations\npunc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n\nlist2 = []\n\nfor doc in text:\n    list1 = []\n    for words in doc:\n        for char in words:\n            if char in punc:\n                words = words.replace(char,\"\")\n        if len(words) > 0:\n            list1.append(words)\n    list2.append(list1)\n   \ntext = list2\n#print(text)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#remove stopwords\nlist2 = []\nfor doc in text:\n    list1 = []\n    for words in doc:\n        if words not in stopwords.words('english'):\n            list1.append(words)\n    list2.append(list1)\n    \ntext = list2\n#print(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lemmatization\nwordnet = WordNetLemmatizer()\n    \ntext_lemmatize = []\n\nfor doc in text:\n    list1 = []\n    for word in doc:\n        list1.append(wordnet.lemmatize(word))\n\n    text_lemmatize.append(list1)\n\ntext = text_lemmatize\n#print(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list1 = []\nfor doc in text:\n    string = ' '.join(doc)\n    list1.append(string)\n\ntext = list1\n#print(text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving Cleaned data "},{"metadata":{"trusted":false},"cell_type":"code","source":"#saving cleaned data in a pickle file\n# with open(\"cleaned_text\",\"wb\") as f:\n#     pickle.dump(text, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#saving cleaned data in a pickle file for test data\n# with open(\"test_cleaned_text\",\"wb\") as f:\n#     pickle.dump(text, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Cleaned data "},{"metadata":{"trusted":false},"cell_type":"code","source":"#loading text from train\n# import pickle\n\n# with open(\"cleaned_text\",\"rb\") as f:\n#     text = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#loading text from test\n# import pickle\n\n# with open(\"test_cleaned_text\",\"rb\") as f:\n#     text = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"#text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Vectorization using TFIDF "},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = list(df['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(text, Y, test_size=0.0001, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_train),\" \",len(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", decode_error=\"ignore\")\ntfidf_vectorizer.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ncls = SVC()\ncls.fit(tfidf_vectorizer.transform(X_train), y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\ny_pred = cls.predict(tfidf_vectorizer.transform(X_test))\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = [\"Amazing day\",\"disaster earthquake\"]\nans = cls.predict(tfidf_vectorizer.transform(val))\nans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data "},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv(r\"../input/nlp-getting-started/test.csv\")\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"text = list(df2['text'])\n#text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean test data from above code "},{"metadata":{"trusted":true},"cell_type":"code","source":"#text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans = cls.predict(tfidf_vectorizer.transform(text))\nans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission "},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': df2['id'], 'target': ans })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('my_submission_svm', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Please upvote the notebook if you liked it.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}