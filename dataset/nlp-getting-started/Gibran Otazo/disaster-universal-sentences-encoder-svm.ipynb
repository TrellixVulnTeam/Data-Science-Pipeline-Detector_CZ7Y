{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Notebook approach.\n\nIn this approach, I've made used of universal sentences encoder from tensorflow_hub, to vectorize the sentences, and then SVM to do the classification. "},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"!pip install --user tensorflow_text","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text\n\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loadind datasets."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(text):\n    text = re.sub(r\"http\\S+\", \" \", text) # remove urls\n    text = re.sub(r\"RT \", \" \", text) # remove rt\n    text = re.sub(r\"[^a-zA-Z\\'\\.\\,\\d\\s]\", \" \", text) # remove special character except # @ . ,\n    text = re.sub(r\"[0-9]\", \" \", text) # remove number\n    text = re.sub(r'\\t', ' ', text) # remove tabs\n    text = re.sub(r'\\n', ' ', text) # remove line jump\n    text = re.sub(r\"\\s+\", \" \", text) # remove extra white space\n    text = text.strip()\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.text = train.text.apply(clean)\ntest.text = test.text.apply(clean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading universal sentences encoder."},{"metadata":{"trusted":true},"cell_type":"code","source":"use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentences embedding."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = []\nfor r in tqdm(train.text.values):\n  emb = use(r)\n  review_emb = tf.reshape(emb, [-1]).numpy()\n  X_train.append(review_emb)\n\nX_train = np.array(X_train)\ny_train = train.target.values\n\nX_test = []\nfor r in tqdm(test.text.values):\n  emb = use(r)\n  review_emb = tf.reshape(emb, [-1]).numpy()\n  X_test.append(review_emb)\n\nX_test = np.array(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sampling over data train."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_arrays, test_arrays, train_labels, test_labels = train_test_split(X_train,y_train,test_size=0.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training svm model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def svc_param_selection(X, y, nfolds):\n    #Cs = [0.001, 0.01, 0.1, 1, 10]\n    Cs = [1.070, 1.074, 1.075, 1.1, 1.125]\n    #gammas = [0.001, 0.01, 0.1, 1]\n    gammas = [2.065,2.075, 2.08]\n    param_grid = {'C': Cs, 'gamma' : gammas}\n    grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=nfolds, n_jobs=8)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search\n\nmodel = svc_param_selection(train_arrays,train_labels, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Best parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions over valuation data."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test_arrays)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(test_labels,pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(test_labels,pred)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model.predict(X_test)\nsubmission['target'] = test_pred.round().astype(int)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}