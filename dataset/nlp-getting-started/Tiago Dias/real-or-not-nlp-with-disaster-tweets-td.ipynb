{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install wordninja\n!pip install textblob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importação dos pacotes para Analise\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nimport xgboost as xgb\nimport numpy as np\nfrom sklearn.model_selection import KFold, train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, log_loss, f1_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom joblib import dump, load\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nimport wordninja\nimport textblob\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\n\nimport warnings\nwarnings.simplefilter(action = 'ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importação dos dataset\ntrain = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsub = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Tamanho do arquivo de Treino', train.shape)\nprint('Tamanho do arquivo de Teste', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.append(test)\ndf.reset_index(inplace=True, drop=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando palavras juntas\ndf['text_split'] = df['text'].apply(wordninja.split)\ndf['text_new'] = df['text_split'].apply(TreebankWordDetokenizer().detokenize)\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando o balanceamento dos Tweets\ndf['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Variáveis importantes\npontuacao = ['.',',','-','+',':',';','&','+','/','!','?','#','%','(',')','  ']\n# Palavras para retirar da análise\nstop_words = stopwords.words('english')\n# Tamanho da validação de teste\ntest_size = 0.2\nrandom_state = 42\n# Parametros do vetor CountVectorizer\nngram_range = (1, 2)\nstrip_accents = 'ascii'\n# Parametros do vetor TfidfTransformer\nuse_idf = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Excluindo da descrição texto após os números, informações julgadas irrelevantes para a classificação.\ndf['text_new'] = df['text_new'].str.replace('[0-9]+', '', regex=True)\n\n# Excluindo da descrição puntuação, informações julgadas irrelevantes para a classificação.\nfor x in pontuacao:\n  df['text_new'] = df['text_new'].str.replace(x, ' ')\n  \ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função Treinamento, Teste, Resultado \ndef train(feature, target, new_feature, new_target):\n  cvt = CountVectorizer(ngram_range=ngram_range, strip_accents=strip_accents, stop_words=stop_words)\n  tfi = TfidfTransformer(use_idf=use_idf)\n  clf = RandomForestClassifier(n_estimators=500)\n  #clf = LogisticRegression(multi_class='multinomial')\n  #clf = MLPClassifier((10,))\n\n  # Criando pipeline\n  clf = Pipeline([('cvt', cvt), ('tfi', tfi), ('clf', clf)])\n  \n  # Dividindo dataset em treino e teste\n  x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=test_size, random_state=random_state)\n\n  # Executando pipeline\n  clf.fit(x_train, y_train)\n\n  # Avaliando a performance com predição\n  predicted = clf.predict(x_test)\n  predicted_proba = clf.predict_proba(x_test)\n  print('#---------Indicadores Classificação---------#\\n')\n  print(classification_report(y_test, predicted))\n  print('#----Log Loss----#')\n  print(log_loss(y_test, predicted_proba))\n  print('\\n#----F1 Score----#')\n  print(f1_score(y_test, predicted))\n\n  # Predição dos novos dados\n  predicted_new = clf.predict(new_feature)\n\n  # Probabilidade das predições\n  y_proba = clf.predict_proba(new_feature)\n  estimadores = clf.classes_\n\n  # Adicionando a coluna para o novo DF\n  df_test[new_target] = predicted_new\n\n  return df_test, y_proba, estimadores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função Treinamento, Teste, Resultado XGB\ndef train_xgb(feature, target, new_feature, new_target):\n    cvt = CountVectorizer(ngram_range=ngram_range, strip_accents=strip_accents, stop_words=stop_words)\n    tfi = TfidfTransformer(use_idf=use_idf)\n\n    # Criando pipeline\n    pip = Pipeline([('cvt', cvt), ('tfi', tfi)])\n    feature = pip.fit_transform(feature)\n\n    #print(\"XGBClassifier\\n\")\n    #print(\"Parameter optimization\\n\")\n    xgb_model = xgb.XGBClassifier()\n    clf = GridSearchCV(xgb_model, {'booster': ['gbtree','gblinear','dart'],\n                                   'n_estimators': [25, 50, 75]})\n    clf.fit(feature, target)\n    #print('Melhores parametros\\n', clf.best_score_)\n    #print('Melhor Score\\n', clf.best_params_)\n    predicted = clf.predict(feature)\n    predicted_proba = clf.predict_proba(feature)\n    print('#---------Indicadores Classificação---------#\\n')\n    print(classification_report(target, predicted))\n    print('#----Log Loss----#')\n    print(log_loss(target, predicted_proba))\n    print('\\n#----F1 Score----#')\n    print(f1_score(target, predicted))\n\n    new_feature = df_test['text_new']\n    new_feature = pip.transform(new_feature)\n\n    # Predição dos novos dados\n    predicted_xgb = clf.predict(new_feature)\n\n    # Probabilidade das predições\n    y_proba_xgb = clf.predict_proba(new_feature)\n    estimadores_xgb = clf.classes_\n\n    # Adicionando a coluna para o novo DF\n    df_test[new_target] = predicted_xgb\n    \n    return df_test, y_proba_xgb, estimadores_xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando df treino de test\ndf.drop(columns=['keyword','location'], inplace=True)\ndf_train = df.dropna().copy()\ndf_test = df.loc[(df.target.isnull())].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecionando apenas o item a ser classificado e o target do DF principal\nfeature = df_train['text_new']\ntarget = df_train.target\n# Dados de Teste\nnew_feature = df_test['text_new']\nnew_target = 'target'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chamando Função\ndf_test, y_proba, estimadores = train(feature, target, new_feature, new_target)\ndf_test['target'] = df_test['target'].apply(int)\ndf_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chamando Função XGB\ndf_test, y_proba_xgb, estimadores_xgb = train_xgb(feature, target, new_feature, new_target)\ndf_test['target'] = df_test['target'].apply(int)\ndf_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exportando classificação\nsubmission = df_test[['id','target']]\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exportando classificação XGB\nsubmission_xgb = df_test[['id','target']]\nsubmission_xgb.to_csv('submission_xgb.csv', index=False)\nsubmission_xgb.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}