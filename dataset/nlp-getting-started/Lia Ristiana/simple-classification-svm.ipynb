{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom nltk import word_tokenize\n\nimport os, re\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test the Data using Accuracy"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### function to clean text (remove punctuation, links, lowercase all letters, etc)\ndef clean_text(text):\n    temp = text.lower()\n    temp = re.sub('\\n', \" \", temp)\n    temp = re.sub('\\'', \"\", temp)\n    temp = re.sub('-', \" \", temp)\n    temp = re.sub(r\"(http|https|pic.)\\S+\",\" \",temp)\n    temp = re.sub(r'[^\\w\\s]',' ',temp)\n    \n    return temp\n\n### list of stop words that need to be removed\nstop_words = ['as', 'in', 'of', 'is', 'are', 'were', 'was', 'it', 'for', 'to', 'from', 'into', 'onto', \n              'this', 'that', 'being', 'the','those', 'these', 'such', 'a', 'an']\n### function to remove unnecessary words\ndef remove_stopwords(text):\n    tokenized_words = word_tokenize(text)\n    temp = [word for word in tokenized_words if word not in stop_words]\n    temp = ' '.join(temp)\n    return temp\n\n### We save the cleaned and normalized texts in the new column, called 'clean'\ntrain['clean'] = train['text'].apply(clean_text)\ntrain['clean'] = train['clean'].apply(remove_stopwords)\ntrain['clean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_attributes(text, keyword):\n    var_list = [text, keyword]\n    combined = ' '.join(x for x in var_list if x)\n    return combined\n\ntrain.fillna('', inplace=True)\ntrain['combine'] = train.apply(lambda x: combine_attributes(x['clean'], x['keyword']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train['combine']\ny = train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer()\n\nX_train_vect = vectorizer.fit_transform(X_train)\nX_test_vect = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\n\nclf = SVC(kernel='linear')\nclf.fit(X_train_vect, y_train)\n\ny_pred = clf.predict(X_test_vect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Create Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### apply preprocessing on train data\ntrain['clean'] = train['text'].apply(clean_text)\ntrain['clean'] = train['clean'].apply(remove_stopwords)\n\n### apply preprocessing on test data\ntest['clean'] = test['text'].apply(clean_text)\ntest['clean'] = test['clean'].apply(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna('', inplace=True)\ntrain['combine'] = train.apply(lambda x: combine_attributes(x['clean'], x['keyword']), axis=1)\n\ntest.fillna('', inplace=True)\ntest['combine'] = test.apply(lambda x: combine_attributes(x['clean'], x['keyword']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train['combine']\ny_train = train['target']\n\nX_test = test['combine']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer()\n\nX_train_vect = vectorizer.fit_transform(X_train)\nX_test_vect = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(kernel='linear')\nclf.fit(X_train_vect, y_train)\n\ny_pred = clf.predict(X_test_vect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame({'id':test['id'], 'target':y_pred})\nresult.to_csv('svm_submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}