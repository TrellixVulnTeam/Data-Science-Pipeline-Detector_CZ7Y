{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-28T13:36:31.831827Z","iopub.execute_input":"2022-06-28T13:36:31.83292Z","iopub.status.idle":"2022-06-28T13:36:31.863294Z","shell.execute_reply.started":"2022-06-28T13:36:31.832793Z","shell.execute_reply":"2022-06-28T13:36:31.862254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import text_to_word_sequence\nfrom tensorflow.keras.preprocessing.text import Tokenizer  \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom collections import Counter\nfrom pathlib import Path\nimport os\nimport numpy as np\nimport re\nimport string\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\nfrom nltk.corpus import wordnet\nimport unicodedata\nimport html\nstop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:33.00859Z","iopub.execute_input":"2022-06-28T13:36:33.009245Z","iopub.status.idle":"2022-06-28T13:36:39.290787Z","shell.execute_reply.started":"2022-06-28T13:36:33.009204Z","shell.execute_reply":"2022-06-28T13:36:39.289849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"../input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:39.292769Z","iopub.execute_input":"2022-06-28T13:36:39.293443Z","iopub.status.idle":"2022-06-28T13:36:39.362426Z","shell.execute_reply.started":"2022-06-28T13:36:39.293404Z","shell.execute_reply":"2022-06-28T13:36:39.361458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"target\"] == 0][\"text\"].values[10]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:39.36385Z","iopub.execute_input":"2022-06-28T13:36:39.364999Z","iopub.status.idle":"2022-06-28T13:36:39.381517Z","shell.execute_reply.started":"2022-06-28T13:36:39.364962Z","shell.execute_reply":"2022-06-28T13:36:39.380445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"target\"] == 1][\"text\"].values[10]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:39.384482Z","iopub.execute_input":"2022-06-28T13:36:39.384862Z","iopub.status.idle":"2022-06-28T13:36:39.394835Z","shell.execute_reply.started":"2022-06-28T13:36:39.384823Z","shell.execute_reply":"2022-06-28T13:36:39.393713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Perform proper Text preprocessing steps\n\n* Data cleaning :\n   *    Remove special characters and punctuations","metadata":{}},{"cell_type":"code","source":"def subtext_repeation_in_df(df, col, subtext, num):\n    # Calc statistics as table for character repetition (1...num times) from subtext list in the df[col]\n    \n    text = \"\".join(df[col])\n    result = pd.DataFrame(columns = ['subtext', 'count'])\n    i = 0\n    if (len(df) > 0) and (len(subtext) > 0):\n        for c in subtext:\n            for j in range(num):\n                cs = c*(j+1)\n                result.loc[i,'count'] = text.count(cs)\n                if c == ' ':\n                    cs = cs.replace(' ','<space>')\n                result.loc[i,'subtext'] = cs                \n                i += 1\n    print('Number of all data is', len(df))\n    result = result[result['count'] > 0].reset_index(drop=True)\n    display(result.sort_values(by='count',ascending=False))\n    \n    print('Text examples')\n    problem_examples = pd.DataFrame(columns = ['problem_examples'])\n    problem_examples['problem_examples'] = ''\n    for i in range(len(result)):\n        problem_examples.loc[i,'problem_examples'] = df[df[col].str.find(result.loc[i,'subtext'])>-1].reset_index(drop=True).loc[0, col]\n    problem_examples = problem_examples.drop_duplicates()\n    display(problem_examples)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:39.397377Z","iopub.execute_input":"2022-06-28T13:36:39.39794Z","iopub.status.idle":"2022-06-28T13:36:39.408484Z","shell.execute_reply.started":"2022-06-28T13:36:39.397903Z","shell.execute_reply":"2022-06-28T13:36:39.40759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysis of punctuation marks repetition in training data\nprint('Statistics for punctuation marks repetition in training data')\nsubtext_repeation_in_df(train_df, 'text', list(string.punctuation), 10)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:39.409907Z","iopub.execute_input":"2022-06-28T13:36:39.410511Z","iopub.status.idle":"2022-06-28T13:36:40.398592Z","shell.execute_reply.started":"2022-06-28T13:36:39.410471Z","shell.execute_reply":"2022-06-28T13:36:40.397686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punctuation(text):\n    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.400141Z","iopub.execute_input":"2022-06-28T13:36:40.400523Z","iopub.status.idle":"2022-06-28T13:36:40.40641Z","shell.execute_reply.started":"2022-06-28T13:36:40.400487Z","shell.execute_reply":"2022-06-28T13:36:40.405407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.407732Z","iopub.execute_input":"2022-06-28T13:36:40.408726Z","iopub.status.idle":"2022-06-28T13:36:40.417714Z","shell.execute_reply.started":"2022-06-28T13:36:40.408685Z","shell.execute_reply":"2022-06-28T13:36:40.416629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remove_punctuation(train_df['text'].iloc[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.419016Z","iopub.execute_input":"2022-06-28T13:36:40.419953Z","iopub.status.idle":"2022-06-28T13:36:40.427571Z","shell.execute_reply.started":"2022-06-28T13:36:40.4199Z","shell.execute_reply":"2022-06-28T13:36:40.426319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Case normalization","metadata":{}},{"cell_type":"code","source":"def to_lowercase(text):\n    return text.lower()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.4323Z","iopub.execute_input":"2022-06-28T13:36:40.432652Z","iopub.status.idle":"2022-06-28T13:36:40.437109Z","shell.execute_reply.started":"2022-06-28T13:36:40.432625Z","shell.execute_reply":"2022-06-28T13:36:40.435715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_lowercase(remove_punctuation(train_df['text'].iloc[0]))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.439153Z","iopub.execute_input":"2022-06-28T13:36:40.439662Z","iopub.status.idle":"2022-06-28T13:36:40.447991Z","shell.execute_reply.started":"2022-06-28T13:36:40.439621Z","shell.execute_reply":"2022-06-28T13:36:40.446934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Replace all Numbers","metadata":{}},{"cell_type":"code","source":"def replace_numbers(text):\n    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n    return re.sub(r'\\d+', '', text)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.449417Z","iopub.execute_input":"2022-06-28T13:36:40.450344Z","iopub.status.idle":"2022-06-28T13:36:40.455691Z","shell.execute_reply.started":"2022-06-28T13:36:40.450306Z","shell.execute_reply":"2022-06-28T13:36:40.454433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'].iloc[95]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.456982Z","iopub.execute_input":"2022-06-28T13:36:40.457946Z","iopub.status.idle":"2022-06-28T13:36:40.46599Z","shell.execute_reply.started":"2022-06-28T13:36:40.457911Z","shell.execute_reply":"2022-06-28T13:36:40.464774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"replace_numbers(to_lowercase(remove_punctuation(train_df['text'].iloc[95])))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.467438Z","iopub.execute_input":"2022-06-28T13:36:40.468495Z","iopub.status.idle":"2022-06-28T13:36:40.475819Z","shell.execute_reply.started":"2022-06-28T13:36:40.468452Z","shell.execute_reply":"2022-06-28T13:36:40.474742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Words tokenization : create list of words","metadata":{}},{"cell_type":"code","source":"def text2words(text):\n    return word_tokenize(text)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.477258Z","iopub.execute_input":"2022-06-28T13:36:40.478325Z","iopub.status.idle":"2022-06-28T13:36:40.485283Z","shell.execute_reply.started":"2022-06-28T13:36:40.478288Z","shell.execute_reply":"2022-06-28T13:36:40.484242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text2words(replace_numbers(to_lowercase(remove_punctuation(train_df['text'].iloc[95]))))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.486563Z","iopub.execute_input":"2022-06-28T13:36:40.487314Z","iopub.status.idle":"2022-06-28T13:36:40.505934Z","shell.execute_reply.started":"2022-06-28T13:36:40.487275Z","shell.execute_reply":"2022-06-28T13:36:40.504965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Remove Stop words like ( 'the', 'to', 'on', 'we',...etc)","metadata":{}},{"cell_type":"code","source":"def remove_stopwords(words, stop_words):\n    \"\"\"\n    :param words:\n    :type words:\n    :param stop_words: from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n    or\n    from spacy.lang.en.stop_words import STOP_WORDS\n    :type stop_words:\n    :return:\n    :rtype:\n    \"\"\"\n    return [word for word in words if word not in stop_words]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.507177Z","iopub.execute_input":"2022-06-28T13:36:40.507995Z","iopub.status.idle":"2022-06-28T13:36:40.513433Z","shell.execute_reply.started":"2022-06-28T13:36:40.507959Z","shell.execute_reply":"2022-06-28T13:36:40.512422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t= text2words(replace_numbers(to_lowercase(remove_punctuation(train_df['text'].iloc[95]))))\nremove_stopwords( t, stop_words)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.554953Z","iopub.execute_input":"2022-06-28T13:36:40.555336Z","iopub.status.idle":"2022-06-28T13:36:40.565734Z","shell.execute_reply.started":"2022-06-28T13:36:40.555308Z","shell.execute_reply":"2022-06-28T13:36:40.564827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Stemming","metadata":{}},{"cell_type":"code","source":"def stem_words(words):\n    \"\"\"Stem words in text\"\"\"\n    stemmer = PorterStemmer()\n    return [stemmer.stem(word) for word in words]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:40.962456Z","iopub.execute_input":"2022-06-28T13:36:40.96321Z","iopub.status.idle":"2022-06-28T13:36:40.97083Z","shell.execute_reply.started":"2022-06-28T13:36:40.963154Z","shell.execute_reply":"2022-06-28T13:36:40.969471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t= remove_stopwords(text2words(replace_numbers(to_lowercase(remove_punctuation(train_df['text'].iloc[95])))),stop_words)\nstem_words(t)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:41.206458Z","iopub.execute_input":"2022-06-28T13:36:41.206759Z","iopub.status.idle":"2022-06-28T13:36:41.216166Z","shell.execute_reply.started":"2022-06-28T13:36:41.206731Z","shell.execute_reply":"2022-06-28T13:36:41.214811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Another preprocess : Lemmatizing","metadata":{}},{"cell_type":"code","source":"def lemmatize_words(words):\n    \"\"\"Lemmatize words in text\"\"\"\n\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in words]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:41.91878Z","iopub.execute_input":"2022-06-28T13:36:41.919562Z","iopub.status.idle":"2022-06-28T13:36:41.924969Z","shell.execute_reply.started":"2022-06-28T13:36:41.919518Z","shell.execute_reply":"2022-06-28T13:36:41.923641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t= remove_stopwords(text2words(replace_numbers(to_lowercase(remove_punctuation(train_df['text'].iloc[95])))),stop_words)\nlemmatize_words(t)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:43.382329Z","iopub.execute_input":"2022-06-28T13:36:43.383079Z","iopub.status.idle":"2022-06-28T13:36:45.201169Z","shell.execute_reply.started":"2022-06-28T13:36:43.383038Z","shell.execute_reply":"2022-06-28T13:36:45.200124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lemmatize_verbs(words):\n    \"\"\"Lemmatize verbs in text\"\"\"\n\n    lemmatizer = WordNetLemmatizer()\n    return ' '.join([lemmatizer.lemmatize(word, pos='v') for word in words])\n","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:45.203049Z","iopub.execute_input":"2022-06-28T13:36:45.203507Z","iopub.status.idle":"2022-06-28T13:36:45.208974Z","shell.execute_reply.started":"2022-06-28T13:36:45.203466Z","shell.execute_reply":"2022-06-28T13:36:45.208036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data ","metadata":{}},{"cell_type":"code","source":"train_ds_text = train_df.drop([\"id\",\"keyword\",\"location\"], axis=1)\ntest_ds_text = test_df.drop([\"id\",\"keyword\",\"location\"], axis=1)\ntraining_messages = []\ntest_messages = []\ntraining_labels = []\nfor index, item in train_ds_text.iterrows():\n    message, label = item[\"text\"], item[\"target\"]\n    training_messages.append(str(message))\n    training_labels.append(label)\n    \n    \nfor index, item in test_ds_text.iterrows():\n    message = item[\"text\"]\n    test_messages.append(str(message))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:45.210309Z","iopub.execute_input":"2022-06-28T13:36:45.211293Z","iopub.status.idle":"2022-06-28T13:36:45.91142Z","shell.execute_reply.started":"2022-06-28T13:36:45.211256Z","shell.execute_reply":"2022-06-28T13:36:45.91037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_special_chars(text):\n    re1 = re.compile(r'  +')\n    x1 = text.lower().replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n    return re1.sub(' ', html.unescape(x1))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:48.669675Z","iopub.execute_input":"2022-06-28T13:36:48.670018Z","iopub.status.idle":"2022-06-28T13:36:48.677115Z","shell.execute_reply.started":"2022-06-28T13:36:48.669987Z","shell.execute_reply":"2022-06-28T13:36:48.675983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Text preparation","metadata":{}},{"cell_type":"code","source":"def normalize_text( text):\n    text = remove_special_chars(text)\n    text = remove_punctuation(text)\n    text = to_lowercase(text)\n    text = replace_numbers(text)\n    words = text2words(text)\n    words = remove_stopwords(words, stop_words)\n    #words = stem_words(words)# Either stem ovocar lemmatize\n    words = lemmatize_words(words)\n    words = lemmatize_verbs(words)\n    \n\n    return ''.join(words)\n\ndef normalize_corpus(corpus):\n    return [normalize_text(t) for t in corpus]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:51.792313Z","iopub.execute_input":"2022-06-28T13:36:51.793353Z","iopub.status.idle":"2022-06-28T13:36:51.800979Z","shell.execute_reply.started":"2022-06-28T13:36:51.7933Z","shell.execute_reply":"2022-06-28T13:36:51.799866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn_texts = normalize_corpus(training_messages)\ntst_texts = normalize_corpus(test_messages)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:36:53.337282Z","iopub.execute_input":"2022-06-28T13:36:53.337632Z","iopub.status.idle":"2022-06-28T13:36:56.914016Z","shell.execute_reply.started":"2022-06-28T13:36:53.337602Z","shell.execute_reply":"2022-06-28T13:36:56.913039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### * BoW (Binary features)","metadata":{}},{"cell_type":"code","source":"tok = Tokenizer(num_words=1000, oov_token='UNK')\n#tok = Tokenizer(oov_token='UNK')\ntok.fit_on_texts(trn_texts + tst_texts)\n# Extract binary BoW features\nx_train = tok.texts_to_matrix(trn_texts, mode='binary')\nx_test = tok.texts_to_matrix(tst_texts, mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:38:04.507685Z","iopub.execute_input":"2022-06-28T13:38:04.508047Z","iopub.status.idle":"2022-06-28T13:38:04.969793Z","shell.execute_reply.started":"2022-06-28T13:38:04.508017Z","shell.execute_reply":"2022-06-28T13:38:04.968551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.asarray(training_labels).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:38:04.971803Z","iopub.execute_input":"2022-06-28T13:38:04.972196Z","iopub.status.idle":"2022-06-28T13:38:04.979532Z","shell.execute_reply.started":"2022-06-28T13:38:04.97216Z","shell.execute_reply":"2022-06-28T13:38:04.978477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:38:10.956408Z","iopub.execute_input":"2022-06-28T13:38:10.956759Z","iopub.status.idle":"2022-06-28T13:38:10.962726Z","shell.execute_reply.started":"2022-06-28T13:38:10.956728Z","shell.execute_reply":"2022-06-28T13:38:10.961645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.Bulid Model","metadata":{}},{"cell_type":"code","source":"x_val = x_train[:1000]\npartial_x_train = x_train[1000:]\n\ny_val = y_train[:1000]\npartial_y_train = y_train[1000:]\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(1000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss=losses.binary_crossentropy,\n              metrics=[metrics.binary_accuracy])\n\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=20,\n                    batch_size=512,\n                    validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:38:56.445796Z","iopub.execute_input":"2022-06-28T12:38:56.446135Z","iopub.status.idle":"2022-06-28T12:39:02.543565Z","shell.execute_reply.started":"2022-06-28T12:38:56.446107Z","shell.execute_reply":"2022-06-28T12:39:02.54263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:41:41.913113Z","iopub.execute_input":"2022-06-28T12:41:41.914174Z","iopub.status.idle":"2022-06-28T12:41:42.143856Z","shell.execute_reply.started":"2022-06-28T12:41:41.914127Z","shell.execute_reply":"2022-06-28T12:41:42.142976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:41:49.314678Z","iopub.execute_input":"2022-06-28T12:41:49.315262Z","iopub.status.idle":"2022-06-28T12:41:49.516061Z","shell.execute_reply.started":"2022-06-28T12:41:49.315223Z","shell.execute_reply":"2022-06-28T12:41:49.515146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Submission File","metadata":{}},{"cell_type":"code","source":"# model = models.Sequential()\n# model.add(layers.Dense(16, activation='relu', input_shape=(1000,)))\n# model.add(layers.Dense(16, activation='relu'))\n# model.add(layers.Dense(16, activation='relu'))\n# model.add(layers.Dense(1, activation='sigmoid'))\n\n# model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n#               loss=losses.binary_crossentropy,\n#               metrics=[metrics.binary_accuracy])\n\n# model.fit(partial_x_train,\n#                     partial_y_train,\n#                     epochs=4,\n#                     batch_size=512,\n#                     validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:54:50.620656Z","iopub.execute_input":"2022-06-28T12:54:50.621006Z","iopub.status.idle":"2022-06-28T12:54:52.050026Z","shell.execute_reply.started":"2022-06-28T12:54:50.620977Z","shell.execute_reply":"2022-06-28T12:54:52.04909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:55:03.607975Z","iopub.execute_input":"2022-06-28T12:55:03.608312Z","iopub.status.idle":"2022-06-28T12:55:03.830684Z","shell.execute_reply.started":"2022-06-28T12:55:03.60828Z","shell.execute_reply":"2022-06-28T12:55:03.829747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:55:05.63788Z","iopub.execute_input":"2022-06-28T12:55:05.638221Z","iopub.status.idle":"2022-06-28T12:55:05.646737Z","shell.execute_reply.started":"2022-06-28T12:55:05.638191Z","shell.execute_reply":"2022-06-28T12:55:05.645531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result[result>=0.5]=1\n# result[result<0.5]=0","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:55:15.935857Z","iopub.execute_input":"2022-06-28T12:55:15.936195Z","iopub.status.idle":"2022-06-28T12:55:15.94161Z","shell.execute_reply.started":"2022-06-28T12:55:15.936165Z","shell.execute_reply":"2022-06-28T12:55:15.940324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:55:26.94546Z","iopub.execute_input":"2022-06-28T12:55:26.946316Z","iopub.status.idle":"2022-06-28T12:55:26.953806Z","shell.execute_reply.started":"2022-06-28T12:55:26.946281Z","shell.execute_reply":"2022-06-28T12:55:26.95256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_submission=pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\n# sample_submission['target']=result\n# sample_submission['target']=sample_submission['target'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:55:32.937482Z","iopub.execute_input":"2022-06-28T12:55:32.938385Z","iopub.status.idle":"2022-06-28T12:55:32.947693Z","shell.execute_reply.started":"2022-06-28T12:55:32.938347Z","shell.execute_reply":"2022-06-28T12:55:32.946742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample_submission.head()\n# sample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:55:34.452227Z","iopub.execute_input":"2022-06-28T12:55:34.452867Z","iopub.status.idle":"2022-06-28T12:55:34.464601Z","shell.execute_reply.started":"2022-06-28T12:55:34.452828Z","shell.execute_reply":"2022-06-28T12:55:34.46361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### using count\nx_train = tok.texts_to_matrix(trn_texts, mode='count')\nx_test = tok.texts_to_matrix(tst_texts, mode='count')\n\nx_val = x_train[:1000]\npartial_x_train = x_train[1000:]\n\ny_val = y_train[:1000]\npartial_y_train = y_train[1000:]\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(1000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss=losses.binary_crossentropy,\n              metrics=[metrics.binary_accuracy])\n\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=20,\n                    batch_size=512,\n                    validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:04:57.928378Z","iopub.execute_input":"2022-06-28T13:04:57.928879Z","iopub.status.idle":"2022-06-28T13:05:00.435832Z","shell.execute_reply.started":"2022-06-28T13:04:57.928844Z","shell.execute_reply":"2022-06-28T13:05:00.434904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:05:19.891906Z","iopub.execute_input":"2022-06-28T13:05:19.892241Z","iopub.status.idle":"2022-06-28T13:05:20.098452Z","shell.execute_reply.started":"2022-06-28T13:05:19.892212Z","shell.execute_reply":"2022-06-28T13:05:20.097533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:06:41.209984Z","iopub.execute_input":"2022-06-28T13:06:41.210552Z","iopub.status.idle":"2022-06-28T13:06:41.421402Z","shell.execute_reply.started":"2022-06-28T13:06:41.210389Z","shell.execute_reply":"2022-06-28T13:06:41.420311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Submission File","metadata":{}},{"cell_type":"code","source":"# model = models.Sequential()\n# model.add(layers.Dense(16, activation='relu', input_shape=(1000,)))\n# model.add(layers.Dense(16, activation='relu'))\n# model.add(layers.Dense(16, activation='relu'))\n# model.add(layers.Dense(1, activation='sigmoid'))\n\n# model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n#               loss=losses.binary_crossentropy,\n#               metrics=[metrics.binary_accuracy])\n\n# model.fit(partial_x_train,\n#                     partial_y_train,\n#                     epochs=5,\n#                     batch_size=512,\n#                     validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:08:10.773256Z","iopub.execute_input":"2022-06-28T13:08:10.77418Z","iopub.status.idle":"2022-06-28T13:08:11.836209Z","shell.execute_reply.started":"2022-06-28T13:08:10.774138Z","shell.execute_reply":"2022-06-28T13:08:11.835308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = model.predict(x_test)\n# result[result>=0.5]=1\n# result[result<0.5]=0\n# result","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:08:46.355391Z","iopub.execute_input":"2022-06-28T13:08:46.355861Z","iopub.status.idle":"2022-06-28T13:08:46.622229Z","shell.execute_reply.started":"2022-06-28T13:08:46.355821Z","shell.execute_reply":"2022-06-28T13:08:46.621293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_submission=pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\n# sample_submission['target']=result\n# sample_submission['target']=sample_submission['target'].astype(int)\n# #sample_submission.head()\n# sample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:09:15.574213Z","iopub.execute_input":"2022-06-28T13:09:15.574863Z","iopub.status.idle":"2022-06-28T13:09:15.594401Z","shell.execute_reply.started":"2022-06-28T13:09:15.574826Z","shell.execute_reply":"2022-06-28T13:09:15.593271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### using freq\nx_train = tok.texts_to_matrix(trn_texts, mode='freq')\nx_test = tok.texts_to_matrix(tst_texts, mode='freq')\n\nx_val = x_train[:1000]\npartial_x_train = x_train[1000:]\n\ny_val = y_train[:1000]\npartial_y_train = y_train[1000:]\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(1000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss=losses.binary_crossentropy,\n              metrics=[metrics.binary_accuracy])\n\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=20,\n                    batch_size=512,\n                    validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:16.68233Z","iopub.execute_input":"2022-06-28T13:14:16.683257Z","iopub.status.idle":"2022-06-28T13:14:20.044649Z","shell.execute_reply.started":"2022-06-28T13:14:16.683222Z","shell.execute_reply":"2022-06-28T13:14:20.043644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:40.607018Z","iopub.execute_input":"2022-06-28T13:14:40.607513Z","iopub.status.idle":"2022-06-28T13:14:40.826728Z","shell.execute_reply.started":"2022-06-28T13:14:40.607473Z","shell.execute_reply":"2022-06-28T13:14:40.825707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:41.61418Z","iopub.execute_input":"2022-06-28T13:15:41.61454Z","iopub.status.idle":"2022-06-28T13:15:41.811247Z","shell.execute_reply.started":"2022-06-28T13:15:41.614509Z","shell.execute_reply":"2022-06-28T13:15:41.810392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Submission File","metadata":{}},{"cell_type":"code","source":"# model = models.Sequential()\n# model.add(layers.Dense(16, activation='relu', input_shape=(1000,)))\n# model.add(layers.Dense(16, activation='relu'))\n# model.add(layers.Dense(16, activation='relu'))\n# model.add(layers.Dense(1, activation='sigmoid'))\n\n# model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n#               loss=losses.binary_crossentropy,\n#               metrics=[metrics.binary_accuracy])\n\n# model.fit(partial_x_train,\n#                     partial_y_train,\n#                     epochs=10,\n#                     batch_size=512,\n#                     validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:18:32.856856Z","iopub.execute_input":"2022-06-28T13:18:32.857205Z","iopub.status.idle":"2022-06-28T13:18:34.490235Z","shell.execute_reply.started":"2022-06-28T13:18:32.857176Z","shell.execute_reply":"2022-06-28T13:18:34.489338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = model.predict(x_test)\n# result[result>=0.5]=1\n# result[result<0.5]=0\n# sample_submission=pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\n# sample_submission['target']=result\n# sample_submission['target']=sample_submission['target'].astype(int)\n# #sample_submission.head()\n# sample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:18:57.341872Z","iopub.execute_input":"2022-06-28T13:18:57.34222Z","iopub.status.idle":"2022-06-28T13:18:57.573534Z","shell.execute_reply.started":"2022-06-28T13:18:57.342183Z","shell.execute_reply":"2022-06-28T13:18:57.57261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use LSTM ","metadata":{}},{"cell_type":"code","source":"maxlen = max([len(t) for t in trn_texts])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:37:14.038535Z","iopub.execute_input":"2022-06-28T13:37:14.039437Z","iopub.status.idle":"2022-06-28T13:37:14.045641Z","shell.execute_reply.started":"2022-06-28T13:37:14.039397Z","shell.execute_reply":"2022-06-28T13:37:14.044616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlen","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:37:14.920865Z","iopub.execute_input":"2022-06-28T13:37:14.921231Z","iopub.status.idle":"2022-06-28T13:37:14.929081Z","shell.execute_reply.started":"2022-06-28T13:37:14.921179Z","shell.execute_reply":"2022-06-28T13:37:14.928046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=[len(t) for t in trn_texts]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:37:16.381884Z","iopub.execute_input":"2022-06-28T13:37:16.382258Z","iopub.status.idle":"2022-06-28T13:37:16.388046Z","shell.execute_reply.started":"2022-06-28T13:37:16.382226Z","shell.execute_reply":"2022-06-28T13:37:16.386669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(l)\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:37:18.44517Z","iopub.execute_input":"2022-06-28T13:37:18.445677Z","iopub.status.idle":"2022-06-28T13:37:18.803025Z","shell.execute_reply.started":"2022-06-28T13:37:18.445639Z","shell.execute_reply":"2022-06-28T13:37:18.802163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlen=80","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:37:23.222757Z","iopub.execute_input":"2022-06-28T13:37:23.223668Z","iopub.status.idle":"2022-06-28T13:37:23.228317Z","shell.execute_reply.started":"2022-06-28T13:37:23.223629Z","shell.execute_reply":"2022-06-28T13:37:23.227223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_messages2 = tok.texts_to_sequences(trn_texts)\n\ntraining_padded = pad_sequences(training_messages2,\n                                maxlen=maxlen, \n                                truncating='post', \n                                padding='post'\n                               )","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:38:20.487353Z","iopub.execute_input":"2022-06-28T13:38:20.488361Z","iopub.status.idle":"2022-06-28T13:38:20.626047Z","shell.execute_reply.started":"2022-06-28T13:38:20.488312Z","shell.execute_reply":"2022-06-28T13:38:20.625102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #tst_texts\ntest_messages = tok.texts_to_sequences(tst_texts)\n\ntest_padded = pad_sequences(test_messages,\n                                maxlen=maxlen, \n                                truncating='post', \n                                padding='post'\n                               )","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:38:22.111645Z","iopub.execute_input":"2022-06-28T13:38:22.112697Z","iopub.status.idle":"2022-06-28T13:38:22.179582Z","shell.execute_reply.started":"2022-06-28T13:38:22.112645Z","shell.execute_reply":"2022-06-28T13:38:22.178701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_padded = np.array(training_padded)\nx_val = training_padded[:1000]\npartial_x_train = training_padded[1000:]\n\ny_val = y_train[:1000]\npartial_y_train = y_train[1000:]\n\nmodel = models.Sequential()\nmodel.add(layers.Embedding(1000, 20, input_length=maxlen))\nmodel.add(layers.Bidirectional(layers.LSTM(50, dropout=0.2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='Adamax',\n    metrics=[metrics.binary_accuracy]\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:46:21.303549Z","iopub.execute_input":"2022-06-28T13:46:21.303914Z","iopub.status.idle":"2022-06-28T13:46:21.719931Z","shell.execute_reply.started":"2022-06-28T13:46:21.303883Z","shell.execute_reply":"2022-06-28T13:46:21.718926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=35,\n                    batch_size=128,\n                    validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:46:23.16797Z","iopub.execute_input":"2022-06-28T13:46:23.168382Z","iopub.status.idle":"2022-06-28T13:46:49.135683Z","shell.execute_reply.started":"2022-06-28T13:46:23.168349Z","shell.execute_reply":"2022-06-28T13:46:49.134604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:46:56.581852Z","iopub.execute_input":"2022-06-28T13:46:56.582239Z","iopub.status.idle":"2022-06-28T13:46:56.788102Z","shell.execute_reply.started":"2022-06-28T13:46:56.582201Z","shell.execute_reply":"2022-06-28T13:46:56.787122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:48:48.2789Z","iopub.execute_input":"2022-06-28T13:48:48.279499Z","iopub.status.idle":"2022-06-28T13:48:48.511032Z","shell.execute_reply.started":"2022-06-28T13:48:48.279451Z","shell.execute_reply":"2022-06-28T13:48:48.510135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Submission File\n","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Embedding(1000, 20, input_length=maxlen))\nmodel.add(layers.Bidirectional(layers.LSTM(50, dropout=0.2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='Adamax',\n    metrics=[metrics.binary_accuracy]\n)\n\n\nmodel.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=15,\n                    batch_size=128,\n                    validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:51:48.390289Z","iopub.execute_input":"2022-06-28T13:51:48.39134Z","iopub.status.idle":"2022-06-28T13:52:00.969076Z","shell.execute_reply.started":"2022-06-28T13:51:48.391287Z","shell.execute_reply":"2022-06-28T13:52:00.968116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = model.predict(test_padded)\nresult[result>=0.5]=1\nresult[result<0.5]=0\nsample_submission=pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\nsample_submission['target']=result\nsample_submission['target']=sample_submission['target'].astype(int)\n#sample_submission.head()\nsample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:53:58.116585Z","iopub.execute_input":"2022-06-28T13:53:58.117045Z","iopub.status.idle":"2022-06-28T13:53:58.652289Z","shell.execute_reply.started":"2022-06-28T13:53:58.117003Z","shell.execute_reply":"2022-06-28T13:53:58.651256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}