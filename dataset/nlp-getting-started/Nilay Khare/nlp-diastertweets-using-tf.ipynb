{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/c/nlp-getting-started : NLP Disaster Tweets\ndf = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape , df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((df.target == 1).sum()) # Disaster\nprint((df.target == 0).sum()) # No Disaster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing\nimport re\nimport string\n\ndef remove_URL(text):\n    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n    return url.sub(r\"\", text)\n\n# https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-from-a-string-in-python-3-x-using-translate/34294022\ndef remove_punct(text):\n    translator = str.maketrans(\"\", \"\", string.punctuation)\n    return text.translate(translator)\n\nstring.punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern = re.compile(r\"https?://(\\S+|www)\\.\\S+\")\nfor t in df.text:\n    matches = pattern.findall(t)\n    for match in matches:\n        print(t)\n        print(match)\n        print(pattern.sub(r\"\", t))\n    if len(matches) > 0:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern = re.compile(r\"https?://(\\S+|www)\\.\\S+\")\nfor t in df_test.text:\n    matches = pattern.findall(t)\n    for match in matches:\n        print(t)\n        print(match)\n        print(pattern.sub(r\"\", t))\n    if len(matches) > 0:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text\"] = df.text.map(remove_URL) # map(lambda x: remove_URL(x))\ndf[\"text\"] = df.text.map(remove_punct)\ndf[\"text\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[\"text\"] = df_test.text.map(remove_URL) # map(lambda x: remove_URL(x))\ndf_test[\"text\"] = df_test.text.map(remove_punct)\ndf_test[\"text\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove stopwords\n# pip install nltk\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\n# Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine\n# has been programmed to ignore, both when indexing entries for searching and when retrieving them \n# as the result of a search query.\nstop = set(stopwords.words(\"english\"))\n\n# https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python\ndef remove_stopwords(text):\n    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n    return \" \".join(filtered_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text\"] = df.text.map(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[\"text\"] = df_test.text.map(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\n# Count unique words\ndef counter_word(text_col):\n    count = Counter()\n    for text in text_col.values:\n        for word in text.split():\n            count[word] += 1\n    return count\n\n\ncounter = counter_word(df.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(counter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter.most_common(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_unique_words = len(counter)\nnum_unique_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split dataset into training and validation set\ntrain_size = int(df.shape[0] * 0.9)\n\ntrain_df = df[:train_size]\nval_df = df[train_size:]\n\n# split text and labels\ntrain_sentences = train_df.text.to_numpy()\ntrain_labels = train_df.target.to_numpy()\nval_sentences = val_df.text.to_numpy()\nval_labels = val_df.target.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentences = df_test.text.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sentences.shape, val_sentences.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentences.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tokenize\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n# vectorize a text corpus by turning each text into a sequence of integers\ntokenizer = Tokenizer(num_words=num_unique_words)\ntokenizer.fit_on_texts(train_sentences) # fit only to training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# each word has unique index\nword_index = tokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(train_sentences)\nval_sequences = tokenizer.texts_to_sequences(val_sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequences = tokenizer.texts_to_sequences(test_sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_sentences[10:15])\nprint(train_sequences[10:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_sentences[10:15])\nprint(test_sequences[10:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pad the sequences to have the same length\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Max number of words in a sequence\nmax_length = 20\n\ntrain_padded = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\nval_padded = pad_sequences(val_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\ntrain_padded.shape, val_padded.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_padded[10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_padded[10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_sentences[10])\nprint(train_sequences[10])\nprint(train_padded[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_sentences[10])\nprint(test_sequences[10])\nprint(test_padded[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check reversing the indices\n\n# flip (key, value)\nreverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode(sequence):\n    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoded_text = decode(train_sequences[10])\n\nprint(train_sequences[10])\nprint(decoded_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoded_text = decode(test_sequences[10])\n\nprint(test_sequences[10])\nprint(decoded_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create LSTM model\nfrom tensorflow.keras import layers\n\n# Embedding: https://www.tensorflow.org/tutorials/text/word_embeddings\n# Turns positive integers (indexes) into dense vectors of fixed size. (other approach could be one-hot-encoding)\n\n# Word embeddings give us a way to use an efficient, dense representation in which similar words have \n# a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a \n# dense vector of floating point values (the length of the vector is a parameter you specify).\n\nmodel = keras.models.Sequential()\nmodel.add(layers.Embedding(num_unique_words, 32, input_length=max_length))\n\n# The layer will take as input an integer matrix of size (batch, input_length),\n# and the largest integer (i.e. word index) in the input should be no larger than num_words (vocabulary size).\n# Now model.output_shape is (None, input_length, 32), where `None` is the batch dimension.\n\n\nmodel.add(layers.LSTM(64, dropout=0.1))\nmodel.add(layers.Dense(1, activation=\"sigmoid\"))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = keras.losses.BinaryCrossentropy(from_logits=False)\noptim = keras.optimizers.Adam(lr=0.001)\nmetrics = [\"accuracy\"]\n\nmodel.compile(loss=loss, optimizer=optim, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.fit(train_padded, train_labels, epochs=20, validation_data=(val_padded, val_labels), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(num_unique_words, 32, input_length=max_length),\n    tf.keras.layers.LSTM(64, dropout=0.1),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n])\nmodel.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])\nbatch_size = 50\nmax_epochs = 20\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience = 3)\nmodel.fit(train_padded,\n         train_labels,\n         batch_size = batch_size,\n         epochs = max_epochs,\n         callbacks = [early_stopping],\n          validation_data = (val_padded, val_labels),\n          verbose = 2\n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(train_padded)\npredictions = [1 if p > 0.5 else 0 for p in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_sentences[10:20])\n\nprint(train_labels[10:20])\nprint(predictions[10:20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_padded)\npredictions = [1 if p > 0.5 else 0 for p in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_sentences[0])\nprint(predictions[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"id\": df_test[\"id\"],\n        \"target\": predictions\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}