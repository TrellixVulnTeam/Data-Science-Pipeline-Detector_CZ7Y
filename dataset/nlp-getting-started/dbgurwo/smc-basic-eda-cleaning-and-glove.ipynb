{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing required Libraries.  \n*필요한 라이브러리 가져오기*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:09.719474Z","iopub.execute_input":"2022-05-28T02:18:09.719772Z","iopub.status.idle":"2022-05-28T02:18:09.730044Z","shell.execute_reply.started":"2022-05-28T02:18:09.719719Z","shell.execute_reply":"2022-05-28T02:18:09.728965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n#os.listdir('../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:09.759254Z","iopub.execute_input":"2022-05-28T02:18:09.75948Z","iopub.status.idle":"2022-05-28T02:18:09.763054Z","shell.execute_reply.started":"2022-05-28T02:18:09.759437Z","shell.execute_reply":"2022-05-28T02:18:09.762148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data and getting basic idea  \n*데이터 로드 및 기본 아이디어 얻기*","metadata":{}},{"cell_type":"code","source":"tweet= pd.read_csv('../input/nlp-getting-started/train.csv')\ntest=pd.read_csv('../input/nlp-getting-started/test.csv')\ntweet.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:09.799Z","iopub.execute_input":"2022-05-28T02:18:09.799219Z","iopub.status.idle":"2022-05-28T02:18:09.840398Z","shell.execute_reply.started":"2022-05-28T02:18:09.799177Z","shell.execute_reply":"2022-05-28T02:18:09.839814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('There are {} rows and {} columns in train'.format(tweet.shape[0],tweet.shape[1]))\nprint('There are {} rows and {} columns in train'.format(test.shape[0],test.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:09.848911Z","iopub.execute_input":"2022-05-28T02:18:09.84913Z","iopub.status.idle":"2022-05-28T02:18:09.854595Z","shell.execute_reply.started":"2022-05-28T02:18:09.849089Z","shell.execute_reply":"2022-05-28T02:18:09.853792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Columns  \n`id` - a unique identifier for each tweet  \n`text` - the text of the tweet    \n`location` - the location the tweet was sent from (may be blank)  \n`keyword` - a particular keyword from the tweet (may be blank)  \n`target` - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)","metadata":{}},{"cell_type":"markdown","source":"## Class distribution  \n*클래스 분포*","metadata":{}},{"cell_type":"markdown","source":"Before we begin with anything else,let's check the class distribution.There are only two classes 0 and 1.  \n*다른 작업을 시작하기 전에 클래스 분포를 확인하겠습니다. 클래스 0과 1만 두 개 있습니다.*","metadata":{}},{"cell_type":"code","source":"x=tweet.target.value_counts()\nsns.barplot(x.index,x)\nplt.gca().set_ylabel('samples')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:09.904433Z","iopub.execute_input":"2022-05-28T02:18:09.904667Z","iopub.status.idle":"2022-05-28T02:18:10.100644Z","shell.execute_reply.started":"2022-05-28T02:18:09.904623Z","shell.execute_reply":"2022-05-28T02:18:10.099609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are more tweets with class 0 ( No disaster) than class 1 ( disaster tweets).  \n*클래스 1(재해 트윗)보다 클래스 0(재해 없음)의 트윗이 더 많습니다.*","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis of tweets  \n*트윗의 탐색적 데이터 분석*","metadata":{}},{"cell_type":"markdown","source":"First,we will do very basic analysis,that is character level,word level and sentence level analysis.  \n*먼저 문자 수준, 단어 수준 및 문장 수준 분석인 매우 기본적인 분석을 수행합니다.*","metadata":{}},{"cell_type":"markdown","source":"### Number of characters in tweets  \n*트윗의 문자 수*","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=tweet[tweet['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster tweets')\ntweet_len=tweet[tweet['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Characters in tweets')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:10.106034Z","iopub.execute_input":"2022-05-28T02:18:10.106472Z","iopub.status.idle":"2022-05-28T02:18:10.573599Z","shell.execute_reply.started":"2022-05-28T02:18:10.106308Z","shell.execute_reply":"2022-05-28T02:18:10.571485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of both seems to be almost same.120 t0 140 characters in a tweet are the most common among both.  \n*둘의 분포는 거의 같은 것 같습니다. 120 ~ 140 트윗의 문자가 둘 중 가장 일반적입니다.*","metadata":{}},{"cell_type":"markdown","source":"### Number of words in a tweet  \n*트윗의 단어 수*","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=tweet[tweet['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster tweets')\ntweet_len=tweet[tweet['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Words in a tweet')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:10.578259Z","iopub.execute_input":"2022-05-28T02:18:10.580583Z","iopub.status.idle":"2022-05-28T02:18:11.057557Z","shell.execute_reply.started":"2022-05-28T02:18:10.580515Z","shell.execute_reply":"2022-05-28T02:18:11.05653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Average word length in a tweet  \n\n*트윗의 평균 단어 길이*","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword=tweet[tweet['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\nax1.set_title('disaster')\nword=tweet[tweet['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\nax2.set_title('Not disaster')\nfig.suptitle('Average word length in each tweet')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:11.0623Z","iopub.execute_input":"2022-05-28T02:18:11.062894Z","iopub.status.idle":"2022-05-28T02:18:12.303655Z","shell.execute_reply.started":"2022-05-28T02:18:11.062799Z","shell.execute_reply":"2022-05-28T02:18:12.302615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_corpus(target):\n    corpus=[]\n    \n    for x in tweet[tweet['target']==target]['text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:12.31195Z","iopub.execute_input":"2022-05-28T02:18:12.312711Z","iopub.status.idle":"2022-05-28T02:18:12.321744Z","shell.execute_reply.started":"2022-05-28T02:18:12.312372Z","shell.execute_reply":"2022-05-28T02:18:12.320658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Common stopwords in tweets  \n*트윗의 일반적인 불용어*","metadata":{}},{"cell_type":"markdown","source":"First we  will analyze tweets with class 0.  \n*먼저 클래스 0의 트윗을 분석합니다.*","metadata":{}},{"cell_type":"code","source":"corpus=create_corpus(0)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n        \ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:12.326861Z","iopub.execute_input":"2022-05-28T02:18:12.327466Z","iopub.status.idle":"2022-05-28T02:18:12.377114Z","shell.execute_reply.started":"2022-05-28T02:18:12.327253Z","shell.execute_reply":"2022-05-28T02:18:12.376314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y=zip(*top)\nplt.bar(x,y)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:12.380311Z","iopub.execute_input":"2022-05-28T02:18:12.380547Z","iopub.status.idle":"2022-05-28T02:18:12.700532Z","shell.execute_reply.started":"2022-05-28T02:18:12.380503Z","shell.execute_reply":"2022-05-28T02:18:12.698751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now,we will analyze tweets with class 1.  \n*이제 클래스 1로 트윗을 분석하겠습니다.*","metadata":{}},{"cell_type":"code","source":"corpus=create_corpus(1)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n\ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n    \n\n\nx,y=zip(*top)\nplt.bar(x,y)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:12.702187Z","iopub.execute_input":"2022-05-28T02:18:12.702738Z","iopub.status.idle":"2022-05-28T02:18:13.049531Z","shell.execute_reply.started":"2022-05-28T02:18:12.702547Z","shell.execute_reply":"2022-05-28T02:18:13.048522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In both of them,\"the\" dominates which is followed by \"a\" in class 0 and \"in\" in class 1.  \n*둘 다 \"the\"가 지배적이며 클래스 0에서는 \"a\"가, 클래스 1에서는 \"in\"이 뒤따릅니다.*","metadata":{}},{"cell_type":"markdown","source":"### Analyzing punctuations.\n*구두점 분석.*","metadata":{}},{"cell_type":"markdown","source":"First let's check tweets indicating real disaster.  \n*먼저 실제 재난을 나타내는 트윗을 확인합시다.*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\ncorpus=create_corpus(1)\n\ndic=defaultdict(int)\nimport string\nspecial = string.punctuation\nfor i in (corpus):\n    if i in special:\n        dic[i]+=1\n        \nx,y=zip(*dic.items())\nplt.bar(x,y)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:13.055037Z","iopub.execute_input":"2022-05-28T02:18:13.055606Z","iopub.status.idle":"2022-05-28T02:18:13.655107Z","shell.execute_reply.started":"2022-05-28T02:18:13.055434Z","shell.execute_reply":"2022-05-28T02:18:13.654242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now,we will move on to class 0.  \n*이제 클래스 0으로 넘어갑니다.*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\ncorpus=create_corpus(0)\n\ndic=defaultdict(int)\nimport string\nspecial = string.punctuation\nfor i in (corpus):\n    if i in special:\n        dic[i]+=1\n        \nx,y=zip(*dic.items())\nplt.bar(x,y,color='green')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:13.656448Z","iopub.execute_input":"2022-05-28T02:18:13.656872Z","iopub.status.idle":"2022-05-28T02:18:14.110796Z","shell.execute_reply.started":"2022-05-28T02:18:13.656728Z","shell.execute_reply":"2022-05-28T02:18:14.109305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Common words  \n*흔한 단어*","metadata":{}},{"cell_type":"code","source":"\ncounter=Counter(corpus)\nmost=counter.most_common()\nx=[]\ny=[]\nfor word,count in most[:40]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:14.112211Z","iopub.execute_input":"2022-05-28T02:18:14.112503Z","iopub.status.idle":"2022-05-28T02:18:14.153058Z","shell.execute_reply.started":"2022-05-28T02:18:14.112452Z","shell.execute_reply":"2022-05-28T02:18:14.152123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=y,y=x)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:14.15669Z","iopub.execute_input":"2022-05-28T02:18:14.156968Z","iopub.status.idle":"2022-05-28T02:18:14.426722Z","shell.execute_reply.started":"2022-05-28T02:18:14.156921Z","shell.execute_reply":"2022-05-28T02:18:14.425902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lot of cleaning needed.  \n많은 청소가 필요합니다.","metadata":{}},{"cell_type":"markdown","source":"### Ngram analysis  \n*Ngram 분석*","metadata":{}},{"cell_type":"markdown","source":"we will do a bigram (n=2) analysis over the tweets.Let's check the most common bigrams in tweets.  \n*우리는 트윗에 대해 bigram(n=2) 분석을 수행할 것입니다. 트윗에서 가장 일반적인 bigram을 확인합시다.*","metadata":{}},{"cell_type":"code","source":"def get_top_tweet_bigrams(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:14.428018Z","iopub.execute_input":"2022-05-28T02:18:14.42846Z","iopub.status.idle":"2022-05-28T02:18:14.436753Z","shell.execute_reply.started":"2022-05-28T02:18:14.428406Z","shell.execute_reply":"2022-05-28T02:18:14.435878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\ntop_tweet_bigrams=get_top_tweet_bigrams(tweet['text'])[:10]\nx,y=map(list,zip(*top_tweet_bigrams))\nsns.barplot(x=y,y=x)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:14.438198Z","iopub.execute_input":"2022-05-28T02:18:14.438739Z","iopub.status.idle":"2022-05-28T02:18:15.531168Z","shell.execute_reply.started":"2022-05-28T02:18:14.438689Z","shell.execute_reply":"2022-05-28T02:18:15.530171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will need lot of cleaning here..  \n*여기 청소가 많이 필요합니다..*","metadata":{}},{"cell_type":"markdown","source":"## Data Cleaning  \n*데이터 정리*\n\nAs we know,twitter tweets always have to be cleaned before we go onto modelling.So we will do some basic cleaning such as spelling correction,removing punctuations,removing html tags and emojis etc.\n\n알다시피, 트위터 트윗은 모델링을 시작하기 전에 항상 정리해야 합니다. 따라서 맞춤법 수정, 구두점 제거, html 태그 및 이모티콘 제거 등과 같은 기본적인 정리 작업을 수행하겠습니다.","metadata":{}},{"cell_type":"code","source":"df=pd.concat([tweet,test])\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.5358Z","iopub.execute_input":"2022-05-28T02:18:15.536242Z","iopub.status.idle":"2022-05-28T02:18:15.56035Z","shell.execute_reply.started":"2022-05-28T02:18:15.536084Z","shell.execute_reply":"2022-05-28T02:18:15.559188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing urls  \n*URL 제거*","metadata":{}},{"cell_type":"code","source":"example=\"New competition launched :https://www.kaggle.com/c/nlp-getting-started\"","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.565486Z","iopub.execute_input":"2022-05-28T02:18:15.568405Z","iopub.status.idle":"2022-05-28T02:18:15.574033Z","shell.execute_reply.started":"2022-05-28T02:18:15.565745Z","shell.execute_reply":"2022-05-28T02:18:15.572038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\nremove_URL(example)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.575706Z","iopub.execute_input":"2022-05-28T02:18:15.576386Z","iopub.status.idle":"2022-05-28T02:18:15.591482Z","shell.execute_reply.started":"2022-05-28T02:18:15.576093Z","shell.execute_reply":"2022-05-28T02:18:15.590295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x : remove_URL(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.593691Z","iopub.execute_input":"2022-05-28T02:18:15.594337Z","iopub.status.idle":"2022-05-28T02:18:15.650666Z","shell.execute_reply.started":"2022-05-28T02:18:15.593974Z","shell.execute_reply":"2022-05-28T02:18:15.650045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing HTML tags  \n\n*HTML 태그 제거*","metadata":{}},{"cell_type":"code","source":"example = \"\"\"<div>\n<h1>Real or Fake</h1>\n<p>Kaggle </p>\n<a href=\"https://www.kaggle.com/c/nlp-getting-started\">getting started</a>\n</div>\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.652163Z","iopub.execute_input":"2022-05-28T02:18:15.652646Z","iopub.status.idle":"2022-05-28T02:18:15.65671Z","shell.execute_reply.started":"2022-05-28T02:18:15.652537Z","shell.execute_reply":"2022-05-28T02:18:15.655778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\nprint(remove_html(example))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.658609Z","iopub.execute_input":"2022-05-28T02:18:15.659119Z","iopub.status.idle":"2022-05-28T02:18:15.666237Z","shell.execute_reply.started":"2022-05-28T02:18:15.658875Z","shell.execute_reply":"2022-05-28T02:18:15.665242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x : remove_html(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.667962Z","iopub.execute_input":"2022-05-28T02:18:15.668416Z","iopub.status.idle":"2022-05-28T02:18:15.694904Z","shell.execute_reply.started":"2022-05-28T02:18:15.668221Z","shell.execute_reply":"2022-05-28T02:18:15.694342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Romoving Emojis  \n\n*이모티콘 제거*","metadata":{}},{"cell_type":"code","source":"# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\nremove_emoji(\"Omg another Earthquake 😔😔\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.696458Z","iopub.execute_input":"2022-05-28T02:18:15.696855Z","iopub.status.idle":"2022-05-28T02:18:15.704023Z","shell.execute_reply.started":"2022-05-28T02:18:15.696692Z","shell.execute_reply":"2022-05-28T02:18:15.702905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x: remove_emoji(x))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.706002Z","iopub.execute_input":"2022-05-28T02:18:15.706512Z","iopub.status.idle":"2022-05-28T02:18:15.790588Z","shell.execute_reply.started":"2022-05-28T02:18:15.706266Z","shell.execute_reply":"2022-05-28T02:18:15.789926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing punctuations  \n*구두점 제거*","metadata":{}},{"cell_type":"code","source":"def remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)\n\nexample=\"I am a #king\"\nprint(remove_punct(example))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.792681Z","iopub.execute_input":"2022-05-28T02:18:15.793173Z","iopub.status.idle":"2022-05-28T02:18:15.799159Z","shell.execute_reply.started":"2022-05-28T02:18:15.793126Z","shell.execute_reply":"2022-05-28T02:18:15.798212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x : remove_punct(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:15.800902Z","iopub.execute_input":"2022-05-28T02:18:15.801434Z","iopub.status.idle":"2022-05-28T02:18:15.865616Z","shell.execute_reply.started":"2022-05-28T02:18:15.801135Z","shell.execute_reply":"2022-05-28T02:18:15.864941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Spelling Correction  \n*맞춤법 수정*\n","metadata":{}},{"cell_type":"markdown","source":"Even if I'm not good at spelling I can correct it with python, I will use `pyspellcheker` to do that.  \n*철자를 잘 못써도 python으로 고칠 수 있어요, 'pyspellcheker'를 사용해서 수정하겠습니다*","metadata":{}},{"cell_type":"markdown","source":"### `pyspellcheker`  \nPure Python Spell Checking based on Peter Norvig’s blog post on setting up a simple spell checking algorithm.  \n*간단한 맞춤법 검사 알고리즘 설정에 대한 Peter Norvig의 블로그 게시물을 기반으로 하는 순수 Python 맞춤법 검사입니다.*\n\nIt uses a Levenshtein Distance algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are more likely the correct results.\n\n*Levenshtein Distance 알고리즘을 사용하여 원래 단어에서 2 편집 거리 내에서 순열을 찾습니다. 그런 다음 모든 순열(삽입, 삭제, 대체 및 전치)을 단어 빈도 목록의 알려진 단어와 비교합니다. 빈도 목록에서 더 자주 발견되는 단어가 올바른 결과일 가능성이 더 큽니다.*  \n\n*(https://pypi.org/project/pyspellchecker/)*","metadata":{}},{"cell_type":"code","source":"!pip install pyspellchecker","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-28T02:18:15.867038Z","iopub.execute_input":"2022-05-28T02:18:15.867577Z","iopub.status.idle":"2022-05-28T02:18:20.805814Z","shell.execute_reply.started":"2022-05-28T02:18:15.867283Z","shell.execute_reply":"2022-05-28T02:18:20.805017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spellchecker import SpellChecker\n\nspell = SpellChecker()\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)\n        \ntext = \"corect me plese\"\ncorrect_spellings(text)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:20.809116Z","iopub.execute_input":"2022-05-28T02:18:20.809397Z","iopub.status.idle":"2022-05-28T02:18:20.95507Z","shell.execute_reply.started":"2022-05-28T02:18:20.809341Z","shell.execute_reply":"2022-05-28T02:18:20.953959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df['text']=df['text'].apply(lambda x : correct_spellings(x)#)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:20.956509Z","iopub.execute_input":"2022-05-28T02:18:20.956945Z","iopub.status.idle":"2022-05-28T02:18:20.960885Z","shell.execute_reply.started":"2022-05-28T02:18:20.956756Z","shell.execute_reply":"2022-05-28T02:18:20.959937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GloVe for Vectorization  \n\n*벡터화를 위한 GloV*","metadata":{}},{"cell_type":"markdown","source":"### `GloVe` : Global Vectors for Word Representation  \nGloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.  \n*GloVe는 단어에 대한 벡터 표현을 얻기 위한 비지도 학습 알고리즘입니다. 훈련은 말뭉치에서 집계된 전역 단어 단어 동시 발생 통계에 대해 수행되며 결과 표현은 단어 벡터 공간의 흥미로운 선형 하위 구조를 보여줍니다.*  \n*(https://nlp.stanford.edu/pubs/glove.pdf)*","metadata":{}},{"cell_type":"markdown","source":"Here we will use GloVe pretrained corpus model to represent our words.It is available in 3 varieties :50D ,100D and 200 Dimentional.We will try 100 D here.  \n*여기에서는 GloVe 사전 훈련된 말뭉치 모델을 사용하여 단어를 표현합니다. 50D, 100D 및 200 Dimentional의 3가지 종류가 있습니다. 여기서는 100D를 시도하겠습니다.*","metadata":{}},{"cell_type":"code","source":"\ndef create_corpus(df):\n    corpus=[]\n    for tweet in tqdm(df['text']):\n        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n        corpus.append(words)\n    return corpus\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:20.962493Z","iopub.execute_input":"2022-05-28T02:18:20.963019Z","iopub.status.idle":"2022-05-28T02:18:20.972137Z","shell.execute_reply.started":"2022-05-28T02:18:20.962926Z","shell.execute_reply":"2022-05-28T02:18:20.971018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus=create_corpus(df)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:20.973653Z","iopub.execute_input":"2022-05-28T02:18:20.974258Z","iopub.status.idle":"2022-05-28T02:18:23.486944Z","shell.execute_reply.started":"2022-05-28T02:18:20.974136Z","shell.execute_reply":"2022-05-28T02:18:23.486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dict={}\nwith open('../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt','r') as f:\n    for line in f:\n        values=line.split()\n        word=values[0]\n        vectors=np.asarray(values[1:],'float32')\n        embedding_dict[word]=vectors\nf.close()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:23.488214Z","iopub.execute_input":"2022-05-28T02:18:23.488517Z","iopub.status.idle":"2022-05-28T02:18:41.376663Z","shell.execute_reply.started":"2022-05-28T02:18:23.488471Z","shell.execute_reply":"2022-05-28T02:18:41.375929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN=50\ntokenizer_obj=Tokenizer()\ntokenizer_obj.fit_on_texts(corpus)\nsequences=tokenizer_obj.texts_to_sequences(corpus)\n\ntweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:41.381689Z","iopub.execute_input":"2022-05-28T02:18:41.381943Z","iopub.status.idle":"2022-05-28T02:18:41.654363Z","shell.execute_reply.started":"2022-05-28T02:18:41.381898Z","shell.execute_reply":"2022-05-28T02:18:41.653652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_index=tokenizer_obj.word_index\nprint('Number of unique words:',len(word_index))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:41.656941Z","iopub.execute_input":"2022-05-28T02:18:41.657392Z","iopub.status.idle":"2022-05-28T02:18:41.663836Z","shell.execute_reply.started":"2022-05-28T02:18:41.65734Z","shell.execute_reply":"2022-05-28T02:18:41.663166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_words=len(word_index)+1\nembedding_matrix=np.zeros((num_words,100))\n\nfor word,i in tqdm(word_index.items()):\n    if i > num_words:\n        continue\n    \n    emb_vec=embedding_dict.get(word)\n    if emb_vec is not None:\n        embedding_matrix[i]=emb_vec\n            ","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:41.665469Z","iopub.execute_input":"2022-05-28T02:18:41.666383Z","iopub.status.idle":"2022-05-28T02:18:41.736617Z","shell.execute_reply.started":"2022-05-28T02:18:41.666342Z","shell.execute_reply":"2022-05-28T02:18:41.735815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline Model  \n*기준 모델*","metadata":{}},{"cell_type":"code","source":"model=Sequential()\n\nembedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix),\n                   input_length=MAX_LEN,trainable=False)\n\nmodel.add(embedding)\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\noptimzer=Adam(learning_rate=1e-5)\n\nmodel.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:41.737962Z","iopub.execute_input":"2022-05-28T02:18:41.738393Z","iopub.status.idle":"2022-05-28T02:18:42.03689Z","shell.execute_reply.started":"2022-05-28T02:18:41.73821Z","shell.execute_reply":"2022-05-28T02:18:42.036148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:42.038223Z","iopub.execute_input":"2022-05-28T02:18:42.038536Z","iopub.status.idle":"2022-05-28T02:18:42.046532Z","shell.execute_reply.started":"2022-05-28T02:18:42.03849Z","shell.execute_reply":"2022-05-28T02:18:42.045549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=tweet_pad[:tweet.shape[0]]\ntest=tweet_pad[tweet.shape[0]:]","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:42.047968Z","iopub.execute_input":"2022-05-28T02:18:42.048456Z","iopub.status.idle":"2022-05-28T02:18:42.055165Z","shell.execute_reply.started":"2022-05-28T02:18:42.048402Z","shell.execute_reply":"2022-05-28T02:18:42.054144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(train,tweet['target'].values,test_size=0.15)\nprint('Shape of train',X_train.shape)\nprint(\"Shape of Validation \",X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:18:42.056695Z","iopub.execute_input":"2022-05-28T02:18:42.057272Z","iopub.status.idle":"2022-05-28T02:18:42.067881Z","shell.execute_reply.started":"2022-05-28T02:18:42.057223Z","shell.execute_reply":"2022-05-28T02:18:42.067179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}