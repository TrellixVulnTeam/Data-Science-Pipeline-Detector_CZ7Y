{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-19T10:09:57.474807Z","iopub.status.idle":"2021-10-19T10:09:57.47527Z","shell.execute_reply.started":"2021-10-19T10:09:57.475001Z","shell.execute_reply":"2021-10-19T10:09:57.475027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 불러오기\n- 데이터를 불러오도록 한다. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \ntrain = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nprint('Data Loading is done!')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:10:06.383905Z","iopub.execute_input":"2021-10-19T10:10:06.384202Z","iopub.status.idle":"2021-10-19T10:10:06.45141Z","shell.execute_reply.started":"2021-10-19T10:10:06.384171Z","shell.execute_reply":"2021-10-19T10:10:06.45064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:10:11.96987Z","iopub.execute_input":"2021-10-19T10:10:11.970661Z","iopub.status.idle":"2021-10-19T10:10:11.991584Z","shell.execute_reply.started":"2021-10-19T10:10:11.970609Z","shell.execute_reply":"2021-10-19T10:10:11.990799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:10:28.732727Z","iopub.execute_input":"2021-10-19T10:10:28.733002Z","iopub.status.idle":"2021-10-19T10:10:28.738611Z","shell.execute_reply.started":"2021-10-19T10:10:28.732975Z","shell.execute_reply":"2021-10-19T10:10:28.73768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.info())","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:10:39.344496Z","iopub.execute_input":"2021-10-19T10:10:39.345277Z","iopub.status.idle":"2021-10-19T10:10:39.369862Z","shell.execute_reply.started":"2021-10-19T10:10:39.345227Z","shell.execute_reply":"2021-10-19T10:10:39.368867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.info())","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:10:57.647797Z","iopub.execute_input":"2021-10-19T10:10:57.649417Z","iopub.status.idle":"2021-10-19T10:10:57.669662Z","shell.execute_reply.started":"2021-10-19T10:10:57.649367Z","shell.execute_reply":"2021-10-19T10:10:57.668787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.head())","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:11:07.996299Z","iopub.execute_input":"2021-10-19T10:11:07.996681Z","iopub.status.idle":"2021-10-19T10:11:08.004301Z","shell.execute_reply.started":"2021-10-19T10:11:07.996644Z","shell.execute_reply":"2021-10-19T10:11:08.003455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA (Exploratory Data Analysis)\n- Target 데이터에 대해 시각화를 해보도록 한다. ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(train['target'].value_counts())\nnews_class = train['target'].value_counts()\nlabels = ['Non-Disaster', 'Disaster']\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.bar(labels, news_class, color=['green', 'orange'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:13:33.720635Z","iopub.execute_input":"2021-10-19T10:13:33.7209Z","iopub.status.idle":"2021-10-19T10:13:34.57883Z","shell.execute_reply.started":"2021-10-19T10:13:33.720872Z","shell.execute_reply":"2021-10-19T10:13:34.578041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Non Disaster 데이터와 Disaster 데이터를 비교해본다.\n- 전체적으로 진짜 재난 뉴스의 데이터의 평균적인 길이가 길어보이는 경향이 있다. ","metadata":{}},{"cell_type":"code","source":"disaster_tweet_len = train[train['target']==1]['text'].str.len()\nnon_disaster_tweet_len = train[train['target']==0]['text'].str.len()\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))\nax[0].hist(disaster_tweet_len, color='green')\nax[0].set_title(\"Disaster Tweet Length\")\n\nax[1].hist(non_disaster_tweet_len, color='orange')\nax[1].set_title(\"Non Disaster Tweet Length\")\n\nfig.suptitle('All words in Tweets')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:16:15.930994Z","iopub.execute_input":"2021-10-19T10:16:15.931559Z","iopub.status.idle":"2021-10-19T10:16:16.393694Z","shell.execute_reply.started":"2021-10-19T10:16:15.931519Z","shell.execute_reply":"2021-10-19T10:16:16.392957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 6))\nax[0].boxplot(disaster_tweet_len, labels=['counts'], showmeans=True)\nax[0].set_title(\"Disaster Tweet Length\")\n\nax[1].boxplot(non_disaster_tweet_len, labels=['counts'], showmeans=True)\nax[1].set_title(\"Non Disaster Tweet Length\")\n\nfig.suptitle('All words in Tweets')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:19:44.820019Z","iopub.execute_input":"2021-10-19T10:19:44.820743Z","iopub.status.idle":"2021-10-19T10:19:45.094664Z","shell.execute_reply.started":"2021-10-19T10:19:44.820706Z","shell.execute_reply":"2021-10-19T10:19:45.09395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndisaster_tweet_len = train[train['target']==1]['text'].str.len()\nnon_disaster_tweet_len = train[train['target']==0]['text'].str.len()\n\nprint(\"Max Length of Disaster Tweet: {}\".format(np.max(disaster_tweet_len)))\nprint(\"Min Length of Disaster Tweet: {}\".format(np.min(disaster_tweet_len)))\nprint(\"Mean Length of Disaster Tweet: {:.2f}\".format(np.mean(disaster_tweet_len)))\nprint(\"Median Length of Disaster Tweet: {}\".format(np.median(disaster_tweet_len)))\n\nprint(\"Max Length of Non Disaster Tweet: {}\".format(np.max(non_disaster_tweet_len)))\nprint(\"Min Length of Non Disaster Tweet: {}\".format(np.min(non_disaster_tweet_len)))\nprint(\"Mean Length of Non Disaster Tweet: {:.2f}\".format(np.mean(non_disaster_tweet_len)))\nprint(\"Median Length of Non Disaster Tweet: {}\".format(np.median(non_disaster_tweet_len)))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:19:53.562735Z","iopub.execute_input":"2021-10-19T10:19:53.563003Z","iopub.status.idle":"2021-10-19T10:19:53.586489Z","shell.execute_reply.started":"2021-10-19T10:19:53.562974Z","shell.execute_reply":"2021-10-19T10:19:53.585783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 실제 주요 키워드를 보면 차이점이 있어 보인다. \n    + Disaster Tweet: Outbreak, wreckage\n    + Non Disaster Tweet:body%20bags, ","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\ndisaster_tweet_keywords = dict(train[train['target']==1]['keyword'].value_counts())\nnon_disaster_tweet_keywords = dict(train[train['target']==0]['keyword'].value_counts())\n\nstopwords = set(STOPWORDS)\ndisaster_wordcloud = WordCloud(stopwords=stopwords, width=800, height=400, background_color=\"white\").\\\ngenerate_from_frequencies(disaster_tweet_keywords)\nnon_disaster_wordcloud = WordCloud(stopwords=stopwords, width=800, height=400, background_color=\"white\").\\\ngenerate_from_frequencies(non_disaster_tweet_keywords)\n\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 10))\nax[0].imshow(disaster_wordcloud, interpolation='bilinear')\nax[0].axis('off')\nax[0].set_title(\"Disaster Tweet\")\nax[1].imshow(non_disaster_wordcloud, interpolation='bilinear')\nax[1].axis('off')\nax[1].set_title(\"Non Disaster Tweet\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:20:02.46724Z","iopub.execute_input":"2021-10-19T10:20:02.467498Z","iopub.status.idle":"2021-10-19T10:20:04.636292Z","shell.execute_reply.started":"2021-10-19T10:20:02.46747Z","shell.execute_reply":"2021-10-19T10:20:04.635611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### 결측치 확인\n- 텍스트에는 결측치가 존재하지 않음","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndef check_na(data):\n  isnull_na = (data.isnull().sum() / len(data)) * 100\n  data_na = isnull_na.drop(isnull_na[isnull_na == 0].index).sort_values(ascending=False)\n  missing_data = pd.DataFrame({'Missing Ratio': data_na, \n                               'Data Type': data.dtypes[data_na.index]})\n  print(\"결측치 데이터 컬럼과 건수:\\n\", missing_data)\n\ncheck_na(train)\ncheck_na(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:25:27.31623Z","iopub.execute_input":"2021-10-19T10:25:27.316823Z","iopub.status.idle":"2021-10-19T10:25:27.341855Z","shell.execute_reply.started":"2021-10-19T10:25:27.316783Z","shell.execute_reply":"2021-10-19T10:25:27.340989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 모델링에 필요 없는 변수들은 제거하였다. ","metadata":{}},{"cell_type":"code","source":"test_id = test['id']\n\nfor datas in [train, test]:\n  datas = datas.drop(['id', 'keyword', 'location'], axis=1, inplace=True)\n\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:26:58.032904Z","iopub.execute_input":"2021-10-19T10:26:58.033203Z","iopub.status.idle":"2021-10-19T10:26:58.042157Z","shell.execute_reply.started":"2021-10-19T10:26:58.03317Z","shell.execute_reply":"2021-10-19T10:26:58.041509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text Cleansing\n- HTML 태그 제거\n- 특수문자 공백으로 바꾸기\n- 대문자 소문자로 바꾼 후, 리스트로 만들기\n- 불용어 제거하기","metadata":{}},{"cell_type":"markdown","source":"#### remove_url\n- url만 제거하는 함수를 만든다. ","metadata":{}},{"cell_type":"code","source":"import re\n\ndef remove_url(text):\n  url = re.compile(r'https?://\\S+|www\\.\\S+')\n  return url.sub(r'', text)\n\nsample_text = \"새로운 캐글 대회가 열렸습니다. 주소: https://www.kaggle.com/c/nlp-getting-started\"\nremove_url(sample_text)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:33:06.801549Z","iopub.execute_input":"2021-10-19T10:33:06.801826Z","iopub.status.idle":"2021-10-19T10:33:06.808584Z","shell.execute_reply.started":"2021-10-19T10:33:06.801796Z","shell.execute_reply":"2021-10-19T10:33:06.807473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### remove_html\n- 이번에는 html 코드를 제거하는 정규표현식을 확인하고, 실제 html 태그가 없어지는지 확인한다. ","metadata":{}},{"cell_type":"code","source":"def remove_html(text):\n  html = re.compile(r'<.*?>')\n  return html.sub(r'', text)\n\nsample_text =\"\"\"<div>\n<h1> Real News or Fake News </h1>\n<p> Kaggle Machine Learning </p>\n</div>\"\"\"\n\nprint(remove_html(sample_text))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:37:14.22029Z","iopub.execute_input":"2021-10-19T10:37:14.220782Z","iopub.status.idle":"2021-10-19T10:37:14.227907Z","shell.execute_reply.started":"2021-10-19T10:37:14.220747Z","shell.execute_reply":"2021-10-19T10:37:14.226785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### remove_emoji\n- 이번에는 텍스트에 있는 emoji를 제거하는 코드를 작성한다.  \n","metadata":{}},{"cell_type":"code","source":"!pip install emoji --upgrade","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:39:25.855868Z","iopub.execute_input":"2021-10-19T10:39:25.856152Z","iopub.status.idle":"2021-10-19T10:39:34.400635Z","shell.execute_reply.started":"2021-10-19T10:39:25.856103Z","shell.execute_reply":"2021-10-19T10:39:34.399809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import emoji\nprint(emoji.emojize('Phd is very easy!!! :thumbs_up:'))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:49:37.168244Z","iopub.execute_input":"2021-10-19T10:49:37.168806Z","iopub.status.idle":"2021-10-19T10:49:37.206257Z","shell.execute_reply.started":"2021-10-19T10:49:37.168767Z","shell.execute_reply":"2021-10-19T10:49:37.205568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_emoji(text):\n  emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n  return emoji_pattern.sub(r'', text)\n\nremove_emoji(\"Hello, 👍\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:49:46.616873Z","iopub.execute_input":"2021-10-19T10:49:46.617224Z","iopub.status.idle":"2021-10-19T10:49:46.629625Z","shell.execute_reply.started":"2021-10-19T10:49:46.61719Z","shell.execute_reply":"2021-10-19T10:49:46.626321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove Special Letters\n- 기존 특수 문자는 제거하는 함수를 작성한다. ","metadata":{}},{"cell_type":"code","source":"def remove_punct(text):\n  return re.sub(\"[^a-zA-Z]\", \" \", text)\n\nsample_text = \"Hello!, Can I have one question?.., Is it #Outbreak?\"\nremove_punct(sample_text)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:55:12.680802Z","iopub.execute_input":"2021-10-19T10:55:12.681072Z","iopub.status.idle":"2021-10-19T10:55:12.687076Z","shell.execute_reply.started":"2021-10-19T10:55:12.681041Z","shell.execute_reply":"2021-10-19T10:55:12.686398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 불용어 제거\n- 불용어를 제거하기 위해서는 별도의 라이브러리가 필요하다. ","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nprint(\"Total Length of stopwords:\", len(stopwords.words('english')))\nprint(stopwords.words('english')[:10])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:58:18.049346Z","iopub.execute_input":"2021-10-19T10:58:18.049807Z","iopub.status.idle":"2021-10-19T10:58:18.742511Z","shell.execute_reply.started":"2021-10-19T10:58:18.049769Z","shell.execute_reply":"2021-10-19T10:58:18.741795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### data cleansing \n- 데이터 전처리를 전체 함수를 작성한다. ","metadata":{}},{"cell_type":"code","source":"import string\nimport re\nfrom nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\n\ndef data_cleansing(text, remove_stopwords = False):\n  # remove url \n  url = re.compile(r'https?://\\S+|www\\.\\S+')\n  cleaned_text = url.sub(r'', text)\n\n  # remove html\n  html = re.compile(r'<.*?>')\n  cleaned_text = html.sub(r'', cleaned_text)\n\n  # remove emoji\n  emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n  cleaned_text = emoji_pattern.sub(r'', cleaned_text)\n\n  # Special Letters to empty space\n  cleaned_text = re.sub(\"[^a-zA-Z]\", \" \", cleaned_text)\n\n  # Lowercase\n  cleaned_text = cleaned_text.lower().split()\n\n  if remove_stopwords:\n    stops = set(stopwords.words(\"english\"))\n    cleaned_text = [word for word in cleaned_text if not word in stops]\n    clean_review = ' '.join(cleaned_text)\n  else:\n    clean_review = ' '.join(cleaned_text)\n\n  return clean_review","metadata":{"execution":{"iopub.status.busy":"2021-10-19T10:58:52.281977Z","iopub.execute_input":"2021-10-19T10:58:52.282693Z","iopub.status.idle":"2021-10-19T10:58:52.292471Z","shell.execute_reply.started":"2021-10-19T10:58:52.282656Z","shell.execute_reply":"2021-10-19T10:58:52.291031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 이제 각 데이터에 반복문을 활용하여 텍스트 전처리를 시행한다. \n- 기존 text와 cleaned_text를 비교해본다. ","metadata":{}},{"cell_type":"code","source":"clean_train_reviews = []\nfor datas in [train, test]:\n    datas['cleaned_text'] = datas['text'].apply(lambda x : data_cleansing(x, remove_stopwords=True))\n\ntrain.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:08:50.11186Z","iopub.execute_input":"2021-10-19T11:08:50.112151Z","iopub.status.idle":"2021-10-19T11:08:51.822485Z","shell.execute_reply.started":"2021-10-19T11:08:50.112099Z","shell.execute_reply":"2021-10-19T11:08:51.821558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:08:59.612294Z","iopub.execute_input":"2021-10-19T11:08:59.612875Z","iopub.status.idle":"2021-10-19T11:08:59.622422Z","shell.execute_reply.started":"2021-10-19T11:08:59.612835Z","shell.execute_reply":"2021-10-19T11:08:59.621476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Transformation Vectorizer\n- 텍스트는 문자이기 때문에, 이제 이를 숫자로 변경해야 한다. ","metadata":{}},{"cell_type":"markdown","source":"### Count Vectorizer\n- CountVectorizer는 각 텍스트를 알파벳으로 정렬한 후, 빈도수로 계산한다. ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncorpus = ['As you know, I want to be with you']\nvector = CountVectorizer()\nprint(vector.fit_transform(corpus).toarray()) \nprint(vector.vocabulary_)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:37:29.386916Z","iopub.execute_input":"2021-10-19T11:37:29.387195Z","iopub.status.idle":"2021-10-19T11:37:29.39426Z","shell.execute_reply.started":"2021-10-19T11:37:29.387164Z","shell.execute_reply":"2021-10-19T11:37:29.393532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncorpus = ['As you know, I want to be with you', \n          'Thank you, but I cannot be with you']\nvector = CountVectorizer()\nprint(vector.fit_transform(corpus).toarray()) \nprint(vector.vocabulary_)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:45:37.770582Z","iopub.execute_input":"2021-10-19T11:45:37.770836Z","iopub.status.idle":"2021-10-19T11:45:37.783956Z","shell.execute_reply.started":"2021-10-19T11:45:37.770808Z","shell.execute_reply":"2021-10-19T11:45:37.783013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TfidfVectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ncorpus = ['Can I have lunch with you?', \n          'No, I cannot have it with you.', \n          'Because, I need to study later']\ntfidfv = TfidfVectorizer().fit(corpus)\nprint(np.round(tfidfv.transform(corpus).toarray(), 2))\nprint(tfidfv.vocabulary_)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:46:04.593882Z","iopub.execute_input":"2021-10-19T11:46:04.594159Z","iopub.status.idle":"2021-10-19T11:46:04.60677Z","shell.execute_reply.started":"2021-10-19T11:46:04.594122Z","shell.execute_reply":"2021-10-19T11:46:04.605968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:46:29.77179Z","iopub.execute_input":"2021-10-19T11:46:29.772351Z","iopub.status.idle":"2021-10-19T11:46:29.777533Z","shell.execute_reply.started":"2021-10-19T11:46:29.772311Z","shell.execute_reply":"2021-10-19T11:46:29.776801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(min_df = 0.0, analyzer='char', sublinear_tf=True, ngram_range=(1, 3), max_features = 10000)\nX = vectorizer.fit_transform(train['cleaned_text']).todense()\ny = train['target'].values","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:46:31.018607Z","iopub.execute_input":"2021-10-19T11:46:31.019454Z","iopub.status.idle":"2021-10-19T11:46:32.495267Z","shell.execute_reply.started":"2021-10-19T11:46:31.019404Z","shell.execute_reply":"2021-10-19T11:46:32.49454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:46:37.083555Z","iopub.execute_input":"2021-10-19T11:46:37.084319Z","iopub.status.idle":"2021-10-19T11:46:37.089064Z","shell.execute_reply.started":"2021-10-19T11:46:37.084283Z","shell.execute_reply":"2021-10-19T11:46:37.088192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=0)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:46:42.72305Z","iopub.execute_input":"2021-10-19T11:46:42.723592Z","iopub.status.idle":"2021-10-19T11:46:42.91386Z","shell.execute_reply.started":"2021-10-19T11:46:42.723551Z","shell.execute_reply":"2021-10-19T11:46:42.913004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlgs = LogisticRegression(class_weight = 'balanced')\nlgs.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:46:49.096233Z","iopub.execute_input":"2021-10-19T11:46:49.096835Z","iopub.status.idle":"2021-10-19T11:46:51.928776Z","shell.execute_reply.started":"2021-10-19T11:46:49.0968Z","shell.execute_reply":"2021-10-19T11:46:51.92805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nX_testset = vectorizer.transform(test['cleaned_text']).todense()\nprint(\"The Shape of Test Dataset:\", X_testset.shape)\n\ny_test_pred = lgs.predict(X_testset)\nprint(\"The Predict Value:\", y_test_pred)\ny_test_pred = np.where(y_test_pred >= 0.5, 1, 0)\nprint(\"The Predict Class:\", y_test_pred)\n\nsubmission_file = pd.DataFrame({'id': test_id, 'target': y_test_pred})\nprint(submission_file.head())\n\nsubmission_file.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T11:47:02.315153Z","iopub.execute_input":"2021-10-19T11:47:02.31542Z","iopub.status.idle":"2021-10-19T11:47:03.115872Z","shell.execute_reply.started":"2021-10-19T11:47:02.315392Z","shell.execute_reply":"2021-10-19T11:47:03.115046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}