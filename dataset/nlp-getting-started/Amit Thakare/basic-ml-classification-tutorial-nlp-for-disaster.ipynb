{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Basic ML Classification for Beginners\n## Introduction\nIn this simple tutorial, I am going to show you how to do ML classification with simple classification methods, like Naive Bayes.\n\nFirst of all, we need to load all the files needed for this process. Kaggle provided 3 files in this competition, but we are going to use only the train.csv file, which has been labelled, to test the data.\n\nIf you want to learn how to use all training data in the classifier and use the testing data for submission, you can skip ahead to the **Create Submission** section."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom nltk import word_tokenize\n\nimport os, re\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load train.csv file"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Text\nThe first process that we need to perform is to clean the text, such as lowering all the letters, removing punctuations & links, and removing unnecessary words (stop words). You can use the stop words list already provided by NLTK library, but here I am going to write one myself. Any word contained in the stop words list will be removed from the text. You can also modify the list that I have created and add the words yourself."},{"metadata":{"trusted":true},"cell_type":"code","source":"### function to clean text (remove punctuation, links, lowercase all letters, etc)\ndef clean_text(text):\n    temp = text.lower()\n    temp = re.sub('\\n', \" \", temp)\n    temp = re.sub('\\'', \"\", temp)\n    temp = re.sub('-', \" \", temp)\n    temp = re.sub(r\"(http|https|pic.)\\S+\",\" \",temp)\n    temp = re.sub(r'[^\\w\\s]',' ',temp)\n    \n    return temp\n\n### list of stop words that need to be removed\nstop_words = ['as', 'in', 'of', 'is', 'are', 'were', 'was', 'it', 'for', 'to', 'from', 'into', 'onto', \n              'this', 'that', 'being', 'the','those', 'these', 'such', 'a', 'an']\n### function to remove unnecessary words\ndef remove_stopwords(text):\n    tokenized_words = word_tokenize(text)\n    temp = [word for word in tokenized_words if word not in stop_words]\n    temp = ' '.join(temp)\n    return temp\n\n### We save the cleaned and normalized texts in the new column, called 'clean'\ntrain['clean'] = train['text'].apply(clean_text)\ntrain['clean'] = train['clean'].apply(remove_stopwords)\ntrain['clean']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combining data with keywords and location attributes\nYou can skip this part and go straight to the next one if you just want to use the text as features. In this part, we are going to combine the text with location and keyword attributes to enrich the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_attributes(text, location, keyword):\n    var_list = [text, location, keyword]\n    combined = ' '.join(x for x in var_list if x)\n    return combined\n\ntrain.fillna('', inplace=True)\ntrain['combine'] = train.apply(lambda x: combine_attributes(x['clean'], x['location'], x['keyword']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split train data into train_data and test_data for testing purpose\nIn order to test the classifier that we are going to use, we need to split our train data into training and testing. Training data are used to train the classifier, just like what it's called. Meanwhile, testing data are used to test how good the classifier is working.\n\nIf you decided not to combine the text, location, and keyword as I explained above, you should replace the `X = train['combine']` to `X = train['clean']`, so that it will use the cleaned data."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train['combine']\ny = train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vectorize the text using TFIDF\nSince computer cannot actually read words, we have to convert those words into readable format, which is in number. So, text vectorization is used to map words or phrases to a corresponding vector of real numbers. One of the most popular technique of text vectorization is TFIDF."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer()\n\nX_train_vect = vectorizer.fit_transform(X_train)\nX_test_vect = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build the Classifier\nWe are using Multinomial Naive Bayes for our classifier. It's important to note that only the training data that have been vectorized used to fit the classifier. The testing data that have been vectorized are used for prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X_train_vect, y_train)\n\ny_pred = clf.predict(X_test_vect)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy Score\nThe accuracy score attained in this experiment is shown below. It can be improved by using other classification methods, such as SVM, Logistic Regression, Decision Tree, etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix\nNext, we will figure out the distribution of prediction result using confusion matrix. A *good* confusion matrix would consist of many **true positives**, as shown in the diagonal from the top left to bottom right."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Submission File\nAfter testing out the data and gaining the accuracy using train data only, now it's time to build classifier using all train data to get prediction for the test data. We cannot get accuracy for this experiment, because the result will go straight for submission. Here I will show you how to create submission file for the competition.\n\n## Load files\nTo submit into the competition, we will use the train data for the training and apply the prediction on the test data. The result of the prediction on the test data are what we are going to submit for the competition. So, first of all, we have to load both files."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\nSince we already defined the functions above, we can just call the functions for this step to work."},{"metadata":{"trusted":true},"cell_type":"code","source":"### apply preprocessing on train data\ntrain['clean'] = train['text'].apply(clean_text)\ntrain['clean'] = train['clean'].apply(remove_stopwords)\n\n### apply preprocessing on test data\ntest['clean'] = test['text'].apply(clean_text)\ntest['clean'] = test['clean'].apply(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna('', inplace=True)\ntrain['combine'] = train.apply(lambda x: combine_attributes(x['clean'], x['location'], x['keyword']), axis=1)\n\ntest.fillna('', inplace=True)\ntest['combine'] = test.apply(lambda x: combine_attributes(x['clean'], x['location'], x['keyword']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train['combine']\ny_train = train['target']\n\nX_test = test['combine']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Text Vectorization using TF-IDF\nIt is important to note that we have to define the object for vectorizer, so don't use the vectorizer object that we have used above."},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer()\n\nX_train_vect = vectorizer.fit_transform(X_train)\nX_test_vect = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MultinomialNB()\nclf.fit(X_train_vect, y_train)\n\ny_pred = clf.predict(X_test_vect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame({'id':test['id'], 'target':y_pred})\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission File\nHere is the file that we need to submit for submission. It contains the columns id and target."},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('mnb_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you for reading my beginner tutorial on NLP and ML. Feel free to correct my kernel or give any suggestion on the comment below.\n\nLia"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}