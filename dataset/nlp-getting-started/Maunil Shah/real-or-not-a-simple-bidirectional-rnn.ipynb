{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This is NLP based classification problem is solved using a simple Bidirectional LSTM based RNN. \n## If you like my work then do consider upvoting this notebook.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, re, unidecode, random, math\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import L1L2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-08T05:52:29.857661Z","iopub.execute_input":"2022-04-08T05:52:29.857894Z","iopub.status.idle":"2022-04-08T05:52:29.865345Z","shell.execute_reply.started":"2022-04-08T05:52:29.85786Z","shell.execute_reply":"2022-04-08T05:52:29.864544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_cleaner(data):\n    data = data.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n    \n    soup = BeautifulSoup(data, 'html.parser')\n    data = soup.get_text(separator=' ')\n    \n    remove_http = re.sub(r'http\\S+', '', data)\n    data = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_http)\n    \n    data = unidecode.unidecode(data)\n    data = data.lower()\n    data = re.sub(r\"[^a-zA-Z0-9:$-,()%.?!]+\", ' ', data) \n    data = re.sub(r\"[:$-,()%.?!]+\", ' ',data)\n    \n    stoplist = stopwords.words(\"english\")\n    data = [word for word in word_tokenize(data) if word not in stoplist]\n    data = \" \".join(data)\n    \n    return data\n\ndef seed_everything(SEED = 13):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    tf.random.set_seed(SEED)\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    \nseed_everything()\nprint('seeded everything to get same output')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:29.86674Z","iopub.execute_input":"2022-04-08T05:52:29.867445Z","iopub.status.idle":"2022-04-08T05:52:29.879743Z","shell.execute_reply.started":"2022-04-08T05:52:29.867341Z","shell.execute_reply":"2022-04-08T05:52:29.878959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/nlp-getting-started/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:29.88099Z","iopub.execute_input":"2022-04-08T05:52:29.881773Z","iopub.status.idle":"2022-04-08T05:52:29.915307Z","shell.execute_reply.started":"2022-04-08T05:52:29.881733Z","shell.execute_reply":"2022-04-08T05:52:29.914564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_df['id']\ndel train_df['keyword']\ndel train_df['location']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:29.916572Z","iopub.execute_input":"2022-04-08T05:52:29.91682Z","iopub.status.idle":"2022-04-08T05:52:29.930223Z","shell.execute_reply.started":"2022-04-08T05:52:29.916787Z","shell.execute_reply":"2022-04-08T05:52:29.929489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(train_df.target.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:29.931468Z","iopub.execute_input":"2022-04-08T05:52:29.931722Z","iopub.status.idle":"2022-04-08T05:52:29.937787Z","shell.execute_reply.started":"2022-04-08T05:52:29.931688Z","shell.execute_reply":"2022-04-08T05:52:29.937052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'] = [data_cleaner(train_df['text'][i]) for i in tqdm(range(train_df.shape[0]))]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:29.939098Z","iopub.execute_input":"2022-04-08T05:52:29.939931Z","iopub.status.idle":"2022-04-08T05:52:33.836133Z","shell.execute_reply.started":"2022-04-08T05:52:29.939893Z","shell.execute_reply":"2022-04-08T05:52:33.835329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def myModel():    \n    model = Sequential(name='Bidirectional_RNN')\n    model.add(Embedding(1000, 256, input_length = 256))\n    #model.add(Bidirectional((LSTM(512, return_sequences = True, recurrent_dropout=0.0, kernel_regularizer = L1L2(l1=0.0, l2=0.01)))))\n    #model.add(Dropout(0.5))\n    #model.add(Bidirectional((LSTM(512, return_sequences = True, recurrent_dropout=0.0))))\n    #model.add(Dropout(0.5))\n    \n    #model.add(Bidirectional(LSTM(256, return_sequences = True, recurrent_dropout=0.0, kernel_regularizer = L1L2(l1=0.0, l2=0.01))))\n    #model.add(Dropout(0.5))\n    \n    #model.add(Bidirectional(LSTM(128, return_sequences = True, recurrent_dropout=0.0, kernel_regularizer = L1L2(l1=0.0, l2=0.01))))\n    #model.add(Dropout(0.5))\n    model.add(Bidirectional(LSTM(128, return_sequences = True, recurrent_dropout=0.0, kernel_regularizer = L1L2(l1=0.0, l2=0.01))))\n    model.add(Dropout(0.5))\n    \n    model.add(Bidirectional(LSTM(64, return_sequences = True, recurrent_dropout=0.0, kernel_regularizer = L1L2(l1=0.0, l2=0.01))))\n    model.add(Dropout(0.5))\n    \n    model.add(Bidirectional(LSTM(32, return_sequences = False, recurrent_dropout=0.0, kernel_regularizer = L1L2(l1=0.0, l2=0.01))))\n    model.add(Dropout(0.4))\n    #model.add(Bidirectional(LSTM(32, return_sequences = False, recurrent_dropout=0.0, kernel_regularizer = L1L2(l1=0.0, l2=0.01))))\n    #model.add(Dropout(0.4))\n    \n    model.add(Dense(256, activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(16, activation = 'relu'))\n    model.add(Dropout(0.1))\n    \n    model.add(Dense(1, activation = 'sigmoid'))\n    print(model.summary())\n    return model\n\nmodel = myModel()    \nmodel.compile(\noptimizer=Adam(learning_rate=0.0001),\nloss='binary_crossentropy',\nmetrics=['Accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:33.838413Z","iopub.execute_input":"2022-04-08T05:52:33.838986Z","iopub.status.idle":"2022-04-08T05:52:37.667723Z","shell.execute_reply.started":"2022-04-08T05:52:33.838946Z","shell.execute_reply":"2022-04-08T05:52:37.667022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = train_df['text']\ntokenizer = Tokenizer(num_words=1000)\ntokenizer.fit_on_texts(text.values)\nx_train = tokenizer.texts_to_sequences(text.values)\nx_train = pad_sequences(x_train, maxlen=256)\nprint('generated pad sequences')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:37.669888Z","iopub.execute_input":"2022-04-08T05:52:37.670133Z","iopub.status.idle":"2022-04-08T05:52:37.944088Z","shell.execute_reply.started":"2022-04-08T05:52:37.670099Z","shell.execute_reply":"2022-04-08T05:52:37.942675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train_df['target']\nlr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.25,\n    patience=3,\n    verbose=0,\n    mode='min'\n)\n\nchk_point = ModelCheckpoint(\n    '/kaggle/working/best_model.h5',\n    monitor='val_loss',\n    verbose=0,\n    save_best_only=True,\n    mode='min'\n)\n\nes = EarlyStopping(\n    patience=5,\n    min_delta=0,\n    monitor='val_loss',\n    #restore_best_weights=True,\n    verbose=0,\n    mode='min',\n    baseline=None\n)\n\nhistory = model.fit(\n    x_train, y_train,\n    validation_split=0.2,\n    batch_size=64,\n    epochs = 100,\n    callbacks=[es,lr,chk_point],\n    shuffle=True,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:52:42.330348Z","iopub.execute_input":"2022-04-08T05:52:42.331029Z","iopub.status.idle":"2022-04-08T05:56:51.162614Z","shell.execute_reply.started":"2022-04-08T05:52:42.330993Z","shell.execute_reply":"2022-04-08T05:56:51.16194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://www.pluralsight.com/guides/data-visualization-deep-learning-model-using-matplotlib\nplt.plot(history.history['Accuracy'])\nplt.plot(history.history['val_Accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:57:09.156677Z","iopub.execute_input":"2022-04-08T05:57:09.157371Z","iopub.status.idle":"2022-04-08T05:57:09.36908Z","shell.execute_reply.started":"2022-04-08T05:57:09.157333Z","shell.execute_reply":"2022-04-08T05:57:09.368394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:57:13.661891Z","iopub.execute_input":"2022-04-08T05:57:13.662775Z","iopub.status.idle":"2022-04-08T05:57:13.850496Z","shell.execute_reply.started":"2022-04-08T05:57:13.662737Z","shell.execute_reply":"2022-04-08T05:57:13.849843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/nlp-getting-started/test.csv')\ntest_df['text'] = [data_cleaner(test_df['text'][i]) for i in tqdm(range(test_df.shape[0]))]\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:57:15.134357Z","iopub.execute_input":"2022-04-08T05:57:15.135089Z","iopub.status.idle":"2022-04-08T05:57:16.845534Z","shell.execute_reply.started":"2022-04-08T05:57:15.135046Z","shell.execute_reply":"2022-04-08T05:57:16.844843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = test_df['text']\nx_test = tokenizer.texts_to_sequences(text.values)\nx_test = pad_sequences(x_test, maxlen=256)\nprint('generated pad sequences')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:57:24.763383Z","iopub.execute_input":"2022-04-08T05:57:24.76366Z","iopub.status.idle":"2022-04-08T05:57:24.8303Z","shell.execute_reply.started":"2022-04-08T05:57:24.763626Z","shell.execute_reply":"2022-04-08T05:57:24.829522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('./best_model.h5')\npreds = model.predict(x_test)\npred = [1 if i>0.5 else 0 for i in preds]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:57:25.797101Z","iopub.execute_input":"2022-04-08T05:57:25.797842Z","iopub.status.idle":"2022-04-08T05:57:31.632119Z","shell.execute_reply.started":"2022-04-08T05:57:25.79779Z","shell.execute_reply":"2022-04-08T05:57:31.63121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.DataFrame()\nsubmission['id']=test_df['id'].to_list()\nsubmission['target']=pred","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:57:37.847971Z","iopub.execute_input":"2022-04-08T05:57:37.848228Z","iopub.status.idle":"2022-04-08T05:57:37.859336Z","shell.execute_reply.started":"2022-04-08T05:57:37.848199Z","shell.execute_reply":"2022-04-08T05:57:37.858299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:57:39.174582Z","iopub.execute_input":"2022-04-08T05:57:39.175169Z","iopub.status.idle":"2022-04-08T05:57:39.193443Z","shell.execute_reply.started":"2022-04-08T05:57:39.175132Z","shell.execute_reply":"2022-04-08T05:57:39.192798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}