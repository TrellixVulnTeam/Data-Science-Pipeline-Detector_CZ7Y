{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 라이브러리 및 데이터 다운로드","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:29:34.23067Z","start_time":"2022-06-06T05:29:34.213076Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nimport nltk\nimport string\nimport tensorflow_hub as hub\nimport tensorflow as tf\nimport sklearn","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:29:46.515211Z","start_time":"2022-06-06T05:29:37.829827Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\nX_test = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\nsubmission = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\ny = data[\"target\"]","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:29:46.687625Z","start_time":"2022-06-06T05:29:46.54753Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:33:20.187905Z","start_time":"2022-06-06T05:33:20.166018Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data[\"text\"]","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:33:20.467527Z","start_time":"2022-06-06T05:33:20.457528Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_for_tree = data[[\"keyword\", \"location\"]]","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:33:23.035717Z","start_time":"2022-06-06T05:33:23.029761Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"텍스트 데이터를 이용한 LSTM과 Tabular data를 이용하여 RandomForest를 학습시키기 위하여 데이터를 분할해주었다.  \n__X__ 는 LSTM을 위한 텍스트 데이터이며 __X_for_tree__ 는 RandomForest를 위한 Tabular data이다.","metadata":{}},{"cell_type":"markdown","source":"# 노이즈 제거\n텍스트 데이터는 많은 노이즈를 가지고 있으므로 제거해주는 과정은 필수이다.","metadata":{}},{"cell_type":"code","source":"X[:10]","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:34:28.971768Z","start_time":"2022-06-06T05:34:28.961797Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text) \n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\nX = pd.Series(map(clean_text, X))","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:34:32.500738Z","start_time":"2022-06-06T05:34:32.353297Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[:10]","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:34:32.655912Z","start_time":"2022-06-06T05:34:32.649927Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 토큰화  \n모델이 문장을 한번에 학습하는게 아닌 단어 별로 학습할 수 있도록 토큰화 시켜준다.","metadata":{}},{"cell_type":"code","source":"X = [nltk.word_tokenize(sentence) for sentence in X]","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:36:30.693848Z","start_time":"2022-06-06T05:36:30.005259Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X[:5])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:36:31.377705Z","start_time":"2022-06-06T05:36:31.346324Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 불용어 제거   \n텍스트 데이터에는 모델 학습에 큰 의미를 주지 않는 불용어가 다량 존재한다.  \n[I see fire at the mountain] -> [see fire mountain] 이와 같은 식으로 전처리를 진행 한다.  \n상당히 어려워보이는 작업이지만 nltk 라이브러리에는 이미 영어 불용어 사전이 구현되어 있기 때문에 이를 사용하여 간단히 가능하다.","metadata":{}},{"cell_type":"code","source":"nltk.corpus.stopwords.words('english')[:5]","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:40:28.692963Z","start_time":"2022-06-06T05:40:28.673189Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X[:5])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:40:36.29456Z","start_time":"2022-06-06T05:40:36.265639Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_stopwords(text):\n    words = [w for w in text if w not in nltk.corpus.stopwords.words('english')]\n    return words\n\nX = list(map(remove_stopwords, X))","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:40:56.015467Z","start_time":"2022-06-06T05:40:37.130585Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X[:5])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:40:56.09345Z","start_time":"2022-06-06T05:40:56.08149Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 정수 인코딩\n모델은 단어 그 자체를 학습하지 못하기 때문에 정수로 인코딩 해주어야 한다.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(X[:5])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:41:51.912228Z","start_time":"2022-06-06T05:41:51.902301Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(X)\nX = tokenizer.texts_to_sequences(X)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:41:52.781627Z","start_time":"2022-06-06T05:41:52.681502Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X[:5])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:41:53.698294Z","start_time":"2022-06-06T05:41:53.681821Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 패딩\nLSTM을 이용하여 텍스트 데이터를 훈련할 예정인데 RNN 계열 모델은 시쿼스가 너무 길어지면 학습이 잘 진행되지 않는다.  \n데이터를 그래도 사용할 시 가장 긴 길이를 기준으로 패딩하게 되는데 이를 방지하지 위하여 정보를 너무 잃지 않는 길이로 패딩하였다.","metadata":{}},{"cell_type":"code","source":"print(\"Average langth of tweet:\", sum(map(len, X))/len(X))\nplt.hist([len(tweet) for tweet in X])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:47:00.775755Z","start_time":"2022-06-06T05:47:00.580625Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\nax1.hist([len(X[i]) for i in range(len(X)) if y[i]==1])\nax1.set_title(\"Real\")\nax2.hist([len(X[i]) for i in range(len(X)) if y[i]==0], color=\"orange\")\nax2.set_title(\"Fake\")","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:47:01.870586Z","start_time":"2022-06-06T05:47:01.605774Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor tweet in X:\n    if len(tweet) > 20:\n        count+=1\nprint((len(X)-count) / len(X))","metadata":{"ExecuteTime":{"end_time":"2022-06-03T06:23:00.019219Z","start_time":"2022-06-03T06:23:00.005846Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = keras.preprocessing.sequence.pad_sequences(X, maxlen=20, padding=\"post\")","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:48:05.127166Z","start_time":"2022-06-06T05:48:05.100514Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"아래는 Test data를 위하여 생성한 위의 과정을 모두 합치 함수이다.","metadata":{}},{"cell_type":"code","source":"def preprocess(text_sequence):\n    text_sequence = pd.Series(map(clean_text, text_sequence))    \n    text_sequence = [nltk.word_tokenize(sentence) for sentence in text_sequence]\n    text_sequence = list(map(remove_stopwords, text_sequence))    \n    text_sequence =  tokenizer.texts_to_sequences(text_sequence)\n    text_sequence = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=20, padding=\"post\") \n    return text_sequence","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:48:40.549914Z","start_time":"2022-06-06T05:48:40.544958Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 테이블형 데이터 인코딩 및 데이터 split\n테이블형 데이터에서 __keyword, location__  컬럼 역시 정수로 만들어주어야 한다.  \nsklearn의 LabelEncoder를 이용하여 전처리 하였으며 보이지 않은 데이터에 대하여서 nan으로 만들어주었다.  \n이미 인코더가 nan을 학습했으므로 문제 없이 동작한다.","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, random_state=42)\nX_train_tree, X_valid_tree, y_train, y_valid = train_test_split(X_for_tree, y, stratify=y, random_state=42)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:49:12.389769Z","start_time":"2022-06-06T05:49:12.372814Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_encoder = LabelEncoder()\nX_train_tree[\"keyword\"] = k_encoder.fit_transform(X_train_tree[\"keyword\"])\nX_valid_tree[\"keyword\"] = k_encoder.transform(X_valid_tree[\"keyword\"])\n\nl_encoder = LabelEncoder()\nX_train_tree[\"location\"] = l_encoder.fit_transform(X_train_tree[\"location\"])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:49:44.004842Z","start_time":"2022-06-06T05:49:43.984461Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = np.array(X_valid_tree[\"location\"])\n\nfor index in range(len(temp)):\n    if temp[index] not in l_encoder.classes_:\n        temp[index] = np.nan\n        \nX_valid_tree[\"location\"] = temp\nX_valid_tree[\"location\"] = l_encoder.transform(X_valid_tree[\"location\"])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:57:53.653331Z","start_time":"2022-06-06T05:57:53.553285Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 모델 훈련","metadata":{}},{"cell_type":"code","source":"def make_model(iter = 1, hidden=100):\n    Input = keras.Input(shape=[20])\n\n    x = keras.layers.Reshape((20, 1))(Input)\n    \n    for _ in range(iter):\n        x = keras.layers.Bidirectional(keras.layers.LSTM(hidden, return_sequences=True))(x)\n        \n    x = keras.layers.Bidirectional(keras.layers.LSTM(hidden))(x)\n    x = keras.layers.Dense((hidden+40)/2, activation=\"relu\")(x)\n    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n\n    model = keras.Model(inputs=Input, outputs=output)\n    model.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\", optimizer=\"adam\")\n    return model","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:53:50.085255Z","start_time":"2022-06-06T05:53:50.077251Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = make_model(1, 100)\nhistory = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=30)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:55:20.234443Z","start_time":"2022-06-06T05:53:51.397121Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I grid search model shape by iter and hidden and I use parameteres above to train text data.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 10))\nplt.plot(history.history[\"accuracy\"], label=\"Train\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Valid\")\nplt.legend()","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:56:17.923164Z","start_time":"2022-06-06T05:56:17.788361Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_valid, y_valid)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:56:23.448481Z","start_time":"2022-06-06T05:56:22.896244Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_model = RandomForestClassifier()\ntree_model.fit(X_train_tree, y_train)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:56:31.945528Z","start_time":"2022-06-06T05:56:31.392747Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid_tree","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:57:16.914631Z","start_time":"2022-06-06T05:57:16.896802Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_model.score(X_valid_tree, y_valid)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T05:57:56.057641Z","start_time":"2022-06-06T05:57:55.997976Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tree모델이 LSTM보다 더 좋은 성능을 보인다.  \n자연어 전처리에 대한 지식과 RNN계열 지식이 부족하여 복잡한 데이터를 제대로 학습하는 모델을 만들지 못한것 같다.","metadata":{}},{"cell_type":"code","source":"tree_score = tree_model.predict_proba(X_valid_tree)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:00:28.617962Z","start_time":"2022-06-06T06:00:28.557138Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann_score = np.concatenate((1-model.predict(X_valid), model.predict(X_valid)), axis=1)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:00:33.83676Z","start_time":"2022-06-06T06:00:31.55667Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_score","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:00:38.365414Z","start_time":"2022-06-06T06:00:38.356409Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann_score","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:00:41.333658Z","start_time":"2022-06-06T06:00:41.328671Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sklearn.metrics.accuracy_score(np.argmax(tree_score + ann_score, axis=1), y_valid)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:01:42.588566Z","start_time":"2022-06-06T06:01:42.57701Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"각각의 라벨값에 대한 확신 정도?를 합쳐서 가장 높을 값을 선택하는 방식으로 Soft Voting Ensemble을 진행하였다.","metadata":{}},{"cell_type":"markdown","source":"# 제출  \n제출 전에 Train 데이터를 모두 사용하여 모델을 재학습 시킬 필요가 있다.","metadata":{}},{"cell_type":"code","source":"model = make_model(1, 100)\nmodel.fit(X,y, epochs=30)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:04:44.39407Z","start_time":"2022-06-06T06:03:08.948228Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_encoder = LabelEncoder()\ndata[\"keyword\"] = k_encoder.fit_transform(data[\"keyword\"])\nl_encoder = LabelEncoder()\ndata[\"location\"] = l_encoder.fit_transform(data[\"location\"])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:11:08.206877Z","start_time":"2022-06-06T06:11:08.172929Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_model = RandomForestClassifier()\ntree_model.fit(data[[\"keyword\", \"location\"]], y)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:11:26.097451Z","start_time":"2022-06-06T06:11:25.378595Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"X_test에 대하여서 똑같이 전처리 해주어야 한다.","metadata":{}},{"cell_type":"code","source":"X_test_text = preprocess(X_test[\"text\"])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:07:42.331026Z","start_time":"2022-06-06T06:07:34.288425Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = np.array(X_test[\"location\"])\n\nfor index in range(len(temp)):\n    if temp[index] not in l_encoder.classes_:\n        temp[index] = np.nan\n        \nX_test[\"location\"] = temp","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:07:42.583466Z","start_time":"2022-06-06T06:07:42.395948Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[\"keyword\"] = k_encoder.transform(X_test[\"keyword\"])\nX_test[\"location\"] = l_encoder.transform(X_test[\"location\"])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:07:42.661593Z","start_time":"2022-06-06T06:07:42.647018Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann_score = np.concatenate((1-model.predict(X_test_text), model.predict(X_test_text)), axis=1)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:08:21.83393Z","start_time":"2022-06-06T06:08:19.604366Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_score = tree_model.predict_proba(X_test[[\"keyword\", \"location\"]])","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:11:33.327591Z","start_time":"2022-06-06T06:11:33.260869Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Final_score = np.argmax(tree_score+ann_score, axis=1)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:11:47.075346Z","start_time":"2022-06-06T06:11:47.064346Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"target\"] = Final_score","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:11:49.929035Z","start_time":"2022-06-06T06:11:49.917067Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=None)","metadata":{"ExecuteTime":{"end_time":"2022-06-06T06:11:52.817272Z","start_time":"2022-06-06T06:11:52.796241Z"}},"execution_count":null,"outputs":[]}]}