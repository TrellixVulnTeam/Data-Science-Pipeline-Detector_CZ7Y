{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![imh](data:image/png;base64,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)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\n# for stopwords Removal\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom textblob import TextBlob\n# for regular expressions\nimport re\nfrom nltk.stem.porter import PorterStemmer","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:52.357214Z","iopub.execute_input":"2022-02-09T22:48:52.357972Z","iopub.status.idle":"2022-02-09T22:48:54.176305Z","shell.execute_reply.started":"2022-02-09T22:48:52.357837Z","shell.execute_reply":"2022-02-09T22:48:54.175522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv('../input/nlp-getting-started/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.177679Z","iopub.execute_input":"2022-02-09T22:48:54.17804Z","iopub.status.idle":"2022-02-09T22:48:54.2232Z","shell.execute_reply.started":"2022-02-09T22:48:54.178008Z","shell.execute_reply":"2022-02-09T22:48:54.222642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# عرض اول عشر صفوف","metadata":{}},{"cell_type":"code","source":"train_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.224075Z","iopub.execute_input":"2022-02-09T22:48:54.224617Z","iopub.status.idle":"2022-02-09T22:48:54.244165Z","shell.execute_reply.started":"2022-02-09T22:48:54.224583Z","shell.execute_reply":"2022-02-09T22:48:54.243652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# عرض بعض المعلومات عن البيانات","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.245787Z","iopub.execute_input":"2022-02-09T22:48:54.246373Z","iopub.status.idle":"2022-02-09T22:48:54.272962Z","shell.execute_reply.started":"2022-02-09T22:48:54.246333Z","shell.execute_reply":"2022-02-09T22:48:54.271988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of Data is: \",train_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.274365Z","iopub.execute_input":"2022-02-09T22:48:54.27522Z","iopub.status.idle":"2022-02-09T22:48:54.281158Z","shell.execute_reply.started":"2022-02-09T22:48:54.275155Z","shell.execute_reply":"2022-02-09T22:48:54.280018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# عمل تنظيف للبيانات ","metadata":{}},{"cell_type":"code","source":"train_df.drop(['id','keyword', 'location'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.282814Z","iopub.execute_input":"2022-02-09T22:48:54.283228Z","iopub.status.idle":"2022-02-09T22:48:54.30751Z","shell.execute_reply.started":"2022-02-09T22:48:54.283181Z","shell.execute_reply":"2022-02-09T22:48:54.305726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# إزالة علامات الترقيم والأرقام","metadata":{}},{"cell_type":"code","source":"# First lets remove Punctuations from the Reviews\ndef punctuation_removal(messy_str):\n    clean_list = [char for char in messy_str if char not in string.punctuation]\n    clean_str = ''.join(clean_list)\n    return clean_str\n\ntrain_df['text'] = train_df['text'].apply(punctuation_removal)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.308935Z","iopub.execute_input":"2022-02-09T22:48:54.309702Z","iopub.status.idle":"2022-02-09T22:48:54.407929Z","shell.execute_reply.started":"2022-02-09T22:48:54.309658Z","shell.execute_reply":"2022-02-09T22:48:54.407264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets make a function to remove Numbers from the reviews\nimport re\ndef drop_numbers(list_text):\n    list_text_new = []\n    for i in list_text:\n        if not re.search('\\d', i):\n            list_text_new.append(i)\n    return ''.join(list_text_new)\n\ntrain_df['text'] = train_df['text'].apply(drop_numbers)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.409158Z","iopub.execute_input":"2022-02-09T22:48:54.409588Z","iopub.status.idle":"2022-02-09T22:48:54.964081Z","shell.execute_reply.started":"2022-02-09T22:48:54.409559Z","shell.execute_reply":"2022-02-09T22:48:54.963096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.965294Z","iopub.execute_input":"2022-02-09T22:48:54.965545Z","iopub.status.idle":"2022-02-09T22:48:54.972677Z","shell.execute_reply.started":"2022-02-09T22:48:54.965516Z","shell.execute_reply":"2022-02-09T22:48:54.971714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets plot the Wordscloud\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(stop_words = 'english')\nwords = cv.fit_transform(train_df['text'])\nsum_words = words.sum(axis=0)\n\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n\nwordcloud = WordCloud(background_color = 'black', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 10))\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.title(\"Vocabulary from text Reviews\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:48:54.976509Z","iopub.execute_input":"2022-02-09T22:48:54.977221Z","iopub.status.idle":"2022-02-09T22:49:05.120384Z","shell.execute_reply.started":"2022-02-09T22:48:54.977176Z","shell.execute_reply":"2022-02-09T22:49:05.119421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"markdown","source":" ### Bag of Words\n\nThe bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.","metadata":{}},{"cell_type":"code","source":"# creating bag of words\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(max_features = 2500)\ndf=cv.fit_transform(train_df['text']).toarray()\nx = df[:,[ 0]]\ny = train_df['target'].values\n\nprint(x.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.121759Z","iopub.execute_input":"2022-02-09T22:49:05.122054Z","iopub.status.idle":"2022-02-09T22:49:05.381019Z","shell.execute_reply.started":"2022-02-09T22:49:05.12202Z","shell.execute_reply":"2022-02-09T22:49:05.380359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of X:\",len(x))\nprint(\"Shape of Y:\",len(y))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.382396Z","iopub.execute_input":"2022-02-09T22:49:05.382865Z","iopub.status.idle":"2022-02-09T22:49:05.388693Z","shell.execute_reply.started":"2022-02-09T22:49:05.382824Z","shell.execute_reply":"2022-02-09T22:49:05.387773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.390319Z","iopub.execute_input":"2022-02-09T22:49:05.391006Z","iopub.status.idle":"2022-02-09T22:49:05.403265Z","shell.execute_reply.started":"2022-02-09T22:49:05.390959Z","shell.execute_reply":"2022-02-09T22:49:05.402341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.404986Z","iopub.execute_input":"2022-02-09T22:49:05.405623Z","iopub.status.idle":"2022-02-09T22:49:05.41461Z","shell.execute_reply.started":"2022-02-09T22:49:05.405581Z","shell.execute_reply":"2022-02-09T22:49:05.413893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Classification","metadata":{}},{"cell_type":"code","source":"# Fitting Decision Tree Classification to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 1000)\nclassifier1.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.416045Z","iopub.execute_input":"2022-02-09T22:49:05.416661Z","iopub.status.idle":"2022-02-09T22:49:05.514978Z","shell.execute_reply.started":"2022-02-09T22:49:05.416596Z","shell.execute_reply":"2022-02-09T22:49:05.51409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier1.predict(X_test)\nprint('Y_pred :',y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.51653Z","iopub.execute_input":"2022-02-09T22:49:05.517027Z","iopub.status.idle":"2022-02-09T22:49:05.523581Z","shell.execute_reply.started":"2022-02-09T22:49:05.516982Z","shell.execute_reply":"2022-02-09T22:49:05.522783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.524621Z","iopub.execute_input":"2022-02-09T22:49:05.525374Z","iopub.status.idle":"2022-02-09T22:49:05.541909Z","shell.execute_reply.started":"2022-02-09T22:49:05.525339Z","shell.execute_reply":"2022-02-09T22:49:05.540994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score=classifier1.score(X_test,y_pred)\nscore","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.543126Z","iopub.execute_input":"2022-02-09T22:49:05.543768Z","iopub.status.idle":"2022-02-09T22:49:05.550669Z","shell.execute_reply.started":"2022-02-09T22:49:05.543731Z","shell.execute_reply":"2022-02-09T22:49:05.549742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classification","metadata":{}},{"cell_type":"code","source":"# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:05.552059Z","iopub.execute_input":"2022-02-09T22:49:05.552518Z","iopub.status.idle":"2022-02-09T22:49:07.378559Z","shell.execute_reply.started":"2022-02-09T22:49:05.552488Z","shell.execute_reply":"2022-02-09T22:49:07.377682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:07.379828Z","iopub.execute_input":"2022-02-09T22:49:07.380104Z","iopub.status.idle":"2022-02-09T22:49:07.650892Z","shell.execute_reply.started":"2022-02-09T22:49:07.380074Z","shell.execute_reply":"2022-02-09T22:49:07.649713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:07.652313Z","iopub.execute_input":"2022-02-09T22:49:07.652626Z","iopub.status.idle":"2022-02-09T22:49:07.662663Z","shell.execute_reply.started":"2022-02-09T22:49:07.652585Z","shell.execute_reply":"2022-02-09T22:49:07.661783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score=classifier.score(X_test,y_pred)\nscore","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:07.664475Z","iopub.execute_input":"2022-02-09T22:49:07.665008Z","iopub.status.idle":"2022-02-09T22:49:07.814224Z","shell.execute_reply.started":"2022-02-09T22:49:07.664937Z","shell.execute_reply":"2022-02-09T22:49:07.813688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:07.815039Z","iopub.execute_input":"2022-02-09T22:49:07.815349Z","iopub.status.idle":"2022-02-09T22:49:08.017651Z","shell.execute_reply.started":"2022-02-09T22:49:07.815322Z","shell.execute_reply":"2022-02-09T22:49:08.016596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_stopword(text):\n    text_tokens = word_tokenize(text)\n    tokens = [word for word in text_tokens if not word in set(stopwords.words('english'))]\n    tokens_text = ' '.join(tokens)\n    return tokens_text\n\ntrain_df['text'] = train_df['text'].apply(remove_stopword)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:08.01911Z","iopub.execute_input":"2022-02-09T22:49:08.019419Z","iopub.status.idle":"2022-02-09T22:49:23.017796Z","shell.execute_reply.started":"2022-02-09T22:49:08.019378Z","shell.execute_reply":"2022-02-09T22:49:23.016996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'].values","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:23.018914Z","iopub.execute_input":"2022-02-09T22:49:23.019191Z","iopub.status.idle":"2022-02-09T22:49:23.025161Z","shell.execute_reply.started":"2022-02-09T22:49:23.019161Z","shell.execute_reply":"2022-02-09T22:49:23.024279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# تصنيف الكلمات الى السلبى والايجابى","metadata":{}},{"cell_type":"code","source":"# Lets calculate the Polarity of the Reviews\ndef get_polarity(text):\n    textblob = TextBlob(str(text))\n    pol = textblob.sentiment.polarity\n    if(pol==0):\n        return \"Neutral\"\n    elif(pol>0 and pol<=0.3):\n        return \"Weakly Positive\"\n    elif(pol>0.3 and pol<=0.6):\n        return \"Positive\"\n    elif(pol>0.6 and pol<=1):\n        return \"Strongly Positive\"\n    elif(pol>-0.3 and pol<=0):\n        return \"Weakly Negative\"\n    elif(pol>-0.6 and pol<=-0.3):\n        return \"Negative\"\n    elif(pol>-1 and pol<=-0.6):\n        return \"Strongly Negative\"\n    \ntrain_df['polarity'] = train_df['text'].apply(get_polarity)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:23.026712Z","iopub.execute_input":"2022-02-09T22:49:23.027114Z","iopub.status.idle":"2022-02-09T22:49:24.392167Z","shell.execute_reply.started":"2022-02-09T22:49:23.027071Z","shell.execute_reply":"2022-02-09T22:49:24.391182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['polarity'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T22:49:24.3935Z","iopub.execute_input":"2022-02-09T22:49:24.393917Z","iopub.status.idle":"2022-02-09T22:49:24.403301Z","shell.execute_reply.started":"2022-02-09T22:49:24.393871Z","shell.execute_reply":"2022-02-09T22:49:24.402294Z"},"trusted":true},"execution_count":null,"outputs":[]}]}