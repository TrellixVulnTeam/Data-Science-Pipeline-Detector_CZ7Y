{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bert Model with Pytorch \n\nThis notebook is basic on Abhishek Thakur YouTube video \"Training Sentiment Model Using BERT and Serving it with Flask API\" you can find the video here : https://www.youtube.com/watch?v=hinZO--TEk4 "},{"metadata":{"id":"UInSvrNSZPn1","colab_type":"text"},"cell_type":"markdown","source":"# Import libraries and Config "},{"metadata":{"trusted":true},"cell_type":"code","source":"import transformers \nimport torch.nn as nn \nimport torch \nfrom tqdm import tqdm\nimport torch \nimport torch.nn as nn \nimport pandas as pd\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup","execution_count":null,"outputs":[]},{"metadata":{"id":"KQlMlebvZRwP","colab_type":"code","outputId":"cfcde3ed-a3aa-4fd3-a54e-1a030ea9f0fd","colab":{"base_uri":"https://localhost:8080/","height":62},"trusted":true},"cell_type":"code","source":"MAX_Len = 512 \nTRAIN_BATCH_SIZE =8 \nVALID_BATCH_SIZE = 4\nBERT_PATH = '../input/bert-base-uncased'\nTOKENZIER = transformers.BertTokenizer.from_pretrained(BERT_PATH ,do_lower_case = True )","execution_count":null,"outputs":[]},{"metadata":{"id":"3cQ1utk8X9vj","colab_type":"text"},"cell_type":"markdown","source":"# Creat Model "},{"metadata":{"id":"yP43ulvRYsOm","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class BertBaseUncased(nn.Module) :\n    def __init__(self) : \n        super(BertBaseUncased,self).__init__() \n        self.bert = transformers.BertModel.from_pretrained(BERT_PATH) \n        self.bert_drop = nn.Dropout(0.4) \n        self.out = nn.Linear(768,1) \n    def forward(self,ids,mask,token_type_ids) : \n        out1,out2 = self.bert( \n            ids , \n            attention_mask = mask , \n            token_type_ids = token_type_ids \n        )\n        bo = self.bert_drop(out2) \n        output = self.out(bo) \n        return output ","execution_count":null,"outputs":[]},{"metadata":{"id":"AiJIGkNRcCj1","colab_type":"text"},"cell_type":"markdown","source":"# Data set "},{"metadata":{"id":"y1O6Qblqdsb4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class BERTDataset : \n    def __init__(self,df) : \n        \n        self.text = df['text'].values\n        self.target = df['target'].values \n        self.tokenizer = TOKENZIER \n        self.max_len = MAX_Len \n    def __len__(self) : \n        return len(self.text) \n    def __getitem__(self, item):\n        text = str(self.text[item])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n                text,\n                None,\n                add_special_tokens=True,\n                max_length=self.max_len\n            )\n\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        token_type_ids = inputs[\"token_type_ids\"]\n\n        padding_length = self.max_len - len(ids)\n        ids = ids + ([0] * padding_length)\n        mask = mask + ([0] * padding_length)\n        token_type_ids = token_type_ids + ([0] * padding_length)\n\n        return {\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n                'targets': torch.tensor(self.target[item], dtype=torch.float)\n            }","execution_count":null,"outputs":[]},{"metadata":{"id":"RAGxYHXzgxQ3","colab_type":"text"},"cell_type":"markdown","source":"# Engine "},{"metadata":{"id":"_BXGFFS2jhmd","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"id":"Asq4vE1FjfTS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, scheduler):\n    model.train()\n\n    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n        ids = d[\"ids\"]\n        token_type_ids = d[\"token_type_ids\"]\n        mask = d[\"mask\"]\n        targets = d[\"targets\"]\n\n        ids = ids.to(device, dtype=torch.long)\n        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets = targets.to(device, dtype=torch.float)\n\n        optimizer.zero_grad()\n        outputs = model(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )\n\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        optimizer.step()\n       \n","execution_count":null,"outputs":[]},{"metadata":{"id":"C55CMeLFgzyK","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":" def eval_fn(data_loader, model):\n    model.eval()\n    fin_targets = []\n    fin_outputs = []\n    with torch.no_grad():\n        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n            ids = d[\"ids\"]\n            token_type_ids = d[\"token_type_ids\"]\n            mask = d[\"mask\"]\n            targets = d[\"targets\"]\n\n            ids = ids.to(device, dtype=torch.long)\n            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            targets = targets.to(device, dtype=torch.float)\n\n            outputs = model(\n                ids=ids,\n                mask=mask,\n                token_type_ids=token_type_ids\n            )\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets","execution_count":null,"outputs":[]},{"metadata":{"id":"v4Rs8SOml3qr","colab_type":"text"},"cell_type":"markdown","source":"# Training the model "},{"metadata":{"id":"xbDUKu42l3Y8","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"DEVICE =torch.device(\"cuda\")\ndevice = torch.device(\"cuda\")\ndef run(model,EPOCHS):\n    dfx = pd.read_csv('../input/nlp-getting-started/train.csv').fillna(\"none\")\n    df_train, df_valid = model_selection.train_test_split(\n        dfx,\n        test_size=0.1,\n        random_state=42,\n        stratify=dfx.target.values\n    )\n\n\n\n    train_dataset = BERTDataset(\n        df_train\n    )\n\n    train_data_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=TRAIN_BATCH_SIZE,\n        num_workers=4\n    )\n\n    valid_dataset = BERTDataset(\n        df_valid\n\n    )\n\n    valid_data_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=VALID_BATCH_SIZE,\n        num_workers=1\n    )\n\n    device = torch.device(\"cuda\")\n    \n    \n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n    ]\n\n    num_train_steps = int(len(train_data_loader)) * EPOCHS\n    optimizer = AdamW(optimizer_parameters, lr=1e-5)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=0,\n        num_training_steps=num_train_steps\n    )\n\n\n    model = nn.DataParallel(model)\n\n    best_accuracy = 0\n    for epoch in range(EPOCHS):\n        train_fn(train_data_loader, model, optimizer, scheduler)\n        outputs, targets = eval_fn(valid_data_loader, model)\n        outputs = np.array(outputs) >= 0.5\n        accuracy = metrics.accuracy_score(targets, outputs)\n        print(f\"Accuracy Score = {accuracy}\")\n        scheduler.step()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"p_1Oq1uK1qqg","colab_type":"code","outputId":"1c930398-6332-43e0-b723-d8b48286f9ac","colab":{"base_uri":"https://localhost:8080/","height":284},"trusted":true},"cell_type":"code","source":"model = BertBaseUncased()\nmodel.to(device)\ngetattr(tqdm, '_instances', {}).clear()\nrun(model,1)","execution_count":null,"outputs":[]},{"metadata":{"id":"G0St4ri3JRfg","colab_type":"text"},"cell_type":"markdown","source":"# Make Prediction "},{"metadata":{"id":"nndLPPZ4bU8i","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def sentence_prediction(sentence):\n    tokenizer = TOKENZIER\n    max_len = MAX_Len\n    text = str(sentence)\n    text = \" \".join(text.split())\n\n    inputs = tokenizer.encode_plus(\n        text,\n        None,\n        add_special_tokens=True,\n        max_length=max_len\n    )\n\n    ids = inputs[\"input_ids\"]\n    mask = inputs[\"attention_mask\"]\n    token_type_ids = inputs[\"token_type_ids\"]\n\n    padding_length = max_len - len(ids)\n    ids = ids + ([0] * padding_length)\n    mask = mask + ([0] * padding_length)\n    token_type_ids = token_type_ids + ([0] * padding_length)\n\n    ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n    mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n    token_type_ids = torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n\n    ids = ids.to(DEVICE, dtype=torch.long)\n    token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n    mask = mask.to(DEVICE, dtype=torch.long)\n\n    outputs = model(\n        ids=ids,\n        mask=mask,\n        token_type_ids=token_type_ids\n    )\n\n    outputs = torch.sigmoid(outputs).cpu().detach().numpy()\n    return outputs[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/nlp-getting-started/test.csv')\ntest['target'] = test['text'].apply(sentence_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = test[['id','target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = sub['target'].round().astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using keywords for prediction improvement"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/nlp-getting-started/train.csv')\ntrain = train.fillna('None')\nag = train.groupby('keyword').agg({'text':np.size, 'target':np.mean}).rename(columns={'text':'Count', 'target':'Disaster Probability'})\nag.sort_values('Disaster Probability', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyword_list = list(ag[(ag['Count']>2) & (ag['Disaster Probability']>=0.9)].index)\nkeyword_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = test['id'][test.keyword.isin(keyword_list)].values\nsub['target'][sub['id'].isin(ids)] = 1\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I hope you find this kernel useful and enjoyable.\n\n\nand here you will find my notebook about working with text data in pandas : https://www.kaggle.com/nhoues1997/working-with-text-data-in-pandas\n\n\nYour comments and feedback are most welcome. \n"}],"metadata":{"colab":{"name":"Real_or_Not_! (1).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}