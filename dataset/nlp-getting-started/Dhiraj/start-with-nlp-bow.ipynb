{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nimport string\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.target.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.location.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.keyword.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.keyword.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.location.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.target.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation - Since, value for target variable is almost equal in number, we can apply machine learning algorithm on it."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nsns.barplot(train.target.value_counts().index, train.target.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.location.value_counts().nlargest(10)\nplt.figure(figsize=(10,4))\nsns.barplot(train.location.value_counts().nlargest(10),train.location.value_counts().nlargest(10).index, orient='h')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://stackoverflow.com/questions/26540035/rotate-label-text-in-seaborn-factorplot\n\n#train.keyword.value_counts().nlargest(20)\nplt.figure(figsize=(15,6))\nsns.barplot(train.keyword.value_counts().nlargest(20).index,train.keyword.value_counts().nlargest(20))\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing of text data"},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing\n1. Changing text to lower case\n2. Removal of stopwords, punctuation and html tags from data\n3. Stemming\n4. Lemmatization"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['low_text'] =  train['text'].str.lower()\ntest['low_text'] = test['text'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"string.punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\ntrain['aftr_punct'] = train['low_text'].str.translate(str.maketrans(\"\",\"\",string.punctuation))\ntest['aftr_punct'] = test['low_text'].str.translate(str.maketrans(\"\",\"\",string.punctuation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns',None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopword = stopwords.words('english')\nstopword","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopword = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", \n            'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', \n            'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n            'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', \n            'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n            'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', \n            'into','through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n            'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n            'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own',\n            'same', 'so', 'than', 'too', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm',\n            'o', 're', 've', 'y', 'ma',]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in stopword])\n\ntrain['stp_text'] = train['aftr_punct'].apply(lambda text: remove_stopwords(text))\ntest['stp_text'] = test['aftr_punct'].apply(lambda text: remove_stopwords(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()\ndef stem_word(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([stemmer.stem(word) for word in text.split()])\n\ntrain['stem_text'] = train['stp_text'].apply(lambda text: stem_word(text))\ntest['stem_text'] = test['stp_text'].apply(lambda text: stem_word(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n\ntrain['lemmatize_text'] = train['stp_text'].apply(lambda text: lemmatize_words(text))\ntest['lemmatize_text'] = test['stp_text'].apply(lambda text: lemmatize_words(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train[['id','keyword','location','lemmatize_text','target']]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = test[['id','keyword','location','lemmatize_text']]\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nwordcloud = WordCloud( background_color='white').generate(\" \".join(train_df['lemmatize_text']))\nplt.imshow(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting text to vector"},{"metadata":{},"cell_type":"markdown","source":"with test.fit_transform, we will get 11,713 features which are not same as train but with test.transform, we will get 21,032 features which are same as train"},{"metadata":{"trusted":true},"cell_type":"code","source":"bow = CountVectorizer()\ntrain_vector = bow.fit_transform(train_df['lemmatize_text'])\ntest_vector = bow.transform(test_df['lemmatize_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### https://www.kaggle.com/parulpandey/getting-started-with-nlp-a-general-intro"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression()\nscore = model_selection.cross_val_score(clf, train_vector, train_df['target'], cv=5, scoring='f1')\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(train_vector,train_df['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_nb = MultinomialNB()\nscore = model_selection.cross_val_score(clf_nb, train_vector, train_df['target'], cv=5, scoring='f1')\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_nb.fit(train_vector, train_df['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since Naive Bayes has more accuracy than Logistic Regression, we will use it to predict test dataset target value and for final submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"] = clf_nb.predict(test_vector)\nsample_submission.to_csv(\"submission.csv\", index=False)\n#sample_submission.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can upload this csv and check our score on LB. \n\n#### End of Notebook!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}