{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom collections import Counter\nfrom collections import defaultdict\nimport text_hammer as th\nimport missingno as msno\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom transformers import AutoTokenizer,TFBertModel\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nimport re\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.corpus import stopwords\nimport gensim\nfrom nltk.data import find\nfrom tensorflow.keras.layers import LSTM, Dense, Masking, Dropout\nfrom tensorflow.keras import Sequential, Input, optimizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import LearningRateSchedule\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Input, Model\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.utils import plot_model\nimport transformers\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments\nfrom transformers import TFBertModel, Trainer\nfrom tokenizers import Tokenizer\nfrom transformers import BertTokenizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nimport missingno as msno\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchmetrics\nfrom torchvision import transforms, models\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Callback, LightningModule, Trainer\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\nfrom tqdm.notebook import tqdm\nimport json\nfrom sklearn.metrics import precision_recall_fscore_support\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport re\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nimport transformers\nfrom transformers import BertModel, BertTokenizerFast\nfrom transformers import DistilBertModel, DistilBertTokenizerFast, AdamW\nfrom wordcloud import WordCloud\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:00:40.745448Z","iopub.execute_input":"2022-06-14T00:00:40.745919Z","iopub.status.idle":"2022-06-14T00:00:40.771672Z","shell.execute_reply.started":"2022-06-14T00:00:40.745885Z","shell.execute_reply":"2022-06-14T00:00:40.770471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Realizando a leitura do dataframe de treino","metadata":{}},{"cell_type":"code","source":"nlp_train = pd.read_csv('../input/nlp-getting-started/train.csv')\nnlp_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:00:43.392973Z","iopub.execute_input":"2022-06-14T00:00:43.395386Z","iopub.status.idle":"2022-06-14T00:00:43.452199Z","shell.execute_reply.started":"2022-06-14T00:00:43.395327Z","shell.execute_reply":"2022-06-14T00:00:43.451411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nnlp_test.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:00:44.360752Z","iopub.execute_input":"2022-06-14T00:00:44.361696Z","iopub.status.idle":"2022-06-14T00:00:44.392822Z","shell.execute_reply.started":"2022-06-14T00:00:44.361635Z","shell.execute_reply":"2022-06-14T00:00:44.391628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inserindo o esquema de cores\nO esquema de cores na linguagem de programação Python se estabelece a partir do uso a ser totalmente utilizado em que o notebook será analisado ou treinado, muitas das vezes bastante usado em visualização de dados.","metadata":{}},{"cell_type":"code","source":"custom_colors = ['#000000', '#E31E33', '#4A53E1', '#F5AD02', '#94D5EA', '#F6F8F7']\ncustom_palette = sns.set_palette(sns.color_palette(custom_colors))\nsns.palplot(sns.color_palette(custom_colors), size=1)\nplt.tick_params(axis='both', labelsize=0, length=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:00:46.830658Z","iopub.execute_input":"2022-06-14T00:00:46.831183Z","iopub.status.idle":"2022-06-14T00:00:46.943996Z","shell.execute_reply.started":"2022-06-14T00:00:46.831136Z","shell.execute_reply":"2022-06-14T00:00:46.942747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# using dataprep package - EDA\nfrom dataprep.eda import plot\nplot(nlp_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:01:44.252239Z","iopub.execute_input":"2022-06-14T00:01:44.253411Z","iopub.status.idle":"2022-06-14T00:01:45.100994Z","shell.execute_reply.started":"2022-06-14T00:01:44.253367Z","shell.execute_reply":"2022-06-14T00:01:45.099147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse Correlations\nfrom dataprep.eda import plot_correlation\nplot_correlation(nlp_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T00:02:31.375427Z","iopub.execute_input":"2022-06-14T00:02:31.375956Z","iopub.status.idle":"2022-06-14T00:02:31.827195Z","shell.execute_reply.started":"2022-06-14T00:02:31.375919Z","shell.execute_reply":"2022-06-14T00:02:31.826028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Buscando a contagem dos destinos de na coluna do dataframe Target.\nplt.title('Contagem dos destinos Target (0 e 1)')\nsns.countplot(nlp_train['target'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:57:25.384479Z","iopub.execute_input":"2022-06-13T14:57:25.384849Z","iopub.status.idle":"2022-06-13T14:57:25.549108Z","shell.execute_reply.started":"2022-06-13T14:57:25.384821Z","shell.execute_reply":"2022-06-13T14:57:25.548084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Buscando a contagem de cada desastre acontecido dentro do twitter.\nplt.figure(figsize = (15, 12))\nax = plt.axes()\nax.set_facecolor('white')\nax = sns.countplot(x = 'target', data = nlp_train, palette = [custom_colors[2], custom_colors[1]], edgecolor = 'white', linewidth = 1.2)\nplt.title('Contagem de desastres', fontsize = 25)\nplt.xlabel('Desastre', fontsize = 20)\nplt.ylabel('Contagem do desastre', fontsize = 20)\nax.xaxis.set_tick_params(labelsize = 15)\nax.yaxis.set_tick_params(labelsize = 15)\nbbox_args = dict(boxstyle = 'round', fc = '0.9')\nfor p in ax.patches:\n        ax.annotate('{:.0f} = {:.2f}%'.format(p.get_height(), (p.get_height() / len(nlp_train['target'])) * 100), (p.get_x() + 0.25, p.get_height() + 60), \n                   color = 'black',\n                   bbox = bbox_args,\n                   fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:57:26.648666Z","iopub.execute_input":"2022-06-13T14:57:26.649242Z","iopub.status.idle":"2022-06-13T14:57:26.857648Z","shell.execute_reply.started":"2022-06-13T14:57:26.649194Z","shell.execute_reply":"2022-06-13T14:57:26.85668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Buscando a contagens em cada coluna do dataframe.\nmsno.bar(nlp_train, color=(0, 0, 0), sort=\"ascending\", figsize=(15, 10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:57:28.884069Z","iopub.execute_input":"2022-06-13T14:57:28.88452Z","iopub.status.idle":"2022-06-13T14:57:29.464518Z","shell.execute_reply.started":"2022-06-13T14:57:28.884485Z","shell.execute_reply":"2022-06-13T14:57:29.463231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Palavras mais repetidas no dataframe de Treino e Teste.\nplt.figure(figsize=(15,40))\nprint(f'Buscando as Palavras-chave únicas no dataframe de treino = {len(nlp_train.keyword.unique())}')\nprint(f'Buscando as Palavras-chave únicas no dataframe de teste=  {len(nlp_test.keyword.unique())}')\nsns.countplot(y=nlp_train['keyword'], color=(0,0,1), label='Treino')\nsns.countplot(y=nlp_test['keyword'], color=(0,0,0), label='Teste')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:57:30.523359Z","iopub.execute_input":"2022-06-13T14:57:30.523761Z","iopub.status.idle":"2022-06-13T14:57:33.894576Z","shell.execute_reply.started":"2022-06-13T14:57:30.523727Z","shell.execute_reply":"2022-06-13T14:57:33.89345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deixando a contagem de palavras repetidas com uma visualização de dados mais limpa e mais bem visual.\nplt.figure(figsize=(15,100))\nsns.countplot(data=nlp_train, y='keyword', hue='target')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:57:33.89651Z","iopub.execute_input":"2022-06-13T14:57:33.897478Z","iopub.status.idle":"2022-06-13T14:57:37.82356Z","shell.execute_reply.started":"2022-06-13T14:57:33.897425Z","shell.execute_reply":"2022-06-13T14:57:37.822643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verificando as localizações dos desastres acontecidos.\nnlp_train['location'].value_counts()[:10]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:57:37.824796Z","iopub.execute_input":"2022-06-13T14:57:37.825125Z","iopub.status.idle":"2022-06-13T14:57:37.835727Z","shell.execute_reply.started":"2022-06-13T14:57:37.825096Z","shell.execute_reply":"2022-06-13T14:57:37.834746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 13))\nax = plt.axes()\nax.set_facecolor('white')\nax = ((nlp_train.location.value_counts())[:10]).plot(kind='bar', color=custom_colors[3], linewidth=2, edgecolor='white')\nplt.title('Contagem das localizações', fontsize=30)\nplt.xlabel('Localização', fontsize=25)\nplt.ylabel('Número da contagem', fontsize=25)\nax.xaxis.set_tick_params(labelsize=15, rotation=30)\nax.yaxis.set_tick_params(labelsize=15)\nbbox_args = dict(boxstyle='round', fc='0.9')\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x() + 0.15, p.get_height() + 2), bbox=bbox_args, color=custom_colors[0], fontsize=10)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:57:37.837204Z","iopub.execute_input":"2022-06-13T14:57:37.838532Z","iopub.status.idle":"2022-06-13T14:57:38.109644Z","shell.execute_reply.started":"2022-06-13T14:57:37.838477Z","shell.execute_reply":"2022-06-13T14:57:38.108721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Nesse treinamento estamos transformando os dados e classificando seus ajustes","metadata":{}},{"cell_type":"code","source":"text_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', SGDClassifier())\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:58:02.459693Z","iopub.execute_input":"2022-06-13T14:58:02.460101Z","iopub.status.idle":"2022-06-13T14:58:02.465382Z","shell.execute_reply.started":"2022-06-13T14:58:02.460067Z","shell.execute_reply":"2022-06-13T14:58:02.464117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_clf.fit(nlp_train['text'], nlp_train['target'])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:58:03.366901Z","iopub.execute_input":"2022-06-13T14:58:03.367374Z","iopub.status.idle":"2022-06-13T14:58:03.63852Z","shell.execute_reply.started":"2022-06-13T14:58:03.367321Z","shell.execute_reply":"2022-06-13T14:58:03.637396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Nesse treinamento usamos TF-IDF com a Regressão Logística","metadata":{}},{"cell_type":"code","source":"X = nlp_train['text']\ny = nlp_train['target']","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:58:06.137207Z","iopub.execute_input":"2022-06-13T14:58:06.13771Z","iopub.status.idle":"2022-06-13T14:58:06.142885Z","shell.execute_reply.started":"2022-06-13T14:58:06.137672Z","shell.execute_reply":"2022-06-13T14:58:06.142016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5)\ntrain_average_score = 0\nvalidation_average_score = 0\nvalidation_oof_predictions = np.zeros((len(X)))\n\nfor fold_n, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_test, y_test = X[test_idx], y[test_idx]\n    \n    model = Pipeline([\n        ('Encoder', TfidfVectorizer(max_features=None)),\n        ('Clf', LogisticRegression(penalty='l2', C=1, solver='liblinear'))\n    ])\n    \n    model.fit(X_train, y_train)\n    \n    train_predictions = model.predict_proba(X_train)[:, 1]\n    validation_predictions = model.predict_proba(X_test)[:, 1]\n    \n    train_score = roc_auc_score(y_train, train_predictions)\n    validation_score = roc_auc_score(y_test, validation_predictions)\n    \n    train_average_score += train_score / 5\n    validation_average_score += validation_score / 5\n    validation_oof_predictions[test_idx,] = (validation_predictions > 0.5).astype(int)\n    \nprint(f'Fold: {fold_n}, train auc: {train_score:.3f}, validation auc: {validation_score:.3f}')\nprint(f'Train average: {train_average_score:.3f}, validation average: {validation_average_score:.3f}')\nprint(f'OOF Accuracy Score: {accuracy_score(y, validation_oof_predictions)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:58:07.536877Z","iopub.execute_input":"2022-06-13T14:58:07.53759Z","iopub.status.idle":"2022-06-13T14:58:09.358635Z","shell.execute_reply.started":"2022-06-13T14:58:07.537538Z","shell.execute_reply":"2022-06-13T14:58:09.357923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prever e salvar para enviar","metadata":{}},{"cell_type":"code","source":"nlp_test['target'] = text_clf.predict(nlp_test['text'])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:58:09.360451Z","iopub.execute_input":"2022-06-13T14:58:09.360739Z","iopub.status.idle":"2022-06-13T14:58:09.419417Z","shell.execute_reply.started":"2022-06-13T14:58:09.360713Z","shell.execute_reply":"2022-06-13T14:58:09.418518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp_test[['id', 'target']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T14:58:10.380599Z","iopub.execute_input":"2022-06-13T14:58:10.381844Z","iopub.status.idle":"2022-06-13T14:58:10.394576Z","shell.execute_reply.started":"2022-06-13T14:58:10.3818Z","shell.execute_reply":"2022-06-13T14:58:10.393587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}