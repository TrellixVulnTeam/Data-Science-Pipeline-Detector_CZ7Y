{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Competition description\n\nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n\nBut, it’s not always clear whether a person’s words are actually announcing a disaster.\n\nAcknowledgments\n\nThis dataset was created by the company figure-eight and originally shared on their ‘Data For Everyone’ website here.","metadata":{}},{"cell_type":"markdown","source":"Import libraries","metadata":{}},{"cell_type":"code","source":"#import libraries\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:34.827393Z","iopub.execute_input":"2022-03-31T16:38:34.827956Z","iopub.status.idle":"2022-03-31T16:38:35.807212Z","shell.execute_reply.started":"2022-03-31T16:38:34.827904Z","shell.execute_reply":"2022-03-31T16:38:35.806262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loads train, test, and sample files","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-31T16:38:35.809707Z","iopub.execute_input":"2022-03-31T16:38:35.81004Z","iopub.status.idle":"2022-03-31T16:38:35.81714Z","shell.execute_reply.started":"2022-03-31T16:38:35.810008Z","shell.execute_reply":"2022-03-31T16:38:35.816226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load files:-\ntrain  = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsample_sub=pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-03-31T16:38:35.81842Z","iopub.execute_input":"2022-03-31T16:38:35.818826Z","iopub.status.idle":"2022-03-31T16:38:35.907685Z","shell.execute_reply.started":"2022-03-31T16:38:35.818797Z","shell.execute_reply":"2022-03-31T16:38:35.906442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:35.909178Z","iopub.execute_input":"2022-03-31T16:38:35.909597Z","iopub.status.idle":"2022-03-31T16:38:35.917496Z","shell.execute_reply.started":"2022-03-31T16:38:35.90956Z","shell.execute_reply":"2022-03-31T16:38:35.916373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Impute any null values","metadata":{}},{"cell_type":"code","source":"train.isnull().sum(), test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:35.921548Z","iopub.execute_input":"2022-03-31T16:38:35.922581Z","iopub.status.idle":"2022-03-31T16:38:35.94343Z","shell.execute_reply.started":"2022-03-31T16:38:35.922527Z","shell.execute_reply":"2022-03-31T16:38:35.942258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# substitue NaN value here with mode\n\ntrain['location'] = train['location'].fillna(train['location'].mode()[0])\ntrain['keyword'] = train['keyword'].fillna(train['keyword'].mode()[0])\n\ntest['location'] = test['location'].fillna(test['location'].mode()[0])\ntest['keyword'] = test['keyword'].fillna(test['keyword'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:35.947075Z","iopub.execute_input":"2022-03-31T16:38:35.947988Z","iopub.status.idle":"2022-03-31T16:38:35.966689Z","shell.execute_reply.started":"2022-03-31T16:38:35.94793Z","shell.execute_reply":"2022-03-31T16:38:35.965399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum().sum(), test.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:35.968089Z","iopub.execute_input":"2022-03-31T16:38:35.968494Z","iopub.status.idle":"2022-03-31T16:38:35.986715Z","shell.execute_reply.started":"2022-03-31T16:38:35.96846Z","shell.execute_reply":"2022-03-31T16:38:35.985504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:35.988781Z","iopub.execute_input":"2022-03-31T16:38:35.989742Z","iopub.status.idle":"2022-03-31T16:38:35.997769Z","shell.execute_reply.started":"2022-03-31T16:38:35.989688Z","shell.execute_reply":"2022-03-31T16:38:35.996478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare tweets in train and test file","metadata":{}},{"cell_type":"code","source":"#compare tweets in train and test file\nlength_train=train['text'].str.len()\nlength_test=test['text'].str.len()\nplt.hist(length_train, bins=20, label=\"train_tweets\")\nplt.hist(length_test, bins=20, label=\"test_tweets\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:35.999456Z","iopub.execute_input":"2022-03-31T16:38:35.999936Z","iopub.status.idle":"2022-03-31T16:38:36.308342Z","shell.execute_reply.started":"2022-03-31T16:38:35.999903Z","shell.execute_reply":"2022-03-31T16:38:36.307167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Identify percentage of disaster tweets","metadata":{}},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.310351Z","iopub.execute_input":"2022-03-31T16:38:36.310805Z","iopub.status.idle":"2022-03-31T16:38:36.32466Z","shell.execute_reply.started":"2022-03-31T16:38:36.310758Z","shell.execute_reply":"2022-03-31T16:38:36.323774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentage_disaster=(train.target.value_counts() / len(train.target)) * 100\npercentage_disaster","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.326016Z","iopub.execute_input":"2022-03-31T16:38:36.326494Z","iopub.status.idle":"2022-03-31T16:38:36.355958Z","shell.execute_reply.started":"2022-03-31T16:38:36.326446Z","shell.execute_reply":"2022-03-31T16:38:36.354835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = train.groupby('target')['target'].sum()\nlabel/len(train)*100","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.357525Z","iopub.execute_input":"2022-03-31T16:38:36.357972Z","iopub.status.idle":"2022-03-31T16:38:36.37116Z","shell.execute_reply.started":"2022-03-31T16:38:36.35794Z","shell.execute_reply":"2022-03-31T16:38:36.370373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby('target').text.count().plot.bar(ylim=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.372404Z","iopub.execute_input":"2022-03-31T16:38:36.37286Z","iopub.status.idle":"2022-03-31T16:38:36.498493Z","shell.execute_reply.started":"2022-03-31T16:38:36.372827Z","shell.execute_reply":"2022-03-31T16:38:36.497533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing raw text and getting it ready for machine learning","metadata":{}},{"cell_type":"code","source":"# Importing HTMLParser\nfrom html.parser import HTMLParser\nhtml_parser = HTMLParser()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.500385Z","iopub.execute_input":"2022-03-31T16:38:36.500823Z","iopub.status.idle":"2022-03-31T16:38:36.506304Z","shell.execute_reply.started":"2022-03-31T16:38:36.500779Z","shell.execute_reply":"2022-03-31T16:38:36.505204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Created a new columns i.e. clean_tweet contains the same tweets but cleaned version\ntrain['processed_text'] = train['text'].apply(lambda x: html_parser.unescape(x))\ntest['processed_text'] = test['text'].apply(lambda x: html_parser.unescape(x))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.507797Z","iopub.execute_input":"2022-03-31T16:38:36.508111Z","iopub.status.idle":"2022-03-31T16:38:36.54338Z","shell.execute_reply.started":"2022-03-31T16:38:36.508072Z","shell.execute_reply":"2022-03-31T16:38:36.54207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apostrophe Dictionary\napostrophe_dict = {\n\"ain't\": \"am not / are not\",\n\"aren't\": \"are not / am not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he had / he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he shall / he will\",\n\"he'll've\": \"he shall have / he will have\",\n\"he's\": \"he has / he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how has / how is\",\n\"i'd\": \"I had / I would\",\n\"i'd've\": \"I would have\",\n\"i'll\": \"I shall / I will\",\n\"i'll've\": \"I shall have / I will have\",\n\"i'm\": \"I am\",\n\"i've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it had / it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it shall / it will\",\n\"it'll've\": \"it shall have / it will have\",\n\"it's\": \"it has / it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she had / she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she shall / she will\",\n\"she'll've\": \"she shall have / she will have\",\n\"she's\": \"she has / she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as / so is\",\n\"that'd\": \"that would / that had\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that has / that is\",\n\"there'd\": \"there had / there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there has / there is\",\n\"they'd\": \"they had / they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they shall / they will\",\n\"they'll've\": \"they shall have / they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had / we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what shall / what will\",\n\"what'll've\": \"what shall have / what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what has / what is\",\n\"what've\": \"what have\",\n\"when's\": \"when has / when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where has / where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who shall / who will\",\n\"who'll've\": \"who shall have / who will have\",\n\"who's\": \"who has / who is\",\n\"who've\": \"who have\",\n\"why's\": \"why has / why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you had / you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you shall / you will\",\n\"you'll've\": \"you shall have / you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}\napostrophe_dict","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.545038Z","iopub.execute_input":"2022-03-31T16:38:36.545375Z","iopub.status.idle":"2022-03-31T16:38:36.57078Z","shell.execute_reply.started":"2022-03-31T16:38:36.54534Z","shell.execute_reply":"2022-03-31T16:38:36.569443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lookup_dict(text, dictionary):\n    for word in text.split():\n        if word.lower() in dictionary:\n            if word.lower() in text.split():\n                text = text.replace(word, dictionary[word.lower()])\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.572235Z","iopub.execute_input":"2022-03-31T16:38:36.572622Z","iopub.status.idle":"2022-03-31T16:38:36.582068Z","shell.execute_reply.started":"2022-03-31T16:38:36.572574Z","shell.execute_reply":"2022-03-31T16:38:36.581018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['processed_text'] = train['processed_text'].apply(lambda x: lookup_dict(x,apostrophe_dict))\ntest['processed_text'] = test['processed_text'].apply(lambda x: lookup_dict(x,apostrophe_dict))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.583111Z","iopub.execute_input":"2022-03-31T16:38:36.583396Z","iopub.status.idle":"2022-03-31T16:38:36.643867Z","shell.execute_reply.started":"2022-03-31T16:38:36.583369Z","shell.execute_reply":"2022-03-31T16:38:36.642542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"short_word_dict = {\n\"121\": \"one to one\",\n\"a/s/l\": \"age, sex, location\",\n\"adn\": \"any day now\",\n\"afaik\": \"as far as I know\",\n\"afk\": \"away from keyboard\",\n\"aight\": \"alright\",\n\"alol\": \"actually laughing out loud\",\n\"b4\": \"before\",\n\"b4n\": \"bye for now\",\n\"bak\": \"back at the keyboard\",\n\"bf\": \"boyfriend\",\n\"bff\": \"best friends forever\",\n\"bfn\": \"bye for now\",\n\"bg\": \"big grin\",\n\"bta\": \"but then again\",\n\"btw\": \"by the way\",\n\"cid\": \"crying in disgrace\",\n\"cnp\": \"continued in my next post\",\n\"cp\": \"chat post\",\n\"cu\": \"see you\",\n\"cul\": \"see you later\",\n\"cul8r\": \"see you later\",\n\"cya\": \"bye\",\n\"cyo\": \"see you online\",\n\"dbau\": \"doing business as usual\",\n\"fud\": \"fear, uncertainty, and doubt\",\n\"fwiw\": \"for what it's worth\",\n\"fyi\": \"for your information\",\n\"g\": \"grin\",\n\"g2g\": \"got to go\",\n\"ga\": \"go ahead\",\n\"gal\": \"get a life\",\n\"gf\": \"girlfriend\",\n\"gfn\": \"gone for now\",\n\"gmbo\": \"giggling my butt off\",\n\"gmta\": \"great minds think alike\",\n\"h8\": \"hate\",\n\"hagn\": \"have a good night\",\n\"hdop\": \"help delete online predators\",\n\"hhis\": \"hanging head in shame\",\n\"iac\": \"in any case\",\n\"ianal\": \"I am not a lawyer\",\n\"ic\": \"I see\",\n\"idk\": \"I don't know\",\n\"imao\": \"in my arrogant opinion\",\n\"imnsho\": \"in my not so humble opinion\",\n\"imo\": \"in my opinion\",\n\"iow\": \"in other words\",\n\"ipn\": \"I’m posting naked\",\n\"irl\": \"in real life\",\n\"jk\": \"just kidding\",\n\"l8r\": \"later\",\n\"ld\": \"later, dude\",\n\"ldr\": \"long distance relationship\",\n\"llta\": \"lots and lots of thunderous applause\",\n\"lmao\": \"laugh my ass off\",\n\"lmirl\": \"let's meet in real life\",\n\"lol\": \"laugh out loud\",\n\"ltr\": \"longterm relationship\",\n\"lulab\": \"love you like a brother\",\n\"lulas\": \"love you like a sister\",\n\"luv\": \"love\",\n\"m/f\": \"male or female\",\n\"m8\": \"mate\",\n\"milf\": \"mother I would like to fuck\",\n\"oll\": \"online love\",\n\"omg\": \"oh my god\",\n\"otoh\": \"on the other hand\",\n\"pir\": \"parent in room\",\n\"ppl\": \"people\",\n\"r\": \"are\",\n\"rofl\": \"roll on the floor laughing\",\n\"rpg\": \"role playing games\",\n\"ru\": \"are you\",\n\"shid\": \"slaps head in disgust\",\n\"somy\": \"sick of me yet\",\n\"sot\": \"short of time\",\n\"thanx\": \"thanks\",\n\"thx\": \"thanks\",\n\"ttyl\": \"talk to you later\",\n\"u\": \"you\",\n\"ur\": \"you are\",\n\"uw\": \"you’re welcome\",\n\"wb\": \"welcome back\",\n\"wfm\": \"works for me\",\n\"wibni\": \"wouldn't it be nice if\",\n\"wtf\": \"what the fuck\",\n\"wtg\": \"way to go\",\n\"wtgp\": \"want to go private\",\n\"ym\": \"young man\",\n\"gr8\": \"great\"\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.645579Z","iopub.execute_input":"2022-03-31T16:38:36.645885Z","iopub.status.idle":"2022-03-31T16:38:36.660669Z","shell.execute_reply.started":"2022-03-31T16:38:36.645858Z","shell.execute_reply":"2022-03-31T16:38:36.659617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['processed_text'] = train['processed_text'].apply(lambda x: lookup_dict(x,short_word_dict))\ntest['processed_text'] = test['processed_text'].apply(lambda x: lookup_dict(x,short_word_dict))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.662153Z","iopub.execute_input":"2022-03-31T16:38:36.662778Z","iopub.status.idle":"2022-03-31T16:38:36.72173Z","shell.execute_reply.started":"2022-03-31T16:38:36.662727Z","shell.execute_reply":"2022-03-31T16:38:36.720791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emoticon_dict = {\n\":)\": \"happy\",\n\":‑)\": \"happy\",\n\":-]\": \"happy\",\n\":-3\": \"happy\",\n\":->\": \"happy\",\n\"8-)\": \"happy\",\n\":-}\": \"happy\",\n\":o)\": \"happy\",\n\":c)\": \"happy\",\n\":^)\": \"happy\",\n\"=]\": \"happy\",\n\"=)\": \"happy\",\n\"<3\": \"happy\",\n\":-(\": \"sad\",\n\":(\": \"sad\",\n\":c\": \"sad\",\n\":<\": \"sad\",\n\":[\": \"sad\",\n\">:[\": \"sad\",\n\":{\": \"sad\",\n\">:(\": \"sad\",\n\":-c\": \"sad\",\n\":-< \": \"sad\",\n\":-[\": \"sad\",\n\":-||\": \"sad\"\n}\nemoticon_dict","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.72284Z","iopub.execute_input":"2022-03-31T16:38:36.723276Z","iopub.status.idle":"2022-03-31T16:38:36.732225Z","shell.execute_reply.started":"2022-03-31T16:38:36.723245Z","shell.execute_reply":"2022-03-31T16:38:36.731452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['processed_text'] = train['processed_text'].apply(lambda x: lookup_dict(x,emoticon_dict))\ntest['processed_text'] = test['processed_text'].apply(lambda x: lookup_dict(x,emoticon_dict))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.73329Z","iopub.execute_input":"2022-03-31T16:38:36.733705Z","iopub.status.idle":"2022-03-31T16:38:36.787667Z","shell.execute_reply.started":"2022-03-31T16:38:36.733675Z","shell.execute_reply":"2022-03-31T16:38:36.786684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\nstemmer = PorterStemmer()\nwords = stopwords.words(\"english\")\n\ntrain['processed_text'] = train['text'].apply(lambda x: \" \".join([stemmer.stem(i) \nfor i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n\ntest['processed_text'] = test['text'].apply(lambda x: \" \".join([stemmer.stem(i) \nfor i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:38:36.789003Z","iopub.execute_input":"2022-03-31T16:38:36.789304Z","iopub.status.idle":"2022-03-31T16:39:00.626589Z","shell.execute_reply.started":"2022-03-31T16:38:36.789254Z","shell.execute_reply":"2022-03-31T16:39:00.625561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\n\n#make all words lower case\ntrain['processed_text'] = train['processed_text'].str.lower()\ntest['processed_text'] = test['processed_text'].str.lower()\n\n#Remove punctuation\ntable = str.maketrans('', '', string.punctuation)\ntrain['processed_text'] = [train['processed_text'][row].translate(table) for row in range(len(train['processed_text']))]\ntest['processed_text'] = [test['processed_text'][row].translate(table) for row in range(len(test['processed_text']))]\n\n# remove hash tags\ntrain['processed_text'] = train['processed_text'].str.replace(\"#\", \" \")\ntest['processed_text'] = test['processed_text'].str.replace(\"#\", \" \")\n\n#remove words less than 1 character\ntrain['processed_text'] = train['processed_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\ntest['processed_text'] = test['processed_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:00.628063Z","iopub.execute_input":"2022-03-31T16:39:00.62843Z","iopub.status.idle":"2022-03-31T16:39:00.783231Z","shell.execute_reply.started":"2022-03-31T16:39:00.628398Z","shell.execute_reply":"2022-03-31T16:39:00.782441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#put frequent words in a mosiac\nfreq_words = ' '.join([text for text in train['processed_text']])\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(freq_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:00.784512Z","iopub.execute_input":"2022-03-31T16:39:00.784783Z","iopub.status.idle":"2022-03-31T16:39:01.881451Z","shell.execute_reply.started":"2022-03-31T16:39:00.784756Z","shell.execute_reply":"2022-03-31T16:39:01.875077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove rare words","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom itertools import chain\n\n# split words into lists\nv = train['processed_text'].str.split().tolist() \n# compute global word frequency\nc = Counter(chain.from_iterable(v))\n# filter, join, and re-assign\ntrain['processed_text'] = [' '.join([j for j in i if c[j] > 1]) for i in v]\n\n# split words into lists\nv = test['processed_text'].str.split().tolist() \n# compute global word frequency\nc = Counter(chain.from_iterable(v))\n# filter, join, and re-assign\ntest['processed_text'] = [' '.join([j for j in i if c[j] > 1]) for i in v]","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:01.882797Z","iopub.execute_input":"2022-03-31T16:39:01.883296Z","iopub.status.idle":"2022-03-31T16:39:01.945179Z","shell.execute_reply.started":"2022-03-31T16:39:01.883252Z","shell.execute_reply":"2022-03-31T16:39:01.944397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:01.94646Z","iopub.execute_input":"2022-03-31T16:39:01.946963Z","iopub.status.idle":"2022-03-31T16:39:01.969792Z","shell.execute_reply.started":"2022-03-31T16:39:01.946931Z","shell.execute_reply":"2022-03-31T16:39:01.969034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:01.97088Z","iopub.execute_input":"2022-03-31T16:39:01.971321Z","iopub.status.idle":"2022-03-31T16:39:01.988418Z","shell.execute_reply.started":"2022-03-31T16:39:01.971264Z","shell.execute_reply":"2022-03-31T16:39:01.987696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define X, y and X_test","metadata":{}},{"cell_type":"code","source":"#define x, y and t_test\ny=train.target\nX=train['processed_text']\nX_test=test['processed_text']","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:01.989402Z","iopub.execute_input":"2022-03-31T16:39:01.989772Z","iopub.status.idle":"2022-03-31T16:39:01.994707Z","shell.execute_reply.started":"2022-03-31T16:39:01.989743Z","shell.execute_reply":"2022-03-31T16:39:01.993647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split train set for training and testing","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.10, random_state=42, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:01.996217Z","iopub.execute_input":"2022-03-31T16:39:01.996555Z","iopub.status.idle":"2022-03-31T16:39:02.013562Z","shell.execute_reply.started":"2022-03-31T16:39:01.996526Z","shell.execute_reply":"2022-03-31T16:39:02.012521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, y_train.shape,y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:02.015131Z","iopub.execute_input":"2022-03-31T16:39:02.015572Z","iopub.status.idle":"2022-03-31T16:39:02.023387Z","shell.execute_reply.started":"2022-03-31T16:39:02.015529Z","shell.execute_reply":"2022-03-31T16:39:02.022372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting Text to Word Frequency Vectors with TfidfVectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\ntrain_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\nval_tfIdf = vectorizer_tfidf.transform(X_val.values.astype('U'))\nX_test_tfIdf = vectorizer_tfidf.transform(X_test.values.astype('U'))\nprint(vectorizer_tfidf.get_feature_names()[:5])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:02.029246Z","iopub.execute_input":"2022-03-31T16:39:02.02958Z","iopub.status.idle":"2022-03-31T16:39:02.173667Z","shell.execute_reply.started":"2022-03-31T16:39:02.029551Z","shell.execute_reply":"2022-03-31T16:39:02.172635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tfIdf.shape,  val_tfIdf.shape, X_test_tfIdf.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:02.175458Z","iopub.execute_input":"2022-03-31T16:39:02.175752Z","iopub.status.idle":"2022-03-31T16:39:02.182329Z","shell.execute_reply.started":"2022-03-31T16:39:02.175723Z","shell.execute_reply":"2022-03-31T16:39:02.181402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define and train the model","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\n\nmodel=XGBClassifier(max_depth=6, n_estimators=2000)              #MLPClassifier(early_stopping=True)\nmodel.fit(train_tfIdf, y_train)\n#create hyper parameters\npenalty=['l1', 'l2']\nC=np.logspace(0,4,10)\nhyperparameters=dict()   #penalty=penalty, C=C)\n#create grid search\nclf=GridSearchCV(model, hyperparameters, cv=5, verbose=0)\n#fit the model\nbest_model=clf.fit(train_tfIdf, y_train) # training the model\nprint(clf.score(train_tfIdf, y_train))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:39:02.183548Z","iopub.execute_input":"2022-03-31T16:39:02.183872Z","iopub.status.idle":"2022-03-31T16:40:21.890782Z","shell.execute_reply.started":"2022-03-31T16:39:02.183838Z","shell.execute_reply":"2022-03-31T16:40:21.889556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model.predict(val_tfIdf)\nprint(clf.score(val_tfIdf, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:40:21.892297Z","iopub.execute_input":"2022-03-31T16:40:21.892984Z","iopub.status.idle":"2022-03-31T16:40:21.979584Z","shell.execute_reply.started":"2022-03-31T16:40:21.892938Z","shell.execute_reply":"2022-03-31T16:40:21.978402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=best_model\ny_pred = model.predict_proba(val_tfIdf)\ny_pred = y_pred >= 0.3\ny_pred=y_pred.astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:40:21.981467Z","iopub.execute_input":"2022-03-31T16:40:21.982167Z","iopub.status.idle":"2022-03-31T16:40:22.027858Z","shell.execute_reply.started":"2022-03-31T16:40:21.982118Z","shell.execute_reply":"2022-03-31T16:40:22.026847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict_proba(val_tfIdf) # predicting on the validation set\nprediction_int = prediction[:,1] >= 0.3 # if prediction is greater than or equal to 0.3 then 1 else 0\nprediction_int = prediction_int.astype(np.int)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:40:22.029511Z","iopub.execute_input":"2022-03-31T16:40:22.030206Z","iopub.status.idle":"2022-03-31T16:40:22.076111Z","shell.execute_reply.started":"2022-03-31T16:40:22.030159Z","shell.execute_reply":"2022-03-31T16:40:22.075117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our Code - For Performance Evaluation\ndf=pd.DataFrame({'Actual': y_val, 'Predicted':prediction_int})\ndf","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:40:22.078135Z","iopub.execute_input":"2022-03-31T16:40:22.078905Z","iopub.status.idle":"2022-03-31T16:40:22.097502Z","shell.execute_reply.started":"2022-03-31T16:40:22.078854Z","shell.execute_reply":"2022-03-31T16:40:22.096378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual = []\nfor output in df['Actual']:\n    actual.append(output)\n\npredicted = []\nfor output in df['Predicted']:\n    predicted.append(output)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(predicted, actual)\ntn, fp, fn, tp = cm.ravel()\n\nprint(cm, tn, fp, fn, tp)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:40:22.099122Z","iopub.execute_input":"2022-03-31T16:40:22.099813Z","iopub.status.idle":"2022-03-31T16:40:22.114636Z","shell.execute_reply.started":"2022-03-31T16:40:22.099771Z","shell.execute_reply":"2022-03-31T16:40:22.113265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = (tp + tn)/(tp + tn + fp + fn)\nprint(\"accuracy: \", accuracy)\n\nprecision = (tp)/(tp + fp)\nprint(\"precision: \", precision)\n\nrecall = (tp)/(tp + fn)\nprint(\"recall: \", recall)\n\nf1 = 2*precision*recall/(precision+recall)\nprint(\"f1 score: \", f1)\n\nspecificity = (tn)/(tn+fp)\nprint(\"specficity: \", specificity)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T16:40:22.116322Z","iopub.execute_input":"2022-03-31T16:40:22.117023Z","iopub.status.idle":"2022-03-31T16:40:22.128852Z","shell.execute_reply.started":"2022-03-31T16:40:22.116981Z","shell.execute_reply":"2022-03-31T16:40:22.1276Z"},"trusted":true},"execution_count":null,"outputs":[]}]}