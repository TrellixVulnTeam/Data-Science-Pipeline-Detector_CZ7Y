{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"*Update V3 : Fixed calculation for LOGPRIOR value in the function create_naive_bayes_map*","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport tqdm.notebook as tqdm\nimport re\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.corpus import stopwords         \nfrom nltk.stem import PorterStemmer  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T03:41:44.826363Z","iopub.execute_input":"2022-04-26T03:41:44.827225Z","iopub.status.idle":"2022-04-26T03:41:44.834006Z","shell.execute_reply.started":"2022-04-26T03:41:44.827156Z","shell.execute_reply":"2022-04-26T03:41:44.832801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.tqdm_notebook.pandas()\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:44.835725Z","iopub.execute_input":"2022-04-26T03:41:44.836158Z","iopub.status.idle":"2022-04-26T03:41:44.852754Z","shell.execute_reply.started":"2022-04-26T03:41:44.836123Z","shell.execute_reply":"2022-04-26T03:41:44.852033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STOP_WORDS = stopwords.words('english') \nPUNCTUATIONS = '\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:44.854114Z","iopub.execute_input":"2022-04-26T03:41:44.854626Z","iopub.status.idle":"2022-04-26T03:41:44.867256Z","shell.execute_reply.started":"2022-04-26T03:41:44.85459Z","shell.execute_reply":"2022-04-26T03:41:44.865926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data\n***","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/nlp-getting-started/train.csv')\ntest_data = pd.read_csv('../input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:44.869236Z","iopub.execute_input":"2022-04-26T03:41:44.86953Z","iopub.status.idle":"2022-04-26T03:41:44.929706Z","shell.execute_reply.started":"2022-04-26T03:41:44.869495Z","shell.execute_reply":"2022-04-26T03:41:44.929002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:44.930865Z","iopub.execute_input":"2022-04-26T03:41:44.931628Z","iopub.status.idle":"2022-04-26T03:41:44.943219Z","shell.execute_reply.started":"2022-04-26T03:41:44.931588Z","shell.execute_reply":"2022-04-26T03:41:44.94224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text = re.sub(r'^RT[\\s]+', '', text)\n    text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)\n    text = re.sub(r'#', '', text)\n    return text\n\ndef remove_stop_words_and_puntuation(tokenized_text):\n    text_clean = []\n    \n    for word in tokenized_text:\n        if (word not in PUNCTUATIONS and word not in STOP_WORDS):\n            text_clean.append(word)\n            \n    return text_clean\n    \ndef stemm_text(tokenized_text):\n    text_stemm = []\n    \n    stemmer = PorterStemmer()\n    \n    for word in tokenized_text:\n        text_stemm.append(stemmer.stem(word))\n        \n    return text_stemm\n\ndef process_text(text):\n    text = clean_text(text)\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n                               reduce_len=True)\n    text = tokenizer.tokenize(text)\n    \n    text = remove_stop_words_and_puntuation(text)\n    text = stemm_text(text)\n            \n    return text\n\ndef create_frequency_map(data: pd.DataFrame, process_text_enabled = False):\n    data_dict = data.to_dict()\n\n    frequency_map = {}\n\n    for idx in tqdm.tqdm_notebook(range(len(data_dict[\"id\"]))):\n        if process_text_enabled == True:\n            words = process_text(data_dict[\"text\"][idx])\n        else:\n            words = data_dict[\"text\"][idx]\n            \n        for word in words:\n            target = data_dict[\"target\"][idx]\n            \n            if (word.lower(), target) in frequency_map:\n                frequency_map[(word.lower(), target)] += 1\n            else:\n                frequency_map[(word.lower(), target)] = 1\n\n    return frequency_map\n    \ndef process_train_data(train_data : pd.DataFrame):\n    data = train_data.copy()\n    \n    data['processed_text'] = data['text'].progress_apply(lambda x : process_text(x)) \n    \n    return data\n\ndef create_naive_bayes_map(data : pd.DataFrame, process_text_enabled):\n    \n    data_dict = data.to_dict()\n\n    naive_bayes_map = {}\n\n    frequency_map = create_frequency_map(data, process_text_enabled)\n    total_pos = 0.0\n    total_neg = 0.0\n    unique_words = {}\n   \n    for key in frequency_map:\n        if key[1] == 1:\n            total_pos += frequency_map[key]\n        else:\n            total_neg += frequency_map[key]\n        if key[0] not in unique_words:\n            unique_words[key[0]] = []\n            \n    total_unique_words = len(unique_words)\n    \n    total_target_pos = 0\n    total_target_neg = 0\n    \n    for idx in data_dict['target']:\n        if data_dict['target'][idx] == 1:\n            total_target_pos += 1\n        else:\n            total_target_neg += 1\n    \n    for key in frequency_map:\n\n        if key[0] not in naive_bayes_map:\n                naive_bayes_map[key[0]] = {'pos': 0.0, 'neg': 0.0, \n                                           'pos_smooth' : 1 / (total_pos + total_unique_words), \n                                           'neg_smooth' : 1 / (total_neg + total_unique_words) }\n\n        if key[1] == 1:\n            naive_bayes_map[key[0]]['pos'] = frequency_map[key] /  total_pos\n            naive_bayes_map[key[0]]['pos_smooth'] = calculate_laplacian_smoothing(frequency_map[key], total_pos, total_unique_words)\n            \n        else:\n            naive_bayes_map[key[0]]['neg'] = frequency_map[key] / total_neg\n            naive_bayes_map[key[0]]['neg_smooth'] = calculate_laplacian_smoothing(frequency_map[key], total_neg, total_unique_words)\n            \n    \n    for key in naive_bayes_map:\n        word_lambda = np.log(naive_bayes_map[key]['pos_smooth'] / naive_bayes_map[key]['neg_smooth'])\n        naive_bayes_map[key]['lambda'] = word_lambda\n    \n    log_prior = np.log(total_target_pos/total_target_neg)\n    \n    sum_pos = 0\n    sum_neg = 0\n    sum_pos_smooth = 0\n    sum_neg_smooth = 0                         \n                             \n    for key in naive_bayes_map:\n        sum_pos += naive_bayes_map[key]['pos']\n        sum_neg += naive_bayes_map[key]['neg']\n        sum_pos_smooth += naive_bayes_map[key]['pos_smooth']\n        sum_neg_smooth += naive_bayes_map[key]['neg_smooth']\n        \n    \n    \n    print(f'POS : {total_pos}, NEG :{total_neg}, Unique_words : {total_unique_words}, LOG_PRIOR : {log_prior}')\n    print(f'SUM_POS : {sum_pos}, SUM_NEG : {sum_neg}, SUM_POS_SMOOTH : {sum_pos_smooth}, SUM_NEG_SMOOTH : {sum_neg_smooth}')\n        \n   \n    return naive_bayes_map, log_prior\n \ndef calculate_laplacian_smoothing(freq_value, total , total_unique_words):\n    return (freq_value + 1) / (total + total_unique_words)\n\ndef sigmoid(z): \n    \n    h =  1/(1 + np.exp(-z))\n    \n    return h","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:44.945072Z","iopub.execute_input":"2022-04-26T03:41:44.945388Z","iopub.status.idle":"2022-04-26T03:41:44.975283Z","shell.execute_reply.started":"2022-04-26T03:41:44.945328Z","shell.execute_reply":"2022-04-26T03:41:44.974551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(text, process_text_enabled = True):\n    \n    if process_text_enabled == True:\n        text = process_text(text)\n    \n    score = 0\n    for word in text:\n        if word in NAIVE_BAYES_MAP:\n            score += NAIVE_BAYES_MAP[word]['lambda']\n        \n    return score + LOG_PRIOR","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:44.976648Z","iopub.execute_input":"2022-04-26T03:41:44.977436Z","iopub.status.idle":"2022-04-26T03:41:44.996878Z","shell.execute_reply.started":"2022-04-26T03:41:44.977386Z","shell.execute_reply":"2022-04-26T03:41:44.996027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Na√Øve Bayes Map\n***","metadata":{}},{"cell_type":"code","source":"NAIVE_BAYES_MAP, LOG_PRIOR = create_naive_bayes_map(train_data, process_text_enabled=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:45.079003Z","iopub.execute_input":"2022-04-26T03:41:45.079306Z","iopub.status.idle":"2022-04-26T03:41:49.52464Z","shell.execute_reply.started":"2022-04-26T03:41:45.079274Z","shell.execute_reply":"2022-04-26T03:41:49.523573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_naive_bayes_map = pd.DataFrame(NAIVE_BAYES_MAP)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:49.526278Z","iopub.execute_input":"2022-04-26T03:41:49.526531Z","iopub.status.idle":"2022-04-26T03:41:50.032368Z","shell.execute_reply.started":"2022-04-26T03:41:49.526501Z","shell.execute_reply":"2022-04-26T03:41:50.031398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_naive_bayes_map.T.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:50.034396Z","iopub.execute_input":"2022-04-26T03:41:50.034738Z","iopub.status.idle":"2022-04-26T03:41:50.050885Z","shell.execute_reply.started":"2022-04-26T03:41:50.034693Z","shell.execute_reply":"2022-04-26T03:41:50.049644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_naive_bayes_map.T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:50.052608Z","iopub.execute_input":"2022-04-26T03:41:50.052964Z","iopub.status.idle":"2022-04-26T03:41:50.086996Z","shell.execute_reply.started":"2022-04-26T03:41:50.05293Z","shell.execute_reply":"2022-04-26T03:41:50.086152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Words most likely to denote Disaster\n***","metadata":{}},{"cell_type":"code","source":"df_naive_bayes_map.T.sort_values(by=['lambda'], ascending=False).head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:50.089095Z","iopub.execute_input":"2022-04-26T03:41:50.089365Z","iopub.status.idle":"2022-04-26T03:41:50.10689Z","shell.execute_reply.started":"2022-04-26T03:41:50.089312Z","shell.execute_reply":"2022-04-26T03:41:50.106273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Words less likely to denote Disaster\n***","metadata":{}},{"cell_type":"code","source":"df_naive_bayes_map.T.sort_values(by=['lambda'], ascending=True).head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:50.10829Z","iopub.execute_input":"2022-04-26T03:41:50.108665Z","iopub.status.idle":"2022-04-26T03:41:50.126053Z","shell.execute_reply.started":"2022-04-26T03:41:50.108627Z","shell.execute_reply":"2022-04-26T03:41:50.125401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test\n***","metadata":{}},{"cell_type":"code","source":"idx = 15\ntarget = train_data['target'][idx]\ntext = train_data['text'][idx]\nprobability = predict(text)\n\nprint(f'{target} : {sigmoid(probability)} - {text}')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:50.127196Z","iopub.execute_input":"2022-04-26T03:41:50.12757Z","iopub.status.idle":"2022-04-26T03:41:50.133779Z","shell.execute_reply.started":"2022-04-26T03:41:50.12754Z","shell.execute_reply":"2022-04-26T03:41:50.1328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n***","metadata":{}},{"cell_type":"code","source":"def create_submission(data : pd.DataFrame):\n    data_dict = test_data.to_dict()\n    \n    submission = {'id': [], 'target' :[]}\n    \n    for idx in tqdm.tqdm_notebook(range(len(data_dict[\"id\"]))):\n        submission['id'].append(data_dict[\"id\"][idx])\n        \n        pred = 1 if sigmoid(predict(data_dict[\"text\"][idx])) >=0.5 else 0\n        \n        submission['target'].append(pred)\n            \n    return submission","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:50.135409Z","iopub.execute_input":"2022-04-26T03:41:50.135936Z","iopub.status.idle":"2022-04-26T03:41:50.147159Z","shell.execute_reply.started":"2022-04-26T03:41:50.13589Z","shell.execute_reply":"2022-04-26T03:41:50.146445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = create_submission(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:50.148139Z","iopub.execute_input":"2022-04-26T03:41:50.148417Z","iopub.status.idle":"2022-04-26T03:41:52.099683Z","shell.execute_reply.started":"2022-04-26T03:41:50.148383Z","shell.execute_reply":"2022-04-26T03:41:52.09865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.DataFrame(submission)\ndf_submission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:52.100948Z","iopub.execute_input":"2022-04-26T03:41:52.101188Z","iopub.status.idle":"2022-04-26T03:41:52.116575Z","shell.execute_reply.started":"2022-04-26T03:41:52.101158Z","shell.execute_reply":"2022-04-26T03:41:52.115569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"execution":{"iopub.status.busy":"2022-04-26T03:41:52.117841Z","iopub.execute_input":"2022-04-26T03:41:52.118155Z","iopub.status.idle":"2022-04-26T03:41:52.132841Z","shell.execute_reply.started":"2022-04-26T03:41:52.118119Z","shell.execute_reply":"2022-04-26T03:41:52.131853Z"},"trusted":true},"execution_count":null,"outputs":[]}]}