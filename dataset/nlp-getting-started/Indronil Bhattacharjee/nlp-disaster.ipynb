{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tweet=df_train['text']\ny_train=df_train['target']\ntest_tweet=df_test['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import TweetTokenizer\ndef process_tweet(tweet):\n    stemmer = PorterStemmer()\n    stopword = stopwords.words('english')\n    tweet = re.sub(r'\\$\\w*', '', tweet)\n    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n    tweet = re.sub(r'#', '', tweet)\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=False)\n    tweet_tokens = tokenizer.tokenize(tweet)\n    tweets_clean = \"\"\n    for word in tweet_tokens:\n        if (word not in stopword and word not in punctuation):\n            stem_word = stemmer.stem(word)\n            tweets_clean=tweets_clean+stem_word+\" \"\n    return tweets_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets=[]\nfor i in range(0,len(train_tweet)):\n    tweets.append(process_tweet(train_tweet[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_tweets=[]\nfor i in range(0,len(test_tweet)):\n    t_tweets.append(process_tweet(test_tweet[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_tweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import feature_extraction\ncount_vectorizer = feature_extraction.text.TfidfVectorizer()\nx_train = count_vectorizer.fit_transform(tweets)\nx_test = count_vectorizer.transform(t_tweets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=x_train.toarray()\nx_test=x_test.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(C=1.0, penalty='l2', max_iter=500) \nlr.fit(x_train, y_train)\ny_test=lr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrforest = RandomForestClassifier(n_estimators = 1000, random_state = 1) \nrforest.fit(x_train,y_train)\ny_test = rforest.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_test =df_test['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = pd.DataFrame()\ndf3['id'] = id_test.tolist()\ndf3['target'] = y_test.tolist()\ndf3.to_csv(\"./file.csv\", sep=',',index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.target.value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}