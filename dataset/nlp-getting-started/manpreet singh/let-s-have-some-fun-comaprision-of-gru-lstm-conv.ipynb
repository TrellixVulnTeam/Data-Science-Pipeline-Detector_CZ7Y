{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n#from dataprep.eda import plot\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ntest_data=pd.read_csv(\"../input/nlp-getting-started/test.csv\")\nsample=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# dot head() will show dataframe upto five rows, niiiiceeee","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ahan, from Dataframe to Numpy array.\n> dot values will have all the credit\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X=train_data.text.values\ntrain_y=train_data.target.values\ntest_X=test_data.text.values\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Okie, remove all bullshit from text*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nREPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\nBAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\nSTOPWORDS = set(stopwords.words('english'))\n\ndef preprocess(text):\n    \"\"\"\n        text: a string\n        \n        return: modified initial string\n    \"\"\"\n    text = text.lower()# lowercase text\n    text = REPLACE_BY_SPACE_RE.sub('',text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n    text = BAD_SYMBOLS_RE.sub('', text)# delete symbols which are in BAD_SYMBOLS_RE from text\n    text = ' '.join([x for x in text.split() if x and x not in STOPWORDS]) # delete stopwords from text\n    return text\ntrain_X=[preprocess(x) for x in train_X]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X,val_X,train_y,val_y=train_test_split(train_X,train_y,shuffle=True)\nprint(train_X[:5])\nprint(\"--------------------------\")\nprint(train_y[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X=np.array(train_X)\ntrain_X.shape,train_X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have words but our NN can't really understand them , ughh**\n\n> WHYYYYYYYYYY ???, so much drama NN.\n\n**so we do need to tokenize them and convert into sequences**\n\n*I am TENSORFLOW, i got your back..*\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size=1000\ntrun='post'\nmax_length=150\ntokenizer=Tokenizer(num_words=vocab_size,oov_token='<OOV>')\ntokenizer.fit_on_texts(train_X)\nword_index=tokenizer.word_index\nseq=tokenizer.texts_to_sequences(train_X)\npadded=pad_sequences(seq,maxlen=max_length,truncating=trun,padding='post')\n\nval_seq=tokenizer.texts_to_sequences(val_X)\nval_padded=pad_sequences(val_seq,maxlen=max_length,truncating=trun,padding='post')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Uncomment below and see majiiicccc ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#word_index.items()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Embedding network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_emb=tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,20,input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D() ,\n    tf.keras.layers.Dense(64,activation='elu'),\n    tf.keras.layers.Dense(128,activation='elu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(264,activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(264,activation='elu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(264,activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_emb.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\nhistory=model_emb.fit(padded,train_y,epochs=20,validation_data=(val_padded,val_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def want_plot_call_me(history,string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string,'val_'+string])\n    plt.show()\n    \nwant_plot_call_me(history,'accuracy')\nwant_plot_call_me(history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_and_sub(testt,model,name):\n    '''\n        This guy will save model into csv.\n        testt: test set\n        model: NN model\n        name: file name\n    '''\n    test=[preprocess(x) for x in testt]\n    test=np.array(test)\n    test_seq=tokenizer.texts_to_sequences(test)\n    test_padded=pad_sequences(test_seq,maxlen=max_length,truncating=trun,padding='post')  \n    pred=model.predict(test_padded).squeeze()\n    pred=[1 if x>0.5 else 0 for x in pred]\n    pred=np.array(pred)\n    sample.target=pred\n    sample.to_csv(name,index=False)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets do submission part","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_sub(test_X,model_emb,\"model_emb.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Turn for CONV1d boi","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cnv=tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,20,input_length=max_length),\n    tf.keras.layers.Conv1D(64,5,activation='relu'),\n    tf.keras.layers.GlobalAveragePooling1D() ,\n    tf.keras.layers.Dense(64,activation='elu'),\n    tf.keras.layers.Dense(128,activation='elu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(264,activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(264,activation='elu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(264,activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cnv.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\nhistory=model_cnv.fit(padded,train_y,epochs=20,validation_data=(val_padded,val_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"want_plot_call_me(history,'accuracy')\nwant_plot_call_me(history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_sub(test_X,model_cnv,\"model_cnv.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# why not The Great LLLLLSSSSTTTMMMMM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm=tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,25,input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(264,activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\nhistory=model_lstm.fit(padded,train_y,epochs=20,validation_data=(val_padded,val_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"want_plot_call_me(history,'accuracy')\nwant_plot_call_me(history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_sub(test_X,model_lstm,\"model_lstm.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gru=tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,20,input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n    tf.keras.layers.Dense(64,activation='elu'),\n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(264,activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(512,activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(264,activation='elu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(264,activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gru.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\nhistory=model_gru.fit(padded,train_y,epochs=20,validation_data=(val_padded,val_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"want_plot_call_me(history,'accuracy')\nwant_plot_call_me(history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_sub(test_X,model_gru,\"model_gru.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}