{"cells":[{"metadata":{},"cell_type":"markdown","source":"# In this notebook,i am explaining some basic visualisations on text data.If you are a beginner to NLP,please watch below notebook where i explained some concepts in NLP.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/sainathkrothapalli/beginners-approach-to-nlp-problems","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting countplot to see the categories count visually.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.countplot(data['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also use pie chart to percentage of both categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['target'].value_counts().head(10).plot.pie(autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Location and keyword feature","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First checking top 10 location from where the tweets are coming.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['location'].value_counts()[:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now plotting top 10 keywords,as shown below fatalities is top keyword","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['keyword'].value_counts()[:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now plotting the top 10 locations where disaster tweets are coming,as shown below USA tops the list.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['target']==1]['location'].value_counts()[:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text feature","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Word count","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First writing a function to find length of the words in the text and applying it to text feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def wl(text):\n    return len(text.split(\" \"))\ndata['word_length']=data['text'].apply(wl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now plotting the word_length,as shown below most of the words in a sentence are between 8 and 22.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['word_length'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now plotting kdeplots,to see the distribution of word_length with respect to disaster and real tweets.As shown below,word_length of both real and disaster tweets lies between 5 and 28,and some of the disaster word count is more than 40.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data[data['target']==1]['word_length'],color='g')\nsns.kdeplot(data[data['target']==0]['word_length'],color='r')\nplt.legend(['disaster','real'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using the bar plots to check word count in tweets,as shown below disaster tweets has more word count.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='target',y='word_length',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Character count","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here also we  are doing the same way as above,first creating a feature called char_length and plotting the distribution using histogram-as shown below many tweets are having char count more than 100.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['char_length']=data['text'].apply(len)\ndata['char_length'].hist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data[data['target']==1]['char_length'],color='g')\nsns.kdeplot(data[data['target']==0]['char_length'],color='r')\nplt.legend(['disaster','real'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='target',y='char_length',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using scatterplot to check if there is any relation b/w char count and word count,as shown below there is positive relation that means if char count increases the word count increases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='char_length',y='word_length',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using plobability plot to see if there are normally distributed or not.As shown below word_length is some what normally distributes where as char_length is not. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nimport statsmodels.api as sm \nstats.probplot(data['char_length'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.probplot(data['word_length'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unique words in tweets","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here also we are creating a feature called unique_word_count,and plotting it using histogram,as shown below most unique word count lies b/w 8 and 22.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['unique_word_count'] =data['text'].apply(lambda x: len(set(str(x).split())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['unique_word_count'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data[data['target']==1]['unique_word_count'],color='g')\nsns.kdeplot(data[data['target']==0]['unique_word_count'],color='r')\nplt.legend(['disaster','real'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using scatterplot to check if there is any relation b/w unique word count and word count,as shown below there is almost positive relation that means if unique word count increases the word count increases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='unique_word_count',y='word_length',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using scatterplot to check if there is any relation b/w char count and  unique word count,as shown below there is positive relation that means if char count increases the unique word count increases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='char_length',y='unique_word_count',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stop words count","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing nesessary libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now creating feature called stop_words which consist of len of stop words in each tweet.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" all_stopwords = stopwords.words('english')\ndata['stop_words']=data['text'].apply(lambda x: len([words for words in str(x).lower().split() if words in all_stopwords]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From below histogram,we can say that we can say that,stop words count for most of the tweets is less than 8.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['stop_words'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From below bar plot we can say stop words count is less in disaster tweets than real ones.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='target',y='stop_words',data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data[data['target']==1]['stop_words'],color='g')\nsns.kdeplot(data[data['target']==0]['stop_words'],color='r')\nplt.legend(['disaster','real'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using scatterplot to check if there is any relation b/w stop words and remaing three created feature,as shown below there is some positive relation b/w stop words and (word_length,unique_word_count)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features=['word_length','char_length','unique_word_count']\nfor i in features:\n    sns.scatterplot(x=i,y='stop_words',data=data)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can clearly see the correlation b/w the features using below heatmap.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=data.corr()\nsns.heatmap(corr,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown above unique_word_count and word_length has 0.97 correlation.\n               unique_word_count and char_length has 0.85 correlation.\n               char_length and word_length has 0.83 correlation.\n               word_length and stop words has 0.75 correlation.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Simple code to get bigrams","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is th simple code to get bigrams from text.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.util import ngrams\ndef get_bigram(text):\n    big=''\n    token = nltk.word_tokenize(text)\n    big=(list(ngrams(token, 2)))\n    return str(big)    \ndata['bigram']=data['text'].apply(get_bigram)       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['bigram']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Please upvote if you like,any suggestions and mistakes put it in comments,Thank you.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}