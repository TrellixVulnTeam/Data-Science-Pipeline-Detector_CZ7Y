{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Vectorizers** - #1 micro challenge\n# Rules\nI have an idea of an alternative challenge format for a while. I want to test it.\nIn short, it's a short challenge with specific measurable goals to be achieved.\n\nIn this challenge, you are given a fixed pipeline and only can change the vectorization process. The vectorization method interface is fixed, the rest is up to you.\n\nIn order to compete, you need to **make your Kaggle notebook public**.\n\n# Challenge [data](https://www.kaggle.com/c/nlp-getting-started/data)\nData is the same as for the official competition, you can read description here https://www.kaggle.com/c/nlp-getting-started/data\n\n# Goals\n- ü•â Bronze. F1-score >= **0.80** at **public** leaderboard \n- ü•à Silver. F1-score >= **0.81** at **public** leaderboard\n- ü•á Gold. F1-score >= **0.81** at **public** leaderboard + runtime is below **1 minute**\n\n# [Submit](https://forms.gle/H8MPo4xpu4NDVsX49)\nYou can submit your **public** Kaggle notebook via this [link](https://forms.gle/H8MPo4xpu4NDVsX49) \n# [Leaderboard](http://bit.ly/36pSp3S) \nThe final leaderboard is sorted by a medal type and then by submission time. The earlier you achieved the goal is better. You can see current leaderboard by this [link](http://bit.ly/36pSp3S)"},{"metadata":{},"cell_type":"markdown","source":"# Fixed pipeline\nIn order to participate, the part below need to be unchanged"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom joblib import Parallel, delayed\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import f1_score\nimport scipy\n\n\ndef simple_pipeline():\n    print(\"Load data\")\n    train, test = load_data()\n    \n    data = pd.concat([train, test], axis=0, ignore_index=True)\n    print(\"Vectorization\")\n    X = vectorization(data.drop('target', axis=1))\n    if type(X) == scipy.sparse.coo_matrix:\n        X = X.tocsr()\n        \n    test_mask = data.is_test.values\n    \n    X_train = X[~test_mask]\n    y_train = data['target'][~test_mask]\n    \n    X_test = X[test_mask]\n    if scipy.sparse.issparse(X):\n        X_train.sort_indices()\n        X_test.sort_indices()\n\n    model = build_model(X_train, y_train)\n    \n    print(\"Prediction with model\")\n    p = model.predict(X_test)\n    \n    print(\"Generate submission\")\n    make_submission(data[test_mask], p)\n\n\ndef load_data():\n    train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n    train['is_test'] = False\n    \n    test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n    test['target'] = -1\n    test['is_test'] = True\n    \n    return train, test\n\n\ndef calculate_validation_metric(model, X, y, metric):\n    folds = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n    score = cross_val_score(model, X, y, scoring=metric, cv=folds, n_jobs=4)\n    \n    return np.mean(score), model\n\n\ndef select_model(X, y):\n    models = [\n        LinearSVC(C=30),\n        LinearSVC(C=10),\n        LinearSVC(C=3),\n        LinearSVC(C=1),\n        LinearSVC(C=0.3),\n        LinearSVC(C=0.1),\n        LinearSVC(C=0.03),\n        RidgeClassifier(alpha=30),\n        RidgeClassifier(alpha=10),\n        RidgeClassifier(alpha=3),\n        RidgeClassifier(alpha=1),\n        RidgeClassifier(alpha=0.3),\n        RidgeClassifier(alpha=0.1),\n        RidgeClassifier(alpha=0.03),\n        LogisticRegression(C=30),\n        LogisticRegression(C=10),\n        LogisticRegression(C=3),\n        LogisticRegression(C=1),\n        LogisticRegression(C=0.3),\n        LogisticRegression(C=0.1),\n        LogisticRegression(C=0.03),\n    ]\n    \n    results = [calculate_validation_metric(\n        model, X, y, 'f1_macro',\n    ) for model in models]\n\n    best_result, best_model = max(results, key = lambda x: x[0]) \n    print(\"Best model validation result: {:.4f}\".format(best_result))\n    print(\"Best model: {}\".format(best_model))\n    \n    return best_model\n\n\ndef build_model(X, y):\n    print(\"Selecting best model\")\n    best_model = select_model(X, y)\n    \n    print(\"Refit model to full dataset\")\n    best_model.fit(X, y)\n    \n    return best_model\n\n    \ndef make_submission(data, p):\n    submission = data[['id']].copy()\n    submission['target'] = p\n    submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Your part\n## In *vectorization* method you can change everything and use any dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models.word2vec import Word2Vec \nimport re\nimport nltk\nfrom nltk import wordpunct_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom scipy.sparse import hstack\n\ndef text_to_sent(t):\n    wordnet_lemmatizer = WordNetLemmatizer()\n    text = t.fillna(\"\").str.lower()\n    sentences = text.str.split().apply(lambda x: [wordnet_lemmatizer.lemmatize(w) for w in x])\n    return [[y for y in x if re.match('[–∞-—è—ëa-z0-9]', y)]\n            for x in sentences]\n\ndef vectorization(data):\n    \"\"\"\n    data is concatenated train and test datasets with target excluded\n    Result value \"vectors\" expected to have some number of rows as data\n    \"\"\"\n    \n    word_vec = TfidfVectorizer(\n        ngram_range=(1, 1),\n        max_df=0.99,\n        min_df=2,\n        use_idf=True,\n        smooth_idf=True,\n        sublinear_tf=False,\n        norm='l2'\n    )\n    \n    char_vec = TfidfVectorizer(\n    analyzer='char_wb',\n    ngram_range=(3, 8), \n    max_df=0.99, \n    min_df=0.001,\n    use_idf=True,\n    smooth_idf=True,\n    sublinear_tf=False,\n    norm='l2'\n    )\n    \n    text = data['text'].fillna('')\n    char_vectors = char_vec.fit_transform(text)\n    \n    word_vectors = word_vec.fit_transform(text)\n#     vectors =  hstack((char_vectors, word_vectors))\n\n    sentences = text_to_sent(data['text'])\n\n    num_features = 300  # –∏—Ç–æ–≥–æ–≤–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞\n    min_word_count = 2  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å —Å–ª–æ–≤–∞, —á—Ç–æ–±—ã –æ–Ω–æ –ø–æ–ø–∞–ª–æ –≤ –º–æ–¥–µ–ª—å\n    num_workers = 8     # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä –≤–∞—à–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞, —á—Ç–æ–± –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤\n    context = 10        # —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ \n    downsampling = 1e-3 # –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –º–µ—Ç—Ä–∏–∫–∞ –º–æ–¥–µ–ª–∏\n\n    model = Word2Vec(sentences, workers=num_workers, size=num_features,\n                     min_count=min_word_count, window=context, sample=downsampling)\n    \n    index2word_set = set(model.wv.index2word)\n    \n    def text_to_vec(words):\n        text_vec = np.zeros((300,), dtype=\"float32\")\n        n_words = 0\n        for word in words:\n            if word in index2word_set:\n                n_words = n_words + 1\n                text_vec = np.add(text_vec, model.wv[word])\n        if n_words != 0:\n            text_vec /= n_words\n        return text_vec\n    \n    texts_vecs = np.zeros((len(data['text']), 300), dtype=\"float32\")\n\n    for i, s in enumerate(sentences):\n        texts_vecs[i] = text_to_vec(s)\n        \n    vectors =  hstack((char_vectors, texts_vecs, word_vectors))\n    \n    return vectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\nsimple_pipeline()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}