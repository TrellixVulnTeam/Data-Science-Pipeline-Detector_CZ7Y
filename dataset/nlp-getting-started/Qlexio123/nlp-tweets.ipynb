{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Compétition: Natural Language Processing with Disaster Tweets\n\n## Analyse des jeux de données\n\n* sample_submission est le jeu contenant les réponses\n* train.csv est le jeu d'entraînement avec le label\n* test.csv est le jeu de test sur lequel faire tourner le modèle\n\n### Sample_submission","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\n\nfrom nltk import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom transformers import XLNetTokenizer, TFXLNetModel, \\\n                        RobertaTokenizer, TFRobertaModel\n\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow as tf\nfrom tensorflow_addons.metrics import F1Score\n\nfrom tensorflow.keras.backend import clear_session\n# import keras.backend as K\nfrom numba import cuda\nimport gc\nimport keras_tuner as kt\nfrom time import sleep","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:20.792602Z","iopub.execute_input":"2022-04-03T10:04:20.794226Z","iopub.status.idle":"2022-04-03T10:04:29.216656Z","shell.execute_reply.started":"2022-04-03T10:04:20.79415Z","shell.execute_reply":"2022-04-03T10:04:29.215942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_sub.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.218677Z","iopub.execute_input":"2022-04-03T10:04:29.219114Z","iopub.status.idle":"2022-04-03T10:04:29.245198Z","shell.execute_reply.started":"2022-04-03T10:04:29.219072Z","shell.execute_reply":"2022-04-03T10:04:29.244439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les résultats de la prédiction pour la compétition doivent être retournée dans un tableau de n x 2 dimensions avec:\n* id: la colonne contenant les \"id\" des tweets\n* target: lalabel prédit par mon modèle\n\n### Train","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ntrain_df.head(50)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.246656Z","iopub.execute_input":"2022-04-03T10:04:29.246899Z","iopub.status.idle":"2022-04-03T10:04:29.294455Z","shell.execute_reply.started":"2022-04-03T10:04:29.246866Z","shell.execute_reply":"2022-04-03T10:04:29.29379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.296303Z","iopub.execute_input":"2022-04-03T10:04:29.296624Z","iopub.status.idle":"2022-04-03T10:04:29.318785Z","shell.execute_reply.started":"2022-04-03T10:04:29.296588Z","shell.execute_reply":"2022-04-03T10:04:29.318086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le jeu est composé de 7613 individus pour 5 features.\n\n\"keyword\" et \"location\" possèdent des valeurs nulles. Analysons les.","metadata":{}},{"cell_type":"code","source":"cols = []\nnb_val_null = []\n\nfor col in train_df.columns:\n    cols.append(col)\n    nb_val_null.append(train_df[col].isnull().sum())\n\nfor col, nb_null in zip(cols, nb_val_null):\n    print(f\"{col}: {nb_null} valeurs nulles, soit {round(nb_null / len(train_df) *100, 3)}%\")\n\nplt.bar(cols, nb_val_null, 0.8)\nplt.ylim(0, len(train_df))\n\ntrain_quant = np.quantile([0, len(train_df)], [0.25, 0.5])\n\nplt.axhline(train_quant[0], color= \"g\", linestyle= \"--\", label= \"Quartile 25%\")\nplt.axhline(train_quant[1], color= \"r\", linestyle= \"--\", label= \"Quartile 50%\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.319867Z","iopub.execute_input":"2022-04-03T10:04:29.320515Z","iopub.status.idle":"2022-04-03T10:04:29.509637Z","shell.execute_reply.started":"2022-04-03T10:04:29.320479Z","shell.execute_reply":"2022-04-03T10:04:29.508953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La feature \"location\" contient plus de 33% de valeurs nulles. De plus, ces valeurs étant des variables nominales; il m'est quasiment impossible de les compléter. Je vais donc droper cette colonne.\n\n\"keyword\" posséde 0.8% de valeurs nulles, je vais essayer d'entraîner une classification pour combler les valeurs manquantes.\n","metadata":{}},{"cell_type":"code","source":"print(f\"Il y a {train_df['keyword'].nunique()} valeurs uniques dans la feature 'keyword'\")\ntrain_df[\"keyword\"].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.510878Z","iopub.execute_input":"2022-04-03T10:04:29.511119Z","iopub.status.idle":"2022-04-03T10:04:29.519816Z","shell.execute_reply.started":"2022-04-03T10:04:29.511086Z","shell.execute_reply":"2022-04-03T10:04:29.519014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On peut voir que certains keywords possèdent plusieurs mots séparés par un espace encodé (%20). Il sera donc potentiellement nécessaire d'effectuer un remplacement. Je vais utilise le méthode python urllib.parse.unquote().\n","metadata":{}},{"cell_type":"markdown","source":"### Test","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\ntest_df[test_df[\"location\"].notnull()].head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.521057Z","iopub.execute_input":"2022-04-03T10:04:29.521445Z","iopub.status.idle":"2022-04-03T10:04:29.554319Z","shell.execute_reply.started":"2022-04-03T10:04:29.521404Z","shell.execute_reply":"2022-04-03T10:04:29.553657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"location\" contient le même genre de valeurs que son homologue dans le jeu d'entraînement. La suppression de cette colonne est confirmée.","metadata":{}},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.555482Z","iopub.execute_input":"2022-04-03T10:04:29.555718Z","iopub.status.idle":"2022-04-03T10:04:29.566969Z","shell.execute_reply.started":"2022-04-03T10:04:29.555685Z","shell.execute_reply":"2022-04-03T10:04:29.566084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le jeu est composé de 4 features pour 3263 individus.\n\n\"keyword\" et \"location\" possèdent des valeurs nulles.","metadata":{}},{"cell_type":"code","source":"cols = []\nnb_val_null = []\n\nfor col in test_df.columns:\n    cols.append(col)\n    nb_val_null.append(test_df[col].isnull().sum())\n\nfor col, nb_null in zip(cols, nb_val_null):\n    print(f\"{col}: {nb_null} valeurs nulles, soir {round(nb_null / len(test_df) *100, 3)}%\")\n\nplt.bar(cols, nb_val_null, 0.8)\nplt.ylim(0, len(train_df))\n\ntest_quant = np.quantile([0, len(test_df)], [0.25, 0.5])\n\nplt.axhline(test_quant[0], color= \"g\", linestyle= \"--\", label= \"Quartile 25%\")\nplt.axhline(test_quant[1], color= \"r\", linestyle= \"--\", label= \"Quartile 50%\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.569777Z","iopub.execute_input":"2022-04-03T10:04:29.570524Z","iopub.status.idle":"2022-04-03T10:04:29.754068Z","shell.execute_reply.started":"2022-04-03T10:04:29.570489Z","shell.execute_reply":"2022-04-03T10:04:29.753334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dans ce jeu aussi, je vais utliser une concaténation des jeux d'entraînement et de test pour avoir un corpus plus grand pour compléter les valeurs nulles de \"keyword\".","metadata":{}},{"cell_type":"code","source":"print(f\"Il y a {test_df['keyword'].nunique()} valeurs uniques dans la feature 'keyword'\")\ntest_df[\"keyword\"].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.757399Z","iopub.execute_input":"2022-04-03T10:04:29.757618Z","iopub.status.idle":"2022-04-03T10:04:29.765881Z","shell.execute_reply.started":"2022-04-03T10:04:29.757591Z","shell.execute_reply":"2022-04-03T10:04:29.765129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert train_df[\"keyword\"].unique().tolist() == test_df[\"keyword\"].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.767568Z","iopub.execute_input":"2022-04-03T10:04:29.768065Z","iopub.status.idle":"2022-04-03T10:04:29.774238Z","shell.execute_reply.started":"2022-04-03T10:04:29.768026Z","shell.execute_reply":"2022-04-03T10:04:29.773455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les valeurs composant la feature \"keyword\" sont identiques.\n\nAnalysons les.","metadata":{}},{"cell_type":"code","source":"train_val_hist = train_df[\"keyword\"].value_counts().reset_index()\ntrain_val_hist.sort_values(by= \"index\", inplace= True)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.775952Z","iopub.execute_input":"2022-04-03T10:04:29.776511Z","iopub.status.idle":"2022-04-03T10:04:29.786276Z","shell.execute_reply.started":"2022-04-03T10:04:29.776473Z","shell.execute_reply":"2022-04-03T10:04:29.785568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize= (25, 10))\n\nplt.bar(train_val_hist.loc[:, \"index\"], round(\n    train_val_hist.loc[:, \"keyword\"] / train_val_hist[\"keyword\"].max() *100, 1))\nplt.axhline(np.mean(round(\n    train_val_hist.loc[:, \"keyword\"] / train_val_hist[\"keyword\"].max() *100, 1)), \n    color= \"r\", linestyle= \"--\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:29.787192Z","iopub.execute_input":"2022-04-03T10:04:29.787405Z","iopub.status.idle":"2022-04-03T10:04:32.323961Z","shell.execute_reply.started":"2022-04-03T10:04:29.787363Z","shell.execute_reply":"2022-04-03T10:04:32.323301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_val_hist = test_df[\"keyword\"].value_counts().reset_index()\ntest_val_hist.sort_values(by= \"index\", inplace= True)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:32.325077Z","iopub.execute_input":"2022-04-03T10:04:32.325742Z","iopub.status.idle":"2022-04-03T10:04:32.333208Z","shell.execute_reply.started":"2022-04-03T10:04:32.325704Z","shell.execute_reply":"2022-04-03T10:04:32.3326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize= (25, 10))\n\nplt.bar(test_val_hist.loc[:, \"index\"], round(\n    test_val_hist.loc[:, \"keyword\"] / test_val_hist[\"keyword\"].max() *100, 1))\nplt.axhline(np.mean(round(\n    test_val_hist.loc[:, \"keyword\"] / test_val_hist[\"keyword\"].max() *100, 1)), \n    color= \"r\", linestyle= \"--\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:32.334289Z","iopub.execute_input":"2022-04-03T10:04:32.33461Z","iopub.status.idle":"2022-04-03T10:04:34.979417Z","shell.execute_reply.started":"2022-04-03T10:04:32.334572Z","shell.execute_reply":"2022-04-03T10:04:34.978737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On voit clairement  que les mots de la feature \"keyword\" ne sont pas répartis de la même manière dans le jeu d'entraînement que dans le jeu de test.\n\nLe nombre de \"keyword\" du jeu d'entraînment sont relativement proche de la moyenne alors qu'ils sont plus aléatoirement répartis dans le jeu de test.\n\n\n### Mise en forme des jeux de données\n\n* [x] Retrait de la colonne \"location\"\n* [x] Retrait des liens\n* Tokenisation de la colonne \"text\"\n  * [x] Retrait des citations des noms d'utilisateurs\n  * [x] Garde des hashtags! et de toutes les combinaisons alphanumériques\n  * [x] Doublon des hashtags sans le symbole '#'\n* [x] Lemmatisation de la colonne \"text\"","metadata":{}},{"cell_type":"code","source":"train_dff = train_df.drop(\"location\", axis= 1)\ntest_dff = test_df.drop(\"location\", axis= 1)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:34.980658Z","iopub.execute_input":"2022-04-03T10:04:34.98105Z","iopub.status.idle":"2022-04-03T10:04:34.987691Z","shell.execute_reply.started":"2022-04-03T10:04:34.981011Z","shell.execute_reply":"2022-04-03T10:04:34.986973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_url(text):\n    text_f = []\n    for word in text.split():\n        word = word.lower()\n        word = re.sub(r'https?:\\/\\/.*', \"\", word)\n        word = re.sub(r'^@.*', \"\", word)\n        word = re.sub(r'\\&amp', \"&\", word)\n        \n        text_f.append(word)\n        \n        if re.search(r'^#.*', word) is not None:\n            text_f.append(re.split(r'^#', word)[-1])\n\n    return \" \".join(text_f)\n\n\ntrain_dff[\"text\"] = train_dff[\"text\"].apply(lambda x: remove_url(x))\ntest_dff[\"text\"] = test_dff[\"text\"].apply(lambda x: remove_url(x))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:34.989272Z","iopub.execute_input":"2022-04-03T10:04:34.989755Z","iopub.status.idle":"2022-04-03T10:04:36.05634Z","shell.execute_reply.started":"2022-04-03T10:04:34.989718Z","shell.execute_reply":"2022-04-03T10:04:36.05563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dff[\"text\"].head(25)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:36.057641Z","iopub.execute_input":"2022-04-03T10:04:36.057869Z","iopub.status.idle":"2022-04-03T10:04:36.065676Z","shell.execute_reply.started":"2022-04-03T10:04:36.057835Z","shell.execute_reply":"2022-04-03T10:04:36.063909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords = set(stopwords.words(\"english\"))\nregex_form = r'#?[a-zA-Z0-9]+|\\&'\ntokenizer = RegexpTokenizer(regex_form)\n\ndef tokenisation_stopwords(text, tokenizer, stopwords):\n    words = tokenizer.tokenize(text)\n    words = [word for word in words if word not in stopwords]\n\n    return words\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:36.066955Z","iopub.execute_input":"2022-04-03T10:04:36.067347Z","iopub.status.idle":"2022-04-03T10:04:36.077975Z","shell.execute_reply.started":"2022-04-03T10:04:36.067308Z","shell.execute_reply":"2022-04-03T10:04:36.077202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dff[\"text\"] = train_dff[\"text\"].apply(lambda x: tokenisation_stopwords(x, tokenizer, stopwords))\ntest_dff[\"text\"] = test_dff[\"text\"].apply(lambda x: tokenisation_stopwords(x, tokenizer, stopwords))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:36.079196Z","iopub.execute_input":"2022-04-03T10:04:36.081522Z","iopub.status.idle":"2022-04-03T10:04:36.203782Z","shell.execute_reply.started":"2022-04-03T10:04:36.081483Z","shell.execute_reply":"2022-04-03T10:04:36.203162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dff.loc[12, \"text\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:36.204978Z","iopub.execute_input":"2022-04-03T10:04:36.205217Z","iopub.status.idle":"2022-04-03T10:04:36.211627Z","shell.execute_reply.started":"2022-04-03T10:04:36.205184Z","shell.execute_reply":"2022-04-03T10:04:36.210838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lematizer = WordNetLemmatizer()\n\ntrain_dff[\"text\"] = train_dff[\"text\"].apply(lambda x: [lematizer.lemmatize(word, \"n\") for word in x])\ntrain_dff[\"text\"] = train_dff[\"text\"].apply(lambda x: [lematizer.lemmatize(word, \"v\") for word in x])\n\ntest_dff[\"text\"] = test_dff[\"text\"].apply(lambda x: [lematizer.lemmatize(word, \"n\") for word in x])\ntest_dff[\"text\"] = test_dff[\"text\"].apply(lambda x: [lematizer.lemmatize(word, \"v\") for word in x])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:36.213457Z","iopub.execute_input":"2022-04-03T10:04:36.213794Z","iopub.status.idle":"2022-04-03T10:04:39.028728Z","shell.execute_reply.started":"2022-04-03T10:04:36.213758Z","shell.execute_reply":"2022-04-03T10:04:39.027998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dff.loc[12, \"text\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:39.029833Z","iopub.execute_input":"2022-04-03T10:04:39.030091Z","iopub.status.idle":"2022-04-03T10:04:39.03659Z","shell.execute_reply.started":"2022-04-03T10:04:39.030057Z","shell.execute_reply":"2022-04-03T10:04:39.035907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transformation des données de la feature \"keyword\"\n\nL'idée était de calculer un poids à partir de la feature \"keyword\" et de Word2Vec. Après ajout de ce poids dans le texte et entraînement avec XLNet et RoBERTa les résultats des métriques sont les mêmes. Cette étape est donc retirée.\n\n~~Je vais entraîner les tweets avec word2vec. Cela va permettre de récupérer les coefficients de similarité entre le mot dans la feature \"keyword\" et le tweet et de calculer le poids de \"keyword\" par rapport au tweet.~~\n\n~~Si \"keyword\" == null, le poids est fixé à 0~~\n\n~~Si \"keyword\" == 1+ mot(s), le poids est la somme des coefficients de similarité présents sur x mots (x est le nombre de mots retourné par la méthode \"most_similar\"; à définir)~~\n\n\nPar contre, je peux ajouter ajouter les \"keyword\" désencodés au tweets.","metadata":{}},{"cell_type":"code","source":"from urllib.parse import unquote\n\ndef unquote_join(keyword, text):\n    if keyword is np.nan:\n        return \" \".join(text)\n    else:\n        tmp_keyword = unquote(keyword).split()\n        return \" \".join(text + tmp_keyword)\n\n\ntrain_dff[\"decoded_joined\"] = train_dff[[\"keyword\", \"text\"]].apply(lambda t: \n                                                                   unquote_join(t[0], t[1]), axis= 1)\ntest_dff[\"decoded_joined\"] = test_dff[[\"keyword\", \"text\"]].apply(lambda t: \n                                                                   unquote_join(t[0], t[1]), axis= 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:39.037646Z","iopub.execute_input":"2022-04-03T10:04:39.038357Z","iopub.status.idle":"2022-04-03T10:04:39.200778Z","shell.execute_reply.started":"2022-04-03T10:04:39.03832Z","shell.execute_reply":"2022-04-03T10:04:39.200093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Répartition des mots dans les tweets","metadata":{}},{"cell_type":"code","source":"def repartition_mots(df, df_name):\n    tmp_len = []\n    for i in range(len(df)):\n        tmp_len.append(len(df.loc[i, \"decoded_joined\"].split()))\n\n    print(f\"\\nJeu: {df_name}\\n{'*' *50}\\n\")\n    print(f\"Nb mini de mots: {min(tmp_len)}\")\n    print(f\"Nb maxi de mots: {max(tmp_len)}\")\n    nb_mots_max = max(tmp_len)\n    print(f\"Nb moyenne de mots: {np.mean(tmp_len)}\")\n    print(f\"Nb de mots médian: {np.quantile(tmp_len, 0.5)}\")\n\n    fig = plt.figure(figsize= (25, 10))\n    plt.hist(tmp_len, bins= max(tmp_len))\n    plt.axvline(np.mean(tmp_len), color= \"r\", linestyle= \"--\", label= \"Moyenne\")\n    plt.axvline(np.quantile(tmp_len, 0.5), color= \"g\", linestyle= \"--\", label= \"Médiane\")\n    plt.xlim(min(tmp_len), max(tmp_len))\n\n    plt.legend()\n\n    plt.show()\n\n    return nb_mots_max\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:39.201881Z","iopub.execute_input":"2022-04-03T10:04:39.202204Z","iopub.status.idle":"2022-04-03T10:04:39.210869Z","shell.execute_reply.started":"2022-04-03T10:04:39.202166Z","shell.execute_reply":"2022-04-03T10:04:39.210194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_mots_max = []\n\nnb_mots_max.append(repartition_mots(train_dff, \"Train\"))\nnb_mots_max.append(repartition_mots(test_dff, \"Test\"))\n\nnb_mots_max = np.max(nb_mots_max)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:39.211968Z","iopub.execute_input":"2022-04-03T10:04:39.212608Z","iopub.status.idle":"2022-04-03T10:04:40.004934Z","shell.execute_reply.started":"2022-04-03T10:04:39.212566Z","shell.execute_reply":"2022-04-03T10:04:40.004226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le nombre maximum de mots dans un tweet est de 30 mots.\n\nJe vais maintenant afficher un nuage de mots pour les jeux d'entraînement et de test.\n","metadata":{}},{"cell_type":"code","source":"def prepare_cloud(df):\n    comment_words = \"\"\n\n    for i in range(len(df)):\n        comment_words += df.loc[i, \"decoded_joined\"] + \" \"\n\n        if (i +1) % 1000 == 0:\n            print(f\"{i +1}/{len(df)}\")\n    \n    return comment_words\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:40.006053Z","iopub.execute_input":"2022-04-03T10:04:40.006492Z","iopub.status.idle":"2022-04-03T10:04:40.01179Z","shell.execute_reply.started":"2022-04-03T10:04:40.006452Z","shell.execute_reply":"2022-04-03T10:04:40.01114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\nstopwords = set(STOPWORDS)\n\nw_cloud_train = WordCloud(width= 1600, height= 1600, background_color= \"white\", \n    stopwords= stopwords, min_font_size= 8).generate(prepare_cloud(train_dff))\nw_cloud_test = WordCloud(width= 1600, height= 1600, background_color= \"white\", \n    stopwords= stopwords, min_font_size= 8).generate(prepare_cloud(test_dff))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:40.018221Z","iopub.execute_input":"2022-04-03T10:04:40.018814Z","iopub.status.idle":"2022-04-03T10:04:50.509889Z","shell.execute_reply.started":"2022-04-03T10:04:40.018784Z","shell.execute_reply":"2022-04-03T10:04:50.5091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nplt.imshow(w_cloud_train)\nplt.title(\"Nuage de mots du jeu Train\")\n\nplt.show()\n\nfig = plt.figure(figsize=(10, 10))\nplt.imshow(w_cloud_test)\nplt.title(\"Nuage de mots du jeu Test\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:50.511184Z","iopub.execute_input":"2022-04-03T10:04:50.511467Z","iopub.status.idle":"2022-04-03T10:04:52.877817Z","shell.execute_reply.started":"2022-04-03T10:04:50.511431Z","shell.execute_reply":"2022-04-03T10:04:52.87374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sur le jeu d'entraînement, on peut voir que les mots \"go\", \"u\", \"one\", \"new\", \"fire\" sont les plus présents.\n\nSur le jeu de test, on peut voir que les mots \"go\" et \"new\", \"say\", \"fire\", \"one\", \"u\" sont les plus présents.\n\n","metadata":{}},{"cell_type":"markdown","source":"# XLNet\n\nJe vais chercher une méthode de classification rapide et efficace. paperswithcode.com est une piste à suivre.\n\nJe vais utiliser la méthode XLNet de la librairie \"transformers\". En effet, ce modèle est ce qu'il se fait de mieux pour le moment en ce qui concerne [la classification de textes](https://paperswithcode.com/sota/text-classification-on-ag-news)\n\nD'abord, je vais créer les jeux de train et de test. Pour le jeu de validation, j'utiliserai le paramètre \"validation_split\" de la méthode fit().","metadata":{}},{"cell_type":"code","source":"# Séparation de l'ensemble train/validation du jeu de test\nX_train_df, X_test_df, y_train_df, y_test_df = train_test_split(train_dff[\"decoded_joined\"], \n    train_dff[\"target\"], train_size= 0.8, random_state= 42)\n\nprint(\"X: \", X_train_df.iloc[:10])\nprint(f\"y: {y_train_df.iloc[:10]}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:52.879272Z","iopub.execute_input":"2022-04-03T10:04:52.879768Z","iopub.status.idle":"2022-04-03T10:04:52.89399Z","shell.execute_reply.started":"2022-04-03T10:04:52.879732Z","shell.execute_reply":"2022-04-03T10:04:52.893258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_empty(df_train, df_test):\n    tmp_df_train = df_train.copy()\n    tmp_df_test = df_test.copy()\n    for idx in df_train.index:\n        if len(df_train[idx]) == 0:\n            tmp_df_train = tmp_df_train.drop(idx)\n            tmp_df_test = tmp_df_test.drop(idx)\n    \n    return tmp_df_train, tmp_df_test\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:52.896598Z","iopub.execute_input":"2022-04-03T10:04:52.896825Z","iopub.status.idle":"2022-04-03T10:04:52.903417Z","shell.execute_reply.started":"2022-04-03T10:04:52.896791Z","shell.execute_reply":"2022-04-03T10:04:52.902363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dff, y_train_dff = remove_empty(X_train_df, y_train_df)\nX_test_dff, y_test_dff = remove_empty(X_test_df, y_test_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:52.905108Z","iopub.execute_input":"2022-04-03T10:04:52.905541Z","iopub.status.idle":"2022-04-03T10:04:52.952695Z","shell.execute_reply.started":"2022-04-03T10:04:52.905502Z","shell.execute_reply":"2022-04-03T10:04:52.952054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"XLNet est fourni avec des modèles pré-entraînés pour effectuer du partial fine tuning.\nLes modèles sont trouvables [ici](https://huggingface.co/models?library=tf&sort=modified&search=xlnet)\n\nJ'ai choisi \"xlnet_large_cased\" qui est le plus gros jeu pour des textes en anglais et le plus récent.\n\nD'ailleurs, je suis tombé sur [\"riccardode/tweets_disaster\"](https://huggingface.co/riccardode/tweets_disaster) qui semble plus approprié. Ce dernier sera étudié par la suite.","metadata":{}},{"cell_type":"code","source":"# Modèle XLNet pré-entraîné\nxlnet_pretrained_model = \"xlnet-large-cased\"\n\n# Chargement du tokenizer avec les poids du modèle choisi\nxlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_pretrained_model)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:52.95413Z","iopub.execute_input":"2022-04-03T10:04:52.954611Z","iopub.status.idle":"2022-04-03T10:04:58.674898Z","shell.execute_reply.started":"2022-04-03T10:04:52.954576Z","shell.execute_reply":"2022-04-03T10:04:58.674251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tokenisation des tweets","metadata":{}},{"cell_type":"code","source":"X_train_xlnet = [xlnet_tokenizer.encode_plus(t, max_length= 120, padding= \"max_length\", truncation= True,\n                                           add_special_tokens= True) for t in X_train_dff] # \nX_test_xlnet = [xlnet_tokenizer.encode_plus(t, max_length= 120, padding= \"max_length\", truncation= True,\n                                          add_special_tokens= True) for t in X_test_dff]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:04:58.676244Z","iopub.execute_input":"2022-04-03T10:04:58.676534Z","iopub.status.idle":"2022-04-03T10:05:00.371054Z","shell.execute_reply.started":"2022-04-03T10:04:58.676497Z","shell.execute_reply":"2022-04-03T10:05:00.37029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_xlnet = np.array([inp[\"input_ids\"] for inp in X_train_xlnet])\nX_test_xlnet = np.array([inp[\"input_ids\"] for inp in X_test_xlnet])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:00.372357Z","iopub.execute_input":"2022-04-03T10:05:00.372716Z","iopub.status.idle":"2022-04-03T10:05:00.501568Z","shell.execute_reply.started":"2022-04-03T10:05:00.372676Z","shell.execute_reply":"2022-04-03T10:05:00.500728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fonction pour plotter les métriques.","metadata":{}},{"cell_type":"code","source":"def dl_metrics(history, metric_1, metric_2, metric_3):\n    fig = plt.figure(figsize=(10, 45))\n    # Historique d'accuracy\n    plt.subplot(3, 1, 1)\n    plt.plot(history.history[metric_1], color=\"g\")\n    plt.plot(history.history[\"val_\" + metric_1],\n              linestyle= \"--\", color=\"orange\")\n    plt.title(\"Métrique: \" + metric_1, fontsize=18)\n    plt.ylabel(metric_1)\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc= \"upper left\")\n    # Historique de f1_m\n    plt.subplot(3, 1, 2)\n    plt.plot(history.history[metric_2], color=\"g\")\n    plt.plot(history.history[\"val_\" + metric_2],\n              linestyle= \"--\", color= \"orange\")\n    plt.title(\"Métrique: \" + metric_2, fontsize=18)\n    plt.ylabel(metric_2)\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc= \"upper left\")\n    # Historique de loss\n    plt.subplot(3, 1, 3)\n    plt.plot(history.history[metric_3], color=\"g\")\n    plt.plot(history.history[\"val_\" + metric_3],\n              linestyle= \"--\", color= \"orange\")\n    plt.title(\"Métrique: \" + metric_3, fontsize=18)\n    plt.ylabel(metric_3)\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc= \"upper left\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:00.502847Z","iopub.execute_input":"2022-04-03T10:05:00.503182Z","iopub.status.idle":"2022-04-03T10:05:00.51926Z","shell.execute_reply.started":"2022-04-03T10:05:00.503146Z","shell.execute_reply":"2022-04-03T10:05:00.518356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"XLNet modèle\n\n***L'entraînement avec les poids du modèle fixés ainsi l'optimisation des hyperparamètres sont mis en commentaires pour des raisons de ressources. Les résultats peuvent être vu sur la Version #11 de ce kernel.***","metadata":{}},{"cell_type":"code","source":"clear_session()\ngc.collect()\n# cuda.select_device(0)\n# cuda.close()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:00.520344Z","iopub.execute_input":"2022-04-03T10:05:00.520705Z","iopub.status.idle":"2022-04-03T10:05:00.824926Z","shell.execute_reply.started":"2022-04-03T10:05:00.520673Z","shell.execute_reply":"2022-04-03T10:05:00.824226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1 = F1Score(1, average= \"weighted\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:00.826238Z","iopub.execute_input":"2022-04-03T10:05:00.826508Z","iopub.status.idle":"2022-04-03T10:05:05.303832Z","shell.execute_reply.started":"2022-04-03T10:05:00.826473Z","shell.execute_reply":"2022-04-03T10:05:05.303052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_xlnet_keyword_model(xlnet_base):\n#     word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32') # X_train_xlnet.shape[1]\n\n#     xlnet = TFXLNetModel.from_pretrained(xlnet_base)\n    \n#     for layer in xlnet.layers:\n#         layer.trainable = False\n    \n#     xlnet_encodings = xlnet(word_inputs)[0]\n\n#     # CLASSIFICATION HEAD \n#     # Collect last step from last hidden state (CLS)\n#     doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n#     # Apply dropout for regularization\n# #     doc_encoding = tf.keras.layers.Dense(2048, activation= \"relu\")(doc_encoding)\n#     doc_encoding = tf.keras.layers.Dense(1024, activation= \"relu\")(doc_encoding)\n# #     doc_encoding = tf.keras.layers.Dropout(.2)(doc_encoding)\n# #     doc_encoding = tf.keras.layers.Dense(512, activation= \"relu\")(doc_encoding)\n#     doc_encoding = tf.keras.layers.Dropout(.2)(doc_encoding)\n#     # Final output \n#     outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n\n#     # Compile model\n#     model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 2e-5), loss='binary_crossentropy', \n#         metrics=['accuracy', f1])\n\n#     return model","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.305183Z","iopub.execute_input":"2022-04-03T10:05:05.305616Z","iopub.status.idle":"2022-04-03T10:05:05.31116Z","shell.execute_reply.started":"2022-04-03T10:05:05.305577Z","shell.execute_reply":"2022-04-03T10:05:05.310352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet_model_pft = create_xlnet_keyword_model(xlnet_pretrained_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.312642Z","iopub.execute_input":"2022-04-03T10:05:05.312963Z","iopub.status.idle":"2022-04-03T10:05:05.325396Z","shell.execute_reply.started":"2022-04-03T10:05:05.312928Z","shell.execute_reply":"2022-04-03T10:05:05.324423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet_model_pft.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.326641Z","iopub.execute_input":"2022-04-03T10:05:05.326973Z","iopub.status.idle":"2022-04-03T10:05:05.333856Z","shell.execute_reply.started":"2022-04-03T10:05:05.326932Z","shell.execute_reply":"2022-04-03T10:05:05.333071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for layer in xlnet_model_pft.layers[-25:]:\n#     print(layer)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.33513Z","iopub.execute_input":"2022-04-03T10:05:05.33543Z","iopub.status.idle":"2022-04-03T10:05:05.342591Z","shell.execute_reply.started":"2022-04-03T10:05:05.335351Z","shell.execute_reply":"2022-04-03T10:05:05.341735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def warmup(epoch, lr):\n    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n    However, as we are finetuning for few epoch it's not crucial.\n    \"\"\"\n    return max(lr + 1e-6, 2e-5)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.343938Z","iopub.execute_input":"2022-04-03T10:05:05.344265Z","iopub.status.idle":"2022-04-03T10:05:05.351632Z","shell.execute_reply.started":"2022-04-03T10:05:05.344165Z","shell.execute_reply":"2022-04-03T10:05:05.350933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint_filepath = \"./xlnet_pft_checkpoint/checkpoint\"\n\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 4, min_delta=0.02, \n#                                      restore_best_weights=True),\n#     tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor= 1e-6, patience=2, \n#                                          verbose=0, mode='auto', \n#                                          min_delta=0.001, cooldown=0, min_lr=1e-6),\n#     tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n#                                        monitor='val_accuracy', mode='max', save_best_only=True)\n# ]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.35359Z","iopub.execute_input":"2022-04-03T10:05:05.353792Z","iopub.status.idle":"2022-04-03T10:05:05.360295Z","shell.execute_reply.started":"2022-04-03T10:05:05.35376Z","shell.execute_reply":"2022-04-03T10:05:05.359461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet_history = xlnet_model_pft.fit(X_train_xlnet, y= y_train_dff, epochs= 20, batch_size= 16, \n#                                           validation_split= 0.2, callbacks= callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.361464Z","iopub.execute_input":"2022-04-03T10:05:05.361693Z","iopub.status.idle":"2022-04-03T10:05:05.371828Z","shell.execute_reply.started":"2022-04-03T10:05:05.361664Z","shell.execute_reply":"2022-04-03T10:05:05.371024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dl_metrics(xlnet_history, \"accuracy\", \"f1_score\", \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.372807Z","iopub.execute_input":"2022-04-03T10:05:05.373056Z","iopub.status.idle":"2022-04-03T10:05:05.380508Z","shell.execute_reply.started":"2022-04-03T10:05:05.373021Z","shell.execute_reply":"2022-04-03T10:05:05.379765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet_model_pft.evaluate(X_test_xlnet, y_test_dff, batch_size= 16)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.381181Z","iopub.execute_input":"2022-04-03T10:05:05.381475Z","iopub.status.idle":"2022-04-03T10:05:05.389128Z","shell.execute_reply.started":"2022-04-03T10:05:05.381435Z","shell.execute_reply":"2022-04-03T10:05:05.388355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Essayons d'optimiser les paramètres de la couche Dense.","metadata":{}},{"cell_type":"code","source":"# def model_builder(hp):\n#     word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32') # X_train_xlnet.shape[1]\n\n#     xlnet = TFXLNetModel.from_pretrained(xlnet_pretrained_model)\n    \n#     for layer in xlnet.layers:\n#         layer.trainable = False\n    \n#     xlnet_encodings = xlnet(word_inputs)[0]\n\n#     # CLASSIFICATION HEAD \n#     # Collect last step from last hidden state (CLS)\n#     doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n#     # Apply dropout for regularization\n\n#     # Tune dense units\n#     hp_units = hp.Int('dense_units',\n#                       min_value=512,\n#                       max_value=2048,\n#                       step=128,\n#                       default=1024)\n    \n#     doc_encoding = tf.keras.layers.Dense(hp_units, activation= \"relu\")(doc_encoding)\n#     doc_encoding = tf.keras.layers.Dropout(.2)(doc_encoding)\n#     # Final output \n#     outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n\n#     # Compile model\n#     model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 2e-5), loss='binary_crossentropy', \n#         metrics=['accuracy', f1])\n\n#     return model","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.390503Z","iopub.execute_input":"2022-04-03T10:05:05.390876Z","iopub.status.idle":"2022-04-03T10:05:05.396286Z","shell.execute_reply.started":"2022-04-03T10:05:05.390839Z","shell.execute_reply":"2022-04-03T10:05:05.395444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import keras_tuner as kt\n\n# # Création du tuner de kerastuner\n# tuner = kt.RandomSearch(\n#     model_builder, \n#     objective='val_accuracy',\n#     max_trials=5)\n\n# # Réglage du early stopping\n# stop_early = tf.keras.callbacks.EarlyStopping(\n#     monitor='val_accuracy',\n#     patience=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.397464Z","iopub.execute_input":"2022-04-03T10:05:05.398509Z","iopub.status.idle":"2022-04-03T10:05:05.405991Z","shell.execute_reply.started":"2022-04-03T10:05:05.398471Z","shell.execute_reply":"2022-04-03T10:05:05.40527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Recherche des meilleurs paramètres\n# tuner.search(X_train_xlnet, y_train_dff, batch_size=16, validation_split= 0.2,\n#     epochs=10, callbacks=[stop_early])\n\n# # Affichage des meilleurs paramètres\n# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# print(f\"Meilleur Dense units : {best_hps.get('dense_units')}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.407302Z","iopub.execute_input":"2022-04-03T10:05:05.40778Z","iopub.status.idle":"2022-04-03T10:05:05.413757Z","shell.execute_reply.started":"2022-04-03T10:05:05.407744Z","shell.execute_reply":"2022-04-03T10:05:05.413051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Meilleur hyperparamètre couche Dense: units = 1792","metadata":{}},{"cell_type":"code","source":"# checkpoint_filepath = \"./xlnet_hypermodel_checkpoint/checkpoint\"\n\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 4, min_delta=0.02, \n#                                      restore_best_weights=True),\n#     tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor= 1e-6, patience=2, \n#                                          verbose=0, mode='auto', \n#                                          min_delta=0.001, cooldown=0, min_lr=1e-6),\n#     tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n#                                        monitor='val_accuracy', mode='max', save_best_only=True)\n# ]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.415094Z","iopub.execute_input":"2022-04-03T10:05:05.415574Z","iopub.status.idle":"2022-04-03T10:05:05.421614Z","shell.execute_reply.started":"2022-04-03T10:05:05.41554Z","shell.execute_reply":"2022-04-03T10:05:05.420927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hypermodel_xlnet = tuner.hypermodel.build(best_hps)\n# xlnet_history = hypermodel_xlnet.fit(X_train_xlnet, y= y_train_dff, epochs= 20, batch_size= 16, \n#                                           validation_split= 0.2, callbacks= callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.42287Z","iopub.execute_input":"2022-04-03T10:05:05.42356Z","iopub.status.idle":"2022-04-03T10:05:05.431306Z","shell.execute_reply.started":"2022-04-03T10:05:05.423524Z","shell.execute_reply":"2022-04-03T10:05:05.430604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dl_metrics(xlnet_history, \"accuracy\", \"f1_score\", \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.433915Z","iopub.execute_input":"2022-04-03T10:05:05.435557Z","iopub.status.idle":"2022-04-03T10:05:05.439244Z","shell.execute_reply.started":"2022-04-03T10:05:05.435519Z","shell.execute_reply":"2022-04-03T10:05:05.438123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hypermodel_xlnet.evaluate(X_test_xlnet, y_test_dff, batch_size= 16)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.440664Z","iopub.execute_input":"2022-04-03T10:05:05.44123Z","iopub.status.idle":"2022-04-03T10:05:05.446816Z","shell.execute_reply.started":"2022-04-03T10:05:05.441158Z","shell.execute_reply":"2022-04-03T10:05:05.446124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Voyons les résultats avec du fine tuning.\n\n***Ces derniers ont aussi été commentés pour une question de ressources. Les résultats sont visibles dans la Version #12.***","metadata":{}},{"cell_type":"code","source":"# def create_xlnet_keyword_model(xlnet_base):\n#     word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32') # X_train_xlnet.shape[1]\n\n#     xlnet = TFXLNetModel.from_pretrained(xlnet_base)\n    \n#     for layer in xlnet.layers:\n#         layer.trainable = True\n    \n#     xlnet_encodings = xlnet(word_inputs)[0]\n\n#     # CLASSIFICATION HEAD \n#     # Collect last step from last hidden state (CLS)\n#     doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n#     # Apply dropout for regularization\n# #     doc_encoding = tf.keras.layers.Dense(2048, activation= \"relu\")(doc_encoding)\n#     doc_encoding = tf.keras.layers.Dense(1792, activation= \"relu\")(doc_encoding)\n# #     doc_encoding = tf.keras.layers.Dropout(.2)(doc_encoding)\n# #     doc_encoding = tf.keras.layers.Dense(512, activation= \"relu\")(doc_encoding)\n#     doc_encoding = tf.keras.layers.Dropout(.2)(doc_encoding)\n#     # Final output \n#     outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n\n#     # Compile model\n#     model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 2e-5), loss='binary_crossentropy', \n#         metrics=['accuracy', f1])\n\n#     return model","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.448263Z","iopub.execute_input":"2022-04-03T10:05:05.450105Z","iopub.status.idle":"2022-04-03T10:05:05.456049Z","shell.execute_reply.started":"2022-04-03T10:05:05.450074Z","shell.execute_reply":"2022-04-03T10:05:05.455047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet_model = create_xlnet_keyword_model(xlnet_pretrained_model)\n# xlnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.457334Z","iopub.execute_input":"2022-04-03T10:05:05.457765Z","iopub.status.idle":"2022-04-03T10:05:05.465621Z","shell.execute_reply.started":"2022-04-03T10:05:05.457723Z","shell.execute_reply":"2022-04-03T10:05:05.464763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint_filepath = \"./xlnet_model_checkpoint/checkpoint\"\n\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 4, min_delta=0.02, \n#                                      restore_best_weights=True),\n#     tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor= 1e-6, patience=2, \n#                                          verbose=0, mode='auto', \n#                                          min_delta=0.001, cooldown=0, min_lr=1e-6),\n#     tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n#                                        monitor='val_accuracy', mode='max', save_best_only=True)\n# ]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.467443Z","iopub.execute_input":"2022-04-03T10:05:05.468514Z","iopub.status.idle":"2022-04-03T10:05:05.475104Z","shell.execute_reply.started":"2022-04-03T10:05:05.468474Z","shell.execute_reply":"2022-04-03T10:05:05.473747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet_history = xlnet_model.fit(X_train_xlnet, y= y_train_dff, epochs= 20, batch_size= 16, \n#                                           validation_split= 0.2, callbacks= callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.476184Z","iopub.execute_input":"2022-04-03T10:05:05.478512Z","iopub.status.idle":"2022-04-03T10:05:05.484592Z","shell.execute_reply.started":"2022-04-03T10:05:05.47846Z","shell.execute_reply":"2022-04-03T10:05:05.483863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dl_metrics(xlnet_history, \"accuracy\", \"f1_score\", \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.485858Z","iopub.execute_input":"2022-04-03T10:05:05.486347Z","iopub.status.idle":"2022-04-03T10:05:05.492522Z","shell.execute_reply.started":"2022-04-03T10:05:05.486308Z","shell.execute_reply":"2022-04-03T10:05:05.4915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet_model.evaluate(X_test_xlnet, y_test_dff, batch_size= 16)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.494986Z","iopub.execute_input":"2022-04-03T10:05:05.495419Z","iopub.status.idle":"2022-04-03T10:05:05.500163Z","shell.execute_reply.started":"2022-04-03T10:05:05.495351Z","shell.execute_reply":"2022-04-03T10:05:05.499413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Résultats des différents essais avec XLNet:\n\nEntraînement:\n\n| -- | xlnet_pft | hypermodel_xlnet | xlnet_model |\n| -- | -- | -- | -- |\n| F1 score | 0.6000 | 0.6000 | 0.6000 |\n| Accuracy | 0.5681 | 0.5521 | 0.5207 |\n| Loss | 1.1190 | 1.1068 | 0.8238 |\n| Epoch | 7 | 3 | 1 |\n\nÉvaluation:\n\n| -- | xlnet_pft | hypermodel_xlnet | xlnet_model |\n| -- | -- | -- | -- |\n| F1 score | 0.5976 | 0.5976 | 0.5976 |\n| Accuracy | 0.6362 | 0.6474 | 0.5739 |\n| Loss | 0.6888 | 0.6810 | 0.7510 |\n\nLe modèle avec les hyperparamètres optimisés obtient une accuracy légèrement inférieure (-2.8%) qu'avant l'optimisation. Pour ce qui est de l'évaluation, il obtient une accuray légèrement supérieure (1.8%) cette fois. Je vais donc privilégier le modèle optimisé si je choisis XLNet.","metadata":{}},{"cell_type":"markdown","source":"# RoBERTa\n\nLe modèle \"riccardode/tweets_disaster\" ne peut pas être utilisé.\n\nJ'ai trouvé \"vinai/bertweet-large\" qui peut convenir. Ce modèle fonctionne avec l'algorithme RoBERTa.\n","metadata":{}},{"cell_type":"code","source":"# Modèle RoBERTa pré-entraîné\nroberta_pretrained_model = \"vinai/bertweet-large\"\n\n# Chargement du tokenizer avec les poids du modèle choisi\nroberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_pretrained_model)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:05.501367Z","iopub.execute_input":"2022-04-03T10:05:05.502253Z","iopub.status.idle":"2022-04-03T10:05:12.629487Z","shell.execute_reply.started":"2022-04-03T10:05:05.502211Z","shell.execute_reply":"2022-04-03T10:05:12.628788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 90\n\ndef roberta_encode(texts, tokenizer):\n    ct = len(texts)\n    input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n    attention_mask = np.zeros((ct, MAX_LEN), dtype='int32')\n    token_type_ids = np.zeros((ct, MAX_LEN), dtype='int32') # Not used in text classification\n\n    for k, text in enumerate(texts):\n        # Tokenize\n        tok_text = tokenizer.tokenize(\" \".join(text))\n        \n        # Truncate and convert tokens to numerical IDs\n        enc_text = tokenizer.convert_tokens_to_ids(tok_text[:(MAX_LEN-2)])\n        \n        input_length = len(enc_text) + 2\n        input_length = input_length if input_length < MAX_LEN else MAX_LEN\n        \n        # Add tokens [CLS] and [SEP] at the beginning and the end\n        input_ids[k,:input_length] = np.asarray([0] + enc_text + [2], dtype='int32')\n        \n        # Set to 1s in the attention input\n        attention_mask[k,:input_length] = 1\n\n    return {\n        'input_word_ids': input_ids,\n        'input_mask': attention_mask,\n        'input_type_ids': token_type_ids\n    }","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:12.630743Z","iopub.execute_input":"2022-04-03T10:05:12.631062Z","iopub.status.idle":"2022-04-03T10:05:12.640802Z","shell.execute_reply.started":"2022-04-03T10:05:12.631024Z","shell.execute_reply":"2022-04-03T10:05:12.639688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_roberta = roberta_encode(X_train_dff, roberta_tokenizer)\nX_test_roberta = roberta_encode(X_test_dff, roberta_tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:12.642425Z","iopub.execute_input":"2022-04-03T10:05:12.642709Z","iopub.status.idle":"2022-04-03T10:05:15.983847Z","shell.execute_reply.started":"2022-04-03T10:05:12.642673Z","shell.execute_reply":"2022-04-03T10:05:15.983153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Les entraînements sans et avec optimisations sont mis en commentaires pour une question de ressources. Les résultats sont visibles sur la version #13.***","metadata":{}},{"cell_type":"code","source":"def build_model(n_categories, pretrained_model):\n#     with strategy.scope():\n    input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_word_ids')\n    input_mask = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n    input_type_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_type_ids')\n\n    # Import RoBERTa model from HuggingFace\n    roberta_model = TFRobertaModel.from_pretrained(pretrained_model)\n    \n    for layer in roberta_model.layers:\n        layer.trainable = False\n    \n    x = roberta_model(input_word_ids, attention_mask=input_mask, token_type_ids=input_type_ids)\n\n    # Huggingface transformers have multiple outputs, embeddings are the first one,\n    # so let's slice out the first position\n    x = x[0]\n\n    x = tf.keras.layers.Dropout(0.1)(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(256, activation='relu')(x)\n    x = tf.keras.layers.Dense(n_categories, activation='sigmoid')(x)\n\n    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=x)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy', f1])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:15.985247Z","iopub.execute_input":"2022-04-03T10:05:15.9855Z","iopub.status.idle":"2022-04-03T10:05:15.994892Z","shell.execute_reply.started":"2022-04-03T10:05:15.985466Z","shell.execute_reply":"2022-04-03T10:05:15.994135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_model_pft = build_model(1, roberta_pretrained_model)\nroberta_model_pft.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:05:15.996012Z","iopub.execute_input":"2022-04-03T10:05:15.996251Z","iopub.status.idle":"2022-04-03T10:06:23.794886Z","shell.execute_reply.started":"2022-04-03T10:05:15.996213Z","shell.execute_reply":"2022-04-03T10:06:23.794204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = \"./roberta_pft_checkpoint/checkpoint\"\n\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 4, min_delta=0.02, \n#                                      restore_best_weights=True),\n#     tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor= 1e-6, patience=2, \n#                                          verbose=0, mode='auto', \n#                                          min_delta=0.001, cooldown=0, min_lr=1e-6),\n#     tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n#                                        monitor='val_accuracy', mode='max', save_best_only=True)\n# ]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.796125Z","iopub.execute_input":"2022-04-03T10:06:23.796365Z","iopub.status.idle":"2022-04-03T10:06:23.803143Z","shell.execute_reply.started":"2022-04-03T10:06:23.79633Z","shell.execute_reply":"2022-04-03T10:06:23.802372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roberta_history = roberta_model_pft.fit(X_train_roberta, y= y_train_dff, epochs= 20, batch_size= 16, \n#                                           validation_split= 0.2, callbacks= callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.804249Z","iopub.execute_input":"2022-04-03T10:06:23.8046Z","iopub.status.idle":"2022-04-03T10:06:23.812237Z","shell.execute_reply.started":"2022-04-03T10:06:23.80456Z","shell.execute_reply":"2022-04-03T10:06:23.811557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dl_metrics(roberta_history, \"accuracy\", \"f1_score\", \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.813602Z","iopub.execute_input":"2022-04-03T10:06:23.814116Z","iopub.status.idle":"2022-04-03T10:06:23.819835Z","shell.execute_reply.started":"2022-04-03T10:06:23.814076Z","shell.execute_reply":"2022-04-03T10:06:23.819072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roberta_model_pft.evaluate(X_test_roberta, y_test_dff, batch_size= 16)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.820919Z","iopub.execute_input":"2022-04-03T10:06:23.821395Z","iopub.status.idle":"2022-04-03T10:06:23.826531Z","shell.execute_reply.started":"2022-04-03T10:06:23.821342Z","shell.execute_reply":"2022-04-03T10:06:23.82563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimisation des hyperparamètres","metadata":{}},{"cell_type":"code","source":"# def model_builder(hp):\n# #     with strategy.scope():\n#     input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_word_ids')\n#     input_mask = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n#     input_type_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_type_ids')\n\n#     # Import RoBERTa model from HuggingFace\n#     roberta_model = TFRobertaModel.from_pretrained(roberta_pretrained_model)\n    \n#     for layer in roberta_model.layers:\n#         layer.trainable = False\n    \n#     x = roberta_model(input_word_ids, attention_mask=input_mask, token_type_ids=input_type_ids)\n\n#     # Huggingface transformers have multiple outputs, embeddings are the first one,\n#     # so let's slice out the first position\n#     x = x[0]\n\n#     x = tf.keras.layers.Dropout(0.1)(x)\n#     x = tf.keras.layers.Flatten()(x)\n    \n#         # Tune dense units\n#     hp_units = hp.Int('dense_units',\n#                       min_value=32,\n#                       max_value=516,\n#                       step=32,\n#                       default=256)\n    \n#     x = tf.keras.layers.Dense(hp_units, activation='relu')(x)\n#     x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n#     model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=x)\n#     model.compile(\n#         optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n#         loss='binary_crossentropy',\n#         metrics=['accuracy', f1])\n\n#     return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.82794Z","iopub.execute_input":"2022-04-03T10:06:23.828772Z","iopub.status.idle":"2022-04-03T10:06:23.83547Z","shell.execute_reply.started":"2022-04-03T10:06:23.828734Z","shell.execute_reply":"2022-04-03T10:06:23.834666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import keras_tuner as kt\n\n# # Création du tuner de kerastuner\n# tuner = kt.RandomSearch(\n#     model_builder, \n#     objective='val_accuracy',\n#     max_trials=5)\n\n# # Réglage du early stopping\n# stop_early = tf.keras.callbacks.EarlyStopping(\n#     monitor='val_accuracy',\n#     patience=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.836729Z","iopub.execute_input":"2022-04-03T10:06:23.83698Z","iopub.status.idle":"2022-04-03T10:06:23.845408Z","shell.execute_reply.started":"2022-04-03T10:06:23.836946Z","shell.execute_reply":"2022-04-03T10:06:23.84471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Recherche des meilleurs paramètres\n# tuner.search(X_train_roberta, y_train_dff, batch_size=16, validation_split= 0.2,\n#     epochs=10, callbacks=[stop_early])\n\n# # Affichage des meilleurs paramètres\n# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# print(f\"Meilleur Dense units : {best_hps.get('dense_units')}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.846574Z","iopub.execute_input":"2022-04-03T10:06:23.846839Z","iopub.status.idle":"2022-04-03T10:06:23.853402Z","shell.execute_reply.started":"2022-04-03T10:06:23.846803Z","shell.execute_reply":"2022-04-03T10:06:23.852533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- Meilleur hyperparamètre pour la couche Dense: units = 224 -->","metadata":{}},{"cell_type":"code","source":"# checkpoint_filepath = \"./roberta_hypermodel_checkpoint/checkpoint\"\n\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 4, min_delta=0.02, \n#                                      restore_best_weights=True),\n#     tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor= 1e-6, patience=2, \n#                                          verbose=0, mode='auto', \n#                                          min_delta=0.001, cooldown=0, min_lr=1e-6),\n#     tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n#                                        monitor='val_accuracy', mode='max', save_best_only=True)\n# ]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.855717Z","iopub.execute_input":"2022-04-03T10:06:23.856563Z","iopub.status.idle":"2022-04-03T10:06:23.862897Z","shell.execute_reply.started":"2022-04-03T10:06:23.856524Z","shell.execute_reply":"2022-04-03T10:06:23.862166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hypermodel_roberta = tuner.hypermodel.build(best_hps)\n# roberta_history = hypermodel_roberta.fit(X_train_roberta, y= y_train_dff, epochs= 20, batch_size= 16, \n#                                           validation_split= 0.2, callbacks= callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.86416Z","iopub.execute_input":"2022-04-03T10:06:23.864678Z","iopub.status.idle":"2022-04-03T10:06:23.870755Z","shell.execute_reply.started":"2022-04-03T10:06:23.864642Z","shell.execute_reply":"2022-04-03T10:06:23.870036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dl_metrics(roberta_history, \"accuracy\", \"f1_score\", \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.872111Z","iopub.execute_input":"2022-04-03T10:06:23.872363Z","iopub.status.idle":"2022-04-03T10:06:23.877843Z","shell.execute_reply.started":"2022-04-03T10:06:23.872327Z","shell.execute_reply":"2022-04-03T10:06:23.877117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hypermodel_roberta.evaluate(X_test_roberta, y_test_dff, batch_size= 16)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.879135Z","iopub.execute_input":"2022-04-03T10:06:23.879809Z","iopub.status.idle":"2022-04-03T10:06:23.885935Z","shell.execute_reply.started":"2022-04-03T10:06:23.879771Z","shell.execute_reply":"2022-04-03T10:06:23.885233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Voyons les résultats de RoBERTa après un fine tuning.\n\n***Ces résultats ont été mis en commentaires pour les mêmes raisons que précédemment. Ils sont visibles dans la version #13.***","metadata":{}},{"cell_type":"code","source":"# def build_model(n_categories, pretrained_model):\n# #     with strategy.scope():\n#     input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_word_ids')\n#     input_mask = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n#     input_type_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_type_ids')\n\n#     # Import RoBERTa model from HuggingFace\n#     roberta_model = TFRobertaModel.from_pretrained(pretrained_model)\n    \n#     for layer in roberta_model.layers:\n#         layer.trainable = True\n    \n#     x = roberta_model(input_word_ids, attention_mask=input_mask, token_type_ids=input_type_ids)\n\n#     # Huggingface transformers have multiple outputs, embeddings are the first one,\n#     # so let's slice out the first position\n#     x = x[0]\n\n#     x = tf.keras.layers.Dropout(0.1)(x)\n#     x = tf.keras.layers.Flatten()(x)\n#     x = tf.keras.layers.Dense(224, activation='relu')(x)\n#     x = tf.keras.layers.Dense(n_categories, activation='sigmoid')(x)\n\n#     model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=x)\n#     model.compile(\n#         optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n#         loss='binary_crossentropy',\n#         metrics=['accuracy', f1])\n\n#     return model","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.887497Z","iopub.execute_input":"2022-04-03T10:06:23.888407Z","iopub.status.idle":"2022-04-03T10:06:23.89354Z","shell.execute_reply.started":"2022-04-03T10:06:23.888238Z","shell.execute_reply":"2022-04-03T10:06:23.892845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roberta_model = build_model(1, roberta_pretrained_model)\n# roberta_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.894624Z","iopub.execute_input":"2022-04-03T10:06:23.895299Z","iopub.status.idle":"2022-04-03T10:06:23.902118Z","shell.execute_reply.started":"2022-04-03T10:06:23.895262Z","shell.execute_reply":"2022-04-03T10:06:23.901414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint_filepath = \"./roberta_model_checkpoint/checkpoint\"\n\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 4, min_delta=0.02, \n#                                      restore_best_weights=True),\n#     tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor= 1e-6, patience=2, \n#                                          verbose=0, mode='auto', \n#                                          min_delta=0.001, cooldown=0, min_lr=1e-6),\n#     tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n#                                        monitor='val_accuracy', mode='max', save_best_only=True)\n# ]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.903329Z","iopub.execute_input":"2022-04-03T10:06:23.904093Z","iopub.status.idle":"2022-04-03T10:06:23.910185Z","shell.execute_reply.started":"2022-04-03T10:06:23.904056Z","shell.execute_reply":"2022-04-03T10:06:23.909528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roberta_history = roberta_model.fit(X_train_roberta, y= y_train_dff, epochs= 20, batch_size= 16, \n#                                           validation_split= 0.2, callbacks= callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.911329Z","iopub.execute_input":"2022-04-03T10:06:23.912168Z","iopub.status.idle":"2022-04-03T10:06:23.918571Z","shell.execute_reply.started":"2022-04-03T10:06:23.912131Z","shell.execute_reply":"2022-04-03T10:06:23.917876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dl_metrics(roberta_history, \"accuracy\", \"f1_score\", \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.919797Z","iopub.execute_input":"2022-04-03T10:06:23.920535Z","iopub.status.idle":"2022-04-03T10:06:23.92659Z","shell.execute_reply.started":"2022-04-03T10:06:23.920498Z","shell.execute_reply":"2022-04-03T10:06:23.925869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roberta_model.evaluate(X_test_roberta, y_test_dff, batch_size= 16)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.934081Z","iopub.execute_input":"2022-04-03T10:06:23.934634Z","iopub.status.idle":"2022-04-03T10:06:23.938213Z","shell.execute_reply.started":"2022-04-03T10:06:23.934599Z","shell.execute_reply":"2022-04-03T10:06:23.937465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Résultats des différents essais avec RoBERTa:\n\nEntraînement:\n\n| -- | roberta_pft | hypermodel_roberta | roberta_model |\n| -- | -- | -- | -- |\n| F1 score | 0.6000 | 0.6000 | 0.6000 |\n| Accuracy | 0.7098 | 0.6765 | 0.5472 |\n| Loss | 0.5699 | 0.6104 | 0.7047 |\n| Epoch | 3 | 2 | 1 |\n\nÉvaluation:\n\n| -- | roberta_pft | hypermodel_roberta | roberta_model |\n| -- | -- | -- | -- |\n| F1 score | 0.5976 | 0.5976 | 0.5976 |\n| Accuracy | 0.6658 | 0.6605 | 0.5739 |\n| Loss | 0.6335 | 0.6185 | 0.7041 |\n\nLe modèle avec les hyperparamètres de bases, c'est-à-dire non optimisés, obtient les meilleurs accuracy autant pour la phase d'entraînement que d'évaluation. Je vais donc privilégier le modèle de base si je choisis RoBERTa.","metadata":{}},{"cell_type":"markdown","source":"# Comparaison des modèles\n\nRésultats issus des entraînements et évaluations:\n\nEntraînement\n\n| -- | XLNet | RoBERTa |\n| -- | -- | -- |\n| Epochs | 5 | 3 |\n| F1 score | 0.6000 | 0.6000 |\n| Accuracy | 0.5521 | 0.7098 |\n| Loss | 1.1068 | 0.5699 |\n\nÉvaluation\n\n| -- | XLNet | RoBERTa |\n| -- | -- | -- |\n| F1 score | 0.5976 | 0.5976 |\n| Accuracy | 0.6474 | 0.6658 |\n| Loss | 0.6810 | 0.6335 |\n\nOn peut voir que les F1 scores des deux modèles sont égaux.\nL'accuracy de RoBERTa est supérieure de 28.6% à celle de XLNet lors de l'entraînement et de 2.8% lors de l'évaluation.\n\nDe plus, RoBERTa est plus rapide à entraîner que XLNet avec respectivement 279ms/step et 444ms/step.\n\nJe vais donc opter pour RoBERTa pour obtenir les prédictions de la compétition.\n","metadata":{}},{"cell_type":"code","source":"roberta_model_pft.load_weights(\"../input/RoBERTa-checkpoint/checkpoint\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:23.939462Z","iopub.execute_input":"2022-04-03T10:06:23.940057Z","iopub.status.idle":"2022-04-03T10:06:36.761224Z","shell.execute_reply.started":"2022-04-03T10:06:23.94002Z","shell.execute_reply":"2022-04-03T10:06:36.760436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Affichage de la matrice de confusion et du rapport de classification.","metadata":{}},{"cell_type":"code","source":"predictions = roberta_model_pft.predict(X_test_roberta)[:, 0]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:36.765035Z","iopub.execute_input":"2022-04-03T10:06:36.765293Z","iopub.status.idle":"2022-04-03T10:06:59.750285Z","shell.execute_reply.started":"2022-04-03T10:06:36.765257Z","shell.execute_reply":"2022-04-03T10:06:59.749447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:59.753616Z","iopub.execute_input":"2022-04-03T10:06:59.75426Z","iopub.status.idle":"2022-04-03T10:06:59.761311Z","shell.execute_reply.started":"2022-04-03T10:06:59.754225Z","shell.execute_reply":"2022-04-03T10:06:59.760207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analyse de la courbe ROC pour obtenir un Recall supérieur à 80% et une Précision ~= 50%.","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\n\n[fpr, tpr, thr] = metrics.roc_curve(y_test_dff, predictions)\nplt.plot(fpr, tpr, color='coral', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1 - specificite', fontsize=14)\nplt.ylabel('Sensibilite', fontsize=14)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:59.763167Z","iopub.execute_input":"2022-04-03T10:06:59.764555Z","iopub.status.idle":"2022-04-03T10:06:59.965949Z","shell.execute_reply.started":"2022-04-03T10:06:59.764512Z","shell.execute_reply":"2022-04-03T10:06:59.965215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# indice du premier seuil pour lequel\n# la sensibilité est supérieure à 0.75\nidx = np.min(np.where(tpr > 0.95)) \n\nprint(\"Sensibilité : {:.2f}\".format(tpr[idx]))\nprint(\"Spécificité : {:.2f}\".format(1-fpr[idx]))\nprint(\"Seuil : {:.2f}\".format(thr[idx]))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:19:45.633671Z","iopub.execute_input":"2022-04-03T10:19:45.634481Z","iopub.status.idle":"2022-04-03T10:19:45.640909Z","shell.execute_reply.started":"2022-04-03T10:19:45.634438Z","shell.execute_reply":"2022-04-03T10:19:45.640121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.auc(fpr, tpr))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:06:59.97732Z","iopub.execute_input":"2022-04-03T10:06:59.977583Z","iopub.status.idle":"2022-04-03T10:06:59.983556Z","shell.execute_reply.started":"2022-04-03T10:06:59.977547Z","shell.execute_reply":"2022-04-03T10:06:59.982861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'aire sous la courbe vaut 0.696 ce qui indique que le classifieur est partiellement aléatoire.\n\nLe seuil est fixé à 0.13.","metadata":{}},{"cell_type":"code","source":"preds = np.where(predictions >= 0.5, 1, 0)\npreds[:25]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:20:31.809235Z","iopub.execute_input":"2022-04-03T10:20:31.809514Z","iopub.status.idle":"2022-04-03T10:20:31.81591Z","shell.execute_reply.started":"2022-04-03T10:20:31.809483Z","shell.execute_reply":"2022-04-03T10:20:31.815104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\nfig = plt.figure(figsize=(5, 5))\nax = sns.heatmap(confusion_matrix(y_test_dff, preds), annot= True)\nax.set_xlabel(\"Labels predits\", color=\"g\")\nax.set_ylabel(\"True labels\", color=\"orange\")\n# ax.xaxis.set_ticklabels(le.classes_, \n#                         rotation='vertical')\n# ax.yaxis.set_ticklabels(le.classes_,\n#                         rotation='horizontal')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:20:34.098082Z","iopub.execute_input":"2022-04-03T10:20:34.098351Z","iopub.status.idle":"2022-04-03T10:20:34.339254Z","shell.execute_reply.started":"2022-04-03T10:20:34.09832Z","shell.execute_reply":"2022-04-03T10:20:34.338578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\n\nprecision, recall, fscore, support = precision_recall_fscore_support(y_test_dff, preds, average= \"binary\")\n\nprint(f\"Détails de la matrice de confusion:\")\nprint(f\"Précision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 score: {fscore}\")\nsupport","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:20:45.804781Z","iopub.execute_input":"2022-04-03T10:20:45.805061Z","iopub.status.idle":"2022-04-03T10:20:45.814763Z","shell.execute_reply.started":"2022-04-03T10:20:45.80503Z","shell.execute_reply":"2022-04-03T10:20:45.814019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(\n    y_test_dff, preds, \n#     target_names= set(y_test_dff)\n))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:20:47.599428Z","iopub.execute_input":"2022-04-03T10:20:47.599953Z","iopub.status.idle":"2022-04-03T10:20:47.613786Z","shell.execute_reply.started":"2022-04-03T10:20:47.599915Z","shell.execute_reply":"2022-04-03T10:20:47.613109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prédictions finales pour la compétition.","metadata":{}},{"cell_type":"code","source":"test_roberta = roberta_encode(test_dff[\"decoded_joined\"], roberta_tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:20:56.961256Z","iopub.execute_input":"2022-04-03T10:20:56.961531Z","iopub.status.idle":"2022-04-03T10:20:58.414339Z","shell.execute_reply.started":"2022-04-03T10:20:56.9615Z","shell.execute_reply":"2022-04-03T10:20:58.413629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dff[\"target\"] = roberta_model_pft.predict(test_roberta)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:25:03.315466Z","iopub.execute_input":"2022-04-03T10:25:03.315727Z","iopub.status.idle":"2022-04-03T10:25:44.313953Z","shell.execute_reply.started":"2022-04-03T10:25:03.315698Z","shell.execute_reply":"2022-04-03T10:25:44.313185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dff[\"target\"] = test_dff[\"target\"].mask(test_dff[\"target\"] >= 0.5, 1).astype(\"int\")\ntest_dff[\"target\"] = test_dff[\"target\"].mask(test_dff[\"target\"] < 0.5, 0).astype(\"int\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:25:44.315635Z","iopub.execute_input":"2022-04-03T10:25:44.315897Z","iopub.status.idle":"2022-04-03T10:25:44.325245Z","shell.execute_reply.started":"2022-04-03T10:25:44.315861Z","shell.execute_reply":"2022-04-03T10:25:44.324454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(test_dff[[\"id\", \"target\"]])\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:25:44.326651Z","iopub.execute_input":"2022-04-03T10:25:44.327178Z","iopub.status.idle":"2022-04-03T10:25:44.343023Z","shell.execute_reply.started":"2022-04-03T10:25:44.327141Z","shell.execute_reply":"2022-04-03T10:25:44.342329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index= False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:25:44.344895Z","iopub.execute_input":"2022-04-03T10:25:44.345174Z","iopub.status.idle":"2022-04-03T10:25:44.356866Z","shell.execute_reply.started":"2022-04-03T10:25:44.345139Z","shell.execute_reply":"2022-04-03T10:25:44.356256Z"},"trusted":true},"execution_count":null,"outputs":[]}]}