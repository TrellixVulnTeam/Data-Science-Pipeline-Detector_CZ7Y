{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><font size=\"+3.5\" color=\"blue\" style=\"font-family: Futura\"><center>Natural Langauge Processing</center></font></h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\">In current genreation NLP is going heigher and higher everyday. So many bigtech companies are using NLP im there product. like <a href=\"https://google.com\">Google</a> in Google assistant, <a href=\"https://apple.com\">Apple</a> in siri, <a href=\"https:www.amazon.com\">Amazon</a> in Alexa, <a href='https://microsoft.com'>Microsoft</a> and so on.</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\">Here I am going to explain Natural Langauge Processing. I have learn lot of thing from good Youtube channels and so many blogs which i sharing here which will help you also. <a href=\"https://www.youtube.com/playlist?list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm\">NLP Basic(Youtube)</a> and <a href=\"https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1\">Blog</a> this site and channle both helping me so much to learn Data Science and Machine learnig. Here i am using some diffrent approch for presentation which i learn from this <a href='https://www.kaggle.com/vishalvanpariya/house-pricing-ultimate-guide/edit'>kernel</a>.</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-family: Futura; color:blue;\">Overview</h2>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* [<font size='3' style=\"font-family: Futura\">1.Importing Important Libraries</font>](#1)\n* [<font size='3' style=\"font-family: Futura\">2.Importing Data</font>](#2)\n* [<font size='3' style=\"font-family: Futura\">3.Data Cleaning</font>](#3)\n* [<font size='3' style=\"font-family: Futura\">4.Feature Scalling</font>](#4)\n* [<font size='3' style=\"font-family: Futura\">5.Modeling</font>](#5)\n* [<font size='3' style=\"font-family: Futura\">6.Submission</font>](#6)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-family: Futura; color:green \"><b>1. Libraries</b></h2><br><a id='1'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk import word_tokenize\nfrom collections import defaultdict\nfrom nltk.stem import WordNetLemmatizer\nimport string\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\">\n<b style=\"color:blue\">Use Of Liberaries:</b><br><br>\n    &emsp;&emsp;<b style=\"color:green\">1. Numpy :</b> we will use it for maths opration<br>\n    &emsp;&emsp;<b style=\"color:green\">2. Pandas :</b> Data Handling<br>\n    &emsp;&emsp;<b style=\"color:green\">3. re :</b> Regular Expression<br>\n    &emsp;&emsp;<b style=\"color:green\">4. Stopwords :</b> Remove Stopwords<br>\n    &emsp;&emsp;<b style=\"color:green\">5. PorterStemmer :</b> For Stemming<br>\n    &emsp;&emsp;<b style=\"color:green\">6. word_tokenize :</b> For work token<br>\n    &emsp;&emsp;<b style=\"color:green\">7. defaultdict :</b> For dictionary<br>\n    &emsp;&emsp;<b style=\"color:green\">8. WordNetLemmatizer :</b> For word lemmatize<br>\n    &emsp;&emsp;<b style=\"color:green\">9. String :</b> For string oprations<br>\n    &emsp;&emsp;<b style=\"color:green\">10. TfidfVectorizer :</b> Vecterization<br>\n</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-family: Futura; color:green \"><b>2. Import Data</b></h2><br><a id='2'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/nlp-getting-started/train.csv')\ntest=pd.read_csv('../input/nlp-getting-started/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-family: Futura; color:green \"><b>3. Data Cleaning</b></h2><br><a id='3'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\">\n<b style=\"color:green\">id</b> - a unique identifier for each tweet<br>\n    <b style=\"color:green\">text</b> - the text of the tweet<br>\n<b style=\"color:green\">location</b> - the location the tweet was sent from (may be blank)<br>\n<b style=\"color:green\">keyword</b> - a particular keyword from the tweet (may be blank)<br>\n<b style=\"color:green\">target</b> - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)<br>\n</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\">Let's delete keyword and location</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop('keyword',1)\ntrain=train.drop('location',1)\n\ntest=test.drop('keyword',1)\ntest=test.drop('location',1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\">let's have important data from Dataframe</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train.iloc[:,-1]\nx_train=train.iloc[:,:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ps=PorterStemmer()\nlemmatizer=WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def atcontain(text):\n    ar=[]\n    text=text.split()\n    for t in text:\n        if(\"@\" in t):\n            ar.append(\"TAGSOMEBODY\")\n        else:\n            ar.append(t)\n    return \" \".join(ar)\n    \n\ndef dataclean(data):\n    corpus=[]\n    for i in range(data.shape[0]):\n        tweet=data.iloc[i,-1]\n        tweet=atcontain(tweet)\n        tweet=re.sub(r'http\\S+', '', tweet)\n        tweet=re.sub('[^a-zA-z]',\" \",tweet)\n        tweet=tweet.lower()\n        tweet=word_tokenize(tweet)\n#         tweet=[ps.stem(word) for word in tweet if word not in stopwords.words('english')]\n        tweet=[lemmatizer.lemmatize(word) for word in tweet if word not in stopwords.words('english')]\n        tweet=[word for word in tweet if word not in set(string.punctuation)]\n        tweet=\" \".join(tweet)\n        corpus.append(tweet)\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\"><b style=\"color:green\">Creating data clean function:</b><br>\n    in this function we are going remove puctuationa,stopword and changing to lower case<br>\n    i have commented one line in function which is for porter stemmer, i commented it because it is decresing model accuracy\n</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_corpus_train=dataclean(x_train)\nx_corpus_test=dataclean(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura; color:green\">Data Cleaned</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dic=defaultdict(int)\nfor text in x_corpus_train:\n    text=text.split()\n    for word in text:\n        dic[word]=dic[word]+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='3' style=\"font-family: Futura\">Sorting values through frequency of word</font>","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sorted_data=sorted(dic.items(), key=lambda x:x[1],reverse=True)\nsorted_data[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-family: Futura; color:green \"><b>4. Feature Scalling</b></h2><br><a id='4'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=TfidfVectorizer(max_features=8000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_vector=cv.fit_transform(x_corpus_train).toarray()\nx_test_vector=cv.transform(x_corpus_test).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-family: Futura; color:green \"><b>5. Modeling</b></h2><br><a id='5'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"font-family: Futura; color:blue \"><b>1. Naive Bayes</b></h3><br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB()\nmodel.fit(x_train_vector,y_train)\nprint(model.score(x_train_vector,y_train))\ny_pred=model.predict(x_test_vector)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"font-family: Futura; color:blue \"><b>2. Randomforest</b></h3><br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(random_state=4,n_estimators=500,warm_start=True,max_depth=6,min_samples_leaf=2,max_features='auto',min_samples_split=3)\nrfc.fit(x_train_vector,y_train)\nprint(rfc.score(x_train_vector,y_train))\ny_pred=rfc.predict(x_test_vector)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"font-family: Futura; color:blue \"><b>3. XGBoost</b></h3><br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb=XGBClassifier()\nxgb.fit(x_train_vector,y_train,early_stopping_rounds=5, \n             eval_set=[(x_train_vector,y_train)], \n             verbose=False)\nprint(xgb.score(x_train_vector,y_train))\ny_pred=xgb.predict(x_test_vector)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"font-family: Futura; color:blue \"><b>4. Logistic Regression</b></h3><br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nreg=LogisticRegression()\nreg.fit(x_train_vector,y_train)\nprint(reg.score(x_train_vector,y_train))\ny_pred=reg.predict(x_test_vector)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"font-family: Futura; color:blue \"><b>5. PassiveAggressiveClassifier</b></h3><br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import PassiveAggressiveClassifier\npassive=PassiveAggressiveClassifier()\npassive.fit(x_train_vector,y_train)\nprint(passive.score(x_train_vector,y_train))\ny_pred=passive.predict(x_test_vector)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-family: Futura; color:green \"><b>6. Submission</b></h2><br><a id='6'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\nsubmission['target']=y_pred\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<h1>Check out my other Notebooks</h1><font size='4'>\n<a href=\"https://www.kaggle.com/vishalvanpariya/top-5-on-leaderboard\" target=\"_blank\">House Price</a><br>\n<a href=\"https://www.kaggle.com/vishalvanpariya/data-explanation-titanic\" target=\"_blank\">Titanic EDA</a><br>\n<a href=\"https://www.kaggle.com/vishalvanpariya/titanic-top-6\" target=\"_blank\">Titanic Notebook</a><br>\n<a href=\"https://www.kaggle.com/vishalvanpariya/nlp-for-beginners\" target=\"_blank\">NLP</a><br><font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}