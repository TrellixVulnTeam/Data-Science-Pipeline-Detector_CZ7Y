{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n%matplotlib inline\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nimport xgboost\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,SpatialDropout1D\nfrom tensorflow.keras.layers import LSTM,Dropout\nfrom keras.layers import Bidirectional\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom numpy import array\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"target\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(\"target\",data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA PREPROCESSING"},{"metadata":{},"cell_type":"markdown","source":"Let initiliaze our stemmer and tokenizer and do some data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweettoken = TweetTokenizer(strip_handles=True, reduce_len=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmatizer=WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer=PorterStemmer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collect=[]\ncollecttest=[]\ndef preprocess(t,kpc):\n    def form_sentence(tweet):\n        tweet_blob = TextBlob(tweet)\n        return ' '.join(tweet_blob.words)\n    t=form_sentence(t)\n    tee=re.sub('[^a-zA-Z]',\" \",t)\n    tee=tee.lower()\n    res=tweettoken.tokenize(tee)\n    for i in res:\n        if i in stopwords.words('english'):\n            res.remove(i)\n    rest=[]\n    for k in res:\n        rest.append(stemmer.stem(k))\n    ret=\" \".join(rest)\n    if kpc==1:\n        collect.append(ret)\n    elif kpc==0:\n        collecttest.append(ret)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def splitpro(t,q,m):\n         for j in range(q):\n                 preprocess(t[\"text\"].iloc[j],m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splitpro(train,7613,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splitpro(test,3263,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(collect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(collecttest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collect[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collecttest[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val=train[\"target\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oneh=[]\noneht=[]\ndef hot(cc,k):\n    for i in cc:\n        if k==1:\n            oneh.append(one_hot(i,500))\n        elif k==0:\n            oneht.append(one_hot(i,500))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hot(collect,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hot(collecttest,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(oneh[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max=0\nfor i in oneh:\n    tq=len(i)\n    if tq>max:\n        max=tq\nprint(max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent=38\nemoneh=pad_sequences(oneh,padding=\"post\",maxlen=sent)\nemoneht=pad_sequences(oneht,padding=\"post\",maxlen=sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest=train_test_split(emoneh,val,train_size=0.80,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(500,15,input_length=sent))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=50,batch_size=300,verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tttt=model.predict(emoneht)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tttt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttttt=tttt.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = pd.Series(ttttt,name=\"target\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=test[\"id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submiss = pd.concat([pd.Series(t,name = \"id\"),r],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submiss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submiss.to_csv(\"disasml20.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}