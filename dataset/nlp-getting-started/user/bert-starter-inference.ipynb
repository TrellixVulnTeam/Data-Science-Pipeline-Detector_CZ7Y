{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport re\nimport os\nimport torch\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Install HuggingFace implementation of bert (https://huggingface.co/)."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertModel, BertTokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_to_dataset = '/kaggle/input/nlp-getting-started/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(path_to_dataset, 'test.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining our simple model (logistic regression over the bert base model)."},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(torch.nn.Module):\n    \n    def __init__(self, ):\n        \n        super(Model, self).__init__()\n        self.base_model = BertModel.from_pretrained('bert-base-uncased') #pretrained bert model\n        self.fc1 = torch.nn.Linear(768, 1) #use logistic regression\n        \n    def forward(self, ids, masks):\n        \n        x = self.base_model(ids, attention_mask=masks)[1]\n        x = self.fc1(x)\n        return x\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_to_model = '/kaggle/input/nlpgetstartedbertbasemoel/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the pretrained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load(os.path.join(path_to_model, 'model.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_encode(text, max_len=512):\n    \n    text = tokenizer.tokenize(text)\n    text = text[:max_len-2]\n    input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n    tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n    tokens += [0] * (max_len - len(input_sequence))\n    pad_masks = [1] * len(input_sequence) + [0] * (max_len - len(input_sequence))\n\n    return tokens, pad_masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, test_tokens, test_pad_masks):\n        \n        super(TestDataset, self).__init__()\n        self.test_tokens = test_tokens\n        self.test_pad_masks = test_pad_masks\n        \n    def __getitem__(self, index):\n        \n        tokens = self.test_tokens[index]\n        masks = self.test_pad_masks[index]\n        \n        return (tokens, masks)\n    \n    def __len__(self,):\n        \n        return len(self.test_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tokens = []\ntest_pad_masks = []\nfor text in test_df.text:\n    tokens, masks = bert_encode(text)\n    test_tokens.append(tokens)\n    test_pad_masks.append(masks)\n    \ntest_tokens = np.array(test_tokens)\ntest_pad_masks = np.array(test_pad_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = TestDataset(\n    test_tokens=test_tokens,\n    test_pad_masks=test_pad_masks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=3, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\ny_preds = []\nfor (tokens, masks) in test_dataloader:\n\n    y_pred = model(\n                torch.tensor(tokens, dtype=torch.long).to(device),\n                torch.tensor(masks, dtype=torch.long).to(device),\n            )\n    y_preds += y_pred.detach().cpu().numpy().squeeze().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(os.path.join(path_to_dataset, 'sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target is 1 if the output is greater than 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['target'] = (np.array(y_preds) >= 0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Writing to submission.csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}