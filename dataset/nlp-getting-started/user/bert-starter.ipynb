{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"dDLYS2xJYQ6l","colab_type":"code","colab":{}},"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nimport os\nimport torch\nimport numpy as np\nimport tqdm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"ft25hGgZYQ6o","colab_type":"code","outputId":"34c17ee8-5b82-47e7-fc2d-cbb9bfb89b10","colab":{"base_uri":"https://localhost:8080/","height":373}},"cell_type":"code","source":"!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"LreMa21WYQ60","colab_type":"code","outputId":"16b57e05-3859-4da7-d784-d0f9309ebf4e","colab":{"base_uri":"https://localhost:8080/","height":62}},"cell_type":"code","source":"from transformers import BertModel, BertTokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"egoYyBasYQ62","colab_type":"code","colab":{}},"cell_type":"code","source":"path_to_dataset = '/kaggle/input/nlp-getting-started/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"60yz6umrYQ65","colab_type":"code","colab":{}},"cell_type":"code","source":"test = pd.read_csv(os.path.join(path_to_dataset, 'test.csv'))\ntrain = pd.read_csv(os.path.join(path_to_dataset, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"3mUsu0OnYQ7L","colab_type":"code","colab":{}},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"uvKfV5xVYQ7Q","colab_type":"code","colab":{}},"cell_type":"code","source":"class Model(torch.nn.Module):\n    \n    def __init__(self, ):\n        \n        super(Model, self).__init__()\n        self.base_model = BertModel.from_pretrained('bert-base-uncased') # use pre-trained BERT model by HuggingFace\n        self.fc1 = torch.nn.Linear(768, 1) # simple logistic regression above the bert model\n        \n    def forward(self, ids, masks):\n        \n        x = self.base_model(ids, attention_mask=masks)[1]\n        x = self.fc1(x)\n        return x\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"4RxtBVRzYQ7U","colab_type":"code","colab":{}},"cell_type":"code","source":"model = Model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"P9jYAk2tYQ7a","colab_type":"code","colab":{}},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"hu0G6gWPYQ7g","colab_type":"code","colab":{}},"cell_type":"code","source":"model = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"D25GxDlnYQ7l","colab_type":"code","colab":{}},"cell_type":"code","source":"def bert_encode(text, max_len=512):\n    \n    text = tokenizer.tokenize(text)\n    text = text[:max_len-2]\n    input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n    tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n    tokens += [0] * (max_len - len(input_sequence))\n    pad_masks = [1] * len(input_sequence) + [0] * (max_len - len(input_sequence))\n\n    return tokens, pad_masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"3fJiZDy_YQ7o","colab_type":"code","colab":{}},"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-z0-9] \\n', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use first 6000 for training, rest for validation"},{"metadata":{"trusted":true,"id":"eXv4GsJpYQ7w","colab_type":"code","colab":{}},"cell_type":"code","source":"train_text = train.text[:6000]\nval_text = train.text[6000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"0CVkqo36YQ70","colab_type":"code","colab":{}},"cell_type":"code","source":"train_text = train_text.apply(clean_text)\nval_text = val_text.apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"UrF1Zo-dYQ79","colab_type":"code","colab":{}},"cell_type":"code","source":"train_tokens = []\ntrain_pad_masks = []\nfor text in train_text:\n    tokens, masks = bert_encode(text)\n    train_tokens.append(tokens)\n    train_pad_masks.append(masks)\n    \ntrain_tokens = np.array(train_tokens)\ntrain_pad_masks = np.array(train_pad_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"6fQTuqiGYQ8D","colab_type":"code","colab":{}},"cell_type":"code","source":"val_tokens = []\nval_pad_masks = []\nfor text in val_text:\n    tokens, masks = bert_encode(text)\n    val_tokens.append(tokens)\n    val_pad_masks.append(masks)\n    \nval_tokens = np.array(val_tokens)\nval_pad_masks = np.array(val_pad_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"yze74WnSYQ8G","colab_type":"code","colab":{}},"cell_type":"code","source":"\nclass Dataset(torch.utils.data.Dataset):\n    \n    def __init__(self, train_tokens, train_pad_masks, targets):\n        \n        super(Dataset, self).__init__()\n        self.train_tokens = train_tokens\n        self.train_pad_masks = train_pad_masks\n        self.targets = targets\n        \n    def __getitem__(self, index):\n        \n        tokens = self.train_tokens[index]\n        masks = self.train_pad_masks[index]\n        target = self.targets[index]\n        \n        return (tokens, masks), target\n    \n    def __len__(self,):\n        \n        return len(self.train_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"F-IoZpwYYQ8I","colab_type":"code","colab":{}},"cell_type":"code","source":"train_dataset = Dataset(\n                    train_tokens=train_tokens,\n                    train_pad_masks=train_pad_masks,\n                    targets=train.target[:6000]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 6\nEPOCHS = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"VbgDF9-sYQ8K","colab_type":"code","colab":{}},"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.BCEWithLogitsLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use Adam Optimizer with learning rate of 0.00001"},{"metadata":{"trusted":true,"id":"RBUVo0o4YQ8R","colab_type":"code","colab":{}},"cell_type":"code","source":"opt = torch.optim.Adam(model.parameters(), lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train for 2 epochs."},{"metadata":{"trusted":true,"id":"MAn-sCjzYQ8W","colab_type":"code","outputId":"295b32fc-0beb-4317-a806-375b1d190aa2","colab":{"base_uri":"https://localhost:8080/","height":1000}},"cell_type":"code","source":"model.train()\ny_preds = []\n\nfor epoch in range(EPOCHS):\n        for i, ((tokens, masks), target) in enumerate(train_dataloader):\n\n            y_pred = model(\n                        tokens.long().to(device), \n                        masks.long().to(device)\n                    )\n            loss = criterion(y_pred, target[:, None].float().to(device))\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            print('\\rEpoch: %d/%d, %f%% loss: %0.2f'% (epoch+1, EPOCHS, i/len(train_dataloader)*100, loss.item()), end='')\n        print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test the model on the validation dataset"},{"metadata":{"id":"Ft0-NpxmhJXq","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"val_dataset = Dataset(\n                    train_tokens=val_tokens,\n                    train_pad_masks=val_pad_masks,\n                    targets=train.target[6000:].reset_index(drop=True)\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"f0oq-S-DaADT","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=3, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define accuracy metric"},{"metadata":{"id":"ve63qae4iDwh","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def accuracy(y_actual, y_pred):\n    y_ = y_pred > 0\n    return np.sum(y_actual == y_).astype('int') / y_actual.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"QQplK689h5aU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b7dd9071-6156-4772-8114-81b7445668e6","trusted":true},"cell_type":"code","source":"model.eval()\navg_acc = 0\nfor i, ((tokens, masks), target) in enumerate(val_dataloader):\n\n    y_pred = model(\n                tokens.long().to(device), \n                masks.long().to(device), \n            )\n    loss = criterion(y_pred,  target[:, None].float().to(device))\n    acc = accuracy(target.cpu().numpy(), y_pred.detach().cpu().numpy().squeeze())\n    avg_acc += acc\n    print('\\r%0.2f%% loss: %0.2f, accuracy %0.2f'% (i/len(val_dataloader)*100, loss.item(), acc), end='')\nprint('\\nAverage accuracy: ', avg_acc / len(val_dataloader))","execution_count":null,"outputs":[]},{"metadata":{"id":"ta_HjUOlkcoC","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, test_tokens, test_pad_masks):\n        \n        super(TestDataset, self).__init__()\n        self.test_tokens = test_tokens\n        self.test_pad_masks = test_pad_masks\n        \n    def __getitem__(self, index):\n        \n        tokens = self.test_tokens[index]\n        masks = self.test_pad_masks[index]\n        \n        return (tokens, masks)\n    \n    def __len__(self,):\n        \n        return len(self.test_tokens)","execution_count":null,"outputs":[]},{"metadata":{"id":"bxHhO1ShkwuE","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"test_tokens = []\ntest_pad_masks = []\nfor text in test.text:\n    tokens, masks = bert_encode(text)\n    test_tokens.append(tokens)\n    test_pad_masks.append(masks)\n    \ntest_tokens = np.array(test_tokens)\ntest_pad_masks = np.array(test_pad_masks)","execution_count":null,"outputs":[]},{"metadata":{"id":"h2S0s7Mskceg","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"test_dataset = TestDataset(\n    test_tokens=test_tokens,\n    test_pad_masks=test_pad_masks\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"NqNQdB7nkrwX","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=3, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"XWdtUf72lbeU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"6df1b8a3-575c-4dc7-bfa8-e1409c0b4da9","trusted":true},"cell_type":"code","source":"model.eval()\ny_preds = []\nfor (tokens, masks) in test_dataloader:\n\n    y_pred = model(\n                tokens.long().to(device), \n                masks.long().to(device), \n            )\n    y_preds += y_pred.detach().cpu().numpy().squeeze().tolist()","execution_count":null,"outputs":[]},{"metadata":{"id":"mYhm2iiZl9Dr","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(os.path.join(path_to_dataset, 'sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{"id":"PQViCYQamCp4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"submission_df['target'] = (np.array(y_preds) > 0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"id":"T2-2y6R5nDDp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"e5aa08a2-280a-485b-dd69-7bccbf938ab9","trusted":true},"cell_type":"code","source":"submission_df.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"1XT7pT-smVlJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"outputId":"0f2e9c14-2ffc-4d0d-f783-96b36e4670cc","trusted":true},"cell_type":"code","source":"submission_df","execution_count":null,"outputs":[]},{"metadata":{"id":"VLB7DwOzmYCq","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZaJks0hknH4p","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"kernel69237ad76a.ipynb","provenance":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}