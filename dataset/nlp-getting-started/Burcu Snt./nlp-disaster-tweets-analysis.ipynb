{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this study, we will guess the posted tweet whether about disaster or not. Before we start, let's take a look what we have. In this data we have 5 columns as seen below.\n\n* id - a unique identifier for each tweet\n* text - the text of the tweet\n* location - the location the tweet was sent from (may be blank)\n* keyword - a particular keyword from the tweet (may be blank)\n* target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)","metadata":{}},{"cell_type":"markdown","source":" Let's import to libraries that we use in our case study.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T17:08:16.642102Z","iopub.execute_input":"2021-10-31T17:08:16.642675Z","iopub.status.idle":"2021-10-31T17:08:17.645252Z","shell.execute_reply.started":"2021-10-31T17:08:16.642638Z","shell.execute_reply":"2021-10-31T17:08:17.644377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading our dataset. And we know that, it's a dataframe.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-31T16:54:16.94503Z","iopub.execute_input":"2021-10-31T16:54:16.945592Z","iopub.status.idle":"2021-10-31T16:54:16.982997Z","shell.execute_reply.started":"2021-10-31T16:54:16.945552Z","shell.execute_reply":"2021-10-31T16:54:16.982054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T16:54:19.430169Z","iopub.execute_input":"2021-10-31T16:54:19.43075Z","iopub.status.idle":"2021-10-31T16:54:19.444998Z","shell.execute_reply.started":"2021-10-31T16:54:19.430711Z","shell.execute_reply":"2021-10-31T16:54:19.444067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-10-31T16:54:22.69774Z","iopub.execute_input":"2021-10-31T16:54:22.698039Z","iopub.status.idle":"2021-10-31T16:54:22.72885Z","shell.execute_reply.started":"2021-10-31T16:54:22.698009Z","shell.execute_reply":"2021-10-31T16:54:22.728093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"We have \" + str(df.shape[0]) + \" samples \" + \"and \" + str(df.shape[1]) + \" columns.\")","metadata":{"execution":{"iopub.status.busy":"2021-10-31T16:54:24.893327Z","iopub.execute_input":"2021-10-31T16:54:24.893611Z","iopub.status.idle":"2021-10-31T16:54:24.89872Z","shell.execute_reply.started":"2021-10-31T16:54:24.893581Z","shell.execute_reply":"2021-10-31T16:54:24.897915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we seen below, the most na values are in keyword and location variable.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T16:54:27.235664Z","iopub.execute_input":"2021-10-31T16:54:27.23637Z","iopub.status.idle":"2021-10-31T16:54:27.250701Z","shell.execute_reply.started":"2021-10-31T16:54:27.236325Z","shell.execute_reply":"2021-10-31T16:54:27.249989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check some location and keyword values in the data.\nFirst I started with location. I group by location data with sum, also apply same things to keyword. When I filter the data I applied mean values for each of them just to be sure not complicated graph.","metadata":{}},{"cell_type":"code","source":"location_df = pd.DataFrame(df[\"location\"].value_counts())\nlocation_df = location_df.rename(columns = {'location':'counts'})\nlocation_df.reset_index(inplace = True)\nlocation_df = location_df.rename(columns = {'index':'location'})\nprint(\"mean: \" + str(location_df.counts.mean()))\n#type(location_df)\n#location_df\nlocation_df = location_df[location_df.counts > 16]\n#location_df.head(100)\nlocation_df.plot.barh(x = 'location' , y = 'counts')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T18:24:19.075572Z","iopub.execute_input":"2021-10-31T18:24:19.075848Z","iopub.status.idle":"2021-10-31T18:24:19.412111Z","shell.execute_reply.started":"2021-10-31T18:24:19.075819Z","shell.execute_reply":"2021-10-31T18:24:19.411484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keyword_df = pd.DataFrame(df[\"keyword\"].value_counts())\nkeyword_df = keyword_df.rename(columns = {'keyword':'counts'})\nkeyword_df.reset_index(inplace = True)\nkeyword_df = keyword_df.rename(columns = {'index':'keyword'})\nprint(\"mean: \" + str(keyword_df.counts.mean()))\n#type(keyword_df)\n#keyword_df\nkeyword_df = keyword_df[keyword_df.counts > 38 ]\n#keyword_df.head(100)\nkeyword_df.plot.barh(x = 'keyword' , y = 'counts')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T18:24:36.81443Z","iopub.execute_input":"2021-10-31T18:24:36.814844Z","iopub.status.idle":"2021-10-31T18:24:37.26699Z","shell.execute_reply.started":"2021-10-31T18:24:36.814814Z","shell.execute_reply":"2021-10-31T18:24:37.266182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  to be continued","metadata":{}}]}