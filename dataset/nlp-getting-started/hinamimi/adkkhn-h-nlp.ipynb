{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\nfrom datetime import datetime\nfrom pytz import timezone\ndatetime.now(timezone('Asia/Tokyo')).strftime('%Y/%m/%d %H:%M:%S')\n\ndef refer_args(x):\n    if type(x) == 'method':\n        print(*x.__code__.co_varnames.split(), sep='\\n')\n    else:\n        print(*[x for x in dir(x) if not x.startswith('__')], sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom collections import Counter\nimport re\nimport string\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom nltk.corpus import stopwords\nstop=set(stopwords.words('english'))\nfrom nltk.util import ngrams\nfrom nltk.tokenize import word_tokenize\nimport gensim\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/nlp-getting-started/train.csv')\ndf_train_meta = pd.read_csv('../input/nlpwithdisastertweets-searching-real-tweets/train_tweet.csv')\ndf_test = pd.read_csv('../input/nlp-getting-started/test.csv')\ndf_test_meta = pd.read_csv('../input/nlpwithdisastertweets-searching-real-tweets/test_tweet.csv')\ndf_train.head(3)\ndf_train_meta.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(3)\ndf_train_meta.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_meta['permalink'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\n## ハッシュタグの数を抽出\ndf_train_meta['nb_hashtag'] = \\\n        df_train_meta['hashtags'].fillna('').apply(lambda x:x.count('#'))\n\n## リプライの数を抽出\ndf_train_meta['nb_mention'] = \\\n        df_train_meta['mentions'].fillna('').apply(lambda x:x.count('@'))\n\n## コンペ以降のツイートデータを無視\ncompete_start_date = datetime(2019, 12, 20, tzinfo=timezone('UTC'))\nsr_date = pd.to_datetime(df_train_meta['date'].fillna(datetime.now()))\ndf_train_meta[sr_date >= compete_start_date] = pd.NA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['exist tweet'] = df_train_meta['id'].notna()\ndf_train['favorites'] = df_train_meta['favorites']\ndf_train['retweets'] = df_train_meta['retweets']\ndf_train['mentions'] = df_train_meta['nb_mention']\ndf_train['hashtags'] = df_train_meta['hashtags']\ndf_train['date'] = df_train_meta['date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n_ = sns.barplot(x='exist tweet', y='target', data=df_train, ax=ax1)\n_ = sns.countplot(x='exist tweet', hue='target', data=df_train, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = (-2, -0.5, 0.5, 2.5, 9.5, 1000)\ngroup_names = ('Unknown', '0', '1-2', '3-9', '10-')\ndf_train['FavGroup'] = pd.cut(df_train['favorites'].fillna(-1), bins, labels=group_names)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n_ = sns.barplot(x='FavGroup', y='target', data=df_train, ax=ax1)\n_ = sns.countplot(x='FavGroup', hue='target', data=df_train, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = (-2, -0.5, 0.5, 2.5, 9.5, 1000)\ngroup_names = ('Unknown', '0', '1-2', '3-9', '10-')\ndf_train['RetGroup'] = pd.cut(df_train['retweets'].fillna(-1), bins, labels=group_names)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n_ = sns.barplot(x='RetGroup', y='target', data=df_train, ax=ax1)\n_ = sns.countplot(x='RetGroup', hue='target', data=df_train, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = (-2, -0.5, 0.5, 2.5, 4.5, 1000)\ngroup_names = ('Unknown', '0', '1-2', '3-4', '5-')\ndf_train['MenGroup'] = pd.cut(df_train['mentions'].fillna(-1), bins, labels=group_names)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n_ = sns.barplot(x='MenGroup', y='target', data=df_train, ax=ax1)\n_ = sns.countplot(x='MenGroup', hue='target', data=df_train, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = (-2, -0.5, 0.5, 1000)\ngroup_names = ('Unknown', '0', '1-')\ndf_train['HashGroup'] = pd.cut(df_train['mentions'].fillna(-1), bins, labels=group_names)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n_ = sns.barplot(x='HashGroup', y='target', data=df_train, ax=ax1)\n_ = sns.countplot(x='HashGroup', hue='target', data=df_train, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}