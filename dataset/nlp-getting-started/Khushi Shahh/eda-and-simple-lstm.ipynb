{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing needed libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom wordcloud import STOPWORDS\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\nimport gc\nimport operator\nimport nltk\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.metrics import precision_score, recall_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.563999Z","iopub.execute_input":"2021-07-23T17:16:22.56443Z","iopub.status.idle":"2021-07-23T17:16:22.580266Z","shell.execute_reply.started":"2021-07-23T17:16:22.564392Z","shell.execute_reply":"2021-07-23T17:16:22.578725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"../input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.582318Z","iopub.execute_input":"2021-07-23T17:16:22.582787Z","iopub.status.idle":"2021-07-23T17:16:22.63718Z","shell.execute_reply.started":"2021-07-23T17:16:22.582741Z","shell.execute_reply":"2021-07-23T17:16:22.636174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.638953Z","iopub.execute_input":"2021-07-23T17:16:22.639264Z","iopub.status.idle":"2021-07-23T17:16:22.668602Z","shell.execute_reply.started":"2021-07-23T17:16:22.639235Z","shell.execute_reply":"2021-07-23T17:16:22.667604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.67009Z","iopub.execute_input":"2021-07-23T17:16:22.670597Z","iopub.status.idle":"2021-07-23T17:16:22.6834Z","shell.execute_reply.started":"2021-07-23T17:16:22.670524Z","shell.execute_reply":"2021-07-23T17:16:22.682067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.size","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.685019Z","iopub.execute_input":"2021-07-23T17:16:22.685334Z","iopub.status.idle":"2021-07-23T17:16:22.698199Z","shell.execute_reply.started":"2021-07-23T17:16:22.685307Z","shell.execute_reply":"2021-07-23T17:16:22.697048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.size","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.699702Z","iopub.execute_input":"2021-07-23T17:16:22.700054Z","iopub.status.idle":"2021-07-23T17:16:22.710546Z","shell.execute_reply.started":"2021-07-23T17:16:22.700023Z","shell.execute_reply":"2021-07-23T17:16:22.709395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"sns.countplot(train['target'])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.711887Z","iopub.execute_input":"2021-07-23T17:16:22.712195Z","iopub.status.idle":"2021-07-23T17:16:22.878378Z","shell.execute_reply.started":"2021-07-23T17:16:22.712165Z","shell.execute_reply":"2021-07-23T17:16:22.87708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## There are more tweets with target 0 (No disaster) than of Target 1( Disaster)","metadata":{}},{"cell_type":"code","source":"sns.barplot(train['keyword'].isnull().values)\nprint(\"The number of null values in keyword are\", train['keyword'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:22.882198Z","iopub.execute_input":"2021-07-23T17:16:22.882547Z","iopub.status.idle":"2021-07-23T17:16:23.109872Z","shell.execute_reply.started":"2021-07-23T17:16:22.882518Z","shell.execute_reply":"2021-07-23T17:16:23.108755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(train['location'].isnull().values)\nprint(\"The number of null values in location are\", train['location'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.112146Z","iopub.execute_input":"2021-07-23T17:16:23.112478Z","iopub.status.idle":"2021-07-23T17:16:23.353413Z","shell.execute_reply.started":"2021-07-23T17:16:23.112445Z","shell.execute_reply":"2021-07-23T17:16:23.352288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## So, around 8% of keyword values and 33% of Location values are null in train sample","metadata":{}},{"cell_type":"code","source":"sns.barplot(test['keyword'].isnull().values)\nprint(\"The number of null values in keyword are\", test['keyword'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.354904Z","iopub.execute_input":"2021-07-23T17:16:23.35525Z","iopub.status.idle":"2021-07-23T17:16:23.566517Z","shell.execute_reply.started":"2021-07-23T17:16:23.355203Z","shell.execute_reply":"2021-07-23T17:16:23.565108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(test['location'].isnull().values)\nprint(\"The number of null values in keyword are\", test['location'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.568342Z","iopub.execute_input":"2021-07-23T17:16:23.568807Z","iopub.status.idle":"2021-07-23T17:16:23.807213Z","shell.execute_reply.started":"2021-07-23T17:16:23.56877Z","shell.execute_reply":"2021-07-23T17:16:23.805682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## So, both training and test set have same ratio of missing values in keyword and location","metadata":{}},{"cell_type":"markdown","source":"## Filling the null values with \"Unknown\" for EDA purpose","metadata":{}},{"cell_type":"code","source":"for df in [train, test]:\n    for col in ['keyword', 'location']:\n        df[col] = df[col].fillna('Unknown')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.808676Z","iopub.execute_input":"2021-07-23T17:16:23.809152Z","iopub.status.idle":"2021-07-23T17:16:23.832869Z","shell.execute_reply.started":"2021-07-23T17:16:23.8091Z","shell.execute_reply":"2021-07-23T17:16:23.831474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['keyword'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.834971Z","iopub.execute_input":"2021-07-23T17:16:23.835452Z","iopub.status.idle":"2021-07-23T17:16:23.848533Z","shell.execute_reply.started":"2021-07-23T17:16:23.835406Z","shell.execute_reply":"2021-07-23T17:16:23.847417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top keywords that suggest a disaster tweet","metadata":{}},{"cell_type":"code","source":"ag = train.groupby('keyword').agg({'text':np.size, 'target':np.mean}).rename(columns={'text':'Count', 'target':'Disaster Probability'})\nag.sort_values('Disaster Probability', ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.849994Z","iopub.execute_input":"2021-07-23T17:16:23.850462Z","iopub.status.idle":"2021-07-23T17:16:23.886048Z","shell.execute_reply.started":"2021-07-23T17:16:23.850417Z","shell.execute_reply":"2021-07-23T17:16:23.884909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top keywords that suggest not being a disaster tweet","metadata":{}},{"cell_type":"code","source":"ag = train.groupby('keyword').agg({'text':np.size, 'target':np.mean}).rename(columns={'text':'Count', 'target':'Disaster Probability'})\nag.sort_values('Disaster Probability', ascending=True).head(20)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.889599Z","iopub.execute_input":"2021-07-23T17:16:23.889924Z","iopub.status.idle":"2021-07-23T17:16:23.918195Z","shell.execute_reply.started":"2021-07-23T17:16:23.889894Z","shell.execute_reply":"2021-07-23T17:16:23.917149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len1=train[train['target']==1]['text'].str.len()\nax1.hist(tweet_len1,color='pink')\nax1.set_title('disaster tweets')\ntweet_len2=train[train['target']==0]['text'].str.len()\nax2.hist(tweet_len2,color='blue')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Characters in tweets', size=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:23.919658Z","iopub.execute_input":"2021-07-23T17:16:23.920274Z","iopub.status.idle":"2021-07-23T17:16:24.258543Z","shell.execute_reply.started":"2021-07-23T17:16:23.920228Z","shell.execute_reply":"2021-07-23T17:16:24.25762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The character distribution is almost same for both","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nax1.hist(train['text'].apply(lambda x: len(str(x).split())), color='pink')\nax1.hist(test['text'].apply(lambda x: len(str(x).split())), color='green')\nax1.set_title('Word Count distribution in Training, Test Set')\nax2.hist(train['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS])), color='pink')\nax2.hist(test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS])),color='green')\nax2.set_title('Stop words distribution in Training, Test Set')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:16:24.261843Z","iopub.execute_input":"2021-07-23T17:16:24.262162Z","iopub.status.idle":"2021-07-23T17:16:24.789198Z","shell.execute_reply.started":"2021-07-23T17:16:24.262132Z","shell.execute_reply":"2021-07-23T17:16:24.788059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Emojis convey a lot, so we will replace them with words","metadata":{}},{"cell_type":"code","source":"!pip install emot","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:17:59.498892Z","iopub.execute_input":"2021-07-23T17:17:59.49928Z","iopub.status.idle":"2021-07-23T17:18:08.772255Z","shell.execute_reply.started":"2021-07-23T17:17:59.499245Z","shell.execute_reply":"2021-07-23T17:18:08.770999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n# Function for converting emojis into word\ndef convert_emojis(text):\n    for emot in UNICODE_EMO:\n        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n    return text\n\ntrain['text'] = train['text'].apply(lambda x: convert_emojis(x))\ntest['text'] = test['text'].apply(lambda x: convert_emojis(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:18:45.460738Z","iopub.execute_input":"2021-07-23T17:18:45.461151Z","iopub.status.idle":"2021-07-23T17:19:07.212416Z","shell.execute_reply.started":"2021-07-23T17:18:45.461115Z","shell.execute_reply":"2021-07-23T17:19:07.211665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## URL, Mention etc. play no significant rule in the sentiment of tweet, so we will remove them ","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n# load stop words\nstop_word = stopwords.words('english')\n\ndef clean(text):\n    #     remove urls\n    text = re.sub(r'http\\S+', \" \", text)\n    #     remove mentions\n    text = re.sub(r'@\\w+',' ',text)\n    #     remove hastags\n    text = re.sub(r'#\\w+', ' ', text)\n    #     remove digits\n    text = re.sub(r'\\d+', ' ', text)\n    #     remove html tags\n    text = re.sub('r<.*?>',' ', text) \n    #     remove stop words \n    text = text.split()\n    text = \" \".join([word for word in text if not word in stop_word])\n        \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:19:07.213838Z","iopub.execute_input":"2021-07-23T17:19:07.214349Z","iopub.status.idle":"2021-07-23T17:19:07.221701Z","shell.execute_reply.started":"2021-07-23T17:19:07.214316Z","shell.execute_reply":"2021-07-23T17:19:07.220865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['text'] = train['text'].apply(lambda x: clean(x))\ntest['text'] = test['text'].apply(lambda x: clean(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:19:07.223325Z","iopub.execute_input":"2021-07-23T17:19:07.223752Z","iopub.status.idle":"2021-07-23T17:19:07.707894Z","shell.execute_reply.started":"2021-07-23T17:19:07.223724Z","shell.execute_reply":"2021-07-23T17:19:07.707191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:19:07.709163Z","iopub.execute_input":"2021-07-23T17:19:07.709609Z","iopub.status.idle":"2021-07-23T17:19:07.721216Z","shell.execute_reply.started":"2021-07-23T17:19:07.709567Z","shell.execute_reply":"2021-07-23T17:19:07.720584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Word Embedding using Glove","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\ndef create_corpus(train):\n    corpus=[]\n    for tweet in tqdm(train['text']):\n        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n        corpus.append(words)\n    return corpus\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:19:07.722235Z","iopub.execute_input":"2021-07-23T17:19:07.722694Z","iopub.status.idle":"2021-07-23T17:19:07.73426Z","shell.execute_reply.started":"2021-07-23T17:19:07.722664Z","shell.execute_reply":"2021-07-23T17:19:07.733475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus=create_corpus(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:19:07.735291Z","iopub.execute_input":"2021-07-23T17:19:07.735704Z","iopub.status.idle":"2021-07-23T17:19:09.61453Z","shell.execute_reply.started":"2021-07-23T17:19:07.735676Z","shell.execute_reply":"2021-07-23T17:19:09.613325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dict={}\nwith open('../input/glove6b/glove.6B.100d.txt','r', encoding='utf8') as f:\n    for line in f:\n        values=line.split()\n        word=values[0]\n        vectors=np.asarray(values[1:],'float32')\n        embedding_dict[word]=vectors\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:20.699868Z","iopub.execute_input":"2021-07-23T17:20:20.700218Z","iopub.status.idle":"2021-07-23T17:20:39.849139Z","shell.execute_reply.started":"2021-07-23T17:20:20.70019Z","shell.execute_reply":"2021-07-23T17:20:39.848042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN=50\ntokenizer_obj=Tokenizer()\ntokenizer_obj.fit_on_texts(corpus)\nsequences=tokenizer_obj.texts_to_sequences(corpus)\n\ntweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.093691Z","iopub.execute_input":"2021-07-23T17:20:49.094085Z","iopub.status.idle":"2021-07-23T17:20:49.282333Z","shell.execute_reply.started":"2021-07-23T17:20:49.094047Z","shell.execute_reply":"2021-07-23T17:20:49.281629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_index=tokenizer_obj.word_index\nprint('Number of unique words:',len(word_index))","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.283478Z","iopub.execute_input":"2021-07-23T17:20:49.283928Z","iopub.status.idle":"2021-07-23T17:20:49.289139Z","shell.execute_reply.started":"2021-07-23T17:20:49.283899Z","shell.execute_reply":"2021-07-23T17:20:49.288116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_words=len(word_index)+1\nembedding_matrix=np.zeros((num_words,100))\n\nfor word,i in tqdm(word_index.items()):\n    if i > num_words:\n        continue\n    \n    emb_vec=embedding_dict.get(word)\n    if emb_vec is not None:\n        embedding_matrix[i]=emb_vec","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.292651Z","iopub.execute_input":"2021-07-23T17:20:49.293164Z","iopub.status.idle":"2021-07-23T17:20:49.356609Z","shell.execute_reply.started":"2021-07-23T17:20:49.293117Z","shell.execute_reply":"2021-07-23T17:20:49.355625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic LSTM model","metadata":{}},{"cell_type":"code","source":"model=Sequential()\n\nembedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix),\n                   input_length=MAX_LEN,trainable=False)\n\nmodel.add(embedding)\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\noptimzer=Adam(learning_rate=1e-5)\n\nmodel.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.358313Z","iopub.execute_input":"2021-07-23T17:20:49.358657Z","iopub.status.idle":"2021-07-23T17:20:49.675331Z","shell.execute_reply.started":"2021-07-23T17:20:49.358624Z","shell.execute_reply":"2021-07-23T17:20:49.67412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.676935Z","iopub.execute_input":"2021-07-23T17:20:49.677229Z","iopub.status.idle":"2021-07-23T17:20:49.687738Z","shell.execute_reply.started":"2021-07-23T17:20:49.677201Z","shell.execute_reply":"2021-07-23T17:20:49.686311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train1=tweet_pad[:train.shape[0]]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.689247Z","iopub.execute_input":"2021-07-23T17:20:49.689615Z","iopub.status.idle":"2021-07-23T17:20:49.694245Z","shell.execute_reply.started":"2021-07-23T17:20:49.689568Z","shell.execute_reply":"2021-07-23T17:20:49.693426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(train1,train['target'].values,test_size=0.2)\nprint('Shape of train',X_train.shape)\nprint(\"Shape of Validation \",X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.695608Z","iopub.execute_input":"2021-07-23T17:20:49.695943Z","iopub.status.idle":"2021-07-23T17:20:49.713649Z","shell.execute_reply.started":"2021-07-23T17:20:49.69591Z","shell.execute_reply":"2021-07-23T17:20:49.712234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(X_train,y_train,batch_size=4,epochs=15,validation_data=(X_test,y_test),verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T17:20:49.717391Z","iopub.execute_input":"2021-07-23T17:20:49.717825Z","iopub.status.idle":"2021-07-23T17:42:21.662216Z","shell.execute_reply.started":"2021-07-23T17:20:49.717792Z","shell.execute_reply":"2021-07-23T17:42:21.66088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## If you want to score even more, change all the tweets that has keywords wreckage, debris, derailment to 1 as we saw above in EDA that they have almost 100% chance of being disaster tweet. Similarly, check for Non Disaster tweets","metadata":{}},{"cell_type":"markdown","source":"## Upvote if you found it helpful!","metadata":{}}]}