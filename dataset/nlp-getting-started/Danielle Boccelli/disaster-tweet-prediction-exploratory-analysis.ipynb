{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import packages\nimport re\nimport spacy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib.pyplot import figure\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom wordcloud import WordCloud\n\n# Custom settings\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\ncat_cols = [\"#4f8c9d\", \"#94da40\", \"#7212ff\", \"#31d0a5\", \"#333a9e\", \"#b8b2f0\", \"#1c4c5e\", \"#8bd0eb\", \"#760796\", \"#39970e\"]\nsns.palplot(sns.color_palette(cat_cols))\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nsns.set_palette(cat_cols)\nsns.set_context(\"talk\", font_scale=.9)\n\n# Load data\nnlp = spacy.load('en')\ntrain = pd.read_csv('../input/nlp-getting-started/train.csv', index_col = 0)\ntest = pd.read_csv('../input/nlp-getting-started/test.csv', index_col = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.isnull().sum().sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are ' + str(len(train.keyword.unique())) + ' unique keywords.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the top 40 keywords for taget = 1\nfigure(figsize=(16, 16))\n\nplt.subplot(1, 2, 1)\nplt1 = sns.countplot(y=\"keyword\", \n                     data=train,\n                     hue=train.target,\n                     order=train[train.target==1].keyword\n                     .value_counts()\n                     .iloc[:40].index)\nplt1.set_ylabel('')\nplt1.set_title('Top Keywords for Target = 1')\n\n#Show the top 40 keywords for taget = 0\nplt.subplot(1, 2, 2)\nplt2 = sns.countplot(y=\"keyword\", \n                     data=train,\n                     hue=train.target,\n                     order=train[train.target==0]\n                     .keyword.value_counts()\n                     .iloc[:40].index)\nplt2.set_ylabel('')\nplt2.set_title('Top Keywords for Target = 0')\n\nplt.tight_layout(pad=3.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Location\n\nMost tweets in the training data do not have a location. Of the ones that do, location does not appear to be a good predictor of the target variable. Moreover, while location might be useful during training (if a disaster occurred in a particular location), it is probably not generalizable and therefore should not be considered in a model."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are ' + str(len(train.location.unique())) + ' unique locations.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the top 10 locations for taget = 1\nfigure(figsize=(16, 6))\n\nplt.subplot(1, 2, 1)\nplt1 = sns.countplot(y=\"location\", \n                     data=train,\n                     hue=train.target,\n                     order=train[train.target==1].location\n                     .value_counts()\n                     .iloc[:10].index)\nplt1.set_ylabel('')\nplt1.set_title('Top Locations for Target = 1')\nplt1.legend(loc='lower right')\n\n#Show the top 10 locations for taget = 0\nplt.subplot(1, 2, 2)\nplt2 = sns.countplot(y=\"location\", \n                     data=train,\n                     hue=train.target,\n                     order=train[train.target==0].location\n                     .value_counts()\n                     .iloc[:10].index)\nplt2.set_ylabel('')\nplt2.set_title('Top Locations for Target = 0')\nplt2.legend(loc='lower right')\n\nplt.tight_layout(pad=3.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(figsize=(8, 6))\ntrain[\"loc_bool\"] = [\"No Location\" if pd.isnull(x) else \"Location\" for x in train[\"location\"]]\n\nplt1 = sns.countplot(x=\"loc_bool\", \n                     data=train,\n                     hue=train.target)\nplt1.set_ylabel('')\nplt1.set_xlabel('')\nplt1.set_title('');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tweets "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('These are examples of disaster tweets: \\n')\nprint(train[train.target==1]['text'][1:20])\n\nprint('\\n')\n\nprint('These are examples of non-disaster tweets: \\n')\nprint(train[train.target==0]['text'][1:20])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## URL\n\nIt appears as if tweets with URLs are slightly more likely to be disaster-related tweets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add boolean variable for URL\ntrain[\"URL\"] = train.text.str.match(r'[a-z]*[:.]+\\S+', '')\n\n# Remove URLs from tweets\ntrain.text = [re.sub(r'[a-z]*[:.]+\\S+', '', x) for x in train.text]\ntrain.text = [re.sub(r'\\&amp', '', x) for x in train.text]\n\n# Create bar chart\nfigure(figsize=(8, 6))\n\ndf_p1 = train[[\"target\", \"URL\"]].groupby([\"target\"]).mean().reset_index()\nplt1 = sns.barplot(x=\"target\", y=\"URL\", data=df_p1)\n\nvals = plt1.get_yticks()\nplt1.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\nplt1.set_ylabel('')\nplt1.set_xlabel('')\nplt1.set_title('Percent of Tweets with URLs');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ALL CAPS"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"CAPS\"] = [True if x == x.lower() else False for x in train.text]\n\nfigure(figsize=(8, 6))\n\ndf_p1 = train[[\"target\", \"CAPS\"]].groupby([\"target\"]).mean().reset_index()\n\nplt1 = sns.barplot(x=\"target\",\n                   y=\"CAPS\",\n                   data=df_p1)\n\n\nvals = plt1.get_yticks()\nplt1.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\nplt1.set_ylabel('')\nplt1.set_xlabel('')\nplt1.set_title('Percent of Capitalized Tweets');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Exclaim\"] = [True if '!' in x else False for x in train.text]\n\nfigure(figsize=(8, 6))\n\ndf_p1 = train[[\"target\", \"Exclaim\"]].groupby([\"target\"]).mean().reset_index()\n\nplt1 = sns.barplot(x=\"target\",\n                   y=\"Exclaim\",\n                   data=df_p1)\n\n\nvals = plt1.get_yticks()\nplt1.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\nplt1.set_ylabel('')\nplt1.set_xlabel('')\nplt1.set_title('Percent of Exclamations');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting up corpora for explorary analysis of text\ntext_TRUE = nlp(train[train['target']==1]['text'].str.cat(sep=' '))\ntext_FALSE = nlp(train[train['target']==0]['text'].str.cat(sep=' '))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove stop words, punctuation, and spaces\nall_TRUE = [token.text.lower() for token in text_TRUE\n            if token.is_stop != True \n            and token.is_punct != True \n            and token.text != ' ' \n            and token.text != '  '\n            and token.text != '\\n' \n            and token.text != '\\n\\n']\n\nall_FALSE = [token.text.lower() for token in text_FALSE \n             if token.is_stop != True \n             and token.is_punct != True \n             and token.text != ' ' \n             and token.text != '  '\n             and token.text != '\\n'\n             and token.text != '\\n\\n']\n\n# Create subsets that include only nouns or only verbs\nnouns_TRUE = [token.text.lower() for token in text_TRUE if token.pos_ == \"NOUN\"]\nnouns_FALSE = [token.text.lower() for token in text_FALSE if token.pos_ == \"NOUN\"]\n\nverbs_TRUE = [token.text.lower() for token in text_TRUE if token.pos_ == \"VERB\"]\nverbs_FALSE = [token.text.lower() for token in text_FALSE if token.pos_ == \"VERB\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the most common words, nouns, and verbs\ncommon_all_TRUE = pd.DataFrame(Counter(all_TRUE).most_common(20), columns = [\"Word\", \"Frequency\"])\ncommon_all_FALSE = pd.DataFrame(Counter(all_FALSE).most_common(20), columns = [\"Word\", \"Frequency\"])\ncommon_nouns_TRUE = pd.DataFrame(Counter(nouns_TRUE).most_common(20), columns = [\"Word\", \"Frequency\"])\ncommon_nouns_FALSE = pd.DataFrame(Counter(nouns_FALSE).most_common(20), columns = [\"Word\", \"Frequency\"])\ncommon_verbs_TRUE = pd.DataFrame(Counter(verbs_TRUE).most_common(20), columns = [\"Word\", \"Frequency\"])\ncommon_verbs_FALSE = pd.DataFrame(Counter(verbs_FALSE).most_common(20), columns = [\"Word\", \"Frequency\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(figsize=(16, 6))\n\nplt.subplot(1, 2, 1)\np1=sns.barplot(x=common_all_TRUE.Frequency, y=common_all_TRUE.Word);\n\nplt.subplot(1, 2, 2)\np2=sns.barplot(x=common_all_FALSE.Frequency, y=common_all_FALSE.Word);\n\np1.set_title('Target = 1');\np2.set_title('Target = 0');\np2.set_ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(figsize=(16, 6))\n\nplt.subplot(1, 2, 1)\np1=sns.barplot(x=common_nouns_TRUE.Frequency, y=common_nouns_TRUE.Word);\n\nplt.subplot(1, 2, 2)\np2=sns.barplot(x=common_nouns_FALSE.Frequency, y=common_nouns_FALSE.Word);\n\np1.set_title('Target = 1');\np2.set_title('Target = 0');\np2.set_ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(figsize=(16, 6))\n\nplt.subplot(1, 2, 1)\np1=sns.barplot(x=common_verbs_TRUE.Frequency, y=common_verbs_TRUE.Word);\n\nplt.subplot(1, 2, 2)\np2=sns.barplot(x=common_verbs_FALSE.Frequency, y=common_verbs_FALSE.Word);\n\np1.set_title('Target = 1');\np2.set_title('Target = 0');\np2.set_ylabel('');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}