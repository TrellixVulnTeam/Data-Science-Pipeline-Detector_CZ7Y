{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Disaster Tweets Classification: TF-IDF","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n- [1. Overview](#1.)\n- [2. Import Packages and Datasets](#2.)\n- [3. Data Wrangling](#3.)\n- [4. Exploratory Data Analysis & Data Preprocessing](#4.)\n- [5. Model Development](#5.)\n- [6. Submission](#6.)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1.\"></a>\n## 1. Overview\nIn this notebook I will build a Disaster Tweets Classification Model using TF-IDF vectorization in Keras.","metadata":{"execution":{"iopub.status.busy":"2021-07-30T17:25:03.395939Z","iopub.execute_input":"2021-07-30T17:25:03.396519Z","iopub.status.idle":"2021-07-30T17:25:03.400557Z","shell.execute_reply.started":"2021-07-30T17:25:03.396471Z","shell.execute_reply":"2021-07-30T17:25:03.39968Z"}}},{"cell_type":"markdown","source":"<a id=\"2.\"></a>\n## 2. Import Packages and Datasets ","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow==2.7.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:15.893834Z","iopub.execute_input":"2021-11-14T19:46:15.894467Z","iopub.status.idle":"2021-11-14T19:46:19.007446Z","shell.execute_reply.started":"2021-11-14T19:46:15.894376Z","shell.execute_reply":"2021-11-14T19:46:19.006435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:22.846885Z","iopub.execute_input":"2021-11-14T19:46:22.847284Z","iopub.status.idle":"2021-11-14T19:46:22.888834Z","shell.execute_reply.started":"2021-11-14T19:46:22.847247Z","shell.execute_reply":"2021-11-14T19:46:22.887959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:25.536762Z","iopub.execute_input":"2021-11-14T19:46:25.537144Z","iopub.status.idle":"2021-11-14T19:46:25.543968Z","shell.execute_reply.started":"2021-11-14T19:46:25.537108Z","shell.execute_reply":"2021-11-14T19:46:25.542866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:27.373444Z","iopub.execute_input":"2021-11-14T19:46:27.373792Z","iopub.status.idle":"2021-11-14T19:46:27.398554Z","shell.execute_reply.started":"2021-11-14T19:46:27.373757Z","shell.execute_reply":"2021-11-14T19:46:27.397609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.location.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:29.240466Z","iopub.execute_input":"2021-11-14T19:46:29.240805Z","iopub.status.idle":"2021-11-14T19:46:29.254386Z","shell.execute_reply.started":"2021-11-14T19:46:29.24077Z","shell.execute_reply":"2021-11-14T19:46:29.253465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3.\"></a>\n## 3. Data Wrangling\nLet's see null values for each column.","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:31.355635Z","iopub.execute_input":"2021-11-14T19:46:31.355977Z","iopub.status.idle":"2021-11-14T19:46:31.367376Z","shell.execute_reply.started":"2021-11-14T19:46:31.355944Z","shell.execute_reply":"2021-11-14T19:46:31.366094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:33.422073Z","iopub.execute_input":"2021-11-14T19:46:33.422723Z","iopub.status.idle":"2021-11-14T19:46:33.452069Z","shell.execute_reply.started":"2021-11-14T19:46:33.422672Z","shell.execute_reply":"2021-11-14T19:46:33.451099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"keyword\"].replace(np.NAN, \"\", inplace=True)\ntrain[\"location\"].replace(np.NAN, \"\", inplace=True)\ntest[\"keyword\"].replace(np.NAN, \"\", inplace=True)\ntest[\"location\"].replace(np.NAN, \"\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:35.451563Z","iopub.execute_input":"2021-11-14T19:46:35.45191Z","iopub.status.idle":"2021-11-14T19:46:35.464827Z","shell.execute_reply.started":"2021-11-14T19:46:35.451875Z","shell.execute_reply":"2021-11-14T19:46:35.463929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:37.75712Z","iopub.execute_input":"2021-11-14T19:46:37.757471Z","iopub.status.idle":"2021-11-14T19:46:37.767407Z","shell.execute_reply.started":"2021-11-14T19:46:37.757439Z","shell.execute_reply":"2021-11-14T19:46:37.766434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:39.437836Z","iopub.execute_input":"2021-11-14T19:46:39.43821Z","iopub.status.idle":"2021-11-14T19:46:39.447972Z","shell.execute_reply.started":"2021-11-14T19:46:39.438173Z","shell.execute_reply":"2021-11-14T19:46:39.446872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test[\"keyword\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:41.683315Z","iopub.execute_input":"2021-11-14T19:46:41.683661Z","iopub.status.idle":"2021-11-14T19:46:41.689628Z","shell.execute_reply.started":"2021-11-14T19:46:41.683629Z","shell.execute_reply":"2021-11-14T19:46:41.688598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4.\"></a>\n## 4. Exploratory Data Analysis & Data Preprocessing\n- Tokenize Texts\n- Show Staticstic info of texts","metadata":{"execution":{"iopub.status.busy":"2021-07-30T17:38:49.025447Z","iopub.execute_input":"2021-07-30T17:38:49.027434Z","iopub.status.idle":"2021-07-30T17:38:49.031233Z","shell.execute_reply.started":"2021-07-30T17:38:49.027392Z","shell.execute_reply":"2021-07-30T17:38:49.029903Z"}}},{"cell_type":"code","source":"contents = []\nfor data in [train, test]:\n    for i in range(data.shape[0]):\n        item = data.iloc[i]\n        sentence = item[\"keyword\"] + \" \" + item[\"text\"] + \" \" + item[\"location\"]\n        contents.append(sentence.lower())","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:46:43.437525Z","iopub.execute_input":"2021-11-14T19:46:43.437857Z","iopub.status.idle":"2021-11-14T19:46:45.091778Z","shell.execute_reply.started":"2021-11-14T19:46:43.437824Z","shell.execute_reply":"2021-11-14T19:46:45.090912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_contents = contents[:len(train)]\ntest_contents = contents[len(train):]","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:52:05.011185Z","iopub.execute_input":"2021-11-14T19:52:05.011552Z","iopub.status.idle":"2021-11-14T19:52:05.019057Z","shell.execute_reply.started":"2021-11-14T19:52:05.011518Z","shell.execute_reply":"2021-11-14T19:52:05.018101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"X\"] = train_contents\ntest[\"X\"] = test_contents","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:53:42.911144Z","iopub.execute_input":"2021-11-14T19:53:42.911527Z","iopub.status.idle":"2021-11-14T19:53:42.92093Z","shell.execute_reply.started":"2021-11-14T19:53:42.911488Z","shell.execute_reply":"2021-11-14T19:53:42.919909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TF-IDF Vectorization","metadata":{"execution":{"iopub.status.busy":"2021-07-30T18:56:39.165984Z","iopub.execute_input":"2021-07-30T18:56:39.166349Z","iopub.status.idle":"2021-07-30T18:56:39.170003Z","shell.execute_reply.started":"2021-07-30T18:56:39.166319Z","shell.execute_reply":"2021-07-30T18:56:39.169074Z"}}},{"cell_type":"code","source":"vocab_size = 10000\ntext_vectorizer = layers.TextVectorization(max_tokens=vocab_size, output_mode=\"tf-idf\", ngrams=2)\n# Index the bigrams and learn the TF-IDF weights via `adapt()`\n\nwith tf.device(\"CPU\"):\n    # A bug that prevents this from running on GPU for now.\n    text_vectorizer.adapt(contents)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:52:57.053152Z","iopub.execute_input":"2021-11-14T19:52:57.053485Z","iopub.status.idle":"2021-11-14T19:52:58.544313Z","shell.execute_reply.started":"2021-11-14T19:52:57.053453Z","shell.execute_reply":"2021-11-14T19:52:58.541029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5.\"></a>\n## Model Development","metadata":{}},{"cell_type":"markdown","source":"### BinaryCrossEntropy with weights \nUse this version of BinaryCrossEntropy to solve class imbalance problem.","metadata":{}},{"cell_type":"code","source":"class BinaryCrossEntropy(tf.keras.losses.Loss):\n\n    def __init__(self, postive_rate = 0.5):\n        super().__init__()\n        self.negative_weights = postive_rate\n        self.positive_weights = 1 - postive_rate\n        \n    def call(self, y_true, y_pred):\n        print(y_true, y_pred)\n        y_true = tf.cast(y_true, y_pred.dtype)\n        pos = self.positive_weights * y_true * tf.math.log(y_pred + tf.keras.backend.epsilon())\n        neg = self.negative_weights * (1.0 - y_true) * tf.math.log(1.0 - y_pred + tf.keras.backend.epsilon())\n        return -(pos + neg)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:55:15.189373Z","iopub.execute_input":"2021-11-14T19:55:15.189721Z","iopub.status.idle":"2021-11-14T19:55:15.196499Z","shell.execute_reply.started":"2021-11-14T19:55:15.189687Z","shell.execute_reply":"2021-11-14T19:55:15.195286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text Classification Model","metadata":{}},{"cell_type":"code","source":"def get_model():\n    inputs = layers.Input(shape=(None, ), dtype=\"string\")\n    x = text_vectorizer(inputs)\n    x = layers.Dense(32, activation=\"relu\")(x)\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n    return keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:55:20.298189Z","iopub.execute_input":"2021-11-14T19:55:20.298543Z","iopub.status.idle":"2021-11-14T19:55:20.304251Z","shell.execute_reply.started":"2021-11-14T19:55:20.29851Z","shell.execute_reply":"2021-11-14T19:55:20.303209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:53:05.741794Z","iopub.execute_input":"2021-11-14T19:53:05.742175Z","iopub.status.idle":"2021-11-14T19:53:05.91387Z","shell.execute_reply.started":"2021-11-14T19:53:05.742141Z","shell.execute_reply":"2021-11-14T19:53:05.912918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = 1\nmodels = []\ntf.keras.backend.clear_session()\nfor train_indices, val_indices in StratifiedKFold(5, shuffle=True, random_state=42).split(train, train[\"target\"]):\n    print(\"Fold %d\" %(index))\n    train_features, train_targets = train.iloc[train_indices][\"X\"], train.iloc[train_indices][\"target\"]\n    validation_features, validation_targets = train.iloc[val_indices][\"X\"], train.iloc[val_indices][\"target\"]\n    model_checkpoint_path = \"model%d.tf\"%(index)\n    model = get_model()\n    loss = BinaryCrossEntropy(train_targets.mean())\n    adam = tf.keras.optimizers.Adam(3e-4)\n    model.compile(loss=loss, optimizer=adam, metrics=[\"accuracy\"])\n    early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n    recuce_Lr = tf.keras.callbacks.ReduceLROnPlateau(patience=2)\n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_checkpoint_path, monitor=\"val_accuracy\", save_best_only=True, save_weights_only=True)\n    history = model.fit(train_features, train_targets, validation_data=(validation_features, validation_targets), epochs=100, callbacks=[early_stop, model_checkpoint])\n    pd.DataFrame(history.history).plot(kind=\"line\")\n    plt.title(\"Performance of Fold %d\"%(index))\n    plt.show()\n    model.load_weights(model_checkpoint_path)\n    y_val_pred = np.array(model.predict(validation_features) > 0.5, dtype=\"int\").reshape(-1)\n    cm = confusion_matrix(validation_targets, y_val_pred)\n    sns.heatmap(cm, annot=True)\n    plt.show()\n    print(\"Classification Report: \\n\")\n    print(classification_report(validation_targets, y_val_pred))\n    acc_score = accuracy_score(validation_targets, y_val_pred)\n    print(\"Accuracy Score: %.2f\"%(acc_score))\n    models.append(model)\n    index += 1","metadata":{"execution":{"iopub.status.busy":"2021-11-14T19:58:08.688464Z","iopub.execute_input":"2021-11-14T19:58:08.688816Z","iopub.status.idle":"2021-11-14T19:59:38.848935Z","shell.execute_reply.started":"2021-11-14T19:58:08.688782Z","shell.execute_reply":"2021-11-14T19:59:38.847904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6.\"></a>\n## 6. Submission","metadata":{}},{"cell_type":"code","source":"y_test = np.mean([model.predict(test[\"X\"]).reshape(-1) for model in models], axis=0)\ny_test = np.array(y_test > 0.5, dtype=int)\nsubmission = pd.DataFrame({\"id\": test[\"id\"], \"target\": y_test})\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T20:00:00.003497Z","iopub.execute_input":"2021-11-14T20:00:00.003832Z","iopub.status.idle":"2021-11-14T20:00:01.504709Z","shell.execute_reply.started":"2021-11-14T20:00:00.003793Z","shell.execute_reply":"2021-11-14T20:00:01.50385Z"},"trusted":true},"execution_count":null,"outputs":[]}]}