{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"In this notebook I will explore the Disaster Tweets competition dataset and use [scikit-learn's](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) `CountVectorizer` to convert a collection of text - tweets - to a matrix of token counts.\n\nSubmissions are evaluated using [F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) between the predicted and expected answers.\n\nF1 is calculated as follows:\n$$\\text{F1}=2 * \\frac{precision * recall}{precision + recall}$$\n\nwhere:\n$$\\text{precision}=\\frac{TP}{TP + FP}$$\n\n$$\\text{recall}=\\frac{TP}{TP + FN}$$\n\nand:\n- True Positive [TP] = prediction is 1, and the ground truth is also 1\n- False Positive [FP] = prediction is 1, and the ground truth is 0\n- False Negative [FN] = prediction is 0, and the ground truth is 1","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import linear_model, model_selection\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-03T05:09:06.807434Z","iopub.execute_input":"2022-03-03T05:09:06.807764Z","iopub.status.idle":"2022-03-03T05:09:08.694695Z","shell.execute_reply.started":"2022-03-03T05:09:06.807684Z","shell.execute_reply":"2022-03-03T05:09:08.693569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/nlp-getting-started/train.csv')\ndf_train.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:08.696909Z","iopub.execute_input":"2022-03-03T05:09:08.697161Z","iopub.status.idle":"2022-03-03T05:09:08.766817Z","shell.execute_reply.started":"2022-03-03T05:09:08.69713Z","shell.execute_reply":"2022-03-03T05:09:08.766122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Class distribution","metadata":{}},{"cell_type":"code","source":"sns.countplot(df_train['target'])\ndf_train['target'].value_counts() / len(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:08.767725Z","iopub.execute_input":"2022-03-03T05:09:08.768255Z","iopub.status.idle":"2022-03-03T05:09:08.978414Z","shell.execute_reply.started":"2022-03-03T05:09:08.768194Z","shell.execute_reply":"2022-03-03T05:09:08.97747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"43% of tweets are about disasters, the other 57% of tweets are not.","metadata":{}},{"cell_type":"markdown","source":"There are several ways to extract numerical data from the 'text' field. These include:\n- length of the tweet\n- the number of words and [stop words](https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words)\n- [polarity and subjectivity](https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis)\n\nand a lot more, but I will get started with just these for now.","metadata":{}},{"cell_type":"code","source":"tweets = []\nfor tweet in df_train['text']:\n    tweets += [tweet]\n\nnum_words = []\nnum_stop_words = []\npolarity = []\nsubjectivity = []\n\nfor tweet in tweets:\n    num_words += [len(tweet.split())]\n    num_stop_words += [len([stopword for stopword in tweet.lower().split() if stopword in STOPWORDS])]\n    tweet_blob = TextBlob(tweet)\n    polarity += [tweet_blob.sentiment.polarity]\n    subjectivity += [tweet_blob.sentiment.subjectivity]\n\ndf_train['length'] = df_train['text'].str.len()\ndf_train['num_words'] = num_words\ndf_train['num_stop_words'] = num_stop_words\ndf_train['polarity'] = polarity\ndf_train['subjectivity'] = subjectivity","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:08.979468Z","iopub.execute_input":"2022-03-03T05:09:08.979847Z","iopub.status.idle":"2022-03-03T05:09:11.255805Z","shell.execute_reply.started":"2022-03-03T05:09:08.979815Z","shell.execute_reply":"2022-03-03T05:09:11.254992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.groupby('target')['length', 'num_words', 'num_stop_words', 'polarity', 'subjectivity'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:11.257884Z","iopub.execute_input":"2022-03-03T05:09:11.258163Z","iopub.status.idle":"2022-03-03T05:09:11.280041Z","shell.execute_reply.started":"2022-03-03T05:09:11.258132Z","shell.execute_reply":"2022-03-03T05:09:11.279251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On average, disaster tweets are longer and contain fewer stop words. The differences in polarity and subjectivity are less pronounced but our model may make use of them.\n\nIf we create a list of words, we can create a word cloud with the most frequently used words. Let's do that to see if anything stands out.","metadata":{}},{"cell_type":"code","source":"regular_tweets = df_train[df_train['target'] == 0]['text'].to_list()\ndisaster_tweets = df_train[df_train['target'] == 1]['text'].to_list()\n\njoined_regular_tweets = ' '.join(regular_tweets)\njoined_disaster_tweets = ' '.join(disaster_tweets)\n\nregular_cloud = WordCloud().generate(joined_regular_tweets)\ndisaster_cloud = WordCloud().generate(joined_disaster_tweets)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:11.281299Z","iopub.execute_input":"2022-03-03T05:09:11.28154Z","iopub.status.idle":"2022-03-03T05:09:12.629661Z","shell.execute_reply.started":"2022-03-03T05:09:11.281511Z","shell.execute_reply":"2022-03-03T05:09:12.628844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 12))\n\nfig.add_subplot(221)\nplt.title('Regular tweets')\nplt.imshow(regular_cloud)\n\nfig.add_subplot(222)\nplt.title('Disaster tweets')\nplt.imshow(disaster_cloud)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:12.630787Z","iopub.execute_input":"2022-03-03T05:09:12.631001Z","iopub.status.idle":"2022-03-03T05:09:13.346869Z","shell.execute_reply.started":"2022-03-03T05:09:12.630975Z","shell.execute_reply":"2022-03-03T05:09:13.345952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A lot of text cleaning will be needed.","metadata":{}},{"cell_type":"markdown","source":"### Work in progress","metadata":{}},{"cell_type":"code","source":"vect = CountVectorizer(max_features=100, ngram_range=(1, 3))\nvect.fit(tweets)\n\nbow = vect.transform(tweets)\n\nX = pd.DataFrame(bow.toarray(), columns=vect.get_feature_names())\nprint(X.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:13.348116Z","iopub.execute_input":"2022-03-03T05:09:13.348419Z","iopub.status.idle":"2022-03-03T05:09:14.748362Z","shell.execute_reply.started":"2022-03-03T05:09:13.348376Z","shell.execute_reply":"2022-03-03T05:09:14.747329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors = vect.fit_transform(df_train['text'])\n\nclf = linear_model.RidgeClassifier()\n\nscores = model_selection.cross_val_score(clf, train_vectors, df_train['target'], cv=5, scoring='f1')\nscores","metadata":{"execution":{"iopub.status.busy":"2022-03-03T05:09:35.200775Z","iopub.execute_input":"2022-03-03T05:09:35.201046Z","iopub.status.idle":"2022-03-03T05:09:36.359408Z","shell.execute_reply.started":"2022-03-03T05:09:35.201017Z","shell.execute_reply":"2022-03-03T05:09:36.358542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}