{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Predict which Tweets are about real disasters**\n"},{"metadata":{},"cell_type":"markdown","source":"# Installing Required Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ktrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install contractions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Importing Required Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys  \nimport re\nimport string\nimport contractions\nfrom sklearn.model_selection import train_test_split\nimport ktrain\nimport tensorflow as tf\nfrom ktrain import text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ndf_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(df_train.keyword.isna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(df_train.location.isna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Droping keyword and location columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(columns=['keyword', 'location' ,'id'], inplace=True)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Initial Text Pre-Processing**\n**We'll remove hashtags(#example), @username and links(starting with http:// or https://) only. As we are going to use BERT, we are not removing emoticons as it will help BERT in prediction. We will again do text pre-processing later using BERT.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_process(tweet):\n    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())  # remove #tags and @usernames\n    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) # remove urls\n    return(tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_process1(tweet):\n    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) # remove urls\n    return(tweet)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling constractions**:  Below funnction will replace constactions (e.g. wouldn't to would not)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fn_contractions(tweet):\n    expanded_words = []\n    for word in tweet.split():\n        expanded_words.append(contractions.fix(word))\n    return(' '.join(expanded_words))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['text'] = df_train['text'].apply(lambda x:pre_process(x))\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['text'] = df_train['text'].apply(lambda x:fn_contractions(x))\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val['text'] = df_val['text'].apply(lambda x:pre_process(x))\ndf_val['text'] = df_val['text'].apply(lambda x:fn_contractions(x))\ndf_val","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spliting Data for Test and Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(df_train, test_size=0.2)\nX_train = train.text.tolist()\nX_test = test.text.tolist()\ny_train = train.target.tolist()\ny_test = test.target.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_train),len(X_test),len(y_train),len(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model building using BERT"},{"metadata":{},"cell_type":"markdown","source":"We are using bert-base-uncased model. You can choose any other model. I am selecting maxlen of tokenization as 512 (it's max for BERT)."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_arch ='bert-base-uncased'\nfactors = [0,1] # We have two factors to predict.\nMAXLEN = 512\ntrans = text.Transformer(model_arch, maxlen=MAXLEN, class_names= factors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = trans.preprocess_train(X_train,y_train)\ntest_data = trans.preprocess_test(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = trans.get_classifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner = ktrain.get_learner(model, train_data=train_data, val_data=test_data, batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learner.lr_find(show_plot=True, max_epochs=10) #finding optimal learning rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.fit_onecycle(3e-5, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.validate(val_data=test_data, class_names=factors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor = ktrain.get_predictor(learner.model, preproc=trans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val['target'] = predictor.predict(df_val.text.tolist())\ndf_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val.to_csv('/kaggle/working/test_result_final.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission = df_val[['id','target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv('/kaggle/working/submission5.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}