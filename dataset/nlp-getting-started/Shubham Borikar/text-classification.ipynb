{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport string\nimport seaborn as sns\nimport spacy\n\nnlp = spacy.load('en')\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading data\ntweets_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying top 5 rows of the data\ntweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'We have {tweets_df.shape[0]} rows of data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'We have {tweets_df.keyword.nunique()} unique values in keyword and {tweets_df.location.nunique()} unique values in location.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'There are {tweets_df.target.value_counts()[0]} tweets that are not disaster and {tweets_df.target.value_counts()[1]} tweets that are real disaster')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pie chart showing distribution of tweets (disaster and no disaster)\ntarget = ['Disaster', 'No Disater']\ncolors = ['r', 'g']\nplt.pie(tweets_df.target.value_counts(), labels=target, colors=colors, startangle=90, autopct='%.1f%%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = tweets_df.text.str.len()\nlens.mean(), lens.std(), lens.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens.hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ntweets_df['text'] = tweets_df['text'].apply(remove_URL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ntweets_df['text'] = tweets_df['text'].apply(remove_html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ntweets_df['text'] = tweets_df['text'].apply(remove_emoji)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['text'] = tweets_df['text'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stop_words_and_punct(text):\n    doc = nlp(text)\n    return ' '.join([str(token) for token in doc if not token.is_stop and not token.is_punct])\n\ntweets_df['text'] = tweets_df['text'].apply(remove_stop_words_and_punct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lammetize(text):\n    doc = nlp(text)\n    return ' '.join([str(token.lemma_) for token in doc]).replace('-PRON-', 'I')\n\ntweets_df['text'] = tweets_df['text'].apply(lammetize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = tweets_df[['text', 'target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', LR())])\n\nlr = lr.fit(X_train, y_train)\n\nlr_predicted = lr.predict(X_test)\n\nprint(f1_score(y_test, lr_predicted))\nprint(accuracy_score(y_test, lr_predicted))\nprint(confusion_matrix(y_test, lr_predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', RandomForestClassifier())])\n\nrf = rf.fit(X_train, y_train)\n\nprint(f1_score(y_test, rf.predict(X_test)))\nprint(accuracy_score(y_test, rf.predict(X_test)))\nprint(confusion_matrix(y_test, rf.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"et = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', ExtraTreesClassifier())])\n\net = et.fit(X_train, y_train)\n\nprint(f1_score(y_test, et.predict(X_test)))\nprint(accuracy_score(y_test, et.predict(X_test)))\nprint(confusion_matrix(y_test, et.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', AdaBoostClassifier())])\n\nada = ada.fit(X_train, y_train)\n\nprint(f1_score(y_test, ada.predict(X_test)))\nprint(accuracy_score(y_test, ada.predict(X_test)))\nprint(confusion_matrix(y_test, ada.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', GradientBoostingClassifier())])\n\ngb = gb.fit(X_train, y_train)\n\nprint(f1_score(y_test, gb.predict(X_test)))\nprint(accuracy_score(y_test, gb.predict(X_test)))\nprint(confusion_matrix(y_test, gb.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame([lr.predict(X_test), rf.predict(X_test), et.predict(X_test), ada.predict(X_test), gb.predict(X_test)]).T\npred_df.columns = ['LR', 'RF', 'ET', 'ADA', 'GB']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df['Mode'] = pred_df.apply(statistics.mode, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f1_score(y_test, pred_df['Mode']))\nprint(accuracy_score(y_test, pred_df['Mode']))\nprint(confusion_matrix(y_test, pred_df['Mode']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ndf_test['text'] = df_test['text'].apply(remove_URL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ndf_test['text'] = df_test['text'].apply(remove_html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndf_test['text'] = df_test['text'].apply(remove_emoji)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['text'] = df_test['text'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stop_words_and_punct(text):\n    doc = nlp(text)\n    return ' '.join([str(token) for token in doc if not token.is_stop and not token.is_punct])\n\ndf_test['text'] = df_test['text'].apply(remove_stop_words_and_punct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lammetize(text):\n    doc = nlp(text)\n    return ' '.join([str(token.lemma_) for token in doc]).replace('-PRON-', 'I')\n\ndf_test['text'] = df_test['text'].apply(lammetize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfte = df_test['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_df = pd.DataFrame([lr.predict(dfte), rf.predict(dfte), et.predict(dfte), ada.predict(dfte), gb.predict(dfte)]).T\ntest_pred_df.columns = ['LR', 'RF', 'ET', 'ADA', 'GB']\n\nimport statistics\n\ntest_pred_df['Mode'] = test_pred_df.apply(statistics.mode, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_subm = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_subm['target'] = test_pred_df['Mode']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_subm.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}