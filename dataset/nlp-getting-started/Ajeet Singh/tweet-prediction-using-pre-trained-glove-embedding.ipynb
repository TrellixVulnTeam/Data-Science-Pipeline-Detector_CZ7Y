{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Tweets Prediction using Pre-Trained GloVe Embedding","metadata":{}},{"cell_type":"markdown","source":"### Import the necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom numpy import asarray\nfrom numpy import zeros\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:09:42.353132Z","iopub.execute_input":"2022-06-12T13:09:42.353598Z","iopub.status.idle":"2022-06-12T13:09:42.359608Z","shell.execute_reply.started":"2022-06-12T13:09:42.353556Z","shell.execute_reply":"2022-06-12T13:09:42.358859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read/View the train dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:10:11.513892Z","iopub.execute_input":"2022-06-12T13:10:11.514471Z","iopub.status.idle":"2022-06-12T13:10:11.555166Z","shell.execute_reply.started":"2022-06-12T13:10:11.514429Z","shell.execute_reply":"2022-06-12T13:10:11.554217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split the given dataset into train and test dataset (80:20 ratio)","metadata":{}},{"cell_type":"code","source":"split_ratio = 0.8\nsentences = train.text.values\nlabels = train.target.values\ntraining_size = int(len(sentences) * split_ratio)\ntraining_sentences = sentences[0:training_size]\ntesting_sentences = sentences[training_size:]\ntraining_labels = labels[0:training_size]\ntesting_labels = labels[training_size:]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:55:31.851547Z","iopub.execute_input":"2022-06-12T12:55:31.851946Z","iopub.status.idle":"2022-06-12T12:55:31.858071Z","shell.execute_reply.started":"2022-06-12T12:55:31.851913Z","shell.execute_reply":"2022-06-12T12:55:31.856891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the tokenizer","metadata":{}},{"cell_type":"code","source":"t = Tokenizer()\nt.fit_on_texts(training_sentences)\nvocab_size = len(t.word_index) + 1\n# integer encode the documents\ntrain_encoded_sentences = t.texts_to_sequences(training_sentences)\ntest_encoded_sentences = t.texts_to_sequences(testing_sentences)\n\n# pad documents to a max length of 125 words\nmax_length = 125\ntraining_padded = pad_sequences(train_encoded_sentences, maxlen=max_length, padding='post')\ntesting_padded = pad_sequences(test_encoded_sentences, maxlen=max_length, padding='post')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:59:07.93882Z","iopub.execute_input":"2022-06-12T12:59:07.93972Z","iopub.status.idle":"2022-06-12T12:59:31.344813Z","shell.execute_reply.started":"2022-06-12T12:59:07.939684Z","shell.execute_reply":"2022-06-12T12:59:31.343887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the whole embedding into memory and create embedding vectors","metadata":{}},{"cell_type":"code","source":"glove_size = 300\nembeddings_index = dict()\nf = open('/kaggle/input/glove6b/glove.6B.300d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))\n\n# create a weight matrix for words in training sentences\nembedding_matrix = zeros((vocab_size, glove_size))\nfor word, i in t.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the Model","metadata":{}},{"cell_type":"code","source":"# define model\nmodel = Sequential()\n#we do not want to update the learned word weights in this model, therefore we will set the \n#trainable attribute for the model to be False.\nembed = Embedding(vocab_size, glove_size, weights=[embedding_matrix], input_length=max_length, trainable=False)\nmodel.add(embed)\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# summarize the model\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:02:15.208265Z","iopub.execute_input":"2022-06-12T13:02:15.208664Z","iopub.status.idle":"2022-06-12T13:02:18.660439Z","shell.execute_reply.started":"2022-06-12T13:02:15.208625Z","shell.execute_reply":"2022-06-12T13:02:18.659681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model","metadata":{}},{"cell_type":"code","source":"# fit the model\nnum_epochs = 5\nhistory = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict the test data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntest_sentences = test.text.values\ntest_sequences = t.texts_to_sequences(test_sentences)\ntest_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n\nlst = []\nfor x in model.predict(test_padded):\n    lst.append((lambda x: 0 if x < 0.5 else 1)(x))\nsample_submission = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\nsample_submission[\"target\"] = lst\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:05:38.487846Z","iopub.execute_input":"2022-06-12T13:05:38.488269Z","iopub.status.idle":"2022-06-12T13:05:38.874114Z","shell.execute_reply.started":"2022-06-12T13:05:38.488234Z","shell.execute_reply":"2022-06-12T13:05:38.873039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:05:47.123105Z","iopub.execute_input":"2022-06-12T13:05:47.12354Z","iopub.status.idle":"2022-06-12T13:05:47.136588Z","shell.execute_reply.started":"2022-06-12T13:05:47.123506Z","shell.execute_reply":"2022-06-12T13:05:47.135368Z"},"trusted":true},"execution_count":null,"outputs":[]}]}