{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport spacy\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T12:55:18.261404Z","iopub.execute_input":"2021-11-22T12:55:18.262136Z","iopub.status.idle":"2021-11-22T12:55:18.266635Z","shell.execute_reply.started":"2021-11-22T12:55:18.262084Z","shell.execute_reply":"2021-11-22T12:55:18.265848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading NLP\nnlp = spacy.load('en_core_web_lg')\n\n#Loading the train data\ntrain_data = pd.read_csv('../input/nlp-getting-started/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T12:55:20.641942Z","iopub.execute_input":"2021-11-22T12:55:20.642507Z","iopub.status.idle":"2021-11-22T12:55:22.515692Z","shell.execute_reply.started":"2021-11-22T12:55:20.642458Z","shell.execute_reply":"2021-11-22T12:55:22.515003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading the vectors\nwith nlp.disable_pipes():\n    vectors = np.array([nlp(text.text).vector for idx, text in train_data.iterrows()])\n\n## Center the vectors\n# Calculate the mean for the vectors\nvec_mean = vectors.mean(axis=0)\n# Subtract the mean from the vectors\ncentered = vectors-vec_mean","metadata":{"execution":{"iopub.status.busy":"2021-11-22T12:55:22.518407Z","iopub.execute_input":"2021-11-22T12:55:22.518721Z","iopub.status.idle":"2021-11-22T12:56:23.195516Z","shell.execute_reply.started":"2021-11-22T12:55:22.518679Z","shell.execute_reply":"2021-11-22T12:56:23.19468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training the model\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(centered , train_data.target, \n                                                    test_size=0.1, random_state=1)\n\n#Lets perform scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\nX_val_scaled = scaler.transform(X_val.astype(np.float32))\n\n# Create the SVC model\nmodel = SVC(gamma='scale')\n\n# Fit the model\nmodel.fit(X_train_scaled,y_train)\n\n# Check model accuracy\nprint(f'Model test accuracy: {model.score(X_val_scaled, y_val)*100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T12:56:55.252184Z","iopub.execute_input":"2021-11-22T12:56:55.252463Z","iopub.status.idle":"2021-11-22T12:57:12.060013Z","shell.execute_reply.started":"2021-11-22T12:56:55.252434Z","shell.execute_reply":"2021-11-22T12:57:12.058996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the test data\ntest_data = pd.read_csv('../input/nlp-getting-started/test.csv')\n\n#Loading the test vectors\nwith nlp.disable_pipes():\n    test_vectors = np.array([nlp(text.text).vector for idx, text in test_data.iterrows()])\n\n## Center the test vectors\n# Calculate the mean for the vectors\nvec_mean_test = test_vectors.mean(axis=0)\n# Subtract the mean from the vectors\ncentered_test = test_vectors-vec_mean_test\n    \n#Perform scaling\nX_test_scaled = scaler.fit_transform(centered_test.astype(np.float32))\n\n#Predict\npredictions=model.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T12:57:12.062154Z","iopub.execute_input":"2021-11-22T12:57:12.062477Z","iopub.status.idle":"2021-11-22T12:57:43.775231Z","shell.execute_reply.started":"2021-11-22T12:57:12.062436Z","shell.execute_reply":"2021-11-22T12:57:43.77427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare it in the format for submission\npredictions_df=pd.DataFrame(predictions,index=test_data.index,columns=['target'])\npredictions_df=test_data.join(predictions_df.target)\npredictions_df=predictions_df.drop(columns=['keyword','location','text'])\npredictions_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T12:57:43.776704Z","iopub.execute_input":"2021-11-22T12:57:43.776948Z","iopub.status.idle":"2021-11-22T12:57:43.802257Z","shell.execute_reply.started":"2021-11-22T12:57:43.776922Z","shell.execute_reply":"2021-11-22T12:57:43.801473Z"},"trusted":true},"execution_count":null,"outputs":[]}]}