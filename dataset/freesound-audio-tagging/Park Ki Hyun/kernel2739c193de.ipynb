{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport librosa\nimport librosa.display\nimport IPython.display\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.listdir('../input/train-test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/freesound-audio-tagging/train.csv')\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_path = '../input/freesound-audio-tagging/audio_train/'\nfrom scipy.io import wavfile\nfname, label, verified = train.values[0]\nrate, data = wavfile.read(audio_path+fname)\n\nprint(label)\nprint('Sampling Rate:\\t{}'.format(rate))\nprint('Total Frames:\\t{}'.format(data.shape[0]))\nprint(data)\n\ny, sr = librosa.load(audio_path+fname)\nIPython.display.Audio(data=y, rate=sr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a = np.load('../input/train-test/train_test.npy', allow_pickle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pad_audio_data = pad_sequences(np.load('../input/train-test/train_test.npy', allow_pickle=True), maxlen=sr*2, value = 0, dtype = 'float32' )\npad_audio_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelEncoder = {}\nfor i, label in enumerate(train['label'].unique()):\n    labelEncoder[label] = i\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Encoding_label = np.zeros(9473, dtype = object)\n\nfor i in tqdm(range(0,9473)):\n    fname, label, verified = train.values[i]\n    Encoding_label[i] = labelEncoder[label]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Encoding_label = to_categorical(Encoding_label,41)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(data[:1024])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"D = librosa.amplitude_to_db(librosa.stft(y[:1024]),ref=np.max)\n\nplt.plot(D.flatten())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S = librosa.feature.melspectrogram(y, sr=sr)\n\nplt.figure(figsize=(12,4))\nlibrosa.display.specshow(librosa.power_to_db(S,ref=np.max), sr=sr, x_axis='time', y_axis='mel')\nplt.colorbar(format='%+2.0f dB')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc = librosa.feature.mfcc(y=y, sr=sr)\n\n\nplt.figure(figsize=(12,4))\nlibrosa.display.specshow(mfcc, x_axis='time')\nplt.colorbar(format='%+2.0f dB')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_level_db = -100\n \ndef _normalize(S):\n    return np.clip((librosa.power_to_db(S,ref=np.max) - min_level_db) / -min_level_db, 0, 1)\nnorm_S = _normalize(S)\n\nplt.figure(figsize=(12, 4))\nlibrosa.display.specshow(norm_S, sr=sr, x_axis='time', y_axis='mel')\nplt.title('norm mel power spectrogram')\nplt.colorbar(format='%+0.1f dB')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv1D,Dense,Dropout,MaxPool1D,Flatten\nfrom keras import optimizers\n\ninput_length = sr * 2 \nn_classes = train['label'].unique().shape[0]\ninput_audio_data = np.expand_dims(pad_audio_data, axis=2)\nopt = optimizers.Adam(learning_rate=0.00001)\n\n\ndef create_cnn():\n    model = Sequential()\n    model.add(Conv1D(filters=4, kernel_size=16, activation='relu', padding='same', input_shape=(input_length, 1)))\n    model.add(MaxPool1D(pool_size=2))\n    model.add(Dropout(rate=0.1))\n    model.add(Conv1D(filters=6, kernel_size=16, activation='relu', padding='same'))\n    model.add(MaxPool1D(pool_size=2))\n    model.add(Dropout(rate=0.1))\n    model.add(Conv1D(filters=9, kernel_size=16, activation='relu', padding='same'))\n    model.add(MaxPool1D(pool_size=2))\n    model.add(Dropout(rate=0.1))\n    model.add(Flatten())\n    model.add(Dense(units=100, activation = 'relu'))\n    model.add(Dense(units=n_classes, activation = 'softmax'))\n    \n    model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = opt)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_cnn()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(input_audio_data,Encoding_label, epochs=20, validation_split = 1/6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}