{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom tqdm import tqdm\npd.options.display.width = 180\npd.options.display.max_colwidth = 120\n\n# data_dir = Path('./input')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-20T12:06:31.737539Z","iopub.execute_input":"2022-06-20T12:06:31.737823Z","iopub.status.idle":"2022-06-20T12:06:31.852238Z","shell.execute_reply.started":"2022-06-20T12:06:31.737758Z","shell.execute_reply":"2022-06-20T12:06:31.851478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.makedirs(\"./outputs\", exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:06:31.853906Z","iopub.execute_input":"2022-06-20T12:06:31.854411Z","iopub.status.idle":"2022-06-20T12:06:31.858719Z","shell.execute_reply.started":"2022-06-20T12:06:31.85437Z","shell.execute_reply":"2022-06-20T12:06:31.85801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nmodel_name_or_path = 'microsoft/codebert-base'\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:06:31.860134Z","iopub.execute_input":"2022-06-20T12:06:31.860701Z","iopub.status.idle":"2022-06-20T12:06:33.960235Z","shell.execute_reply.started":"2022-06-20T12:06:31.860664Z","shell.execute_reply":"2022-06-20T12:06:33.959325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#metric.py\nfrom bisect import bisect\n\ndef count_inversions(a):\n    inversions = 0\n    sorted_so_far = []\n    for i, u in enumerate(a):\n        j = bisect(sorted_so_far, u)\n        inversions += i - j\n        sorted_so_far.insert(j, u)\n    return inversions\n\n\ndef kendall_tau(ground_truth, predictions):\n    total_inversions = 0\n    total_2max = 0  # twice the maximum possible inversions across all instances\n    for gt, pred in zip(ground_truth, predictions):\n        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n        total_inversions += count_inversions(ranks)\n        n = len(gt)\n        total_2max += n * (n - 1)\n    return 1 - 4 * total_inversions / total_2max\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:06:33.962995Z","iopub.execute_input":"2022-06-20T12:06:33.964103Z","iopub.status.idle":"2022-06-20T12:06:33.974645Z","shell.execute_reply.started":"2022-06-20T12:06:33.964067Z","shell.execute_reply":"2022-06-20T12:06:33.973409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.py\nfrom tqdm import tqdm\nimport sys, os\nfrom transformers import AutoModel, AutoTokenizer\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\n\nclass MarkdownModel(nn.Module):\n    def __init__(self, model_path):\n        super(MarkdownModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_path)\n        self.top = nn.Linear(769, 1)\n        \n    def forward(self, ids, mask, fts):\n        x = self.model(ids, mask)[0]\n        x = self.top(torch.cat((x[:, 0, :], fts),1))\n        return x\n\n\n#dataset.py\nfrom torch.utils.data import DataLoader, Dataset\n\nclass MarkdownDataset(Dataset):\n\n    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.md_max_len = md_max_len\n        self.total_max_len = total_max_len  # maxlen allowed by model config\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n        self.fts = fts\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n\n        inputs = self.tokenizer.encode_plus(\n            row.source,\n            None,\n            add_special_tokens=True,\n            max_length=self.md_max_len,\n            padding=\"max_length\",\n            return_token_type_ids=True,\n            truncation=True\n        )\n        code_inputs = self.tokenizer.batch_encode_plus(\n            [str(x) for x in self.fts[row.id][\"codes\"]],\n            add_special_tokens=True,\n            max_length=23,\n            padding=\"max_length\",\n            truncation=True\n        )\n        n_md = self.fts[row.id][\"total_md\"]\n        n_code = self.fts[row.id][\"total_code\"]\n        if n_md + n_code == 0:\n            fts = torch.FloatTensor([0])\n        else:\n            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n\n        ids = inputs['input_ids']\n        for x in code_inputs['input_ids']:\n            ids.extend(x[:-1])\n        ids = ids[:self.total_max_len]\n        if len(ids) != self.total_max_len:\n            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n        ids = torch.LongTensor(ids)\n\n        mask = inputs['attention_mask']\n        for x in code_inputs['attention_mask']:\n            mask.extend(x[:-1])\n        mask = mask[:self.total_max_len]\n        if len(mask) != self.total_max_len:\n            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n        mask = torch.LongTensor(mask)\n\n        assert len(ids) == self.total_max_len\n\n        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n\n    def __len__(self):\n        return self.df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:06:33.976024Z","iopub.execute_input":"2022-06-20T12:06:33.976595Z","iopub.status.idle":"2022-06-20T12:06:39.486304Z","shell.execute_reply.started":"2022-06-20T12:06:33.97649Z","shell.execute_reply":"2022-06-20T12:06:39.485489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 50k\n\n# train_df_mark = pd.read_csv('../input/ai4code/data/data/train_mark.csv').drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# train_fts = json.load(open('../input/ai4code/data/data/train_fts.json'))\n# val_df_mark = pd.read_csv('../input/ai4code/data/data/val_mark.csv').drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# val_fts = json.load(open('../input/ai4code/data/data/val_fts.json'))\n# val_df = pd.read_csv('../input/ai4code/data/data/val.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 20k\n\n# train_df_mark = pd.read_csv('../input/data2/train_mark_2.csv').drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# train_fts = json.load(open('../input/data2/train_fts_2.json'))\n# val_df_mark = pd.read_csv('../input/data2/val_mark_2.csv').drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# val_fts = json.load(open('../input/data2/val_fts_2.json'))\n# val_df = pd.read_csv('../input/data2/val_2.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T02:57:17.657968Z","iopub.execute_input":"2022-06-12T02:57:17.65838Z","iopub.status.idle":"2022-06-12T02:57:22.526889Z","shell.execute_reply.started":"2022-06-12T02:57:17.658345Z","shell.execute_reply":"2022-06-12T02:57:22.525949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 1k\n\n# train_df_mark = pd.read_csv('../input/data-1k/data_1k/train_mark.csv').drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# train_fts = json.load(open('../input/data-1k/data_1k/train_fts.json'))\n# val_df_mark = pd.read_csv('../input/data-1k/data_1k/val_mark.csv').drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# val_fts = json.load(open('../input/data-1k/data_1k/val_fts.json'))\n# val_df = pd.read_csv('../input/data-1k/data_1k/val.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:07:30.647108Z","iopub.execute_input":"2022-06-20T12:07:30.647667Z","iopub.status.idle":"2022-06-20T12:07:30.976943Z","shell.execute_reply.started":"2022-06-20T12:07:30.647631Z","shell.execute_reply":"2022-06-20T12:07:30.976145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = Path('../input/AI4Code')\n\norder_df = pd.read_csv(data_dir / \"train_orders.csv\").set_index(\"id\")\ndf_orders = pd.read_csv(\n    data_dir / 'train_orders.csv',\n    index_col='id',\n    squeeze=True,\n).str.split()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:07:37.976329Z","iopub.execute_input":"2022-06-20T12:07:37.97707Z","iopub.status.idle":"2022-06-20T12:07:40.727926Z","shell.execute_reply.started":"2022-06-20T12:07:37.977036Z","shell.execute_reply":"2022-06-20T12:07:40.727109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"md_max_len = 64\ntotal_max_len = 512\nbatch_size = 8\naccumulation_steps = 4\nepochs = 2\nn_workers = 8\n\n\n# train_ds = MarkdownDataset(train_df_mark, model_name_or_path=model_name_or_path, md_max_len=md_max_len,\n#                            total_max_len=total_max_len, fts=train_fts)\n# val_ds = MarkdownDataset(val_df_mark, model_name_or_path=model_name_or_path, md_max_len=md_max_len,\n#                          total_max_len=total_max_len, fts=val_fts)\n# train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=n_workers,\n#                           pin_memory=False, drop_last=True)\n# val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=n_workers,\n#                         pin_memory=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:09:06.614236Z","iopub.execute_input":"2022-06-20T12:09:06.614696Z","iopub.status.idle":"2022-06-20T12:09:34.333791Z","shell.execute_reply.started":"2022-06-20T12:09:06.614658Z","shell.execute_reply":"2022-06-20T12:09:34.332799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(data):\n    return tuple(d.to(device) for d in data[:-1]), data[-1].to(device)\n\n\ndef validate(model, val_loader):\n    model.eval()\n\n    tbar = tqdm(val_loader, file=sys.stdout)\n\n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            with torch.cuda.amp.autocast():\n                pred = model(*inputs)\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n\n    return np.concatenate(labels), np.concatenate(preds)\n\nfrom transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n# def train(model, train_loader, val_loader, epochs):\n#     np.random.seed(0)\n#     # Creating optimizer and lr schedulers\n#     param_optimizer = list(model.named_parameters())\n#     no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n#     optimizer_grouped_parameters = [\n#         {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n#         {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n#     ]\n\n#     num_train_optimization_steps = int(epochs * len(train_loader) / accumulation_steps)\n#     optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5,\n#                       correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n#                                                 num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n\n#     criterion = torch.nn.L1Loss()\n#     scaler = torch.cuda.amp.GradScaler()\n\n#     for e in range(epochs):\n#         model.train()\n#         tbar = tqdm(train_loader, file=sys.stdout)\n#         loss_list = []\n#         preds = []\n#         labels = []\n\n#         for idx, data in enumerate(tbar):\n#             inputs, target = read_data(data)\n\n#             with torch.cuda.amp.autocast():\n#                 pred = model(*inputs)\n#                 loss = criterion(pred, target)\n#             scaler.scale(loss).backward()\n#             if idx % accumulation_steps == 0 or idx == len(tbar) - 1:\n#                 scaler.step(optimizer)\n#                 scaler.update()\n#                 optimizer.zero_grad()\n#                 scheduler.step()\n\n#             loss_list.append(loss.detach().cpu().item())\n#             preds.append(pred.detach().cpu().numpy().ravel())\n#             labels.append(target.detach().cpu().numpy().ravel())\n\n#             avg_loss = np.round(np.mean(loss_list), 4)\n\n#             tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n\n#         y_val, y_pred = validate(model, val_loader)\n#         val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n#         val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n#         y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n#         print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n#         torch.save(model.state_dict(), \"./outputs/model_1k_23.bin\")\n\n#     return model, y_pred\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:10:11.833536Z","iopub.execute_input":"2022-06-20T12:10:11.83388Z","iopub.status.idle":"2022-06-20T12:10:11.853606Z","shell.execute_reply.started":"2022-06-20T12:10:11.83385Z","shell.execute_reply":"2022-06-20T12:10:11.852855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = MarkdownModel(model_name_or_path)\n# model = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:10:12.668815Z","iopub.execute_input":"2022-06-20T12:10:12.670629Z","iopub.status.idle":"2022-06-20T12:11:03.563198Z","shell.execute_reply.started":"2022-06-20T12:10:12.670535Z","shell.execute_reply":"2022-06-20T12:11:03.562378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model, y_pred = train(model, train_loader, val_loader, epochs=epochs)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:11:03.564676Z","iopub.execute_input":"2022-06-20T12:11:03.565028Z","iopub.status.idle":"2022-06-20T12:38:16.245145Z","shell.execute_reply.started":"2022-06-20T12:11:03.564993Z","shell.execute_reply":"2022-06-20T12:38:16.243983Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train 끝!","metadata":{}},{"cell_type":"code","source":"def read_notebook(path):\n    return (\n        pd.read_json(\n            path,\n            dtype={'cell_type': 'category', 'source': 'str'})\n        .assign(id=path.stem)\n        .rename_axis('cell_id')\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:38:16.252396Z","iopub.execute_input":"2022-06-20T12:38:16.25466Z","iopub.status.idle":"2022-06-20T12:38:16.260912Z","shell.execute_reply.started":"2022-06-20T12:38:16.254613Z","shell.execute_reply":"2022-06-20T12:38:16.260243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = Path('../input/AI4Code')\npaths_test = list((data_dir / 'test').glob('*.json'))\n\nnotebooks_test = [\n    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n]\n\ntest_df = (\n    pd.concat(notebooks_test)\n    .set_index('id', append=True)\n    .swaplevel()\n    .sort_index(level='id', sort_remaining=False)\n).reset_index()\n\n# 각 노트북 내에서 code셀&md셀 각각 번호가 0부터 매겨짐\ntest_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount() #cumcount(): 각 그룹의 각 항목에 0부터 번호를 매김!\ntest_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:38:16.263159Z","iopub.execute_input":"2022-06-20T12:38:16.263523Z","iopub.status.idle":"2022-06-20T12:38:16.354911Z","shell.execute_reply.started":"2022-06-20T12:38:16.263487Z","shell.execute_reply":"2022-06-20T12:38:16.354127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:38:16.356324Z","iopub.execute_input":"2022-06-20T12:38:16.356883Z","iopub.status.idle":"2022-06-20T12:38:16.378145Z","shell.execute_reply.started":"2022-06-20T12:38:16.356846Z","shell.execute_reply":"2022-06-20T12:38:16.377452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Additional code cells\n\n#preprocess.py -11\ndef clean_code(cell):\n    return str(cell).replace(\"\\\\n\", \"\\n\")\n\n\ndef sample_cells(cells, n):\n    cells = [clean_code(cell) for cell in cells]\n    if n >= len(cells):\n        return [cell[:200] for cell in cells]\n    else:\n        results = []\n        step = len(cells) / n\n        idx = 0\n        while int(np.round(idx)) < len(cells):\n            results.append(cells[int(np.round(idx))])\n            idx += step\n        assert cells[0] in results\n        if cells[-1] not in results:\n            results[-1] = cells[-1]\n        return results\n\n\ndef get_features(df):\n    features = dict()\n    df = df.sort_values(\"rank\").reset_index(drop=True)\n    for idx, sub_df in tqdm(df.groupby(\"id\")):\n        features[idx] = dict()\n        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n        total_code = code_sub_df.shape[0]\n        codes = sample_cells(code_sub_df.source.values, 20)\n        features[idx][\"total_code\"] = total_code\n        features[idx][\"total_md\"] = total_md\n        features[idx][\"codes\"] = codes\n    return features","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:38:16.37929Z","iopub.execute_input":"2022-06-20T12:38:16.379697Z","iopub.status.idle":"2022-06-20T12:38:16.390191Z","shell.execute_reply.started":"2022-06-20T12:38:16.379662Z","shell.execute_reply":"2022-06-20T12:38:16.389277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_fts = get_features(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:38:16.391813Z","iopub.execute_input":"2022-06-20T12:38:16.392348Z","iopub.status.idle":"2022-06-20T12:38:16.412529Z","shell.execute_reply.started":"2022-06-20T12:38:16.392309Z","shell.execute_reply":"2022-06-20T12:38:16.411684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model_path, ckpt_path):\n    model = MarkdownModel(model_path)\n    model = model.cuda()\n    model.eval()\n    model.load_state_dict(torch.load(ckpt_path))\n    BS = 32\n    NW = 8\n    MAX_LEN = 64\n    test_df[\"pct_rank\"] = 0\n    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                              pin_memory=False, drop_last=False)\n    _, y_test = validate(model, test_loader)\n    return y_test","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:38:16.41362Z","iopub.execute_input":"2022-06-20T12:38:16.414165Z","iopub.status.idle":"2022-06-20T12:38:16.422582Z","shell.execute_reply.started":"2022-06-20T12:38:16.41413Z","shell.execute_reply":"2022-06-20T12:38:16.421584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"../input/codebertbase/codebert-base\"\n\n# ckpt_path = \"../input/ai4codemodelspublic/model.bin\"\nckpt_path = \"../input/outpust-1k-23/model_1k_23.bin\"","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:46:29.441308Z","iopub.execute_input":"2022-06-20T12:46:29.442173Z","iopub.status.idle":"2022-06-20T12:46:29.446466Z","shell.execute_reply.started":"2022-06-20T12:46:29.442133Z","shell.execute_reply":"2022-06-20T12:46:29.445401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !apt install git-lfs\n\n# !git lfs install\n","metadata":{"execution":{"iopub.status.busy":"2022-06-12T02:58:05.658118Z","iopub.execute_input":"2022-06-12T02:58:05.658464Z","iopub.status.idle":"2022-06-12T02:58:07.786731Z","shell.execute_reply.started":"2022-06-12T02:58:05.658436Z","shell.execute_reply":"2022-06-12T02:58:07.785655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_2 = predict(model_path, ckpt_path)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:46:31.363888Z","iopub.execute_input":"2022-06-20T12:46:31.364237Z","iopub.status.idle":"2022-06-20T12:46:34.951379Z","shell.execute_reply.started":"2022-06-20T12:46:31.364206Z","shell.execute_reply":"2022-06-20T12:46:34.950335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_test = (y_test_1 + y_test_2)/2\ny_test = y_test_2","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:46:34.953709Z","iopub.execute_input":"2022-06-20T12:46:34.956547Z","iopub.status.idle":"2022-06-20T12:46:34.96001Z","shell.execute_reply.started":"2022-06-20T12:46:34.95651Z","shell.execute_reply":"2022-06-20T12:46:34.959287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:46:34.961367Z","iopub.execute_input":"2022-06-20T12:46:34.962517Z","iopub.status.idle":"2022-06-20T12:46:34.974333Z","shell.execute_reply.started":"2022-06-20T12:46:34.962476Z","shell.execute_reply":"2022-06-20T12:46:34.973562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\nsub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T12:46:36.305502Z","iopub.execute_input":"2022-06-20T12:46:36.306694Z","iopub.status.idle":"2022-06-20T12:46:36.334378Z","shell.execute_reply.started":"2022-06-20T12:46:36.30665Z","shell.execute_reply":"2022-06-20T12:46:36.332325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T13:19:42.715733Z","iopub.execute_input":"2022-06-20T13:19:42.716099Z","iopub.status.idle":"2022-06-20T13:19:42.721904Z","shell.execute_reply.started":"2022-06-20T13:19:42.716069Z","shell.execute_reply":"2022-06-20T13:19:42.721115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}