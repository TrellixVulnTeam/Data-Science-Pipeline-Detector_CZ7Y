{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI4Code Pytorch CodeBert Baseline (standalone)\n\nThis is based on https://www.kaggle.com/code/aerdem4/ai4code-pytorch-distilbert-baseline/notebook with DistilBert replaced with CodeBert (sadly, I misplaced the example CodeBert training code I also looked at, but it's pretty much subbing DistilBert for Roberta.)  \n\nThis is *not* a competitve model by itself (0.7438) - the distillation process appears to adapt more efficiently.  The .8xxx models are all using far more intensive training - but in my case i'm still wrapping my head around using all this, this is the first Kaggle comp I've done in quite a while :)\n\nI also stripped down the notebook a bit to focus on the code.  For more comments go back to the ancestors :)","metadata":{"papermill":{"duration":0.031568,"end_time":"2022-05-12T10:15:13.890382","exception":false,"start_time":"2022-05-12T10:15:13.858814","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom tqdm import tqdm\n\npd.options.display.width = 180\npd.options.display.max_colwidth = 120\n\n#BERT_PATH = \"../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\"\nBERT_PATH = \"../input/codebert-base/codebert-base\"\n\ndata_dir = Path('../input/AI4Code')","metadata":{"papermill":{"duration":0.122804,"end_time":"2022-05-12T10:15:14.04297","exception":false,"start_time":"2022-05-12T10:15:13.920166","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:07:40.531106Z","iopub.execute_input":"2022-06-05T21:07:40.53142Z","iopub.status.idle":"2022-06-05T21:07:40.619322Z","shell.execute_reply.started":"2022-06-05T21:07:40.531353Z","shell.execute_reply":"2022-06-05T21:07:40.618722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TRAIN = 10000\n\n\ndef read_notebook(path):\n    return (\n        pd.read_json(\n            path,\n            dtype={'cell_type': 'category', 'source': 'str'})\n        .assign(id=path.stem)\n        .rename_axis('cell_id')\n    )\n\n\npaths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\nnotebooks_train = [\n    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n]\ndf = (\n    pd.concat(notebooks_train)\n    .set_index('id', append=True)\n    .swaplevel()\n    .sort_index(level='id', sort_remaining=False)\n)\n","metadata":{"papermill":{"duration":82.291505,"end_time":"2022-05-12T10:16:36.365197","exception":false,"start_time":"2022-05-12T10:15:14.073692","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:08:03.152445Z","iopub.execute_input":"2022-06-05T21:08:03.1527Z","iopub.status.idle":"2022-06-05T21:09:49.335203Z","shell.execute_reply.started":"2022-06-05T21:08:03.152671Z","shell.execute_reply":"2022-06-05T21:09:49.334438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_orders = pd.read_csv(\n    data_dir / 'train_orders.csv',\n    index_col='id',\n    squeeze=True,\n).str.split()  # Split the string representation of cell_ids into a list\n\ndef get_ranks(base, derived):\n    return [base.index(d) for d in derived]\n\n#nb\n\ndf_orders_ = df_orders.to_frame().join(\n    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n    how='right',\n)\n\nranks = {}\nfor id_, cell_order, cell_id in df_orders_.itertuples():\n    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n\ndf_ranks = (\n    pd.DataFrame\n    .from_dict(ranks, orient='index')\n    .rename_axis('id')\n    .apply(pd.Series.explode)\n    .set_index('cell_id', append=True)\n)\n\n#df_ranks\n\ndf_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n#df_ancestors\n\ndf = df.reset_index().merge(df_ranks, on=[\"id\", \"cell_id\"]).merge(df_ancestors, on=[\"id\"])\n#df\n\ndf[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n#df[\"pct_rank\"].hist(bins=10)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:09:49.336868Z","iopub.execute_input":"2022-06-05T21:09:49.337121Z","iopub.status.idle":"2022-06-05T21:09:55.140778Z","shell.execute_reply.started":"2022-06-05T21:09:49.337088Z","shell.execute_reply":"2022-06-05T21:09:55.139876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit\n\nNVALID = 0.1  # size of validation set\n\nsplitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n\ntrain_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n\ntrain_df = df.loc[train_ind].reset_index(drop=True)\nval_df = df.loc[val_ind].reset_index(drop=True)","metadata":{"papermill":{"duration":1.895199,"end_time":"2022-05-12T10:16:49.969199","exception":false,"start_time":"2022-05-12T10:16:48.074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:11:34.210086Z","iopub.execute_input":"2022-06-05T21:11:34.21035Z","iopub.status.idle":"2022-06-05T21:11:35.467241Z","shell.execute_reply.started":"2022-06-05T21:11:34.21032Z","shell.execute_reply":"2022-06-05T21:11:35.466493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bisect import bisect\n\n\ndef count_inversions(a):\n    inversions = 0\n    sorted_so_far = []\n    for i, u in enumerate(a):\n        j = bisect(sorted_so_far, u)\n        inversions += i - j\n        sorted_so_far.insert(j, u)\n    return inversions\n\n\ndef kendall_tau(ground_truth, predictions):\n    total_inversions = 0\n    total_2max = 0  # twice the maximum possible inversions across all instances\n    for gt, pred in zip(ground_truth, predictions):\n        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n        total_inversions += count_inversions(ranks)\n        n = len(gt)\n        total_2max += n * (n - 1)\n    return 1 - 4 * total_inversions / total_2max","metadata":{"papermill":{"duration":0.262837,"end_time":"2022-05-12T10:16:51.011588","exception":false,"start_time":"2022-05-12T10:16:50.748751","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:11:36.819847Z","iopub.execute_input":"2022-06-05T21:11:36.820136Z","iopub.status.idle":"2022-06-05T21:11:36.827933Z","shell.execute_reply.started":"2022-06-05T21:11:36.820104Z","shell.execute_reply":"2022-06-05T21:11:36.82688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n\nval_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)","metadata":{"papermill":{"duration":0.371916,"end_time":"2022-05-12T10:16:52.797271","exception":false,"start_time":"2022-05-12T10:16:52.425355","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:11:38.465409Z","iopub.execute_input":"2022-06-05T21:11:38.46607Z","iopub.status.idle":"2022-06-05T21:11:38.581292Z","shell.execute_reply.started":"2022-06-05T21:11:38.466032Z","shell.execute_reply":"2022-06-05T21:11:38.580568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nmean_squared_error(val_df_mark[\"pct_rank\"], np.ones(val_df_mark.shape[0])*train_df_mark[\"pct_rank\"].mean())","metadata":{"papermill":{"duration":0.280778,"end_time":"2022-05-12T10:16:53.349877","exception":false,"start_time":"2022-05-12T10:16:53.069099","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:11:39.573481Z","iopub.execute_input":"2022-06-05T21:11:39.573745Z","iopub.status.idle":"2022-06-05T21:11:39.597174Z","shell.execute_reply.started":"2022-06-05T21:11:39.573699Z","shell.execute_reply":"2022-06-05T21:11:39.596546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport sys, os\nfrom transformers import DistilBertModel, DistilBertTokenizer\nfrom transformers import RobertaModel, RobertaTokenizer\nimport transformers\n#from transformers import , DistilBertTokenizer\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\n\nMAX_LEN = 128\n\n# additional ref cell 8 of https://www.kaggle.com/code/heyytanay/ai4code-pytorch-training-codebert-w-b\n# 18 of https://www.kaggle.com/code/yuanzhezhou/ai4code-pairwise-bertsmall-inference\n\nclass MarkdownModel(nn.Module):\n    def __init__(self):\n        super(MarkdownModel, self).__init__()\n        self.bert = transformers.RobertaModel.from_pretrained(BERT_PATH)\n        self.drop = nn.Dropout(0.2)\n        self.top = nn.Linear(768, 1)\n        \n    def forward(self, ids, mask):\n        x = self.bert(ids, mask)[0]\n        x = self.drop(x)\n        x = self.top(x[:, 0, :])\n        x = torch.sigmoid(x)\n        return x","metadata":{"papermill":{"duration":7.145711,"end_time":"2022-05-12T10:17:00.757077","exception":false,"start_time":"2022-05-12T10:16:53.611366","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:13:02.546286Z","iopub.execute_input":"2022-06-05T21:13:02.546566Z","iopub.status.idle":"2022-06-05T21:13:02.554541Z","shell.execute_reply.started":"2022-06-05T21:13:02.546536Z","shell.execute_reply":"2022-06-05T21:13:02.553701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\n\n\nclass MarkdownDataset(Dataset):\n    \n    def __init__(self, df, max_len):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.max_len = max_len\n        self.tokenizer = RobertaTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        inputs = self.tokenizer.encode_plus(\n            row.source,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = torch.LongTensor(inputs['input_ids'])\n        mask = torch.LongTensor(inputs['attention_mask'])\n\n        return ids, mask, torch.FloatTensor([row.pct_rank])\n\n    def __len__(self):\n        return self.df.shape[0]\n    \ntrain_ds = MarkdownDataset(train_df_mark, max_len=MAX_LEN)\nval_ds = MarkdownDataset(val_df_mark, max_len=MAX_LEN)\n\n#val_ds[0]","metadata":{"papermill":{"duration":0.474499,"end_time":"2022-05-12T10:17:01.487031","exception":false,"start_time":"2022-05-12T10:17:01.012532","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:13:03.423775Z","iopub.execute_input":"2022-06-05T21:13:03.424228Z","iopub.status.idle":"2022-06-05T21:13:03.670945Z","shell.execute_reply.started":"2022-06-05T21:13:03.42419Z","shell.execute_reply":"2022-06-05T21:13:03.670168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_lr(optimizer, epoch):\n    if epoch < 1:\n        lr = 5e-5\n    elif epoch < 2:\n        lr = 1e-3\n    elif epoch < 5:\n        lr = 1e-4\n    else:\n        lr = 1e-5\n\n    for p in optimizer.param_groups:\n        p['lr'] = lr\n    return lr\n    \ndef get_optimizer(net):\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n                                 eps=1e-08)\n    return optimizer","metadata":{"papermill":{"duration":0.265988,"end_time":"2022-05-12T10:17:02.580374","exception":false,"start_time":"2022-05-12T10:17:02.314386","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:13:03.956326Z","iopub.execute_input":"2022-06-05T21:13:03.956665Z","iopub.status.idle":"2022-06-05T21:13:03.967254Z","shell.execute_reply.started":"2022-06-05T21:13:03.956633Z","shell.execute_reply":"2022-06-05T21:13:03.966504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BS = 32\nNW = 2\n\ntrain_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n                          pin_memory=False, drop_last=True)\nval_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                          pin_memory=False, drop_last=False)","metadata":{"papermill":{"duration":0.298424,"end_time":"2022-05-12T10:17:03.132","exception":false,"start_time":"2022-05-12T10:17:02.833576","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:13:04.975095Z","iopub.execute_input":"2022-06-05T21:13:04.975565Z","iopub.status.idle":"2022-06-05T21:13:04.981663Z","shell.execute_reply.started":"2022-06-05T21:13:04.975527Z","shell.execute_reply":"2022-06-05T21:13:04.980939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n\n\ndef validate(model, val_loader):\n    model.eval()\n    \n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            pred = model(inputs[0], inputs[1])\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(labels), np.concatenate(preds)\n\ndef train(model, train_loader, val_loader, epochs):\n    np.random.seed(0)\n    \n    optimizer = get_optimizer(model)\n\n    criterion = torch.nn.MSELoss()\n    \n    for e in range(epochs):   \n        model.train()\n        tbar = tqdm(train_loader, file=sys.stdout)\n        \n        lr = adjust_lr(optimizer, e)\n        \n        loss_list = []\n        preds = []\n        labels = []\n\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            optimizer.zero_grad()\n            pred = model(inputs[0], inputs[1])\n\n            loss = criterion(pred, target)\n            loss.backward()\n            optimizer.step()\n            \n            loss_list.append(loss.detach().cpu().item())\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n            \n            avg_loss = np.round(np.mean(loss_list), 4)\n\n            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n            \n        y_val, y_pred = validate(model, val_loader)\n            \n        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n        print()\n    return model, y_pred\n\nmodel = MarkdownModel()\nmodel = model.cuda()\nmodel, y_pred = train(model, train_loader, val_loader, epochs=1)","metadata":{"papermill":{"duration":987.160977,"end_time":"2022-05-12T10:33:30.548236","exception":false,"start_time":"2022-05-12T10:17:03.387259","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:13:06.820297Z","iopub.execute_input":"2022-06-05T21:13:06.820554Z","iopub.status.idle":"2022-06-05T21:42:57.474319Z","shell.execute_reply.started":"2022-06-05T21:13:06.820526Z","shell.execute_reply":"2022-06-05T21:42:57.470698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not that this is a particularly hot model, but I don't think it should go completely to waste either :)","metadata":{}},{"cell_type":"code","source":"torch.save(model, 'codebert-trained2.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:42:57.476604Z","iopub.execute_input":"2022-06-05T21:42:57.477051Z","iopub.status.idle":"2022-06-05T21:42:58.351832Z","shell.execute_reply.started":"2022-06-05T21:42:57.477009Z","shell.execute_reply":"2022-06-05T21:42:58.351043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\nval_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred","metadata":{"papermill":{"duration":3.695855,"end_time":"2022-05-12T10:33:37.305989","exception":false,"start_time":"2022-05-12T10:33:33.610134","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:42:58.353342Z","iopub.execute_input":"2022-06-05T21:42:58.353598Z","iopub.status.idle":"2022-06-05T21:42:58.428286Z","shell.execute_reply.started":"2022-06-05T21:42:58.35356Z","shell.execute_reply":"2022-06-05T21:42:58.427642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compute the validation score.  This is going to be a bit lower than the Distilbert baseline.","metadata":{}},{"cell_type":"code","source":"y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\nkendall_tau(df_orders.loc[y_dummy.index], y_dummy)","metadata":{"papermill":{"duration":3.230655,"end_time":"2022-05-12T10:33:43.545936","exception":false,"start_time":"2022-05-12T10:33:40.315281","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:48:11.337714Z","iopub.execute_input":"2022-06-05T21:48:11.338206Z","iopub.status.idle":"2022-06-05T21:48:11.503889Z","shell.execute_reply.started":"2022-06-05T21:48:11.338169Z","shell.execute_reply":"2022-06-05T21:48:11.503047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths_test = list((data_dir / 'test').glob('*.json'))\nnotebooks_test = [\n    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n]\ntest_df = (\n    pd.concat(notebooks_test)\n    .set_index('id', append=True)\n    .swaplevel()\n    .sort_index(level='id', sort_remaining=False)\n).reset_index()","metadata":{"papermill":{"duration":3.156008,"end_time":"2022-05-12T10:33:49.98707","exception":false,"start_time":"2022-05-12T10:33:46.831062","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T15:12:46.010828Z","iopub.execute_input":"2022-06-05T15:12:46.01115Z","iopub.status.idle":"2022-06-05T15:12:46.080374Z","shell.execute_reply.started":"2022-06-05T15:12:46.011094Z","shell.execute_reply":"2022-06-05T15:12:46.079344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\ntest_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)","metadata":{"papermill":{"duration":3.580422,"end_time":"2022-05-12T10:33:56.648552","exception":false,"start_time":"2022-05-12T10:33:53.06813","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T15:12:46.081821Z","iopub.execute_input":"2022-06-05T15:12:46.082599Z","iopub.status.idle":"2022-06-05T15:12:46.096274Z","shell.execute_reply.started":"2022-06-05T15:12:46.082559Z","shell.execute_reply":"2022-06-05T15:12:46.095079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"pct_rank\"] = 0\ntest_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), max_len=MAX_LEN)\ntest_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                          pin_memory=False, drop_last=False)\n\nlen(test_ds), test_ds[0]","metadata":{"papermill":{"duration":3.130783,"end_time":"2022-05-12T10:34:03.120038","exception":false,"start_time":"2022-05-12T10:33:59.989255","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T15:12:46.098333Z","iopub.execute_input":"2022-06-05T15:12:46.098788Z","iopub.status.idle":"2022-06-05T15:12:46.226052Z","shell.execute_reply.started":"2022-06-05T15:12:46.098747Z","shell.execute_reply":"2022-06-05T15:12:46.225042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_test = validate(model, test_loader)","metadata":{"papermill":{"duration":4.00212,"end_time":"2022-05-12T10:34:10.223448","exception":false,"start_time":"2022-05-12T10:34:06.221328","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T15:12:46.227874Z","iopub.execute_input":"2022-06-05T15:12:46.228282Z","iopub.status.idle":"2022-06-05T15:12:46.672914Z","shell.execute_reply.started":"2022-06-05T15:12:46.228252Z","shell.execute_reply":"2022-06-05T15:12:46.671888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test","metadata":{"papermill":{"duration":3.164567,"end_time":"2022-05-12T10:34:16.415308","exception":false,"start_time":"2022-05-12T10:34:13.250741","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T15:12:46.675061Z","iopub.execute_input":"2022-06-05T15:12:46.675392Z","iopub.status.idle":"2022-06-05T15:12:46.685271Z","shell.execute_reply.started":"2022-06-05T15:12:46.675355Z","shell.execute_reply":"2022-06-05T15:12:46.684167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\nsub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\nsub_df.head()","metadata":{"papermill":{"duration":3.093752,"end_time":"2022-05-12T10:34:22.827853","exception":false,"start_time":"2022-05-12T10:34:19.734101","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T15:12:46.686717Z","iopub.execute_input":"2022-06-05T15:12:46.687112Z","iopub.status.idle":"2022-06-05T15:12:46.710162Z","shell.execute_reply.started":"2022-06-05T15:12:46.687068Z","shell.execute_reply":"2022-06-05T15:12:46.709241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","metadata":{"papermill":{"duration":3.551878,"end_time":"2022-05-12T10:34:29.528868","exception":false,"start_time":"2022-05-12T10:34:25.97699","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T15:12:46.713603Z","iopub.execute_input":"2022-06-05T15:12:46.714018Z","iopub.status.idle":"2022-06-05T15:12:46.723501Z","shell.execute_reply.started":"2022-06-05T15:12:46.713948Z","shell.execute_reply":"2022-06-05T15:12:46.722314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's see how much memory was needed.  v2 *might* work on an 8GB GPU if you're not running anything else, but this version needs 16GB. :P","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:21:26.28696Z","iopub.execute_input":"2022-06-05T16:21:26.287796Z","iopub.status.idle":"2022-06-05T16:21:26.320842Z","shell.execute_reply.started":"2022-06-05T16:21:26.287698Z","shell.execute_reply":"2022-06-05T16:21:26.319372Z"}}},{"cell_type":"code","source":"print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\nprint(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\nprint(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))","metadata":{"papermill":{"duration":3.030555,"end_time":"2022-05-12T10:34:35.897014","exception":false,"start_time":"2022-05-12T10:34:32.866459","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-05T21:48:29.544531Z","iopub.execute_input":"2022-06-05T21:48:29.544798Z","iopub.status.idle":"2022-06-05T21:48:29.5516Z","shell.execute_reply.started":"2022-06-05T21:48:29.544768Z","shell.execute_reply":"2022-06-05T21:48:29.550852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nsubprocess.run(\"nvidia-smi\")","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:48:30.107108Z","iopub.execute_input":"2022-06-05T21:48:30.10786Z","iopub.status.idle":"2022-06-05T21:48:30.246428Z","shell.execute_reply.started":"2022-06-05T21:48:30.107827Z","shell.execute_reply":"2022-06-05T21:48:30.245634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}