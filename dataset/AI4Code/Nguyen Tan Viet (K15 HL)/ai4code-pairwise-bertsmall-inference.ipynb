{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pairwise inference\nIn this notebook, we demonstrate how to use pairwise model to predict in this competition. Please note that the inference time is much longer than pointwise method or using cosine similarity. \n\n1. I used a bert-small model pretrained with pairwise-mlm.\n2. Training with pairwise examples with negative samples randomly sampled.\n3. **Inference and predict for all the pairs for test dataset.**\n\n* [Pretrain](https://www.kaggle.com/code/yuanzhezhou/ai4code-pairwise-bertsmall-pretrain/notebook)\n* [Training](https://www.kaggle.com/yuanzhezhou/ai4code-pairwise-bertsmall-training)\n* [Inference](https://www.kaggle.com/yuanzhezhou/ai4code-pairwise-bertsmall-inference)","metadata":{}},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom tqdm import tqdm\n\npd.options.display.width = 180\npd.options.display.max_colwidth = 120\n\nBERT_PATH = \"../input/huggingface-roberta-variants/pytorch-xlm-roberta-base/pytorch-xlm-roberta-base\"\n\ndata_dir = Path('../input/AI4Code')","metadata":{"papermill":{"duration":0.122804,"end_time":"2022-05-12T10:15:14.04297","exception":false,"start_time":"2022-05-12T10:15:13.920166","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:09.491485Z","iopub.execute_input":"2022-06-27T01:34:09.491777Z","iopub.status.idle":"2022-06-27T01:34:09.499212Z","shell.execute_reply.started":"2022-06-27T01:34:09.491745Z","shell.execute_reply":"2022-06-27T01:34:09.497453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NUM_TRAIN = 200\n\n\ndef read_notebook(path):\n    return (\n        pd.read_json(\n            path,\n            dtype={'cell_type': 'category', 'source': 'str'})\n        .assign(id=path.stem)\n        .rename_axis('cell_id')\n    )\n\n\n# paths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n# notebooks_train = [\n#     read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n# ]\n# df = (\n#     pd.concat(notebooks_train)\n#     .set_index('id', append=True)\n#     .swaplevel()\n#     .sort_index(level='id', sort_remaining=False)\n# )\n\n# df","metadata":{"papermill":{"duration":82.291505,"end_time":"2022-05-12T10:16:36.365197","exception":false,"start_time":"2022-05-12T10:15:14.073692","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:09.712007Z","iopub.execute_input":"2022-06-27T01:34:09.712426Z","iopub.status.idle":"2022-06-27T01:34:09.720838Z","shell.execute_reply.started":"2022-06-27T01:34:09.712383Z","shell.execute_reply":"2022-06-27T01:34:09.719593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ranks(base, derived):\n    return [base.index(d) for d in derived]\n\n# cell_ranks = get_ranks(cell_order, list(nb.index))\n# nb.insert(0, 'rank', cell_ranks)\n\n# nb","metadata":{"papermill":{"duration":0.265625,"end_time":"2022-05-12T10:16:41.501618","exception":false,"start_time":"2022-05-12T10:16:41.235993","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:09.889715Z","iopub.execute_input":"2022-06-27T01:34:09.890386Z","iopub.status.idle":"2022-06-27T01:34:09.895954Z","shell.execute_reply.started":"2022-06-27T01:34:09.890337Z","shell.execute_reply":"2022-06-27T01:34:09.894447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\n# import fasttext\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.stem import WordNetLemmatizer\nfrom pathlib import Path\nimport nltk\nnltk.download('wordnet')\n\nstemmer = WordNetLemmatizer()\n\ndef preprocess_text(document):\n        # Remove all the special characters\n        document = re.sub(r'\\W', ' ', str(document))\n\n        # remove all single characters\n        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n\n        # Remove single characters from the start\n        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n\n        # Substituting multiple spaces with single space\n        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n\n        # Removing prefixed 'b'\n        document = re.sub(r'^b\\s+', '', document)\n\n        # Converting to Lowercase\n        document = document.lower()\n        #return document\n\n        # Lemmatization\n        tokens = document.split()\n        tokens = [stemmer.lemmatize(word) for word in tokens]\n        tokens = [word for word in tokens if len(word) > 3]\n\n        preprocessed_text = ' '.join(tokens)\n        return preprocessed_text\n\n    \ndef preprocess_df(df):\n    \"\"\"\n    This function is for processing sorce of notebook\n    returns preprocessed dataframe\n    \"\"\"\n    return [preprocess_text(message) for message in df.source]\n\n# df.source = df.source.apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:34:10.082413Z","iopub.execute_input":"2022-06-27T01:34:10.082828Z","iopub.status.idle":"2022-06-27T01:34:30.125798Z","shell.execute_reply.started":"2022-06-27T01:34:10.082794Z","shell.execute_reply":"2022-06-27T01:34:30.124361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef generate_triplet(df, mode='train'):\n  triplets = []\n  ids = df.id.unique()\n  random_drop = np.random.random(size=10000)>0.9\n  count = 0\n\n  for id, df_tmp in tqdm(df.groupby('id')):\n    df_tmp_markdown = df_tmp[df_tmp['cell_type']=='markdown']\n\n    df_tmp_code = df_tmp[df_tmp['cell_type']=='code']\n    df_tmp_code_rank = df_tmp_code['rank'].values\n    df_tmp_code_cell_id = df_tmp_code['cell_id'].values\n\n    for cell_id, rank in df_tmp_markdown[['cell_id', 'rank']].values:\n      labels = np.array([(r==(rank+1)) for r in df_tmp_code_rank]).astype('int')\n\n      for cid, label in zip(df_tmp_code_cell_id, labels):\n        count += 1\n        if label==1:\n          triplets.append( [cell_id, cid, label] )\n          # triplets.append( [cid, cell_id, label] )\n        elif mode == 'test':\n          triplets.append( [cell_id, cid, label] )\n          # triplets.append( [cid, cell_id, label] )\n        elif random_drop[count%10000]:\n          triplets.append( [cell_id, cid, label] )\n          # triplets.append( [cid, cell_id, label] )\n        \n  return triplets\n\n# triplets = generate_triplet(train_df)\n# val_triplets = generate_triplet(val_df, mode = 'test')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:34:30.128365Z","iopub.execute_input":"2022-06-27T01:34:30.128694Z","iopub.status.idle":"2022-06-27T01:34:30.139623Z","shell.execute_reply.started":"2022-06-27T01:34:30.12865Z","shell.execute_reply":"2022-06-27T01:34:30.138498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bisect import bisect\n\n\ndef count_inversions(a):\n    inversions = 0\n    sorted_so_far = []\n    for i, u in enumerate(a):\n        j = bisect(sorted_so_far, u)\n        inversions += i - j\n        sorted_so_far.insert(j, u)\n    return inversions\n\n\ndef kendall_tau(ground_truth, predictions):\n    total_inversions = 0\n    total_2max = 0  # twice the maximum possible inversions across all instances\n    for gt, pred in zip(ground_truth, predictions):\n        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n        total_inversions += count_inversions(ranks)\n        n = len(gt)\n        total_2max += n * (n - 1)\n    return 1 - 4 * total_inversions / total_2max","metadata":{"papermill":{"duration":0.262837,"end_time":"2022-05-12T10:16:51.011588","exception":false,"start_time":"2022-05-12T10:16:50.748751","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.141916Z","iopub.execute_input":"2022-06-27T01:34:30.142681Z","iopub.status.idle":"2022-06-27T01:34:30.155644Z","shell.execute_reply.started":"2022-06-27T01:34:30.142633Z","shell.execute_reply":"2022-06-27T01:34:30.154429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\nfrom transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n\nMAX_LEN = 70\n\n    \nclass MarkdownModel(nn.Module):\n    def __init__(self):\n        super(MarkdownModel, self).__init__()\n        self.distill_bert = AutoModel.from_pretrained(\"../input/huggingface-roberta-variants/pytorch-xlm-roberta-base/pytorch-xlm-roberta-base\")\n        self.top = nn.Linear(768, 1)\n\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, ids, mask):\n        x = self.distill_bert(ids, mask)[0]\n        x = self.dropout(x)\n        x = self.top(x[:, 0, :])\n        x = torch.sigmoid(x) \n        return x","metadata":{"papermill":{"duration":7.145711,"end_time":"2022-05-12T10:17:00.757077","exception":false,"start_time":"2022-05-12T10:16:53.611366","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.158636Z","iopub.execute_input":"2022-06-27T01:34:30.159391Z","iopub.status.idle":"2022-06-27T01:34:30.171186Z","shell.execute_reply.started":"2022-06-27T01:34:30.159343Z","shell.execute_reply":"2022-06-27T01:34:30.169828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\n\n\nclass MarkdownDataset(Dataset):\n    \n    def __init__(self, df, max_len, mode='train'):\n        super().__init__()\n        self.df = df\n        self.max_len = max_len\n        self.tokenizer = AutoTokenizer.from_pretrained(\"../input/huggingface-roberta-variants/pytorch-xlm-roberta-base/pytorch-xlm-roberta-base\",use_fast=True)\n        self.mode=mode\n\n    def __getitem__(self, index):\n        row = self.df[index]\n\n        label = row[-1]\n\n        txt = dict_cellid_source[row[0]] + '[SEP]' + dict_cellid_source[row[1]]\n\n        inputs = self.tokenizer.encode_plus(\n            txt,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = torch.LongTensor(inputs['input_ids'])\n        mask = torch.LongTensor(inputs['attention_mask'])\n\n        return ids, mask, torch.FloatTensor([label])\n\n\n\n\n    def __len__(self):\n        return len(self.df)\n\n\n# train_ds = MarkdownDataset(triplets, max_len=MAX_LEN, mode='test')\n# val_ds = MarkdownDataset(val_triplets, max_len=MAX_LEN, mode='test')\n\n\n# train_ds[1]","metadata":{"papermill":{"duration":0.474499,"end_time":"2022-05-12T10:17:01.487031","exception":false,"start_time":"2022-05-12T10:17:01.012532","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.173779Z","iopub.execute_input":"2022-06-27T01:34:30.174715Z","iopub.status.idle":"2022-06-27T01:34:30.187623Z","shell.execute_reply.started":"2022-06-27T01:34:30.174669Z","shell.execute_reply":"2022-06-27T01:34:30.18659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_lr(optimizer, epoch):\n    if epoch < 1:\n        lr = 5e-5\n    elif epoch < 2:\n        lr = 1e-3\n    elif epoch < 5:\n        lr = 1e-4\n    else:\n        lr = 1e-5\n\n    for p in optimizer.param_groups:\n        p['lr'] = lr\n    return lr\n    \ndef get_optimizer(net):\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n                                 eps=1e-08)\n    return optimizer\n\nBS = 128\nNW = 8\n\n# train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n#                           pin_memory=False, drop_last=True)\n# val_loader = DataLoader(val_ds, batch_size=BS * 8, shuffle=False, num_workers=NW,\n#                           pin_memory=False, drop_last=False)","metadata":{"papermill":{"duration":0.265988,"end_time":"2022-05-12T10:17:02.580374","exception":false,"start_time":"2022-05-12T10:17:02.314386","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.190737Z","iopub.execute_input":"2022-06-27T01:34:30.191456Z","iopub.status.idle":"2022-06-27T01:34:30.201503Z","shell.execute_reply.started":"2022-06-27T01:34:30.191406Z","shell.execute_reply":"2022-06-27T01:34:30.200349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n\n\ndef validate(model, val_loader, mode='train'):\n    model.eval()\n    \n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    preds = np.zeros(len(val_loader.dataset), dtype='float32')\n    labels = []\n    count = 0\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            pred = model(inputs[0], inputs[1]).detach().cpu().numpy().ravel()\n\n            preds[count:count+len(pred)] = pred\n            count += len(pred)\n            \n            if mode=='test':\n              labels.append(target.detach().cpu().numpy().ravel())\n    if mode=='test':\n      return preds\n    else:\n      return np.concatenate(labels), np.concatenate(preds)\n","metadata":{"papermill":{"duration":987.160977,"end_time":"2022-05-12T10:33:30.548236","exception":false,"start_time":"2022-05-12T10:17:03.387259","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.204228Z","iopub.execute_input":"2022-06-27T01:34:30.204666Z","iopub.status.idle":"2022-06-27T01:34:30.218468Z","shell.execute_reply.started":"2022-06-27T01:34:30.204531Z","shell.execute_reply":"2022-06-27T01:34:30.217364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths_test = list((data_dir / 'test').glob('*.json'))\nnotebooks_test = [\n    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n]\ntest_df = (\n    pd.concat(notebooks_test)\n    .set_index('id', append=True)\n    .swaplevel()\n    .sort_index(level='id', sort_remaining=False)\n).reset_index()","metadata":{"papermill":{"duration":3.156008,"end_time":"2022-05-12T10:33:49.98707","exception":false,"start_time":"2022-05-12T10:33:46.831062","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.222268Z","iopub.execute_input":"2022-06-27T01:34:30.222931Z","iopub.status.idle":"2022-06-27T01:34:30.311765Z","shell.execute_reply.started":"2022-06-27T01:34:30.222845Z","shell.execute_reply":"2022-06-27T01:34:30.310759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.source = test_df.source.apply(preprocess_text)\ndict_cellid_source = dict(zip(test_df['cell_id'].values, test_df['source'].values))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:34:30.313485Z","iopub.execute_input":"2022-06-27T01:34:30.313997Z","iopub.status.idle":"2022-06-27T01:34:30.372898Z","shell.execute_reply.started":"2022-06-27T01:34:30.313954Z","shell.execute_reply":"2022-06-27T01:34:30.371891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\ntest_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=False)","metadata":{"papermill":{"duration":3.580422,"end_time":"2022-05-12T10:33:56.648552","exception":false,"start_time":"2022-05-12T10:33:53.06813","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.376871Z","iopub.execute_input":"2022-06-27T01:34:30.377452Z","iopub.status.idle":"2022-06-27T01:34:30.389902Z","shell.execute_reply.started":"2022-06-27T01:34:30.377405Z","shell.execute_reply":"2022-06-27T01:34:30.388824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_triplets = generate_triplet(test_df, mode = 'test')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:34:30.391677Z","iopub.execute_input":"2022-06-27T01:34:30.392339Z","iopub.status.idle":"2022-06-27T01:34:30.462834Z","shell.execute_reply.started":"2022-06-27T01:34:30.392274Z","shell.execute_reply":"2022-06-27T01:34:30.461897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"pct_rank\"] = 0\ntest_ds = MarkdownDataset(test_triplets, max_len=MAX_LEN)\ntest_loader = DataLoader(test_ds, batch_size=BS * 4, shuffle=False,num_workers=2,\n                          pin_memory=False, drop_last=False)\n\n\nimport gc \ngc.collect()","metadata":{"papermill":{"duration":3.130783,"end_time":"2022-05-12T10:34:03.120038","exception":false,"start_time":"2022-05-12T10:33:59.989255","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:30.464512Z","iopub.execute_input":"2022-06-27T01:34:30.465016Z","iopub.status.idle":"2022-06-27T01:34:31.732637Z","shell.execute_reply.started":"2022-06-27T01:34:30.46496Z","shell.execute_reply":"2022-06-27T01:34:31.731325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys \nimport os \nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nmodel = MarkdownModel()\nmodel = model.cuda()\nmodel.load_state_dict(torch.load('../input/xlmroberta/my_own_model_4.bin'))\ny_test = validate(model, test_loader, mode='test')\n\n","metadata":{"papermill":{"duration":4.00212,"end_time":"2022-05-12T10:34:10.223448","exception":false,"start_time":"2022-05-12T10:34:06.221328","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:31.734359Z","iopub.execute_input":"2022-06-27T01:34:31.734755Z","iopub.status.idle":"2022-06-27T01:34:38.596708Z","shell.execute_reply.started":"2022-06-27T01:34:31.734712Z","shell.execute_reply":"2022-06-27T01:34:38.595539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_copy = y_test","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:34:38.598571Z","iopub.execute_input":"2022-06-27T01:34:38.600077Z","iopub.status.idle":"2022-06-27T01:34:38.605626Z","shell.execute_reply.started":"2022-06-27T01:34:38.600024Z","shell.execute_reply":"2022-06-27T01:34:38.604434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_vals = []\ncount = 0\nind = 0\nfor id, df_tmp in tqdm(test_df.groupby('id')):\n  df_tmp_mark = df_tmp[df_tmp['cell_type']=='markdown']\n  df_tmp_code = df_tmp[df_tmp['cell_type']!='markdown']\n  df_tmp_code_rank = df_tmp_code['rank'].rank().values\n  N_code = len(df_tmp_code_rank)\n  N_mark = len(df_tmp_mark)\n\n  preds_tmp = preds_copy[count:count+N_mark * N_code]\n  count += N_mark * N_code\n\n  for i in range(N_mark):\n#     x = []\n#     y = []\n    pred = preds_tmp[i*N_code:i*N_code+N_code] \n    softmax = np.exp((pred-np.mean(pred)) *20)/np.sum(np.exp((pred-np.mean(pred)) *20))\n#     x.extend(pred)\n#     y.extend(softmax)\n#     plt.figure(ind)\n#     plt.scatter(x, y)\n#     n = range(0,len(x))\n#     for i in n:\n#         plt.annotate(str(i), (x[i], y[i]))\n    rank = np.sum(softmax * df_tmp_code_rank)\n    pred_vals.append(rank)\n    ind+=1\nplt.show()\ndel model\ndel test_triplets[:]\ndel dict_cellid_source\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:34:38.607525Z","iopub.execute_input":"2022-06-27T01:34:38.607903Z","iopub.status.idle":"2022-06-27T01:34:38.971267Z","shell.execute_reply.started":"2022-06-27T01:34:38.607839Z","shell.execute_reply":"2022-06-27T01:34:38.970383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = pred_vals","metadata":{"papermill":{"duration":3.164567,"end_time":"2022-05-12T10:34:16.415308","exception":false,"start_time":"2022-05-12T10:34:13.250741","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:38.972842Z","iopub.execute_input":"2022-06-27T01:34:38.973283Z","iopub.status.idle":"2022-06-27T01:34:38.980785Z","shell.execute_reply.started":"2022-06-27T01:34:38.973223Z","shell.execute_reply":"2022-06-27T01:34:38.979194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\nsub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\nsub_df.head()","metadata":{"papermill":{"duration":3.093752,"end_time":"2022-05-12T10:34:22.827853","exception":false,"start_time":"2022-05-12T10:34:19.734101","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:38.982347Z","iopub.execute_input":"2022-06-27T01:34:38.983524Z","iopub.status.idle":"2022-06-27T01:34:39.005957Z","shell.execute_reply.started":"2022-06-27T01:34:38.983468Z","shell.execute_reply":"2022-06-27T01:34:39.004958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","metadata":{"papermill":{"duration":3.551878,"end_time":"2022-05-12T10:34:29.528868","exception":false,"start_time":"2022-05-12T10:34:25.97699","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-27T01:34:39.007486Z","iopub.execute_input":"2022-06-27T01:34:39.007906Z","iopub.status.idle":"2022-06-27T01:34:39.057062Z","shell.execute_reply.started":"2022-06-27T01:34:39.00784Z","shell.execute_reply":"2022-06-27T01:34:39.055933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Please upvote if you find it helpful! :D","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}