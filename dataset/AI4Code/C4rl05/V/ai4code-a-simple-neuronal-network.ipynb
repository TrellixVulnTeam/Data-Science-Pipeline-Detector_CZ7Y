{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI4Code, A simple Neuronal Network\nHello this models will implement a simple Neuronal Net to tackle the prediction problem...\n\n## Work in Progress, Come Back Soon âœ¨\n\n**Competition Description...**\n\nThe goal of this competition is to understand the relationship between code and comments in Python notebooks. You are challenged to reconstruct the order of markdown cells in a given notebook based on the order of the code cells, demonstrating comprehension of which natural language references which code.","metadata":{}},{"cell_type":"code","source":"%%time\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nexamples = 15\ncounter = 0\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        counter += 1\n        print(os.path.join(dirname, filename))\n        if counter > examples:\n            break\n\nprint('')            \nprint('Done...')\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T23:23:46.604419Z","iopub.execute_input":"2022-05-13T23:23:46.604775Z","iopub.status.idle":"2022-05-13T23:24:15.325044Z","shell.execute_reply.started":"2022-05-13T23:23:46.604739Z","shell.execute_reply":"2022-05-13T23:24:15.323981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Import the requiered libraries...\nimport json\nfrom pathlib import Path\n\nfrom scipy import sparse\nfrom tqdm import tqdm\n\npd.options.display.width = 180\npd.options.display.max_colwidth = 120\n\ndata_dir = Path('../input/AI4Code')","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:24:15.326835Z","iopub.execute_input":"2022-05-13T23:24:15.327076Z","iopub.status.idle":"2022-05-13T23:24:15.333904Z","shell.execute_reply.started":"2022-05-13T23:24:15.327045Z","shell.execute_reply":"2022-05-13T23:24:15.333083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nNUM_TRAIN = 10_000\n\n# Define a function to read a json file...\ndef read_notebook(path):\n    \"\"\"\n    Read a json file and import it to a dataframe...\n    Args:\n        path (str): The filepath location to be loaded into the dataframe.\n    Returns:\n        df (dataframe): A dataframe with the json information.\n    \"\"\"\n\n    types = {'cell_type': 'category', 'source': 'str'}\n    df = pd.read_json(path, dtype = types).assign(id = path.stem).rename_axis('cell_id')\n    return df \n\n# Create a list of the locations of all the training files...\npaths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n\n# Create a list of dataframes from json files...\nnotebooks_train = [read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')]","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:24:15.335365Z","iopub.execute_input":"2022-05-13T23:24:15.335592Z","iopub.status.idle":"2022-05-13T23:25:14.681613Z","shell.execute_reply.started":"2022-05-13T23:24:15.335562Z","shell.execute_reply":"2022-05-13T23:25:14.680795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Concat the dataframes from the notebooks_train into one frame...\n\ntrn_data = pd.concat(notebooks_train).set_index('id', append = True).swaplevel().sort_index(level = 'id', sort_remaining = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:14.690583Z","iopub.execute_input":"2022-05-13T23:25:14.69091Z","iopub.status.idle":"2022-05-13T23:25:20.495368Z","shell.execute_reply.started":"2022-05-13T23:25:14.690874Z","shell.execute_reply":"2022-05-13T23:25:20.494482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display th efirst five to ten rows of data...\n\ntrn_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:20.496774Z","iopub.execute_input":"2022-05-13T23:25:20.497011Z","iopub.status.idle":"2022-05-13T23:25:20.51102Z","shell.execute_reply.started":"2022-05-13T23:25:20.496974Z","shell.execute_reply":"2022-05-13T23:25:20.50987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display th efirst five to ten rows of data...\n\n# Get an example notebook\nnb_id = trn_data.index.unique('id')[6]\nprint('Notebook:', nb_id)\n\nprint(\"The disordered notebook:\")\nnb = trn_data.loc[nb_id, :]\ndisplay(nb)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:20.512577Z","iopub.execute_input":"2022-05-13T23:25:20.512831Z","iopub.status.idle":"2022-05-13T23:25:20.547565Z","shell.execute_reply.started":"2022-05-13T23:25:20.512801Z","shell.execute_reply":"2022-05-13T23:25:20.547005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_orders = pd.read_csv('/kaggle/input/AI4Code/train_orders.csv')\ndf_orders.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:20.548849Z","iopub.execute_input":"2022-05-13T23:25:20.549052Z","iopub.status.idle":"2022-05-13T23:25:21.327074Z","shell.execute_reply.started":"2022-05-13T23:25:20.549026Z","shell.execute_reply":"2022-05-13T23:25:21.326172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_orders = pd.read_csv(data_dir / 'train_orders.csv', index_col='id',squeeze=True,).str.split()  # Split the string representation of cell_ids into a list\ndf_orders.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:21.328813Z","iopub.execute_input":"2022-05-13T23:25:21.329133Z","iopub.status.idle":"2022-05-13T23:25:23.098872Z","shell.execute_reply.started":"2022-05-13T23:25:21.32909Z","shell.execute_reply":"2022-05-13T23:25:23.098017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Get the correct order\ncell_order = df_orders.loc[nb_id]\n\nprint(\"The ordered notebook:\")\nnb.loc[cell_order, :]","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:23.100353Z","iopub.execute_input":"2022-05-13T23:25:23.100569Z","iopub.status.idle":"2022-05-13T23:25:23.138518Z","shell.execute_reply.started":"2022-05-13T23:25:23.10054Z","shell.execute_reply":"2022-05-13T23:25:23.137514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#...\nprint(cell_order)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:23.141611Z","iopub.execute_input":"2022-05-13T23:25:23.14238Z","iopub.status.idle":"2022-05-13T23:25:23.148618Z","shell.execute_reply.started":"2022-05-13T23:25:23.142337Z","shell.execute_reply":"2022-05-13T23:25:23.147929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#...\ndef get_ranks(base, derived):\n    return [base.index(d) for d in derived]\n\ncell_ranks = get_ranks(cell_order, list(nb.index))\nnb.insert(0, 'rank', cell_ranks)\nnb","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:23.1499Z","iopub.execute_input":"2022-05-13T23:25:23.150112Z","iopub.status.idle":"2022-05-13T23:25:23.173248Z","shell.execute_reply.started":"2022-05-13T23:25:23.150086Z","shell.execute_reply":"2022-05-13T23:25:23.172079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Convert the df_orders to a dataframe...\ndf_orders = df_orders.to_frame()\ndf_orders.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:23.174909Z","iopub.execute_input":"2022-05-13T23:25:23.175778Z","iopub.status.idle":"2022-05-13T23:25:23.194973Z","shell.execute_reply.started":"2022-05-13T23:25:23.17573Z","shell.execute_reply":"2022-05-13T23:25:23.194338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Join the df_orders_ dataframe with the json dataframe...\ntrn_data_grouped = trn_data.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\ntrn_data_grouped.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:23.195873Z","iopub.execute_input":"2022-05-13T23:25:23.196618Z","iopub.status.idle":"2022-05-13T23:25:23.73951Z","shell.execute_reply.started":"2022-05-13T23:25:23.196579Z","shell.execute_reply":"2022-05-13T23:25:23.738595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_orders_ = df_orders.join(trn_data_grouped, how = 'right')\ndf_orders_.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:23.740951Z","iopub.execute_input":"2022-05-13T23:25:23.741266Z","iopub.status.idle":"2022-05-13T23:25:23.802108Z","shell.execute_reply.started":"2022-05-13T23:25:23.74122Z","shell.execute_reply":"2022-05-13T23:25:23.801281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nranks = {} # Creates an empty dictionary of ranks...\nfor id_, cell_order, cell_id in df_orders_.itertuples():\n    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:23.803469Z","iopub.execute_input":"2022-05-13T23:25:23.804299Z","iopub.status.idle":"2022-05-13T23:25:24.484877Z","shell.execute_reply.started":"2022-05-13T23:25:23.804243Z","shell.execute_reply":"2022-05-13T23:25:24.483859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_ranks = pd.DataFrame.from_dict(ranks, orient = 'index').rename_axis('id').apply(pd.Series.explode).set_index('cell_id', append = True)\ndf_ranks.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:24.486723Z","iopub.execute_input":"2022-05-13T23:25:24.487062Z","iopub.status.idle":"2022-05-13T23:25:26.499948Z","shell.execute_reply.started":"2022-05-13T23:25:24.487018Z","shell.execute_reply":"2022-05-13T23:25:26.498966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\ndf_ancestors","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:26.501401Z","iopub.execute_input":"2022-05-13T23:25:26.501754Z","iopub.status.idle":"2022-05-13T23:25:26.73181Z","shell.execute_reply.started":"2022-05-13T23:25:26.501708Z","shell.execute_reply":"2022-05-13T23:25:26.730985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import GroupShuffleSplit\n\nNVALID = 0.1  # size of validation set\n\nsplitter = GroupShuffleSplit(n_splits = 1, test_size = NVALID, random_state = 0)\n\n# Split, keeping notebooks with a common origin (ancestor_id) together\nids = trn_data.index.unique('id')\nancestors = df_ancestors.loc[ids, 'ancestor_id']\nids_train, ids_valid = next(splitter.split(ids, groups = ancestors))\nids_train, ids_valid = ids[ids_train], ids[ids_valid]\n\ndf_train = trn_data.loc[ids_train, :]\ndf_valid = trn_data.loc[ids_valid, :]","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:26.73323Z","iopub.execute_input":"2022-05-13T23:25:26.733612Z","iopub.status.idle":"2022-05-13T23:25:26.872198Z","shell.execute_reply.started":"2022-05-13T23:25:26.733566Z","shell.execute_reply":"2022-05-13T23:25:26.871239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:26.873512Z","iopub.execute_input":"2022-05-13T23:25:26.874259Z","iopub.status.idle":"2022-05-13T23:25:26.889657Z","shell.execute_reply.started":"2022-05-13T23:25:26.874222Z","shell.execute_reply":"2022-05-13T23:25:26.888756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Training set\ntfidf = TfidfVectorizer(min_df=0.01)\nX_train = tfidf.fit_transform(df_train['source'].astype(str))\n# Rank of each cell within the notebook\ny_train = df_ranks.loc[ids_train].to_numpy()\n# Number of cells in each notebook\ngroups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:26.890964Z","iopub.execute_input":"2022-05-13T23:25:26.891583Z","iopub.status.idle":"2022-05-13T23:25:45.505291Z","shell.execute_reply.started":"2022-05-13T23:25:26.89155Z","shell.execute_reply":"2022-05-13T23:25:45.504497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf.get_feature_names_out()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:45.506607Z","iopub.execute_input":"2022-05-13T23:25:45.50692Z","iopub.status.idle":"2022-05-13T23:25:45.517022Z","shell.execute_reply.started":"2022-05-13T23:25:45.50688Z","shell.execute_reply":"2022-05-13T23:25:45.516214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:45.518104Z","iopub.execute_input":"2022-05-13T23:25:45.518338Z","iopub.status.idle":"2022-05-13T23:25:45.530043Z","shell.execute_reply.started":"2022-05-13T23:25:45.518309Z","shell.execute_reply":"2022-05-13T23:25:45.529217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add code cell ordering\nX_train = sparse.hstack((\n    X_train,\n    np.where(\n        df_train['cell_type'] == 'code',\n        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n        0,\n    ).reshape(-1, 1)\n))\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:45.531219Z","iopub.execute_input":"2022-05-13T23:25:45.531456Z","iopub.status.idle":"2022-05-13T23:25:45.822015Z","shell.execute_reply.started":"2022-05-13T23:25:45.531417Z","shell.execute_reply":"2022-05-13T23:25:45.82125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:25:45.823539Z","iopub.execute_input":"2022-05-13T23:25:45.824041Z","iopub.status.idle":"2022-05-13T23:25:45.830356Z","shell.execute_reply.started":"2022-05-13T23:25:45.823996Z","shell.execute_reply":"2022-05-13T23:25:45.829429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRanker\n\nmodel = XGBRanker(\n    min_child_weight=10,\n    subsample=0.5,\n    tree_method='hist',\n)\nmodel.fit(X_train, y_train, group=groups)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:40:33.710582Z","iopub.execute_input":"2022-05-13T23:40:33.710955Z","iopub.status.idle":"2022-05-13T23:40:47.909517Z","shell.execute_reply.started":"2022-05-13T23:40:33.710923Z","shell.execute_reply":"2022-05-13T23:40:47.908893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation set\nX_valid = tfidf.transform(df_valid['source'].astype(str))\n# The metric uses cell ids\ny_valid = df_orders.loc[ids_valid]\n\nX_valid = sparse.hstack((\n    X_valid,\n    np.where(\n        df_valid['cell_type'] == 'code',\n        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n        0,\n    ).reshape(-1, 1)\n))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:43:14.467982Z","iopub.execute_input":"2022-05-13T23:43:14.468872Z","iopub.status.idle":"2022-05-13T23:43:16.317662Z","shell.execute_reply.started":"2022-05-13T23:43:14.468818Z","shell.execute_reply":"2022-05-13T23:43:16.316862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)\ny_pred = (\n    y_pred\n    .sort_values(['id', 'rank'])  # Sort the cells in each notebook by their rank.\n                                  # The cell_ids are now in the order the model predicted.\n    .reset_index('cell_id')  # Convert the cell_id index into a column.\n    .groupby('id')['cell_id'].apply(list)  # Group the cell_ids for each notebook into a list.\n)\ny_pred.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:43:25.295705Z","iopub.execute_input":"2022-05-13T23:43:25.296484Z","iopub.status.idle":"2022-05-13T23:43:25.486371Z","shell.execute_reply.started":"2022-05-13T23:43:25.296436Z","shell.execute_reply":"2022-05-13T23:43:25.485504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_id = df_valid.index.get_level_values('id').unique()[8]\n\ndisplay(trn_data.loc[nb_id])\ndisplay(trn_data.loc[nb_id].loc[y_pred.loc[nb_id]])","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:44:06.03716Z","iopub.execute_input":"2022-05-13T23:44:06.037496Z","iopub.status.idle":"2022-05-13T23:44:06.076278Z","shell.execute_reply.started":"2022-05-13T23:44:06.037462Z","shell.execute_reply":"2022-05-13T23:44:06.07503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bisect import bisect\n\n\ndef count_inversions(a):\n    inversions = 0\n    sorted_so_far = []\n    for i, u in enumerate(a):\n        j = bisect(sorted_so_far, u)\n        inversions += i - j\n        sorted_so_far.insert(j, u)\n    return inversions\n\n\ndef kendall_tau(ground_truth, predictions):\n    total_inversions = 0\n    total_2max = 0  # twice the maximum possible inversions across all instances\n    for gt, pred in zip(ground_truth, predictions):\n        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n        total_inversions += count_inversions(ranks)\n        n = len(gt)\n        total_2max += n * (n - 1)\n    return 1 - 4 * total_inversions / total_2max","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:45:02.610407Z","iopub.execute_input":"2022-05-13T23:45:02.610784Z","iopub.status.idle":"2022-05-13T23:45:02.620647Z","shell.execute_reply.started":"2022-05-13T23:45:02.610749Z","shell.execute_reply":"2022-05-13T23:45:02.619655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\nkendall_tau(y_valid, y_dummy)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T23:45:07.819139Z","iopub.execute_input":"2022-05-13T23:45:07.819497Z","iopub.status.idle":"2022-05-13T23:45:07.915883Z","shell.execute_reply.started":"2022-05-13T23:45:07.819457Z","shell.execute_reply":"2022-05-13T23:45:07.914489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}