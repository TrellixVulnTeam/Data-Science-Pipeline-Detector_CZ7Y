{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport nltk \nfrom nltk.corpus import stopwords\n#to remove HTML tags from the doc\nfrom bs4 import BeautifulSoup \n#removing numbers,punctuations,i.e regular expressions from the doc\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10ab0fc74cc84bd21c10a743b7f4c6983c2fc711"},"cell_type":"code","source":"train_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15476741997fb010fe4f1453a9e81ae1821d6dfb"},"cell_type":"code","source":"# view the first review\ntrain_data.review[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e0ab5d8ac440863ed74e1a239d0811589a48d50"},"cell_type":"code","source":"# html tags and comments are removed and stored in sample1\n\nsample1 = BeautifulSoup(train_data.review[0],\"html.parser\")\n\n# using get_text() we can see only text in html doc\n\nprint(sample1.get_text())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d00704125bb85bc816fd1456e539181fd334d44"},"cell_type":"code","source":"# a '^' within square brackets searches anything other than the one on it\n# hence here it matches everything from numbers and punctuations etc , leaving only the words\n\nletters_only = re.sub(\"[^a-zA-Z]\",\" \",sample1.get_text())\nprint(letters_only)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd3ad01bb0aca627e111ff7daa3898ca726c3c90"},"cell_type":"code","source":"# changing all the words to lowercase to create a bag of words later\n\nlower_case = letters_only.lower()\n\n# the whole doc is now split to create an array from which most common words called \"stop words\" will be removed\n\nwords = lower_case.split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e6767d4df38e9da55cf292e1bc4381333be2d14"},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\n\n# most common stopwords used in english language\n\nprint(stopwords.words(\"english\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aeb602dfdd189f485bad1c9a44bb2fd7d273d9c9"},"cell_type":"code","source":"# removing  stopwords from sample1 so that relevant words can be filtered out and stored in words\n\nwords = [w for w in words if w not in stopwords.words(\"english\")]\nprint(words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f8e60a820136e6e6ee5bdaefda48c951bf921ef"},"cell_type":"code","source":"# the above code cleans only one review , let's make a function to clean all the reviews\ndef review_to_words(raw_review):\n    #remove html using BeautifulSoup\n    review_text = BeautifulSoup(raw_review,\"html.parser\").get_text()\n    #removing raw letters,numbers,punctuations\n    letters_only = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n    #creating an array , resolving whitespaces\n    words = letters_only.lower().split()\n    #create an array of stopwords so that we don't have to access corpus to search for a stopword\n    stop = set(stopwords.words(\"english\"))\n    #removing stopwords from the raw_review\n    meaningful_words = [w for w in words if w not in stop]\n    #return a string with only the words that are important\n    return(\" \".join(meaningful_words))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"062263aa01b072f0b87c8faba7193e2dea32aaea"},"cell_type":"code","source":"# finding the number of reviews\nnum_rev = train_data.review.size\nprint(num_rev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8308a764ea156df3882e342cd746aae1d38bfc2"},"cell_type":"code","source":"# storing all cleaned reviews in one place\n\ncleaned_rev = []\nfor i in range(num_rev):\n    cleaned_rev.append(review_to_words(train_data.review[i]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"856c7a0c4ab2dc7cd76729c5b0f08f974e516580"},"cell_type":"markdown","source":"creating bag of words model"},{"metadata":{"trusted":true,"_uuid":"133522cb429245363ceceec0a0025a1fc6efc4a1"},"cell_type":"code","source":"# creating a function, vectorizer to convert the words into vectors\n\nvectorizer = CountVectorizer(analyzer=\"word\",\n                            preprocessor=None,\n                            stop_words=\"english\",\n                            max_features=5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e817e074a574a6e1882ba9755a59d2b2932d1232"},"cell_type":"code","source":"# converting reviews from text into features\n\ntrain_data_features = vectorizer.fit_transform(cleaned_rev)\n\n#change the classifier into array\n\ntrain_data_features = train_data_features.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"372e2f246a7d245f381f04ad9c40ef9ade78d7cc"},"cell_type":"code","source":"X = train_data_features\n\n#dependent variable,y will be 1 for positive and 0 for negative review\n\ny = train_data.sentiment ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4858064859c00fbc1bacf526b44640ab33e526c"},"cell_type":"code","source":"# 25000 rows and 5000 features\n\nprint (X.shape) \nprint (y.shape) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"695ffded042af66a83de305528425099f881dfb0"},"cell_type":"code","source":"# splitting the training data into test and train\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03db2b75d6ea416d6ca70d6ef91f062906e47678"},"cell_type":"code","source":"# Applying MultinomialNaiveBayes for classification \n\nnaive = MultinomialNB()\nclassifier = naive.fit(X_train,y_train)\npredict = classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(predict,y_test)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfb0369ab62f0d7224e7ff3e67190e072027fc6a"},"cell_type":"code","source":"accuracy = cm.trace()/cm.sum()\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40568ef498d9a86deb891482a97a3f69fe3fbdc6"},"cell_type":"code","source":"# loading test data for prediction\n\ntest_data = pd.read_csv(\"../input/testData.tsv\",header=0, delimiter=\"\\t\", quoting=3)\ntest_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0371fc87b05169d2992a7ac373073f48795d34b5"},"cell_type":"code","source":"# preprocessing of test data\n\nnumber_of_review = len(test_data[\"review\"])\nprint(number_of_review)\n\n# removing all punctuations,numbers, etc from test data\n\nclean_review =[]\nfor i in range(number_of_review):\n    clean_review.append(review_to_words(test_data[\"review\"][i]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0df4756a08e3d3cbfd07445560b59c424baebfdf"},"cell_type":"code","source":"# converting text into features and features to array\n\ntest_data_features = vectorizer.fit_transform(clean_review)\ntest_data_features = test_data_features.toarray()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a1b3793ca050e71e55b470619530ae46c7853a7"},"cell_type":"code","source":"# predicting test data by the classifier\n\ny_pred_M = classifier.predict(test_data_features)\n\n# accuracy and f1 score\n\nprint(accuracy_score(y,y_pred_M))\nprint(f1_score(y,y_pred_M))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9feba2e1c19a3fc7f31acf10075d362bc5cb8dde"},"cell_type":"code","source":"# Applying BernolliNaiveBayes Classifier to training data \n\nBernNB = BernoulliNB(binarize = 0.01)\nBernNB.fit(X_train,y_train)\nprint(BernNB)\n\n# applying classifier to the test data\n\ny_pred_B = BernNB.predict(test_data_features)\nprint (accuracy_score(y,y_pred_B))\nprint (f1_score(y,y_pred_B))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13949e2a1a15d9c62dcd946139093fe2bb18f667"},"cell_type":"code","source":"# since accuracy and f1_score are slightly higher in MultinomialNaiveBayes, \n# predicted value of that model is used for the submission.\n\n# Copy the results to a pandas dataframe with an \"id\" column and\n# a \"sentiment\" column\n\noutput = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\": y_pred_M} )\n\n# Use pandas to write the comma-separated output file\n\noutput.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}