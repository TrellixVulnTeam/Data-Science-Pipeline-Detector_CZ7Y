{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Load"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '/kaggle/working/'\ntrain = pd.read_csv(PATH+'labeledTrainData.tsv', delimiter='\\t', quoting=3)\ntest = pd.read_csv(PATH+'testData.tsv', delimiter='\\t', quoting=3)\nunlabeled_train = pd.read_csv(PATH+'unlabeledTrainData.tsv', header=0, delimiter='\\t', quoting=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\nprint(unlabeled_train.shape)\n\nprint(train['review'].size)\nprint(test['review'].size)\nprint(unlabeled_train['review'].size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://github.com/Bligh-Park/Kaggle/raw/main/Word2VecUtil.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from Word2VecUtil import KaggleWord2VecUtility","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KaggleWord2VecUtility.review_to_wordlist(train['review'][0][:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = []\nfor review in train['review']:\n    sentences += KaggleWord2VecUtility.review_to_sentences(\n        review, remove_stopwords=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for review in unlabeled_train['review']:\n    sentences += KaggleWord2VecUtility.review_to_sentences(\n        review, remove_stopwords=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences[0][:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences[1][:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word2Vec 모델을 학습\n전처리를 거쳐 파싱된 문장의 목록으로 모델을 학습시킬 준비가 됨\n### word2vec 모델의 파라미터\n* 아키텍처 : 아키텍처 옵션은 skip-gram(default) 또는 CBOW모델. skip-gram은 느리지만 더 나은 결과가 나옴\n* 학습 알고리즘 : Hierachical softmax(default) 또는 negative 샘플링. 여기서는 기본값이 잘 동작.\n* 빈번하게 등장하는 단어에 대한 다운 샘플링 : Google 문서는 0.00001에서 0.001 사이의 값을 권장한다. 여기에서는 0.001에 가까운 값이 최종 모델의 정확도를 높이는 것으로 보여진다.\n* 단어벡터 차원 : 많은 feature를 사용한다고 항상 좋은 것은 아니지만 대체적으로 좀 더 나은 모델이 된다. 합리적인 값은 수십에서 수백 개가 될 수 있고 여기에서는 300으로 지정.\n* 컨텍스트/창 크기 : 학습 알고리즘이 고려해야 하는 컨텍스트의 단어 수는 얼마나 될까? hierachical softmax를 위해 좀 더 큰 수가 좋지만 10 정도가 적당\n* worker threads : 실행 할 병렬 프로세스의 수로 컴퓨터마다 다르지만 대부분의 시스템에서 4에서 6 사이의 값을 사용\n* 최소 단어 수 : 어휘의 크기를 의미하는 단어로 제한하는 데 도움이 된다. 모든 문서에서 여러번 발생하지 않는 단어는 무시된다. 10에서 100사이가 적당하며 이 경진대회의 데이터는 각 영화가 30개씩 리뷰가 있기 때문에 개별 영화 제목에 너무 많은 중요성이 붙는 것을 피하기 위해 최소 단어 수를 40으로 설정한다. 그 결과 전체 어휘 크기는 약 15,000 단어가 된다. 높은 값은 제한 된 실행시간에 도움이 된다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import logging\nlogging.basicConfig(\n    format='%(asctime)s : %(levelname)s : %(message)s',\n    level=logging.INFO)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 파라미터 값 지정\nnum_features = 300 # 문자 벡터 차원 수\nmin_word_count = 40 # 최소 무자 수\nnum_workers = 4 # 병렬 처리 쓰레드 수\ncontext = 10 # 문자열 창 크기\ndownsampling = 1e-3 # 문자 빈도 수 downsample\n\n# 초기화 및 모델 학습\nfrom gensim.models import word2vec\n\n# 모델 학습\nmodel = word2vec.Word2Vec(sentences,\n                         workers=num_workers,\n                         size=num_features,\n                         min_count=min_word_count,\n                         window=context,\n                         sample=downsampling)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 학습 완료 후 필요없는 메모리 unload\nmodel.init_sims(replace=True)\n\nmodel_name = '300features_40minwords_10text'\n\nmodel.save(model_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 모델 결과 탐색"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 유사도가 없는 단어 추출\nmodel.wv.doesnt_match('man woman child kitchen'.split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.doesnt_match('france england germany berlin'.split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 가장 유사한 단어를 추출\nmodel.wv.most_similar('man')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('queen')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vocab 에 없는 단어 테스트\nmodel.wv.most_similar('awful')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('film')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('happy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stemming 되어 있는 것 고려\nmodel.wv.most_similar('happi')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word2Vec으로 벡터화한 단어를 t-SNE를 통해 시각화"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport gensim\nimport gensim.models as g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\nmpl.rcParams['axes.unicode_minus'] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = '300features_40minwords_10text'\nmodel = g.Doc2Vec.load(model_name)\n\nvocab = list(model.wv.vocab)\nX = model[vocab]\n\nprint(len(X))\nprint(X[0][:10])\ntsne = TSNE(n_components=2)\n\n# 100개의 단어에 대해서만 시각화\nX_tsne = tsne.fit_transform(X[:100, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(X_tsne, index=vocab[:100], columns=['x', 'y'])\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.set_size_inches(40, 20)\nax = fig.add_subplot(1, 1, 1)\n\nax.scatter(df['x'], df['y'])\n\nfor word, pos in df.iterrows():\n    ax.annotate(word, pos, fontsize=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ndef makeFeatureVec(words, model, num_features):\n    '''\n    주어진 문장에서 단어 벡터의 평균을 구하는 함수\n    '''\n    # 속도를 위해 0으로 채운 배열을 초기화\n    featureVec = np.zeros((num_features,), dtype='float32')\n    \n    nwords = 0.\n    # Index2word는 모델의 사전에 있는 단어명을 담은 리스트이다.\n    # 속도를 위해 set 형태로 초기화 한다.\n    index2word_set = set(model.wv.index2word)\n    \n    # 루프를 돌며 모델 사전에 포함이 되는 단어라면 피처에 추가한다.\n    for word in words:\n        if word in index2word_set:\n            nwords = nwords + 1.\n            featureVec = np.add(featureVec, model[word])\n    \n    # 결과를 단어수로 나누어 평균을 구한다.\n    featureVec = np.divide(featureVec, nwords)\n    return featureVec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getAvgFeatureVecs(reviews, model, num_features):\n    # 리뷰 단어 목록의 각각에 대한 평균 feature 벡터를 계산하고\n    # 2D numpy 배열을 반환한다.\n    \n    # 카운터를 초기화\n    counter = 0.\n    # 속도를 내기 위해 2d 넘파이 배열을 미리 할당\n    reviewFeatureVecs = np.zeros(\n        (len(reviews), num_features), dtype='float32')\n    \n    for review in reviews:\n        # 매 1000개 리뷰마다 상태를 출력\n        if counter%1000. == 0.:\n            print('Review %d of %d' % (counter, len(reviews)))\n        # 평균 피처 벡트를 만들기 우해 위에서 정의한 함수를 호출\n        reviewFeatureVecs[int(counter)] = makeFeatureVec(review, model, \\\n                                                        num_features)\n        # 카운터를 증가\n        counter = counter + 1.\n    return reviewFeatureVecs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 멀티스레드로 4개의 워커를 사용해 처리한다.\ndef getCleanReviews(reviews):\n    clean_reviews = []\n    clean_reviews = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n            reviews['review'], KaggleWord2VecUtility.review_to_wordlist,\\\n            workers=4)\n    return clean_reviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\ntrainDataVecs = getAvgFeatureVecs(\\\n    getCleanReviews(train), model, num_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\ntestDataVecs = getAvgFeatureVecs(\\\n    getCleanReviews(test), model, num_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomForest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(\n    n_estimators=100, n_jobs=-1, random_state=2018)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nforest = forest.fit(trainDataVecs, train['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n%time\nscore = np.mean(cross_val_score(\\\n        forest, trainDataVecs, \\\n        train['sentiment'], cv=10, scoring='roc_auc'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = forest.predict(testDataVecs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 캐글 제출 파일 생성"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\noutput.to_csv('Word2Vec_AverageVEctors_{0:.5f}.csv'.format(score),\n             index=False, quoting=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 결과 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_sentiment = output['sentiment'].value_counts()\nprint(output_sentiment[0] - output_sentiment[1])\noutput_sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\n\nfig, axes = plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsns.countplot(train['sentiment'], ax=axes[0])\nsns.countplot(output['sentiment'], ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}