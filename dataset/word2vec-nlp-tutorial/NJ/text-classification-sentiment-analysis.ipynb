{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook we are working with a dataset of IMDB reviews. We heavily make use of the tutorial given with the competition. We want to perform sentiment analysis i.e. is a given review positive or negative? "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the libraries we need. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nnltk.download('brown')\nfrom nltk.corpus import stopwords\nfrom collections import Counter ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip', compression='zip',header=0,delimiter='\\t',quoting=0, doublequote=False, escapechar='\\\\')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training data has 3 columns: id, sentiment and review. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning and Text Preprocessing\n\nLet's look at a few reviews. It will give us some insight on what needs to be cleaned up in the text. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['review'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['review'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['review'][2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A few things we observe: HTML tags, and both upper- and lower-case are used. Also, there are still some backslashes appearing before some possession apostrophes. \n\n1) We will use the BeautifulSoup package to remove the HTML tags as this is good practice compared to using a regular expressions. \n\n2) We will remove all punctuation. Although text like !!! and :( do convey sentiment, since this is our first attempt at sentiment analysis, for simplicity, we will remove all punctuation. However, we will treat numbers as words and retain them.\n\n3) We will get rid of stop words. These are words that are used very often but do not convey any important information e.g. of, to, in, on etc. \n\n4) We will normalize the text by converting everything to lower-case."},{"metadata":{"trusted":true},"cell_type":"code","source":"def review_to_words(review):\n    html_removed = BeautifulSoup(review).get_text()\n    punctuation_removed = re.sub('[^a-zA-Z0-9]',' ',str(html_removed))\n    lower_case = punctuation_removed.lower()\n    words = lower_case.split()\n    #Searching sets in python is much faster than searching lists\n    stops = set(stopwords.words(\"english\"))\n    words = [w for w in words if not w in stops] \n    return( \" \".join(words ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_review = review_to_words( df_train['review'][0] )\nprint(df_train['review'][0])\nprint(processed_review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"processed_reviews = []\nfor i in range(0,df_train['review'].size):\n    processed_reviews.append(review_to_words(df_train['review'][i]))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using Bag of Words to create Features \n\nHow many total distinct words are we left with after preprocessing? "},{"metadata":{"trusted":true},"cell_type":"code","source":"words = []\n\nfor review in processed_reviews:\n    for w in review.split():\n        words.append(w)\n\nprint(words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(words))\nprint(len(set(words)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are over 75000 unique words, therefore we will use only the most frequent 5000 words. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}