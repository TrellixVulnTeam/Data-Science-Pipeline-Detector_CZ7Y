{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:49:34.294825Z","iopub.execute_input":"2021-12-30T12:49:34.295179Z","iopub.status.idle":"2021-12-30T12:49:34.30684Z","shell.execute_reply.started":"2021-12-30T12:49:34.295117Z","shell.execute_reply":"2021-12-30T12:49:34.30621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re \nimport nltk\nfrom nltk.corpus import stopwords\nfrom bs4 import BeautifulSoup  \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain = pd.read_csv(\"/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\", delimiter = \"\\t\")\ntest = pd.read_csv(\"/kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip\", delimiter = \"\\t\")\n\ntrain.shape\ntest.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:51:37.180626Z","iopub.execute_input":"2021-12-30T12:51:37.181125Z","iopub.status.idle":"2021-12-30T12:51:38.419222Z","shell.execute_reply.started":"2021-12-30T12:51:37.181092Z","shell.execute_reply":"2021-12-30T12:51:38.418473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_data(data): \n    num_reviews = data[\"review\"].size\n    data_reviews_clean = []\n    for i in range(0, num_reviews): \n        review_text = BeautifulSoup(data[\"review\"][i]).get_text() \n        letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n        words = letters_only.lower().split()        \n        stopwordss = set(stopwords.words(\"english\"))                  \n        meaningful_words = [w for w in words if not w in stopwordss]  \n\n        data_reviews_clean.append(\" \".join(meaningful_words))\n        \n    return data_reviews_clean;","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:51:57.298014Z","iopub.execute_input":"2021-12-30T12:51:57.298305Z","iopub.status.idle":"2021-12-30T12:51:57.305212Z","shell.execute_reply.started":"2021-12-30T12:51:57.298268Z","shell.execute_reply":"2021-12-30T12:51:57.304471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean = clean_data(train)\nvector_train = CountVectorizer(analyzer = \"word\",tokenizer = None, preprocessor = None,stop_words = None, max_features = 10000)\ntrain_features = vector_train.fit_transform(train_clean)   \ntrain_features = train_features.toarray()\n\nforest_clf = RandomForestClassifier(n_estimators = 150)  \nforest_clf.fit(train_features,train[\"sentiment\"])\n\ntest_clean = clean_data(test)\n\nvector_test = vector_train.transform(test_clean)\ntest_features = vector_test.toarray()\n\nresult = forest_clf.predict(test_features)\nresult","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:57:54.686198Z","iopub.execute_input":"2021-12-30T12:57:54.686635Z","iopub.status.idle":"2021-12-30T13:01:16.541457Z","shell.execute_reply.started":"2021-12-30T12:57:54.686603Z","shell.execute_reply":"2021-12-30T13:01:16.540746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:01:48.878047Z","iopub.execute_input":"2021-12-30T13:01:48.878331Z","iopub.status.idle":"2021-12-30T13:01:48.893338Z","shell.execute_reply.started":"2021-12-30T13:01:48.878302Z","shell.execute_reply":"2021-12-30T13:01:48.892566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsubmission.to_csv( \"submission.csv\", index=False, quoting=3 )","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:01:52.821381Z","iopub.execute_input":"2021-12-30T13:01:52.821707Z","iopub.status.idle":"2021-12-30T13:01:52.857101Z","shell.execute_reply.started":"2021-12-30T13:01:52.821669Z","shell.execute_reply":"2021-12-30T13:01:52.856203Z"},"trusted":true},"execution_count":null,"outputs":[]}]}