{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd \nimport re\nfrom sklearn.ensemble import RandomForestClassifier\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\ntrain_data = pd.read_csv(\"../input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\", header=0, delimiter=\"\\t\", quoting=3)\ntest_data = pd.read_csv(\"../input/word2vec-nlp-tutorial/testData.tsv.zip\", header=0, delimiter=\"\\t\", quoting=3 )\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ntrain_data.shape\ntest_data.shape\n\n\ndef rew(r_rew):\n    rev_text = BeautifulSoup(r_rew).get_text()\n    l = re.sub(\"[^a-zA-Z]\", \" \", rev_text)\n    low_case = l.lower()\n    words = low_case.split()\n    stop = set(stopwords.words(\"english\"))\n    words_n = [word for word in words if not word in stop]\n    return( \" \".join(words_n))\ndef clean(data):\n    clean = []\n    size = data[\"review\"].size\n    for i in range( 0, size): \n        clean.append(rew(data[\"review\"][i]))\n    return clean\nstr_words = rew(train_data[\"review\"][0])\nstr_words\nfrom sklearn.feature_extraction.text import CountVectorizer\ntrain_clean = clean(train_data)\n\nvector = CountVectorizer(analyzer = \"word\",tokenizer = None, preprocessor = None,stop_words = None, max_features = 20000)\ntrain_vector = vector.fit_transform(train_clean)\ntrain_vector\n\nvoc = vector.get_feature_names()\nvoc\ntrain_vector.shape\ntrain_data['sentiment'].shape\n\nclf = RandomForestClassifier(n_estimators = 110) \nmas_train = train_vector.toarray()\nclf.fit(mas_train,train_data[\"sentiment\"])\n\ntest_clean = clean(test_data)\n\ntest_vector = vector.transform(test_clean)\ntest_array = test_vector.toarray()\n\nresult = clf.predict(test_array)\nsub = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\":result} )\nsub.to_csv( \"submission.csv\", index=False, quoting=3 )","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T14:07:19.48807Z","iopub.execute_input":"2021-12-18T14:07:19.488387Z","iopub.status.idle":"2021-12-18T14:11:29.39986Z","shell.execute_reply.started":"2021-12-18T14:07:19.488355Z","shell.execute_reply":"2021-12-18T14:11:29.398785Z"},"trusted":true},"execution_count":null,"outputs":[]}]}