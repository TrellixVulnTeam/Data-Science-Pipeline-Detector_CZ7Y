{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nnltk.download(\"all\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-12T01:57:19.411374Z","iopub.execute_input":"2021-09-12T01:57:19.411785Z","iopub.status.idle":"2021-09-12T01:57:40.76915Z","shell.execute_reply.started":"2021-09-12T01:57:19.411699Z","shell.execute_reply":"2021-09-12T01:57:40.768385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install beautifulsoup4","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:57:40.771874Z","iopub.execute_input":"2021-09-12T01:57:40.77212Z","iopub.status.idle":"2021-09-12T01:57:49.691506Z","shell.execute_reply.started":"2021-09-12T01:57:40.772095Z","shell.execute_reply":"2021-09-12T01:57:49.690587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unzip folders","metadata":{}},{"cell_type":"code","source":"!unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\n!unzip  /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:57:49.695072Z","iopub.execute_input":"2021-09-12T01:57:49.695344Z","iopub.status.idle":"2021-09-12T01:57:53.08209Z","shell.execute_reply.started":"2021-09-12T01:57:49.695314Z","shell.execute_reply":"2021-09-12T01:57:53.081187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read the data","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv(\"./labeledTrainData.tsv\",delimiter=\"\\t\",quoting=3)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:58:31.520677Z","iopub.execute_input":"2021-09-12T01:58:31.521041Z","iopub.status.idle":"2021-09-12T01:58:31.832024Z","shell.execute_reply.started":"2021-09-12T01:58:31.521007Z","shell.execute_reply":"2021-09-12T01:58:31.830989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, \"header=0\" indicates that the first line of the file contains column names, \"delimiter=\\t\" indicates that the fields are separated by tabs, and quoting=3 tells Python to ignore doubled quotes, otherwise you may encounter errors trying to read the file.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:58:32.565696Z","iopub.execute_input":"2021-09-12T01:58:32.566019Z","iopub.status.idle":"2021-09-12T01:58:32.58822Z","shell.execute_reply.started":"2021-09-12T01:58:32.565991Z","shell.execute_reply":"2021-09-12T01:58:32.587288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sample review\nprint(train['review'][0])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T01:58:48.17008Z","iopub.execute_input":"2021-09-12T01:58:48.170414Z","iopub.status.idle":"2021-09-12T01:58:48.177312Z","shell.execute_reply.started":"2021-09-12T01:58:48.170383Z","shell.execute_reply":"2021-09-12T01:58:48.176432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Pre processing Pipeline","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nstopwords=stopwords.words(\"english\")\n\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:00:02.002439Z","iopub.execute_input":"2021-09-12T02:00:02.002812Z","iopub.status.idle":"2021-09-12T02:00:02.010115Z","shell.execute_reply.started":"2021-09-12T02:00:02.002778Z","shell.execute_reply":"2021-09-12T02:00:02.008957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_tweets(raw_text,stopwords=stopwords):\n    '''Golden function for cleaning text data'''\n    \n    # Removing HTML Tags\n    html_removed_text=BeautifulSoup(raw_text).get_text()\n    \n    # Remove any non character\n    character_only_text=re.sub(\"[^a-zA-Z]\",\" \",html_removed_text)\n    \n    # Lowercase and split\n    lower_text=character_only_text.lower().split()\n    \n    #Get STOPWORDS and remove\n    stop_remove_text=[i for i in lower_text if not i in stopwords]\n    \n    #Lemmatization\n    lemma_removed_text=[wordnet_lemmatizer.lemmatize(word,'v') for word in stop_remove_text]\n    \n    # Remove one character words\n#     lemma_removed_text=[word for word in stop_remove_text if len(word)>1]\n    \n    return \" \".join(lemma_removed_text)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:11:17.560171Z","iopub.execute_input":"2021-09-12T03:11:17.560495Z","iopub.status.idle":"2021-09-12T03:11:17.568806Z","shell.execute_reply.started":"2021-09-12T03:11:17.560466Z","shell.execute_reply":"2021-09-12T03:11:17.567951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check on sample\ntrain.loc[:1,\"review\"].apply(clean_tweets)[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:11:24.465469Z","iopub.execute_input":"2021-09-12T03:11:24.465833Z","iopub.status.idle":"2021-09-12T03:11:24.480192Z","shell.execute_reply.started":"2021-09-12T03:11:24.465802Z","shell.execute_reply":"2021-09-12T03:11:24.479438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# orginal Review\ntrain.loc[0,\"review\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:11:24.77679Z","iopub.execute_input":"2021-09-12T03:11:24.777104Z","iopub.status.idle":"2021-09-12T03:11:24.783444Z","shell.execute_reply.started":"2021-09-12T03:11:24.777076Z","shell.execute_reply":"2021-09-12T03:11:24.78236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['clean_review']=train['review'].apply(clean_tweets)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:11:25.353445Z","iopub.execute_input":"2021-09-12T03:11:25.353981Z","iopub.status.idle":"2021-09-12T03:12:03.613351Z","shell.execute_reply.started":"2021-09-12T03:11:25.35394Z","shell.execute_reply":"2021-09-12T03:12:03.612542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:03.61476Z","iopub.execute_input":"2021-09-12T03:12:03.615085Z","iopub.status.idle":"2021-09-12T03:12:03.627896Z","shell.execute_reply.started":"2021-09-12T03:12:03.61505Z","shell.execute_reply":"2021-09-12T03:12:03.626789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nword_counter=Counter(\" \".join(train['clean_review'].tolist()).split())","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:03.630275Z","iopub.execute_input":"2021-09-12T03:12:03.63073Z","iopub.status.idle":"2021-09-12T03:12:04.348421Z","shell.execute_reply.started":"2021-09-12T03:12:03.630693Z","shell.execute_reply":"2021-09-12T03:12:04.34759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_counter.most_common(4)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:04.349994Z","iopub.execute_input":"2021-09-12T03:12:04.350323Z","iopub.status.idle":"2021-09-12T03:12:04.375022Z","shell.execute_reply.started":"2021-09-12T03:12:04.350287Z","shell.execute_reply":"2021-09-12T03:12:04.374117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Top Words in negative reviews\nnegative_word_counter=Counter(\" \".join(train.loc[train['sentiment']==1,\"clean_review\"].tolist()).split())\n\n#Top words in positive reviews\npositive_word_counter=Counter(\" \".join(train.loc[train['sentiment']==0,\"clean_review\"].tolist()).split())","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:04.376284Z","iopub.execute_input":"2021-09-12T03:12:04.37689Z","iopub.status.idle":"2021-09-12T03:12:04.996619Z","shell.execute_reply.started":"2021-09-12T03:12:04.376828Z","shell.execute_reply":"2021-09-12T03:12:04.995748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_word_counter.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:04.99788Z","iopub.execute_input":"2021-09-12T03:12:04.998281Z","iopub.status.idle":"2021-09-12T03:12:05.016906Z","shell.execute_reply.started":"2021-09-12T03:12:04.998237Z","shell.execute_reply":"2021-09-12T03:12:05.016224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_word_counter.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:05.01813Z","iopub.execute_input":"2021-09-12T03:12:05.018477Z","iopub.status.idle":"2021-09-12T03:12:05.035978Z","shell.execute_reply.started":"2021-09-12T03:12:05.018443Z","shell.execute_reply":"2021-09-12T03:12:05.035206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Baseline Model\n# If you are seeing a high overlap in unigram between two categories(here its positive or negative)\n# Then the next thing you should try is to look for bigrams or trigrams","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:05.038658Z","iopub.execute_input":"2021-09-12T03:12:05.039102Z","iopub.status.idle":"2021-09-12T03:12:05.044029Z","shell.execute_reply.started":"2021-09-12T03:12:05.039062Z","shell.execute_reply":"2021-09-12T03:12:05.042995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bag of Words - Model\n\n## Count Vectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:05.045933Z","iopub.execute_input":"2021-09-12T03:12:05.046398Z","iopub.status.idle":"2021-09-12T03:12:05.052674Z","shell.execute_reply.started":"2021-09-12T03:12:05.046364Z","shell.execute_reply":"2021-09-12T03:12:05.051521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the data","metadata":{}},{"cell_type":"code","source":"X=train['clean_review'] #Predictors\ny=train['sentiment'] #Target","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:05.05399Z","iopub.execute_input":"2021-09-12T03:12:05.054361Z","iopub.status.idle":"2021-09-12T03:12:05.061478Z","shell.execute_reply.started":"2021-09-12T03:12:05.054324Z","shell.execute_reply":"2021-09-12T03:12:05.060454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:05.064225Z","iopub.execute_input":"2021-09-12T03:12:05.064513Z","iopub.status.idle":"2021-09-12T03:12:05.074978Z","shell.execute_reply.started":"2021-09-12T03:12:05.06449Z","shell.execute_reply":"2021-09-12T03:12:05.074231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_vector(vectorizer,data):\n    '''Pass vectorizer and data'''\n    train_vector=vectorizer.transform(data.tolist())\n    return train_vector.toarray()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:05.076307Z","iopub.execute_input":"2021-09-12T03:12:05.076847Z","iopub.status.idle":"2021-09-12T03:12:05.081594Z","shell.execute_reply.started":"2021-09-12T03:12:05.07681Z","shell.execute_reply":"2021-09-12T03:12:05.08039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer(max_features=1000)\nvectorizer.fit(X_train.tolist())","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:05.083128Z","iopub.execute_input":"2021-09-12T03:12:05.083694Z","iopub.status.idle":"2021-09-12T03:12:07.264189Z","shell.execute_reply.started":"2021-09-12T03:12:05.083659Z","shell.execute_reply":"2021-09-12T03:12:07.263399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_vector=create_vector(vectorizer,X_train)\nX_test_vector=create_vector(vectorizer,X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:07.265397Z","iopub.execute_input":"2021-09-12T03:12:07.265769Z","iopub.status.idle":"2021-09-12T03:12:10.658179Z","shell.execute_reply.started":"2021-09-12T03:12:07.26573Z","shell.execute_reply":"2021-09-12T03:12:10.657309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_vector.shape, X_train_vector.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:10.65941Z","iopub.execute_input":"2021-09-12T03:12:10.659783Z","iopub.status.idle":"2021-09-12T03:12:10.667961Z","shell.execute_reply.started":"2021-09-12T03:12:10.659748Z","shell.execute_reply":"2021-09-12T03:12:10.667061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create ML Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# TRY with XGBOOST,SVM","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:39:26.056099Z","iopub.execute_input":"2021-09-12T02:39:26.056506Z","iopub.status.idle":"2021-09-12T02:39:26.063342Z","shell.execute_reply.started":"2021-09-12T02:39:26.056469Z","shell.execute_reply":"2021-09-12T02:39:26.062287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest=RandomForestClassifier()\nforest.fit(X_train_vector,y_train)\n\n\ny_pred=forest.predict(X_test_vector)\nprint(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:39:26.064897Z","iopub.execute_input":"2021-09-12T02:39:26.065421Z","iopub.status.idle":"2021-09-12T02:39:34.800006Z","shell.execute_reply.started":"2021-09-12T02:39:26.065386Z","shell.execute_reply":"2021-09-12T02:39:34.798412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets make a submission","metadata":{}},{"cell_type":"code","source":"test=pd.read_csv(\"./testData.tsv\",delimiter=\"\\t\")\ntest['clean_review']=test['review'].apply(clean_tweets)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:39:34.801311Z","iopub.execute_input":"2021-09-12T02:39:34.801672Z","iopub.status.idle":"2021-09-12T02:40:11.30662Z","shell.execute_reply.started":"2021-09-12T02:39:34.801634Z","shell.execute_reply":"2021-09-12T02:40:11.30576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_feature_vector=create_vector(vectorizer,test['clean_review'])\ntest_predictions=forest.predict(test_feature_vector)\n\ntest['sentiment']=test_predictions\ntest[['id','sentiment']].to_csv(\"submission_file_rf_count.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:40:11.307918Z","iopub.execute_input":"2021-09-12T02:40:11.308257Z","iopub.status.idle":"2021-09-12T02:40:15.580865Z","shell.execute_reply.started":"2021-09-12T02:40:11.308221Z","shell.execute_reply":"2021-09-12T02:40:15.579941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TFIDF Vectorizer","metadata":{}},{"cell_type":"code","source":"# ----- PLEASE TRY THIS ------","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:40:15.582251Z","iopub.execute_input":"2021-09-12T02:40:15.582834Z","iopub.status.idle":"2021-09-12T02:40:15.586622Z","shell.execute_reply.started":"2021-09-12T02:40:15.582795Z","shell.execute_reply":"2021-09-12T02:40:15.585824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word2Vec Model","metadata":{}},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\ntrain_unlabelled=pd.read_csv(\"./unlabeledTrainData.tsv\",delimiter=\"\\t\",quoting=3)\ntrain_unlabelled['clean_review']=train_unlabelled['review'].apply(clean_tweets)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:12:10.669242Z","iopub.execute_input":"2021-09-12T03:12:10.669782Z","iopub.status.idle":"2021-09-12T03:13:26.615102Z","shell.execute_reply.started":"2021-09-12T03:12:10.669732Z","shell.execute_reply":"2021-09-12T03:13:26.614159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences=[]\nsentences.extend(train['clean_review'])\nsentences.extend(test['clean_review'])\nsentences.extend(train_unlabelled['clean_review'])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:13:26.619362Z","iopub.execute_input":"2021-09-12T03:13:26.621377Z","iopub.status.idle":"2021-09-12T03:13:26.65841Z","shell.execute_reply.started":"2021-09-12T03:13:26.621337Z","shell.execute_reply":"2021-09-12T03:13:26.657518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove duplicate sentences,if any\nsentences=list(set(sentences))","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:13:26.662692Z","iopub.execute_input":"2021-09-12T03:13:26.664821Z","iopub.status.idle":"2021-09-12T03:13:26.754464Z","shell.execute_reply.started":"2021-09-12T03:13:26.664778Z","shell.execute_reply":"2021-09-12T03:13:26.753658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sentences)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:13:26.75568Z","iopub.execute_input":"2021-09-12T03:13:26.760481Z","iopub.status.idle":"2021-09-12T03:13:26.768405Z","shell.execute_reply.started":"2021-09-12T03:13:26.760432Z","shell.execute_reply":"2021-09-12T03:13:26.767548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train a custom word2vec model","metadata":{}},{"cell_type":"markdown","source":"## The parameters:\n\n* `min_count` <font color='purple'>=</font> <font color='green'>int</font> - Ignores all words with total absolute frequency lower than this - (2, 100)\n\n\n* `window` <font color='purple'>=</font> <font color='green'>int</font> - The maximum distance between the current and predicted word within a sentence. E.g. `window` words on the left and `window` words on the left of our target - (2, 10)\n\n\n* `size` <font color='purple'>=</font> <font color='green'>int</font> - Dimensionality of the feature vectors. - (50, 300)\n\n\n* `sample` <font color='purple'>=</font> <font color='green'>float</font> - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial.  - (0, 1e-5)\n\n\n* `alpha` <font color='purple'>=</font> <font color='green'>float</font> - The initial learning rate - (0.01, 0.05)\n\n\n* `min_alpha` <font color='purple'>=</font> <font color='green'>float</font> - Learning rate will linearly drop to `min_alpha` as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n\n\n* `negative` <font color='purple'>=</font> <font color='green'>int</font> - If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n\n\n* `workers` <font color='purple'>=</font> <font color='green'>int</font> - Use these many worker threads to train the model (=faster training with multicore machines)","metadata":{}},{"cell_type":"code","source":"sentences=[i.split() for i in sentences]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:14:03.700132Z","iopub.execute_input":"2021-09-12T03:14:03.700474Z","iopub.status.idle":"2021-09-12T03:14:05.532918Z","shell.execute_reply.started":"2021-09-12T03:14:03.700439Z","shell.execute_reply":"2021-09-12T03:14:05.532028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:14:05.534442Z","iopub.execute_input":"2021-09-12T03:14:05.53481Z","iopub.status.idle":"2021-09-12T03:14:05.543987Z","shell.execute_reply.started":"2021-09-12T03:14:05.534772Z","shell.execute_reply":"2021-09-12T03:14:05.543033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Beginner\ndel w2v_model\nw2v_model = Word2Vec(sentences=sentences,min_count=20,\n                     window=2,\n                     vector_size=100,\n                     workers=-1)\nw2v_model.wv.most_similar(\"great\")","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:14:06.591863Z","iopub.execute_input":"2021-09-12T03:14:06.592176Z","iopub.status.idle":"2021-09-12T03:14:10.249564Z","shell.execute_reply.started":"2021-09-12T03:14:06.592147Z","shell.execute_reply":"2021-09-12T03:14:10.178857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For Advance users , we create in three steps\nimport multiprocessing\ncores = multiprocessing.cpu_count()\n\nw2v_model = Word2Vec(min_count=20,\n                     window=2,\n                     vector_size=300,\n                     sample=6e-5, \n                     alpha=0.03, \n                     min_alpha=0.0007, \n                     negative=20,\n                     workers=cores-1)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:14:32.064632Z","iopub.execute_input":"2021-09-12T03:14:32.064948Z","iopub.status.idle":"2021-09-12T03:14:32.071849Z","shell.execute_reply.started":"2021-09-12T03:14:32.06492Z","shell.execute_reply":"2021-09-12T03:14:32.070738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# w2v_model = Word2Vec(min_count=20,\n#                      window=2,\n#                      vector_size=300,\n#                      sample=6e-5, \n#                      alpha=0.03, \n#                      min_alpha=0.0007, \n# #                      negative=20,\n#                      workers=-1)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:55:16.255929Z","iopub.execute_input":"2021-09-12T02:55:16.256251Z","iopub.status.idle":"2021-09-12T02:55:16.263976Z","shell.execute_reply.started":"2021-09-12T02:55:16.256219Z","shell.execute_reply":"2021-09-12T02:55:16.263032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the Vocabulary Table:\nWord2Vec requires us to build the vocabulary table (simply digesting all the words and filtering out the unique words, and doing some basic counts on them):","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from time import time\nt = time()\n\nw2v_model.build_vocab(sentences, progress_per=10000)\n\nprint('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:14:36.943835Z","iopub.execute_input":"2021-09-12T03:14:36.944147Z","iopub.status.idle":"2021-09-12T03:14:39.767416Z","shell.execute_reply.started":"2021-09-12T03:14:36.944119Z","shell.execute_reply":"2021-09-12T03:14:39.766519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training of the model:\n_Parameters of the training:_\n* `total_examples` <font color='purple'>=</font> <font color='green'>int</font> - Count of sentences;\n* `epochs` <font color='purple'>=</font> <font color='green'>int</font> - Number of iterations (epochs) over the corpus - [10, 20, 30]","metadata":{}},{"cell_type":"code","source":"t = time()\n\nw2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=10, report_delay=1)\n\nprint('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:14:47.605448Z","iopub.execute_input":"2021-09-12T03:14:47.605809Z","iopub.status.idle":"2021-09-12T03:23:31.477244Z","shell.execute_reply.started":"2021-09-12T03:14:47.605776Z","shell.execute_reply":"2021-09-12T03:23:31.476319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.most_similar(\"leave\")","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:23:31.479496Z","iopub.execute_input":"2021-09-12T03:23:31.479861Z","iopub.status.idle":"2021-09-12T03:23:31.52207Z","shell.execute_reply.started":"2021-09-12T03:23:31.479825Z","shell.execute_reply":"2021-09-12T03:23:31.521186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.most_similar(positive=[\"home\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:26:35.745935Z","iopub.execute_input":"2021-09-12T03:26:35.746268Z","iopub.status.idle":"2021-09-12T03:26:35.759967Z","shell.execute_reply.started":"2021-09-12T03:26:35.746239Z","shell.execute_reply":"2021-09-12T03:26:35.759009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.similarity(\"stupid\", 'worse')","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:26:42.413941Z","iopub.execute_input":"2021-09-12T03:26:42.414272Z","iopub.status.idle":"2021-09-12T03:26:42.424345Z","shell.execute_reply.started":"2021-09-12T03:26:42.414242Z","shell.execute_reply":"2021-09-12T03:26:42.42351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv.doesnt_match(['great', 'stupid', 'good'])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T02:41:58.328645Z","iopub.execute_input":"2021-09-12T02:41:58.32899Z","iopub.status.idle":"2021-09-12T02:41:58.339112Z","shell.execute_reply.started":"2021-09-12T02:41:58.32896Z","shell.execute_reply":"2021-09-12T02:41:58.338109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### t-SNE visualizations:\nt-SNE is a non-linear dimensionality reduction algorithm that attempts to represent high-dimensional data and the underlying relationships between vectors in a lower-dimensional space.<br>\nHere is a good tutorial on it: https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n \nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:26:54.195361Z","iopub.execute_input":"2021-09-12T03:26:54.195722Z","iopub.status.idle":"2021-09-12T03:26:54.204303Z","shell.execute_reply.started":"2021-09-12T03:26:54.195691Z","shell.execute_reply":"2021-09-12T03:26:54.203259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our goal in this section is to plot our 300 dimensions vectors into 2 dimensional graphs, and see if we can spot interesting patterns.<br>\nFor that we are going to use t-SNE implementation from scikit-learn.\n\nTo make the visualizations more relevant, we will look at the relationships between a query word (in <font color='red'>**red**</font>), its most similar words in the model (in <font color=\"blue\">**blue**</font>), and other words from the vocabulary (in <font color='green'>**green**</font>).","metadata":{}},{"cell_type":"code","source":"def tsnescatterplot(model, word, list_names):\n    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n    its list of most similar words, and a list of words.\n    \"\"\"\n    arrays = np.empty((0, 300), dtype='f')\n    word_labels = [word]\n    color_list  = ['red']\n\n    # adds the vector of the query word\n    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n    \n    # gets list of most similar words\n    close_words = model.wv.most_similar([word])\n    \n    # adds the vector for each of the closest words to the array\n    for wrd_score in close_words:\n        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n        word_labels.append(wrd_score[0])\n        color_list.append('blue')\n        arrays = np.append(arrays, wrd_vector, axis=0)\n    \n    # adds the vector for each of the words from list_names to the array\n    for wrd in list_names:\n        wrd_vector = model.wv.__getitem__([wrd])\n        word_labels.append(wrd)\n        color_list.append('green')\n        arrays = np.append(arrays, wrd_vector, axis=0)\n        \n    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n    reduc = PCA(n_components=14,svd_solver='full').fit_transform(arrays)\n    \n    # Finds t-SNE coordinates for 2 dimensions\n    np.set_printoptions(suppress=True)\n    \n    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n    \n    # Sets everything up to plot\n    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n                       'y': [y for y in Y[:, 1]],\n                       'words': word_labels,\n                       'color': color_list})\n    \n    fig, _ = plt.subplots()\n    fig.set_size_inches(9, 9)\n    \n    # Basic plot\n    p1 = sns.regplot(data=df,\n                     x=\"x\",\n                     y=\"y\",\n                     fit_reg=False,\n                     marker=\"o\",\n                     scatter_kws={'s': 40,\n                                  'facecolors': df['color']\n                                 }\n                    )\n    \n    # Adds annotations one by one with a loop\n    for line in range(0, df.shape[0]):\n         p1.text(df[\"x\"][line],\n                 df['y'][line],\n                 '  ' + df[\"words\"][line].title(),\n                 horizontalalignment='left',\n                 verticalalignment='bottom', size='medium',\n                 color=df['color'][line],\n                 weight='normal'\n                ).set_size(15)\n\n    \n    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n            \n    plt.title('t-SNE visualization for {}'.format(word.title()))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:26:55.23277Z","iopub.execute_input":"2021-09-12T03:26:55.234295Z","iopub.status.idle":"2021-09-12T03:26:55.254596Z","shell.execute_reply.started":"2021-09-12T03:26:55.234245Z","shell.execute_reply":"2021-09-12T03:26:55.253759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsnescatterplot(w2v_model, 'good',  [i[0] for i in w2v_model.wv.most_similar(positive=[\"bad\"])])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:26:55.939676Z","iopub.execute_input":"2021-09-12T03:26:55.940011Z","iopub.status.idle":"2021-09-12T03:26:56.564778Z","shell.execute_reply.started":"2021-09-12T03:26:55.93998Z","shell.execute_reply":"2021-09-12T03:26:56.563893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features=300\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:13.450969Z","iopub.execute_input":"2021-09-12T03:27:13.451312Z","iopub.status.idle":"2021-09-12T03:27:13.45464Z","shell.execute_reply.started":"2021-09-12T03:27:13.45128Z","shell.execute_reply":"2021-09-12T03:27:13.453755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_vectors(model,sentence):\n    \n    '''Get sentence vectors'''\n    \n    vectors=[]\n    for i in sentence.split():\n        try:\n            vectors.append(model.wv[i])\n        except:\n            continue\n    return np.average(vectors,axis=0)\n            \n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:13.725747Z","iopub.execute_input":"2021-09-12T03:27:13.72607Z","iopub.status.idle":"2021-09-12T03:27:13.730835Z","shell.execute_reply.started":"2021-09-12T03:27:13.726041Z","shell.execute_reply":"2021-09-12T03:27:13.730001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_vectors(w2v_model,\"this is good today okay thats fine\")","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:14.312Z","iopub.execute_input":"2021-09-12T03:27:14.312319Z","iopub.status.idle":"2021-09-12T03:27:14.321725Z","shell.execute_reply.started":"2021-09-12T03:27:14.312289Z","shell.execute_reply":"2021-09-12T03:27:14.320822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model.wv['aayush']","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:15.4063Z","iopub.execute_input":"2021-09-12T03:27:15.406665Z","iopub.status.idle":"2021-09-12T03:27:15.432506Z","shell.execute_reply.started":"2021-09-12T03:27:15.406631Z","shell.execute_reply":"2021-09-12T03:27:15.430307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_vectors(w2v_model,\"aayush is a good actor and prove his skills\")","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:15.879684Z","iopub.execute_input":"2021-09-12T03:27:15.880014Z","iopub.status.idle":"2021-09-12T03:27:15.889349Z","shell.execute_reply.started":"2021-09-12T03:27:15.879987Z","shell.execute_reply":"2021-09-12T03:27:15.888443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_doc_vectors(model,documents,num_features=300):\n    \n    # Initialize a counter\n    counter = 0\n    \n    # Preallocate a 2D numpy array, for speed\n    reviewFeatureVecs = np.zeros((len(documents),num_features),dtype=\"float32\")\n    \n    # Loop through the reviews\n    for sentence in documents:\n        # Print a status message every 1000th review\n        if counter%1000 == 0:\n            print(\"Review %d of %d\" % (counter, len(documents)))\n        # Call the function (defined above) that makes average feature vectors\n        reviewFeatureVecs[counter] = get_vectors(model,sentence)\n        \n        # Increment the counter\n        counter = counter + 1\n    return reviewFeatureVecs\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:16.793753Z","iopub.execute_input":"2021-09-12T03:27:16.794072Z","iopub.status.idle":"2021-09-12T03:27:16.800421Z","shell.execute_reply.started":"2021-09-12T03:27:16.794041Z","shell.execute_reply":"2021-09-12T03:27:16.798991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"documents=[\"hey\",\"hey this\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:18.485931Z","iopub.execute_input":"2021-09-12T03:27:18.486279Z","iopub.status.idle":"2021-09-12T03:27:18.490273Z","shell.execute_reply.started":"2021-09-12T03:27:18.486248Z","shell.execute_reply":"2021-09-12T03:27:18.489199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample\nget_doc_vectors(w2v_model,documents,num_features=300).shape","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:18.864986Z","iopub.execute_input":"2021-09-12T03:27:18.865317Z","iopub.status.idle":"2021-09-12T03:27:18.871496Z","shell.execute_reply.started":"2021-09-12T03:27:18.865284Z","shell.execute_reply":"2021-09-12T03:27:18.8707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_w2v_vectors=get_doc_vectors(w2v_model,X_train,num_features=300)\nX_test_w2v_vectors=get_doc_vectors(w2v_model,X_test,num_features=300)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:19.470261Z","iopub.execute_input":"2021-09-12T03:27:19.470606Z","iopub.status.idle":"2021-09-12T03:27:29.058125Z","shell.execute_reply.started":"2021-09-12T03:27:19.470575Z","shell.execute_reply":"2021-09-12T03:27:29.057205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_w2v_vectors.shape, X_test_w2v_vectors.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:29.059587Z","iopub.execute_input":"2021-09-12T03:27:29.060124Z","iopub.status.idle":"2021-09-12T03:27:29.066217Z","shell.execute_reply.started":"2021-09-12T03:27:29.060082Z","shell.execute_reply":"2021-09-12T03:27:29.065336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest=RandomForestClassifier()\nforest.fit(X_train_w2v_vectors,y_train)\ny_pred=forest.predict(X_test_w2v_vectors)\nprint(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:27:29.067846Z","iopub.execute_input":"2021-09-12T03:27:29.068356Z","iopub.status.idle":"2021-09-12T03:27:53.409661Z","shell.execute_reply.started":"2021-09-12T03:27:29.068314Z","shell.execute_reply":"2021-09-12T03:27:53.40882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pretrained Models","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"1. 1. 1. ","metadata":{}},{"cell_type":"code","source":"import gensim.downloader\nprint(gensim.downloader.info()['models'].keys())","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:01:09.960799Z","iopub.execute_input":"2021-09-12T03:01:09.961202Z","iopub.status.idle":"2021-09-12T03:01:10.174554Z","shell.execute_reply.started":"2021-09-12T03:01:09.961158Z","shell.execute_reply":"2021-09-12T03:01:10.173634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glove_vectors = gensim.downloader.load('glove-twitter-25')","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:01:44.357512Z","iopub.execute_input":"2021-09-12T03:01:44.357877Z","iopub.status.idle":"2021-09-12T03:03:06.565825Z","shell.execute_reply.started":"2021-09-12T03:01:44.357846Z","shell.execute_reply":"2021-09-12T03:03:06.564931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pretrained_vectors(model,sentence):\n    '''Get sentence vectors'''\n    \n    vectors=[]\n    for i in sentence.split():\n        try:\n            vectors.append(model[i])\n        except:\n            continue\n    return np.average(vectors,axis=0)\n            \n    \ndef get_pretrained_models(model,documents,num_features=25):\n    \n    # Initialize a counter\n    counter = 0\n    \n    # Preallocate a 2D numpy array, for speed\n    reviewFeatureVecs = np.zeros((len(documents),num_features),dtype=\"float32\")\n    \n    # Loop through the reviews\n    for sentence in documents:\n        # Print a status message every 1000th review\n        if counter%1000 == 0:\n            print(\"Review %d of %d\" % (counter, len(documents)))\n        # Call the function (defined above) that makes average feature vectors\n        reviewFeatureVecs[counter] = get_pretrained_vectors(model,sentence)\n        \n        # Increment the counter\n        counter = counter + 1\n    return reviewFeatureVecs\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:08:38.452794Z","iopub.execute_input":"2021-09-12T03:08:38.453131Z","iopub.status.idle":"2021-09-12T03:08:38.46124Z","shell.execute_reply.started":"2021-09-12T03:08:38.4531Z","shell.execute_reply":"2021-09-12T03:08:38.460283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_w2v_vectors=get_pretrained_models(glove_vectors,X_train,num_features=25)\nX_test_w2v_vectors=get_pretrained_models(glove_vectors,X_test,num_features=25)\n\nforest=RandomForestClassifier()\nforest.fit(X_train_w2v_vectors,y_train)\ny_pred=forest.predict(X_test_w2v_vectors)\nprint(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-12T03:08:39.688235Z","iopub.execute_input":"2021-09-12T03:08:39.688577Z","iopub.status.idle":"2021-09-12T03:08:55.648626Z","shell.execute_reply.started":"2021-09-12T03:08:39.688523Z","shell.execute_reply":"2021-09-12T03:08:55.647701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference\nhttps://www.kaggle.com/aayushkubba/twitter-sentiment-analysis-word2vec-doc2vec\nhttps://www.kaggle.com/aayushkubba/nlp-word2vec","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}