{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <center> Predict Sentiment Analysis over Movie Reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import necessary packages\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\n#nltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\n# nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten, Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Import dataset\ndf_train = pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv', delimiter='\\t')\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to clean text."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to clean text\ndef clean_text(input_text):\n    \"\"\"\n    Processes the give text and removes all non words, digits, single letters and extra spaces.\n\n    Parameters\n    -----------\n    1. input_text = Text to clean.\n    2. token = 'word' or 'sentence'\n\n    Returns: Text.\n\n    \"\"\"\n\n    text = re.sub(r'\\W',' ', input_text) #Remove all non words\n    text = re.sub(r'\\d+',' ', text) #Remove all digits\n    text = text.lower() #Converting text into lowercase\n    text = re.sub(r'\\s+[a-z]\\s+',' ', text) #Remove all single letters\n    text = re.sub(r'^\\s+','', text) #Remove space from start of text\n    text = re.sub(r'\\s+$','', text) #Remove space from end of text\n    text = re.sub(r'\\s+',' ', text) #Remove all multi space    \n    text = text.split(' ') #Split the words into tokens\n    text = [word for word in text if word not in stop_words] #Remove stopwords\n    text = [WordNetLemmatizer().lemmatize(word) for word in text] #Lemmatize the words(get root form)\n    text = ' '.join(text)\n\n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validate the clean text function"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Actual Text\ntemp = df_train.loc[0,'review']\ntemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cleaned text\nclean_text(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply clean text over movie reviews\ndf_train['processed_reviews'] = df_train['review'].apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Review dataset\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding average total length of words in review\ndf_train['processed_reviews'].apply(lambda x: len(x.split(' '))).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 6000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(df_train['processed_reviews'])\nlist_tokens = tokenizer.texts_to_sequences(df_train['processed_reviews'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 130 #Selected from mean of text length\nX_train = pad_sequences(list_tokens, maxlen=maxlen)\ny_train = df_train['sentiment']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_size = 128\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_size))\nmodel.add(Bidirectional(LSTM(32, return_sequences = True)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(20, activation=\"relu\"))\nmodel.add(Dropout(0.05))\nmodel.add(Dense(1, activation=\"sigmoid\"))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 100\nepochs = 3\nmodel.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read the Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/testData.tsv', delimiter='\\t')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['processed_review'] = df_test['review'].apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocess Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_sentences_test = df_test['processed_review']\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\nX_test = pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set the prediction value\np=[]\nfor val in prediction:\n    if val > 0.5:\n        p.append(1)\n    else:\n        p.append(0)\n        \nsr_pred = pd.Series(data=p, name='sentiment')\nsr_pred[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['id', 'sentiment'])\nsubmission['id'] = df_test['id']\nsubmission['sentiment'] = sr_pred\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('first_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Secured score - 0.85456"},{"metadata":{},"cell_type":"markdown","source":"**Credits:** This work is insipired this notebook from Nilan - https://www.kaggle.com/nilanml/imdb-review-deep-model-94-89-accuracy"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}