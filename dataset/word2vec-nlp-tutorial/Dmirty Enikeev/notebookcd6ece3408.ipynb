{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T04:39:06.786784Z","iopub.execute_input":"2021-12-22T04:39:06.787414Z","iopub.status.idle":"2021-12-22T04:39:06.797935Z","shell.execute_reply.started":"2021-12-22T04:39:06.787362Z","shell.execute_reply":"2021-12-22T04:39:06.797056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:40:33.202166Z","iopub.execute_input":"2021-12-22T04:40:33.202489Z","iopub.status.idle":"2021-12-22T04:40:34.788209Z","shell.execute_reply.started":"2021-12-22T04:40:33.202455Z","shell.execute_reply":"2021-12-22T04:40:34.786655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:39:02.714267Z","iopub.status.idle":"2021-12-22T04:39:02.71547Z","shell.execute_reply.started":"2021-12-22T04:39:02.715104Z","shell.execute_reply":"2021-12-22T04:39:02.71515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport random\nfrom math import exp, log\nfrom datetime import datetime\nfrom operator import itemgetter\n\ndef clean(s):\n    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n\ndef get_data_tsv(loc_dataset, opts):\n    for e, line in enumerate(open(loc_dataset, 'rb')):\n        if e > 0:\n            r = line.decode('utf-8').strip().split('\\t')\n            id = r[0]\n            \n            if opts['clean']:\n                try:\n                    r[2] = clean(r[2])\n                except:\n                    r[1] = clean(r[1])\n            \n            if len(r) == 3:\n                features = [(hash(f)%opts['D'], 1) for f in r[2].split()]\n                label = int(r[1])\n            else:\n                features = [(hash(f)%opts['D'], 1) for f in r[1].split()]\n                label = 1\n            \n            if opts['2grams']:\n                for i in range(len(features)-1):\n                    features.append(\n                        (hash(str(features[i][0])+str(features[i+1][0]))%opts['D'], 1))\n            yield label, id, features","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:43:01.252485Z","iopub.execute_input":"2021-12-22T04:43:01.252884Z","iopub.status.idle":"2021-12-22T04:43:01.468525Z","shell.execute_reply.started":"2021-12-22T04:43:01.252843Z","shell.execute_reply":"2021-12-22T04:43:01.467285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dot_product(features, weights):\n    dotp = 0\n    for f in features:\n        dotp += weights[f[0]]*f[1]\n    return dotp\n\ndef train_tron(loc_dataset, opts):\n    start = datetime.now()\n    \n    if opts['random_init']:\n        random.seed(3003)\n        weight = [random.random()] * opts['D']\n    else:\n        weights = [0.] * opts['D']\n    \n    for pass_nr in range(opts['n_passes']):\n        error_counter = 0\n        for e, (label, id, features) in enumerate( \\\n            get_data_tsv(loc_dataset, opts)):\n            dp = dot_product(features, weights) > 0.5\n            error = label - dp\n            if error != 0:\n                error_counter += 1\n                for index, value in features:\n                    weights[index] += opts['learning_rate'] * error * log(1.+value)\n        \n        if error_counter == 0 or error_counter < opts['errors_satisfied']:\n            break\n    return weights","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:43:05.70901Z","iopub.execute_input":"2021-12-22T04:43:05.70954Z","iopub.status.idle":"2021-12-22T04:43:05.719681Z","shell.execute_reply.started":"2021-12-22T04:43:05.7095Z","shell.execute_reply":"2021-12-22T04:43:05.718831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_tron(loc_dataset,weights,opts):\n    start = datetime.now()\n    preds = []\n    error_counter = 0\n    for e, (label, id, features) in enumerate( \\\n        get_data_tsv(loc_dataset,opts) ):\n\n        dotp = dot_product(features, weights)\n        dp = dotp > 0.5\n        if dp > 0.5:\n            preds.append( [id, 1, dotp ] )\n        else:\n            preds.append( [id, 0, dotp ] )\n        \n        if label - dp != 0:\n            error_counter += 1\n\n    max_dotp = max(preds,key=itemgetter(2))[2]\n    min_dotp = min(preds,key=itemgetter(2))[2]\n    for p in preds:\n        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp)) \n        \n    print(\"Done testing in %s\"%str(datetime.now()-start))\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:43:10.076817Z","iopub.execute_input":"2021-12-22T04:43:10.077398Z","iopub.status.idle":"2021-12-22T04:43:10.087027Z","shell.execute_reply.started":"2021-12-22T04:43:10.077361Z","shell.execute_reply":"2021-12-22T04:43:10.085839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opts = {}\nopts[\"D\"] = 2 ** 25\nopts[\"learning_rate\"] = 0.1\nopts[\"n_passes\"] = 80\nopts[\"errors_satisfied\"] = 0\nopts[\"random_init\"] = False\nopts[\"clean\"] = True\nopts[\"2grams\"] = True\n\n%time \nweights = train_tron(path + \"labeledTrainData.tsv\",opts)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:43:13.466485Z","iopub.execute_input":"2021-12-22T04:43:13.466821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time \npreds = test_tron(path + \"testData.tsv\",weights,opts)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:39:02.72906Z","iopub.status.idle":"2021-12-22T04:39:02.729946Z","shell.execute_reply.started":"2021-12-22T04:39:02.729618Z","shell.execute_reply":"2021-12-22T04:39:02.729653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"a_submit_perceptron.csv\",\"wb\") as outfile:\n    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n    for p in sorted(preds):\n        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T04:39:02.731784Z","iopub.status.idle":"2021-12-22T04:39:02.732707Z","shell.execute_reply.started":"2021-12-22T04:39:02.73236Z","shell.execute_reply":"2021-12-22T04:39:02.732396Z"},"trusted":true},"execution_count":null,"outputs":[]}]}