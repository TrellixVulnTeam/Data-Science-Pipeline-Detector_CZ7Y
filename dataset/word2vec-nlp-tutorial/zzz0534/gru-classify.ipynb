{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\n#import pandas as pd\nos.chdir(\"../input/word2vec-nlp-tutorial\")","metadata":{"ExecuteTime":{"end_time":"2021-03-05T02:58:15.116476Z","start_time":"2021-03-05T02:58:14.979841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -o labeledTrainData.tsv.zip -d /kaggle/working\n!unzip -o testData.tsv.zip -d /kaggle/working\n!unzip -o unlabeledTrainData.tsv.zip -d /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/working')\nwith open('labeledTrainData.tsv','r',encoding='utf-8') as f1:\n    trdata = f1.readlines()\n    trlist = []\n    trrate = []\n    for sent in trdata[1:]:\n        sen = sent.strip('\\n').split('\\t')\n        trlist.append(sen[2].split(' '))\n        trrate.append(sen[1])","metadata":{"ExecuteTime":{"end_time":"2021-03-05T02:58:17.232331Z","start_time":"2021-03-05T02:58:16.490498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('testData.tsv','r',encoding='utf-8') as f1:\n    tedata = f1.readlines()\n    telist = []\n    for sent in tedata[1:]:\n        sen = sent.strip('\\n').split('\\t')\n        telist.append(sen[1].split(' '))\nwith open('unlabeledTrainData.tsv','r',encoding='utf-8') as f1:\n    tr_nolabel = f1.readlines()\n    tr_nolist = []\n    for sent in tr_nolabel[1:]:\n        sen = sent.strip('\\n').split('\\t')\n        tr_nolist.append(sen[1].split(' '))","metadata":{"ExecuteTime":{"end_time":"2021-03-04T14:42:35.086994Z","start_time":"2021-03-04T14:42:31.593511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nfrom gensim.models import word2vec\nfrom time import time\n\npath_prefix = './'\nworddata = trlist+telist+tr_nolist\nprint(\"the len of data is {}\".format(len(worddata)))\nst=time()\nmodel = word2vec.Word2Vec(worddata,vector_size=250, window=5, min_count=5, workers=12, epochs=10, sg=0)\nmodel.save(os.path.join(path_prefix, 'w2v_all.model'))\nprint(\"we use time {} min\".format((time()-st)/60))","metadata":{"ExecuteTime":{"end_time":"2021-03-04T15:05:13.806003Z","start_time":"2021-03-04T14:45:54.420801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word2idx = model.wv.key_to_index\nidx2word = model.wv.index_to_key\nembeddingmatrix = []\nfor i,v in enumerate(idx2word):\n    embeddingmatrix.append(model.wv[v])\n#\"PAD\" vector\nvec1 = np.random.rand(250)\n#\"UNK\" vector\nvec2 = np.random.rand(250)\nword2idx[\"PAD\"] = len(word2idx)\nidx2word.append(\"PAD\")\nembeddingmatrix.append(vec1)\nword2idx[\"UNK\"] = len(word2idx)\nidx2word.append(\"UNK\")\nembeddingmatrix.append(vec2)\n#embeddingmatrix = torch.cat([embeddingmatrix,vec1,vec2],0)","metadata":{"ExecuteTime":{"end_time":"2021-03-05T02:58:30.57319Z","start_time":"2021-03-05T02:58:29.971482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set the length of word is 40\nsenlen = 100\ntrain_num = []\nfor senten in trlist:\n    wordlist = []\n    if len(senten) >= senlen:\n        for sen in senten[:senlen]:\n            if sen in word2idx.keys():\n                wordlist.append(word2idx[sen])\n            else:\n                wordlist.append(word2idx['UNK'])\n        train_num.append(wordlist)\n    else:\n        less_num = senlen - len(senten)\n        for sen in senten:\n            if sen in word2idx.keys():\n                wordlist.append(word2idx[sen])\n            else:\n                wordlist.append(word2idx['UNK'])\n        for _ in range(less_num):\n            wordlist.append(word2idx['PAD'])\n        train_num.append(wordlist)","metadata":{"ExecuteTime":{"end_time":"2021-03-05T02:58:33.14566Z","start_time":"2021-03-05T02:58:32.524247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils import data\n# define tordata type\nclass moviedata(data.Dataset):\n    def __init__(self, X, y):\n        self.data = X\n        self.label = y\n    def __getitem__(self, idx):\n        if self.label is None: return self.data[idx]\n        return self.data[idx], self.label[idx]\n    def __len__(self):\n        return len(self.data)","metadata":{"ExecuteTime":{"end_time":"2021-03-05T02:58:35.581961Z","start_time":"2021-03-05T02:58:35.038075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nclass gru_net(nn.Module):\n    def __init__(self,embedding, hidden_dim, num_layers, dropout=0.5,embedding_train=False):\n        super(gru_net, self).__init__()\n        self.embedding = nn.Embedding(embedding.size(0),embedding.size(1))\n        self.embedding.weight = nn.Parameter(embedding)\n        self.embedding.weight.requires_grad = embedding_train\n        self.embedding_dim = embedding.size(1)\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        self.dropout = dropout\n        self.gru = nn.GRU(self.embedding_dim,self.hidden_dim,num_layers=self.num_layers,batch_first=True)\n        self.classfier = nn.Sequential(\n            nn.Dropout(self.dropout),\n            nn.Linear(self.hidden_dim,1),\n            nn.Sigmoid()\n        )\n    def forward(self,inputs):\n        inputs = self.embedding(inputs)\n        inputs = inputs.float().cuda()\n        x, _ = self.gru(inputs, None)\n        x = x[:,-1,:]# x is [batch,seq_len,hidden_size]\n        x = self.classfier(x)\n        return x","metadata":{"ExecuteTime":{"end_time":"2021-03-05T03:10:09.521453Z","start_time":"2021-03-05T03:10:09.489445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluation(outputs, labels):\n    # outputs => probability (float)\n    # labels => labels\n    outputs[outputs>=0.5] = 1 # 大於等於 0.5 為有惡意\n    outputs[outputs<0.5] = 0 # 小於 0.5 為無惡意\n    correct = torch.sum(torch.eq(outputs, labels)).item()\n    return correct","metadata":{"ExecuteTime":{"end_time":"2021-03-05T02:58:45.133909Z","start_time":"2021-03-05T02:58:45.126901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport argparse\nimport numpy as np\nfrom torch import nn\nfrom gensim.models import word2vec\n#from sklearn.model_selection import train_test_split","metadata":{"ExecuteTime":{"end_time":"2021-03-05T02:58:50.185803Z","start_time":"2021-03-05T02:58:50.180786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nembedding_train=False # fix embedding during training\nbatch_size = 128\nepoch = 10\nlr = 0.001\nmodel_dir = './'\n\nprint(len(train_num))\nX = torch.LongTensor(train_num)\ny = [int(rate) for rate in trrate]\ny = torch.LongTensor(y)\nembeddingmatrix = torch.from_numpy(np.array(embeddingmatrix))\n#embeddingmatrix = torch.tensor(embeddingmatrix)\n#establish model\ngmodel = gru_net(embeddingmatrix, hidden_dim=150, num_layers=1, dropout=0.5,embedding_train=embedding_train)\ngmodel = gmodel.to(device)\n# split data\nx_train,x_valid,y_train,y_valid = X[:18000],X[18000:],y[:18000],y[18000:]\n# dataloader\ntrain_dataset = moviedata(X=x_train, y=y_train)\nval_dataset = moviedata(X=x_valid, y=y_valid)\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                            batch_size = batch_size,\n                                            shuffle = True,\n                                            num_workers = 4)\n\nval_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n                                            batch_size = batch_size,\n                                            shuffle = False,\n                                            num_workers = 4)\ntorch.cuda.empty_cache()\ntrain_process(batch_size, epoch, lr, model_dir, train_loader, val_loader, gmodel, device)","metadata":{"ExecuteTime":{"end_time":"2021-03-05T03:12:18.703502Z","start_time":"2021-03-05T03:12:17.741486Z"},"trusted":true},"execution_count":null,"outputs":[]}]}