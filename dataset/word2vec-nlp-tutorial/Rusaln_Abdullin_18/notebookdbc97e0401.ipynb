{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\ntrain_data = pd.read_csv(\"../input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\", header=0, delimiter=\"\\t\", quoting=3)\ntest_data = pd.read_csv(\"../input/word2vec-nlp-tutorial/testData.tsv.zip\", header=0, delimiter=\"\\t\", quoting=3 )\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ntrain_data.shape\ntest_data.shape\ntrain_data.columns.values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\ndef rew_word(r_rew):\n    rev_text = BeautifulSoup(r_rew).get_text()\n    l = re.sub(\"[^a-zA-Z]\", \" \", rev_text)\n    low_case = l.lower()\n    words = low_case.split()\n    stop = set(stopwords.words(\"english\"))\n    words_n = [word for word in words if not word in stop]\n    return( \" \".join(words_n))\ndef data_clean(data):\n    data_clean = []\n    size = data[\"review\"].size\n    for i in range( 0, size):\n        if((i+1)%1000 == 0):\n            print(f\"Review {i+1} from {size}\\n\") \n        data_clean.append(rew_word(data[\"review\"][i]))\n    return data_clean\nstr_words = rew_word(train_data[\"review\"][0])\nstr_words\nfrom sklearn.feature_extraction.text import CountVectorizer\ntrain_clean = data_clean(train_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector = CountVectorizer(analyzer = \"word\",   \\\n                             tokenizer = None,    \\\n                             preprocessor = None, \\\n                             stop_words = None,   \\\n                             max_features = 20000)\ntrain_vector = vector.fit_transform(train_clean)\ntrain_vector","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc = vector.get_feature_names()\nvoc\ntrain_vector.shape\ntrain_data['sentiment'].shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators = 110) \nmas_train = train_vector.toarray()\nclf.fit(mas_train,train_data[\"sentiment\"])\n\ntest_clean = data_clean(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vector = vector.transform(test_clean)\ntest_array = test_vector.toarray()\n\nresult = clf.predict(test_array)\nsub = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\":result} )\nsub.to_csv( \"submission.csv\", index=False, quoting=3 )","metadata":{},"execution_count":null,"outputs":[]}]}