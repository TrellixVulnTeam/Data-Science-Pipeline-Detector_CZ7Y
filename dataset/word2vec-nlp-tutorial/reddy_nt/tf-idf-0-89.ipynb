{"cells":[{"metadata":{"_uuid":"7f93c7c067d84e923ac2e088f2843febb6508afe"},"cell_type":"markdown","source":"# IMDB movie reviews\n1. Build conventional model using tf-idf feature extraction\n2. Use word embeddings and deep learning"},{"metadata":{"trusted":true,"_uuid":"2c6d61bf6fb351de493d110a0701e37b6a37de78"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdaefdadafd9914518399e3b1aefae36463a57c6"},"cell_type":"code","source":"# imports\n\nimport os\nimport re\nimport json\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import RegexpTokenizer\nfrom matplotlib import pyplot as plt\nfrom sklearn.externals import joblib\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import LinearSVC\nfrom IPython.display import FileLink\n\n# config\n\nwarnings.filterwarnings('ignore')\ndata_path = '../input/'\n%matplotlib inline\n# os.chdir(data_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba43e3cb7ee9b57463414fd8da41ae513db11272"},"cell_type":"markdown","source":"## Data load.."},{"metadata":{"trusted":true,"_uuid":"dbb2ac3f9cbe5074bd1bd81ff07a6efd4366f2e7"},"cell_type":"code","source":"lbl_train = pd.read_csv(data_path+'labeledTrainData.tsv', sep='\\t')\nprint(\"Shape: {}\".format(lbl_train.shape))\nprint(lbl_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd1a9a8db8908686428f9026ca49289c00420a66"},"cell_type":"code","source":"unlbl_train = pd.read_csv(data_path+'unlabeledTrainData.tsv', sep='\\t', error_bad_lines=False)\nprint(\"Shape: {}\".format(unlbl_train.shape))\nprint(unlbl_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5986c661d18ecf648c86b16af1f2444b402f5be7"},"cell_type":"code","source":"test = pd.read_csv(data_path+'testData.tsv', sep='\\t')\nprint(f'Shape: {test.shape}')\nprint(test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d7844d27ceb4c3a0c74997073a917f08d854a55"},"cell_type":"code","source":"samplesub = pd.read_csv(data_path+'./sampleSubmission.csv')\nsamplesub.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ba25107256b59345ca7d215ad868bbe1c34423a"},"cell_type":"markdown","source":"## Analysis.."},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"e9da3d27b3285c9266b07896837a7508c596becc"},"cell_type":"code","source":"# random positive/negative review\n\nprint(f'pos:\\n{lbl_train.review[np.random.randint(0, 25000)]}')\nprint(f'neg:\\n{test.review[np.random.randint(0, 25000)]}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2590fe9224066059f78de7abd9be9990a1d04979"},"cell_type":"markdown","source":">Some observations\n1. Remove HTML tags like line breaks <br\\>\n2. Remove punctuations"},{"metadata":{"trusted":true,"_uuid":"668e00de5cfa6cf311abf79ef433d26eebf125ca"},"cell_type":"code","source":"# Average number of words in pos & neg reviews\n\navg_pos_words = lbl_train[lbl_train.sentiment==1].review.apply(lambda x: len(x.split())).mean()\navg_neg_words = lbl_train[lbl_train.sentiment==0].review.apply(lambda x: len(x.split())).mean()\n\nplt.figure(figsize=(10, 3))\nplt.barh(['Positive', 'Negative'], [avg_pos_words, avg_neg_words], height=0.5)\nplt.xticks(np.arange(0, 300, 25))\nplt.xlabel('Average Number of words')\nplt.ylabel('Sentiment')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"201df329bb239ef888de5226603930eff468b48b"},"cell_type":"markdown","source":"**Average number of words for both positive and negative words are almost same**"},{"metadata":{"trusted":true,"_uuid":"80cd0176bde67a1dc1edcfe9b51a638cbd2d93ac"},"cell_type":"code","source":"def clean_review(review):\n    # remove line breaks\n    review = re.sub(r'<br />', '', review)\n    # remove punctuations/tokenize\n    tokenizer = RegexpTokenizer(r'\\w+')\n    review = tokenizer.tokenize(review)\n    # apply stemming\n    stemmer = PorterStemmer()\n    review = ' '.join([stemmer.stem(y) for y in review])\n    return review\n\n# clean train, test and unlabeled train\nlbl_train.review = lbl_train.review.apply(lambda x: clean_review(x))\ntest.review = test.review.apply(lambda x: clean_review(x))\nunlbl_train = unlbl_train.review.apply(lambda x: clean_review(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1f5a569b077749a2be76f5cab525d4195922747"},"cell_type":"markdown","source":"## Model building.."},{"metadata":{"_uuid":"94837e7fd78cb285f427321fb280782cbdefdb54"},"cell_type":"markdown","source":"### TF-IDF"},{"metadata":{"trusted":true,"_uuid":"badb609bf08f7d61c357cd6f788608ff0fe541e7"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(lbl_train.review, lbl_train.sentiment,\n                                                    test_size=0.2, random_state=13)\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0e4a05fb31b2a8e6787d1c53ce97940f9454fb9"},"cell_type":"code","source":"%%time\n\nlg_pipeline = Pipeline([\n    ('tfidf', TfidfVectorizer(max_df=0.9)),\n    ('lg', LogisticRegression(n_jobs=-1))\n])\n\nlg_pipeline.fit(X_train, y_train)\nprint(f'Accuracy: {np.mean(lg_pipeline.predict(X_test)==y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ea2d14e6b3093a9bb854b39f7ab043617fd6d31"},"cell_type":"code","source":"%%time\n\nrfc_pipeline = Pipeline([\n    ('tfidf', TfidfVectorizer(max_df=0.9)),\n    ('rfc', RandomForestClassifier(n_estimators=100, n_jobs=-1))\n])\n\nrfc_pipeline.fit(X_train, y_train)\nprint(f\"Accuracy: {np.mean(rfc_pipeline.predict(X_test)==y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98faed463ba9e889d340add102635b92ffdcad94"},"cell_type":"code","source":"%%time\n\nnb_pipeline = Pipeline([\n    ('tfidf', TfidfVectorizer(max_df=0.9)),\n    ('nb', BernoulliNB())\n])\n\nnb_pipeline.fit(X_train, y_train)\nprint(f'Accuracy: {np.mean(nb_pipeline.predict(X_test)==y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a1c4e3b754adfb7095b32020f064ca8ad7b6e39"},"cell_type":"markdown","source":"1. As always, Logistic is fast and produced best baseline results\n2. Random forest and Naive bayes are similar"},{"metadata":{"trusted":true,"_uuid":"de0035b6e83a1cd8e77335247bcb85df162e99eb"},"cell_type":"code","source":"# parameter tuning\n\nlg_params = {\n    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n    'lg__C': [0.1, 1, 10],\n}\n\nrfc_params = {\n    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n    'rfc__max_features': ['auto', 'sqrt'],\n    'rfc__bootstrap': [True, False],\n    'rfc__n_estimators': [200, 400, 600],\n    'rfc__min_samples_split': [2, 5, 10],\n    'rfc__min_samples_leaf': [1, 2, 4]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5e48ef3ba507abab2023066df7e04f414854cd6"},"cell_type":"markdown","source":"**Commenting the grid search fit method, as it takes more time. However, the results I have got have been saved later in notebook**"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"49662e615ff67d65fa8e28107f0939d0eaa92253"},"cell_type":"code","source":"%%time\n\nlg_grid = GridSearchCV(lg_pipeline, param_grid=lg_params, cv=3, verbose=True, n_jobs=-1)\n# lg_grid.fit(X_train, y_train)\n# lg_grid.best_params_\n# print(f\"Logistic gridsearch accuracy: {np.mean(lg_grid.predict(X_test)==y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9512f29b602d72e9b9abd5a8dd137c3d8026357"},"cell_type":"code","source":"%%time\n\nrfc_grid = RandomizedSearchCV(rfc_pipeline, param_distributions=rfc_params, cv=3, verbose=True, n_jobs=-1)\n# rfc_grid.fit(X_train, y_train)\n# rfc_grid.best_params_\n# print(f\"Accuracy: {np.mean(rfc_grid.predict(X_test)==y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8461b29323b7a44e7312488ad35149b7b6737c64"},"cell_type":"code","source":"lg_best_params = {'lg__C': 10, 'tfidf__ngram_range': (1, 2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"489b5f3b4e9e6d695f0d617441e00cb6f931be46"},"cell_type":"code","source":"rfc_best_params = {'tfidf__ngram_range': (1, 3),\n 'rfc__n_estimators': 400,\n 'rfc__min_samples_split': 5,\n 'rfc__min_samples_leaf': 4,\n 'rfc__max_features': 'sqrt',\n 'rfc__bootstrap': False}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25beafca8e50bd2ec42d74eddf77ce4146d0cba0"},"cell_type":"code","source":"lg_pipeline.set_params(**lg_best_params)\nrfc_pipeline.set_params(**rfc_best_params)\n\nlg_pipeline.fit(lbl_train.review, lbl_train.sentiment)\nrfc_pipeline.fit(lbl_train.review, lbl_train.sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c722b885af8062d9bca4332ab9651b73d86d8c14"},"cell_type":"code","source":"nb_pipeline.set_params(tfidf__ngram_range=(1,3))\nnb_pipeline.fit(lbl_train.review, lbl_train.sentiment)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"436e7b35ab9bc419261e634ca3e8a69644af722b"},"cell_type":"markdown","source":"## Avengers Ensemble"},{"metadata":{"trusted":true,"_uuid":"76c9183bfb2d3cc783625feaae3d16b7b277859b"},"cell_type":"code","source":"lg_preds = lg_pipeline.predict(test.review)\nrfc_preds = rfc_pipeline.predict(test.review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a562c355a310a98e479beb208c3663085f9ec21b"},"cell_type":"code","source":"nb_preds = nb_pipeline.predict(test.review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f045b706c10716121aee57d4bb8a2d910c36f2b1"},"cell_type":"code","source":"# Pick the test prediction by voting\n\npredictions = pd.DataFrame({'lg': lg_preds, 'rfc': rfc_preds, 'nb': nb_preds}).mode(axis=1).rename(columns={0: 'sentiment'})\nsubmission = pd.DataFrame({'id': test.id.values, 'sentiment': predictions.sentiment.values})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true,"_uuid":"9a5de3d957830ceb61edf03cc920570441730010"},"cell_type":"code","source":"submission.to_csv('submission2.csv', index=False)\n# FileLink('./submission2.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edbcb83e80a2787eeb0f187ad9ff616162ed4a44"},"cell_type":"markdown","source":"## Word Embeddings"},{"metadata":{"trusted":true,"_uuid":"707357e2857d52d33f981e6b92491beef4752684"},"cell_type":"markdown","source":"We will use a plain Implementation of RNN with a embedding layer, and will move to LSTM"},{"metadata":{"trusted":true,"_uuid":"0bc784b5034ded9e4e77fa1d8f6780d867414b10"},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.layers import LSTM, Bidirectional, GlobalMaxPool1D\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b32696412a2dae120068cea95c3e06f9d5876ef"},"cell_type":"code","source":"# Let's fix vocab size to 20000\nvocab_size = 10000\n\nt = Tokenizer(num_words=vocab_size)\nt.fit_on_texts(lbl_train.review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b32696412a2dae120068cea95c3e06f9d5876ef"},"cell_type":"code","source":"# create sequences to feed into Neural network model\nsequences = t.texts_to_sequences(lbl_train.review)\n\n# As the average length of all reviews is around 250, \n# lets the keep the input dim to 250 and pad the sequences if it is less that 250 words\nsequences = pad_sequences(sequences, maxlen=150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b9a90529936197e9d22b5c87f2b0fdeeb758b23"},"cell_type":"code","source":"# Now the length of each review is 350, and there are 25000 items\nsequences.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1150e8dc54a46713c1c16d041196afceff47343"},"cell_type":"code","source":"# Network architecture\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=150, name='embed'))\nmodel.add(Bidirectional(LSTM(32, return_sequences=True, name='lstm')))\nmodel.add(GlobalMaxPool1D(name='gmax1'))\nmodel.add(Dense(20, name='dense1'))\n# model.add(Flatten(name='flatten'))\nmodel.add(Dropout(0.05, name='drop1'))\nmodel.add(Dense(1, activation='sigmoid', name='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a02b039a4166781c3973fe85e3e0890705207dce"},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(sequences, lbl_train.sentiment.values, validation_split=0.2, epochs=5, batch_size=128, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c5bf8a074897ce242d6a68dfd044fa1a30ada23"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e1aa547af17cb11c3782956f935528989ffde70"},"cell_type":"code","source":"test_sequences = t.texts_to_sequences(test.review)\ntest_sequences = pad_sequences(test_sequences, maxlen=150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a053a924b3b5a017cb12bd1844f6cb1502d6bda6"},"cell_type":"code","source":"len(test_sequences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"340fcd7a6f9f4b7dda40191e524285d7dad28e05"},"cell_type":"code","source":"test_sequences.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"931d0aad8f608cc88946acbd85793849541331a1"},"cell_type":"code","source":"preds = model.predict(test_sequences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcadf9598dcd861951a3c3349ada016088704ff9"},"cell_type":"code","source":"preds = (preds>0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f380981001552077d3865ab2e2030decdf0a390"},"cell_type":"code","source":"preds = [int(p) for p in preds]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb4e41009c0b78c062a4b01ebfa1f998dfccab94"},"cell_type":"code","source":"submission2 = pd.DataFrame({'id': test.id.values, 'sentiment': preds})\nsubmission2.to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"866a430b84e48e175f14a728e02d362f7f3e4f3b"},"cell_type":"code","source":"FileLink('./submission2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15a55c617792eb627d4e000f20e3a2d62a508f04"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}