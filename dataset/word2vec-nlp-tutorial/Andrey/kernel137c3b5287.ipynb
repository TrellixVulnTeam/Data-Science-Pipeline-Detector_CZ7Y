{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Bag of Words Meets Bags of Popcorn**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Загружаем данные"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"../input/word2vec-nlp-tutorial/labeledTrainData.tsv\", header=0, \\\n delimiter=\"\\t\", quoting=3)\ndisplay(data.head())\nprint(data.shape)\nprint(data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Взглянем на какой-нибудь из обзоров([номер текста])"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (data[\"review\"][3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В тексте присутствуют HTML теги. Избавимся от них"},{"metadata":{"trusted":true},"cell_type":"code","source":"from bs4 import BeautifulSoup \nexample1 = BeautifulSoup(data[\"review\"][3]) \nprint (example1.get_text())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь удалим знаки препинания"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nletters_only=re.sub(\"[^a-zA-Z]\",\" \",example1.get_text())\nprint (letters_only)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Преобразуем слова в нижний регистр и снова соединяем в строку"},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_case = letters_only.lower()\nwords = lower_case.split()\nclean_text=(\" \".join(words))\nprint(clean_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Удаление стоп-слов"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nprint (stopwords.words(\"english\") )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = [w for w in words if not w in (stopwords.words(\"english\"))]\nprint(words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Объединив всё в одну функцию"},{"metadata":{"trusted":true},"cell_type":"code","source":"def review_to_words( raw_review ):\n    review_text=BeautifulSoup(raw_review).get_text()\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n    words = letters_only.lower().split()\n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проведём чистку всех отзывов"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_reviews = data[\"review\"].size\n\nclean_reviews = []\nfor i in range( 0, num_reviews ):\n clean_reviews.append( review_to_words(data[\"review\"][i] ) )\nprint(num_reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(analyzer = \"word\", \\\ntokenizer = None, \\\n preprocessor = None, \\\n stop_words = None, \\\n max_features = 5000) \ntrain_data_features = vectorizer.fit_transform(clean_reviews)\ntrain_data_features = train_data_features.toarray()\nprint(train_data_features.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разделим данные на обучающие и тестовые\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data_features\ny = data.sentiment \n'''from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(X)\nX=scaler.transform(X)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=130)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"GridSearch+Логистическая регрессия"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\ngrid={\"C\":[0.1,0.3,1,3,10]}\nLR=LogisticRegression()\nLRgrid=GridSearchCV(LR,grid,cv=10)\nLRgrid.fit(X_train,y_train)\n\nprint(\"Лучшие параметры: ) \",LR.best_params_)\nprint(\"Лучший результат: :\",LR.best_score_)'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Логистическая регрессия"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\na=[0.1,0.3,1,3,10]\nfor i in range (5):\n    LR = LogisticRegression(C=a[i])\n    LR.fit(X_train, y_train)\n    print(\"Точность тренировки: C=\",a[i], LR.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Лучше С=0.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = LogisticRegression(C=0.1)\nLR.fit(X_train, y_train)\nprint(\"Точность тренировки: C=0.1\", LR.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Наивный Байесовский классификатор"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nNB = GaussianNB()\nNB.fit(X_train,y_train)\nprint(\"Точность тренировки: \", NB.score(X_test, y_test))\nNB.fit(X_test, y_test)\nprint(\"Точность тренировки(валидационные): \", NB.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Логистическая регрессия лучше. Будем использовать её для загрузки данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Загрузка данных\ntest = pd.read_csv(\"../input/word2vec-nlp-tutorial/testData.tsv\", header=0, delimiter=\"\\t\", \\\n quoting=3 )\n\nnum_reviews = len(test[\"review\"])\nclean_test_reviews = [] \nfor i in range(0,num_reviews):\n if( (i+1) % 1000 == 0 ):\n     print(\"Review %d of %d\\n\" % (i+1, num_reviews))\n clean_review = review_to_words( test[\"review\"][i] )\n clean_test_reviews.append( clean_review )\ntest_data_features = vectorizer.transform(clean_test_reviews)\ntest_data_features = test_data_features.toarray()\nresult = LR.predict(test_data_features)\n\noutput = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n# Сохраняем\noutput.to_csv( \"..kaggle/workong/Bag_of_Words_model.csv\", index=False, quoting=3 )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}