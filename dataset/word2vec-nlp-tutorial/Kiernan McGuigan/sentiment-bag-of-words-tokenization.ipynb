{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-24T20:25:22.556305Z","iopub.execute_input":"2021-12-24T20:25:22.556599Z","iopub.status.idle":"2021-12-24T20:25:22.572814Z","shell.execute_reply.started":"2021-12-24T20:25:22.556569Z","shell.execute_reply":"2021-12-24T20:25:22.571782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import callbacks, models, layers\nimport matplotlib.pyplot as plt\n\n# tokenization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# bag of words\n","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:22.575809Z","iopub.execute_input":"2021-12-24T20:25:22.576657Z","iopub.status.idle":"2021-12-24T20:25:22.58405Z","shell.execute_reply.started":"2021-12-24T20:25:22.576613Z","shell.execute_reply":"2021-12-24T20:25:22.583013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE = '/kaggle/input/word2vec-nlp-tutorial'\nMAX_WORDS = 25_000","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:22.586188Z","iopub.execute_input":"2021-12-24T20:25:22.586522Z","iopub.status.idle":"2021-12-24T20:25:22.595959Z","shell.execute_reply.started":"2021-12-24T20:25:22.586465Z","shell.execute_reply":"2021-12-24T20:25:22.594826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:22.598452Z","iopub.execute_input":"2021-12-24T20:25:22.599335Z","iopub.status.idle":"2021-12-24T20:25:22.609063Z","shell.execute_reply.started":"2021-12-24T20:25:22.599288Z","shell.execute_reply":"2021-12-24T20:25:22.607898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(os.path.join(BASE,'labeledTrainData.tsv.zip'), header=0, delimiter=\"\\t\", quoting=3)\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:22.613296Z","iopub.execute_input":"2021-12-24T20:25:22.613812Z","iopub.status.idle":"2021-12-24T20:25:23.160454Z","shell.execute_reply.started":"2021-12-24T20:25:22.613767Z","shell.execute_reply":"2021-12-24T20:25:23.159557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(os.path.join(BASE,'testData.tsv.zip'), header=0, delimiter=\"\\t\", quoting=3)\ntest.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:23.163154Z","iopub.execute_input":"2021-12-24T20:25:23.163744Z","iopub.status.idle":"2021-12-24T20:25:23.696425Z","shell.execute_reply.started":"2021-12-24T20:25:23.163685Z","shell.execute_reply":"2021-12-24T20:25:23.695473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train[\"sentiment\"][0])\ntrain[\"review\"][0]","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:23.699316Z","iopub.execute_input":"2021-12-24T20:25:23.699949Z","iopub.status.idle":"2021-12-24T20:25:23.70898Z","shell.execute_reply.started":"2021-12-24T20:25:23.699898Z","shell.execute_reply":"2021-12-24T20:25:23.707943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words = stopwords.words(\"english\")\ndef clean(review):\n    clean_html = BeautifulSoup(review).get_text()\n    clean_non_letters = re.sub(\"[^a-zA-Z]\", \" \", clean_html)\n    cleaned_lowercase = clean_non_letters.lower()\n    words = cleaned_lowercase.split()\n    cleaned_words = [w for w in words if w not in stop_words]\n    return \" \".join(cleaned_words)\n\ntrain[\"cleaned_review\"] = train[\"review\"].apply(clean)\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:23.710637Z","iopub.execute_input":"2021-12-24T20:25:23.711239Z","iopub.status.idle":"2021-12-24T20:25:48.399947Z","shell.execute_reply.started":"2021-12-24T20:25:23.711194Z","shell.execute_reply":"2021-12-24T20:25:48.398824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization approach","metadata":{}},{"cell_type":"code","source":"# with no constraints there are 74_066 words in the training set\ntokenizer = Tokenizer(num_words=MAX_WORDS)\ntokenizer.fit_on_texts(train.cleaned_review)\ntotal_words = len(tokenizer.word_index) + 1\ntotal_words","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:48.401716Z","iopub.execute_input":"2021-12-24T20:25:48.402136Z","iopub.status.idle":"2021-12-24T20:25:51.173783Z","shell.execute_reply.started":"2021-12-24T20:25:48.402069Z","shell.execute_reply":"2021-12-24T20:25:51.17256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = tokenizer.texts_to_sequences(train.cleaned_review)\nmax_sequence_len = max([len(x) for x in sequences])\npadded_sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\nlabels = np.array(train.sentiment)\nX_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=0)\nprint(X_train.shape, y_train.shape, X_val.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:51.175782Z","iopub.execute_input":"2021-12-24T20:25:51.176182Z","iopub.status.idle":"2021-12-24T20:25:54.008793Z","shell.execute_reply.started":"2021-12-24T20:25:51.176109Z","shell.execute_reply":"2021-12-24T20:25:54.00772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_dataset(data, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n    dataset = dataset.cache().shuffle(X_train.shape[0] + 1).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset\ntrain_ds = to_dataset(X_train, y_train)\nval_ds = to_dataset(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:54.010511Z","iopub.execute_input":"2021-12-24T20:25:54.010803Z","iopub.status.idle":"2021-12-24T20:25:54.150387Z","shell.execute_reply.started":"2021-12-24T20:25:54.010762Z","shell.execute_reply":"2021-12-24T20:25:54.149309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LSTM_SIZE = 8\ndef bi_lstm_model():\n    model = models.Sequential()\n    model.add(layers.Embedding(total_words, 16, input_length=max_sequence_len - 1))\n    model.add(layers.Bidirectional(layers.LSTM(LSTM_SIZE)))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n    return model, f'bidirectional_lstm_{LSTM_SIZE}'\n\ndef lstm_model():\n    model = models.Sequential()\n    model.add(layers.Embedding(total_words, 4, input_length=max_sequence_len - 1))\n    model.add(layers.LSTM(LSTM_SIZE))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n    return model, f'lstm_{LSTM_SIZE}'","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:25:54.154539Z","iopub.execute_input":"2021-12-24T20:25:54.154799Z","iopub.status.idle":"2021-12-24T20:25:54.164077Z","shell.execute_reply.started":"2021-12-24T20:25:54.154767Z","shell.execute_reply":"2021-12-24T20:25:54.162772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenizer_train(model, name):\n    reducer = callbacks.ReduceLROnPlateau(monior='val_loss', factor=0.5, patience=3, mode='min', cooldown=1)\n    stopper = callbacks.EarlyStopping(monitor='val_loss', patience=6, mode='min', restore_best_weights=True)\n    hist = model.fit(train_ds,\n              epochs=100,\n              verbose=1,\n              callbacks=[stopper, reducer],\n              validation_data=val_ds)\n    results = model.evaluate(val_ds)\n    model.save(f'/kaggle/working/{name}')\n    print(f\"results: {results}, type: {type(results)}\")\n    return hist","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:27:24.072714Z","iopub.execute_input":"2021-12-24T20:27:24.073028Z","iopub.status.idle":"2021-12-24T20:27:24.080471Z","shell.execute_reply.started":"2021-12-24T20:27:24.072996Z","shell.execute_reply":"2021-12-24T20:27:24.079517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, name = lstm_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:27:24.987993Z","iopub.execute_input":"2021-12-24T20:27:24.988641Z","iopub.status.idle":"2021-12-24T20:27:25.756208Z","shell.execute_reply.started":"2021-12-24T20:27:24.988607Z","shell.execute_reply":"2021-12-24T20:27:25.754999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = tokenizer_train(model, name)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:27:26.162295Z","iopub.execute_input":"2021-12-24T20:27:26.162602Z","iopub.status.idle":"2021-12-24T20:28:04.026894Z","shell.execute_reply.started":"2021-12-24T20:27:26.162569Z","shell.execute_reply":"2021-12-24T20:28:04.025637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(3, 1, figsize=(8,8), tight_layout=True)\n    \naxs[0].plot(hist.history['loss'])\naxs[0].plot(hist.history['val_loss'])\naxs[0].set_title('binary_crossentropy Loss')\naxs[0].set_ylabel('Loss')\naxs[0].set_xlabel('Epoch')\naxs[0].legend(['train', 'val'], loc='upper right')\n\naxs[1].plot(hist.history['binary_accuracy'])\naxs[1].plot(hist.history['val_binary_accuracy'])\naxs[1].set_title('binary_accuracy Metric')\naxs[1].set_ylabel('Error')\naxs[1].set_xlabel('Epoch')\naxs[1].legend(['train', 'val'], loc='upper left')\n\naxs[2].plot(hist.history['lr'])\naxs[2].set_title('Learining Rate')\naxs[2].set_ylabel('LR')\naxs[2].set_xlabel('Epoch')\nplt.savefig(f'/kaggle/working/{name}_graphs.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:28:04.03013Z","iopub.execute_input":"2021-12-24T20:28:04.030624Z","iopub.status.idle":"2021-12-24T20:28:04.889244Z","shell.execute_reply.started":"2021-12-24T20:28:04.030568Z","shell.execute_reply":"2021-12-24T20:28:04.888195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"cleaned_review\"] = test[\"review\"].apply(clean)\ntest","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:28:04.891059Z","iopub.execute_input":"2021-12-24T20:28:04.891602Z","iopub.status.idle":"2021-12-24T20:28:28.742967Z","shell.execute_reply.started":"2021-12-24T20:28:04.891556Z","shell.execute_reply":"2021-12-24T20:28:28.741922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = tokenizer.texts_to_sequences(test.cleaned_review)\ntest_sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\nprint(test_sequences.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:28:28.745546Z","iopub.execute_input":"2021-12-24T20:28:28.746122Z","iopub.status.idle":"2021-12-24T20:28:31.592468Z","shell.execute_reply.started":"2021-12-24T20:28:28.746055Z","shell.execute_reply":"2021-12-24T20:28:31.591493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_sequences).flatten()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:29:55.888735Z","iopub.execute_input":"2021-12-24T20:29:55.889505Z","iopub.status.idle":"2021-12-24T20:30:36.983541Z","shell.execute_reply.started":"2021-12-24T20:29:55.889469Z","shell.execute_reply":"2021-12-24T20:30:36.982519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:30:36.985595Z","iopub.execute_input":"2021-12-24T20:30:36.986813Z","iopub.status.idle":"2021-12-24T20:30:36.99369Z","shell.execute_reply.started":"2021-12-24T20:30:36.986767Z","shell.execute_reply":"2021-12-24T20:30:36.992607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame(data={\"id\":test.id, \"sentiment\":predictions})\noutput.to_csv(\"word_tokenization_model.csv\", index=False, quoting=3)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T20:30:36.995259Z","iopub.execute_input":"2021-12-24T20:30:36.996221Z","iopub.status.idle":"2021-12-24T20:30:37.072552Z","shell.execute_reply.started":"2021-12-24T20:30:36.996176Z","shell.execute_reply":"2021-12-24T20:30:37.071416Z"},"trusted":true},"execution_count":null,"outputs":[]}]}