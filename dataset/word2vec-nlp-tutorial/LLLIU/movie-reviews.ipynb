{"cells":[{"metadata":{"trusted":true,"_uuid":"68080a29fabab8fa8c090d42b5a89878fc19fb9b"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24385405878511253ae17e8aa0c24263cb957588"},"cell_type":"code","source":"data_dir = '../input/'\ntrain_data = pd.read_csv(data_dir+'labeledTrainData.tsv',delimiter=\"\\t\")\ntest_data = pd.read_csv(data_dir+'testData.tsv',delimiter=\"\\t\")\ntest_test = pd.read_csv(data_dir+'unlabeledTrainData.tsv',delimiter=\"\\t\",error_bad_lines= False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40fad435a01ba932b9001073b962f4b538ea7af8"},"cell_type":"code","source":"train_score = train_data['sentiment']\ntrain_review = train_data['review']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bcba2cd7a1b27feb631dc9c83ca62f41709c820"},"cell_type":"code","source":"import re\ndef review_to_wordlist(review):\n    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n    words = review_text.lower()\n    return words\n\ntrain_set = []\nfor i in range(0,len(train_review)):\n    train_set.append(review_to_wordlist(train_review[i]))\n    \ntest_set = []\nfor i in range(0,len(test_data['review'])):\n    test_set.append(review_to_wordlist(test_data['review'][i]))\n\ntest_set = np.array(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc18d8dfc88b04046d16b479a7fe7965e749b5ea"},"cell_type":"code","source":"import nltk\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b316473c69587da597c065e9360bed1050708d5"},"cell_type":"code","source":"from nltk.stem import PorterStemmer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nps = PorterStemmer()\n\ntest_set_stem = []\nfor word in test_set:\n    test_set_stem.append(ps.stem(word))\n\ntrain_set_stem = []\nfor word in train_set:\n    train_set_stem.append(ps.stem(word))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad2a888c34691109f466234d8d76866d72da83a3"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# vectorizer = CountVectorizer()\n\n\n# data_train_count = vectorizer.fit_transform(train_data)\n# data_test_count  = vectorizer.transform(test_data)\n\ntfidf = TfidfVectorizer(\n           ngram_range=(1,3), \n           use_idf=1,\n           smooth_idf=1,\n           stop_words = 'english') \n\n\ndata_train_count_tf = tfidf.fit_transform(train_set_stem)\ndata_test_count_tf  = tfidf.transform(test_set_stem)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"93ba3d90a9ac08ffd1b6ee6fbb1e9942388a89e9"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB \n\nclf = MultinomialNB()\nclf.fit(data_train_count_tf, train_score)\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\nprint ( np.mean(cross_val_score(clf, data_train_count_tf, train_score, cv=10, scoring='accuracy')))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"466c3389cd94c851f9c5f84ff2969480c79b81bc"},"cell_type":"code","source":"pred = clf.predict(data_test_count_tf)\nprint (pred)\n\ndf = pd.DataFrame({\"id\": test_data['id'],\"sentiment\": pred})\n\ndf.to_csv('submission_2.csv',index = False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5bf7995934063bb4bf0bda29b6f899f839728c7b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}