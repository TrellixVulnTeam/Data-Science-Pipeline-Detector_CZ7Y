{"cells":[{"metadata":{},"cell_type":"markdown","source":"turn on the internet in Settings of this notebook for git clone","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from importlib import reload\nimport sys\nfrom imp import reload\nimport warnings\nwarnings.filterwarnings('ignore')\nif sys.version[0] == '2':\n    reload(sys)\n    sys.setdefaultencoding(\"utf-8\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"unzip the training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile('../input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip') as existing_zip:\n    existing_zip.extractall()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"read the training data","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf1 = pd.read_csv('labeledTrainData.tsv', delimiter=\"\\t\")\ndf1 = df1.drop(['id'], axis=1)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"concat two dataset","execution_count":null},{"metadata":{"trusted":true,"_uuid":"1f502985bfb208f282d096cf4eda4df52ba628e3"},"cell_type":"code","source":"df = df1\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"clean text by deleteing the stop words and lemmatize","execution_count":null},{"metadata":{"trusted":true,"_uuid":"e08a2867d342084bde763daecb65f094273b06c7"},"cell_type":"code","source":"import re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words(\"english\")) \nlemmatizer = WordNetLemmatizer()\n\n\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n    text = text.lower()\n    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n    text = [word for word in text if not word in stop_words]\n    text = \" \".join(text)\n    return text\n\ndf['Processed_Reviews'] = df.review.apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28850b4961bc5ece382efbfe28b997884feaa804"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"010bdbd431234117fda785d37ff82bbadbcc1ab4"},"cell_type":"code","source":"df.Processed_Reviews.apply(lambda x: len(x.split(\" \"))).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"prepare test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile('../input/word2vec-nlp-tutorial/testData.tsv.zip') as existing_zip:\n    existing_zip.extractall()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv(\"testData.tsv\",header=0, delimiter=\"\\t\", quoting=3)\ndf_test.head()\ndf_test[\"review\"]=df_test.review.apply(lambda x: clean_text(x))\ndf_test[\"sentiment\"] = df_test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\ny_test = df_test[\"sentiment\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"install fasttext library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/facebookresearch/fastText.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd fastText/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training method for fasttext library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import fasttext\ndef train_ft(train_filename, test_filename, autotune_is=False):\n    if autotune_is:\n        ft = fasttext.train_supervised(\n            input=train_filename,\n            autotuneValidationFile=test_filename,\n        )\n    else:\n        ft = fasttext.train_supervised(\n            train_filename,\n            lr=0.489508510723173,\n            lrUpdateRate=100,\n            dim=100,\n            minn=2,\n            maxn=5,\n            ws=5,\n            epoch=100,\n            neg=5,\n        )\n    return ft\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_fasttext_params(model):\n    print(\"lr: {}\".format(model.lr))\n    print(\"lrUpdateRate: {}\".format(model.lrUpdateRate))\n    print(\"dim: {}\".format(model.dim))\n    print(\"minCount: {}\".format(model.minCount))\n    print(\"minCountLabel: {}\".format(model.minCountLabel))\n    print(\"minn: {}\".format(model.minn))\n    print(\"maxn: {}\".format(model.maxn))\n    print(\"wordNgrams: {}\".format(model.wordNgrams))\n    print(\"ws: {}\".format(model.ws))\n    print(\"epoch: {}\".format(model.epoch))\n    print(\"neg: {}\".format(model.neg))\n    print(\"loss: {}\".format(model.loss))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"write the train data and test data for fasttext library and train on it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filename = \"train.txt\"\ntest_filename = \"test.txt\"\nautotune_is = True\nwith open(train_filename, 'w') as f_train:\n    for row_data in df.itertuples():\n        f_train.write('__label__{} '.format(row_data.sentiment) + row_data.Processed_Reviews + '\\n')\nwith open(test_filename, 'w') as f_test:\n    for row_data in df_test.itertuples():\n        f_test.write('__label__{} '.format(row_data.sentiment) + row_data.review + '\\n')\n\n            \n            \nft = train_ft(train_filename, test_filename, autotune_is)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_fasttext_params(ft)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"confirm the result","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels, pred_probs = ft.predict(df_test[\"review\"].tolist(), k=-1)\ny_pred = [int(x[0][-1]) for x in pred_labels]\n\n\nfrom sklearn.metrics import precision_score,recall_score,f1_score, confusion_matrix\nprint('precision-score: {0}'.format(precision_score(y_pred, y_test)))\nprint('recall-score: {0}'.format(recall_score(y_pred, y_test)))\nprint('F1-score: {0}'.format(f1_score(y_pred, y_test)))\nprint('Confusion matrix:')\nconfusion_matrix(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ouput submission file \nimport copy\ndf_sub = copy.deepcopy(df_test)\ndf_sub[\"sentiment\"] = y_pred\ndf_sub = df_sub[['id','sentiment']]\ndf_sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}