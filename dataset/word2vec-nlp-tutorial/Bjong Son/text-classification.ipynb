{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/word2vec-nlp-tutorial/labeledTrainData.tsv\", delimiter='\\t')\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data =  pd.read_csv(\"../input/word2vec-nlp-tutorial/testData.tsv\", delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport pandas\nimport numpy\nimport json\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(review,remove_stopwords = False):\n    # html 제거\n    review_text = BeautifulSoup(review,\"html5lib\").get_text()\n    \n    # 특수문자 제거\n    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n    \n    # 소문자로 통일 후 리스트화\n    words = review_text.lower().split()\n    \n    if remove_stopwords:\n        # 불용어 제거\n        stop_words = set(stopwords.words('english'))\n        words = [w for w in words if not w in stop_words]\n \n    clean_review = ' '.join(words)\n    \n    return clean_review","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_train_reviews = []\nclean_test_reviews = []\n\nfor review in train_data['review']:\n    clean_train_reviews.append(preprocess(review,remove_stopwords = True))\n    \nfor review in test_data['review']:\n    clean_test_reviews.append(preprocess(review, remove_stopwords = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 174\n\ntokenizer = Tokenizer()\n\ntokenizer.fit_on_texts(clean_train_reviews + clean_train_reviews)\n\ntext_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\ntrain_inputs = pad_sequences(text_sequences,maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n\ntext_sequences = tokenizer.texts_to_sequences(clean_test_reviews)\ntest_inputs = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tokenizer.word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\n\nmodel = keras.Sequential()\nmodel.add(keras.layers.Embedding(vocab_size, 16))\nmodel.add(keras.layers.GlobalAveragePooling1D())\nmodel.add(keras.layers.Dense(16, activation=tf.nn.relu))\nmodel.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = train_inputs[:5000]\npartial_x_train = train_inputs[5000:]\n\ny_val = np.array(train_data['sentiment'][:5000])\npartial_y_train = np.array(train_data['sentiment'][5000:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(partial_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=30,\n                    batch_size=512,\n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_val = np.rint(model.predict(x_val)).astype('int32').squeeze()\n\nfor i in range(50):\n    print(y_val[i], pred_val[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = np.rint(model.predict(test_inputs)).astype('int32').squeeze()\n\nprint(pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commit_df = pd.DataFrame({'id': test_data['id'], 'sentiment':pred})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commit_df.to_csv('commit7.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commit_test = pd.read_csv(\"./commit7.csv\")\ncommit_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/word2vec-nlp-tutorial/sampleSubmission.csv\")\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}