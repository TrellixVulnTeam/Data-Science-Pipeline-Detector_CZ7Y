{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-20T22:46:28.469685Z","iopub.execute_input":"2021-12-20T22:46:28.470021Z","iopub.status.idle":"2021-12-20T22:46:28.481947Z","shell.execute_reply.started":"2021-12-20T22:46:28.469974Z","shell.execute_reply":"2021-12-20T22:46:28.481122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\", header=0, delimiter=\"\\t\", quoting=3)\ntest_data = pd.read_csv(\"../input/word2vec-nlp-tutorial/testData.tsv.zip\", header=0, delimiter=\"\\t\", quoting=3 )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:46:28.483831Z","iopub.execute_input":"2021-12-20T22:46:28.484616Z","iopub.status.idle":"2021-12-20T22:46:30.855613Z","shell.execute_reply.started":"2021-12-20T22:46:28.484577Z","shell.execute_reply":"2021-12-20T22:46:30.854678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Функция для очистки текстов от html тегов и знаков препинания, которая получает список слов и удаляет слова, которые на обучение не влияют**\n","metadata":{}},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\ndef rew_word(r_rew):\n    rev_text = BeautifulSoup(r_rew).get_text()\n    l = re.sub(\"[^a-zA-Z]\", \" \", rev_text)\n    low_case = l.lower()\n    words = low_case.split()\n    stop = set(stopwords.words(\"english\"))\n    words_n = [word for word in words if not word in stop]\n    return( \" \".join(words_n))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:46:30.858021Z","iopub.execute_input":"2021-12-20T22:46:30.858267Z","iopub.status.idle":"2021-12-20T22:46:30.868632Z","shell.execute_reply.started":"2021-12-20T22:46:30.858236Z","shell.execute_reply":"2021-12-20T22:46:30.867709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Обработка текстов в обучающей выборке**","metadata":{}},{"cell_type":"code","source":"def data_clean(data):\n    data_clean = []\n    size = data[\"review\"].size\n    for i in range( 0, size):\n        if((i+1)%1000 == 0):\n            print(f\"Review {i+1} from {size}\\n\") \n        data_clean.append(rew_word(data[\"review\"][i]))\n    return data_clean","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:46:30.869916Z","iopub.execute_input":"2021-12-20T22:46:30.870181Z","iopub.status.idle":"2021-12-20T22:46:30.887262Z","shell.execute_reply.started":"2021-12-20T22:46:30.870125Z","shell.execute_reply":"2021-12-20T22:46:30.886233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ntrain_clean = data_clean(train_data)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:46:30.889502Z","iopub.execute_input":"2021-12-20T22:46:30.88989Z","iopub.status.idle":"2021-12-20T22:46:51.895498Z","shell.execute_reply.started":"2021-12-20T22:46:30.889856Z","shell.execute_reply":"2021-12-20T22:46:51.894652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Формирование вектора признаков из выборки, полученной в результате выполнения функции data_clean**\n","metadata":{}},{"cell_type":"code","source":"vector = CountVectorizer(analyzer = \"word\",   \\\n                             tokenizer = None,    \\\n                             preprocessor = None, \\\n                             stop_words = None,   \\\n                             max_features = 20000)\ntrain_vector = vector.fit_transform(train_clean)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:46:51.897456Z","iopub.execute_input":"2021-12-20T22:46:51.897697Z","iopub.status.idle":"2021-12-20T22:46:56.079681Z","shell.execute_reply.started":"2021-12-20T22:46:51.897668Z","shell.execute_reply":"2021-12-20T22:46:56.078711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vector.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:46:56.081613Z","iopub.execute_input":"2021-12-20T22:46:56.081863Z","iopub.status.idle":"2021-12-20T22:46:56.089712Z","shell.execute_reply.started":"2021-12-20T22:46:56.081835Z","shell.execute_reply":"2021-12-20T22:46:56.088576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Обучение модели методом случайного леса**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators = 110) \nmas_train = train_vector.toarray()\nclf.fit(mas_train,train_data[\"sentiment\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:46:56.091074Z","iopub.execute_input":"2021-12-20T22:46:56.091301Z","iopub.status.idle":"2021-12-20T22:50:52.176596Z","shell.execute_reply.started":"2021-12-20T22:46:56.091274Z","shell.execute_reply":"2021-12-20T22:50:52.175672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Очищение данных тестовой выборки**","metadata":{}},{"cell_type":"code","source":"test_clean = data_clean(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:50:52.178102Z","iopub.execute_input":"2021-12-20T22:50:52.178454Z","iopub.status.idle":"2021-12-20T22:51:13.189077Z","shell.execute_reply.started":"2021-12-20T22:50:52.17842Z","shell.execute_reply":"2021-12-20T22:51:13.188198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vector = vector.transform(test_clean)\ntest_array = test_vector.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:51:13.190204Z","iopub.execute_input":"2021-12-20T22:51:13.190443Z","iopub.status.idle":"2021-12-20T22:51:19.461881Z","shell.execute_reply.started":"2021-12-20T22:51:13.190411Z","shell.execute_reply":"2021-12-20T22:51:19.460955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Применение модели на тестовой выборке и запись результатов в файл","metadata":{}},{"cell_type":"code","source":"result = clf.predict(test_array)\nsub = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\":result} )\nsub.to_csv( \"submission.csv\", index=False, quoting=3 )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:51:19.463056Z","iopub.execute_input":"2021-12-20T22:51:19.46327Z","iopub.status.idle":"2021-12-20T22:51:25.915533Z","shell.execute_reply.started":"2021-12-20T22:51:19.463244Z","shell.execute_reply":"2021-12-20T22:51:25.914271Z"},"trusted":true},"execution_count":null,"outputs":[]}]}