{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-29T15:35:08.08086Z","iopub.execute_input":"2021-12-29T15:35:08.081617Z","iopub.status.idle":"2021-12-29T15:35:08.112223Z","shell.execute_reply.started":"2021-12-29T15:35:08.08151Z","shell.execute_reply":"2021-12-29T15:35:08.111606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:38.219526Z","iopub.execute_input":"2021-12-29T15:35:38.219823Z","iopub.status.idle":"2021-12-29T15:35:42.138702Z","shell.execute_reply.started":"2021-12-29T15:35:38.219793Z","shell.execute_reply":"2021-12-29T15:35:42.13771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"./labeledTrainData.tsv\",delimiter=\"\\t\",quoting=3)\ntest = pd.read_csv(\"./testData.tsv\",delimiter=\"\\t\",quoting=3)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:43.778024Z","iopub.execute_input":"2021-12-29T15:35:43.778322Z","iopub.status.idle":"2021-12-29T15:35:44.541355Z","shell.execute_reply.started":"2021-12-29T15:35:43.778289Z","shell.execute_reply":"2021-12-29T15:35:44.540632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:45.227019Z","iopub.execute_input":"2021-12-29T15:35:45.227641Z","iopub.status.idle":"2021-12-29T15:35:45.249021Z","shell.execute_reply.started":"2021-12-29T15:35:45.227589Z","shell.execute_reply":"2021-12-29T15:35:45.248162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['review'][3]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:45.410294Z","iopub.execute_input":"2021-12-29T15:35:45.410605Z","iopub.status.idle":"2021-12-29T15:35:45.419332Z","shell.execute_reply.started":"2021-12-29T15:35:45.410542Z","shell.execute_reply":"2021-12-29T15:35:45.418532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport string","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:45.585148Z","iopub.execute_input":"2021-12-29T15:35:45.585473Z","iopub.status.idle":"2021-12-29T15:35:46.244656Z","shell.execute_reply.started":"2021-12-29T15:35:45.585439Z","shell.execute_reply":"2021-12-29T15:35:46.243893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Убираю знаки пунктуации, тэги и привожу слова к их леммам","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nstopwords=stopwords.words(\"english\")\n\ntokenizer = nltk.WordPunctTokenizer()\n\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\n\ndef clean_tweets(raw_review):\n    # токенизируем\n    line = tokenizer.tokenize(raw_review.lower())\n    \n    # уберем маленькие слова\n    filtered_line = [w for w in line if all(c not in string.punctuation for c in w) and len(w) > 3]\n    \n    # удалим стоп слова\n    good_line = [word for word in filtered_line if word not in stopwords]\n    \n    # лемматизация\n    good_line = [wordnet_lemmatizer.lemmatize(word,'v') for word in good_line]\n    \n    return \" \".join(good_line)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:46.245934Z","iopub.execute_input":"2021-12-29T15:35:46.246132Z","iopub.status.idle":"2021-12-29T15:35:46.26094Z","shell.execute_reply.started":"2021-12-29T15:35:46.246103Z","shell.execute_reply":"2021-12-29T15:35:46.260038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"clean_review\"] = train.loc[:, \"review\"].apply(clean_tweets)\ntest[\"clean_review\"] = test.loc[:, \"review\"].apply(clean_tweets)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:46.261999Z","iopub.execute_input":"2021-12-29T15:35:46.262212Z","iopub.status.idle":"2021-12-29T15:36:54.156826Z","shell.execute_reply.started":"2021-12-29T15:35:46.262186Z","shell.execute_reply":"2021-12-29T15:36:54.155902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['clean_review'][0]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:36:54.158912Z","iopub.execute_input":"2021-12-29T15:36:54.159641Z","iopub.status.idle":"2021-12-29T15:36:54.165321Z","shell.execute_reply.started":"2021-12-29T15:36:54.159598Z","shell.execute_reply":"2021-12-29T15:36:54.164493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Снова разделяю на слова","metadata":{}},{"cell_type":"code","source":"train_sents = [i.split() for i in train['clean_review']]\ntest_sents = [i.split() for i in test['clean_review']]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:36:54.166655Z","iopub.execute_input":"2021-12-29T15:36:54.167232Z","iopub.status.idle":"2021-12-29T15:36:55.117336Z","shell.execute_reply.started":"2021-12-29T15:36:54.167189Z","shell.execute_reply":"2021-12-29T15:36:55.116467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Пробовал предобученные эмбеддинги, давали около 0.8","metadata":{}},{"cell_type":"code","source":"import gensim\nimport gensim.downloader as api\n\n#word2vec = api.load(\"glove-twitter-100\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:36:55.118903Z","iopub.execute_input":"2021-12-29T15:36:55.119217Z","iopub.status.idle":"2021-12-29T15:36:55.124009Z","shell.execute_reply.started":"2021-12-29T15:36:55.119174Z","shell.execute_reply":"2021-12-29T15:36:55.123026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.test.utils import common_texts\nfrom gensim.models import Word2Vec\n\nword2vec = Word2Vec(sentences=train_sents + test_sents,\n                 min_count=20,\n                 window=5,\n                 sample=6e-5,\n                 vector_size=300,\n                 workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:36:55.125097Z","iopub.execute_input":"2021-12-29T15:36:55.125296Z","iopub.status.idle":"2021-12-29T15:37:19.740853Z","shell.execute_reply.started":"2021-12-29T15:36:55.125272Z","shell.execute_reply":"2021-12-29T15:37:19.740039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получаю вектор эмбэддинг для предложения, пропуски заполняю нулевыми векторами, также пробовал просто пропускать, качество примерно одинаковое.","metadata":{}},{"cell_type":"code","source":"X = []\ny = []\nfor i, sent in enumerate(train_sents):\n    y.append(train['sentiment'][i])\n    vectors = []\n    for word in sent:\n        if word in word2vec.wv:\n            vectors.append(word2vec.wv[word])\n        else:\n            vectors.append(list(np.zeros(300)))\n    X.append(np.mean(vectors, axis=0))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:37:19.742338Z","iopub.execute_input":"2021-12-29T15:37:19.742622Z","iopub.status.idle":"2021-12-29T15:37:47.279693Z","shell.execute_reply.started":"2021-12-29T15:37:19.742571Z","shell.execute_reply":"2021-12-29T15:37:47.27882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:37:47.280984Z","iopub.execute_input":"2021-12-29T15:37:47.281212Z","iopub.status.idle":"2021-12-29T15:37:47.286805Z","shell.execute_reply.started":"2021-12-29T15:37:47.281184Z","shell.execute_reply":"2021-12-29T15:37:47.286062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Делю на трейн и валидацию","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:37:47.288791Z","iopub.execute_input":"2021-12-29T15:37:47.28899Z","iopub.status.idle":"2021-12-29T15:37:47.318734Z","shell.execute_reply.started":"2021-12-29T15:37:47.288966Z","shell.execute_reply":"2021-12-29T15:37:47.318129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:37:47.31987Z","iopub.execute_input":"2021-12-29T15:37:47.320269Z","iopub.status.idle":"2021-12-29T15:37:47.44024Z","shell.execute_reply.started":"2021-12-29T15:37:47.320241Z","shell.execute_reply":"2021-12-29T15:37:47.439577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обучаю","metadata":{}},{"cell_type":"code","source":"model = SGDClassifier(alpha=0.00007, l1_ratio=0.15)\nmodel.fit(X_train,y_train)\n\n\ny_pred = model.predict(X_test)\nprint(classification_report(y_test,y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:46:19.791112Z","iopub.execute_input":"2021-12-29T15:46:19.791379Z","iopub.status.idle":"2021-12-29T15:46:20.483562Z","shell.execute_reply.started":"2021-12-29T15:46:19.791351Z","shell.execute_reply":"2021-12-29T15:46:20.482601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получаю эмбэддинги предложений для тестовой выборки","metadata":{}},{"cell_type":"code","source":"X_sub = []\nids = []\nfor i, sent in enumerate(test_sents):\n    ids.append(test['id'][i].replace('\"', ''))\n    vectors = []\n    for word in sent:\n        if word in word2vec.wv:\n            vectors.append(word2vec.wv[word])\n        else:\n            vectors.append(list(np.zeros(300)))\n    X_sub.append(np.mean(vectors, axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:09.528404Z","iopub.status.idle":"2021-12-29T15:35:09.528864Z","shell.execute_reply.started":"2021-12-29T15:35:09.528622Z","shell.execute_reply":"2021-12-29T15:35:09.528647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сабмит","metadata":{}},{"cell_type":"code","source":"ans = model.predict(X_sub)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:09.529879Z","iopub.status.idle":"2021-12-29T15:35:09.530332Z","shell.execute_reply.started":"2021-12-29T15:35:09.530091Z","shell.execute_reply":"2021-12-29T15:35:09.530115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({'id': ids, 'sentiment': ans}).to_csv('sub_7.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:35:09.531702Z","iopub.status.idle":"2021-12-29T15:35:09.532163Z","shell.execute_reply.started":"2021-12-29T15:35:09.531905Z","shell.execute_reply":"2021-12-29T15:35:09.531929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}