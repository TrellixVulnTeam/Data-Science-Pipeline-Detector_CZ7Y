{"cells":[{"metadata":{"trusted":true,"_uuid":"0f33e9ebcf56a2f4ac05b09fc375cf1d748f20fa"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28ef4e63cbaaa7235993a04293665bfc09da6cd6"},"cell_type":"code","source":"train = pd.read_csv('../input/labeledTrainData.tsv', sep='\\t', quoting=3)\ntest = pd.read_csv('../input/testData.tsv', sep='\\t', quoting=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35f4b85abf85b5a1a750f4ccf19f62adf01e2711"},"cell_type":"code","source":"def cleaning(raw_review):\n    remove_tags = BeautifulSoup(raw_review).get_text()\n    letters = re.sub(\"[^a-zA-Z]\",\" \", remove_tags)\n    lower_case = letters.lower()\n    words = lower_case.split()\n    stopword = stopwords.words(\"english\")\n    meaningful_words = [w for w in words if not w in stopword]\n    return(\" \".join(meaningful_words))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f8972daf3d301a0acc52001373ca787608240b88"},"cell_type":"code","source":"total_review = len(train[\"review\"])\nclean_train_reviews = []\nfor i in range(0 , total_review):\n    clean_train_reviews.append(cleaning(train[\"review\"][i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e056f10eaeaee60289203a8e8d23a90b110c166"},"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features = 10000)\ntrain_data_feature = vectorizer.fit_transform(clean_train_reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"940d05eb62e4fc0d8f92edc5aaff188ddb8fbf05"},"cell_type":"code","source":"total_test_review = len(test[\"review\"])\nclean_test_reviews = []\nfor i in range(0 , total_test_review):\n    clean_test_reviews.append(cleaning(test[\"review\"][i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f76937529a69bcf3cbdaacc7fefde5a0dfc035a0"},"cell_type":"code","source":"test_data_feature = vectorizer.fit_transform(clean_test_reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"718ca766a01387b557dd79d2d240695c1374975a"},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg = logreg.fit(train_data_feature, train[\"sentiment\"])\nresult = logreg.predict(test_data_feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9f54ccc30a217b2bd3670f6fb152a3415829eba"},"cell_type":"code","source":"output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\noutput.to_csv( \"Bag_of_Words_output.csv\", index=False, quoting=3 )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}