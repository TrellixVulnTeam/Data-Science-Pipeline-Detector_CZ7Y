{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"b117a8f4c292ee16934f16adffa2daf0d2f5d238"},"cell_type":"code","source":"!pip3 show nltk ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1b275b741f60a9e2f95112da044c4f4059fe8b6"},"cell_type":"code","source":"nltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3159761a112f98a69e898ef964d24ae4409ae282"},"cell_type":"code","source":"sentence = \"\"\"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ac5e7882412cea89734dd0eb985c5d7f701914f0"},"cell_type":"code","source":"tokens = nltk.word_tokenize(sentence)\ntokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc1a26a2921043f15cd509c61b9184305705672a"},"cell_type":"code","source":" tagged=nltk.pos_tag(tokens)\n#토큰화 하는 예제\n#토큰은 한 단어 수준? 보통 띄어쓰기 단위","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cc6ff85d33f3587080c1afd0935343f610ac314","scrolled":true},"cell_type":"code","source":"tagged[0:6]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e2c8e11e9f08ba5534f2b9b11ea86381e5fd44c"},"cell_type":"markdown","source":"# 데이터 구성<br>\n### Train data 구성:<br>\n### ID, Sentiment(Label), Review<br>\n### Test data 구성:<br>\n### ID, Review<br>\n\n## Sentiment는 0,1 로 구성 되어 있으며 1은 Positive, 0은 Negative**"},{"metadata":{"_uuid":"5f64ea902959d73f3c2f8450afacfb0543cc615b"},"cell_type":"markdown","source":"# 1.데이터 읽기"},{"metadata":{"trusted":true,"_uuid":"c30cc6bec6b4516869ddae531923b1f78a24406f"},"cell_type":"code","source":"import pandas as pd\n\"\"\"\nheader=0 은 파일의 첫번째 줄에  이름이 있음을 나타내며\ndelimiter =\\t 는 필드가 탭으로 구분 (in r sep=\"\\t\")\nquoting = 3 옵션 3은 쌍따옴표 무시\nQUOTE_MINIMAL (0), 구분자 같은 특별한 문자가 포함된 필드만 적용\nQUOTE_ALL (1), 모든 필드에 적용\nQUOTE_NONNUMERIC (2) or 숫자가 아닌 값에만 적용\nQUOTE_NONE (3). 값을 둘러싸지 않음\n기본은 QUOTE_MINIMAL (0)\n\"\"\"\ntrain0=pd.read_csv(\"../input/labeledTrainData.tsv\",header=0,delimiter='\\t',quoting=0)\ntrain1=pd.read_csv(\"../input/labeledTrainData.tsv\",header=0,delimiter='\\t',quoting=1)\ntrain2=pd.read_csv(\"../input/labeledTrainData.tsv\",header=0,delimiter='\\t',quoting=2)\ntrain=pd.read_csv(\"../input/labeledTrainData.tsv\",header=0,delimiter='\\t',quoting=3)\ntest=pd.read_csv(\"../input/testData.tsv\",header=0,delimiter='\\t',quoting=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd0634d74fe4daa101b767df8a61e6824e2b808f"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4a854cbc97c03640f01ba2b9fd0e659b45e8243"},"cell_type":"code","source":"train0.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"02d1a6f74b2072090e4fba4b79c35ba9107af27b"},"cell_type":"code","source":"train1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"46097264aabf4fe2995f33bdaae8ec094ae5c970"},"cell_type":"code","source":"train2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"38f798acc7e4888c68a226b652cb429b892bda54"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"839fd02c3ee77a3b8f5475ab8e0dcba61f6f7f7e"},"cell_type":"code","source":"test.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0603705c8606fe576198b3cec703691ec86da4cb"},"cell_type":"code","source":"train.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"91e4d05531285c715063081ce97b162449a70e11"},"cell_type":"code","source":"test.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"180adc79edf20c5516630aa57e04f76d645a274b"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f82f4a3d9b71dfa4b2a248767d73f94afeda38a"},"cell_type":"markdown","source":"## id, review는 문자\n## sentiment 는 숫자"},{"metadata":{"trusted":true,"_uuid":"8280ce33bca10b089a3c47f124ef0bc8ddf7f642"},"cell_type":"code","source":"train.describe()\n#sentiment에 대해 분석해줌","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c2ebbdea9524222de41f09b00103e657a33a9df"},"cell_type":"code","source":" train['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0df83cc4b7a89a77fb747555cfde7bd438849b67"},"cell_type":"code","source":"train['review'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f90d9ce939aed3265dbe957ec8bd9bbb576e1a4"},"cell_type":"code","source":"# html 태그 때문에 텍스트 전처리 필요\ntrain['review'][0][:700]\n#첫번째 데이터에 대해 700자 까지만 본다","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12748a747b96e4da556a5aca8a8338b81bf6f9c6"},"cell_type":"markdown","source":"# 트위터의 형태소 분석기 사용\n정규화 normalization (입니닼ㅋㅋ -> 입니다 ㅋㅋ, 샤릉해 -> 사랑해)\n\n한국어를 처리하는 예시입니닼ㅋㅋㅋㅋㅋ -> 한국어를 처리하는 예시입니다 ㅋㅋ\n토큰화 tokenization\n\n한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어Noun, 를Josa, 처리Noun, 하는Verb, 예시Noun, 입Adjective, 니다Eomi ㅋㅋKoreanParticle\n어근화 stemming (입니다 -> 이다)\n\n한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어Noun, 를Josa, 처리Noun, 하다Verb, 예시Noun, 이다Adjective, ㅋㅋKoreanParticle\n어구 추출 phrase extraction\n\n한국어를 처리하는 예시입니다 ㅋㅋ -> 한국어, 처리, 예시, 처리하는 예시\n\n[관련 슬라이드](http://docs.google.com/presentation/d/10CZj8ry03oCk_Jqw879HFELzOLjJZ0EOi4KJbtRSIeU/edit)\n\n[트위터 형태소 분석기](https://github.com/twitter/twitter-korean-text)"},{"metadata":{"trusted":true,"_kg_hide-output":false,"scrolled":true,"_uuid":"4875c89cf3ca3664c55cdfd8a50675ba22578baf"},"cell_type":"code","source":"from bs4 import BeautifulSoup\n\nexample1 = BeautifulSoup(train['review'][0], \"html5lib\")\n\n#html5lib parser을 통해 태그 삭제\n#\"html.parser\" : 빠르지만 유연하지 않기 때문에 단순한 HTML문서에 사용합니다.\n#\"lxml\" : 매우 빠르고 유연합니다.\n#\"xml\" : XML 파일에만 사용합니다.\n#\"html5lib\" : 복잡한 구조의 HTML에 대해서 사용합니다.\n#출처: \n#https://jungwoon.github.io/python/2018/03/20/Data-Analysis-With-Python-3/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7409edd50acc15a489be460e9b8bb683405429b5"},"cell_type":"code","source":"print(type(example1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c16241f174db278ec52f7a04403c67f1d335bb08"},"cell_type":"markdown","source":"![KakaoTalk_20181120_211608657.png](https://raw.githubusercontent.com/Sup90/R-/master/KakaoTalk_20181120_211608657.png)"},{"metadata":{"trusted":true,"_kg_hide-output":false,"_uuid":"6aa8e9cffbe421aa86356b661b2c2774f67d9851"},"cell_type":"code","source":"print(train['review'][0][:700])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false,"_uuid":"686d2a8e1fec11c10e0e64706f0dbd81b69cdc8a"},"cell_type":"code","source":"print(type(example1.get_text()))\n#클래스가 str변환됨","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false,"scrolled":true,"_uuid":"5a09cc01e4e61eafa8d4f77ddb60bc9114562cd5"},"cell_type":"code","source":"example1.get_text()[:700]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false,"scrolled":true,"_uuid":"b8595801727776a0e2acd34988d3908b6850ba72"},"cell_type":"code","source":"import re #정규표현식 호출-> 특수문제 제거 용도\n#소문자와 대문자가 아닌 것은 공백으로 대체\nletters_only=re.sub('[^a-zA-Z]', ' ', example1.get_text())\n#^은 아닌거 선택, a-z까지 소문자, A-Z 대문자 아닌거는 ' '으로 치환 \n#대상: example1.get_text()\nletters_only","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fee7843536b26877bc2bb4a3afad53c9da5b5a5c"},"cell_type":"code","source":"#모두 소문자로 변환\nlower_case=letters_only.lower()\nlower_case","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"f64dc57d15e4c8f56d43b065299c8c22a0831fb4"},"cell_type":"code","source":"#토큰화\nwords=lower_case.split()\n#단순히 공백(스페이스, 탭 )기준으로 짜른 후 리스트로 반환\nprint(type(words))\nprint(len(words))\nwords[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dccb46d8a99abbf184b807d74a9cdc9b044ceee9"},"cell_type":"markdown","source":"# 불용어 제거(Stopword Removal)\n### 일반적으로 코퍼스에서 자주 나타나는 단어는 학습 모델로서 학습이나 예측 프로세스에 실제로 기여하지 않아 다른 텍스트와 구별하지 못한다. 예를 들어 조사, 접미사, i, me, my, it, this, that, is, are 등과 같은 단어는 빈번하게 등장하지만, 실제 의미를 찾는데 크게 기여하지 않는다. Stopwords는 to또는 the와 같은 용어를 포함하므로 사전 처리 단계에서 제거하는 것이 좋다. NLTK에는 153개의 영어 불용어가 미리 정의되어 있다. 17개의 언어에 대해 정의되어 있으며 한국어는 없다."},{"metadata":{"trusted":true,"_uuid":"5c546fbfc5efce166290d2202e2d3d5c3fcad830"},"cell_type":"code","source":"#words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fe993e34457b1ce6011079b873feba18d85dfa72","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"import nltk\n#로컬 환경에서 nltk 설치는 잘되지만 nltk 데이터가 설치가 잘안된다.\nfrom nltk.corpus import stopwords\n#nltk의 corpus에서 stopwords 호출\nstopwords.words('english')[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ba3bec7c4e50cf09bacf1f61633d74c67ad7652e"},"cell_type":"code","source":"#stopword를 제거한 토큰들\nwords=[w for w in words if not w in stopwords.words('english')]\n# w에 대해 w가 words에 있을 때 w가 stopwords에 없다면 words에 w를 넣어라 \n# 3개의 변수가 같아야함\nprint(len(words))\nwords[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"724862cc9c415cc5d9090a92cf5edc2957f52522"},"cell_type":"markdown","source":"# 스테밍(어간추출, 형태소 분석)\n### 출처 : 어간 추출 - 위키백과, 우리 모두의 백과사전\n\n### 어간 추출(語幹 抽出, 영어: stemming)은 어형이 변형된 단어로부터 접사 등을 제거하고 그 단어의 어간을 분리해 내는 것\n### message, messages, messaging과 같이 복수형, 진행형 등의 문자를 같은 의미의 단어로 다룰 수 있도록 도와준다.\n### stemming(형태소 분석): 여기에서는 NLTK에서 제공하는 형태소 분석기를 사용한다. 포터 형태소 분석기는 보수적이고 랭커스터 형태소 분석기는 좀 더 적극적이다. 형태소 분석 규칙의 적극성 때문에 랭커스터 형태소 분석기는 더 많은 동음이의어 형태소를 생산한다. 참고 : 모두의 데이터 과학 with 파이썬(길벗)"},{"metadata":{"trusted":true,"_uuid":"eb5ed9ac7d66abb194898d2ec83b8295933d4d4e","scrolled":true},"cell_type":"code","source":"stemmer=nltk.stem.PorterStemmer()\nprint(stemmer.stem('maximum'))\nprint(\"The stemmed form of running is:\",stemmer.stem(\"running\"))\nprint(\"The stemmed form of runs is: {}\".format(stemmer.stem(\"runs\")))\nprint(\"The stemmed form of run is: {}\".format(stemmer.stem(\"run\")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bb413e6d276e2c5c96cd2a899b30671a6f70603"},"cell_type":"code","source":"# 랭커스터 스태머의 사용 예\nfrom nltk.stem.lancaster import LancasterStemmer\nlancaster_stemmer = LancasterStemmer()\nprint(lancaster_stemmer.stem('maximum'))\nprint(\"The stemmed form of running is: {}\".format(lancaster_stemmer.stem(\"running\")))\nprint(\"The stemmed form of runs is: {}\".format(lancaster_stemmer.stem(\"runs\")))\nprint(\"The stemmed form of run is: {}\".format(lancaster_stemmer.stem(\"run\")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f4f3010968cc9f37ba482964a3d784896f4d3da"},"cell_type":"code","source":"from nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer('english')\n#snowball stemmer 한국어는 지원안함\nwords = [stemmer.stem(w) for w in words]\n#for문을 돌면서 words에서 w를 뽑아 stemmer를 적용하여 words에 저장","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68e05ae382530a70899e035028895f40430b0e40"},"cell_type":"code","source":"#words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c64ad0bb41cb12319f59e47c682ed04e5f551f7"},"cell_type":"code","source":"words[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"772518e2d5ec7500d342f5d25214d616a72cb94f"},"cell_type":"code","source":"stemmer.stem(\"cats\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"996343106e64ec5ffa5bd1fb050032930d447dbf"},"cell_type":"code","source":"words[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f469c965e7c8cde72eb40963a3d9e5e7d00c6a3"},"cell_type":"markdown","source":"['stuff',\n 'go',\n 'moment',\n 'mj',\n 'start',\n 'listen',\n 'music',\n 'watch',\n 'odd',\n 'documentari']\n \n ['stuff',\n 'going',\n 'moment',\n 'mj',\n 'started',\n 'listening',\n 'music',\n 'watching',\n 'odd',\n 'documentary']\n "},{"metadata":{"_uuid":"7cf391e6c5baab4a377777cce537c82cbeef666a"},"cell_type":"markdown","source":"Lemmatization 음소표기법\n언어학에서 음소 표기법 (또는 lemmatization)은 단어의 보조 정리 또는 사전 형식에 의해 식별되는 단일 항목으로 분석될 수 있도록 굴절된 형태의 단어를 그룹화하는 과정이다.\n예를 들어 동음이의어가 문맥에 따라 다른 의미가 있는데\n\n1) 배가 맛있다.\n2) 배를 타는 것이 재미있다.\n3) 평소보다 두 배로 많이 먹어서 배가 아프다.\n\n위에 있는 3개의 문장에 있는 배는 모두 다른 의미가 있다. \n\n레마타이제이션은 이때 앞뒤 문맥을 보고 단어의 의미를 식별하는 것이다.\n영어에서 meet는 meeting으로 쓰였을 때 회의를 뜻하지만, meet일 때는 만나다는 뜻을 갖는데 그 단어가 명사로 쓰였는지 동사로 쓰였는지에 따라 적합한 의미가 있도록 추출하는 것이다.\n\nStemming은 단어 그 자체만을 고려하지만 Lemmatization은 그 단어가 문장 속에서 어떤 품사(Part-of-speech)로 쓰였는지까지 판단한다.\nLemmatization이 문장이 문장 속에서 의미를 반영하여 어간을 추출한다고 할 수 있다."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"2f1ccaab9099049065be8cf2928619f81b83d759"},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\na=\"the boy's cars are different colors\"\nb='she is meeting friends'\na1=a.split()\nb1=b.split()\nprint(wordnet_lemmatizer.lemmatize('fly'))\nprint(wordnet_lemmatizer.lemmatize('flies'))\nprint(wordnet_lemmatizer.lemmatize('a'))\na2= [wordnet_lemmatizer.lemmatize(w) for w in a1]\nb2= [wordnet_lemmatizer.lemmatize(w) for w in b1]\n# 처리 후 단어\nb2[:10]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6f04081cae1b1d780b8f8ab57ddc8b647fbb35eb"},"cell_type":"code","source":"def review_to_words(raw_review):\n    # 1. HTML 제거\n    review_text = BeautifulSoup(raw_review,'lxml').get_text()\n    # 2. 영문자가 아닌 문자는 공백으로 변환\n    letters_only = re.sub('[^a-zA-Z]',' ',review_text)\n    # 3. 소문자 변환 및 띄어쓰기 단위로 토큰화\n    words=letters_only.lower().split()\n    type(words)\n    # 4. 파이썬에서는 리스트보다 세트로 찾는게 훨씬 빠르다.\n    # stopwords 를 세트로 변환한다.\n    stops=set(stopwords.words('english'))\n    type(stops)\n    # 5. stopwords 불용어 제거\n    meaningful_words=[w for w in words if not w in stops]\n    # 6. 어간추출\n    stemming_words=[stemmer.stem(w) for w in meaningful_words]\n    # 7. 공백으로 구분된 문자열을 결합하여 결과를 반환\n    return(' '.join(stemming_words))\n\nclean_review=review_to_words(train['review'][0])\nclean_review[:700]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d946930f0b25340d375e29195ebf3ac055912524"},"cell_type":"code","source":"def review_to_words2( raw_review ):\n    # 1. HTML 제거\n    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n    # 2. 영문자가 아닌 문자는 공백으로 변환\n    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n    # 3. 소문자 변환\n    words = letters_only.lower().split()\n    # 4. 파이썬에서는 리스트보다 세트로 찾는 게 훨씬 빠르다.\n    # stopwords 를 세트로 변환한다.\n    stops = set(stopwords.words('english'))\n    # 5. Stopwords 불용어 제거\n    meaningful_words = [w for w in words if not w in stops]\n    # 6. 어간추출\n    stemming_words = [stemmer.stem(w) for w in meaningful_words]\n    # 7. 공백으로 구분된 문자열로 결합하여 결과를 반환\n    return( ' '.join(stemming_words) )\nclean_review = review_to_words(train['review'][0])\nclean_review","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5153683123c1a5ca41386e93fde8a5a5d1187928"},"cell_type":"code","source":"#전체 데이터 리뷰를 대상으로 전처리\n#전체 리뷰 데이터 수\nnum_reviews=train['review'].size\nnum_reviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92e25e75d92566e5dd7ec097016c0c87a61ee2ae"},"cell_type":"code","source":"#for i in range(0, num_reviews):\n#    if (i + 1)%5000 == 0:\n#        print('Review {} of {} '.format(i+1, num_reviews))    \n#    clean_train_reviews.append(review_to_words(train['review'][i]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"d3c206d09f9a38376fdbf6746b03e7f2b1793717"},"cell_type":"code","source":"# %time train['review_clean']=train['review'].apply(review_to_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"730c59fbb1d46301efc3db465e0eba2b0e9f9573"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"06f7f114cfdc7151c060d5ad09a902d17d9b52dd"},"cell_type":"code","source":"train['review']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6b6534cae4a699c2db364276c8f446c93cb07aca"},"cell_type":"code","source":"#train데이터에서 review컬럼에 대해 review_to_words 함수를 적용\n#코드를 한줄로 만들었지만 여전히 오래걸림\nfrom multiprocessing import Pool\nimport numpy as np\n\ndef _apply_df(args):\n    df, func, kwargs = args\n    return df.apply(func, **kwargs)\n\ndef apply_by_multiprocessing(df, func, **kwargs):\n    # 키워드 항목 중 workers 파라메터를 꺼냄\n    workers = kwargs.pop('workers')\n    # 위에서 가져온 workers 수로 프로세스 풀을 정의\n    pool = Pool(processes=workers)\n    # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n    result = pool.map(_apply_df, [(d, func, kwargs)\n            for d in np.array_split(df, workers)])\n    pool.close()\n    # 작업 결과를 합쳐서 반환\n    return pd.concat(list(result))\n\nclean_train_reviews=apply_by_multiprocessing(\\\n                                                  train['review'],review_to_words,workers=4)\nclean_test_reviews = apply_by_multiprocessing(\\\n    test['review'], review_to_words2, workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c8d2cd35570763c1b92fbb133920cb5c741128a"},"cell_type":"code","source":"clean_train_reviews[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19fdf3e6d71519e396f0ea9c4cdf2ff4ec78e12d"},"cell_type":"markdown","source":"\n# 워드 클라우드\n### 단어의 빈도 수 데이터를 가지고 있을 때 이용할 수 있는 시각화 방법\n### 단순히 빈도 수를 표현하기 보다는 상관관계나 유사도 등으로 배치하는 게 더 의미 있기 때문에 큰 정보를 얻기는 어렵다.\n## si업체에서 사용 근데 큰의미 x"},{"metadata":{"trusted":true,"_uuid":"6f472f1b23fa61973ba00f7c91060bf323c14c6c"},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n# %matplotlib inline 설정을 해주어야지만 노트북 안에 그래프가 디스플레이 된다.\n%matplotlib inline\n\ndef displayWordCloud(data = None, backgroundcolor = 'white', width=800, height=600 ):\n    wordcloud = WordCloud(stopwords = STOPWORDS, #불용어 처리\n                          background_color = backgroundcolor, # 배경색\n                         width = width, height = height).generate(data)\n    plt.figure(figsize = (15 , 10))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"f7134be50ce03420f575ef2e9ba246c781e028bf"},"cell_type":"code","source":"' '.join(clean_train_reviews[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f472f1b23fa61973ba00f7c91060bf323c14c6c"},"cell_type":"code","source":"# 학습 데이터의 모든 단어에 대한 워드 클라우드를 그려본다.\n%time displayWordCloud(''.join(clean_train_reviews))\n\n# 왜 ' '.join을 쓰는가?\n# 공백으로 구분된 문자열로 결합?\n# 데이터를 공백으로 구분하여 통째로 넣는 것","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db67d3f662eeff2f9c9977ff99731c9144afcb20"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15ea4dad78a3ea46ac4e7eec6fb8b5a1421a7f95","scrolled":true},"cell_type":"code","source":"# 단어 수\ntrain['num_words'] = clean_train_reviews.apply(lambda x: len(str(x).split()))\n#apply에다가 lambda 식 적용\n#str(x) 문자화\n#str(x).split() tokenize\n#len(str(x).split()) 단어 수 count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2821c63b01857e50c0eb561aad5a202adaa5c693"},"cell_type":"code","source":"len(str(clean_train_reviews[1]).split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15ea4dad78a3ea46ac4e7eec6fb8b5a1421a7f95"},"cell_type":"code","source":"# 중복을 제거한 단어 수\ntrain['num_uniq_words'] = clean_train_reviews.apply(lambda x: len(set(str(x).split())))\n#set을 통해 리스트를 set으로 변환하여 중복 제거","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15ea4dad78a3ea46ac4e7eec6fb8b5a1421a7f95"},"cell_type":"code","source":"# 첫 번째 리뷰에 대해 tokenize\nx = clean_train_reviews[0]\nx = str(x).split()\nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9883a7ab8061431e552a72c50420caa743bf901"},"cell_type":"code","source":"import seaborn as sns\n\nfig, axes = plt.subplots(ncols=2)\n#가로로 2개의 그래프 구현\nfig.set_size_inches(18, 6)\nprint('리뷰 별 단어 평균값 :', train['num_words'].mean())\nprint('리뷰 별 단어 중간값', train['num_words'].median())\nsns.distplot(train['num_words'], bins=100, ax=axes[0])\naxes[0].axvline(train['num_words'].median(), linestyle='dashed')\naxes[0].set_title('리뷰 별 단어 수 분포')\nprint('리뷰 별 고유 단어 평균값 :', train['num_uniq_words'].mean())\nprint('리뷰 별 고유 단어 중간값', train['num_uniq_words'].median())\nsns.distplot(train['num_uniq_words'], bins=100, color='g', ax=axes[1])\naxes[1].axvline(train['num_uniq_words'].median(), linestyle='dashed')\naxes[1].set_title('리뷰 별 고유한 단어 수 분포')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9883a7ab8061431e552a72c50420caa743bf901"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"894603e1ba5f546583ea1dcb66c1fff3f2391644"},"cell_type":"markdown","source":"# 사이킷런의 CountVectorizer를 통해 피처 생성\n## 정규표현식을 사용해 토큰을 추출한다.\n## 모두 소문자로 변환시키기 때문에 good, Good, gOod이 모두 같은 특성이 된다.\n## 의미 없는 특성을 많이 생성하기 때문에 적어도 두 개의 문서에 나타난 토큰만을 사용한다.\n## min_df로 토큰이 나타날 최소 문서 개수를 지정할 수 있다."},{"metadata":{"trusted":true,"_uuid":"183027108c9980bd07248e44a03dd6bd4a97a07a"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import Pipeline\n\n# 튜토리얼과 다르게 파라메터 값을 수정 \n# 파라메터 값만 수정해도 캐글 스코어 차이가 크게 남\nvectorizer = CountVectorizer(analyzer = 'word', \n                             tokenizer = None,#tokenizer 설정\n                             preprocessor = None, \n                             stop_words = None,#불용어\n                             min_df = 2, # 토큰이 나타날 최소 문서 개수\n                             ngram_range=(1, 3),#ngram 갯수\n                             max_features = 20000 #최대 토큰 갯수\n                            )\nvectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2714e19cc9efd4644c9fe3365bd746dfd41bd565"},"cell_type":"code","source":"# fit_transform의 속도 개선을 위해 파이프라인을 사용하도록 개선\n# 참고 : https://stackoverflow.com/questions/28160335/plot-a-document-tfidf-2d-graph\npipeline = Pipeline([\n    ('vect', vectorizer),# 'vectorizer'자리에 tf - idf 사용 가능\n])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2714e19cc9efd4644c9fe3365bd746dfd41bd565"},"cell_type":"code","source":"%time train_data_features = pipeline.fit_transform(clean_train_reviews)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"487a09ecda2306c6d4a446b51dc219a5eda7d1d6"},"cell_type":"code","source":"train_data_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f387e4d025b563810e12873a7e24281e75ec66ad"},"cell_type":"code","source":"train_data_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27cfd458e7f1f6fb75bd8a72c718f32d4b9cdcb7"},"cell_type":"code","source":"vocab = vectorizer.get_feature_names()\n#행렬의 feature name을 확인 가능\n\nvocab[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a6d0471779e1c7fb27b4b83054f793c174e1828"},"cell_type":"code","source":"train_data_features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab89835d267f807d87f168981c07100da3297e8c"},"cell_type":"code","source":"# 벡터화된 피처를 확인해 봄\nimport numpy as np\ndist = np.sum(train_data_features, axis=0)\ndist\ndist.shape\n#http://taewan.kim/post/numpy_sum_axis/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab89835d267f807d87f168981c07100da3297e8c"},"cell_type":"code","source":"for tag, count in zip(vocab, dist):\n    print(count)\n    print(tag)\n#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab89835d267f807d87f168981c07100da3297e8c"},"cell_type":"code","source":"pd.DataFrame(dist, columns=vocab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d37200cfc20bdd1eb9c1c8c699a86d5872967db"},"cell_type":"code","source":"pd.DataFrame(train_data_features[:100].toarray(), columns=vocab).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d31bf703c963013bef5812ebbb0ce75502cefbc"},"cell_type":"markdown","source":"랜덤 포레스트의 가장 핵심적인 특징은 임의성(randomness)에 의해 서로 조금씩 다른 특성을 갖는 트리들로 구성된다는 점이다. 이 특징은 각 트리의 예측(prediction)들이 비상관화(decorrelation) 되게 하며, 결과적으로 일반화(generalization) 성능을 향상한다. 또한, 임의화(randomization)는 포레스트가 노이즈가 포함된 데이터에 대해서도 강인하게 만들어 준다."},{"metadata":{"trusted":true,"_uuid":"c58ee6ce3afdd9f9fdc54dfc0a2e0c94c80325bd"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# 랜덤포레스트 분류기를 사용\nforest = RandomForestClassifier(\n    n_estimators = 100, n_jobs = -1,#모든 코어 사용 -1\n    random_state=2018 #파라미터 튜닝을 위해 회차마다 결과 동일하게 만듬    \n    )\nforest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e0f2d7a76d200e7a452b5001896e024ed6f391a"},"cell_type":"code","source":"%time forest = forest.fit(train_data_features ,train['sentiment']) #행렬 데이터,벡터 데이터\n                        \n                         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bbf0ea080c4ad84123d7c0c2b95869e95ca587f"},"cell_type":"code","source":"forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07cc62540edda42d4cb40aad8a74d6e7ae1d5ec4"},"cell_type":"code","source":"from sklearn.cross_validation import cross_val_score\n%time np.mean(cross_val_score(forest, train_data_features, train['sentiment'], cv=10,scoring='roc_auc'))#cross validation #roc 커브 사용\n                               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"962ac0bcd8afd8ed7797fc4817cd6c160f2ede67"},"cell_type":"code","source":"# 위에서 정제해준 리뷰의 첫 번째 데이터를 확인\nclean_test_reviews[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51dd533b303545b3cabe988fc6f52eff9b0442da"},"cell_type":"code","source":"# 테스트 데이터를 벡터화 함\n%time test_data_features = pipeline.transform(clean_test_reviews)#파이프 라인을 통해 여러개의 쓰래드 사용하여 벡터화\ntest_data_features = test_data_features.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5207a6982273f5e512e20b95bf891e99acc97c7"},"cell_type":"code","source":"test_data_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"568e01f5de48076a81ec2a18fd54a205b4675745"},"cell_type":"code","source":"# 벡터화된 단어로 숫자가 문서에서 등장하는 횟수를 나타낸다\ntest_data_features[5][:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faaa9eec9cb357da6aaf34dcf58a9d5e481a357b"},"cell_type":"code","source":"# 벡터화하며 만든 사전에서 해당 단어가 무엇인지 찾아볼 수 있다.\n# vocab = vectorizer.get_feature_names()\nvocab[8], vocab[2558], vocab[2559], vocab[2560]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7389ddc28eb4bac3c89d46f907ec5183cbba58ba"},"cell_type":"code","source":"# 테스트 데이터를 넣고 예측한다.\nresult = forest.predict(test_data_features)\nresult[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"417c14a2feb789bc2781282ea50b1582509f4f51"},"cell_type":"code","source":"# 예측 결과를 저장하기 위해 데이터프레임에 담아 준다.\noutput = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22b7ef6e5b758cd1bff06f2cf8076fa09f8b4e2a"},"cell_type":"code","source":"output.to_csv('data/tutorial_1_BOW_model.csv', index=False, quoting=3)\noutput_sentiment = output['sentiment'].value_counts()\nprint(output_sentiment[0] - output_sentiment[1])\noutput_sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11b937f2412efa177bd20d7e994b40a0627d67ee"},"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsns.countplot(train['sentiment'], ax=axes[0])\nsns.countplot(output['sentiment'], ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e93dbb90d9c0d1b99814db924a841fdb0e5a8666"},"cell_type":"markdown","source":"첫 번째 제출을 할 준비가 되었다.\n리뷰를 다르게 정리하거나 'Bag of Words' 표현을 위해 다른 수의 어휘 단어를 선택하거나 포터 스테밍 등을 시도해 볼 수 있다.\n다른 데이터 세트로 NLP를 시도해 보려면 로튼 토마토(Rotten Tomatoes)를 해보는 것도 좋다."},{"metadata":{"trusted":true,"_uuid":"5cc66b46bb6ae9b0fbdc5eb09169e5d7b7bf30c3"},"cell_type":"code","source":"# 파라메터를 조정해 가며 점수를 조금씩 올려본다.\n\n# uni-gram 사용 시 캐글 점수 0.84476\nprint(436/578)\n# tri-gram 사용 시 캐글 점수 0.84608\nprint(388/578)\n# 어간추출 후 캐글 점수 0.84780\nprint(339/578)\n# 랜덤포레스트의 max_depth = 5 로 지정하고\n# CountVectorizer의 tokenizer=nltk.word_tokenize 를 지정 후 캐글 점수 0.81460\nprint(546/578)\n# 랜덤포레스트의 max_depth = 5 는 다시 None으로 변경\n# CountVectorizer max_features = 10000개로 변경 후 캐글 점수 0.85272\nprint(321/578)\n# CountVectorizer의 tokenizer=nltk.word_tokenize 를 지정 후 캐글 점수 0.85044\nprint(326/578)\n# CountVectorizer max_features = 10000개로 변경 후 캐글 점수 0.85612\nprint(305/578)\n# 0.85884\nprint(296/578)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}