{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bag of Words Meets Bags of Popcorn","metadata":{}},{"cell_type":"markdown","source":"## Imports & Reading the Data","metadata":{}},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom string import punctuation, printable, digits\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential, load_model\n\nfrom matplotlib import pyplot as plt\nplt.style.use('ggplot')\n\nimport spacy\nnlp = spacy.load('en_core_web_sm')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-30T18:35:11.181888Z","iopub.execute_input":"2021-10-30T18:35:11.182197Z","iopub.status.idle":"2021-10-30T18:35:11.668322Z","shell.execute_reply.started":"2021-10-30T18:35:11.182164Z","shell.execute_reply":"2021-10-30T18:35:11.66739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\ntrain_df = pd.read_csv('../input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip', delimiter = \"\\t\", encoding = 'utf-8')\ntest_df = pd.read_csv('../input/word2vec-nlp-tutorial/testData.tsv.zip', delimiter = \"\\t\", encoding = 'utf-8')\n\ncombined_dfs = [train_df, test_df]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-10-30T18:35:11.670121Z","iopub.execute_input":"2021-10-30T18:35:11.670335Z","iopub.status.idle":"2021-10-30T18:35:12.897176Z","shell.execute_reply.started":"2021-10-30T18:35:11.67031Z","shell.execute_reply":"2021-10-30T18:35:12.896401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since all reviews have been divided into two balanced groups by their sentiments (Each containing 12500 reviews), we need not to worry about the metrics we are going to use. (*Accuracy* for instance be misleading on an imbalanced dataset!)","metadata":{}},{"cell_type":"markdown","source":"## Preprocessings","metadata":{}},{"cell_type":"code","source":"# Remove HTML tags\ndef remove_html(text: str, replacement = ' ') -> str:\n    return re.sub(r'<.*?>', replacement, text)\n\n# Remove non-ASCII characters\ndef filter_printables(text: str) -> str:\n    return ''.join(filter(lambda x: x in printable, text))\n\n# Remove numbers from the string\ndef remove_numbers(string: str) -> str:\n    return string.translate({ord(d): None for d in digits})\n\n# Remove two backslashes\ndef remove_double_backslashes(text: str) -> str:\n    return text.replace('\\\\', '')\n\n# Remove all punctuations\ndef remove_punctuation(string: str, repl: str = '') -> str:\n    return string.translate(str.maketrans('', '', punctuation))\n\n# Fix multiple spacings\ndef fix_spacing(string: str) -> str:\n    return ' '.join(string.split())\n\n# Lemmatize all words\ndef lemmatize(string: str) -> str:\n    return ' '.join([token.lemma_ for token in nlp(string)])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:35:12.899285Z","iopub.execute_input":"2021-10-30T18:35:12.899598Z","iopub.status.idle":"2021-10-30T18:35:12.908787Z","shell.execute_reply.started":"2021-10-30T18:35:12.899559Z","shell.execute_reply":"2021-10-30T18:35:12.907975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for df in combined_dfs:\n    df['review'] = df['review'].apply(remove_html)\n    df['review'] = df['review'].apply(remove_numbers)\n    df['review'] = df['review'].apply(filter_printables)\n    df['review'] = df['review'].apply(remove_double_backslashes)\n    df['review'] = df['review'].apply(remove_punctuation)\n#     df['review'] = df['review'].apply(lemmatize)\n    df['review'] = df['review'].apply(fix_spacing)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:35:12.910692Z","iopub.execute_input":"2021-10-30T18:35:12.911155Z","iopub.status.idle":"2021-10-30T18:35:23.425801Z","shell.execute_reply.started":"2021-10-30T18:35:12.911122Z","shell.execute_reply":"2021-10-30T18:35:23.424931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_counts = train_df['review'].apply(lambda x: len(x.split())).values\nplt.hist(words_counts)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:35:23.427161Z","iopub.execute_input":"2021-10-30T18:35:23.4274Z","iopub.status.idle":"2021-10-30T18:35:23.958455Z","shell.execute_reply.started":"2021-10-30T18:35:23.427372Z","shell.execute_reply":"2021-10-30T18:35:23.957435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(\n  num_words = 1000,       # the maximum number of words to keep (Only the most common num_words-1 words will be kept)\n  lower = True,           # boolean. Whether to convert the texts to lowercase.\n  split = ' ',            # str. Separator for word splitting.\n  char_level = False,     # if True, every character will be treated as a token.\n  oov_token = None        # replaces out-of-vocabulary words during text_to_sequence calls with oov_token\n)\ntokenizer.fit_on_texts(train_df['review'])   # can be a list of strings\n\n# Modes: 'binary', 'count', 'freq', 'tfidf'\nX_train = tokenizer.texts_to_matrix(train_df['review'], mode = 'binary')\nX_test = tokenizer.texts_to_matrix(test_df['review'], mode = 'binary')\n\ny_train = train_df['sentiment']","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:35:23.959727Z","iopub.execute_input":"2021-10-30T18:35:23.959941Z","iopub.status.idle":"2021-10-30T18:35:38.411764Z","shell.execute_reply.started":"2021-10-30T18:35:23.959916Z","shell.execute_reply":"2021-10-30T18:35:38.410701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(units = 64, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel.add(Dense(units = 1, activation = 'relu'))\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = ['accuracy']\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:35:38.413325Z","iopub.execute_input":"2021-10-30T18:35:38.413598Z","iopub.status.idle":"2021-10-30T18:35:38.448989Z","shell.execute_reply.started":"2021-10-30T18:35:38.413562Z","shell.execute_reply":"2021-10-30T18:35:38.448331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define callbacks\ncallbacks = [\n    EarlyStopping(patience = 3),\n    ModelCheckpoint(\n        filepath = 'model.h5',\n        save_best_only = True,\n        monitor = 'val_accuracy',\n        verbose = 1\n    )\n]\n\n# Train the model\nhistory = model.fit(\n    X_train,\n    y_train,\n    epochs = 10,\n    batch_size = 32,\n    validation_split = 0.2,\n    verbose = 2,\n    callbacks = callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:35:38.450185Z","iopub.execute_input":"2021-10-30T18:35:38.450611Z","iopub.status.idle":"2021-10-30T18:35:43.83182Z","shell.execute_reply.started":"2021-10-30T18:35:38.450569Z","shell.execute_reply":"2021-10-30T18:35:43.830912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\nepochs = [i for i in range(len(history.history['loss']))]\n\n# Loss\nax[0].plot(epochs, history.history['loss'], label = 'loss')\nax[0].plot(epochs, history.history['val_loss'], label = 'val_loss')\nax[0].legend()\n\n# Accuracy\nax[1].plot(epochs, history.history['accuracy'], label = 'accuracy')\nax[1].plot(epochs, history.history['val_accuracy'], label = 'val_accuracy')\nax[1].legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:35:43.833759Z","iopub.execute_input":"2021-10-30T18:35:43.833993Z","iopub.status.idle":"2021-10-30T18:35:44.188884Z","shell.execute_reply.started":"2021-10-30T18:35:43.833966Z","shell.execute_reply":"2021-10-30T18:35:44.188281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make prediction\nmodel = load_model('model.h5')\npred = model.predict(X_test)\npred = (pred > 0.5).astype(int).ravel()\n\n# Create submission\nsubmission = pd.DataFrame(data = {\n    'id': test_df['id'],\n    'sentiment': pred\n})\nsubmission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:39:12.311753Z","iopub.execute_input":"2021-10-30T18:39:12.312287Z","iopub.status.idle":"2021-10-30T18:39:13.156559Z","shell.execute_reply.started":"2021-10-30T18:39:12.312244Z","shell.execute_reply":"2021-10-30T18:39:13.155687Z"},"trusted":true},"execution_count":null,"outputs":[]}]}