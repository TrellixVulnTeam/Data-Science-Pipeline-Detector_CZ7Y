{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T08:01:31.647488Z","iopub.execute_input":"2021-07-26T08:01:31.647882Z","iopub.status.idle":"2021-07-26T08:01:31.661996Z","shell.execute_reply.started":"2021-07-26T08:01:31.647851Z","shell.execute_reply":"2021-07-26T08:01:31.660428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip', delimiter=\"\\t\")\ndf_train = df_train.drop(['id'], axis=1)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T07:23:31.636699Z","iopub.execute_input":"2021-07-26T07:23:31.637191Z","iopub.status.idle":"2021-07-26T07:23:32.309046Z","shell.execute_reply.started":"2021-07-26T07:23:31.637161Z","shell.execute_reply":"2021-07-26T07:23:32.30801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test =pd.read_csv(\"../input/word2vec-nlp-tutorial/testData.tsv.zip\",header=0, delimiter=\"\\t\"\n                     #, quoting=3\n                    )\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:06:30.546343Z","iopub.execute_input":"2021-07-26T08:06:30.546759Z","iopub.status.idle":"2021-07-26T08:06:31.201351Z","shell.execute_reply.started":"2021-07-26T08:06:30.546725Z","shell.execute_reply":"2021-07-26T08:06:31.199895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizing","metadata":{}},{"cell_type":"code","source":"maxlen = 100\ntraining_samples = 200\nvalidation_samples = 10000\nmax_words = 10000\n\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(df_train['review'])\nsequences = tokenizer.texts_to_sequences(df_train['review'])\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\ndata = pad_sequences(sequences, maxlen=maxlen)\nlabels = np.asarray(df_train['sentiment'])\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)\nindices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\nx_train = data[:training_samples]\ny_train = labels[:training_samples]\nx_val = data[training_samples: training_samples + validation_samples]\ny_val = labels[training_samples: training_samples + validation_samples]","metadata":{"execution":{"iopub.status.busy":"2021-07-26T07:29:40.384381Z","iopub.execute_input":"2021-07-26T07:29:40.384933Z","iopub.status.idle":"2021-07-26T07:29:51.669956Z","shell.execute_reply.started":"2021-07-26T07:29:40.384896Z","shell.execute_reply":"2021-07-26T07:29:51.668707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GloVe","metadata":{}},{"cell_type":"code","source":"embeddings_index = {}\nf = open('../input/glove6b100dtxt/glove.6B.100d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T07:56:13.721218Z","iopub.execute_input":"2021-07-26T07:56:13.721771Z","iopub.status.idle":"2021-07-26T07:56:32.584157Z","shell.execute_reply.started":"2021-07-26T07:56:13.721737Z","shell.execute_reply":"2021-07-26T07:56:32.583155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 100\nembedding_matrix = np.zeros((max_words, embedding_dim))\nfor word, i in word_index.items():\n    if i < max_words:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-07-26T07:58:03.159519Z","iopub.execute_input":"2021-07-26T07:58:03.159915Z","iopub.status.idle":"2021-07-26T07:58:03.224066Z","shell.execute_reply.started":"2021-07-26T07:58:03.159884Z","shell.execute_reply":"2021-07-26T07:58:03.222851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen))\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T07:58:50.538753Z","iopub.execute_input":"2021-07-26T07:58:50.539105Z","iopub.status.idle":"2021-07-26T07:58:50.664954Z","shell.execute_reply.started":"2021-07-26T07:58:50.539076Z","shell.execute_reply":"2021-07-26T07:58:50.66423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.layers[0].set_weights([embedding_matrix])\nmodel.layers[0].trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:00:09.783569Z","iopub.execute_input":"2021-07-26T08:00:09.783907Z","iopub.status.idle":"2021-07-26T08:00:09.791008Z","shell.execute_reply.started":"2021-07-26T08:00:09.78388Z","shell.execute_reply":"2021-07-26T08:00:09.789855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and evaluation","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='rmsprop',\n    loss='binary_crossentropy',\n    metrics=['acc'])\nhistory = model.fit(x_train, y_train,\n    epochs=10,\n    batch_size=32,\n    validation_data=(x_val, y_val))\nmodel.save_weights('pre_trained_glove_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:01:09.650112Z","iopub.execute_input":"2021-07-26T08:01:09.650494Z","iopub.status.idle":"2021-07-26T08:01:17.284962Z","shell.execute_reply.started":"2021-07-26T08:01:09.650462Z","shell.execute_reply":"2021-07-26T08:01:17.283826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:01:46.024797Z","iopub.execute_input":"2021-07-26T08:01:46.025231Z","iopub.status.idle":"2021-07-26T08:01:46.38538Z","shell.execute_reply.started":"2021-07-26T08:01:46.025195Z","shell.execute_reply":"2021-07-26T08:01:46.383675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Same model without pretrained embeddings","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen))\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\nmodel.compile(optimizer='rmsprop',\n    loss='binary_crossentropy',\n    metrics=['acc'])\nhistory = model.fit(x_train, y_train,\n    epochs=10,\n    batch_size=32,\n    validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:03:31.752342Z","iopub.execute_input":"2021-07-26T08:03:31.752819Z","iopub.status.idle":"2021-07-26T08:03:41.852609Z","shell.execute_reply.started":"2021-07-26T08:03:31.752778Z","shell.execute_reply":"2021-07-26T08:03:41.851229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:04:17.5446Z","iopub.execute_input":"2021-07-26T08:04:17.544988Z","iopub.status.idle":"2021-07-26T08:04:17.870938Z","shell.execute_reply.started":"2021-07-26T08:04:17.544956Z","shell.execute_reply":"2021-07-26T08:04:17.86963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize test data","metadata":{}},{"cell_type":"code","source":"sequences = tokenizer.texts_to_sequences(df_test['review'])\nx_test = pad_sequences(sequences, maxlen=maxlen)\n#y_test = np.asarray(labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:22:48.854877Z","iopub.execute_input":"2021-07-26T08:22:48.8553Z","iopub.status.idle":"2021-07-26T08:22:54.139455Z","shell.execute_reply.started":"2021-07-26T08:22:48.855262Z","shell.execute_reply":"2021-07-26T08:22:54.138433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict test","metadata":{}},{"cell_type":"code","source":"model.load_weights('pre_trained_glove_model.h5')\nmodel.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T08:22:54.140888Z","iopub.execute_input":"2021-07-26T08:22:54.141221Z","iopub.status.idle":"2021-07-26T08:22:55.485348Z","shell.execute_reply.started":"2021-07-26T08:22:54.14119Z","shell.execute_reply":"2021-07-26T08:22:55.484598Z"},"trusted":true},"execution_count":null,"outputs":[]}]}