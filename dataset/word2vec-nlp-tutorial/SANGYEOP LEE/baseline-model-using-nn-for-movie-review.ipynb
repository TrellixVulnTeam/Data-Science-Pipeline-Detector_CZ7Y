{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Imgur](https://i.imgur.com/iy82iZq.png)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zipfile\n\nfiles=['/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip',\n       '/kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip',\n       '/kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip']\n\nfor file in files :\n    zip = zipfile.ZipFile(file,'r')\n    zip.extractall()\n    zip.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/working/labeledTrainData.tsv', delimiter=\"\\t\")\ntest=pd.read_csv('/kaggle/working/testData.tsv', delimiter=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/sampleSubmission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. EDA of review texts\n1. `Character distriubtion` of each review\n1. `Word distriubtion` of each review\n1. `Word cloud` of each word\n1. Distribution by `Sentiment class`\n1. Ratio with `special characters`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('the train data is : {} line'.format(len(train)))\nprint('the test data is : {} line'.format(len(test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_len=train['review'].apply(len)\ntest_len=test['review'].apply(len)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot((train_len),color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot((test_len),color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['word_n'] = train['review'].apply(lambda x : len(x.split(' ')))\ntest['word_n'] = test['review'].apply(lambda x : len(x.split(' ')))\n\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot(train['word_n'],color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot(test['word_n'],color='blue')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['length']=train['review'].apply(len)\ntrain['length'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['word_n'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- `Distribution of words in one review` is similar both in train and test set\n- The `mean words` count is 233 and `std` is 173 words\n- The character count seems to show similar distribution with word count"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\ncloud=WordCloud(width=800, height=600).generate(\" \".join(train['review'])) # join function can help merge all words into one string. \" \" means space can be a sep between words.\nplt.figure(figsize=(15,10))\nplt.imshow(cloud)\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- `br` is the most frequent one. But br is a sort of HTML tag, Thus it should be removed.\n- `movie` or `film` is the theme which all reviews share. Thus I suppose `idf(inverse document frequency)` shoul be close to zero"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axe = plt.subplots(1,3, figsize=(23,5))\nsns.countplot(train['sentiment'], ax=axe[0])\nsns.boxenplot(x=train['sentiment'], y=train['length'], data=train, ax=axe[1])\nsns.boxenplot(x=train['sentiment'], y=train['word_n'], data=train, ax=axe[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The distribution of sentiment is `half and half` between zero and one\n- The review length distribution by sentiment is similar but if somebody feels harshly dissatisfied, the reveiw tends to be wordy (more outliers)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('the review with question mark is {}'.format(np.mean(train['review'].apply(lambda x : '?' in x))))\nprint('the review with fullstop mark is {}'.format(np.mean(train['review'].apply(lambda x : '.' in x))))\nprint('the ratio of the first capital letter is {}'.format(np.mean(train['review'].apply(lambda x : x[0].isupper()))))\nprint('the ratio with the capital letter is {}'.format(np.mean(train['review'].apply(lambda x : max(y.isupper() for y in x)))))\nprint('the ratio with the number is {}'.format(np.mean(train['review'].apply(lambda x : max(y.isdigit() for y in x)))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Preprocessing\n1. Remove `HTML tags` such as `<br>` using BeautifulSoup\n1. Only `english character` will remain using regular expression\n1. By NLTK, `stopwords` will be eliminated"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport json\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']=train['review'].apply(lambda x: BeautifulSoup(x,\"html5lib\").get_text())\ntest['review']=test['review'].apply(lambda x: BeautifulSoup(x,\"html5lib\").get_text())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review']=train['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",x))\ntest['review']=test['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stops = set(stopwords.words(\"english\"))\n\nfor i in range(0,25000) : \n    review = train.iloc[i,2] # review column : 2 \n    review = review.lower().split()\n    words = [r for r in review if not r in stops]\n    clean_review = ' '.join(words)\n    train.iloc[i,2] = clean_review","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,25000) : \n    review = test.iloc[i,1] # review column : 1\n    review = review.lower().split()\n    words = [r for r in review if not r in stops]\n    clean_review = ' '.join(words)\n    test.iloc[i,1] = clean_review","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['word_n_2'] = train['review'].apply(lambda x : len(x.split(' ')))\ntest['word_n_2'] = test['review'].apply(lambda x : len(x.split(' ')))\n\nfig, axe = plt.subplots(1,1, figsize=(7,5))\nsns.boxenplot(x=train['sentiment'], y=train['word_n_2'], data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- After preprocessing, the distribution by sentiment in train data is `not so different` from previous state `except total counts`"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ntk = Tokenizer()\ntk.fit_on_texts(list(train['review'])+list(test['review']))\ntext_seq_tr=tk.texts_to_sequences(train['review'])\ntext_seq_te=tk.texts_to_sequences(test['review'])\nword_ind=tk.word_index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Usiung keras, tokenization and mapping to numbers are done\n- When fitting, `use all data from train and text data set`, which prevents model from errors"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total word count is :',len(word_ind))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_info={}\ndata_info['word_ind']=word_ind\ndata_info['word_len']=len(word_ind)+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot(pd.Series(text_seq_tr).apply(lambda x : len(x)))\nfig.add_subplot(1,2,2)\nsns.distplot(pd.Series(text_seq_te).apply(lambda x : len(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\npad_train=pad_sequences(text_seq_tr, maxlen=400) \npad_test=pad_sequences(text_seq_te, maxlen=400) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- `max length` is set, if length more than max length, `zero value` will replace that place"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(pad_train, train['sentiment'], random_state=77, test_size=0.07, stratify=train['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- use validation set, when we make a model. test_size is set in between 5% to 10%, to use more data"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tk.word_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Modeling\n1. *`sequential model`* using adam optimizer\n1. set `early stopping` and `model checkpoint` (patient option)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Sequential\nfrom keras.layers import Dense, Embedding, Flatten\n\nmodel=Sequential()\nmodel.add(Embedding(101247,65, input_length=400))\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes=EarlyStopping(patience=4) \nmc=ModelCheckpoint('best.h5',save_best_only=True)\nmodel.fit(x_train,y_train, batch_size=128, epochs=10, validation_data=[x_valid,y_valid], callbacks=[es,mc]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('best.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res=model.predict(pad_test, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['sentiment_pro']=res[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[sub['sentiment_pro']>=0.5,\"sentiment\"]=1\nsub.loc[sub['sentiment_pro']<0.5,\"sentiment\"]=0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Use *`0.5 as thereshold`* to specify one or zero"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=sub[['id','sentiment']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('result.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}