{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom bs4 import BeautifulSoup\nimport nltk #Natural Language Toolkit, for stop words\nimport re # get letter filter\nfrom nltk.corpus import stopwords\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\ntrain_path = '../input/labeledTrainData.tsv'\ninput_data = pd.read_csv(train_path, header= 0, delimiter= '\\t',quoting= 3)\n# print(input_data.review[0])\n# print(input_data.describe())\ninput_data.describe()\ninput_data.columns\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f401a9f406aee107b9da053d020584d3c50cd77"},"cell_type":"code","source":"set(stopwords.words('english'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def review_to_words(origin_data):\n    data_no_html = BeautifulSoup(origin_data,'lxml').get_text()\n    letters_only = re.sub('[^a-zA-Z]',' ',data_no_html)\n    words=letters_only.lower().split()\n    stops=set(stopwords.words('english'))\n    meaningful_words = [w for w in words if not w in stops]\n    return (\" \".join(meaningful_words))\n\nclean_train_reviews = []\nfor i in range(0, input_data['review'].size):\n    clean_train_reviews.append(review_to_words(input_data['review'][i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58738921d1a9a417eb9cefbe69887caaec7e1558"},"cell_type":"code","source":"train_X = np.array(clean_train_reviews)\ntrain_y = np.array(input_data['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3236746e25c30f7b71d62bc9fcc4ede521a63136"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer \nvectorizer = CountVectorizer(analyzer = 'word', max_features = 5000) \ntrain_data_features = vectorizer.fit_transform(train_X)\nprint(train_data_features.dtype) \ntrain_data_features = train_data_features.toarray() \nprint(train_data_features.dtype) \n# vocab = vectorizer.get_feature_names()\n# dist=np.sum(train_data_features,axis=0)\n# for tag,count in zip(vocab,dist):\n#     print(count,tag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d4c1a59b7fe9faddf500a4e95cc9682b440baff"},"cell_type":"code","source":"test = pd.read_csv(\"../input/testData.tsv\", header=0, \\\n                    delimiter=\"\\t\", quoting=3)\nclean_test_reviews = []\nfor i in range(0, test[\"review\"].size ):\n    clean_test_reviews.append(review_to_words(test[\"review\"][i]))\ntest_X = np.array(clean_test_reviews)\n\ntest_data_features = vectorizer.fit_transform(test_X)\ntest_data_features = test_data_features.toarray() \n# vocab = vectorizer.get_feature_names()\n# dist=np.sum(train_data_features,axis=0)\n# for tag,count in zip(vocab,dist):\n#     print(count,tag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea2441dde7f345dcf7ffe81a16ee1f0519d5b1d2"},"cell_type":"code","source":"t_X, v_X, t_y, v_y = train_test_split(train_data_features, train_y, random_state = 0)\n\nr_forest = RandomForestClassifier(n_estimators = 100) \nr_forest.fit(t_X, t_y)\npredict_r = r_forest.predict(v_X)\n\nd_model = DecisionTreeRegressor()\nd_model.fit(t_X, t_y)\npredict_d = d_model.predict(v_X)\n\nresult = pd.DataFrame({'validate': v_y, 'predictR': predict_r, 'predictD': predict_d})\nresult['DifferenceR'] = result['validate'] == result ['predictR']\nresult['DifferenceD'] = result['validate'] == result ['predictD']\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27a0196ccdc82d2834c41fe7b41ed3c0f44ee1b6"},"cell_type":"code","source":"print(\"Error rate R: \" + str(len(result[result['DifferenceR'] == False]) / len(result)))\nprint(\"Error rate D: \" + str(len(result[result['DifferenceD'] == False]) / len(result)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a34f135701ba230c24adbbf9c0fc0497afc26a8"},"cell_type":"code","source":"r_forest.fit(train_data_features, train_y)\nanswer = r_forest.predict(test_data_features)\noutput = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":answer} )\noutput.to_csv( \"Bag_of_Words_model1.csv\", index=False, quoting=3)\n\n# result=pd.DataFrame({ 'PassengerId': test_data.PassengerId, 'Survived': test_result })\n# result.head()\n# result.to_csv(\"Titanic_result.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b29c84027bdf7ab4a9e7e87a5763a347da4b102"},"cell_type":"code","source":"output.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb0a8c8171ecaa16f2f8f04ce6271f04a29f39a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}