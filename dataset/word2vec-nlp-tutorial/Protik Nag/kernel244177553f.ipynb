{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport re\n\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import LancasterStemmer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/word2vec-nlp-tutorial/labeledTrainData.tsv', quoting=3, delimiter='\\t', header=0)\ntest = pd.read_csv('../input/word2vec-nlp-tutorial/testData.tsv', quoting=3, delimiter='\\t', header=0)\nsubmission = pd.read_csv('../input/word2vec-nlp-tutorial/sampleSubmission.csv', quoting=3, delimiter='\\t', header=0)\nunlabeledTrain = pd.read_csv('../input/word2vec-nlp-tutorial/unlabeledTrainData.tsv', quoting=3, delimiter='\\t', header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Shape = \", train.shape)\nprint(\"Test Shape = \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.columns.values)\nprint(test.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def review_to_words(raw_review):\n    review_text = BeautifulSoup(raw_review,'lxml').get_text()       \n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n    letters_only = re.sub(\"!\", \"WOW \", letters_only)\n    words = letters_only.lower().split()                 \n    stops = set(stopwords.words(\"english\"))              \n    meaningful_words = [w for w in words if not w in stops]\n    singles = [stemmer.stem(x) for x in meaningful_words]\n    return( \" \".join(singles)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_train_reviews = []\nnum_reviews = len(train['review'])\nfor i in range( 0, num_reviews ):\n    if( (i+1)%1000 == 0 ):\n        print(\"Review %d of %d\\n\" % ( i+1, num_reviews ))                                                                    \n    clean_train_reviews.append( review_to_words( train[\"review\"][i] ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = \"english\", max_features = 7000) \ntrain_data_features = vectorizer.fit_transform(clean_train_reviews)\n\ntrain_data_features = train_data_features.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab = vectorizer.get_feature_names()\nprint(vocab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = np.sum(train_data_features, axis=0)\n\nfor tag, count in zip(vocab, dist):\n    print(count, tag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training the random forest...\")\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(n_estimators = 300) \nforest = forest.fit( train_data_features, train[\"sentiment\"] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/word2vec-nlp-tutorial/testData.tsv\", header=0, delimiter=\"\\t\", \\\n                   quoting=3 )\n\nprint(test.shape)\n\nnum_reviews = len(test[\"review\"])\nclean_test_reviews = [] \n\nprint(\"Cleaning and parsing the test set movie reviews...\\n\")\nfor i in range(0,num_reviews):\n    if( (i+1) % 5000 == 0 ):\n        print(\"Review %d of %d\\n\" % (i+1, num_reviews))\n    clean_review = review_to_words( test[\"review\"][i] )\n    clean_test_reviews.append( clean_review )\n\ntest_data_features = vectorizer.transform(clean_test_reviews)\ntest_data_features = test_data_features.toarray()\n\nresult = forest.predict(test_data_features)\n\noutput = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\noutput.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score: 0.85288"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}