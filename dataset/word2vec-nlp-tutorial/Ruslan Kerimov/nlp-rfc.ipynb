{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Подгружаем необходимые библиотеки и данные","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nfrom nltk.corpus import stopwords   \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ntrain = pd.read_csv('../input/bag-of-words-meets-bags-of-popcorn-fixed-zips/labeledTrainData.tsv',\n                    header=0,\n                    delimiter=\"\\t\",\n                    quoting=3)\ntest = pd.read_csv('../input/bag-of-words-meets-bags-of-popcorn-fixed-zips/testData.tsv',\n                   header=0,\n                   delimiter=\"\\t\",\n                   quoting=3 )","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T19:18:01.884584Z","iopub.execute_input":"2021-12-18T19:18:01.885005Z","iopub.status.idle":"2021-12-18T19:18:02.876074Z","shell.execute_reply.started":"2021-12-18T19:18:01.884951Z","shell.execute_reply":"2021-12-18T19:18:02.875059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Напишем функцию которая преобразует текст превью строку из слов. Уберём html-код и символы не являющимися словами. Результат работы функции: строка из слов разделённых пробелами.","metadata":{}},{"cell_type":"code","source":"def review_to_words( raw_review ):\n\n    review_text = BeautifulSoup(raw_review).get_text() \n \n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n\n    words = letters_only.lower().split()                             \n\n    stops = set(stopwords.words(\"english\"))                  \n\n    meaningful_words = [w for w in words if not w in stops]   \n\n    return( \" \".join( meaningful_words )) ","metadata":{"execution":{"iopub.status.busy":"2021-12-18T19:18:02.893066Z","iopub.execute_input":"2021-12-18T19:18:02.893469Z","iopub.status.idle":"2021-12-18T19:18:02.900152Z","shell.execute_reply.started":"2021-12-18T19:18:02.893431Z","shell.execute_reply":"2021-12-18T19:18:02.899294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Вызовем функцию для каждого ревью","metadata":{}},{"cell_type":"code","source":"num_reviews = train[\"review\"].size\n\nclean_train_reviews = []\n\nfor i in range( 0, num_reviews ):\n    if( (i+1)%1000 == 0 ):\n        print(\"Review %d of %d\\n\" % ( i+1, num_reviews ))\n    clean_train_reviews.append( review_to_words( train[\"review\"][i] ) )","metadata":{"execution":{"iopub.status.busy":"2021-12-18T19:18:02.901795Z","iopub.execute_input":"2021-12-18T19:18:02.902304Z","iopub.status.idle":"2021-12-18T19:18:25.052228Z","shell.execute_reply.started":"2021-12-18T19:18:02.902259Z","shell.execute_reply":"2021-12-18T19:18:25.051374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Используем CountVectorizer. Обучаем и преобразуем тренировочные данные в лист векторов. После этого можно преобразовать всё в удобный для работы формат 0 - numpy массив.","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(analyzer = \"word\",   \\\n                             tokenizer = None,    \\\n                             preprocessor = None, \\\n                             stop_words = None,   \\\n                             max_features = 10000) \n\ntrain_data_features = vectorizer.fit_transform(clean_train_reviews)\n\ntrain_data_features = train_data_features.toarray()\n\ntrain_data_features.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-18T19:18:25.053642Z","iopub.execute_input":"2021-12-18T19:18:25.053903Z","iopub.status.idle":"2021-12-18T19:18:31.070877Z","shell.execute_reply.started":"2021-12-18T19:18:25.053871Z","shell.execute_reply":"2021-12-18T19:18:31.069999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Выведем полученный словарь","metadata":{}},{"cell_type":"code","source":"vocab = vectorizer.get_feature_names()\nlen(vocab)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T19:18:31.072733Z","iopub.execute_input":"2021-12-18T19:18:31.073035Z","iopub.status.idle":"2021-12-18T19:18:31.092705Z","shell.execute_reply.started":"2021-12-18T19:18:31.073002Z","shell.execute_reply":"2021-12-18T19:18:31.091975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В качестве классификатора используем случайный лес. Заполним лист \"очищенными\" ревью. Преобразуем в numpy массив, после этого можно предсказывать.","metadata":{}},{"cell_type":"code","source":"forest = RandomForestClassifier(n_jobs=-1, n_estimators=500)\n\nforest = forest.fit( train_data_features, train[\"sentiment\"] )\n\nnum_reviews = len(test[\"review\"])\nclean_test_reviews = [] \n\nfor i in range(0,num_reviews):\n    if( (i+1) % 1000 == 0 ):\n        print(\"Review %d of %d\\n\" % (i+1, num_reviews))\n    clean_review = review_to_words( test[\"review\"][i] )\n    clean_test_reviews.append( clean_review )\n\ntest_data_features = vectorizer.transform(clean_test_reviews)\ntest_data_features = test_data_features.toarray()\n\nresult = forest.predict(test_data_features)\n\noutput = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n\noutput.to_csv( \"./submission.csv\", index=False, quoting=3 )","metadata":{"execution":{"iopub.status.busy":"2021-12-18T19:18:31.093854Z","iopub.execute_input":"2021-12-18T19:18:31.094195Z"},"trusted":true},"execution_count":null,"outputs":[]}]}