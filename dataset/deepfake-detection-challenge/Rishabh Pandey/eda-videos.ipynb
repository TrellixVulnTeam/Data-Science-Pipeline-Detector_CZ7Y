{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport json\n\nmeta = pd.DataFrame(json.load(open('/kaggle/input/deepfake-detection-challenge/train_sample_videos/metadata.json'))).T\nprint(meta.head())\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"meta['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta[meta['label']=='REAL'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read a random real video in memory and analyse\nimport random\ntry:\n    import imageio\n    import pylab\nexcept Exception as e:\n    !pip install imageio\n    !pip install pylab\n    import pylab\n    import imageio\n!pip install imageio-ffmpeg\nreal_vids = meta[(meta['label'] == 'REAL') & (meta['split'] == 'train')]\nrand_real_vid = real_vids.index[random.randint(0,len(real_vids))] \nfilename = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'+rand_real_vid\nprint(filename)\nvid = imageio.get_reader(filename,  'ffmpeg')\ntype(vid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vid.count_frames()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = vid.get_data(1)\npylab.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find number of frames in each video\nimport tqdm\nframes_per_video = list()\nfor file in tqdm.tqdm(meta.index):\n    filename = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'+file\n    vid = imageio.get_reader(filename,  'ffmpeg')\n    frames_per_video.append(vid.count_frames())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(frames_per_video)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### all images does not have same number of frames"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read meta data info about each video\nimport tqdm\nmeta_per_video = list()\nfor file in tqdm.tqdm(meta.index):\n    filename = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'+file\n    vid = imageio.get_reader(filename,  'ffmpeg')\n    vid_meta = vid._meta\n    # append other info from meta file\n    vid_meta['num_frames'] = vid.count_frames()\n    vid_meta['filename'] = file\n    vid_meta['label'] = meta.loc[file]['label']\n    vid_meta['split'] = meta.loc[file]['split']\n    vid_meta['original'] = meta.loc[file]['original']\n    meta_per_video.append(vid_meta)\n#convert list of dict to pandas dataframe for easy analysis\nmeta_videos = pd.DataFrame(meta_per_video)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_videos.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(filter(lambda x:x.split('.')[1]!='mp4',os.listdir('../input/deepfake-detection-challenge/test_videos')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### there is no meta data file in test directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmeta_per_video = list()\nfor file in tqdm.tqdm(os.listdir('../input/deepfake-detection-challenge/test_videos')):\n    filename = '/kaggle/input/deepfake-detection-challenge/test_videos/'+file\n    vid = imageio.get_reader(filename,  'ffmpeg')\n    vid_meta = vid._meta\n    # append other info from meta file\n    vid_meta['num_frames'] = vid.count_frames()\n    vid_meta['filename'] = file\n    meta_per_video.append(vid_meta)\n#convert list of dict to pandas dataframe for easy analysis\nmeta_test_videos = pd.DataFrame(meta_per_video)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_test_videos.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### test videos num_frams distibution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(meta_test_videos['num_frames'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading the entire data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the libraries \nimport PIL.Image\nimport PIL.ImageDraw\ntry:\n    import face_recognition\nexcept:\n    !pip install face_recognition\n    import face_recognition\n    \n# load a video\nvid = imageio.get_reader('/kaggle/input/deepfake-detection-challenge/train_sample_videos/aagfhgtpmv.mp4',  'ffmpeg')\n\n# get a random frame of video\nimage = vid.get_data(random.randint(0,vid.count_frames()))\n\n# Load the jpg file into a NumPy array\n#image = face_recognition.load_image_file(image)\n\n# Find all the faces in the image\nface_locations = face_recognition.face_locations(image)\n\nnumber_of_faces = len(face_locations)\nprint(\"I found {} face(s) in this photograph.\".format(number_of_faces))\n\n# Load the image into a Python Image Library object so that we can draw on top of it and display it\npil_image = PIL.Image.fromarray(image)\n\nfor face_location in face_locations:\n\n    # Print the location of each face in this image. Each face is a list of co-ordinates in (top, right, bottom, left) order.\n    top, right, bottom, left = face_location\n    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n    # Let's draw a box around the face\n    draw = PIL.ImageDraw.Draw(pil_image)\n    draw.rectangle([left, top, right, bottom], outline=\"red\")\n\n# Display the image on screen\npil_image.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}