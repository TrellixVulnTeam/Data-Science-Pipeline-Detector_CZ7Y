{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imageio\n!pip install imageio-ffmpeg\n!pip install mtcnn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom collections import defaultdict\nimport cv2\nimport numpy as np\nimport pylab\nimport imageio\nfrom mtcnn import MTCNN\nimport cv2\nimport json\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_data(path,complete_path=False):\n    '''get file names of train and test data folder\n       complete_path - get list with the full path  \n        '''\n    dataset = []\n    folderseq = []\n    for dirname, _, filenames in os.walk(path):\n        \n        folderseq.append(_)\n\n        for folder in _:\n            \n            for dire,_,file in os.walk(os.path.join(dirname,folder)):\n                if complete_path == True:\n                    full_path = []\n                    for val in file:\n                        full_path.append(os.path.join(dire,val))\n                    dataset.append(full_path)\n                else:\n                    dataset.append(file)\n#     print(dataset)\n   \n    if folderseq[0][0] == 'train_sample_videos':\n        return dataset[0],dataset[1]\n        \n    else :\n        return dataset[1],dataset[0]\n        \n    \ndef count_file(file_list):\n    '''Check type of file format in each train test folder'''\n    count = defaultdict(int)\n    for file in file_list:\n        fileformat = file.split('.')[1]\n        count[fileformat] += 1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_FOLDER = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'\nTEST_FOLDER = '/kaggle/input/deepfake-detection-challenge/test_videos/'\ntrain_file,test_file = train_test_data('/kaggle/input/deepfake-detection-challenge/',complete_path=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_file(train_file),count_file(test_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"400 MP4 in train folder with one metadata.json .\n400 MP4 in test folder ."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_jsonpath(train_file):\n    '''get the path on json file in train data'''\n    for file in train_file:        \n        if file.split('.')[1] == 'json':\n            json_index = train_file.index(file)\n    metadata = os.path.join(TRAIN_FOLDER,train_file[json_index])\n    return metadata\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata = get_jsonpath(train_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''remove metadata form train folder '''\ntrain_file.remove('metadata.json')\nprint(len(train_file))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total of 400 video files in train_file after removing metadata.json "},{"metadata":{"trusted":true},"cell_type":"code","source":"json_meta = pd.read_json(metadata)\njson_meta = json_meta.T.reset_index()\njson_meta.columns = ['input', 'label', 'split', 'original']\njson_meta.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"json_meta['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_datacoverage(json_meta,train_file):\n    '''check how may .mp4 files of metadata.json present in our dataset'''\n    original = json_meta.dropna().values.tolist()\n    test1 = []\n    for val in original:\n        if val in train_file:\n            test1.append(val)\n    return print('Out of {} videos {} files available in dataset'.format(len(original),len(test1)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All  input videos of json  file present in train folder\ncheck_datacoverage(json_meta['input'],train_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Out of 323 original videos only 58 vides files available in train dataset\ncheck_datacoverage(json_meta['original'],train_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_data(metadata,train_file):\n    '''generate dataset of only those FAKE - REAL file pairs that are available in the dataset'''\n    json_data = json.load(open(metadata))\n    dataset = []\n    for val in json_data:\n        if val in train_file:\n            if json_data[val]['label'] == 'FAKE':\n                if json_data[val]['original'] in train_file:\n                    dataset.append((val,json_data[val]['original']))\n    print('Total File Pairs - {}'.format(len(dataset)))\n    return dataset\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_original_data = generate_data(metadata,train_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dataset = fake_original_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_imgio(data,frames):\n    '''Return fake and real images  for single video file\n    with numbers of frames set to scan for faces. All images are resized to\n        160*160 size\n    '''\n    test0 = []\n    test1 = []\n    vid = imageio.get_reader(os.path.join(TRAIN_FOLDER,data[0]),  'ffmpeg')\n    vid2 = imageio.get_reader(os.path.join(TRAIN_FOLDER,data[1]),  'ffmpeg')\n    nums = np.linspace(0,vid.count_frames() - 1,frames,dtype=int)\n    for num in nums:\n        try:\n            image = vid.get_data(num)\n            image2 = vid2.get_data(num)\n    #         print(image)\n            img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            img2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n            detector = MTCNN()\n            x1, y1, width, height = detector.detect_faces(img)[0]['box']\n            x2, y2 = x1 + width, y1 + height\n            res = cv2.resize(img[y1:y2, x1:x2],(160,160))\n            res = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n            test0.append(res)\n            res2 = cv2.resize(img2[y1:y2, x1:x2],(160,160))\n            res2 = cv2.cvtColor(res2, cv2.COLOR_BGR2GRAY)\n            test1.append(res2)\n        except:\n            continue\n#         break\n        \n        \n    test0 = np.stack(test0)\n    test1 = np.stack(test1)\n    return test0,test1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_img(num):\n    '''select the frame to show fake and real image out of total frames set to scan'''\n    fig,ax = plt.subplots(1,2,figsize=(10,10))\n    ax[0].imshow(x[num])\n    ax[0].set_title('FAKE')\n    ax[1].imshow(y[num])\n    ax[1].set_title('REAL')\n    \nx,y = get_data_imgio(fake_original_data[30],30)\nx.shape,y.shape\n# Each vides mp4 file 30 frames are selected to get faces from them ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_img(22) #select from 0 - 29 because 30 frames selected to scan the image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y = get_data_imgio(fake_original_data[15],30)\nshow_img(17) #select from 0 - 29 because 30 frames selected to scan the image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"above is example on one frame of one MP4 file with fake and real images side to each other "},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_training_data(fake_original_data):\n    '''generate fake and original video  with there labels'''\n    trainx = []\n    trainy = []\n    for data in tqdm(fake_original_data):\n        try:\n            train,test = get_data_imgio(data,30)\n            trainx.append(train)\n            trainy.append(test)\n        except:\n            continue\n#         break\n    inp = np.vstack(trainx)\n    real = np.vstack(trainy)\n    zero = np.zeros(inp.shape[0])\n    one = np.ones(inp.shape[0])\n    label = np.concatenate((zero,one))\n    images = np.concatenate((inp,real),axis=0)\n    images = np.expand_dims(images,axis=-1)\n    \n    return images,label\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = generate_training_data(fake_original_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}