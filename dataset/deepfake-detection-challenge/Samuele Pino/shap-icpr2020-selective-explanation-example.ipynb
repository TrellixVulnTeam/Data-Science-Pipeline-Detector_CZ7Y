{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This kernel imports code from codebase.py, a custom script I made.\n# It is available at: https://www.kaggle.com/samuelepino/codebase\n\nimport os\nimport sys\nsys.path.append(\"../usr/lib/codebase/\")\nfrom codebase import ICPR, Segmenter, Explainer, Pipeline, VideoLoader, FigureManager","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Configuration\nN_VIDEOS = 1\nFRAMES_PER_VIDEO = 30\nSHAP_SAMPLES = 16000\nN_SEGMENTS = 200\n\n# Initialization\nclassifier = ICPR(frames_per_video=FRAMES_PER_VIDEO, consecutive_frames=True)\nseg = Segmenter(mode=\"color\", segmentsNumber=N_SEGMENTS)\nexpl = Explainer(classifier=classifier, trackTime=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load videos\n\ndfdc_vidlist = VideoLoader.loadFilenamesDFDC(\n    videoCount=N_VIDEOS, \n    fakeClassValue=classifier.FAKE_CLASS_VAL,\n    realClassValue=classifier.REAL_CLASS_VAL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdc_vidlist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show first video\n\nvidName = dfdc_vidlist[0][0]\nvidClass = dfdc_vidlist[0][1]\nvidPath = os.path.join(VideoLoader.DFDC_trainVideoDir, vidName)\nimageSequence = classifier.getFaceCroppedVideo(vidPath)\n\nFigureManager.saveAndDisplayGIF(\n                imageSequence, vidName+\".gif\",\n                fps=15, displayOnNotebook=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get frame predictions\n\nimport numpy as np\n\nframesPred = np.zeros(imageSequence.shape[0])\nframesPred = expl.normalizePredictions(classifier.predictFaceImages(imageSequence))\nvideoPred = np.mean(framesPred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Video's true class is\", vidClass)\nprint(\"Video has been predicted as\", videoPred)\nprint(\" \")\nprint(\"Fake frames have value close to:\", classifier.FAKE_CLASS_VAL)\nprint(\"Real frames have value close to:\", classifier.REAL_CLASS_VAL)\nprint(\" \")\n\nhighlighted_frames = 3\n\ntop_fake_frames = np.argsort(framesPred)[:highlighted_frames]\ntop_real_frames = np.argsort(-framesPred)[:highlighted_frames]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the 'fakest' frames\n\nfrom matplotlib import pyplot as plt\n\nprint(\"The 'fakest' frames are:\")\n\nfig, ax = plt.subplots(1, highlighted_frames, figsize=(4*highlighted_frames, 4))\nfig.set_facecolor('white')\n\nfor i, frame_id in enumerate(top_fake_frames):\n    \n    ax[i].imshow(imageSequence[frame_id])\n    ax[i].set_title(f\"Frame {frame_id}, value {framesPred[frame_id]:.4f}\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the 'realest' frames\n\nprint(\"The 'realest' frames are:\")\n\nfig, ax = plt.subplots(1, highlighted_frames, figsize=(4*highlighted_frames, 4))\nfig.set_facecolor('white')\n\nfor i, frame_id in enumerate(top_real_frames):\n    ax[i].imshow(imageSequence[frame_id])\n    ax[i].set_title(f\"Frame {frame_id}, value {framesPred[frame_id]:.4f}\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# explanation for the 'fakest' frame\n\np = Pipeline(classifier, seg, expl, segmentationDim=\"2D\", explanationMode=\"frame\",\n             nSegments=N_SEGMENTS, shapSamples=SHAP_SAMPLES)\n\np.start(imageSequence[top_fake_frames[0]:top_fake_frames[0]+1], vidClass, vidName+\"-fake-frames\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# explanation for the 'realest' frame\n\np = Pipeline(classifier, seg, expl, segmentationDim=\"2D\", explanationMode=\"frame\",\n             nSegments=N_SEGMENTS, shapSamples=SHAP_SAMPLES)\n\np.start(imageSequence[top_real_frames[0]:top_real_frames[0]+1], vidClass, vidName[:-4]+\"-real-frames\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do the same for other 9 videos","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configuration\nN_VIDEOS = 10\n\n# Initialization\nclassifier = ICPR(frames_per_video=FRAMES_PER_VIDEO, consecutive_frames=True)\nseg = Segmenter(mode=\"color\", segmentsNumber=N_SEGMENTS)\nexpl = Explainer(classifier=classifier, trackTime=False)\n\n# load videos\n\ndfdc_vidlist = VideoLoader.loadFilenamesDFDC(\n    videoCount=N_VIDEOS, \n    fakeClassValue=classifier.FAKE_CLASS_VAL,\n    realClassValue=classifier.REAL_CLASS_VAL)[1:]\n\nfor (vidName, vidClass) in dfdc_vidlist:\n    \n    print(f\"\\nAnalyzing video {vidName} (class {vidClass})\")\n    \n    vidPath = os.path.join(VideoLoader.DFDC_trainVideoDir, vidName)\n    imageSequence = classifier.getFaceCroppedVideo(vidPath)\n    \n    # get frame predictions\n    framesPred = expl.normalizePredictions(classifier.predictFaceImages(imageSequence))\n    videoPred = np.mean(framesPred)\n    \n    print(\"Video's true class is\", vidClass)\n    print(\"Video has been predicted as\", videoPred)\n    print(\" \")\n    print(\"Fake frames have value close to:\", classifier.FAKE_CLASS_VAL)\n    print(\"Real frames have value close to:\", classifier.REAL_CLASS_VAL)\n    print(\" \")\n\n    highlighted_frames = 3\n\n    top_fake_frames = np.argsort(framesPred)[:highlighted_frames]\n    top_real_frames = np.argsort(-framesPred)[:highlighted_frames]\n    \n    # show the 'fakest' frames\n    print(\"The 'fakest' frames are:\")\n    fig, ax = plt.subplots(1, highlighted_frames, figsize=(4*highlighted_frames, 4))\n    fig.set_facecolor('white')\n    for i, frame_id in enumerate(top_fake_frames):\n        ax[i].imshow(imageSequence[frame_id])\n        ax[i].set_title(f\"Frame {frame_id}, value {framesPred[frame_id]:.4f}\")\n    plt.show()\n    \n    # show the 'realest' frames\n    print(\"The 'realest' frames are:\")\n    fig, ax = plt.subplots(1, highlighted_frames, figsize=(4*highlighted_frames, 4))\n    fig.set_facecolor('white')\n    for i, frame_id in enumerate(top_real_frames):\n        ax[i].imshow(imageSequence[frame_id])\n        ax[i].set_title(f\"Frame {frame_id}, value {framesPred[frame_id]:.4f}\")\n    plt.show()\n    \n    # explanation for the 'fakest' frame\n    p = Pipeline(classifier, seg, expl, segmentationDim=\"2D\", explanationMode=\"frame\",\n                 nSegments=N_SEGMENTS, shapSamples=SHAP_SAMPLES)\n    p.start(imageSequence[top_fake_frames[0]:top_fake_frames[0]+1], vidClass, vidName[:-4]+\"-fake-frames\")\n        \n    # explanation for the 'realest' frame\n    p = Pipeline(classifier, seg, expl, segmentationDim=\"2D\", explanationMode=\"frame\",\n                 nSegments=N_SEGMENTS, shapSamples=SHAP_SAMPLES)\n    p.start(imageSequence[top_real_frames[0]:top_real_frames[0]+1], vidClass, vidName[:-4]+\"-real-frames\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}