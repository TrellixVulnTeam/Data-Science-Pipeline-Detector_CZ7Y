{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install face_recognition","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-01T17:06:53.826688Z","iopub.execute_input":"2022-04-01T17:06:53.827095Z","iopub.status.idle":"2022-04-01T17:14:48.909449Z","shell.execute_reply.started":"2022-04-01T17:06:53.827032Z","shell.execute_reply":"2022-04-01T17:14:48.907738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets define the mesonet model - mesonet.py","metadata":{}},{"cell_type":"code","source":"from keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense,Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\nfrom keras.optimizers import Adam\nimport os\nimport glob\nimport torch\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nIMGWIDTH = 256\nimport face_recognition","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:14:48.913068Z","iopub.execute_input":"2022-04-01T17:14:48.913642Z","iopub.status.idle":"2022-04-01T17:14:59.783852Z","shell.execute_reply.started":"2022-04-01T17:14:48.913545Z","shell.execute_reply":"2022-04-01T17:14:59.782213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier:\n    def __init__():\n        self.model = 0\n    \n    def predict(self, x):\n        return self.model.predict(x)\n    \n    def fit(self, x, y):\n        return self.model.train_on_batch(x, y)\n    \n    def get_accuracy(self, x, y):\n        return self.model.test_on_batch(x, y)\n    \n    def load(self, path):\n        self.model.load_weights(path)\n\nclass Meso4(Classifier):\n    def __init__(self, learning_rate=0.001):\n        self.model = self.init_model()\n        optimizer = Adam(lr = learning_rate)\n        self.model.compile(optimizer = optimizer, loss='mean_squared_error', metrics=['accuracy'])\n    \n    def init_model(self):\n        x = Input(shape=(IMGWIDTH, IMGWIDTH, 3))\n        \n        x1 = Conv2D(8, (3,3), padding='same', activation='relu')(x)\n        x1 = BatchNormalization()(x1)\n        x1 = MaxPooling2D(pool_size=(2,2), padding='same')(x1)\n        \n        x2 = Conv2D(8,(5,5), padding='same', activation='relu')(x1)\n        x2 = BatchNormalization()(x2)\n        x2 = MaxPooling2D(pool_size=(2,2), padding='same')(x2)\n        \n        x3 = Conv2D(16, (5,5), padding='same', activation='relu')(x2)\n        x3 = BatchNormalization()(x3)\n        x3 = MaxPooling2D(pool_size=(2,2), padding='same')(x3)\n        \n        x4 = Conv2D(16,(5,5), padding='same', activation='relu')(x3)\n        x4 = BatchNormalization()(x4)\n        x4 = MaxPooling2D(pool_size=(4,4), padding='same')(x4)\n        \n        y = Flatten()(x4)\n        y = Dropout(0.5)(y)\n        y = Dense(16)(y)\n        y = LeakyReLU(alpha=0.1)(y)\n        y = Dropout(0.5)(y)\n        y = Dense(1, activation='sigmoid')(y)\n        \n        return KerasModel(input=x, outputs=y)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:14:59.807917Z","iopub.execute_input":"2022-04-01T17:14:59.808294Z","iopub.status.idle":"2022-04-01T17:14:59.833956Z","shell.execute_reply.started":"2022-04-01T17:14:59.808228Z","shell.execute_reply":"2022-04-01T17:14:59.832017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting the trained model weights","metadata":{}},{"cell_type":"code","source":"!wget https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/raw/master/Chapter04/Deepfake%20Recognition/mesonet_weights/Meso4_DF","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:14:59.835848Z","iopub.execute_input":"2022-04-01T17:14:59.836166Z","iopub.status.idle":"2022-04-01T17:15:01.571751Z","shell.execute_reply.started":"2022-04-01T17:14:59.836112Z","shell.execute_reply":"2022-04-01T17:15:01.57033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nMesoNet_classifier = Meso4()\nMesoNet_classifier.load(\"Meso4_DF\")","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:15:01.574603Z","iopub.execute_input":"2022-04-01T17:15:01.575036Z","iopub.status.idle":"2022-04-01T17:15:02.174461Z","shell.execute_reply.started":"2022-04-01T17:15:01.574964Z","shell.execute_reply":"2022-04-01T17:15:02.172902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# See github.com/timesler/facenet-pytorch:\n#from facenet_pytorch import MTCNN, InceptionResnetV1\n\n#device = 'cuda:0' if torch.cuda.is_available() else 'cpu' #checks if GPY is being used or the CPU\n#print(f'Running on device: {device}')\n#torch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:15:02.176822Z","iopub.execute_input":"2022-04-01T17:15:02.177343Z","iopub.status.idle":"2022-04-01T17:15:02.183905Z","shell.execute_reply.started":"2022-04-01T17:15:02.177223Z","shell.execute_reply":"2022-04-01T17:15:02.181994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Have to run code below in the fisrt time running","metadata":{}},{"cell_type":"code","source":"# Get all test videos\nfilenames = glob.glob('/kaggle/input/deepfake-detection-challenge/test_videos/*.mp4')\n\n# Number of frames to sample (evenly spaced) from each video\nn_frames = 10\n\nwith torch.no_grad():\n    face_list_whole_data=[]\n    for i, filename in enumerate(filenames[:5]):\n        print(f'Processing {i+1:5n} of {len(filenames):5n} videos\\r', end='')    \n        try:\n            # Create video reader and find length\n            v_cap = cv2.VideoCapture(filename)\n            v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n            # Pick 'n_frames' evenly spaced frames to sample\n            sample = np.linspace(0, v_len - 1, n_frames).round().astype(int)\n            face_list_1video = []\n            for j in range(v_len):\n                if j in sample:\n                    success, vframe = v_cap.read()\n                    vframe = cv2.cvtColor(vframe, cv2.COLOR_BGR2RGB)\n                    face_locations = face_recognition.face_locations(vframe)\n                    face_list_1frame=[]\n                    for face_location in face_locations:\n                    # Print the location of each face in this image\n                        top, right, bottom, left = face_location\n                    #print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n                    # Access the actual face itself:\n                        face_image = vframe[top:bottom, left:right]\n                        res = cv2.resize(face_image, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                        face_list_1frame.append(res/255)\n                    face_list_1video.append(face_list_1frame)\n            face_list_whole_data.append(face_list_1video)\n        except KeyboardInterrupt:\n            raise Exception(\"Stopped.\")","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:17:07.488072Z","iopub.execute_input":"2022-04-01T17:17:07.48852Z","iopub.status.idle":"2022-04-01T17:18:20.989708Z","shell.execute_reply.started":"2022-04-01T17:17:07.488455Z","shell.execute_reply":"2022-04-01T17:18:20.988609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Show one face in a selected frame","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize=(5, 5))\nplt.grid(False)\nax.xaxis.set_visible(False)\nax.yaxis.set_visible(False)\nax.imshow(face_list_whole_data[1][1][0])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:18:20.992343Z","iopub.execute_input":"2022-04-01T17:18:20.992727Z","iopub.status.idle":"2022-04-01T17:18:21.150753Z","shell.execute_reply.started":"2022-04-01T17:18:20.992667Z","shell.execute_reply":"2022-04-01T17:18:21.149474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_prob_list=[0]*len(face_list_whole_data)\nfor i, video in enumerate(face_list_whole_data):\n    prob_list=[]\n    for j, frame in enumerate(video):\n        img_array=np.array(frame)\n        probabilistic_predictions = MesoNet_classifier.predict(img_array)\n        prob_list.append(probabilistic_predictions)\n    all_prob_list[i]=prob_list\n        #predictions = [num_to_label[round(x[0])] for x in probabilistic_predictions]\n        #print(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:18:21.152836Z","iopub.execute_input":"2022-04-01T17:18:21.153215Z","iopub.status.idle":"2022-04-01T17:18:22.074622Z","shell.execute_reply.started":"2022-04-01T17:18:21.153114Z","shell.execute_reply":"2022-04-01T17:18:22.072943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_prob_list","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:18:22.079047Z","iopub.execute_input":"2022-04-01T17:18:22.080243Z","iopub.status.idle":"2022-04-01T17:18:22.100566Z","shell.execute_reply.started":"2022-04-01T17:18:22.080155Z","shell.execute_reply":"2022-04-01T17:18:22.099527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bias = -0.4\nweight = 0.068235746\n\nsubmission = []\nsubm_prob=[]\nfor filename, prob in zip(filenames, all_prob_list):\n    if prob is not None and len(prob) == 10:\n        indiv_prob=[]\n        for i in prob:\n            #p = 1 / (1 + np.exp(-(bias + (weight * i).sum())))\n            #indiv_prob.append(p)\n            indiv_prob.append(i)\n    subm_prob.append(indiv_prob)\n    #else: prob = 0.5\n    submission.append([os.path.basename(filename), sum(indiv_prob)/len(indiv_prob)])\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:18:22.103485Z","iopub.execute_input":"2022-04-01T17:18:22.10384Z","iopub.status.idle":"2022-04-01T17:18:22.112083Z","shell.execute_reply.started":"2022-04-01T17:18:22.103782Z","shell.execute_reply":"2022-04-01T17:18:22.111149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:18:22.113634Z","iopub.execute_input":"2022-04-01T17:18:22.114122Z","iopub.status.idle":"2022-04-01T17:18:22.132315Z","shell.execute_reply.started":"2022-04-01T17:18:22.114053Z","shell.execute_reply":"2022-04-01T17:18:22.130992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_to_label = {1:\"real\", 0:\"fake\"}","metadata":{"execution":{"iopub.status.busy":"2022-04-01T17:18:22.133997Z","iopub.execute_input":"2022-04-01T17:18:22.134511Z","iopub.status.idle":"2022-04-01T17:18:22.148116Z","shell.execute_reply.started":"2022-04-01T17:18:22.134441Z","shell.execute_reply":"2022-04-01T17:18:22.147225Z"},"trusted":true},"execution_count":null,"outputs":[]}]}