{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n%matplotlib inline \nimport cv2 as cv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-14T01:06:35.459799Z","iopub.execute_input":"2021-10-14T01:06:35.460168Z","iopub.status.idle":"2021-10-14T01:06:38.592568Z","shell.execute_reply.started":"2021-10-14T01:06:35.460094Z","shell.execute_reply":"2021-10-14T01:06:38.591696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# set variables","metadata":{}},{"cell_type":"code","source":"DATA_FOLDER = '../input/deepfake-detection-challenge'\nTRAIN_SAMPLE_FOLDER = 'train_sample_videos'\nTEST_FOLDER = 'test_videos'\n\ntrain_list = list(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))\ntest_list = list(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))\njson_file = [file for file in train_list if  file.endswith('json')][0]\nprint(f\"JSON file: {json_file}\")\n\nFACE_DETECTION_FOLDER = '../input/haar-cascades-for-face-detection'\nprint(f\"Face detection resources: {os.listdir(FACE_DETECTION_FOLDER)}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:38.594836Z","iopub.execute_input":"2021-10-14T01:06:38.5951Z","iopub.status.idle":"2021-10-14T01:06:38.854687Z","shell.execute_reply.started":"2021-10-14T01:06:38.595055Z","shell.execute_reply":"2021-10-14T01:06:38.853771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.define ObjectDetector ","metadata":{}},{"cell_type":"code","source":"class ObjectDetector():\n    '''\n    Class for Object Detection\n    '''\n    def __init__(self,object_cascade_path):\n        '''\n        param: object_cascade_path - path for the *.xml defining the parameters for {face, eye, smile, profile}\n        detection algorithm\n        source of the haarcascade resource is: https://github.com/opencv/opencv/tree/master/data/haarcascades\n        '''\n\n        self.objectCascade=cv.CascadeClassifier(object_cascade_path)\n\n\n    def detect(self, image, scale_factor=1.3,\n               min_neighbors=5,\n               min_size=(20,20)):\n        '''\n        Function return rectangle coordinates of object for given image\n        param: image - image to process\n        param: scale_factor - scale factor used for object detection\n        param: min_neighbors - minimum number of parameters considered during object detection\n        param: min_size - minimum size of bounding box for object detected\n        '''\n        rects=self.objectCascade.detectMultiScale(image,\n                                                scaleFactor=scale_factor,\n                                                minNeighbors=min_neighbors,\n                                                minSize=min_size)\n        return rects","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:38.856159Z","iopub.execute_input":"2021-10-14T01:06:38.85642Z","iopub.status.idle":"2021-10-14T01:06:38.864892Z","shell.execute_reply.started":"2021-10-14T01:06:38.856374Z","shell.execute_reply":"2021-10-14T01:06:38.86378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.make detector ( front / eye / profile / smile)","metadata":{}},{"cell_type":"code","source":"#Frontal face, profile, eye and smile  haar cascade loaded\nfrontal_cascade_path= os.path.join(FACE_DETECTION_FOLDER,'haarcascade_frontalface_default.xml')\neye_cascade_path= os.path.join(FACE_DETECTION_FOLDER,'haarcascade_eye.xml')\nprofile_cascade_path= os.path.join(FACE_DETECTION_FOLDER,'haarcascade_profileface.xml')\nsmile_cascade_path= os.path.join(FACE_DETECTION_FOLDER,'haarcascade_smile.xml')\n\n#Detector object created\n# frontal face\nfod=ObjectDetector(frontal_cascade_path)\n# eye\neod=ObjectDetector(eye_cascade_path)\n# profile face\npod=ObjectDetector(profile_cascade_path)\n# smile\nsod=ObjectDetector(smile_cascade_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:38.866327Z","iopub.execute_input":"2021-10-14T01:06:38.866573Z","iopub.status.idle":"2021-10-14T01:06:38.995229Z","shell.execute_reply.started":"2021-10-14T01:06:38.866531Z","shell.execute_reply":"2021-10-14T01:06:38.994468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.detect base function","metadata":{}},{"cell_type":"code","source":"def detect_objects(image, scale_factor, min_neighbors, min_size):\n    '''\n    Objects detection function\n    Identify frontal face, eyes, smile and profile face and display the detected objects over the image\n    param: image - the image extracted from the video\n    param: scale_factor - scale factor parameter for `detect` function of ObjectDetector object\n    param: min_neighbors - min neighbors parameter for `detect` function of ObjectDetector object\n    param: min_size - minimum size parameter for f`detect` function of ObjectDetector object\n    '''\n    \n    image_gray=cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n\n\n    eyes=eod.detect(image_gray,\n                   scale_factor=scale_factor,\n                   min_neighbors=min_neighbors,\n                   min_size=(int(min_size[0]/2), int(min_size[1]/2)))\n\n    for x, y, w, h in eyes:\n        #detected eyes shown in color image\n        cv.circle(image,(int(x+w/2),int(y+h/2)),(int((w + h)/4)),(0, 0,255),3)\n \n    # deactivated due to many false positive\n    smiles=sod.detect(image_gray,\n                  scale_factor=scale_factor,\n                  min_neighbors=min_neighbors,\n                  min_size=(int(min_size[0]/2), int(min_size[1]/2)))\n\n    for x, y, w, h in smiles:\n       #detected smiles shown in color image\n       cv.rectangle(image,(x,y),(x+w, y+h),(0, 0,255),3)\n\n\n    profiles=pod.detect(image_gray,\n                   scale_factor=scale_factor,\n                   min_neighbors=min_neighbors,\n                   min_size=min_size)\n\n    for x, y, w, h in profiles:\n        #detected profiles shown in color image\n        cv.rectangle(image,(x,y),(x+w, y+h),(255, 0,0),3)\n\n    faces=fod.detect(image_gray,\n                   scale_factor=scale_factor,\n                   min_neighbors=min_neighbors,\n                   min_size=min_size)\n\n    for x, y, w, h in faces:\n        #detected faces shown in color image\n        cv.rectangle(image,(x,y),(x+w, y+h),(0, 255,0),3)\n\n    # image\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(111)\n    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n    ax.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:38.997002Z","iopub.execute_input":"2021-10-14T01:06:38.997382Z","iopub.status.idle":"2021-10-14T01:06:39.014418Z","shell.execute_reply.started":"2021-10-14T01:06:38.997341Z","shell.execute_reply":"2021-10-14T01:06:39.013323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Detect Function ","metadata":{}},{"cell_type":"code","source":"def extract_image_objects(video_file, video_set_folder=TRAIN_SAMPLE_FOLDER):\n    '''\n    Extract one image from the video and then perform face/eyes/smile/profile detection on the image\n    param: video_file - the video from which to extract the image from which we extract the face\n    '''\n    video_path = os.path.join(DATA_FOLDER, video_set_folder,video_file)\n    capture_image = cv.VideoCapture(video_path) \n    ret, frame = capture_image.read()\n    #frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n    detect_objects(image=frame, \n            scale_factor=1.3, \n            min_neighbors=5, \n            min_size=(50, 50))  \n  ","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:39.016501Z","iopub.execute_input":"2021-10-14T01:06:39.016926Z","iopub.status.idle":"2021-10-14T01:06:39.034254Z","shell.execute_reply.started":"2021-10-14T01:06:39.016855Z","shell.execute_reply":"2021-10-14T01:06:39.032978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# detect test ","metadata":{}},{"cell_type":"code","source":"def get_meta_from_json(path):\n    df = pd.read_json(os.path.join(DATA_FOLDER, path, json_file))\n    df = df.T\n    return df\n\nmeta_train_df = get_meta_from_json(TRAIN_SAMPLE_FOLDER)\nmeta_train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:39.037644Z","iopub.execute_input":"2021-10-14T01:06:39.038004Z","iopub.status.idle":"2021-10-14T01:06:39.871346Z","shell.execute_reply.started":"2021-10-14T01:06:39.037946Z","shell.execute_reply":"2021-10-14T01:06:39.870499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"same_original_fake_train_sample_video = list(meta_train_df.loc[meta_train_df.original=='kgbkktcjxf.mp4'].index)\nfor video_file in same_original_fake_train_sample_video[1:4]:\n    print(video_file)\n    extract_image_objects(video_file)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T01:06:39.872722Z","iopub.execute_input":"2021-10-14T01:06:39.872959Z","iopub.status.idle":"2021-10-14T01:06:42.563798Z","shell.execute_reply.started":"2021-10-14T01:06:39.872919Z","shell.execute_reply":"2021-10-14T01:06:42.563055Z"},"trusted":true},"execution_count":null,"outputs":[]}]}