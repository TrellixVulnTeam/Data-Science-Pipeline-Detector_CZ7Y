{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA_FOLDER = '../input/deepfake-detection-challenge'\nTRAIN_SAMPLE_FOLDER = 'train_sample_videos'\nTEST_FOLDER = 'test_videos'\n\nprint(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\nprint(f\"Test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list = list(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))\njson_file = [file for file in train_list if  file.endswith('json')][0]\nprint(f\"JSON file: {json_file}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_meta_from_json(path):\n    df = pd.read_json(os.path.join(DATA_FOLDER, path, json_file))\n    df = df.T\n    return df\n\nmeta_train_df = get_meta_from_json(TRAIN_SAMPLE_FOLDER)\nmeta_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image_from_video(video_file):\n    capture_image = cv.VideoCapture(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file)) \n    ret, frame = capture_image.read()\n    return ret, frame\n\ndef display_image_from_video(video_file):\n    ret, frame = read_image_from_video(video_file)\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(111)\n    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n    ax.set_title(video_file)\n    ax.imshow(frame)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_train_video = [\"aelzhcnwgf.mp4\", \"adylbeequz.mp4\"]\nfor video_file in fake_train_video:\n    display_image_from_video(video_file)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def save_image(image, filename, label):\n    if not isinstance(image, Image.Image):\n        image = Image.fromarray(image)\n    image.save(\"./images/%s/%s.jpg\" % (label, filename))\n    print(\"Saved as %s.jpg\" % filename)\n\nif not os.path.exists(\"./images\"):\n    os.mkdir(\"./images\")\n    \nif not os.path.exists(\"./images/real\"):\n    os.mkdir(\"./images/real\")\n    \nif not os.path.exists(\"./images/fake\"):\n    os.mkdir(\"./images/fake\")\n    \nfor video_file, label in zip(meta_train_df.index, meta_train_df.label):\n    ret, frame = read_image_from_video(video_file)\n    if ret:\n        save_image(frame, os.path.splitext(video_file)[0], label.lower())\n    else:\n        print(\"Failed to read image from video %s\" % video_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_train_df['image'] = meta_train_df.index.str.replace(\"mp4\", \"jpg\")\nmeta_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_DATA_FOLDER = \"./images\"\n\ndef read_image(image_path):\n    return np.asarray(Image.open(image_path))\n\ndef display_image(image):\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(111)\n    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n    ax.imshow(image)\n\nimage = read_image(os.path.join(IMAGE_DATA_FOLDER, \"fake\", \"aelzhcnwgf.jpg\"))\ndisplay_image(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def downscale_image(image):\n    image_size = [image.shape[1], image.shape[0]]\n    return np.asarray(Image.fromarray(image)\n        .resize([image_size[0] // 4, image_size[1] // 4], Image.BOX))\n\nlr_image = downscale_image(image)\ndisplay_image(lr_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_image = tf.expand_dims(lr_image, 0)\nlr_image = tf.cast(lr_image, tf.float32)\nhr_image = model(lr_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr_image = tf.cast(hr_image, tf.uint8)\ndisplay_image(tf.squeeze(hr_image).numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_DATA_FOLDER = \"./images\"\n\ndef read_image(image_path):\n    return np.asarray(Image.open(image_path))\n\ndef display_image(image):\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(111)\n    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n    ax.imshow(image)\n\nimage = read_image(os.path.join(IMAGE_DATA_FOLDER, \"fake\", \"adylbeequz.jpg\"))\ndisplay_image(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def downscale_image(image):\n    image_size = [image.shape[1], image.shape[0]]\n    return np.asarray(Image.fromarray(image)\n        .resize([image_size[0] // 4, image_size[1] // 4], Image.BOX))\n\nlr_image = downscale_image(image)\ndisplay_image(lr_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_image = tf.expand_dims(lr_image, 0)\nlr_image = tf.cast(lr_image, tf.float32)\nhr_image = model(lr_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr_image = tf.cast(hr_image, tf.uint8)\ndisplay_image(tf.squeeze(hr_image).numpy())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}