{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install '/kaggle/input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport json\nimport numpy as np\nimport pandas as pd\n#from PIL import Image, ImageChops, ImageEnhance, ImageDraw\nfrom mtcnn import MTCNN\nfrom tensorflow.keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train 영상 path\ntest_video_path = '../input/deepfake-detection-challenge/test_videos/'\ntest_videos_path = [test_video_path + x for x in sorted(os.listdir(test_video_path))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = load_model('../input/model2/deepfake-detection-model-ir7-2.h5')\n# model = load_model('../input/model3/chimacV8-09.h5')\nmodel = load_model('../input/kerasmodel3/deepfake-detection-model-xception2.h5')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vid_num = 0\nall_vid = len(test_videos_path)\nfilename = []\nlabel = []\nmtcnn = MTCNN()\n# origin 영상 얼굴찾기\nfor vid_num, vid in enumerate(test_videos_path):\n    frame = 0\n    vid_name = vid.split('/')[-1]\n    pred = 0\n    detect_face_num = 0\n    before_face_img_coord = []\n    cap = cv2.VideoCapture(vid)\n    while(cap.isOpened()):\n        if frame == 10:\n            break\n        ret, img = cap.read()\n        if ret == False:\n            break\n\n            \n        if not before_face_img_coord:\n            face = mtcnn.detect_faces(img)\n            if not face:\n                frame += 1\n                continue\n            x1,y1,w,h = face[0]['box']\n            x2 = min(x1+w, img.shape[1])\n            y2 = min(y1+h, img.shape[0])\n            x1 = max(x1, 0)\n            y1 = max(y1, 0)\n            crop_img = img[y1:y2, x1:x2]\n            \n            \n            crop_img = cv2.resize(crop_img, (128, 128))\n            crop_img = (crop_img.flatten() / 255.0).reshape(-1, 128, 128, 3)\n            pred += model.predict(crop_img)[0][0]\n            \n            \n            before_face_img_coord = [y1,y2,x1,x2]\n            detect_face_num += 1\n\n        # 이전에 얼굴을 검출했으면 그주변에서 검색\n        else:\n            im = img[max(before_face_img_coord[0]-50,0) : min(before_face_img_coord[1]+50,img.shape[0]),\n                        max(before_face_img_coord[2]-50,0) : min(before_face_img_coord[3]+50,img.shape[1])]\n            face = mtcnn.detect_faces(im)\n            if face:\n                x11,y11,w,h = face[0]['box']\n                x1 = max(max(before_face_img_coord[2]-50, 0) + x11, 0)\n                x2 = min(x1 + w, img.shape[1])\n                y1 = max(max(before_face_img_coord[0]-50, 0) + y11, 0)\n                y2 = min(y1 + h, img.shape[0])\n                crop_img = img[y1:y2, x1:x2]\n                \n                \n                crop_img = cv2.resize(crop_img, (128, 128))\n                crop_img = (crop_img.flatten() / 255.0).reshape(-1, 128, 128, 3)\n                pred += model.predict(crop_img)[0][0]\n                \n                \n                before_face_img_coord = [y1,y2,x1,x2]\n                detect_face_num += 1\n        frame += 1\n\n    if before_face_img_coord:\n        acc = pred/detect_face_num\n        #acc = pred/300\n    else:\n        acc = 0.5\n        \n    filename.append(vid_name)\n    label.append(acc)\n    \n    print('*',end='')\n    if (vid_num+1) % 50 == 49:\n        print(vid_num,'/',all_vid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vid_num = 0\n# all_vid = len(test_videos_path)\n# filename = []\n# score = []\n# # origin 영상 얼굴찾기\n# for vid_num, vid in enumerate(test_videos_path):\n#     frame = 0\n#     vid_name = vid.split('/')[-1]\n#     before_face_img_coord = []\n#     cap = cv2.VideoCapture(path)\n#     while(cap.isOpened()):\n#         if frame == 300:\n#             break\n#         ret, img = cap.read()\n#         if ret == False:\n#             break\n        \n#         # 처음이면\n#         if not before_face_img_coord:\n#             face = mtcnn.detect_faces(img)\n#             # 처음인데 얼굴이 없으면 0.5로\n#             if not face:\n#                 break\n#             x1,y1,w,h = face['box']\n#             x2 = min(x1+w, img.shape[1])\n#             y2 = min(y1+h, img.shape[0])\n#             x1 = max(x1, 0)\n#             y1 = max(y1, 0)\n#             crop_img = img[y1:y2, x1:x2]\n#             crop_img = cv2.resize(crop_img, (299, 299))\n#             np.append(face_images, crop_img)\n#             before_face_img_coord = [y1,y2,x1,x2]\n                \n#         # 이전에 얼굴을 검출했으면 그주변에서 검색\n#         else:\n#             im = image[max(before_face_img_coord[0]-200,0) : min(before_face_img_coord[1]+200,img.shape[0]),\n#                         max(before_face_img_coord[2]-200,0) : min(before_face_img_coord[3]+200,img.shape[1])]\n#             face = mtcnn.detect_faces(im)\n#             if face:\n#                 x11,y11,w,h = face[0]['box']\n#                 x1 = max(max(coord[2]-200, 0) + x11, 0)\n#                 x2 = min(x1 + w, img.shape[1])\n#                 y1 = max(max(coord[0]-200, 0) + y11, 0)\n#                 y2 = min(y1 + h, img.shape[0])\n#                 crop_img = img[y1:y2, x1:x2]\n#                 crop_img = cv2.resize(crop_img, (299, 299))\n#                 np.append(face_images, crop_img)\n#                 before_face_img_coord=[y1,y2,x1,x2]\n            \n#             # 검색 안됐으면 그전 사진으로\n#             else:\n#                 crop_img = img[before_face_img_coord[0]:before_face_img_coord[1],\n#                                before_face_img_coord[2]:before_face_img_coord[3]]\n#                 np.append(face_images, crop_img)\n#         frame += 1\n\n#     print(face_images.shape) # must be (1, 300, 299, 299, 3)\n#     if face_images:\n#         pred = model.predict(face_images)\n#     else:\n#         pred = 0\n#     filename.append(vid_name)\n#     label.append(pred)\n    \n#     print('*',end='')\n#     if (vid_num+1) % 50 == 49:\n#         print(vid_num,'/',all_vid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'filename': filename, 'label': label})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission.loc[my_submission['label']==1,'label'] = 0.95\nmy_submission.loc[my_submission['label']==0,'label'] = 0.05\nmy_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}