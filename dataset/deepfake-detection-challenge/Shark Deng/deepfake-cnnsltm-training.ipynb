{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Device"},{"metadata":{"trusted":false},"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevices = device_lib.list_local_devices()\nprint(len(devices))\nfor i in devices:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import tensorflow as tf\nif tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"assert tf.test.is_gpu_available()\nassert tf.test.is_built_with_cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import tensorflow as tf \nimport keras\n\nconfig = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \nsess = tf.Session(config=config) \nkeras.backend.set_session(sess)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import glob \nimport os \nimport cv2 \nimport numpy as np \nimport pandas as pd \nfrom tqdm.notebook import tqdm\nimport random\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.layers import Conv3D, ConvLSTM2D, Dense, Flatten, Dropout, BatchNormalization, MaxPooling3D, Conv2D\nfrom keras.layers import Input\nfrom keras.models import Sequential, load_model, Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"SEQ_LENGTH = 10\nIMG_SIZE = 150\nBATCH_SIZE = 5\nEPOCHS = 5\nLABELS = ['REAL', 'FAKE']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train"},{"metadata":{},"cell_type":"markdown","source":"## Get data"},{"metadata":{"trusted":false},"cell_type":"code","source":"dirs = glob.glob('dfdc*')\n\nall_video_paths = np.array([])\nall_labels = np.array([])\n\n\nfor d in tqdm(dirs):\n    \n    # get rid of all 4 trunks\n    if d[-2:-1] == '4':\n        continue\n\n    meta = pd.read_json(d + '/metadata.json')\n    vn = meta.columns.values\n    vp = [d+'/'+n for n in vn]\n    all_video_paths = np.concatenate([all_video_paths, vp])\n    \n    labels = [meta[n]['label'] for n in vn]\n    labels = [LABELS.index(l) for l in labels]\n    all_labels = np.concatenate([all_labels, labels])\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# train_dir0 = 'dfdc_train_part_0/'\n# train_dir1 = 'dfdc_train_part_1/'\n# train_dir2 = 'dfdc_train_part_2/'\n\n# meta0 = pd.read_json('dfdc_train_part_0/metadata.json')\n# meta1 = pd.read_json('dfdc_train_part_1/metadata.json')\n# meta2 = pd.read_json('dfdc_train_part_2/metadata.json')\n\n# video_names0 = meta0.columns.values\n# video_names1 = meta1.columns.values\n# video_names2 = meta2.columns.values\n\n# meta = meta0 + meta1 + meta2 \n# video_names = meta.columns.values\n\n# video_paths0 = [train_dir0 + name for name in video_names0]\n# video_paths1 = [train_dir1 + name for name in video_names1]\n# video_paths2 = [train_dir2 + name for name in video_names2]\n\n# all_video_paths = video_paths0 + video_paths1 + video_paths2 \n# print(all_video_paths[:2])\n\n\n# tmp0 = [meta0[video_names0[i]].label for i in range(len(video_names0))]\n# tmp1 = [meta1[video_names1[i]].label for i in range(len(video_names1))]\n# tmp2 = [meta2[video_names2[i]].label for i in range(len(video_names2))]\n\n# tmp = tmp0 + tmp1 + tmp2\n# all_labels = [LABELS.index(l) for l in tmp]\n# len(all_labels)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Balance data"},{"metadata":{"trusted":false},"cell_type":"code","source":"fake_index = np.where(np.array(all_labels) == 1)[0]\ntrue_index = np.where(np.array(all_labels) == 0)[0]\nprint(len(fake_index))\nprint(len(true_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fake_index = np.random.choice(fake_index, len(true_index))\nprint(len(fake_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"true_vp = [all_video_paths[i] for i in true_index]\ntrue_label = [all_labels[i] for i in true_index]\nfake_vp = [all_video_paths[i] for i in fake_index]\nfake_label = [all_labels[i] for i in fake_index]\nprint(len(true_vp))\nprint(len(true_label))\nprint(len(fake_vp))\nprint(len(fake_label))\n\npaths = np.concatenate([true_vp, fake_vp])\nlabels = np.concatenate([true_label, fake_label])\nprint(len(paths))\nprint(len(labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shuffle"},{"metadata":{"trusted":false},"cell_type":"code","source":"# shuffle \nc = list(zip(paths, labels))\nrandom.shuffle(c)\npaths, labels = zip(*c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split"},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(paths, labels, test_size=0.2)\n\nprint(len(x_train))\nprint(len(y_train))\nprint(len(x_val))\nprint(len(y_val))\n\nprint(x_train[:10])\nprint(y_train[:10])\nprint(x_val[:10])\nprint(y_val[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_sequence(video_path):\n    v_cap = cv2.VideoCapture(video_path)\n    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    samples = np.linspace(0, v_len-1, SEQ_LENGTH).round()\n    imgs = []\n    for i in range(v_len):\n        rel, frame = v_cap.read()\n        if frame is None:\n            print(video_path)\n            \n        if i in samples:\n            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) # resize\n            img = np.mean(img, axis=-1)\n            img = np.expand_dims(img, axis=-1)\n            imgs.append(img)\n    \n    # update i\n    v_cap.release()\n    \n    return np.array(imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# training\ndef generator():\n    i = 0\n    while True:\n        # reset i\n        if i >= len(x_train):\n            i = 0  \n        \n        \n        # get batch\n        batch_videos = x_train[i:i+BATCH_SIZE]\n        batch_labels = y_train[i:i+BATCH_SIZE]\n        \n        X = []\n        for v in batch_videos:\n            X.append(get_sequence(v))\n            \n            \n        # upgrade i\n        i += BATCH_SIZE\n            \n        yield np.array(X), np.array(batch_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gen = generator()\na, b = next(gen)\nprint(a.shape)\nprint(b.shape)\ngen = generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model \ndef CNNLSTM(input_shape=(20, 300, 300, 1)):\n    model = Sequential()\n\n    model.add(Conv3D(16, kernel_size=3, activation='relu', padding='same', input_shape=input_shape,  data_format='channels_last'))\n    model.add(BatchNormalization())\n    \n    model.add(ConvLSTM2D(32, kernel_size=(3), padding='same', return_sequences=True))\n    model.add(BatchNormalization())\n    \n    model.add(Conv3D(1, kernel_size=3, activation='relu', padding='same', data_format='channels_last'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling3D(strides=2))\n    \n    model.add(Conv3D(1, kernel_size=3, activation='relu', padding='same', data_format='channels_last'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling3D(strides=2))\n    \n    model.add(Flatten())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1, activation='sigmoid'))\n\n\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# first train\nmodel = CNNLSTM((SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 1))\n\n# more train \n# model = load_model('./cnnlstm-5.h5')\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# callbacks\nes = EarlyStopping(monitor='loss', verbose=1, patience=3)\nrc = ReduceLROnPlateau(monitor='loss', verbose=1, factor=0.2, patience=3, min_lr=1e-5)\n\ncb = [es, rc]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# don't use hardcode video numbers\nhistory = model.fit_generator(generator=gen, \n                              epochs=EPOCHS, \n                              steps_per_epoch = len(x_train)//BATCH_SIZE,\n                              callbacks=cb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# \nmodel.save('./cnnlstm-9.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"conda_tensorflow_p36","language":"python","name":"conda_tensorflow_p36"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}