{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <div style=\"text-align: center\"> First Impression about Deepfake Detection Challenge\n\n</div>\n<img src=\"http://www.unidiversidad.com.ar/cache_2/deepfakevide_630_945.jpg\">\n\nDeepfake techniques, which present realistic AI-generated videos of people doing and saying fictional things, have the potential to have a significant impact on how people determine the legitimacy of information presented online. These content generation and modification technologies may affect the quality of public discourse and the safeguarding of human rightsâ€”especially given that deepfakes may be used maliciously as a source of misinformation, manipulation, harassment, and persuasion. Identifying manipulated media is a technically demanding and rapidly evolving challenge that requires collaborations across the entire tech industry and beyond.\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a> <br>\n## Notebook  Content\n\n1. [Import](#1)\n1. [Load Data](#2)\n1. [Display images](#3)\n1. [TAke some frames](#4)\n1. [Face Detection](#5)\n1. [Region Of interest](#6)\n1. [Example of Submission](#7)\n\n"},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"1\"></a> <br>**\n## 1- Import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"2\"></a> <br>**\n## 2- Load Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n\ntrain_dir = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'\ntrain_video_files = [train_dir + x for x in os.listdir(train_dir)]\ntest_dir = '/kaggle/input/deepfake-detection-challenge/test_videos/'\ntest_video_files = [test_dir + x for x in os.listdir(test_dir)]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_json('/kaggle/input/deepfake-detection-challenge/train_sample_videos/metadata.json').transpose()\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape # We have 400 videos ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.original.nunique()  # from this aprox 209 originals create 400, would be the same video? lest check soon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.label.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.label.value_counts(normalize=True) # Check that aprox 80% are fake","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['original'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['original']=='meawmsgiti.mp4']  # Looking the same files of videos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"video1= train_dir + 'akxoopqjqz.mp4'  \nvideo2 =train_dir + 'altziddtxi.mp4'\nvideo3 = train_dir+ 'arlmiizoob.mp4'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"3\"></a> <br>**\n## 3- Display Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_img(video):\n    cap = cv2.VideoCapture(video)  # take 1 picture\n    ret, frame = cap.read()\n    fig = plt.figure(figsize=(8,8))\n    ax = fig.add_subplot(111)\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    ax.imshow(frame)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_img(video1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_img(video2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_img(video3)  # lets check this picture ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start working with simple video"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_Video = train_video_files[8]\nfirst_Video","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name_video = first_Video.split('/', 5)[5] # I will use this funtion soon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train.index == name_video] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"4\"></a> <br>**\n## 4- take some Frames"},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\ncap = cv2.VideoCapture(first_Video)\nret,frame = cap.read()\n\nwhile count < 3:\n    cap.set(cv2.CAP_PROP_POS_MSEC,(count*1000))   \n    ret,frame = cap.read()\n    if count == 0:\n        image0 = frame\n    elif count == 1:\n        image1 = frame\n    elif count == 2:\n        image2 = frame\n    \n    #cv2.imwrite( filepath+ \"\\frame%d.jpg\" % count, image)     # Next I will save frame as JPEG\n    count = count + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display(img):\n    \n    fig = plt.figure(figsize=(8,8))\n    ax = fig.add_subplot(111)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    ax.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(image0)  # frame 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(image1) # frame 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(image2) # frame 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"5\"></a> <br>**\n## 5- Face Detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# You need to Download or add this file to your notebook, Check in the input files\n\nface_cascade = cv2.CascadeClassifier('/kaggle/input/cascade/haarcascade_frontalface_default.xml' ) # Cascade for faces","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def detect_face(img):\n    \n    face_img = img.copy()\n  \n    face_rects = face_cascade.detectMultiScale(face_img,scaleFactor=1.3, minNeighbors=5) \n    \n    for (x,y,w,h) in face_rects: \n        cv2.rectangle(face_img, (x,y), (x+w,y+h), (0,255,0), 10) \n        \n    return face_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = detect_face(image2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"second_Video= train_video_files[10]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name_video2 = second_Video.split('/', 5)[5] # I will use this funtion soon\nname_video2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train.index == name_video2] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncount = 0\ncap = cv2.VideoCapture(second_Video)\nret,frame = cap.read()\n\nwhile count < 5:\n    cap.set(cv2.CAP_PROP_POS_MSEC,(count*1000))   \n    ret,frame = cap.read()\n    if count == 0:\n        image0 = frame\n    elif count == 1:\n        image1 = frame\n    elif count == 2:\n        image2 = frame\n    elif count == 3:\n        image3 = frame\n    elif count == 4:\n        image4 = frame\n    \n    #cv2.imwrite( pathOut + \"\\\\frame%d.jpg\" % count, image)     # Next I will save frame as JPEG\n    count = count + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = detect_face(image0)\ndisplay(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = detect_face(image2)\ndisplay(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = detect_face(image3)\ndisplay(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"6\"></a> <br>**\n## 6- Create a Region of Interest (ROI)*"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  Lets Check the region of interest\n\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ROI(img):\n    \n    face_img = img.copy()\n  \n    face_rects = face_cascade.detectMultiScale(face_img,scaleFactor=1.3, minNeighbors=5) \n    \n    for (x,y,w,h) in face_rects: \n        roi = face_img[y:y+h,x:x+w] \n        \n        \n    return roi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = ROI(image3)\ndisplay(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Expand Region of interest"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ROI_Expand(img):\n    \n    offset = 50  # play around this value\n    \n    face_img = img.copy()\n  \n    face_rects = face_cascade.detectMultiScale(face_img,scaleFactor=1.3, minNeighbors=5) \n    \n    for (x,y,w,h) in face_rects: \n        roi = face_img[y-offset:y+h+offset,x-offset:x+w+offset] \n        \n        \n    return roi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = ROI_Expand(image3)\ndisplay(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"7\"></a> <br>**\n## 7- Example of Submission*"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/deepfake-detection-challenge/sample_submission.csv\")\nsubmission['label'] = 0.5 # \nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I hope this notebook **helpfull** for you\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}