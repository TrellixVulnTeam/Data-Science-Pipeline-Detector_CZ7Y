{"cells":[{"metadata":{},"cell_type":"markdown","source":"DataPreparation\n\n(Uploadflie) \n- test_make_pic.pkl : I change test video files to face pictures by openCV \n- make_pic : I change train video files to face pictures by openCV "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\npic_data = pd.read_pickle(\"/kaggle/input/dataset-train/make_pic.pkl\")\npic_data[\"pixcel\"] = pic_data[\"pixcel\"].apply(lambda x:np.array(x)/255 if type(x)==\"list\" else x)\ntrain = pd.read_json(\"../input/deepfake-detection-challenge/train_sample_videos/metadata.json\").T\ntrain[\"label\"] = train[\"label\"].apply(lambda x:0 if x==\"REAL\" else 1)\ntrain[\"video_file\"] = train.index\ntrain = pd.merge(train,pic_data,on=\"video_file\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nbb = []\nfor u in range(len(train[train[\"label\"]==1][\"pixcel\"])):\n    datagen = image.ImageDataGenerator(rotation_range=20)\n    x = train[train[\"label\"]==1][\"pixcel\"].values[u].reshape(1,128,128,3)\n    gen = datagen.flow(x, batch_size=1)\n    for i in range(3):\n        batches = next(gen)\n        gen_img = batches[0].astype(np.uint8)\n        bb.append(gen_img)\n        \ntrain = train.drop([\"original\",\"split\",\"video_file\"],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a = pd.DataFrame()\n#a[\"pixcel\"] = bb\n#a[\"label\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train  = train.append(a)\ntrain_data_box = []\nfor i in train[\"pixcel\"].values:\n    train_data_box = np.append(train_data_box,i)\ntrain_data_box = train_data_box.reshape(-1,128,128,3)\n\nlabel = train[\"label\"]\nlabel = pd.DataFrame(label.values)[0]\n\npic_data = pd.read_pickle(\"/kaggle/input/test-data/test_make_pic.pkl\").rename(columns={\"video_file\":\"filename\"})\nsample = pd.read_csv(\"/kaggle/input/deepfake-detection-challenge/sample_submission.csv\")\ntest_data = pd.merge(sample,pic_data,on=\"filename\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_box = []\nfor i in test_data[\"pixcel\"].values:\n    test_data_box = np.append(test_data_box,i)\ntest_data_box = test_data_box.reshape(-1,128,128,3)/255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPool2D\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.layers.core import Dense,Activation, Dropout, Flatten\nimport keras\nfrom keras.layers import BatchNormalization\nfrom IPython.display import display, HTML, clear_output\n\nsplit_num = 2\n\nkf = KFold(n_splits=split_num, shuffle=True)\noof_pred = np.zeros((train_data_box.shape[0], ))\ny_pred = np.zeros((label.shape[0], ))\ny_pred = y_pred.astype(\"float\")\n\npp = 0\n\nfor train_index, eval_index in kf.split(train_data_box):\n    x_train, x_test = train_data_box[train_index], train_data_box[eval_index]\n    y_train, y_test = label[train_index], label[eval_index]\n\n    x_train = x_train/255\n    x_test = x_test/255\n\n    # モデルの定義\n    model = Sequential()\n\n    model.add(Conv2D(64,3,input_shape=(128,128,3)))\n    model.add(Activation('relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n\n    model.add(Conv2D(64,3,input_shape=(128,128,3)))\n    model.add(Activation('relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n\n    model.add(Conv2D(64,3,input_shape=(128,128,3)))\n    model.add(Activation('relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n\n    model.add(Conv2D(64,3,input_shape=(128,128,3)))\n    model.add(Activation('relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n\n\n    model.add(Flatten())\n    model.add(Dense(32))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.5))\n    #model.add(BatchNormalization())\n\n    model.add(Dense(32))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.5))\n\n    model.add(Dense(32))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n\n    model.add(Dense(32))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n\n    model.add(Dense(1, activation='sigmoid'))\n\n    adam = RMSprop(lr=0.2e-4)\n    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=[\"accuracy\"])\n    #model.summary()\n    \n    #es_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n\n    ep = 200\n    history = model.fit(x_train,y_train, batch_size=32, nb_epoch=ep, verbose=1,validation_data=(x_test,y_test))#,callbacks=[es_cb])\n\n    clear_output()\n\n    oof_pred[eval_index] = y_test.values.reshape(oof_pred[eval_index].shape)\n    y_pred[eval_index] = model.predict(x_test).reshape(y_pred[eval_index].shape)\n    \n    pp = model.predict(test_data_box) + pp\n    \npp = pp/split_num\nprint(\"finished\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 可視化\nplt.plot(range(1, ep+1), history.history['loss'], label=\"loss\")\nplt.plot(range(1, ep+1), history.history['val_loss'], label=\"val_loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport glob\nimport os\nimport tqdm\nfilenames = glob.glob(os.path.join('/kaggle/input', 'deepfake-detection-challenge/test_videos/*.mp4'))\nsub = pd.read_csv(os.path.join('/kaggle/input', 'deepfake-detection-challenge/sample_submission.csv'))\nsub[\"label\"] = 0.5\nfile = []\nfor filename in tqdm.tqdm(filenames):\n    file.append(filename.split('/')[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[\"filename\"] = sorted(file, key=lambda s: s if s[0].isalnum() else s[1:])\nsub[\"label\"] = pp\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}