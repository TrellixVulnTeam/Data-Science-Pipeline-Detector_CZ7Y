{"cells":[{"metadata":{},"cell_type":"markdown","source":"I first started with yolov3 face detection model implemented with Keras. However I couldn't run it in Kaggle notebooks with tensorflow gpu due to old implementation of tf version = 1.6.0. So I found this pytorch face detector which is pretty fast via GPU."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install ../input/facenetpytorchmodel/facenet_pytorch-2.0.1-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from facenet_pytorch import MTCNN, InceptionResnetV1\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom pathlib import Path\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"IS_TEST = True\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_video(video_path, start_frame=0, end_frame=None, use_pbar=False):\n    reader = cv2.VideoCapture(video_path)\n    fps = reader.get(cv2.CAP_PROP_FPS)\n    num_frames = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n    if end_frame is None:\n        end_frame = num_frames\n    pbar = tqdm(total=end_frame-start_frame, desc=\"Reading frames\") if use_pbar else None\n    frame_num = 0\n    frames = []\n    while reader.isOpened():\n        _, img = reader.read()\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if img is None:\n            break\n        frame_num += 1\n        if frame_num < start_frame:\n            continue\n        frames.append(img)\n        if use_pbar:\n            pbar.update(1)\n        if frame_num >= end_frame:\n            break\n    return frames\n\ndef denormalize(img):\n    return ((img + 1.) * 127.5).astype(np.uint8)\n\ndef crop_faces(imgs, save_path=None):\n    for img in imgs:\n        img_cropped = mtcnn(Image.fromarray(img))\n        img_cropped = img_cropped.permute(1, 2, 0).numpy()\n        img_cropped = denormalize(img_cropped)\n        plt.subplot(121)\n        plt.imshow(img)\n        plt.subplot(122)\n        plt.imshow(img_cropped)\n        plt.show()\n        plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/deepfake-detection-challenge/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if IS_TEST:\n    submission = submission.iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mtcnn = MTCNN(image_size=224, margin=20, device=DEVICE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfor video_fn in tqdm(submission['filename'].unique()):\n    video_path = f'../input/deepfake-detection-challenge/test_videos/{video_fn}'\n    frames = read_video(video_path, start_frame=0, end_frame=10, use_pbar=True)\n    crop_faces(frames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}