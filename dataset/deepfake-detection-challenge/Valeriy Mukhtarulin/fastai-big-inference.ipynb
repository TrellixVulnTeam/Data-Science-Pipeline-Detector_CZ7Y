{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook I inference using my pretrained model, including pre-processing. The model was pretrained on a small subset of the data.\n\nSources:\n\nhttps://www.kaggle.com/humananalog/inference-demo"},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar xf /kaggle/input/ffmpeg-static-build/ffmpeg-git-amd64-static.tar.xz\n# !ln -s /kaggle/input/fastai-audio/audio .\n# !ln -s /kaggle/input/fastai/fastai .\n# !pip install -qU \"/kaggle/input/fastai2-wheels/fastprogress-0.2.2-py3-none-any.whl\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install -qU git+https://github.com/fastai/fastai\n# !pip install -qU torch torchaudio torchvision\n# !git clone https://github.com/mogwai/fastai_audio\n# %cd fastai_audio\n# !./install.sh\n# %cd ../\n# !ln -s /kaggle/input/fastai_audio/audio .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from audio import *  \n# from fastai.basics import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import gc\n# from functools import partial\nfrom pathlib import Path\n\nimport torchvision\nfrom fastai.vision import *\nfrom tqdm.notebook import tqdm\n\n\nhome = Path(\".\")\ninput_dir = Path(\"../input/deepfake-detection-challenge\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from fastai.utils import *\n# show_install(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torchvision\n# torchvision.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torchaudio.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !apt-get --assume-yes install sox libsox-dev libsox-fmt-all libsndfile1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.read_json(input_dir/\"train_sample_videos/metadata.json\").T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Audio"},{"metadata":{"trusted":true},"cell_type":"code","source":"ext = \".wav\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_path = Path(\"test_audio\")\naudio_path.mkdir(exist_ok=True)\ntrain_audio_path = Path(\"train_audio\")\ntrain_audio_path.mkdir(exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mp4_to_wav(filenames, out):\n    Path(out).mkdir(exist_ok=True)\n    for fn in tqdm(filenames):\n        out_fn = f\"{out/fn.stem}{ext}\"\n        command = f\"/kaggle/working/ffmpeg-git-20191209-amd64-static/ffmpeg -i '{fn}' -ar 44100 -vn '{out_fn}'\"\n        subprocess.call(command, shell=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mp4_to_wav((input_dir/\"test_videos\").ls(), audio_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mp4_to_wav((input_dir/\"train_sample_videos\").ls(), train_audio_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# config = AudioConfig()\n# config.duration = 10_000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get_y = lambda x: labels.loc[f\"{x.stem}.mp4\"].label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# audios = (AudioList.from_folder(train_audio_path, config=config)\n#           .split_by_rand_pct(.2, seed=42)\n#           .label_from_func(get_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BSA=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# db = audios.databunch(bs=BSA)\n# db.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = audio_learner(db)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = load_learner(\"/kaggle/input/deepfake\", \"export.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test = AudioList.from_folder(audio_path, config=config); test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.predict(test[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds = []\n# for t in test:\n#     preds.append(learn.data.classes[np.argmax(learn.predict(t)[2])])\n# preds[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def predict_from_file(wav_file, learner, verbose=True):  \n#     item = AudioItem(path=wav_file)\n#     if verbose: display(item)\n#     al = AudioList([item], path=item.path, config=config)\n#     ai = AudioList.open(al, item.path)\n#     y, pred, raw_pred = learner.predict(ai)\n#     if verbose: print(y)\n#     if verbose: print(pred.item())\n#     if verbose: print(raw_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict_from_file(test[0].path, learner )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Video"},{"metadata":{"trusted":true},"cell_type":"code","source":"# BS = 1 #CPU\nBS = 864","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ln -s /kaggle/input/blazeface-pytorch/* ./\n!ln -s /kaggle/input/deepfakes-inference-demo/helpers ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from blazeface import BlazeFace\nfacedet = BlazeFace().to(torch.device(\"cuda:0\"));\n# facedet = BlazeFace();\nfacedet.load_weights(\"blazeface.pth\")\nfacedet.load_anchors(\"anchors.npy\")\n_ = facedet.train(False)\n\nfrom helpers.read_video_1 import VideoReader\nfrom helpers.face_extract_1 import FaceExtractor\n\nframes_per_video = 17\n\nvideo_reader = VideoReader()\nvideo_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\nface_extractor = FaceExtractor(video_read_fn, facedet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_faces(video_path, batch_size):\n    # Find the faces for N frames in the video.\n    faces = face_extractor.process_video(video_path)\n\n    # Only look at one face per frame.\n    face_extractor.keep_only_best_face(faces)\n    \n    if len(faces) > 0:\n        # NOTE: When running on the CPU, the batch size must be fixed\n        # or else memory usage will blow up. (Bug in PyTorch?)\n        x = []\n\n        # If we found any faces, prepare them for the model.\n        n = 0\n        for frame_data in faces:\n            for face in frame_data[\"faces\"]:\n                x.append(face)\n                n += 1\n    return x\n\ndef predict_on_mp4(names, learner, bs=17):\n    preds = []\n    for fn in tqdm(names):\n        if fn.is_file():\n            faces = extract_faces(fn, batch_size=bs)\n            pred = [learner.predict(Image(torchvision.transforms.ToTensor()(f)))[2] for f in faces]\n            if not pred:\n                display(f\"No pred from {fn}\")\n            preds.append(pred)\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mace(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    \"Mean absolute error between clamped `pred` and `targ`.\"\n    pred,targ = flatten_check(pred,targ)\n    return torch.abs(targ - pred.clamp(0., 1.)).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = load_learner(\"/kaggle/input/deepfake\", \"big_shots_not_random_0_13.pkl\", bs=BS).to_fp32()\n# learn = load_learner(\"/kaggle/input/deepfake\", \"shots.pkl\", bs=BS).to_fp32()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_preds = predict_on_mp4((input_dir/\"test_videos\").ls(), learn); len(raw_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # classes\n# preds = []\n# for p in raw_preds:\n#     try:\n#         preds.append(torch.stack(p, dim=0).argmax(dim=1).float().mean().item())\n#     except:\n#         preds.append(0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nfor p in raw_preds:\n    try:\n        preds.append(torch.stack(p, dim=0).mean().clamp(0.1,0.9).item())\n    except:\n        preds.append(0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm = pd.read_csv(input_dir/\"sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm[\"label\"] = preds\n# subm[\"label\"] = 1 - subm[\"label\"] # for binary classification where 0 is FAKE and 1 is REAL\n# subm[\"label\"].value_counts(bins=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm.to_csv(\"submission.csv\", index=False, float_format='%.20f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}