{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install \"/kaggle/input/kornia020/kornia-0.2.0e110f3b-py2.py3-none-any.whl\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport kornia\n\nimport cv2\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef imshow(input: torch.Tensor):\n    #out: torch.Tensor = torchvision.utils.make_grid(input, nrow=4, padding=0)\n    out = input[:1]\n    out_np: np.array = kornia.tensor_to_image(out)\n    plt.imshow(out_np); plt.axis('off');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load video and preprocess\ndef load_video(video_path: str, num_frames: int) -> torch.Tensor:\n    print(video_path)\n    # TODO: need to install torchvision 0.5\n    # vframes, aframe, info = torchvision.io.read_video('data/deep_fake.mp4')\n\n    # Create a VideoCapture object and read from input file\n    # If the input is the camera, pass 0 instead of the video file name\n    cap = cv2.VideoCapture(video_path)\n\n    # Check if camera opened successfully\n    if (cap.isOpened() == False): \n        print(\"Error opening video stream or file\")\n\n    # Read until video is completed\n    frames_list: List[np.ndarray] = []\n    \n    count: int = 0\n    while(cap.isOpened() and count < num_frames):\n        # Capture frame-by-frame\n        ret, frame_tmp = cap.read()\n        frames_list.append(frame_tmp)\n        count += 1\n\n    # create numpy array BxHxWxC\n    frames_np: np.ndarray = np.array(frames_list)\n\n    # we need the tensor to be in the shape BxCxHxW\n    return kornia.image_to_tensor(frames_np)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define data augmentation pipeline\n# Please, check new data augmentation API:\n# https://kornia.readthedocs.io/en/latest/augmentation.html\ntransforms = nn.Sequential(\n    kornia.geometry.Resize(256),\n    kornia.color.Normalize(mean=0., std=255.),\n    kornia.augmentation.RandomHorizontalFlip(),\n    kornia.augmentation.RandomGrayscale(),\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input/deepfake-detection-challenge/'):\n    for filename in filenames:\n        if filename[-3:] == \"csv\": continue\n        file_path: str = os.path.join(dirname, filename)\n\n        # load a video\n        frames: torch.Tensor = load_video(file_path, num_frames=30)\n        print(frames.shape)\n        \n        imshow(frames)\n        \n        # send data to CUDA device\n        if torch.cuda.is_available():\n            frames = frames.cuda()\n        \n        # perform data augmentation\n        frames_out: torch.Tensor = transforms(frames)\n        print(frames_out.shape)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}