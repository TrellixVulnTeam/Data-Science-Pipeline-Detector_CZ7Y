{"cells":[{"metadata":{},"cell_type":"markdown","source":"Here is the training notebook for [this](https://www.kaggle.com/unkownhihi/dfdc-lrcn-inference) inference notebook. The reason why I'm doing it, is because I saw myself in other competition, struggling to get to the medal zone, but don't have a clue how people got there. I removed the dataset because I want to avoid people just clone, run, submit. \n\nThis training notebook is nothing special, just load, train."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport glob\nimport random\nfrom tqdm.notebook import tqdm\nfolders=os.listdir('../input/example1')+os.listdir('../input/example2')\nmetadatas=[]\nfor x in tqdm(folders):\n    metadatas.append(pd.read_json('../input/metadatas/metadata'+x.replace('example','')+'.json'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths=[]\nY=[]\nfor x in tqdm(folders):\n    for y in glob.glob('../input/dfdc-images-p*/'+x+'/*.jpg'):\n        if '_' in y:\n            continue\n        if not os.path.exists(y):\n            continue\n        Y.append(['REAL','FAKE'].index(metadatas[folders.index(x)][y.replace('../input/dfdc-images-p1/','').replace('../input/dfdc-images-p2/','').replace(x+'/','').replace('.jpg','.mp4')]['label']))\n        paths.append(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real=[]\nfake=[]\nfor m,n in zip(paths,Y):\n    if n==0:\n        real.append(m)\n    else:\n        fake.append(m)\nfake=random.sample(fake,len(real))\npaths,Y=[],[]\nfor x in real:\n    paths.append(x)\n    Y.append(0)\nfor x in fake:\n    paths.append(x)\n    Y.append(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shuffle(X,y):\n    new_train=[]\n    for m,n in zip(X,y):\n        new_train.append([m,n])\n    random.shuffle(new_train)\n    X,y=[],[]\n    for x in new_train:\n        X.append(x[0])\n        y.append(x[1])\n    return X,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths,y=shuffle(paths,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_birghtness(img):\n    return img/img.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_img(img):\n    imgs=[]\n    for x in range(10):\n        imgs.append(get_birghtness(img[:,x*240:(x+1)*240,:]))\n    return np.array(imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gets(paths):\n    al=[]\n    for x in paths:\n        al.append(process_img(cv2.cvtColor(cv2.imread(x),cv2.COLOR_BGR2RGB)))\n    return al\ndef generator(paths,y,batch_size=16):\n    while True:\n        for x in range(len(paths)//batch_size):\n            if x*batch_size+batch_size>len(paths):\n                yield (np.array(gets(paths[x*batch_size:])),y[x*batch_size:])\n            yield (np.array(gets(paths[x*batch_size:x*batch_size+batch_size])),\n                   y[x*batch_size:x*batch_size+batch_size])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet\nimport efficientnet.keras as efn\nbottleneck = efn.EfficientNetB1(weights='imagenet',include_top=False,pooling='avg')\nfrom keras.layers import *\ninp=Input((10,240,240,3))\nx=TimeDistributed(bottleneck)(inp)\nx = LSTM(128)(x)\nx = Dense(64, activation='elu')(x)\nx = Dense(1,activation='sigmoid')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(paths,y,test_size=0.15)\nfrom keras import Model\nmodel=Model(inp,x)\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler\ndef schedule(epoch):\n    return [6e-4,1e-4][epoch]\ncallback=LearningRateScheduler(schedule)\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-4))\n#model.fit(X,y,batch_size=16)\nmodel.fit_generator(generator(X_train,y_train,4),steps_per_epoch=len(X_train)//4+1,validation_data=generator(X_test,y_test,4),validation_steps=len(X_test)//4+1,epochs=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Please upvote if you found this helpful."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}