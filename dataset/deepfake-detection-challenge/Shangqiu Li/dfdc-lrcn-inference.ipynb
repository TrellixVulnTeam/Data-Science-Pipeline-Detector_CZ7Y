{"cells":[{"metadata":{},"cell_type":"markdown","source":"Here is just an example of how to use mobilenet face extractor for inference, and also lrcn. \n\n\nI didn't make the weights public, because people(including me) don't like high scoring infernece kernel. \n\n\n**BUT I'm also taking request to make the weights public. I'm OK with making the weights public.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/efficientnet/efficientnet-1.0.0-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport cv2\nimport glob\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport os\nimport efficientnet.keras as efn\nfrom keras.layers import *\nfrom keras import Model\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initialize Face Extractor"},{"metadata":{"trusted":true},"cell_type":"code","source":"detection_graph = tf.Graph()\nwith detection_graph.as_default():\n    od_graph_def = tf.compat.v1.GraphDef()\n    with tf.io.gfile.GFile('../input/mobilenet-face/frozen_inference_graph_face.pb', 'rb') as fid:\n        serialized_graph = fid.read()\n        od_graph_def.ParseFromString(serialized_graph)\n        tf.import_graph_def(od_graph_def, name='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = detection_graph.as_default()\ncm.__enter__()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsess=tf.compat.v1.Session(graph=detection_graph, config=config)\nimage_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\nboxes_tensor = detection_graph.get_tensor_by_name('detection_boxes:0')\nscores_tensor = detection_graph.get_tensor_by_name('detection_scores:0')\nnum_detections = detection_graph.get_tensor_by_name('num_detections:0')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffb09dc9-4297-4768-97e3-a9a9a8f37fe0","_cell_guid":"ef1c1fd7-b763-4a40-a5c0-524bfbc503e0","trusted":true},"cell_type":"code","source":"def get_img(images):\n    global boxes,scores,num_detections\n    im_heights,im_widths=[],[]\n    imgs=[]\n    for image in images:\n        (im_height,im_width)=image.shape[:-1]\n        imgs.append(image)\n        im_heights.append(im_height)\n        im_widths.append(im_widths)\n    imgs=np.array(imgs)\n    (boxes, scores_) = sess.run(\n        [boxes_tensor, scores_tensor],\n        feed_dict={image_tensor: imgs})\n    finals=[]\n    for x in range(boxes.shape[0]):\n        scores=scores_[x]\n        max_=np.where(scores==scores.max())[0][0]\n        box=boxes[x][max_]\n        ymin, xmin, ymax, xmax = box\n        (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                      ymin * im_height, ymax * im_height)\n        left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n        image=imgs[x]\n        finals.append(cv2.cvtColor(cv2.resize(image[max([0,top-40]):bottom+80,max([0,left-40]):right+80],(240,240)),cv2.COLOR_BGR2RGB))\n    return finals\ndef detect_video(video):\n    frame_count=10\n    capture = cv2.VideoCapture(video)\n    v_len = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_idxs = np.linspace(0,v_len,frame_count, endpoint=False, dtype=np.int)\n    imgs=[]\n    i=0\n    for frame_idx in range(int(v_len)):\n        ret = capture.grab()\n        if not ret: \n            print(\"Error grabbing frame %d from movie %s\" % (frame_idx, video))\n        if frame_idx >= frame_idxs[i]:\n            if frame_idx-frame_idxs[i]>20:\n                return None\n            ret, frame = capture.retrieve()\n            if not ret or frame is None:\n                print(\"Error retrieving frame %d from movie %s\" % (frame_idx, video))\n            else:\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                imgs.append(frame)\n            i += 1\n            if i >= len(frame_idxs):\n                break\n    imgs=get_img(imgs)\n    if len(imgs)<10:\n        return None\n    return np.hstack(imgs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('./videos/')\nfor x in tqdm(glob.glob('../input/deepfake-detection-challenge/test_videos/*.mp4')):\n    try:\n        filename=x.replace('../input/deepfake-detection-challenge/test_videos/','').replace('.mp4','.jpg')\n        a=detect_video(x)\n        if a is None:\n            continue\n        cv2.imwrite('./videos/'+filename,a)\n    except Exception as err:\n        print(err)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm.__exit__(None,Exception,'exit')\nsess.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initialize Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck = efn.EfficientNetB1(weights=None,include_top=False,pooling='avg')\ninp=Input((10,240,240,3))\nx=TimeDistributed(bottleneck)(inp)\nx = LSTM(128)(x)\nx = Dense(64, activation='elu')(x)\nx = Dense(1,activation='sigmoid')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Model(inp,x)\nmodel.load_weights('../input/dfdc-model3/model.h5')\n\ndef get_birghtness(img):\n    return img/img.max()\n# %% [code]\ndef process_img(img,flip=False):\n    imgs=[]\n    for x in range(10):\n        if flip:\n            imgs.append(get_birghtness(cv2.flip(img[:,x*240:(x+1)*240,:],1)))\n        else:\n            imgs.append(get_birghtness(img[:,x*240:(x+1)*240,:]))\n    return np.array(imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/deepfake-detection-challenge/sample_submission.csv\")\ntest_files=glob.glob('./videos/*.jpg')\nsubmission=pd.DataFrame()\nsubmission['filename']=os.listdir(('../input/deepfake-detection-challenge/test_videos/'))\nsubmission['label']=0.5\nfilenames=[]\nbatch=[]\nbatch1=[]\npreds=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in test_files:\n    img=process_img(cv2.cvtColor(cv2.imread(x),cv2.COLOR_BGR2RGB))\n    if img is None:\n        continue\n    batch.append(img)\n    batch1.append(process_img(cv2.cvtColor(cv2.imread(x),cv2.COLOR_BGR2RGB),True))\n    filenames.append(x.replace('./videos/','').replace('.jpg','.mp4'))\n    if len(batch)==16:\n        preds+=(((0.5*model.predict(np.array(batch))))+((0.5*model.predict(np.array(batch1))))).tolist()\n        batch=[]\n        batch1=[]\nif len(batch)!=0:\n    preds+=(((0.5*model.predict(np.array(batch))))+((0.5*model.predict(np.array(batch1))))).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_preds=[]\nfor x in preds:\n    new_preds.append(x[0])\nprint(sum(new_preds)/len(new_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x,y in zip(new_preds,filenames):\n    submission.loc[submission['filename']==y,'label']=min([max([0.1,x]),0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(submission['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(submission['label']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\n!rm -r videos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks for reading. Please upvote if you found it helpful."}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}