{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install --no-deps ../input/maruti/maruti-1.3.1-py3-none-any.whl\n!pip install /kaggle/input/facenetmtcnn/facenet_pytorch-2.1.1-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nfrom facenet_pytorch import MTCNN\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nfrom PIL import Image\nimport numpy as np\nimport math\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom maruti.imports.ml import *\nfrom torch.nn.utils.rnn import pack_sequence\nimport keras\nimport tensorflow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = '../input/deepfake-detection-challenge/test_videos/'\ntest_videos = sorted(os.listdir(test_dir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tensorflow.device('/gpu:0'):\n    model = tensorflow.keras.models.load_model('/kaggle/input/pytorch-keras-models/Resnext101.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize([256,256]),\n    transforms.CenterCrop([224,224]),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mtcnn = MTCNN(select_largest=False,device=device)\ngroup_transform = mdata.group_transform['val'] # default transform\ngroup_transform = lambda x: torch.stack(tuple(map(preprocess, x)))\n\ndef get_brightness_score(img):\n    return maruti.vision.image.brightness_score(img)\n\ndef adjust_brightness(img):\n    if(get_brightness_score(img) < 1.5):\n        return maruti.vision.image.adjust_brightness(img,1.5)\n\ndef get_batch(path):\n    frame_count, _ = mvis.vid_info(path)\n    frame_idx = np.linspace(0, frame_count-1, 8, dtype=int)\n    frame_list = list(mvis.get_face_frames(path, frame_idx))\n    for i in frame_list:\n        i = np.array(adjust_brightness(i))\n    return frame_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SPEED TEST\nspeed_test = False\nif speed_test:\n    start = time.perf_counter()\n    for vid in tqdm(test_videos[:10]):\n        print(predict(test_dir+vid))\n    print((time.perf_counter()-start)/10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.perf_counter()\npredictions = []\nfor i, vid in tqdm(enumerate(test_videos)):\n    if i%20==19:\n        os.system(f'echo {str(i)} {predictions[-1]:.2f}')\n    try:\n        pred = []\n        x = np.array(get_batch(test_dir+vid))\n        for i in x:\n            i = np.reshape(i,(1,224,224,3))\n        predictions.append(np.mean(np.array(model.predict(x))))\n    except Exception as e:\n        print(vid+' error:'+str(e))\n        predictions.append(0.5)\n\nprint((time.perf_counter()-start)/len(test_videos))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame({\"filename\": test_videos, \"label\": predictions})\nsubmission_df['label'] = np.clip(submission_df['label'],0.05,0.95)\nsubmission_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}