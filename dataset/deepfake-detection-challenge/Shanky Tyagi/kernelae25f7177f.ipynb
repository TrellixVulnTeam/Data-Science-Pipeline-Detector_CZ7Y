{"cells":[{"metadata":{"_uuid":"0639ea25-9093-4b2a-88c6-80709578e459","_cell_guid":"80e12364-b37e-4017-968c-a9a15ea83919","trusted":true},"cell_type":"code","source":"from PIL import Image\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.metrics import log_loss\nfrom PIL import Image, ImageDraw\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset, Subset\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimport matplotlib.pylab as plt\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/face-recognition/dlib-19.19.0.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/face-recognition/face_recognition_models-0.3.0.tar.gz\n!pip install /kaggle/input/face-recognition/face_recognition-1.3.0-py2.py3-none-any.whl\n!pip install /kaggle/input/face-recognition/face_recognition-1.3.0/dist/face_recognition-1.3.0.tar","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79da7c24-3883-4936-acfb-89e920554c0c","_cell_guid":"085770bd-404a-4913-be06-601d863b2df9","trusted":true},"cell_type":"code","source":"train_metadata = pd.read_json('../input/deepfake-detection-challenge/train_sample_videos/metadata.json').transpose()\ntrain_metadata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa61eb2e-4822-49e9-9d85-93daf28d4f16","_cell_guid":"a95562fa-9c9c-4422-b458-dcab6d05dbce","trusted":true},"cell_type":"code","source":"print(\"PyTorch version:\", torch.__version__)\nprint(\"CUDA version:\", torch.version.cuda)\nprint(\"cuDNN version:\", torch.backends.cudnn.version())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ngpu","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa998085-5473-4ded-b4a1-81f36f33a615","_cell_guid":"3ae5f351-7c8b-4012-b49e-f7916fb53c74","trusted":true},"cell_type":"code","source":"train_metadata.groupby('label')['label'].count().plot(figsize=(15, 5), kind='bar', title='Distribution of Labels in the Training Set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe170578-2a60-448f-918c-d0c3c125e76d","_cell_guid":"5474957b-af0b-4e0d-bfe5-d3e674c69c5f","trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'\nfig, ax = plt.subplots(1,1, figsize=(15, 15))\ntrain_video_files = [train_dir + x for x in os.listdir(train_dir)]\nvideo_file = train_video_files[30]\ncap = cv2.VideoCapture(video_file)\nsuccess, image = cap.read()\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ncap.release()   \nax.imshow(image)\nax.xaxis.set_visible(False)\nax.yaxis.set_visible(False)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import face_recognition\nface_recog = face_recognition.face_locations(image)\nfrom PIL import Image\nprint(\"I found{} face(s) in the photograph\".format(len(face_recog)))\n\nfor face_location in face_recog:\n    top, right, bottom, left =  face_location\n    print(\"face is located Top:{}, Left:{}, Bottom:{}, Right:{}\".format(top, left, bottom, right))\n    face_image = image[top:bottom, left:right]\n    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n    plt.grid(False)\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n    ax.imshow(face_image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b456854c-df01-4bd4-9071-581fd1d59c5c","_cell_guid":"cd50ec9e-0371-47ee-afec-a2e38295a509","trusted":true},"cell_type":"code","source":"face_list =  face_recognition.face_landmarks(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image, ImageDraw\npil_image = Image.fromarray(image)\np = ImageDraw.Draw(pil_image)\n\nfor face_marks in face_list:\n    for facial_data in face_marks.keys():\n        print(\"point{}\".format(facial_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for facial_data in face_marks.keys():\n    p.line(face_marks[facial_data], width=4)\n\ndisplay(pil_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(19, 2, figsize=(15, 80))\naxs = np.array(axs)\naxs = axs.reshape(-1)\ni = 0\nfor fn in train_metadata.index[:23]:\n    label = train_metadata.loc[fn]['label']\n    orig = train_metadata.loc[fn]['label']\n    video_file = f'/kaggle/input/deepfake-detection-challenge/train_sample_videos/{fn}'\n    ax = axs[i]\n    cap = cv2.VideoCapture(video_file)\n    success, image = cap.read()\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    face_locations = face_recognition.face_locations(image)\n    if len(face_locations) > 0:\n        # Print first face\n        face_location = face_locations[0]\n        top, right, bottom, left = face_location\n        face_image = image[top:bottom, left:right]\n        ax.imshow(face_image)\n        ax.grid(False)\n        ax.title.set_text(f'{fn} - {label}')\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n        # Find landmarks\n        face_landmarks_list = face_recognition.face_landmarks(face_image)\n        face_landmarks = face_landmarks_list[0]\n        pil_image = Image.fromarray(face_image)\n        d = ImageDraw.Draw(pil_image)\n        for facial_feature in face_landmarks.keys():\n            d.line(face_landmarks[facial_feature], width=2)\n        landmark_face_array = np.array(pil_image)\n        ax2 = axs[i+1]\n        ax2.imshow(landmark_face_array)\n        ax2.grid(False)\n        ax2.title.set_text(f'{fn} - {label}')\n        ax2.xaxis.set_visible(False)\n        ax2.yaxis.set_visible(False)\n        i += 2\nplt.grid(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv(\"/kaggle/input/deepfake-detection-challenge/sample_submission.csv\")\nsample_sub['label'] = 0.5\nsample_sub.loc[sample_sub['filename'] == 'aassnaulhq.mp4', 'label'] = 0 # Guess the true value\nsample_sub.loc[sample_sub['filename'] == 'aayfryxljh.mp4', 'label'] = 0\nsample_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05485e4d-7ed5-4a5a-ab50-a1813636ba3b","_cell_guid":"c0550e03-a41a-4598-befa-5fcae076c502","trusted":true},"cell_type":"code","source":"sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}