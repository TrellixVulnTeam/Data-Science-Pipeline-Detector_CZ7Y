{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a demonstration of how to capture frames from training videos and feed into the Pretrained Inception-V3 to extract 2048 dimensional feature vector. This is just the preprocessing step done on all the (77 (REAL) + 79 (FAKE)) training videos. The dataset undersampled.\n\n**Note**: Enable internet on kernel settings to download the weights for Inception-V3"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Importing the required libraries\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport pickle\nimport time\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.preprocessing import image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Version\n\nimport tensorflow as tf\nprint('Tensorflow version:', tf.__version__)\nprint('OpenCV version:', cv2.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing the paths\n\ninput_path = '/kaggle/input/deepfake-detection-challenge/'\ntrain_dir = glob.glob(input_path + 'train_sample_videos/*.mp4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the labels of training data\n\ndf_train = pd.read_json(input_path + 'train_sample_videos/metadata.json').transpose()\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the count of labels\n\n# Fake class is in majority\ndf_train.label.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Undersampling\n\ni = 0\nfor ind in df_train.index: \n    if(i > 243):\n        break\n    if(df_train['label'][ind] == 'FAKE'):\n        i += 1\n        train_dir.remove(input_path + 'train_sample_videos/' + ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking the base model as Inception V3 and initializing its weight with imagenet\n\n# Enable internet on kernel settings\ninput_tensor = Input(shape = (229, 229, 3))\ncnn_model = InceptionV3(input_tensor = input_tensor, weights = 'imagenet', include_top = False, pooling = 'avg')\ncnn_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of frames per video\n\nfpv = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating 40 frames per video, resizing it to (229, 229, 3) and feeding it to Pretrained Inception-V3 to extract features\n# Extracted features are stored in cnn_output\n\nt = time.time()\ncnn_output = {}\n# count1 = 0\nfor v in train_dir:\n    t1 = time.time()\n    folder_name = v.split('/')[5]\n    cap = cv2.VideoCapture(v)\n    count = 0\n    while count < fpv:\n        cap.set(cv2.CAP_PROP_POS_MSEC,((count * 30) + 5000))   \n        ret, frame = cap.read()\n        frame = cv2.resize(frame, (229, 229))\n        x = image.img_to_array(frame)\n        x = np.expand_dims(x, axis = 0)\n        x = preprocess_input(x)\n        result = cnn_model.predict(x)\n        if folder_name not in cnn_output.keys():\n            cnn_output[folder_name] = []\n        cnn_output[folder_name].append(list(result))\n        count = count + 1\n#     count1 += 1\n#     print('Elapsed: ', time.time() - t1, ' | ', count1, '/', len(train_dir), ' | ', v)\nprint('Total elapsed: ', time.time() - t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the cnn_output\n\nos.mknod('cnn_output.txt')\nwith open('cnn_output.txt', 'wb') as f:\n    pickle.dump(cnn_output, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# # Retrieving the cnn_output\n\n# with open('cnn_output.txt', 'rb') as f:\n#     cnn_output = pickle.load(f)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}