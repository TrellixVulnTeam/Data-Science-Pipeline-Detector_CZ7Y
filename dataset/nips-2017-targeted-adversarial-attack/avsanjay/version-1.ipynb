{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.1","nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}},"cells":[{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"34300a80-4923-4c1d-878d-33c186cb53b2","_uuid":"d02ec69d764d9c2cca8879ef1716d644ca3c4844"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport csv\nimport os\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.misc import imread\nfrom scipy.misc import imsave\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.nets import inception\n\nslim = tf.contrib.slim\n\nimport sys\nsys.path.insert(0, r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\")\n\nfrom cleverhans.attacks import FastGradientMethod\nfrom cleverhans.attacks import BasicIterativeMethod\n\ntensorflow_master = \"\"\ncheckpoint_path   = r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\input\\inception_v3.ckpt\"\ninput_dir         = r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\input\\images\"\noutput_dir        = r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\output\"\n\ntf.flags.DEFINE_string(\n    'master', '', 'The address of the TensorFlow master to use.')\n\ntf.flags.DEFINE_string(\n    'checkpoint_path', '', 'Path to checkpoint for inception network.')\n\ntf.flags.DEFINE_string(\n    'input_dir', '', 'Input directory with images.')\n\ntf.flags.DEFINE_string(\n    'output_dir', '', 'Output directory with images.')\n\ntf.flags.DEFINE_float(\n    'max_epsilon', 16.0, 'Maximum size of adversarial perturbation.')\n\ntf.flags.DEFINE_integer(\n    'image_width', 299, 'Width of each input images.')\n\ntf.flags.DEFINE_integer(\n    'image_height', 299, 'Height of each input images.')\n\ntf.flags.DEFINE_integer(\n    'batch_size', 16, 'How many images process at one time.')\n\nFLAGS = tf.flags.FLAGS\n\ndef load_target_class(input_dir):\n  \"\"\"Loads target classes.\"\"\"\n  with tf.gfile.Open(os.path.join(input_dir, 'target_class.csv')) as f:\n    return {row[0]: int(row[1]) for row in csv.reader(f) if len(row) >= 2}\n\n\ndef load_images(input_dir, batch_shape):\n  \"\"\"Read png images from input directory in batches.\n\n  Args:\n    input_dir: input directory\n    batch_shape: shape of minibatch array, i.e. [batch_size, height, width, 3]\n\n  Yields:\n    filenames: list file names without path of each image\n      Lenght of this list could be less than batch_size, in this case only\n      first few images of the result are elements of the minibatch.\n    images: array with all images from this batch\n  \"\"\"\n  #input_dir = r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_attacks\\fgsm\\input\"\n  images = np.zeros(batch_shape)\n  filenames = []\n  idx = 0\n  batch_size = batch_shape[0]\n  for filepath in tf.gfile.Glob(os.path.join(input_dir, '*.png')):\n    #with tf.gfile.Open(filepath) as f:\n      #image = np.array(Image.open(f).convert('RGB')).astype(np.float) / 255.0\n    # Images for inception classifier are normalized to be in [-1, 1] interval.\n    #images[idx, :, :, :] = image * 2.0 - 1.0\n    with tf.gfile.Open(filepath, \"rb\") as f:\n        images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float) * 2.0 / 255.0 - 1.0\n\n    filenames.append(os.path.basename(filepath))\n    idx += 1\n    if idx == batch_size:\n      yield filenames, images\n      filenames = []\n      images = np.zeros(batch_shape)\n      idx = 0\n  if idx > 0:\n    yield filenames, images\n\n\ndef save_images(images, filenames, output_dir):\n  \"\"\"Saves images to the output directory.\n\n  Args:\n    images: array with minibatch of images\n    filenames: list of filenames without path\n      If number of file names in this list less than number of images in\n      the minibatch then only first len(filenames) images will be saved.\n    output_dir: directory where to save images\n  \"\"\"\n  for i, filename in enumerate(filenames):\n    # Images for inception classifier are normalized to be in [-1, 1] interval,\n    # so rescale them back to [0, 1].\n    with tf.gfile.Open(os.path.join(output_dir, filename), 'w') as f:\n      imsave(f, (images[i, :, :, :] + 1.0) * 0.5, format='png')\n\nglobLogits = 0\nglobEnd_points = 0\n\nclass InceptionModel(object):\n  \"\"\"Model class for CleverHans library.\"\"\"\n\n  def __init__(self, num_classes):\n    self.num_classes = num_classes\n    self.built = False\n\n  def __call__(self, x_input):\n    \"\"\"Constructs model and return probabilities for given input.\"\"\"\n    reuse = True if self.built else None\n    with slim.arg_scope(inception.inception_v3_arg_scope()):\n     logits, end_points = inception.inception_v3(\n          x_input, num_classes=self.num_classes, is_training=False,\n          reuse=reuse)\n    global globLogits\n    global globEnd_points\n\n    #globLogits = logits\n    #globEnd_points = end_points\n    self.built = True\n    output = end_points['Predictions']\n    # Strip off the extra reshape op at the output\n    probs = output.op.inputs[0]\n    return  probs\n\n\n\n\neps = 2.0 * FLAGS.max_epsilon / 255.0\nbatch_shape = [FLAGS.batch_size, FLAGS.image_height, FLAGS.image_width, 3]\nnum_classes = 1001\n\ncategories = pd.read_csv(r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\input\\categories.csv\")\nimage_classes = pd.read_csv(r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\input\\images.csv\")\n\n\n\nall_images_target_class = {image_classes[\"ImageId\"][i] + \".png\": image_classes[\"TargetClass\"][i]\n                           for i in image_classes.index}\n\noutput = pd.DataFrame.from_dict(all_images_target_class, orient = 'index')\noutput.to_csv(r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\input\\target_class.csv\")\n#pd.DataFrame(all_images_target_class).T.reset_index().to_csv('target_class.csv',header = False, index = True)\n# output = pd.DataFrame({'ID': test['ID'].astype(np.int32), 'y': y_pred})\n# output.to_csv('best_pred.csv')\n\n\nimage_metadata = pd.DataFrame()\n\nfor filenames, images in load_images(input_dir, batch_shape):\n    image_metadata1 = pd.DataFrame({\"ImageId\": [f[:-4] for f in filenames]}).merge(image_classes,\n                                                                                   on=\"ImageId\")\n    frames = [image_metadata, image_metadata1]\n    image_metadata = pd.concat(frames)\n\n    #image_metadata = image_metadata1.append(image_metadata)\n\n\n\ntrue_classes = image_metadata[\"TrueLabel\"].tolist()\ntarget_classes = true_labels = image_metadata[\"TargetClass\"].tolist()\ntrue_classes_names = (pd.DataFrame({\"CategoryId\": true_classes})\n                        .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\ntarget_classes_names = (pd.DataFrame({\"CategoryId\": target_classes})\n                          .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n\n#all_images_target_class = {image_metadata[\"ImageId\"][i] + \".png\": image_metadata[\"TargetClass\"][i]\n                           #for i in image_metadata.index}\nall_images_target_class = {image_classes[\"ImageId\"][i] + \".png\": image_classes[\"TargetClass\"][i]\n                           for i in image_classes.index}\n\n#all_images_target_class.to_csv('target_class.csv')\n\nimage_metadata2 = image_metadata\nimage_metadata2['PredictedClass'] = 0\n\n#image_metadata2 = image_metadata2.reset_index(drop=True)\n#image_metadata2 = image_metadata2.reset_index(drop=True)\n\nimage_metadata2.index = range(len(image_metadata2.index))\n\n#duplicated3 = image_metadata.duplicated('index')\n#duplicated = image_metadata[image_metadata.duplicated(['index'],keep = False)]\n#duplicated2 = image_metadata2[image_metadat2.index.duplicated()]\n\nwith tf.Graph().as_default():\n    # Prepare graph\n    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n\n    #model = InceptionModel(num_classes)\n\n    target_class_input = tf.placeholder(tf.int32, shape=[FLAGS.batch_size])\n    one_hot_target_class = tf.one_hot(target_class_input, num_classes)\n\n    #fgsm = FastGradientMethod(model)\n    #x_adv = fgsm.generate(x_input, y_target=one_hot_target_class, eps=eps, clip_min=-1., clip_max=1.)\n\n    #basicIterative = BasicIterativeMethod(model)\n    #x_adv = basicIterative.generate(x_input, y_target=one_hot_target_class, eps=eps, clip_min=-1., clip_max=1.)\n\n    with slim.arg_scope(inception.inception_v3_arg_scope()):\n        logits, end_points = inception.inception_v3(\n            x_input, num_classes=num_classes, is_training=False)\n\n    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n\n    #logits =globLogits\n    #end_points = globEnd_points\n\n    #model = returnValue['y0']\n    #logits = returnValue['y1']\n    #end_points = returnValue['y2']\n\n\n\n    #fgsm = FastGradientMethod(model)\n    #x_adv1 = fgsm.generate(x_input,y_target= one_hot_target_class, eps=eps, clip_min=-1., clip_max=1.)\n\n\n\n    #basicIterative = BasicIterativeMethod(model)\n    #x_adv2 = basicIterative.generate(x_input,y_target= one_hot_target_class, eps=eps, clip_min=-1., clip_max=1.)\n\n\n\n    #output = end_points['Predictions']\n    # Strip off the extra reshape op at the output\n    #probs = output.op.inputs[0]\n\n    #model = probs\n\n    #output = end_points['Predictions']\n    #Strip off the extra reshape op at the output\n    #probs = output.op.inputs[0]\n    #fgsm = FastGradientMethod(probs)\n    #x_adv = fgsm.generate(x_input, eps=eps, clip_min=-1., clip_max=1.)\n\n\n    #target_class_input = tf.placeholder(tf.int32, shape=[FLAGS.batch_size])\n    #one_hot_target_class = tf.one_hot(target_class_input, num_classes)\n    # cross_entropy will be a vector of size 16. One value for one input image. There are 16 input images in a batch\n    # https://stackoverflow.com/questions/34240703/difference-between-tensorflow-tf-nn-softmax-and-tf-nn-softmax-cross-entropy-with\n    cross_entropy = tf.losses.softmax_cross_entropy(one_hot_target_class,\n                                                    logits,\n                                                    label_smoothing=0.1,\n                                                    weights=1.0)\n    # one_hot_target_class is of the type [16,1001]. In each row only one column belonging to the image has 1. The rest has zero\n    # logits is the output of the classifier. It is also of the type [16,1001]\n    # Each row contains the probability that this image belongs to one of the 1001 class\n    # The contents of each row, as they are probabilities adds up to 1.\n    cross_entropy += tf.losses.softmax_cross_entropy(one_hot_target_class,\n                                                     end_points['AuxLogits'],\n                                                     label_smoothing=0.1,\n                                                     weights=0.4)\n\n    #cross_entropy += tf.losses.softmax_cross_entropy(one_hot_target_class,\n    #                                                 end_points['Predictions'],\n    #                                                 label_smoothing=0.1,\n    #                                                 weights=0.4)\n\n    #end_points['auxlogits] is another output similiar to logits. It is similiar to logits\n    # other intermediery outputs are also available. May be we can use that.\n    # https://stackoverflow.com/questions/35226428/how-do-i-get-the-gradient-of-the-loss-at-a-tensorflow-variable\n    x_adv = x_input - eps * tf.sign(tf.gradients(cross_entropy, x_input)[0])\n    #y = x_adv5.assert_equal_None\n    #x_adv6 = x_adv2 - eps * tf.sign(tf.gradients(cross_entropy, x_adv5)[0])\n    #x_adv = x_adv1 - eps * tf.sign(tf.gradients(cross_entropy, x_adv6)[0])\n\n\n\n\n    # x_input is of the shape [16,299,299,3]\n    # the 16 belongs to the 16 images in the batch\n    # Each image has 299 rows. Each row has 299 columns. Each column has a value like [4,4,6]\n    # each value is [R,G,B] vector\n    # cross_entropy will be of the type [16] i.e one value for the 16 images\n    # tf.gradients will take  the x_input value which is of type 299,299, 3\n    # and divide each of the 3 values contained in row, column by the cross entropy value\n    # if row 1 is like this [ [16,16,16], [ 8, 4, 2] , [ 2, 4, 6].......\n    # if the corss entropy value for row 1 is 2\n    # tf.gradient will return some thing like this\n    # [ [ 8,8,8], [4,2,1] [ 1, 2, 3]......\n\n    x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n\n    # clip_by_value  clips these triplet value between  -1 to 1.\n\n    saver = tf.train.Saver(slim.get_model_variables())\n    session_creator = tf.train.ChiefSessionCreator(\n        scaffold=tf.train.Scaffold(saver=saver),\n        checkpoint_filename_with_path=FLAGS.checkpoint_path,\n        master=FLAGS.master)\n\n    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n      for filenames, images in load_images(input_dir, batch_shape):\n        print(\"looping thru.... i should have multiple of this printouts\")\n        target_class_for_batch = (\n            [all_images_target_class[n] for n in filenames]\n            + [0] * (FLAGS.batch_size - len(filenames)))\n\n        #target_class_for_batch2 = [all_images_target_class[n] for n in filenames]\n        #target_class_for_batch3 = [all_images_target_class[n] for n in filenames] + ([1] * ((FLAGS.batch_size - len(filenames) +1)))\n        #experiment = [1] * ((FLAGS.batch_size - len(filenames) +1))\n        #subValue = FLAGS.batch_size - len(filenames)\n        #for n in filenames:\n            #target_class_temp = all_images_target_class[n]\n\n\n        # both x_input and target_class_input are place holders\n        # both are nodes in the graphs. Final or intermediatory\n        targeted_images = sess.run(x_adv,\n                              feed_dict={\n                                  x_input: images,\n                                  target_class_input: target_class_for_batch})\n\n        #predicted_targeted_classes = sess.run(predicted_labels, feed_dict={x_input: targeted_images})\n        #debugpoint = end_points['Predictions']\n        #predicted_labels = tf.argmax(end_points['Predictions'])\n\n\n        save_images(targeted_images, filenames, output_dir)\n\n        predicted_targeted_classes = sess.run(predicted_labels, feed_dict={x_input: targeted_images})\n\n        predicted_targeted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_targeted_classes})\n                                            .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n        i = 0\n        j = 0\n\n  #      for j in range(len(predicted_targeted_classes)):\n  #          temp = predicted_targeted_classes[j]\n\n        #j = 0\n\n        #image_metadata2 = image_metadata\n        #image_metadata2['PredictedClass'] = 0\n\n\n        print(\" just before the for loop..... again i should have multiple of these print outs\")\n        for n in filenames:\n            newfilename = n.split(\".\")[0]\n            print(newfilename)\n            for index, row in image_metadata.iterrows():\n                if row['ImageId'] == newfilename:\n                   #roww['PredictedClass'] = predicted_targeted_classes[j]\n                   print(\"i am in the inner if loop\")\n                   print(\"index value is\")\n                   print(index)\n                   image_metadata2.set_value(index,'PredictedClass',predicted_targeted_classes[j] )\n                   break\n\n\n  #      for n in filenames:\n  #          newfilename = n.split(\".\")[0]\n  #          for i in range(len(image_metadata2)):\n  #              if image_metadata2.iloc[i]['ImageId'] == newfilename:\n  #                  image_metadata2.set_value(i,'PredictedClass',predicted_targeted_classes[j] )\n                    #image_metadata2.at[i,'PredictedClass'] = predicted_targeted_classes[j]\n                    #image_metadata2[i]['PredictedClass'] = predicted_targeted_classes[j]\n  #                  j = j+ 1\n  #                  break\n\n    k = 0\n    image_metadata2.to_csv(\n            r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\input\\final_results.csv\")\n\n    all_images_target_class2 = {image_metadata2[\"ImageId\"][i] + \".png\": image_metadata2[\"PredictedClass\"][i]\n                               for i in image_metadata2.index}\n\n    output2 = pd.DataFrame.from_dict(all_images_target_class2, orient='index')\n    output2.to_csv(\n        r\"C:\\Users\\avsanjay\\PycharmProjects\\kaggle\\cleverhans-master\\cleverhans-master\\examples\\nips17_adversarial_competition\\sample_targeted_attacks\\step_target_class\\input\\target_class2.csv\")\n            #if image_metadata.iloc[:,[\"ImageId\"]] == newfilename:\n                #image_metadata.iloc[[\"ImageId\"== newfilename],[\"predicted_target\"]] = predicted_targeted_classes[i]\n                #i = i+1\n\n        # all_images_target_class = {image_metadata[\"ImageId\"][i] + \".png\": image_metadata[\"TargetClass\"][i]\n        # for i in image_metadata.index}\n        #with tf.Graph().as_default():\n        #    x_input1 = tf.placeholder(tf.float32, shape=batch_shape)\n\n        #    with slim.arg_scope(inception.inception_v3_arg_scope()):\n        #        _, end_points = inception.inception_v3(x_input1, num_classes=num_classes, is_training=False)\n\n            #predicted_labels = tf.argmax(end_points['Predictions'], 1)\n\n        #    predicted_targeted_classes = sess.run(predicted_labels, feed_dict={x_input: targeted_images})\n\n            #saver = tf.train.Saver(slim.get_model_variables())\n            #session_creator = tf.train.ChiefSessionCreator(\n            #    scaffold=tf.train.Scaffold(saver=saver),\n            #    checkpoint_filename_with_path=checkpoint_path,\n            #    master=tensorflow_master)\n\n            #with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n        #predicted_targeted_classes = sess.run(predicted_labels, feed_dict={x_input: targeted_images})\n\n            #predicted_targeted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_targeted_classes})\n","cell_type":"code","outputs":[]}],"nbformat_minor":1,"nbformat":4}