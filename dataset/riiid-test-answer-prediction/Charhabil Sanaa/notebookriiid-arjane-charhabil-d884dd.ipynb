{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/riiid-test-answer-prediction'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import riiideducation\n\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, learning_curve\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nimport eli5\n\n\n\n%matplotlib inline\n# for heatmap and other plots\ncolorMap1 = sns.color_palette(\"RdBu_r\")\n# for countplot and others plots\ncolorMap2 = 'Blues_r'\n\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"/kaggle/input/riiid-test-answer-prediction/train.csv\"\nquestions_path = \"../input/riiid-test-answer-prediction/questions.csv\"\nlectures_path = \"../input/riiid-test-answer-prediction/lectures.csv\"\ntest = \"../input/riiid-test-answer-prediction/example_test.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DATA EXPLORATION & EDA**"},{"metadata":{},"cell_type":"markdown","source":"We used the 5% of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain = pd.read_csv(train_path, low_memory=False,  nrows=10123033,\n                       dtype={'row_id': 'int64', 'timestamp': 'int64', 'user_id': 'int32', 'content_id': 'int16', 'content_type_id': 'int8',\n                              'task_container_id': 'int16', 'user_answer': 'int8', 'answered_correctly': 'int8', 'prior_question_elapsed_time': 'float32', \n                             'prior_question_had_explanation': 'boolean',\n                             }\n                      )\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train shape: {train.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.memory_usage()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.hist(train['answered_correctly'], bins=100)\nplt.xlabel('answered_correctly')\nplt.ylabel('Fréquence')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.hist(train['user_answer'], bins=100)\nplt.xlabel('user_answer')\nplt.ylabel('Fréquence')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_plot = (train['answered_correctly'].groupby(train['user_answer']))\nsns.barplot(x='answered_correctly', y='user_answer', data=train)\nplt.title('answered_correctly for user_answer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()*100/train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\npercent = (train.isnull().sum()*100/train.shape[0]).sort_values(ascending=False)\npercent.plot(kind=\"bar\", figsize = (20,10), fontsize = 20)\nplt.xlabel(\"Columns\", fontsize = 20)\nplt.ylabel(\"Value Percent(%)\", fontsize = 20)\nplt.title(\"Total Missing Value \", fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tester les methodes de traitement des valeurs nulles:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#La suppression:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remplacement par une valeur factice :","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['prior_question_elapsed_time'].fillna(0,inplace=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.memory_usage()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Les variables catégoriques--> Aucune\ntrain.dtypes==object","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['row_id', 'timestamp'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['answered_correctly'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['answered_correctly']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['answered_correctly'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features engineering"},{"metadata":{},"cell_type":"markdown","source":"\nDans l'approche Features Engineering , on essaye de garder les caractéristiques les plus pertinents et les plus utils dans notre étude , pour cela on va dans un premier moment , on va faire une étude de corrélation pour les données séparés , puis on va ajouter d'autres colomne et fonctionalites qu'on trouve assez pertinentes puis on va appliquer des modèles afin de savoir l'importance des Caractéristiques ."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_with_target = train.corr()['answered_correctly'].sort_values(ascending=False)\nplt.figure(figsize=(14,7))\ncorr_with_target.drop('answered_correctly').plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature = ['answered_correctly','user_id', 'content_id', 'task_container_id',\n       'user_answer', 'prior_question_elapsed_time','prior_question_had_explanation']\ndf = train[feature]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_with_target = df.corr()[\"answered_correctly\"].sort_values(ascending=False)\nplt.figure(figsize=(14,7))\ncorr_with_target.drop(\"answered_correctly\").plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,20))\nsns.set(font_scale=1)\nsns.heatmap(df.corr(),annot=True,cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_matrix  = train.corr()\ncorrelation_matrix[\"answered_correctly\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features"},{"metadata":{},"cell_type":"markdown","source":"I'll give just some part from our data bacause of the RAM limit on Kaggle kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = int(train.shape[0] * 1)\ntrain_n = train.sample(n=n, random_state=42)\nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_characteristics = train.groupby('user_id').agg({'answered_correctly':\n                                                  ['mean', 'median', 'std', 'skew', 'count']})\nuser_characteristics.columns = [\n    'mean_user_acc',\n    'median_user_acc',\n    'std_user_acc',\n    'skew_user_acc',\n    'number_of_answered_q'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_characteristics.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_container_characteristics = train.groupby('task_container_id').agg({'answered_correctly':\n                                                                      ['mean', 'median', 'std', 'skew', 'count']})\ntask_container_characteristics.columns = [\n    'mean_task_acc',\n    'median_task_acc',\n    'std_task_acc',\n    'skew_task_acc',\n    'number_of_asked_task_containers'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_container_characteristics.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_characteristics = train.groupby('content_id').agg({'answered_correctly':\n                                                        ['mean', 'median', 'std', 'skew', 'count']})\ncontent_characteristics.columns = [\n    'mean_acc',\n    'median_acc',\n    'std_acc',\n    'skew_acc',\n    'number_of_asked_q'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_characteristics.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_n.copy()\ndel train_n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(user_characteristics, how='left', on='user_id')\ntrain = train.merge(task_container_characteristics, how='left', on='task_container_id')\ntrain = train.merge(content_characteristics, how='left', on='content_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The target: answered_correctly"},{"metadata":{},"cell_type":"markdown","source":"Answered_correctly is our target, and we have to predict to probability for an answer to be correct. "},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\n    'prior_question_elapsed_time', \n    'prior_question_had_explanation',\n    'mean_user_acc',\n    'median_user_acc',\n    'std_user_acc',\n    'skew_user_acc',\n    'number_of_answered_q',\n    'mean_task_acc',\n    'median_task_acc',\n    'std_task_acc',\n    'skew_task_acc',\n    'number_of_asked_task_containers',\n    'mean_acc',\n    'median_acc',\n    'std_acc',\n    'skew_acc',\n    'number_of_asked_q'\n]\n\ntarget = 'answered_correctly'\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop features that we are not going to use in our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_to_drop = set(train.columns.values.tolist()).difference(features + [target])\nfor col in col_to_drop:\n    del train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['prior_question_had_explanation'] = train['prior_question_had_explanation'].fillna(value=False).astype(bool)\ntrain = train.fillna(value=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.replace([np.inf, -np.inf], np.nan)\ntrain = train.fillna(0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df, y_train, y_test = train_test_split(train[features], train[target], random_state=777, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. **LGBMClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf = LGBMClassifier(random_state=777)\n\n#params = {\n#   'n_estimators': [50, 150, 300],'max_depth': [3, 5, 10],'num_leaves': [5, 15, 30],'min_data_in_leaf': [5, 50, 100],\n#    'feature_fraction': [0.1, 0.5, 1.],'lambda': [0., 0.5, 1.],\n#}\n#cv = RandomizedSearchCV(clf, param_distributions=params, cv=5, n_iter=50, verbose=2)\n#cv.fit(train_df, y_train)\n\n#print(cv.best_params_)\n#print(cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'num_leaves': 30, \n    'n_estimators': 300, \n    'min_data_in_leaf': 100, \n    'max_depth': 5, \n    'lambda': 0.0, \n    'feature_fraction': 1.0\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier(**params)\nmodel.fit(train_df, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LGB ROC-AUC score: ', roc_auc_score(y_test.values, model.predict_proba(test_df)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(model, top=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. **LogisticRegression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.fit(train_df, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting the test set results and calculating the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(test_df)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(test_df, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The result is telling us that we have 208239+1844304 correct predictions and 804476+108660  incorrect predictions.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Grid Search\nfrom sklearn.model_selection import GridSearchCV\nclf = LogisticRegression()\ngrid_values = {'penalty': ['l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\ngrid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall')\ngrid_clf_acc.fit(train_df, y_train)\n\n#Predict values based on new parameters\ny_pred_acc = grid_clf_acc.predict(test_df)\n\n# New Model Evaluation metrics \nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))\n\n#Logistic Regression (Grid Search) Confusion matrix\nconfusion_matrix(y_test,y_pred_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **The support is the number of occurrences of each class in y_test.**\n\nROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(test_df))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(test_df)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner)."},{"metadata":{},"cell_type":"markdown","source":"3. **RandomForestClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(train_df, y_train)\nclf_pred = clf.predict(test_df)\nprint('Accuracy of Random Forest Classifier on test set: {:.2f}'.format(clf.score(test_df, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [100, 300, 500, 800, 1200]\nmax_depth = [5, 8, 15, 25, 30]\nmin_samples_split = [2, 5, 10, 15, 100]\nmin_samples_leaf = [1, 2, 5, 10] \n\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf)\n\ngridF = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, n_jobs = -1)\nbestF = gridF.fit(train_df, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forestOpt = RandomForestClassifier(random_state = 1, max_depth = 15,     \n                                   n_estimators = 500, min_samples_split = 2, min_samples_leaf = 1)\n                                   \nmodelOpt = forestOpt.fit(train_df, y_train)\ny_pred = modelOpt.predict(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_roc_auc = roc_auc_score(y_test, clf.predict(test_df))\nfpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(test_df)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Random Forest Classifier(area = %0.2f)' % clf_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('clf_ROC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* gridsearch pour les parametres. essayer la summission"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nclf1 = LogisticRegression(max_iter=1000, random_state=123)\nclf2 = RandomForestClassifier(n_estimators=100, random_state=123)\nclf3 = GaussianNB()\nX = np.array([[-1.0, -1.0], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\ny = np.array([1, 1, 2, 2])\n\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n                        voting='soft',\n                        weights=[1, 1, 5])\n\n# predict class probabilities for all classifiers\nprobas = [c.fit(X, y).predict_proba(X) for c in (clf1, clf2, clf3, eclf)]\n\n# get class probabilities for the first sample in the dataset\nclass1_1 = [pr[0, 0] for pr in probas]\nclass2_1 = [pr[0, 1] for pr in probas]\n\n\n# plotting\n\nN = 4  # number of groups\nind = np.arange(N)  # group positions\nwidth = 0.35  # bar width\n\nfig, ax = plt.subplots()\n\n# bars for classifier 1-3\np1 = ax.bar(ind, np.hstack(([class1_1[:-1], [0]])), width,\n            color='green', edgecolor='k')\np2 = ax.bar(ind + width, np.hstack(([class2_1[:-1], [0]])), width,\n            color='lightgreen', edgecolor='k')\n\n# bars for VotingClassifier\np3 = ax.bar(ind, [0, 0, 0, class1_1[-1]], width,\n            color='blue', edgecolor='k')\np4 = ax.bar(ind + width, [0, 0, 0, class2_1[-1]], width,\n            color='steelblue', edgecolor='k')\n\n# plot annotations\nplt.axvline(2.8, color='k', linestyle='dashed')\nax.set_xticks(ind + width)\nax.set_xticklabels(['LogisticRegression\\nweight 1',\n                    'GaussianNB\\nweight 1',\n                    'RandomForestClassifier\\nweight 5',\n                    'VotingClassifier\\n(average probabilities)'],\n                   rotation=40,\n                   ha='right')\nplt.ylim([0, 1])\nplt.title('Class probabilities for sample 1 by different classifiers')\nplt.legend([p1[0], p2[0]], ['class 1', 'class 2'], loc='upper left')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leaderboard  = pd.DataFrame({'Accuracy':[2.80,1.41, 1.78]},index = ['Logistic Regression',\n                                                                    'Random Forest', 'LGBMClassifier'])\nfig_dims = (15, 8)\n\nfig, a = plt.subplots(figsize=fig_dims)\nax = sns.barplot(x=\"Accuracy\", y=leaderboard.index, data=leaderboard,ax=a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SUBMISSION "},{"metadata":{"trusted":true},"cell_type":"code","source":"env = riiideducation.make_env()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    # merge\n    test_df = test_df.merge(user_characteristics, on = \"user_id\", how = \"left\")\n    test_df = test_df.merge(task_container_characteristics, on = \"task_container_id\", how = \"left\")\n    test_df = test_df.merge(content_characteristics, on = \"content_id\", how = \"left\")\n    \n    # type transformation\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(value=False).astype(bool)\n    test_df.fillna(value = 0.5, inplace = True)\n    test_df = test_df.replace([np.inf, -np.inf], np.nan)\n    test_df = test_df.fillna(0.5)\n    \n    # preds\n    test_df['answered_correctly'] = model.predict_proba(test_df[features])[:, 1]\n    cols_to_submission = ['row_id', 'answered_correctly', 'group_num']\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}