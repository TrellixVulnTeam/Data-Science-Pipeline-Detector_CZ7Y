{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\n#显示所有行\npd.set_option('display.max_rows', None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv',\n                   usecols=[ 2, 3, 4, 7],\n                   dtype={\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',                          \n                          'answered_correctly':'int8',\n                          }\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lectures = pd.read_csv('../input/get-train-file/lectures.csv')\n# lectures['content_type_id'] = 1\n# lectures = lectures.rename(columns={'lecture_id':'content_id','tag':'lecture_tag','part':'lecture_part'})\n# lectures['type_of'] = lectures['type_of'].replace('solving question', 'solving_question')\n\n# lecture_tag_count =  lectures['lecture_tag'].value_counts().to_dict()\n# lectures['lecture_tag'] = lectures['lecture_tag'].map(lecture_tag_count)\n\n# # lectures['lecture_tag'] = lectures['lecture_tag'].apply(lambda x : 6 if ((x==7)|(x==5)) else x)\n\n# lectures = pd.get_dummies(lectures, columns=['lecture_part','lecture_tag','type_of'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lectures_column = lectures.columns.to_list()\nlectures_column.remove('content_id')\nlectures_column.remove('content_type_id')\n#获取lecture列名","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_list = list(train['user_id'].unique())#获取所有用户名","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list(train['user_id'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_info = pd.DataFrame(columns = ['user_id', 'lecture_part_1', 'lecture_part_2', 'lecture_part_3',\n       'lecture_part_4', 'lecture_part_5', 'lecture_part_6', 'lecture_part_7',\n       'lecture_tag_1', 'lecture_tag_2', 'lecture_tag_3', 'lecture_tag_4','lecture_tag_5',\n       'lecture_tag_6','lecture_tag_7', 'type_of_concept', 'type_of_intention',\n       'type_of_solving_question', 'type_of_starter', 'answered_cumsum',\n       'answered_count'])\n\n\ni=0\nwhile True:\n    user = user_list[i:i+50000]\n    if len(user)==0:\n        break\n    temp = train[train['user_id'].isin(user)]    \n    temp = pd.merge(temp,lectures, on = ['content_id','content_type_id'], how='left')\n    temp[lectures_column] = temp[lectures_column].fillna(0)\n    temp_group = temp.groupby(['user_id'])[lectures_column].agg('sum').reset_index()\n    \n    temp = temp[temp['content_type_id'] == 0].reset_index(drop=True)\n    temp_group_count = temp[['user_id','answered_correctly']].groupby(['user_id']).agg(['sum','count']).reset_index(drop=True)\n    temp_group_count.columns=['answered_cumsum','answered_count']\n\n    temp_group[['answered_cumsum','answered_count']] = temp_group_count\n    \n    user_info = pd.concat([user_info,temp_group],axis = 0).reset_index(drop = True)\n    i=i+50000\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_info_columns = list(user_info.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_info_columns.remove('user_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in user_info_columns:\n    user_info[i] = user_info[i].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_info['user_correctly_rate'] = user_info['answered_cumsum']/user_info['answered_count']\nuser_info['user_correctly_rate'] = user_info['user_correctly_rate'].mask((user_info['answered_count'] < 5), .65)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_info.to_csv('user_info.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_info.head(100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}