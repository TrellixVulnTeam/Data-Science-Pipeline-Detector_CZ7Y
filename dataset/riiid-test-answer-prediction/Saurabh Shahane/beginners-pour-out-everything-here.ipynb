{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Pour out everything\n### If you are new to machine learning and if you don't know which algorithm to use then this notebook is for you!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"full_train = pd.read_csv(\"/kaggle/input/riiid-test-answer-prediction/train.csv\",nrows=20000)\nquestions = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv')\nlectures = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/lectures.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fmean = full_train.mean()\nfull_train = full_train.fillna(fmean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n       'task_container_id', 'user_answer',\n       'prior_question_elapsed_time']\ntarget = ['answered_correctly']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = full_train[features]\ny = full_train[target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Best way to do machine learning modelling if you don't know which one to use specifically is to pour out all the models into the loop and then analyze"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''code taken from https://www.kaggle.com/nilanml/telecom-customer-churn-voting-80-1-accuracy'''\n\nclassifiers = [['Neural Network :', MLPClassifier()],\n               ['LogisticRegression :', LogisticRegression()],\n               ['ExtraTreesClassifier :', ExtraTreesClassifier()],\n               ['DecisionTree :',DecisionTreeClassifier()],\n               ['RandomForest :',RandomForestClassifier()], \n               ['Naive Bayes :', GaussianNB()],\n               ['KNeighbours :', KNeighborsClassifier()],\n               ['SVM :', SVC()],\n               ['AdaBoostClassifier :', AdaBoostClassifier()],\n               ['GradientBoostingClassifier: ', GradientBoostingClassifier()],\n               ['XGB :', XGBClassifier()],\n               ['CatBoost :', CatBoostClassifier(logging_level='Silent')]]\n\npredictions_df = pd.DataFrame()\npredictions_df['answered_correctly'] = y_test['answered_correctly'].values\n\nfor name,classifier in classifiers:\n    classifier = classifier\n    classifier.fit(X_train, y_train.values.ravel())\n    predictions = classifier.predict(X_test)\n    predictions_df[name.strip(\" :\")] = predictions\n    print(name, accuracy_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Just see which model gives the best score and then try to improve that model by hyperparameter optimization."},{"metadata":{},"cell_type":"markdown","source":"### If there are two three models which gives you nearly same score then consider those models as well "},{"metadata":{},"cell_type":"markdown","source":"### You can use the evaluation metric according to your need"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}