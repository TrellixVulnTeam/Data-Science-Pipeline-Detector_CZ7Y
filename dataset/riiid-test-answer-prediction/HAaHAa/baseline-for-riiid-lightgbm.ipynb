{"cells":[{"metadata":{},"cell_type":"markdown","source":"V3 base gbdt\n\nV4 base lightgbm"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use first 10**5 rows of train dataset for data exploring. Using more efficient datatypes as shown in introduction notebook."},{"metadata":{},"cell_type":"markdown","source":"Exploring questions stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv',\n                         usecols=['row_id', 'user_id', 'answered_correctly', 'content_id', 'prior_question_had_explanation', 'prior_question_elapsed_time'],\n                         dtype={'row_id': 'int64',  'user_id': 'int32', 'content_id': 'int16', 'answered_correctly': 'int8', 'prior_question_had_explanation': 'boolean', 'prior_question_elapsed_time':'float32'}\n                         )\n\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_df_inf = train_df[train_df.answered_correctly != -1].groupby('user_id').agg({'answered_correctly': ['mean', 'median', 'std', 'skew', 'count']}).reset_index()\nuser_df_inf.columns = ['user_id',\n                   'mean_user_acc',\n    'median_user_acc',\n    'std_user_acc',\n    'skew_user_acc',\n    'number_of_answered_q']\nuser_df_inf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_df = train_df[train_df.answered_correctly != -1].groupby('content_id').agg({'answered_correctly': ['count', 'mean']}).reset_index()\ncontent_df.columns = ['content_id', 'content_questions', 'content_mean']\ncontent_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_lect = train_df.groupby([\"user_id\", \"answered_correctly\"]).size().unstack()\nuser_lect.columns = ['lecture', 'wrong', 'right']\nuser_lect['lecture'] = user_lect['lecture'].fillna(0)\nuser_lect = user_lect.astype('Int64')\nuser_lect['watches_lecture'] = np.where(user_lect.lecture > 0, 1, 0)\nuser_lect = user_lect.reset_index()\nuser_lect = user_lect[['user_id', 'watches_lecture']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_lect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_df = user_df_inf.merge(user_lect, on = \"user_id\", how = \"left\")\ndel user_lect,train_df,user_df_inf\nuser_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_pickle(\"../input/riidcv/cv1_train.pickle\")\nvalidation_df = pd.read_pickle(\"../input/riidcv/cv1_valid.pickle\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nlabel_enc = LabelEncoder()\nmean_prior = train_df.prior_question_elapsed_time.astype(\"float64\").mean()\ntrain_df= train_df.merge(user_df, on = \"user_id\", how = \"left\")\ntrain_df = train_df.merge(content_df, on = \"content_id\", how = \"left\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['content_questions'].fillna(0, inplace = True)\ntrain_df['content_mean'].fillna(0.5, inplace = True)\ntrain_df['watches_lecture'].fillna(0, inplace = True)\ntrain_df['number_of_answered_q'].fillna(0, inplace = True)\ntrain_df['mean_user_acc'].fillna(0.5, inplace = True)\ntrain_df['prior_question_elapsed_time'].fillna(mean_prior, inplace = True)\ntrain_df['prior_question_had_explanation'].fillna(False, inplace = True)\ntrain_df['prior_question_had_explanation'] = label_enc.fit_transform(train_df['prior_question_had_explanation'])\ntrain_df[['content_questions', 'number_of_answered_q']] = train_df[['content_questions', 'number_of_answered_q']].astype(int)\ntrain_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_df = validation_df.merge(user_df, on = \"user_id\", how = \"left\")\nvalidation_df = validation_df.merge(content_df, on = \"content_id\", how = \"left\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_df['content_questions'].fillna(0, inplace = True)\nvalidation_df['content_mean'].fillna(0.5, inplace = True)\nvalidation_df['watches_lecture'].fillna(0, inplace = True)\nvalidation_df['number_of_answered_q'].fillna(0, inplace = True)\nvalidation_df['mean_user_acc'].fillna(0.5, inplace = True)\nvalidation_df['prior_question_had_explanation'].fillna(False, inplace = True)\nvalidation_df['prior_question_elapsed_time'].fillna(mean_prior, inplace = True)\nvalidation_df['prior_question_had_explanation'] = label_enc.fit_transform(validation_df['prior_question_had_explanation'])\nvalidation_df[['content_questions', 'number_of_answered_q']] = validation_df[['content_questions', 'number_of_answered_q']].astype(int)\nvalidation_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['number_of_answered_q', 'content_questions', 'content_mean', \n            'prior_question_had_explanation', 'prior_question_elapsed_time', 'watches_lecture','mean_user_acc','std_user_acc','skew_user_acc','number_of_answered_q']\n\n\ntrain = train_df\n\ny_train = train['answered_correctly']\ntrain = train[features]\n\ny_val = validation_df['answered_correctly']\nvalidation = validation_df[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(train, y_train)\nlgb_eval = lgb.Dataset(validation, y_val)\ndel train, y_train, validation, y_val\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params = {'objective': 'binary',\n#           'metric': 'auc',\n#           'seed': 42,\n#           'learning_rate': 0.1, \n#           \"boosting_type\": \"gbdt\",\n#          }\n# model = lgb.train(\n#     params, lgb_train,\n#     valid_sets=[lgb_train, lgb_eval],\n#     verbose_eval=1,\n#     num_boost_round=10000,\n#     early_stopping_rounds=8\n# )\nmodel = lgb.train(\n                    {'objective': 'binary',#,#,\n                        'metric': 'auc',\n                   #  'num_iterations':1,\n                    },#50\n\n                    lgb_train,\n                    valid_sets=[lgb_train, lgb_eval],\n                    verbose_eval=10,\n                    num_boost_round=10000,\n                    early_stopping_rounds=10\n                )\n_ = lgb.plot_importance(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions = pd.DataFrame(model.predict(validation),index=validation.index)\n\n# from sklearn.metrics import roc_auc_score\n# roc_auc_score(y_val,predictions[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params = {\n#     'objective': 'binary',\n#     'seed': 42,\n#     'metric': 'auc',\n#     'learning_rate': 0.05,\n#     'max_bin': 1000,\n#     'num_leaves': 80,\n#     'num_iterations' : 1\n# }\n# model = lgb.train(\n#     params,\n#     lgb_train,\n#     valid_sets=[lgb_train,lgb_eval],\n#     verbose_eval=5,\n#     num_boost_round=100,\n#     early_stopping_rounds=10\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\nenv = riiideducation.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.merge(user_df, on = \"user_id\", how = \"left\")\n    test_df = test_df.merge(content_df, on = \"content_id\", how = \"left\")\n    test_df['content_questions'].fillna(0, inplace = True)\n    test_df['content_mean'].fillna(0.5, inplace = True)\n    test_df['watches_lecture'].fillna(0, inplace = True)\n    test_df['number_of_answered_q'].fillna(0, inplace = True)\n    test_df['mean_user_acc'].fillna(0.5, inplace = True)\n    test_df['prior_question_elapsed_time'].fillna(mean_prior, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace = True)\n    test_df['prior_question_had_explanation'] = label_enc.fit_transform(test_df['prior_question_had_explanation'])\n    test_df[['content_questions', 'number_of_answered_q']] = test_df[['content_questions', 'number_of_answered_q']].astype(int)\n    test_df['answered_correctly'] =  model.predict(test_df[features])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}