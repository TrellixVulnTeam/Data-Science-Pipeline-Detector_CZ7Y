{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import math\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.metrics import AUC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"piv1 = pd.read_csv(\"../input/riiid-fixed-infos/content.csv\")\npiv2 = pd.read_csv(\"../input/riiid-fixed-infos/task.csv\")\npiv3 = pd.read_csv(\"../input/riiid-fixed-infos/user.csv\")\n\nfor col, df in zip([\"content_sum\", \"task_container_sum\", \"user_sum\"], [piv1, piv2, piv3]):\n    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n#\nm1 = piv1[\"content_sum\"].median()\nm2 = piv2[\"task_container_sum\"].median()\nm3 = piv3[\"user_sum\"].median()\n\n\n# OTHER CONSTANTS\ndata_path = \"../input/riiid-test-answer-prediction/train.csv\"\nTARGET = \"answered_correctly\"\nTIME_MEAN = 21000.0\nTIME_MIN = 0.0\nTIME_MAX = 300000.0\nmap_prior = {True:1, False:0}\nepsilon = 1e-6\nFE = [\"content_emb\",\"content_sum\" ,\"task_container_emb\", \"task_container_sum\",\n      \"user_emb\", \"user_sum\",\"duration\", \"prior_answer\",\"score\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df = df.merge(piv1, how=\"left\", on=\"content_id\")\n    df[\"content_emb\"] = df[\"content_emb\"].fillna(0.5)\n    df[\"content_sum\"] = df[\"content_sum\"].fillna(m1)\n    df = df.merge(piv2, how=\"left\", on=\"task_container_id\")\n    df[\"task_container_emb\"] = df[\"task_container_emb\"].fillna(0.5)\n    df[\"task_container_sum\"] = df[\"task_container_sum\"].fillna(m2)\n    df = df.merge(piv3, how=\"left\", on=\"user_id\")\n    df[\"user_emb\"] = df[\"user_emb\"].fillna(0.5)\n    df[\"user_sum\"] = df[\"user_sum\"].fillna(m3)\n    df[\"prior_question_elapsed_time\"] = df[\"prior_question_elapsed_time\"].fillna(TIME_MEAN)\n    df[\"duration\"] = (df[\"prior_question_elapsed_time\"] - TIME_MIN) / (TIME_MAX - TIME_MIN)\n    df[\"prior_answer\"] = df[\"prior_question_had_explanation\"].map(map_prior)\n    df[\"prior_answer\"] = df[\"prior_answer\"].fillna(0)\n    df[\"score\"] = 2*df[\"content_emb\"]*df[\"user_emb\"] / (df[\"content_emb\"]+ df[\"user_emb\"] + epsilon)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#tr = pd.read_csv(\"../input/riiid-test-answer-prediction/train.csv\", low_memory=False, nrows=10**7)\n\nwith open(data_path) as fp:\n    for (rows, _) in enumerate(fp, 1):\n       pass\nrows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nimport tensorflow as tf\nfrom keras import backend as k\n\ndata_batch_size = 5*10**6\ntrain_batch_size = 50_000\n\nbatch = pd.read_csv(data_path, chunksize=data_batch_size)\nfor idx, ds in enumerate(batch):\n    print('-'*20)\n    print(\"Batch: {}\".format(idx))\n    print('-'*20)\n    ds = preprocess(ds)\n    X = ds.loc[ds.answered_correctly!=-1, FE].values\n    Y = ds.loc[ds.answered_correctly!=-1, TARGET].values\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    cvscores = []\n    input_dim = X.shape[1]\n    del ds\n    if idx==0:\n        # create model\n        model = Sequential()\n        model.add(Dense(60, input_dim=input_dim, activation='relu'))\n        model.add(Dense(120, activation='relu'))\n        model.add(Dense(180, activation='relu'))\n        model.add(Dense(120, activation='relu'))\n        model.add(Dense(60, activation='relu'))\n        model.add(Dense(30, activation='relu'))\n        model.add(Dense(1, activation='sigmoid'))\n        # Compile model\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  ##AUC()])\n    else:\n        model = keras.models.load_model('riiid_model.h5')\n    for train, val in kfold.split(X, Y):\n        # Fit the model\n        model.fit(X[train], Y[train], epochs=5, batch_size=train_batch_size, verbose=0)\n        # evaluate the model\n        scores = model.evaluate(X[val], Y[val], verbose=0)\n        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n        cvscores.append(scores[1] * 100)\n    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n    model.save('riiid_model.h5')\n    del X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\n\nenv = riiideducation.make_env()\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for test_df, sample_prediction_df in iter_test:\n    test_df = preprocess(test_df)\n    Xtest = test_df[FE].values\n    preds = model.predict(Xtest, batch_size=50_000, verbose=0)[:, 0]\n    test_df['answered_correctly'] = preds\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}