{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\n\n%matplotlib inline\n\n# You can only call make_env() once, so don't lose it!\nimport riiideducation\n#env = riiideducation.make_env()\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# INSPIRED BY\n\n- [Kostiantyn Isaienkov's EDA Notebook](https://www.kaggle.com/isaienkov/riiid-answer-correctness-prediction-eda-modeling/)\n- [Ilia Larchenko's Simple EDA and Baseline Notebook](https://www.kaggle.com/ilialar/simple-eda-and-baseline)\n"},{"metadata":{},"cell_type":"markdown","source":"### Training data is in the competition dataset as usual\n\nIt's larger than will fit in memory with default settings, so we'll specify more efficient datatypes and only load a subset of the data for now."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading Files\n\n#train_df - Two options, for a smallish sample load data with code\n# cell a couple below. For all data go to modelling section in notebook.\n\n#questions.csv\nused_data_types_dict = {\n    'question_id': 'int16',\n    'bundle_id': 'int16',\n    'correct_answer': 'int8',\n    'part': 'int8',\n    'tags': 'str',\n}\n\n\nquestions = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv',\n                       usecols = used_data_types_dict.keys(), dtype=used_data_types_dict)\n\n\n#lectures.csv\nlect = pd.read_csv('../input/riiid-test-answer-prediction/lectures.csv')\n\n#example_test\net = pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv', index_col='row_id')\n\n#train_df\ntrain_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv', low_memory=False, nrows=10**7, \n                       dtype={'row_id': 'int64',\n                              'timestamp': 'int64',\n                              'user_id': 'int32',\n                              'content_id': 'int16',\n                              'content_type_id': 'int8',\n                              'task_container_id': 'int16',\n                              'user_answer': 'int8',\n                              'answered_correctly': 'int8',\n                              'prior_question_elapsed_time': 'float32',\n                              'prior_question_had_explanation': 'boolean',\n                             })\nprint(train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CHECKLIST\n#1: Explore variables\n    #TRAIN.CSV \n    #QUESTIONS.CSV\n    #LECTURES.CSV\n\n#2: Explore creating new features from variables combinations\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration Stuff"},{"metadata":{},"cell_type":"markdown","source":"### train.csv"},{"metadata":{},"cell_type":"markdown","source":"* timestamp: done\n* user_id: done\n* content_id: done\n* content_type_id: done\n* task_container_id: done\n* user_answer: done\n* answered_correctly: done\n* prior_question_elapsed_time: done\n* prior_question_had_explanation: done"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = train_df[train_df['answered_correctly'] == 1]\nincorrect = train_df[train_df['answered_correctly'] == 0]\n\nprint (\"Correct: %i (%.1f%%)\"%(len(correct), float(len(correct))/len(train_df)*100.0))\nprint (\"Incorrect: %i (%.1f%%)\"%(len(incorrect), float(len(incorrect))/len(train_df)*100.0))\nprint (\"Total: %i\"%len(train_df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### timestamp"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.timestamp.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlim(0,50000000000)\nsns.distplot(a=correct['timestamp'], label='correct', kde=False)\nsns.distplot(a=incorrect['timestamp'], label=\"incorrect\", kde=False)\nplt.title(\"TimeStamp: Correct vs Incorrect\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### prior_question_elapsed_time"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlim(0, 150000)\n\nsns.distplot(a=correct['prior_question_elapsed_time'], label='correct', kde=False)\nsns.distplot(a=incorrect['prior_question_elapsed_time'], label=\"incorrect\", kde=False)\nplt.title(\"prior_question_elapsed_time: Correct vs Incorrect\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### prior_question_had_explanation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['prior_question_had_explanation', 'answered_correctly']].groupby(['prior_question_had_explanation'], \n                                                                           as_index=False, dropna=False).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ideas?\n\n* for the first question of a test is the prior_question_had_explanation always false, or is it filled with a null value?\n\n* why are the prior_question_elapsed_time and prior_question_elapsed_time not the same in terms of null values?"},{"metadata":{},"cell_type":"markdown","source":"### Task Container ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.task_container_id.nunique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['task_container_id'].value_counts(ascending=True)[-30:].plot(kind='barh', figsize=(10,6),\n                                                                      title='Top 30: task_container_ids')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['task_container_id'].value_counts().plot(kind='line', figsize=(10,6))\nplt.xlabel('task_container_id')\nplt.ylabel('counts')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### user_answer"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.user_answer.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['user_answer', 'answered_correctly']].groupby(['user_answer'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### User ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['user_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#essentially makes a dataset with the value_counts of the user_id column\n#need to figure out how to effectively use this.\nds = train_df['user_id'].value_counts().reset_index()\nds.columns = ['user_id', 'count']\nds = ds.sort_values('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['user_id'].value_counts(ascending=True)[-30:].plot(kind='barh', figsize=(10,6),\n                                                                      title='Top 30: user_ids')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['user_id'].value_counts()[-30:].plot(kind='barh', figsize=(10,6),\n                                                                      title='Bottom 30: user_ids')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.lineplot(x=train_df['user_id'], y=train_df['user_id'].value_counts())\nplt.xlabel(\"user_id\")\nplt.ylabel(\"count\")\nplt.title(\"number of rows per user_id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see from the above that the value_count doesnt seem to change between low and high user_id's. "},{"metadata":{},"cell_type":"markdown","source":"### content_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.content_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = train_df['content_id'].value_counts().reset_index()\nds.columns = ['content_id', 'count']\nds = ds.sort_values('count', ascending=False)\n\nds.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title('Top 30: content_ids')\n\nsns.barplot(x=ds.head(30)['count'], y=ds.head(30).content_id, orient = 'h', \n            order=ds.head(30).sort_values('count', ascending = False).content_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title('Bottom 30: content_ids')\n\nsns.barplot(x=ds.tail(30)['count'], y=ds.tail(30).content_id, orient = 'h', \n            order=ds.tail(30).sort_values('count').content_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(data=ds['count'])\nplt.xlabel('content_id')\nplt.ylabel('count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### content_type_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.user_answer.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.content_type_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 0 if the event was a question being posed to the user\n* 1 if the event was the user watching a lecture\n\nnote: we can see that there are the same number of content_type_id = 1 as there is user_answer = -1."},{"metadata":{},"cell_type":"markdown","source":"# questions.csv\n\nquestion_id - foreign key for the content_id column in train/test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"que = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv', index_col='question_id')\nque","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"que.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### correct_answer"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = que['correct_answer'].value_counts(normalize=True).reset_index()\nds.columns = ['correct_answer', 'number_of_answers']\nds = ds.sort_values(['number_of_answers'], ascending=False)\n\nds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### bundle_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"que.bundle_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = que.bundle_id.value_counts().value_counts(normalize=True)\nds = pd.DataFrame({'#_in_bundle':ds.index, 'percentage_of_questions':ds.values}) #created a data frame otherwise it would come out as a series\nds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"que.loc[que['bundle_id'] == 7795]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Maybe bundles with more that one question are connected? ie if you get the first question wrong you might be able to solve the remaining Q's?\n"},{"metadata":{},"cell_type":"markdown","source":"### part"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = que['part'].value_counts(normalize=True).reset_index()\nds.columns = ['parts', 'percentage_of_questions']\nds = ds.sort_values(['percentage_of_questions'], ascending=False)\nds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tags\n\nsome feature eng here for sure"},{"metadata":{"trusted":true},"cell_type":"code","source":"#seeing how many tags most of the questions have \nds = que['tags'].str.split().str.len().value_counts(normalize=True)\nds = pd.DataFrame({'#_of_tags':ds.index, 'percentage_of_questions':ds.values})\nds['#_of_tags'] = ds['#_of_tags'].astype(int)\n\nds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seeing which tags occur most frequently\nds = que['tags'].str.split(' ').explode('tags').reset_index()\nds = ds['tags'].value_counts().reset_index()\nds.columns = ['tag_number', 'count']\n\nds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title('Top 30: tags')\n\nsns.barplot(x=ds.head(30)['count'], y=ds.head(30).tag_number, orient = 'h', \n            order=ds.head(30).sort_values('count', ascending = False).tag_number)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title('Bottom 30: tags')\n\nsns.barplot(x=ds.tail(30)['count'], y=ds.tail(30).tag_number, orient = 'h', \n            order=ds.tail(30).sort_values('count', ascending = False).tag_number)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.lineplot(x=ds['tag_number'], y=ds['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# lectures.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"lect = pd.read_csv('../input/riiid-test-answer-prediction/lectures.csv')\nlect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lect.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = lect.part.value_counts()\nds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = lect.part.value_counts(normalize=True)\nds = pd.DataFrame({'part_numb':ds.index, 'percentage_of_questions':ds.values})\nds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### type_of"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = lect.type_of.value_counts()\nds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = lect.type_of.value_counts()\nds.plot(kind='bar', )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = lect.loc[lect['type_of'] == 'solving question']\nds.part.value_counts(normalize=True).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = lect.loc[lect['type_of'] == 'concept']\nds.part.value_counts(normalize=True).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tag"},{"metadata":{"trusted":true},"cell_type":"code","source":"lect.tag.value_counts().value_counts().to_frame().plot(kind='bar')\nplt.xlabel('Tag_number')\nplt.ylabel('count')\nplt.title('Number of Lectures with each tag number')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# example_test_rows.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"et = pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv', index_col='row_id')\net","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_questions_only_df = train_df[train_df['answered_correctly']!=-1]\ntrain_questions_only_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_questions_only_df = pd.merge(train_questions_only_df, questions['part'], \n                                   left_on='content_id', right_index=True, how = 'left')\ntrain_questions_only_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removes rows that are lectures and .groupby the user_id\ngrouped_by_user_df = train_questions_only_df.groupby('user_id')\n\n#getting the mean accuracy, question count of each user and other math stuff\nuser_answers_df = grouped_by_user_df.agg({'answered_correctly': ['mean', 'count', 'std', 'median', 'skew']}).copy()\nuser_answers_df.columns = [\n    'mean_user_accuracy', \n    'questions_answered', \n    'std_user_accuracy', \n    'median_user_accuracy', \n    'skew_user_accuracy'\n]\n\nuser_answers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#grouping by content_id\ngrouped_by_content_df = train_questions_only_df.groupby('content_id')\n\n#getting mean count and other stuff for each content_id\ncontent_answers_df = grouped_by_content_df.agg({'answered_correctly': ['mean', 'count', 'std', 'median', 'skew']}).copy()\ncontent_answers_df.columns = [\n    'mean_accuracy', \n    'question_asked', \n    'std_accuracy', \n    'median_accuracy', \n    'skew_accuracy'\n]\n\ncontent_answers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_by_part_df = train_questions_only_df.groupby('part')\n\npart_answers_df = grouped_by_part_df.agg({'answered_correctly': ['mean', 'count', 'std', 'skew']}).copy()\npart_answers_df.columns = [\n    'part_mean_accuracy', \n    'part_questions_answered', \n    'part_std_user_accuracy',  \n    'part_skew_user_accuracy'\n]\n\npart_answers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\n    'mean_user_accuracy', \n    'questions_answered',\n    'std_user_accuracy', \n    'median_user_accuracy',\n    'skew_user_accuracy',\n    'mean_accuracy', \n    'question_asked',\n    'std_accuracy', \n    'median_accuracy',\n    'prior_question_elapsed_time', \n    'prior_question_had_explanation',\n    'skew_accuracy',\n    'part',\n    'part_mean_accuracy', \n    'part_questions_answered', \n    'part_std_user_accuracy',  \n    'part_skew_user_accuracy'\n]\ntarget = 'answered_correctly'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df[target] != -1]\n\ntrain_df = pd.merge(train_df, questions['part'], \n                    left_on='content_id', right_index=True, how = 'left')\n\ntrain_df = train_df.merge(user_answers_df, how='left', on='user_id')\ntrain_df = train_df.merge(content_answers_df, how='left', on='content_id')\ntrain_df = train_df.merge(part_answers_df, how='left', left_on='part', right_index=True)\n\ntrain_df['prior_question_had_explanation'] = train_df['prior_question_had_explanation'].fillna(value=False).astype(bool)\ntrain_df = train_df.fillna(value=0.5)\n\ntrain_df = train_df[features + [target]]\ntrain_df = train_df.replace([np.inf, -np.inf], np.nan)\ntrain_df = train_df.fillna(0.5)\n\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Maybe creating a loop to see if user has seen question before"},{"metadata":{},"cell_type":"markdown","source":"This is an idea I had to create some sort of loop that checks if the user has seen the question before. It takes far too long to run, and I might have to try a different mehtod than pandas to speed up the process. \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse import csc_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seen_before_df_keys=csc_matrix((0, 0), dtype=np.int8).toarray()\nseen_before_df=csc_matrix((0, 13523), dtype=np.int8).toarray()\nclean_row=csc_matrix((1, 13523), dtype=np.int8).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seen_question_before(dataset, seen_before_df_keys, seen_before_df, clean_row):\n    \n    dataset['seen_q_before']=0\n\n    for i in dataset.index:\n        x = dataset.loc[i] \n        if np.any(seen_before_df_keys == x.user_id)==True:\n            dataset.at[i, 'seen_q_before'] = seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]\n            seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]+=1\n\n        elif np.any(seen_before_df_keys == x.user_id)==False:\n            seen_before_df_keys = np.append(seen_before_df_keys, x.user_id)\n            seen_before_df = np.append(seen_before_df, clean_row, axis=0)\n\n            dataset.at[i, 'seen_q_before'] = seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]\n            seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]+=1\n    \n    return (dataset, seen_before_df_keys, seen_before_df)\n        \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"et, seen_before_df_keys, seen_before_df = seen_question_before(et, seen_before_df_keys, \n                                                                          seen_before_df, clean_row)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}