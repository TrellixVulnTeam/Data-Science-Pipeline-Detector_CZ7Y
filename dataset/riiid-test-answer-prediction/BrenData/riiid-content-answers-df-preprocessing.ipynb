{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Opening Notes\n\nThis notebook is one of the key pieces of the LGB model I created. By creating this dataframe in a seperate notebook I was able to create some pretty awesome features and stay within the CPU limits of the kaggle notebook environment. "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final import in the following kernel was super awesome. I knew there was some way the tags were connected together, and the I found Alex Bader's method of clustering these tags to be the best! His notebook taught me about an awesome framework called networkx which provided some awesome visualizations of the connections between tags. Please check out his notebook at this link -> [Link](https://www.kaggle.com/spacelx/2020-r3id-clustering-question-tags)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nused_data_types_dict = {\n    'question_id': 'int16',\n    'bundle_id': 'int16',\n    'correct_answer': 'int8',\n    'part': 'int8',\n    'tags': 'str',\n}\n\nquestions = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv',\n                       usecols = used_data_types_dict.keys(), dtype=used_data_types_dict)\n\nlectures_df = pd.read_csv('../input/riiid-test-answer-prediction/lectures.csv')\n#ex = pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv')\n\nquestions_communities = pd.read_csv('../input/2020-r3id-clustering-question-tags/question_cmnts.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfeatures_df = pd.read_pickle('../input/riiid-splitting-train-and-test-data/features_q_only.pkl.zip')\n#train_df = pd.read_pickle('../input/riiid-splitting-train-and-test-data/train_q_only.pkl.zip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following cell shifts the prior_question_elapsed_time variable up one position so that we can see the amount of time it took to answer the question. I used this variable to find out the average amount of time it took to answer each question. "},{"metadata":{"trusted":true},"cell_type":"code","source":"features_df['q_time'] = features_df['prior_question_elapsed_time'].shift(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping all lectures\ntrain_questions_only_df = features_df[features_df['answered_correctly']!=-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following function was used to get the average question time of each question by question_id. One thing to note is that it took me a while to figure out why I kept getting all these inf variables for average question time. I figured out that the only way to solve this issue was to replace all the inf values in the column with nan values, and then use fillna on those cells. There was probably a better value that zero, buts that what I used!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_avg_q_time(train_questions_only_df):\n    \n    train_questions_only_df = train_questions_only_df.replace([np.inf, -np.inf], np.nan)\n    train_questions_only_df['q_time'].fillna(0, inplace=True)\n    train_questions_only_df = train_questions_only_df[train_questions_only_df['answered_correctly']!=0]\n    \n    grouped_by_content_df = train_questions_only_df.groupby('content_id')\n    \n    content_avg_q_time_df = grouped_by_content_df.agg({'q_time':['mean']})\n    \n    for i in questions[~questions.index.isin(content_avg_q_time_df.index)].index.values:\n        content_avg_q_time_df.loc[i] = content_avg_q_time_df.values.mean()\n     \n    content_avg_q_time_df = content_avg_q_time_df.reset_index()\n    \n    content_avg_q_time_df.columns = [\n    'content_id',\n    'avg_q_time', \n    ]\n    \n    content_avg_q_time_df = content_avg_q_time_df.set_index('content_id').sort_index()\n        \n    return(content_avg_q_time_df)\n\ncontent_avg_q_time_df = get_avg_q_time(train_questions_only_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting questions accuracy, number of times it was asked and the number of times it was correct. I took all three of these so that I could loop through and update these as we see more datapoints. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#grouping by content_id\ngrouped_by_content_df = train_questions_only_df.groupby('content_id')\n\n#getting mean count and other stuff for each content_id\ncontent_answers_df = grouped_by_content_df.agg({'answered_correctly': ['mean', 'count', 'sum']}).copy()\ncontent_answers_df.columns = [\n    'q_mean_accuracy', \n    'q_question_asked',\n    'q_question_correct',\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There were actually some question_id's that we did not get to see, and I created a nifty function to fill these values. I filled the ration of number of correct and incorrect with roughly the overall avg. I thought adding the number of times the question was asked at 10 was reasonable. This was because I was planning on looping and updating this. If this was 1, one or two incorrect questions would seriouslt effect the supposed question accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_missing_questions(content_answers_df, questions):\n    \n    for i in questions[~questions.index.isin(content_answers_df.index)].index.values:\n        content_answers_df.loc[i] = [0.6, 10, 6]\n        \n    content_answers_df = content_answers_df.sort_index()\n        \n    return(content_answers_df)\n\ncontent_answers_df = add_missing_questions(content_answers_df, questions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is another nifty pandas manipulation statement and checks how many quesitons in the bundle_id that is tied to that specific question. This is a pretty cool feature I extracted, and Im glad I was able to do so in one line!"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions['num_in_bundle'] = questions.groupby(['bundle_id'])['question_id'].transform('count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merging all the dataframes I have created in this notebook into one. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding community\ncontent_answers_df = content_answers_df.merge(questions_communities['community'], left_index=True, right_index=True)\n\n#adding numb in bundle\ncontent_answers_df = content_answers_df.merge(questions['num_in_bundle'], left_index=True, right_index=True)\n\n#adding avg_q_time\ncontent_answers_df = content_answers_df.merge(content_avg_q_time_df['avg_q_time'], left_index=True, right_index=True)\n\ncontent_answers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_answers_df.to_pickle('./content_answers_df.pkl.zip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Closing Notes\n\nIts typical for a data scientist working on decision tree models, but I do wonder what other features I could have gotten that could be tied to eac question_id. I defintaley could have filled the questions that were unseen with values that were representive of their tag or part. \n\nI think its impossible to fully exlpore all ways you can create features from the data given, but I do think I could have utilizaed the timestamp and lag_time features in conjunction with these stats to create some pretty powerful varaibles. Im interested to see some creative features used after the competition ends."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}