{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Simple HPO using optuna lgbm integration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Used most of coding from this kernel https://www.kaggle.com/lgreig/simple-lgbm-baseline\n# and https://www.kaggle.com/thebigd8ta/riiid-lgbm-start\n\nimport riiideducation\nimport dask.dataframe as dd\nimport  pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nenv = riiideducation.make_env()\n\n#train= pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv',\n#                usecols=[1, 2, 3,4,7,8,9], dtype={'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8','prior_question_elapsed_time': 'float32','prior_question_had_explanation': 'boolean'}\n#              )\n\ntrain = pd.read_feather('../input/riiid-feather-format/train.feather')\n\ntrain = train[train.content_type_id == False]\n#arrange by timestamp\ntrain = train.sort_values(['timestamp'], ascending=True)\n\ntrain.drop(['timestamp','content_type_id'], axis=1,   inplace=True)\n\nresults_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content\"]\n\nresults_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\nresults_u.columns = [\"answered_correctly_user\", 'sum']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train\nprint (X.shape)\ndel train\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[\"prior_question_had_explanation\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[\"prior_question_had_explanation\"].fillna(False, inplace=True) # ?\nX[\"prior_question_had_explanation\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c, on=['content_id'], how=\"left\")\nX=X[X.answered_correctly!= -1 ]\nX=X.sort_values(['user_id'])\nY = X[[\"answered_correctly\"]]\nX = X.drop([\"answered_correctly\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])\nX.head()\n\nX = X[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']] \nX.fillna(0.5,  inplace=True)\nfrom  sklearn.tree import DecisionTreeClassifier\nfrom  sklearn.model_selection import train_test_split\nXt, Xv, Yt, Yv = train_test_split(X, Y, test_size = 0.01, shuffle=False)\n\nimport lightgbm as lgb\n\n#use optuna to find lgb parameters\n#import optuna.integration.lightgbm as lgb\n\nparams = {'objective': 'binary',\n 'feature_pre_filter': False,\n 'lambda_l1': 9.277442449206187e-06,\n 'lambda_l2': 5.145214812238188e-06,\n 'num_leaves': 43,\n 'feature_fraction': 0.7,\n 'bagging_fraction': 0.6696041270563738,\n 'bagging_freq': 3,\n 'min_child_samples': 20,\n 'num_iterations': 10000,\n 'early_stopping_round': 10}\n\nlgb_train = lgb.Dataset(Xt, Yt)\nlgb_eval = lgb.Dataset(Xv, Yv, reference=lgb_train)\n\nmodel = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=10,\n    num_boost_round=10000,\n    early_stopping_rounds=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params from optuna\n# params = model.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(Xv)\ny_true = np.array(Yv)\nroc_auc_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test =  pd.read_csv('/kaggle/input/riiid-test-answer-prediction/example_test.csv')\ntest[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test[\"prior_question_had_explanation\"])\ntest = pd.merge(test, results_u, on=['user_id'],  how=\"left\")\ntest = pd.merge(test, results_c, on=['content_id'],  how=\"left\")\ntest[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']]\ntest.fillna(0.5, inplace=True)\n\ny_pred = model.predict(test[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']])\n\ntest['answered_correctly'] = y_pred\n\n# results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n# results_c.columns = [\"answered_correctly_content\"]\n\n# results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\n# results_u.columns = [\"answered_correctly_user\", 'sum']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, results_u, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_c, on=['content_id'],  how=\"left\")\n    test_df['answered_correctly_user'].fillna(0.5, inplace=True)\n    test_df['answered_correctly_content'].fillna(0.5, inplace=True)\n    test_df['sum'].fillna(0, inplace=True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}