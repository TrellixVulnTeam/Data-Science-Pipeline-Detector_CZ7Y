{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Riiid! Answer Correctness Prediction with help lightgbm classifier with futures and parameters tuning. Submission version."},{"metadata":{},"cell_type":"markdown","source":"# Link on my guide notebook. \n\n# https://www.kaggle.com/beable/lgbm-with-parameters-features-selection"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import optuna\nfrom sklearn.feature_selection import RFECV\nfrom lightgbm import LGBMClassifier\nimport pandas as pd\nimport joblib\nimport numpy as np\nimport riiideducation\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport optuna.integration.lightgbm as lgb\nfrom optuna.samplers import TPESampler\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df = pd.read_csv(\n    '../input/riiid-test-answer-prediction/questions.csv',\n    usecols=[0, 3],\n    dtype={'question_id': 'int16', 'part': 'int8'}\n)\n\nmodel = joblib.load('../input/lgb-model-2/Final_lgb_2.joblib')\nselector = joblib.load('../input/selector-2/Selector_2.joblib')\n\nuser_answers_df = pd.read_csv('../input/preprocessingcontentuser/user.csv')\ncontent_answers_df = pd.read_csv('../input/preprocessingcontentuser/content.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\n    'timestamp',\n    'user_id',\n    'content_id',\n    'prior_question_elapsed_time',\n    'prior_question_had_explanation',\n\n    'part',\n\n    'mean_user_accuracy',\n    'questions_skew',\n    'questions_std',\n    'questions_var',\n    'questions_sem',\n\n    'content_mean',\n    'content_skew',\n    'content_std',\n    'content_var',\n    'content_sem'\n]\n\nfeatures = [features[i] for i in range(len(selector.support_)) if selector.support_[i] == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = riiideducation.make_env()\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    \n    test_df = pd.merge(test_df, questions_df, left_on='content_id', right_on='question_id', how='left')\n    test_df.drop(columns=['question_id'], inplace=True)\n    test_df['prior_question_had_explanation'].fillna(bool(True), inplace=True)\n    test_df = test_df.replace([-np.inf, np.inf], np.nan)\n    test_df = test_df.fillna(test_df.mean())\n    \n    test_df = test_df[test_df['content_type_id'] != 1]\n    \n    test_df = test_df.merge(user_answers_df, how='left', on='user_id')\n    test_df = test_df.merge(content_answers_df, how='left', on='content_id')\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].astype(bool)\n    test_df = test_df.replace([-np.inf, np.inf], np.nan)\n    test_df = test_df.fillna(test_df.mean())\n\n    \n    test_df['answered_correctly'] = model.predict_proba(test_df[features])[:,1]\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}