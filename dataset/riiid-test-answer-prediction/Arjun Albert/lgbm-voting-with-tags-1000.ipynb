{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import riiideducation # enviorment\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport lightgbm as lgb # light gradient boosting model\nimport dask.dataframe as dd # dask fast dataframe importer\nfrom sklearn.metrics import roc_auc_score # area under the curve calculator\nfrom sklearn.preprocessing import LabelEncoder # label encoder\nimport matplotlib.pyplot as plt # plotting\n\nimport gc \nimport os \nimport sys\n\n\ntraining_path           = '/kaggle/input/riiid-test-answer-prediction/train.csv'\nquestions_path          = '/kaggle/input/riiid-test-answer-prediction/questions.csv'\nlectures_path           = '/kaggle/input/riiid-test-answer-prediction/lectures.csv'\nexample_submission_path = '/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv'\nexample_test_path       = '/kaggle/input/riiid-test-answer-prediction/example_test.csv'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\"\"\"\nPrint the paths for local enviorment input files.\n\"\"\"\ndef print_paths():\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n            \n\n\"\"\"\nPrint the input string to the notebook console. \nAlso prints the input string to Kaggle kenrel.\n\"\"\"\ndef print_log(s):\n    print(s)\n    sys.__stdout__.write(s)\n    \n\n\"\"\"\nConvert the existing dataframe values to data types.\nAlso replace NaN values with -1. \nReturns the dataframes for training as well as labels.\n\"\"\"    \ndef getDataFramesForTraining(dataframe):\n    data = dataframe[features]\n    data['prior_question_elapsed_time'].fillna(-1, inplace=True)\n    return data, dataframe['answered_correctly']\n\n\n\"\"\"\nConvert the existing dataframe values to data types.\nAlso replace NaN values with -1. \nReturns the dataframes for testing.\n\"\"\"\ndef getDataFramesForTesting(dataframe):\n    data = dataframe[features]\n    data['prior_question_elapsed_time'].fillna(-1, inplace=True)\n    return data\n\n\n\"\"\"\nConvert the existing dataframe values to correct data types.\nSplice tag column into multiple columns and append them to questions dataframe.\nReturns the dataframes for questions.\n\"\"\"\ndef getDataFramesForQuestions(dataframe):\n    tag = dataframe[\"tags\"].str.split(\" \", n = 10, expand = True) \n    tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n    dataframe =  pd.concat([dataframe,tag], axis=1)\n    for tag in tag.columns:\n        dataframe[tag] = pd.to_numeric(dataframe[tag], errors='coerce')\n    return dataframe\n\n\"\"\"\nMerge in the questions tag columns joining\non question_id and content_id.\nReturn the merged dataframe.\n\"\"\"\ndef mergeQuestions(train, questions):\n    return pd.merge(train, questions, left_on = 'content_id', right_on = 'question_id', how = 'left') \n\n\n\"\"\"\n\n\"\"\"\ndef encodeColumns(dataframe):\n    lb_make = LabelEncoder()\n    dataframe['prior_question_had_explanation'].fillna(True, inplace=True)\n    dataframe[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(dataframe[\"prior_question_had_explanation\"])\n    return dataframe\n\n\n\"\"\"\n\n\"\"\"\ndef expandTags(questions):\n    tag = questions[\"tags\"].str.split(\" \", n = 10, expand = True) \n    tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n    questions =  pd.concat([questions,tag],axis=1)\n    for tag in tag.columns:\n        questions[tag] = pd.to_numeric(questions[tag], errors='coerce')\n    return questions\n\n\n\"\"\"\n\n\"\"\"\ndef plot_metrics(model, eval_results):\n    lgb.plot_importance(model)\n    plt.show()\n    metrics = ['auc', 'l1', 'l2']\n    for metric in metrics: \n        lgb.plot_metric(eval_results, metric=metric)\n        plt.show()\n        \n\n\"\"\"\n\n\"\"\"\ndef createSubmission(model):\n    env = riiideducation.make_env()\n    for test_df, sample_prediction_df in env.iter_test():\n        test_df_enc = encodeColumns(test_df)\n        test_df_enc = mergeQuestions(test_df_enc, questions)\n        testdata = getDataFramesForTesting(test_df_enc)\n        test_df['answered_correctly'] =  model.predict(testdata[features])\n        env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n        \n\n\"\"\"\n\n\"\"\"\ndef splitTrainValid(train, labels):\n    trainingCount = int(len(labels.index) * training_valid_ratio)\n    train_dataset = lgb.Dataset(train[:trainingCount], labels[:trainingCount], categorical_feature = categorical_features)\n    valid_dataset = lgb.Dataset(train[trainingCount:], labels[trainingCount:], categorical_feature = categorical_features)\n    return train_dataset, valid_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['content_id', 'prior_question_elapsed_time', 'prior_question_had_explanation_enc', 'tags1','tags2','tags3','tags4']\ncategorical_features = ['tags1','tags2','tags3','tags4']\n\ntraining_cols = ['content_id', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'answered_correctly']\nquestion_cols = [0, 1, 3, 4]\n\ntraining_dtype = {'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8','prior_question_elapsed_time': 'float32','prior_question_had_explanation': 'boolean'}\nquestion_dtype = {'question_id': 'int16', 'part': 'int8','bundle_id': 'int8','tags': 'str'}\n\nmillion = 1000000\ntraining_valid_ratio = 0.9\nmax_iterations = 1000\neval_round = 10\neval_results = {}\n\ntraining_params = {'objective'            : 'binary',\n                   'metric'               :('auc', 'l1', 'l2'),\n                   'boosting'             : 'gbdt',\n                   'tree_learner'         : 'voting',\n                   'learning_rate'        :  0.11,\n                   'num_leaves'           :  80,\n                   'min_data_in_leaf'     :  20,\n                   'early_stopping_rounds':  10}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(training_path, nrows=60*million, engine='c', usecols=training_cols, dtype=training_dtype)\n\ngc.collect()\nprint_log('Done reading training data.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions = pd.read_csv(questions_path, usecols=question_cols, dtype=question_dtype)\n\ngc.collect()\nprint_log('Done reading questions data.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions = expandTags(questions)\n\ngc.collect()\nprint_log('Done grabbing tags.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = mergeQuestions(train, questions)\n\ngc.collect()\nprint_log('Done merging questions.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = encodeColumns(train)\n\ngc.collect()\nprint_log('Done encoding columns.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, labels = getDataFramesForTraining(train)\n\ngc.collect()\nprint_log('Done labelling data.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset, valid_dataset = splitTrainValid(train, labels)\n\ngc.collect()\nprint_log('Done splitting training and valid.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(training_params, train_dataset, valid_sets=[train_dataset, valid_dataset], num_boost_round=max_iterations, verbose_eval=eval_round, evals_result=eval_results)\n\ngc.collect()\nprint_log('Done training.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"createSubmission(model)\n    \ngc.collect()    \nprint_log('Done with inference.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics(model, eval_results)\n\ngc.collect()\nprint_log('Done all.')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}