{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport seaborn as sns\nimport os\nfrom matplotlib.ticker import FuncFormatter\nimport datetime\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv',\n                   usecols=[1, 2, 3, 4, 5, 7, 8, 9],\n                   dtype={\n                          'timestamp': 'uint64',\n                          'user_id': 'uint32',\n                          'content_id': 'uint16',\n                          'content_type_id': 'uint8',\n                          'task_container_id': 'uint16',\n                          'answered_correctly':'uint8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Describe data\n\n#print('The Train Dataset has {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n#print('\\n')\n#print(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.isnull().sum()\n#train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n\n#train.content_type_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(f'We have {train.content_id.nunique()} content ids in our train set, of which {train[train.content_type_id == 0].content_id.nunique()} are questions.')\n#print(f'We have {train.user_id.nunique()} unique users in our train set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.content_type_id == False].sort_values('timestamp').reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['lag'] = train.groupby('user_id')['answered_correctly'].shift()\n#train_test = train[train.user_id == 124]\n#train_test\n#test_create_feature = train_test.groupby(['user_id','task_container_id'])['answered_correctly'].mean()\n#user_feats_df = pd.DataFrame(test_create_feature)\n#train_test = pd.concat([train_test, user_feats_df], axis=1)\n#user_feats_df['userId_taskId'] = user_feats_df.index\n#user_feats_df['user_Id'] = [user_feats_df['userId_taskId'][x][0] for x in range(0,user_feats_df.shape[0])]\n#user_feats_df['task_Id'] = [user_feats_df['userId_taskId'][x][1] for x in range(0,user_feats_df.shape[0])]\n#user_feats_df.reset_index(drop = True, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cum = train.groupby('user_id')['lag'].agg(['cumsum', 'cumcount'])\n# User correctness (measure the users' learning progress)\n#train['user_correctness'] = cum['cumsum'] / cum['cumcount']\n# Drop the 'lag' feature\n#train.drop(columns = ['lag'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train[(train.content_type_id == False)].task_container_id.nunique()\n#number_answers.to_csv('number_answers.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number_answers['number_answers'] = number_answers.groupby(['user_id','content_id'])['content_id.1'].cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train[(train['user_id'] ==499347415) & (train['content_id'] == 7964)]\n#train.loc[train['user_id']==115]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group1 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['count'])\ngroup1.columns = ['avg_questions']\ngroup2 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['nunique'])\ngroup2.columns = ['avg_questions']\ngroup3 = group1 / group2\ngroup3['avg_questions_seen'] = group3.avg_questions.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['task_correctly'] = train.groupby(['user_id', 'task_container_id']).answered_correctly.transform('mean').astype(np.float32)\n#train['question_answers'] = train.groupby(['user_id']).content_id.transform('nunique').astype(np.uint16)\n#train['number_answers'] = train.groupby(['user_id']).content_id.transform('count').astype(np.uint16)\n#train['answers_ratio'] = (train['question_answers'] / train['number_answers']).astype(np.float16)\nquestions_info = train.groupby(['user_id']).content_id.agg(['nunique','count']).astype(np.uint16)\nquestions_info.columns = ['question_answers_train','number_answers_train']\nquestions_info['avg_answers_train'] = (questions_info['question_answers_train'] / questions_info['number_answers_train']).astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_u_final = train.loc[train.content_type_id == False, ['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_final.columns = ['answered_correctly_user']\n\n#results_u2_final = train.loc[train.content_type_id == False, ['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n#results_u2_final.columns = ['explanation_mean_user']\n\ntask_final = train.loc[train.content_type_id == False, ['task_container_id','answered_correctly']].groupby(['task_container_id']).agg(['mean'])\ntask_final.columns = ['task_correctly']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"elapsed_mean = train.prior_question_elapsed_time.mean()\ntrain['prior_question_elapsed_time'] = train['prior_question_elapsed_time'].fillna(elapsed_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_question = train.groupby(['user_id'])['prior_question_elapsed_time'].agg(['mean'])\ntime_question.columns = ['time_questions']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The values to filter the null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving value to fillna\nelapsed_mean = train.prior_question_elapsed_time.mean()\n#prior_mean_user = results_u2_final.explanation_mean_user.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#task_final_u = train.groupby(['user_id','task_container_id'])['answered_correctly'].mean()\n#task_final_u.columns = ['task_correctly_user']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv')\n#questions = questions_df.copy()\n#questions.rename(columns = {'question_id' : 'content_id'}, inplace = True)\ntrain = pd.merge(train, questions_df[['question_id', 'part']], left_on='content_id', right_on='question_id', how='left')\ndel(questions_df)\ntrain[['part','question_id']].astype('uint16')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#part_count = train.groupby(['content_id'])['answered_correctly'].count()\n#part_answers = train.groupby(['content_id'])['answered_correctly'].sum()\n#question_correctly = pd.merge(part_count,part_answers, on = 'content_id',  how=\"left\" )\n#question_correctly.columns = ['content_answers_count', 'content_answered_correctly']\n#question_correctly['content_percenty'] = question_correctly.content_answered_correctly / question_correctly.content_answers_count\n#question_correctly.to_csv('question_correctly.csv', index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"part_detail\"] = train.part.apply(lambda x : \n                                                             \"Listening_Image\" if x == 1 else\n                                                             \"Listening_question\" if x ==2 else\n                                                             \"Listening_conversation\" if x ==3 else\n                                                             \"Listening_conversation\" if x == 4 else\n                                                             \"Reading_grammar\" if x == 5 else\n                                                             \"Reading_fill_in \" if x == 6 else\n                                                             \"Reading_mail\"\n                                                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_correctly = pd.read_csv('../input/feature/question_correctly.csv')\n#part_user = pd.read_csv('../input/feature/part_user.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split the Validation and Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = train.groupby('user_id').tail(10)\ntrain = train[~train.index.isin(validation.index)]\nlen(train) + len(validation)\n#import gc\n\n#cv2_train = pd.read_pickle(\"../input/cv2-data/cv2_train.pickle\")\n#cv2_valid = pd.read_pickle(\"../input/cv2-data/cv2_valid.pickle\")\n\n\n\n\n#validation = train[train.row_id.isin(cv2_valid.row_id)]\n#train = train[train.row_id.isin(cv2_train.row_id)]\n\n#validation = validation.drop(columns = \"row_id\")\n#train = train.drop(columns = \"row_id\")\n\n#del cv2_train, cv2_valid\n#gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_u_val = validation.loc[validation.content_type_id == False, ['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_val.columns = ['answered_correctly_user']\n\n#results_u2_val = validation.loc[validation.content_type_id == False, ['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n#results_u2_val.columns = ['explanation_mean_user']\n\ntask_val = validation.loc[validation.content_type_id == False, ['task_container_id','answered_correctly']].groupby(['task_container_id']).agg(['mean'])\ntask_val.columns = ['task_correctly']\n\ntime_question_val = validation.groupby(['user_id'])['prior_question_elapsed_time'].agg(['mean'])\ntime_question_val.columns = ['time_questions']\n\nvalidation['question_answers'] = validation.groupby(['user_id']).content_id.transform('nunique').astype(np.uint16)\nvalidation['number_answers'] = validation.groupby(['user_id']).content_id.transform('count').astype(np.uint16)\nvalidation['answers_ratio'] = (validation['number_answers'] / validation['question_answers']).astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.groupby('user_id').tail(20)\ntrain = train[~train.index.isin(X.index)]\nlen(X) + len(train) + len(validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_u_X = X.loc[X.content_type_id == False, ['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_X.columns = ['answered_correctly_user']\n\n#results_u2_X = X.loc[X.content_type_id == False, ['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n#results_u2_X.columns = ['explanation_mean_user']\n\ntask_X = X.loc[X.content_type_id == False, ['task_container_id','answered_correctly']].groupby(['task_container_id']).agg(['mean'])\ntask_X.columns = ['task_correctly']\n\ntime_question_X = X.groupby(['user_id'])['prior_question_elapsed_time'].agg(['mean'])\ntime_question_X.columns = ['time_questions']\n\nX['question_answers'] = X.groupby(['user_id']).content_id.transform('nunique').astype(np.uint16)\nX['number_answers'] = X.groupby(['user_id']).content_id.transform('count').astype(np.uint16)\nX['answers_ratio'] = (X['number_answers'] / X['question_answers']).astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)\nX.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#task_X\ndel(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.merge(X, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\nX = pd.merge(X, task_X, left_on=['task_container_id'], right_index= True, how=\"left\")\nX = pd.merge(X, results_u_X, on=['user_id'], how=\"left\")\n#X = pd.merge(X, results_u2_X, on=['user_id'], how=\"left\")\nX = pd.merge(X, question_correctly, on = ['content_id'], how = 'left')\n#X = pd.merge(X, part_user, on = ['user_id'], how = 'left' )\nX = pd.merge(X, time_question_X, on = ['user_id'], how = 'left' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = pd.merge(validation, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\nvalidation = pd.merge(validation, task_val, left_on=['task_container_id'], right_index= True, how=\"left\")\nvalidation = pd.merge(validation, results_u_val, on=['user_id'], how=\"left\")\n#validation = pd.merge(validation, results_u2_val, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, question_correctly, on = ['content_id'], how = 'left')\n#validation = pd.merge(validation, part_user, on = ['user_id'], how = 'left' )\nvalidation = pd.merge(validation, time_question_val, on = ['user_id'], how = 'left' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\n\n#X[\"prior_question_had_explanation\"] = X[\"prior_question_had_explanation\"].fillna(False)\n#validation[\"prior_question_had_explanation\"] = validation[\"prior_question_had_explanation\"].fillna(False)\n\n#validation[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(validation[\"prior_question_had_explanation\"])\n#X[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = pd.get_dummies(validation)\nX = pd.get_dummies(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['hmean_user_content_accuracy'] = 2 * (\n        (X['answered_correctly_user'] * X['content_percenty']) /\n        (X['answered_correctly_user'] + X['content_percenty'])\n    )\n\n\nX_val['hmean_user_content_accuracy'] = 2 * (\n        (X_val['answered_correctly_user'] * X_val['content_percenty']) /\n        (X_val['answered_correctly_user'] + X_val['content_percenty'])\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X.isnull().sum()\nX_val.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['answered_correctly_user' ,'avg_questions_seen','content_percenty','hmean_user_content_accuracy',\n       'content_answers_count','prior_question_elapsed_time','part_detail_Listening_Image','part_detail_Listening_conversation',\n       'part_detail_Listening_question','part_detail_Reading_fill_in','part_detail_Reading_grammar','part_detail_Reading_mail',\n           'part','question_answers','number_answers'\n      ]\nX = X.reindex(columns = columns)\nX_val = X_val.reindex(columns = columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X['answered_correctly_user'].fillna(0.65,  inplace=True)\n#X['explanation_mean_user'] = X['explanation_mean_user'].fillna(prior_mean_user)\n\n#X['avg_questions_seen'].fillna(1, inplace = True)\n#X['prior_question_elapsed_time'] = X['prior_question_elapsed_time'].fillna(elapsed_mean)\n#X['prior_question_had_explanation_enc'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_val['answered_correctly_user'].fillna(0.65,  inplace=True)\n#X_val['explanation_mean_user']= X_val['explanation_mean_user'].fillna(prior_mean_user)\n\n#X_val['avg_questions_seen'].fillna(1, inplace = True)\n#X_val['prior_question_elapsed_time'] = X_val['prior_question_elapsed_time'].fillna(elapsed_mean)\n#X_val['prior_question_had_explanation_enc'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['part_detail_Reading_fill_in'] = X['part_detail_Reading_fill_in'].fillna(0)\nX_val['part_detail_Reading_fill_in'] = X_val['part_detail_Reading_fill_in'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nparams = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'seed': 42,\n    'boosting' : 'gbdt',\n    'max_bin': 1500,\n    'learning_rate': 0.02,\n    'num_leaves': 80\n}\n\nlgb_train = lgb.Dataset(X, y)\nlgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=50,\n    num_boost_round=3000,\n    early_stopping_rounds=50\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.metrics import roc_auc_score\n\n#y_pred = model.predict(X_val)\n#y_true = np.array(y_val)\n#roc_auc_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(model)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(model, importance_type = 'gain')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\nenv = riiideducation.make_env()\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n    #elapsed_mean = test_df.prior_question_elapsed_time.mean()\n    test_df['prior_question_elapsed_time'] = test_df['prior_question_elapsed_time'].fillna(elapsed_mean)\n    \n    test_df = pd.merge(test_df, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n    test_df = pd.merge(test_df, results_u_final, on=['user_id'],  how=\"left\")\n    #test_df = pd.merge(test_df, task_final, left_on=['task_container_id'], right_index= True, how=\"left\")\n    test_df = pd.merge(test_df, question_correctly, on = ['content_id'], how = 'left')\n    test_df[\"prior_question_had_explanation\"] = test_df[\"prior_question_had_explanation\"].fillna(False)\n    \n    test_df = pd.merge(test_df, questions_df[['question_id', 'part']], left_on='content_id', right_on='question_id', how='left')\n    test_df['question_id'].astype('uint16')\n    test_df['part'].astype('uint8')\n    #time_question = test_df.groupby(['user_id'])['prior_question_elapsed_time'].agg(['mean'])\n    #time_question.columns = ['time_questions']\n    #test_df = pd.merge(test_df, time_question, on = ['user_id'], how = 'left' )\n    #test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    test_df['number_answers_test'] = test_df.groupby(['user_id']).content_id.transform('count').astype(np.uint16)\n    test_df['question_answers_test'] = test_df.groupby(['user_id']).content_id.transform('nunique').astype(np.uint16)\n    test_df = pd.merge(test_df, questions_info, on = ['user_id'], how = 'left' )\n    test_df['question_answers_train'] = test_df['question_answers_train'].fillna(0)\n    test_df['number_answers_train'] = test_df['number_answers_train'].fillna(0)\n    test_df['number_answers'] = test_df['number_answers_train']+ test_df['number_answers_test']\n    test_df['question_answers'] = test_df['question_answers_train']+ test_df['question_answers_test']\n    #question_answers_train\tnumber_answers_train\n    test_df['hmean_user_content_accuracy'] = 2 * (\n        (test_df['answered_correctly_user'] * test_df['content_percenty']) /\n        (test_df['answered_correctly_user'] + test_df['content_percenty'])\n    )\n    \n    test_df[\"part_detail\"] = test_df.part.apply(lambda x : \n                                                             \"Listening_Image\" if x == 1 else\n                                                             \"Listening_question\" if x ==2 else\n                                                             \"Listening_conversation\" if x ==3 else\n                                                             \"Listening_conversation\" if x == 4 else\n                                                             \"Reading_grammar\" if x == 5 else\n                                                             \"Reading_fill_in \" if x == 6 else\n                                                             \"Reading_mail\"\n                                                            )\n\n    test_df = pd.get_dummies(test_df)\n    #test_df['part_detail_Reading_fill_in'] = test_df['part_detail_Reading_fill_in'].fillna(0)\n    \n    test_df['answered_correctly'] =  model.predict(test_df.reindex(columns=columns))\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(train.answered_correctly.value_counts())\n\n#print('\\n')\n#ans = train.answered_correctly.value_counts()\n\n#fig = plt.figure(figsize=(12,6))\n#ax = ans.plot.bar()\n#plt.title(\"Numer of the answers correctly\")\n#plt.xticks(rotation=0)\n#ax.get_yaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(train.content_id.value_counts()[:30])\n\n#print('\\n')\n\n#content_id = train.content_id.value_counts()[:30]\n\n#fig = plt.figure(figsize=(12,6))\n#ax = content_id.plot.bar()\n#plt.title(\"Numer of the content ID\")\n#plt.xticks(rotation=90)\n#ax.get_yaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#time_col = ['timestamp', 'prior_question_elapsed_time',]\n#plt.figure(figsize=(14,6))\n#for i, col in enumerate(time_col):\n#    plt.subplot(1, 2, i + 1)\n#    train[col].hist(bins = 50,color='red')\n#    plt.title(col)\n#    plt.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}