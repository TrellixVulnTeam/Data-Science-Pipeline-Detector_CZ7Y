{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport random\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.utils.rnn as rnn_utils\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn import datasets, linear_model\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n#read in data (dropped some columns)\n#train_all = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv',low_memory=False,nrows=10**6)\n#train_q=train_all[train_all.content_type_id==0]\n#train_q.fillna(0.0,inplace=True)\n#train_q.prior_question_had_explanation=train_q.prior_question_had_explanation.astype(int)\n\n\n# Draw plot to see if there are any obvious trends\n#g = sns.pairplot(train_q,\n#                 vars = ['answered_correctly',#'content_id',\n#                         'prior_question_elapsed_time' ,'prior_question_had_explanation'],\n#                 kind='scatter',\n#                 markers = '.')\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data\nRead in the training data and question reference data.\n\nWe only keep the column \n\n**'timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly'**\n\nThen, we only consider the data where **'conten_type_id' == 0**, which means this record is about a question not a lecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndtype = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8'}\ntrain_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv', usecols=[1, 2, 3,4,7], dtype=dtype)\ntrain_df = train_df[train_df.content_type_id == 0]\ntrain_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)\n\nquestion_df=pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv',usecols=[0,3])\n\n\n#Set up part\nquestion_df.part=question_df.part.fillna(-1).astype('int8')\nquestion_df.columns=['content_id','part']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split the training dataset into 10 subsets"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nn=train_df.shape\nn=n[0]\nn=n//10\nseparated=[]\nfor i in range(0,10):\n    separated.append(train_df.iloc[i*n:(i+1)*n-1,1:].copy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Group all the training data by **'user_id'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = train_df[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n            r['content_id'].values,\n            r['answered_correctly'].values))\ncontent_id=train_df.content_id\nIDs=train_df.user_id\ndel train_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a **'user_ref'** to store the information of each user.\n\nIt includes:\n*  The number of different questions in total.\n*  The number of tries (because a user might do a question several times)\n*  The historical correct rate of this user\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\na,b=np.unique(group.iloc[0][0],return_counts=True)\nn=group.shape\nn=n[0]\nuser_ref=[]\nids=np.asarray(group.index)\nfor i in range(0,n):\n    temp=group.iloc[i][0]\n    unique, counts=np.unique(temp,return_counts=True)\n    del temp\n    types=len(unique)\n    all_q=sum(counts)\n    avg=group.iloc[i][1].mean()\n    temp=[ids[i],types,all_q,avg]\n    user_ref.append(temp)\n\nuser_ref=pd.DataFrame(user_ref, columns=['user_id', 'number_of_questions', 'number_of_total_tries','correct_rate'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# For each event, we attach the information of the user and the information of the question"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnew_trains=[]\nfor i in range(0,10):\n    temp=separated[0].merge(user_ref,left_on='user_id', right_on='user_id')\n    temp=temp.merge(question_df,left_on='content_id',right_on='content_id')\n    new_trains.append(temp)\n    del separated[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Put the 10 subsets back together"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfinal_train=new_trains[0]\n#final_train=[]\ndel new_trains[0]\nfor i in range(0,9):\n    #final_train=pd.concat([final_train,new_trains[0]])\n    final_train=final_train.append(new_trains[0], ignore_index=True)\n    del new_trains[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finishing the Setup\nUse the train_X as the train set, it has columns \n\n**'user_id', 'content_id', 'content_type_id', 'answered_correctly', 'number_of_questions', 'number_of_total_tries', 'correct_rate', 'part'**\n\nAnd train_Y  is its corresponding y"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_Y=final_train[['answered_correctly']]\ntrain_X=final_train[['user_id', 'content_id', 'content_type_id', 'number_of_questions', 'number_of_total_tries', 'correct_rate', 'part']]\ndel final_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define a function to deal with test dataset.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will assume the format of test set is the same as the give sample\n#It takes a given dataset (with only question entries), and convert it \n#to the same format as the training set.\ndef formattest(given):\n    test=given[['user_id', 'content_id', 'content_type_id']]\n    test=test.merge(user_ref,left_on='user_id', right_on='user_id',how='left').merge(question_df,left_on='content_id',right_on='content_id',how='left')\n    test=test.fillna(-1)\n    return test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.head()\n#train_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Y.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xmean = train_X.mean()\ntrain_X.fillna(xmean)\nymean = train_Y.mean()\ntrain_Y.fillna(ymean)\n\ntrain_X = train_X.to_numpy()\ntrain_Y = train_Y.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"cross-validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nprint(train_X.shape)\nprint(train_Y.shape)\ntrain_X = train_X[1:1000000,:]\ntrain_Y = train_Y[1:1000000,:]\n\nprint(train_X.shape)\nprint(train_Y.shape)\nX_train, X_test, Y_train, Y_test = train_test_split(train_X, train_Y, test_size=0.4, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split  \n#from sklearn.preprocessing import Imputer \nfrom sklearn.preprocessing import MinMaxScaler  \nfrom sklearn.preprocessing import label_binarize  \nfrom sklearn.decomposition import PCA \nfrom sklearn.ensemble import RandomForestClassifier  \nfrom sklearn.datasets import make_moons\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n\n\n#clf = AdaBoostClassifier(n_estimators=500)\n#clf.fit(X_train, Y_train)\n#y_pred = clf.predict(X_test)\n#accuracy_score(Y_test, y_pred)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf = GradientBoostingClassifier(n_estimators=500)\n#clf.fit(X_train, Y_train)\n#y_pred = clf.predict(X_test)\n#accuracy_score(Y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nrfc = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=3, max_features=None, random_state=0)\nrfc.fit(X_train, Y_train)\ny_pred = rfc.predict(X_test)\naccuracy_score(Y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\nenv = riiideducation.make_env()\niter_test = env.iter_test()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df,sample_prediction_df) in iter_test:\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    sample_test = test_df[test_df['content_type_id'] == 0]\n    test = formattest(sample_test)\n    del sample_test\n    #del sample_test\n    res = rfc.predict_proba(test)[:,1]\n    test_df['answered_correctly'] = res \n    del test\n    test_df.fillna(0.5, inplace=True)\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}