{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn.feature_selection import RFE\nfrom sklearn.feature_selection import RFECV\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import IsolationForest\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/dont-overfit-ii/train.csv')\ntest = pd.read_csv('/kaggle/input/dont-overfit-ii/test.csv')\nlabels = train.columns.drop(['id', 'target'])\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'target', data = train, palette = 'hls')\nplt.show\nplt.savefig('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['id','target'],axis = 1)\nY = train['target']\nX_eval = test.drop(['id'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_eval.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelXGB = XGBClassifier(max_depth = 2, gamma = 2, eta = 0.8, reg_alpha = 0.5, reg_lambda = 0.5)\nrfe = RFE(modelXGB)\nrfe.fit(X,Y)\nprint('selected features:')\nprint(labels[rfe.support_].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_fs = rfe.transform(X)\nX_fs_eval = rfe.transform(X_eval)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_fs = X_fs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='minority', n_jobs=-1)\nX_sm, y_sm = smote.fit_resample(X_fs,Y)\n\ndf = pd.DataFrame(X_sm)\ndf['target'] = y_sm\n\nsns.countplot(x = 'target', data = df, palette = 'hls')\nplt.show\nplt.savefig('count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normX = df.drop(['target'], axis = 1)\nnormY = df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelLR = LogisticRegression(solver = 'liblinear',C = 0.05, penalty = 'l2', class_weight ='balanced', max_iter = 10)\nmodelDT = DecisionTreeClassifier(random_state = 0, max_depth = 3, min_samples_leaf = 3, min_samples_split = 2 )\nmodelXGB = XGBClassifier(max_depth = 2, gamma = 2, eta = 0.8, reg_alpha = 0.5, reg_lambda = 0.5)\nmodelSVM = svm.SVC(kernel ='linear', gamma='scale')\nmodelKNN = KNeighborsClassifier(n_neighbors=3)\nmodelGNB = GaussianNB()\nscaler = StandardScaler()\n\nnormX = scaler.fit_transform(normX)\n\nX_eval = scaler.fit_transform(X_fs_eval)\n\nmodelLR.fit(normX, normY)\nY_pred_LR = modelLR.predict_proba(X_fs_eval)\n\nmodelDT.fit(normX, normY)\nY_pred_DT = modelDT.predict_proba(X_fs_eval)\n\nmodelXGB.fit(normX, normY)\nY_pred_XGB = modelXGB.predict_proba(X_fs_eval)\n\nmodelSVM.fit(normX, normY)\nY_pred_SVM= modelSVM.predict(X_fs_eval)\n\nmodelKNN.fit(normX, normY)\nY_pred_KNN= modelKNN.predict_proba(X_fs_eval)\n\nmodelGNB.fit(normX, normY)\nY_pred_GNB= modelGNB.predict_proba(X_fs_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.classifier import StackingClassifier\nm = StackingClassifier(\n    classifiers=[\n        modelLR,\n        modelDT,\n        modelXGB\n    ],\n    use_probas=True,\n    meta_classifier= modelLR\n)\n\nm.fit(normX, normY)\n\npred = m.predict_proba(X_fs_eval)[:,1]\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/dont-overfit-ii/sample_submission.csv')\n\nsubmission['target'] = pred\nsubmission.to_csv('sample_submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}