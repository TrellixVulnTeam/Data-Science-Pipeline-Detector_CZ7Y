{"cells":[{"metadata":{},"cell_type":"markdown","source":"First of all I have used ideas from these websites: \n\nhttps://www.statisticshowto.datasciencecentral.com/lasso-regression/\n\n\nIn this kernel we are going to use Lasso regression which is a type of linear regression that produces [sparse models](https://www.quora.com/Why-need-to-find-sparse-models-in-machine-learning). \n\nLasso regression performs L1 regularization, which adds a penalty equal to the absolute value of the magnitude of the coefficients. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Loading the packages\nimport numpy as np\nimport pandas as pd \nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer \nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Loading the training dataset\ndf_train = pd.read_csv(\"../input/train.csv\")\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_train[\"target\"]\n# We exclude the target and id columns from the training dataset\ndf_train.pop(\"target\");\ndf_train.pop(\"id\")\ncolnames1 = df_train.columns\n","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to standardize the explanatory variables by removing the mean and scaling to unit variance. The reason for that is to help convergence of the technique used in the optimization. "},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(df_train)\nX = scaler.transform(df_train)\ndf_train = pd.DataFrame(data = X, columns=colnames1)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to perform a grid search in order to find a good value for the hyperparameters $\\lambda$ of Lasso regression. The following web page is a good reference: \n\n[Tuning ML Hyperparameters](https://alfurka.github.io/2018-11-18-grid-search/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find best hyperparameters (roc_auc)\nrandom_state = 0\nclf = LogisticRegression(random_state = random_state)\nparam_grid = {'class_weight' : ['balanced'], \n              'penalty' : ['l1'],  \n              'C' : [0.0001, 0.0005, 0.001, \n                     0.005, 0.01, 0.05, 0.1, 0.5, 1, \n                     10, 100, 1000, 1500, 2000, 2500, \n                     2600, 2700, 2800, 2900, 3000, 3100, 3200  \n                     ] , # This hyperparameter is lambda \n              'max_iter' : [100, 1000, 2000, 5000, 10000] }\n\n# Make an roc_auc scoring object using make_scorer()\nscorer = make_scorer(roc_auc_score)\n\ngrid = GridSearchCV(estimator = clf, param_grid = param_grid , \n                    scoring = scorer, verbose = 1, cv=20,\n                    n_jobs = -1)\n\n\nX = df_train.values\n\ngrid.fit(X,y)\n\nprint(\"Best Score:\" + str(grid.best_score_))\n\nbest_parameters = grid.best_params_\n","execution_count":5,"outputs":[{"output_type":"stream","text":"Fitting 20 folds for each of 110 candidates, totalling 2200 fits\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.6s\n[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   10.1s\n[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:   19.7s\n[Parallel(n_jobs=-1)]: Done 1530 tasks      | elapsed:   41.3s\n","name":"stderr"},{"output_type":"stream","text":"Best Score:0.7203\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 2200 out of 2200 | elapsed:   59.3s finished\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to print the hyperparameters of the best model \nbest_clf = grid.best_estimator_\nprint(best_clf)","execution_count":6,"outputs":[{"output_type":"stream","text":"LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\n          multi_class='warn', n_jobs=None, penalty='l1', random_state=0,\n          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\n          multi_class='warn', n_jobs=None, penalty='l1', random_state=0,\n          solver='warn', tol=0.0001, verbose=0, warm_start=False);\n\nmodel.fit(X, y);\n","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we are going to generate the submission file. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/test.csv\")\ndf_test.pop(\"id\");\nX = df_test \nX = scaler.transform(X)\ndf_test = pd.DataFrame(data = X, columns=colnames1)  \nX = df_test.values\n\ny_pred = model.predict_proba(X)\ny_pred = y_pred[:,1]  ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit prediction\nsmpsb_df = pd.read_csv(\"../input/sample_submission.csv\")\nsmpsb_df[\"target\"] = y_pred\nsmpsb_df.to_csv(\"submission.csv\", index=None)\n","execution_count":9,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}