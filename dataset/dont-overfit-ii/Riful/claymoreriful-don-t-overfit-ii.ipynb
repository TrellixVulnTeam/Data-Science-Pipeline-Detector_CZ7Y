{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"from IPython.display import display, HTML\n\ndisplay(HTML(data=\"\"\"\n<style>\n    div#notebook-container    { width: 95%; }\n    div#menubar-container     { width: 65%; }\n    div#maintoolbar-container { width: 99%; }\n</style>\n\"\"\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import FastICA, PCA, FactorAnalysis\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom scipy.stats import norm\nimport warnings \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, DotProduct\nfrom sklearn.naive_bayes import GaussianNB\n\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_rows', -1)\npd.set_option('display.expand_frame_repr', False)\npd.options.display.max_columns = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\ntrain_label = train_data.pop('target')\n\ntest_id = test_data.pop('id')\ntrain_data.drop('id', axis=1, inplace=True)\n\nstats_data = pd.concat([train_data, test_data])\n\nprint('Train rows:', train_data.shape)\nprint('Test rows:', test_data.shape)\nprint('Stats rows:', stats_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# percent missing values\ndesc = stats_data.describe().T\ndesc['missing %'] = 1- (desc['count'] / len(stats_data))\n#display(desc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale, PCA, ICA, FA\nCOMPONENTS = 100\n\n# Standardize the input data\nscaler = StandardScaler().fit(stats_data)\ntrain_scaled = scaler.transform(train_data)\nstats_scaled = scaler.transform(stats_data)\n\n# PCA\npca = PCA(n_components=COMPONENTS).fit(stats_scaled)\ntrain_pca = pca.transform(train_scaled)\n#print(\"PCA: Calculated Eigenvectors:\\n\", pca.components_.T)\ndisplay(\"PCA: Variance for each Dimension:\", pca.explained_variance_ratio_)\nplt.title('PCA: First 2 Eigenvectors')\nplt.scatter(train_pca[:, 0], train_pca[:, 1], c=train_label)\nplt.show()\n\n# ICA\nica = FastICA(n_components=COMPONENTS).fit(stats_scaled)\ntrain_ica = ica.transform(train_scaled)  \n#print(\"ICA: Calculated Eigenvectors:\\n\", ica.components_.T)\nplt.title('ICA: First 2 Eigenvectors')\nplt.scatter(train_ica[:, 0], train_ica[:, 1], c=train_label)\nplt.show()\n\n# FA\nfa = FactorAnalysis(n_components=COMPONENTS).fit(stats_scaled)\ntrain_fa = fa.transform(train_scaled)\n#print(\"FactorAnalysis: Calculated Eigenvectors:\\n\", factor.components_.T)\nplt.title('FA: First 2 Eigenvectors')\nplt.scatter(train_fa[:, 0], train_fa[:, 1], c=train_label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlations between variables\nplt.subplot(121)\nsns.heatmap(train_data.corr()).set_title('Train Data Correlation')\nplt.subplot(122)\nsns.heatmap(stats_data.corr()).set_title('Stats Data Correlation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlations with Target\nabsCorrWithDep = []\nfor var in train_data.columns:\n    a = np.corrcoef(train_data[var], train_label)\n    a = a[0][1]\n    dic = {}\n    dic.update(column=var, cor=a)\n    absCorrWithDep.append(dic)\nabsCorrWithDep = pd.DataFrame(absCorrWithDep)\n\nsns.distplot(absCorrWithDep['cor'], hist=True, kde=True, color = 'blue', bins = 30).set_title('Train Data Correlation with Target')\nplt.show()\n\ncors = pd.DataFrame(absCorrWithDep['cor'].values)\ncors.columns = ['Correlation']\ncors['Index'] = range(0, len(cors))\ncors['AbsCorr'] = abs(cors['Correlation'])\ncors = cors.reindex(columns=['Index', 'Correlation', 'AbsCorr'])\ncors = cors.sort_values(by='AbsCorr', ascending=False)\n\ndisplay(cors.head())\n\nplt.plot(cors['AbsCorr'].values)\nplt.ylabel('AbsCorr')\nplt.show()\n\nprint(\"len(AbsCorr >= 0.2)\", len(cors[cors['AbsCorr'] >= 0.2]))\nprint(\"len(AbsCorr >= 0.15)\", len(cors[cors['AbsCorr'] >= 0.15]))\nprint(\"len(AbsCorr >= 0.1)\", len(cors[cors['AbsCorr'] >= 0.1]))\n\ncor_list = cors['Index'].values\ndisplay(\"Top 15 Indices in order:\", cor_list[0:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tree Based\n# forest of trees to evaluate the importance of features\n# fit a number of randomized decision trees on various sub-samples of the dataset and use averaging to rank order features\n\n#orderedParams['DTree'] = {}\norderedParams = {}\norderedImportances = {}\n\nselForestFit = ExtraTreesClassifier(n_estimators = 100).fit(train_scaled, train_label)\nimportances = selForestFit.feature_importances_\n\nr = []\nfor a,b in enumerate(importances):\n    r.append([a,b])\nr = pd.DataFrame(r)\nr.columns = ['Index', 'Tree_Importance']\nr = r.sort_values(by='Tree_Importance', ascending=False)\ndisplay(r.head())\n\nplt.plot(r['Tree_Importance'].values)\nplt.ylabel('Tree_Importance')\nplt.show()\n\nprint(\"len(Tree_Importance >= 0.0055)\", len(r[r['Tree_Importance'] >= 0.0055]))\nprint(\"len(Tree_Importance >= 0.005)\", len(r[r['Tree_Importance'] >= 0.005]))\nprint(\"len(Tree_Importance >= 0.004)\", len(r[r['Tree_Importance'] >= 0.004]))\n\ntree_list = r['Index'].values\ndisplay(\"Top 15 Indices in order:\", tree_list[0:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input: \n# an input array with normal distributed float values\n# a target array with 0-1 values, denoting an event or not. 1 = event\n# an integer that denotes the number of bins\n\n# Output DataFrame: \n# BinNr, Min_Value, Max_Value, Count\n# Event, Event_Rate, NonEvent, NonEvent_Rate, Dist_Event, Dist_NonEvent, WoE, IV\n\ndef normDist_WoE (frame, target, nrOfBins):\n    ranges = []\n    for i in range(0, nrOfBins + 1):\n        ranges.append(norm.ppf(i / nrOfBins, loc=0, scale=1))\n        \n    df = pd.DataFrame(frame)\n    df.columns = ['val']\n    df['target'] = target.astype(int)\n    df['bin'] = 0\n    for i in range(1, nrOfBins + 1):\n        df.loc[(df['val'] >= ranges[i-1]) & (df['val'] < ranges[i]), 'bin'] = i\n    \n    result = []\n    for i in range(1, nrOfBins + 1):\n        dic = {}\n        dic.update(BinNr=i, Min_Value=ranges[i-1], Max_Value=ranges[i], Count=len(df[df['bin'] == i]),\n                   Event=len(df[(df['bin'] == i) & (df['target'] == 1)]), \n                   NonEvent=len(df[(df['bin'] == i) & (df['target'] != 1)]))\n        result.append(dic)\n    result = pd.DataFrame(result)\n    result = result.reindex(columns=(['BinNr', 'Min_Value', 'Max_Value', 'Count', 'Event', 'NonEvent']))\n\n    result['Event_Rate'] = result['Event'] / result['Count']\n    result['NonEvent_Rate'] = result['NonEvent'] / result['Count']\n    result['Dist_Event'] = result['Event'] / sum(result['Event'])\n    result['Dist_NonEvent'] = result['NonEvent'] / sum(result['NonEvent'])\n    result['WoE'] = np.log(result['Dist_Event'] / result['Dist_NonEvent'])\n    result['IV'] = (result['Dist_Event'] - result['Dist_NonEvent']) * np.log(result['Dist_Event'] /result['Dist_NonEvent'])\n    \n    return (sum(result['IV']), result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hypothesis:\n## Variables are used together and then encoded with an activation function\n# Test:\n## Bin the variables into X ranges. For each of them, use WeightOfEvidence and IV\n## If the variables are run through a monotone function prior to their combination and the activation function, \n## then we may be able to notice something. \n### Try X = 5\n\n# - All variables are normal distributions with a standard deviation of 1\n# - All variables are centered around 0\n#   -> Cumulative distribution function -> Percent pint function (inverse of cdf) -> percentiles\n#   -> Same bin-intervals for all variables\n\nBIN_SIZE = 5\n\nwoe_table = pd.DataFrame()\niv_table = []\nfor i in train_data.columns:\n    curr_iv, curr_woe = normDist_WoE(train_data[i], train_label, BIN_SIZE)\n    iv_table.append([i, curr_iv])\n    curr_woe['Index'] = i\n    curr_woe = curr_woe.reindex(columns=['Index'] + curr_woe.columns[:-1].tolist())\n    curr_woe = pd.DataFrame(curr_woe)\n    woe_table = pd.concat([woe_table, curr_woe])\n    \niv_table = pd.DataFrame(iv_table)\niv_table.columns = ['Index', 'IV']\niv_table = iv_table.sort_values(by='IV', ascending=False)\n\ndisplay(iv_table.head())\n\nplt.plot(iv_table['IV'].values)\nplt.ylabel('IV')\nplt.show()\n\nprint(\"len(IV >= 0.2)\", len(iv_table[iv_table['IV'] >= 0.2]))\nprint(\"len(IV >= 0.15)\", len(iv_table[iv_table['IV'] >= 0.15]))\nprint(\"len(IV >= 0.1)\", len(iv_table[iv_table['IV'] >= 0.1]))\n#display(woe_table)\n\niv_list = iv_table['Index'].values\ndisplay(\"Top 15 Indices in order:\", iv_list[0:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine the 3 methods of selecting the top influential Indices\n\nc = cor_list[0:15]\nt = tree_list[0:15]\ni = iv_list[0:15]\nthree_top_15_lists = [*c, *t, *i]\nthree_top_15_lists = list(map(str, three_top_15_lists))\nthree_top_15_lists = np.array(three_top_15_lists)\n\nunique_elements, counts_elements = np.unique(three_top_15_lists, return_counts=True)\n\nthree_top_15_lists = pd.DataFrame({'Index' :unique_elements , 'Count' : counts_elements})\nthree_top_15_lists = three_top_15_lists.sort_values(by='Count', ascending=False)\n\ndisplay(\"3x Top Indices:\", three_top_15_lists[three_top_15_lists['Count'] == 3].Index.values)\ndisplay(\"2x Top Indices:\", three_top_15_lists[three_top_15_lists['Count'] == 2].Index.values)\ndisplay(\"1x Top Indices:\", three_top_15_lists[three_top_15_lists['Count'] == 1].Index.values)\n\n# Note: Running PCA, ICA, FA on the reduced sets (filtered by top indices) did not provide any improved results - compared to before","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare split and score for modelling \ntrain_data_filtered = train_data[[*three_top_15_lists[three_top_15_lists['Count'] == 3].Index.values, \n                                  *three_top_15_lists[three_top_15_lists['Count'] == 2].Index.values]]\n\ntest_data_filtered = test_data[[*three_top_15_lists[three_top_15_lists['Count'] == 3].Index.values, \n                                *three_top_15_lists[three_top_15_lists['Count'] == 2].Index.values]]\n\ntrain_label_int = train_label.astype(int) # for easier classification\n\ndisplay(train_data_filtered.head())\ndisplay(test_data_filtered.head())\n\ntrain_X, val_X, train_y, val_y = train_test_split(train_data_filtered, train_label_int, test_size=0.1, random_state = None, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One in ten rule\n## -> limit to Nr. of events / 10 -> learnable parameters\n## -> 250 train data /2 (0/1 labels) -> ~12 parameters\n## -> only use the 3x and 2x top indices\n\n# Logistic Regression\nlogit = LogisticRegressionCV(solver='liblinear', cv=5, dual=False, penalty='l1', multi_class='ovr')\nlogit.fit(train_X, train_y)\nscore = logit.score(val_X, val_y)\nprint(\"Logistic Regression:\", score)\nprint(logit.predict(val_X))\ndisplay([p[1] for p in logit.predict_proba(val_X)])\n\n# Nearest Neighbors\nclf = KNeighborsClassifier(n_neighbors=3, weights='distance', algorithm='auto', p=2)\nclf.fit(train_X, train_y)\nscore = clf.score(val_X, val_y)\nprint(\"KNN:\", score)\n#result = clf.predict(val_X)\n#result_prob = clf.predict_proba(val_X)\n\n# Gaussian Process\n## Kernels: RBF, Matern (generalized RBF), Rational quadratic, dot-product\nfor k in [RBF(), Matern(), RationalQuadratic(), DotProduct()]:\n    gpc = GaussianProcessClassifier(kernel=k, n_restarts_optimizer=5, max_iter_predict=200)\n    gpc.fit(train_X, train_y)\n    score = gpc.score(val_X, val_y)\n    print(\"GaussianProcess\", k, score)\n    #result = gpc.predict(val_X)\n    #result_prob = gpc.predict_proba(val_X)\n#print(gpc.predict(val_X)) #  Dot Product\n#display([p[1] for p in gpc.predict_proba(val_X)])\n\n# Naive Bayes\nnb = GaussianNB()\nnb.fit(train_X, train_y)\nscore = nb.score(val_X, val_y)\nprint(\"Naive Bayes:\", score)\nprint(nb.predict(val_X))\ndisplay([p[1] for p in nb.predict_proba(val_X)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Noted score values:\n#  GaussianProcess RBF:               [0.56, 0.68, 0.6,  0.52, 0.84, 0.6,  0.8]\n#  GaussianProcess Matern:            [0.56, 0.68, 0.6,  0.8,  0.84, 0.6,  0.8]\n#  GaussianProcess RationalQuadratic: [0.68, 0.68, 0.8,  0.8,  0.84, 0.6,  0.8]\n#  GaussianProcess DotProduct:        [0.76, 0.72, 0.84, 0.76, 0.8,  0.68, 0.76]\n#  KNN:                               [0.68, 0.68, 0.8,  0.64, 0.8,  0.52, 0.68]\n#  Logistic Regression:               [0.76, 0.72, 0.84, 0.76, 0.84, 0.64, 0.76]\n#  Naive Bayes:                       [0.68, 0.6,  0.72, 0.84, 0.84, 0.64, 0.8]\n \n# Conclusion:\n# - KNN is worse than Logistic Regression and Naive Bayes\n# - DotProduct is the best GaussianProcess. Same average than RationalQuadratic but a little less variance -> more stable\n \n# - Logistic Regression and DotProduct are very similar but Logistic Regression is the simpler concept -> Razor says to pic Logit in this case\n# -> This holds true for assigning very similar probabilities\n \n# Decision:\n# => Use the median of Logistic Regression and Naive Bayes for the final probability","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1) Re-Train Logistic and Naive Bayes with the full training set\n# 2) Predict the test set\n# 3) Write output into submission.csv\nlogit = LogisticRegressionCV(solver='liblinear', cv=5, dual=False, penalty='l1', multi_class='ovr')\nlogit.fit(train_data_filtered, train_label_int)\nlogit_prediction = [p[1] for p in logit.predict_proba(test_data_filtered)]\n\nnb = GaussianNB()\nnb.fit(train_data_filtered, train_label_int)\nnb_prediction = [p[1] for p in nb.predict_proba(test_data_filtered)]\n\nsub_preds = [(i + j) / 2 for i, j in zip(logit_prediction, nb_prediction)]\nsubmission = [[a, b] for a, b in zip(test_id.values, sub_preds)]\nsubmission = pd.DataFrame(submission, columns=['id', 'target'])\n\ndisplay(submission.head())\nprint(\"len(submission)\", len(submission))\nprint(\"len(target ~ 1)\", len(submission[submission.target >= 0.5]))\nprint(\"len(target ~ 0)\", len(submission[submission.target < 0.5]))\n\nsns.distplot(submission['target'], hist=True, kde=True, color = 'blue', bins = 25).set_title('Predictions')\nplt.show()\n\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}