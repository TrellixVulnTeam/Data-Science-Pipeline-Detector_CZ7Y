{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Basic Attempt at Don't Overfit 2**"},{"metadata":{},"cell_type":"markdown","source":"First import the modules that will be used"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn import linear_model\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the training and test files, check the shape and read the first 5 rows of the training set"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Read files\ntrain = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/train.csv')\ntest = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/test.csv')\n\n#Check shapes\nprint('Train Shape: ', train.shape) \nprint('Test Shape: ', test.shape)\n\ntrain.head() #First 5 rows.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the first rows we see that 'target' is obviously the target and the ID column can be dropped. Seeing as we don't have any target values in our test set, we can split the training set and run potential models on this.\n\nNext we set the y and X values."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['target'] #Assign the y target value for potential models.\nX_train = train.drop(['target', 'id'], axis=1) #Drop target and ID for X_train\n\nX_test = test.drop(['id'], axis=1) #Drop ID from the test set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seeing as we have different ranges of values, we will benefit from scaling the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can list all the models that we will use. \n\nSeeing as we are predicting probability, we will use regression models."},{"metadata":{"trusted":true},"cell_type":"code","source":"log = linear_model.LogisticRegression(solver='liblinear')\nridge = linear_model.Ridge()\nSGD = linear_model.SGDRegressor()\nelastic = linear_model.ElasticNet()\nlars = linear_model.Lars()\nlasso = linear_model.Lasso()\nlassolars = linear_model.LassoLars()\northo = linear_model.OrthogonalMatchingPursuit()\nARD = linear_model.ARDRegression()\nbaye = linear_model.BayesianRidge()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We define a function to check the cross validation scores for individual models. \"cross_val_score\" splits the data into say 5 folds. Then for each fold it fits the data on 4 folds and scores the 5th fold. Then it gives you the 5 scores from which you can calculate a mean and variance for the score."},{"metadata":{"trusted":true},"cell_type":"code","source":"def cv_scores(model):\n    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc') #5 folds\n    print('Model: ', model)\n    print('CV Mean: ', np.mean(scores)) #Mean of the 5 scores\n    print('STD: ', np.std(scores)) #Standard deviation of the 5 scores\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [log, ridge, SGD, elastic, lars, lasso, lassolars, ortho, ARD, baye]\n\nfor model in models:\n    cv_scores(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Orthogonal Matching is the best model\n2. Followed by Logistic Regression\n3. ARD Regression\n4. Bayesian Ridge\n5. SGD Regressor\n\nLets try and tune the hyperparameters for each one of these models, and then run again."},{"metadata":{},"cell_type":"markdown","source":"# Orthogonal Matching Model"},{"metadata":{},"cell_type":"markdown","source":"By picking a range of hyper parameters and running a grid search, we can find the best possible parameters for the Orthogonal Matching Model on a 5 fold cross validation splitting strategy on our training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_nonzero_coefs = np.arange(1, 50, 1)\ntol = [None, 1, 2, 5, 8, 15, 25, 35]\nfit_intercept = [True, False]\nnormalize = [True, False]\nprecompute = [True, False]\n\nfrom sklearn.model_selection import StratifiedKFold\n\nparameters = dict(n_nonzero_coefs = n_nonzero_coefs,\n             tol = tol,\n             fit_intercept = fit_intercept,\n             normalize = normalize,\n             precompute = precompute)\n\ngrid = GridSearchCV(estimator = ortho, param_grid = parameters, scoring = 'roc_auc', verbose = 1, n_jobs=-1) #n_jobs use all proccessors\ngridresult = grid.fit(X_train, y_train)\n\nprint('The best score was {:.5f} with parameters of {}'.format(gridresult.best_score_, gridresult.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ortho = linear_model.OrthogonalMatchingPursuit(n_nonzero_coefs = 8, fit_intercept = True, normalize = False, precompute = True,\n                                              tol = None)\ncv_scores(ortho)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using this model we can now make predictions on the test data and save it into a submission csv:"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = ortho.fit(X_train, y_train).predict(X_test)\n\nsubmission = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/sample_submission.csv')\nsubmission['target'] = predict\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Score of 0.839 when submitted. Good score!"},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"solver = ['liblinear', 'saga'] #both handle l1 and l2 penalty\npenalty = ['l1', 'l2']\nC = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\nclass_weight = ['balanced']\n\nparameters = dict(solver = solver,\n             penalty = penalty,\n             C = C,\n             class_weight = class_weight)\n\ngrid = GridSearchCV(estimator = log, param_grid = parameters, scoring = 'roc_auc', verbose = 1, n_jobs=-1) #n_jobs use all proccessors\ngridresult = grid.fit(X_train, y_train)\n\nprint('The best score was {:.5f} with parameters of {}'.format(gridresult.best_score_, gridresult.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log = linear_model.LogisticRegression(C = 1, class_weight = {1: 0.5, 0: 0.5}, penalty = 'l1', solver = 'liblinear')\ncv_scores(log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = log.fit(X_train, y_train).predict(X_test)\n\nsubmission = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/sample_submission.csv')\nsubmission['target'] = predict\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Score of 0.735."},{"metadata":{},"cell_type":"markdown","source":"# ARD Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_iter = np.arange(1,501,100)\nverbose = [True, False]\nalpha_1 = (1e-9, 1.0, 'log-uniform')\nalpha_2 = (1e-9, 1.0, 'log-uniform')\nlambda_1 = (1e-9, 1000, 'log-uniform')\nlambda_2 = (1e-9, 1000, 'log-uniform')\n\nparameters = dict(n_iter = n_iter,\n                 verbose = verbose,\n                 alpha_1 = alpha_1,\n                 alpha_2 = alpha_2,\n                 lambda_1 = lambda_1,\n                 lambda_2 = lambda_2)\n\ngrid = GridSearchCV(estimator = ARD, param_grid = parameters, scoring = 'roc_auc', verbose = 1, n_jobs=-1) #n_jobs use all proccessors\ngridresult = grid.fit(X_train, y_train)\n\nprint('The best score was {:.5f} with parameters of {}'.format(gridresult.best_score_, gridresult.best_params_))\n\n#randomsearch = RandomizedSearchCV(estimator = ARD, param_distributions = parameters, scoring = 'roc_auc', verbose = 1, \n                                  #n_jobs= -1)\n#searchresult = randomsearch.fit(X_train, y_train)\n\n#print('The best score was {:.5f} with parameters of {}'.format(searchresult.best_score_, searchresult.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ARD = linear_model.ARDRegression(alpha_1=1e-09, alpha_2 = 1.0, lambda_1 = 1e-09, lambda_2 = 1e-09, n_iter = 1, verbose = True)\n\ncv_scores(ARD)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = ARD.fit(X_train, y_train).predict(X_test)\n\nsubmission = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/sample_submission.csv')\nsubmission['target'] = predict\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Produces a score of 0.733."},{"metadata":{},"cell_type":"markdown","source":"# Bayesian Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skopt import BayesSearchCV\n\nn_iter = np.arange(1,501,100)\nalpha_1 = (1e-9, 1.0, 'log-uniform')\nalpha_2 = (1e-9, 1.0, 'log-uniform')\nlambda_1 = (1e-9, 1000, 'log-uniform')\nlambda_2 = (1e-9, 1000, 'log-uniform')\n\n\nparams = dict(n_iter = n_iter,\n             alpha_1 = alpha_1,\n             alpha_2 = alpha_2,\n             lambda_1 = lambda_1,\n             lambda_2 = lambda_2,\n             )\n\n#bayes = BayesSearchCV(estimator = baye, search_spaces = params, scoring='roc_auc', verbose=1, n_jobs=-1, n_iter=12)\n#bayesresult = bayes.fit(X_train, y_train)\n#print('The best score was {:.5f} with parameters of {}'.format(bayesresult.best_score_, bayesresult.best_params_))\n\ngrid = GridSearchCV(estimator = baye, param_grid = params, scoring='roc_auc', verbose=1, n_jobs=-1)\ngridresult = grid.fit(X_train, y_train)\nprint('The best score was {:.5f} with parameters of {}'.format(gridresult.best_score_, gridresult.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baye = linear_model.BayesianRidge(alpha_1=1.0, alpha_2=1.0, lambda_1=1e-09, lambda_2=1e-09, n_iter=1)\ncv_scores(baye)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = baye.fit(X_train, y_train).predict(X_test)\n\nsubmission = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/sample_submission.csv')\nsubmission['target'] = predict\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Score of 0.740."},{"metadata":{},"cell_type":"markdown","source":"# SGD Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"penalty = ['l1', 'l2', 'elasticnet']\nalpha = [1, 10, 100, 1000]\nlearning_rate = ['constant', 'optimal', 'invscaling', 'adaptive']\neta0 = [1, 10, 100]\n\nparams = dict(\n                           penalty=penalty,\n                           alpha=alpha,\n                           learning_rate=learning_rate,\n                           eta0=eta0)\n\ngrid = GridSearchCV(estimator = SGD, param_grid = params, scoring='roc_auc', verbose=1, n_jobs=-1)\ngridresult = grid.fit(X_train, y_train)\nprint('The best score was {:.5f} with parameters of {}'.format(gridresult.best_score_, gridresult.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SGD = linear_model.SGDRegressor(alpha=10, eta0=1, learning_rate='adaptive', penalty='l2')\ncv_scores(SGD)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = SGD.fit(X_train, y_train).predict(X_test)\n\nsubmission = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/sample_submission.csv')\nsubmission['target'] = predict\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Score of 0.746."},{"metadata":{},"cell_type":"markdown","source":"# Final order of submission scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nsub_score = []\n\nmodels = ['Orthogonal Matching', 'Linear Regression', 'ARD Regression', 'Bayesian Ridge', 'SGD Regressor']\nsub_score = [0.839, 0.735, 0.733, 0.740, 0.746]\n\nfor i in range(len(models)):\n    print(models[i], 'with a score of: ', sub_score[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}