{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":44,"outputs":[{"output_type":"stream","text":"['sample_submission.csv', 'test.csv', 'train.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape,  df_test.shape","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"((250, 302), (19750, 301))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"   id  target      0      1      2  ...      295    296    297    298    299\n0   0     1.0 -0.098  2.165  0.681  ...   -2.097  1.051 -0.414  1.038 -1.065\n1   1     0.0  1.081 -0.973 -0.383  ...   -1.624 -0.458 -1.099 -0.936  0.973\n2   2     1.0 -0.523 -0.089 -0.348  ...   -1.165 -1.544  0.004  0.800 -1.211\n3   3     1.0  0.067 -0.021  0.392  ...    0.467 -0.562 -0.254 -0.533  0.238\n4   4     1.0  2.347 -0.831  0.511  ...    1.378  1.246  1.478  0.428  0.253\n\n[5 rows x 302 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>...</th>\n      <th>260</th>\n      <th>261</th>\n      <th>262</th>\n      <th>263</th>\n      <th>264</th>\n      <th>265</th>\n      <th>266</th>\n      <th>267</th>\n      <th>268</th>\n      <th>269</th>\n      <th>270</th>\n      <th>271</th>\n      <th>272</th>\n      <th>273</th>\n      <th>274</th>\n      <th>275</th>\n      <th>276</th>\n      <th>277</th>\n      <th>278</th>\n      <th>279</th>\n      <th>280</th>\n      <th>281</th>\n      <th>282</th>\n      <th>283</th>\n      <th>284</th>\n      <th>285</th>\n      <th>286</th>\n      <th>287</th>\n      <th>288</th>\n      <th>289</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>-0.098</td>\n      <td>2.165</td>\n      <td>0.681</td>\n      <td>-0.614</td>\n      <td>1.309</td>\n      <td>-0.455</td>\n      <td>-0.236</td>\n      <td>0.276</td>\n      <td>-2.246</td>\n      <td>1.825</td>\n      <td>-0.912</td>\n      <td>-0.107</td>\n      <td>0.305</td>\n      <td>0.102</td>\n      <td>0.826</td>\n      <td>0.417</td>\n      <td>0.177</td>\n      <td>-0.673</td>\n      <td>-0.503</td>\n      <td>1.864</td>\n      <td>0.410</td>\n      <td>-1.927</td>\n      <td>0.102</td>\n      <td>-0.931</td>\n      <td>1.763</td>\n      <td>1.449</td>\n      <td>-1.097</td>\n      <td>-0.686</td>\n      <td>-0.250</td>\n      <td>-1.859</td>\n      <td>1.125</td>\n      <td>1.009</td>\n      <td>-2.296</td>\n      <td>0.385</td>\n      <td>-0.876</td>\n      <td>1.528</td>\n      <td>-0.144</td>\n      <td>-1.078</td>\n      <td>...</td>\n      <td>-0.681</td>\n      <td>1.250</td>\n      <td>-0.565</td>\n      <td>-1.318</td>\n      <td>-0.923</td>\n      <td>0.075</td>\n      <td>-0.704</td>\n      <td>2.457</td>\n      <td>0.771</td>\n      <td>-0.460</td>\n      <td>0.569</td>\n      <td>-1.320</td>\n      <td>-1.516</td>\n      <td>-2.145</td>\n      <td>-1.120</td>\n      <td>0.156</td>\n      <td>0.820</td>\n      <td>-1.049</td>\n      <td>-1.125</td>\n      <td>0.484</td>\n      <td>0.617</td>\n      <td>1.253</td>\n      <td>1.248</td>\n      <td>0.504</td>\n      <td>-0.802</td>\n      <td>-0.896</td>\n      <td>-1.793</td>\n      <td>-0.284</td>\n      <td>-0.601</td>\n      <td>0.569</td>\n      <td>0.867</td>\n      <td>1.347</td>\n      <td>0.504</td>\n      <td>-0.649</td>\n      <td>0.672</td>\n      <td>-2.097</td>\n      <td>1.051</td>\n      <td>-0.414</td>\n      <td>1.038</td>\n      <td>-1.065</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.081</td>\n      <td>-0.973</td>\n      <td>-0.383</td>\n      <td>0.326</td>\n      <td>-0.428</td>\n      <td>0.317</td>\n      <td>1.172</td>\n      <td>0.352</td>\n      <td>0.004</td>\n      <td>-0.291</td>\n      <td>2.907</td>\n      <td>1.085</td>\n      <td>2.144</td>\n      <td>1.540</td>\n      <td>0.584</td>\n      <td>1.133</td>\n      <td>1.098</td>\n      <td>-0.237</td>\n      <td>-0.498</td>\n      <td>0.283</td>\n      <td>-1.100</td>\n      <td>-0.417</td>\n      <td>1.382</td>\n      <td>-0.515</td>\n      <td>-1.519</td>\n      <td>0.619</td>\n      <td>-0.128</td>\n      <td>0.866</td>\n      <td>-0.540</td>\n      <td>1.238</td>\n      <td>-0.227</td>\n      <td>0.269</td>\n      <td>-0.390</td>\n      <td>-2.721</td>\n      <td>1.659</td>\n      <td>0.106</td>\n      <td>-0.121</td>\n      <td>1.719</td>\n      <td>...</td>\n      <td>0.971</td>\n      <td>-1.489</td>\n      <td>0.530</td>\n      <td>0.917</td>\n      <td>-0.094</td>\n      <td>-1.407</td>\n      <td>0.887</td>\n      <td>-0.104</td>\n      <td>-0.583</td>\n      <td>1.267</td>\n      <td>-1.667</td>\n      <td>-2.771</td>\n      <td>-0.516</td>\n      <td>1.312</td>\n      <td>0.491</td>\n      <td>0.932</td>\n      <td>2.064</td>\n      <td>0.422</td>\n      <td>1.215</td>\n      <td>2.012</td>\n      <td>0.043</td>\n      <td>-0.307</td>\n      <td>-0.059</td>\n      <td>1.121</td>\n      <td>1.333</td>\n      <td>0.211</td>\n      <td>1.753</td>\n      <td>0.053</td>\n      <td>1.274</td>\n      <td>-0.612</td>\n      <td>-0.165</td>\n      <td>-1.695</td>\n      <td>-1.257</td>\n      <td>1.359</td>\n      <td>-0.808</td>\n      <td>-1.624</td>\n      <td>-0.458</td>\n      <td>-1.099</td>\n      <td>-0.936</td>\n      <td>0.973</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>-0.523</td>\n      <td>-0.089</td>\n      <td>-0.348</td>\n      <td>0.148</td>\n      <td>-0.022</td>\n      <td>0.404</td>\n      <td>-0.023</td>\n      <td>-0.172</td>\n      <td>0.137</td>\n      <td>0.183</td>\n      <td>0.459</td>\n      <td>0.478</td>\n      <td>-0.425</td>\n      <td>0.352</td>\n      <td>1.095</td>\n      <td>0.300</td>\n      <td>-1.044</td>\n      <td>0.270</td>\n      <td>-1.038</td>\n      <td>0.144</td>\n      <td>-1.658</td>\n      <td>-0.946</td>\n      <td>0.633</td>\n      <td>-0.772</td>\n      <td>1.786</td>\n      <td>0.136</td>\n      <td>-0.103</td>\n      <td>-1.223</td>\n      <td>2.273</td>\n      <td>0.055</td>\n      <td>-2.032</td>\n      <td>-0.452</td>\n      <td>0.064</td>\n      <td>0.924</td>\n      <td>-0.692</td>\n      <td>-0.067</td>\n      <td>-0.917</td>\n      <td>1.896</td>\n      <td>...</td>\n      <td>-0.540</td>\n      <td>-0.299</td>\n      <td>1.074</td>\n      <td>-0.748</td>\n      <td>1.086</td>\n      <td>-0.766</td>\n      <td>-0.931</td>\n      <td>0.432</td>\n      <td>1.345</td>\n      <td>-0.491</td>\n      <td>-1.602</td>\n      <td>-0.727</td>\n      <td>0.346</td>\n      <td>0.780</td>\n      <td>-0.527</td>\n      <td>-1.122</td>\n      <td>-0.208</td>\n      <td>-0.730</td>\n      <td>-0.302</td>\n      <td>2.535</td>\n      <td>-1.045</td>\n      <td>0.037</td>\n      <td>0.020</td>\n      <td>1.373</td>\n      <td>0.456</td>\n      <td>-0.277</td>\n      <td>1.381</td>\n      <td>1.843</td>\n      <td>0.749</td>\n      <td>0.202</td>\n      <td>0.013</td>\n      <td>0.263</td>\n      <td>-1.222</td>\n      <td>0.726</td>\n      <td>1.444</td>\n      <td>-1.165</td>\n      <td>-1.544</td>\n      <td>0.004</td>\n      <td>0.800</td>\n      <td>-1.211</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0.067</td>\n      <td>-0.021</td>\n      <td>0.392</td>\n      <td>-1.637</td>\n      <td>-0.446</td>\n      <td>-0.725</td>\n      <td>-1.035</td>\n      <td>0.834</td>\n      <td>0.503</td>\n      <td>0.274</td>\n      <td>0.335</td>\n      <td>-1.148</td>\n      <td>0.067</td>\n      <td>-1.010</td>\n      <td>1.048</td>\n      <td>-1.442</td>\n      <td>0.210</td>\n      <td>0.836</td>\n      <td>-0.326</td>\n      <td>0.716</td>\n      <td>-0.764</td>\n      <td>0.248</td>\n      <td>-1.308</td>\n      <td>2.127</td>\n      <td>0.365</td>\n      <td>0.296</td>\n      <td>-0.808</td>\n      <td>1.854</td>\n      <td>0.118</td>\n      <td>0.380</td>\n      <td>0.999</td>\n      <td>-1.171</td>\n      <td>2.798</td>\n      <td>0.394</td>\n      <td>-1.048</td>\n      <td>1.078</td>\n      <td>0.401</td>\n      <td>-0.486</td>\n      <td>...</td>\n      <td>-0.083</td>\n      <td>-0.831</td>\n      <td>1.251</td>\n      <td>-0.206</td>\n      <td>-0.933</td>\n      <td>-1.215</td>\n      <td>0.281</td>\n      <td>0.512</td>\n      <td>-0.424</td>\n      <td>0.769</td>\n      <td>0.223</td>\n      <td>-0.710</td>\n      <td>2.725</td>\n      <td>0.176</td>\n      <td>0.845</td>\n      <td>-1.226</td>\n      <td>1.527</td>\n      <td>-1.701</td>\n      <td>0.597</td>\n      <td>0.150</td>\n      <td>1.864</td>\n      <td>0.322</td>\n      <td>-0.214</td>\n      <td>1.282</td>\n      <td>0.408</td>\n      <td>-0.910</td>\n      <td>1.020</td>\n      <td>-0.299</td>\n      <td>-1.574</td>\n      <td>-1.618</td>\n      <td>-0.404</td>\n      <td>0.640</td>\n      <td>-0.595</td>\n      <td>-0.966</td>\n      <td>0.900</td>\n      <td>0.467</td>\n      <td>-0.562</td>\n      <td>-0.254</td>\n      <td>-0.533</td>\n      <td>0.238</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>2.347</td>\n      <td>-0.831</td>\n      <td>0.511</td>\n      <td>-0.021</td>\n      <td>1.225</td>\n      <td>1.594</td>\n      <td>0.585</td>\n      <td>1.509</td>\n      <td>-0.012</td>\n      <td>2.198</td>\n      <td>0.190</td>\n      <td>0.453</td>\n      <td>0.494</td>\n      <td>1.478</td>\n      <td>-1.412</td>\n      <td>0.270</td>\n      <td>-1.312</td>\n      <td>-0.322</td>\n      <td>-0.688</td>\n      <td>-0.198</td>\n      <td>-0.285</td>\n      <td>1.042</td>\n      <td>-0.315</td>\n      <td>-0.478</td>\n      <td>0.024</td>\n      <td>-0.190</td>\n      <td>1.656</td>\n      <td>-0.469</td>\n      <td>-1.437</td>\n      <td>-0.581</td>\n      <td>-0.308</td>\n      <td>-0.837</td>\n      <td>-1.739</td>\n      <td>0.037</td>\n      <td>0.336</td>\n      <td>-1.102</td>\n      <td>2.371</td>\n      <td>0.554</td>\n      <td>...</td>\n      <td>-1.050</td>\n      <td>-0.347</td>\n      <td>0.904</td>\n      <td>-1.324</td>\n      <td>-0.849</td>\n      <td>3.432</td>\n      <td>0.222</td>\n      <td>0.416</td>\n      <td>0.174</td>\n      <td>-1.517</td>\n      <td>-0.337</td>\n      <td>0.055</td>\n      <td>-0.464</td>\n      <td>0.014</td>\n      <td>-1.073</td>\n      <td>0.325</td>\n      <td>-0.523</td>\n      <td>-0.692</td>\n      <td>0.190</td>\n      <td>-0.883</td>\n      <td>-1.830</td>\n      <td>1.408</td>\n      <td>2.319</td>\n      <td>1.704</td>\n      <td>-0.723</td>\n      <td>1.014</td>\n      <td>0.064</td>\n      <td>0.096</td>\n      <td>-0.775</td>\n      <td>1.845</td>\n      <td>0.898</td>\n      <td>0.134</td>\n      <td>2.415</td>\n      <td>-0.996</td>\n      <td>-1.006</td>\n      <td>1.378</td>\n      <td>1.246</td>\n      <td>1.478</td>\n      <td>0.428</td>\n      <td>0.253</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df_train[\"target\"]\ndf_train = df_train.drop([\"target\",\"id\"], axis=1)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test= df_test.drop([\"id\"], axis=1)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(target)","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"160.0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndf_train = sc.fit_transform(df_train)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the dataset into train and validation dataset\nfrom sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(df_train,target, test_size=0.10, random_state=42)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA(n_components = 100)\nx_train = lda.fit_transform(x_train,y_train)\nx_valid = lda.transform(x_valid)","execution_count":53,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nm = LogisticRegression(random_state = 0)\nm.fit(x_train,y_train)","execution_count":54,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","name":"stderr"},{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting the test set\ny_pred = classifier.predict(x_valid)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check confusion metrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_pred, y_valid)\ncm","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"array([[ 5,  6],\n       [ 2, 12]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building a single tree\nfrom sklearn.ensemble import RandomForestClassifier\nm = RandomForestClassifier(n_estimators=40, n_jobs=-1)\n\nm.fit(x_train, y_train)","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = m.predict(x_valid)","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm =confusion_matrix(y_pred, y_valid)\ncm","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"array([[ 5,  6],\n       [ 2, 12]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#worked on test data\ndf_test = pd.read_csv(\"../input/test.csv\")\n\n#remove Id\nx_test = df_test.drop([\"id\"], axis=1)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_test = sc.fit_transform(x_test)\n\n#lda\nx_test = lda.transform(x_test)\n\n\n#predict the target value\ny_test = m.predict(x_test).astype(int)\n\n\n# Save predictions in format used for competition scoring\noutput = pd.DataFrame({'id': df_test.id,'target': y_test})\noutput.to_csv('submission.csv', index=False)\noutput.head()","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"    id  target\n0  250       0\n1  251       0\n2  252       0\n3  253       1\n4  254       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>250</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>251</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>252</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>253</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>254</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}