{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# В этом ноутбуке происходит обучение на новых данных, к сожалению, проверка submit все также сталась на старых данных.\n\n## Именно поэтому модели из этого ноутбка не будут совпадать с моделями в презентации","metadata":{}},{"cell_type":"code","source":"%%capture\n\nimport sys\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# %load_ext autoreload\n# %autoreload 2\n\nPIP_PATH = Path(sys.executable).parent / 'pip3'\n\n!$PIP_PATH install \\\n    matplotlib \\\n    plotly \\\n    seaborn \\\n    pandas \\\n    lightgbm \\\n    xgboost \\\n    eli5 \\\n    shap \\\n    numpy \\\n    mlxtend \\\n    statsmodels \\\n    catboost \\\n    'imbalanced-learn' \\\n    'umap-learn[plot]'","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:12:09.148678Z","iopub.execute_input":"2021-12-21T17:12:09.149762Z","iopub.status.idle":"2021-12-21T17:12:26.537572Z","shell.execute_reply.started":"2021-12-21T17:12:09.149584Z","shell.execute_reply":"2021-12-21T17:12:26.536725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/c/dont-overfit-ii/discussion/169948\nDATA_DIR = Path('../input/dont-overfit-ii')\nlist(DATA_DIR.glob('*'))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:14:50.276164Z","iopub.execute_input":"2021-12-21T17:14:50.276813Z","iopub.status.idle":"2021-12-21T17:14:50.292937Z","shell.execute_reply.started":"2021-12-21T17:14:50.276729Z","shell.execute_reply":"2021-12-21T17:14:50.292341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom sklearn.model_selection import (\n    train_test_split, \n    StratifiedKFold, \n    KFold, \n    cross_val_score, \n    GridSearchCV, \n    RepeatedStratifiedKFold, \n    LeaveOneOut,\n    StratifiedShuffleSplit\n)\nfrom sklearn.preprocessing import StandardScaler, KBinsDiscretizer, RobustScaler\nimport os\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport json\nimport ast\nimport time\nfrom sklearn import linear_model\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap\n\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.feature_selection import (\n    GenericUnivariateSelect, \n    SelectPercentile, \n    SelectKBest, \n    f_classif, \n    mutual_info_classif, \n    RFE\n)\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom catboost import CatBoostClassifier","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-12-21T17:14:52.011631Z","iopub.execute_input":"2021-12-21T17:14:52.012067Z","iopub.status.idle":"2021-12-21T17:14:52.027227Z","shell.execute_reply.started":"2021-12-21T17:14:52.012029Z","shell.execute_reply":"2021-12-21T17:14:52.026467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(DATA_DIR / 'train.csv')\ntest = pd.read_csv(DATA_DIR / 'test.csv')\ntrain.shape","metadata":{"_uuid":"1c971fbc1a1b8249045b120924058402a036e665","execution":{"iopub.status.busy":"2021-12-21T17:14:54.349252Z","iopub.execute_input":"2021-12-21T17:14:54.349546Z","iopub.status.idle":"2021-12-21T17:14:55.551047Z","shell.execute_reply.started":"2021-12-21T17:14:54.349514Z","shell.execute_reply":"2021-12-21T17:14:55.550517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:14:57.763286Z","iopub.execute_input":"2021-12-21T17:14:57.763984Z","iopub.status.idle":"2021-12-21T17:14:57.769363Z","shell.execute_reply.started":"2021-12-21T17:14:57.763949Z","shell.execute_reply":"2021-12-21T17:14:57.768538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:14:58.057215Z","iopub.execute_input":"2021-12-21T17:14:58.057604Z","iopub.status.idle":"2021-12-21T17:14:58.287512Z","shell.execute_reply.started":"2021-12-21T17:14:58.057571Z","shell.execute_reply":"2021-12-21T17:14:58.286682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"de\"></a>\n## Data exploration","metadata":{"_uuid":"7b40dd26ead2705ebf0058b0aa528c89a18aedbe"}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:14:58.500945Z","iopub.execute_input":"2021-12-21T17:14:58.501225Z","iopub.status.idle":"2021-12-21T17:14:58.5349Z","shell.execute_reply.started":"2021-12-21T17:14:58.501193Z","shell.execute_reply":"2021-12-21T17:14:58.534018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"67a26174603f6a28709b7e0431aa431832ae608d","execution":{"iopub.status.busy":"2021-12-21T17:14:58.699212Z","iopub.execute_input":"2021-12-21T17:14:58.699483Z","iopub.status.idle":"2021-12-21T17:14:58.928263Z","shell.execute_reply.started":"2021-12-21T17:14:58.699449Z","shell.execute_reply":"2021-12-21T17:14:58.927453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train.columns[2:]].std().plot(kind='hist');\nplt.title('Distribution of stds of all columns');","metadata":{"_uuid":"504b609f61494c21f8b078182e06191581ecb2a6","execution":{"iopub.status.busy":"2021-12-21T17:14:58.92969Z","iopub.execute_input":"2021-12-21T17:14:58.929908Z","iopub.status.idle":"2021-12-21T17:14:59.188184Z","shell.execute_reply.started":"2021-12-21T17:14:58.929884Z","shell.execute_reply":"2021-12-21T17:14:59.187431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train.columns[2:]].mean().plot(kind='hist');\nplt.title('Distribution of means of all columns');","metadata":{"_uuid":"b7b0f65d2d5c999a44a3f71e013b1b6a6ff08980","execution":{"iopub.status.busy":"2021-12-21T17:14:59.189674Z","iopub.execute_input":"2021-12-21T17:14:59.189884Z","iopub.status.idle":"2021-12-21T17:14:59.418291Z","shell.execute_reply.started":"2021-12-21T17:14:59.189858Z","shell.execute_reply":"2021-12-21T17:14:59.417474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we have no missing values\ntrain.isnull().any().any()","metadata":{"_uuid":"d205e01b009224a3189903e1858dd592fb222d2d","execution":{"iopub.status.busy":"2021-12-21T17:14:59.419813Z","iopub.execute_input":"2021-12-21T17:14:59.42005Z","iopub.status.idle":"2021-12-21T17:14:59.428262Z","shell.execute_reply.started":"2021-12-21T17:14:59.420023Z","shell.execute_reply":"2021-12-21T17:14:59.427408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Distributions of first 28 columns')\nplt.figure(figsize=(26, 24))\nfor i, col in enumerate(list(train.columns)[2:30]):\n    plt.subplot(7, 4, i + 1)\n    plt.hist(train[col])\n    plt.title(col)","metadata":{"_uuid":"30e64cca712542d662201263914d8fc25496563e","execution":{"iopub.status.busy":"2021-12-21T17:14:59.429651Z","iopub.execute_input":"2021-12-21T17:14:59.429891Z","iopub.status.idle":"2021-12-21T17:15:03.177958Z","shell.execute_reply.started":"2021-12-21T17:14:59.429864Z","shell.execute_reply":"2021-12-21T17:15:03.177318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"_uuid":"227daacd39977e5658c7e27db2686d8f65fdff3c","execution":{"iopub.status.busy":"2021-12-21T17:15:03.179315Z","iopub.execute_input":"2021-12-21T17:15:03.180992Z","iopub.status.idle":"2021-12-21T17:15:03.190118Z","shell.execute_reply.started":"2021-12-21T17:15:03.180958Z","shell.execute_reply":"2021-12-21T17:15:03.189419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this overview we can see the following things:\n* target is binary and has some disbalance: 36% of samples belong to 0 class;\n* values in columns are more or less similar;\n* columns have std of 1 +/- 0.1 (min and max values are 0.889, 1.117 respectively);\n* columns have mean of 0 +/- 0.15 (min and max values are -0.2, 0.1896 respectively);","metadata":{"_uuid":"89e9ed49ceff33d27cd1888336c3c46a38c5c8aa"}},{"cell_type":"markdown","source":"Let's have a look at correlations now!","metadata":{"_uuid":"06df27b43428261da7daf02e708b934519d78ac2"}},{"cell_type":"code","source":"corrs = train.corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrs = corrs[corrs['level_0'] != corrs['level_1']]\ncorrs.tail(10)","metadata":{"_uuid":"ae63462aa70238f0a2858de687dc7d2ae319589a","execution":{"iopub.status.busy":"2021-12-21T17:15:03.191576Z","iopub.execute_input":"2021-12-21T17:15:03.19189Z","iopub.status.idle":"2021-12-21T17:15:03.295508Z","shell.execute_reply.started":"2021-12-21T17:15:03.191849Z","shell.execute_reply":"2021-12-21T17:15:03.294795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that correlations between features are lower that 0.3 and the most correlated feature with target has correlation of 0.37. So we have no highly correlated features which we could drop, on the other hand we could drop some columns with have little correlation with the target.","metadata":{"_uuid":"d2d921a5d3bf606b88853988c10acad020685334"}},{"cell_type":"markdown","source":"<a id=\"bm\"></a>\n## Basic modelling","metadata":{"_uuid":"a4f28e1e3c847e2fe165034dd870154afb7fe939"}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\nX_train = train.drop(['id', 'target'], axis=1)\ny_train = train['target']\nX_test = test.drop(['id'], axis=1)\nn_fold = 5\nloo_folds = LeaveOneOut()\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\nrepeated_folds = RepeatedStratifiedKFold(n_splits=20, n_repeats=20, random_state=42)\n\nrandom_folds = StratifiedShuffleSplit(n_splits=12, test_size=0.35, train_size=0.65, random_state=42)\n\nscaler = StandardScaler()\n\n# X_train = scaler.fit_transform(X_train)\n# X_test = scaler.transform(X_test)\n\nX_train_splt,X_val,y_train_splt,y_val = train_test_split(X_train, y_train,\n                                           test_size=.25, random_state=42, shuffle=True,stratify=y_train)\n\nX_train = X_train.values\nX_test = X_test.values\n\nprint(X_train_splt.shape ,X_val.shape, y_train_splt.shape, y_val.shape)","metadata":{"_uuid":"8f3eef02d6beac1b76f88c75bb842da9a313f592","execution":{"iopub.status.busy":"2021-12-21T17:15:03.296593Z","iopub.execute_input":"2021-12-21T17:15:03.29694Z","iopub.status.idle":"2021-12-21T17:15:03.331714Z","shell.execute_reply.started":"2021-12-21T17:15:03.296898Z","shell.execute_reply":"2021-12-21T17:15:03.331122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Viz","metadata":{}},{"cell_type":"code","source":"import random\nrandom.seed(42)\n\nmost_corr_feats = train.corr()['target'][2:].sort_values().head(10).index.tolist()\ndfp = train[[\"id\", \"target\"]+most_corr_feats]\nsns.set(style=\"ticks\")\n\nsns.pairplot(dfp.drop(\"id\",1), hue='target');","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:15:03.332677Z","iopub.execute_input":"2021-12-21T17:15:03.333302Z","iopub.status.idle":"2021-12-21T17:15:28.215525Z","shell.execute_reply.started":"2021-12-21T17:15:03.333272Z","shell.execute_reply":"2021-12-21T17:15:28.214586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import umap \nimport umap.plot\n\n# mapper = umap.UMAP().fit(X_train)\n# umap.plot.points(mapper, labels=y_train)\n\n\ndef draw_umap(n_neighbors=15, min_dist=0.1, n_components=2, metric='euclidean', title=''):\n    fit = umap.UMAP(\n        n_neighbors=n_neighbors,\n        min_dist=min_dist,\n        n_components=n_components,\n        metric=metric\n    )\n    u = fit.fit_transform(X_train);\n    fig = plt.figure()\n    if n_components == 1:\n        ax = fig.add_subplot(111)\n        ax.scatter(u[:,0], range(len(u)), c=y_train)\n    if n_components == 2:\n#         ax = fig.add_subplot(111)\n#         ax.scatter(u[:,0], u[:,1], c=y_train)\n        umap.plot.points(fit, labels=y_train)\n    if n_components == 3:\n        ax = fig.add_subplot(111, projection='3d')\n        ax.scatter(u[:,0], u[:,1], u[:,2], c=y_train, s=100)\n    plt.title(title, fontsize=18)\n    \n    \ndraw_umap(\n    n_neighbors=20, \n    min_dist=1, \n    n_components=2, \n#     metric='cosine',\n    title='UMAP viz'\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:16:29.421069Z","iopub.execute_input":"2021-12-21T17:16:29.421346Z","iopub.status.idle":"2021-12-21T17:16:31.920192Z","shell.execute_reply.started":"2021-12-21T17:16:29.421317Z","shell.execute_reply":"2021-12-21T17:16:31.919336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=2, random_state=42)\n\nprincipalComponents = pca.fit_transform(scaler.fit_transform(X_train))\nprincipalDf = pd.DataFrame(data = principalComponents, \n                           columns = [\n                               'principal component 1', \n                               'principal component 2'\n                           ])\n\nfig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = [0, 1]\ncolors = ['r', 'g', ]\nfor target, color in zip(targets,colors):\n    indicesToKeep = y_train == target\n    ax.scatter(principalDf.loc[indicesToKeep, 'principal component 1']\n               , principalDf.loc[indicesToKeep, 'principal component 2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:16:36.622762Z","iopub.execute_input":"2021-12-21T17:16:36.623033Z","iopub.status.idle":"2021-12-21T17:16:36.96139Z","shell.execute_reply.started":"2021-12-21T17:16:36.623004Z","shell.execute_reply":"2021-12-21T17:16:36.960571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(random_state=42)\npca.fit(scaler.fit_transform(X_train))\ntmp = pd.DataFrame(pca.singular_values_)\ntmp /= tmp.sum()\ntmp.cumsum().plot()\nplt.title('PC components value')\nplt.xlabel('n_components')\nplt.ylabel('% of information')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:16:36.963007Z","iopub.execute_input":"2021-12-21T17:16:36.965991Z","iopub.status.idle":"2021-12-21T17:16:37.209586Z","shell.execute_reply.started":"2021-12-21T17:16:36.965952Z","shell.execute_reply":"2021-12-21T17:16:37.209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"code","source":"def generate_submission_file(prediction, name):\n    submission = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n    submission['target'] = prediction\n    submission.to_csv(Path('.') / f'{name}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:16:38.716407Z","iopub.execute_input":"2021-12-21T17:16:38.716937Z","iopub.status.idle":"2021-12-21T17:16:38.72147Z","shell.execute_reply.started":"2021-12-21T17:16:38.716902Z","shell.execute_reply":"2021-12-21T17:16:38.720663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score, make_scorer, confusion_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n\n\ndef print_metrics(pipeline,\n                  X_train=X_train_splt, X_val=X_val,\n                  y_train=y_train_splt, y_val=y_val):\n\n    perdt = pipeline.predict(X_train)\n    perdv = pipeline.predict(X_val)\n    cmt = confusion_matrix(y_train, perdt)\n    cmv = confusion_matrix(y_val, perdv)\n\n#     print('\\nTrain Aaccuracy =',accuracy_score(y_train, perdt) ,\n#           ' \\nValidation Aaccuracy =',accuracy_score(y_val, perdv))\n    print('---'*6)\n    print('AUC train: ',roc_auc_score(y_train, perdt) )\n    print('AUC Val: ',roc_auc_score(y_val,perdv) )\n    print()\n    print('MSE train: ', mean_squared_error(y_train, perdt))\n    print('MSE Val: ',   mean_squared_error(y_val, perdv))\n    print()\n    print('MAE train: ', mean_absolute_error(y_train, perdt))\n    print('MAE Val: ',   mean_absolute_error(y_val, perdv))\n    print()    \n    print('COS train: ', cosine_similarity(\n        y_train.values.reshape(1, -1), perdt.reshape(1, -1))[0][0])\n    print('COS Val: ',   cosine_similarity(\n        y_val.values.reshape(1, -1), perdv.reshape(1, -1))[0][0])\n    print()    \n    print('Euclidean train: ', euclidean_distances(\n        y_train.values.reshape(1, -1), perdt.reshape(1, -1))[0][0])\n    print('Euclidean Val: ',   euclidean_distances(\n        y_val.values.reshape(1, -1), perdv.reshape(1, -1))[0][0])\n    print()    \n    print('R2 train: ', r2_score(y_train, perdt))\n    print('R2 Val: ',   r2_score(y_val, perdv))\n    print()\n    print('Confusion matrix train: \\n',cmt)\n    print('Confusion matrix val: \\n',cmv)\n    print('---'*6)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:20:39.802133Z","iopub.execute_input":"2021-12-21T17:20:39.802753Z","iopub.status.idle":"2021-12-21T17:20:39.813803Z","shell.execute_reply.started":"2021-12-21T17:20:39.802714Z","shell.execute_reply":"2021-12-21T17:20:39.812848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(X, X_test, y, params=None, folds=random_folds, \n                model_type='sklearn', \n                averaging='usual',\n                model=None,\n                verbose=True,\n               ):\n    oof = np.zeros(len(X))\n    prediction = np.zeros(len(X_test))\n    scores = []\n    feature_importance = pd.DataFrame()\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        # print('Fold', fold_n, 'started at', time.ctime())\n        X_train, X_valid = X[train_index], X[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n            \n        if model_type == 'sklearn':\n            model = model\n            if params:\n                model.set_params(**params)\n#             print(model.get_params())\n            model.fit(X_train, y_train)\n            y_pred_valid = model.predict(X_valid).reshape(-1,)\n            \n            if verbose:\n                print_metrics(\n                    model,\n                    X_train=X_train,\n                    y_train=y_train,\n                    X_val=X_valid,\n                    y_val=y_valid,\n                )\n            score = roc_auc_score(y_valid, y_pred_valid)\n#             print(f'Fold {fold_n}. AUC: {score:.4f}.')\n#             print('')\n            \n            y_pred = model.predict_proba(X_test)[:, 1]\n                    \n        oof[valid_index] = y_pred_valid.reshape(-1,)\n        scores.append(roc_auc_score(y_valid, y_pred_valid))\n\n        if averaging == 'usual':\n            prediction += y_pred\n        elif averaging == 'rank':\n            prediction += pd.Series(y_pred).rank().values  \n    \n    prediction /= n_fold\n    if verbose: \n        print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    return oof, prediction, scores","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:16:39.95344Z","iopub.execute_input":"2021-12-21T17:16:39.954063Z","iopub.status.idle":"2021-12-21T17:16:39.963688Z","shell.execute_reply.started":"2021-12-21T17:16:39.954024Z","shell.execute_reply":"2021-12-21T17:16:39.962735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"# ?linear_model.LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:16:41.456355Z","iopub.execute_input":"2021-12-21T17:16:41.457238Z","iopub.status.idle":"2021-12-21T17:16:41.46021Z","shell.execute_reply.started":"2021-12-21T17:16:41.457184Z","shell.execute_reply":"2021-12-21T17:16:41.459678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nimport warnings\n\n# https://coderoad.ru/53784971/%D0%9A%D0%B0%D0%BA-%D0%BE%D1%82%D0%BA%D0%BB%D1%8E%D1%87%D0%B8%D1%82%D1%8C-ConvergenceWarning-%D1%81-%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E-sklearn\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:16:41.849987Z","iopub.execute_input":"2021-12-21T17:16:41.850389Z","iopub.status.idle":"2021-12-21T17:16:41.854583Z","shell.execute_reply.started":"2021-12-21T17:16:41.850359Z","shell.execute_reply":"2021-12-21T17:16:41.853805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('regression', linear_model.LogisticRegression(\n        random_state=42, \n        max_iter=500, \n        class_weight='balanced')\n    )\n])\n\n\ndef add_noise(np_array, noise_std=0.01):\n#     add a bit of noise to reduce overfitting\n    return np_array + np.random.normal(0, noise_std, np_array.shape)\n\n\nparam_grid = [\n#      LASSO\n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['liblinear'],\n    'regression__penalty' : ['l1'],\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__C' : np.logspace(1, 2, 10),\n    }, \n#     RIDGE\n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['liblinear'],\n    'regression__penalty' : ['l2'],\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__C' : np.logspace(0.5, 2, 10),\n    }, \n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['saga'],\n    'regression__penalty' : ['elasticnet'],\n    'regression__C' : np.logspace(0.5, 2, 10),\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__l1_ratio': np.logspace(-1, 0, 5)\n    }\n]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    verbose=1,\n    cv=n_fold, \n    scoring='roc_auc'\n)\n\ngrid_search.fit(add_noise(X_train), y_train)\n\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\nbest_params = grid_search.best_params_\n_, prediction_lr, scores_lr = train_model(add_noise(X_train), X_test, y_train, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True,\n                                            folds=random_folds)\ngenerate_submission_file(prediction_lr, 'pipeline_lr_v4')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:20:50.004045Z","iopub.execute_input":"2021-12-21T17:20:50.004302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"# ?SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('svm', SVC(random_state=42, probability=True))\n])\n\nbase_params = {\n    'svm__class_weight' : ['balanced', {0:2, 1:1}],\n    'svm__C': np.logspace(-1, 2, 10),\n    'scaler': [\n               StandardScaler(),  \n               RobustScaler(),\n#                KBinsDiscretizer(n_bins=25, strategy='quantile')\n              ],\n}\n\nparam_grid = [{\n    'svm__kernel': ['linear',],\n    **base_params\n}, \n    {\n    'svm__kernel': [ 'rbf',],\n    'svm__gamma': np.logspace(-4, 0, 5),\n    **base_params\n}, \n    {\n    'svm__kernel': ['sigmoid'],\n    'svm__gamma': np.logspace(-4, 0, 5),\n    'svm__coef0': np.logspace(-3, 1, 5),\n    **base_params\n}, \n    {\n\n    'svm__kernel': [ 'poly'],\n    'svm__degree': [3,5],\n    'svm__coef0': np.logspace(-3, 0, 5),\n    **base_params\n}]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    verbose=1,\n    cv=n_fold, \n    scoring='roc_auc'\n)\n\ngrid_search.fit(add_noise(X_train), y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\n# print_metrics(pipeline, grid_search.best_params_)\n\nbest_params = grid_search.best_params_\n_, predictions_svc, scores_svc = train_model(add_noise(X_train), X_test, y_train, \n                                     params=best_params, \n                                     model_type='sklearn', \n                                     model=pipeline, \n                                     verbose=True)\ngenerate_submission_file(predictions_svc, 'pipeline_svc')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forest","metadata":{}},{"cell_type":"code","source":"# ?RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('forest', RandomForestClassifier(random_state=42))\n])\n\nbase_params = {\n    'forest__class_weight' : [\n        'balanced', 'balanced_subsample'],\n    'forest__n_estimators': [150],\n    'forest__criterion': [\"entropy\"],\n    'forest__max_depth': [4, 5],\n    'forest__max_samples': [15, 20, 30, None],\n    'forest__ccp_alpha': [0.04, 0.1, 0.18],\n    'forest__max_features': [3, 4, 5],\n    'forest__max_leaf_nodes': [4, 6, 8, 10]\n}\n\n\nparam_grid = [{\n    **base_params\n}]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    cv=n_fold, \n    verbose=1,\n    scoring='roc_auc'\n)\n\ngrid_search.fit(X_train, y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\nbest_params = grid_search.best_params_\n_, predictions_forest, scores_forest = train_model(X_train, X_test, y_train, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True)\ngenerate_submission_file(predictions_forest, 'pipeline_forest')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RandomUnderSampling","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(random_state=42)\nX_resampled, y_resampled = rus.fit_resample(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('forest', RandomForestClassifier(random_state=42))\n])\n\nbase_params = {\n    'forest__class_weight' : [None, 'balanced_subsample'],\n    'forest__n_estimators': [20, 50, 150],\n    'forest__criterion': [\"entropy\"],\n    'forest__max_depth': [4, 5],\n    'forest__max_samples': [15, 20, 30, None],\n    'forest__ccp_alpha': [0.1, 0.18],\n    'forest__max_features': [3, 4, 5],\n    'forest__max_leaf_nodes': [4, 6, 8, 10]\n}\n\nparam_grid = [{\n    **base_params\n}]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    cv=n_fold, \n    verbose=1,\n#     scoring='roc_auc',\n    scoring='accuracy'\n)\n\ngrid_search.fit(X_resampled, y_resampled)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\nbest_params = grid_search.best_params_\n_, predictions_forest_under_sample, scores_forest_under_sample = train_model(\n    X_resampled, X_test, y_resampled, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True)\n\ngenerate_submission_file(predictions_forest_under_sample, 'pipeline_forest_under_sample')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LR","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('regression', linear_model.LogisticRegression(\n        random_state=42, \n        max_iter=500, \n        class_weight='balanced')\n    )\n])\n\n\ndef add_noise(np_array, noise_std=0.01):\n#     add a bit of noise to reduce overfitting\n    return np_array + np.random.normal(0, noise_std, np_array.shape)\n\n\nparam_grid = [\n#      LASSO\n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['liblinear'],\n    'regression__penalty' : ['l1'],\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__C' : np.logspace(1, 2, 10),\n    }, \n#     RIDGE\n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['liblinear'],\n    'regression__penalty' : ['l2'],\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__C' : np.logspace(0.5, 2, 10),\n    }, \n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['saga'],\n    'regression__penalty' : ['elasticnet'],\n    'regression__C' : np.logspace(0.5, 2, 10),\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__l1_ratio': np.logspace(-1, 0, 5)\n    }\n]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    verbose=1,\n    cv=n_fold, \n    scoring='roc_auc'\n)\n\ngrid_search.fit(add_noise(X_resampled), y_resampled)\n\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\nbest_params = grid_search.best_params_\n_, prediction_lr_under_sample, scores_lr_under_sample = train_model(\n    add_noise(X_resampled), X_test, y_resampled, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True,\n                                            folds=random_folds)\ngenerate_submission_file(prediction_lr_under_sample, 'pipeline_lr_under_sample')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVC","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.ensemble import RandomForestClassifier\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('svm', SVC(random_state=42, probability=True))\n])\n\nbase_params = {\n    'svm__class_weight' : [None],\n    'svm__C': np.logspace(1, 2, 10),\n    'scaler': [\n               StandardScaler(),  \n               RobustScaler(),\n#                KBinsDiscretizer(n_bins=25, strategy='quantile')\n              ],\n}\n\nparam_grid = [{\n    'svm__kernel': ['linear',],\n    **base_params\n}, \n{\n    'svm__kernel': [ 'rbf',],\n    'svm__gamma': np.logspace(-4, 0, 5),\n    **base_params\n}, \n    {\n    'svm__kernel': ['sigmoid'],\n    'svm__gamma': np.logspace(-4, 0, 5),\n    'svm__coef0': np.logspace(-3, 2, 10),\n    **base_params\n}, \n    {\n\n    'svm__kernel': [ 'poly'],\n    'svm__degree': [3,5],\n    'svm__coef0': np.logspace(-3, 0, 5),\n    **base_params\n}\n]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    verbose=1,\n    cv=n_fold, \n    scoring='roc_auc'\n)\n\ngrid_search.fit(X_resampled, y_resampled)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\n# print_metrics(pipeline, grid_search.best_params_)\n\nbest_params = grid_search.best_params_\n\n_, predictions_svc_under_sample, scores_svc_under_sample = train_model(\n                        X_resampled, X_test, y_resampled, \n                                     params=best_params, \n                                     model_type='sklearn', \n                                     model=pipeline, \n                                     verbose=True)\ngenerate_submission_file(predictions_svc_under_sample, 'pipeline_svc_under_sample')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"mlextend\"></a>\n# mutual_info_classif","metadata":{"_uuid":"cb5994704ef34d093e24d4a3983de73b6c98c1bd"}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, SCORERS ,auc, confusion_matrix,accuracy_score,recall_score,precision_score\nfrom sklearn.decomposition import PCA    \nfrom sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn import svm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi = mutual_info_classif(X_train, y_train, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selectedFeature  =  np.array( mi > 0.02)\nselected_cols = train.drop(['id', 'target'], axis=1).columns[selectedFeature]\nprint('number of selected columns',selectedFeature.sum())\nprint('number of selected columns', selected_cols)","metadata":{"_uuid":"46b0caca758e3864e8820e8e21af53a103890444","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features_train_X = train.drop(['id', 'target'], axis=1)[selected_cols].values\nselected_features_test_X = test.drop(['id'], axis=1)[selected_cols].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RandomForest","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.ensemble import RandomForestClassifier\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('forest', RandomForestClassifier(random_state=42))\n])\n\nbase_params = {\n    'forest__class_weight' : [None, 'balanced_subsample'],\n    'forest__n_estimators': [20, 50, 150],\n    'forest__criterion': [\"entropy\"],\n    'forest__max_depth': [4, 5],\n    'forest__max_samples': [15, 20, 30, None],\n    'forest__ccp_alpha': [0.1, 0.18],\n    'forest__max_features': [3, 4, 5],\n    'forest__max_leaf_nodes': [4, 6, 8, 10]\n}\n\nparam_grid = [{\n    **base_params\n}]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    cv=n_fold, \n    verbose=1,\n#     scoring='roc_auc',\n    scoring='accuracy'\n)\n\ngrid_search.fit(add_noise(selected_features_train_X), y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\nbest_params = grid_search.best_params_\n_, predictions_forest_mutual_info, scores_forest_mutual_info = train_model(\n    add_noise(selected_features_train_X), selected_features_test_X, y_train, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True)\n\ngenerate_submission_file(predictions_forest_mutual_info, 'pipeline_forest_mutual_info')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('regression', linear_model.LogisticRegression(\n        random_state=42, \n        max_iter=500, \n        class_weight='balanced')\n    )\n])\n\n\nparam_grid = [\n#      LASSO\n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['liblinear'],\n    'regression__penalty' : ['l1'],\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__C' : np.logspace(1, 2, 10),\n    }, \n#     RIDGE\n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['liblinear'],\n    'regression__penalty' : ['l2'],\n    'regression__tol' : np.logspace(-3, 0, 10),\n    'regression__C' : np.logspace(0.5, 2, 10),\n    }, \n    {\n    'scaler': [StandardScaler(), RobustScaler()],\n    'regression__solver': ['saga'],\n    'regression__penalty' : ['elasticnet'],\n    'regression__C' : np.logspace(0.1, 1, 10),\n    'regression__tol' : np.logspace(-3, 0, 15),\n    'regression__l1_ratio': np.logspace(-1, 0, 10)\n    }\n]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    verbose=1,\n    cv=n_fold, \n    scoring='roc_auc'\n)\n\ngrid_search.fit(add_noise(selected_features_train_X), y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\n\nbest_params = grid_search.best_params_\n_, prediction_lr_mutual_info, scores_lr_mutual_info = train_model(add_noise(selected_features_train_X),\n                                     selected_features_test_X, y_train, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True,\n                                            folds=random_folds\n                                    )\n\ngenerate_submission_file(prediction_lr_mutual_info, 'pipeline_lr_mutual_info_v4')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params = grid_search.best_params_\n_, _, _ = train_model(add_noise(selected_features_train_X),\n                                     selected_features_test_X, y_train, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True,\n                                            folds=KFold(n_splits=2)\n                                    )","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVC","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\ndefault_params = dict(\n    class_weight='balanced',\n    kernel='linear'\n)\n\npipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('svm', SVC(random_state=42, probability=True))\n])\n\nbase_params = {\n    'svm__class_weight' : ['balanced'],\n    'svm__C': np.logspace(-3, 0, 10),\n}\n\nparam_grid = [{\n    'svm__kernel': ['linear',],\n    'svm__class_weight' : ['balanced'],\n    'svm__C': np.logspace(-3, 0, 10),\n}, {\n    'svm__kernel': [ 'rbf', 'sigmoid'],\n    'svm__gamma': np.logspace(-4, 0, 10),\n    'svm__class_weight' : ['balanced'],\n    'svm__C': np.logspace(-3, 0, 10),\n}, {\n    'svm__kernel': [ 'poly',],\n    'svm__degree': [2,3,],\n    'svm__coef0': np.logspace(-3, 0, 10),\n    'svm__class_weight' : ['balanced'],\n    'svm__C': np.logspace(-3, 0, 10),\n}]\n\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    cv=n_fold, \n    scoring='roc_auc',\n    verbose=1,\n    return_train_score=True\n)\n\n\ngrid_search.fit(selected_features_train_X, y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\n\nbest_params = grid_search.best_params_\n_, predictions_svc_mutual_info, scores_svc_mutual_info = train_model(\n                                            selected_features_train_X, \n                                            selected_features_test_X, y_train, \n                                            params=best_params, \n                                            model_type='sklearn', \n                                            model=pipeline, verbose=True)\ngenerate_submission_file(predictions_svc_mutual_info, 'pipeline_svc_mutual_info')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\npprint({'svm__C': 0.0021544346900318843, 'svm__class_weight': 'balanced', 'svm__kernel': 'linear'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"model\"></a>\n# Fast Modelling","metadata":{"_uuid":"1ebbe316febc785339dde063c927c297d124ef72"}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\noof_gnb, prediction_gnb, scores_gnb = train_model(\n    X_train, X_test, y_train,\n    model_type='sklearn', model=gnb)\ngenerate_submission_file(prediction_gnb, 'pipeline_GaussianNB')","metadata":{"_uuid":"2f035ad28718fe9f932b4ea63637a3ac3c1bd9d1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nabc = AdaBoostClassifier()\n\nparameter_grid = {'n_estimators': [5, 10, 20, 50, 100],\n                  'learning_rate': [0.001, 0.01, 0.1, 1.0, 10.0]\n                 }\n\ngrid_search = GridSearchCV(abc, param_grid=parameter_grid, cv=folds, scoring='roc_auc')\ngrid_search.fit(X_train, y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\nabc = AdaBoostClassifier(**grid_search.best_params_)\noof_abc, prediction_abc, scores_abc = train_model(\n    X_train, X_test, y_train, params=grid_search.best_params_, \n    model_type='sklearn', model=abc, verbose=True)\ngenerate_submission_file(prediction_abc, 'pipeline_AdaBoostClassifier')","metadata":{"_uuid":"d00ff4a78c464d35a25c101c4f2f03efc453c615","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\netc = ExtraTreesClassifier()\n\nparameter_grid = {'n_estimators': [10, 50, 100, 1000],\n                  'max_depth': [None, 3, 5, 15]\n                 }\n\ngrid_search = GridSearchCV(etc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\netc = ExtraTreesClassifier()\noof_etc, prediction_etc, scores_etc = train_model(\n    X_train, X_test, y_train, params=grid_search.best_params_, model_type='sklearn', \n    model=etc, verbose=True)\n\ngenerate_submission_file(prediction_etc, 'pipeline_ExtraTreesClassifier')","metadata":{"_uuid":"f57a2c0f0da71197a1163a8bed02efc0c8d89e3b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.gaussian_process import GaussianProcessClassifier\ngpc = GaussianProcessClassifier()\noof_gpc, prediction_gpc, scores_gpc = train_model(X_train, X_test, y_train, \n                                                   model_type='sklearn', model=gpc)\n\ngenerate_submission_file(prediction_gpc, 'pipeline_GaussianProcessClassifier')","metadata":{"_uuid":"fd36b69df66bb55c2506eb40bf42fd64698d583f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknc = KNeighborsClassifier()\n\nparameter_grid = {'n_neighbors': [2, 3, 5, 10, 20],\n                  'weights': ['uniform', 'distance'],\n                  'leaf_size': [5, 10, 30]\n                 }\n\ngrid_search = GridSearchCV(knc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\nknc = KNeighborsClassifier(**grid_search.best_params_)\noof_knc, prediction_knc, scores_knc = train_model(\n    X_train, X_test, y_train, model_type='sklearn', model=knc)\ngenerate_submission_file(prediction_knc, 'pipeline_KNeighborsClassifier')","metadata":{"_uuid":"4e6940fd73f9064824626c17e0abd117824bf261","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nbnb = BernoulliNB()\n\nparameter_grid = {'alpha': [0.0001, 1, 2, 10]\n                 }\n\ngrid_search = GridSearchCV(bnb, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\nbnb = BernoulliNB(**grid_search.best_params_)\noof_bnb, prediction_bnb, scores_bnb = train_model(X_train, X_test, y_train, \n                                                  model_type='sklearn', model=bnb)\ngenerate_submission_file(prediction_bnb, 'pipeline_BernoulliNB')","metadata":{"_uuid":"ad1c850d35de23d06d5c267b5c3082188d1f9999","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgd = linear_model.SGDClassifier(eta0=1, max_iter=1000, tol=0.0001)\n\nparameter_grid = {'loss': ['log', 'modified_huber'],\n                  'penalty': ['l1', 'l2', 'elasticnet'],\n                  'alpha': [0.001, 0.01],\n                  'l1_ratio': [0, 0.15, 0.5, 1.0],\n                  'learning_rate': ['optimal', 'invscaling', 'adaptive']\n                 }\n\ngrid_search = GridSearchCV(sgd, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\nsgd = linear_model.SGDClassifier(eta0=1, tol=0.0001, **grid_search.best_params_)\noof_sgd, prediction_sgd, scores_sgd = train_model(\n    X_train, X_test, y_train, model_type='sklearn', model=sgd)\n\ngenerate_submission_file(prediction_sgd, 'pipeline_SGD')","metadata":{"_uuid":"54452c184551d9d2ad94f4dc468f92e75cc3f984","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8));\nscores_df = pd.DataFrame({'LogisticRegression': scores_lr})\nscores_df['LogisticRegressionMutualInfo'] = scores_lr_mutual_info\nscores_df['LogisticRegressionUnderSample'] = scores_lr_under_sample\n\nscores_df['SVC'] = scores_svc\nscores_df['SVCMutualInfo'] = scores_svc_mutual_info\nscores_df['SVCUnderSample'] = scores_svc_under_sample\n\nscores_df['RandomForestClassifier'] = scores_forest\nscores_df['RandomForestClassifierUnderSample'] = scores_forest_under_sample\nscores_df['RandomForestClassifierMutualInfo'] = scores_forest_mutual_info\n\nscores_df['GaussianNB'] = scores_gnb\nscores_df['AdaBoostClassifier'] = scores_abc\nscores_df['ExtraTreesClassifier'] = scores_etc\nscores_df['GaussianProcessClassifier'] = scores_gpc\nscores_df['KNeighborsClassifier'] = scores_knc\nscores_df['BernoulliNB'] = scores_bnb\nscores_df['SGDClassifier'] = scores_sgd\n\nsns.boxplot(data=scores_df);\nplt.xticks(rotation=45);","metadata":{"_uuid":"2335b870061080430fc25c9e99111357088824b8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SGD Shap","metadata":{}},{"cell_type":"code","source":"explainer = shap.LinearExplainer(sgd, X_train)\nshap_values = explainer.shap_values(X_train)\n\nshap.summary_plot(shap_values, X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eli5.show_weights(sgd, top=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}