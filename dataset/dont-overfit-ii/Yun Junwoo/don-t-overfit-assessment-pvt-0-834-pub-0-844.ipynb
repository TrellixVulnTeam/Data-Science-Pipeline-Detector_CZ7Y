{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Note\n\nI have discovered that kaggle has new data set but using older data for evaluation\n\nThus, the competition scores wrongly.\n\nThat's why I am using old version data for training.\n\n### discussion about this issue\n\nhttps://www.kaggle.com/c/dont-overfit-ii/discussion/169948"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import cross_val_score\nfrom tqdm import tqdm\nfrom scipy.stats import ks_2samp\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = pd.read_csv('../input/dont-overfit-ii/train.csv', index_col = 'id') # new data\n#test = pd.read_csv('../input/dont-overfit-ii/test.csv', index_col = 'id') # new data\n\ntrain = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/train.csv', index_col = 'id') # old data\ntest = pd.read_csv('../input/older-dataset-for-dont-overfit-ii-challenge/test.csv', index_col = 'id') # old data\ntrain.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train['target']\ntrain = train.drop(columns='target')\ntrain.head(4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(range(2), (train.shape[0], test.shape[0]), align='center', alpha=0.8)\nplt.xticks(range(2), ('train','test'))\nplt.ylabel('Number of data') \nplt.title('Can we avoid overfitting')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor i in range(5):\n    for j in range(5):\n        plt.subplot(5,5,5*i+j+1)\n        plt.hist(test[str(5*i+j)],bins=100)\n        plt.title('Column '+str(5*i+j))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You could see all caraible columns has gaussian distribution\n# with mean 0 and std 1 \n# But will there any differnece with test data?\n\nprint(train.mean().sum()/300)\nprint(train.std().sum()/300)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from kernal  \"https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data\"\n\ndef get_diff_columns(train_df, test_df, show_plots=True, show_all=False, threshold=0.1):\n    \"\"\"Use KS to estimate columns where distributions differ a lot from each other\"\"\"\n\n    # Find the columns where the distributions are very different\n    diff_data = []\n    for col in tqdm(train_df.columns):\n        statistic, pvalue = ks_2samp(\n            train_df[col].values, \n            test_df[col].values\n        )\n        if pvalue > 0.05 and np.abs(statistic) < threshold:\n            diff_data.append({'feature': col, 'p': np.round(pvalue, 5), 'statistic': np.round(np.abs(statistic), 2)})\n\n    # Put the differences into a dataframe\n    diff_df = pd.DataFrame(diff_data).sort_values(by='statistic', ascending=False)\n    print(f\"number of features with diff distribution : {len(diff_df)}\")\n    if show_plots:\n        # Let us see the distributions of these columns to confirm they are indeed different\n        n_cols = 5\n        n_rows = 5\n        _, axes = plt.subplots(n_rows, n_cols, figsize=(20, 3*n_rows))\n        axes = [x for l in axes for x in l]\n\n        # Create plots\n        for i, (_, row) in enumerate(diff_df.iterrows()):\n            if i >= len(axes):\n                break\n            extreme = np.max(np.abs(train_df[row.feature].tolist() + test_df[row.feature].tolist()))\n            train_df.loc[:, row.feature].apply(np.log1p).hist(\n                ax=axes[i], alpha=0.5, label='Train', density=True,\n                bins=np.arange(-extreme, extreme, 0.25)\n            )\n            test_df.loc[:, row.feature].apply(np.log1p).hist(\n                ax=axes[i], alpha=0.5, label='Test', density=True,\n                bins=np.arange(-extreme, extreme, 0.25)\n            )\n            axes[i].set_title(f\"Statistic = {row.statistic}, p = {row.p}\")\n            axes[i].set_xlabel(f'Log({row.feature})')\n            axes[i].legend()\n\n        plt.tight_layout()\n        plt.show()\n        \n    return diff_df\n\n# Get the columns which differ a lot between test and train\ndiff_df = get_diff_columns(train, test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As distribution of train and test are different, we use roboust scaler for scaling\n\ndata = RobustScaler().fit_transform(np.concatenate((train, test), axis=0))\ntrain = data[:250]\ntrain += np.random.normal(0, 0.01, train.shape)\ntest = data[250:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression(class_weight='balanced', solver='liblinear', penalty ='l1', C= 0.1, max_iter=10000)\nclf.fit(train, train_y)\nprint(f'5-fold val score : {cross_val_score(clf, train, train_y, cv=5)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(train, train_y)\nans = clf.predict_proba(test)\nans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/dont-overfit-ii/sample_submission.csv')\nsubmit['target'] = ans[:,1]\nsubmit.to_csv('submit.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}