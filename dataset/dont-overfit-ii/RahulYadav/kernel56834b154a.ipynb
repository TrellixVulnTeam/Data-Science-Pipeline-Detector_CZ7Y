{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"background-image:'img/backimage.png';padding:65px\">\n    <h1 style=\"position: right;left:0px;font-size:50px;top:0px;bottom:0px\"><u>Don't Overfit II</u></h1>\n    <h1 style=\"position: right;left:0px;font-size:25px;top:0px;bottom:0px\"><u>A Fistful of Samples</u></h1>\n</div>\n\n<h1 style=\"font-size:30px;padding:10px\"><u>1. Problem Overview:</u></h1>\n<p></p>\n<p >This problem is Kaggle's Playground Prediction Competition (<a href=\"https://www.kaggle.com/c/dont-overfit-ii/overview\">link</a>). This extension of “Don’t Overfit!”, objective of this study is to create strategies and techniques for modelling ML solutions robust to overfitting.</p>\n<p>The study is related to other domain data such as medical data where we have very small samples of given instances/classes. Training data have 250 training samples and 300 continuous variables (features), test data consist 19750 samples.</p>\n\n<h1 style=\"font-size:30px;padding:10px\"><u>2. Data avaiable.</u></h1>\n<p></p>\n<p >The there are three files available:</p>\n<ol>\n    <li><u>train.csv:</u> &nbsp;&nbsp;&nbsp;&nbsp; Contain 250 training exapmle and 300 features with column id and target (class labels)</li>\n    <li><u>test.csv:</u> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Contain 19750 training exapmle and 300 features with column id </li>\n    <li><u>sample.csv:</u> &nbsp;Conatain sample format for submission</li>\n</ol>\n\n<h1 style=\"font-size:30px;padding:10px\"><u>3. Proposed Workflow:</u></h1>\n<p><p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing graph lib.\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# lib to read data and mathematical operations \nimport pandas as pd\nimport numpy as np\n\n# Libaries for featureengg. and ML\n# Preprocessing Scaling features\nfrom sklearn.preprocessing import MinMaxScaler,RobustScaler,StandardScaler,Normalizer\n# library for feature selection\nfrom sklearn.model_selection import StratifiedKFold,RepeatedKFold,RepeatedStratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom mlxtend.feature_selection import SequentialFeatureSelector as sfs\n# for ml model to be used for feature selection\nfrom sklearn.linear_model import LogisticRegression,Lasso\n# metrics for evaluate the prediction\nfrom sklearn.metrics import roc_auc_score,make_scorer\n\n# for training model\nfrom sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, cross_val_score\n\n# to Ignore warnings\nimport warnings; warnings.simplefilter('ignore')\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"font-size:30px;\"><u>5. Read Data: </u></h1>\n<p></p>\n<p>In this section :</p>\n<ol>\n    <li>Read train and test data </li>\n    <li>Compare Train and Test Data size </li>\n    <li>Analysis Train data</li>\n    <ol type='a'>\n         <li>Look for NONE values (if found replace them with approperiate values)</li>\n        <li>Total Data Points and features</li>\n        <li>Coorelation between features</li>\n        <li>Class Labels in dataset</li>\n        <li>Variables Distribustion</li>\n    </ol>\n</ol>\n\n\n\n<h3>References used in this section are follows</h3>\n<p>[1] https://www.tutorialspoint.com/matplotlib/matplotlib_pie_chart.htm : for ploting pi charts</p> \n<p>[2] https://seaborn.pydata.org/examples/many_pairwise_correlations.html : for finding correraltion between matrices</p>\n<p>[3] https://www.kaggle.com/praxitelisk/don-t-overfit-ii-eda-ml : for ploting variable pdf distribution</p>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h3>5.1 Read train and test data</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the training data\ndata = pd.read_csv('../input/dont-overfit-ii/train.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating label matrics\ntarget = data.target.values.astype(int)\n# removing id and target coulumns for preparing training data \ntrain_data = data.drop(columns=['id','target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading and creating test data\ntest_data = pd.read_csv('../input/dont-overfit-ii/test.csv')\ntest_data = test_data.drop(columns='id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>5.2 Campare Train and Test data size</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# using ref [1]\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\nlangs = ['Train Data', 'Test Data']\nstudents = [train_data.shape[0],test_data.shape[0]]\nax.pie(students, labels = langs,autopct='%1.2f%%')\nplt.title('Train and Test data distribution')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h5><b><u>Note:</u>Only 1.25% data is avaialable for training and rest 98.75% is for testing</b><h5>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h3>5.3 Analysing Training Data</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h3>5.3.A. Looking for missing values </h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are \"',data.isna().sum().sum(),'\" missing values in data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>5.3.B. Total Data Points and features </h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total training samples \\t: {}\".format(train_data.shape[0]))\nprint(\"Total features \\t\\t: {}\".format(train_data.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('All features have {} data type'.format(list(train_data.dtypes)[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>5.3.C. Coorelation between features </h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ref [2]\n# finding correlation \ncorr = train_data.corr().abs()\nupper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.5 and 0.2\ntop_50 = [column for column in upper.columns if any(upper[column] > 0.50)]\ntop_20 = [column for column in upper.columns if any(upper[column] > 0.20)]\n\n\nprint('There {:0.2f}% feature have more than 0.5 correlation and {}% features have more than 0.2 correlation'.format((len(top_50)/train_data.shape[1])*100,(len(top_20)/train_data.shape[1])*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrs = data.corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrs = corrs[corrs['level_0'] == 'target']\ncorrs.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_corr = list(corrs.level_1[-31:-1].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target_corr.remove('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(target_corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>5.3.D. Class Labels in dataset </h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels, counts = np.unique(target,return_counts=True)\nprint('Total class labels : {}\\n'.format(len(labels)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\nlangs = ['0', '1']\nstudents = [183,67]\nax.pie(students, labels = langs,autopct='%1.2f%%')\nplt.title('Target Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>5.3.E. Variable distribution </h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# using ref [3]\nprint('\\t\\t\\t\\tFeature Distribution')\nprint('-'*100)\n\nplt.figure(figsize=(30, 200))\nplt.subplots_adjust(hspace=0.5,wspace=0.1)\nfor i, col in enumerate(data.columns[2:]):\n    plt.subplot(50, 6, i + 1)\n    sns.kdeplot(data.loc[data['target'] == 1, col], shade=True, label='1')\n    sns.kdeplot(data.loc[data['target'] == 0, col], shade=True, label='0')\n    plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"font-size:30px;\"><u>6. Stand. Train Data: </u></h1>\n<p></p>\n<p>In this Data is stand./scaled using the ref [4] and following image is also taken from ref [4]:</p>\n<img src=\"img/scale.png\" alt=\"Workflow\">\n\n\n<h3>References used in this section are follows</h3>\n<p>[4] https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02 </p> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_std_norm(train,test,col,scaler=None):\n    \"\"\"\n    This function is used to scale features of train and test data.\n    INPUT:\n        train : Training data (data-frame)\n        test  : Test data (data-frame)\n        scaler: Scaling method (sklearn preprocessing methods) to be used. The options are as follows:\n                a. minMax        : MinMaxScaler \n                b. robustScaler  : RobustScaler \n                c. stdScaler     : StandardScaler\n                d. normalization : Normalizer\n                e. None(default) : No Scaler selected\n    OUTPUT:\n        Xtrain : Scaled training data\n        Xtest  : Scaled testing data\n    \"\"\"\n    if scaler =='minMax':\n        print('Scaling Data Using MinMax Scaler ...')\n        mm_scaler = MinMaxScaler()\n        mm_scaler = mm_scaler.fit(train[col])\n        Xtrain = mm_scaler.transform(train[col])\n        Xtest = mm_scaler.transform(test[col])\n    elif scaler =='robustScaler':\n        print('Scaling Data Using RobustScaler Scaler ...')\n        rs_scaler = RobustScaler()\n        rs_scaler = rs_scaler.fit(train[col])\n        Xtrain = rs_scaler.transform(train[col])\n        Xtest = rs_scaler.transform(test[col])\n    elif scaler =='stdScaler':\n        print('Scaling Data Using StandardScaler Scaler ...')\n        ss_scaler = StandardScaler()\n        ss_scaler = ss_scaler.fit(train[col])\n        Xtrain = ss_scaler.transform(train[col])\n        Xtest = ss_scaler.transform(test[col])\n    elif scaler =='normalization':\n        print('Scaling Data Using Normalizing Scaler ...')\n        n_scaler = Normalizer()\n        n_scaler = n_scaler.fit(train[col])\n        Xtrain = n_scaler.transform(train[col])\n        Xtest = n_scaler.transform(test[col])\n    else:\n        print('No scaler selected...')\n        \n        return train,test\n    return pd.DataFrame(Xtrain,columns=col),pd.DataFrame(Xtest,columns=col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col =list(train_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_mm,test_mm=feature_std_norm(train_data,test_data,col,scaler='minMax')\ntrain_rs,test_rs=feature_std_norm(train_data,test_data,col,scaler='robustScaler')\ntrain_ss,test_ss=feature_std_norm(train_data,test_data,col,scaler='stdScaler')\ntrain_nn,test_nn=feature_std_norm(train_data,test_data,col,scaler='normalization')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparing Sacled feature distribution (feature 0 only)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data[['target','0']]\nfeatures['mm_0'] = train_mm['0']\nfeatures['rs_0'] = train_rs['0']\nfeatures['ss_0'] = train_ss['0']\nfeatures['nn_0'] = train_nn['0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features.head()\n# using ref [3]\nprint('\\t\\t\\t\\tScaled Feature Distribution')\nprint('-'*100)\n\nplt.figure(figsize=(30, 7))\nplt.subplots_adjust(hspace=0.5,wspace=0.1)\nfor i, col in enumerate(features.columns[1:]):\n    plt.subplot(1, 5, i + 1)\n    sns.kdeplot(features.loc[features['target'] == 1, col], shade=True, label='1')\n    sns.kdeplot(features.loc[features['target'] == 0, col], shade=True, label='0')\n    plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The distribution of data has not changed much ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"font-size:30px;\"><u>6. Feature Selection: </u></h1>\n<p></p>\n<p>Following two methods were used for feature selection</p>\n<ol>\n    <li>Recursive Feature Elimination and cross-validated selection (RFE)</li>\n    <li>Forwad Feature Selection (FFS) </li>\n</ol>\n\n<p><b>RFE</b>: Scikit-learn is used for RFE implementation with 5 fold (Stratification) and selected top 20 features using. Doumentation is available <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html\">here</a>.</p>\n\n<p><b>FFS</b>: Mlxtend is used for FFS implementation with 5 fold (Stratification) and selected top 20 features usinng ref. [5]. Documentation is available<a href=\"http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.feature_selection/#sequentialfeatureselector\">here</a>.</p>\n\n<p>For selecting features i have used simple linear model (logistic regression with L1 reg. balanced class weight) since training data is small data and for evaluating auc is used [6]. <p>\n    \n<p>For Every possible combination data experimental data was genrated as follows:</p>\n    \n<img src=\"img/EC.jpg\" alt=\"Workflow\" height=\"842\" width=\"642\">\n\n\n<h3>References used in this section are follows</h3>\n<p>[5] https://www.kdnuggets.com/2018/06/step-forward-feature-selection-python.html </p> \n<p>[6] https://www.kaggle.com/iloveyyp/svmtest </p> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# training models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ref:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# robust_roc_auc = make_scorer(scoring_roc_auc)\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/enespolat/grid-search-with-logistic-regression\nparam_model1 ={\"C\":[0.2, 0.25, 0.27, 0.29, 0.31, 0.33, 0.35, 0.37], \"penalty\":[\"l1\"],\n               'tol'   : [0.0001, 0.00011, 0.00009],'solver':['liblinear'],'max_iter':[500]}\n\n#https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\nparam_model3 = {'min_child_weight': [1,2,3],\n                'learning_rate':[0.01,0.05,0.1,0.5,1],\n                'colsample_bytree': [0.2,0.4,0.5],\n                'max_depth': [2,3,4,5],\n                'n_estimators':[5,10,20,50,100]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state=234587\nmodel1 = LogisticRegression(class_weight='balanced',random_state=random_state) \nmodel3 = XGBClassifier(objective='binary:logistic',random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data\nX = train_data.values\ny = target\ntest = test_data.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score, make_scorer","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n_fold = 20\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\nrepeated_folds = RepeatedStratifiedKFold(n_splits=20, n_repeats=20, random_state=42)\nr2_threshold = 0.185\nfrom imblearn.over_sampling import SMOTE\n\ndef train_model(X, X_tests, y, params, text,folds=folds, averaging='usual', model=None,r2_threshold=r2_threshold,feature_selection=True):\n    prediction = np.zeros(len(X_tests))\n    scores = []\n    \n    if feature_selection:\n        grid_search = GridSearchCV(model, param_grid=params, verbose=0, n_jobs=-1, scoring='roc_auc', cv=20)\n        grid_search.fit(X,y)\n        feature_selector = RFECV(grid_search.best_estimator_, min_features_to_select=12, scoring='roc_auc',\n                                 step=15, verbose=0, cv=20, n_jobs=-1)\n\n        \n    print(\"~\"*120)\n    print('\\t\\t\\t\\t\\t',text)\n    print('-'*120,'\\n')\n    print('\\t\\tVal. scores for each folds and stacking status...')\n    print('-'*120)\n    print(\"  fold   | val_mse  |  val_mae  |  val_roc  |  val_r2    \")\n    print(\"----------------------------------------------------------\")\n    \n        \n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        # print('Fold', fold_n, 'started at', time.ctime())\n        X_train, X_valid = X[train_index], X[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n        \n        if feature_selection:\n            feature_selector.fit(X_train, y_train)\n            X_train  = feature_selector.transform(X_train)\n            X_valid  = feature_selector.transform(X_valid)\n            X_test   = feature_selector.transform(X_tests)\n            model    = feature_selector.estimator_\n        \n        \n        grid_search = GridSearchCV(model, param_grid=params, n_jobs=-1, scoring='roc_auc', cv=20)\n        grid_search.fit(X_train, y_train)\n#         lsvc = \n            \n        model = grid_search.best_estimator_\n#         print(model)\n        model.fit(X_train, y_train)\n        y_pred_valid = model.predict(X_valid).reshape(-1,)\n#         score = roc_auc_score(y_valid, y_pred_valid)\n        # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n        # print('')\n        \n        val_mse = mean_squared_error(y_valid, y_pred_valid)\n        val_mae = mean_absolute_error(y_valid, y_pred_valid)\n        val_roc = roc_auc_score(y_valid, y_pred_valid)\n        val_r2  = r2_score(y_valid, y_pred_valid)\n\n#         y_pred = model.predict_proba(X_test)[:, 1]\n            \n#         oof[valid_index] = y_pred_valid.reshape(-1,)\n#         scores.append(roc_auc_score(y_valid, y_pred_valid))\n#         print('ROC {}: {:.4f}.'.format(fold_n, roc_auc_score(y_valid, y_pred_valid)))\n#         if averaging == 'usual':\n#             prediction += y_pred\n#         elif averaging == 'rank':\n#             prediction += pd.Series(y_pred).rank().values\n        if val_r2 > r2_threshold:\n            message = '<-- OK - Stacking'\n            y_pred = model.predict_proba(X_test)[:, 1]\n#             oof[valid_index] = y_pred_valid.reshape(-1,)\n            score = roc_auc_score(y_valid, y_pred_valid)\n            \n            scores.append(roc_auc_score(y_valid, y_pred_valid))\n            if averaging == 'usual':\n                prediction += y_pred\n            elif averaging == 'rank':\n                prediction += pd.Series(y_pred).rank().values\n        else:\n            message = '<-- skipping'\n            \n        print(\"{:2}       | {:.4f}   |  {:.4f}   |  {:.4f}   |  {:.4f}    \\t{}   \".format(fold_n, val_mse, val_mae, val_roc, val_r2,message))\n    \n    \n    \n    prediction /= n_fold\n    if prediction.sum()>0:\n        print('-'*50)\n        print('CV mean score of model after folds: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n        print()\n        sub = pd.read_csv('../input/dont-overfit-ii/sample_submission.csv')\n        sub['target']=prediction\n        sub.to_csv('{}.csv'.format(text),index=False)\n        \n        print('\\n Result : Created Submission file - \"{}.csv\"'.format(text))\n        print('_'*120,'\\n\\n')\n    else:\n        print('\\n Results Discarding the current ML agorithm - because Threshod cretria not meet')\n        print('_'*120,'\\n\\n')\n    \n    return prediction, scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Models","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"_,s1a = train_model(train_rs.values,test_rs.values,y, text='Experiment-1a',params=param_model1, model=model1,feature_selection=True)\n\n_,s1b = train_model(train_rs[target_corr].values,test_rs[target_corr].values,y, text='Experiment-1b',params=param_model1, model=model1,feature_selection=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# with stats and distances","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def with_statistics(X):\n    statistics = pd.DataFrame()\n    statistics['mean']   = X.mean(axis=1)\n    statistics['kurt']   = X.kurt(axis=1)\n    statistics['mad']    = X.mad(axis=1)\n    statistics['median'] = X.median(axis=1)\n    statistics['max']    = X.max(axis=1)\n    statistics['min']    = X.min(axis=1)\n    statistics['skew']   = X.skew(axis=1)\n    statistics['sem']    = X.sem(axis=1)\n    sin_temp = np.sin(X)\n    cos_temp = np.cos(X)\n    tan_temp = np.tan(X)\n    statistics['mean_sin'] = np.mean(sin_temp, axis=1)\n    statistics['mean_cos'] = np.mean(cos_temp, axis=1)\n    statistics['mean_tan'] = np.mean(tan_temp, axis=1)\n    # Hyperbolic FE\n    sinh_temp = np.sinh(X)\n    cosh_temp = np.cosh(X)\n    tanh_temp = np.tanh(X)\n    statistics['mean_sinh'] = np.mean(sin_temp, axis=1)\n    statistics['mean_cosh'] = np.mean(cos_temp, axis=1)\n    statistics['mean_tanh'] = np.mean(tan_temp, axis=1)\n    # Exponents FE\n    exp_temp = np.exp(X)\n    expm1_temp = np.expm1(X)\n    exp2_temp = np.exp2(X)\n    statistics['mean_exp'] = np.mean(exp_temp, axis=1)\n    statistics['mean_expm1'] = np.mean(expm1_temp, axis=1)\n    statistics['mean_exp2'] = np.mean(exp2_temp, axis=1)\n    # Polynomial FE\n    # X**2\n    statistics['mean_x2'] = np.mean(np.power(X,2), axis=1)\n    # X**3\n    statistics['mean_x3'] = np.mean(np.power(X,3), axis=1)\n    # X**4\n    statistics['mean_x4'] = np.mean(np.power(X,4), axis=1)\n    \n    from sklearn.neighbors import NearestNeighbors\n    neigh = NearestNeighbors(5, n_jobs=-1)\n    neigh.fit(X)\n\n    dists, _ = neigh.kneighbors(X, n_neighbors=5)\n    dists = np.delete(dists, 0, 1)\n    statistics['minDist'] = dists.mean(axis=1)\n    statistics['maxDist'] = dists.max(axis=1)\n    statistics['meanDist'] = dists.min(axis=1)\n\n    X = pd.concat([X, statistics], axis=1)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1 = with_statistics(train_rs)\ntest_1 = test = with_statistics(test_rs)\n\ntrain_2 = with_statistics(train_ss)\ntest_2 =  with_statistics(test_ss)\n\ntrain_3 = with_statistics(train_rs[target_corr])\ntest_3 = test = with_statistics(test_rs[target_corr])\n\ntrain_4 = with_statistics(train_ss[target_corr])\ntest_4 =  with_statistics(test_ss[target_corr])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_,s4a = train_model(train_1.values,test_1.values,y, text='Experiment-4a',params=param_model1, model=model1,feature_selection=True)\n\n_,s4b = train_model(train_3.values,test_3.values,y, text='Experiment-4b',params=param_model1, model=model1,feature_selection=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}