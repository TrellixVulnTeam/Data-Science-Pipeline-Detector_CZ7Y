{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Introduction: visualisation des données et mise en place des variables**","metadata":{}},{"cell_type":"markdown","source":"On asigne les données aux variables d'entrainement et de test. ","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/dont-overfit-ii/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/dont-overfit-ii/test.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche les données de train","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici on affiche dans un graphique train et test, pour voir la difference de quantité de donnée ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nnames = ('train.csv', 'test.csv')\ny_position = range(len(names))\n \nplt.bar(\n    y_position, \n    (train.shape[0], test.shape[0]), \n    align='center', \n    alpha=0.8\n)\nplt.xticks(y_position, names)\nplt.ylabel('Nombre') \nplt.title('Quantité de données ')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On créer les variables pour les modeles de machines learning","metadata":{}},{"cell_type":"code","source":"\nX=train.drop([\"target\", \"id\"], axis=1)\ny=train[\"target\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche les lignes avec seulement y=1","metadata":{}},{"cell_type":"code","source":"y[y==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Création des modeles de machine learning**","metadata":{}},{"cell_type":"markdown","source":"On importe toutes les librairies dont on a besoin ","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom matplotlib import pyplot as plt\nfrom sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creation des modeles de machine learning; certain de classification et d'autres de regression pour voir la difference lors de ce probleme ","metadata":{}},{"cell_type":"code","source":"model_ridge = linear_model.Ridge()\nmodel_lasso = linear_model.Lasso()\nmodel_log_reg = linear_model.LogisticRegression(solver='liblinear')\nmodel_reg_lin = linear_model.LinearRegression()\nmodel_knc = KNeighborsClassifier(n_neighbors=20)\nmodel_forest_reg = RandomForestRegressor(n_estimators = 10, random_state = 0)\nmodel_tree = DecisionTreeClassifier(max_depth=3, random_state=1)\nmodel_forest = RandomForestClassifier(n_estimators=15, max_depth=2, random_state=1)\nmodel_neighbor = KNeighborsClassifier(n_neighbors=5)\n\nmodels = [model_ridge, model_lasso, model_log_reg,model_reg_lin, model_knc,model_forest_reg,model_tree,model_forest,model_neighbor]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Entrainement des modeles**","metadata":{}},{"cell_type":"code","source":"model_ridge.fit(X,y)\nmodel_lasso.fit(X,y)\nmodel_log_reg.fit(X,y)\nmodel_reg_lin.fit(X,y)\nmodel_knc.fit(X,y)\nmodel_forest_reg.fit(X,y)\nmodel_tree.fit(X,y)\nmodel_forest.fit(X,y)\nmodel_neighbor.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On regade ce que donne les predictions apres entrainement ","metadata":{}},{"cell_type":"code","source":"model_log_reg.fit(X,y)\nmodel_log_reg.predict(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_forest_reg.fit(X,y)\nmodel_forest_reg.predict(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_forest.fit(X,y)\nmodel_forest.predict_proba(X)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation des modèles**","metadata":{}},{"cell_type":"markdown","source":"On essaie d'evaluer les modèles avec confusion_matrix\n\nOn a des modèles qui retournent du binaire et des continues, confusion_matrix ne fonctionne qu'avec ceux retournant des continues. \nCette evaluation ne convient pas pour tous nos modèles ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nmodel_a_evaluer = model_ridge\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_a_evaluer = model_lasso\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_a_evaluer = model_log_reg\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pas d'erreur pour 250 données ","metadata":{}},{"cell_type":"code","source":"model_a_evaluer = model_reg_lin\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_a_evaluer = model_knc\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici, le KNeighborsClassifier fait 67 erreurs sur 250","metadata":{}},{"cell_type":"code","source":"model_a_evaluer = model_forest_reg\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_a_evaluer = model_tree\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici DecisionTreeClassifier fait 37 erreurs sur 250","metadata":{}},{"cell_type":"code","source":"model_a_evaluer = model_forest\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici, RandomForestClassifier fait 65 erreurs sur 250","metadata":{}},{"cell_type":"code","source":"model_a_evaluer = model_neighbor\nconfusion_matrix(y, model_a_evaluer.predict(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici, KNeighborsClassifier fait 58 erreurs sur 250","metadata":{}},{"cell_type":"markdown","source":"Meme si cela ne permet pas d'evaluer tous les modeles, cela nous donne un premier avis sur les modèles qui sont plus performanats que d'autres ","metadata":{}},{"cell_type":"markdown","source":"Ici on va maintement évaluer les modèles avec une cross validation, on creer donc une fonction permettant d'évaluer les scores de tous nos modeles. On lui demmande d'afficher la moyennes de nos scores ainsi que l'équart tye pour avoir une vue global de chaque modèle","metadata":{}},{"cell_type":"code","source":"def cVal_scores(model):\n    scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n    print('Moyenne des scores: ', np.mean(scores))\n    print('Ecart-type des scores: ', np.std(scores))\n    print('\\n') # Saut de ligne pour plus de visibilité","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La boucle for nous permet de tester chaque modèles un à un dans notre fonction précédemment crée, puis d'afficher les scores","metadata":{}},{"cell_type":"code","source":"for model in models:\n    print(model)\n    cVal_scores(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On peut voir que le modèle le plus performant est la regression lineaire avec une moyenne des scores la plus haute (0,7) et un écart type minime de 0,04 (le deuxieme plus petit)","metadata":{}},{"cell_type":"markdown","source":"**Recherche des meilleurs paramètres**","metadata":{}},{"cell_type":"markdown","source":"Maintenant on passe à la recherches des meilleurs parametres pour la regression lineaire. Pour cela on va tester tous les differents paramètres possibles un à un puis on va retourner les meilleurs. \nOn utilise la fonction de sklearn GridSearchCV pour cela.\nInconvegnant : ce test est long puisqu'on va tester tous les paramètres, ici 1600 fits","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\npenalite = ['l1', 'l2']\nC = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\nclass_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\nsolver = ['liblinear', 'saga','newton-cg', 'sag','lbfgs']\n\nparam = dict(penalty=penalite,\n             C=C,\n             class_weight=class_weight,\n             solver=solver)\n\ngrid = GridSearchCV(estimator=model_log_reg, param_grid=param, scoring='roc_auc', verbose=1, n_jobs=-1)\nresult = grid.fit(X,y)\n\nprint('Meilleur Score: ', result.best_score_)\nprint('Meilleurs Paramètres: ', result.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici on a une erreur, mais on va tester notre model avec les valeurs retournés ","metadata":{}},{"cell_type":"code","source":"model_log_reg = linear_model.LogisticRegression(C=0.1, class_weight={1:0.6, 0:0.4}, penalty='l1', solver='liblinear')\ncVal_scores(model_log_reg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On refait la meme chose mais avec moins de valeurs à tester dans le solver, pour voir s'il y a une difference \nici 640 fits, ce qui est beaucoup moins que la première fois, donc pour plus court à tester ","metadata":{}},{"cell_type":"code","source":"\npenalite = ['l1', 'l2']\nC = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\nclass_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\nsolver = ['liblinear', 'saga']\n\nparam = dict(penalty=penalite,\n            C=C,\n            class_weight=class_weight,\n            solver=solver)\n\ngrid = GridSearchCV(estimator=model_log_reg, param_grid=param, scoring='roc_auc', verbose=1, n_jobs=-1)\nresult = grid.fit(X,y)\n\nprint('Meilleur Score: ', result.best_score_)\nprint('Meilleurs Paramètres: ', result.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Il est intéressant de voir qu'on a plus d'erreurs, et une difference au niveau des parametres retournés\n","metadata":{}},{"cell_type":"code","source":"model_log_reg = linear_model.LogisticRegression(C=0.1, class_weight={1:0.6, 0:0.4}, penalty='l1', solver='liblinear')\ncVal_scores(model_log_reg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Enfin, on cherche notre target soit Y_test, avec les donnée de test et les meilleurs parametres apres avoir entrainé le modèle ","metadata":{}},{"cell_type":"code","source":"X_test=test.drop([\"id\"], axis=1)\nmodel_log_reg.fit(X,y),\n\ny_test=model_log_reg.predict(X_test)\n\ny_test\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test[y_test==0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test[y_test==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}