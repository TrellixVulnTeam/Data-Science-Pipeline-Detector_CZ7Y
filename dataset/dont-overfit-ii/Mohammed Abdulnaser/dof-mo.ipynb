{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno as msno\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-17T11:46:14.253899Z","iopub.execute_input":"2021-08-17T11:46:14.254278Z","iopub.status.idle":"2021-08-17T11:46:14.267791Z","shell.execute_reply.started":"2021-08-17T11:46:14.254245Z","shell.execute_reply":"2021-08-17T11:46:14.266423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv('../input/dont-overfit-ii/train.csv')\ndf_test=pd.read_csv('../input/dont-overfit-ii/test.csv')\n\nlabels=df_train.columns.drop(['id','target'])\ntarget=df_train['target']\nide=df_test['id']\ndf_test=df_test.drop('id',axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:06.172852Z","iopub.execute_input":"2021-08-17T11:53:06.173216Z","iopub.status.idle":"2021-08-17T11:53:07.215021Z","shell.execute_reply.started":"2021-08-17T11:53:06.173185Z","shell.execute_reply":"2021-08-17T11:53:07.213839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:07.216634Z","iopub.execute_input":"2021-08-17T11:53:07.217044Z","iopub.status.idle":"2021-08-17T11:53:07.2443Z","shell.execute_reply.started":"2021-08-17T11:53:07.217001Z","shell.execute_reply":"2021-08-17T11:53:07.243458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:07.381874Z","iopub.execute_input":"2021-08-17T11:53:07.382433Z","iopub.status.idle":"2021-08-17T11:53:07.414053Z","shell.execute_reply.started":"2021-08-17T11:53:07.382397Z","shell.execute_reply":"2021-08-17T11:53:07.412832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As our training data is considerd small data and will tend to over fit simple models should be used or complex models with a good tuning the hyper parameters like L1 and L2 for regulaization and any parameter will lead to genralize our model, So I will try to Firstly see if there is any missing values first then will try simple models**","metadata":{}},{"cell_type":"code","source":"msno.matrix(df_train,figsize=(20,7))","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:08.164714Z","iopub.execute_input":"2021-08-17T11:53:08.165055Z","iopub.status.idle":"2021-08-17T11:53:08.862526Z","shell.execute_reply.started":"2021-08-17T11:53:08.165025Z","shell.execute_reply":"2021-08-17T11:53:08.861389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx_train, x_test, y_train, y_test = train_test_split(df_train[labels] , target,  train_size=0.8, test_size=0.2, random_state =0)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:08.864353Z","iopub.execute_input":"2021-08-17T11:53:08.864798Z","iopub.status.idle":"2021-08-17T11:53:08.873754Z","shell.execute_reply.started":"2021-08-17T11:53:08.864752Z","shell.execute_reply":"2021-08-17T11:53:08.872472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First I will try to use Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(x_train, y_train)\npreds=model.predict(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:09.000656Z","iopub.execute_input":"2021-08-17T11:53:09.001005Z","iopub.status.idle":"2021-08-17T11:53:09.039159Z","shell.execute_reply.started":"2021-08-17T11:53:09.000975Z","shell.execute_reply":"2021-08-17T11:53:09.037785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint('auc_train:', roc_auc_score(y_train,model.predict(x_train)))\nprint('auc_test:' , roc_auc_score(y_test, preds))","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:09.041171Z","iopub.execute_input":"2021-08-17T11:53:09.041624Z","iopub.status.idle":"2021-08-17T11:53:09.067173Z","shell.execute_reply.started":"2021-08-17T11:53:09.041579Z","shell.execute_reply":"2021-08-17T11:53:09.066054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**So I will be using a more complex model and try to make a good tuning for it**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nm = XGBClassifier(max_depth=2,gamma=11,eta=0.8,reg_alpha=0.7,reg_lambda=0.9,eval_metric=None)\nm.fit(x_train, y_train)\npred=m.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:09.098281Z","iopub.execute_input":"2021-08-17T11:53:09.098838Z","iopub.status.idle":"2021-08-17T11:53:09.509593Z","shell.execute_reply.started":"2021-08-17T11:53:09.098792Z","shell.execute_reply":"2021-08-17T11:53:09.508726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('auc_train:', roc_auc_score(y_train,m.predict(x_train)))\nprint('auc_test:' , roc_auc_score(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:09.511015Z","iopub.execute_input":"2021-08-17T11:53:09.511594Z","iopub.status.idle":"2021-08-17T11:53:09.527671Z","shell.execute_reply.started":"2021-08-17T11:53:09.51155Z","shell.execute_reply":"2021-08-17T11:53:09.525597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_test.shape)\nou=m.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:09.531636Z","iopub.execute_input":"2021-08-17T11:53:09.533497Z","iopub.status.idle":"2021-08-17T11:53:09.582041Z","shell.execute_reply.started":"2021-08-17T11:53:09.533447Z","shell.execute_reply":"2021-08-17T11:53:09.581208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output=pd.DataFrame({'id':ide,\n                    'target':ou})","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:17.364712Z","iopub.execute_input":"2021-08-17T11:53:17.365087Z","iopub.status.idle":"2021-08-17T11:53:17.37057Z","shell.execute_reply.started":"2021-08-17T11:53:17.365055Z","shell.execute_reply":"2021-08-17T11:53:17.369422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:53:18.969638Z","iopub.execute_input":"2021-08-17T11:53:18.970037Z","iopub.status.idle":"2021-08-17T11:53:19.025828Z","shell.execute_reply.started":"2021-08-17T11:53:18.970006Z","shell.execute_reply":"2021-08-17T11:53:19.024736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}