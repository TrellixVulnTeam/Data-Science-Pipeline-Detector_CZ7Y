{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Example for my blog post [How To Avoid Overfitting](https://medium.com/@gokhang1327/how-to-avoid-overfitting-for-beginners-deep-learning-ed2817a7e65)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading data into a pandas dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/dont-overfit-ii/train.csv\", index_col=\"id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is not any missing value situation in this data."},{"metadata":{},"cell_type":"markdown","source":"## Train-test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(columns=[\"target\"])\ny = df.filter([\"target\"])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X.values, y.values, test_size=0.2, random_state=42\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"80% train, 20% test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer = tf.keras.Input(shape=(300,))\n\nhidden_layer_1 = tf.keras.layers.Dense(1024, activation='relu')(input_layer)\n\nhidden_layer_2 = tf.keras.layers.Dense(512, activation='relu')(hidden_layer_1)\n\nhidden_layer_3 = tf.keras.layers.Dense(256, activation='relu')(hidden_layer_2)\n\noutput_layer = tf.keras.layers.Dense(1, activation='sigmoid')(hidden_layer_3)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    batch_size=64,\n    epochs=100,\n    validation_split=0.25\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is the example of overfitting."},{"metadata":{},"cell_type":"markdown","source":"## How To Avoid Overfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer = tf.keras.Input(shape=(300,))\n\nhidden_layer_1 = tf.keras.layers.Dense(32, activation='relu')(input_layer)  # Simplifying model: less layers, less neurons\nhidden_layer_1 = tf.keras.layers.Dropout(rate=0.2)(hidden_layer_1)  # Adding dropout layers\n\nhidden_layer_2 = tf.keras.layers.Dense(16, activation='relu')(hidden_layer_1)  # Simplifying model: less layers, less neurons\nhidden_layer_2 = tf.keras.layers.Dropout(rate=0.2)(hidden_layer_2)  # Adding dropout layers\n\noutput_layer = tf.keras.layers.Dense(1, activation='sigmoid')(hidden_layer_2)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nes_callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=3\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    batch_size=64,\n    epochs=100,\n    callbacks=[es_callback],  # Stop training process earlier\n    validation_split=0.25\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see that these methods decrease overfitting. But ofcourse not enough because this train set is too small to make this competition harder."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}