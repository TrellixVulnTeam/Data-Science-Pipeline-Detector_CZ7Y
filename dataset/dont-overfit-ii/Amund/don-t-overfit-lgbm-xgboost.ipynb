{"cells":[{"metadata":{},"cell_type":"markdown","source":"Playing around with LightGBM and XGBoost on the dont overfit II dataset:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom time import time \n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntarget= train['target']\ntrain = train.drop(['target','id'], axis = 1)\ntest = test.drop(['id'], axis = 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How not to overfit with gradient boosted trees: \n* Reduce tree complexity by setting num_leaves or max_depth small.\n* Use a small learning rate\n* Use feature_fraction and bagging_fraction/bagging_freq. \n* Try to penalize L1 and L2\n* By default min_data_in_leaf is 20, this needs to be reduced in this small dataset, otherwise you will struggle to predict a 0. "},{"metadata":{"trusted":true},"cell_type":"code","source":"params_LGBM = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'num_leaves': 4,\n    'learning_rate': 0.012,\n    'feature_fraction': 0.6,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 1,\n    'verbose': 0,\n    'lambda_l1':0.4,\n    'lambda_l2':0.9,\n    'min_data_in_leaf': 2,\n    'max_bin': 25,\n    'min_data_in_bin':2    \n}\nparams_XGB =  {\n    'booster': 'gbtree',\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'max_depth': 2,\n    'eta': 0.012,\n    'subsample': 0.7,    \n    'verbosity': 0,\n    'alpha':0.4,\n    'lambda':0.9,\n    'colsample_bytree': 0.8,\n    'colsample_bylevel': 0.8,\n    'colsample_bynode': 0.8,\n   # 'three_method':'hist'    \n}  \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"def cv_LGBM(train,target,params,rounds):      \n    lgb_train = lgb.Dataset(train, target)\n    hist = lgb.cv(\n                params,\n                lgb_train,\n                num_boost_round=rounds\n                   )   \n    scores = pd.DataFrame.from_dict(hist)\n    return(scores)\n\ndef train_LGBM(train,target,params,rounds):\n    lgb_train = lgb.Dataset(train,target)\n    booster = lgb.train(\n        params,lgb_train,\n        num_boost_round = rounds,\n        verbose_eval = False\n    )\n    return(booster)\n\ndef cv_XGB(train,target,params,rounds):  \n    xgb_train = xgb.DMatrix(train, label = target)       \n    hist = xgb.cv(\n        params,\n        xgb_train,\n        num_boost_round=rounds,\n        stratified = True)  \n    scores = pd.DataFrame.from_dict(hist)\n    return(scores)\n\ndef train_XGB(train,target,params,rounds):  \n        xgb_train = xgb.DMatrix(train, label = target)    \n        booster = xgb.train(\n            params,\n            xgb_train,\n            num_boost_round = rounds, )\n        return(booster)\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_LGBM = cv_LGBM(train,target,params_LGBM,rounds = 3000)\n    \nscores_XGB = cv_XGB(train,target,params_XGB, rounds = 3000)\n\nscores = pd.DataFrame()\nscores['XGB'],scores['LGBM'] = scores_XGB['test-auc-mean'],scores_LGBM['auc-mean']\nplt.plot(scores)\nplt.legend(labels = ('XGB','LGMB'))\nprint(scores[-10:])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LightGMB scoring 0.792 in public leaderboard with these parameters and all features. \nXGBoost scoring 0.795 on public leaderboard with these parameters and all features. \n\nGenerally; CV is more conservative than the public leaderboard.. "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Trying if PCA gives improvement:"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler().fit(train+test) #Shoud only train be fitted? Using train+test gives improvement.\n\ntrain_scaled = scaler.transform(train)\ntest_scaled = scaler.transform(test)\n\npca = PCA(n_components = 50)\ntrain_pca = pca.fit_transform(train_scaled)\ntest_pca = pca.transform(test_scaled)\n\nscores_LGBM = cv_LGBM(train_pca,target,params_LGBM,rounds = 1000)    \nscores_XGB = cv_XGB(train_pca,target,params_XGB, rounds = 1000)\n\nscores = pd.DataFrame()\nscores['XGB'],scores['LGBM'] = scores_XGB['test-auc-mean'],scores_LGBM['auc-mean']\n\nplt.plot(scores)\nplt.legend(labels = ('XGB','LGMB'))\nprint(scores[-10:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PCA is not very effective..\n\nTrying feature removal:"},{"metadata":{"trusted":true,"_uuid":"ac4866c8bb7fb3a3f1d99eb1674748cf236b1023","_kg_hide-input":false},"cell_type":"code","source":"# Stolen from https://www.kaggle.com/tboyle10/feature-selection\nbooster = train_LGBM(train,target,params = params_LGBM, rounds = 1000)\n\nfeature_importance = booster.feature_importance(importance_type = 'gain')\nsorted_idx = np.argsort(feature_importance)\n#print(sorted_idx)\nplot_idx = sorted_idx[-20:]\n\npos = np.arange(plot_idx.shape[0]) + .5\nplt.barh(pos,feature_importance[plot_idx])\nplt.yticks(pos,plot_idx)\n\nplt.title('Feature Importance', fontsize=20)\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_params_LGBM = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'num_leaves': 6,\n    'learning_rate': 0.012,\n    'feature_fraction': 0.4,\n    'bagging_fraction': 0.35,\n    'bagging_freq': 2,\n    'verbose': 0,\n    'lambda_l1':0.5,\n    'lambda_l2':0.9,\n    'min_data_in_leaf': 2,\n    'max_bin': 200,\n    'min_data_in_bin':2    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f259d2a044fc6023beb9902df94da3cb5ae1361","scrolled":true},"cell_type":"code","source":"#Returns a booster with n less features\ndef removeAndRun(n_features,train,target,test):\n    #Train boosters\n    lgbm = train_LGBM(train,target, params = params_LGBM, rounds = 1000)\n    xgbm = train_XGB(train,target, params = params_XGB, rounds = 100)\n    \n    #Finding and removing least important features in lightgbm \n    feature_importance = lgbm.feature_importance(importance_type = 'gain')\n    sorted_idx = np.argsort(feature_importance)\n    remove = sorted_idx[:n_features]\n   \n    train_reduced = train\n    test_reduced = test\n    for index in remove:\n        train_reduced = train_reduced.drop(str(index),axis = 1)\n        test_reduced = test_reduced.drop(str(index),axis = 1)\n        \n    #Re-train\n    lgbm = train_LGBM(train_reduced,target, params = reduced_params_LGBM, rounds = 5000)\n    xgbm = train_XGB(train_reduced,target, params = params_XGB, rounds = 5000)\n    \n    return lgbm,xgbm,train_reduced,test_reduced\n\nlgbm,xgbm,train_reduced,test_reduced= removeAndRun(250, train, target, test)\nscores_LGBM = cv_LGBM(train_reduced,target,reduced_params_LGBM,rounds = 3000)   \nscores_XGB = cv_XGB(train_reduced,target,params_XGB, rounds = 3000)\n\nscores = pd.DataFrame()\nscores['XGB'],scores['LGBM'] = scores_XGB['test-auc-mean'],scores_LGBM['auc-mean']\nprint('shape of training data: ' ,np.shape(train_reduced.ix[0]))\nplt.plot(scores)\nplt.legend(labels = ('XGB','LGMB'))\nprint(scores[-10:])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both XGB and LGB scores the same on public leaderboard after feature removal woth the \"old\" parameters. \n\nLGBM scores 0.81 in public leaderboard with the new reduced_parameters. \n\nSo the CV-function is now overfitting. LGB seems to underperform more than XGB when comparing to CV. LGB and XGB seems equal on public leaderboard. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_xgb = xgb.DMatrix(test_reduced)\n#test_lgbm = lgb.Dataset(test_reduced) no need. \nfinal = lgbm.predict(test_reduced)\n\nplt.scatter(range(300),(final[:300]))\nplt.legend(['Float'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fac097dc4dca5273ce5a28ac8c3d782b6d9038d"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\n\nsubmission['target'] = final\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_tree(lgbm,tree_index = 0,figsize = (20,20))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}