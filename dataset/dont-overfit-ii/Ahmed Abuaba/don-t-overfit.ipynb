{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:33.695673Z","iopub.execute_input":"2021-08-07T06:12:33.696262Z","iopub.status.idle":"2021-08-07T06:12:34.488062Z","shell.execute_reply.started":"2021-08-07T06:12:33.696177Z","shell.execute_reply":"2021-08-07T06:12:34.486516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the Files","metadata":{}},{"cell_type":"code","source":"# Reading Train File\ntrain_df = pd.read_csv(\"../input/dont-overfit-ii/train.csv\")\n#train_df.head()\ntrain_df = train_df.drop(\"id\", axis=1)\n# Create a data with all columns except target\nX_train_not_scaled = train_df.drop(\"target\", axis=1)\n\n# Create a target. labels dataset\ny_train = (train_df[[\"target\"]])\n\n# Reading Test File\ntest_df = pd.read_csv(\"../input/dont-overfit-ii/test.csv\")\n#test_df.head() \nX_test_not_scaled = test_df.drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:34.494384Z","iopub.execute_input":"2021-08-07T06:12:34.494667Z","iopub.status.idle":"2021-08-07T06:12:35.817006Z","shell.execute_reply.started":"2021-08-07T06:12:34.494632Z","shell.execute_reply":"2021-08-07T06:12:35.816038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape\nX_test_not_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:35.818441Z","iopub.execute_input":"2021-08-07T06:12:35.818713Z","iopub.status.idle":"2021-08-07T06:12:35.827389Z","shell.execute_reply.started":"2021-08-07T06:12:35.818685Z","shell.execute_reply":"2021-08-07T06:12:35.826123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Values","metadata":{}},{"cell_type":"code","source":"train_df.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:35.829029Z","iopub.execute_input":"2021-08-07T06:12:35.829417Z","iopub.status.idle":"2021-08-07T06:12:35.838596Z","shell.execute_reply.started":"2021-08-07T06:12:35.829387Z","shell.execute_reply":"2021-08-07T06:12:35.837605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_not_scaled.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:35.839901Z","iopub.execute_input":"2021-08-07T06:12:35.840256Z","iopub.status.idle":"2021-08-07T06:12:35.856011Z","shell.execute_reply.started":"2021-08-07T06:12:35.840227Z","shell.execute_reply":"2021-08-07T06:12:35.855087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df.isnull().sum().sort_values(ascending = False).head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:35.857097Z","iopub.execute_input":"2021-08-07T06:12:35.857363Z","iopub.status.idle":"2021-08-07T06:12:35.861801Z","shell.execute_reply.started":"2021-08-07T06:12:35.857337Z","shell.execute_reply":"2021-08-07T06:12:35.860791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_test_not_scaled.isnull().sum().sort_values(ascending = False).head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:35.863345Z","iopub.execute_input":"2021-08-07T06:12:35.863767Z","iopub.status.idle":"2021-08-07T06:12:35.87313Z","shell.execute_reply.started":"2021-08-07T06:12:35.863734Z","shell.execute_reply":"2021-08-07T06:12:35.872071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check for Non Numaric values","metadata":{}},{"cell_type":"code","source":"train_df.applymap(np.isreal).values.all()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:35.876098Z","iopub.execute_input":"2021-08-07T06:12:35.876395Z","iopub.status.idle":"2021-08-07T06:12:36.025102Z","shell.execute_reply.started":"2021-08-07T06:12:35.876369Z","shell.execute_reply":"2021-08-07T06:12:36.024212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_not_scaled.applymap(np.isreal).values.all()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:36.02653Z","iopub.execute_input":"2021-08-07T06:12:36.026791Z","iopub.status.idle":"2021-08-07T06:12:42.186982Z","shell.execute_reply.started":"2021-08-07T06:12:36.026764Z","shell.execute_reply":"2021-08-07T06:12:42.18629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standard Scaling","metadata":{}},{"cell_type":"markdown","source":"train data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n#Scaling Numerical columns\nstd = StandardScaler()\nX_train = std.fit_transform(X_train_not_scaled)\nX_train = pd.DataFrame(X_train)\n#X_train = X_train_not_scaled.merge(X_train,left_index=True,right_index=True,how = \"left\")\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:42.187913Z","iopub.execute_input":"2021-08-07T06:12:42.188349Z","iopub.status.idle":"2021-08-07T06:12:42.312697Z","shell.execute_reply.started":"2021-08-07T06:12:42.18832Z","shell.execute_reply":"2021-08-07T06:12:42.311554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"test data","metadata":{}},{"cell_type":"code","source":"#Scaling Numerical columns\nstd = StandardScaler()\nX_test = std.fit_transform(X_test_not_scaled)\nX_test = pd.DataFrame(X_test)\n#X_test = X_test_not_scaled.merge(X_test,left_index=True,right_index=True,how = \"left\")\nX_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:42.313788Z","iopub.execute_input":"2021-08-07T06:12:42.314089Z","iopub.status.idle":"2021-08-07T06:12:42.470397Z","shell.execute_reply.started":"2021-08-07T06:12:42.314056Z","shell.execute_reply":"2021-08-07T06:12:42.469448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:42.471971Z","iopub.execute_input":"2021-08-07T06:12:42.472377Z","iopub.status.idle":"2021-08-07T06:12:42.487047Z","shell.execute_reply.started":"2021-08-07T06:12:42.472335Z","shell.execute_reply":"2021-08-07T06:12:42.486278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GridSearch CV and Modeling","metadata":{}},{"cell_type":"markdown","source":"here i have used grid search to find the best scores for the logistic regression model:\n* i have used the **\"liblinear\"** solver as its very suitable at small data set as we have at the training data \n* for the grid parameters i choosed:\n  * {\"**class_wight**\"} : as the target here at the data is **not equally distributed** between 0,1 o records are bigger than 1 records 2.7 times\n  * {\"**penalty**\"} : to ckhoose the best **norm-method** for the solver in optimization of the cost function.\n  * {\"**C**\"} : to control the REGULARIZATION to avoid the OVERFITTING of the model as **C equals the reciprocal of the LAMBDA hyper parameter**. ","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# Find best hyperparameters (roc_auc)\nrandom_state = 42\nlog_clf = LogisticRegression(solver='liblinear',random_state = random_state)\nparam_grid = {'class_weight' : ['balanced', None], \n                'penalty' : ['l2','l1'],  \n                'C' : [0.001, 0.01, 0.1, 1, 10, 100]}\n\ngrid = GridSearchCV(estimator = log_clf, param_grid = param_grid , scoring = 'roc_auc', verbose = 1, n_jobs = -1, cv = 20)\n\ngrid.fit(X_train,y_train)\n\nprint(\"Best Score:\" + str(grid.best_score_))\nprint(\"Best Parameters: \" + str(grid.best_params_))\n\nbest_parameters = grid.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:42.488046Z","iopub.execute_input":"2021-08-07T06:12:42.488438Z","iopub.status.idle":"2021-08-07T06:12:48.684916Z","shell.execute_reply.started":"2021-08-07T06:12:42.488402Z","shell.execute_reply":"2021-08-07T06:12:48.683626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_clf = LogisticRegression(solver='liblinear',random_state = random_state,**best_parameters)\nlog_clf.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:48.686566Z","iopub.execute_input":"2021-08-07T06:12:48.686849Z","iopub.status.idle":"2021-08-07T06:12:48.706675Z","shell.execute_reply.started":"2021-08-07T06:12:48.686819Z","shell.execute_reply":"2021-08-07T06:12:48.705608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AUCROC \"just for showing\"","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\ny_pred_proba = log_clf.predict_proba(X_train)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_train,  y_pred_proba)\nauc = metrics.roc_auc_score(y_train, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:48.708168Z","iopub.execute_input":"2021-08-07T06:12:48.708748Z","iopub.status.idle":"2021-08-07T06:12:48.92975Z","shell.execute_reply.started":"2021-08-07T06:12:48.708702Z","shell.execute_reply":"2021-08-07T06:12:48.929061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Prediction","metadata":{}},{"cell_type":"code","source":"y_pred_0_1 = log_clf.predict(X_test)\ny_pred_0_1","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:48.930941Z","iopub.execute_input":"2021-08-07T06:12:48.93151Z","iopub.status.idle":"2021-08-07T06:12:48.952443Z","shell.execute_reply.started":"2021-08-07T06:12:48.931467Z","shell.execute_reply":"2021-08-07T06:12:48.951192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predicted_proba = log_clf.predict_proba(X_test)[::,1]\ny_test_predicted_proba","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:48.954025Z","iopub.execute_input":"2021-08-07T06:12:48.954594Z","iopub.status.idle":"2021-08-07T06:12:48.980558Z","shell.execute_reply.started":"2021-08-07T06:12:48.954552Z","shell.execute_reply":"2021-08-07T06:12:48.979573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Submission files","metadata":{}},{"cell_type":"code","source":"test_df['target'] = y_pred_0_1","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:48.981932Z","iopub.execute_input":"2021-08-07T06:12:48.982509Z","iopub.status.idle":"2021-08-07T06:12:48.989486Z","shell.execute_reply.started":"2021-08-07T06:12:48.982467Z","shell.execute_reply":"2021-08-07T06:12:48.988122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[['id', 'target']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T06:12:48.991129Z","iopub.execute_input":"2021-08-07T06:12:48.991943Z","iopub.status.idle":"2021-08-07T06:12:49.112675Z","shell.execute_reply.started":"2021-08-07T06:12:48.991883Z","shell.execute_reply":"2021-08-07T06:12:49.11192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i don't know why are the compitition scores not improving in significant way !! i have tried many things in grid search of the model and data preparation and this notebook is the best scores of my work which didn't vary significantly!!, this may be due any change in the data sets from KAGGLE side and i wish to know the reason !!!","metadata":{}}]}