{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\nfrom sklearn.feature_selection import RFE, RFECV\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, cross_validate\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, make_scorer \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score, auc, log_loss\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom scipy.stats import ks_2samp","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:33:57.558671Z","iopub.execute_input":"2021-08-30T20:33:57.559536Z","iopub.status.idle":"2021-08-30T20:34:00.222271Z","shell.execute_reply.started":"2021-08-30T20:33:57.559357Z","shell.execute_reply":"2021-08-30T20:34:00.221095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/dont-overfit-ii/train.csv')\ntest = pd.read_csv('../input/dont-overfit-ii/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:03.534616Z","iopub.execute_input":"2021-08-30T20:34:03.534985Z","iopub.status.idle":"2021-08-30T20:34:05.108658Z","shell.execute_reply.started":"2021-08-30T20:34:03.534955Z","shell.execute_reply":"2021-08-30T20:34:05.107549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:05.110258Z","iopub.execute_input":"2021-08-30T20:34:05.110561Z","iopub.status.idle":"2021-08-30T20:34:05.159339Z","shell.execute_reply.started":"2021-08-30T20:34:05.110533Z","shell.execute_reply":"2021-08-30T20:34:05.158008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()[train.isnull().sum() > 0]","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:05.161132Z","iopub.execute_input":"2021-08-30T20:34:05.161434Z","iopub.status.idle":"2021-08-30T20:34:05.17392Z","shell.execute_reply.started":"2021-08-30T20:34:05.161407Z","shell.execute_reply":"2021-08-30T20:34:05.173099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:05.175533Z","iopub.execute_input":"2021-08-30T20:34:05.175973Z","iopub.status.idle":"2021-08-30T20:34:05.210311Z","shell.execute_reply.started":"2021-08-30T20:34:05.175944Z","shell.execute_reply":"2021-08-30T20:34:05.209591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"#from kernel  \"https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data\"\ndef get_diff_columns(train_df, test_df, show_plots=True, show_all=False, threshold=0.1):\n    \"\"\"Use KS to estimate columns where distributions differ a lot from each other\"\"\"\n\n    # Find the columns where the distributions are very different\n    diff_data = []\n    for col in tqdm(train_df.columns):\n        statistic, pvalue = ks_2samp(\n            train_df[col].values, \n            test_df[col].values\n        )\n        if pvalue > 0.05 and np.abs(statistic) < threshold:\n            diff_data.append({'feature': col, 'p': np.round(pvalue, 5), 'statistic': np.round(np.abs(statistic), 2)})\n\n    # Put the differences into a dataframe\n    diff_df = pd.DataFrame(diff_data).sort_values(by='statistic', ascending=False)\n    print(f\"number of features with diff distribution : {len(diff_df)}\")\n    if show_plots:\n        # Let us see the distributions of these columns to confirm they are indeed different\n        n_cols = 5\n        n_rows = 5\n        _, axes = plt.subplots(n_rows, n_cols, figsize=(20, 3*n_rows))\n        axes = [x for l in axes for x in l]\n\n        # Create plots\n        for i, (_, row) in enumerate(diff_df.iterrows()):\n            if i >= len(axes):\n                break\n            extreme = np.max(np.abs(train_df[row.feature].tolist() + test_df[row.feature].tolist()))\n            train_df.loc[:, row.feature].apply(np.log1p).hist(\n                ax=axes[i], alpha=0.5, label='Train', density=True,\n                bins=np.arange(-extreme, extreme, 0.25)\n            )\n            test_df.loc[:, row.feature].apply(np.log1p).hist(\n                ax=axes[i], alpha=0.5, label='Test', density=True,\n                bins=np.arange(-extreme, extreme, 0.25)\n            )\n            axes[i].set_title(f\"Statistic = {row.statistic}, p = {row.p}\")\n            axes[i].set_xlabel(f'Log({row.feature})')\n            axes[i].legend()\n\n        plt.tight_layout()\n        plt.show()\n        \n    return diff_df\n\n# Get the columns which differ a lot between test and train\ndiff_df = get_diff_columns(train.drop(['id','target'], axis=1), test.drop(['id'], axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:05.21156Z","iopub.execute_input":"2021-08-30T20:34:05.212019Z","iopub.status.idle":"2021-08-30T20:34:15.130673Z","shell.execute_reply.started":"2021-08-30T20:34:05.211985Z","shell.execute_reply":"2021-08-30T20:34:15.12991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_with_y = pd.DataFrame(train.drop(['id','target'], axis=1).corrwith(train[\"target\"]).abs()).reset_index()\ncorr_with_y.columns = [\"Feature\", \"Correlation with Target\"]\ncorr_with_y = corr_with_y.sort_values(by=\"Correlation with Target\", ascending=False)\ncorr_with_y.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:15.131843Z","iopub.execute_input":"2021-08-30T20:34:15.132269Z","iopub.status.idle":"2021-08-30T20:34:15.232117Z","shell.execute_reply.started":"2021-08-30T20:34:15.132239Z","shell.execute_reply":"2021-08-30T20:34:15.231172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop identity and target columns\nvariables_train = train.drop(['id','target'], axis=1)\nvar_resp = train[\"target\"].copy()\nvariables_test = test.drop(['id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:15.233293Z","iopub.execute_input":"2021-08-30T20:34:15.233582Z","iopub.status.idle":"2021-08-30T20:34:15.255849Z","shell.execute_reply.started":"2021-08-30T20:34:15.233553Z","shell.execute_reply":"2021-08-30T20:34:15.254729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View % of each class of the response var\n(var_resp.value_counts()/var_resp.count())*100","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:15.258048Z","iopub.execute_input":"2021-08-30T20:34:15.258366Z","iopub.status.idle":"2021-08-30T20:34:15.271834Z","shell.execute_reply.started":"2021-08-30T20:34:15.258333Z","shell.execute_reply":"2021-08-30T20:34:15.270676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make the break between training and testing with stratify before any base treatment\nx_train, x_test, y_train, y_test = train_test_split(variables_train, var_resp, test_size=0.2, random_state=2, stratify=var_resp)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:15.273161Z","iopub.execute_input":"2021-08-30T20:34:15.273491Z","iopub.status.idle":"2021-08-30T20:34:15.282774Z","shell.execute_reply.started":"2021-08-30T20:34:15.273458Z","shell.execute_reply":"2021-08-30T20:34:15.281756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature engineering","metadata":{}},{"cell_type":"code","source":"def with_statistics(X):\n    statistics = pd.DataFrame()\n    statistics['mean']   = X.mean(axis=1)\n    statistics['std']    = X.std(axis=1)\n    statistics['kurt']   = X.kurt(axis=1)\n    statistics['mad']    = X.mad(axis=1)\n    statistics['median'] = X.median(axis=1)\n    statistics['max']    = X.max(axis=1)\n    statistics['min']    = X.min(axis=1)\n    statistics['skew']   = X.skew(axis=1)\n    statistics['sem']    = X.sem(axis=1)\n    \n    from sklearn.neighbors import NearestNeighbors\n    neigh = NearestNeighbors(n_jobs=-1)\n    neigh.fit(X)\n\n    dists, _ = neigh.kneighbors(X)\n    dists = np.delete(dists, 0, 1)\n    statistics['minDist'] = dists.mean(axis=1)\n    statistics['maxDist'] = dists.max(axis=1)\n    statistics['meanDist'] = dists.min(axis=1)\n\n# Trigometric FE\n    sin_temp = np.sin(X)\n    cos_temp = np.cos(X)\n    tan_temp = np.tan(X)\n    statistics['mean_sin'] = np.mean(sin_temp, axis=1)\n    statistics['mean_cos'] = np.mean(cos_temp, axis=1)\n    statistics['mean_tan'] = np.mean(tan_temp, axis=1)\n# Hyperbolic FE\n    sinh_temp = np.sinh(X)\n    cosh_temp = np.cosh(X)\n    tanh_temp = np.tanh(X)\n    statistics['mean_sinh'] = np.mean(sinh_temp, axis=1)\n    statistics['mean_cosh'] = np.mean(cosh_temp, axis=1)\n    statistics['mean_tanh'] = np.mean(tanh_temp, axis=1)\n# Exponents FE\n    exp_temp = np.exp(X)\n    expm1_temp = np.expm1(X)\n    exp2_temp = np.exp2(X)\n    statistics['mean_exp'] = np.mean(exp_temp, axis=1)\n    statistics['mean_expm1'] = np.mean(expm1_temp, axis=1)\n    statistics['mean_exp2'] = np.mean(exp2_temp, axis=1)\n# Polynomial FE\n    # X**2\n    statistics['mean_x2'] = np.mean(np.power(X, 2), axis=1)\n    # X**3\n    statistics['mean_x3'] = np.mean(np.power(X, 3), axis=1)\n    # X**4\n    statistics['mean_x4'] = np.mean(np.power(X, 4), axis=1)\n    \n    X = pd.concat([X, statistics], axis=1)\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:15.284644Z","iopub.execute_input":"2021-08-30T20:34:15.285062Z","iopub.status.idle":"2021-08-30T20:34:15.305596Z","shell.execute_reply.started":"2021-08-30T20:34:15.285029Z","shell.execute_reply":"2021-08-30T20:34:15.304787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply feature engineering on training and testing/validating datasets\nx_train = with_statistics(x_train).values\nx_test = with_statistics(x_test).values\nvariables_test = with_statistics(variables_test).values","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:34:15.306894Z","iopub.execute_input":"2021-08-30T20:34:15.307362Z","iopub.status.idle":"2021-08-30T20:36:42.508217Z","shell.execute_reply.started":"2021-08-30T20:34:15.307323Z","shell.execute_reply":"2021-08-30T20:36:42.507352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here I apply a Pipeline to standardize the scale on numerical data\n# As we don't have missings and categorical data, I don't need to worry about this part\n# As we have 282/301 variables with different distribution on training and test basis, we will standardize with RobustScaler\n\npreprocessor = Pipeline([\n        ('selector', VarianceThreshold()),\n        ('std_scaler', RobustScaler())\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:36:42.509688Z","iopub.execute_input":"2021-08-30T20:36:42.510294Z","iopub.status.idle":"2021-08-30T20:36:42.515548Z","shell.execute_reply.started":"2021-08-30T20:36:42.510248Z","shell.execute_reply":"2021-08-30T20:36:42.514577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling with hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"# define roc_auc_metric robust to only one class in y_pred\ndef scoring_roc_auc(y, y_pred):\n    try:\n        return roc_auc_score(y, y_pred)\n    except:\n        return 0.5\n\nrobust_roc_auc = make_scorer(scoring_roc_auc)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T20:36:42.51702Z","iopub.execute_input":"2021-08-30T20:36:42.517594Z","iopub.status.idle":"2021-08-30T20:36:42.532058Z","shell.execute_reply.started":"2021-08-30T20:36:42.51755Z","shell.execute_reply":"2021-08-30T20:36:42.530946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of trees\n# Increase to previne overfit\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 10000, num = 4)]\n\nparam_grid = [\n    {\n        'classify__n_estimators': n_estimators,\n        'classify__reg_lambda': [0.00001, 1000],\n        'classify__reg_alpha': [0.00001, 1000]\n    } \n]\n\nmodel = Pipeline([\n        ('preprocessor', preprocessor),\n        ('classify', lgb.LGBMClassifier(\n            objective = 'binary',\n            n_jobs = -1,\n            boosting_type = 'gbdt',\n            metric = 'binary_error',\n            class_weight='balanced',\n            # Decrease both to previne overfit\n            # Maximum number of levels in tree\n            max_depth = 2,\n            num_leaves = 2\n        ))\n])\n\n# GridSearchCV with specify roc_auc that is robust against unbalanced datasets\ngrid_search = GridSearchCV(\n    model, param_grid, cv=20, scoring=robust_roc_auc, verbose=1, return_train_score=True, n_jobs=-1)\n\ngrid_search = grid_search.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:07:09.219283Z","iopub.execute_input":"2021-08-30T23:07:09.219803Z","iopub.status.idle":"2021-08-30T23:29:08.275206Z","shell.execute_reply.started":"2021-08-30T23:07:09.219764Z","shell.execute_reply":"2021-08-30T23:29:08.274231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:08.276936Z","iopub.execute_input":"2021-08-30T23:29:08.277446Z","iopub.status.idle":"2021-08-30T23:29:08.285794Z","shell.execute_reply.started":"2021-08-30T23:29:08.277406Z","shell.execute_reply":"2021-08-30T23:29:08.284327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prepared = grid_search.best_estimator_.named_steps['preprocessor'].transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:08.288148Z","iopub.execute_input":"2021-08-30T23:29:08.288483Z","iopub.status.idle":"2021-08-30T23:29:08.299722Z","shell.execute_reply.started":"2021-08-30T23:29:08.288453Z","shell.execute_reply":"2021-08-30T23:29:08.298479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search.best_estimator_.named_steps['classify'].score(test_prepared, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:08.301165Z","iopub.execute_input":"2021-08-30T23:29:08.301519Z","iopub.status.idle":"2021-08-30T23:29:08.316504Z","shell.execute_reply.started":"2021-08-30T23:29:08.30149Z","shell.execute_reply":"2021-08-30T23:29:08.314146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = grid_search.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:45.38265Z","iopub.execute_input":"2021-08-30T23:29:45.38306Z","iopub.status.idle":"2021-08-30T23:29:45.38829Z","shell.execute_reply.started":"2021-08-30T23:29:45.383026Z","shell.execute_reply":"2021-08-30T23:29:45.386869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_estimation = model.named_steps['classify'].predict(test_prepared)\ny_test_score = model.named_steps['classify'].predict_proba(test_prepared)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:46.35511Z","iopub.execute_input":"2021-08-30T23:29:46.355467Z","iopub.status.idle":"2021-08-30T23:29:46.365723Z","shell.execute_reply.started":"2021-08-30T23:29:46.355438Z","shell.execute_reply":"2021-08-30T23:29:46.364653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_report = classification_report(y_test, y_test_estimation, digits=4)\nprint(\"Test:\\n\",test_report)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:47.363219Z","iopub.execute_input":"2021-08-30T23:29:47.363925Z","iopub.status.idle":"2021-08-30T23:29:47.375954Z","shell.execute_reply.started":"2021-08-30T23:29:47.363864Z","shell.execute_reply":"2021-08-30T23:29:47.374755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ID = test['id'].copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:51.535042Z","iopub.execute_input":"2021-08-30T23:29:51.535409Z","iopub.status.idle":"2021-08-30T23:29:51.54358Z","shell.execute_reply.started":"2021-08-30T23:29:51.535372Z","shell.execute_reply":"2021-08-30T23:29:51.54229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test = grid_search.best_estimator_.named_steps['preprocessor'].transform(variables_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:52.689365Z","iopub.execute_input":"2021-08-30T23:29:52.689771Z","iopub.status.idle":"2021-08-30T23:29:52.791964Z","shell.execute_reply.started":"2021-08-30T23:29:52.689736Z","shell.execute_reply":"2021-08-30T23:29:52.790642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted_test = grid_search.best_estimator_.named_steps['classify'].predict_proba(final_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:55.146444Z","iopub.execute_input":"2021-08-30T23:29:55.146872Z","iopub.status.idle":"2021-08-30T23:29:55.256323Z","shell.execute_reply.started":"2021-08-30T23:29:55.146836Z","shell.execute_reply":"2021-08-30T23:29:55.255232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.DataFrame({'Id': test_ID, 'target': y_predicted_test})","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:55.952737Z","iopub.execute_input":"2021-08-30T23:29:55.953362Z","iopub.status.idle":"2021-08-30T23:29:55.960759Z","shell.execute_reply.started":"2021-08-30T23:29:55.953327Z","shell.execute_reply":"2021-08-30T23:29:55.960047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.to_csv('LightGBM_output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:29:59.577757Z","iopub.execute_input":"2021-08-30T23:29:59.578422Z","iopub.status.idle":"2021-08-30T23:29:59.666834Z","shell.execute_reply.started":"2021-08-30T23:29:59.578386Z","shell.execute_reply":"2021-08-30T23:29:59.665809Z"},"trusted":true},"execution_count":null,"outputs":[]}]}