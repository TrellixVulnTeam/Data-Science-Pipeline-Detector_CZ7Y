{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Gathering Domain knowledge\nI haven't yet watched American football ! If you are a guy like me,this video might be helpful to understand how the game works.To proceed with this competition we need a bit of domain knowledge.So try watching this video..\n[Youtube](https://www.youtube.com/watch?v=Ddwp1HyEFRE)\n"},{"metadata":{},"cell_type":"markdown","source":"<font color='violet' size=5> What is in this kernel?</font>\n- Getting basic idea about the problem.\n- Handling Missing values.\n- Data preparation and processing.\n- Baseline model.\n- Evaluation.\n- Predicting on test. \n- Making our submission.\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://media.giphy.com/media/Vj9cncmZLtXG0/giphy.gif)"},{"metadata":{},"cell_type":"markdown","source":"<font color='red' size=5>Please consider giving an upvote if you feel this notebook was helpful</font>\n### Importing Required Libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nfrom kaggle.competitions import nflrush\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom keras import Sequential\nfrom keras.layers import Dense,BatchNormalization,Dropout\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau\nimport datetime\nimport tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Getting a basic Idea\n- Each row of the train dataframe contains the attributes of a single player in the match with the target value.\n- There are 22 players in a single game.\n- Each of this 22 player participating in game has a row.\n- This mean that we have 509762 / 22 = 23171 samples effectively.\n- There are many missing values in different columns,WindSpeed, WindDirection, Temperature, GameWeather, Humidity, StadiumType, and FieldPosition.\n- We will preprocess the data and make it in a trainable form.\n\n"},{"metadata":{},"cell_type":"markdown","source":"#### Setting up the environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"env=nflrush.make_env()\ndf_train=pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The train dataframe contrains {} rows and {} columns'.format(df_train.shape[0],df_train.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  handling missing values...\nThanks to this wonderful\n[Kernel](https://www.kaggle.com/jastornaut/nfl-eda-ftw-lean-clean-and-astroturf-green) by  Jeff Astor."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_train.isna().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check windspeed"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_train['WindSpeed'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling values in windspeed"},{"metadata":{},"cell_type":"markdown","source":"- There are many different type of values in Windspeed,we will clean them.\n- We will remove mph/MPH if its present\n- we will return average value if there is a range of values eg(11 - 15).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def windspeed(x):\n    x=str(x)\n    if x.isdigit():\n        return int(x)\n    elif (x.isalpha()):\n        return 0\n    elif (x.isalnum()):\n        return int(x.upper().split('M')[0])                             #return 12 incase of 12mp or 12 MPH\n    elif '-' in x:\n        return int((int(x.split('-')[0])+int(x.split('-')[1]))/2)   # return average windspeed incase of 11 - 20 etc..\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['WindSpeed']=df_train['WindSpeed'].apply(windspeed)\ndf_train['WindSpeed'].fillna(df_train['WindSpeed'].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_train['WindSpeed'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yeh,We have cleaned all the windspeed values.\n\n### WindDirection values"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_train['WindDirection'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This function has been updated to reflect what Subin An (https://www.kaggle.com/subinium) mentioned in comments below.\n# WindDirection is indicated by the direction that wind is flowing FROM - https://en.wikipedia.org/wiki/Wind_direction\n\ndef clean_wind_direction(wind_direction):\n    wd = str(wind_direction).upper()\n    if wd == 'N' or 'FROM N' in wd:\n        return 'north'\n    if wd == 'S' or 'FROM S' in wd:\n        return 'south'\n    if wd == 'W' or 'FROM W' in wd:\n        return 'west'\n    if wd == 'E' or 'FROM E' in wd:\n        return 'east'\n    \n    if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n        return 'south west'\n    if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n        return 'south east'\n    if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n        return 'north west'\n    if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n        return 'north east'\n    \n    if 'NW' in wd or 'NORTHWEST' in wd:\n        return 'north west'\n    if 'NE' in wd or 'NORTH EAST' in wd:\n        return 'north east'\n    if 'SW' in wd or 'SOUTHWEST' in wd:\n        return 'south west'\n    if 'SE' in wd or 'SOUTHEAST' in wd:\n        return 'south east'\n\n    return 'none'\n\ndf_train['WindDirection'] = df_train['WindDirection'].apply(clean_wind_direction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unhide above cell**"},{"metadata":{},"cell_type":"markdown","source":"### Handling humidity and Temperature\n- We will just fill the values using forward filling technique"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Humidity'].fillna(method='ffill', inplace=True)\ndf_train['Temperature'].fillna(method='ffill', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling Game wheather and Stadium types"},{"metadata":{"trusted":true},"cell_type":"code","source":"na_map = {\n    'Orientation': df_train['Orientation'].mean(),\n    'Dir': df_train['Dir'].mean(),\n    'DefendersInTheBox': np.math.ceil(df_train['DefendersInTheBox'].mean()),\n    'OffenseFormation': 'UNKNOWN'\n}\n\ndf_train.fillna(na_map, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def group_game_weather(weather):\n    rain = [\n        'Rainy', 'Rain Chance 40%', 'Showers',\n        'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n        'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain'\n    ]\n    overcast = [\n        'Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n        'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n        'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n        'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n        'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n        'Partly Cloudy', 'Cloudy'\n    ]\n    clear = [\n        'Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n        'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n        'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n        'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n        'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n        'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny'\n    ]\n    snow  = ['Heavy lake effect snow', 'Snow']\n    none  = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n    \n    if weather in rain:\n        return 'rain'\n    elif weather in overcast:\n        return 'overcast'\n    elif weather in clear:\n        return 'clear'\n    elif weather in snow:\n        return 'snow'\n    elif weather in none:\n        return 'none'\n    \n    return 'none'\n\ndf_train['GameWeather'] = df_train['GameWeather'].apply(group_game_weather)\n\ndf_train['FieldPosition'] = np.where(df_train['YardLine'] == 50, df_train['PossessionTeam'], df_train['FieldPosition'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def group_stadium_types(stadium):\n    outdoor       = [\n        'Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', \n        'Outdor', 'Ourdoor', 'Outside', 'Outddors', \n        'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl'\n    ]\n    indoor_closed = [\n        'Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', \n        'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed',\n    ]\n    indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n    dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n    dome_open     = ['Domed, Open', 'Domed, open']\n    \n    if stadium in outdoor:\n        return 'outdoor'\n    elif stadium in indoor_closed:\n        return 'indoor closed'\n    elif stadium in indoor_open:\n        return 'indoor open'\n    elif stadium in dome_closed:\n        return 'dome closed'\n    elif stadium in dome_open:\n        return 'dome open'\n    else:\n        return 'unknown'\n    \ndf_train['StadiumType'] = df_train['StadiumType'].apply(group_stadium_types)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unhide above cell**\n- The stadium types and weather is cleaned."},{"metadata":{},"cell_type":"markdown","source":"### BirthDate, GameHour and Time\n- we will extract and consider Birth year of each player\n- We will extract and consider Hour from GameClock\n- We will calucate TimeDelta by subtracting TimeSnap from TimeHandoff .\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['TimeHandoff'] = df_train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\ndf_train['TimeSnap'] = df_train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\ndf_train['TimeDelta'] = df_train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\ndf_train.drop(['TimeSnap','TimeHandoff'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['BirthYear']=df_train['PlayerBirthDate'].apply(lambda x : int(x.split('/')[2]))\ndf_train['GameHour']=df_train['GameClock'].apply(lambda x : int(x.split(':')[0]))\n\ndf_train.drop(['PlayerBirthDate',\"GameClock\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['PlayerHeight']=df_train['PlayerHeight'].apply(lambda x : np.mean(list(map(int,x.split('-')))))\n#df_train.drop('PlayerHeight',axis=1,inplace=True)                                                       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DefensePersonnel\n"},{"metadata":{},"cell_type":"markdown","source":" - We will split the DefensePersonnel variable into **DL , LB ,  BL , OL**\n - We will filter them and store them as int variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_defense(x):\n    num=[]\n    num=x.split(',')\n    dl=int(num[0].split(' ')[0])\n    lb=int(num[1].split(' ')[1])\n    db=int(num[2].split(' ')[1])\n    if(len(num)>3):\n         ol=int(num[3].split(' ')[1])\n    else:\n         ol=0\n    return [dl,lb,db,ol]\n\nvalues=df_train['DefensePersonnel'].apply(process_defense)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"u,v,x,y=list(map(list,zip(*values)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['DL']=u\ndf_train['LB']=v\ndf_train['BL']=x\ndf_train['OL']=y\ndf_train.drop(['DefensePersonnel'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding values..\n- In this step we will encode all categorical variables.\n- we will use Label Encoding for this.\n- we will store each of instances in a dictionary for later use during test set preparation."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_obj=[]\nfor c in df_train.columns:\n    if(df_train[c].dtype != int):\n            try:\n                df_train[c]=df_train[c].astype('float16')\n            except:\n                new_obj.append(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbdic={}\nfor c in new_obj:\n    lb=LabelEncoder()\n    lb=lb.fit(df_train[c].values)\n    lbdic[c]=lb\n    df_train[c]=lb.transform(df_train[c].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preparation"},{"metadata":{},"cell_type":"markdown","source":"In the below session we will process and prepare data inorder to feed it to our model.\n- First,we will drop some columns which are not relevant.\n- we will classify our varibles into three lists ,is one,two and more.\n- one contains variable having unique values.\n- more contains variables having more than 2 different values."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_drop=['GameId','PlayId','NflId','NflIdRusher']\none=[]\ntwo=[]\nmore=[]\nfor col in df_train.drop(columns_drop,axis=1).columns:\n    if df_train[col][:22].nunique() <2:\n        one.append(col)\n    elif df_train[col][:22].nunique() <=2:\n        two.append(col)\n    else:\n        more.append(col)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The number of attributes for preprocessing =',len(one)+len(two)+len(more))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"During the next steps we will actually convert the data to our required form.Each row in the output dataframe will represent a game.Our target variable is Yards,which is the the yardage gained on the play."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_cols=[]\nfor col in more:\n    for i in range(0,11):\n        new_cols.append(str(col)+'A'+str(i))\n    for i in range(0,11):\n         new_cols.append(str(col)+'B'+str(i))\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.DataFrame()\nx=np.tile(np.arange(0,22),14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=[]\nfor c in more:\n\n    for  i in range(0,22):\n         out.append(df_train[i:len(df_train):22][c].values)\n        \n        \n        \nfor col in zip(new_cols,np.arange(len(out))):\n    train[col]=out[i]\nout=np.array(out).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.DataFrame(data=out,columns=new_cols)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next step we will group our dataframe using PlayId and select values from columns which are labelled as **one**."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_one=df_train.groupby(['PlayId'])[one].first()\nfor col in df_one.columns:\n    train[col]=df_one[col].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check our target variable distribution.."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['Yards'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_object=[]\nobj=[]\nfor col in more+one:\n    if df_train[col].dtype != 'object':\n        not_object.append(col)\n    else:\n        obj.append(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will split our train and taget variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop('Yards',axis=1)\ny=train['Yards']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keras model\n- In this section we will use keras Sequencial models to build our model.\n- We will use Dropout and BatchNormalization.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model=Sequential()\n    model.add(Dense(356,input_shape=[X.shape[1]],activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.4))\n    model.add(Dense(200,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.4))\n    model.add(Dense(256,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.3))\n    model.add(Dense(212,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.3))\n    model.add(Dense(199,activation='sigmoid'))\n\n    optimizer=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)\n    model.compile(optimizer=optimizer,loss=['mse'],metrics=['accuracy'])\n    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                                patience=3, \n                                                verbose=1, \n                                                factor=0.5, \n                                                min_lr=0.00001)\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will also convert our Target variable to appropriate form.Ie 199 x 1 array."},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_y(X_train,y_train):\n    Y_train=np.zeros((X_train.shape[0],199))\n    for i,yard in enumerate(y_train):\n        Y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n    \n    return Y_train\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KFold cross validation.."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkfold=KFold(n_splits=3,shuffle=True)\n\nfor train_ind,val in kfold.split(X,y):\n    \n    x_train,xval = X.iloc[train_ind],X.iloc[val]\n    y_train,yval= y.iloc[train_ind],y.iloc[val]\n    \n    y_train=transform_y(x_train,y_train)\n    y_val=transform_y(xval,yval)\n    \n    model=None\n    model=create_model()\n    \n    history=model.fit(x_train,y_train,epochs=20,validation_data=[xval,y_val],verbose=0)\n    print('validation accuracy : {}'.format(np.mean(history.history['val_accuracy'])))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will also use learning rate reducer to reduce learning rate and help it converge easily to minima point."},{"metadata":{},"cell_type":"markdown","source":"## Making prediction"},{"metadata":{},"cell_type":"markdown","source":"- This function is to prepare and predict on test data.\n- We will have to replicate all the data processing steps that we have done above in this function.\n- This ensures that our data is made fit for prediction.\n- In this competition we will have to use **env.iter_test()** and **env.predict()**.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_prediction(test,sample,env,model,df_train):\n    \n    na_map = {\n    'Orientation': df_train['Orientation'].mean(),\n    'Dir': df_train['Dir'].mean(),\n    'DefendersInTheBox': 7.0,\n    'OffenseFormation': 'UNKNOWN','WindSpeed':df_train['WindSpeed'].mean()\n    }\n\n    test.fillna(na_map, inplace=True)\n    test['Temperature'].fillna(61.0,inplace=True)\n    test['WindSpeed']=test['WindSpeed'].apply(windspeed)\n    #test['WindSpeed'].fillna(df_train['WindSpeed'].mean(),inplace=True)\n\n    test['GameWeather'] = test['GameWeather'].apply(group_game_weather)\n    test['FieldPosition'] = np.where(test['YardLine'] == 50, test['PossessionTeam'], test['FieldPosition'])\n    test['StadiumType'] = test['StadiumType'].apply(group_stadium_types)\n    test['WindDirection'] = test['WindDirection'].apply(clean_wind_direction)\n    \n    test['TimeHandoff'] = test['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    test['TimeSnap'] = test['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    test['TimeDelta'] = test.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    test.drop(['TimeSnap','TimeHandoff'],axis=1,inplace=True)\n   \n    test['PlayerHeight']=test['PlayerHeight'].apply(lambda x : np.mean(list(map(int,x.split('-')))))\n\n\n\n\n    test['BirthYear']=test['PlayerBirthDate'].apply(lambda x : int(x.split('/')[2]))\n    test['GameHour']=test['GameClock'].apply(lambda x : int(x.split(':')[0]))\n    test.drop(['PlayerBirthDate',\"GameClock\"],axis=1,inplace=True)\n\n    values=test['DefensePersonnel'].apply(process_defense)\n    u,v,x,y=list(map(list,zip(*values)))\n    test['DL']=u\n    test['LB']=v\n    test['BL']=x\n    test['OL']=y\n    test.drop(['DefensePersonnel'],axis=1,inplace=True)\n    \n    new_obj=[]\n    for c in test.columns:\n        if(test[c].dtype != int):\n                try:\n                    test[c]=test[c].astype('float16')\n                except:\n                    new_obj.append(c)\n\n    for c in new_obj:\n        try:\n            test[c]=lbdic[c].transform(test[c].values)\n        except:\n            l=LabelEncoder()\n            test[c]=l.fit_transform(test[c].values)\n            \n    \n    columns_drop=['GameId','PlayId','NflId','NflIdRusher']\n    one=[]\n    two=[]\n    more=[]\n    for col in test.drop(columns_drop,axis=1).columns:\n        if test[col][:22].nunique() <2:\n            one.append(col)\n        elif test[col][:22].nunique() <=2:\n            two.append(col)\n        else:\n            more.append(col)\n        \n\n    new_cols=[]\n    for col in more:\n        for i in range(0,11):\n            new_cols.append(str(col)+'A'+str(i))\n        for i in range(0,11):\n             new_cols.append(str(col)+'B'+str(i))\n\n    \n\n    out=[]\n    for c in more:\n        out.append(test[c].values)\n    \n   \n    new_out=[]\n    for i in out:\n        for j in i:\n            new_out.append(j)\n\n    new_test=pd.DataFrame(data=[new_out],columns=new_cols)\n\n    df_one=test.groupby(['PlayId'])[one].first()\n    for col in df_one.columns:\n        new_test[col]=df_one[col].values\n\n    \n    new_test.fillna(na_map,inplace=True)\n    new_test['Temperature'].fillna(61.0,inplace=True)\n        \n    y_pred=np.zeros((1,199))\n    \n    y_pred = model.predict(new_test)\n    \n        \n    for pred in y_pred:\n        prev = 0\n        for i in range(len(pred)):\n            if pred[i]<prev:\n                pred[i]=prev\n            prev=pred[i]\n    \n    y_pred[:, -1] = np.ones(shape=(y_pred.shape[0], 1))\n    y_pred[:, 0] = np.zeros(shape=(y_pred.shape[0], 1))\n  \n    pred=pd.DataFrame(data=y_pred,columns=sample.columns)\n    env.predict(pred)\n\n    return y_pred\n\n        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submitting to competition.."},{"metadata":{"trusted":true},"cell_type":"code","source":"#model=create_model()\nfor test, sample in tqdm.tqdm(env.iter_test()):\n    make_prediction(test,sample,env,model,df_train)\n    \nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='red' size=5 >Please do upvote if you like my work..</font>\n\n<p><font color='blue' size=4>Comments are most welcomed</font></p>\n\n<font color='green' size=3>Kernel under construction !!!</font>\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}