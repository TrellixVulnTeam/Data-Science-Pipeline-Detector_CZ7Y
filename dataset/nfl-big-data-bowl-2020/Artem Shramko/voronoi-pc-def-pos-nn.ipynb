{"cells":[{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:34.444922Z","start_time":"2019-11-06T13:27:30.768021Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nTRAIN_ABLE_FALSE=True\nif TRAIN_ABLE_FALSE:\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\nimport numpy as np\nimport pandas as pd\nimport sklearn.metrics as mtr\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.callbacks import Callback\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport datetime\n\nimport math\nimport scipy\nfrom random import choice\nfrom scipy.spatial.distance import euclidean\nfrom scipy.special import expit\nfrom tqdm import tqdm\n\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\n\nTRAIN_OFFLINE = False\n\n\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn.metrics as mtr\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold\nimport time\n\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization,LeakyReLU,PReLU,ELU,ThresholdedReLU,Concatenate\nfrom keras.models import Model\nimport keras.backend as K\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.optimizers import Adam\nimport re\nfrom keras.losses import binary_crossentropy\nfrom  keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\nimport codecs\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import f1_score\n\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline\n\nTRAIN_OFFLINE = False\n\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 150)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:34.450789Z","start_time":"2019-11-06T13:27:34.447583Z"},"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:37.305506Z","start_time":"2019-11-06T13:27:34.452843Z"},"trusted":true},"cell_type":"code","source":"# train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\nif TRAIN_OFFLINE:\n    train = pd.read_csv('../input/train.csv', dtype={'WindSpeed': 'object'})\nelse:\n    train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n    ","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:37.336457Z","start_time":"2019-11-06T13:27:37.308386Z"},"trusted":true},"cell_type":"code","source":"outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:37.385294Z","start_time":"2019-11-06T13:27:37.340021Z"},"trusted":true},"cell_type":"code","source":"\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Field Control"},{"metadata":{"trusted":true},"cell_type":"code","source":"def positional(df):\n    \n    \n    # Offense\n    offensive_line = [\"G\",\"C\",\"T\", \"OL\"] #calculate their force, distance of runner to centroid, st.d.\n    running_back = [\"RB\",\"FB\",\"HB\",\"TB\",\"WB\"] # running back, oposing\n    wide_receiver = [\"SE\",\"FL\",\"SL\"] #run fast\n\n    # Defense\n    defensive_line = [\"DL\",\"DT\",\"NT\",\"DE\"] #force\n    lineback = [\"LB\",\"OLB\",\"ILB\",\"MLB\"] # force, speed\n    defensive_back = [\"DB\",\"SS\",\"FS\",\"CB\",\"NB\"]\n\n    def field_position(x):\n        if x in offensive_line:\n            return \"OL\"\n        if x in running_back:\n            return \"RB\"\n        if x in wide_receiver:\n            return \"WR\"\n        if x in defensive_line:\n            return \"DL\"\n        if x in lineback:\n            return \"LB\"\n        if x in defensive_back:\n            return \"DB\"\n\n    df[\"pos_group\"] = df[\"Position\"].apply(field_position)\n    \n    df[\"Force\"] = df[[\"A\",\"PlayerWeight\"]].apply(lambda x: max(x[0]*x[1],x[1]),axis=1)\n    \n    # Rusher feats\n\n    rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Dir_std', 'S', 'A', 'X_std', 'Y_std', \"Force\",\"Voronoi\"]]\n                                                 # \"IsBallCarrier\", \"IsOnOffense\"]]\n    rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS', 'RusherA', 'RusherX', 'RusherY',\"RusherForce\",\"RusherVoronoi\"]\n\n    df = df.merge(rusher,on=['GameId','PlayId'], how='inner')\n\n    init_cols = df.columns\n    \n    # Offense\n\n    df[\"OL_force\"] = df[df[\"pos_group\"]==\"OL\"].groupby([\"GameId\",\"PlayId\"])[\"Force\"].transform(\"mean\")\n    df[\"OL_Voronoi\"] = df[df[\"pos_group\"]==\"OL\"].groupby([\"GameId\",\"PlayId\"])[\"Voronoi\"].transform(\"sum\")\n    df[\"OL_X\"] = df[df[\"pos_group\"]==\"OL\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    df[\"OL_Y\"] = df[df[\"pos_group\"]==\"OL\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"mean\")\n\n    df[\"RB_force\"] = df[df[\"pos_group\"]==\"RB\"].groupby([\"GameId\",\"PlayId\"])[\"Force\"].transform(\"mean\")\n    df[\"RB_Voronoi\"] = df[df[\"pos_group\"]==\"RB\"].groupby([\"GameId\",\"PlayId\"])[\"Voronoi\"].transform(\"sum\")\n    df[\"RB_X\"] = df[df[\"pos_group\"]==\"RB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    df[\"RB_Y\"] = df[df[\"pos_group\"]==\"RB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"mean\")\n\n\n    #df[\"WR_force\"] = df[df[\"pos_group\"]==\"WR\"].groupby([\"GameId\",\"PlayId\"])[\"Force\"].transform(\"mean\")\n    #df[\"WR_Voronoi\"] = df[df[\"pos_group\"]==\"WR\"].groupby([\"GameId\",\"PlayId\"])[\"Voronoi\"].transform(\"mean\")\n    #df[\"WR_speed\"] = df[df[\"pos_group\"]==\"WR\"].groupby([\"GameId\",\"PlayId\"])[\"S\"].transform(\"mean\")\n\n    # Defense\n\n    df[\"DL_force\"] = df[df[\"pos_group\"]==\"DL\"].groupby([\"GameId\",\"PlayId\"])[\"Force\"].transform(\"mean\")\n    df[\"DL_Voronoi\"] = df[df[\"pos_group\"]==\"DL\"].groupby([\"GameId\",\"PlayId\"])[\"Voronoi\"].transform(\"sum\")\n    df[\"DL_X\"] = df[df[\"pos_group\"]==\"DL\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    df[\"DL_Y\"] = df[df[\"pos_group\"]==\"DL\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"mean\")\n\n    df[\"LB_force\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"Force\"].transform(\"mean\")\n    df[\"LB_Voronoi\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"Voronoi\"].transform(\"sum\")\n    df[\"LB_X\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    df[\"LB_Y\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"mean\")\n    #df[\"LB_Y_stdiv\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"std\")\n    #df[\"LB_X_stdiv\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"std\")\n\n    #df[\"LB_Y_spread\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"max\") -\\\n    #                    df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"min\")\n    #df[\"LB_X_spread\"] = df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"max\") -\\\n    #                df[df[\"pos_group\"]==\"LB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"min\")\n\n    df[\"DB_force\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"Force\"].transform(\"mean\")\n    df[\"DB_Voronoi\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"Voronoi\"].transform(\"sum\")\n    df[\"DB_speed\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"S\"].transform(\"mean\")\n    df[\"DB_X\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    df[\"DB_Y\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"mean\")\n   # df[\"DB_Y_stdiv\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"std\")\n   # df[\"DB_X_stdiv\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"std\")\n   # df[\"DB_Y_spread\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"max\") - \\\n   #                     df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"min\")\n   # df[\"DB_X_spread\"] = df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"max\") - \\\n   #                     df[df[\"pos_group\"]==\"DB\"].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"min\")\n\n    pos_cols = [\"OL_force\", \"OL_Voronoi\", \"OL_X\", \"OL_Y\",\n                \"RB_force\", \"RB_Voronoi\", \"RB_X\", \"RB_Y\",\n                #\"WR_force\", #\"WR_speed\", \"WR_Voronoi\", \n                \"DL_force\", \"DL_Voronoi\", \"DL_X\", \"DL_Y\", \n                \"LB_force\", \"LB_Voronoi\", \"LB_X\", \"LB_Y\", #\"LB_Y_spread\", \"LB_Y_stdiv\", \"LB_X_stdiv\", \"LB_X_spread\",\n                \"DB_force\", \"DB_speed\", \"DB_Voronoi\",\"DB_X\", \"DB_Y\"] #\"DB_Y_stdiv\", \"DB_Y_spread\",\"DB_X_spread\", \"DB_X_stdiv\"]\n\n    for col in pos_cols:\n        df[col] = df.groupby([\"GameId\",\"PlayId\"])[col].transform(lambda grp: grp.fillna(np.mean(grp)))\n\n    df[\"OL_vs_DL_Force\"] = df[\"OL_force\"] - df[\"DL_force\"]\n    #df[\"OL_vs_DL_Voronoi\"] = df[\"OL_Voronoi\"] - df[\"DL_Voronoi\"]\n\n    df[\"RB_vs_LB_Force\"] = df[\"RB_force\"] - df[\"LB_force\"]\n    df[\"RB_vs_LB_Voronoi\"] =  df[\"RB_Voronoi\"] - df[\"LB_Voronoi\"] \n    \n    df[\"Rusher_vs_LB_Force\"] = df[\"RusherForce\"] - df[\"LB_force\"]\n    df[\"Rusher_vs_LB_Voronoi\"] = df[\"RusherVoronoi\"] - df[\"LB_Voronoi\"]\n\n    df[\"Rusher_vs_DL_Force\"] = df[\"RusherForce\"] - df[\"DL_force\"]\n    df[\"Rusher_vs_DL_Voronoi\"] = df[\"RusherVoronoi\"] - df[\"DL_Voronoi\"]\n    \n    \n    #df[\"WR_vs_DB_Force\"] = df[\"WR_force\"] - df[\"DB_force\"]\n    #df[\"WR_vs_DB_Voronoi\"] = df[\"WR_Voronoi\"] - df[\"DB_Voronoi\"]\n    #df[\"WR_vs_DB_speed\"] = df[\"WR_speed\"] - df[\"DB_speed\"]\n    \n    # Euclidean distances\n\n    #df[\"dist_to_DL\"] = df[[\"DL_X\", \"DL_Y\", \"RusherX\",\"RusherY\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    df[\"dist_to_DL\"] = ((df[\"RusherX\"]-df[\"DL_X\"])**2+(df[\"RusherY\"]-df[\"DL_Y\"])**2)**0.5\n    \n    #df[\"dist_to_LB\"] = df[[\"LB_X\", \"LB_Y\", \"RusherX\",\"RusherY\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    df[\"dist_to_LB\"] = ((df[\"RusherX\"]-df[\"LB_X\"])**2+(df[\"RusherY\"]-df[\"LB_Y\"])**2)**0.5\n\n    #df[\"dist_RB_to_LB\"] = df[[\"LB_X\", \"LB_Y\", \"RB_X\",\"RB_Y\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    df[\"dist_RB_to_LB\"] = ((df[\"LB_X\"]-df[\"RB_X\"])**2+(df[\"LB_Y\"]-df[\"RB_Y\"])**2)**0.5\n\n    #df[\"dist_to_DB\"] = df[[\"DB_X\", \"DB_Y\", \"RusherX\",\"RusherY\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    #df[\"dist_to_RB\"] = ((df[\"RusherX\"]-df[\"RB_X\"])**2+(df[\"RusherY\"]-df[\"RB_Y\"])**2)**0.5\n    \n    #df[\"dist_to_OL\"] = df[[\"OL_X\", \"OL_Y\", \"RusherX\",\"RusherY\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    #df[\"dist_to_OL\"] = ((df[\"RusherX\"]-df[\"OL_X\"])**2+(df[\"RusherY\"]-df[\"OL_Y\"])**2)**0.5\n\n    #df[\"dist_to_RB\"] = df[[\"RB_X\", \"RB_Y\", \"RusherX\",\"RusherY\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    #df[\"dist_to_DB\"] = ((df[\"RusherX\"]-df[\"DB_X\"])**2+(df[\"RusherY\"]-df[\"DB_Y\"])**2)**0.5\n    \n    drop_cols = [ \"OL_X\", \"OL_Y\",\"RB_X\", \"RB_Y\",\"LB_X\", \"LB_Y\",\"DL_X\", \"DL_Y\",\"DB_X\", \"DB_Y\"]\n\n    force_cols = [col for col in pos_cols if \"force\" in col]\n    #Xs = [col for col in pos_cols if \"X\" in col]\n    #Ys = [col for col in pos_cols if \"Y\" in col]\n    \n    df.drop(force_cols, axis=1, inplace = True)\n    df.drop(drop_cols, axis=1, inplace = True)\n    #df.drop(Xs, axis=1, inplace=True)\n    #df.drop(Ys, axis=1, inplace=True)\n\n    new_cols = [col for col in df.columns.values if col not in init_cols]\n    \n    return df, new_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"def get_play_control(df):\n    \n    #cols = list(df.columns)\n    \n    rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Dir_std', 'S', 'A', 'X_std', 'Y_std']]\n                                                 # \"IsBallCarrier\", \"IsOnOffense\"]]\n    rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS', 'RusherA', 'RusherX', 'RusherY']\n\n    df = df.merge(rusher,on=['GameId','PlayId'], how='inner')\n\n\n    df[\"theta\"] = df[\"Orientation_std\"].apply(math.radians)\n    df[\"dist_to_ball\"] = df[['X_std', 'Y_std', 'RusherX', 'RusherY']].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    df[\"RADIUS\"] = df[\"dist_to_ball\"].apply(radius_calc)\n    df[\"S_ratio\"] = df[\"S\"].apply(lambda x: (x/13)**2)\n    \n    df[\"influence\"] = df[[\"RADIUS\", \"S_ratio\", \"theta\", \"RusherX\", \"RusherY\", \"S\", \"X_std\", \"Y_std\" ]].apply(lambda x: influence(*x), axis=1)\n    play_control = df[df[\"IsOnOffense\"]].groupby(['GameId','PlayId'])[\"influence\"].sum() - df[~df[\"IsOnOffense\"]].groupby(['GameId','PlayId'])[\"influence\"].sum()\n    df = pd.merge(df, play_control.rename(\"play_control\"),on=['GameId','PlayId'],how='inner')    \n    #cols.append(\"influence\")\n    #cols.append(\"play_control\")\n    \n    #df.drop(rusher.columns, axis=1, inplace=True)\n    #df.drop([\"theta\", \"dist_to_ball\", \"RADIUS\", \"S_ratio\"], axis=1, inplace=True)\n    \n    return df[['GameId','PlayId', \"influence\", \"play_control\"]]\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_def_feats(df):\n    \n    \"\"\"\n    'secondsLeftInHalf',\n    'numericFormation',\n    \"Defense_X_stdiv\", \n    \"Defense_Y_stdiv\", \n    \"Defense_Y_spread\", \n    \"Defense_X_spread\", \n    \"min_time_to_tackle\",\n    \"mean_time_to_tackle\",\n    \"dist_to_offense_centroid\",\n    \"dist_to_defense_centroid\"\n    \"\"\"\n    \n    def translate_game_clock(row):\n        raw_game_clock = row['GameClock']\n        quarter = row['Quarter']\n        minutes, seconds_raw = raw_game_clock.partition(':')[::2]\n\n        seconds = seconds_raw.partition(':')[0]\n\n        total_seconds_left_in_quarter = int(seconds) + (int(minutes) * 60)\n\n        if quarter == 3 or quarter == 1:\n            return total_seconds_left_in_quarter + 900\n        elif quarter == 4 or quarter == 2:\n            return total_seconds_left_in_quarter\n    \n    df['secondsLeftInHalf'] = df.apply(translate_game_clock, axis=1)\n    \n    df['OffenseFormation'] = df['OffenseFormation'].map(lambda f : 'EMPTY' if pd.isna(f) else f)\n\n    def formation(row):\n        form = row['OffenseFormation'].strip()\n        if form == 'SHOTGUN':\n            return 0\n        elif form == 'SINGLEBACK':\n            return 1\n        elif form == 'EMPTY':\n            return 2\n        elif form == 'I_FORM':\n            return 3\n        elif form == 'PISTOL':\n            return 4\n        elif form == 'JUMBO':\n            return 5\n        elif form == 'WILDCAT':\n            return 6\n        elif form=='ACE':\n            return 7\n        else:\n            return -1\n\n    %time df['numericFormation'] = df.apply(formation, axis=1)\n    \n    # X and Y st.d.\n    df[\"Defense_X_stdiv\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"std\")\n    df[\"Defense_Y_stdiv\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"std\")\n\n    # Y spread\n    df[\"Defense_Y_max\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"max\") \n    df[\"Defense_Y_min\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"Y_std\"].transform(\"min\")\n    df[\"Defense_Y_spread\"] = df[\"Defense_Y_max\"] - df[\"Defense_Y_min\"]\n\n    # X spread\n    df[\"Defense_X_max\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"max\") \n    df[\"Defense_X_min\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"min\")\n    df[\"Defense_X_spread\"] = df[\"Defense_X_max\"] - df[\"Defense_X_min\"]\n        \n    # time to tackle\n    df[\"time_to_tackle\"] = df[\"dist_to_ball\"]/df[\"S\"].apply(lambda x: max(x,1))  \n    df[\"min_time_to_tackle\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"time_to_tackle\"].transform(\"min\")\n    df[\"mean_time_to_tackle\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"time_to_tackle\"].transform(\"mean\")\n    \n    #centroids\n    df[\"Offense_X\"] = df[df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    df[\"Offense_Y\"] = df[df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    \n    df[\"Defense_X\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    df[\"Defense_Y\"] = df[~df[\"IsOnOffense\"]==True].groupby([\"GameId\",\"PlayId\"])[\"X_std\"].transform(\"mean\")\n    \n    for col in [\"Defense_X_stdiv\", \"Defense_Y_stdiv\", \"Defense_Y_spread\", \"Defense_X_spread\", \n                \"min_time_to_tackle\",\"mean_time_to_tackle\",\n               \"Offense_X\",\"Offense_Y\",\"Defense_X\",\"Defense_Y\"]:\n        df[col] = df.groupby([\"GameId\",\"PlayId\"])[col].transform(lambda grp: grp.fillna(np.mean(grp)))\n        \n    #df[\"dist_to_offense_centroid\"] = df[[\"Offense_X\", \"Offense_Y\", \"RusherX\",\"RusherY\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    df[\"dist_to_offense_centroid\"] = ((df[\"RusherX\"]-df[\"Offense_X\"])**2+(df[\"RusherY\"]-df[\"Offense_Y\"])**2)**0.5\n\n    #df[\"dist_to_defense_centroid\"] = df[[\"Defense_X\", \"Defense_Y\", \"RusherX\",\"RusherY\"]].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    df[\"dist_to_defense_centroid\"] = ((df[\"RusherX\"]-df[\"Defense_X\"])**2+(df[\"RusherY\"]-df[\"Defense_Y\"])**2)**0.5\n\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_play_control(df):\n    \n    # it makes sense to use unadjusted X, Y and Orientation for calculating play control\n    \n    rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Orientation', 'S', 'A', 'X', 'Y']]\n                                                 # \"IsBallCarrier\", \"IsOnOffense\"]]\n    rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS', 'RusherA', 'RusherX', 'RusherY']\n\n    df = df.merge(rusher,on=['GameId','PlayId'], how='inner')\n\n\n    df[\"theta\"] = df[\"Orientation\"].apply(math.radians)\n    #df[\"dist_to_ball\"] = df[['X', 'Y', 'RusherX', 'RusherY']].apply(lambda x: euclidean( (x[0], x[1]), (x[2], x[3]) ), axis=1)\n    df[\"dist_to_ball\"] = ((df[\"RusherX\"]-df[\"X\"])**2+(df[\"RusherY\"]-df[\"Y\"])**2)**0.5\n    df[\"RADIUS\"] = df[\"dist_to_ball\"].apply(radius_calc)\n    df[\"S_ratio\"] = df[\"S\"].apply(lambda x: (x/13)**2)\n    \n    df[\"influence\"] = df[[\"RADIUS\", \"S_ratio\", \"theta\", \"RusherX\", \"RusherY\", \"S\", \"X\", \"Y\" ]].apply(lambda x: influence(*x), axis=1)\n    #play_control = df[df[\"IsOnOffense\"]].groupby(['GameId','PlayId'])[\"influence\"].sum() - df[~df[\"IsOnOffense\"]].groupby(['GameId','PlayId'])[\"influence\"].sum()\n    #play_control.set_index(df[\"PlayId\"])\n    #df = pd.merge(df, play_control.rename(\"play_control\"),on=['PlayId'],how='inner')    \n    \n    df[\"OffenceControl\"] = df[df[\"IsOnOffense\"]].groupby(['GameId','PlayId'])[\"influence\"].transform(\"sum\") \n    df[\"DefenceControl\"] = df[~df[\"IsOnOffense\"]].groupby(['GameId','PlayId'])[\"influence\"].transform(\"sum\")\n    \n    df[\"OffenceControl\"]= df.groupby(['GameId','PlayId'])[\"OffenceControl\"].fillna(method=\"ffill\")\n    df[\"OffenceControl\"]= df.groupby(['GameId','PlayId'])[\"OffenceControl\"].fillna(method=\"bfill\")\n    df[\"DefenceControl\"]= df.groupby(['GameId','PlayId'])[\"DefenceControl\"].fillna(method=\"ffill\")\n    df[\"DefenceControl\"]= df.groupby(['GameId','PlayId'])[\"DefenceControl\"].fillna(method=\"bfill\")\n    \n    df[\"play_control\"] = df[\"OffenceControl\"] - df[\"DefenceControl\"]\n    \n    df = new_def_feats(df)\n    \n    df.drop(rusher.columns, axis=1, inplace=True)\n    df.drop([\"theta\", \"dist_to_ball\", \"RADIUS\", \"S_ratio\", \"OffenceControl\", \"DefenceControl\"], axis=1, inplace=True)\n    \n    return df\n\n\n    #cols.append(\"influence\")\n    #cols.append(\"play_control\")\n    \n    #\n    #df.drop([\"theta\", \"dist_to_ball\", \"RADIUS\", \"S_ratio\"], axis=1, inplace=True)\n    \n    #return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@np.vectorize    \ndef influence(RADIUS, S_ratio, theta, RusherX, RusherY, speed, X_std, Y_std ):\n\n    player_coords = np.array([X_std, Y_std])\n    point = np.array([RusherX, RusherY])\n    \n    S_matrix = np.matrix([[RADIUS * (1 + S_ratio), 0], [0, RADIUS * (1 - S_ratio)]])\n    R_matrix = np.matrix([[np.cos(theta), - np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n    COV_matrix = np.dot(np.dot(np.dot(R_matrix, S_matrix), S_matrix), np.linalg.inv(R_matrix))\n    \n    norm_fact = (1 / 2 * np.pi) * (1 / np.sqrt(np.linalg.det(COV_matrix)))    \n    mu_play = player_coords + speed * np.array([np.cos(theta), np.sin(theta)]) / 2\n    \n    intermed_scalar_player = np.dot(np.dot((player_coords - mu_play),\n                                    np.linalg.inv(COV_matrix)),\n                             np.transpose((player_coords - mu_play)))\n    player_influence = norm_fact * np.exp(- 0.5 * intermed_scalar_player[0, 0])\n    \n    intermed_scalar_point = np.dot(np.dot((point - mu_play), \n                                    np.linalg.inv(COV_matrix)), \n                             np.transpose((point - mu_play)))\n    point_influence = norm_fact * np.exp(- 0.5 * intermed_scalar_point[0, 0])\n\n    return point_influence / player_influence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def radius_calc(dist_to_ball):\n    ''' I know this function is a bit awkward but there is not the exact formula in the paper,\n    so I try to find something polynomial resembling\n    Please consider this function as a parameter rather than fixed\n    I'm sure experts in NFL could find a way better curve for this'''\n    return 4 + 6 * (dist_to_ball >= 15) + (dist_to_ball ** 3) / 560 * (dist_to_ball < 15)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:38.130612Z","start_time":"2019-11-06T13:27:38.110539Z"},"trusted":true},"cell_type":"code","source":"def strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x/15))\n    except:\n        return \"nan\"\ndef preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    #train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    #train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n    #train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    #train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n    ## Orientation and Dir\n    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## OffensePersonnel\n    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n    temp.columns = [\"Offense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## DefensePersonnel\n    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n    temp.columns = [\"Defense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# my code for feature cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_features(train):\n    \n    \"\"\"\n    New clean features:\n    \n    WindDirection --> WindDirection_std     #in dergees\n    \n    MatchDay\n    \n    Hight Feet\n    \n    try:\n        train.loc[train['Season'] == 2017, 'Orientation'] = np.mod(90 + train.loc[train['Season'] == 2017, 'Orientation'], 360)\n        print(\"...    | Season\")\n    except:\n        pass\n    \"\"\"\n    #########################################################################################################\n    \n    # Team names\n    \n    #########################################################################################################\n    try:\n    \n        train.loc[train.VisitorTeamAbbr == \"ARI\", 'VisitorTeamAbbr'] = \"ARZ\"\n        train.loc[train.HomeTeamAbbr == \"ARI\", 'HomeTeamAbbr'] = \"ARZ\"\n\n        train.loc[train.VisitorTeamAbbr == \"BAL\", 'VisitorTeamAbbr'] = \"BLT\"\n        train.loc[train.HomeTeamAbbr == \"BAL\", 'HomeTeamAbbr'] = \"BLT\"\n\n        train.loc[train.VisitorTeamAbbr == \"CLE\", 'VisitorTeamAbbr'] = \"CLV\"\n        train.loc[train.HomeTeamAbbr == \"CLE\", 'HomeTeamAbbr'] = \"CLV\"\n\n        train.loc[train.VisitorTeamAbbr == \"HOU\", 'VisitorTeamAbbr'] = \"HST\"\n        train.loc[train.HomeTeamAbbr == \"HOU\", 'HomeTeamAbbr'] = \"HST\"\n    except:\n        pass\n    \n    #########################################################################################################\n    \n    # Wind Direction\n    \n    #########################################################################################################\n    \n    print(\"...    | Wind Direction\")\n    \n    try:\n    \n        train['WindDirection_std'] = train['WindDirection'].fillna(0) #.apply(lambda x: x.lower())\n    except:\n        train['WindDirection_std'] = 0\n        train['WindDirection'] = \"unknown\"\n    \n    north = ['N','From S','North']\n    south = ['S','From N','South','s']\n    west = ['W','From E','West']\n    east = ['E','From W','from W','EAST','East']\n    \n    north_east = ['FROM SW','NE','NORTH EAST','North East','NorthEast','Northeast','From SW']\n    north_west = ['E','NW','NORTHWEST', 'Northwest']\n    south_east = ['SE','SOUTHEAST','Southeast']\n    south_west = ['SW','SOUTHWEST','SouthWest','Southwest']\n    \n    nne = [\"NNE\", \"From SSW\", \"N-NE\", \"North Northeast\"]\n    ene = [\"East North East\", 'ENE','From WSW']\n    ese = ['East Southeast', 'ESE','From WNW']\n    sse = [ 'From NNW', 'South Southeast','SSE']\n    ssw = [ 'From NNE', 'South Southwest','SSW']\n    wsw = [ 'From ENE', 'W-SW','West-Southwest','WSW']\n    wnw = [ 'From ESE', 'W-NW','WNW','West Northwest']\n    nnw = [ 'From SSE','North/Northwest','NNW']\n    \n    def clean_wind_dir(x):\n        if x in north:\n            return 0\n        elif x in south:\n            return 180\n        elif x in west:\n            return 270\n        elif x in east:\n            return 90\n        elif x in north_east:\n            return 45\n        elif x in north_west:\n            return 315\n        elif x in south_east:\n            return 135\n        elif x in south_west:\n            return 225\n        elif x in nne:\n            return 20\n        elif x in ene:\n            return 70\n        elif x in sse:\n            return 110\n        elif x in ssw:\n            return 200\n        elif x in wsw:\n            return 250\n        elif x in wnw:\n            return 290\n        elif x in nnw:\n            return 340\n        else:\n            return 0\n        \n    train['WindDirection_std'] = train['WindDirection_std'].apply(clean_wind_dir)\n        \n    \"\"\"\n    no_wind = ['clear','Calm']\n    #nan = ['1','8','13']\n    nan = [i for i in train['WindDirection'].fillna(\"0\") if i.isdigit()]\n\n    train['WindDirection_std'] = train['WindDirection_std'].replace(north,0)         #'north'\n    train['WindDirection_std'] = train['WindDirection_std'].replace(south,180)       #'south'\n    train['WindDirection_std'] = train['WindDirection_std'].replace(west, 270)       #'west'\n    train['WindDirection_std'] = train['WindDirection_std'].replace(east, 90)        #'east'\n    \n    train['WindDirection_std'] = train['WindDirection_std'].replace(north_east,45)   #'north_east'\n    train['WindDirection_std'] = train['WindDirection_std'].replace(north_west, 315) #'north_west'\n    train['WindDirection_std'] = train['WindDirection_std'].replace(south_east, 135) #'south_east'\n    train['WindDirection_std'] = train['WindDirection_std'].replace(south_west, 225) #'south_west'\n    \n    train['WindDirection_std'] = train['WindDirection_std'].replace(nan,0)\n    #train['WindDirection_std'] = train['WindDirection'].fillna(\"unknown\")\n    \n    train['WindDirection_std'] = train['WindDirection_std'].replace(nne, 20)         # NNE\n    train['WindDirection_std'] = train['WindDirection_std'].replace(ene, 70)         # ENE\n    train['WindDirection_std'] = train['WindDirection_std'].replace(ese, 110)        # ESE\n    train['WindDirection_std'] = train['WindDirection_std'].replace(sse, 160)        # SSE\n    train['WindDirection_std'] = train['WindDirection_std'].replace(ssw, 200)        # SSW\n    train['WindDirection_std'] = train['WindDirection_std'].replace(wsw, 250)        # WSW\n    train['WindDirection_std'] = train['WindDirection_std'].replace(wnw, 290)        # WNW\n    train['WindDirection_std'] = train['WindDirection_std'].replace(nnw, 340)        # NNW    \n    \n    train['WindDirection_std'] = train['WindDirection_std'].replace(no_wind,0)\n    #train['WindDirection_std'] = train['WindDirection'].replace(\"unknown\",0)\n\n    def winddir(x):\n        if type(x) == str:\n            return 0\n    train['WindDirection_std'] = train['WindDirection_std'].apply(winddir)\n    \n    # rotating for right-to-left plays\n    \"\"\"\n \n    #########################################################################################################\n    \n    # Wind Speed\n    \n    #########################################################################################################\n    print(\"...    | Wind Speed\")\n\n    \n    \n    def give_me_WindSpeed(txt):\n        txt = str(txt).lower().replace('mph', '').strip()\n        if '-' in txt:\n            txt = (int(txt.split('-')[0]) + int(txt.split('-')[1])) / 2\n        try:\n            return float(txt)\n        except:\n            return -1\n        \n    train['WindSpeed'] = train['WindSpeed'].apply(give_me_WindSpeed)\n    \n    #########################################################################################################\n    \n    # Weather\n    \n    #########################################################################################################\n    print(\"...    | Weather\")\n\n    \n    def give_me_GameWeather(txt):\n        txt = str(txt).lower().replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly').replace('clear and sunny', 'sunny and clear')\n        txt = txt.replace('skies', '').replace(\"mostly\", \"\").strip()\n        if \"indoor\" in txt:\n            txt = \"indoor\"\n        ans = 1\n        if pd.isna(txt):\n            return 0\n        if 'partly' in txt:\n            ans*=0.5\n        if 'climate controlled' in txt or 'indoor' in txt:\n            return ans*5\n        if 'sunny' in txt or 'sun' in txt:\n            return ans*3\n        if 'clear' in txt:\n            return ans\n        if 'cloudy' in txt:\n            return -ans\n        if 'rain' in txt or 'rainy' in txt:\n            return -3*ans\n        if 'snow' in txt:\n            return -5*ans\n        return 0\n\n    train['GameWeather_std'] = train['GameWeather'].apply(give_me_GameWeather)\n    \n    rain = ['Rainy', 'Rain Chance 40%', 'Showers','Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n        'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n\n    overcast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n                'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n                'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n                'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n                'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n                'Partly Cloudy', 'Cloudy']\n\n    clear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n            'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n            'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n            'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n            'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n            'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny', 'Sunny, Windy']\n\n    snow  = ['Heavy lake effect snow', 'Snow']\n\n    none  = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n    \n    def clean_weather(x):\n        if x in rain:\n            return \"rain\"\n        elif x in overcast:\n            return \"overcast\"\n        elif x in clear:\n            return \"clear\"\n        elif x in snow:\n            return \"snow\"\n        else:\n            return \"other\"\n    \n    train['GameWeather'] = train['GameWeather'].apply(clean_weather)\n    #train['GameWeather'] = train['GameWeather'].replace(rain,'rain')\n    #train['GameWeather'] = train['GameWeather'].replace(overcast,'overcast')\n    #train['GameWeather'] = train['GameWeather'].replace(clear,'clear')\n    #train['GameWeather'] = train['GameWeather'].replace(snow,'snow')\n    #train['GameWeather'] = train['GameWeather'].replace(none,'none')    \n    \n    #########################################################################################################\n    \n    # Turf\n    \n    #########################################################################################################   \n    print(\"...    | Turf\")\n    \n    \n    def clean_turf(x):\n        if \"art\" in x:\n            return 0\n        if \"grass\" in x:\n            return 1\n        if \"natural\" in x:\n            return 1\n        if \"turf\" in x:\n            return 0\n        else:\n            return 0\n        \n    train[\"Turf_std\"] = train[\"Turf\"].apply(lambda x: clean_turf(x.lower()))\n    \n    #########################################################################################################\n    \n    # Stadium\n    \n    #########################################################################################################      \n    print(\"...    | Stadium\")\n    \n    \n    stadium_replace = {\n    \"Twickenham Stadium\":\"Twickenham\",\n    \"Los Angeles Memorial Coliesum\":\"Los Angeles Memorial Coliseum\",\n    \"FirstEnergy Stadium\":\"FirstEnergyStadium\",\n    \"FirstEnergy\":\"FirstEnergyStadium\",\n    \"First Energy Stadium\":\"FirstEnergyStadium\",\n    \"M&T Bank Stadium\":\"M & T Bank Stadium\",\n    \"M&T Stadium\": \"M & T Bank Stadium\",\n    \"Broncos Stadium at Mile High\":\"Broncos Stadium At Mile High\",\n    \"Mercedes-Benz Dome\":\"Mercedes-Benz Stadium\",\n    \"Mercedes-Benz Superdome\": \"Mercedes-Benz Stadium\",\n    \"MetLife Stadium\":\"Metlife Stadium\",\n    \"MetLife\":\"Metlife Stadium\",\n    }\n\n    for key, value in stadium_replace.items():\n        train[\"Stadium\"] = train[\"Stadium\"].replace(key, value)\n        \n        \n    #########################################################################################################\n    \n    # Stadium Type\n    \n    #########################################################################################################           \n    \n    outdoor       = [\n    'Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', \n    'Outdor', 'Ourdoor', 'Outside', 'Outddors', \n    'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl'\n    ]\n    indoor_closed = [\n    'Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', \n    'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed',\n    ]\n    indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n    dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n    dome_open     = ['Domed, Open', 'Domed, open']\n    \n    train['StadiumType'] = train['StadiumType'].replace(outdoor, \"outdoor\")\n    train['StadiumType'] = train['StadiumType'].replace(indoor_closed, 'indoor closed')\n    train['StadiumType'] = train['StadiumType'].replace(indoor_open, 'indoor open')\n    train['StadiumType'] = train['StadiumType'].replace(dome_closed, 'dome closed')\n    train['StadiumType'] = train['StadiumType'].replace(dome_open, 'dome open')\n    \n    #########################################################################################################\n    \n    # Time\n    \n    #########################################################################################################      \n    \n    def timesnap2day(x):\n        days = x.split(\"-\")\n        return 365 * int(days[0]) + 30 * int(days[1]) + int(days[2][:2])\n    \n    train['MatchDay'] = train['TimeSnap'].apply(timesnap2day)    \n    \n    \n    print(\"...    | Time\")\n\n    def strtoseconds(txt):\n        txt = txt.split(':')\n        return int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n      \n    train['GameClock_std'] = train['GameClock'].apply(strtoseconds)    \n    \n    \n\n#     train['Birth_year'] = train['PlayerBirthDate'].apply(lambda x: int(x.split('/')[2]))\n\n    #########################################################################################################\n    \n    # Height\n    \n    #########################################################################################################    \n    train['Height_feet'] = train['PlayerHeight'].apply(lambda x: int(x.split('-')[0]))\n    #train['PlayerHeight'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n    \n    \n    \n    # Return\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_NAs(train):\n    \n    def na_categorical(x):\n        try:\n            return x.fillna(x.mode()[0])\n        except:\n            return x.fillna(method=\"ffill\")\n\n    train[\"OffenseFormation\"] = train.OffenseFormation.transform(lambda x: na_categorical(x))\n    \n    \n    train[\"StadiumType\"] = train.groupby(\"Stadium\")[\"StadiumType\"].transform(lambda x: na_categorical(x))    \n    \n    train[\"DefendersInTheBox\"] = train.groupby(\"DefensePersonnel\")[\"DefendersInTheBox\"].transform(lambda x: x.fillna(x.median()))\n    \n    try:    \n        # Weather, Temperature\n        train[\"GameWeather_std\"] = train.groupby(\"Week\")[\"GameWeather_std\"].transform(lambda x: x.median())\n    except:\n        train[\"GameWeather_std\"] = train[\"GameWeather_std\"].transform(lambda x: x.fillna(x.median()))\n\n    try:\n        train[\"Temperature\"] = train.groupby(\"Week\")[\"Temperature\"].transform(lambda x: x.fillna(x.mean()))    \n    except:\n        train['Temperature'] = train['Temperature'].fillna(train['Temperature'].median(), inplace=True)\n    \n    try:\n        train[\"WindSpeed\"] = train.groupby(\"Week\")[\"WindSpeed\"].transform(lambda x: x.fillna(x.mean()))\n    except:\n        train[\"WindSpeed\"] = train[\"WindSpeed\"].transform(lambda x: x.fillna(x.mean()))\n        \n    def wind_speed_closed(x):\n        if \"closed\" in x[0]:\n            return 0\n        \n    #train[\"WindSpeed\"] = train[[\"StadiumType\",\"WindSpeed\"]].fillna(\"\").apply(wind_speed_closed)\n    train[\"StadiumClosed\"] = train[\"StadiumType\"].fillna(\"\").apply(lambda x: \"closed\" in x)\n    #train[train[\"StadiumClosed\"]==1, \"WindSpeed\"] = 0\n\n    # making sure\n    train['Temperature'] = train['Temperature'].fillna(75)\n    train['Humidity'] = train['Humidity'].fillna(65)\n    train[\"WindSpeed\"] = train[\"WindSpeed\"].fillna(10)     \n    \n    \n    \n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  \ndef fix_sides(train):\n    # https://www.kaggle.com/cpmpml/initial-wrangling-voronoi-areas-in-python\n    \n    \"\"\"\n    New features:\n    \n    TeamOnOffence:        home / away\n    ToLeft :              binary\n    IsBallCarrier:        binary\n    \n    YardLine_std\n    X_std\n    Y_std\n    Orientation_std\n    Dir_std\n    \"\"\"\n\n    train['ToLeft'] = train.PlayDirection == \"left\"\n    train['IsBallCarrier'] = train.NflId == train.NflIdRusher\n    \n    # fix team names\n\n    \n    train.loc[train.VisitorTeamAbbr == \"ARI\", 'VisitorTeamAbbr'] = \"ARZ\"\n    train.loc[train.HomeTeamAbbr == \"ARI\", 'HomeTeamAbbr'] = \"ARZ\"\n\n    train.loc[train.VisitorTeamAbbr == \"BAL\", 'VisitorTeamAbbr'] = \"BLT\"\n    train.loc[train.HomeTeamAbbr == \"BAL\", 'HomeTeamAbbr'] = \"BLT\"\n\n    train.loc[train.VisitorTeamAbbr == \"CLE\", 'VisitorTeamAbbr'] = \"CLV\"\n    train.loc[train.HomeTeamAbbr == \"CLE\", 'HomeTeamAbbr'] = \"CLV\"\n\n    train.loc[train.VisitorTeamAbbr == \"HOU\", 'VisitorTeamAbbr'] = \"HST\"\n    train.loc[train.HomeTeamAbbr == \"HOU\", 'HomeTeamAbbr'] = \"HST\"\n\n    \n    '''\n    Our ultimate goal will be to ensure that the offensive team (PossessionTeam) is moving left to right, \n    even if in the raw data, the offense is moving right to left.\n    '''\n    \n    train['TeamOnOffense'] = \"home\"\n    train.loc[train.PossessionTeam != train.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n    train['IsOnOffense'] = train.Team == train.TeamOnOffense # Is player on offense?\n    train['YardLine_std'] = 100 - train.YardLine\n    train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n              'YardLine_std'\n             ] = train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n              'YardLine']\n    train['X_std'] = train.X\n    train.loc[train.ToLeft, 'X_std'] = 120 - train.loc[train.ToLeft, 'X'] \n    train['Y_std'] = train.Y\n    train.loc[train.ToLeft, 'Y_std'] = 160/3 - train.loc[train.ToLeft, 'Y'] \n    train['Orientation_std'] = train.Orientation\n    train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'], 360)\n    train['Dir_std'] = train.Dir\n    train.loc[train.ToLeft, 'Dir_std'] = np.mod(180 + train.loc[train.ToLeft, 'Dir_std'], 360)\n    train.loc[train.ToLeft, 'WindDirection_std'] = np.mod(180 + train.loc[train.ToLeft, 'WindDirection_std'], 360)\n\n    \n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def voronoi_feats(train):\n    \n    def shoelace(corners):\n        n = len(corners) # of corners\n        area = 0.0\n        for i in range(n):\n            j = (i + 1) % n\n            area += corners[i][0] * corners[j][1]\n            area -= corners[j][0] * corners[i][1]\n        area = abs(area) / 2.0\n        return area\n    \n    def get_voronoi(play_id, train):\n        df = train[train.PlayId == play_id]\n        xy = df[['X_std', 'Y_std']].values\n        n_points = xy.shape[0]\n        xy1 = xy.copy()\n        xy1[:,1] = - xy[:,1]\n        xy2 = xy.copy()\n        xy2[:,1] = 320/3 - xy[:,1]\n        xy3 = xy.copy()\n        xy3[:,0] = 20 - xy[:,0]\n        xy4 = xy.copy()\n        xy4[:,0] = 220 - xy[:,0]\n        xy = np.concatenate((xy, xy1, xy2, xy3, xy4), axis=0)\n        offense = df.IsOnOffense.values\n        vor = Voronoi(xy)\n        areas = []\n        #voronoi_plot_2d(vor, ax=ax, show_points=False, show_vertices=False)\n        for r in range(n_points):\n            region = vor.regions[vor.point_region[r]]\n            if not -1 in region:\n                polygon = [vor.vertices[i] for i in region]\n                polygon_area = shoelace(polygon)\n                areas.append(polygon_area)\n        #areas = [int(a) for a in areas]\n        fractions = [a/sum(areas) for a in areas]\n        return areas, fractions\n    \n    plays = train.PlayId.unique()\n    train[\"Voronoi\"] = 0\n    train[\"Voronoi_fraction\"] = 0\n    for play in plays:\n        area, frac = get_voronoi(play, train)\n        n = len(train[train.PlayId == play])\n        while len(area)<n:\n            area.append(0)\n            frac.append(0)\n        train.loc[train.PlayId == play,\"Voronoi\"] = area[:n]\n        train.loc[train.PlayId == play,\"Voronoi_fraction\"] = frac[:n]\n        \n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(train):\n    \n    \"\"\"\n    New features:\n    \n    OffenceHome\n    OffenceLead\n    YardsToGo\n    BMI\n    isRB\n    Speed_and_Wind_dot\n    DefendersInTheBox_vs_Distance\n    DL\n    LB\n    DB\n    RB\n    TE\n    WR\n    Morning\n    Afternoon\n    Evening\n    Hours\n    YardsFromOwnGoal\n    Snowing\n    U\n    W\n    Uo\n    Wo\n    \"\"\"\n    \n    # How many points is the ofence team ahead\n\n    train['OffenseTeam'] = train['PossessionTeam']\n    train['OffenseHome'] = train[['OffenseTeam','HomeTeamAbbr']].apply(lambda x: 1 if x[0] == x[1] else 0, axis = 1)\n    train['DefenseTeam'] = train[['OffenseHome','HomeTeamAbbr','VisitorTeamAbbr']].apply(lambda x: x[2] if x[0] == 1 else x[1], axis = 1)\n    train['OffenseLead'] = train[['OffenseHome','HomeScoreBeforePlay','VisitorScoreBeforePlay']].apply(lambda x: x[1]-x[2] if x[0] == 1 else x[2]-x[1], axis = 1)\n    \n    \n    # Yards to go\n    train['YardsToGo'] = train[['FieldPosition','OffenseTeam','YardLine']].apply( \\\n            lambda x: (50-x['YardLine'])+50 if x['OffenseTeam']==x['FieldPosition'] else x['YardLine'],1)\n    \n    # BMI\n    train[\"BMI\"] = train[\"Height_feet\"]/train[\"PlayerWeight\"]\n    \n    # Speed and WindSpeed vector dot product\n    #train[\"Speed_and_Wind_dot\"] = train[[\"S\",'WindSpeed',\"Dir_std\",\"WindDirection_std\"]].apply(lambda x: x[0]*x[1]*math.cos(x[2]-x[3]))\n    def dotpr(x):\n        return x[0]*x[1]*np.cos(x[2]-x[3])\n    train[\"Speed_and_Wind_dot\"] = train[[\"S\",'WindSpeed',\"Dir_std\",\"WindDirection_std\"]].apply(dotpr, axis=1)\n    \n    train[\"isRB\"] = train[\"Position\"].apply(lambda x: x == \"RB\")\n    \n    # dummified Offence Formation\n    #off_form = train['OffenseFormation'].unique()\n    #train = pd.concat([train.drop(['OffenseFormation'], axis=1), pd.get_dummies(train['OffenseFormation'], prefix='Formation')], axis=1)\n    #dummy_col = train.columns\n    \n    train['DefendersInTheBox_vs_Distance'] = train['DefendersInTheBox'] / train['Distance']\n    \n    \"\"\"\n    # Defence and offence personnel\n    train['DL'] = 0\n    train['LB'] = 0\n    train['DB'] = 0\n    \n    arr = [[int(s[0]) for s in t.split(\", \")] for t in train[\"OffensePersonnel\"]]\n    train['RB'] = 0\n    train['TE'] = 0\n    train['WR'] = 0\n\n    arr = [[int(s[0]) for s in t.split(\", \")] for t in train[\"DefensePersonnel\"]]\n    train['DL'] = [a[0] for a in arr]\n    train['LB'] = [a[1] for a in arr]\n    train['DB'] = [a[2] for a in arr]\n    \n    arr = [[int(s[0]) for s in t.split(\", \")] for t in train[\"OffensePersonnel\"]]\n    train['RB'] = [a[0] for a in arr]\n    train['TE'] = [a[1] for a in arr]\n    train['WR'] = [a[2] for a in arr]\n    \"\"\"\n    # Time\n    train['Morning'] = train['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >=0 and int(x[0:2]) <12) else 0)\n    train['Afternoon'] = train['GameClock'].apply(lambda x : 1 if (int(x[0:2]) <18 and int(x[0:2]) >=12) else 0)\n    train['Evening'] = train['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >= 18 and int(x[0:2]) < 24) else 0)\n    train['Hours'] = train['GameClock'].apply(lambda x : int(x[0:2]))  \n    \n    # is this correct?\n    train.loc[train.FieldPosition == train.PossessionTeam,'YardsFromOwnGoal'] = train.loc[train.FieldPosition == train.PossessionTeam,'YardLine']\n    train.loc[train.FieldPosition != train.PossessionTeam,'YardsFromOwnGoal'] = 50 - train.loc[train.FieldPosition != train.PossessionTeam,'YardLine']\n    \n    train[\"Snowing\"] = train[\"GameWeather\"].apply(lambda x: x == \"snow\")\n    \n    \n    train['U'] = train['S'] * 1.75 * np.cos(train['Dir_std'])+ train['X_std']\n    train['W'] = train['S'] * 1.75 * np.sin(train['Dir_std']) + train['Y_std']\n    \n    # orientation vector\n    train['Uo'] = train['S'] * 1.25 * np.cos(train['Orientation_std'])+ train['X_std']\n    train['Wo'] = train['S'] * 1.25 * np.sin(train['Orientation_std']) + train['Y_std']\n    \n    train = train.drop(['OffenseTeam',\"DefenseTeam\"], axis=1)\n    \n    \n    def projection_features(df):\n        rad = 2 * np.pi * (90 - df[['Orientation_std']]) / 360\n        v_0 = df['S'].values * np.cos(rad).values.reshape(-1)\n        v_1 = np.sin(rad).values.reshape(-1)\n\n        a_0 = df['A'].values * np.cos(rad).values.reshape(-1)\n        a_1 = np.sin(rad)\n\n        df['v_0'] = v_0\n        df['v_1'] = v_1\n        df['a_0'] = a_0\n        df['a_1'] = a_1\n        \n        return df\n    \n    train = projection_features(train)\n    \n    def euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n\n        return np.sqrt(x_diff + y_diff)\n    \n    \n    return train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions for anchoring offense moving left from {0,0}"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:38.156575Z","start_time":"2019-11-06T13:27:38.132416Z"},"trusted":true},"cell_type":"code","source":"def create_features(df, deploy=False):\n    def new_X(x_coordinate, play_direction):\n        if play_direction == 'left':\n            return 120.0 - x_coordinate\n        else:\n            return x_coordinate\n\n    def new_line(rush_team, field_position, yardline):\n        if rush_team == field_position:\n            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n            return 10.0 + yardline\n        else:\n            # half the field plus the yards between midfield and the line of scrimmage\n            return 60.0 + (50 - yardline)\n\n    def new_orientation(angle, play_direction):\n        if play_direction == 'left':\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return new_angle\n        else:\n            return angle\n\n    def euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n\n        return np.sqrt(x_diff + y_diff)\n\n    def back_direction(orientation):\n        if orientation > 180.0:\n            return 1\n        else:\n            return 0\n\n    def update_yardline(df):\n        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n        return new_yardline\n\n    def update_orientation(df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n        return df\n\n    def back_features(df):\n        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n\n        return carriers\n\n    def features_relative_to_back(df, carriers):\n        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n                                   'min_dist','max_dist','mean_dist','std_dist']\n\n        return player_distance\n\n    def defense_features(df):\n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n\n        return defense\n\n    def static_features(df, p_cols):\n        \n        \n        add_new_feas = []\n\n        ## Height\n        df['PlayerHeight_dense'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n        \n        add_new_feas.append('PlayerHeight_dense')\n\n        ## Time\n        df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n        df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n        df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n        df['PlayerBirthDate'] =df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n        ## Age\n        seconds_in_year = 60*60*24*365.25\n        df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n        add_new_feas.append('PlayerAge')\n\n        ## WindSpeed\n        #df['WindSpeed_ob'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n        #df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n        #df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n        #df['WindSpeed_dense'] = df['WindSpeed_ob'].apply(strtofloat)\n        #add_new_feas.append('WindSpeed_dense')\n\n        ## Weather\n        df['GameWeather_process'] = df['GameWeather'].str.lower()\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n        df['GameWeather_dense'] = df['GameWeather_process'].apply(map_weather)\n        add_new_feas.append('GameWeather_dense')\n#         ## Rusher\n#         train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n#         train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n#         temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n#         train = train.merge(temp, on = \"PlayId\")\n#         train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n        ## dense -> categorical\n#         train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n#         train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n#         train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n#         train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n        # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n        # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n        # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n        ## Orientation and Dir\n        df[\"Orientation_ob\"] = df[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n        df[\"Dir_ob\"] = df[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n        df[\"Orientation_sin\"] = df[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Orientation_cos\"] = df[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        add_new_feas.append(\"Orientation_cos\")\n        add_new_feas.append(\"Orientation_sin\")\n        \n        \n        df[\"Dir_sin\"] = df[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Dir_cos\"] = df[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        add_new_feas.append(\"Dir_sin\")\n        add_new_feas.append(\"Dir_cos\")\n        \n        df[\"WindDir_sin\"] = df[\"WindDirection_std\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"WindDir_cos\"] = df[\"WindDirection_std\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        add_new_feas.append(\"WindDir_sin\")\n        add_new_feas.append(\"WindDir_cos\")\n\n        # Player force: F=m*a\n        \n        df[\"Force\"] = df[\"PlayerWeight\"]*df[\"A\"]\n\n        ## diff Score\n        df[\"diffScoreBeforePlay\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n        add_new_feas.append(\"diffScoreBeforePlay\")\n        \n        # features from Artem\n        add_new_feas.append(\"TimeDelta\")\n        \n        fe = ['v_0', 'v_1', \n            #'a_0', 'a_1', \n            #\"YardsToGo\", \n              \"BMI\", \n            \"Force\",\n            #\"Snowing\", \n              #\"RB\", \"DL\", \"LB\", \"DB\", \"TE\", \"WR\", \n              #\"U\", \"W\", \"Uo\", \"Wo\", \n            \"Speed_and_Wind_dot\",\n            \"Voronoi\", \"Voronoi_fraction\",\n            #\"IsOnOffense\"]\n               \"play_control\"]\n        \n        def_f = [    'secondsLeftInHalf',\n    'numericFormation',\n    \"Defense_X_stdiv\", \n    \"Defense_Y_stdiv\", \n    \"Defense_Y_spread\", \n    \"Defense_X_spread\", \n    \"min_time_to_tackle\",\n    \"mean_time_to_tackle\",\n    \"dist_to_offense_centroid\",\n    \"dist_to_defense_centroid\"]\n    \n        static_features = df[df['NflId'] == df['NflIdRusher']][add_new_feas+fe+p_cols + def_f +['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n#         static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n        static_features.fillna(-999,inplace=True)\n#         for i in add_new_feas:\n#             static_features[i] = static_features[i].fillna(np.mean(static_features[i]))\n            \n\n        return static_features\n\n    def split_personnel(s):\n        splits = s.split(',')\n        for i in range(len(splits)):\n            splits[i] = splits[i].strip()\n\n        return splits\n\n    def defense_formation(l):\n        dl = 0\n        lb = 0\n        db = 0\n        other = 0\n\n        for position in l:\n            sub_string = position.split(' ')\n            if sub_string[1] == 'DL':\n                dl += int(sub_string[0])\n            elif sub_string[1] in ['LB','OL']:\n                lb += int(sub_string[0])\n            else:\n                db += int(sub_string[0])\n\n        counts = (dl,lb,db,other)\n\n        return counts\n\n    def offense_formation(l):\n        qb = 0\n        rb = 0\n        wr = 0\n        te = 0\n        ol = 0\n\n        sub_total = 0\n        qb_listed = False\n        for position in l:\n            sub_string = position.split(' ')\n            pos = sub_string[1]\n            cnt = int(sub_string[0])\n\n            if pos == 'QB':\n                qb += cnt\n                sub_total += cnt\n                qb_listed = True\n            # Assuming LB is a line backer lined up as full back\n            elif pos in ['RB','LB']:\n                rb += cnt\n                sub_total += cnt\n            # Assuming DB is a defensive back and lined up as WR\n            elif pos in ['WR','DB']:\n                wr += cnt\n                sub_total += cnt\n            elif pos == 'TE':\n                te += cnt\n                sub_total += cnt\n            # Assuming DL is a defensive lineman lined up as an additional line man\n            else:\n                ol += cnt\n                sub_total += cnt\n\n        # If not all 11 players were noted at given positions we need to make some assumptions\n        # I will assume if a QB is not listed then there was 1 QB on the play\n        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n        if sub_total < 11:\n            diff = 11 - sub_total\n            if not qb_listed:\n                qb += 1\n                diff -= 1\n            ol += diff\n\n        counts = (qb,rb,wr,te,ol)\n\n        return counts\n    \n    def personnel_features(df):\n        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n\n        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n\n        # Let's create some features to specify if the OL is covered\n        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n        # Let's create a feature to specify if the defense is preventing the run\n        # Let's just assume 7 or more DL and LB is run prevention\n        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n\n        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n        \n        return personnel\n    \n    def rusher_features(df):\n        \n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Dir', 'S', 'A', 'X', 'Y']]\n        rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS', 'RusherA', 'RusherX', 'RusherY']\n        \n       \n        radian_angle = (90 - rusher['RusherDir']) * np.pi / 180.0\n        v_horizontal = np.abs(rusher['RusherS'] * np.cos(radian_angle))\n        v_vertical = np.abs(rusher['RusherS'] * np.sin(radian_angle)) \n        \n        #rusher[\"dist_to_rusher\"] = df\n       \n        rusher['v_horizontal'] = v_horizontal\n        rusher['v_vertical'] = v_vertical\n        \n        \n        rusher.columns = ['GameId','PlayId', 'RusherDir', \n                          'RusherS',\n                          'RusherA','RusherX', 'RusherY','v_horizontal', 'v_vertical']\n        \n        \n        return rusher\n    \n    def dist_to_rusher(x):\n        a = (x[0],x[1])\n        b = (x[2],x[3])\n        return euclidean(a,b)\n\n    def combine_features(relative_to_back, defense,rushing, static, deploy=deploy):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,rushing,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n        #df = pd.merge(df,pc,how='left')\n\n\n        if not deploy:\n            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n        return df\n    \n    #print(\"Cleaning features...\")\n    df = clean_features(df)\n    \n    #print(\"Removing NAs...\")\n    #df = remove_NAs(df)\n    \n    #print(\"Feature Engineering...\")\n    df = fix_sides(df)\n    df = feature_engineering(df)\n    \n    #print(\"Calculating Voronoi Areas\")\n    df = voronoi_feats(df)\n    \n    #print(\"Calculating Play Control\")\n    pc = get_play_control(df)    \n    \n    #df[\"influence\"] = pc[\"influence\"].values\n    df[\"play_control\"] = pc[\"play_control\"].values\n    \n    for col in [    'secondsLeftInHalf',\n    'numericFormation',\n    \"Defense_X_stdiv\", \n    \"Defense_Y_stdiv\", \n    \"Defense_Y_spread\", \n    \"Defense_X_spread\", \n    \"min_time_to_tackle\",\n    \"mean_time_to_tackle\",\n    \"dist_to_offense_centroid\",\n    \"dist_to_defense_centroid\"]:\n        df[col] = pc[col].values\n    \n    # positional features\n    pf, p_cols = positional(df)\n    \n    for col in p_cols:\n        df[col] = pf[col].values\n    \n    #print(\"Yardline features...\")\n    yardline = update_yardline(df)\n    #print(\"Fixing orientation...\")\n    df = update_orientation(df, yardline)\n    #print(\"Backline features...\")\n    back_feats = back_features(df)\n    #print(\"Features relative to backline...\")\n    rel_back = features_relative_to_back(df, back_feats)\n    #print(\"Defence features...\")\n    def_feats = defense_features(df)\n    #print(\"Static features...\")\n    static_feats = static_features(df, p_cols)\n    #print(\"Rusher features...\")\n    rush_feats = rusher_features(df)\n    #print(\"Personnel features...\")\n    personnel = personnel_features(df)\n    #basetable = combine_features(rel_back, def_feats, static_feats, deploy=deploy)\n    basetable = combine_features(rel_back, def_feats,rush_feats,static_feats, deploy=deploy)\n    \n    # some more rusher based features\n    #basetable[\"distance_to_rusher\"] = 0\n    \n    #basetable[\"distance_to_rusher\"] = basetable[[\"X\",\"Y\",\"RusherX\",\"RusherY\"]].apply(lambda x: dist_to_rusher(x), axis=1)\n    basetable[\"s_delta_0\"] = basetable[\"v_0\"]-basetable['v_horizontal']\n    basetable[\"s_delta_1\"] = basetable[\"v_1\"]-basetable['v_vertical']\n    \n    #basetable[\"influence\"] = pc[\"influence\"].values\n    #basetable[\"control\"] = pc[\"play_control\"].values\n    \n    basetable.drop([\"v_0\",\"v_1\",\"X\",\"Y\",\"S\",\"A\", \"Force\"],axis=1, inplace=True)\n    \n    #print(\"Complete.\")\n    \n    return basetable","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.301052Z","start_time":"2019-11-06T13:27:38.158256Z"},"trusted":true},"cell_type":"code","source":"%time train_basetable = create_features(train, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_basetable.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's split our data into train/val"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.332475Z","start_time":"2019-11-06T13:31:22.303336Z"},"trusted":true},"cell_type":"code","source":"X = train_basetable.copy()\nyards = X.Yards\n\ny = np.zeros((yards.shape[0], 199))\nfor idx, target in enumerate(list(yards)):\n    y[idx][99 + target] = 1\n\nX.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(25, 25)})\ncorr = X.corr()\nplt.figure() \nax = sns.heatmap(corr, linewidths=.5, annot=True, cmap=\"YlGnBu\", fmt='.1g')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop highly correlated features (37->28)\ncolumns = np.full((corr.shape[0],), True, dtype=bool)\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >= 0.99:\n            if columns[j]:\n                columns[j] = False\n\nfeature_columns = X.columns.values\ndrop_columns = X.columns[columns == False].values\nprint(feature_columns)\nprint(drop_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(X[feature_columns])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.35269Z","start_time":"2019-11-06T13:31:22.334326Z"},"trusted":true},"cell_type":"code","source":"\"\"\"scaler = StandardScaler()\nX = scaler.fit_transform(X)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.372453Z","start_time":"2019-11-06T13:31:22.354418Z"},"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.377333Z","start_time":"2019-11-06T13:31:22.374128Z"},"trusted":true},"cell_type":"code","source":"print(X_train.shape, X_val.shape)\nprint(y_train.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's build NN"},{"metadata":{},"cell_type":"markdown","source":"Below class Metric based entirely on: https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping\n<br></br>\nBelow early stopping entirely based on: https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112868#latest-656533"},{"metadata":{"trusted":true},"cell_type":"code","source":"def crps_score(y_prediction, y_valid, shape=X.shape[0]):\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_prediction, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * shape)\n    crps = np.round(val_s, 6)\n    \n    return crps","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.386553Z","start_time":"2019-11-06T13:31:22.379178Z"},"trusted":true},"cell_type":"code","source":"from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda, LeakyReLU\nfrom keras.models import Model\nimport keras.backend as K\nimport re\nfrom keras.losses import binary_crossentropy\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport codecs\n\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom sklearn.metrics import f1_score\n\n\n\n\nclass CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n        print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s\n    \n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.395056Z","start_time":"2019-11-06T13:31:22.38849Z"},"trusted":true},"cell_type":"code","source":"def get_model(x_tr,y_tr,x_val,y_val):\n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dense(1024, input_dim=X.shape[1])(inp)\n    x = LeakyReLU(alpha=0.3)(x)\n    x = Dropout(0.2)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512)(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.2)(x)\n    x = BatchNormalization()(x)\n    x = Dense(256)(x)\n    x = LeakyReLU(alpha=0.1)(x)\n    x = Dropout(0.2)(x)\n    x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp,out)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n    #add lookahead\n#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n#     lookahead.inject(model) # add into model\n\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=20)\n\n    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=1, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]/bsz\n    \n\n\n    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=1)\n    model.load_weights(\"best_model.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n    crps = np.round(val_s, 6)\n\n    return model,crps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"def get_rf(x_tr, y_tr, x_val, y_val, shape):\n    model = RandomForestRegressor(bootstrap=False, max_features=0.3, min_samples_leaf=15, \n                                  min_samples_split=8, n_estimators=50, n_jobs=-1, random_state=42)\n    model.fit(x_tr, y_tr)\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    crps = crps_score(y_pred, y_valid, shape=shape)\n    \n    return model, crps\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:37:42.061299Z","start_time":"2019-11-06T13:31:22.396693Z"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nimport time\n\nlosses = []\nmodels = []\ncrps_csv = []\n\ns_time = time.time()\n\n\nfor k in range(2):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        print(\"-----------\")\n        print(\"-----------\")\n        tr_x,tr_y = X[tr_inds],y[tr_inds]\n        val_x,val_y = X[val_inds],y[val_inds]\n        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n        models.append(model)\n        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n        crps_csv.append(crps)\n \nprint(\"mean crps is %f\"%np.mean(crps_csv))\n\n\ndef predict(x_te):\n    model_num = len(models)\n    for k,m in enumerate(models):\n        if k==0:\n            y_pred = m.predict(x_te,batch_size=1024)\n        else:\n            y_pred+=m.predict(x_te,batch_size=1024)\n            \n    y_pred = y_pred / model_num\n    \n    return y_pred\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"loop = 2\nfold = 5\n\noof_nn = np.zeros([loop, y.shape[0], y.shape[1]])\noof_rf = np.zeros([loop, y.shape[0], y.shape[1]])\n\nmodels_nn = []\ncrps_csv_nn = []\nmodels_rf = []\ncrps_csv_rf = []\n\nfeature_importance = np.zeros([loop, fold, X.shape[1]])\n\ns_time = time.time()\n\nfor k in range(loop):\n    kfold = KFold(fold, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        print(\"-----------\")\n        print(f'Loop {k+1}/{loop}' + f' Fold {k_fold+1}/{fold}')\n        print(\"-----------\")\n        tr_x, tr_y = X[tr_inds], y[tr_inds]\n        val_x, val_y = X[val_inds], y[val_inds]\n        \n        # Train NN\n        nn, crps_nn = get_nn(tr_x, tr_y, val_x, val_y, shape=val_x.shape[0])\n        models_nn.append(nn)\n        print(\"the %d fold crps (NN) is %f\"%((k_fold+1), crps_nn))\n        crps_csv_nn.append(crps_nn)\n        \n        # Train RF\n        rf, crps_rf = get_rf(tr_x, tr_y, val_x, val_y, shape=val_x.shape[0])\n        models_rf.append(rf)\n        print(\"the %d fold crps (RF) is %f\"%((k_fold+1), crps_rf))\n        crps_csv_rf.append(crps_rf)\n        \n        # Feature Importance\n        feature_importance[k, k_fold, :] = rf.feature_importances_\n        \n        #Predict OOF\n        oof_nn[k, val_inds, :] = nn.predict(val_x)\n        oof_rf[k, val_inds, :] = rf.predict(val_x)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(x_tr,y_tr,x_val,y_val):\n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dense(1024, input_dim=X.shape[1])(inp)\n    x = LeakyReLU(alpha=0.3)(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512)(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512)(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(256)(x)\n    x = LeakyReLU(alpha=0.1)(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp,out)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n    #add lookahead\n#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n#     lookahead.inject(model) # add into model\n\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=10)\n\n    mc = ModelCheckpoint('best_model1.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=1, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]/bsz\n    \n\n\n    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=1)\n    model.load_weights(\"best_model1.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n    crps = np.round(val_s, 6)\n\n    return model,crps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nimport time\n\ns_time = time.time()\n\n\nfor k in range(1):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        print(\"-----------\")\n        print(\"-----------\")\n        tr_x,tr_y = X[tr_inds],y[tr_inds]\n        val_x,val_y = X[val_inds],y[val_inds]\n        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n        models.append(model)\n        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n        crps_csv.append(crps)\n \nprint(\"mean crps is %f\"%np.mean(crps_csv))\n\n\ndef predict(x_te):\n    model_num = len(models)\n    for k,m in enumerate(models):\n        if k==0:\n            y_pred = m.predict(x_te,batch_size=1024)\n        else:\n            y_pred+=m.predict(x_te,batch_size=1024)\n            \n    y_pred = y_pred / model_num\n    \n    return y_pred\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(x_tr,y_tr,x_val,y_val):\n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dense(512, input_dim=X.shape[1])(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512)(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp,out)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n    #add lookahead\n#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n#     lookahead.inject(model) # add into model\n\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=10)\n\n    mc = ModelCheckpoint('best_model2.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=1, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]/bsz\n    \n\n\n    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=1)\n    model.load_weights(\"best_model2.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n    crps = np.round(val_s, 6)\n\n    return model,crps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nimport time\n\ns_time = time.time()\n\n\nfor k in range(1):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        print(\"-----------\")\n        print(\"-----------\")\n        tr_x,tr_y = X[tr_inds],y[tr_inds]\n        val_x,val_y = X[val_inds],y[val_inds]\n        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n        models.append(model)\n        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n        crps_csv.append(crps)\n \nprint(\"mean crps is %f\"%np.mean(crps_csv))\n\n\ndef predict(x_te):\n    model_num = len(models)\n    for k,m in enumerate(models):\n        if k==0:\n            y_pred = m.predict(x_te,batch_size=1024)\n        else:\n            y_pred+=m.predict(x_te,batch_size=1024)\n            \n    y_pred = y_pred / model_num\n    \n    return y_pred\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:37:42.068378Z","start_time":"2019-11-06T13:37:42.063981Z"},"trusted":true},"cell_type":"code","source":"\"\"\"print(\"mean crps is %f\"%np.mean(crps_csv))\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"crps_oof_nn = []\ncrps_oof_rf = []\n\nfor k in range(loop):\n    crps_oof_nn.append(crps_score(oof_nn[k,...], y))\n    crps_oof_rf.append(crps_score(oof_rf[k,...], y))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"feature_importances = pd.DataFrame(np.mean(feature_importance, axis=0).T, columns=[[f'fold_{fold_n}' for fold_n in range(fold)]])\nfeature_importances['feature'] = feature_columns\nfeature_importances['average'] = feature_importances[[f'fold_{fold_n}' for fold_n in range(fold)]].mean(axis=1)\nfeature_importances.sort_values(by=('average',), ascending=False).head(10)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"feature_importance_flatten = pd.DataFrame()\nfor i in range(len(feature_importances.columns)-2):\n    col = ['feature', feature_importances.columns.values[i][0]]\n    feature_importance_flatten = pd.concat([feature_importance_flatten, feature_importances[col].rename(columns={f'fold_{i}': 'importance'})], axis=0)\n\nplt.figure(figsize=(16, 16))\nsns.barplot(data=feature_importance_flatten.sort_values(by=('importance',), ascending=False), x=('importance',), y=('feature',))\nplt.title(f'Feature Importances over {loop} loops and {fold} folds')\nplt.show()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"def weight_opt(oof_nn, oof_rf, y_true):\n    weight_nn = np.inf\n    best_crps = np.inf\n    \n    for i in np.arange(0, 1.01, 0.05):\n        crps_blend = np.zeros(oof_nn.shape[0])\n        for k in range(oof_nn.shape[0]):\n            crps_blend[k] = crps_score(i * oof_nn[k,...] + (1-i) * oof_rf[k,...], y_true)\n        if np.mean(crps_blend) < best_crps:\n            best_crps = np.mean(crps_blend)\n            weight_nn = round(i, 2)\n            \n        print(str(round(i, 2)) + ' : mean crps (Blend) is ', round(np.mean(crps_blend), 6))\n        \n    print('-'*36)\n    print('Best weight for NN: ', weight_nn)\n    print('Best weight for RF: ', round(1-weight_nn, 2))\n    print('Best mean crps (Blend): ', round(best_crps, 6))\n    \n    return weight_nn, round(1-weight_nn, 2)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"weight_nn, weight_rf = weight_opt(oof_nn, oof_rf, y)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"def predict(x_te, models_nn, models_rf, weight_nn, weight_rf):\n    model_num_nn = len(models_nn)\n    model_num_rf = len(models_rf)\n    for k,m in enumerate(models_nn):\n        if k==0:\n            y_pred_nn = m.predict(x_te, batch_size=1024)\n            y_pred_rf = models_rf[k].predict(x_te)\n        else:\n            y_pred_nn += m.predict(x_te, batch_size=1024)\n            y_pred_rf += models_rf[k].predict(x_te)\n            \n    y_pred_nn = y_pred_nn / model_num_nn\n    y_pred_rf = y_pred_rf / model_num_rf\n    \n    return weight_nn * y_pred_nn + weight_rf * y_pred_rf\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time for the actual submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"%%time\nif  TRAIN_OFFLINE==False:\n    from kaggle.competitions import nflrush\n    env = nflrush.make_env()\n    iter_test = env.iter_test()\n\n    for (test_df, sample_prediction_df) in iter_test:\n        basetable = create_features(test_df, deploy=True)\n        basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n        \n        scaled_basetable = scaler.transform(basetable[feature_columns])\n\n        y_pred = predict(scaled_basetable, models_nn, models_rf, weight_nn, weight_rf)\n        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n\n        preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n        env.predict(preds_df)\n\n    env.write_submission_file()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:37:42.077763Z","start_time":"2019-11-06T13:37:42.070691Z"},"trusted":true},"cell_type":"code","source":"%%time\nif  TRAIN_OFFLINE==False:\n    from kaggle.competitions import nflrush\n    env = nflrush.make_env()\n    iter_test = env.iter_test()\n\n    for (test_df, sample_prediction_df) in iter_test:\n        basetable = create_features(test_df, deploy=True)\n        basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n        scaled_basetable = scaler.transform(basetable)\n\n        y_pred = predict(scaled_basetable)\n        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n\n        preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n        env.predict(preds_df)\n\n    env.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}