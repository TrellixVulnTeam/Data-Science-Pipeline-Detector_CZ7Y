{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport matplotlib.mlab as mlab\nimport matplotlib.patches as patches\nimport seaborn as sns; sns.set(color_codes=True)\nimport datetime\nfrom sklearn.linear_model import LogisticRegression\nimport statsmodels.api as sm\nfrom scipy.stats import norm\nfrom keras import backend as K\nimport tensorflow as tf\nimport tqdm\nimport time\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.preprocessing import StandardScaler\n\ndf_train=pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)\ndf = df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def personnelmap(val):\n    if 'OL' not in val:\n        return val+', 5 OL'\n    else:\n        return val\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OffensePersonnel'] = df['OffensePersonnel'].apply(personnelmap)\nprint(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\ndef weather1(txt):\n    txt = str(txt).lower()\n    if pd.isna(txt):\n        return \"none\"\n    if \"indoor\" in txt:\n        return \"indoor\"\n    if \"rain\" in txt:\n        return \"rain\"\n    if \"snow\" in txt:\n        return \"snow\"\n    else:\n        return \"other\"\n#For Later\ndef norm(x):\n    return (x - train_stats['mean']) / (train_stats['std'])\n\n# Function for height to inches.  Already in X-Y -> h=12X+Y\ndef height_to_inch(x):\n    return 12 * int(x.split('-')[0]) + int(x.split('-')[1])\n\ndf['PlayerHeight'] = df['PlayerHeight'].apply(height_to_inch)\n\n#Remap Possession Teams for consistancy \nmap_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\nfor abb in df['PossessionTeam'].unique():\n    map_abbr[abb] = abb\n\n#Dummy Variables for Snow, Rain, Indoors, Turf\n    \ndf['GameWeather'] = df['GameWeather'].apply(weather1)\ndf = pd.concat([df.drop(['GameWeather'], axis=1), pd.get_dummies(df['GameWeather'], prefix='Weather')], axis=1)\n\nTurf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \ndf['Turf'] = df['Turf'].map(Turf)\n\ndf = pd.concat([df.drop(['Turf'], axis=1), pd.get_dummies(df['Turf'], prefix='Turf')], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\ndf['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\ndf['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\ndf['X_std'] = df.apply(lambda x: x.X if x.PlayDirection == 'right' else 120 - x.X, axis=1)\ndf['Y_std'] = df.apply(lambda x: x.Y if x.PlayDirection == 'right' else 53.3 - x.Y, axis=1)\ndf['Orientation_std'] = df.apply(lambda x: x.Orientation \\\n    if x.PlayDirection == 'right' \\\n    else x.Orientation + 180, axis=1)\ndf['YardLine_std'] = df.apply(lambda x: x.YardLine + 10 \\\n    if (x.PlayDirection == 'right') & (x.FieldPosition == x.PossessionTeam) \\\n       | (x.PlayDirection == 'left') & (x.FieldPosition == x.PossessionTeam) \\\n    else 60 + (50 - x.YardLine), axis=1)\ndf['FieldPosition_std'] = df.apply(lambda x: 'left' \\\n    if x.FieldPosition == \\\n       x.PossessionTeam \\\n    else 'right', axis=1)\n\ndf['OffDef'] = df.apply(lambda x: \"Off\" if ((x.Team == 'home') & (x.PossessionTeam == x.HomeTeamAbbr)) | \\\n                                           ((x.Team == 'away') & (x.PossessionTeam == x.VisitorTeamAbbr)) \\\n                                        else \"Def\", axis=1)\n\ndf.drop(['X', 'Y', 'Orientation', 'YardLine', 'FieldPosition'], axis=1, inplace=True)\ndf[\"Rusher\"]=df[\"NflId\"]==df[\"NflIdRusher\"]\ndf.drop(columns=[\"WindDirection\",\"WindSpeed\",\"PlayerCollegeName\"],inplace=True)\n\ndf['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\ndf['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n\ndf['TimeToHandoff'] = df.apply(lambda row: (row['TimeHandoff']-row['TimeSnap']).total_seconds(),axis=1)\n\ndf = pd.concat([df.drop(['OffenseFormation'], axis=1), pd.get_dummies(df['OffenseFormation'], prefix='Formation')], axis=1)\ndf[\"DistanceToRusher\"] = (df.X_std - df.X_std[df.groupby('PlayId')['Rusher'].transform('idxmax')].reset_index(drop=True))**2 \\\n                        +(df.Y_std - df.Y_std[df.groupby('PlayId')['Rusher'].transform('idxmax')].reset_index(drop=True))**2\ndf[\"DistanceToRusher\"] = np.sqrt(df.DistanceToRusher)\ndf[\"Def_DistanceToRusher\"] = df.apply(lambda x:x.DistanceToRusher if x.OffDef=='Def' else np.nan,axis=1)\n\n\n# New DF that has rusher only and the position of the closest defender\ndf_rusher = pd.merge(df.loc[df['Rusher'].groupby(df['PlayId']).idxmax()],\\\n         df.loc[df['Def_DistanceToRusher'].groupby(df['PlayId']).idxmin(), ['PlayId','Def_DistanceToRusher']],\\\n         on='PlayId',\n         suffixes=['','_closest']\n        )\n\ndf_rusher.drop(columns=['Def_DistanceToRusher','Rusher','OffDef','Humidity'], inplace=True)\ndf_rusher.drop(columns=['PlayId','GameId','TimeHandoff','TimeSnap','DistanceToRusher'],inplace=True)\n\ndf_rusher['Direction_Rad'] = (90 - df_rusher.loc[:,'Dir']) * np.pi / 180.0\n\ndf_rusher['RusherVx'] = np.abs(df_rusher.loc[:,'S']) * np.cos(df_rusher.Direction_Rad)\ndf_rusher['RusherVy'] = np.abs(df_rusher.loc[:,'S']) * np.sin(df_rusher.Direction_Rad)\n\ndf_rusher['TimeToClosestDefender'] = df_rusher.loc[:,'Def_DistanceToRusher_closest']/(df_rusher.loc[:,'S']+0.0001)\n\ndf_rusher.drop(columns='Direction_Rad')\n\nprint(list(df_rusher.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)\n\ndf_rushertemp = df_rusher.dropna()\n\ndf_rushertemp['Yards1'] = df_rushertemp.Yards + 99\ndf_rushertemp.drop(columns='Yards',inplace=True)\nprint(df_rushertemp.columns)\n\ntrain_dataset = df_rushertemp\ntrain_dataset.drop(columns = ['GameClock','DefensePersonnel','OffensePersonnel','HomeTeamAbbr','VisitorTeamAbbr','Stadium','Team','StadiumType','Location','PossessionTeam','DisplayName','FieldPosition_std','NflId','JerseyNumber','PlayDirection','PlayerBirthDate','Position'],inplace = True)\n\ntrain_stats = train_dataset.describe()\ntrain_stats.pop('Yards1')\ntrain_stats = train_stats.transpose()\n\ntrain_labels = train_dataset.pop('Yards1')\n\n\nss = StandardScaler()\n\n#normed_train_data = norm(train_dataset)\nscaled_df = ss.fit_transform(train_dataset)\nnormed_train_data = pd.DataFrame(scaled_df, columns=train_dataset.columns)\ndummy_col = normed_train_data.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n  model = keras.Sequential([\n    layers.Input(shape=(len(train_dataset.keys()),)),\n    layers.Dense(800, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(.1), \n    layers.Dense(400,activation='relu'),\n    layers.LeakyReLU(alpha = .15),\n    layers.Dropout(.25),\n    layers.BatchNormalization(),      \n    layers.Dense(400),\n    layers.PReLU(), \n    layers.Dense(200, activation='relu'),\n    layers.Dropout(.15), \n    layers.BatchNormalization(),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(.1),\n    layers.BatchNormalization(),\n    layers.Dense(199,activation='softmax')  \n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n  #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.2, nesterov=False)\n  #optimizer = tf.keras.optimizers.Adam(learning_rate=0.005, decay = 1e-4)\n    \n  model.compile(loss='sparse_categorical_crossentropy' ,\n                optimizer=optimizer,\n                metrics=['mae','accuracy'])\n  return model\n\n\nmodel = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rkf = RepeatedKFold(n_splits=5, n_repeats=5)\n\nx1 = time.time()\nX_train = normed_train_data\nY_train = train_labels\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n\nEPOCHS = 100\n\n\nfor tr_idx, vl_idx in rkf.split(X_train, Y_train):\n    x_tr, y_tr = X_train.iloc[tr_idx], Y_train.iloc[tr_idx]\n    x_vl, y_vl = X_train.iloc[vl_idx], Y_train.iloc[vl_idx]\n    history = model.fit(x_tr, y_tr, epochs=EPOCHS,\n                    validation_data=[x_vl, y_vl], verbose=1, callbacks=[early_stop])\n    \nx2 = time.time()\nprint(x2-x1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_crps(y_pred_cdfs, actuals):\n     stops = np.arange(-99, 100)\n     unit_steps = stops >= actuals.reshape(-1, 1)\n     crps = np.mean((y_pred_cdfs - unit_steps)**2)\n     return crps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred = model.predict(X_train) \ncalc_crps(np.cumsum(ypred,axis=1),np.array(Y_train))/199","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(df,sample,env,model):\n    df = df.reset_index()\n    for abb in df['PossessionTeam'].unique():\n        map_abbr[abb] = abb\n    \n    df['PlayerHeight'] = df['PlayerHeight'].apply(height_to_inch)\n\n    df['GameWeather'] = df['GameWeather'].apply(weather1)\n    df = pd.concat([df.drop(['GameWeather'], axis=1), pd.get_dummies(df['GameWeather'], prefix='Weather')], axis=1)\n    df['Turf'] = df['Turf'].map(Turf)\n    df = pd.concat([df.drop(['Turf'], axis=1), pd.get_dummies(df['Turf'], prefix='Turf')], axis=1)\n    df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n    df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\n    df['X_std'] = df.apply(lambda x: x.X if x.PlayDirection == 'right' else 120 - x.X, axis=1)\n    df['Y_std'] = df.apply(lambda x: x.Y if x.PlayDirection == 'right' else 53.3 - x.Y, axis=1)\n    df['Orientation_std'] = df.apply(lambda x: x.Orientation \\\n        if x.PlayDirection == 'right' \\\n        else x.Orientation + 180, axis=1)\n    df['YardLine_std'] = df.apply(lambda x: x.YardLine + 10 \\\n        if (x.PlayDirection == 'right') & (x.FieldPosition == x.PossessionTeam) \\\n           | (x.PlayDirection == 'left') & (x.FieldPosition == x.PossessionTeam) \\\n        else 60 + (50 - x.YardLine), axis=1)\n    df['FieldPosition_std'] = df.apply(lambda x: 'left' \\\n        if x.FieldPosition == x.PossessionTeam \\\n        else 'right', axis=1)\n\n    df['OffDef'] = df.apply(lambda x: \"Off\" if ((x.Team == 'home') & (x.PossessionTeam == x.HomeTeamAbbr)) | \\\n                                           ((x.Team == 'away') & (x.PossessionTeam == x.VisitorTeamAbbr)) \\\n                                            else \"Def\", axis=1)\n\n    df.drop(['X', 'Y', 'Orientation', 'YardLine', 'FieldPosition',\"WindDirection\",\"WindSpeed\",\"PlayerCollegeName\"], axis=1, inplace=True)\n    \n    df[\"Rusher\"]=df[\"NflId\"]==df[\"NflIdRusher\"]\n\n    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n\n    df['TimeToHandoff'] = df.apply(lambda row: (row['TimeHandoff']-row['TimeSnap']).total_seconds(),axis=1)\n\n    df = pd.concat([df.drop(['OffenseFormation'], axis=1), pd.get_dummies(df['OffenseFormation'], prefix='Formation')], axis=1)\n    df[\"DistanceToRusher\"] = (df.X_std - df.X_std[df.groupby('PlayId')['Rusher'].transform('idxmax')].reset_index(drop=True))**2 \\\n                            +(df.Y_std - df.Y_std[df.groupby('PlayId')['Rusher'].transform('idxmax')].reset_index(drop=True))**2\n    df[\"DistanceToRusher\"] = np.sqrt(df.DistanceToRusher)\n    df[\"Def_DistanceToRusher\"] = df.apply(lambda x:x.DistanceToRusher if x.OffDef=='Def' else np.nan,axis=1)\n\n    df_rusher = pd.DataFrame(data=[df.loc[df['Rusher'].idxmax()]])\n    df_rusher[\"Def_DistanceToRusher\"] = np.min(df.loc[:,'Def_DistanceToRusher'])\n    df_rusher.drop(columns=['Rusher','OffDef','Humidity'], inplace=True)\n    df_rusher.drop(columns=['PlayId','GameId','TimeHandoff','TimeSnap'],inplace=True)\n    df_rusher['Direction_Rad'] = (90 - df_rusher.loc[:,'Dir']) * np.pi / 180.0\n\n    df_rusher['RusherVx'] = np.abs(df_rusher.loc[:,'S']) * np.cos(df_rusher.Direction_Rad)\n    df_rusher['RusherVy'] = np.abs(df_rusher.loc[:,'S']) * np.sin(df_rusher.Direction_Rad)\n    df_rusher.drop(columns='Direction_Rad')\n    df_rusher['TimeToClosestDefender'] = df_rusher.loc[:,'Def_DistanceToRusher']/(df_rusher.loc[:,'S']+0.0001)\n\n    train_dataset = df_rusher\n    train_dataset.drop(columns = ['GameClock','DefensePersonnel','OffensePersonnel','HomeTeamAbbr','VisitorTeamAbbr','Stadium','Team','StadiumType','Location','PossessionTeam','DisplayName','FieldPosition_std','NflId','JerseyNumber','PlayDirection','PlayerBirthDate','Position','DistanceToRusher'],inplace = True)\n    missing_cols = set( dummy_col ) - set( train_dataset.columns )-set('Yards')\n    \n    for c in missing_cols:\n        train_dataset[c] = 0\n    \n    train_dataset = train_dataset[dummy_col]    \n    \n    scaled_df = ss.fit_transform(train_dataset)\n    normed_train_data = pd.DataFrame(scaled_df, columns=train_dataset.columns)\n    \n    if np.array(normed_train_data.Temperature.isna())==True:\n        normed_train_data.loc[:,'Temperature'] = 0\n        \n    y_pred = model.predict(normed_train_data)\n    y_pred = np.cumsum(y_pred)\n    env.predict(pd.DataFrame(data=[y_pred.clip(0,1)],columns=sample.columns))\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env=nflrush.make_env()\ntesting = []\nfor test, sample in tqdm.tqdm(env.iter_test()):\n    make_pred(test, sample, env, model)\n    \nenv.write_submission_file()    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}