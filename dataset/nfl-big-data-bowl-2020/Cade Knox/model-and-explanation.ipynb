{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime, tqdm\nimport math\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport re\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nimport catboost as cb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold\nfrom sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\nimport sqlite3\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nimport gc\nfrom scipy.stats import pearsonr\nfrom bayes_opt import BayesianOptimization\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nfrom kaggle.competitions import nflrush\nenv = nflrush.make_env()\n\n# Training data is in the competition dataset as usual\n\ntrn_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False, dtype={'WindSpeed': 'object'})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I want to be able to look at all data Im working with so change settings to show me all columns\npd.set_option('display.max_columns', 60)\ntrn_df\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Get a feel for the data I have and summarise how many unique players, games, formations etc\n\nlen(trn_df.NflId.unique())\nlen(trn_df.PlayId.unique())\nlen(trn_df.GameId.unique())\nlen(trn_df.Season.unique())\nlen(trn_df[trn_df.Season==2017].PlayId.unique())\nlen(trn_df[trn_df.Season==2018].PlayId.unique())\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of total players in the dataset is 2,231.\nNumber of total plays in the data is 23,171.\nNumber of total games in the data is 512.\n2 total seasons are in the data set with 2017 accounting for 11,900 plays and 2018 accounting for 11,271."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Must correct some of the team abbreviations to match up\n\ntrn_df.loc[trn_df.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\ntrn_df.loc[trn_df.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n\ntrn_df.loc[trn_df.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\ntrn_df.loc[trn_df.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n\ntrn_df.loc[trn_df.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\ntrn_df.loc[trn_df.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n\ntrn_df.loc[trn_df.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\ntrn_df.loc[trn_df.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n\ntrn_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Want to use just rusher info here\n\ntrn_df['is_run'] = trn_df.NflId == trn_df.NflIdRusher\ntrn_sin = trn_df[trn_df.is_run==True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change the format of time so it takes into account quarters\n\ndef transform_time_quarter(str1):\n    return int(str1[:2])*60 + int(str1[3:5])\ndef transform_time_all(str1,quarter):\n    if quarter<=4:\n        return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n    if quarter ==5:\n        return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\ntrn_sin['time_quarter'] = trn_sin.GameClock.map(lambda x:transform_time_quarter(x))\ntrn_sin['time_end'] = trn_sin.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formatting handoff and snap time time to then adjust for how long handoff is from snap, determines different type of plays\n\ntrn_sin['TimeHandoff'] = trn_sin['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\ntrn_sin['TimeSnap'] = trn_sin['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\ntrn_sin['handoff_snap_diff'] = (trn_sin['TimeHandoff'] - trn_sin['TimeSnap']).map(lambda x:x.seconds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now that I've created the time diff I can drop time snap and handoff, also gameclock and a few of the ids that arent useful\n\nremove_features = ['GameId','PlayId','DisplayName','GameClock','TimeHandoff','TimeSnap']\n\ntrn_sin['date_game'] = trn_sin.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\ntrn_sin['runner_age'] = (trn_sin.date_game.map(pd.to_datetime) - trn_sin.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365\nremove_features.append('HomeTeamAbbr')\nremove_features.append('VisitorTeamAbbr')\nremove_features.append('PlayerBirthDate')\nremove_features.append('is_run')\ndef transform_height(te):\n    return (int(te.split('-')[0])*12 + int(te.split('-')[1]))*2.54/100\ntrn_sin['runner_height'] = trn_sin.PlayerHeight.map(transform_height)\nremove_features.append('PossessionTeam')\nremove_features.append('FieldPosition')\nremove_features.append('PlayerHeight')\nremove_features.append('NflIdRusher')\nremove_features.append('date_game')\ntrn_sin['own_field'] = (trn_sin['FieldPosition'] == trn_sin['PossessionTeam']).astype(int)\ndist_to_end_trn = trn_sin.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\nremove_features.append('own_field')\n\n# to drop all I have to just use what i created earlier and axis = 1 for columns\n\ntrn_sin.drop(remove_features,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_sin.fillna(-999,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data sets here which will be important for my regression to have yards seperated from rest\n\ny_trn_df = trn_sin.Yards\nX_trn_df = trn_sin.drop(['Yards'],axis=1)\nfor f in X_trn_df.columns:\n    if X_trn_df[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_trn_df[f])+[-999])\n        X_trn_df[f] = lbl.transform(list(X_trn_df[f]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Have to create the submission csv which will end up giving me a CRPS for the data for each play\n\ndef get_cdf_df(yards_array):\n    pdf, edges = np.histogram(yards_array, bins=199,\n                 range=(-99,100), density=True)\n    cdf = pdf.cumsum().clip(0, 1)\n    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n                            columns=['Yards'+str(i) for i in range(-99,100)])\n    return cdf_df\ncdf = get_cdf_df(y_trn_df).values.reshape(-1,)\n\ndef get_score(y_pred,cdf,w,dist_to_end):\n    y_pred = int(y_pred)\n    if y_pred ==w:\n        y_pred_array = cdf.copy()\n    elif y_pred - w >0:\n        y_pred_array = np.zeros(199)\n        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n    elif w - y_pred >0:\n        y_pred_array = np.ones(199)\n        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n    y_pred_array[-1]=1\n    y_pred_array[(dist_to_end+99):]=1\n    return y_pred_array    \n\ndef get_score_1(y_pred,y_true,cdf,w,dist_to_end):\n    y_pred = int(y_pred)\n    if y_pred ==w:\n        y_pred_array = cdf.copy()\n    elif y_pred - w >0:\n        y_pred_array = np.zeros(199)\n        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n    elif w - y_pred >0:\n        y_pred_array = np.ones(199)\n        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n    y_pred_array[-1]=1\n    y_pred_array[(dist_to_end+99):]=1\n    y_true_array = np.zeros(199)\n    y_true_array[(y_true+99):]=1\n    return np.mean((y_pred_array - y_true_array)**2)\n\n# I want to calculate the CRPS for my csv and return it for every row\ndef CRPS(y_preds,y_trues,w,cdf,dist_to_ends):\n    if len(y_preds) != len(y_trues):\n        print('length does not match')\n        return None\n    n = len(y_preds)\n    tmp = []\n    for a,b,c in zip(y_preds, y_trues,dist_to_ends):\n        tmp.append(get_score_1(a,b,cdf,w,c))\n    return np.mean(tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a LightGBM, Light Gradient Boosting Machine, seems like the best way about. Handles large amount of data fast\n\nkf=KFold(n_splits = 5)\nresu1 = 0\nimpor1 = 0\nresu2_cprs = 0\nresu3_mae=0\ny_pred = 0\nstack_trn = np.zeros([X_trn_df.shape[0],])\nmodels = []\nfor trn_index, test_index in kf.split(X_trn_df, y_trn_df):\n    X_trn2= X_trn_df.iloc[trn_index,:]\n    y_trn2= y_trn_df.iloc[trn_index]\n    X_test2= X_trn_df.iloc[test_index,:]\n    y_test2= y_trn_df.iloc[test_index]\n    clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,learning_rate=0.005,importance_type = 'gain',\n                     n_jobs = -1,metric='mae')\n    clf.fit(X_trn2,y_trn2,eval_set = [(X_trn2,y_trn2),(X_test2,y_test2)],early_stopping_rounds=200,verbose=50)\n    models.append(clf)\n    temp_predict = clf.predict(X_test2)\n    stack_trn[test_index] = temp_predict\n    #y_pred += clf.predict(X_test2)/5\n    mse = mean_squared_error(y_test2, temp_predict)\n    crps = CRPS(temp_predict,y_test2,4,cdf,dist_to_end_trn.iloc[test_index])\n    mae = mean_absolute_error(y_test2, temp_predict)\n    print(crps)\n    \n# Many people used LightGBM or Neural Networks/ Random Forest Models, LightGBM I was told was the least amount of machine learning so why I chose it\n    \n    resu1 += mse/5\n    resu2_cprs += crps/5\n    resu3_mae += mae/5 \n    impor1 += clf.feature_importances_/5\n    gc.collect()\nprint('mean mse:',resu1)\nprint('oof mse:',mean_squared_error(y_trn_df,stack_trn))\nprint('mean mae:',resu3_mae)\nprint('oof mae:',mean_absolute_error(y_trn_df,stack_trn))\nprint('mean cprs:',resu2_cprs)\nprint('oof cprs:',CRPS(stack_trn,y_trn_df,4,cdf,dist_to_end_trn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_test(test):\n    test.loc[test.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n    test.loc[test.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n\n    test.loc[test.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n    test.loc[test.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n\n    test.loc[test.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n    test.loc[test.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n\n    test.loc[test.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n    test.loc[test.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n    test['is_run'] = test.NflId == test.NflIdRusher\n    test_sin = test[test.is_run==True]\n    test_sin['time_quarter'] = test_sin.GameClock.map(lambda x:transform_time_quarter(x))\n    test_sin['time_end'] = test_sin.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n    test_sin['TimeHandoff'] = test_sin['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    test_sin['TimeSnap'] = test_sin['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    test_sin['handoff_snap_diff'] = (test_sin['TimeHandoff'] - test_sin['TimeSnap']).map(lambda x:x.seconds)\n    test_sin['date_game'] = test_sin.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n    test_sin['runner_age'] = (test_sin.date_game.map(pd.to_datetime) - test_sin.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365\n    test_sin['runner_height'] = test_sin.PlayerHeight.map(transform_height)\n    return test_sin.drop(remove_features,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally run my prediction\n\nfor (test_df, sample_prediction_df) in env.iter_test():\n    test_df['own_field'] = (test_df['FieldPosition'] == test_df['PossessionTeam']).astype(int)\n    dist_to_end_test = test_df.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n    X_test = transform_test(test_df)\n    X_test.fillna(-999,inplace=True)\n    for f in X_test.columns:\n        if X_test[f].dtype=='object':\n            X_test[f] = X_test[f].map(lambda x:x if x in set(X_trn_df[f]) else -999)\n    for f in X_test.columns:\n        if X_test[f].dtype=='object': \n            lbl = preprocessing.LabelEncoder()\n            lbl.fit(list(X_trn_df[f])+[-999])\n            X_test[f] = lbl.transform(list(X_test[f])) \n    pred_value = 0\n    for model in models:\n        pred_value += model.predict(X_test)[0]/5\n    pred_data = list(get_score(pred_value,cdf,4,dist_to_end_test.values[0]))\n    pred_data = np.array(pred_data).reshape(1,199)\n    pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n                               columns = sample_prediction_df.columns, \\\n                                #data = np.array(pred_data))\n                                data = pred_data)\n    env.predict(pred_target)\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a visual diagram of plays with the runningbacks direction\n\ntrn_df['ToLeft'] = trn_df.PlayDirection == \"left\"\ntrn_df['IsBallCarrier'] = trn_df.NflId == trn_df.NflIdRusher\ntrn_df['Dir_rad'] = np.mod(90 - trn_df.Dir, 360) * math.pi/180.0\n\n# First creating the football field figure\n\ndef create_football_field(linenumbers=True,\n                          endzones=True,\n                          highlight_line=False,\n                          highlight_line_number=50,\n                          highlighted_name='Line of Scrimmage',\n                          fifty_is_los=False,\n                          figsize=(12*2, 6.33*2)):\n    # creating shape\n    rect = patches.Rectangle((0, 0), 120, 53.3, linewidth=0.1,\n                             edgecolor='r', facecolor='darkgreen', zorder=0,  alpha=0.5)\n\n    fig, ax = plt.subplots(1, figsize=figsize)\n    ax.add_patch(rect)\n\n    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n             color='white')\n    if fifty_is_los:\n        plt.plot([60, 60], [0, 53.3], color='gold')\n        plt.text(62, 50, '<- Player Yardline at Snap', color='gold')\n    # Endzones\n    if endzones:\n        ez1 = patches.Rectangle((0, 0), 10, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ez2 = patches.Rectangle((110, 0), 120, 53.3,\n                                linewidth=0.1,\n                                edgecolor='r',\n                                facecolor='blue',\n                                alpha=0.2,\n                                zorder=0)\n        ax.add_patch(ez1)\n        ax.add_patch(ez2)\n    plt.xlim(0, 120)\n    plt.ylim(-5, 58.3)\n    plt.axis('off')\n    if linenumbers:\n        for x in range(20, 110, 10):\n            numb = x\n            if x > 50:\n                numb = 120 - x\n            plt.text(x, 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white')\n            plt.text(x - 0.95, 53.3 - 5, str(numb - 10),\n                     horizontalalignment='center',\n                     fontsize=20,  # fontname='Arial',\n                     color='white', rotation=180)\n    if endzones:\n        hash_range = range(11, 110)\n    else:\n        hash_range = range(1, 120)\n\n    for x in hash_range:\n        ax.plot([x, x], [0.4, 0.7], color='white')\n        ax.plot([x, x], [53.0, 52.5], color='white')\n        ax.plot([x, x], [22.91, 23.57], color='white')\n        ax.plot([x, x], [29.73, 30.39], color='white')\n\n    if highlight_line:\n        hl = highlight_line_number + 10\n        plt.plot([hl, hl], [0, 53.3], color='yellow')\n        plt.text(hl + 2, 50, '<- {}'.format(highlighted_name),\n                 color='yellow')\n    return fig, ax\ncreate_football_field()\n\ndef get_dx_dy(radian_angle, dist):\n    dx = dist * math.cos(radian_angle)\n    dy = dist * math.sin(radian_angle)\n    return dx, dy\n\n# Create a show_play function , to do this we take the scatter of players then want to consider x and y locations\n\ndef show_play(play_id, trn_df=trn_df):\n    df = trn_df[trn_df.PlayId == play_id]\n    fig, ax = create_football_field()\n    ax.scatter(df.X, df.Y, cmap='rainbow', c=~(df.Team == 'home'), s=100)\n    rusher_row = df[df.NflIdRusher == df.NflId]\n    ax.scatter(rusher_row.X, rusher_row.Y, color='black')\n    yards_covered = rusher_row[\"Yards\"].values[0]\n    x = rusher_row[\"X\"].values[0]\n    y = rusher_row[\"Y\"].values[0]\n    rusher_dir = rusher_row[\"Dir_rad\"].values[0]\n    rusher_speed = rusher_row[\"S\"].values[0]\n    dx, dy = get_dx_dy(rusher_dir, rusher_speed)\n\n# We use labeling with plt to give us a better description and almost an if else statement for if its right or left\n    \n    ax.arrow(x, y, dx, dy, length_includes_head=True, width=0.3, color='black')\n    left = 'left' if df.ToLeft.sum() > 0 else 'right'\n    plt.title(f'Play # {play_id} moving to {left}, yard distance is {yards_covered}', fontsize=20)\n    plt.legend()\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see plays visually now with movement, and details at the top\nshow_play(20181230154157)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}