{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n"},{"metadata":{},"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/WoSvK1u.jpg\" width=\"500px\"></center>"},{"metadata":{},"cell_type":"markdown","source":"In this kernel, I will do some basic EDA. I will visualize features in the dataset, and in the process, try to gain some insights about the patterns in the data. After that, I will show how to a CNN model in PyTorch to solve this problem. So let's get right into it :)"},{"metadata":{},"cell_type":"markdown","source":"<font size=3 color='red'>Please upvote if you find it useful or interesting :) It motivates me to produce more quality content.</font>"},{"metadata":{},"cell_type":"markdown","source":"### Install and import the necessary libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport time\nimport math\nimport tqdm\nimport numpy as np\nimport pandas as pd\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm_notebook as tqdm\nfrom kaggle.competitions import nflrush\n\nenv = nflrush.make_env()\niter_test = env.iter_test()\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import MinMaxScaler\n\n!pip install -qqq hiddenlayer\nimport hiddenlayer as hl\n\nimport IPython\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Declare the necessary constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 8\nBATCH_SIZE = 128\nDATA_PATH = '../input/nfl-big-data-bowl-2020/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the training data"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH + 'train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA ðŸ“Š\n\nNow, I am going to use **seaborn** and **plotly** to visualize and analyze the data."},{"metadata":{},"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/HrT6xFJ.png\" width=\"300px\"></center>"},{"metadata":{},"cell_type":"markdown","source":"## X coordinate\n\nThese are the *x*-coordinates of the players on the field during the games."},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot(hist_data=[train_df.sample(frac=0.025)[\"X\"]], group_labels=\"X\", colors=['rgb(26, 153, 0)'])\nfig.update_layout(title=\"X coordinate\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"X coordinate\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the distribution plot above, we can see that the *x*-coordinates of the players in the dataset has a somewhat bimodal distribution. There are two major peaks in the probability density, at around 35 and 85 yards. This is probably where most players are concentrated on average: in between the midway line and their end of the field. The two peaks probably represent the two teams playing the game."},{"metadata":{},"cell_type":"markdown","source":"## X coordinate vs. Yards"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nplot = sns.jointplot(x=data[\"X\"], y=data[\"Yards\"], kind='kde', color='forestgreen', height=7)\nplot.set_axis_labels('X coordinate', 'Yards', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the KDE plot above, we can see that the *x*-coordinate does not have any clear correlation or relationship with the number of yards gained in the play. The density is concentrated at the center, at around **X = 50** and **Yards = 3**. The probability density decreases rapidly as one moves away from this central region, where most of the data is concentrated."},{"metadata":{},"cell_type":"markdown","source":"## Y coordinate\n\nThese are the *y*-coordinates of the players on the field during the games."},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot(hist_data=[train_df.sample(frac=0.025)[\"Y\"]], group_labels=\"Y\", colors=['rgb(179, 0, 30)'])\nfig.update_layout(title=\"Y coordinate\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Y coordinate\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the distribution plot above, we can see that the *y*-coordinates of the players in the dataset has a somewhat normal, unimodal distribution. There ais one major peaks in the probability density, at around **Y = 25** yards, which is near the center of the pitch. The two small peaks at the extreme ends of the distribution probably represent the players on the extreme left and right \"sides\" or \"flanks\" of the field."},{"metadata":{},"cell_type":"markdown","source":"## Y coordinate vs. Yards"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nplot = sns.jointplot(x=data[\"Y\"], y=data[\"Yards\"], kind='kde', color=(179/255, 0, 30/255), height=7)\nplot.set_axis_labels('Y coordinate', 'Yards', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the KDE plot above, we can see that the *y*-coordinate does not have any clear correlation or relationship with the number of yards gained in the play. The density is concentrated at the center, at around **Y = 25** and **Yards = 3**. The probability density decreases rapidly as one moves away from this central region, where most of the data is concentrated."},{"metadata":{},"cell_type":"markdown","source":"## X coordinate vs. Y coordinate"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nplot = sns.jointplot(x=data[\"X\"], y=data[\"Y\"], kind='kde', color='mediumvioletred', height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above, we can see that most of the *xy*-coordinate data is concentrated around a flat rectangular region in the dead center of the field. The probability density decreases as we move away from this central rectangle. The rectange extends from **X = 35 to 85** and **Y = 20 to 30**."},{"metadata":{},"cell_type":"markdown","source":"## X coordinate vs. Y coordinate for different offense formations"},{"metadata":{},"cell_type":"markdown","source":"Now, I will look at how the *xy*-coordinate distribution of players is different for different offense formations."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data = train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"empty_data = data.query('OffenseFormation == \"EMPTY\"')\niform_data = data.query('OffenseFormation == \"I_FORM\"')\njumbo_data = data.query('OffenseFormation == \"JUMBO\"')\npistol_data = data.query('OffenseFormation == \"PISTOL\"')\nshotgun_data = data.query('OffenseFormation == \"SHOTGUN\"')\nsingleback_data = data.query('OffenseFormation == \"SINGLEBACK\"')\nwildcat_data = data.query('OffenseFormation == \"WILDCAT\"')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"colors = ['red', 'orangered', 'orange', (179/255, 149/255, 0), 'forestgreen', 'blue', 'blueviolet', 'darkviolet']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Empty formation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot = sns.jointplot(x=empty_data[\"X\"], y=empty_data[\"Y\"], kind='kde', color=colors[0], height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above (for the \"empty\" formation), we can see that the *x*-coordinates are concentrated heavily around the **X = 40** mark. Maybe this suggests that attacks of this form occur mainly from the left side of the field, because this value of **X** is closer to the left end of the field than the right end. But, there is also comparatively less dense region of probability density at around **X = 80**, suggesting that attacks can also take place from the other side of the field, but this is less likely."},{"metadata":{},"cell_type":"markdown","source":"### \"I\" formation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot = sns.jointplot(x=iform_data[\"X\"], y=iform_data[\"Y\"], kind='kde', color=colors[1], height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above (for the \"I\" formation), we can see that most of the *xy*-coordinate data is concentrated around a flat rectangular region in the dead center of the field. The probability density decreases as we move away from this central rectangle. The rectange extends from **X = 10 to 110** and **Y = 15 to 35**. This suggests that most attacks of this type occur from the center of the field. But, there are also minor regions of density at the top and bottom extremes of the field, suggesting that such attacks can also take place from the left and right flanks of the field."},{"metadata":{},"cell_type":"markdown","source":"### Jumbo formation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot = sns.jointplot(x=jumbo_data[\"X\"], y=jumbo_data[\"Y\"], kind='kde', color=colors[2], height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above (for the \"jumbo\" formation), we can see that most of the *xy*-coordinate data is heavily concentrated at two regions on the field, at around **X = 10** and **X = 110**. The density in between these two regions is comparatively very low. This suggests that such attacks generally take place at the left and right extremes of the field, and not at the center."},{"metadata":{},"cell_type":"markdown","source":"### Pistol formation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot = sns.jointplot(x=pistol_data[\"X\"], y=pistol_data[\"Y\"], kind='kde', color=colors[3], height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above (for the \"pistol\" formation), we can see that most of the *xy*-coordinate data is concentrated around a flat rectangular region in the dead center of the field. The probability density decreases as we move away from this central rectangle. The rectange extends from **X = 10 to 110** and **Y = 15 to 35**. This suggests that most attacks of this type occur from the center of the field. But, there are also minor regions of density at the top and bottom extremes of the field, suggesting that such attacks can also take place from the left and right flanks of the field."},{"metadata":{},"cell_type":"markdown","source":"### Shotgun formation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot = sns.jointplot(x=shotgun_data[\"X\"], y=shotgun_data[\"Y\"], kind='kde', color=colors[4], height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once again, in the plot above (for the \"shotgun\" formation), we can see that most of the *xy*-coordinate data is concentrated around a flat rectangular region in the dead center of the field. The probability density decreases as we move away from this central rectangle. The rectange extends from **X = 10 to 110** and **Y = 15 to 35**. This suggests that most attacks of this type occur from the center of the field. But, there are also minor regions of density at the top and bottom extremes of the field, suggesting that such attacks can also take place from the left and right flanks of the field."},{"metadata":{},"cell_type":"markdown","source":"### Singleback formation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot = sns.jointplot(x=singleback_data[\"X\"], y=singleback_data[\"Y\"], kind='kde', color=colors[5], height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a similar pattern to the \"pistol\" formation here. In the plot above (for the \"singleback\" formation), we can see that most of the *xy*-coordinate data is concentrated around a flat rectangular region in the dead center of the field. The probability density decreases as we move away from this central rectangle. The rectange extends from **X = 10 to 110** and **Y = 15 to 35**. This suggests that most attacks of this type occur from the center of the field. But, there are also minor regions of density at the top and bottom extremes of the field, suggesting that such attacks can also take place from the left and right flanks of the field."},{"metadata":{},"cell_type":"markdown","source":"### Wilcat formation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot = sns.jointplot(x=wildcat_data[\"X\"], y=wildcat_data[\"Y\"], kind='kde', color=colors[6], height=7)\nplot.set_axis_labels('X coordinate', 'Y coordinate', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above (for the \"wildcat\" formation), we can see that the *x*-coordinates are concentrated heavily around the **X = 20** and **X = 70** marks. Maybe this suggests that attacks of this form occur from both sides of the field. But, every few attacks of this form at values of **X > 110**."},{"metadata":{},"cell_type":"markdown","source":"## Dir\n\n**Dir** is the angle of the player's motion during the play"},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot(hist_data=[train_df.sample(frac=0.025).query('Dir == Dir')[\"Dir\"]], group_labels=[\"Dir\"], colors=['rgb(255, 102, 25)'])\nfig.update_layout(title=\"Dir\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Dir\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot, we can see that the distribution of **Dir** is roughly trimodal (three peaks). One peak occurs approximately at the center at around **Dir = 190**, and the other two peaks occur at the extreme ends of the distribution, at **Dir = 0** and **Dir = 350**. This probably represents two types of motion in players: almost straight motion (0 or 350 degrees) and diagonal motion (190 degrees)."},{"metadata":{},"cell_type":"markdown","source":"## Dir vs. Yards"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nplot = sns.jointplot(x=data[\"Dir\"], y=data[\"Yards\"], kind='kde', color=(255/255, 102/255, 25/255), height=7)\nplot.set_axis_labels('Dir', 'Yards', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the KDE plot above, we can see that the **Dir** value does not have any clear correlation or relationship with the number of yards gained in the play. The density is concentrated at three symmetric  areas around the center, at **Dir = 0, 190 and 350**. The probability density decreases rapidly as one moves away from these three region, where most of the data is concentrated."},{"metadata":{},"cell_type":"markdown","source":"## Acceleration\n\n**A** is the acceleration of the player in yards per second per second."},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot(hist_data=[train_df.sample(frac=0.025)[\"A\"]], group_labels=\"A\", colors=['rgb(0, 0, 230)'])\nfig.update_layout(title=\"A\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"A\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above, we can see that the distribution of **A** is asymmetrical, unimodal, and heavily skewed to the right. The probability density of the acceleration peaks at around **A = 1** yard per second per second. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nplot = sns.jointplot(x=data[\"A\"], y=data[\"Yards\"], kind='kde', color=(0, 0, 230/255), height=7)\nplot.set_axis_labels('A', 'Yards', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the KDE plot above, we can see that the acceleration does not have any clear correlation or relationship with the number of yards gained in the play. The density is concentrated at the left edge, at around **A = 1** and **Yards = 3**. The probability density decreases as one moves away from this central region, where most of the data is concentrated."},{"metadata":{},"cell_type":"markdown","source":"## Speed"},{"metadata":{},"cell_type":"markdown","source":"**S** is the speed of the player in yards per second."},{"metadata":{"trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot(hist_data=[train_df.sample(frac=0.025)[\"S\"]], group_labels=\"S\", colors=['rgb(230, 0, 191)'])\nfig.update_layout(title=\"S\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"S\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above, we can see that the distribution of **S** is asymmetrical, unimodal, and heavily skewed to the right. The probability density of the speed peaks at around **S = 2** yard per second. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nplot = sns.jointplot(x=data[\"S\"], y=data[\"Yards\"], kind='kde', color=(230/255, 0, 191/255), height=7)\nplot.set_axis_labels('S', 'Yards', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the KDE plot above, we can see that the speed does not have any clear correlation or relationship with the number of yards gained in the play. The density is concentrated at the left edge, at around **S = 2** and **Yards = 3**. The probability density decreases as one moves away from this central region, where most of the data is concentrated."},{"metadata":{},"cell_type":"markdown","source":"## Humidity\n\nHumidity is the percentage (from 0 to 100) of water vapour present in the air during the game."},{"metadata":{},"cell_type":"markdown","source":"### Dsitribution plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)[\"Humidity\"]\nfig = ff.create_distplot(hist_data=[data.fillna(data.mean())], group_labels=[\"Humidity\"], colors=['rgb(0, 102, 102)'])\nfig.update_layout(title=\"Humidity\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Humidity\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above, we can see that the distribution of humidity in the dataset has a slight leftward skew and is bimodal in nature. The distribution has two peaks at around **Humidity = 0 and 70**. The first peak, at **Humidity = 0** is very sudden and goes against the gentle leftward skew of the data."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nplot = sns.jointplot(x=data[\"Humidity\"], y=data[\"Yards\"], kind='kde', color=(0/255, 77/255, 77/255), height=7)\nplot.set_axis_labels('Humidity', 'Yards', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the KDE plot above, we can see that the humidity does not have any clear correlation or relationship with the number of yards gained in the play. The density is concentrated at the right edge, at around **Humidity = 70** and **Yards = 3**. There is another high density region at **Humidity = 0**. The probability density decreases as one moves away from these regions, where most of the data is concentrated."},{"metadata":{},"cell_type":"markdown","source":"## Temperature\n\n**Temperature** is the temperature (in degrees Fahrenheit) during the game."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)[\"Temperature\"]\nfig = ff.create_distplot(hist_data=[data.fillna(data.mean())], group_labels=[\"Temperature\"], colors=['rgb(51, 34, 0)'])\nfig.update_layout(title=\"Temperature\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Temperature\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above, we can see that the distribution of humidity in the dataset has a slight leftward skew and is roughly unimodal in nature. The distribution has one peak at around **Temperature = 60** degrees Fahrenheit."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nplot = sns.jointplot(x=data[\"Temperature\"], y=data[\"Yards\"], kind='kde', color=(51/255, 34/255, 0), height=7)\nplot.set_axis_labels('Temperature', 'Yards', fontsize=16)\nplt.show(plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the KDE plot above, we can see that the humidity does not have any clear correlation or relationship with the number of yards gained in the play. The density is concentrated towards the right side, at around **Temperature = 60** and **Yards = 3**. The probability density decreases as one moves away from this region, where most of the data is concentrated."},{"metadata":{},"cell_type":"markdown","source":"## Team vs. Yards"},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\naway_data = data.query('Team == \"away\"')[\"Yards\"]\nhome_data = data.query('Team == \"home\"')[\"Yards\"]\n\nfig = ff.create_distplot(hist_data=[away_data, home_data],\n                         group_labels=[\"Away\", \"Home\"],\n                         show_hist=False)\n\nfig.update_layout(title=\"Team vs. Yards\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Yards\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot above, we can see that the distribution of yards gained is almost identical for home teams and away teams. Therefore, whether a player is from the home team or the away team does not affect the yards gained during a play."},{"metadata":{},"cell_type":"markdown","source":"### Box plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\ndata = [away_data, home_data]\ntags = [\"Away\", \"Home\"]\n\nfor index, category in enumerate(data):\n    fig.add_trace(go.Box(y=category, name=tags[index]))\n\nfig.update_layout(title=\"Team vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"Team\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above plot, we can once again see that the distribution of yards gained is almost identical for home and away teams."},{"metadata":{},"cell_type":"markdown","source":"### Violin plot"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\ndata = [away_data, home_data]\ntags = [\"Away\", \"Home\"]\n\nfor index, category in enumerate(data):\n    fig.add_trace(go.Violin(y=category, name=tags[index]))\n\nfig.update_layout(title=\"Team vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"Team\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above plot, once gain, reinforces the fact that the distributions are very similar."},{"metadata":{},"cell_type":"markdown","source":"## WindDirection vs. Yards"},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nnorth_data = data.query('WindDirection == \"N\"')[\"Yards\"]\neast_data = data.query('WindDirection == \"E\"')[\"Yards\"]\nwest_data = data.query('WindDirection == \"W\"')[\"Yards\"]\nsouth_data = data.query('WindDirection == \"S\"')[\"Yards\"]\n\nfig = ff.create_distplot(hist_data=[north_data, east_data, west_data, south_data],\n                         group_labels=[\"North\", \"East\", \"West\", \"South\"],\n                         show_hist=False)\n\nfig.update_layout(title=\"WindDirection vs. Yards\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Yards\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the distributions above are unimodal and seem to have a slight rightward skew. The distributions are different from each other, but the difference in not very sizeable. The distribution for **East** wind direction has the highest mean yards gained, whereas the **West** wind direction has the lowest mean yards gained."},{"metadata":{},"cell_type":"markdown","source":"### Box plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\ndata = [north_data, east_data, west_data, south_data]\ntags = [\"North\", \"East\", \"West\", \"South\"]\n\nfor index, category in enumerate(data):\n    fig.add_trace(go.Box(y=category, name=tags[index]))\n    \nfig.update_layout(title=\"WindDirection vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"WindDirection\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above plot, we can once again see that the distribution of yards gained are somewhat similar for different wind directions. But, the distribution for **East** wind direction has the highest mean yards gained, whereas the **West** wind direction has the lowest mean yards gained. "},{"metadata":{},"cell_type":"markdown","source":"### Violin plot"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\ndata = [north_data, east_data, west_data, south_data]\ntags = [\"North\", \"East\", \"West\", \"South\"]\n\nfor index, category in enumerate(data):\n    fig.add_trace(go.Violin(y=category, name=tags[index]))\n\nfig.update_layout(title=\"WindDirection vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"WindDirection\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above plot, once gain, reinforces the fact that the distributions are very similar, but the **West** distribution has the highest mean and the **East** distribution has the lowest mean."},{"metadata":{},"cell_type":"markdown","source":"## Offense formation vs. Yards"},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nempty_data = data.query('OffenseFormation == \"EMPTY\"')[\"Yards\"]\niform_data = data.query('OffenseFormation == \"I_FORM\"')[\"Yards\"]\njumbo_data = data.query('OffenseFormation == \"JUMBO\"')[\"Yards\"]\npistol_data = data.query('OffenseFormation == \"PISTOL\"')[\"Yards\"]\nshotgun_data = data.query('OffenseFormation == \"SHOTGUN\"')[\"Yards\"]\nsingleback_data = data.query('OffenseFormation == \"SINGLEBACK\"')[\"Yards\"]\nwildcat_data = data.query('OffenseFormation == \"WILDCAT\"')[\"Yards\"]\n\nfig = ff.create_distplot(hist_data=[empty_data, iform_data, jumbo_data,\n                                    pistol_data, shotgun_data, singleback_data, wildcat_data],\n                         group_labels=[\"Empty\", \"I-Form\", \"Jumbo\", \"Pistol\",\n                                       \"Shotgun\", \"Singleback\", \"Wildcat\"],\n                         show_hist=False)\n\nfig.update_layout(title=\"OffenseFormation vs. Yards\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Yards\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above plot, we can see that most of the distributions are very similar except the **Jumbo** and **Empty** distributions. Although all the distributions are unimodal and roughly normal, the distribution for **Jumbo** has a significantly lower mean than the other distributions, and the distributions for **Empty**, on the other hand, has a significantly higher mean than the other distributions. Therefore, **Empty** offense formations generally tend to have higher yards gained than average. And, **Jumbo** offense formations generally tend to have lower yards gained than average."},{"metadata":{},"cell_type":"markdown","source":"### Box plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\ndata = [empty_data, iform_data, jumbo_data, pistol_data, shotgun_data, singleback_data, wildcat_data]\ntags = [\"Empty\", \"I-Form\", \"Jumbo\", \"Pistol\", \"Shotgun\", \"Singleback\", \"Wildcat\"]\n\nfor index, category in enumerate(data):\n    fig.add_trace(go.Box(y=category, name=tags[index]))\n\nfig.update_layout(title=\"OffenseFormation vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"OffenseFormation\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot above also shows that **Empty** formations generally result in higher-than-average yards gained, and **Jumbo** formations generally result in lower-than-average yards gained. All the other formations are almost exactly identical to each other in terms of yards gained."},{"metadata":{},"cell_type":"markdown","source":"### Violin plot"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\ndata = [empty_data, iform_data, jumbo_data, pistol_data, shotgun_data, singleback_data, wildcat_data]\ntags = [\"Empty\", \"I-Form\", \"Jumbo\", \"Pistol\", \"Shotgun\", \"Singleback\", \"Wildcat\"]\n\nfor index, category in enumerate(data):\n    fig.add_trace(go.Violin(y=category, name=tags[index]))\n\nfig.update_layout(title=\"OffenseFormation vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"OffenseFormation\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above plot, once gain, reinforces the fact that **Empty** formations generally result in higher-than-average yards gained, and **Jumbo** formations generally result in lower-than-average yards gained."},{"metadata":{},"cell_type":"markdown","source":"## HomeTeamAbbr vs. Yards"},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nhist_data = [data.loc[data[\"HomeTeamAbbr\"] == home_team_abbr][\"Yards\"] for home_team_abbr in set(data['HomeTeamAbbr'])]\n\nfig = ff.create_distplot(hist_data=hist_data, group_labels=list(set(data['HomeTeamAbbr'])), show_hist=False)\nfig.update_layout(title=\"HomeTeamAbbr vs. Yards\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Yards\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot, we can see that almost all the home teams have very similar distributions of yards gained."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"hist_data = [ele for ele in reversed(hist_data)] \ntags = [ele for ele in reversed(list(set(data['HomeTeamAbbr'])))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Box plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\nfor index, category in enumerate(hist_data):\n    fig.add_trace(go.Box(y=category, name=tags[index]))\n\nfig.update_layout(title=\"HomeTeamAbbr vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"HomeTeamAbbr\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above plot, we can see that most distributions are similar. But, the few teams that have the highest average yards gained are the **Wahington Redskins, Oakland Raiders, and Green Bay Packers**. On the other hand, the teams that have the lowest average yards gained are the **Chicago Bears and New York Jets**. "},{"metadata":{},"cell_type":"markdown","source":"### Violin plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\nfor index, category in enumerate(hist_data):\n    fig.add_trace(go.Violin(y=category, name=tags[index]))\n\nfig.update_layout(title=\"HomeTeamAbbr vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"HomeTeamAbbr\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can the same pattern in this plot.\n\n* **Highest Yards Gained**: Wahington Redskins, Oakland Raiders, and Green Bay Packers\n* **Lowest Yards Gained**: Chicago Bears and New York Jets"},{"metadata":{},"cell_type":"markdown","source":"## VisitorTeamAbbr vs. Yards"},{"metadata":{},"cell_type":"markdown","source":"### Distribution plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_df.sample(frac=0.025)\nquantile = data[\"Yards\"].quantile(0.95)\ndata = data.loc[data[\"Yards\"] < quantile]\nhist_data = [data.loc[data[\"VisitorTeamAbbr\"] == visitor_team_abbr][\"Yards\"] for visitor_team_abbr in set(data['VisitorTeamAbbr'])]\n\nfig = ff.create_distplot(hist_data=hist_data, group_labels=list(set(data['VisitorTeamAbbr'])), show_hist=False)\nfig.update_layout(title=\"VisitorTeamAbbr vs. Yards\", yaxis=dict(title=\"Probability Density\"), xaxis=dict(title=\"Yards\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot, we can see that almost all the visitor teams have very similar distributions of yards gained."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"hist_data = [ele for ele in reversed(hist_data)]\ntags = [ele for ele in reversed(list(set(data['VisitorTeamAbbr'])))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Box plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\nfor index, category in enumerate(hist_data):\n    fig.add_trace(go.Box(y=category, name=tags[index]))\n\nfig.update_layout(title=\"VisitorTeamAbbr vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"VisitorTeamAbbr\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above plot, we can see that most distributions are similar. But, the few teams that have the highest average yards gained are the **Oakland Raiders, New England Patriots, and Minnesota Vikings**. On the other hand, the teams that have the lowest average yards gained are the **Jacksonville Jaguars and Carolina Panthers**. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\nfor index, category in enumerate(hist_data):\n    fig.add_trace(go.Violin(y=category, name=tags[index]))\n\nfig.update_layout(title=\"VisitorTeamAbbr vs. Yards\", yaxis=dict(title=\"Yards\"), xaxis=dict(title=\"VisitorTeamAbbr\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can the same pattern in this plot.\n\n* **Highest Yards Gained**: Oakland Raiders, New England Patriots, and Minnesota Vikings\n* **Lowest Yards Gained**: Jacksonville Jaguars and Carolina Panthers"},{"metadata":{},"cell_type":"markdown","source":"# PyTorch Model ðŸ”¥"},{"metadata":{},"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/GOs1cLy.jpg\" width=\"500px\"></center>"},{"metadata":{},"cell_type":"markdown","source":"Now, I am going to show how to build a CNN model to solve this problem using PyTorch."},{"metadata":{},"cell_type":"markdown","source":"### Get categorical value sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['Team', 'FieldPosition', 'OffenseFormation']\nvalue_dicts = []\n\nfor feature in cat_cols:\n    values = set(train_df[feature])\n    value_dicts.append(dict(zip(values, np.arange(len(values)))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define helper functions to generate categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def indices(data, feat_index):\n    value_dict = value_dicts[feat_index]\n    return data[cat_cols[feat_index]].apply(lambda x: value_dict[x])\n\ndef one_hot(indices, feat_index):\n    return to_categorical(indices, num_classes=len(value_dicts[feat_index]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_categorical_features(sample, data):\n    index_values = [indices(sample, index) for index in range(len(value_dicts))]\n    features = tuple([one_hot(value, index) for index, value in enumerate(index_values)])\n    features = np.concatenate(features, axis=1)\n    return features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define helper functions to generate numerical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['X', 'S', 'A', 'Dis', 'Orientation', 'Dir', 'YardLine',\n            'Quarter', 'Down', 'Distance', 'HomeScoreBeforePlay',\n            'VisitorScoreBeforePlay', 'DefendersInTheBox', 'PlayerWeight',\n            'Week', 'Temperature', 'Humidity']\n\ndef get_numerical_features(sample):\n    return sample[num_cols].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a PyTorch Dataset for the problem"},{"metadata":{},"cell_type":"markdown","source":"**What is happening here?**\n\nHere are the steps:\n\n* Group all the data by PlayId\n* Get the 2D data from each PlayId\n* Generate a 2D array with the numerical and categorical features for each PlayId\n* Get the labels for each play\n* Return the features and labels for each play"},{"metadata":{"trusted":true},"cell_type":"code","source":"class NFLCompetitionDataset(Dataset):\n    \n    def __init__(self, data, stage):\n        self.dataframe = data\n        self.stage = stage\n        self.play_ids = list(set(data['PlayId']))\n            \n    def __len__(self):\n        return len(self.play_ids)\n        \n    def __getitem__(self, index):\n        data_locations = self.dataframe['PlayId'] == self.play_ids[index]\n        data_sample = self.dataframe.loc[data_locations]\n        labels = np.array(data_sample['Yards'])\n        labels = np.pad(labels, (0, 25 - len(labels)),\n                        mode='constant',\n                        constant_values=0)\n\n        numerical_features = get_numerical_features(data_sample)\n        features = numerical_features\n\n        padding_length = 25 - features.shape[0]\n        inds = np.where(np.isnan(features))\n        features[inds] = np.take(np.nanmean(features, axis=0), inds[1])\n        inds = np.where(np.isnan(features))\n        features[inds] = 0\n    \n        if padding_length != 0:\n            padding_values = np.vstack([np.mean(features, axis=0).reshape(1, -1)]*padding_length)\n        \n        features = np.concatenate((features, padding_values), axis=0)\n        return features, labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate training and validation sets (80% split)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.sample(frac=1).reset_index(drop=True)\nsplit = np.int32(0.8 * len(train_df))\n\ntrain_set = NFLCompetitionDataset(data=train_df.iloc[:split], stage='train')\nval_set = NFLCompetitionDataset(data=train_df.iloc[split:], stage='val')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1D CNN Model"},{"metadata":{},"cell_type":"markdown","source":"### Define the 1D CNN architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNN1DNetwork(nn.Module):\n    \n    def __init__(self):\n        super(CNN1DNetwork, self).__init__()\n        \n        self.conv1d_1 = nn.Conv1d(in_channels=17, out_channels=100, kernel_size=2)\n        self.conv1d_2 = nn.Conv1d(in_channels=17, out_channels=100, kernel_size=3)\n        self.conv1d_3 = nn.Conv1d(in_channels=17, out_channels=100, kernel_size=4)\n        self.conv1d_4 = nn.Conv1d(in_channels=17, out_channels=100, kernel_size=5)\n        \n        self.dense_1 = nn.Linear(in_features=400, out_features=64)\n        self.dense_2 = nn.Linear(in_features=64, out_features=25)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        x = x.float().permute(0, 2, 1)\n        conv_1 = self.conv1d_1(x)\n        conv_2 = self.conv1d_2(x)\n        conv_3 = self.conv1d_3(x)\n        conv_4 = self.conv1d_4(x)\n    \n        max_pool_1, _ = torch.max(conv_1, 2)\n        max_pool_2, _ = torch.max(conv_2, 2)\n        max_pool_3, _ = torch.max(conv_3, 2)\n        max_pool_4, _ = torch.max(conv_4, 2)\n        \n        features = torch.cat((max_pool_1, max_pool_2, max_pool_3, max_pool_4), 1)\n        conc = self.dense_1(features)\n        conc = self.relu(conc)\n        out = self.dense_2(conc)\n        return out","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize neural network architecture"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"hl_graph = hl.build_graph(CNN1DNetwork(), torch.zeros([1, 25, 17]))\nhl_graph.theme = hl.graph.THEMES[\"blue\"].copy()\nhl_graph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Initialize data loaders"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate the data mean and standard deviation for normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = 0.\nstd = 0.\nnb_samples = 0.\n\nfor data, _ in tqdm(train_loader):\n    batch_samples = data.size(0)\n    data = data.view(batch_samples, data.size(1), -1)\n    mean += data.mean((0, 1))\n    std += data.std((0, 1))\n    nb_samples += batch_samples\n\nmean /= nb_samples\nstd /= nb_samples","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the model (with MSE loss)"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nnetwork = CNN1DNetwork()\noptimizer = Adam(network.parameters(), lr=0.01)\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(EPOCHS):\n    print(\"EPOCH \" + str(epoch + 1))\n    print(\"\")\n    \n    for (train_batch, val_batch) in zip(train_loader, val_loader):\n        train_X, train_y = train_batch\n        val_X, val_y = val_batch\n        \n        train_len = train_X.shape[0]\n        val_len = val_X.shape[0]\n        \n        train_mean = torch.cat(train_len*[torch.cat(25*[mean.view(1, 17)], 0).view(1, 25, 17)], 0)*train_len\n        train_std = torch.cat(train_len*[torch.cat(25*[std.view(1, 17)], 0).view(1, 25, 17)], 0)*train_len\n        val_mean = torch.cat(val_len*[torch.cat(25*[mean.view(1, 17)], 0).view(1, 25, 17)], 0)*val_len\n        val_std = torch.cat(val_len*[torch.cat(25*[std.view(1, 17)], 0).view(1, 25, 17)], 0)*val_len\n\n        train_X = (train_X - train_mean)/train_std\n        val_X = (val_X - val_mean)/val_std\n\n        train_y = torch.tensor(train_y, dtype=torch.float)\n        val_y = torch.tensor(val_y, dtype=torch.float)\n        \n        train_preds = network.forward(train_X)\n        train_loss = nn.MSELoss()(train_preds, train_y)\n        optimizer.zero_grad()\n        train_loss.backward()\n        optimizer.step()\n        \n        val_preds = network.forward(val_X)\n        val_loss = nn.MSELoss()(val_preds, val_y)\n    \n    end = time.time()\n    \n    train_losses.append(train_loss.item())\n    val_losses.append(val_loss.item())\n\n    print(\"Train loss: \" + str(np.round(train_loss.item(), 3)) + \"   \" +\\\n          \"Val loss: \" + str(np.round(val_loss.item(), 3)) + \"   \" +\\\n          \"Total time: \" + str(np.round(end - start, 1)) + \" s\")\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize training and validation losses"},{"metadata":{},"cell_type":"markdown","source":"### Line plot"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=[1, 2, 3, 4, 5, 6, 7, 8], y=train_losses,\n    name='train', mode='lines+markers',\n    marker_color='crimson'\n))\n\nfig.add_trace(go.Scatter(\n    x=[1, 2, 3, 4, 5, 6, 7, 8], y=val_losses,\n    name='val', mode='lines+markers',\n    marker_color=' indigo'\n))\n\nfig.update_traces(mode='lines+markers', marker_line_width=2, marker_size=10)\nfig.update_layout(title='Loss over the epochs', yaxis_zeroline=False, xaxis_zeroline=False)\nfig.update_layout(title=\"Loss over the epochs\", yaxis=dict(title=\"MSE Loss\"), xaxis=dict(title=\"Epochs\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bar plot"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"labels=['Epoch 1', 'Epoch 2', 'Epoch 3', 'Epoch 4',\n        'Epoch 5', 'Epoch 6', 'Epoch 7', 'Epoch 8']\n\nfig = go.Figure(data=[\n    go.Bar(name='train', x=labels, y=train_losses, marker={'color' : 'crimson'}),\n    go.Bar(name='val', x=labels, y=val_losses, marker={'color' : 'indigo'})\n])\n\nfig.update_layout(title=\"Loss over the epochs\", yaxis=dict(title=\"MSE Loss\"))\nfig.update_layout(barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_mean = torch.cat(25*[mean.view(1, 17)], 0).view(1, 25, 17)\ntest_std = torch.cat(25*[std.view(1, 17)], 0).view(1, 25, 17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_prediction(data_sample):\n    numerical_features = get_numerical_features(data_sample)\n    features = numerical_features\n\n    padding_length = 25 - features.shape[0]\n    length = features.shape[0]\n    inds = np.where(np.isnan(features))\n    features[inds] = np.take(np.nanmean(features, axis=0), inds[1])\n    inds = np.where(np.isnan(features))\n    features[inds] = 0\n    \n    if padding_length != 0:\n        padding_values = np.vstack([np.mean(features, axis=0).reshape(1, -1)]*padding_length)\n        \n    features = np.concatenate((features, padding_values), axis=0)\n    features = (features - test_mean.numpy())/test_std.numpy()\n    prediction = network.forward(torch.FloatTensor(features).view(1, 25, 17)).detach().numpy().reshape((25, 1))\n    pred = np.zeros((length, 199))\n\n    for index, row in enumerate(prediction):\n        if np.int32(np.round(row[0])) < 100:\n            pred[index][np.int32(np.round(row[0])) + 99:] = 1\n        else:\n            pred[index][-1] = 1\n\n        if index == length - 1:\n            break\n\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in tqdm(env.iter_test()):\n    predictions = generate_prediction(test_df)\n    env.predict(pd.DataFrame(data=predictions, columns=sample_prediction_df.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Write submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Thank you!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=4 color='red'>That's it! Thanks for reading my kernel. Please upvote if you found it useful or interesting :) It motivates me to produce more quality content.</font>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}