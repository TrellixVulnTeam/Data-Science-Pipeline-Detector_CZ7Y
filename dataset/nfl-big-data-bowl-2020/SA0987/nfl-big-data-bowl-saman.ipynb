{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n# __print__ = print\n# def print(string):\n#     os.system(f'echo \\\"{string}\\\"')\n#     __print__(string)\n\nfname = \"/kaggle/input/nfl-big-data-bowl-2020/train.csv\"\n\n# original public Score .01422","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from kaggle.competitions import nflrush\nimport pandas as pd\nimport datetime\n# Load scikit's random forest classifier library\nfrom sklearn.ensemble import RandomForestClassifier\nimport re\n\n# Load pandas\nimport pandas as pd\n\n# Load numpy\nimport numpy as np\n\n\n\nfrom dateutil.relativedelta import relativedelta\n\n\n\ndef lookup(s):\n    \"\"\"\n    This is an extremely fast approach to datetime parsing.\n    For large data, the same dates are often repeated. Rather than\n    re-parse these, we store all unique dates, parse them, and\n    use a lookup to convert all dates.\n    \"\"\"\n    dates = {date:pd.to_datetime(date) for date in s.unique()}\n    return s.map(dates)\n\ndef ageNow(d):\n       \n    now = datetime.datetime.now()\n    difference = relativedelta(now, d)\n    return(difference.years)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Load scikit's random forest classifier library\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load pandas\nimport pandas as pd\n\n# Load numpy\nimport numpy as np\n\n\n    \nclf = []\n\ndef randomForest(dfIn,cols):\n    global clf\n    # RANDOM FOREST\n\n    # Load the library with the iris dataset\n   \n    # Set random seed\n    np.random.seed(0)\n\n    print(\"Starting 1\")\n    # Create a random forest Classifier. By convention, clf means 'Classifier'\n    clf = RandomForestClassifier(n_jobs=1, random_state=0,n_estimators=10)\n\n    # Train the Classifier to take the training features and learn how they relate\n    # to the training y (the species)\n\n\n    training_df = dfIn[cols][::22]\n\n    y=training_df['Yards']\n    X=training_df[[i for i in training_df.columns if \"Yards\" not in i]]\n\n\n\n    clf.fit(X, y)\n    print(\"Trained\")\n\n\n\n\ndef modifyXY(dfx):\n    dfIn = dfx\n    print('Doing ModifyXY')\n    # add features for us later \n    dfIn['XM'] = dfIn['X'] - 10 # normalize this to absolute yards\n    dfIn['XS'] = dfIn['AbsoluteYardLine'] # this is to use for later and it is easier to understand\n    T = 0.5 # X Y in .5 seconds\n    print('Doing ModifyXY ',T)\n    dfIn['S05'] = dfIn['S'] +  dfIn['A'] * T \n    dfIn['X05'] = dfIn[['X','S','A','Orientation']].apply(lambda x: x['X'] + np.sin(x['Orientation'] * (np.pi/180)) + (x['S'] * T +  x['A']  * x['A'] * T / 2.0),axis=1)\n    dfIn['X05'] = dfIn[['Y','S','A','Orientation']].apply(lambda x: x['Y'] + np.cos(x['Orientation'] * (np.pi/180)) + (x['S'] * T +  x['A']  * x['A'] * T / 2.0),axis=1)\n\n    T = 1 # X Y in 1.0 seconds\n    print('Doing ModifyXY',T)\n    dfIn['S10'] = dfIn['S'] +  dfIn['A'] * T \n    dfIn['Y10'] = dfIn[['X','S','A','Orientation']].apply(lambda x: x['X'] + np.sin(x['Orientation'] * (np.pi/180)) + (x['S'] * T +  x['A']  * x['A'] * T / 2.0),axis=1)\n    dfIn['Y10'] = dfIn[['Y','S','A','Orientation']].apply(lambda x: x['Y'] + np.cos(x['Orientation'] * (np.pi/180)) + (x['S'] * T +  x['A']  * x['A'] * T / 2.0),axis=1)\n    print('Done ModifyXY')\n    \n    print(dfIn.columns)\n    dfOut = dfIn\n    return dfOut\n\ndef isRequired(strIn):\n    global flat_list,isTraining\n    str2 = \".*\"+strIn+\".*\"\n    if (isTraining):\n        print(\"--> isRequired? \",str2,strIn,flat_list)\n\n    r = re.compile(str2)\n    l = list(filter(r.match, flat_list))\n    #print(l,len(l))\n\n    rc = len(l) \n    if rc > 0: \n        if (isTraining):\n            print(\"Field Required = \",strIn)\n    return rc \n        \n    \ndef addFeatures(dfy):\n    global flatlist,isTraining\n\n    \n    dfIn = dfy\n    # correct some typos in the team names \n    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n    for abb in dfIn['PossessionTeam'].unique():\n        map_abbr[abb] = abb\n\n    dfIn['PossessionTeam'] = dfIn['PossessionTeam'].map(map_abbr)\n    dfIn['HomeTeamAbbr'] = dfIn['HomeTeamAbbr'].map(map_abbr)\n    dfIn['VisitorTeamAbbr'] = dfIn['VisitorTeamAbbr'].map(map_abbr)\n    \n   # print('Adding features')\n    # calculate the correct Absolute Yards to go to TD \n    dfIn['AbsoluteYardLine'] = dfIn[['YardLine','PlayDirection','HomeTeamAbbr','PossessionTeam','FieldPosition']].apply(lambda x: int((100-x['YardLine'])) if x['PossessionTeam'] == x['FieldPosition'] else int(int(x['YardLine'])),axis=1)\n    dfIn['PlayerIsRusher']  = dfIn['NflIdRusher'] == dfIn['NflId']\n    \n    # ADD MORE FEATURE CALS HERE\n    if isRequired(\"XS\"):\n        dfIn = modifyXY(dfIn)\n    \n    if isRequired(\"PlayerWeight\"):\n       # print('Adding features PlayerWeight')\n        # calculate the players weights \n        dfIn['PlayerWeightSumDefense'] = dfIn['PlayerWeight']\n        dfIn['PlayerWeightSumOffense'] = dfIn['PlayerWeight']\n\n        dfIn.loc[(dfIn['PossessionTeam'] == dfIn['VisitorTeamAbbr']) & ( dfIn['Team'] == 'away'), 'PlayerWeightSumDefense'] = 0\n        dfIn.loc[(dfIn['PossessionTeam'] == dfIn['HomeTeamAbbr']) & ( dfIn['Team'] == 'home'), 'PlayerWeightSumDefense'] = 0\n        dfIn.loc[(dfIn['PossessionTeam'] != dfIn['VisitorTeamAbbr']) & ( dfIn['Team'] == 'away'), 'PlayerWeightSumOffense'] = 0\n        dfIn.loc[(dfIn['PossessionTeam'] != dfIn['HomeTeamAbbr']) & ( dfIn['Team'] == 'home'), 'PlayerWeightSumOffense'] = 0\n\n\n        w = dfIn.groupby('PlayId')['PlayerWeightSumDefense','PlayerWeightSumOffense'].sum()\n        w.rename(columns={'PlayerWeightSumDefense' : 'PlayerWeightSumDefenseSum', 'PlayerWeightSumOffense' : 'PlayerWeightSumOffenseSum'},inplace=True)\n        #print(\"1\",w.columns)\n        w = w.reset_index()\n        #print(\"2\",w.columns)\n        dfIn.drop(['PlayerWeightSumDefense','PlayerWeightSumOffense'],axis=1,inplace=True)\n        dfIn = pd.merge(dfIn,w,how='left',left_on='PlayId',right_on='PlayId')\n        dfIn['PlayerWeightSumDiff'] = dfIn['PlayerWeightSumDefenseSum'] - dfIn['PlayerWeightSumOffenseSum']\n\n    dfIn2 = dfIn\n    # Calculate Player Age \n    # ensure the Player birth day is date\n    # calculate Age \n    if isRequired(\"PlayerBirthDate\") : dfIn2['PlayerBirthDate'] =  lookup(dfIn2['PlayerBirthDate'])\n    if isRequired(\"PlayerAge\") : dfIn2['PlayerAge'] = dfIn2['PlayerBirthDate'].apply(lambda x: ageNow(x))\n    if isRequired(\"PlayerYearsInNFL\") : dfIn2['PlayerYearsInNFL'] = dfIn2['PlayerAge'] - 22 # from college as 22 year old\n \n\n    ## MORE STUFF \n    dfIn2['GameClock2'] = dfIn2['GameClock'].apply(lambda x: int(x[0:2])+int(x[3:5])/60)\n    dfIn2['AbsoluteGameClock'] = dfIn2[['GameClock','Quarter']].apply(lambda x: int(x['GameClock'][0:2])+float(x['GameClock'][3:5])/60+((4-x['Quarter'])*15),axis=1)\n    dfIn2['AbsoluteGameClockRemaining'] = 60 - dfIn2['AbsoluteGameClock'] \n    \n    \n    # get the ouptut ready to go \n    dfOut = dfIn2\n    return dfOut","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_using_my_model_RandomForest(dfIn,sample_prediction_df):\n    global clfs # all the CLFs\n    global dfME\n    global colsSet # array of columns, one for each CLF\n\n    test_dfIn = dfIn[dfIn['NflIdRusher'] == dfIn['NflId']].copy()\n    test_dfIn = addFeatures(test_dfIn)\n    df3 = pd.DataFrame()\n    c = 0 \n    #print(\"colsSet = \",colsSet)\n#     dfABS = pd.DataFrame([[0] * 199])\n#     dfABS.columns = [\"Yards\"+str(x) for x in range (-99,100)]\n    AbsoluteYardLine = test_dfIn['AbsoluteYardLine'].values[0]\n    minYards =  - AbsoluteYardLine \n    maxYards = 100 - AbsoluteYardLine \n    #dfABS.iloc[ 0 , minYards:maxYards] = 1\n    #print(minYards,maxYards,AbsoluteYardLine)\n    for cols in colsSet:\n        clf = clfs[c]\n        c = c + 1\n        y_df = pd.DataFrame(list(zip(clf.classes_,[x for x in clf.predict_proba(test_dfIn[cols])[0]])))\n        i = range(-99,100)\n        missingyards = set(i).difference(sorted(y))\n        #print( missingyards)\n        y_df = y_df.append(pd.DataFrame(list(zip(missingyards,[0]*len(missingyards)))))\n        y_df.columns = ['Yards','probablity']\n        y_df = y_df.sort_values('Yards')\n\n        df1 =  pd.DataFrame(y_df.set_index('Yards').reset_index()['probablity']).T\n        df1.columns = [\"Yards\"+str(x) for x in range (-99,100)]\n#         for i in range (-99,100): \n#            # print(type(i),type(minYards),type(maxYards))\n#             if i < minYards: df1[\"Yards\"+str(i)] = 0.0\n#             if i > maxYards: df1[\"Yards\"+str(i)] = 0.0\n        df2 = df1.cumsum(axis=1)\n        df3 = pd.concat([df3,df2])\n        \n   #print(df3.T) \n    df4 = pd.DataFrame(df3.sum()).T\n   # print(df4.T)\n    sample_prediction_df = df4.div(df4.max(axis=1), axis=0)\n   # print(sample_prediction_df.T)\n   # print(sample_prediction_df['Yards99'].values[0],sample_prediction_df['Yards99'].values[0] == 1.0)\n    assert sample_prediction_df['Yards99'].values[0] == 1.0, \"Values is not 1.0\"\n\n    return sample_prediction_df\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"isTraining = True \nos.system(f'echo Training')\nclf = 0 \n\n\n# colsSet = [\n#             #['Down','A','S','PlayerWeightSumDiff','JerseyNumber','AbsoluteYardLine','Quarter']\n# #             ['A','S']\n# #             ,['A','S','AbsoluteYardLine']\n# #             ,['A','S','JerseyNumber']\n# #             ,['Down','AbsoluteYardLine']\n#             ['Down','NflId','AbsoluteGameClockRemaining']\n#             ]\n\n\ncolsSet = [\n            #['Down','A','S','PlayerWeightSumDiff','JerseyNumber','AbsoluteYardLine','Quarter']\n#             ['A','S']\n#             ,['A','S','AbsoluteYardLine']\n#             ,['A','S','JerseyNumber']\n#             ,['Down','AbsoluteYardLine']\n#           ['Down','NflId','AbsoluteGameClockRemaining']\n            ['Down','JerseyNumber'] # attempt #2 \n           ]\n\n\ni = 0 \n\n\nflat_list = list(set([item for sublist in colsSet for item in sublist]))\n\n# RANDOM FOREST\n\n\n# Set random seed\nnp.random.seed(0)\n\nprint(\"Starting 1\")\ntrain = True\nif train == True:\n    #filename = '/Users/sa0987/Downloads/nfl-big-data-bowl-2020/train.csv'\n    filename = fname\n    dfIn = pd.read_csv(filename, low_memory=False)\n    train_df  = dfIn\n    test_df = dfIn\n\n    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n    for abb in train_df['PossessionTeam'].unique():\n        map_abbr[abb] = abb\n\n    train_df['PossessionTeam'] = train_df['PossessionTeam'].map(map_abbr)\n    train_df['HomeTeamAbbr'] = train_df['HomeTeamAbbr'].map(map_abbr)\n    train_df['VisitorTeamAbbr'] = train_df['VisitorTeamAbbr'].map(map_abbr)\n   # train_df['AbsoluteYardLine'] = train_df[['YardLine','PlayDirection','HomeTeamAbbr','PossessionTeam','FieldPosition']].apply(lambda x: int((100-x['YardLine'])) if x['PossessionTeam'] == x['FieldPosition'] else int(int(x['YardLine'])),axis=1)\n\n#train_df= pd.read_csv('train.csv')\ntrain_df = addFeatures(train_df)\nisTraining = False\nprint('Done adding to train_df')\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ni = 0 \nclfs = []\nfor cols in colsSet:\n    clf = RandomForestClassifier(n_jobs=1, random_state=0,n_estimators=10)\n\n    Y = ['Yards']\n    training_df = train_df[train_df['PlayerIsRusher'] == True][cols+Y].copy()\n    #training_df = train_df[['JerseyNumber','Down','Yards']][::22]\n\n    y=training_df['Yards']\n    X=training_df[[i for i in training_df.columns if \"Yards\" not in i]]\n\n\n    # Create a random forest Classifier. By convention, clf means 'Classifier'\n    clf = RandomForestClassifier(n_jobs=2, random_state=0,n_estimators=100)\n\n    print(\"Training\")\n    os.system(f'echo training')\n    clf.fit(X, y)\n    print(\"Trained\")\n    os.system(f'echo trained')\n    clfs.append(clf)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\n\n# # You can only call make_env() once, so don't lose it!\nenv = nflrush.make_env()\ni = 0 \n# # You can only iterate through a result from `env.iter_test()` once\n# # so be careful not to lose it once you start iterating.\n\nfor (test_df, sample_prediction_df) in env.iter_test():\n   # predictions_df = make_my_predictions(test_df, sample_prediction_df)\n    #print(test_df[['JerseyNumber','Down']][0:2])\n\n    #dfPredict = predict_using_my_model_Jersey_Down(test_df,sample_prediction_df)\n   # test_df['AbsoluteYardLine'] = test_df[['YardLine','PlayDirection','HomeTeamAbbr','PossessionTeam','FieldPosition']].apply(lambda x: int((100-x['YardLine'])/10) if x['PossessionTeam'] != x['FieldPosition'] else int(int(x['YardLine'])/10),axis=1)\n\n    dfPredict = predict_using_my_model_RandomForest(test_df,sample_prediction_df)\n    \n    #Together \n    #dfPredict = predict_using_my_model_FieldPostionDown(test_df,sample_prediction_df)\n    #dfPredict = predict_using_my_model_FieldPostionBox(test_df,sample_prediction_df)\n\n    os.system(f'echo {i} ')\n    i = i + 1 \n\n\n\n    \n\n    \n\n    \n    env.predict(dfPredict)\n\nenv.write_submission_file()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We've got a submission file!\nimport os\nprint([filename for filename in os.listdir('/kaggle/working') if '.csv' in filename])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}