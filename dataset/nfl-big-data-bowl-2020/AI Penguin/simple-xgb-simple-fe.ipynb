{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pickle\nimport gc\nimport math\nimport scipy.stats\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport xgboost as xgb\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom time import time\nfrom sklearn import preprocessing\nfrom scipy.sparse import csc_matrix\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom imblearn.over_sampling import RandomOverSampler\n\nfrom kaggle.competitions import nflrush\n\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)\npd.set_option('mode.chained_assignment', None)\n\ntrain = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\ntrain_df = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def extract_rusher(data): \n    rusher_df = pd.DataFrame()\n    for A in tqdm(range(0, len(data), 22)):\n        section_df = data[A:A+22]\n        rusher_row = section_df.loc[section_df['NflId'] == section_df['NflIdRusher']]\n        \n        # add distance column, select top 5 rows based on distance\n        section_df = select_distance(rusher_row, section_df) \n        \n        rusher_row['Horziontal_Velocity_Rusher'] = rusher_row['S'] * math.cos(rusher_row['Dir'])\n        #rusher_row['Force_Rusher'] = rusher_row['PlayerWeight']*rusher_row['A']*math.cos(rusher_row['Dir'])  #calculate the horizontal force F = ma\n        #rusher_row['Momentum_Rusher'] = rusher_row['PlayerWeight']*rusher_row['S']*math.cos(rusher_row['Dir'])  # momentum = mv\n        #rusher_row = add_force(rusher_row, section_df)\n        #rusher_row = add_momentum(rusher_row, section_df)\n        rusher_row = add_horizontal_velocity(rusher_row, section_df)\n        rusher_row = add_speed(rusher_row, section_df)\n        rusher_row = add_acceleration(rusher_row, section_df)\n        rusher_row = add_motion_direction(rusher_row, section_df)\n        rusher_row = add_distance_traveled(rusher_row, section_df)\n        rusher_row = add_distance(rusher_row, section_df)\n        rusher_df = pd.concat([rusher_df, rusher_row],sort=False)\n        del section_df, rusher_row\n    del data  \n    return rusher_df\n\ndef test_pipeline(rusher_row, test_df):  #sfm\n    \n\n    rusher_row['Horziontal_Velocity_Rusher'] = rusher_row['S'] * math.cos(rusher_row['Dir'])\n    #rusher_row['Force_Rusher'] = rusher_row['PlayerWeight']*rusher_row['A']*math.cos(rusher_row['Dir'])  #calculate the horizontal force F = ma\n    #rusher_row['Momentum_Rusher'] = rusher_row['PlayerWeight']*rusher_row['S']*math.cos(rusher_row['Dir'])  # momentum = mv\n    #rusher_row = add_force(rusher_row, test_df)\n    #rusher_row = add_momentum(rusher_row, test_df)\n    rusher_row = add_horizontal_velocity(rusher_row, test_df)\n    rusher_row = add_speed(rusher_row, test_df)\n    rusher_row = add_acceleration(rusher_row, test_df)\n    rusher_row = add_motion_direction(rusher_row, test_df)\n    rusher_row = add_distance_traveled(rusher_row, test_df)\n    rusher_row = add_distance(rusher_row, test_df)\n    #rusher_row = rusher_row.drop(columns = ['NflId','NflIdRusher','Humidity','Orientation','PlayerHeight_cm','PlayerAge'])\n    rusher_row = rusher_row.drop(columns = ['NflId','NflIdRusher'])\n    #rusher_row = sfm.transform(rusher_row)\n    \n    return rusher_row\n\n\n# Create a new column: US location will be 1, non-US location will be 0\ndef us_location(data):\n    us_location_list = list(set(list(data['Location'])))\n    non_us_location = ['London, England','London','Mexico City']\n    for A in non_us_location:\n        if A in us_location_list:\n            us_location_list.remove(A)\n    US_location_list = []\n    for A in list(data['Location']):\n        if A in us_location_list:\n            US_location_list.append(1)\n        else:\n            US_location_list.append(0)\n    data['US_location'] =  US_location_list\n    del US_location_list,us_location_list\n    return data\n\ndef generate_string(column, upper_limit):\n    string_no = range(0,upper_limit)\n    string_list = []\n    for A in string_no:\n        string_list.append(column+str(A))   \n    return string_list\n\ndef add_horizontal_velocity(rusher_row, section_df):\n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n\n    horizontal_velocity_non_rusher = []\n    for i in zip(non_rusher_df['S'],non_rusher_df['Dir']):\n        horizontal_velocity_non_rusher.append((i[0]*math.cos(i[1])))\n    \n    string_list = generate_string('Horizontal_Velocity_',len(horizontal_velocity_non_rusher))\n    \n    rusher_row_joined = np.concatenate((rusher_row.values, [horizontal_velocity_non_rusher]),axis = 1)\n    rusher_row_joined_df = pd.DataFrame(data=rusher_row_joined, columns = list(rusher_row.columns) + string_list) \n    del non_rusher_df, horizontal_velocity_non_rusher, string_list\n    return rusher_row_joined_df\n\ndef add_speed(rusher_row, section_df):\n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n    speed_non_rusher = list(non_rusher_df['S'])\n    string_list = generate_string('Speed_',len(speed_non_rusher))\n    rusher_row_joined = np.concatenate((rusher_row.values, [speed_non_rusher]),axis = 1)\n    rusher_row_joined_df = pd.DataFrame(data=rusher_row_joined, columns = list(rusher_row.columns) + string_list) \n    del non_rusher_df, speed_non_rusher, string_list\n    \n    return rusher_row_joined_df\n\ndef add_acceleration(rusher_row, section_df):\n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n    acceleration_non_rusher =  list(non_rusher_df['A'])\n    string_list = generate_string('Acceleration_',len(acceleration_non_rusher))\n    rusher_row_joined = np.concatenate((rusher_row.values, [acceleration_non_rusher]),axis = 1)\n    rusher_row_joined_df = pd.DataFrame(data=rusher_row_joined, columns = list(rusher_row.columns) + string_list) \n    \n    del non_rusher_df, acceleration_non_rusher, string_list\n    return rusher_row_joined_df\n\n\ndef add_force(rusher_row, section_df):\n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n    force_non_rusher = []\n    \n    for i in zip(non_rusher_df['PlayerWeight'],non_rusher_df['A'],non_rusher_df['Dir']):\n        force_non_rusher.append((i[0]*i[1]*math.cos(i[2])))\n    string_list = generate_string('Force_',len(force_non_rusher))\n    \n    for j in range(len(string_list)):\n        rusher_row[string_list[j]] =  force_non_rusher[j] \n    del non_rusher_df, force_non_rusher, string_list\n    return rusher_row\n\ndef add_momentum(rusher_row, section_df):\n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n    momentum_non_rusher = []\n    \n    for i in zip(non_rusher_df['PlayerWeight'],non_rusher_df['S'],non_rusher_df['Dir']):\n        momentum_non_rusher.append((i[0]*i[1]*math.cos(i[2])))\n    string_list = generate_string('Momentum_',len(momentum_non_rusher))\n    \n    for j in range(len(string_list)):\n        rusher_row[string_list[j]] =  momentum_non_rusher[j] \n    del non_rusher_df, momentum_non_rusher, string_list\n    return rusher_row\n\ndef add_motion_direction(rusher_row, section_df):\n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n    direction_non_rusher = list(non_rusher_df['Dir'])\n    string_list = generate_string('Direction_',len(direction_non_rusher))\n    rusher_row_joined = np.concatenate((rusher_row.values, [direction_non_rusher]),axis = 1)\n    rusher_row_joined_df = pd.DataFrame(data=rusher_row_joined, columns = list(rusher_row.columns) + string_list)\n    \n    del non_rusher_df, direction_non_rusher, string_list\n    return rusher_row_joined_df\n\n\ndef add_distance_traveled(rusher_row, section_df):\n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n    dis_non_rusher = list(non_rusher_df['Dis'])\n    string_list = generate_string('Dis_',len(dis_non_rusher))\n    rusher_row_joined = np.concatenate((rusher_row.values, [dis_non_rusher]),axis = 1)\n    rusher_row_joined_df = pd.DataFrame(data=rusher_row_joined, columns = list(rusher_row.columns) + string_list)\n    \n    del non_rusher_df, dis_non_rusher, string_list\n    return rusher_row_joined_df\n\n\ndef OffensePersonnel(data):  \n    data['RB'] = data['OffensePersonnel'].apply(lambda x: int(x[0]))\n    data['TE'] = data['OffensePersonnel'].apply(lambda x: int(x[6]))\n    data['WR'] = data['OffensePersonnel'].apply(lambda x: int(x[12]))\n    \n    return data\n\n\ndef select_distance(rusher_row, section_df):\n    \n    X_rusher = rusher_row['X'].values[0]\n    Y_rusher = rusher_row['Y'].values[0]\n    distance_to_non_rusher = []\n    for A in zip(section_df['X'], section_df['Y']):\n        current_distance = ((A[0]-X_rusher)**2 + (A[1]-Y_rusher)**2)**0.5\n        distance_to_non_rusher.append(current_distance)\n    \n    section_df['straightline_dist'] = distance_to_non_rusher\n    section_df = section_df.sort_values('straightline_dist', ascending= True)\n    #section_df = section_df.iloc[:6] # select the closest 6 rows \n    return section_df\n     \n\ndef add_distance(rusher_row, section_df):\n    \n    non_rusher_df = section_df.loc[section_df['NflId'] != section_df['NflIdRusher']]\n    distance_to_non_rusher = list(non_rusher_df['straightline_dist'])\n    string_list = generate_string('straightline_dist_',len(distance_to_non_rusher))\n\n    rusher_row_joined = np.concatenate((rusher_row.values, [distance_to_non_rusher]),axis = 1)\n    rusher_row_joined_df = pd.DataFrame(data=rusher_row_joined, columns = list(rusher_row.columns) + string_list)\n        \n    del non_rusher_df, distance_to_non_rusher, string_list\n    return rusher_row_joined_df\n\n\n\ndef time_processing(data):\n    \n    data[\"timestamp\"] = pd.to_datetime(data[\"TimeHandoff\"]) \n    #data[\"month\"] = data[\"timestamp\"].dt.month\n    #data[\"dayOfMonth\"] = data[\"timestamp\"].dt.day\n    #data[\"hour\"] = data[\"timestamp\"].dt.hour\n    #data[\"minute\"] = data[\"timestamp\"].dt.minute\n    data = data.drop(columns = ['timestamp'])\n    \n    return data\n\ndef height_processing(data):\n    height_list = []\n    for A in data['PlayerHeight']:\n        if len(A) == 3:\n            height = round((int(A[0])*30.48+int(A[2])*2.54),3)\n        else:\n            height = round((int(A[0])*30.48+int(A[-2:])*2.54),3)\n        height_list.append(height)  \n    data['PlayerHeight_cm'] = height_list \n    return data\n\n\ndrop_columns_train = [\n                'GameId', 'PlayId','DisplayName', 'JerseyNumber',\n                'GameClock', 'FieldPosition', \n                'OffensePersonnel','DefensePersonnel','TimeHandoff','TimeSnap',\n                'PlayerHeight','PlayerBirthDate','PlayerCollegeName',\n                 'Stadium','Location','Turf','OffenseFormation',\n                'GameWeather','StadiumType','WindDirection', 'WindSpeed', #'NflId','NflIdRusher',\n               \n                'Season','Week'#'Position','HomeTeamAbbr','VisitorTeamAbbr','Humidity','PossessionTeam',\n                #'Yards'   # TARGET\n          \n                ]\n\ndrop_columns_test = [\n                'GameId','PlayId','DisplayName','JerseyNumber',\n                'GameClock', 'FieldPosition',\n                'OffensePersonnel','DefensePersonnel','TimeHandoff','TimeSnap',\n                'PlayerHeight','PlayerBirthDate','PlayerCollegeName',\n                'Stadium','Location','Turf','OffenseFormation',\n                'GameWeather','StadiumType','WindDirection','WindSpeed',#'NflId','NflIdRusher',\n               \n                'Season','Week'#'Position','HomeTeamAbbr','VisitorTeamAbbr','Humidity','PossessionTeam',\n\n                ]\n\nfrom sklearn import preprocessing\nlbl = preprocessing.LabelEncoder()\n\ndef preprocessing(data, drop_columns):\n    \n    data = data.fillna(-999)\n    data = us_location(data)\n    data = OffensePersonnel(data)\n    data = time_processing(data)\n    data = height_processing(data)\n    \n    GameClock_list = [int(A[:2])*60 + int(A[3:5]) for A in data['GameClock']]\n    data['GameTimeRemain'] = GameClock_list\n    \n    age_list = [2020-int(str(A)[-4:]) for A in data['PlayerBirthDate']]\n    data['PlayerAge'] = age_list\n    \n    # convert to KG\n    data['PlayerWeight'] = data['PlayerWeight']*0.453592\n    \n    '''\n   \n    onehot_columns = ['HomeTeamAbbr','VisitorTeamAbbr']\n    data = pd.get_dummies(data, prefix_sep=\"__\",columns=onehot_columns)\n    '''\n    \n    data = data.drop(columns= drop_columns)\n    \n    for f in data.columns:\n        if data[f].dtype=='object':\n            lbl.fit(data[f].values)\n            data[f] = lbl.transform(data[f].values)\n\n    return data\n\n\ndef convert_data_type(data):\n    \n    convert_columns = ['Yards','Team','Quarter','Position',\n                      'DefendersInTheBox','PlayerAge','PlayDirection']\n    \n    for A in convert_columns:\n        data[A] = data[A].astype('int64')\n    \n    return data\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_processed = preprocessing(train_df,drop_columns_train)\nrusher_df =  extract_rusher(train_df_processed)\nrusher_df = convert_data_type(rusher_df)\ntarget = rusher_df.Yards.values\n#rusher_df = rusher_df.drop(columns = ['NflId','NflIdRusher','Yards','Humidity','Orientation','PlayerHeight_cm','PlayerAge'])\nrusher_df = rusher_df.drop(columns = ['NflId','NflIdRusher','Yards']) #,'Yards'\ntarget_list = sorted(list(set(target)))\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nimport matplotlib.pyplot as plt\n\ncorr = rusher_df.corr()\ncorr.style.background_gradient(cmap='coolwarm')\ncorr.style.background_gradient(cmap='coolwarm').set_precision(4)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rusher_df = rusher_df.drop(columns = ['Yards']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rusher_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n\ndef split_train(rusher_df, target, train_fraction):\n    \n    X_train = rusher_df.iloc[:int(len(rusher_df)//(1/train_fraction))]\n    X_valid = rusher_df.iloc[int(len(rusher_df)//(1/train_fraction)):]\n    y_train = target[:int(len(rusher_df)//(1/train_fraction))]\n    y_valid = target[int(len(rusher_df)//(1/train_fraction)):]\n    \n    return X_train, X_valid, y_train, y_valid\n\n\nX_train, X_valid, y_train, y_valid = split_train(rusher_df, target, train_fraction = 0.9)\n\n\nclf = xgb.XGBClassifier(\n                            \n                        n_estimators=50,\n                        min_child_weight = 2,\n                        max_depth=6,\n                        verbosity = 1,\n                        n_jobs=-1,                                              \n                        scale_pos_weight=1.025,\n                        tree_method='exact',\n                        objective = 'multi:softmax',\n                        num_class = len(target_list),\n                        predictor='cpu_predictor',\n                        colsample_bytree = 0.66,\n                        subsample = 1,\n                        gamma = 0,\n                        learning_rate=0.15,\n                        num_parallel_tree = 1    \n    \n                       )\n\nclf.fit(X_train, y_train, eval_metric=\"merror\",early_stopping_rounds=20,\n        eval_set=[(X_train, y_train),(X_valid, y_valid)], verbose=True)\n        \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# No validation Set\nclf = xgb.XGBClassifier(\n                            \n                        n_estimators=50,\n                        min_child_weight = 2,\n                        max_depth=6,\n                        verbosity = 1,\n                        n_jobs=-1,                                              \n                        scale_pos_weight=1.025,\n                        tree_method='exact',\n                        objective = 'multi:softmax',\n                        num_class = len(target_list),\n                        predictor='cpu_predictor',\n                        colsample_bytree = 0.66,\n                        subsample = 1,\n                        gamma = 0,\n                        learning_rate=0.15,\n                        num_parallel_tree = 1    \n                       )\n\nclf.fit(rusher_df, target, eval_metric=\"merror\",early_stopping_rounds=20,\n        eval_set=[(rusher_df, target)], verbose=True)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n\nfeature_importance_list = clf.feature_importances_\n\nfeature_dict = dict()\nfor A in range(len(list(rusher_df.columns))):\n    feature_dict[list(rusher_df.columns)[A]] = feature_importance_list[A]\n    \nimport operator\nsorted_feature_dict = sorted(feature_dict.items(), key=operator.itemgetter(1))\n\nsorted_feature_dict\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n\nfrom sklearn.feature_selection import SelectFromModel\nnp.random.seed(1)\nsfm = SelectFromModel(clf, threshold = 0.005)\nsfm.fit(rusher_df, target)\n\n\nrusher_df_reduced = sfm.transform(rusher_df)\nrusher_df_reduced.shape\n\nclf.fit(rusher_df, target, eval_metric=\"merror\",early_stopping_rounds=20,\n        eval_set=[(rusher_df_reduced, target)], verbose=True)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ros = RandomOverSampler(random_state=999)\nX_ros, y_ros = ros.fit_sample(rusher_df, target)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_ros, y_ros, shuffle = True,\n                                test_size = 0.2,random_state = 999)\n\n\nclf = xgb.XGBClassifier(\n                            \n                        n_estimators=500,\n                        min_child_weight = 2,\n                        max_depth=6,\n                        verbosity = 1,\n                        n_jobs=-1,                                              \n                        scale_pos_weight=1.025,\n                        tree_method='hist',\n                        objective = 'multi:softmax',\n                        num_class = len(target_list),\n                        predictor='cpu_predictor',\n                        colsample_bytree = 0.66,\n                        subsample = 1,\n                        gamma = 0,\n                        learning_rate=0.15,\n                        num_parallel_tree = 1    \n    \n                       )\n\nclf.fit(X_train, y_train, eval_metric=\"merror\",early_stopping_rounds=30,\n        eval_set=[(X_train, y_train),(X_valid, y_valid)], verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()\niter_test = env.iter_test()\nbatch_no = 0\n\nfor (test_df, sample_prediction_df) in iter_test:\n    print(f'Predicting Play Number {batch_no}')\n    rusher_row = test_df.loc[test_df['NflId'] == test_df['NflIdRusher']]\n    rusher_row = preprocessing(rusher_row, drop_columns_test)\n    test_df = select_distance(rusher_row, test_df)\n    rusher_row = test_pipeline(rusher_row, test_df)    #sfm\n    #preds_proba_mean = sum([model.predict_proba(rusher_row) for model in models])/len(models)\n    preds_proba = clf.predict_proba(rusher_row.values)\n    \n    pred_df = np.zeros((1, 199))   \n    for A in range(len(target_list)):      \n        pred_df[0][target_list[A]+99] = preds_proba[0][A]        # preds_proba_mean\n    for A in range(1,len(pred_df[0]),1):\n        pred_df[0][A] = pred_df[0][A]+pred_df[0][A-1]   \n    pred_df =  np.clip(pred_df, a_min= 0, a_max=1)\n    pred_df[0][-1] = 1.0\n    \n    final_pred_df = pd.DataFrame(data=pred_df, columns=sample_prediction_df.columns)\n    env.predict(final_pred_df)\n    batch_no += 1\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nenv = nflrush.make_env()\niter_test = env.iter_test()\n(test_df, sample_prediction_df) = next(iter_test)\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}