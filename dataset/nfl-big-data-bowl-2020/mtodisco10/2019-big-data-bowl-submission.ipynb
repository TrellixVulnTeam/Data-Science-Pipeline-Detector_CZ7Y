{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport math\nimport statistics as stats\n\nimport sklearn.metrics as mtr\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import trange, tqdm\n\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.callbacks import Callback\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport datetime\n\nimport itertools\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nfrom scipy.spatial import ConvexHull\n\nfrom scipy.spatial.distance import euclidean\nfrom scipy.special import expit\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 150)\n\nfrom kaggle.competitions import nflrush\nenv = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n#train = train.loc[train.Season != 2017]\n    \noutcomes = train[['GameId','PlayId','Yards']].drop_duplicates()\n\ntrain_2 = train.copy()\ntrain_3 = train.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utility Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x/15))\n    except:\n        return \"nan\"\n    \ndef euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n        return np.sqrt(x_diff + y_diff)\n\ndef standardize_speed(df):\n    #standardize speed by year\n    speed_std = np.where(df.Season == '2017', ((df['S'] - 2.4355) / 1.2930),\n                           np.where(df.Season == '2018', ((df['S'] - 2.7570) / 1.4551), \n                                   ((df['S'] - 2.7456) / 1.4501)))\n    return(speed_std)\n\n#train['S_std'] = standardize_speed(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adjusting & Standardizing"},{"metadata":{"trusted":true},"cell_type":"code","source":"player_schema = {2557850:'De\\'Angelo Henderson',2560913:'Tracy Walker',2550565:'Da\\'Ron Payne',\n                 2556512:'Donte Deayon',2560813:'DJ Moore',2561283:'Zeke Turner',2561544:'Trenton Scott',\n                 2506925:'Domata Peko',2539340:'Ricky Wagner',2560828:'Chuks Okorafor'}\n\nteam_schema = {'ARZ':'ARI','BLT':'BAL','CLV':'CLE','HST':'HOU'}\n\ndef lookup_player_name(player_id, player_name):\n    if player_id in player_schema:\n        return(player_schema[player_id])\n    else:\n        return(player_name)\n\nprint('Adjusting player names and team abbreviations...')    \ndef adjust_players_and_teams(df, player_schema, team_schema):\n    #adjust player names\n    df['DisplayName'] = df.apply(lambda x: lookup_player_name(x['NflId'], x['DisplayName']), axis = 1)\n    \n    #adjust team abbreviations\n    df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].apply(lambda x: team_schema[x] if x in team_schema.keys() else x)\n    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].apply(lambda x: team_schema[x] if x in team_schema.keys() else x)\n    df['PossessionTeam'] = df['PossessionTeam'].apply(lambda x: team_schema[x] if x in team_schema.keys() else x)\n    \n    return(df)\n\nadjusted_df = adjust_players_and_teams(train_2, player_schema, team_schema)\n\nprint('Standardizing player coordinates...')\ndef standardize_coordinates(df):\n    #Is the offense moving from left to right?\n    df['ToLeft'] = df['PlayDirection'] == 'left'\n    \n    #Flagging the ball carrier\n    df['IsBallCarrier'] = df['NflId'] == df['NflIdRusher']\n    \n    #Assigning the possession team as home or away\n    df['TeamOnOffense'] = np.where(df['PossessionTeam'] == df['HomeTeamAbbr'], 'home', 'away')\n    \n    #Which team is on offense?\n    df['IsOnOffense'] = df['Team'] == df['TeamOnOffense']\n    \n    #How far away from the offensive teams own goal line?\n    df['YardsFromOwnGoal'] = np.where(df['PossessionTeam'] == df['FieldPosition'], \n                                            df['YardLine'], 50 + (50 - df['YardLine']))\n    \n    \n    df['YardsFromOwnGoal'] = np.where(df['YardLine'] == 50, 50, df['YardsFromOwnGoal'])\n    \n    #Standardizing X & Y Coordinates for each player\n    df['X_std'] = np.where(df['ToLeft'], 120 - df['X'], df['X']) - 10\n    df['Y_std'] = np.where(df['ToLeft'], 160/3 - df['Y'], df['Y'])\n    \n    return(df)\n\nstandardized_coord_df = standardize_coordinates(adjusted_df)\n\nprint('Standardizing player direction...')\ndef standardize_direction(df):\n    # - 0 degrees = straight left\n    # - 90 degrees = straight up the middle\n    # - 180 degrees = straight right\n    # - 270 degrees = straight backwards\n    df['Dir_std_1'] = np.where((df['ToLeft']) & (df['Dir'] < 90), df['Dir'] + 360, df['Dir'])\n    df['Dir_std_1'] = np.where((df['ToLeft']==False) & (df['Dir'] > 270), df['Dir'] - 360, df['Dir_std_1'])\n    \n    df['Dir_std_2'] = np.where(df['ToLeft'], df['Dir_std_1'] - 180, df['Dir_std_1'])\n    \n    df['X_std_end'] = (df['S']*np.cos((90 - df['Dir_std_2'])*math.pi/180) + df['X_std']).fillna(25)\n    df['Y_std_end'] = (df['S']*np.cos((90 - df['Dir_std_2'])*math.pi/180) + df['Y_std']).fillna(25)\n    \n    df[['Dir_std_1','Dir_std_2']] = df[['Dir_std_1','Dir_std_2']].fillna(90)\n    \n    return(df)\n\nstandardized_dir_df = standardize_direction(standardized_coord_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking to make sure the standardized Dir is correct\nstandardized_dir_df.loc[(standardized_dir_df.IsBallCarrier)].Dir_std_2.hist(bins = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_o_line_stats(df):\n    ol_df = df.loc[(df.Position.isin(['C','G','T','OG','OT','TE'])) & (df.IsOnOffense), \n           ['PlayId','A','Dir_std_1','Dir_std_2','ToLeft', 'Orientation']]\n    \n    ol_df['Dir_std'] = np.where(ol_df.ToLeft, ol_df['Dir_std_2'], ol_df['Dir_std_1'])\n    \n    ol_df['OlMidDir'] = abs(ol_df['Dir_std'] - 90)\n    \n    ol_df['Dir_cat'] = np.where((ol_df.Dir_std < 150) & (ol_df.Dir_std > 30), 10, \n                                np.where(ol_df.Dir_std > 150, 1,\n                                        np.where((ol_df.Dir_std > 0) & (ol_df.Dir_std < 30), 1, -1 )))\n    \n    ol_df['OlMovingDf'] = np.where((ol_df.Dir_std < 150) & (ol_df.Dir_std > 30), 1, 0)\n    ol_df['OlATimesDir'] = ol_df['A'] * ol_df['Dir_cat']\n    \n    ol_df_grouped = ol_df.groupby('PlayId', as_index=False)[['A','OlATimesDir','OlMovingDf', 'OlMidDir', 'Orientation']].mean()\n    ol_df_grouped.rename(columns={'A':'OlAMean', 'Orientation': 'OlOrientationMean'}, inplace=True)\n    \n    return(ol_df_grouped)\n\nol_agg_df = get_o_line_stats(standardized_dir_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_features(df, deploy=False):\n    def new_X(x_coordinate, play_direction):\n        if play_direction == 'left':\n            return(120.0 - x_coordinate)\n        else:\n            return(x_coordinate)\n\n    def new_line(rush_team, field_position, yardline):\n        if rush_team == field_position:\n            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n            return(10.0 + yardline)\n        else:\n            # half the field plus the yards between midfield and the line of scrimmage\n            return(60.0 + (50 - yardline))\n\n    def new_orientation(angle, play_direction):\n        if play_direction == 'left':\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return(new_angle)\n        else:\n            return(angle)\n\n    def back_direction(orientation):\n        if orientation > 180.0:\n            return(1)\n        else:\n            return(0)\n        \n    def update_yardline(df):\n        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n        return(new_yardline)\n\n    def update_orientation(df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n        return(df)\n\n    def back_features(df):\n        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n\n        return(carriers)\n\n    def features_relative_to_back(df, carriers):\n        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n                                   'min_dist','max_dist','mean_dist','std_dist']\n\n        return(player_distance)\n\n    def defense_features(df):\n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n\n        return(defense)\n\n    def static_features(df):\n        add_new_feas = []\n        ## Height\n        df['PlayerHeight_dense'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n        \n        add_new_feas.append('PlayerHeight_dense')\n\n        ## Time\n        df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n        df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n        df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n        df['PlayerBirthDate'] =df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n        ## Age\n        seconds_in_year = 60*60*24*365.25\n        df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n        add_new_feas.append('PlayerAge')\n\n        ## WindSpeed\n        df['WindSpeed_ob'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n        df['WindSpeed_dense'] = df['WindSpeed_ob'].apply(strtofloat)\n        add_new_feas.append('WindSpeed_dense')\n\n        ## Weather\n        df['GameWeather_process'] = df['GameWeather'].str.lower()\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n        df['GameWeather_dense'] = df['GameWeather_process'].apply(map_weather)\n        add_new_feas.append('GameWeather_dense')\n\n        ## Orientation and Dir\n        df[\"Orientation_ob\"] = df[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n        df[\"Dir_ob\"] = df[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n        df[\"Orientation_sin\"] = df[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Orientation_cos\"] = df[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        df[\"Dir_sin\"] = df[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Dir_cos\"] = df[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        add_new_feas.append(\"Dir_sin\")\n        add_new_feas.append(\"Dir_cos\")\n\n        ## diff Score\n        df[\"diffScoreBeforePlay\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n        add_new_feas.append(\"diffScoreBeforePlay\")\n    \n    \n        static_features = df[df['NflId'] == df['NflIdRusher']][add_new_feas+['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox','TimeDelta',]].drop_duplicates()\n\n        static_features.fillna(-999,inplace=True)\n            \n        return(static_features)\n\n    def combine_features(relative_to_back, defense, static, deploy=deploy):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n\n        if not deploy:\n            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n        return(df)\n    \n    yardline = update_yardline(df)\n    df = update_orientation(df, yardline)\n    back_feats = back_features(df)\n    rel_back = features_relative_to_back(df, back_feats)\n    def_feats = defense_features(df)\n    static_feats = static_features(df)\n    basetable = combine_features(rel_back, def_feats, static_feats, deploy=deploy)\n    \n    basetable['MaxYards'] = 110 - basetable['YardLine']\n    \n    return(basetable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time train_basetable = create_features(train, False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# More FE"},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_dict= {'DefensePersonnel': ['DL','LB','DB'],\n         'OffensePersonnel': ['RB','TE','WR','QB','OL']}\n\ndef get_personnel(row, position):\n    filtered_row = [pos_group for pos_group in row if position in pos_group]\n    if len(filtered_row) > 0:\n        return(int(filtered_row[0][0]))\n    else:\n        return(0)\n    \ndef ball_carrier_features(df):\n    bc_df = df.loc[df['IsBallCarrier'], ['PlayId','ToLeft','X_std','Y_std','X_std_end','Y_std_end','Dir_std_1','Dir_std_2','Position', 'A']]\n    bc_df.rename(columns={'X_std': 'X_std_bc','Y_std':'Y_std_bc',\n                          'X_std_end':'X_std_end_bc','Y_std_end':'Y_std_end_bc',\n                          'Dir_std_1':'Dir_std_1_bc','Dir_std_2':'Dir_std_2_bc',\n                          'Position':'BcPosition',\n                         }, inplace=True)\n    bc_df['BcRunRight'] = np.where(((bc_df.ToLeft) & (bc_df.Dir_std_2_bc > 90)) | \n                                   ((bc_df.ToLeft == False) & (bc_df.Dir_std_1_bc > 90)),True, False)\n    bc_df['BcDir'] = np.where(bc_df.ToLeft, bc_df.Dir_std_2_bc, bc_df.Dir_std_1_bc)\n    \n    bc_df['BcFast'] = np.where((bc_df.BcPosition == 'WR') | (bc_df.BcPosition == 'CB'), 1, 0)\n    bc_df['BcSlow'] = np.where((bc_df.BcPosition == 'QB') | (bc_df.BcPosition == 'FB') | \n                               (bc_df.BcPosition == 'DE') | (bc_df.BcPosition == 'DT'), 1, 0)\n    \n    bc_df['BcDirCat'] = np.where((bc_df.BcDir < 150) & (bc_df.BcDir > 30), 10, \n                                np.where(bc_df.BcDir > 150, 1,\n                                        np.where((bc_df.BcDir > 0) & (bc_df.BcDir < 30), 1, -1 )))\n    \n    bc_df['BcMovingDf'] = np.where((bc_df.BcDir < 150) & (bc_df.BcDir > 30), 1, 0)\n    bc_df['BcATimesDir'] = bc_df['A'] * bc_df['BcDirCat']\n    \n    bc_df.drop('A', axis= 1, inplace=True)\n    \n    return(bc_df)\n\ndef calculate_defender_loc(df, ball_carrier_df):\n    def_df = df.loc[df['IsOnOffense']==False]\n    \n    dir_df = def_df[['PlayId','DisplayName','JerseyNumber','X_std','Y_std']].merge(ball_carrier_df, on='PlayId')\n    \n    \n    dir_df['DefenderTowardsPlayDir'] = np.where(((dir_df['BcRunRight']) & (dir_df['Y_std'] <= dir_df['Y_std_bc'])) |\n                                            ((dir_df['BcRunRight'] == False) & (dir_df['Y_std'] >= dir_df['Y_std_bc'])),\n                                            1, 0)\n    \n    dir_agg_df = dir_df.groupby(['PlayId','X_std_bc','Y_std_bc','X_std_end_bc',\n                                 'Y_std_end_bc','BcRunRight','BcDir','BcFast','BcSlow',\n                                 'BcMovingDf','BcATimesDir',\n                                ], as_index=False)['DefenderTowardsPlayDir'].sum()\n    \n    spread_x_df = dir_df.groupby('PlayId', as_index = False)['X_std'].agg({'DefenseMaxX': np.max,\n                                                                           'DefenseMinX': np.min})\n    \n    spread_y_df = dir_df.groupby('PlayId', as_index = False)['Y_std'].agg({'DefenseMaxY': np.max,\n                                                                           'DefenseMinY': np.min})\n    \n    spread_x_df['DefenseXSpread'] = spread_x_df.DefenseMaxX - spread_x_df.DefenseMinX\n    \n    spread_y_df['DefenseYSpread'] = spread_y_df.DefenseMaxY - spread_y_df.DefenseMinY\n    \n    dir_agg_df = dir_agg_df.merge(spread_x_df[['PlayId','DefenseXSpread']], on = 'PlayId').merge(spread_y_df[['PlayId','DefenseYSpread']], on ='PlayId')\n    \n    return(dir_agg_df)\n\nprint('Creating some more features...')\ndef more_feature_engineering(df, positions_schema):\n    df['GameClockAdj'] = df['GameClock'].apply(strtoseconds)\n    \n    for k, v in pos_dict.items():\n        df[k + 'Split'] = df[k].str.split(', ')\n        for pos in v:\n            df[pos + 'Count'] = df[k + 'Split'].apply(lambda row: get_personnel(row, pos))\n    \n    df = df.drop(list(pos_dict.keys()) + [x + 'Split' for x in pos_dict.keys()], axis = 1)\n    \n    df['Home'] = np.where(df['TeamOnOffense'] == 'home', 1, 0)\n    \n    df['Shotgun'] = np.where(df['OffenseFormation'] == 'SHOTGUN', 1, 0)\n    \n    #Which team name is on defense?\n    df['TeamAbbrOnDefense'] = np.where(df['TeamOnOffense'] == 'home', df['VisitorTeamAbbr'], df['HomeTeamAbbr'])\n    \n    #Weather\n    df['GameWeatherPro'] = df['GameWeather'].str.lower().apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    df['GameWeatherPro'] = df['GameWeatherPro'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    df['GameWeatherPro'] = df['GameWeatherPro'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    df['GameWeatherPro'] = df['GameWeatherPro'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    df['GameWeatherPro'] = df['GameWeatherPro'].apply(map_weather)\n    \n    #Diff Score\n    df[\"DiffScoreBeforePlay\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n    df[\"DiffScoreBeforePlayBinary\"] = (df[\"HomeScoreBeforePlay\"] > df[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n    \n    df = df.drop(['GameWeather','Season','TimeHandoff','TimeSnap','PlayerBirthDate','Orientation','Dir','WindSpeed','GameClock'], axis =1)\n    \n    #Ball Carrier Features\n    bc_df = ball_carrier_features(df)\n    \n    #Defender Locations\n    merged_bc_def_df = calculate_defender_loc(df, bc_df)\n    \n    #Merge DataFrames\n    final_fe_df = df.merge(merged_bc_def_df, on ='PlayId')\n    \n    #Calculate Distance between each Defender & the Ball Carrier\n    final_fe_df['DistFromBc'] = np.sqrt((final_fe_df.X_std-final_fe_df.X_std_bc)**2 \n                                           + (final_fe_df.Y_std-final_fe_df.Y_std_bc)**2)\n    \n    final_fe_df['S'] = np.where(final_fe_df['S'] == 0, .1, final_fe_df['S'])\n    \n    final_fe_df['TimeToBc'] = final_fe_df['DistFromBc'] / final_fe_df['S']\n    \n    #Calculate Distance between each Defender & the Ball Carrier\n    final_fe_df['DistFromBcEnd'] = np.sqrt((final_fe_df.X_std_end-final_fe_df.X_std_end_bc)**2 \n                                           + (final_fe_df.Y_std_end-final_fe_df.Y_std_end_bc)**2)\n    \n    final_fe_df['TimeToBcEnd'] = final_fe_df['DistFromBcEnd'] / final_fe_df['S']\n    \n    #Ball Carrier Direction minus Direction of Defender\n    final_fe_df['Dir_std'] = np.where(final_fe_df.ToLeft, final_fe_df.Dir_std_2, final_fe_df.Dir_std_1)\n    #final_fe_df['BcDirDefDir'] = final_fe_df.BcDir - final_fe_df.Dir_std\n    \n    final_fe_df['DefendersInTheBox'] = final_fe_df['DefendersInTheBox'].fillna(int(final_fe_df.DefendersInTheBox.median()))\n    final_fe_df['DefendersInTheBox_vs_Distance'] = final_fe_df['DefendersInTheBox'] / final_fe_df['Distance']\n    \n    final_fe_df['InsideRun'] = np.where((final_fe_df['BcDir'] > 65) & (final_fe_df['BcDir'] < 115), 1, 0)\n    final_fe_df['OffTackle'] = np.where(((final_fe_df['BcDir'] <= 65) & (final_fe_df['BcDir'] > 30)) | \\\n                                         ((final_fe_df['BcDir'] >= 115) & (final_fe_df['BcDir'] < 150)), 1, 0)\n    \n    return(final_fe_df)\n\nfe_df = more_feature_engineering(standardized_dir_df, pos_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select the play specific features to use\nfe_feature_lst = ['GameId','PlayId','GameClockAdj','Shotgun','DefenseXSpread','DefenseYSpread',\n                  'X_std_bc','Y_std_bc','BcDir','InsideRun','OffTackle','TeamOnOffense','YardsFromOwnGoal',\n                  'BcFast','BcSlow','BcMovingDf','BcATimesDir',#'DBCount','DefendersInTheBox_vs_Distance',\n                 ]\n\nfe_feature_df = fe_df[fe_feature_lst].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Voronoi"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bc_voronoi_area(df, point_type='current'):\n    df = df.sort_values(['IsOnOffense','PlayId','IsBallCarrier','Y_std'])\n    bc_v_area_lst = []\n    \n    if point_type == 'current':\n        X_col, Y_col = 'X_std', 'Y_std'\n    elif point_type == 'end':\n        X_col, Y_col = 'X_std_end', 'Y_std_end'\n    else:\n        print('Invalid point type')\n    \n    for play_id in df.PlayId.unique():\n        try:\n            v_fe_df = df.loc[df.PlayId == play_id]\n            v_fe_df = v_fe_df.loc[(v_fe_df.IsOnOffense == False) | (v_fe_df.IsBallCarrier)]\n\n            points = np.c_[v_fe_df[X_col], v_fe_df[Y_col]]\n\n            vor = Voronoi(points)\n\n            vertices = vor.vertices\n            regions = vor.regions\n            point_regions = vor.point_region\n\n            v_perm = [vertices[r] for r in regions[point_regions[-1]]]\n\n            rusher_x = v_fe_df.loc[v_fe_df.IsBallCarrier, X_col].values[0]\n            rusher_y = v_fe_df.loc[v_fe_df.IsBallCarrier, Y_col].values[0]\n\n            vor_df = pd.DataFrame(np.vstack(v_perm), columns = [X_col, Y_col])\n            vor_df[X_col] = np.where(vor_df[X_col] < rusher_x, rusher_x,\n                                  np.where(vor_df[X_col] > rusher_x + 20, rusher_x + 20, vor_df[X_col]))\n\n            vor_df[Y_col] = np.where(vor_df[Y_col] < (rusher_y / 2), rusher_y / 2,\n                                  np.where(vor_df[Y_col] > rusher_y * 2, rusher_y * 2, vor_df[Y_col]))\n            \n            vor_area = ConvexHull(vor_df, qhull_options = 'QJ').area\n            \n            if vor_area > 1000:\n                print(play_id)\n            bc_v_area_lst.append(vor_area)\n\n        except:\n            print('Voronoi Error for play {}'.format(play_id))\n            bc_v_area_lst.append(42)\n            \n    return(bc_v_area_lst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time bc_v_area = get_bc_voronoi_area(fe_df, 'current')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bc_v_area_end = get_bc_voronoi_area(fe_df, 'end')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fe_feature_df['bc_v_area'] = bc_v_area\nfe_feature_df['bc_v_area_end'] = bc_v_area_end","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Influence"},{"metadata":{"trusted":true},"cell_type":"code","source":"def standardize_dataset(train):\n    train['ToLeft'] = train.PlayDirection == \"left\"\n    train['IsBallCarrier'] = train.NflId == train.NflIdRusher\n    train['TeamOnOffense'] = \"home\"\n    train.loc[train.PossessionTeam != train.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n    train['IsOnOffense'] = train.Team == train.TeamOnOffense # Is player on offense?\n    train['YardLine_std'] = 100 - train.YardLine\n    train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n            'YardLine_std'\n             ] = train.loc[train.FieldPosition.fillna('') == train.PossessionTeam,  \n              'YardLine']\n    train['X_std'] = train.X\n    train.loc[train.ToLeft, 'X_std'] = 120 - train.loc[train.ToLeft, 'X'] \n    train['Y_std'] = train.Y\n    train.loc[train.ToLeft, 'Y_std'] = 53.3 - train.loc[train.ToLeft, 'Y'] \n    train['Orientation_std'] = train.Orientation\n    train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'], 360)\n    train['Dir_std'] = train.Dir\n    train.loc[train.ToLeft, 'Dir_std'] = np.mod(180 + train.loc[train.ToLeft, 'Dir_std'], 360)\n    train.loc[train['Season'] == 2017, 'Orientation'] = np.mod(90 + train.loc[train['Season'] == 2017, 'Orientation'], 360)    \n    \n    return train\n\ndominance_df = standardize_dataset(train_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def radius_calc(dist_to_ball):\n    ''' I know this function is a bit awkward but there is not the exact formula in the paper,\n    so I try to find something polynomial resembling\n    Please consider this function as a parameter rather than fixed\n    I'm sure experts in NFL could find a way better curve for this'''\n    return 4 + 6 * (dist_to_ball >= 15) + (dist_to_ball ** 3) / 560 * (dist_to_ball < 15)\n\n@np.vectorize\ndef pitch_control(x_point, y_point):\n    '''Compute the pitch control over a coordinate (x, y)'''\n\n    offense_ids = my_play[my_play['IsOnOffense']].index\n    offense_control = compute_influence(x_point, y_point, offense_ids)\n    offense_score = np.sum(offense_control)\n\n    defense_ids = my_play[~my_play['IsOnOffense']].index\n    defense_control = compute_influence(x_point, y_point, defense_ids)\n    defense_score = np.sum(defense_control)\n\n    return expit(offense_score - defense_score)\n\nclass Controller:\n    '''This class is a wrapper for the two functions written above'''\n    def __init__(self, play):\n        self.play = play\n        self.vec_influence = np.vectorize(self.compute_influence)\n        self.vec_control = np.vectorize(self.pitch_control) \n        \n    def compute_influence(self, x_point, y_point, player_id):\n        '''Compute the influence of a certain player over a coordinate (x, y) of the pitch\n        '''\n        point = np.array([x_point, y_point])\n        player_row = self.play.loc[player_id]\n        theta = math.radians(player_row[56])\n        speed = player_row[5]\n        player_coords = player_row[54:56].values\n        ball_coords = self.play[self.play['IsBallCarrier']].iloc[:, 54:56].values\n\n        dist_to_ball = euclidean(player_coords, ball_coords)\n\n        S_ratio = (speed / 13) ** 2         # we set max_speed to 13 m/s\n        RADIUS = radius_calc(dist_to_ball)  # updated\n\n        S_matrix = np.matrix([[RADIUS * (1 + S_ratio), 0], [0, RADIUS * (1 - S_ratio)]])\n        R_matrix = np.matrix([[np.cos(theta), - np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n        COV_matrix = np.dot(np.dot(np.dot(R_matrix, S_matrix), S_matrix), np.linalg.inv(R_matrix))\n\n        norm_fact = (1 / 2 * np.pi) * (1 / np.sqrt(np.linalg.det(COV_matrix)))    \n        mu_play = player_coords + speed * np.array([np.cos(theta), np.sin(theta)]) / 2\n\n        intermed_scalar_player = np.dot(np.dot((player_coords - mu_play),\n                                        np.linalg.inv(COV_matrix)),\n                                 np.transpose((player_coords - mu_play)))\n        player_influence = norm_fact * np.exp(- 0.5 * intermed_scalar_player[0, 0])\n\n        intermed_scalar_point = np.dot(np.dot((point - mu_play), \n                                        np.linalg.inv(COV_matrix)), \n                                 np.transpose((point - mu_play)))\n        point_influence = norm_fact * np.exp(- 0.5 * intermed_scalar_point[0, 0])\n\n        return point_influence / player_influence\n    \n    \n    def pitch_control(self, x_point, y_point):\n        '''Compute the pitch control over a coordinate (x, y)'''\n\n        offense_ids = self.play[self.play['IsOnOffense']].index\n        offense_control = self.vec_influence(x_point, y_point, offense_ids)\n        offense_score = np.sum(offense_control)\n\n        defense_ids = self.play[~self.play['IsOnOffense']].index\n        defense_control = self.vec_influence(x_point, y_point, defense_ids)\n        defense_score = np.sum(defense_control)\n\n        return expit(offense_score - defense_score)\n    \n    def display_control(self, grid_size=(30, 15), figsize=(11, 7)):\n        front, behind = 15, 5\n        left, right = 20, 20\n\n        colorm = ['purple'] * 11 + ['orange'] * 11\n        colorm[np.where(self.play.Rusher.values)[0][0]] = 'black'\n        player_coords = self.play[self.play['Rusher']][['X_std', 'Y_std']].values[0]\n\n        X, Y = np.meshgrid(np.linspace(player_coords[0] - behind, \n                                       player_coords[0] + front, \n                                       grid_size[0]), \n                           np.linspace(player_coords[1] - left, \n                                       player_coords[1] + right, \n                                       grid_size[1]))\n\n        # infl is an array of shape num_points with values in [0,1] accounting for the pitch control\n        infl = self.vec_control(X, Y)\n\n        plt.figure(figsize=figsize)\n        plt.contourf(X, Y, infl, 12, cmap='bwr')\n        plt.scatter(self.play['X'].values, self.play['Y'].values, c=colorm)\n        plt.title('Yards gained = {}, play_id = {}'.format(self.play['Yards'].values[0], \n                                                           self.play['PlayId'].unique()[0]))\n        plt.show()\n\ncontrol_lst = []\nfor play_id in tqdm(dominance_df.PlayId.unique()):\n    my_play = dominance_df[dominance_df['PlayId']==play_id]\n    control = Controller(my_play)\n    #Bc influence\n    bc_coords = list(*my_play.loc[(my_play.IsBallCarrier), ['X_std','Y_std']].values)\n    pitch_control = control.vec_control(*bc_coords)\n    control_lst.append(pitch_control)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_basetable['BcInfl'] = [np.asscalar(i) for i in control_lst]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Centroids"},{"metadata":{"trusted":true},"cell_type":"code","source":"def centeroidnp(arr):\n    length = arr.shape[0]\n    sum_x = np.sum(arr[:, 0])\n    sum_y = np.sum(arr[:, 1])\n    return(sum_x/length, sum_y/length)\n\ndef get_defense_centroid(df):\n    centroid_lst = []\n    defense_df = df.loc[df.IsOnOffense == False]\n    for play_id in defense_df.PlayId.unique():\n        def_points = defense_df.loc[defense_df.PlayId == play_id, ['X_std','Y_std']]\n        cp = centeroidnp(np.array(def_points))\n        centroid_lst.append(cp)\n        \n    return(centroid_lst)\n\n%time train_basetable['def_centroid'] = get_defense_centroid(fe_df)\ntrain_basetable['def_centroid_X_std'] = train_basetable.def_centroid.apply(lambda x: x[0])\ntrain_basetable['def_centroid_Y_std'] = train_basetable.def_centroid.apply(lambda x: x[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_qb_location(df):\n    qb_fe_df = df.loc[(df.Position == 'QB')].sort_values(['PlayId','S'])\n    #Since some plays have more than 1 QB, I rank them by Speed and choose the slowest\n    qb_fe_df['QbRank'] = qb_fe_df.groupby(by=['PlayId'])['S'].transform(lambda x: x.rank())\n    qb_fe_df = qb_fe_df.loc[qb_fe_df['QbRank'] == 1, ['PlayId', 'X_std', 'Y_std']]\n    qb_fe_df.rename(columns={'X_std':'X_std_qb', 'Y_std': 'Y_std_qb'}, inplace=True)\n    return(qb_fe_df)\n\nqb_location_df = get_qb_location(fe_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_defense_end(df):\n    def_df = df.loc[df.IsOnOffense==False]\n    #Def yards made up to Bc\n    def_df['DefYardsTowardsBc'] =  def_df['DistFromBc'] - def_df['DistFromBcEnd']\n    \n    def_dist_end_df = def_df.groupby('PlayId', as_index=False)['DistFromBcEnd'] \\\n        .agg({'MinDistFromBcEnd':np.min,'MeanDistFromBcEnd':np.mean,'MedDistFromBcEnd':np.median,'StdDistFromBcEnd':np.std})\n    \n    def_toward_bc_df = def_df.groupby('PlayId', as_index = False)['DefYardsTowardsBc'] \\\n        .agg({'SumDefYardsTowardsBc':sum, 'StdDefYardsTowardsBc':np.std, 'MaxDefYardsTowardsBc': np.max})\n    \n    return(def_dist_end_df.merge(def_toward_bc_df, on = 'PlayId'))\n\ndef_dist_end_df = get_defense_end(fe_df)\n\n#def_dir_df = fe_df.loc[fe_df.IsOnOffense==False].groupby('PlayId', as_index=False)['BcDirDefDir'].agg({'StdBcDirDefDir':np.std})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def_time_to_spot_df = fe_df.loc[fe_df.IsOnOffense == False] \\\n    .groupby('PlayId', as_index=False)[['TimeToBc','TimeToBcEnd']] \\\n    .agg([np.min, np.mean, np.median, np.std])\n\ndef_time_to_spot_df.columns = def_time_to_spot_df.columns.droplevel(0)\n\ndef_time_to_spot_df.columns = ['TimeToBc' + c for c in def_time_to_spot_df.columns[0:4]] \\\n    + ['TimeToBcEnd' + c for c in def_time_to_spot_df.columns[4:]]\n\ndef_time_to_spot_df.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fe_defenders = fe_df.loc[fe_df.IsOnOffense == False]\n# fe_defenders['DefTimeToBcRank'] = fe_defenders.groupby('PlayId')['TimeToBc'].transform(lambda x: x.rank())\n# three_def_df = fe_defenders.loc[fe_defenders.DefTimeToBcRank <= 3]\n# grouped_closest_time_df = three_def_df.groupby('PlayId', as_index=False)['DistFromBc'].mean()\n# grouped_closest_time_df.rename(columns={'TimeToBc':'Top3DefMeanTime'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fe_defenders = fe_df.loc[fe_df.IsOnOffense == False]\nfe_defenders['DistFromBcRank'] = fe_defenders.groupby('PlayId')['DistFromBc'].transform(lambda x: x.rank())\nthree_def_df = fe_defenders.loc[fe_defenders.DistFromBcRank <= 3]\ngrouped_closest_dist_df = three_def_df.groupby('PlayId', as_index=False)['DistFromBc'].mean()\ngrouped_closest_dist_df.rename(columns={'DistFromBc':'Top3DistFromBcMean'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge Tables"},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_basetable = train_basetable.merge(def_dist_end_df, on='PlayId') \\\n    .merge(ol_agg_df, on = 'PlayId') \\\n    .merge(fe_feature_df, on=['GameId','PlayId']) \\\n    .merge(qb_location_df, how = 'left', on = 'PlayId') \\\n    .merge(def_time_to_spot_df, how = 'left', on = 'PlayId') \\\n    .merge(grouped_closest_dist_df, how = 'left', on = 'PlayId')\n\nmerged_basetable['Shotgun_Down_Distance'] = merged_basetable['Shotgun'] * merged_basetable['Down'] * merged_basetable['Distance']\n\nmerged_basetable['BcDistFromDefCent'] = np.sqrt((merged_basetable.X_std_bc - merged_basetable.def_centroid_X_std)**2 \n                                           + (merged_basetable.Y_std_bc - merged_basetable.def_centroid_Y_std)**2)\n\nmerged_basetable['BcDistFromQb'] = np.sqrt((merged_basetable.X_std_bc - merged_basetable.X_std_qb)**2 \n                                           + (merged_basetable.Y_std_bc - merged_basetable.Y_std_qb)**2)\n\nmerged_basetable['BcDistFromQb'] = merged_basetable['BcDistFromQb'].fillna(merged_basetable.BcDistFromQb.mean())\n\nmerged_basetable['BcDirFromMid'] = abs(merged_basetable['BcDir'] - 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# down_dummies = pd.get_dummies(merged_basetable.Down, drop_first=True)\n# down_dummies.columns = ['Down' + str(d).upper() for d in down_dummies.columns]\n\n# quarter_dummies = pd.get_dummies(merged_basetable.Quarter, drop_first=True)\n# quarter_dummies.columns = ['Quarter' + str(q).upper() for q in quarter_dummies.columns]\n\n# merged_basetable = pd.concat([merged_basetable,quarter_dummies, down_dummies], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_basetable['Quarter4'] = np.where(merged_basetable.Quarter == 4, 1, 0)\nmerged_basetable['Down4'] = np.where(merged_basetable.Down == 4, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_drop = ['def_centroid','X','Y','X_std_qb','Y_std_qb','def_centroid_X_std','def_centroid_Y_std',\n                'Dir','TeamOnOffense','Quarter','Down','YardsFromOwnGoal',\n               ]\n\nmerged_basetable.drop(cols_to_drop, axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_basetable.corr()['Yards']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LOS"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleanabv(train):\n    #   Clean Abbreviations\n    train['ToLeft'] = train.PlayDirection == \"left\"\n    train['IsBallCarrier'] = train.NflId == train.NflIdRusher\n    train.loc[train.VisitorTeamAbbr == \"ARI\", 'VisitorTeamAbbr'] = \"ARZ\"\n    train.loc[train.HomeTeamAbbr == \"ARI\", 'HomeTeamAbbr'] = \"ARZ\"\n    train.loc[train.VisitorTeamAbbr == \"BAL\", 'VisitorTeamAbbr'] = \"BLT\"\n    train.loc[train.HomeTeamAbbr == \"BAL\", 'HomeTeamAbbr'] = \"BLT\"\n    train.loc[train.VisitorTeamAbbr == \"CLE\", 'VisitorTeamAbbr'] = \"CLV\"\n    train.loc[train.HomeTeamAbbr == \"CLE\", 'HomeTeamAbbr'] = \"CLV\"\n    train.loc[train.VisitorTeamAbbr == \"HOU\", 'VisitorTeamAbbr'] = \"HST\"\n    train.loc[train.HomeTeamAbbr == \"HOU\", 'HomeTeamAbbr'] = \"HST\"\n    #train['Dir_std'] = np.mod(90 - train.Dir, 360)\n    train['Dir_std_1'] = np.where((train['ToLeft']) & (train['Dir'] < 90), train['Dir'] + 360, train['Dir'])\n    train['Dir_std_1'] = np.where((train['ToLeft']==False) & (train['Dir'] > 270), train['Dir'] - 360, train['Dir_std_1'])\n    train['Dir_std_2'] = np.where(train['ToLeft'], train['Dir_std_1'] - 180, train['Dir_std_1'])\n    train['Dir_std'] = np.where(train.ToLeft, train.Dir_std_2, train.Dir_std_1)\n    train.loc[train.DisplayName == \"Bradley Sowell\", \"Position\"] = \"T\"\n    return train\n\ndef getolinesix(play):\n    oline = play.loc[(play.loc[:,\"Position\"]==\"T\") | (play.loc[:,\"Position\"]==\"G\") | (play.loc[:,\"Position\"]==\"C\") | (play.loc[:,\"Position\"]==\"OT\") | (play.loc[:,\"Position\"]==\"OG\"),:]\n    oline = oline.sort_values(by = 'Y')\n    oline = oline.reset_index()\n    firstoline = oline.loc[0,\"level_0\"]\n    lastoline = oline.loc[4,\"level_0\"]\n    onetwo = 0\n    if firstoline>10:\n        offense = play[11:22]\n        onetwo = 2\n    else:\n        offense = play[0:11]\n        onetwo = 1\n    offense = offense.sort_values(by = 'Y')\n    offense = offense.reset_index()\n    ox1 = offense.loc[offense.loc[:,\"level_0\"]==firstoline,:]\n    ox1 = ox1.index\n    ox5 = offense.loc[offense.loc[:,\"level_0\"]==lastoline,:]\n    ox5 = ox5.index\n    \n    if len(ox1) == 0:\n        ox1 = pd.Series([1])\n    \n    if len(ox5) == 0:\n        ox5 = pd.Series([10])\n    \n    lh = 0\n    li = -1\n    rh = 0\n    ri = -1\n    \n    for i in range(ox1[0]-1,-1,-1):\n        tempx = offense.loc[i,\"Y\"]\n        tempy = offense.loc[i,\"X\"]\n        oxx = offense.loc[ox1,\"Y\"]\n        oxy = offense.loc[ox1,\"X\"]\n        tempd = distance(tempx,oxx,tempy,oxy)\n        if tempd <= 4:\n            if offense.loc[i,\"Position\"]==\"TE\":\n                lh = 1\n                #li = offense.loc[i,\"index\"]\n                li = i\n                break\n        else:\n            lh = 0\n            li = -1\n    \n    for i in range(ox5[0]+1,11,1):\n        tempx = offense.loc[i,\"Y\"]\n        tempy = offense.loc[i,\"X\"]\n        oxx = offense.loc[ox5,\"Y\"]\n        oxy = offense.loc[ox5,\"X\"]\n        tempd = distance(tempx,oxx,tempy,oxy)\n        if tempd <= 4:\n            if offense.loc[i,\"Position\"]==\"TE\":\n                rh = 1\n                #print(offense)\n                #ri = offense.loc[i,\"index\"]\n                #print(i)\n                ri = i\n                break\n        else:\n            rh = 0\n            ri = -1\n        \n    play.reset_index()\n    play.sort_values(by = 'Y')\n\n    return oline,ri,rh,li,lh,offense\n\ndef encodepos(play,uniqueteams):\n    possession = np.zeros(22)\n    for i in range(0,22):\n        for j in range(0,32):\n            if play.loc[i,\"PossessionTeam\"]==uniqueteams[j]:\n                possession[i]=j\n    \n    return possession\n\ndef encodefpos(play,uniqueteams):\n    fposition = np.zeros(22)\n    for i in range(0,22):\n        for j in range(0,32):\n            if play.loc[i,\"FieldPosition\"]==uniqueteams[j]:\n                fposition[i]=j\n    \n    return fposition\n\ndef changedirection(play,pos,fpos):\n    #ha = home/away\n    ha = play.loc[play.loc[:,\"NflId\"]==play.loc[0,\"NflIdRusher\"],\"Team\"]\n    bc = np.where(play.loc[:,\"NflId\"]==play.loc[0,\"NflIdRusher\"])[0]\n    bcy = play.loc[bc,\"X\"]\n    bcy = bcy.reset_index()\n    if bc > 10:\n        meandy = stats.mean(play.loc[11:,'X'])\n    else:\n        meandy = stats.mean(play.loc[0:10,'X'])\n    \n    postemp = pos[0]\n    fpostemp = fpos[0]\n    \n    if bcy.loc[0,\"X\"]>meandy:\n        play.loc[:,\"X\"] = 100 - play.loc[:,\"X\"] + 20\n    else:\n        play.loc[:,\"X\"] = play.loc[:,\"X\"]\n        play.loc[:,\"Y\"] = 53.3 - play.loc[:,\"Y\"]\n    \n    if postemp != fpostemp:\n        play.loc[:,\"YardLine\"] = 100 - play.loc[0,\"YardLine\"]\n    \n    ydline =  play.loc[0,\"YardLine\"]\n    \n    return play, ha, ydline, bc\n    \ndef distance(x1,x2,y1,y2):\n    dist = math.sqrt((x1-x2)**2+(y1-y2)**2)\n    return dist\n\ndef linear(x1,x2,y1,y2):\n    slope = (y1-y2)/(x1-x2)\n    temp = slope*x1\n    b = y1-temp\n    return slope, b\n\ndef hmengagedextra(play,ha,ydline,bc):\n    oline,ri,rh,li,lh,offense = getolinesix(play)\n    #print(play)\n    play = play.reset_index()\n    \n    if rh == 1:\n        rol = offense.loc[[ri]]\n        oline = pd.concat([oline,rol])\n        \n    else:\n        temp = oline.loc[[4]]\n        temp.loc[4,\"Y\"]=oline.loc[4,\"Y\"]+2\n        oline = pd.concat([oline,temp])\n    \n    if lh == 1:\n        lol = offense.loc[[li]]\n        oline = pd.concat([lol,oline])\n    else:\n        temp = oline.loc[[0]]\n        temp.loc[0,\"Y\"] = temp.loc[0,\"Y\"]-2\n        oline = pd.concat([temp,oline])\n    olx = oline.loc[:,\"Y\"]\n    olx = olx.reset_index()\n    oly = oline.loc[:,\"X\"]\n    oly = oly.reset_index()\n    #print(oline)\n    \n    bcy = play.loc[bc,\"X\"]\n    bcy = bcy.reset_index()\n    if ha.all() == \"away\":\n        defense = play.loc[11:21,:]\n    else:\n        defense = play.loc[0:10,:]\n        \n    defense = defense.drop(columns=\"level_0\")\n    defense = defense.reset_index()\n    olnum = np.zeros(6)\n    olnumeng = np.zeros(6)\n    numdefbf = np.zeros(6)\n    for i in range(0,11):\n        dx = defense.loc[i,\"Y\"]\n        dy = defense.loc[i,\"X\"]\n        for j in range(0,6):\n            olx1 = olx.loc[j,\"Y\"]\n            olx2 = olx.loc[j+1,\"Y\"]\n            oly1 = oly.loc[j,\"X\"]\n            oly2 = oly.loc[j+1,\"X\"]\n            if (dx > olx1) & (dx <= olx2):\n                dist1 = distance(olx1,dx,oly1,dy)\n                dist2 = distance(olx2,dx,oly2,dy)\n                if (dy < ydline+15) & (dy > bcy.loc[0,\"X\"]):\n                    slope,b = linear(olx1,olx2,oly1,oly2)\n                    tempy = dx*slope+b\n                    if dy<=tempy:\n                        numdefbf[j] = numdefbf[j] + 1\n                    if dist1 <=1.5 or dist2 <=1.5:\n                        olnumeng[j] = olnumeng[j]+1\n                    olnum[j] = olnum[j]+1\n                    \n    return olnum,olnumeng,numdefbf,oline\n\ntrain = pd.read_csv(\"../input/nfl-big-data-bowl-2020/train.csv\", low_memory=False)\n#train = train.loc[train.Season != 2017]\ntrain = cleanabv(train)\nuniqueplays = np.unique(train.loc[:,\"PlayId\"])\nuniqueteams = np.unique(train.loc[:,\"PossessionTeam\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holes_spread = []\nfor i in tqdm(range(0, len(uniqueplays))):\n    play = train.loc[train.loc[:,\"PlayId\"]==uniqueplays[i],:]\n    play = play.reset_index()\n    playid = play.PlayId[0]\n    pos = encodepos(play,uniqueteams)\n    fpos = encodefpos(play,uniqueteams)\n    play,ha,ydline,bc = changedirection(play,pos,fpos)\n    olnum,olnumeng,numdefbf,oline = hmengagedextra(play,ha,ydline,bc)\n    bc_dir = play.loc[play.IsBallCarrier, 'Dir_std'].values[0]\n    oline_y = oline.Y\n    holes = np.diff(oline_y)\n    holes_spread.append(np.mean(holes))\n    \n    if i == 0:\n        olnums = olnum\n        olnumseng = olnumeng\n        numdefsbf = numdefbf\n    else:\n        olnums = np.vstack((olnums,olnum))\n        olnumseng = np.vstack((olnumseng,olnumeng))\n        numdefsbf = np.vstack((numdefsbf,numdefbf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"los_df = outcomes.copy().drop('Yards', axis = 1)\nlos_df['olnums'] = [sum(i) for i in olnums]\nlos_df['olnumseng'] = [sum(i) for i in olnumseng]\nlos_df['numdefsbf'] = [sum(i) for i in numdefsbf]\nlos_df['avgholesize'] = holes_spread","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_basetable = merged_basetable.merge(los_df, on=['GameId', 'PlayId'])\nmerged_basetable['numdefsb_cube'] = merged_basetable['numdefsbf'] ** 3\nmerged_basetable['numdefsbf_cube_div_min_dist'] =  merged_basetable['numdefsb_cube'] / merged_basetable['def_min_dist']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_basetable['BcInfl'] = merged_basetable['BcInfl'].fillna(.8)\nmerged_basetable['v_infl'] = (merged_basetable['BcInfl'] * merged_basetable['bc_v_area_end']).fillna(24)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Remove Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_bound = merged_basetable.Yards.quantile(0.002)\nupper_bound = merged_basetable.Yards.quantile(0.998)\nmerged_basetable = merged_basetable.loc[(merged_basetable.Yards > lower_bound) & (merged_basetable.Yards < upper_bound)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cluster Run Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_features = ['back_from_scrimmage','S','A','Shotgun','BcDistFromQb','InsideRun','OffTackle','TimeDelta','BcDirFromMid',]\ncluster_df = merged_basetable[cluster_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_data(feature_data):\n    mms = MinMaxScaler()\n    mms.fit(feature_data)\n    data_transformed = mms.transform(feature_data)\n    return(data_transformed)\n\ndef plot_elbow(transformed_data, k_max):\n    sum_of_squared_distances = []\n    K = range(1, k_max)\n    for k in K:\n        km = KMeans(n_clusters=k, init = 'k-means++', random_state = 42)\n        km = km.fit(transformed_data)\n        sum_of_squared_distances.append(km.inertia_)\n        \n    plt.plot(K, sum_of_squared_distances, 'bx-')\n    plt.xlabel('k')\n    plt.ylabel('Sum_of_squared_distances')\n    plt.title('Elbow Method For Optimal k')\n    plt.show()\n    \ndef fit_clusters(feature_df, k):\n    kmeans = KMeans(n_clusters = k, init = 'k-means++', random_state = 42, max_iter=100, n_init=1)\n    fit = kmeans.fit(feature_df)\n    return(fit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transformed = scale_data(cluster_df)\nplot_elbow(data_transformed, 15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_fit = fit_clusters(data_transformed, 5)\ncluster_labels = cluster_fit.predict(data_transformed)\nmerged_basetable['RunCluster'] = cluster_labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's split our data into train/val"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = merged_basetable.copy()\nyards = X.Yards\n\ny = np.zeros((yards.shape[0], 199))\nfor idx, target in enumerate(list(yards)):\n    y[idx][99 + target] = 1\n\nX.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)\n\n#Scale the numeric features\nscaler = StandardScaler()\n\nbinary_features = ['back_oriented_down_field', 'back_moving_down_field', 'Shotgun', 'InsideRun', 'OffTackle', \n                   'BcFast','BcSlow','BcMovingDf','Quarter4', 'Down4','RunCluster',\n#                   'Quarter2', 'Quarter3', 'Quarter5', 'Down2', 'Down3', \n                  ]\n\nbinary_array = np.array(X.loc[:, binary_features])\n\nnumeric_df = X.drop(binary_features, axis = 1)\nnumeric_scaled = scaler.fit_transform(numeric_df)\nX_transformed = np.hstack((numeric_scaled, binary_array))\n\nX_train, X_val, y_train, y_val = train_test_split(X_transformed, y, test_size=0.25, random_state=12345)\n\nprint(X_train.shape, X_val.shape)\nprint(y_train.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build NN\nBelow class Metric based entirely on: https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping\n\nBelow early stopping entirely based on: https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112868#latest-656533"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_rf(x_tr, y_tr, x_val, y_val, shape):\n    model = RandomForestRegressor(bootstrap=False, max_features=0.3, min_samples_leaf=15, \n                                  min_samples_split=8, n_estimators=25, n_jobs=-1, random_state=42)\n    model.fit(x_tr, y_tr)\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    crps = crps_score(y_pred, y_valid, shape=shape)\n    \n    return model, crps, y_pred\n\n# Calculate CRPS score\ndef crps_score(y_prediction, y_valid, shape=X.shape[0]):\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_prediction, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * shape)\n    crps = np.round(val_s, 6)\n    return crps\n\nfrom sklearn.ensemble import RandomForestRegressor\n#Train RF\n#rf, crps_rf = get_rf(tr_x, tr_y, val_x, val_y, shape=val_x.shape[0])\nrf, crps_rf, y_pred = get_rf(X_train, y_train, X_val, y_val, shape=X_val.shape[0])\n#models_rf.append(rf)\nprint(\"the crps (RF) is %f\"%(crps_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(list(zip(X.columns, rf.feature_importances_)),\n             columns = ['Feature', 'importances']).sort_values('importances', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\nfrom keras.models import Model\nimport keras.backend as K\nimport re\nfrom keras.losses import binary_crossentropy\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport codecs\n\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom sklearn.metrics import f1_score\n\nclass CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n        print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(x_tr,y_tr,x_val,y_val):\n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dense(1024, input_dim=X.shape[1], activation='relu')(inp)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n#     x = Dense(128, activation='relu')(x)\n#     x = Dropout(0.5)(x)\n#     x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp,out)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n    #add lookahead\n#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n#     lookahead.inject(model) # add into model\n\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=15)\n\n    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=1, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]/bsz\n    \n    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=20, batch_size=bsz,verbose=0)\n    model.load_weights(\"best_model.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n    crps = np.round(val_s, 6)\n\n    return model,crps, y_true, y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nimport time\n\nlosses = []\nmodels = []\ncrps_csv = []\n\ns_time = time.time()\n\nfor k in range(1):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        print(\"-----------\")\n        print(\"-----------\")\n        tr_x,tr_y = X_transformed[tr_inds],y[tr_inds]\n        val_x,val_y = X_transformed[val_inds],y[val_inds]\n        model,crps,y_true,y_preds = get_model(tr_x,tr_y,val_x,val_y)\n        models.append(model)\n        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n        crps_csv.append(crps)\n        \nprint(\"mean crps is %f\"%np.mean(crps_csv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('mean crps is {} and std is {}'.format(np.mean(crps_csv), np.std(crps_csv)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nn_predict(x_te):\n    model_num = len(models)\n    for k,m in enumerate(models):\n        if k==0:\n            y_pred = m.predict(x_te,batch_size=1024)\n        else:\n            y_pred+=m.predict(x_te,batch_size=1024)\n            \n    y_pred = y_pred / model_num\n    \n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time for the actual submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"#if  TRAIN_OFFLINE==False:\nfrom kaggle.competitions import nflrush\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_x_lst = []\n#for (test_df, sample_prediction_df) in iter_test:\n#     try:\ntest_df_2 = test_df.copy()\ntest_df_3 = test_df.copy()\ntest_df_4 = test_df.copy()\n\n#test_df['S_std'] = standardize_speed(test_df)\ntest_basetable = create_features(test_df, deploy=True)\ntest_adjusted_df = adjust_players_and_teams(test_df_2, player_schema, team_schema)\ntest_standardized_coor_df = standardize_coordinates(test_adjusted_df)\ntest_standardized_dir_df = standardize_direction(test_standardized_coor_df)\ntest_ol_agg_df = get_o_line_stats(test_standardized_dir_df)\ntest_merged_basetable = test_basetable.merge(test_ol_agg_df, on='PlayId')\n\ntest_fe_df = more_feature_engineering(test_standardized_dir_df, pos_dict)\ntest_fe_feature_df = test_fe_df[fe_feature_lst].drop_duplicates()\n\n#Voronoi\ntest_bc_v_area = get_bc_voronoi_area(test_fe_df, 'current')\ntest_bc_v_area_end = get_bc_voronoi_area(test_fe_df, 'end')\n\ntest_fe_feature_df['bc_v_area'] = test_bc_v_area[0]\ntest_fe_feature_df['bc_v_area_end'] = test_bc_v_area_end[0]\n\ntest_def_dist_end_df = get_defense_end(test_fe_df)\n\ntest_fe_df[['X_std_end','Y_std_end']] = test_fe_df[['X_std_end','Y_std_end']].fillna(25)\n#QB Location\ntest_qb_location_df = get_qb_location(test_fe_df)\n\n#Time to Spot\ntest_def_time_to_spot_df = test_fe_df.loc[test_fe_df.IsOnOffense == False] \\\n.groupby('PlayId', as_index=False)[['TimeToBc','TimeToBcEnd']] \\\n. agg([np.min, np.mean, np.median, np.std])\n\ntest_def_time_to_spot_df.columns = test_def_time_to_spot_df.columns.droplevel(0)\n\ntest_def_time_to_spot_df.columns = ['TimeToBc' + c for c in test_def_time_to_spot_df.columns[0:4]] \\\n+ ['TimeToBcEnd' + c for c in test_def_time_to_spot_df.columns[4:]]\n\ntest_def_time_to_spot_df.reset_index(inplace=True)\n\n#Top 3 Defenders Distance\ntest_fe_defenders = test_fe_df.loc[test_fe_df.IsOnOffense == False]\ntest_fe_defenders['DistFromBcRank'] = test_fe_defenders.groupby('PlayId')['DistFromBc'].transform(lambda x: x.rank())\ntest_three_def_df = test_fe_defenders.loc[test_fe_defenders.DistFromBcRank <= 3]\ntest_grouped_closest_dist_df = test_three_def_df.groupby('PlayId', as_index=False)['DistFromBc'].mean()\ntest_grouped_closest_dist_df.rename(columns={'DistFromBc':'Top3DistFromBcMean'}, inplace=True)\n\n#Merge Tables\ntest_merged_basetable = test_merged_basetable.merge(test_def_dist_end_df, how = 'left', on='PlayId') \\\n    .merge(test_fe_feature_df, how = 'left', on=['GameId','PlayId']) \\\n    .merge(test_qb_location_df, how = 'left', on = 'PlayId') \\\n    .merge(test_def_time_to_spot_df, how = 'left', on = 'PlayId') \\\n    .merge(test_grouped_closest_dist_df, how = 'left', on = 'PlayId').fillna(25)\n\ntest_merged_basetable['Shotgun_Down_Distance'] = test_merged_basetable['Shotgun'] * test_merged_basetable['Down'] * test_merged_basetable['Distance']\n\n#Influence\n# test_dominance_df = standardize_dataset(test_df_3)\n\n# test_control = Controller(test_dominance_df)\n# #Bc influence\n# test_bc_coords = list(*test_dominance_df.loc[(test_dominance_df.IsBallCarrier), ['X_std','Y_std']].values)\n# test_pitch_control = test_control.vec_control(*test_bc_coords)\n# test_merged_basetable['BcInfl'] = np.asscalar(test_pitch_control)\n\n#Centroid\ntest_merged_basetable['def_centroid'] = get_defense_centroid(test_fe_df)\ntest_merged_basetable['def_centroid_X_std'] = test_merged_basetable.def_centroid.apply(lambda x: x[0])\ntest_merged_basetable['def_centroid_Y_std'] = test_merged_basetable.def_centroid.apply(lambda x: x[1])\n\ntest_merged_basetable['BcDistFromDefCent'] = np.sqrt((test_merged_basetable.X_std_bc - test_merged_basetable.def_centroid_X_std)**2 \n                           + (test_merged_basetable.Y_std_bc - test_merged_basetable.def_centroid_Y_std)**2)\n\ntest_merged_basetable['BcDistFromQb'] = np.sqrt((test_merged_basetable.X_std_bc - test_merged_basetable.X_std_qb)**2 \n                           + (test_merged_basetable.Y_std_bc - test_merged_basetable.Y_std_qb)**2)\n\ntest_merged_basetable['BcDirFromMid'] = abs(test_merged_basetable['BcDir'] - 90)\n\n#One hot\n#     test_merged_basetable['Down2'] = np.where(test_merged_basetable.Down == 2, 1, 0)\n#     test_merged_basetable['Down3'] = np.where(test_merged_basetable.Down == 3, 1, 0)\ntest_merged_basetable['Down4'] = np.where(test_merged_basetable.Down == 4, 1, 0)\n#     test_merged_basetable['Quarter2'] = np.where(test_merged_basetable.Quarter == 2, 1, 0)\n#     test_merged_basetable['Quarter3'] = np.where(test_merged_basetable.Quarter == 3, 1, 0)\ntest_merged_basetable['Quarter4'] = np.where(test_merged_basetable.Quarter == 4, 1, 0)\n#     test_merged_basetable['Quarter5'] = np.where(test_merged_basetable.Quarter == 5, 1, 0)\n\ntest_merged_basetable.drop(['GameId','PlayId'] + cols_to_drop, axis=1, inplace=True)\n\n#Clustering\ntest_cluster_df = test_merged_basetable[cluster_features]\ntest_data_transformed = scale_data(test_cluster_df)\ntest_merged_basetable['RunCluster'] = cluster_fit.predict(test_data_transformed)\n\n#LOS\n#         play = test_df_4.reset_index()\n#         playid = play.PlayId[0]\n#         pos = encodepos(play,uniqueteams)\n#         fpos = encodefpos(play,uniqueteams)\n#         play,ha,ydline,bc = changedirection(play,pos,fpos)\n#         olnum,olnumeng,numdefbf,oline = hmengagedextra(play,ha,ydline,bc)\n#         holes = np.diff(oline.Y)\n\n#         test_merged_basetable['olnums'] = sum(olnum)\n#         test_merged_basetable['olnumseng'] = sum(olnumeng)\n#         test_merged_basetable['numdefsbf'] = sum(numdefbf)\n#         test_merged_basetable['avgholesize'] = np.mean(holes)\n\n#         test_merged_basetable['numdefsb_cube'] = test_merged_basetable['numdefsbf'] ** 3\n#         test_merged_basetable['numdefsbf_cube_div_min_dist'] =  test_merged_basetable['numdefsb_cube'] / test_merged_basetable['def_min_dist']\n\n# test_merged_basetable['BcInfl'] = test_merged_basetable['BcInfl'].fillna(.5)\n# test_merged_basetable['v_infl'] = (test_merged_basetable['BcInfl'] * test_merged_basetable['bc_v_area_end']).fillna(25)\n\ntest_merged_basetable = test_merged_basetable[list(merged_basetable.drop(['GameId','PlayId','Yards'], axis=1).columns)].fillna(1)\ntest_x_lst.append(test_merged_basetable)\n\ntest_binary_array = np.array(test_merged_basetable.loc[:, binary_features])\n\ntest_numeric_df = test_merged_basetable.drop(binary_features, axis = 1)\ntest_numeric_scaled = scaler.transform(test_numeric_df)\ntest_scaled_basetable = np.hstack((test_numeric_scaled, test_binary_array))\n\nnn_y_pred = nn_predict(test_scaled_basetable)\nnn_y_pred = np.clip(np.cumsum(nn_y_pred, axis=1), 0, 1).tolist()[0]\n\nrf_y_pred = rf.predict(test_scaled_basetable)\nrf_y_pred = np.clip(np.cumsum(rf_y_pred, axis=1), 0, 1)\n\nblended_y_pred = (nn_y_pred + rf_y_pred) / 2\n\npreds_df = pd.DataFrame(data=[nn_y_pred], columns=sample_prediction_df.columns)\n\nenv.predict(preds_df)\n#     except:\n#         print('Actual Prediction Failed')\n#         zero_array = np.zeros(199)\n#         preds_df = pd.DataFrame(data=[zero_array], columns=sample_prediction_df.columns)\n#         preds_df.iloc[:,102] = .5\n#         preds_df.iloc[:,103:] = 1\n\n#         env.predict(preds_df)\n\n# env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_merged_basetable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}