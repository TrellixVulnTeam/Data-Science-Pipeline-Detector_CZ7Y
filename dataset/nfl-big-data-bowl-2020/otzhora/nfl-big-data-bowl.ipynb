{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\nimport pandas as pd\n\n# You can only call make_env() once, so don't lose it!\nenv = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\n%matplotlib inline \nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom tqdm.notebook import tqdm\nimport numpy as np\n\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\n\nimport keras\nfrom keras.layers import Dense, Input\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nimport keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### Load training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring train data"},{"metadata":{},"cell_type":"markdown","source":"columns with missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns[(train_df.count() - 509762).to_numpy().nonzero()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"-train_df.count() + 509762","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change play direction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_play_direction(x):\n    x[\"X\"] = 120 - x[\"X\"]\n    x[\"Orientation\"] = 360 - x[\"Orientation\"]\n    x[\"Dir\"] = 360 - x[\"Dir\"]\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df[\"PlayDirection\"] == \"left\"] = train_df[train_df[\"PlayDirection\"] == \"left\"].apply(change_play_direction, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Home"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Home\"] = train_df[\"Team\"] == \"home\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Teams Abbr"},{"metadata":{"trusted":true},"cell_type":"code","source":"map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\nfor abb in train_df['PossessionTeam'].unique():\n    map_abbr[abb] = abb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Possession"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"PossessionTeam\"] = train_df[\"PossessionTeam\"].map(map_abbr)\ntrain_df[\"HomeTeamAbbr\"] = train_df[\"HomeTeamAbbr\"].map(map_abbr)\ntrain_df[\"VisitorTeamAbbr\"] = train_df[\"VisitorTeamAbbr\"].map(map_abbr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['HomePossession'] = train_df['PossessionTeam'] == train_df['HomeTeamAbbr']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Possession\"] = train_df[\"HomePossession\"] == train_df[\"Home\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(44)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rusher"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['IsRusher'] = train_df['NflId'] == train_df['NflIdRusher']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.sort_values(by=['PlayId', \"Possession\", 'IsRusher', \"Position\"]).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.all(train_df.iloc[21::22][\"IsRusher\"].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.iloc[110:132][\"Position\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plays"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays = train_df[\"PlayId\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge "},{"metadata":{"trusted":true},"cell_type":"code","source":"def merge_df(train_df, player_features_list, game_features_list):\n    columns_list = []\n    for i in range(22):\n        for feature in player_features_list:\n            columns_list.append(feature+\"_\"+str(i))\n            \n    merged_df = pd.DataFrame(index=range(len(plays)))\n    \n    # game features \n    for game_feature in game_features_list:\n        merged_df = merged_df.assign(**{game_feature: train_df[game_feature][::22].tolist()})\n        \n    j = 0\n    for i in range(22):\n        for feature in player_features_list:\n            merged_df = merged_df.assign(**{columns_list[j]: train_df[feature][i::22].tolist()})\n            j += 1\n    return merged_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df = merge_df(train_df, [\"X\", \"Y\", \"A\", \"S\", \"Orientation\", \"Dir\"], [\"Yards\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trainning"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = merged_df.drop(columns=[\"Yards\"])\ny_train = merged_df[\"Yards\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.zeros(shape=(X_train.shape[0], 199))\nfor i,yard in enumerate(merged_df['Yards']):\n    y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crps(y_true, y_pred):\n    return K.mean(K.square(y_true - K.cumsum(y_pred, axis=1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RAdam(keras.optimizers.Optimizer):\n    \"\"\"RAdam optimizer.\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Weight decay for each param.\n        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n            algorithm from the paper \"On the Convergence of Adam and\n            Beyond\".\n        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n        min_lr: float >= 0. Minimum learning rate after warmup.\n    # References\n        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n        learning_rate = kwargs.pop('lr', learning_rate)\n        super(RAdam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n            self.total_steps = K.variable(total_steps, name='total_steps')\n            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n            self.min_lr = K.variable(min_lr, name='min_lr')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.initial_weight_decay = weight_decay\n        self.initial_total_steps = total_steps\n        self.amsgrad = amsgrad\n\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n\n        if self.initial_total_steps > 0:\n            warmup_steps = self.total_steps * self.warmup_proportion\n            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n            decay_rate = (self.min_lr - lr) / decay_steps\n            lr = K.switch(\n                t <= warmup_steps,\n                lr * (t / warmup_steps),\n                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n            )\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n        else:\n            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        beta_1_t = K.pow(self.beta_1, t)\n        beta_2_t = K.pow(self.beta_2, t)\n\n        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n\n            m_corr_t = m_t / (1.0 - beta_1_t)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t))\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t))\n\n            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n                         (sma_t - 2.0) / (sma_inf - 2.0) *\n                         sma_inf / sma_t)\n\n            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / (v_corr_t + self.epsilon), m_corr_t)\n\n            if self.initial_weight_decay > 0:\n                p_t += self.weight_decay * p\n\n            p_t = p - lr * p_t\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    @property\n    def lr(self):\n        return self.learning_rate\n\n    @lr.setter\n    def lr(self, learning_rate):\n        self.learning_rate = learning_rate\n\n    def get_config(self):\n        config = {\n            'learning_rate': float(K.get_value(self.learning_rate)),\n            'beta_1': float(K.get_value(self.beta_1)),\n            'beta_2': float(K.get_value(self.beta_2)),\n            'decay': float(K.get_value(self.decay)),\n            'weight_decay': float(K.get_value(self.weight_decay)),\n            'epsilon': self.epsilon,\n            'amsgrad': self.amsgrad,\n            'total_steps': float(K.get_value(self.total_steps)),\n            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n            'min_lr': float(K.get_value(self.min_lr)),\n        }\n        base_config = super(RAdam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=250, input_shape=[X_train.shape[1]])(x)\n    act1 = keras.layers.PReLU()(fc1)\n    bn1 = keras.layers.BatchNormalization()(act1)\n    dp1 = keras.layers.Dropout(0.55)(bn1)\n    gn1 = keras.layers.GaussianNoise(0.15)(dp1)\n    concat1 = keras.layers.Concatenate()([x, gn1])\n    fc2 = keras.layers.Dense(units=300)(concat1)\n    act2 = keras.layers.PReLU()(fc2)\n    bn2 = keras.layers.BatchNormalization()(act2)\n    dp2 = keras.layers.Dropout(0.55)(bn2)\n    gn2 = keras.layers.GaussianNoise(0.15)(dp2)\n    concat2 = keras.layers.Concatenate()([concat1, gn2])\n    fc3 = keras.layers.Dense(units=300)(concat2)\n    act3 = keras.layers.PReLU()(fc3)\n    bn3 = keras.layers.BatchNormalization()(act3)\n    dp3 = keras.layers.Dropout(0.55)(bn3)\n    gn3 = keras.layers.GaussianNoise(0.15)(dp3)\n    concat3 = keras.layers.Concatenate([concat2, gn3])\n    output = keras.layers.Dense(units=199, activation='softmax')(concat2)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model\n\ndef train_model(X_train, y_train, X_val, y_val):\n    model = get_model()\n    model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7), loss=crps)\n    er = EarlyStopping(patience=20, min_delta=1e-4, restore_best_weights=True, monitor='val_loss')\n    model.fit(X_train, y_train, epochs=200, validation_data=[X_val, y_val], batch_size=128)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold\n\nrkf = RepeatedKFold(n_splits=5, n_repeats=5)\n\nmodels = []\n\nfor tr_idx, vl_idx in rkf.split(X_train, y_train):\n   \n    x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n    x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n    #model = train_model(x_tr, y_tr, x_vl, y_vl)33\n    #models.append(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Main loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can only iterate through a result from `env.iter_test()` once\n# so be careful not to lose it once you start iterating.\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test_df, sample_prediction_df) = next(iter_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    \n    env.predict(sample_prediction_df)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}