{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"    import os\n    import pandas as pd\n    from kaggle.competitions import nflrush\n    import numpy as np\n    from sklearn import preprocessing\n    import matplotlib.pyplot as plt\n    import seaborn\n    import random\n    from sklearn.model_selection import KFold\n    import lightgbm as lgb\n    import tqdm, gc\n    from scipy.stats import norm\n\n# Here I just loaded all of the packages that I used when creating my model.\n# The dataset is nflrush which was pulled from kaggle.competitions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()\ntrain_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n\n# Here i just made a new environment and set Python to be able to read the data. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \ntrain_df.head()\n\n# Here is an example of 5 players that includes all of the columns in the dataset. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seaborn.distplot(train_df['Yards'])\nplt.show()\n\n# Here is a graph of the distribution of rushes. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(12,10))\nseaborn.heatmap(train_df.iloc[:,2:].corr(),annot=True, linewidths=.1, fmt='.1f', ax=ax)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_RB = train_df.loc[:,['NflId', 'DisplayName', 'PlayerBirthDate', 'PlayerWeight', 'PlayerHeight', 'PlayerCollegeName']].drop_duplicates()\n\ndf_RB[\"HeightFt\"] = df_RB[\"PlayerHeight\"].str.split('-', expand=True)[0].astype(int)\ndf_RB[\"HeightIn\"] = df_RB[\"PlayerHeight\"].str.split('-', expand=True)[1].astype(int)\ndf_RB[\"HeightCm\"] = df_RB[\"HeightFt\"]*30.48 + df_RB[\"HeightIn\"]*2.54\n\ndf_RB[\"WeightKg\"] = df_RB[\"PlayerWeight\"]*0.45359237\n\ndf_height = df_RB.groupby(['PlayerHeight','HeightFt','HeightIn']).size().reset_index().sort_values([\"HeightFt\", \"HeightIn\"])\n\ndf_height.columns = [\"PlayerHeight\",\"HeightFt\",\"HeightIn\",\"Count\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CTeam = df_RB[\"PlayerCollegeName\"].value_counts()\ndf_CTeamCount = pd.DataFrame({'College Name':CTeam.index, 'Count':CTeam.values}).sort_values(\"Count\", ascending = False).head(50)\n\nfig = px.bar(df_CTeamCount, x='College Name', y='Count', title=\"The 50 Top Colleges With The Most Players\", height=700, width=800)\n\nfig.update_traces(marker_color='rgb(239, 117, 100)', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=2, opacity=0.7)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"speed_df = train_df.loc[:,['DisplayName', 'S']].groupby('DisplayName').mean()\nspeed_df.columns = [\"Average Speed\"]\nspeed_df = speed_df.sort_values(\"Average Speed\", ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(speed_df, x=\"Average Speed\",\n                   title='Average Speed Distribution of RBs',\n                   opacity=0.8,\n                   color_discrete_sequence=['indianred']\n                   )\n\nfig.update_layout(\n    yaxis_title_text='Count',\n    height=500, width=800)\n\nfig.update_traces(marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.8\n                 )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_used = [\"GameId\",\"PlayId\",\"Yards\"]\nunique_columns = []\nfor c in train_df.columns:\n    if c not in not_used and len(set(train_df[c][:11]))!= 1:\n        unique_columns.append(c)\nprint(unique_columns)\n\n# I took out the columns i wasn't going to use and then appended the unique columns.\n# I also decided to print out the unique columns just so I would have a visual. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fe(df):\n    df['X1'] = 120 - df['X']\n    df['Y1'] = 53.3 - df['Y']\n    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n    \n    def give_me_WindSpeed(x):\n        x = str(x)\n        x = x.replace('mph', '').strip()\n        if '-' in x:\n            x = (int(x.split('-')[0]) + int(x.split('-')[1])) / 2\n        try:\n            return float(x)\n        except:\n            return -99\n    \n    df['WindSpeed'] = df['WindSpeed'].apply(lambda p: give_me_WindSpeed(p))\n    \n    def give_me_GameWeather(x):\n        x = str(x).lower()\n        if 'indoor' in x:\n            return  'indoor'\n        elif 'cloud' in x or 'coudy' in x or 'clouidy' in x:\n            return 'cloudy'\n        elif 'rain' in x or 'shower' in x:\n            return 'rain'\n        elif 'sunny' in x:\n            return 'sunny'\n        elif 'clear' in x:\n            return 'clear'\n        elif 'cold' in x or 'cool' in x:\n            return 'cool'\n        elif 'snow' in x:\n            return 'snow'\n        return x\n    \n    df['GameWeather'] = df['GameWeather'].apply(lambda p: give_me_GameWeather(p))\n# Above, I adjusted the wind speed column and made adjustments to the outputs of GameWeather    \n\n    df['Field_eq_Possession'] = df['FieldPosition'] == df['PossessionTeam']\n    \n    df['is_rusher'] = df['NflId'] == df['NflIdRusher']\n    \n    for c in df.columns:\n        if c in not_used: continue\n        elif c == 'TimeHandoff':\n            df['TimeHandoff_min'] = pd.Series([int(x[-7:-5]) for x in df[c]])\n            df['TimeHandoff_sec'] = pd.Series([int(x[-4:-2]) for x in df[c]])\n# '2017-09-08T00:44:05.000Z'to '00:44:05.000Z' because time matters more than date in this case\n            df[c] = pd.Series([x[11:] for x in df[c]])\n        elif c == 'TimeSnap':\n            df['TimeSnap_min'] = pd.Series([int(x[-7:-5]) for x in df[c]])\n            df['TimeSnap_sec'] = pd.Series([int(x[-4:-2]) for x in df[c]])\n\n            df[c] = pd.Series([x[11:] for x in df[c]])\n        elif c == 'PlayerHeight':\n            df['height_1'] = pd.Series([int(x[0]) for x in df[c]])\n            df['height_2'] = pd.Series([int(x[2]) for x in df[c]])\n            df['height_3'] = df['height_1'] * 12 + df['height_2']\n            df['BMI'] = (df['PlayerWeight'] * 703) / ((df['height_1'] * 12 + df['height_2']) ** 2)\n        elif c == \"DefensePersonnel\":\n            arr = [[int(s[0]) for s in t.split(\", \")] for t in df[\"DefensePersonnel\"]]\n            df[\"DL\"] = pd.Series([a[0] for a in arr])\n            df[\"LB\"] = pd.Series([a[1] for a in arr])\n            df[\"DB\"] = pd.Series([a[2] for a in arr])       \n        elif c == \"OffensePersonnel\":\n            arr = [[int(s[0]) for s in t.split(\", \")] for t in df[\"OffensePersonnel\"]]\n            df[\"RB\"] = pd.Series([a[0] for a in arr])\n            df[\"TE\"] = pd.Series([a[1] for a in arr])\n            df[\"WR\"] = pd.Series([a[2] for a in arr])\n        elif c == \"GameClock\":\n            arr = [[int(s[0]) for s in t.split(\":\")] for t in df[\"GameClock\"]]\n            df[\"GameHour\"] = pd.Series([a[0] for a in arr])\n            df[\"GameMinute\"] = pd.Series([a[1] for a in arr])\n        elif c == \"PlayerBirthDate\":\n            df['Season'] = pd.Series([int(x) for x in df['Season']])\n            df[\"BirthY\"] = pd.Series([int(t.split('/')[2]) for t in df[\"PlayerBirthDate\"]])\n            df['age'] = df['Season'] - df['BirthY']\n            df['Season'] = pd.Series([str(x) for x in df['Season']])\n# For the code above, this adjusted the variables I wrote down in all of the columns above\n            \n    df['handoff_snap_diff_min'] = df['TimeHandoff_min'] - df['TimeSnap_min']\n    df['handoff_snap_diff_sec'] = df['handoff_snap_diff_min'] * 60 + df['TimeHandoff_sec'] - df['TimeSnap_sec']\n    return df\n# The lines above are the equations to calculate handoff_snap_diff_min and handoff_snap_diff_sec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = fe(train_df)\n\n# I then set train_df equal to the function fe which then calls train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_dict = {}\nfor c in train_df.columns:\n    if train_df[c].dtype=='object' and c not in not_used: \n        label = preprocessing.LabelEncoder()\n        train_df[c] = label.fit_transform(list(train_df[c].values))\n        label_dict[c] = label\n        \n# These lines create the dictionary label_dict, which adds objects inside of the train_df variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sample(10)\n\n# Here is a sample of 10 outputs from the train_df variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_columns = []\nfor c in train_df.columns:\n    if c in not_used: continue\n    all_columns.append(c)\n\nfor c in unique_columns:\n    for i in range(22):\n        all_columns.append(c+str(i))\n# I created a new list which appended all of the unused columns in train_df\n        \nlen(all_columns)\n\n# Counts the length of the appended dataset which was 401","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(all_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=np.zeros((509762//22,len(all_columns)))\nfor i in tqdm.tqdm(range(0,509762,22)):\n    count=0\n    for c in train_df.columns:\n        if c in not_used: continue\n        train_data[i//22][count] = train_df[c][i]\n        count+=1\n    for c in unique_columns:\n        for j in range(22):\n            train_data[i//22][count] = train_df[c][i+j]\n            count+=1 \n\n# The above was used from from https://www.kaggle.com/hukuda222/nfl-simple-model-using-lightgbm\n# This code loops through all of the attempts and counts the yardage gained on each play. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.array([train_df[\"Yards\"][i] for i in range(0,509762,22)])\nX_train = pd.DataFrame(data=train_data,columns=all_columns)\n\n# Set the groundwork to plot the chart, by setting the labels for each axis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [0 for i in range(199)]\nfor y in y_train:\n    data[int(y+99)]+=1\nplt.plot([i-99 for i in range(199)],data)\n\n# Plots the amount of yards gained on each attempt and the amount of times that rush occured in the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = 10\nseed = 222\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_valid_pred = np.zeros(X_train.shape[0])\nmodels = []\n\nfor tr_idx, val_idx in kf.split(X_train, y_train):\n    tr_x, tr_y = X_train.iloc[tr_idx,:], y_train[tr_idx]\n    vl_x, vl_y = X_train.iloc[val_idx,:], y_train[val_idx]\n            \n    print(len(tr_x),len(vl_x))\n    tr_data = lgb.Dataset(tr_x, label=tr_y)\n    vl_data = lgb.Dataset(vl_x, label=vl_y)  \n    clf = lgb.LGBMRegressor(n_estimators=200,learning_rate=0.01)\n    clf.fit(tr_x, tr_y,\n        eval_set=[(vl_x, vl_y)],\n        early_stopping_rounds=20,\n        verbose=False)\n    y_valid_pred[val_idx] += clf.predict(vl_x, num_iteration=clf.best_iteration_)\n    models.append(clf)\n\ngc.collect()\n\n# Not too familiar with LGBM regressor so borrowed the above code from https://www.kaggle.com/hukuda222/nfl-simple-model-using-lightgbm\n# The above makes predictions on future plays and yards gained. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nscaler.fit(y_train.reshape(-1, 1))\ny_train = scaler.transform(y_train.reshape(-1, 1)).flatten()\n\n# Standardized the objective variable by using the scaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.zeros((509762//22,199))\ny_ans = np.zeros((509762//22,199))\n\nfor i,p in enumerate(np.round(scaler.inverse_transform(y_valid_pred))):\n    p+=99\n    for j in range(199):\n        if j>=p+10:\n            y_pred[i][j]=1.0\n        elif j>=p-10:\n            y_pred[i][j]=(j+10-p)*0.05\n\nfor i,p in enumerate(scaler.inverse_transform(y_train)):\n    p+=99\n    for j in range(199):\n        if j>=p:\n            y_ans[i][j]=1.0\n\nprint(\"validation score:\",np.sum(np.power(y_pred-y_ans,2))/(199*(509762//22)))\n\n# The above calculates my validation score as to how accurate my model can predict the outcome of any riven rushing play out of a range of 199 plays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 0\nfor (test_df, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n    test_df = fe(test_df)\n    for c in test_df.columns:\n        if c in label_dict and test_df[c].dtype=='object' and c not in not_used and not pd.isnull(test_df[c]).any():\n            try:\n                test_df[c] = label_dict[c].transform(list(test_df[c].values))\n            except:\n                test_df[c] = [np.nan for i in range(22)]   \n    count=0\n    test_data = np.zeros((1,len(all_columns)))\n    for c in test_df.columns:\n        if c in not_used: continue\n        test_data[0][count] = test_df[c][index]\n        count+=1\n    for c in unique_columns:\n        for j in range(22):\n            test_data[0][count] = test_df[c][index + j]\n            count+=1        \n    y_pred = np.zeros(199)        \n    y_pred_p = np.sum(np.round(scaler.inverse_transform(\n        [model.predict(test_data)[0] for model in models])))/folds\n    y_pred_p += 99\n    for j in range(199):\n        if j>=y_pred_p+10:\n            y_pred[j]=1.0\n        elif j>=y_pred_p-10:\n            y_pred[j]=(j+10-y_pred_p)*0.05\n    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n    index += 22\nenv.write_submission_file()\n# The above code then finally predicts the outcome of running plays given 199 random unique situations. ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}