{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.callbacks import Callback\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport datetime\n\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n#print(train.shape)\n#train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x/15))\n    except:\n        return \"nan\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_features(df, deploy=False):\n    def new_X(x_coordinate, play_direction):\n        if play_direction == 'left':\n            return 120.0 - x_coordinate\n        else:\n            return x_coordinate\n\n    def new_line(rush_team, field_position, yardline):\n        if rush_team == field_position:\n            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n            return 10.0 + yardline\n        else:\n            # half the field plus the yards between midfield and the line of scrimmage\n            return 60.0 + (50 - yardline)\n\n    def new_orientation(angle, play_direction):\n        if play_direction == 'left':\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return new_angle\n        else:\n            return angle\n\n    def euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n\n        return np.sqrt(x_diff + y_diff)\n    \n    def distX(x1,x2):\n        return abs(x1 - x2)\n\n    def back_direction(orientation):\n        if orientation > 180.0:\n            return 1\n        else:\n            return 0\n\n    def update_yardline(df):\n        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n        return new_yardline\n\n    def update_orientation(df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n        return df\n\n    def back_features(df):\n        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n#         carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n#         carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n#         carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage']]\n        return carriers\n\n    def features_relative_to_back(df, carriers):\n        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n#         player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n#         player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field','min_dist','max_dist','mean_dist','std_dist']\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','min_dist','max_dist','mean_dist','std_dist']\n\n        return player_distance\n\n    def defense_features(df):\n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n#        attac = defense[defense['Team'] == defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n#        attac['def_dist_to_back'] = attac[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n        defense['distX'] = defense[['X','RusherX']].apply(lambda x: distX(x[0],x[1]), axis=1)\n#        defense['distY'] = defense[['Y','RusherY']].apply(lambda x: distX(x[0],x[1]), axis=1)\n        \n#         Boucle for pour trouver le min et sa position\n#         Signe de Ymin - Yrush\n#         Trouver dist_to_back min avec signe opposÃ©\n#         Calculer la distance entre ce joueur et rush\n#         Si plus proche tout en haut ou tout en bas mettre 0 ou max\n        \n        min2 = []\n        dist_12 = []\n        \n        for i in range(int(len(defense)/11)):\n            match = defense.iloc[i*11:(i+1)*11]\n            indexMin = match.index[match[\"def_dist_to_back\"] == min(match[\"def_dist_to_back\"])].tolist()[0]\n            deltaY = (match[\"Y\"][indexMin] - match[\"RusherY\"][indexMin])>0\n            if match[((match[\"RusherY\"] - match[\"Y\"]) > 0) == deltaY][\"def_dist_to_back\"].tolist() == []:\n                if deltaY:\n                    min2.append(0)\n                    dist_12.append(match[\"Y\"][indexMin])\n                else:\n                    min2.append(53.3)\n                    dist_12.append(abs(53.3 - match[\"Y\"][indexMin]))\n            else:    \n                min2.append(min(match[((match[\"RusherY\"] - match[\"Y\"]) > 0) == deltaY][\"def_dist_to_back\"]))\n                indexMin2 = match.index[match[\"def_dist_to_back\"] == min2[i]].tolist()[0]\n                dist_12.append(euclidean_distance(match[\"X\"][indexMin],match[\"Y\"][indexMin],match[\"X\"][indexMin2],match[\"Y\"][indexMin2]))\n\n#        attac = attac.groupby(['GameId','PlayId'])\\\n#                         .agg({'def_dist_to_back':['min','mean','std']})\\\n#                         .reset_index()\n#        attac.columns = ['GameId','PlayId','att_min_dist','att_mean_dist','att_std_dist']\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','mean','std'],'distX':['min','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_mean_dist','def_std_dist','minX','meanX','stdX']\n#        defense = pd.merge(defense, attac, on=['GameId','PlayId'],how='inner')\n        return (defense, min2, dist_12)\n\n    def static_features(df):\n        \n        \n        add_new_feas = []\n\n        ## Height\n        #df['PlayerHeight_dense'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n        \n        #add_new_feas.append('PlayerHeight_dense')\n\n        ## Time\n        #df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n        #df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n        #df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n        #df['PlayerBirthDate'] =df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n        ## Age\n        #seconds_in_year = 60*60*24*365.25\n        #df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n        #add_new_feas.append('PlayerAge')\n\n        ## WindSpeed\n        #df['WindSpeed_ob'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n        #df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n        #df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n        #df['WindSpeed_dense'] = df['WindSpeed_ob'].apply(strtofloat)\n        #add_new_feas.append('WindSpeed_dense')\n\n        ## Weather\n        #df['GameWeather_process'] = df['GameWeather'].str.lower()\n        #df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n        #df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n        #df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n        #df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n        #df['GameWeather_dense'] = df['GameWeather_process'].apply(map_weather)\n        #add_new_feas.append('GameWeather_dense')\n\n        ## Orientation and Dir\n        df[\"Orientation_ob\"] = df[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n        df[\"Dir_ob\"] = df[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n        df[\"Orientation_sin\"] = df[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Orientation_cos\"] = df[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        df[\"Dir_sin\"] = df[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Dir_cos\"] = df[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        add_new_feas.append(\"Dir_sin\")\n        add_new_feas.append(\"Dir_cos\")\n\n        ## diff Score\n        df[\"diffScoreBeforePlay\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n        add_new_feas.append(\"diffScoreBeforePlay\")\n        \n    \n    \n#         static_features = df[df['NflId'] == df['NflIdRusher']][add_new_feas+['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n#                                                             'YardLine','Quarter','Down','Distance','DefendersInTheBox','OffenseFormation']].drop_duplicates()\n        static_features = df[df['NflId'] == df['NflIdRusher']][add_new_feas+['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n\n#         static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n        static_features.fillna(-999,inplace=True)\n#         for i in add_new_feas:\n#             static_features[i] = static_features[i].fillna(np.mean(static_features[i]))\n            \n\n        return static_features\n\n    def combine_features(relative_to_back, defense, static, min2, dist_12, deploy=deploy):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n\n        if not deploy:\n            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n        df['min2'] = min2\n        df['dist_12'] = dist_12\n        \n        return df\n    \n    yardline = update_yardline(df)\n    df = update_orientation(df, yardline)\n    back_feats = back_features(df)\n    rel_back = features_relative_to_back(df, back_feats)\n    def_feats, min2, dist_12 = defense_features(df)\n    static_feats = static_features(df)\n    basetable = combine_features(rel_back, def_feats, static_feats, min2, dist_12, deploy=deploy)\n    \n    return basetable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# moy7 = np.mean(train[train['Season']<2018]['S'])\n# std7 = np.std(train[train['Season']<2018]['S'])\n# moy8 = np.mean(train[train['Season']>2017]['S'])\n# std8 = np.std(train[train['Season']>2017]['S'])\n# train['S'] = train['S']*moy7/moy8\n# train['A'] = train['A']*moy7/moy8\n#train = train[train['Season']>2017]\n# plt.hist(train[train['Season']<2018][\"Yards\"],50)\n# plt.hist(train[train['Season']>2017][\"Yards\"],50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#train = preprocess(train)\ntrain = create_features(train, False)\n\n## OffenseFormation    \n# off_form = train['OffenseFormation'].unique()\n# train = pd.concat([train.drop(['OffenseFormation'], axis=1), pd.get_dummies(train['OffenseFormation'], prefix='Formation')], axis=1)\n# dummy_col = train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.copy()\nyards = X.Yards\n\ndef return_step(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\ny = np.vstack(yards.apply(return_step).values)\n\nX.drop(['GameId','PlayId','Yards','min_dist','max_dist','mean_dist','std_dist','Quarter','Down','Dir', 'Dir_cos','X','Dis'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2 = np.zeros((yards.shape[0], 199))\nfor idx, target in enumerate(list(yards)):\n    y2[idx][99 + target] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Xc = train.copy()\n#Xc.drop(['GameId','PlayId','Quarter','Down','X','Dir', 'Dir_cos'], axis=1, inplace=True)\n#sns.set(rc={'figure.figsize':(30, 30)})\n#corr = Xc.corr()\n#plt.figure() \n#ax = sns.heatmap(corr, linewidths=.5, annot=True, cmap=\"YlGnBu\", fmt='.1g')\n#plt.savefig('corr_heatmap.png')\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_newFE = []\n#for i in range(len(train_y)):\n#    train_newFE.append(min(np.sqrt(((train_dense_players[i,:,0]-train_dense_players[i,21,0])**2+(train_dense_players[i,:,1]-train_dense_players[i,21,1])**2)[0:20])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nclass MultiLGBMClassifier():\n    def __init__(self, resolution, params):\n        ## smoothing size\n        self.resolution = resolution\n        ## initiarize models\n        self.models = [LGBMClassifier(**params) for _ in range(resolution)]\n        \n    def fit(self, x, y):\n        self.classes_list = []\n        for k in tqdm_notebook(range(self.resolution)):\n            ## train each model\n            self.models[k].fit(x, (y + k) // self.resolution)\n            ## (0,1,2,3,4,5,6,7,8,9) -> (0,0,0,0,0,1,1,1,1,1) -> (0,5)\n            classes = np.sort(list(set((y + k) // self.resolution))) * self.resolution - k\n            classes = np.append(classes, 999)\n            self.classes_list.append(classes)\n            \n    def predict(self, x):\n        pred199_list = []\n        for k in range(self.resolution):\n            preds = self.models[k].predict_proba(x)\n            classes = self.classes_list[k]\n            pred199s = self.get_pred199(preds, classes)\n            pred199_list.append(pred199s)\n        self.pred199_list = pred199_list\n        pred199_ens = np.mean(np.stack(pred199_list), axis = 0)\n        return pred199_ens\n    \n    def _get_pred199(self, p, classes):\n        ## categorical prediction -> predicted distribution whose length is 199\n        pred199 = np.zeros(199)\n        for k in range(len(p)):\n            pred199[classes[k] + 99 : classes[k+1] + 99] = p[k]\n        return pred199\n\n    def get_pred199(self, preds, classes):\n        pred199s = []\n        for p in preds:\n            pred199 = np.cumsum(self._get_pred199(p, classes))\n            pred199 = pred199/np.max(pred199)\n            pred199s.append(pred199)\n        return np.vstack(pred199s)\n    \nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\nfrom keras.models import Model\nimport keras.backend as K\nimport re\nfrom keras.losses import binary_crossentropy\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport codecs\n\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom sklearn.metrics import f1_score\n\n\nclass CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n        print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s\n            \ndef get_model(x_tr,y_tr,x_val,y_val):\n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dense(1024, input_dim=X.shape[1], activation='relu')(inp)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp,out)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n    #add lookahead\n#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n#     lookahead.inject(model) # add into model\n\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=10)\n\n    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=1, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]/bsz\n    \n\n\n    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=1)\n    model.load_weights(\"best_model.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n    crps = np.round(val_s, 6)\n\n    return model,crps\n\ndef predictK(x_te):\n    model_num = len(models)\n    for k,m in enumerate(models):\n        if k==0:\n            y_pred = m.predict(x_te,batch_size=1024)\n        else:\n            y_pred+=m.predict(x_te,batch_size=1024)\n            \n    y_pred = y_pred / model_num\n    \n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'lambda_l1': 0.001, 'lambda_l2': 0.001,\n 'num_leaves': 30, 'max_depth': 5, # 2**6 = 64 - Let's set 50 to prevent overfitting\n 'feature_fraction': 0.8,\n 'subsample': 0.8, 'min_child_samples': 10,\n 'learning_rate': 0.011,\n 'num_iterations': 700, 'random_state': 42}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nimport time\nlosses = []\nmodels = []\n\nmodels2 = []\ncrps_csv = []\n\nlosses3 = []\n\n#s_time = time.time()\nfor k in range(1):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(y)):\n        print(\"-----------\")\n        print(\"-----------\")\n        model = MultiLGBMClassifier(resolution = 3, params = params)\n        model.fit(X[tr_inds], yards.values[tr_inds])\n        preds = model.predict(X[val_inds])\n        loss = np.mean((y[val_inds] - preds) ** 2)\n        models.append(model)\n        losses.append(loss)\n        model2,crps = get_model(X[tr_inds],y2[tr_inds],X[val_inds],y2[val_inds])\n        models2.append(model2)\n        crps_csv.append(crps)        \n        preds3 = np.cumsum(model2.predict(X[val_inds]), axis=1)\n        loss3 = np.mean((y[val_inds] - (preds + preds3)/2) ** 2)\n        losses3.append(loss3)\n        print(k_fold, loss)\n        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n        print(loss3)\n        \nprint(\"-------\")\nprint(losses)\nprint(np.mean(losses))\nprint(\"mean crps is %f\"%np.mean(crps_csv))\nprint(losses3)\nprint(np.mean(losses3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = 0\nnum_model = 0\nfor model in models:\n    for m in model.models:\n        feature_importances += m.booster_.feature_importance(\"gain\")\n        num_model += 1\n\nfeature_importances /= num_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['GameId','PlayId','Yards','min_dist','max_dist','mean_dist','std_dist','Quarter','Down','Dir', 'Dir_cos','X','Dis'], axis=1, inplace=True)\nfeature_names = list(train.columns)\nfeature_importance_df = pd.DataFrame(np.vstack([feature_importances, feature_names]).T, columns = [\"importance\", \"name\"])\nfeature_importance_df[\"importance\"] = feature_importance_df[\"importance\"].astype(np.float32)\nfeature_importance_df = feature_importance_df.groupby(\"name\").agg(\"mean\").reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8, 18))\nsns.barplot(data = feature_importance_df.sort_values(by = \"importance\", ascending = False).head(50), x = \"importance\", y = \"name\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## bad features\nlist(feature_importance_df[feature_importance_df[\"importance\"] < np.quantile(feature_importance_df[\"importance\"], 0.3)][\"name\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(test, sample, env, model):\n    outcomes = test[['GameId','PlayId']].drop_duplicates()\n    test = create_features(test, True)\n#     test['OffenseFormation'] = test['OffenseFormation'].apply(lambda x: x if x in off_form else np.nan)\n#     test = pd.concat([test.drop(['OffenseFormation'], axis=1), pd.get_dummies(test['OffenseFormation'], prefix='Formation')], axis=1)\n#     missing_cols = set( dummy_col ) - set( test.columns ) - set('Yards')\n#     for c in missing_cols:\n#         test[c] = 0\n#     test = test[dummy_col]\n    test.drop(['GameId','PlayId','min_dist','max_dist','mean_dist','std_dist','Quarter','Down','X','Dir', 'Dir_cos','Dis'], axis=1, inplace=True)\n    test2 = scaler.transform(test)\n    \n #   test_newFE = []\n #   for i in range(len(test_dense_game)):\n #       test_newFE.append(min(np.sqrt(((test_dense_players[i,:,0]-test_dense_players[i,21,0])**2+(test_dense_players[i,:,1]-test_dense_players[i,21,1])**2)[0:20])))\n      \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test2)\n        pred += _pred\n    pred /= len(models)\n    \n    pred2 = 0\n    for model2 in models2:\n        _pred = np.cumsum(model2.predict(test2), axis=1)\n        pred2 += _pred\n    pred2 /= len(models2)\n    \n    pred3 = (pred + pred2)/2\n    \n    predF = np.clip(pred3, 0, 1)\n    env.predict(pd.DataFrame(data=predF,columns=sample.columns))\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()\npreds = []\nfor test, sample in tqdm_notebook(env.iter_test()):\n    pred = make_pred(test, sample, env, models)\n    preds.append(pred)\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.vstack(preds)\n## check whether prediction is submittable\nprint(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\nprint(np.mean(preds > 1) == 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}