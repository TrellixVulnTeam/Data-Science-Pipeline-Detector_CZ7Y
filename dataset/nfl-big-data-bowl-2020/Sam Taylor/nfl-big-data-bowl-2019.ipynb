{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import re\nimport math\nimport time\nimport codecs\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom pathlib import Path\nfrom functools import wraps\nfrom datetime import datetime\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nfrom hyperopt import Trials, STATUS_OK, tpe\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.base import TransformerMixin\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.neighbors import KernelDensity\n\nimport keras.backend as K\nfrom keras import regularizers\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda, BatchNormalization\nfrom keras.models import Model\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom sklearn.metrics import f1_score\nfrom tensorflow.keras import regularizers\nfrom sklearn.model_selection import train_test_split, KFold\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"TRAIN_DATA_PATH = Path('../input/nfl-big-data-bowl-2020/train.csv')\n#TRAIN_DATA_PATH = Path('/Users/sam.taylor/Desktop/train.csv')\nSEED = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv(TRAIN_DATA_PATH, dtype={'WindSpeed': 'object'})\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.loc[509755:509769, ['WindSpeed', 'WindDirection']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"replacements = [\n    ('LSU', 'Louisiana State'),\n    ('Southern California', 'USC'),\n    ('Miami (Fla.)', 'Miami'),\n    ('Miami, O.', 'Miami OH'),\n    ('Miami (Ohio)', 'Miami OH'),\n    ('Texas-El Paso', 'Texas')\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"position_groups = {\n    'CB' : 'DB',\n    'FS' : 'DB',\n    'SAF' : 'DB',\n    'S' : 'DB',\n    'SS' : 'DB',\n    'DB' : 'DB',\n    'OLB' : 'LB',\n    'ILB' : 'LB',\n    'MLB' : 'LB',\n    'LB' : 'LB',\n    'DE' : 'DL',\n    'DT' : 'DL',\n    'NT' : 'DL',\n    'DL' : 'DL',\n    'G' : 'OL',\n    'OG' : 'OL',\n    'T' : 'OL',\n    'OT' : 'OL',\n    'C' : 'OL',\n    'RB' : 'RB',\n    'FB' : 'RB',\n    'HB' : 'RB',\n    'WR' : 'SK',\n    'QB' : 'SK',\n    'TE' : 'SK'\n}\nposession_positions = {\n    'DB': 0,\n    'LB': 0,\n    'DL': 0,\n    'OL': 1,\n    'RB': 1,\n    'SK': 1\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"COLS_TO_DROP = [\n    'Position', 'IsRusher', 'WindDirection', 'WindSpeed'\n]\nCATEGORICAL_VARS = [\n    'DisplayName', 'PlayerCollegeName', 'Location',\n    'OffensePersonnel', 'Stadium', 'DefensePersonnel',\n    'HomeTeamAbbr', 'VisitorTeamAbbr', 'FieldPosition', 'PossessionTeam',\n    'StadiumType', 'Position', 'Turf', 'PlayerHeight', 'OffenseFormation',\n    'JerseyNumber', 'NflId'\n]\nTRANSFORMED_CATEGORICALS = [\n    'OffensePersonnel', 'DefensePersonnel', 'PlayerHeight',\n    'NflId', 'Turf', 'FieldPosition', 'PlayerCollegeName', 'JerseyNumber',\n    'PossessionTeam', 'GameWeather'\n]\nVARS_TO_ONE_HOT = [var for var in CATEGORICAL_VARS\n                   if var not in TRANSFORMED_CATEGORICALS\n                   and var not in COLS_TO_DROP]\nMAX_CARDINALITY = 24","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cardinalities = train[VARS_TO_ONE_HOT].nunique().sort_values(ascending=False)\ncardinalities","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def shoelace(x, y):\n    return 0.5 * np.abs(np.dot(x, np.roll(y,1))-np.dot(y,np.roll(x,1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def func_timer(fn):\n    @wraps(fn)\n    def timer(*args, **kwargs):\n        print('\\n' + fn.__name__.upper())\n        start_time = datetime.now()\n        res = fn(*args, **kwargs)\n        end_time = datetime.now()\n        time_taken = end_time - start_time\n        time_taken = time_taken.total_seconds() / 60\n        print('{} time taken: {:.2f} mins'.format(fn.__name__, time_taken))\n        return res\n    return timer\n\ndef transformation_check(fn):\n    @wraps(fn)\n    def checker(*args, **kwargs):\n        print(' -- {} -- '.format(fn.__name__))\n        res = fn(*args, **kwargs)\n        end_shape = res.shape\n        null_prc = 100 * (res.isnull().sum() / len(res)).mean()\n        print('\\tshape = {}'.format(end_shape))\n        print('\\tnull % = {:.2f}'.format(null_prc))\n        return res\n    return checker","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class Preprocessor(TransformerMixin):\n    def __init__(self, one_hot_vars, max_cardinality, cols_to_drop=[]):\n        super().__init__()\n        self.target = 'Yards'\n        self.one_hot_vars = one_hot_vars\n        self.max_cardinality = max_cardinality\n        self.cols_to_drop = cols_to_drop\n        self.player_cols = []\n        self.one_hot_encoder = OneHotEncoder(\n            sparse=False, \n            dtype=np.int, \n            handle_unknown='ignore'\n        )\n        self.college_encoding = {}\n        self.jersey_encoding = {}\n        self.map_abbr = None\n\n    @func_timer\n    def initial_cleaning(self, X):\n        \"\"\" Transformative steps that don't need any 'fitted'\n        objects. Also any thing that needs to be done before anything\n        is fit \"\"\"\n        X = self._correct_team_abbreviations(X)\n        X = self._encode_player_height(X)\n        X = self._process_time_variables(X)\n        X = self._fix_wind_variables(X)\n        X = self._fix_stadium_type_and_turf(X)\n        X = self._map_college_and_pos(X)\n        X = self._encode_personnel(X)\n        X = self._normalise_positional_data(X)\n        X = self._calc_voronoi(X)\n        X = self._misc_engineering(X)\n        X.drop(columns=self.cols_to_drop, inplace=True)\n        return X\n\n    @func_timer\n    def fit(self, X, y=None):\n        # Get player related columns\n        self._get_player_cols(X)\n\n        # Fit one hot encoder\n        cardinalities = X[self.one_hot_vars].nunique().to_dict()\n        one_hot_vars = [var for var in self.one_hot_vars\n                        if cardinalities[var] <= self.max_cardinality]\n        self.one_hot_encoder.fit(X[one_hot_vars].fillna('unknown'))\n        self.oh_cols_to_drop = [var for var in self.one_hot_vars\n                                if var not in one_hot_vars]\n        self.one_hot_vars = one_hot_vars\n        \n        # Fit college name and jersey number 'encoder's\n        self.college_encoding = \\\n            X.groupby('PlayerCollegeName')['PlayId'].count().to_dict()\n        self.jersey_encoding = \\\n            X.groupby('JerseyNumber')['PlayId'].count().to_dict()\n        \n        return self\n\n    @func_timer\n    def transform(self, X):\n        X['PlayerCollegeName'] = X['PlayerCollegeName'].map(self.college_encoding)\n        X['PlayerCollegeNameRusher'] = \\\n            X['PlayerCollegeNameRusher'].map(self.college_encoding)\n        X['JerseyNumber'] = X['JerseyNumber'].map(self.jersey_encoding)\n        X = self._apply_one_hot_encoder(X)\n        X = self._flatten_player_vars(X)\n#         X = self._previous_play_data(X)\n        return X\n\n    @transformation_check\n    def _correct_team_abbreviations(self, X):\n        if self.map_abbr is None:\n            self.map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n            for abb in X['PossessionTeam'].unique():\n                self.map_abbr[abb] = abb\n\n        X['PossessionTeam'] = X['PossessionTeam'].map(self.map_abbr)\n        X['HomeTeamAbbr'] = X['HomeTeamAbbr'].map(self.map_abbr)\n        X['VisitorTeamAbbr'] = X['VisitorTeamAbbr'].map(self.map_abbr)\n        return X\n\n    @transformation_check\n    def _encode_player_height(self, X):\n        def string_to_inches(x):\n            feet, inch = x.split('-')\n            return int(inch) + 12 * int(feet)\n\n        X['PlayerHeight'] = X['PlayerHeight'].apply(string_to_inches)\n        return X\n\n    @transformation_check\n    def _process_time_variables(self, X):\n        for col in ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate']:\n            X[col] = pd.to_datetime(X[col], utc=True, infer_datetime_format=True)\n        X['TimeUntilHandoff'] = X['TimeSnap'] - X['TimeHandoff']\n        X['TimeUntilHandoff'] = X['TimeUntilHandoff'].dt.total_seconds()\n\n        X['PlayerAge'] = X['TimeSnap'] - X['PlayerBirthDate']\n        X['PlayerAge'] = X['PlayerAge'].dt.total_seconds() / 31556952\n\n        X['GameClock'] = 360 * X['GameClock'].str[:2].astype(int) \\\n                         + 60 * X['GameClock'].str[3:5].astype(int) \\\n                         + X['GameClock'].str[6:8].astype(int)\n        \n        X['SecondsRemaining'] = 0\n        X.loc[X['Quarter'] == 1, 'SecondsRemaining'] = 45 * 60 + X['GameClock']\n        X.loc[X['Quarter'] == 2, 'SecondsRemaining'] = 30 * 60 + X['GameClock']\n        X.loc[X['Quarter'] == 3, 'SecondsRemaining'] = 15 * 60 + X['GameClock']\n        X.loc[X['Quarter'] == 4, 'SecondsRemaining'] = 0 * 60 + X['GameClock']\n        X.loc[X['Quarter'] == 5, 'SecondsRemaining'] = 0 * 60 + X['GameClock']\n\n        X.drop(columns=['TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], inplace=True)\n        return X\n\n    @transformation_check\n    def _fix_wind_variables(self, X):\n        def average_ranges(x):\n            x = str(x)\n            if '-' in x:\n                low, high = x.split('-')\n                return str((int(high) + int(low)) / 2)\n            elif ' gusts up to ' in x:\n                low, high = x.split(' gusts up to ')\n                return str((int(high) + int(low)) / 2)\n            else:\n                return x\n\n        def coerce_to_int(x):\n            try:\n                x = int(x)\n            except:\n                x = np.nan\n            return x\n        \n        def map_weather(txt):\n            ans = 1\n            if pd.isna(txt):\n                return 0\n            if 'partly' in txt:\n                ans*=0.5\n            if 'climate controlled' in txt or 'indoor' in txt:\n                return ans*3\n            if 'sunny' in txt or 'sun' in txt:\n                return ans*2\n            if 'clear' in txt:\n                return ans\n            if 'cloudy' in txt:\n                return -ans\n            if 'rain' in txt or 'rainy' in txt:\n                return -2*ans\n            if 'snow' in txt:\n                return -3*ans\n            return 0\n\n        X['WindSpeed'] = X['WindSpeed'].str.lower().str.replace('mph', '')\n        X['WindSpeed'] = X['WindSpeed'].str.strip()\n        X['WindSpeed'] = X['WindSpeed'].apply(average_ranges)\n        X['WindSpeed'] = X['WindSpeed'].apply(coerce_to_int)\n        \n        X['GameWeather'] = X['GameWeather'].apply(map_weather)\n\n        acceptable_directions = [\n            'NE', 'SW', 'S', 'NW', 'WSW', 'SE', 'W', 'N', 'NNE', 'WNW', 'SSW',\n            'NNW', 'SSE', 'E', 'ENE', 'ESE'\n        ]\n        X['WindDirection'] = X['WindDirection'].str.upper()\n        X['WindDirection'] = X['WindDirection'].str.replace('FROM ', '').str.replace('-', '')\n        X.loc[~X['WindDirection'].isin(acceptable_directions), 'WindDirection'] = np.nan\n        return X\n    \n    @transformation_check\n    def _fix_stadium_type_and_turf(self, X):\n        stadium_type_map = {\n            'Outdoor': 'Outdoor',\n            'Outdoors': 'Outdoor',\n            'Indoors': 'Indoor',\n            'Dome': 'Indoor',\n            'Indoor': 'Indoor',\n            'Retractable Roof': 'Retr Open',\n            'Open': 'Retr Open',\n            'Retr. Roof-Closed': 'Retr Closed',\n            'Retr. Roof - Closed': 'Retr Closed',\n            'Domed, closed': 'Retr Closed',\n            'Domed, open': 'Retr Open',\n            'Closed Dome': 'Retr Closed',\n            'Dome, closed': 'Retr Closed',\n            'Domed': 'Indoor',\n            'Oudoor': 'Outdoor',\n            'Indoor, Roof Closed': 'Retr Closed',\n            'Retr. Roof Closed': 'Retr Closed',\n            'Retr. Roof-Open': 'Retr Open',\n            'Bowl': 'Outdoor',\n            'Outddors': 'Outdoor',\n            'Heinz Field': 'Outdoor',\n            'Outdoor Retr Roof-Open': 'Retr Open',\n            'Retr. Roof - Open': 'Retr Open',\n            'Indoor, Open Roof': 'Retr Open',\n            'Ourdoor': 'Outdoor',\n            'Outdor': 'Outdoor',\n            'Outside': 'Outdoor',\n            'Cloudy': 'Outdoor',\n            'Domed, Open': 'Retr Open'\n        }\n        X['StadiumType'] = X['StadiumType'].map(stadium_type_map)\n        \n        grass_labels = ['grass', 'natural grass', 'natural', 'naturall grass']\n        X['Turf'] = np.where(X['Turf'].str.lower().isin(grass_labels), 1, 0)\n        \n        def get_city(x):\n            x = x.replace('e.', 'east').replace('.', ',')\n            return x.split(',')[0].strip().lower()\n        X['Location'] = X['Location'].apply(get_city)\n        \n        return X\n    \n    @transformation_check\n    def _map_college_and_pos(self, X):\n        for replacement in replacements:\n            X['PlayerCollegeName'] = X['PlayerCollegeName']\\\n                .replace(replacement[0], replacement[1])\n#         X['CollegeConference'] = X['PlayerCollegeName'].map(college_to_conf)\n#         X['CollegeConference'].fillna('BinJuice', inplace=True)\n#         if 'CollegeConference' not in self.one_hot_vars:\n#             self.one_hot_vars += ['CollegeConference']\n        \n        X['PositionGroup'] = X['Position'].map(position_groups)\n        X['InPossesion'] = X['PositionGroup'].map(posession_positions)\n        return X\n\n    @transformation_check\n    def _encode_personnel(self, X):\n\n        def count_positions(x, offensive):\n            offensive_counts = {'DB': 0, 'DL': 0, 'LB': 0, 'OL': 0, 'QB': 0, 'RB': 0, 'TE': 0, 'WR': 0}\n            defensive_counts = {'DB': 0, 'DL': 0, 'LB': 0, 'OL': 0}\n            if offensive:\n                val_counts=offensive_counts\n            else:\n                val_counts=defensive_counts\n\n            if isinstance(x, str):\n                for position_val in x.split(','):\n                    val, pos = position_val.strip().split(' ')\n                    if pos in val_counts:\n                        val_counts[pos] += int(val)\n            return val_counts\n        \n        X['OffensePersonnel'] = X['OffensePersonnel'] \\\n            .apply(count_positions, offensive=True)\n        off_personnel_df = pd.DataFrame().from_records(X['OffensePersonnel'].values)\n        off_personnel_df.index = X.index\n        off_personnel_df.columns = ['NOffensive' + col for col in off_personnel_df.columns]\n\n        X['DefensePersonnel'] = X['DefensePersonnel'] \\\n            .apply(count_positions, offensive=False)\n        def_personnel_df = pd.DataFrame().from_records(X['DefensePersonnel'].values)\n        def_personnel_df.index = X.index\n        def_personnel_df.columns = ['NDefensive' + col for col in def_personnel_df.columns]\n\n        X.drop(columns=['OffensePersonnel', 'DefensePersonnel'], inplace=True)\n        X = pd.concat([X, off_personnel_df, def_personnel_df], axis=1)\n        return X\n    \n    @transformation_check\n    def _normalise_positional_data(self, X):\n        X['IsLeftDirection'] = X['PlayDirection'] == 'left'\n        \n        X['PossesionInOwnHalf'] = X['PossessionTeam'] == X['FieldPosition']\n        possession_in_own_half = X.groupby(['GameId', 'PlayId'])['PossesionInOwnHalf'].max().reset_index()\n        X = X.drop(columns='PossesionInOwnHalf')\\\n            .merge(possession_in_own_half, on=['GameId', 'PlayId'])\n        \n        X['DistToEndZone'] = X['YardLine']\n        X.loc[X['PossesionInOwnHalf'], 'DistToEndZone'] = 50 + (50 - X['YardLine'])\n        X.loc[X['YardLine'] == 50, 'DistToEndZone'] = 50\n        X['YardLineStd'] = 100 - X['DistToEndZone']\n        \n        X['XStd'] = X['X']\n        X.loc[X['IsLeftDirection'], 'XStd'] = 120 - X.loc[X['IsLeftDirection'], 'X']\n        \n        X['YStd'] = X['Y']\n        X.loc[X['IsLeftDirection'], 'YStd'] = 160 / 3 - X.loc[X['IsLeftDirection'], 'Y']\n        \n        X['PlayerDistToEndZone'] = 100 - (X['XStd'] - 10)\n        \n        X['DirRad'] = np.mod(90 - X['Dir'], 360) * math.pi / 180.0\n        X['DirStd'] = X['DirRad']\n        X.loc[X['IsLeftDirection'], 'DirStd'] = \\\n            np.mod(np.pi + X.loc[X['IsLeftDirection'], 'DirRad'], 2*np.pi)\n        \n        # Fix the problem with orientation over the years\n        X['OrientationRad'] = np.mod(X['Orientation'], 360) * math.pi / 180.0\n        X.loc[X['Season'] >= 2018, 'OrientationRad'] \\\n            = np.mod(X.loc[X['Season'] >= 2018, 'Orientation'] - 90, 360) * math.pi / 180.0\n        \n        X['OrientationStd'] = X['OrientationRad']\n        X.loc[X['IsLeftDirection'], 'OrientationStd'] = \\\n            np.mod(np.pi + X.loc[X['IsLeftDirection'], 'OrientationRad'], 2 * np.pi)\n        X.drop(columns=['OrientationRad'], inplace=True)\n        \n        X['IsLeftDirection'] = (X['IsLeftDirection']).astype(int)\n        X['IsRusher'] = (X['NflId'] == X['NflIdRusher']).astype(int)\n        return X\n    \n    @transformation_check\n    def _calc_voronoi(self, X):\n        max_voronoi = 120 * 53.3\n        X['VoronoiArea'] = 0\n        X['VoronoiAreaNoOffence'] = 0\n        for play_id in X['PlayId'].unique():\n            play = X.loc[X['PlayId'] == play_id].copy()\n\n            # Only consider space 5 yards behind the player furthest back\n            x_cut_off = play['XStd'].min() - 5\n\n            # Also calculate the rusher's voronoi excluding team mates\n            no_offence_play = play[play['IsRusher'].astype(bool) |\n                                   ~play['InPossesion'].astype(bool)]\n\n            def mirror_boundary(xy):\n                xy = xy.values\n                n_points = xy.shape[0]\n                xy1 = xy.copy()\n                xy1[:,1] = -xy[:,1]\n                xy2 = xy.copy()\n                xy2[:,1] = 320/3 - xy[:,1]\n                xy3 = xy.copy()\n                xy3[:,0] = 2 * x_cut_off - xy[:,0]\n                xy4 = xy.copy()\n                xy4[:,0] = 220 - xy[:,0]\n                return np.concatenate((xy, xy1, xy2, xy3, xy4), axis=0), n_points\n\n            # Get voronoi\n            xy, n = mirror_boundary(play[['XStd', 'YStd']])\n            vor = Voronoi(xy)\n\n            no_off_xy, _ = mirror_boundary(no_offence_play[['XStd', 'YStd']])\n            no_off_vor = Voronoi(no_off_xy)\n\n            # Calculate space area\n            areas = np.zeros([play.shape[0], ])\n            for i in range(n):\n                player_point = vor.point_region[i]\n                vertices = vor.vertices[vor.regions[player_point]]\n                areas[i] = shoelace(vertices[:, 0], vertices[:, 1])\n\n            rusher_index = np.argmax(no_offence_play['IsRusher'].values)\n            rusher_index_in_df = no_offence_play.index.values[rusher_index]\n            rusher_region = no_off_vor.point_region[rusher_index]\n            rusher_vertex_index = no_off_vor.regions[rusher_region]\n            rusher_vertices = no_off_vor.vertices[rusher_vertex_index]\n            rusher_area = shoelace(rusher_vertices[:, 0], rusher_vertices[:, 1])\n\n            # Assign to main df\n            X.loc[play.index, 'VoronoiArea'] = areas\n            X.loc[rusher_index_in_df, 'VoronoiAreaNoOffence'] = min(rusher_area, max_voronoi)\n            \n        X.loc[X['VoronoiArea'] > max_voronoi, 'VoronoiArea'] = max_voronoi\n        return X\n\n    @transformation_check\n    def _misc_engineering(self, X):\n        X['ScoreDiff'] = X['HomeScoreBeforePlay'] - X['VisitorScoreBeforePlay']\n        # Set binary variables\n        X['IsAwayTeam'] = (X['Team'] == 'away').astype(int)\n        X['IsInAwayEnd'] = (X['FieldPosition'] == X['VisitorTeamAbbr']).astype(int)\n        X['HomePossesion'] = (X['PossessionTeam'] == X['HomeTeamAbbr']).astype(int)\n        X['AwayInPosession'] = (X['InPossesion'] == X['IsAwayTeam']).astype(int)\n        # Directional features\n        X['SX'] = X['S'] * np.cos(X['DirStd'])\n        X['SY'] = X['S'] * np.sin(X['DirStd'])\n        X['AX'] = X['A'] * np.cos(X['DirStd'])\n        X['AY'] = X['A'] * np.sin(X['DirStd'])\n        X['OrientationCos'] = X['OrientationStd'] * np.cos(X['DirStd'])\n        X['OrientationSin'] = X['OrientationStd'] * np.sin(X['DirStd'])\n        # Closeness to scrimmage line\n        X['XToScrimmage'] = X['YardLineStd'] - (X['XStd'] - 10)\n        \n        # Get Rusher features\n        rusher_pos = X.loc[\n            X['IsRusher'] == 1, \n            ['XStd', 'YStd', 'DirStd', 'S', 'SX', 'SY', 'A', 'AX', 'AY', \n             'Position', 'GameId', 'PlayId', 'PlayerCollegeName', 'Dis',\n             'XToScrimmage', 'PlayerDistToEndZone', 'OrientationStd', 'OrientationCos',\n             'OrientationSin', 'VoronoiArea', 'VoronoiAreaNoOffence']\n        ]\n        X = X.merge(rusher_pos, on=['GameId', 'PlayId'], suffixes=['', 'Rusher'])\n        if 'PositionRusher' not in self.one_hot_vars:\n            self.one_hot_vars += ['PositionRusher']\n        \n        # Relationship of other players to rusher\n        X['XFromRusher'] = abs(X['XStd'] - X['XStdRusher'])\n        X['YFromRusher'] = abs(X['YStd'] - X['YStdRusher'])\n        X['DistFromRusher'] = np.sqrt(np.square(X['XFromRusher']) \n                                      + np.square(X['YFromRusher'])) \n        \n        X['TimeToRusher'] = X['DistFromRusher'] / X['S']\n        X.loc[np.isinf(X['TimeToRusher']), 'TimeToRusher'] = 1000\n        \n        # Force and momentum\n        X['Force'] = X['PlayerWeight'] * X['A']\n        X['Momentum'] = X['PlayerWeight'] * X['S']\n        \n        cols_to_drop = ['NflId', 'NflIdRusher', 'Team', 'PlayDirection', \n                        'FieldPosition', 'PossessionTeam', 'OrientationCos',\n                        'OrientationSin', 'VoronoiAreaNoOffence', \n                        'PlayerDistToEndZone']\n        X.drop(columns=cols_to_drop, inplace=True)\n        return X\n    \n    @transformation_check\n    def _apply_one_hot_encoder(self, X):\n        col_names = []\n        print('\\tdropping columns: {} for having cardinality > {}'\n              .format(' '.join(self.oh_cols_to_drop), self.max_cardinality))\n        X.drop(columns=self.oh_cols_to_drop, inplace=True)\n        self.player_cols = [col for col in self.player_cols\n                            if col not in self.oh_cols_to_drop]\n        print('\\tone hot encoding columns: {}'.format(' '.join(self.one_hot_vars)))\n        X_1h = self.one_hot_encoder.transform(X[self.one_hot_vars].fillna('unknown'))\n\n        for i, col in enumerate(self.one_hot_vars):\n            new_var_names = \\\n                [col + '_' + val for val in self.one_hot_encoder.categories_[i]]\n            col_names += new_var_names\n            if col in self.player_cols:\n                self.player_cols.remove(col)\n                self.player_cols += new_var_names\n\n        X_1h = pd.DataFrame(data=X_1h, index=X.index, columns=col_names)\n        X = pd.concat([X.drop(columns=self.one_hot_vars), X_1h], axis=1)\n        return X\n\n    @transformation_check\n    def _flatten_player_vars(self, X):\n        \n        # Cols to group\n        college_mask = ['CollegeConference' in col for col in X.columns]\n        college_cols = X.columns[college_mask]\n        college_agg = X.groupby(['GameId', 'PlayId'])[college_cols].sum()\n        X.drop(columns=college_cols, inplace=True)\n        \n        mechanics_cols = [\n            'X', 'XStd', 'Y', 'YStd', 'A', 'S', 'Dir', 'DirRad', 'DirStd',\n            'PlayerHeight', 'PlayerWeight', 'PlayerAge', 'Force',\n            'Momentum', 'OrientationStd', 'Dis', 'XFromRusher', 'XToScrimmage',\n            'YFromRusher', 'DistFromRusher', 'AX', 'AY', 'SX', 'SY', 'TimeToRusher'\n        ]\n        mech_agg = X.groupby(['GameId', 'PlayId', 'InPossesion'])[mechanics_cols]\\\n            .agg(['mean', 'std'])\n        mech_agg.columns = ['_'.join(col).strip() for col in mech_agg.columns.values]\n        mech_agg.reset_index(inplace=True)\n        mech_agg.set_index(['GameId', 'PlayId'], inplace=True)\n        mech_agg['InPossesion'] = mech_agg['InPossesion'].map({1: 'off', 0: 'def'})\n        mech_agg = mech_agg.pivot(columns='InPossesion')\n        mech_agg.columns = ['_'.join(col).strip() for col in mech_agg.columns.values]\n        mech_agg.fillna(0, inplace=True)\n        \n        college_like_cols = [\n            'PlayerCollegeName', 'JerseyNumber'\n        ]\n        coll_mean = X.groupby(['GameId', 'PlayId', 'InPossesion'])[college_like_cols]\\\n            .agg(['mean'])\n        coll_mean.columns = ['_'.join(col).strip() for col in coll_mean.columns.values]\n        coll_mean.reset_index(inplace=True)\n        coll_mean.set_index(['GameId', 'PlayId'], inplace=True)\n        coll_mean['InPossesion'] = coll_mean['InPossesion'].map({1: 'off', 0: 'def'})\n        coll_mean = coll_mean.pivot(columns='InPossesion')\n        coll_mean.columns = ['_'.join(col).strip() for col in coll_mean.columns.values]\n        coll_mean.fillna(0, inplace=True)\n        \n        X.drop(columns=college_like_cols, inplace=True)\n        \n        mechanics_cols += ['VoronoiArea']\n        mech_agg_pos = X.groupby(['GameId', 'PlayId', 'PositionGroup', 'InPossesion'])[mechanics_cols]\\\n            .agg(['mean', 'std'])\n        mech_agg_pos.columns = ['_'.join(col).strip() for col in mech_agg_pos.columns.values]\n        mech_agg_pos.reset_index(inplace=True)\n        mech_agg_pos.set_index(['GameId', 'PlayId'], inplace=True)\n        mech_agg_pos['PositionPossession'] = mech_agg_pos['InPossesion'].map({1: 'off', 0: 'def'}) \\\n            + '_' + mech_agg_pos['PositionGroup']\n        mech_agg_pos.drop(columns=['InPossesion', 'PositionGroup'], inplace=True)\n        mech_agg_pos = mech_agg_pos.pivot(columns='PositionPossession')\n        mech_agg_pos.columns = ['_'.join(col).strip() for col in mech_agg_pos.columns.values]\n        mech_agg_pos.fillna(0, inplace=True)\n        \n        X.drop(columns=mechanics_cols, inplace=True)\n        \n        away_ind = X.groupby(['GameId', 'PlayId'])['AwayInPosession', 'ScoreDiff'].max()\n        away_ind['PosessionTeamLeading'] = 0\n        mask = ((away_ind['AwayInPosession'] == 1) & (away_ind['ScoreDiff'] < 0)) | \\\n            ((away_ind['AwayInPosession'] == 0) & (away_ind['ScoreDiff'] > 0))\n        away_ind.loc[mask, 'PosessionTeamLeading'] = 1\n        away_ind['PosessionTeamLead'] = away_ind['ScoreDiff']\n        away_ind.loc[away_ind['AwayInPosession'] == 1, 'PosessionTeamLead'] = \\\n            -away_ind.loc[away_ind['AwayInPosession'] == 1, 'PosessionTeamLead']\n        away_ind['GameWithinConvTouchdown'] = away_ind['ScoreDiff'].abs() <= 8\n        \n        # Cols to ignore\n        ignore_cols = ['IsAwayTeam', 'InPossesion', 'AwayInPosession', \n                       'PositionGroup', 'ScoreDiff', 'Orientation']\n        X.drop(columns=ignore_cols, inplace=True)\n        \n        # Cols to spread wide\n        self.player_cols = [col for col in self.player_cols \n                            if col not in college_cols\n                            and col not in mechanics_cols\n                            and col not in college_like_cols\n                            and col not in ignore_cols]\n        n_player_cols = len(self.player_cols)\n        if self.player_cols:\n            player_data = X[self.player_cols].values.reshape(-1, n_player_cols * 22)\n            new_col_names = [col + '_' + str(player_num)\n                             for player_num in range(22)\n                             for col in self.player_cols]\n\n            player_data = pd.DataFrame(\n                data=player_data,\n                columns=new_col_names\n            )\n            player_data = player_data.infer_objects()\n\n        X.drop(columns=self.player_cols, inplace=True)\n        X = X.drop_duplicates().reset_index(drop=True)\n        \n        if self.player_cols:\n            X = pd.concat([X, player_data], axis=1)\n            \n        X.set_index(['GameId', 'PlayId'], inplace=True)\n        X = X.merge(college_agg, how='left', left_index=True, right_index=True, suffixes=['', 'College'])\n        X = X.merge(mech_agg, how='left', left_index=True, right_index=True, suffixes=['', 'TeamMech'])\n        X = X.merge(coll_mean, how='left', left_index=True, right_index=True, suffixes=['', 'PlayerCollege'])\n        X = X.merge(mech_agg_pos, how='left', left_index=True, right_index=True, suffixes=['', 'TeamPosMech'])\n        X = X.merge(away_ind, how='left', left_index=True, right_index=True, suffixes=['', 'GameInds'])   \n        return X\n    \n    @transformation_check\n    def _previous_play_data(self, X):\n        X[['YardLineLastRush', 'GameClockLastRush', 'DistanceLastRush']] = \\\n            X.groupby(['GameId', 'PlayId'])['YardLineStd', 'GameClock', 'Distance'].shift()\n        X['TimeSinceLastRush'] = X['GameClock'] - X['GameClockLastRush']\n        X.drop(columns=['YardLineLastRush', 'GameClockLastRush', 'DistanceLastRush'], inplace=True)\n        return X\n    \n    def _get_player_cols(self, X):\n        max_vals = X.groupby(['GameId', 'PlayId']).nunique().max()\n        self.player_cols = max_vals[max_vals > 1].index.tolist()\n        self.team_cols = max_vals[max_vals == 2].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class DropColinear(TransformerMixin):\n    def __init__(self, max_corr=1):\n        self.max_corr = max_corr\n        self.all_corellated_cols = []\n        \n    def fit(self, X, y=None):\n        corr = X.corr()\n        corr = pd.DataFrame(np.triu(corr), columns=corr.columns, index=corr.index)\n        for col in corr.index:\n            correlated_cols = corr.columns[corr[col].abs() >= self.max_corr].tolist()\n            correlated_cols = [c_col for c_col in correlated_cols if c_col != col]\n            if correlated_cols:\n                self.all_corellated_cols += correlated_cols\n        self.all_corellated_cols = np.unique(self.all_corellated_cols)\n        return self\n    \n    def transform(self, X):\n        print('Dropping following columns for having a correlation of over {} with '\n              'another variable:\\n{}'.format(self.max_corr, ', '.join(self.all_corellated_cols)))\n        X.drop(columns=self.all_corellated_cols, inplace=True)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"processor = Preprocessor(\n    one_hot_vars=VARS_TO_ONE_HOT,\n    max_cardinality=MAX_CARDINALITY,\n    cols_to_drop=COLS_TO_DROP\n)\nprint(train.shape)\ntrain = processor.initial_cleaning(train)\ntrain = processor.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"dropper = DropColinear(max_corr=1)\ntrain = dropper.fit_transform(train)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass FeatureChecker(TransformerMixin):\n    \n    def fit(self, X):\n        self.std = X.std(axis=0)\n        self.mean = X.mean(axis=0)\n        \n    def transform(self, X):\n        new_mean = X.mean(axis=0)\n        abs_diff = np.absolute(new_mean - self.mean)\n        if any(abs_diff > self.std):\n            cols = np.arange(X.shape[1])\n            print('Following columns are over 1 std dev out form training: {}'\n                  .format(cols[abs_diff > self.std]))\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False)[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(train['VoronoiAreaNoOffenceRusher'], train['Yards'], alpha=.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"yards = train.pop('Yards')\nseason = train.pop('Season')\nseason_weights = season.map({2017: .8, 2018: 1.2, 2019: 1.2}).fillna(1).values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model build"},{"metadata":{"trusted":false},"cell_type":"code","source":"fill_val = train.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = train.copy()\n\ny = np.zeros((yards.shape[0], 199))\nfor idx, target in enumerate(list(yards)):\n    y[idx][99 + target] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col_order = sorted(train.columns)\nX = X[col_order]\nscaler = StandardScaler()\nX = scaler.fit_transform(X.fillna(fill_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n        print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"N_TRAIN = X.shape[0]\nBATCH_SIZE = 1024\nSTEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n\nlr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(0.001,\n    decay_steps=STEPS_PER_EPOCH*100,                                                         \n    decay_rate=1,\n    staircase=False)\n\ndef get_optimizer():\n  return tf.keras.optimizers.Adam(lr_schedule)\n\noptimizer = get_optimizer()\n\ndef get_model(x_tr,y_tr,x_val,y_val,w_tr,dropouts):\n    \n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dropout(0.8)(inp)\n    x = Dense(64, input_dim=X.shape[1], activation='relu',\n             kernel_regularizer=regularizers.l1(0.01))(inp)\n    x = BatchNormalization()(x)\n    x = Dense(64, activation='relu',\n             kernel_regularizer=regularizers.l1(0.01))(x)\n    x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp, out)\n    model.compile(\n        optimizer=optimizer, \n        loss='categorical_crossentropy', \n        metrics=[]\n    )\n\n    es = EarlyStopping(\n        monitor='CRPS_score_val', \n        mode='min',\n        restore_best_weights=True, \n        verbose=1, \n        patience=10\n    )\n\n    mc = ModelCheckpoint(\n        'best_model.h5',\n        monitor='CRPS_score_val',\n        mode='min',\n        save_best_only=True, \n        verbose=1, \n        save_weights_only=True\n    )\n    \n    bsz = 1024\n    steps = x_tr.shape[0] / bsz\n    \n    history = model.fit(\n        x_tr, \n        y_tr,\n        callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], \n        epochs=100, \n        batch_size=bsz,\n        sample_weight=w_tr,\n        verbose=1\n    )\n    model.load_weights(\"best_model.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n    crps = np.round(val_s, 6)\n\n    return {'loss': crps, 'status': STATUS_OK, 'model': model}, history","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_data(X, y, seed):\n    x_tr, y_tr, x_val, y_val = train_test_split(X, y, test_size=0.15, random_state=seed)\n    return x_tr, y_tr, x_val, y_val","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"losses = []\nmodels = []\ncrps_csv = []\ns_time = time.time()\n\nfor k in range(2):\n    kfold = KFold(5, random_state=SEED + k, shuffle=True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        print(\"-----------\")\n        print(\"-----------\")\n        tr_x, tr_y = X[tr_inds],y[tr_inds]\n        val_x, val_y = X[val_inds],y[val_inds]\n        w_tr = season_weights[tr_inds]\n        results, history = get_model(tr_x,tr_y,val_x,val_y,w_tr,dropouts=[.4, .5, .5, .5])\n        models.append(results['model'])\n        print(\"the %d fold crps is %f\"%((k_fold+1), results['loss']))\n        print(\"mean crps is %f\"%np.mean(crps_csv))\n        crps_csv.append(results['loss'])\n\nprint(\"mean crps is %f\"%np.mean(crps_csv))\n\ndef predict(x_te):\n    model_num = len(models)\n    for k,m in enumerate(models):\n        if k==0:\n            y_pred = m.predict(x_te, batch_size=1024)\n        else:\n            y_pred += m.predict(x_te, batch_size=1024)\n            \n    y_pred = y_pred / model_num\n    \n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"mean crps is\\t%f\"%np.mean(crps_csv))\nprint(\"std crps is\\t%f\"%np.std(crps_csv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 2 layers of 64, 0.8 initial drop out","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Current Best Score\n\n#print(\"mean crps is\\t%f\"%np.mean(crps_csv))\n#print(\"std crps is\\t%f\"%np.std(crps_csv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from kaggle.competitions import nflrush\n\nnames = dict(zip(range(199), ['Yards%d' % i for i in range(-99, 100)]))\n\nenv = nflrush.make_env()\nfor i, (df_test, sample_pred) in enumerate(env.iter_test()):\n    test = processor.initial_cleaning(df_test)\n    test = processor.transform(test) \n#     test = dropper.transform(test)\n    \n    for col in col_order:\n        if col not in test.columns:\n            test[col] = 0\n            \n    test = test[col_order]\n    scaled_test = scaler.transform(test.fillna(fill_val))   \n    y_pred = predict(scaled_test)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n\n    preds_df = pd.DataFrame(data=[y_pred], columns=sample_pred.columns)\n    if i == 0:\n        all_preds = preds_df\n        all_test_rows = test\n    else:\n        all_preds = pd.concat([all_preds, preds_df], ignore_index=True, sort=False)\n        all_test_rows = pd.concat([all_test_rows, test], ignore_index=True, sort=False)\n    env.predict(preds_df)\nall_test_rows.to_csv('X_test.csv')\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}