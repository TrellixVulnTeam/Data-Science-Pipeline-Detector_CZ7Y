{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.simplefilter('ignore')\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression \n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nfrom sklearn.ensemble import ExtraTreesRegressor\n#https://www.tensorflow.org/guide/migrate\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nfrom tqdm import tqdm_notebook\nfrom string import punctuation\nimport re\nimport datetime\nfrom scipy.stats import norm\nimport gc\nimport random\n\nnp.random.seed(42)\nrandom.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def convert_pred(yards):\n    p = 99 + yards # 99 + Yards\n    gap = 10 # -10..10\n\n    y_pred = np.zeros(199)\n    y_pred[p-gap:p+gap] = np.cumsum(norm.pdf(np.arange(-gap,gap,1),0,3))\n    y_pred[p+gap:] = 1\n    return pd.Series(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_y(yards):\n    p = 99 + yards # 99 + Yards\n\n    y_ans = np.zeros(199)\n    y_ans[p:] = 1\n    return pd.Series(y_ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_models(models, df):\n    preds = []\n    for model in models:        \n        pred = model.predict(df)            \n        preds.append(pred)\n         \n    return np.column_stack(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GenerateData:\n    def __init__(self, cat_features, drop_cols=[]):\n        self.cat_features = list(set(cat_features) - set(drop_cols))\n        self.drop_cols = drop_cols\n        self.players_score = None\n        self.category_dict = None\n                \n        \n    def make_train_score(self, df):\n        df['MaxHomeScore'] = df.groupby('GameId')['HomeScoreBeforePlay'].transform('max')\n        df['MaxVisitorScore'] = df.groupby('GameId')['VisitorScoreBeforePlay'].transform('max')    \n\n        df['Score'] = 0\n        df.loc[df['Team'] == 'home', 'Score'] = df[df['Team'] == 'home']['MaxHomeScore'] - df[df['Team'] == 'home']['MaxVisitorScore']\n        df.loc[df['Team'] == 'away', 'Score'] = df[df['Team'] == 'away']['MaxVisitorScore'] - df[df['Team'] == 'away']['MaxHomeScore']\n        df['Score'] = df['Score'].map(lambda x: 1 if x>0 else 0 if x<0 else 0.5)\n\n        players_score = df[['GameId', 'NflId', 'Score']].drop_duplicates()\n\n        players_score['GeneralScore'] = players_score.groupby('NflId')['Score'].transform('sum')\n        players_score = players_score[['NflId', 'GeneralScore']].drop_duplicates()\n\n        df = df.merge(players_score, on='NflId', how='left')\n\n        df.loc[df['Team'] == 'away', 'GeneralScore'] = df[df['Team'] == 'away'].groupby('GameId')['GeneralScore'].transform(lambda x: np.round(x.mode().mean()))\n        df.loc[df['Team'] == 'home', 'GeneralScore'] = df[df['Team'] == 'home'].groupby('GameId')['GeneralScore'].transform(lambda x: np.round(x.mode().mean()))\n\n        df.drop(['MaxHomeScore', 'MaxVisitorScore', 'Score'], axis=1, inplace=True)\n    \n        return df, players_score\n    \n    \n    def make_test_score(self, df, players_score):\n        df = df.merge(players_score, on='NflId', how='left')\n\n        df.loc[df['Team'] == 'away', 'GeneralScore'] = df[df['Team'] == 'away'].groupby('GameId')['GeneralScore'].transform(lambda x: np.round(x.mode().mean()))\n        df.loc[df['Team'] == 'home', 'GeneralScore'] = df[df['Team'] == 'home'].groupby('GameId')['GeneralScore'].transform(lambda x: np.round(x.mode().mean()))\n\n        return df\n    \n    \n    # convert to category train and save categories for test\n    def to_category_train(self, df):\n        df = df.fillna(-999)\n        category_dict = {}\n        for col in self.cat_features:\n            f = df[col].factorize()[0]\n            d = dict(zip(df[col], f))\n            category_dict[col] = d\n\n            df[col] = df[col].map(d)\n\n        return df, category_dict\n\n    \n    # convert to categories test, add new categories if need\n    def to_category_test(self, df, category_dict):\n        df = df.fillna(-999)\n        for col, d in category_dict.items():\n            df[col + '_orig'] = df[col]\n            df[col] = df[col].map(d)\n\n            mask = df[col].isna()\n            if mask.any():\n                increment = max(d.values()) + 1\n                df.loc[mask, col] = df.loc[mask, col + '_orig'].factorize()[0] + increment\n                df[col] = df[col].astype('int64')\n\n        del_cols = [i for i in df.columns if '_orig' in i] \n        df.drop(del_cols, axis=1, inplace=True)\n\n        return df\n    \n    \n    def convert_train(self, df):\n        df, self.players_score = self.make_train_score(df)\n        df = self.make_new_features(df)\n        \n        # Clearly: Yards<=YardsLeft and YardsLeft-100<=Yards, thus we are going to drop those wrong lines.\n        df.drop(df.index[(df['YardsLeft']<df['Yards']) | (df['YardsLeft']-100>df['Yards'])], inplace=True)\n        df, self.category_dict = self.to_category_train(df)\n        \n        return df\n    \n    def convert_test(self, df):\n        df = self.make_test_score(df, self.players_score)\n        df = self.make_new_features(df)\n        df = self.to_category_test(df, self.category_dict)\n        \n        return df\n\n    \n    # make common features\n    def make_new_features(self, df):\n        ## convert GameClock to milliseconds\n        def convert_to_milliseconds(t):\n            t = t.split(':')\n            t = list(map(int, t))\n            t = t[0]*60*60 + t[1]*60 + t[2]\n            return t        \n        \n        df['GameClock'] = df['GameClock'].apply(convert_to_milliseconds)\n        \n        \n        ## from https://www.kaggle.com/prashantkikani/nfl-starter-lgb-feature-engg\n        df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n        \n        ## clean and transform StadiumType\n        outdoor = ['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', \n                   'Outside', 'Outddors','Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n\n        indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', 'Retractable Roof',\n                         'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n\n        indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n        dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n        dome_open     = ['Domed, Open', 'Domed, open']\n        \n        df['StadiumType'] = df['StadiumType'].replace(outdoor,'outdoor')\n        df['StadiumType'] = df['StadiumType'].replace(indoor_closed,'indoor_closed')\n        df['StadiumType'] = df['StadiumType'].replace(indoor_open,'indoor_open')\n        df['StadiumType'] = df['StadiumType'].replace(dome_closed,'dome_closed')\n        df['StadiumType'] = df['StadiumType'].replace(dome_open,'dome_open')\n        \n        \n        ## clean and transform Turf\n        #from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\n        natural_grass = ['natural grass','Naturall Grass','Natural Grass']\n        grass = ['Grass']\n        fieldturf = ['FieldTurf','Field turf','FieldTurf360','Field Turf']\n        artificial = ['Artificial','Artifical']\n\n        df['Turf'] = df['Turf'].replace(natural_grass,'natural_grass')\n        df['Turf'] = df['Turf'].replace(grass,'grass')\n        df['Turf'] = df['Turf'].replace(fieldturf,'fieldturf')\n        df['Turf'] = df['Turf'].replace(artificial,'artificial')\n\n        \n        # deal with Possession Team\n        map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n        for abb in df['PossessionTeam'].unique():\n            map_abbr[abb] = abb\n        \n        df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n        df['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n        df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\n        \n        df['HomePossesion'] = df['PossessionTeam'] == df['HomeTeamAbbr']\n        \n        df['Field_eq_Possession'] = df['FieldPosition'] == df['PossessionTeam']\n        df['HomeField'] = df['FieldPosition'] == df['HomeTeamAbbr']\n        \n        ## convert PlayerHeight to inches\n        df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n        \n        ## calculate BMI\n        df['PlayerBMI'] = (703*df['PlayerWeight'])/(df['PlayerHeight']**2)\n                \n        # convert to and calculate unix time\n        df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\")).astype(int)// 10**9\n        df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\")).astype(int)// 10**9\n        df['TimeDelta'] = df['TimeHandoff'] - df['TimeSnap']\n        df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\")).astype(int)// 10**9\n        \n        seconds_in_year = 60*60*24*365.25\n        df['PlayerAge'] = df['PlayerBirthDate'] / seconds_in_year\n        \n        #df.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1, inplace=True)\n        \n        ## WindSpeed and Direction\n        df['WindSpeed'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n        \n        # let's replace the ones that has x-y by (x+y)/2\n        # and also the ones with x gusts up to y\n        df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n        df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n        \n        def str_to_float(txt):\n            try:\n                return float(txt)\n            except:\n                return -999\n            \n        df['WindSpeed'] = df['WindSpeed'].apply(str_to_float)\n        \n    \n        north = ['N','From S','North']\n        south = ['S','From N','South','s']\n        west = ['W','From E','West']\n        east = ['E','From W','from W','EAST','East']\n        north_east = ['FROM SW','FROM SSW','FROM WSW','NE','NORTH EAST','North East','East North East','NorthEast','Northeast','ENE','From WSW','From SW']\n        north_west = ['E','From ESE','NW','NORTHWEST','N-NE','NNE','North/Northwest','W-NW','WNW','West Northwest','Northwest','NNW','From SSE']\n        south_east = ['E','From WNW','SE','SOUTHEAST','South Southeast','East Southeast','Southeast','SSE','From SSW','ESE','From NNW']\n        south_west = ['E','From ENE','SW','SOUTHWEST','W-SW','South Southwest','West-Southwest','WSW','SouthWest','Southwest','SSW','From NNE']\n        no_wind = ['clear','Calm']\n        nan = ['1','8','13']\n\n        df['WindDirection'] = df['WindDirection'].replace(north,'north')\n        df['WindDirection'] = df['WindDirection'].replace(south,'south')\n        df['WindDirection'] = df['WindDirection'].replace(west,'west')\n        df['WindDirection'] = df['WindDirection'].replace(east,'east')\n        df['WindDirection'] = df['WindDirection'].replace(north_east,'north_east')\n        df['WindDirection'] = df['WindDirection'].replace(north_west,'north_west')\n        df['WindDirection'] = df['WindDirection'].replace(south_east,'clear')\n        df['WindDirection'] = df['WindDirection'].replace(south_west,'south_west')\n        df['WindDirection'] = df['WindDirection'].replace(no_wind,'no_wind')\n        df['WindDirection'] = df['WindDirection'].replace(nan,np.nan)       \n        \n        ## deal with PlayDirection\n        df['PlayDirection'] = df['PlayDirection'].apply(lambda x: x.strip() == 'right')\n        \n        ## deal with Team\n        df['Team'] = df['Team'].apply(lambda x: x.strip()=='home')\n               \n        ## deal with GameWeather\n        rain = ['Rainy', 'Rain Chance 40%', 'Showers','Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n                'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n\n        overcast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n                    'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n                    'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n                    'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n                    'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n                    'Partly Cloudy', 'Cloudy']\n\n        clear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n                'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n                'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n                'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n                'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n                'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny', 'Sunny, Windy']\n\n        snow  = ['Heavy lake effect snow', 'Snow']\n\n        none  = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n                \n        df['GameWeather'] = df['GameWeather'].replace(rain,'rain')\n        df['GameWeather'] = df['GameWeather'].replace(overcast,'overcast')\n        df['GameWeather'] = df['GameWeather'].replace(clear,'clear')\n        df['GameWeather'] = df['GameWeather'].replace(snow,'snow')\n        df['GameWeather'] = df['GameWeather'].replace(none,'none')\n        \n        ## deal with NflId and NflIdRusher\n        df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n        #df.drop(['NflId', 'NflIdRusher'], axis=1, inplace=True)\n        \n\n        ## deal with PlayDirection\n        df.loc[df['PlayDirection'] == 'left', 'X'] = 120 - df.loc[df['PlayDirection'] == 'left', 'X']\n        df.loc[df['PlayDirection'] == 'left', 'Y'] = (160 / 3) - df.loc[df['PlayDirection'] == 'left', 'Y']\n        df.loc[df['PlayDirection'] == 'left', 'Orientation'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Orientation'], 360)\n        df.loc[df['PlayDirection'] == 'left', 'Dir'] = np.mod(180 + df.loc[df['PlayDirection'] == 'left', 'Dir'], 360)\n        df['FieldPosition'].fillna('', inplace=True)\n        df.loc[df['PossessionTeam'] != df['FieldPosition'], 'YardLine'] = 100 - df.loc[df['PossessionTeam'] != df['FieldPosition'], 'YardLine']\n\n        # Add 90 to Orientation for 2017 season only\n        df.loc[df['Season'] == 2017, 'Orientation'] = np.mod(90 + df.loc[df['Season'] == 2017, 'Orientation'], 360)\n        \n        ## deal with YardLine\n        df['YardsLeft'] = df.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n        df['YardsLeft'] = df.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)\n        \n        df['DiffScore'] = (df['HomeScoreBeforePlay'] - df['VisitorScoreBeforePlay']).abs()   \n        \n        df['MaxHomeScore'] = df.groupby('GameId')['HomeScoreBeforePlay'].transform('max')\n        df['MaxVisitorScore'] = df.groupby('GameId')['VisitorScoreBeforePlay'].transform('max') \n        \n        df.drop(self.drop_cols, axis=1, inplace=True)\n        \n        \n        return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'Season' is split feature\ncat_features = ['PlayId', 'Team', 'NflId', 'Quarter', 'PossessionTeam', 'FieldPosition', 'NflIdRusher', 'OffenseFormation', 'OffensePersonnel', 'DefendersInTheBox', 'DefensePersonnel', 'PlayDirection', 'PlayerCollegeName', 'Position', 'HomeTeamAbbr', 'VisitorTeamAbbr', 'Week', 'Stadium', 'Location', 'StadiumType', 'Turf', 'GameWeather', 'WindDirection', 'HomePossesion', 'Field_eq_Possession', 'HomeField', 'IsRusher']\ndrop_cols = ['DisplayName', 'JerseyNumber', 'GameId', 'PlayId', 'NflId', 'NflIdRusher'] + ['HomePossesion', 'PlayerAge', 'Temperature', 'Turf']\ndrop_cols += ['YardLine', 'MaxVisitorScore', 'DiffScore', 'DefendersInTheBox', 'WindSpeed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gd = GenerateData(cat_features, drop_cols)\ndf = gd.convert_train(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[df['Season'] == 2017]\ny_train = train['Yards']\ntrain.drop(['Yards', 'Season'], axis=1, inplace=True)\n\nvalid = df[df['Season'] == 2018]\ny_valid = valid['Yards']\nvalid.drop(['Yards', 'Season'], axis=1, inplace=True)\n\ndel df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Two Keras models\nclass KerasCustom:\n    def __init__(self):\n        self.model = None\n        self.input_shape = None\n              \n    def create_model(self, input_shape):\n        model = tf.keras.models.Sequential()\n        model.add(tf.keras.layers.Conv1D(96, 2, activation='tanh', input_shape=(input_shape, 1), kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n        model.add(tf.keras.layers.BatchNormalization())       \n        model.add(tf.keras.layers.Flatten())\n        model.add(tf.keras.layers.Dropout(0.25))\n        model.add(tf.keras.layers.Dense(96, activation='tanh', kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n        model.add(tf.keras.layers.BatchNormalization())\n        model.add(tf.keras.layers.Dropout(0.25))\n        model.add(tf.keras.layers.Dense(1, activation='linear', kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n        model.compile(loss=['mae'], optimizer=tf.keras.optimizers.Adam(lr=0.001))\n\n        return model \n    \n    def fit(self, train, y_train):\n        es = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=5, verbose=1, mode='min', restore_best_weights=True)\n\n        self.input_shape = train.shape[1]\n        self.model = self.create_model(self.input_shape)\n        self.model.fit(train.values.reshape(-1, self.input_shape, 1), y_train, \n                       #validation_data=(df.values.reshape(-1, input_shape, 1), y_test), \n                       epochs=100, #10 \n                       batch_size=1024,\n                       callbacks=[es],\n                       verbose=1)\n\n    def predict(self, df):\n        return self.model.predict(df.values.reshape(-1, self.input_shape, 1))\n\nmodel = KerasCustom()\nmodel.fit(train, y_train)\n\nmodels.append(model)\n\n###\n\nclass KerasCustom:\n    def __init__(self):\n        self.model = None\n        self.input_shape = None\n              \n    def create_model(self, input_shape):\n        model = tf.keras.models.Sequential()\n        model.add(tf.keras.layers.Conv1D(96, 2, activation='tanh', input_shape=(input_shape, 1), kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n        model.add(tf.keras.layers.BatchNormalization())       \n        model.add(tf.keras.layers.Flatten())\n        model.add(tf.keras.layers.Dropout(0.25))\n#         model.add(tf.keras.layers.Dense(96, activation='tanh', kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n#         model.add(tf.keras.layers.BatchNormalization())\n#         model.add(tf.keras.layers.Dropout(0.25))\n        model.add(tf.keras.layers.Dense(1, activation='linear', kernel_initializer=tf.keras.initializers.glorot_uniform(seed=42)))\n        model.compile(loss=['mae'], optimizer=tf.keras.optimizers.Adam(lr=0.001))\n\n        return model \n    \n    def fit(self, train, y_train):\n        es = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=3, verbose=1, mode='min', restore_best_weights=True)\n\n        self.input_shape = train.shape[1]\n        self.model = self.create_model(self.input_shape)\n        self.model.fit(train.values.reshape(-1, self.input_shape, 1), y_train, \n                       #validation_data=(df.values.reshape(-1, input_shape, 1), y_test), \n                       epochs=100, #10 \n                       batch_size=1024,\n                       callbacks=[es],\n                       verbose=1)\n\n    def predict(self, df):\n        return self.model.predict(df.values.reshape(-1, self.input_shape, 1))\n\nmodel = KerasCustom()\nmodel.fit(train, y_train)\n\nmodels.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Three catboost models\ncat_features_ids = [c for c, col in enumerate(train.columns) if col in cat_features]\n\nmodel = CatBoostRegressor(loss_function='MAE',\n                          #eval_metric='MAE',\n                          #early_stopping_rounds=200,\n                          #learning_rate=0.01,\n                          n_estimators=359,\n                          depth=6,\n                          one_hot_max_size=255,\n                          random_seed=42)\n\nmodel.fit(train, y_train,\n          #eval_set=(df, y_test),\n          cat_features=cat_features_ids, \n          #use_best_model=True, \n          verbose=200)\n\nmodels.append(model)\n\n###\n#cat_features_ids = [c for c, col in enumerate(train.columns) if col in cat_features]\n\nmodel = CatBoostRegressor(loss_function='MAE',\n                          #eval_metric='MAE',\n                          #early_stopping_rounds=200,\n                          #learning_rate=0.01,\n                          n_estimators=968,\n                          depth=3,\n                          one_hot_max_size=255,\n                          random_seed=42)\n\nmodel.fit(train, y_train,\n          #eval_set=(df, y_test),\n          cat_features=cat_features_ids, \n          #use_best_model=True, \n          verbose=200)\n\nmodels.append(model)\n\n###\n#cat_features_ids = [c for c, col in enumerate(train.columns) if col in cat_features]\n\nmodel = CatBoostRegressor(loss_function='MAE',\n                          #eval_metric='MAE',\n                          #early_stopping_rounds=200,\n                          #learning_rate=0.01,\n                          n_estimators=136,\n                          depth=9,\n                          one_hot_max_size=255,\n                          random_seed=42)\n\nmodel.fit(train, y_train,\n          #eval_set=(df, y_test),\n          cat_features=cat_features_ids, \n          #use_best_model=True, \n          verbose=200)\n\nmodels.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cat_features_ids = [c for c, col in enumerate(train.columns) if col in cat_features]\n\nmodel = lgb.LGBMRegressor(n_estimators=194, \n                          random_state=42,\n                          learning_rate=0.005,\n                          importance_type = 'gain',\n                          n_jobs = -1,\n                          metric='mae')\n\nmodel.fit(train, y_train,\n          #eval_set=[(train, y), (test[train.columns], y_test)],\n          categorical_feature = cat_features_ids,\n          #early_stopping_rounds=200,\n          verbose=10)\n\nmodels.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=ExtraTreesRegressor(n_estimators=400, n_jobs=-1, bootstrap=True)\nmodel.fit(train, y_train)\n\nmodels.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make predicitons for validation\npred = predict_models(models, valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_model=LinearRegression(n_jobs=-1)\n\nmeta_model.fit(pred, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\nfrom tqdm import tqdm_notebook\n\nenv = nflrush.make_env()\n\n# 3438\nfor (test, sub) in tqdm_notebook(env.iter_test()):\n    df = gd.convert_test(test)\n    df.drop('Season', axis=1, inplace=True)\n    \n    test_pred = predict_models(models, df)\n    \n    final_pred=meta_model.predict(test_pred)\n    \n    final_pred = np.mean(final_pred).astype('int')\n    \n    final_pred = convert_pred(final_pred)\n    sub[sub.columns] = final_pred.values \n    \n    env.predict(sub)\n\nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}