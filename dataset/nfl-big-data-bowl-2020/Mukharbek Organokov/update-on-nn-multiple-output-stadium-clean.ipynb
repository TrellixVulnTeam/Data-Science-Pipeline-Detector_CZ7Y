{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Update of [Neural networks, multiple output + stadium clean](https://www.kaggle.com/truenikita/neural-networks-multiple-output-stadium-clean) kernel (by [Nikita Ageev](https://www.kaggle.com/truenikita))","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Kernel original details\n- Fork of https://www.kaggle.com/mrkmakr/neural-network-with-mae-objective-0-01385  \n with my stadium cleaning https://www.kaggle.com/truenikita/cleaning-of-the-stadium-feature","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### NEWs \n- So, here a lot can be done with architecture to improve the score and get some stuies (up to you what to do later), see below. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ! Please upvote **this** kernel and the [original](https://www.kaggle.com/truenikita/neural-networks-multiple-output-stadium-clean) one with [this1](https://www.kaggle.com/mrkmakr/neural-network-with-mae-objective-0-01385) and [this2](https://www.kaggle.com/truenikita/cleaning-of-the-stadium-feature) which it's based on. ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport keras\n\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n# train = train[:2200]\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/rooshroosh/fork-of-neural-networks-different-architecture\ndef strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x/15))\n    except:\n        return \"nan\"\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n    ## Orientation and Dir\n    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## OffensePersonnel\n    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n    temp.columns = [\"Offense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## DefensePersonnel\n    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n    temp.columns = [\"Defense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n    \n    ## Stadium clean\n    map_stad = {'Broncos Stadium at Mile High': 'Broncos Stadium At Mile High', 'CenturyField': 'CenturyLink Field', 'CenturyLink': 'CenturyLink Field', 'Everbank Field': 'EverBank Field', 'FirstEnergy': 'First Energy Stadium', 'FirstEnergy Stadium': 'First Energy Stadium', 'FirstEnergyStadium': 'First Energy Stadium', 'Lambeau field': 'Lambeau Field', 'Los Angeles Memorial Coliesum': 'Los Angeles Memorial Coliseum', 'M & T Bank Stadium': 'M&T Bank Stadium', 'M&T Stadium': 'M&T Bank Stadium', 'Mercedes-Benz Dome': 'Mercedes-Benz Superdome', 'MetLife': 'MetLife Stadium', 'Metlife Stadium': 'MetLife Stadium', 'NRG': 'NRG Stadium', 'Oakland Alameda-County Coliseum': 'Oakland-Alameda County Coliseum', 'Paul Brown Stdium': 'Paul Brown Stadium', 'Twickenham': 'Twickenham Stadium'}\n    \n    for stad in train['Stadium'].unique():\n        if stad in map_stad.keys():\n            pass\n        else:\n            map_stad[stad]=stad\n\n    train['Stadium'] = train['Stadium'].map(map_stad)\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = preprocess(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Stadium clean\nmap_stad = {'Broncos Stadium at Mile High': 'Broncos Stadium At Mile High', 'CenturyField': 'CenturyLink Field', 'CenturyLink': 'CenturyLink Field', 'Everbank Field': 'EverBank Field', 'FirstEnergy': 'First Energy Stadium', 'FirstEnergy Stadium': 'First Energy Stadium', 'FirstEnergyStadium': 'First Energy Stadium', 'Lambeau field': 'Lambeau Field', 'Los Angeles Memorial Coliesum': 'Los Angeles Memorial Coliseum', 'M & T Bank Stadium': 'M&T Bank Stadium', 'M&T Stadium': 'M&T Bank Stadium', 'Mercedes-Benz Dome': 'Mercedes-Benz Superdome', 'MetLife': 'MetLife Stadium', 'Metlife Stadium': 'MetLife Stadium', 'NRG': 'NRG Stadium', 'Oakland Alameda-County Coliseum': 'Oakland-Alameda County Coliseum', 'Paul Brown Stdium': 'Paul Brown Stadium', 'Twickenham': 'Twickenham Stadium'}\n\nfor stad in train['Stadium'].unique():\n    if stad in map_stad.keys():\n        pass\n    else:\n        map_stad[stad]=stad\n\ntrain['Stadium'] = train['Stadium'].map(map_stad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## DisplayName remove Outlier\nv = train[\"DisplayName\"].value_counts()\nmissing_values = list(v[v < 5].index)\ntrain[\"DisplayName\"] = train[\"DisplayName\"].where(~train[\"DisplayName\"].isin(missing_values), \"nan\")\n\n## PlayerCollegeName remove Outlier\nv = train[\"PlayerCollegeName\"].value_counts()\nmissing_values = list(v[v < 10].index)\ntrain[\"PlayerCollegeName\"] = train[\"PlayerCollegeName\"].where(~train[\"PlayerCollegeName\"].isin(missing_values), \"nan\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.to_pickle(train, \"train.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop(train):\n    drop_cols = [\"GameId\", \"GameWeather\", \"NflId\", \"Season\", \"NflIdRusher\"] \n    drop_cols += ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate']\n    drop_cols += [\"Orientation\", \"Dir\", 'WindSpeed', \"GameClock\"]\n    # drop_cols += [\"DefensePersonnel\",\"OffensePersonnel\"]\n    train = train.drop(drop_cols, axis = 1)\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = drop(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = []\ndense_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append(col)\n        print(\"*cat*\", col, len(train[col].unique()))\n    else:\n        dense_features.append(col)\n        print(\"!dense!\", col, len(train[col].unique()))\ndense_features.remove(\"PlayId\")\ndense_features.remove(\"Yards\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## categorical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat = train[cat_features]\ncategories = []\nmost_appear_each_categories = {}\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n    categories.append(train_cat[col].unique())\ncategories = np.hstack(categories)\nprint(len(categories))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(categories)\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:, col] = le.transform(train_cat[col])\nnum_classes = len(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dense","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dense = train[dense_features]\nsss = {}\nmedians = {}\nfor col in tqdm_notebook(train_dense.columns):\n    print(col)\n    medians[col] = np.nanmedian(train_dense[col])\n    train_dense.loc[:, col] = train_dense[col].fillna(medians[col])\n    ss = StandardScaler()\n    train_dense.loc[:, col] = ss.fit_transform(train_dense[col].values[:,None])\n    sss[col] = ss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Divide features into groups","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## dense features for play\ndense_game_features = train_dense.columns[train_dense[:22].std() == 0]\n## dense features for each player\ndense_player_features = train_dense.columns[train_dense[:22].std() != 0]\n## categorical features for play\ncat_game_features = train_cat.columns[train_cat[:22].std() == 0]\n## categorical features for each player\ncat_player_features = train_cat.columns[train_cat[:22].std() != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dense_game = train_dense[dense_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_dense_game = np.hstack([train_dense_game, train_dense[dense_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_dense_players = [train_dense[dense_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_dense_players = np.stack([t.values for t in train_dense_players]).transpose(1, 0, 2)\n\ntrain_cat_game = train_cat[cat_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_cat_game = np.hstack([train_cat_game, train_cat[cat_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_cat_players = [train_cat[cat_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_cat_players = np.stack([t.values for t in train_cat_players]).transpose(1, 0, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_step(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\ntrain_y_raw = train[\"Yards\"].iloc[np.arange(0, len(train), 22)].reset_index(drop = True)\ntrain_y = np.vstack(train_y_raw.apply(return_step).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dense_game.shape, train_dense_players.shape, train_cat_game.shape, train_cat_players.shape, train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras import regularizers\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\ndef crps(y_true, y_pred):\n    loss = K.mean((K.cumsum(y_pred, axis = 1) - y_true)**2)\n    return loss\n\n## Comments (MO): bs, epochs remained as it is -> you can work around (Please comment below kernel!)\ndef get_model(batch_size = 32, epochs = 10):\n    ## model dense\n    input_dense_game = keras.layers.Input(shape=(train_dense_game.shape[1],))\n    \"\"\"\n    x1 = keras.layers.Dense(32, activation=\"relu\")(input_dense_game)\n    x1 = keras.layers.Dropout(0.5)(x1)\n    # x1 = keras.layers.Dropout(0.1)(x1)\n    \"\"\"\n    ## Comments (MO): higher dropout plus added batch normalization -> you can work around (activation functions, dropout)\n    x1 = keras.layers.Dense(64, activation=\"relu\")(input_dense_game) \n    x1 = keras.layers.BatchNormalization()(x1)\n    x1 = keras.layers.Dropout(0.6)(x1)\n\n    input_dense_players = keras.layers.Input(shape=(train_dense_players.shape[1],train_dense_players.shape[2]))\n    \"\"\"\n    x2 = keras.layers.Dense(32, activation=\"relu\")(input_dense_players)\n    x2 = keras.layers.Dropout(0.5)(x2)\n    # x2 = keras.layers.Flatten()(x2)\n    # x2 = keras.layers.Dropout(0.1)(x2)\n    \"\"\"\n    ## Comments (MO): higher dropout plus added batch normalization -> you can work around (activation functions, dropout)\n    x2 = keras.layers.Dense(64, activation=\"relu\")(input_dense_players) \n    x2 = keras.layers.BatchNormalization()(x2)\n    x2 = keras.layers.Dropout(0.6)(x2)\n\n    ## model categorical\n    input_cat_game = keras.layers.Input(shape=(train_cat_game.shape[1], ))\n    embedding = keras.layers.Embedding(num_classes, 8, embeddings_regularizer=regularizers.l2(1))\n    x3 = embedding(input_cat_game)\n    x3 = keras.layers.Flatten()(x3)\n    x3 = keras.layers.Dense(8, activation=\"relu\")(x3)\n    \"\"\"\n    x3 = keras.layers.Dropout(0.6)(x3)\n    \"\"\"\n    ## Comments (MO): added dropout (0.5 performs better 0.6) and batch normalization -> you can work around (activation functions, dropout)\n    x3 = keras.layers.BatchNormalization()(x3)\n    x3 = keras.layers.Dropout(0.5)(x3)  \n\n    input_cat_players = keras.layers.Input(shape=(train_cat_players.shape[1], train_cat_players.shape[2]))\n    x4 = embedding(input_cat_players)\n    x4 = keras.layers.Reshape((int(x4.shape[1]), int(x4.shape[2]) * int(x4.shape[3])))(x4)\n    x4 = keras.layers.Dense(16, activation=\"relu\")(x4)\n    \"\"\"\n    x4 = keras.layers.Dropout(0.6)(x4)\n    \"\"\"\n    ## Comments (MO): added dropout (0.5 performs better 0.6) -> you can work around (activation functions, dropout)\n    x4 = keras.layers.Dropout(0.5)(x4)\n    \n    ### concat players\n    x_concat_players = keras.layers.Concatenate()([x2,x4])\n    x_concat_players = keras.layers.Dense(16, activation=\"relu\")(x_concat_players)\n    # x_concat_players = keras.layers.GlobalAveragePooling1D()(x_concat_players)\n\n    ## flatten\n    x2 = keras.layers.Flatten()(x2)\n    x4 = keras.layers.Flatten()(x4)\n    x_concat_players = keras.layers.Flatten()(x_concat_players)\n\n    ### concat all\n    x_concat = keras.layers.Concatenate()([x1,x3,x_concat_players] + [x2, x4])\n    x_concats = []\n    n_unit = 128\n    decay_rate = 0.5\n    for k in range(5):\n        x_concat = keras.layers.Dense(n_unit, activation=\"elu\")(x_concat) ## Comments (MO): replaced ReLU by ELU\n        x_concats.append(x_concat)\n        n_unit = int(n_unit * decay_rate)\n    x_concat = keras.layers.Concatenate()(x_concats)\n    x_concat = keras.layers.BatchNormalization()(x_concat) ## Comments (MO): added batch normalization\n    x_concat = keras.layers.Dropout(0.5)(x_concat)\n\n\n    ## concat\n    x_concat = keras.layers.Concatenate()([x1,x3,x_concat_players,x_concat] + [x2, x4])\n    out_soft = keras.layers.Dense(199, activation=\"softmax\", name = \"out_soft\")(x_concat)\n    out_reg = keras.layers.Dense(1, activation=None, name = \"out_reg\")(x_concat)\n    model = keras.models.Model(inputs = [input_dense_game, input_dense_players, input_cat_game, input_cat_players],\n                               outputs = [out_soft, out_reg])\n\n    ## compile\n    model.compile(loss=[crps, keras.losses.mae],\n                  loss_weights=[1.0, 0.01],\n                  optimizer=keras.optimizers.Adam(learning_rate=0.005, decay = 1e-4)) \n\n    ## train\n    tr_x = [train_dense_game[tr_inds], train_dense_players[tr_inds], train_cat_game[tr_inds], train_cat_players[tr_inds]]\n    tr_y = [train_y[tr_inds], train_y_raw[tr_inds]/100]\n    val_x = [train_dense_game[val_inds], train_dense_players[val_inds], train_cat_game[val_inds], train_cat_players[val_inds]]\n    val_y = [train_y[val_inds], train_y_raw[val_inds]/100]\n    model.fit(tr_x,\n              tr_y,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=1,\n              validation_data=(val_x, val_y))\n    loss = model.history.history[\"val_out_soft_loss\"][-1]\n    return model, loss\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nlosses = []\nmodels = []\nfor k in range(2):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_y)):\n        print(\"-----------\")\n        print(\"-----------\")\n        model, loss = get_model(32, 20)\n        models.append(model)\n        print(k_fold, loss)\n        losses.append(loss)\nprint(\"-------\")\nprint(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(test, sample, env, model):\n    test = preprocess(test)\n    test = drop(test)\n\n    ### categorical\n    test_cat = test[cat_features]\n    for col in (test_cat.columns):\n        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n        isnan = ~test_cat.loc[:,col].isin(categories)\n        if np.sum(isnan) > 0:\n#             print(\"------\")\n#             print(\"test have unseen label : col\")\n            if not ((col + \"__nan\") in categories):\n#                 print(\"not nan in train : \", col)\n                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n            else:\n#                 print(\"nan seen in train : \", col)\n                test_cat.loc[isnan,col] = col + \"__nan\"\n    for col in (test_cat.columns):\n        test_cat.loc[:, col] = le.transform(test_cat[col])\n\n    ### dense\n    test_dense = test[dense_features]\n    for col in (test_dense.columns):\n        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n\n    ### divide\n    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n\n    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_dense_game = np.hstack([test_dense_game, test_dense[dense_player_features][test_dense[\"IsRusher\"] > 0]])\n    \n    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n\n    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_cat_game = np.hstack([test_cat_game, test_cat[cat_player_features][test_dense[\"IsRusher\"] > 0]])\n\n    test_inp = [test_dense_game, test_dense_players, test_cat_game, test_cat_players]\n    \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test_inp)[0]\n        _pred = np.cumsum(_pred, axis = 1)\n        pred += _pred\n    pred /= len(models)\n    pred = np.clip(pred, 0, 1)\n    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()\npreds = []\nfor test, sample in tqdm_notebook(env.iter_test()):\n    pred = make_pred(test, sample, env, models)\n    preds.append(pred)\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.vstack(preds)\n## check whether prediction is submittable\nprint(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\nprint(np.mean(preds > 1) == 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}