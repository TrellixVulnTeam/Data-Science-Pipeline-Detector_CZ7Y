{"cells":[{"metadata":{"_cell_guid":"a9798604-b0ed-4ea9-b894-52b8fad97b7b","_uuid":"ff2644fd-b910-43e5-9a2f-959c0adeb15a","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nimport re\nfrom string import punctuation\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\nimport keras\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom keras.utils import plot_model\nfrom keras.optimizers import Adam\nimport keras.backend as K\nimport tensorflow as tf\n\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 150)\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1fbf87f8-5122-4daf-bc70-3e8d31bb5856","_uuid":"fb699687-2bf2-471a-845e-d498aeee7eac","trusted":false},"cell_type":"code","source":"env = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4f97b8fd-2dac-4fe0-aa0b-8c1d1cc7d66f","_uuid":"72f9ce60-48f7-4666-80a4-c343e94bcc5a","trusted":false},"cell_type":"code","source":"train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"89c007b1-c569-4323-b5c9-e7e5b3357fa5","_uuid":"b1676ce2-3fa9-4417-bdcc-c44fa6ecbde1"},"cell_type":"markdown","source":"# Overview"},{"metadata":{"_cell_guid":"f352f6e7-a676-424f-99a6-667d329b75cc","_uuid":"77f26cc6-4a5a-42ef-9871-8fe4d2b204af","trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.select_dtypes(include=[\"float\", 'int']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.select_dtypes(exclude=[\"float\", 'int']).columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"43b712a7-2540-4797-af40-d7a10a1ca8c9","_uuid":"0bee464a-917c-4d31-b250-b883c964028b"},"cell_type":"markdown","source":"- Let's see how PlayId is distribuited"},{"metadata":{"_cell_guid":"9d745e55-0a42-4709-b4f7-e96f6191fa4e","_uuid":"2d962af5-dc48-4465-8fe3-f03c6ff64c63","trusted":false},"cell_type":"code","source":"train['PlayId'].value_counts().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train['Position'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c068d685-9c81-4914-a59a-8de2b1a09867","_uuid":"d3639906-d957-49ff-b87b-63dc2db6259b"},"cell_type":"markdown","source":"As expected, we have 22 of each playid since we have 22 players.\n\nLet's look at our target variable(Yards)."},{"metadata":{"_cell_guid":"fd58ec79-fc81-4f94-8f5e-cb9d53e98651","_uuid":"b13e0151-67bc-40b8-8cd9-4b2b2279fd63","trusted":false},"cell_type":"code","source":"train['Yards'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"817d37f1-cdc6-48be-9a85-31d644b7e9b3","_uuid":"dd912aed-de2c-4417-9706-bab818aebe4c","trusted":false},"cell_type":"code","source":"ax = sns.distplot(train['Yards'])\nplt.vlines(train['Yards'].mean(), plt.ylim()[0], plt.ylim()[1], color='r', linestyles='--');\nplt.text(train['Yards'].mean()+5, plt.ylim()[1]-0.02, \"Mean yards travaled\", size=15, color='r')\nplt.title(\"Yards travaled distribution\", size=20);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bbf962b7-28fe-4b1d-8ce7-af815b5ffe9d","_uuid":"9dd3edf6-c372-4e94-a018-b9fdbc13996a"},"cell_type":"markdown","source":"# Engineering of categorical features"},{"metadata":{"_cell_guid":"2996d6a4-18fc-4ce8-a2d0-a0a58b2b2391","_uuid":"a4f3359c-ab23-413e-b87a-5e9bfa406be6","trusted":false},"cell_type":"code","source":"cat_features = []\nint_features = []\nfloat_features = []\nbool_features = []\nuint8_features = []\nfor col in train.columns:\n    #print(train[col].dtype) #print out to check datatypes\n    if train[col].dtype =='object':\n        cat_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='int64':\n        int_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='float64':\n        float_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='bool':\n        bool_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='uint8':\n        uint8_features.append((col, len(train[col].unique())))\n        \n''' contained datatypes\nint64\nobject\nfloat64\n'''\n\nprint(\"{} Categorical Features found.\".format(len(cat_features)))\nprint(\"{} Integer Features found.\".format(len(int_features)))\nprint(\"{} Float Features found.\".format(len(float_features)))\nprint(\"{} Boolean Features found.\".format(len(bool_features)))\nprint(\"{} uint8 OneHot Features found.\".format(len(uint8_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cat_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GameClock"},{"metadata":{"trusted":false},"cell_type":"code","source":"def convert_to_seconds(txt): #converts string to number of seconds. range = 0-15min 0-900sec\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Offense Formation"},{"metadata":{"trusted":false},"cell_type":"code","source":"def classify_offense_formation(txt): #can be extended\n    if pd.isna(txt):\n        return \"unknown\"\n    txt = txt.lower()\n    if (txt.find(\"single\") != -1): #singleback\n        return \"singleback\"\n    elif (txt.find(\"shot\") != -1): #shotgun\n        return \"shotgun\"\n    elif (txt.find(\"i_form\") != -1): #I_Formation\n        return \"i_form\"\n    elif (txt.find(\"pistol\") != -1): #Pistol\n        return \"pistol\"\n    elif (txt.find(\"jumbo\") != -1): #Jumbo\n        return \"jumbo\"\n    elif (txt.find(\"wildcat\") != -1): #Wildcat\n        return \"wildcat\"\n    elif (txt.find(\"empty\") != -1): #Empty\n        return \"empty\"\n    elif (txt.find(\"ace\") != -1): #Ace\n        return \"ace\"\n    else:\n        return \"unknown\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Offense and Defense Personnel"},{"metadata":{"trusted":false},"cell_type":"code","source":"offense_dict = {'DB' : \"offense_DB\", 'DL' : \"offense_DL\", \n                'LB' : \"offense_LB\", 'OL' : \"offense_OL\", \n                'QB' : \"offense_QB\", 'RB' : \"offense_RB\", \n                'TE' : \"offense_TE\", 'WR' : \"offense_WR\"}\n\ndef ProcessOffensePersonnel(row):\n    for whole_offense in row[\"OffensePersonnel\"].split(\",\"):\n        #print(\"Offense Item: {}\".format(whole_offense))\n        offense_item = whole_offense.strip().split(\" \")\n        if (offense_item[1] in offense_dict.keys()):\n            if offense_item[0].isdigit():\n                row[offense_dict[offense_item[1]]] = int(offense_item[0])\n            else:\n                row[offense_item[offense_item[1]]] = 0\n        else:\n            if offense_item[0].isdigit():\n                row[\"offense_UNKNOWN\"] += int(offense_item[0])\n            else:\n                row[\"offense_UNKNOWN\"] = 0\n    return row","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"defense_dict = {'DB' : \"defense_DB\", 'DL' : \"defense_DL\", \n                'LB' : \"defense_LB\", 'OL' : \"defense_OL\"}\n\ndef ProcessDefensePersonnel(row):\n    for whole_defense in row[\"DefensePersonnel\"].split(\",\"):\n        defense_item = whole_defense.strip().split(\" \")\n        if (defense_item[1] in defense_dict.keys()):\n            if defense_item[0].isdigit():\n                row[defense_dict[defense_item[1]]] = int(defense_item[0])\n            else:\n                row[defense_dict[defense_item[1]]] = 0\n        else:\n            if defense_item[0].isdigit():\n                row[\"defense_UNKNOWN\"] += int(defense_item[0])\n            else:\n                row[\"defense_UNKNOWN\"] = 0\n    return row","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#convert to boolean outdoor = True, indoow = False\ndef classify_stadium_type(txt):\n    if pd.isna(txt):\n        return True\n    txt = txt.lower()\n    if (txt.find(\"ou\") != -1):\n        return True\n    if (txt.find(\"in\") != -1):\n        return False\n    if (txt.find(\"op\") != -1):\n        return True\n    if (txt.find(\"cl\") != -1):\n        return False\n    return True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turf"},{"metadata":{"_cell_guid":"0f0f6f7c-fb7b-49df-aa9d-32108abeb911","_uuid":"00e6126d-2c75-4b0d-9a39-ffa00799cd48","trusted":false},"cell_type":"code","source":"#convert to boolean natural grass = True, artificial = False\ndef classify_turf_type(txt):\n    if pd.isna(txt):\n        print(\"isna\")\n        return True\n    txt = txt.lower()\n    if (txt.find(\"gras\") != -1):\n        return True\n    if (txt.find(\"nat\") != -1):\n        return True\n    #print(\"false\")\n    return False","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4b49a9d6-7ebb-4b9d-8574-7e547c3db476","_uuid":"901347f8-8e6b-43a2-aa0e-545df16da154"},"cell_type":"markdown","source":"## Game Weather"},{"metadata":{"trusted":false},"cell_type":"code","source":"def classify_weather(txt):\n    if pd.isnull(txt):\n        #print(\"isnull\")\n        return \"cloudy\" #default\n    txt = txt.lower()\n    if ((txt.find(\"sun\") != -1) or (txt.find(\"cle\") != -1)): #sunny or clear\n        return \"sunny\"\n    elif ((txt.find(\"oud\") != -1) or (txt.find(\"clo\") != -1)): #cloudy\n        return \"cloudy\"\n    elif ((txt.find(\"rai\") != -1) or (txt.find(\"sho\") != -1)): #rain or shower\n        return \"rainy\"\n    elif ((txt.find(\"indo\") != -1) or (txt.find(\"clim\") != -1)): #indoor climatized\n        return \"indoor\"\n    elif (txt.find(\"sno\") != -1): #snow\n        return \"snow\"\n    else:\n        return \"cloudy\" #default","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Coordinate Transformation"},{"metadata":{"trusted":false},"cell_type":"code","source":"def new_X(x_coordinate, play_direction): #play direction boolean (right=True / left=False)\n    if play_direction == False: #direction = left --> switch play direction, so play direction is always from left to right\n        return 120.0 - x_coordinate\n    else:\n        return x_coordinate #direction = right --> ok\n\n\ndef new_orientation(angle, play_direction): #play direction boolean (right=True / left=False)\n    if play_direction == False: #direction = left --> field was switched --> turn player around\n        new_angle = 360.0 - angle\n        if new_angle == 360.0:\n            return 0.0\n        else:\n            return new_angle\n    else:\n        if angle == 360.0:\n            return 0.0\n        else:\n            return angle\n\n        \ndef line_of_scrimmage_in_coordinates(rush_team, field_position, yardline):\n    #rushin team is always from left to right\n    if rush_team == field_position:\n        # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n        return 10.0 + yardline\n    else:\n        # half the field plus the yards between midfield and the line of scrimmage\n        return 60.0 + (50 - yardline)\n\n    \ndef euclidean_distance(x1,y1,x2,y2):\n    x_diff = (x1-x2)**2\n    y_diff = (y1-y2)**2\n    return np.sqrt(x_diff + y_diff)\n\n\ndef is_looking_back(orientation): #looking back means from right to left, means direction > 180\n    if orientation > 180.0:\n        return True\n    else:\n        return False\n    \ndef recalculate_yardline(df): #transforms YardLine to global field coordinates\n    new_yardline = df[df['NflId'] == df['NflIdRusher']].copy()\n    #enthält je game einen rusher\n    new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: line_of_scrimmage_in_coordinates(x[0],x[1],x[2]), axis=1)\n    new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n    #enthält je play die neu berechnete yardline\n    df = df.drop('YardLine', axis=1)\n    df = pd.merge(df, new_yardline, on=['GameId','PlayId'], how='inner')\n    return df\n\ndef recalculate_pos_and_dir(df): #transforms position direction and orientation to \"rush from left to right\"\n    df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n    df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n    df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n    return df\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def features_relative_coordinates(df):\n    rusher_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']].copy()\n    rusher_features['rusher_yards_to_go'] = rusher_features['YardLine'] - rusher_features['X'] #num yards behind LineOfScrimmage\n    rusher_features['rusher_oriented_back'] = rusher_features['Orientation'].apply(lambda x: is_looking_back(x))\n    rusher_features['rusher_moving_back'] = rusher_features['Dir'].apply(lambda x: is_looking_back(x))\n    rusher_features = rusher_features.rename(columns={'X':'rusher_X', 'Y':'rusher_Y'})\n    rusher_features = rusher_features[['GameId','PlayId','NflIdRusher','rusher_X','rusher_Y','rusher_yards_to_go',\n                         'rusher_oriented_back','rusher_moving_back']]\n    player_distance = df[['GameId','PlayId','NflId','X','Y']].copy() #from all players\n    player_distance = pd.merge(player_distance, rusher_features, on=['GameId','PlayId'], how='inner')\n    #player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']] #leave this line out ???\n    player_distance['dist_to_rusher'] = player_distance[['X','Y','rusher_X','rusher_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n    player_distance = player_distance.groupby(['GameId','PlayId','rusher_yards_to_go','rusher_oriented_back','rusher_moving_back'])\\\n                                            .agg({'dist_to_rusher':['min','max','mean','std']})\\\n                                             .reset_index()\n    player_distance.columns = ['GameId','PlayId','rusher_yards_to_go','rusher_oriented_back','rusher_moving_back',\n                                   'min_dist','max_dist','mean_dist','std_dist']    \n    df = pd.merge(player_distance,df,on=['GameId','PlayId'],how='inner')\n    return df\n    #adds new features 'rusher_yards_to_go', 'rusher_oriented_back','rusher_moving_back'\n    #adds new features 'min_dist','max_dist','mean_dist','std_dist'\n    #for the future: add each players distance to rusher\n\n\ndef defense_features(df):\n    rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']].copy()\n    rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n    defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n    defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n    defense['def_dist_to_rusher'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n    defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_rusher':['min','max','mean','std']})\\\n                         .reset_index()\n    defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n    \n    df = pd.merge(defense,df,on=['GameId','PlayId'],how='inner')\n    return df\n    #adds new features 'def_min_dist','def_max_dist','def_mean_dist','def_std_dist'\n\n    \ndef dist_to_rusher_features(df):\n    rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y']].copy()\n    rusher.columns = ['GameId','PlayId','RusherX','RusherY']\n\n    defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n    defense = defense[['GameId','PlayId',\"NflId\",'X','Y','RusherX','RusherY']]\n    defense['dist_to_rusher'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n    defense.drop([\"X\", \"Y\", \"RusherX\", \"RusherY\"], axis=1, inplace=True)\n    df = pd.merge(defense,df,on=['GameId','PlayId',\"NflId\"],how='inner')\n    return df\n    \n    \ndef calc_new_position(X, Y, S, A, Dir):\n    D1 = S + A/2 #acceleration remains unchanged within 1 second\n    D3 = D1 + 2*S + 2*A #no further acceleration from second 1 - 3\n    X1 = X + D1 * np.sin(Dir/180*np.pi)\n    Y1 = Y + D1 * np.cos(Dir/180*np.pi)\n    X3 = X + D3 * np.sin(Dir/180*np.pi)\n    Y3 = Y + D3 * np.cos(Dir/180*np.pi)\n    return X1, Y1, X3, Y3\n\n\ndef additional_time_series_features(df):\n    #Annahme: Beschleunigung dauert 1 Sekunde an und die Geschwindigkeit bleibt dann gleich\n    features = df[['GameId','PlayId','NflId','X','Y','S','A','Dir']].copy()\n    features[['X1sec', 'Y1sec', 'X3sec', 'Y3sec']] = features[['X','Y','S','A', 'Dir']].apply(lambda x: calc_new_position(x[0],x[1],x[2],x[3],x[4]), axis=1, result_type=\"expand\")\n    features.drop([\"X\", \"Y\", \"S\", \"A\", \"Dir\"], axis=1, inplace=True)\n    df = pd.merge(features,df,on=['GameId','PlayId','NflId'],how='inner')\n    return df\n\n\ndef line(p1, p2):\n    A = (p1[1] - p2[1])\n    B = (p2[0] - p1[0])\n    C = (p1[0]*p2[1] - p2[0]*p1[1])\n    return A, B, -C\n\n\ndef calc_intersection(L1P1X, L1P1Y, L1P2X, L1P2Y, L2P1X, L2P1Y, L2P2X, L2P2Y):\n    L1 = line([L1P1X,L1P1Y],[L1P2X,L1P2Y])\n    L2 = line([L2P1X,L2P1Y],[L2P2X,L2P2Y])\n    D  = L1[0] * L2[1] - L1[1] * L2[0]\n    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n    if D != 0:\n        x = Dx / D\n        y = Dy / D\n        if ((x > L1P1X) and (x > L1P2X)):\n            return False\n        elif ((x < L1P1X) and (x < L1P2X)):\n            return False\n        elif ((x < L2P1X) and (x < L2P2X)):\n            return False\n        elif ((x > L2P1X) and (x > L2P2X)):\n            return False\n        else:\n            if ((y > L1P1Y) and (y > L1P2Y)):\n                return False\n            elif ((y < L1P1Y) and (y < L1P2Y)):\n                return False\n            if ((y > L2P1Y) and (y > L2P2Y)):\n                return False\n            elif ((y < L2P1Y) and (y < L2P2Y)):\n                return False\n            else:\n                return True\n    else:\n        return False\n    \n        \n        \n        \n        \n\ndef calc_crossing_movements(df):\n    rusher_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','X1sec','Y1sec','X3sec','Y3sec']].copy()\n    rusher_features = rusher_features.rename(columns={'X':'rusher_X', 'Y':'rusher_Y', 'X1sec':'rusher_X1sec', 'Y1sec':'rusher_Y1sec', 'X3sec':'rusher_X3sec', 'Y3sec':'rusher_Y3sec'})\n    #print(rusher_features.head())\n    features = df[['GameId','PlayId','NflId','X','Y','X1sec','Y1sec','X3sec','Y3sec']].copy()\n    features = pd.merge(features,rusher_features,on=['GameId','PlayId'],how='inner')\n    #print(features.head())\n    df[\"CrossesWithin_1\"] = features[['X','Y','X1sec','Y1sec','rusher_X','rusher_Y','rusher_X1sec','rusher_Y1sec']].apply(lambda x: calc_intersection(x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7]), axis=1)\n    df[\"CrossesWithin_3\"] = features[['X','Y','X3sec','Y3sec','rusher_X','rusher_Y','rusher_X3sec','rusher_Y3sec']].apply(lambda x: calc_intersection(x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7]), axis=1)\n    return df\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function Generation"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass CategoricalFeaturesProcessor(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X):\n        return self #do nothing\n    def transform(self, X):\n        X['Team'] = X['Team'].apply(lambda x: x.strip()=='home')\n        X.drop(['DisplayName'], axis=1, inplace=True)\n        X['GameClock'] = X['GameClock'].apply(convert_to_seconds)\n        \n        X[\"PossessionTeam\"] = X[\"PossessionTeam\"].replace(\"ARZ\", \"ARI\")\n        X[\"PossessionTeam\"] = X[\"PossessionTeam\"].replace(\"BLT\", \"BAL\")\n        X[\"PossessionTeam\"] = X[\"PossessionTeam\"].replace(\"CLV\", \"CLE\")\n        X[\"PossessionTeam\"] = X[\"PossessionTeam\"].replace(\"HST\", \"HOU\")\n        X[\"FieldPosition\"] = X[\"FieldPosition\"].replace(\"ARZ\", \"ARI\")\n        X[\"FieldPosition\"] = X[\"FieldPosition\"].replace(\"BLT\", \"BAL\")\n        X[\"FieldPosition\"] = X[\"FieldPosition\"].replace(\"CLV\", \"CLE\")\n        X[\"FieldPosition\"] = X[\"FieldPosition\"].replace(\"HST\", \"HOU\")\n        X[\"FieldPosition\"] = X[\"FieldPosition\"].replace(np.nan, \"UNKNOWN\")\n        \n        X['HomePossession'] = X['PossessionTeam'] == X['HomeTeamAbbr']\n        X['HomeField'] = X['FieldPosition'] == X['HomeTeamAbbr']\n        X['PossessionInOwnField'] = X['FieldPosition'] == X['PossessionTeam']\n        X = recalculate_yardline(X)\n        X.drop([\"PossessionTeam\", \"HomeTeamAbbr\", \"VisitorTeamAbbr\", \"FieldPosition\"], axis=1, inplace=True)\n        \n        X[\"OffenseFormation\"] = X[\"OffenseFormation\"].replace(np.nan, \"UNKNOWN\")\n        X['OffenseFormation'] = X['OffenseFormation'].apply(classify_offense_formation)\n        #do one hot encoding\n        X['off_form_singleback'] = X['OffenseFormation'] == \"singleback\"\n        X['off_form_shotgun'] = X['OffenseFormation'] == \"shotgun\"\n        X['off_form_i_form'] = X['OffenseFormation'] == \"i_form\"\n        X['off_form_pistol'] = X['OffenseFormation'] == \"pistol\"\n        X['off_form_jumbo'] = X['OffenseFormation'] == \"jumbo\"\n        X['off_form_wildcat'] = X['OffenseFormation'] == \"wildcat\"\n        X['off_form_empty'] = X['OffenseFormation'] == \"empty\"\n        X['off_form_ace'] = X['OffenseFormation'] == \"ace\"\n        X['off_form_unknown'] = X['OffenseFormation'] == \"unknown\"\n        X.drop([\"OffenseFormation\"], axis=1, inplace=True)\n        \n        offense_dict = {'DB' : \"offense_DB\", 'DL' : \"offense_DL\", \n                        'LB' : \"offense_LB\", 'OL' : \"offense_OL\", \n                        'QB' : \"offense_QB\", 'RB' : \"offense_RB\", \n                        'TE' : \"offense_TE\", 'WR' : \"offense_WR\"}\n        for key in offense_dict.keys():\n            X[offense_dict[key]] = np.zeros((X.shape[0],1))\n        X[\"offense_UNKNOWN\"] = np.zeros((X.shape[0],1))\n        X = X.apply(ProcessOffensePersonnel, axis=1)\n        \n        defense_dict = {'DB' : \"defense_DB\", 'DL' : \"defense_DL\", \n                        'LB' : \"defense_LB\", 'OL' : \"defense_OL\"}\n        for key in defense_dict.keys():\n            X[defense_dict[key]] = np.zeros((X.shape[0],1))\n        X[\"defense_UNKNOWN\"] = np.zeros((X.shape[0],1))\n        X = X.apply(ProcessDefensePersonnel, axis=1)\n        \n        X.drop([\"OffensePersonnel\", \"DefensePersonnel\"], axis=1, inplace=True)\n            \n        X['PlayDirection'] = X['PlayDirection'].apply(lambda x: x.strip() == 'right')\n        X = recalculate_pos_and_dir(X)\n        \n        X = features_relative_coordinates(X)\n        X = defense_features(X)\n        X = dist_to_rusher_features(X)\n        X = additional_time_series_features(X)\n        X = calc_crossing_movements(X)\n        \n        X['TimeHandoff'] = X['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n        X['TimeSnap'] = X['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n        X['PlayerBirthDate'] = X['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n        X['TimeSnapToHandoff'] = X.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n        seconds_in_year = 60*60*24*365\n        X['PlayerAge'] = X.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n        X.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1, inplace=True)\n        \n        X['PlayerHeight'] = X['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n        \n        X['PlayerBMI'] = 703*(X['PlayerWeight']/(X['PlayerHeight'])**2)\n        \n        X.drop([\"PlayerCollegeName\"], axis=1, inplace=True)\n        X.drop([\"Position\"], axis=1, inplace=True)\n        X.drop([\"Stadium\"], axis=1, inplace=True)\n        \n        X['StadiumType'] = X['StadiumType'].apply(classify_stadium_type)\n        \n        X['Turf'] = X['Turf'].apply(classify_turf_type)\n        \n        X.drop([\"Location\"], axis=1, inplace=True)\n        \n        X['GameWeather'] = X['GameWeather'].apply(classify_weather)\n        #Do One Hot Encoding\n        X['weather_cloudy'] = X['GameWeather'] == \"cloudy\"\n        X['weather_sunny'] = X['GameWeather'] == \"sunny\"\n        X['weather_indoor'] = X['GameWeather'] == \"indoor\"\n        X['weather_rainy'] = X['GameWeather'] == \"rainy\"\n        X['weather_snow'] = X['GameWeather'] == \"snow\"\n        X.drop([\"GameWeather\"], axis=1, inplace=True)\n        \n        X.drop([\"WindSpeed\", \"WindDirection\"], axis=1, inplace=True)\n        \n        return X\n    \ncat_feat_processor = CategoricalFeaturesProcessor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Engineering of integer features"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"int_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class NumericalFeatureProcessor(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X):\n        return self #do nothing\n    def transform(self, X):\n        X['IsRusher'] = X['NflId'] == X['NflIdRusher']\n        X.drop(['NflId', 'NflIdRusher'], axis=1, inplace=True)\n        \n        temp_train = X[X[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n        X = X.merge(temp_train, on = \"PlayId\")\n        X[\"RusherTeam\"] = X[\"Team\"] == X[\"RusherTeam\"]\n        \n        X.drop([\"Season\", \"Week\"], axis=1, inplace=True)\n        \n        X['YardsLeft'] = X.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n        X['YardsLeft'] = X.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)\n        \n        X[\"diffScoreBeforePlay\"] = X[\"HomeScoreBeforePlay\"] - X[\"VisitorScoreBeforePlay\"]\n        \n        X[\"Orientation\"].fillna(0, inplace=True)\n        X[\"Dir\"].fillna(0, inplace=True)\n        X[\"DefendersInTheBox\"].fillna(train[\"DefendersInTheBox\"].median(), inplace=True)\n        X[\"Temperature\"].fillna(train[\"Temperature\"].mean(), inplace=True)\n        X[\"Humidity\"].fillna(train[\"Humidity\"].mean(), inplace=True)\n        X.fillna(-999, inplace=True) #default\n        \n        return X\n    \nnum_feat_processor = NumericalFeatureProcessor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Engineering of Float Features"},{"metadata":{"trusted":false},"cell_type":"code","source":"float_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Transformation Classes & Run Pipe"},{"metadata":{"trusted":false},"cell_type":"code","source":"train[train[\"PlayId\"] == 20170907000118]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = cat_feat_processor.fit_transform(train)\ntrain = num_feat_processor.fit_transform(train)\n\ncat_features = []\nint_features = []\nfloat_features = []\nbool_features = []\nuint8_features = []\nfor col in train.columns:\n    #print(train[col].dtype) #print out to check datatypes\n    if train[col].dtype =='object':\n        cat_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='int64':\n        int_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='float64':\n        float_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='bool':\n        bool_features.append((col, len(train[col].unique())))\n    if train[col].dtype =='uint8':\n        uint8_features.append((col, len(train[col].unique())))\n        \n''' contained datatypes\nint64\nobject\nfloat64\n'''\nprint(\"{} columns in total\".format(train.shape[1]))\nprint(\"{} Categorical Features found.\".format(len(cat_features)))\nprint(\"{} Integer Features found.\".format(len(int_features)))\nprint(\"{} Float Features found.\".format(len(float_features)))\nprint(\"{} Boolean Features found.\".format(len(bool_features)))\nprint(\"{} uint8 OneHot Features found.\".format(len(uint8_features)))\n\nprint(\"Integer Features:\\n{}\".format(int_features))\nprint(\"Floating Features:\\n{}\".format(float_features))\nprint(\"Boolean Features:\\n{}\".format(bool_features))\nprint(\"Uint OneHot Features:\\n{}\".format(uint8_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train[train[\"PlayId\"] == 20170907000118]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(calc_intersection(-1, 0, 1, 0, 0, 1, 0, -1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train[\"CrossesWithin_1\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"280b0090-ad48-4c21-91fb-4f762159b74e","_uuid":"14db5230-0ae7-448c-b595-b9683230fe91"},"cell_type":"markdown","source":"# Test & Validation Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"## Trainingdata Generation Class"},{"metadata":{"trusted":false},"cell_type":"code","source":"class TrainingDataPreparation(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X):\n        return self #do nothing\n    def transform(self, X):\n        X = X.sort_values(by=['PlayId', 'RusherTeam', 'IsRusher', 'dist_to_rusher']).reset_index()\n        \n        unused_columns = [\"GameId\",\"PlayId\",\"Team\",\"IsRusher\", \"index\"]\n        unique_columns = [\"X\", \"Y\", \"S\", \"A\", \"X1sec\", \"Y1sec\", \"X3sec\", \"Y3sec\", \"RusherTeam\", \"CrossesWithin_1\", \"CrossesWithin_3\", \"dist_to_rusher\", \"Dis\", \"Orientation\", \"Dir\", \"JerseyNumber\", \"PlayerHeight\", \"PlayerWeight\", \"PlayerAge\", \"PlayerBMI\"]\n        \n        #params that are fed into NN:\n        \n        # 20*22 = 440 params for every player individually, sorted by RusherTeam first, Rusher first, distance_to_rusher\n        # X, Y, S, A, X1, Y1, X3, Y3, CrossesWithin_1, CrossesWithin_3,\n        # dist_to_rusher,Dis,Orientation,Dir,JerseyNumber,PlayerHeight,PlayerWeight,PlayerAge,PlayerBMI,RusherTeam\n        \n        #global params:\n        #4 def_min_dist, def_max_dist, def_mean_dist, def_std_dist, \n        #3 rusher_yards_to_go, rusher_oriented_back, rusher_moving_back,\n        #4 min_dist, max_dist, mean_dist, std_dist, \n        #8 Quarter, GameClock, Down, Distance, HomeScoreBeforePlay, VisitorScoreBeforePlay, DefendersInTheBox, PlayDirection,\n        #9 Yards(!!!), StadiumType, Turf, Temperature, Humidity, HomePossession, HomeField, PossessionInOwnField, YardLine, \n        #5 off_form_singleback, off_form_shotgun, off_form_i_form, off_form_pistol, off_form_jumbo,\n        #4 off_form_wildcat, off_form_empty, off_form_ace, off_form_unknown, \n        #9 offense_DB, offense_DL, offense_LB, offense_OL, offense_QB, offense_RB, offense_TE, offense_WR, offense_UNKNOWN, \n        #5 defense_DB, defense_DL, defense_LB, defense_OL, defense_UNKNOWN,\n        #1 TimeSnapToHandoff, \n        #5 weather_cloudy, weather_sunny, weather_indoor, weather_rainy, weather_snow, \n        #2 YardsLeft, diffScoreBeforePlay\n        #in total 59 global params\n        \n        #499 params in total\n        \n        \n        #original columns\n        #2 'GameId', 'PlayId', --> unused\n        #5 'X1', 'Y1', 'X3', 'Y3', 'dist_to_rusher', --> player\n        #4 'def_min_dist', 'def_max_dist', 'def_mean_dist', 'def_std_dist', --> global\n        #3 'rusher_yards_to_go', 'rusher_oriented_back', 'rusher_moving_back', --> global\n        #4 'min_dist', 'max_dist', 'mean_dist', 'std_dist', --> global\n        #1 'Team', --> unused\n        #8 'X', 'Y', 'S', 'A', 'Dis', 'Orientation', 'Dir', 'JerseyNumber', --> player\n        #5 'Quarter', 'GameClock', 'Down', 'Distance', 'HomeScoreBeforePlay', --> global\n        #3 'VisitorScoreBeforePlay', 'DefendersInTheBox', 'PlayDirection',  --> global\n        #1 'Yards', --> target\n        #2 'PlayerHeight', 'PlayerWeight', --> player\n        #3 'StadiumType', 'Turf', 'Temperature', --> global\n        #5 'Humidity', 'HomePossession', 'HomeField', 'PossessionInOwnField', 'YardLine', --> global\n        #5 'off_form_singleback', 'off_form_shotgun', 'off_form_i_form', 'off_form_pistol', 'off_form_jumbo', --> global\n        #4 'off_form_wildcat', 'off_form_empty', 'off_form_ace', 'off_form_unknown', --> global\n        #9 'offense_DB','offense_DL','offense_LB','offense_OL','offense_QB','offense_RB','offense_TE','offense_WR','offense_UNKNOWN', --> global\n        #5 'defense_DB', 'defense_DL', 'defense_LB', 'defense_OL', 'defense_UNKNOWN', --> global\n        #2 'CrossesWithin_1', 'CrossesWithin_3', --> player\n        #1 'TimeSnapToHandoff', --> global\n        #2 'PlayerAge', 'PlayerBMI', --> player\n        #5 'weather_cloudy', 'weather_sunny', 'weather_indoor', 'weather_rainy', 'weather_snow', --> global\n        #1 'IsRusher', --> unused\n        #1 'RusherTeam', --> player\n        #2 'YardsLeft', 'diffScoreBeforePlay' --> global\n        #58 globals + yards as target\n        #20 player\n        #4 unused + index\n        \n        \n        training_cols = []\n        for c in X.columns:\n            if c not in unique_columns + unused_columns:\n                training_cols.append(c)\n        for c in unique_columns:\n            for i in range(22):\n                training_cols.append(c+str(i))\n        \n        #print(\"{} columns\\n{}\".format(len(training_cols), training_cols))\n        \n        training_data=np.zeros((X.shape[0]//22,len(training_cols)))\n        for i in range(0,X.shape[0],22):#for all plays\n            count=0\n            for c in training_cols:\n                if c in X: #not in unique_columns and not in unused_columns\n                    training_data[i//22][count] = X[c][i]\n                    count+=1\n            for c in unique_columns:\n                for j in range(22):\n                    training_data[i//22][count] = X[c][i+j]\n                    count+=1\n        X = pd.DataFrame(data=training_data, columns=training_cols)\n        \n        return X\n    \ntrain_dat_prep = TrainingDataPreparation()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trainingdata Generation Test"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transformed = train_dat_prep.fit_transform(train)\nprint(train_transformed.shape)\nprint(train_transformed.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Normalization"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train = train_transformed[\"Yards\"]\nX_train = train_transformed.drop([\"Yards\"], axis=1)\nprint(y_train.shape)\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"scaler_X = PowerTransformer()\n#scaler_X = StandardScaler()\nX_train = scaler_X.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#from sklearn.preprocessing import StandardScaler\n#scaler_y = StandardScaler()\n#y_train = y_train.values\n#scaler_y.fit(y_train.reshape(-1,1))\n#y_train = scaler_y.transform(y_train.reshape(-1, 1)).flatten()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{},"cell_type":"markdown","source":"## Building & Training"},{"metadata":{"trusted":false},"cell_type":"code","source":"batch_size=512\nprint(\"Shape of X_train: {}\".format(X_train.shape))\nprint(\"Shape of y_train: {}\".format(y_train.shape))\n\nX_train_nn = X_train\n\ny_train_nn = np.zeros(shape=(X_train.shape[0], 199))\nfor i,yard in enumerate(y_train.astype(int)):\n    y_train_nn[i, yard+99:] = np.ones(shape=(1, 100-yard))\n\nprint(\"Shape of X_train for NN: {}\".format(X_train_nn.shape))\nprint(\"Shape of y_train for NN: {}\".format(y_train_nn.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#from https://www.kaggle.com/davidcairuz/nfl-neural-network-w-softmax\ndef crps(y_true, y_pred):\n    return K.mean(K.square(y_true - K.cumsum(y_pred, axis=1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"'''def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=384, input_shape=[X_train.shape[1]])(x)\n    act1 = keras.layers.PReLU()(fc1)\n    #bn1 = keras.layers.BatchNormalization()(act1)\n    dp1 = keras.layers.Dropout(0.7)(act1)\n    concat1 = keras.layers.Concatenate()([x, dp1])\n    fc2 = keras.layers.Dense(units=320)(concat1)\n    act2 = keras.layers.PReLU()(fc2)\n    bn2 = keras.layers.BatchNormalization()(act2)\n    dp2 = keras.layers.Dropout(0.6)(bn2)\n    concat2 = keras.layers.Concatenate()([x, dp2])\n    fc3 = keras.layers.Dense(units=256)(concat2)\n    act3 = keras.layers.PReLU()(fc3)\n    #bn3 = keras.layers.BatchNormalization()(act3)\n    dp3 = keras.layers.Dropout(0.5)(act3)\n    output = keras.layers.Dense(units=199, activation='softmax')(dp3)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model'''\n\n'''def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=512, activation=\"relu\", input_shape=[X_train.shape[1]])(x)\n    dp1 = keras.layers.Dropout(0.4)(fc1)\n    fc2 = keras.layers.Dense(units=256, activation=\"relu\")(dp1)\n    dp2 = keras.layers.Dropout(0.2)(fc2)\n    output = keras.layers.Dense(units=199, activation='softmax')(dp2)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model'''\n\ndef get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=384, activation=\"relu\", input_shape=[X_train.shape[1]])(x)\n    bn1 = keras.layers.BatchNormalization()(fc1)\n    dp1 = keras.layers.Dropout(0.5)(bn1)\n    fc2 = keras.layers.Dense(units=256, activation=\"relu\")(dp1)\n    bn2 = keras.layers.BatchNormalization()(fc2)\n    dp2 = keras.layers.Dropout(0.5)(bn2)\n    output = keras.layers.Dense(units=199, activation='softmax')(dp2)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model\n\n'''def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=384, input_shape=[X_train.shape[1]])(x)\n    act1 = keras.layers.PReLU()(fc1)\n    dp1 = keras.layers.Dropout(0.7)(act1)\n    fc2 = keras.layers.Dense(units=320)(dp1)\n    act2 = keras.layers.PReLU()(fc2)\n    dp2 = keras.layers.Dropout(0.6)(act2)\n    fc3 = keras.layers.Dense(units=256)(dp2)\n    act3 = keras.layers.PReLU()(fc3)\n    dp3 = keras.layers.Dropout(0.5)(act3)\n    output = keras.layers.Dense(units=199, activation='softmax')(dp3)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model'''\n\n'''def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=1024, activation=\"relu\", input_shape=[X_train.shape[1]])(x)\n    bn1 = keras.layers.BatchNormalization()(fc1)\n    dp1 = keras.layers.Dropout(0.5)(bn1)\n    fc2 = keras.layers.Dense(units=512, activation=\"relu\")(dp1)\n    bn2 = keras.layers.BatchNormalization()(fc2)\n    dp2 = keras.layers.Dropout(0.5)(bn2)\n    fc3 = keras.layers.Dense(units=512, activation=\"relu\")(dp2)\n    bn3 = keras.layers.BatchNormalization()(fc3)\n    dp3 = keras.layers.Dropout(0.5)(bn3)\n    output = keras.layers.Dense(units=199, activation='softmax')(dp3)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model'''\n\n\nearlyStopping = EarlyStopping(\n    monitor='val_loss',\n    patience=15,\n    verbose=1,\n    mode='min',\n    restore_best_weights=True,\n    min_delta=1e-5\n)\n\nreduceLR = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=8,\n    min_lr=1e-6,\n    verbose=1,\n    mode='min'\n)\n\n\n\n\ndef train_model(X_train, y_train, X_val, y_val):\n    model = get_model()\n    #model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-6), loss=crps)\n    model.compile(optimizer=Adam(lr=1e-4), loss=crps)\n    checkPoint = ModelCheckpoint('best_model.h5',monitor='val_loss',mode='min', save_best_only=True, verbose=1, save_weights_only=True)\n    model.fit(X_train, y_train, epochs=150, callbacks=[earlyStopping, reduceLR, checkPoint], validation_data=[X_val, y_val], batch_size=batch_size)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold\n\nrkf = RepeatedKFold(n_splits=5, n_repeats=1)\n\nmodels = []\n\nfor tr_idx, vl_idx in rkf.split(X_train_nn, y_train_nn):\n    \n    x_tr, y_tr = X_train_nn[tr_idx], y_train_nn[tr_idx]\n    x_vl, y_vl = X_train_nn[vl_idx], y_train_nn[vl_idx]\n    \n    model = train_model(x_tr, y_tr, x_vl, y_vl)\n    model.load_weights(\"best_model.h5\")\n    models.append(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation Function"},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_model(models[0], to_file=\"mymodel.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def make_pred_nn(df, models):\n    tdata_local = cat_feat_processor.fit_transform(df)\n    tdata_local = num_feat_processor.fit_transform(tdata_local)\n    tdata_local = train_dat_prep.fit_transform(tdata_local)\n    #y_train = tdata_local[\"Yards\"] #not used\n    #print(\"Shape after transform: {}\".format(tdata_local.shape))\n    if (\"Yards\" in tdata_local.columns):\n        tdata_local = tdata_local.drop([\"Yards\"], axis=1)\n    tdata_local = scaler_X.transform(tdata_local)\n    \n    #print(\"Training Data shape: {}\".format(tdata_local.shape))\n    #print(\"Models shape: {}\".format(len(models)))\n    y_pred = np.zeros((tdata_local.shape[0], 199))        \n    for model in models:\n        y_pred += np.cumsum(model.predict(tdata_local), axis=1)\n    y_pred = y_pred/len(models)\n    #print(\"Output shape: {}\".format(y_pred.shape))\n    return y_pred\n    \n\ndef make_pred_env_nn(df, sample_prediction, env, models):\n    y_pred = make_pred_nn(df, models)\n    env.predict(pd.DataFrame(data=y_pred.clip(0,1),columns=sample_prediction.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate Neural Network on Taining Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"#train_evaluate_nn = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"'''\ny_prediction_nn = np.zeros((X_train_nn.shape[0],199))\ny_true_nn = np.zeros((X_train_nn.shape[0],199))\n\nnum_plays = train_evaluate_nn[\"PlayId\"].unique().shape[0]\nprint(\"Evaluating {} plays.\".format(num_plays))\n\nindex = 0\nfor play in tqdm.tqdm(train_evaluate_nn[\"PlayId\"].unique()):\n    current_play = train_evaluate_nn[train_evaluate_nn[\"PlayId\"] == play].copy()\n    #print(\"Play-ID: {} Shape before transform: {}\".format(play, current_play.shape))\n    y_pred = make_pred_nn(current_play, models)\n    #print(\"Predicted y: {}\".format(y_pred))\n    y_prediction_nn[index] = y_pred[0]\n    y_true_val = current_play[\"Yards\"].values[0]\n    y_true = np.zeros((1, 199))\n    y_true[0, y_true_val+99:] = np.ones((1, 100-y_true_val))\n    y_true_nn[index] = y_true[0]\n    #print(\"True y: {}\\n{}\".format(y_true_val, y_true))  \n    index = index + 1\n'''    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#print(\"Validation score NN:\",np.sum(np.power(y_prediction_nn-y_true_nn,2))/(199*(num_plays)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate Neural Network on Test Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"for test, sample_prediction in tqdm.tqdm(env.iter_test()):\n     make_pred_env_nn(test, sample_prediction, env, models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"181.969px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}