{"cells":[{"metadata":{},"cell_type":"markdown","source":"日本語での説明と予測モデルの一例をかきました。説明はアメリカンフットボールを知らない方のとりかかり向けです。  \n長すぎて読まないという方は最後のセルだけみてください。TL;DR: See the last cell.  \n誤りがありましたらコメントいただけますと幸いです。\n  \n<span style=\"color:crimson\">2019-10-17 「ヤードラインの数値について補足」箇所に追記しました。</span>"},{"metadata":{},"cell_type":"markdown","source":"## やること\n\nアメリカンフットボールでは、1回のプレイごとに、攻撃側のチームが前進しようとします。  \n1回のプレイで攻撃側のチームが何ヤード前進できたかを「ゲイン」とよびます（逆に後退してしまいマイナスになることもあります）。  \n今回やることは、プレイのときの状況（各選手がどこにいてどちらに動いているかや、何回目の攻撃かや、天候など）から、そのプレイにおけるゲインを予測することです。  \n特に今回の予測対象は、「ボールを手渡された選手が走って前進する」ようなプレイ（ランプレイ）に限られています（ボールを手渡さずに投げて前進するパスプレイなどもありますが、データに含まれているのはランプレイがとられたプレイのみであるようです）（[Overview](https://www.kaggle.com/c/nfl-big-data-bowl-2020) には、ナショナルフットボールリーグではプレイの約3分の1がランプレイであるとあります）。  \n \n具体的には、予測対象のプレイに対して、-99ヤードから99ヤードまで1ヤード刻みに「ゲインがそのヤード以下である確率値」を出します（※）。  \n-99ヤードも後退してしまうことはまずないので、Yards-99 はまず 0.0 になります。  \n99ヤードよりも前進することもまずないので、Yards99 もまず 1.0 になります。  \nこの 0.0 から 1.0 までの間を適切につないだ予測分布を出すことになります（累積分布なので、距離が増加したら確率値は同じか増えます。減ることはありません）。例えば、プレイ1に対して「ゲインは絶対に0ヤードだと思う」と予測するなら、Yards-1 までは 0.0、Yards0 からは 1.0 になります。プレイ2に対して「ゲインが0ヤードか1ヤードか半々だと思う」と予測するなら、Yards0 は 0.5、Yard1 以降は 1.0 といった具合です。\n\n|  PlayId  |  Yards-99  |  Yards-98  |  ...  |  Yards-1  |  Yards0  |  Yards1  |  ...  |  Yards98  |  Yards99  |\n| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n|  プレイ1  |  0.0  |  0.0  |  ...  |  0.0  |  1.0  |  1.0  |  ...  |  1.0  |  1.0  |\n|  プレイ2  |  0.0  |  0.0  |  ...  |  0.0  |  0.5  |  1.0  |  ...  |  1.0  |  1.0  |\n　  \n※ 芝生エリアの x 方向の長さは100ヤードなので（ [Data](https://www.kaggle.com/c/nfl-big-data-bowl-2020/data) のイラスト）、戦線が前進するにしても後退するにしても移動距離は100ヤード未満です。  \n  \n---\n  \nまた、このコンペティションは Kaggle Kernel から専用のAPIを利用して取り組まなければなりません（ [NFL Big Data Bowl Official Starter Notebook](https://www.kaggle.com/dster/nfl-big-data-bowl-official-starter-notebook) ）。  \n予測するときはイテレータを回して順々に予測します。  \nただ、このようなルールになるのはおそらく当然です。なぜなら、1回のゲーム内でプレイは何度も繰り返され続いていくので、次のプレイの開始位置（YardLine）が先にわかってしまうと現在のプレイの開始位置との差をとることでゲインはわかってしまうからです（次のプレイがランプレイでなかった場合はデータに含まれないので直接開始位置はわかりませんが、2つ以上先のプレイであっても未来の情報が手に入るのはまずいです）。  \n逆にこのルールでは、直前のプレイの情報までは予測に取り込むということがありえそうです。  \n\n## 評価指標\n\n予測累積分布と真の累積分布の分布間の2乗誤差で評価されます（ [Evaluation](https://www.kaggle.com/c/nfl-big-data-bowl-2020/overview/evaluation) ）。  \n※ $H(n - Y_m)$ は、真のゲイン $Y_m$ 未満の $n$ については $0$、 $Y_m$ 以上の $n$ については $1$ をとる、真の累積分布です。  \n※ 評価データ内の各プレイに対して2乗誤差が計算され、全プレイで平均されます。  \n\n\nまた特筆すべきなのは、Public Leaderboard のスコアはナショナルフットボールリーグの2019年のレギュラーシーズン（2019年9月～12月）の最初の数週間のデータで算出されるのに対し、最終順位に使用されるスコアはそれ以降のデータ（ので、コンペティション開始時点でまだ行われていない試合のデータになると思います）で算出されるという点です（ [NFL Big Data Bowl Official Starter Notebook](https://www.kaggle.com/dster/nfl-big-data-bowl-official-starter-notebook) ）。  \n\nなお、訓練データに含まれているのは2017年と2018年のシーズンのデータになります（Seasonカラム参照）。  \n\n## 訓練データ\ntrain.csv の各行はそのプレイでのある選手の特徴です。  \nなので、あるプレイのゲインを予測するときは、その PlayId をもつレコード全てをもとにすることになるはずです。  \n中には特定の選手の特徴ではなく、プレイ内で共通の特徴やゲーム内で共通の特徴もあります（確認コードは下部です）。  \nプレイは時系列に並んでいます。  \n以下に各カラムのメモをかきました。\n\n```\nGameId                      int64 # ゲームの識別IDです。\nPlayId                      int64 # プレイの識別IDです。\nTeam                       object # この選手がホーム側チームかアウェイ側チームかです。\nX                         float64 # ハンドオフ時刻におけるこの選手の位置の X 座標です。\nY                         float64 # ハンドオフ時刻におけるこの選手の位置の Y 座標です。\nS                         float64 # ハンドオフ時刻におけるこの選手の速度です。\nA                         float64 # ハンドオフ時刻におけるこの選手の加速度です。\nDis                       float64 # （おそらくスナップ時刻から）ハンドオフ時刻までのこの選手の移動距離です。\nOrientation               float64 # ハンドオフ時刻におけるこの選手が向いている向きです（角度の定義はイラスト参照）。？\nDir                       float64 # ハンドオフ時刻におけるこの選手が動いている向きです（角度の定義はイラスト参照）。？\nNflId                       int64 # 選手の識別IDです。\nDisplayName                object # 選手の名前です。\nJerseyNumber                int64 # 選手の背番号です。\nSeason                      int64 # 2017シーズンか2018シーズンかです。《 GameId 内共通 》\nYardLine                    int64 # ヤードライン： プレイの開始位置です（X 座標ではありません）。《 PlayId 内共通 》\nQuarter                     int64 # ゲーム内の第何クォーターであるかです（1クォーターは15分）。《 PlayId 内共通 》\nGameClock                  object # クォーターの残り時間です。《 PlayId 内共通 》\nPossessionTeam             object # どちらのチームが攻撃しているかです。《 PlayId 内共通 》\nDown                        int64 # 第何ダウンの攻撃であるかです。《 PlayId 内共通 》\nDistance                    int64 # 次の4ダウンの攻撃権を得るためにあと何ヤード進まなければならないかです。《 PlayId 内共通 》\nFieldPosition              object # ヤードラインがどちらのチームの陣地かです。ヤードラインがちょうど50ヤードならNaNです。《 PlayId 内共通 》\nHomeScoreBeforePlay         int64 # プレイ直前のホーム側チームの得点です。《 PlayId 内共通 》\nVisitorScoreBeforePlay      int64 # プレイ直前のアウェイ側チームの得点です。《 PlayId 内共通 》\nNflIdRusher                 int64 # ランプレイする選手の NflId です。《 PlayId 内共通 》\nOffenseFormation           object # 攻撃側のフォーメーションです。《 PlayId 内共通 》\nOffensePersonnel           object # 攻撃側の人員配置です。《 PlayId 内共通 》\nDefendersInTheBox         float64 # ボックスといわれるエリア内にいる守備側の人数です。《 PlayId 内共通 》\nDefensePersonnel           object # 守備側の人員配置です。《 PlayId 内共通 》\nPlayDirection              object # このプレイが前進する向きが右方向(+x)か左方向(-x)かどちらかです。《 PlayId 内共通 》\nTimeHandoff                object # ハンドオフ時刻： ランプレイする選手がボールを手渡された時刻です。《 PlayId 内共通 》\nTimeSnap                   object # スナップ時刻： センターの選手がボールをスナップした時刻です。《 PlayId 内共通 》\nYards                       int64 ########## そのプレイにおけるゲイン（予測対象）です。《 PlayId 内共通 》 ##########\nPlayerHeight               object # 選手の身長です（フィート - インチ）。\nPlayerWeight                int64 # 選手の体重です（ポンド）。\nPlayerBirthDate            object # 選手の誕生日です。\nPlayerCollegeName          object # 選手の出身大学です。\nPosition                   object # 選手のポジションです。\nHomeTeamAbbr               object # ホーム側チーム名です。《 GameId 内共通 》\nVisitorTeamAbbr            object # アウェイ側チーム名です。《 GameId 内共通 》\nWeek                        int64 # シーズン開幕何週目かです。《 GameId 内共通 》\nStadium                    object # スタジアムです。《 GameId 内共通 》\nLocation                   object # スタジアムがある都市です。《 GameId 内共通 》\nStadiumType                object # 屋外スタジアムかとかです。《 GameId 内共通 》\nTurf                       object # 天然芝とか人工芝とかです。《 GameId 内共通 》\nGameWeather                object # 天気です。《 GameId 内共通 》\nTemperature               float64 # 温度です。《 GameId 内共通 》\nHumidity                  float64 # 湿度です。《 GameId 内共通 》\nWindSpeed                  object # 風速です。《 GameId 内共通 》\nWindDirection              object # 風向です。《 GameId 内共通 》\n```"},{"metadata":{},"cell_type":"markdown","source":"### ヤードラインの数値について補足 \n\nヤードラインは X 座標ではなく [Data](https://www.kaggle.com/c/nfl-big-data-bowl-2020/data) のイラスト内の白い線の数値であることに注意してください。  \n例えば、訓練データの1行目では、ヤードラインは「NE チーム側（ FieldPosition ）35」とあります。  \nNEチームの陣地が X 座標の小さい側なら 10 + 35 = 45、X 座標の大きい側なら 110 - 35 = 75 がヤードラインの X 座標です。  \nこのプレイIDでの選手の X 座標の平均は約 74 なので、このクォーターでの NE チームの陣地は X 座標の大きい側であり、ヤードラインの X 座標は 75 であるとわかります。  \n陣地は基本的にはクォーターごとに入れ替わります。\n\n<span style=\"color:crimson\">\n※ 2019-10-17 追記  \nヤードライン（YardLine）の X 座標はヤードラインが攻撃側チームにとって自陣か敵陣か ＆ PlayDirection で特定できます。  \n 　right (+X方向) に前進かつ自陣にいるなら左半面にいる →  10 + df['YardLine']  \n 　left (-X方向) に前進かつ自陣にいるなら右半面にいる → 110 - df['YardLine']  \n 　right (+X方向) に前進かつ敵陣にいるなら右半面にいる → 110 - df['YardLine']  \n 　left (-X方向) に前進かつ敵陣にいるなら左半面にいる →  10 + df['YardLine']  \n自陣か敵陣かは、ランプレイする選手 (NflIdRusher == NflId である選手) のチーム名を特定し  \n（Team が home なら HomeTeamAbbr、away なら VisitorTeamAbbr がランプレイする選手のチーム名です）、  \nそれが FieldPosition と一致するかどうかで特定できます。  \n例えば、訓練データで最初に NflIdRusher == NflId である行をみると、このプレイでランプレイする選手の Team は home であり、  \nつまり、HomeTeamAbbr より、NEチームです。  \nかつ、FieldPosition も NE チームなので、ヤードラインは攻撃側チームにとって自陣にあります。  \nそして、PlayDirection は left なので、-X 方向に進んでいます。  \nよって、 -X 方向に前進かつ自陣にいるので右半面にいることがわかり、110 - 35 = 75 がヤードラインの X 座標です。\n</span>"},{"metadata":{},"cell_type":"markdown","source":"## データ読み込み\n\nまずデータを読み込みます。  \n以下ではデータを読み込んだ後にプレイ内で共通の特徴やゲーム内で共通の特徴を調べています。"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n\n# PlayId, GameId 内で共通の値であるカラムを調べる\n# 明らかに選手の特徴であるカラムは除く\nfeats_player = ['Team', 'X', 'Y', 'S', 'A', 'Dis', 'Orientation', 'Dir', \n                'NflId', 'DisplayName', 'JerseyNumber', 'PlayerHeight', 'PlayerWeight', \n                'PlayerBirthDate', 'PlayerCollegeName', 'Position']\n\nfor id_ in ['PlayId', 'GameId']:\n    df_ = df.drop(columns=feats_player)\n    groups = df_.groupby(id_)\n    s = groups.agg(lambda s: len(s.unique())).apply(max) # Id内でユニークな値の個数の最大値\n    print('---------- ' + id_ + ' 内共通 ----------')\n    for index, value in s.iteritems():\n        if value == 1:\n            print(index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 素朴なモデル\n\nアメリカンフットボールのルールに基づいて素朴なモデルを考えてみます。  \nアメリカンフットボールでは、攻撃側のチームは連続して4回（4ダウン）攻撃できますが、4ダウン以内に10ヤード前進しなければ攻撃権を維持できません。  \nつまり、そのプレイが第何ダウンであるかでどれだけ前進するかの戦略が変わってくると思います。ダウン別のヒストグラムをかいてみます。\nすると、第4ダウンにいくほどデータは少ないですが、ゲインが小さい方に偏っていることがわかります（以下）。  "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ndf_play = df.drop_duplicates(subset='PlayId')\nplays_down1 = df_play[df_play['Down'] == 1]\nplays_down2 = df_play[df_play['Down'] == 2]\nplays_down3 = df_play[df_play['Down'] == 3]\nplays_down4 = df_play[df_play['Down'] == 4]\nprint(plays_down1.shape)\nprint(plays_down2.shape)\nprint(plays_down3.shape)\nprint(plays_down4.shape)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12, 4\nrcParams['font.size'] = 16\nplt.hist(plays_down1['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='r', label='down1')\nplt.hist(plays_down2['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='b', label='down2')\nplt.hist(plays_down3['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='g', label='down3')\nplt.hist(plays_down4['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='y', label='down4')\nplt.xlim(-20, 30)\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"第3ダウンと第4ダウンはゲインの分布がやや小さい方に偏っているようにみえます。  \n第3ダウンと第4ダウンについて、攻撃権を維持するのに必要な距離が1ヤードの場合とそれより長い場合に分けてプロットしてみます。  \n攻撃権を維持するのに必要な距離が1ヤードの場合が特に小さい方に偏っていることがわかります（以下）。"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(plays_down3[plays_down3['Distance']==1].shape)\nprint(plays_down3[plays_down3['Distance']>1].shape)\nprint(plays_down4[plays_down4['Distance']==1].shape)\nprint(plays_down4[plays_down4['Distance']>1].shape)\n\nplt.hist(plays_down3[plays_down3['Distance']==1]['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='r', label='down3_1')\nplt.hist(plays_down3[plays_down3['Distance']>1]['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='b', label='down3_not1')\nplt.xlim(-20, 30)\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\nplt.show()\n\nplt.hist(plays_down4[plays_down4['Distance']==1]['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='r', label='down4_1')\nplt.hist(plays_down4[plays_down4['Distance']>1]['Yards'], range=(-100, 100), bins=199, density=True, cumulative=True, alpha=0.3, histtype='stepfilled', color='b', label='down4_not1')\nplt.xlim(-20, 30)\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"上の結果をもとに、「そのプレイが第何ダウンか、3 or 4 ダウンなら残りヤードが1かどうか」のみで経験分布をあてるモデルを実装します。  \n先にベンチマークとして、すべてのプレイに同じ経験分布をあてるモデルを実装します。  \n訓練データのうち 2017 シーズンを訓練データ、2018 シーズンを評価データとすることにします。"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_play_2017 = df_play[df_play['Season'] == 2017]\ndf_play_2018 = df_play[df_play['Season'] == 2018]\n\ncd = np.histogram(df_play_2017['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_play_2017)\n\nyard_to_index = {}\nfor i, y in enumerate(range(-99, 100)):\n    yard_to_index[y] = i\n\n# 理論上ありえない確率を削っておく\n# Ex. 自陣35なら、ゲインは 65 以上にならないし、-35 以下にならない\n# Ex. 敵陣35なら、ゲインは 35 以上にならないし、-65 以下にならない\ndef postprocess(cd, target_df):\n    yardline = target_df['YardLine'].iloc[0]\n    own = (target_df['FieldPosition'].iloc[0] == target_df['PossessionTeam'].iloc[0])\n    if own:\n        cd[:yard_to_index[- yardline]] = 0.0\n        cd[yard_to_index[100 - yardline]:] = 1.0\n    else:\n        cd[:yard_to_index[- 100 + yardline]] = 0.0\n        cd[yard_to_index[yardline]:] = 1.0\n\n##### モデル0： 訓練データの経験分布をそのままあてるだけの予測 #####\ndef make_my_predictions_0(target_df, prediction_df):\n    cd_ = np.copy(cd)\n    postprocess(cd_, target_df)\n    prediction_df.iloc[0,:] = cd_\n\ndf_ = df_play_2017[df_play_2017['Down'] == 1]\ncd1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play_2017[df_play_2017['Down'] == 2]\ncd2 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play_2017[(df_play_2017['Down'] == 3) & (df_play_2017['Distance'] == 1)]\ncd3_1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play_2017[(df_play_2017['Down'] == 3) & (df_play_2017['Distance'] != 1)]\ncd3_not1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play_2017[(df_play_2017['Down'] == 4) & (df_play_2017['Distance'] == 1)]\ncd4_1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play_2017[(df_play_2017['Down'] == 4) & (df_play_2017['Distance'] != 1)]\ncd4_not1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\n\n##### モデル1： 訓練データの経験分布をダウン別、残りヤード別にあてる予測 #####\ndef make_my_predictions_1(target_df, prediction_df):\n    if target_df['Down'].iloc[0] == 1:\n        cd_ = np.copy(cd1)\n    elif target_df['Down'].iloc[0] == 2:\n        cd_ = np.copy(cd2)\n    elif (target_df['Down'].iloc[0] == 3) and (target_df['Distance'].iloc[0] == 1):\n        cd_ = np.copy(cd3_1)\n    elif target_df['Down'].iloc[0] == 3:\n        cd_ = np.copy(cd3_not1)\n    elif (target_df['Down'].iloc[0] == 4) and (target_df['Distance'].iloc[0] == 1):\n        cd_ = np.copy(cd4_1)\n    else:\n        cd_ = np.copy(cd4_not1)\n    postprocess(cd_, target_df)\n    prediction_df.iloc[0,:] = cd_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2つのモデルを評価してみます。  \nモデル1の方がほんの少し誤差が小さいようです。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import display, HTML\n\n# 予測結果のひな型\nprediction_df = pd.DataFrame()\nfor y in range(-99, 100):\n    prediction_df['Yards' + str(y)] = [0.0]\n\nloss = []\n\nfor i in range(len(df_play_2018)):\n    target_df_ = df_play_2018.iloc[[i],:]\n    prediction_df_ = prediction_df.copy()\n    make_my_predictions_0(target_df_, prediction_df_) # モデル0\n    # display(HTML(prediction_df_.to_html(index=False))) # 表示してみる\n    # break\n    \n    actual_ = np.array([0.0] * 199)\n    actual_[yard_to_index[target_df_['Yards'].iloc[0]]:] = 1.0\n    loss_ = (prediction_df_.iloc[0,:] - actual_) * (prediction_df_.iloc[0,:] - actual_)\n    loss.append(loss_.mean())\n\nprint(np.array(loss).mean())\n\nloss = []\n\nfor i in range(len(df_play_2018)):\n    target_df_ = df_play_2018.iloc[[i],:]\n    prediction_df_ = prediction_df.copy()\n    make_my_predictions_1(target_df_, prediction_df_) # モデル1\n    # display(HTML(prediction_df_.to_html(index=False))) # 表示してみる\n    # break\n    \n    actual_ = np.array([0.0] * 199)\n    actual_[yard_to_index[target_df_['Yards'].iloc[0]]:] = 1.0\n    loss_ = (prediction_df_.iloc[0,:] - actual_) * (prediction_df_.iloc[0,:] - actual_)\n    loss.append(loss_.mean())\n\nprint(np.array(loss).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2017シーズンと2018シーズン全てのデータに対して経験分布を算出し直し、テストデータに実行します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"### 1. データを読み込む。\n\n# import pandas as pd\n# import numpy as np\n# df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n# df_play = df.drop_duplicates(subset='PlayId')\n\n### 2. 第1ダウン、第2ダウン、第3ダウン（残り1ヤードか否か）、第4ダウン（残り1ヤードか否か）の別に分布をつくっておく。\n\ndf_ = df_play[df_play['Down'] == 1]\ncd1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play[df_play['Down'] == 2]\ncd2 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play[(df_play['Down'] == 3) & (df_play['Distance'] == 1)]\ncd3_1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play[(df_play['Down'] == 3) & (df_play['Distance'] != 1)]\ncd3_not1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play[(df_play['Down'] == 4) & (df_play['Distance'] == 1)]\ncd4_1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\ndf_ = df_play[(df_play['Down'] == 4) & (df_play['Distance'] != 1)]\ncd4_not1 = np.histogram(df_['Yards'], bins=range(-100, 100, 1))[0].cumsum() / len(df_)\n\n### 3. ダウンと残りヤードだけみてそのまま上の分布をあてる関数を実装する（postprocess はありえない確率の削除； 上の方のセル参照）。 \n\ndef make_my_predictions_1(target_df, prediction_df):\n    if target_df['Down'].iloc[0] == 1:\n        cd_ = np.copy(cd1)\n    elif target_df['Down'].iloc[0] == 2:\n        cd_ = np.copy(cd2)\n    elif (target_df['Down'].iloc[0] == 3) and (target_df['Distance'].iloc[0] == 1):\n        cd_ = np.copy(cd3_1)\n    elif target_df['Down'].iloc[0] == 3:\n        cd_ = np.copy(cd3_not1)\n    elif (target_df['Down'].iloc[0] == 4) and (target_df['Distance'].iloc[0] == 1):\n        cd_ = np.copy(cd4_1)\n    else:\n        cd_ = np.copy(cd4_not1)\n    postprocess(cd_, target_df) # See above\n    prediction_df.iloc[0,:] = cd_\n\n### 4. テストデータに適用する。\n    \nfrom kaggle.competitions import nflrush\nenv = nflrush.make_env()\n\nfor (test_df, prediction_df) in env.iter_test():\n    make_my_predictions_1(test_df, prediction_df)\n    env.predict(prediction_df)\n\nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}