{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import copy\nimport csv\nimport time\nfrom typing import Optional, Tuple, List, Dict, Type\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\n\nfrom torch.nn.modules.module import Module\nfrom torch.nn.modules.dropout import Dropout\nfrom torch.nn.modules.linear import Linear\nfrom torch.nn.modules.normalization import LayerNorm\nfrom torch.nn.parameter import Parameter\nfrom torch.nn.init import xavier_uniform_\nfrom torch.nn.init import constant_\nfrom torch.nn.init import xavier_normal_\nfrom torch.nn.modules.container import ModuleList\n\ntorch.manual_seed(0)\nnp.random.seed(0)\nimport scipy\n\nRand_matrix = scipy.special.logit(np.random.rand(22,22))\n\nclass Data(object):\n    def __init__(self, players: torch.Tensor, rusher: torch.Tensor, meta: torch.Tensor, y: Optional[torch.Tensor],\n                 yardLine: np.ndarray, year: np.ndarray, player_cols: List[str], rusher_cols: List[str],\n                 meta_cols: List[str]):\n        self.players = players\n        self.rusher = rusher\n        self.meta = meta\n        self.y = y\n        self.yardLine = yardLine\n        self.year = year\n        self.player_cols = player_cols\n        self.rusher_cols = rusher_cols\n        self.meta_cols = meta_cols\n\n        assert self.players.size(0) == self.rusher.size(0)\n        if yardLine is not None:\n            assert len(yardLine) == self.players.size(0)\n\n    def len(self):\n        return self.players.size(0)\n\n    def y_soft(self, sigma: float = 1.0):\n        from scipy.ndimage.filters import gaussian_filter1d\n        return torch.from_numpy(gaussian_filter1d(self.y.numpy(), sigma=sigma))\n\n    def slice(self, begin: int, end: int) -> 'Data':\n        p = self.players[begin:end] if self.players is not None else None\n        r = self.rusher[begin:end] if self.rusher is not None else None\n        m = self.meta[begin:end] if self.meta is not None else None\n        y = self.y[begin:end] if self.y is not None else None\n        yd = self.yardLine[begin:end].copy() if self.yardLine is not None else None\n        yr = self.year[begin:end].copy() if self.year is not None else None\n\n        return Data(p, r, m, y, yd, yr, self.player_cols, self.rusher_cols, self.meta_cols)\n\n    def _sample_by_mask(self, mask):\n        mask_tensor = torch.from_numpy(mask)\n        p = self.players[mask_tensor] if self.players is not None else None\n        r = self.rusher[mask_tensor] if self.rusher is not None else None\n        m = self.meta[mask_tensor] if self.meta is not None else None\n        y = self.y[mask_tensor] if self.y is not None else None\n        yd = self.yardLine[mask].copy() if self.yardLine is not None else None\n        yr = self.year[mask].copy() if self.year is not None else None\n\n        return Data(p, r, m, y, yd, yr, self.player_cols, self.rusher_cols, self.meta_cols)\n\n    def downsample_2017(self, dropout_rate: float):\n        assert 0 <= dropout_rate <= 1.0\n        dropout = np.random.choice([True, False], size=len(self.year), p=[1 - dropout_rate, dropout_rate])\n        mask = (self.year != 2017) | dropout\n        return self._sample_by_mask(mask)\n\n    def shuffled(self):\n        indices = np.random.permutation(self.players.shape[0])\n        p = np.take(self.players, indices, axis=0)\n        r = np.take(self.rusher, indices, axis=0) if self.rusher is not None else None\n        m = np.take(self.meta, indices, axis=0) if self.meta is not None else None\n        y = np.take(self.y, indices, axis=0) if self.y is not None else None\n        yd = np.take(self.yardLine, indices, axis=0).copy() if self.yardLine is not None else None\n        yr = np.take(self.year, indices, axis=0).copy() if self.year is not None else None\n        return Data(p, r, m, y, yd, yr, self.player_cols, self.rusher_cols, self.meta_cols)\n\n    def random_split(self, p: float):\n        mask = np.random.choice([True, False], p=[p, 1 - p], size=self.meta.size(0))\n        d1 = self._sample_by_mask(mask)\n        d2 = self._sample_by_mask(~mask)\n        return d1, d2\n\n\ndef concat_dataset(l: Data, r: Data):\n    p = torch.cat((l.players, r.players))\n    rs = torch.cat((l.rusher, r.rusher))\n    m = torch.cat((l.meta, r.meta))\n    y = torch.cat((l.y, r.y)) if l.y is not None else None\n    yd = np.concatenate([l.yardLine, r.yardLine]) if l.yardLine is not None else None\n    yr = np.concatenate([l.year, r.year]) if l.year is not None else None\n    print(p.size())\n    print(yd.shape)\n    return Data(p, rs, m, y, yd, yr, l.player_cols, l.rusher_cols, l.meta_cols)\n\n\n#######################################################################################################################\n## Transformer Building Blocks (backported from PyTorch v1.3)\n#######################################################################################################################\n\n\ndef _get_clones(module, N):\n    return ModuleList([copy.deepcopy(module) for i in range(N)])\n\n\nclass MultiheadAttention(Module):\n    # __annotations__ = {\n    #    'bias_k': torch._jit_internal.Optional[torch.Tensor],\n    #    'bias_v': torch._jit_internal.Optional[torch.Tensor],\n    # }\n    __constants__ = ['q_proj_weight', 'k_proj_weight', 'v_proj_weight', 'in_proj_weight', 'R_proj_weight']\n\n    def __init__(self, embed_dim, num_heads, dropout=0., bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None,\n                 vdim=None):\n        super(MultiheadAttention, self).__init__()\n        self.embed_dim = embed_dim\n        self.kdim = kdim if kdim is not None else embed_dim\n        self.vdim = vdim if vdim is not None else embed_dim\n        self._qkv_same_embed_dim = self.kdim == embed_dim and self.vdim == embed_dim\n\n        self.num_heads = num_heads\n        self.dropout = dropout\n        self.head_dim = embed_dim // num_heads\n        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n\n        if self._qkv_same_embed_dim is False:\n            self.q_proj_weight = Parameter(torch.Tensor(embed_dim, embed_dim))\n            self.k_proj_weight = Parameter(torch.Tensor(embed_dim, self.kdim))\n            self.v_proj_weight = Parameter(torch.Tensor(embed_dim, self.vdim))\n            self.register_parameter('in_proj_weight', None)\n        else:\n            self.in_proj_weight = Parameter(torch.empty(3 * embed_dim, embed_dim))\n            self.register_parameter('q_proj_weight', None)\n            self.register_parameter('k_proj_weight', None)\n            self.register_parameter('v_proj_weight', None)\n            \n        self.R_proj_weight = Parameter(torch.Tensor(22, 22))\n        self.alpha_1 = Parameter(torch.Tensor(1))\n        \n        if bias:\n            self.in_proj_bias = Parameter(torch.empty(3 * embed_dim))\n        else:\n            self.register_parameter('in_proj_bias', None)\n        self.out_proj = Linear(embed_dim, embed_dim, bias=bias)\n\n        if add_bias_kv:\n            self.bias_k = Parameter(torch.empty(1, 1, embed_dim))\n            self.bias_v = Parameter(torch.empty(1, 1, embed_dim))\n        else:\n            self.bias_k = self.bias_v = None\n\n        self.add_zero_attn = add_zero_attn\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        if self._qkv_same_embed_dim:\n            xavier_uniform_(self.in_proj_weight)\n            xavier_normal_(self.R_proj_weight)\n        else:\n            xavier_uniform_(self.q_proj_weight)\n            xavier_uniform_(self.k_proj_weight)\n            xavier_uniform_(self.v_proj_weight)\n            \n\n        if self.in_proj_bias is not None:\n            constant_(self.in_proj_bias, 0.)\n            constant_(self.out_proj.bias, 0.)\n        if self.bias_k is not None:\n            xavier_normal_(self.bias_k)\n        if self.bias_v is not None:\n            xavier_normal_(self.bias_v)\n\n    def forward(self, query, key, value, key_padding_mask=None,\n                need_weights=True, attn_mask=None):\n        # type: (Tensor, Tensor, Tensor, Optional[Tensor], bool, Optional[Tensor]) -> Tuple[Tensor, Optional[Tensor]]\n        if not self._qkv_same_embed_dim:\n            return multi_head_attention_forward(\n                query, key, value, self.embed_dim, self.num_heads,\n                self.in_proj_weight, self.in_proj_bias,\n                self.bias_k, self.bias_v, self.add_zero_attn,\n                self.dropout, self.out_proj.weight, self.out_proj.bias,\n                training=self.training,\n                key_padding_mask=key_padding_mask, need_weights=need_weights,\n                attn_mask=attn_mask, use_separate_proj_weight=True,\n                q_proj_weight=self.q_proj_weight, k_proj_weight=self.k_proj_weight,\n                v_proj_weight=self.v_proj_weight, R_proj_weight=self.R_proj_weight,alpha_1=self.alpha_1)\n        else:\n            return multi_head_attention_forward(\n                query, key, value, self.embed_dim, self.num_heads,\n                self.in_proj_weight, self.in_proj_bias,\n                self.bias_k, self.bias_v, self.add_zero_attn,\n                self.dropout, self.out_proj.weight, self.out_proj.bias,\n                training=self.training,\n                key_padding_mask=key_padding_mask, need_weights=need_weights,\n                attn_mask=attn_mask, R_proj_weight=self.R_proj_weight,alpha_1=self.alpha_1)\n\n\nclass TransformerEncoder(Module):\n    def __init__(self, encoder_layer, num_layers, norm=None):\n        super(TransformerEncoder, self).__init__()\n        self.layers = _get_clones(encoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n\n    def forward(self, src, mask=None, src_key_padding_mask=None):\n        r\"\"\"Pass the input through the encoder layers in turn.\n\n        Args:\n            src: the sequnce to the encoder (required).\n            mask: the mask for the src sequence (optional).\n            src_key_padding_mask: the mask for the src keys per batch (optional).\n\n        Shape:\n            see the docs in Transformer class.\n        \"\"\"\n        output = src\n\n        for i in range(self.num_layers):\n            output = self.layers[i](output, src_mask=mask,\n                                    src_key_padding_mask=src_key_padding_mask)\n\n        if self.norm:\n            output = self.norm(output)\n\n        return output\n\n\nclass TransformerEncoderLayer(Module):\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, dropout_attn=0.1, pre_LN=False):\n        super(TransformerEncoderLayer, self).__init__()\n        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout_attn)\n        # Implementation of Feedforward model\n        self.linear1 = Linear(d_model, dim_feedforward)\n        self.dropout = Dropout(dropout)\n        self.linear2 = Linear(dim_feedforward, d_model)\n\n        self.norm1 = LayerNorm(d_model)\n        self.norm2 = LayerNorm(d_model)\n        self.dropout1 = Dropout(dropout)\n        self.dropout2 = Dropout(dropout)\n\n        self.activation = F.relu\n        self.pre_LN = pre_LN\n\n    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n        r\"\"\"Pass the input through the encoder layer.\n\n        Args:\n            src: the sequnce to the encoder layer (required).\n            src_mask: the mask for the src sequence (optional).\n            src_key_padding_mask: the mask for the src keys per batch (optional).\n\n        Shape:\n            see the docs in Transformer class.\n        \"\"\"\n        if self.pre_LN:\n            src2 = self.norm1(src)\n            src2 = self.self_attn(src2, src2, src2, attn_mask=src_mask,\n                                  key_padding_mask=src_key_padding_mask)[0]\n            src = src + self.dropout1(src2)\n        else:\n            src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n                                  key_padding_mask=src_key_padding_mask)[0]\n            src = src + self.dropout1(src2)\n            src = self.norm1(src)\n        if hasattr(self, \"activation\"):\n            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n        else:  # for backward compatibility\n            src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n        src = src + self.dropout2(src2)\n        src = self.norm2(src)\n        return src\n\n\ndef multi_head_attention_forward(query,  # type: torch.Tensor\n                                 key,  # type: torch.Tensor\n                                 value,  # type: torch.Tensor\n                                 embed_dim_to_check,  # type: int\n                                 num_heads,  # type: int\n                                 in_proj_weight,  # type: torch.Tensor\n                                 in_proj_bias,  # type: torch.Tensor\n                                 bias_k,  # type: Optional[torch.Tensor]\n                                 bias_v,  # type: Optional[torch.Tensor]\n                                 add_zero_attn,  # type: bool\n                                 dropout_p,  # type: float\n                                 out_proj_weight,  # type: torch.Tensor\n                                 out_proj_bias,  # type: torch.Tensor\n                                 training=True,  # type: bool\n                                 key_padding_mask=None,  # type: Optional[torch.Tensor]\n                                 need_weights=True,  # type: bool\n                                 attn_mask=None,  # type: Optional[torch.Tensor]\n                                 use_separate_proj_weight=False,  # type: bool\n                                 q_proj_weight=None,  # type: Optional[torch.Tensor]\n                                 k_proj_weight=None,  # type: Optional[torch.Tensor]\n                                 v_proj_weight=None,  # type: Optional[torch.Tensor]\n                                 R_proj_weight=None,  # type: Optional[torch.Tensor]\n                                 static_k=None,  # type: Optional[torch.Tensor]\n                                 static_v=None,  # type: Optional[torch.Tensor]\n                                 alpha_1=None\n                                 ):\n    # type: (...) -> Tuple[torch.Tensor, Optional[torch.Tensor]]\n    r\"\"\"\n    Args:\n        query, key, value: map a query and a set of key-value pairs to an output.\n            See \"Attention Is All You Need\" for more details.\n        embed_dim_to_check: total dimension of the model.\n        num_heads: parallel attention heads.\n        in_proj_weight, in_proj_bias: input projection weight and bias.\n        bias_k, bias_v: bias of the key and value sequences to be added at dim=0.\n        add_zero_attn: add a new batch of zeros to the key and\n                       value sequences at dim=1.\n        dropout_p: probability of an element to be zeroed.\n        out_proj_weight, out_proj_bias: the output projection weight and bias.\n        training: apply dropout if is ``True``.\n        key_padding_mask: if provided, specified padding elements in the key will\n            be ignored by the attention. This is an binary mask. When the value is True,\n            the corresponding value on the attention layer will be filled with -inf.\n        need_weights: output attn_output_weights.\n        attn_mask: mask that prevents attention to certain positions. This is an additive mask\n            (i.e. the values will be added to the attention layer).\n        use_separate_proj_weight: the function accept the proj. weights for query, key,\n            and value in differnt forms. If false, in_proj_weight will be used, which is\n            a combination of q_proj_weight, k_proj_weight, v_proj_weight.\n        q_proj_weight, k_proj_weight, v_proj_weight, in_proj_bias: input projection weight and bias.\n        static_k, static_v: static key and value used for attention operators.\n\n\n    Shape:\n        Inputs:\n        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n          the embedding dimension.\n        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key_padding_mask: :math:`(N, S)`, ByteTensor, where N is the batch size, S is the source sequence length.\n        - attn_mask: :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n        - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n        - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n\n        Outputs:\n        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n          E is the embedding dimension.\n        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n          L is the target sequence length, S is the source sequence length.\n    \"\"\"\n\n    qkv_same = torch.equal(query, key) and torch.equal(key, value)\n    kv_same = torch.equal(key, value)\n\n    tgt_len, bsz, embed_dim = query.size()\n    assert embed_dim == embed_dim_to_check\n    assert list(query.size()) == [tgt_len, bsz, embed_dim]\n    assert key.size() == value.size()\n\n    head_dim = embed_dim // num_heads\n    assert head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n    scaling = float(head_dim) ** -0.5\n\n    if use_separate_proj_weight is not True:\n        if qkv_same:\n            # self-attention\n            q, k, v = F.linear(query, in_proj_weight, in_proj_bias).chunk(3, dim=-1)\n\n        elif kv_same:\n            # encoder-decoder attention\n            # This is inline in_proj function with in_proj_weight and in_proj_bias\n            _b = in_proj_bias\n            _start = 0\n            _end = embed_dim\n            _w = in_proj_weight[_start:_end, :]\n            if _b is not None:\n                _b = _b[_start:_end]\n            q = F.linear(query, _w, _b)\n\n            if key is None:\n                assert value is None\n                k = None\n                v = None\n            else:\n\n                # This is inline in_proj function with in_proj_weight and in_proj_bias\n                _b = in_proj_bias\n                _start = embed_dim\n                _end = None\n                _w = in_proj_weight[_start:, :]\n                if _b is not None:\n                    _b = _b[_start:]\n                k, v = F.linear(key, _w, _b).chunk(2, dim=-1)\n\n        else:\n            # This is inline in_proj function with in_proj_weight and in_proj_bias\n            _b = in_proj_bias\n            _start = 0\n            _end = embed_dim\n            _w = in_proj_weight[_start:_end, :]\n            if _b is not None:\n                _b = _b[_start:_end]\n            q = F.linear(query, _w, _b)\n\n            # This is inline in_proj function with in_proj_weight and in_proj_bias\n            _b = in_proj_bias\n            _start = embed_dim\n            _end = embed_dim * 2\n            _w = in_proj_weight[_start:_end, :]\n            if _b is not None:\n                _b = _b[_start:_end]\n            k = F.linear(key, _w, _b)\n\n            # This is inline in_proj function with in_proj_weight and in_proj_bias\n            _b = in_proj_bias\n            _start = embed_dim * 2\n            _end = None\n            _w = in_proj_weight[_start:, :]\n            if _b is not None:\n                _b = _b[_start:]\n            v = F.linear(value, _w, _b)\n    else:\n        q_proj_weight_non_opt = torch.jit._unwrap_optional(q_proj_weight)\n        len1, len2 = q_proj_weight_non_opt.size()\n        assert len1 == embed_dim and len2 == query.size(-1)\n\n        k_proj_weight_non_opt = torch.jit._unwrap_optional(k_proj_weight)\n        len1, len2 = k_proj_weight_non_opt.size()\n        assert len1 == embed_dim and len2 == key.size(-1)\n\n        v_proj_weight_non_opt = torch.jit._unwrap_optional(v_proj_weight)\n        len1, len2 = v_proj_weight_non_opt.size()\n        assert len1 == embed_dim and len2 == value.size(-1)\n        \n\n\n        if in_proj_bias is not None:\n            q = F.linear(query, q_proj_weight_non_opt, in_proj_bias[0:embed_dim])\n            k = F.linear(key, k_proj_weight_non_opt, in_proj_bias[embed_dim:(embed_dim * 2)])\n            v = F.linear(value, v_proj_weight_non_opt, in_proj_bias[(embed_dim * 2):])\n        else:\n            q = F.linear(query, q_proj_weight_non_opt, in_proj_bias)\n            k = F.linear(key, k_proj_weight_non_opt, in_proj_bias)\n            v = F.linear(value, v_proj_weight_non_opt, in_proj_bias)\n    q = q * scaling\n\n    R_proj_weight_non_opt = torch.jit._unwrap_optional(R_proj_weight)\n    len1, len2 = R_proj_weight_non_opt.size()\n    \n#     R = F.linear(value, R_proj_weight_non_opt)\n#     print(len1)\n#     print(len2)\n    if bias_k is not None and bias_v is not None:\n        if static_k is None and static_v is None:\n            k = torch.cat([k, bias_k.repeat(1, bsz, 1)])\n            v = torch.cat([v, bias_v.repeat(1, bsz, 1)])\n            if attn_mask is not None:\n                attn_mask = torch.cat([attn_mask,\n                                       torch.zeros((attn_mask.size(0), 1),\n                                                   dtype=attn_mask.dtype,\n                                                   device=attn_mask.device)], dim=1)\n            if key_padding_mask is not None:\n                key_padding_mask = torch.cat(\n                    [key_padding_mask, torch.zeros((key_padding_mask.size(0), 1),\n                                                   dtype=key_padding_mask.dtype,\n                                                   device=key_padding_mask.device)], dim=1)\n        else:\n            assert static_k is None, \"bias cannot be added to static key.\"\n            assert static_v is None, \"bias cannot be added to static value.\"\n    else:\n        assert bias_k is None\n        assert bias_v is None\n\n    q = q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n    if k is not None:\n        k = k.contiguous().view(-1, bsz * num_heads, head_dim).transpose(0, 1)\n    if v is not None:\n        v = v.contiguous().view(-1, bsz * num_heads, head_dim).transpose(0, 1)\n\n    if static_k is not None:\n        assert static_k.size(0) == bsz * num_heads\n        assert static_k.size(2) == head_dim\n        k = static_k\n\n    if static_v is not None:\n        assert static_v.size(0) == bsz * num_heads\n        assert static_v.size(2) == head_dim\n        v = static_v\n\n    src_len = k.size(1)\n\n    if key_padding_mask is not None:\n        assert key_padding_mask.size(0) == bsz\n        assert key_padding_mask.size(1) == src_len\n\n    if add_zero_attn:\n        src_len += 1\n        k = torch.cat([k, torch.zeros((k.size(0), 1) + k.size()[2:], dtype=k.dtype, device=k.device)], dim=1)\n        v = torch.cat([v, torch.zeros((v.size(0), 1) + v.size()[2:], dtype=v.dtype, device=v.device)], dim=1)\n        if attn_mask is not None:\n            attn_mask = torch.cat([attn_mask, torch.zeros((attn_mask.size(0), 1),\n                                                          dtype=attn_mask.dtype,\n                                                          device=attn_mask.device)], dim=1)\n        if key_padding_mask is not None:\n            key_padding_mask = torch.cat(\n                [key_padding_mask, torch.zeros((key_padding_mask.size(0), 1),\n                                               dtype=key_padding_mask.dtype,\n                                               device=key_padding_mask.device)], dim=1)\n\n#     q_k_product = torch.bmm(q, k.transpose(1, 2))\n    \n#     print(attn_output_weights.size())\n#     print(\"test\")\n#     print(torch.Tensor(Rand_matrix).size())\n#     print([bsz * num_heads, tgt_len, src_len])\n\n        \n    temp_matrix = np.tile(R_proj_weight_non_opt.detach().numpy(),(bsz * num_heads,1,1))\n    attn_output_weights = torch.Tensor(temp_matrix)\n#     print(alpha_1)\n\n    assert list(attn_output_weights.size()) == [bsz * num_heads, tgt_len, src_len]\n\n    if attn_mask is not None:\n        attn_mask = attn_mask.unsqueeze(0)\n        attn_output_weights += attn_mask\n\n    if key_padding_mask is not None:\n        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n        attn_output_weights = attn_output_weights.masked_fill(\n            key_padding_mask.unsqueeze(1).unsqueeze(2),\n            float('-inf'),\n        )\n        attn_output_weights = attn_output_weights.view(bsz * num_heads, tgt_len, src_len)\n\n    attn_output_weights = F.softmax(\n        attn_output_weights, dim=-1)\n    attn_output_weights = F.dropout(attn_output_weights, p=dropout_p, training=training)\n\n    attn_output = torch.bmm(attn_output_weights, v)\n    assert list(attn_output.size()) == [bsz * num_heads, tgt_len, head_dim]\n    attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n    attn_output = F.linear(attn_output, out_proj_weight, out_proj_bias)\n\n    if need_weights:\n        # average attention weights over heads\n        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n        return attn_output, attn_output_weights.sum(dim=1) / num_heads\n    else:\n        return attn_output, None\n\n\n#######################################################################################################################\n# The Model\n#######################################################################################################################\n\n\nclass TransformerModel(nn.Module):\n    def __init__(self, ninp: int, nemb: int = 1, nhead: int = 1, nhid: int = 32, nlayers: int = 4, nfinal: int = 1024,\n                 dropout_encoder: float = 0.1, dropout_embed: float = 0.0, dropout_classifier: float = 0.0,\n                 n_class: int = 199, ninp_rusher: int = 16, pre_LN: bool = False, rusher_emb: int = 32,\n                 n_emb_layers: int = 2,\n                 ninp_meta: int = 8, meta_emb: int = 32, gauss_noise: float = 0.0,\n                 gauss_xy_noise: float = 0.0,\n                 n_fin_layers: int = 3, dropout_attn: float = 0):\n        \"\"\"\n\n        :param ninp: 入力の次元数（選手一人あたりの特徴量次元\n        :param nemb: Embedding層の次元\n        :param nhead: multi-head attentionのheadの数\n        :param nhid: transformerの中のFeedForward(FFN)の隠れ層の次元\n        :param nlayers: transformer-encoderの層の数\n        :param nfinal: readout後のLinear層の次元\n        :param dropout_encoder: Self-Attention, Encoder内のdropout\n        :param dropout_embed: Embedding層のdropout\n        :param dropout_classifier: readout後のdropout\n        :param n_class:\n        :param ninp_rusher: Rusherの特徴量次元\n        :param pre_LN: Layer-Normalizationの配置方法をpre-LNにするか\n        :param rusher_emb: RusherのEmbedding次元\n        \"\"\"\n        super(TransformerModel, self).__init__()\n        self.model_type = 'Transformer'\n        encoder_layers = TransformerEncoderLayer(nemb, nhead, nhid, dropout_encoder, pre_LN=pre_LN, dropout_attn=dropout_attn)\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n        self.n_emb_layers = n_emb_layers\n        self.conv1 = nn.Conv1d(in_channels=ninp, out_channels=nemb, kernel_size=1)\n        self.conv2 = nn.Conv1d(in_channels=nemb, out_channels=nemb, kernel_size=1)\n        self.conv3 = nn.Conv1d(in_channels=nemb, out_channels=nemb, kernel_size=1)\n\n        self.relu1 = nn.PReLU()\n        self.relu2 = nn.PReLU()\n        self.relu3 = nn.PReLU()\n        self.relu4 = nn.PReLU()\n        self.relu5 = nn.ReLU()\n        if dropout_embed > 0:\n            self.dropout1 = nn.Dropout(dropout_embed)\n        else:\n            self.dropout1 = None\n\n        self.avgpool = nn.AvgPool1d(kernel_size=22)  # nn.MaxPool1d(kernel_size=22)\n\n        assert n_fin_layers == 3\n\n        self.linear = nn.Sequential(\n            nn.Dropout(dropout_classifier),\n            nn.Linear(nemb + rusher_emb + meta_emb, nfinal),\n            nn.ReLU(),\n            nn.Dropout(dropout_classifier),\n            nn.Linear(nfinal, nfinal),\n            nn.ReLU(),\n            nn.Dropout(dropout_classifier),\n            nn.Linear(nfinal, n_class)\n        )\n\n        self.activation = nn.Softmax(dim=1)\n        self.linear2 = nn.Linear(ninp_rusher, rusher_emb)\n        self.gauss_noise = gauss_noise\n        self.gauss_xy_noise = gauss_xy_noise\n        if meta_emb > 0:\n            self.linear3 = nn.Linear(ninp_meta, meta_emb)\n        else:\n            self.linear3 = None\n\n    def forward(self, x: Data, with_clip: bool = True):\n        # src: [Batch x Players(22) x Player Vector]\n        src = x.players\n        src_rusher = x.rusher\n\n        # src: [Batch x Player Vector x Players(22)]\n        src = src.permute([0, 2, 1])\n\n        if self.training:\n            # gaussian augmentation on training data\n            if self.gauss_noise > 0.0:\n                noise = torch.randn_like(src) * self.gauss_noise\n                src = src + noise\n\n            if self.gauss_xy_noise > 0.0:\n                # dx = torch.randn(src.size(0)) * self.gauss_xy_noise\n                dy = torch.randn(src.size(0)) * self.gauss_xy_noise\n\n                # Batch x 1 x 22\n                # src[:, 0, :] += dx.reshape(src.size(0), 1).expand(src.size(0), src.size(2))\n                src[:, 1, :] += dy.reshape(src.size(0), 1).expand(src.size(0), src.size(2))\n\n                # src_rusher[:, 0] += dx\n                src_rusher[:, 1] += dy\n\n        # src: [Batch x Player Vector(embedded, 4*inp) x Players(22)]\n        src = self.relu1(self.conv1(src))\n        src = self.dropout1(src)\n        src = self.relu2(self.conv2(src))\n        src = self.dropout1(src)\n        src = self.relu3(self.conv3(src))\n\n        src = src.permute([2, 0, 1])\n\n        # output: [Players(22) x Batch x Transformed Player Vector]\n        output = self.transformer_encoder(src)\n\n        # output: [Batch x Transformed Player Vector x Players(22)]\n        output = output.permute([1, 2, 0])\n\n        # output: [Batch x Transformed Player Vector]\n        output = torch.squeeze(self.avgpool(output), dim=2)\n\n        if self.linear3 is not None:\n            output = torch.cat((output, self.relu4(self.linear2(src_rusher)), self.relu5(self.linear3(x.meta))), dim=1)\n        else:\n            output = torch.cat((output, self.relu4(self.linear2(src_rusher))), dim=1)\n\n        # output: [Batch x n_class]\n        output = self.linear(output)\n        output = self.activation(output)\n\n        if not self.training and x.yardLine is not None:\n            output = torch.cumsum(output, dim=1).numpy()\n\n            output = np.clip(output, 0.0, 1.0)\n\n            # mask\n            if with_clip:\n                left = 99 - x.yardLine\n                right = 199 - x.yardLine\n                for k in range(len(output)):\n                    output[k, :left[k] + 1] = 0.0\n                    output[k, right[k]:] = 1.0\n\n        return output\n\n\n#######################################################################################################################\n# Prep and Feature Engineering\n#######################################################################################################################\n\n# Thanks to: https://www.kaggle.com/cpmpml/initial-wrangling-voronoi-areas-in-python\ndef prep(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    df['ToLeft'] = df.PlayDirection == \"left\"\n    df['IsBallCarrier'] = df.NflId == df.NflIdRusher\n\n    df.loc[df.VisitorTeamAbbr == \"ARI\", 'VisitorTeamAbbr'] = \"ARZ\"\n    df.loc[df.HomeTeamAbbr == \"ARI\", 'HomeTeamAbbr'] = \"ARZ\"\n\n    df.loc[df.VisitorTeamAbbr == \"BAL\", 'VisitorTeamAbbr'] = \"BLT\"\n    df.loc[df.HomeTeamAbbr == \"BAL\", 'HomeTeamAbbr'] = \"BLT\"\n\n    df.loc[df.VisitorTeamAbbr == \"CLE\", 'VisitorTeamAbbr'] = \"CLV\"\n    df.loc[df.HomeTeamAbbr == \"CLE\", 'HomeTeamAbbr'] = \"CLV\"\n\n    df.loc[df.VisitorTeamAbbr == \"HOU\", 'VisitorTeamAbbr'] = \"HST\"\n    df.loc[df.HomeTeamAbbr == \"HOU\", 'HomeTeamAbbr'] = \"HST\"\n\n    # standardization\n    df['TeamOnOffense'] = \"home\"\n    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n    df['IsOnOffense'] = df.Team == df.TeamOnOffense  # Is player on offense?\n    df['YardLine_std'] = 100 - df.YardLine\n    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam, 'YardLine_std'] = df.loc[\n        df.FieldPosition.fillna('') == df.PossessionTeam, 'YardLine']\n    df['X_std'] = df.X\n    df.loc[df.ToLeft, 'X_std'] = 120 - df.loc[df.ToLeft, 'X']\n    df['Y_std'] = df.Y\n    df.loc[df.ToLeft, 'Y_std'] = 160 / 3 - df.loc[df.ToLeft, 'Y']\n    df['Orientation_std'] = df.Orientation\n    df.loc[df.ToLeft, 'Orientation_std'] = np.mod(180 + df.loc[df.ToLeft, 'Orientation_std'], 360)\n    df['Dir_std'] = df.Dir\n    df.loc[df.ToLeft, 'Dir_std'] = np.mod(180 + df.loc[df.ToLeft, 'Dir_std'], 360)\n    df['IsOffence'] = df['Team'] == df['TeamOnOffense']\n\n    # translate Home/Visitor to Offence/Defense\n    df['OffenceScoreBeforePlay'] = df['HomeScoreBeforePlay']\n    df.loc[df.TeamOnOffense == \"away\", 'OffenceScoreBeforePlay'] = df.loc[\n        df.TeamOnOffense == \"away\", 'VisitorScoreBeforePlay']\n    df['DefenseScoreBeforePlay'] = df['VisitorScoreBeforePlay']\n    df.loc[df.TeamOnOffense == \"away\", 'DefenseScoreBeforePlay'] = df.loc[\n        df.TeamOnOffense == \"away\", 'HomeScoreBeforePlay']\n\n    df['OffenceTeamAbbr'] = df['HomeTeamAbbr']\n    df.loc[df.TeamOnOffense == \"away\", 'OffenceTeamAbbr'] = df.loc[df.TeamOnOffense == \"away\", 'VisitorTeamAbbr']\n    df['DefenseTeamAbbr'] = df['VisitorTeamAbbr']\n    df.loc[df.TeamOnOffense == \"away\", 'DefenseTeamAbbr'] = df.loc[df.TeamOnOffense == \"away\", 'HomeTeamAbbr']\n\n    df['Year'] = pd.to_datetime(df.TimeSnap).dt.year\n    df.loc[df['Year'] == 2017, 'Orientation_std'] = np.mod(90 + df.loc[df['Year'] == 2017, 'Orientation_std'], 360)\n\n    player_features = ['X_std', 'Y_std', 'S', 'A', 'Dis', 'Orientation_std', 'Dir_std', 'NflId', 'JerseyNumber',\n                       'PlayerHeight',\n                       'PlayerWeight', 'PlayerBirthDate', 'PlayerCollegeName', 'Position', 'IsBallCarrier', 'IsOffence']\n\n    play_features = ['YardLine_std', 'Quarter', 'GameClock', 'PossessionTeam', 'Down', 'Distance', 'FieldPosition',\n                     'OffenceScoreBeforePlay', 'DefenseScoreBeforePlay', 'OffenseFormation', 'OffensePersonnel',\n                     'DefendersInTheBox', 'DefensePersonnel', 'TimeHandoff', 'TimeSnap',\n                     'OffenceTeamAbbr', 'DefenseTeamAbbr', 'Week', 'Stadium', 'Location',\n                     'Turf', 'GameWeather', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection',\n                     'TeamOnOffense', 'HomeTeamAbbr', 'Year']\n\n    if 'Yards' in df:\n        play_features.append('Yards')\n\n    players = df[['PlayId', 'GameId'] + player_features].copy()\n\n    play = df[['GameId', 'PlayId'] + play_features].copy().drop_duplicates(subset=['PlayId'])\n\n    return play, players\n\n\ndef prep_players_nn(play, players, scaler=None, scaler_meta=None):\n    p = players.drop(['NflId', 'JerseyNumber', 'PlayerHeight', 'PlayerBirthDate', 'PlayerCollegeName', 'GameId'],\n                     axis=1).copy()\n\n    if scaler is None:\n        is_training = True\n    else:\n        assert scaler_meta is not None\n        is_training = False\n\n    if 'YardLine_std' not in p:\n        p = pd.merge(p, play[['YardLine_std', 'PlayId']], on='PlayId', how='left')\n\n    p['IsBallCarrier'] = p['IsBallCarrier'].astype(int)\n    p['IsOffence'] = p['IsOffence'].astype(int)\n    p['X_std'] -= p['YardLine_std']\n\n    p['Dir_cos'] = np.cos(np.deg2rad(90 - p['Dir_std']))\n    p['Dir_sin'] = np.sin(np.deg2rad(90 - p['Dir_std']))\n\n    p = p.fillna(0)\n\n    rb = p[p['IsBallCarrier'] == 1][['X_std', 'Y_std', 'PlayId', 'S', 'Dir_sin', 'Dir_cos', 'Dir_std']]\n    rb.columns = ['X_', 'Y_', 'PlayId', 'S_', 'Dir_sin_', 'Dir_cos_', 'Dir_std_']\n\n    p = pd.merge(p, rb, how='left')\n    p['DX'] = p['X_std'] - p['X_']\n    p['DY'] = p['Y_std'] - p['Y_']\n\n    # Relative angle from on Rusher's vector\n    angles = 90.0 - np.rad2deg(np.arctan2(p['DY'], p['DX']))\n    p['AngleFromRB'] = angles - p['Dir_std_']\n    p['AngleFromRB'] = np.mod(p['AngleFromRB'] + 360, 360)\n    p.loc[p['AngleFromRB'] > 180, 'AngleFromRB'] -= 360\n\n    # dTheta of AngleFromRB\n    dt = 0.001\n    p['DX2'] = (p['X_std'] + dt * p['Dir_cos'] * p['S']) - (p['X_'] + dt * p['Dir_cos_'] * p['S_'])\n    p['DY2'] = (p['Y_std'] + dt * p['Dir_sin'] * p['S']) - (p['Y_'] + dt * p['Dir_sin_'] * p['S_'])\n\n    angles = 90.0 - np.rad2deg(np.arctan2(p['DY2'], p['DX2']))\n    p['AngleFromRB2'] = angles - p['Dir_std_']\n    p['AngleFromRB2'] = np.mod(p['AngleFromRB2'] + 360, 360)\n    p.loc[p['AngleFromRB2'] > 180, 'AngleFromRB2'] -= 360\n    p['AngleFromRB2'] = p['AngleFromRB2'] - p['AngleFromRB']\n    p.loc[p['AngleFromRB2'] > 180, 'AngleFromRB2'] -= 360\n    p.loc[p['AngleFromRB2'] < -180, 'AngleFromRB2'] += 360\n\n    p.loc[p['IsBallCarrier'] == 1, 'AngleFromRB'] = 0\n    p.loc[p['IsBallCarrier'] == 1, 'AngleFromRB2'] = 0\n\n    p.drop(['DX2', 'DY2'], axis=1, inplace=True)\n\n    p['AngleTan'] = np.arctan2(p['DY'], p['DX'])\n\n    p = p.replace([np.inf, -np.inf], np.nan)\n    p = p.fillna(0)\n    p.drop(['X_', 'Y_', 'Dir_sin_', 'Dir_cos_', 'S_', 'Dir_std_', 'Orientation_std', 'Dir_std'], axis=1, inplace=True)\n\n    concat = p.drop(['Position', 'PlayId', 'YardLine_std'], axis=1)\n\n    if is_training:\n        scaler = StandardScaler()\n        scaled = scaler.fit_transform(concat.values)\n    else:\n        scaled = scaler.transform(concat.values)\n    df = pd.DataFrame(scaled, columns=concat.columns)\n\n    df_rusher = df[p['IsBallCarrier'] == 1].reset_index(drop=True)\n    drop_cols = ['IsBallCarrier', 'IsOffence', 'OffenseDist0', 'PlayerWeight', 'DX', 'DY', 'AngleFromRB', 'AngleToRB',\n                 'DistDelta', 'AngleTan', 'AngleFromRB2', 'delaunay_adj']\n    drop_cols = [c for c in drop_cols if c in df_rusher.columns]\n    df_rusher.drop(drop_cols, axis=1, inplace=True)\n    df_rusher = df_rusher.set_index(players['PlayId'].iloc[np.arange(0, len(players), 22)])\n\n    # meta features\n    meta = play[['YardLine_std', 'Distance']].copy()\n    meta = meta.replace([np.inf, -np.inf], np.nan)\n    meta = meta.fillna(0)\n\n    if scaler_meta is not None:\n        scaled_meta = scaler_meta.transform(meta.values)\n    else:\n        scaler_meta = StandardScaler()\n        scaled_meta = scaler_meta.fit_transform(meta.values)\n    scaled_meta = pd.DataFrame(scaled_meta, columns=meta.columns)\n\n    return df.set_index(players['PlayId']), df_rusher, scaled_meta, scaler, scaler_meta\n\n\n#######################################################################################################################\n## SnapShot & Ensemble\n#######################################################################################################################\n\n\nclass EnsembleModel(object):\n    def __init__(self):\n        self.models = []\n\n    def add_model(self, model):\n        self.models.append(model)\n\n    def train(self):\n        for m in self.models:\n            m.train()\n\n    def eval(self):\n        for m in self.models:\n            m.eval()\n\n    def __call__(self, *input, **kwargs):\n        assert len(self.models) >= 1\n\n        base = self.models[0](*input, **kwargs)\n\n        for m in self.models[1:]:\n            base += m(*input, **kwargs)\n\n        return base / len(self.models)\n\n\nclass SnapShot(object):\n    def __init__(self, model: nn.Module, epoch: int, loss: float):\n        self.state = copy.deepcopy(model.state_dict())\n        self.epoch = epoch\n        self.loss = loss\n        torch.save(self.state, f'snapshot_{epoch}_{loss}')\n\n\nclass SnapShots(object):\n    def __init__(self, interval: int = 3, torelance: float = 1.01, verbose: bool = True):\n        self.best_model = None  # type: Optional[SnapShot]\n        self.snap_shots = []  # type: List[SnapShot]\n        self.best_val_loss = 1.0\n        self.interval = interval\n        self.torelance = torelance\n        self.verbose = verbose\n\n    def add(self, model: nn.Module, epoch: int, loss: float):\n        if loss < self.best_val_loss:\n            if self.verbose:\n                print(f'best model is updated. epoch{epoch}, loss={loss:.7f}')\n            self.best_model = SnapShot(model, epoch, loss)\n            self.best_val_loss = loss\n        if epoch % self.interval == 0:\n            if self.verbose:\n                print(f'Add snapshot. epoch{epoch}, loss={loss:.7f}')\n            self.snap_shots.append(SnapShot(model, epoch, loss))\n\n    def load_best_single_model(self, model: nn.Module):\n        if self.best_model is not None:\n            model.load_state_dict(self.best_model.state)\n        return model\n\n    def load_ensemble_model(self, cls: Type, params: Dict, max_models: int = 5):\n        model = EnsembleModel()\n        best = cls(**params)\n        self.load_best_single_model(best)\n        model.add_model(best)\n\n        candidates = []  # Tuple[int, float]\n\n        for i, s in enumerate(self.snap_shots):\n            if s.loss > self.torelance * self.best_model.loss:\n                continue\n            if s.epoch == self.best_model.epoch:\n                continue\n\n            candidates.append((i, s.loss))\n\n        # Collect top-n models from snapshot\n        candidates = sorted(candidates, key = lambda x: x[1])\n        if len(candidates) > max_models - 1:\n            candidates = candidates[:max_models - 1]\n        for i, _ in candidates:\n            s = self.snap_shots[i]\n            sub = cls(**params)\n            sub.load_state_dict(s.state)\n            model.add_model(sub)\n            if self.verbose:\n                print(f'add {s.epoch}-th epoch to ensemble (loss:{s.loss:.7f})')\n\n        return model\n\n\n#######################################################################################################################\n# Training & Pseudo-Labeling\n#######################################################################################################################\n\n\ndef train_model(model: nn.Module, scheduler, batch_size: int,\n                train_data: Data, valid_data: Data, writer, epochs: int,\n                downsample_2017: float,\n                calc_train_loss: bool = True,\n                params: Dict = None):\n    np.random.seed(0)\n\n    # Keep number of data in 1 epoch same between 1st/2nd stage\n    std_batch_length = 12000 // batch_size + 1\n    n_total_batch = 0\n    epoch = 1\n    epoch_start_time = time.time()\n    ensemble = None\n\n    model.eval()\n\n    snapshots = SnapShots(torelance=1.007, interval=3)\n    snapshots.add(model, 0, evaluate(model, valid_data))\n\n    model.train()  # Turn on the train mode\n\n    while epoch < epochs:\n        data = train_data.shuffled()\n        if downsample_2017 > 0.0:\n            data = data.downsample_2017(downsample_2017)\n\n        for i in range(0, data.len() - 1, batch_size):\n            iend = min(i + batch_size, data.len())\n            batch_data = data.slice(i, iend)\n            optimizer.zero_grad()\n            output = model(batch_data)\n\n            loss = crps(output, batch_data.y)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n            optimizer.step()\n\n            n_total_batch += 1\n\n            if n_total_batch > std_batch_length:\n                model.eval()\n\n                if calc_train_loss and epoch % 10 == 0:\n                    train_loss = evaluate(model, data)\n                else:\n                    train_loss = -1\n\n                if epoch % 4 == 0 or epoch > 30:\n                    val_loss = evaluate(model, valid_data)\n                    snapshots.add(model, epoch, val_loss)\n                else:\n                    val_loss = -1\n\n                print('| end of epoch {:3d} | lr: {:2.5f} | time: {:5.2f}s | train loss {:5.6f} | '\n                      'valid loss {:5.9f}'.format(epoch, scheduler.get_lr()[0], (time.time() - epoch_start_time),\n                                                  train_loss, val_loss))\n                scheduler.step()\n                if writer is not None:\n                    writer.writerow([epoch, scheduler.get_lr()[0], train_loss, val_loss])\n                    f.flush()\n\n                n_total_batch = 0\n                epoch += 1\n                epoch_start_time = time.time()\n                model.train()  # Turn on the train mode\n\n                if epoch in [40]:\n                    batch_size *= 2\n                    std_batch_length = 12000 // batch_size + 1\n\n    # reload best model\n    model = snapshots.load_best_single_model(model)\n    eval_single = evaluate(model, valid_data)\n\n    try:\n        ensemble = snapshots.load_ensemble_model(TransformerModel, params)\n        eval_ensemble = evaluate(ensemble, valid_data)\n        print(f'final loss: {eval_single:.8f} (single) / {eval_ensemble:.8f} ({len(ensemble.models)} models)')\n    except:\n        pass\n\n    return ensemble if ensemble is not None else model\n\n\ndef evaluate(eval_model: nn.Module, data: Data, with_clip: bool = True):\n    eval_model.eval()  # Turn on the evaluation mode\n    assert data.y is not None\n\n    with torch.no_grad():\n        y_actual = data.y.numpy()\n        y_predicted = eval_model(data, with_clip)\n        loss = np.sum((y_predicted - y_actual) ** 2) / (199 * len(y_predicted))\n\n    return loss\n\n\n#######################################################################################################################\n# Load & Validation Split\n#######################################################################################################################\n\n\ndef return_delta(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\n\ndef NFL_validation_split(df: pd.DataFrame, game_set=None):\n    games = df[['GameId', 'PossessionTeam']].drop_duplicates()\n\n    # Sort so the latest games are first and label the games with cumulative counter\n    games = games.sort_values(['PossessionTeam', 'GameId'], ascending=[True, False])\n    games['row_number'] = games.groupby(['PossessionTeam']).cumcount() + 1\n\n    # Use last 5 games for each team as validation. There will be overlap since two teams will have the same\n    # GameId\n    game_set = game_set or {1, 2, 3, 4, 5}\n\n    # Set of unique game ids\n    game_ids = set(games[games['row_number'].isin(game_set)]['GameId'].unique().tolist())\n\n    return game_ids\n\n\ndef NFL_group_split(df: pd.DataFrame, nfolds: int, nidx: int):\n    kf = GroupKFold(nfolds)\n\n    train_idx, valid_idx = list(kf.split(df, groups=df['GameId']))[nidx]\n\n    return set(df['GameId'].iloc[valid_idx].unique())\n\n\ndef load_data_nn_test(test_df: pd.DataFrame, scaler: StandardScaler, scaler_meta: StandardScaler) -> Data:\n    play, players = prep(test_df)\n    players_nn, rusher_nn, meta_nn, _, _ = prep_players_nn(play, players, scaler, scaler_meta)\n    X = players_nn.values.astype(np.float32).reshape((-1, 22, len(players_nn.columns)))\n    Xr = rusher_nn.values.astype(np.float32)\n    Xm = meta_nn.values.astype(np.float32)\n    year = play['Year'].values.copy()\n\n    return Data(torch.from_numpy(X), torch.from_numpy(Xr), torch.from_numpy(Xm),\n                None, play['YardLine_std'].values.copy(), year,\n                list(players_nn.columns), list(rusher_nn.columns), list(meta_nn.columns))\n\n\ndef load_data_nn(n_plays_sample=None,\n                 nfolds=None, nidx=None,\n                 skiprows=None,\n                 game_set=None) -> Tuple[Data, Data, StandardScaler, StandardScaler]:\n    train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', nrows=n_plays_sample, skiprows=skiprows)\n    \n\n    play, players = prep(train)\n    players_nn, rusher_nn, meta_nn, scaler, scaler_meta = prep_players_nn(play, players, None, None)\n\n    assert len(players_nn) == len(rusher_nn) * 22\n    assert len(rusher_nn) == len(meta_nn)\n    assert len(rusher_nn) == len(play)\n\n    play_ids = np.array(players_nn.index[np.arange(0, len(players_nn), 22)])\n    game_ids = np.array(players['GameId'].values[np.arange(0, len(players_nn), 22)])\n\n    assert len(play_ids) == len(game_ids)\n\n    if nfolds is not None:\n        assert nidx is not None\n        game_ids_valid = NFL_group_split(train, nfolds, nidx)\n    else:\n        game_ids_valid = NFL_validation_split(train, game_set)\n\n    X = players_nn.values.astype(np.float32).reshape((-1, 22, len(players_nn.columns)))\n    Xr = rusher_nn.values.astype(np.float32)\n    Xm = meta_nn.values.astype(np.float32)\n\n    y = np.vstack(play['Yards'].apply(return_delta).values).astype(np.float32)\n\n    yardLine = play['YardLine_std'].values\n    year = play['Year'].values\n\n    valid_mask = np.isin(game_ids, np.array(list(game_ids_valid)))\n\n    X_valid = torch.from_numpy(X[valid_mask])\n    Xr_valid = torch.from_numpy(Xr[valid_mask])\n    Xm_valid = torch.from_numpy(Xm[valid_mask])\n    y_valid = torch.from_numpy(y[valid_mask])\n    yd_valid = yardLine[valid_mask].copy()\n    yr_valid = year[valid_mask].copy()\n\n    X_train = torch.from_numpy(X[~valid_mask])\n    Xr_train = torch.from_numpy(Xr[~valid_mask])\n    Xm_train = torch.from_numpy(Xm[~valid_mask])\n    y_train = torch.from_numpy(y[~valid_mask])\n    yd_train = yardLine[~valid_mask].copy()\n    yr_train = year[~valid_mask].copy()\n\n    print(f'X_train: {X_train.shape}, {Xr_train.shape}, {Xm_train.shape}')\n    print(f'X_valid: {X_valid.shape}, {Xr_valid.shape}, {Xm_valid.shape}')\n    print(f'y_train: {y_train.shape}, y_valid: {y_valid.shape}')\n    print(f'players: {list(players_nn.columns)}')\n    print(f'rusher: {list(rusher_nn.columns)}')\n    print(f'meta: {list(meta_nn.columns)}')\n\n    dtrain = Data(X_train, Xr_train, Xm_train, y_train, yd_train, yr_train,\n                  list(players_nn.columns), list(rusher_nn.columns), list(meta_nn.columns))\n    dvalid = Data(X_valid, Xr_valid, Xm_valid, y_valid, yd_valid, yr_valid,\n                  list(players_nn.columns), list(rusher_nn.columns), list(meta_nn.columns))\n\n    assert len(X) == len(y)\n    return dtrain, dvalid, scaler, scaler_meta\n\n\ndef crps(y_pred, y_true):\n    loss = torch.mean((torch.cumsum(y_pred, dim=1) - y_true) ** 2)\n    return loss\n\n\n#######################################################################################################################\n## Start Training\n#######################################################################################################################\n\nn_holdout = 0\nn_train = None\n\ntrain_data, valid_data, scaler, scaler_meta = load_data_nn(None)\nn_inp = train_data.players.shape[2]  # Dimension of feature vector per player\nnemb = 128  # Dimension of embedding vector per player\nnhead = 1  # multi-head attention\nnhid = 96  # number of hidden units in attention\nnlayers = 4  # number of transformers stacked\nnfinal = 512  # number of hidden units in final layers\nlr = 0.0001\ngamma = 0.976\ndropout_encoder = 0.0\nn_emb_layers = 3\ndropout_classifier = 0.3\ndropout_embed = 0.15\ndropout_attn = 0.35\nbatch_size = 16\nepochs = 100\nmeta_emb = 8\ndownsample_2017 = 0.4\ngauss_noise = 0.15\ngauss_xy_noise = 0.1\nn_fin_layers = 3\n\nmode = 'ensemble'\nlog_filename = 'kernel_v92_encoder_0_attn_02'\n\nparams = {\n    'ninp': n_inp,\n    'nemb': nemb,\n    'nhead': nhead,\n    'nhid': nhid,\n    'nlayers': nlayers,\n    'nfinal': nfinal,\n    'ninp_rusher': train_data.rusher.shape[1],\n    'pre_LN': True,\n    'dropout_encoder': dropout_encoder,\n    'dropout_embed': dropout_embed,\n    'dropout_classifier': dropout_classifier,\n    'n_emb_layers': n_emb_layers,\n    'ninp_meta': train_data.meta.shape[1],\n    'meta_emb': meta_emb,\n    'gauss_noise': gauss_noise,\n    'gauss_xy_noise': gauss_xy_noise,\n    'n_fin_layers': n_fin_layers,\n    'dropout_attn': dropout_attn\n}\n\nno_decay = ['bias', '.norm']\n\nif mode == 'grid':\n    for dropout_embed in [0.05, 0.1, 0.15]:\n        for dropout_encoder in [0.2, 0.3, 0.4]:\n            log_f = f'{log_filename}_embed{dropout_embed}_encoder{dropout_encoder}.csv'\n            params['dropout_encoder'] = dropout_encoder\n            params['dropout_embed'] = dropout_embed\n            model = TransformerModel(**params)\n\n            f = open(log_f, 'w+', newline='')\n            writer = csv.writer(f)\n            writer.writerow([dropout_embed, dropout_classifier])\n            writer.writerow(['epoch', 'lr', 'train_loss', 'valid_loss'])\n\n            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=gamma)\n\n            model = train_model(model, scheduler, batch_size, train_data, valid_data, writer, epochs, downsample_2017, params=params)\nelif mode == 'ensemble':\n    models = EnsembleModel()\n    game_sets = [\n        {1, 3, 5, 7, 9},\n        {2, 4, 6, 8, 10}\n    ]\n\n    for i in range(len(game_sets)):\n        model = TransformerModel(**params)\n        train_data, valid_data, scaler, scaler_meta = load_data_nn(None, nfolds=8, nidx=i) #load_data_nn(None, game_set=game_sets[i])\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr)    \n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=gamma)\n\n        model = train_model(model, scheduler, batch_size, train_data, valid_data, None, epochs, downsample_2017,\n                            calc_train_loss=False, params=params)\n        models.add_model(model)\n    model = models\nelse:\n    assert mode == 'single'\n    model = TransformerModel(**params)\n    f = open(log_filename + '.csv', 'w+', newline='')\n    writer = csv.writer(f)\n    writer.writerow(train_data.player_cols)\n    writer.writerow(train_data.rusher_cols)\n    writer.writerow(['epoch', 'lr', 'train_loss', 'valid_loss'])\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=gamma)\n\n    model = train_model(model, scheduler, batch_size, train_data, valid_data, writer, epochs, downsample_2017, params=params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tta(test_df, sigma_dir=1.0, sigma_y=1.0):\n    n_aug = 10\n    test_df_aug = pd.concat([test_df]*n_aug)\n    \n    test_df_aug['Dir'] += np.random.normal(0, sigma_dir, size=len(test_df_aug))\n\n    # yは共通で上げ下げ\n    test_df_aug['Y'] += np.repeat(np.random.normal(0, sigma_y, size=n_aug), 22)\n    test_df_aug['PlayId'] += np.repeat(np.arange(0, n_aug), 22)\n    \n    return test_df_aug","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\nenv = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()  # Turn on the evaluation mode\nn_prev = 0\n\noriginal_data = concat_dataset(train_data, valid_data)\n\nfor (test_df, sample_prediction_df) in env.iter_test():\n    try:\n        test_df = tta(test_df)\n        X_test = load_data_nn_test(test_df, scaler, scaler_meta)\n\n    except Exception as e:\n        print(f'### ERROR ### {e} / {test_df}')\n        # submit as-is if something happened\n        env.predict(sample_prediction_df)\n        continue\n\n    with torch.no_grad():\n        predicted = model(X_test).mean(axis=0)\n        sample_prediction_df.iloc[0,:] = np.squeeze(predicted)\n        env.predict(sample_prediction_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.write_submission_file()   ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}