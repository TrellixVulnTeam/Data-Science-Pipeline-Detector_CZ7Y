{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Overview\n\nIt demonstrats how to utilize [the unified Wi-Fi dataset](https://www.kaggle.com/kokitanisaka/indoorunifiedwifids).<br>\nThe Neural Net model is not optimized, there's much space to improve the score. \n\nIn this notebook, I refer these two excellent notebooks.\n* [wifi features with lightgbm/KFold](https://www.kaggle.com/hiro5299834/wifi-features-with-lightgbm-kfold) by [@hiro5299834](https://www.kaggle.com/hiro5299834/)<br>\n I took some code fragments from his notebook.\n* [Simple ðŸ‘Œ 99% Accurate Floor Model ðŸ’¯](https://www.kaggle.com/nigelhenry/simple-99-accurate-floor-model) by [@nigelhenry](https://www.kaggle.com/nigelhenry/)<br>\n I use his excellent work, the \"floor\" prediction.\n\nIt takes much much time to finish learning. <br>\nAnd even though I enable the GPU, it doesn't help. <br>\nIf anybody knows how to make it better, can you please make a comment? <br>\n\nThank you!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport glob\nimport pickle\nimport random\nimport os\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### options\nWe can change the way it learns with these options. <br>\nEspecialy **NUM_FEATS** is one of the most important options. <br>\nIt determines how many features are used in the training. <br>\nWe have 100 Wi-Fi features in the dataset, but 100th Wi-Fi signal sounds not important, right? <br>\nSo we can use top Wi-Fi signals if we think we need to. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# options\n\nNUM_FEATS = 20 # number of features that we use. there are 100 feats but we don't need to use all of them\nbase_path = '/kaggle'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_dir = f\"{base_path}/input/indoorunifiedwifids\"\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nsubm = pd.read_csv(f'{base_path}/input/indoor-location-navigation/sample_submission.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(f'{feature_dir}/train_all.pkl', 'rb') as f:\n  data = pickle.load( f)\n\nwith open(f'{feature_dir}/test_all.pkl', 'rb') as f:\n  test_data = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BSSID_FEATS = [f'bssid_{i}' for i in range(NUM_FEATS)]\nRSSI_FEATS  = [f'rssi_{i}' for i in range(NUM_FEATS)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get numbers of bssids to embed them in a layer\n\nwifi_bssids = []\nfor i in range(100):\n    wifi_bssids.extend(data.iloc[:,i].values.tolist())\nwifi_bssids = list(set(wifi_bssids))\n\nwifi_bssids_size = len(wifi_bssids)\nprint(f'BSSID TYPES: {wifi_bssids_size}')\n\nwifi_bssids_test = []\nfor i in range(100):\n    wifi_bssids_test.extend(test_data.iloc[:,i].values.tolist())\nwifi_bssids_test = list(set(wifi_bssids_test))\n\nwifi_bssids_size = len(wifi_bssids_test)\nprint(f'BSSID TYPES: {wifi_bssids_size}')\n\nwifi_bssids.extend(wifi_bssids_test)\nwifi_bssids_size = len(wifi_bssids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocess\n\nle = LabelEncoder()\nle.fit(wifi_bssids)\nle_site = LabelEncoder()\nle_site.fit(data['site_id'])\n\nss = StandardScaler()\nss.fit(data.loc[:,RSSI_FEATS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[:,RSSI_FEATS] = ss.transform(data.loc[:,RSSI_FEATS])#\nfor i in BSSID_FEATS:\n    data.loc[:,i] = le.transform(data.loc[:,i])\n    data.loc[:,i] = data.loc[:,i] + 1\n    \ndata.loc[:, 'site_id'] = le_site.transform(data.loc[:, 'site_id'])\n\ndata.loc[:,RSSI_FEATS] = ss.transform(data.loc[:,RSSI_FEATS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.loc[:,RSSI_FEATS] = ss.transform(test_data.loc[:,RSSI_FEATS])\nfor i in BSSID_FEATS:\n    test_data.loc[:,i] = le.transform(test_data.loc[:,i])\n    test_data.loc[:,i] = test_data.loc[:,i] + 1\n    \ntest_data.loc[:, 'site_id'] = le_site.transform(test_data.loc[:, 'site_id'])\n\ntest_data.loc[:,RSSI_FEATS] = ss.transform(test_data.loc[:,RSSI_FEATS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nnp.random.seed(10)\ndataset = data.values\nnp.random.shuffle(dataset)\nX= dataset[:, 0:20]\nY = dataset[:,200:203]\nX_site=dataset[:,204:205]\nX=np.hstack((X,X_site))\nX = preprocessing.scale(X)\n#X -= X.mean(axis=0)\n#X /= X.std(axis=0)\n#X = preprocessing.scale(X)\nprint(X)\nprint(Y)\nlen(X[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, Y_train = X[:200000], Y[:200000]     \nX_test, Y_test = X[200000:], Y[200000:] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fail version\n'''\nimport numpy as np\nimport pandas as pd\nimport keras\nimport keras.backend as kb\nimport tensorflow as tf\n\nmodel = keras.Sequential([\n    keras.layers.Dense(32, activation=tf.nn.relu, input_shape=(X.shape[-1],)),\n    keras.layers.Dense(32, activation=tf.nn.relu),\n    keras.layers.Dense(32, activation=tf.nn.relu),\n    keras.layers.Dense(3)\n  ])\n\noptimizer = tf.keras.optimizers.RMSprop(0.0099)\n#optimizer = tf.keras.optimizers.RMSprop(0.9)\nmodel.compile(loss='mean_squared_error',optimizer=optimizer)\n#model.summary()\nX_train= np.asarray(X_train).astype('float32')\nY_train= np.asarray(Y_train).astype('float32')\nmodel.fit(X_train,Y_train,epochs=3)\n#model.evaluate(X_test, Y_test, verbose=20)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train= np.asarray(X_train).astype('float32')\nY_train= np.asarray(Y_train).astype('float32')\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(X_train.shape[1],), activation=\"relu\"))\nmodel.add(Dense(32, activation=\"relu\"))\nmodel.add(Dense(3))\nmodel.compile(loss=\"mse\", optimizer=\"adam\",\nmetrics=[\"mae\"])\nmodel.fit(X_train, Y_train, epochs=50, batch_size=16, verbose=0)\nmodel.save_weights('lg.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test= np.asarray(X_test).astype('float32')\nY_test= np.asarray(Y_test).astype('float32')\naccuracy =model.evaluate(X_test, Y_test, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test= np.asarray(X_test).astype('float32')\nY_test= np.asarray(Y_test).astype('float32')\nY_pred = model.predict(X_test, batch_size=10, verbose=0)\nprint(Y_pred) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = test_data.values\nsub_X= dataset[:, 0:20]\nsub_X_site=dataset[:,201:202]\nsub_X=np.hstack((sub_X,sub_X_site))\nprint(sub_X_site[0])\nsub_X = preprocessing.scale(sub_X)\nlen(sub_X[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_X= np.asarray(sub_X).astype('float32')\npre_Y = model.predict(sub_X, batch_size=10, verbose=0)\nprint(pre_Y) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for v in pre_Y:\n    v[2]=int(round(v[2])) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_Y = pd.DataFrame(pre_Y)\npre_Y.to_csv('result.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd working","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}