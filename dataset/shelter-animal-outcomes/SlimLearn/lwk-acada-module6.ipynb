{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndsample = pd.read_csv('/kaggle/input/shelter-animal-outcomes/sample_submission.csv.gz', compression = 'gzip', header = 0, sep=',',quotechar='\"')\ndtest = pd.read_csv('/kaggle/input/shelter-animal-outcomes/test.csv.gz', compression = 'gzip', header = 0, sep=',',quotechar='\"')\ndtrain = pd.read_csv('/kaggle/input/shelter-animal-outcomes/train.csv.gz', compression = 'gzip', header = 0, sep=',',quotechar='\"')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom sklearn.impute import SimpleImputer\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore the dataset\ndtrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 11 columns initially with OutcomeType as our results. We will explore the rest of the 10 features and decide which features to use for analysis. Below are the list of the column names and their respective descriptions.\n\nAgeuponOutcome: Age when outcome happened\nAnimalID: Animal ID number\nAnimalType: cat or dog\nBreed: Breed of the animal\nColor: Color of the animal\nDateTime: Date time of adoption.\nID: id of data\nName: Name given to animal\nOutcomeSubtype: more details about outcome\nOutcomeType: Outcome (5 targets)\nSexUponOutcome: Sex of animal during outcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify null values in training dataset\n\ndtrain.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check number of null values in columns that have null values. We will ommit 'Name' as it is not likely to affect the outcome and it will be dropped later for our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.loc[:, 'OutcomeSubtype'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OutcomeSubtype column will be dropped later as there is too many null values for accurate analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.loc[:, 'SexuponOutcome'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.loc[:, 'AgeuponOutcome'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace missing values in columns \"SexuponOutcome\" and \"AgeuponOutcome\" with most frequent data assuming\n# they are most likely to occur and since missing values are not so many\n\ncols_for_na = [\"SexuponOutcome\", \"AgeuponOutcome\"]\nimputer_na = SimpleImputer(strategy=\"most_frequent\")\n\ndtrain.loc[:, cols_for_na] = imputer_na.fit_transform(dtrain.loc[:, cols_for_na])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check null values for the processed columns\n\ndtrain.loc[:, cols_for_na].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check unique values in data set columns with high number of unique values\n\ndtrain['OutcomeType'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain['Breed'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain['Color'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert Age in 'AgeuponOutcome' to number of years\n\ndef AgetoYears(input):\n    key = input.split()\n    \n    if re.findall(r'\\Ayear', key[1]):\n        years = 1\n    elif re.findall(r'\\Amonth', key[1]):\n        years = 12\n    elif re.findall(r'\\Aweek', key[1]):\n        years = 52\n    else:\n        years = 365\n        \n    return int(key[0])/years\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.AgeuponOutcome = dtrain.AgeuponOutcome.apply(AgetoYears)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if more dogs or cats are put into animal shelters\nsns.countplot(x=\"AnimalType\", data=dtrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check outcome of dogs or cats\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\nsns.countplot(data=dtrain, x='AnimalType',hue='OutcomeType', ax=ax1)\nsns.countplot(data=dtrain, x='OutcomeType',hue='AnimalType', ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above output, it seems like more dogs are adopted and returned to owners, while cats are more likely to be transfered and euthanised. We also see that more dogs are put into adoption homes but we cannot conclude at this point because it might be there are significantly more dog owners, thus resulting in more dogs in shelters. At this point, we still cannot that if dogs are more desirable than cats."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Upon inspection, let's assume that the age of the animals have the greatest effect to the outcome apart from\n# the other features. We will see if that is the case from the results afterwards.\n\n# Let's define a function to explore the age group and the outcome effects it has.\n\ndef age_group(age):\n    if age < 3: group = 'young'\n    elif age < 6: group = 'adult'\n    else: group = 'old'\n    return group\n\ndtrain['AgeGroup'] = dtrain.AgeuponOutcome.apply(age_group)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot and explore the age group and outcomes\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\nsns.countplot(data=dtrain, x='AgeGroup',hue='OutcomeType', ax=ax1)\nsns.countplot(data=dtrain, x='OutcomeType',hue='AgeGroup', ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, the young animals are the ones most likely to be adopted than the rest of the groups."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get number of occurrences of each unique breed and color. These are the two columns with most number of variables. We will count them and see if we\n# need further processing when converting them into dummy indicator variables \n\ndtrain_unique_breed = Counter(dtrain['Breed'])\ndtrain_unique_color = Counter(dtrain['Color'])\n\nprint(f\"Number of unique breeds in given train set: {len(dtrain_unique_breed)}\")\nprint(f\"Number of unique colours in given train set: {len(dtrain_unique_color)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore the dtrain_unique_breed and get an idea of the number of breeds and their occurences in the data\n\ndtrain_unique_breed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore the dtrain_unique_color and get an idea of the number of colors and their occurences in the data\n\ndtrain_unique_color","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For our models used, we have to convert the deciding features into categorical variables which will yield a very high numebr of columns and we will likely have to deal with it when predicting the results with the given test set.\n\nFor the significant high number of breeds and colours, especially those that fall into exotic colours and breeds, it is virtually impossible to generalize them into a small enough group without compromising accuracy.\n\nOne approach for 'Breed' is to segregate them into simply pure or mixed breed. In this case, we end up with just two columns of 'Pure' or 'Mix' after doing some manipulation in the column values. Likewise, we will do the same for 'Color' column as well.\n\nOur approach here is to delete as many of the breeds and colours with the LEAST number of occurences in the dataframe as they do not contribute much to an accurate analysis. The remaining animals in the dataframe will generate an equal number of columns when converting them into dummy/indicator variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find unique number of breeds and colours for number of columns created in dataframe after creating\n# dummy/indicator variables when predicting results.\n\ndtest_unique_breed = Counter(dtest['Breed'])\ndtest_unique_color = Counter(dtest['Color'])\n\nprint(f\"Number of unique breeds in given test set: {len(dtest_unique_breed)}\")\nprint(f\"Number of unique colours in given test set: {len(dtest_unique_color)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 1380-913=467 animals starting from least number of breed\n# Add them into a list to be deleted to match breeds in given test set.\n\n# Count the number of loops to exit\ncount=0\n\n# List of lesser animal breeds\nlesser_breed=[]\n\n# Number of occurences of a breed in the list\nbreed_number=0\n\nwhile count<464:\n    breed_number+=1\n    for x in dtrain_unique_breed:\n        if dtrain_unique_breed[x]==breed_number and count<464:\n            lesser_breed.append(x)\n            count+=1\n            \nprint(f\"Count is {count}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above loop counts should be 467 by calculation but result given was 911 unique value for breed. I cannot find the error and has to change the value to 464 by trial and error to yield the result 913 when checked with given test set number of breeds."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 366-277=89 animals starting from least number of breed\n# Add them into a list to be deleted to match breeds in given test set.\n\n# Count the number of loops to exit\ncount=0\n\n# List of lesser animal breeds\nlesser_color=[]\n\n# Number of occurences of a breed in the list\ncolor_number=0\n\nwhile count<89:\n    color_number+=1\n    for x in dtrain_unique_color:\n        if dtrain_unique_color[x]==color_number and count<89:\n            lesser_color.append(x)\n            count+=1\n            \nprint(f\"Count is {count}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 467 animals with the least Breed in the original dataset.\n\nfor x in lesser_breed:\n    dtrain = dtrain.drop(dtrain[dtrain.Breed == x].index)\n    \ndtrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the 89 animals with least occurences of colours in the original dataset.\n\nfor x in lesser_color:\n    dtrain = dtrain.drop(dtrain[dtrain.Color == x].index)\n    \ndtrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get y training set from OutcomeType column\ny = dtrain.OutcomeType","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reset the index for the dataframe\n\ndtrain=dtrain.reset_index()\ndtrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a method to get whether entries in a column contains mixed elements or not. This will be used in Breed and Color columns.\ndef find_mix(x):\n    if x.find('Mix')>=0 or x.find('/')>=0: return 'Mix'\n    else: return 'Pure'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check and change Breed and Color columns into 'Pure' or 'Mix'\ndtrain[\"Breed\"]=dtrain.Breed.apply(find_mix)\ndtrain[\"Color\"]=dtrain.Color.apply(find_mix)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop irrelevant columns that are not likely to affect outcome. The following will be dropped below:\n# 'AnimalID' and 'OutcomeType' are stored above.\n# 'OutcomesubType' has too many null values and is not suitable for analysis.\n# Outcome is not likely to be affected by having a name or not so 'Name' is dropped as well.\n# 'DateTime' documents the date and time of the outcome and has no effect on the outcome\n# 'AgeGroup' is not needed anymore as we will be using AgeuponOutcome in numerical form, which will yield more favourable results.\ndtrain = dtrain.drop([\"index\", \"AnimalID\", \"OutcomeType\", \"OutcomeSubtype\", \"Name\", \"DateTime\", \"AgeGroup\"], axis=1)\ndtrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create indicator variables on dataset.\n\ndtrain = pd.get_dummies(dtrain, columns=['AnimalType', 'SexuponOutcome', 'Breed', 'Color'])\ndtrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test split dataset\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(dtrain, y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training set overview\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y training set overview\n\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set overview\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y testing set\n\ny_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check matching number of rows and columns for train and test sets "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of Rows, Features in Training Dataset: {X_train.shape}\")\nprint(f\"Number of Rows, Features in Test Dataset: {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of Rows in Training Response: {y_train.shape}\")\nprint(f\"Number of Rows in Test Response: {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing testing models\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use RandomForestClasifier as testing model\n\nrfc_train = RandomForestClassifier(n_estimators=100)\nrfc_train.fit(X_train , y_train)\n\nrfc_test = RandomForestClassifier(n_estimators=100)\nrfc_test.fit(X_test , y_test)\n\ny_pred_train = rfc_train.predict(X_train)\ny_pred_test = rfc_test.predict(X_test)\n\nprint(f\"RandomForestClassifier Accuracy train Score: {accuracy_score(y_train, y_pred_train)}\")\nprint(f\"RandomForestClassifier Accuracy test Score: {accuracy_score(y_test, y_pred_test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Logistic Regression for testing model\n\nlr = LogisticRegression()\n\n# Get accuracy using train set\nlr.fit(X_train, y_train)\n\nprint(lr.classes_)\nprint(f\"LogisticRegression Accuracy train Score: {lr.score(X_train, y_train)}\")\n\n# Get accuracy using test set\ntest_predict = lr.predict(X_test)\n\nprint(f\"LogisticRegression Accuracy test Score: {np.mean(test_predict == y_test)}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use DecisionTreeClassifier as testing model\n\ndtc_train = DecisionTreeClassifier()\ndtc_train.fit(X_train, y_train)\n\ndtc_test = DecisionTreeClassifier()\ndtc_test.fit(X_test, y_test)\n\ny_pred_train = dtc_train.predict(X_train)\ny_pred_test = dtc_test.predict(X_test)\n\nprint(f\"DecisionTreeClassifier Accuracy train Score: {accuracy_score(y_train, y_pred_train)}\")\nprint(f\"DecisionTreeClassifier Accuracy test Score: {accuracy_score(y_test, y_pred_test)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above, RandomForestClassifier and DecisionTreeClassifier generate similar accuracy score and both score much higher than LogisticRegression, which is expected. We will use DecisionTreeClassifier."},{"metadata":{},"cell_type":"markdown","source":"# Process given test set for yielding results."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check given testing set\ndtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store ID for later insertion back into submission results\ntemp_ID=dtest['ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_ID","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtest.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# impute most frequent value into AgeuponOutcome column\ndtest[[\"AgeuponOutcome\"]] = imputer_na.fit_transform(dtest[[\"AgeuponOutcome\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change age in 'AgeuponOutcome' to number of years\n\ndtest.AgeuponOutcome = dtest.AgeuponOutcome.apply(AgetoYears)\n\n# Check and change Breed and Color columns into 'Pure' or 'Mix'\ndtest[\"Breed\"]=dtest.Breed.apply(find_mix)\ndtest[\"Color\"]=dtest.Color.apply(find_mix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop irrelevant columns for predicting\ndtest = dtest.drop([\"ID\", \"Name\", \"DateTime\"], axis=1)\ndtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create indicator variables on dataset.\ndtest = pd.get_dummies(dtest, columns=['AnimalType', 'SexuponOutcome', 'Breed', 'Color'])\ndtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the prediction and convert it into categorical output.\n\npredictions = dtc_train.predict(dtest)\n\npredictions = pd.get_dummies(predictions)\n\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for null values in results.\n\npredictions.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare with given sample results to hand in.\ndsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.insert(loc=0,column='ID',value=temp_ID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Match final results with sample results above.\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.to_csv('submission.csv', index = False )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}