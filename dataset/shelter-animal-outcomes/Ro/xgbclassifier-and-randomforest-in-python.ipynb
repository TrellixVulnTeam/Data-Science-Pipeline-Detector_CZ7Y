{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nimport re\nimport matplotlib as plt\nimport numpy as np\nfrom datetime import *\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\n\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn import cross_validation\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Read the dataset\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ndataset = train.drop(['AnimalID', 'OutcomeSubtype', 'OutcomeType'], axis=1)\ndataset = dataset.append(test.drop('ID', axis=1), ignore_index=True)\nprint(train.shape, test.shape, dataset.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"dataset.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#calculate Age in days\ndef calculate_age(x):\n    if pd.isnull(x):\n        return x\n    num = int(x.split(' ')[0])\n    if 'year' in x:\n        return num * 365\n    elif 'month' in x:\n        return num * 30\n    elif 'week' in x:\n        return num * 7\n    \ndef has_name(x):\n    if pd.isnull(x):\n        return 0\n    return 1\n\ndef is_mix(x):\n    if 'Mix' in x:\n        return 1\n    return 0"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#data transformation\n\ndataset['AgeuponOutcome'] = dataset['AgeuponOutcome'].apply(lambda x : calculate_age(x))\ndataset['AgeuponOutcome'].fillna(dataset['AgeuponOutcome'].dropna().mean(), inplace=True)\n\n\n# Since there is only one NA, I will assign it to maximum class\ndataset['SexuponOutcome'].fillna('Neutered Male', inplace=True)\n\n\n# Does Animal has a name\ndataset['HasName'] = dataset['Name'].apply(has_name)\n\n\n# Is animal of mix breed?\ndataset['IsMix'] = dataset['Breed'].apply(is_mix)\n\n\n# Break SexuponOutcome into two - Sterilized and Sex\nsex = dataset['SexuponOutcome'].str.split(' ', expand=True)\ndataset['Sterilized'] = sex[0]\ndataset['Sterilized'].fillna('Unknown', inplace=True)\ndataset['Sex'] = sex[1]\ndataset['Sex'].fillna('Unknown', inplace=True)\n\n\ndates = dataset['DateTime'].apply(lambda x : datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\ndataset['Year'] = dates.apply(lambda x : x.year)\ndataset['Month'] = dates.apply(lambda x : x.month)\ndataset['Day'] = dates.apply(lambda x : x.weekday())\ndataset['Hour'] = dates.apply(lambda x : x.hour)\n\n\ndataset['Breed_New'] = dataset['Breed'].apply(lambda x: x.split(' Mix')[0])\nbreeds = dataset['Breed_New'].apply(lambda x : x.split('/'))\ndataset['Breed_1'] = breeds.apply(lambda x : x[0])\n# Instead of Breed_2, I will use Multiple_Breeds feature\n#dataset['Breed_2'] = breeds.apply(lambda x : 'Unknown' if len(x) == 1 else x[1] )\ndataset['Multiple_Breeds'] = dataset['Breed'].apply(lambda x : 1 if '/' in x else 0)\n\n\ncolors = dataset['Color'].apply(lambda x : x.split('/'))\ndataset['Color_1'] = colors.apply(lambda x : x[0].split(' ')[0])\n# Instead of Color_2, I will use Multiple_Colors feature\n# dataset['Color_2'] = colors.apply(lambda x : x[1].split(' ')[0] if len(x) > 1 else 'None')\ndataset['Multiple_Colors'] = dataset['Color'].apply(lambda x : 1 if '/' in x else 0)\n\n\n# Encoding\nenc = LabelEncoder()\ndataset['Color_1'] = enc.fit_transform(dataset['Color_1'])\ndataset['Breed_1'] = enc.fit_transform(dataset['Breed_1'])\n\n\n# Dummy Columns\ndummy_columns = ['Sterilized', 'Sex', 'AnimalType']\ndataset = pd.get_dummies(dataset, columns=dummy_columns)\n\n\n# Drop unnecessary columns\ndrop_columns = ['Name', 'DateTime', 'SexuponOutcome', 'Breed', 'Color', 'Breed_New']\ndataset = dataset.drop(drop_columns, axis=1)\n\nprint(train.shape, test.shape, dataset.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_x = dataset.loc[0:26728,]\n\nenc = LabelEncoder()\ntrain_y = enc.fit_transform(train['OutcomeType'])\ntrain_y = pd.DataFrame(train_y)\n\ntest_x = dataset.loc[26729:38185,]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Cross Validation\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(train_x.values, train_y[0].values,\n                                                                     test_size=0.3, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Choose best parameters for randomforest\ndef best_params(train_x, train_y):\n    rfc = RandomForestClassifier()\n    param_grid = { \n        'n_estimators': [50, 400],\n        'max_features': ['auto', 'sqrt', 'log2']\n    }\n    \n    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n    CV_rfc.fit(train_x, train_y)\n    return CV_rfc.best_params_\n\nprint(best_params(train_x.values, train_y[0].values))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# RandomForest Classifier \n\nrf = RandomForestClassifier(n_estimators=400, max_features='log2').fit(X_train, y_train)\nprint('Cross Validation for RandomForestClassifier')\nprint(rf.score(X_test, y_test))\n\nprediction = pd.DataFrame(rf.predict_proba(test_x.values))\nprediction.columns = ['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer']\nprediction = pd.concat([test['ID'], prediction], axis=1)\nprediction.to_csv('randomforest.csv', index=False)\n\n#Public LeaderBoard Score - 0.81316\nprediction.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Simple XGBClassifier. \n# For better results we need to fine tune the parameters\n\nxgboost = XGBClassifier(learning_rate =0.05,\n n_estimators=500,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'multi:softprob',\n nthread=4,\n scale_pos_weight=1,\n seed=27).fit(X_train, y_train)\n\nprint('Cross Validation for XGBClassifier')\nprint(xgboost.score(X_test, y_test))\n\nprediction = pd.DataFrame(xgboost.predict_proba(test_x.values))\nprediction.columns = ['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer']\nprediction = pd.concat([test['ID'], prediction], axis=1)\nprediction.to_csv('xgbclassifier.csv', index=False)\n\n#Public LeaderBoard Score - 0.74264\nprediction.head()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}