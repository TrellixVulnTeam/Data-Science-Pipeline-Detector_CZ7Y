{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Using Embeddings for Categorical Variables"},{"metadata":{},"cell_type":"markdown","source":"<b>Dataset</b> - https://www.kaggle.com/c/shelter-animal-outcomes\n\n<b>Problem Statement</b>: Given certain features about a shelter animal (like age, sex, color, breed), predict its outcome.\n\nThere are 5 possible outcomes: Return_to_owner, Euthanasia, Adoption, Transfer, Died. We are expected to find the probability of an animal's outcome belonging to each of the 5 categories."},{"metadata":{},"cell_type":"markdown","source":"## Library imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as torch_optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{},"cell_type":"markdown","source":"#### Training set "},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/shelter-animal-outcomes/train.csv.gz')\nprint(\"Shape:\", train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/shelter-animal-outcomes/test.csv.gz')\nprint(\"Shape:\", test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sample submission file\n\nFor each row, each outcome's probability needs to be filled into the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/shelter-animal-outcomes/sample_submission.csv.gz')\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Very basic data exploration"},{"metadata":{},"cell_type":"markdown","source":"#### How balanced is the dataset?\n\nAdoption and Transfer seem to occur a lot more than the rest"},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(train['OutcomeType'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### What are the most common names and how many times do they occur? \n\nThere seem to be too many Nan values. Name might not be a very important factor too"},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(train['Name']).most_common(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing\n\nOutcomeSubtype column seems to be of no use, so we drop it. Also, since animal ID is unique, it doesn't help in training"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train.drop(columns= ['OutcomeType', 'OutcomeSubtype', 'AnimalID'])\nY = train['OutcomeType']\ntest_X = test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Stacking train and test set so that they undergo the same preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_df = train_X.append(test_X.drop(columns=['ID']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### splitting datetime into month and year"},{"metadata":{"trusted":true},"cell_type":"code","source":"# stacked_df['DateTime'] = pd.to_datetime(stacked_df['DateTime'])\n# stacked_df['year'] = stacked_df['DateTime'].dt.year\n# stacked_df['month'] = stacked_df['DateTime'].dt.month\nstacked_df = stacked_df.drop(columns=['DateTime'])\nstacked_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### dropping columns with too many nulls"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in stacked_df.columns:\n    if stacked_df[col].isnull().sum() > 10000:\n        print(\"dropping\", col, stacked_df[col].isnull().sum())\n        stacked_df = stacked_df.drop(columns = [col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### label encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in stacked_df.columns:\n    if stacked_df.dtypes[col] == \"object\":\n        stacked_df[col] = stacked_df[col].fillna(\"NA\")\n    else:\n        stacked_df[col] = stacked_df[col].fillna(0)\n    stacked_df[col] = LabelEncoder().fit_transform(stacked_df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making all variables categorical\nfor col in stacked_df.columns:\n    stacked_df[col] = stacked_df[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### splitting back train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = stacked_df[0:26729]\ntest_processed = stacked_df[26729:]\n\n#check if shape[0] matches original\nprint(\"train shape: \", X.shape, \"orignal: \", train.shape)\nprint(\"test shape: \", test_processed.shape, \"original: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Encoding target"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = LabelEncoder().fit_transform(Y)\n\n#sanity check to see numbers match and matching with previous counter to create target dictionary\nprint(Counter(train['OutcomeType']))\nprint(Counter(Y))\ntarget_dict = {\n    'Return_to_owner' : 3,\n    'Euthanasia': 2,\n    'Adoption': 0,\n    'Transfer': 4,\n    'Died': 1\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### train-valid split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.10, random_state=0)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Choosing columns for embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#categorical embedding for columns having more than two values\nembedded_cols = {n: len(col.cat.categories) for n,col in X.items() if len(col.cat.categories) > 2}\nembedded_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedded_col_names = embedded_cols.keys()\nlen(X.columns) - len(embedded_cols) #number of numerical columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Determining size of embedding \n(borrowed from https://www.usfca.edu/data-institute/certificates/fundamentals-deep-learning lesson 2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]\nembedding_sizes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pytorch Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ShelterOutcomeDataset(Dataset):\n    def __init__(self, X, Y, embedded_col_names):\n        X = X.copy()\n        self.X1 = X.loc[:,embedded_col_names].copy().values.astype(np.int64) #categorical columns\n        self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32) #numerical columns\n        self.y = Y\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        return self.X1[idx], self.X2[idx], self.y[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating train and valid datasets\ntrain_ds = ShelterOutcomeDataset(X_train, y_train, embedded_col_names)\nvalid_ds = ShelterOutcomeDataset(X_val, y_val, embedded_col_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making device (GPU/CPU) compatible \n(borrowed from https://jovian.ml/aakashns/04-feedforward-nn)\n\nIn order to make use of a GPU if available, we'll have to move our data and model to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\n\n(modified from https://www.usfca.edu/data-institute/certificates/fundamentals-deep-learning lesson 2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ShelterOutcomeModel(nn.Module):\n    def __init__(self, embedding_sizes, n_cont):\n        super().__init__()\n        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n        n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n        self.n_emb, self.n_cont = n_emb, n_cont\n        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 200)\n        self.lin2 = nn.Linear(200, 70)\n        self.lin3 = nn.Linear(70, 5)\n        self.bn1 = nn.BatchNorm1d(self.n_cont)\n        self.bn2 = nn.BatchNorm1d(200)\n        self.bn3 = nn.BatchNorm1d(70)\n        self.emb_drop = nn.Dropout(0.6)\n        self.drops = nn.Dropout(0.3)\n        \n\n    def forward(self, x_cat, x_cont):\n        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n        x = torch.cat(x, 1)\n        x = self.emb_drop(x)\n        x2 = self.bn1(x_cont)\n        x = torch.cat([x, x2], 1)\n        x = F.relu(self.lin1(x))\n        x = self.drops(x)\n        x = self.bn2(x)\n        x = F.relu(self.lin2(x))\n        x = self.drops(x)\n        x = self.bn3(x)\n        x = self.lin3(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ShelterOutcomeModel(embedding_sizes, 1)\nto_device(model, device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_optimizer(model, lr = 0.001, wd = 0.0):\n    parameters = filter(lambda p: p.requires_grad, model.parameters())\n    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n    return optim","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Training function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, optim, train_dl):\n    model.train()\n    total = 0\n    sum_loss = 0\n    for x1, x2, y in train_dl:\n        batch = y.shape[0]\n        output = model(x1, x2)\n        loss = F.cross_entropy(output, y)   \n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n        total += batch\n        sum_loss += batch*(loss.item())\n    return sum_loss/total","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Evaluation function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_loss(model, valid_dl):\n    model.eval()\n    total = 0\n    sum_loss = 0\n    correct = 0\n    for x1, x2, y in valid_dl:\n        current_batch_size = y.shape[0]\n        out = model(x1, x2)\n        loss = F.cross_entropy(out, y)\n        sum_loss += current_batch_size*(loss.item())\n        total += current_batch_size\n        pred = torch.max(out, 1)[1]\n        correct += (pred == y).float().sum().item()\n    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n    return sum_loss/total, correct/total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_loop(model, epochs, lr=0.01, wd=0.0):\n    optim = get_optimizer(model, lr = lr, wd = wd)\n    for i in range(epochs): \n        loss = train_model(model, optim, train_dl)\n        print(\"training loss: \", loss)\n        val_loss(model, valid_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training "},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 1000\ntrain_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loop(model, epochs=8, lr=0.05, wd=0.00001)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}