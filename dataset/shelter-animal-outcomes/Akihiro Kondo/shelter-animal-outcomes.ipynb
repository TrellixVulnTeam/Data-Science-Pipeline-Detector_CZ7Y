{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data file\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost.sklearn import XGBClassifier \nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/shelter-animal-outcomes/train.csv.gz', header=0)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/shelter-animal-outcomes/test.csv.gz', header=0)\ntest.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/shelter-animal-outcomes/sample_submission.csv.gz', header=0)\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mid = train.copy() \ntrain_mid['train_or_test'] = 'train'\n\ntest_mid = test.copy()\ntest_mid['train_or_test'] = 'test'\n\ntest_mid['OutcomeType'] = 9 # Put 9 to Survived column temporary\nalldata = pd.concat([train_mid, test_mid], sort=False, axis=0).reset_index(drop=True) \n\n# Check all of data\nprint('The size of the train data:' + str(train.shape))\nprint('The size of the test data:' + str(test.shape))\nprint('The size of the submission data:' + str(submission.shape))\nprint('The size of the alldata data:' + str(alldata.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"breed = pd.get_dummies(alldata['Breed'])\ncolor = pd.get_dummies(alldata['Color'])\nsexuponOutcome = pd.get_dummies(alldata['SexuponOutcome'])\nanimalType = pd.get_dummies(alldata['AnimalType'])\noutcomeSubtype = pd.get_dummies(alldata['OutcomeSubtype'])\n\ndel alldata['Color']\ndel alldata['Breed']\ndel alldata['SexuponOutcome']\ndel alldata['AnimalType']\ndel alldata['OutcomeSubtype']\n\n# With or without a name, the importance may change. will do One-Hot encording if name have or not\nalldata['Name'].isnull()\nalldata['Name'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing NaN to Int 0\nalldata['Name'] = alldata['Name'].fillna(0)\n# Regular expression Extract the name of an English word and insert Int 1\nalldata['Name'] = alldata['Name'].replace(r\"\\b[\\\\u\\\\l]+\\b\",1, regex=True)\n\n# Insert 1\nif alldata['Name'] is not 0:\n  alldata['Name'].fillna(1)\n\n# Datetime also important features. But delete temporary\ndel alldata['DateTime']\ndel alldata['AgeuponOutcome']\n\n# Marge all of One-Hot column\nalldata = pd.concat([alldata, breed, color, sexuponOutcome, animalType, outcomeSubtype], axis=1)\n\n# Split alldata into train and test\ntrain = alldata.query('train_or_test == \"train\"')\ntest = alldata.query('train_or_test == \"test\"')\n\ntrain['OutcomeType'] = train['OutcomeType'].replace(\"Adoption\",0).replace(\"Died\",1).replace(\"Euthanasia\",2).replace(\"Return_to_owner\",3).replace(\"Transfer\",4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_col = 'OutcomeType'\ndrop_col = ['AnimalID', 'OutcomeType', 'train_or_test', 'ID', 'Name']\n\ntrain_feature = train.drop(columns=drop_col)\ntrain_target = train[target_col]\ntest_feature = test.drop(columns=drop_col)\n\nX_train, X_test, y_train, y_test = train_test_split(train_feature, train_target, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForest==============\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nprint('='*20)\nprint('RandomForestClassifier')\nprint(f'accuracy of train set: {rf.score(X_train, y_train)}')\nprint(f'accuracy of test set: {rf.score(X_test, y_test)}')\n\nrf_prediction = rf.predict(test_feature)\nrf_prediction\n\n# Create submission data\n# rf_submission = pd.DataFrame({\"ID\":submission['ID'], \"OutcomeType\":rf_prediction})\n# rf_submission.to_csv(\"RandomForest_submission.csv\", index=False)\n\n# SVC==============\n\nsvc = SVC(verbose=True, random_state=0)\nsvc.fit(X_train, y_train)\nprint('='*20)\nprint('SVC')\nprint(f'accuracy of train set: {svc.score(X_train, y_train)}')\nprint(f'accuracy of test set: {svc.score(X_test, y_test)}')\n\nsvc_prediction = svc.predict(test_feature)\nsvc_prediction\n\n\n# LinearSVC==============\n\nlsvc = LinearSVC(verbose=True)\nlsvc.fit(X_train, y_train)\nprint('='*20)\nprint('LinearSVC')\nprint(f'accuracy of train set: {lsvc.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lsvc.score(X_test, y_test)}')\n\nlsvc_prediction = lsvc.predict(test_feature)\nlsvc_prediction\n\n\n# k-近傍法（k-NN）==============\n\nknn = KNeighborsClassifier(n_neighbors=3) #引数は分類数\nknn.fit(X_train, y_train)\nprint('='*20)\nprint('KNeighborsClassifier')\nprint(f'accuracy of train set: {knn.score(X_train, y_train)}')\nprint(f'accuracy of test set: {knn.score(X_test, y_test)}')\n\nknn_prediction = knn.predict(test_feature)\nknn_prediction\n\n\n# 決定木==============\n\ndecisiontree = DecisionTreeClassifier(max_depth=3, random_state=0)\ndecisiontree.fit(X_train, y_train)\nprint('='*20)\nprint('DecisionTreeClassifier')\nprint(f'accuracy of train set: {decisiontree.score(X_train, y_train)}')\nprint(f'accuracy of test set: {decisiontree.score(X_test, y_test)}')\n\ndecisiontree_prediction = decisiontree.predict(test_feature)\ndecisiontree_prediction\n\n\n# SGD Classifier==============\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nprint('='*20)\nprint('SGD Classifier')\nprint(f'accuracy of train set: {sgd.score(X_train, y_train)}')\nprint(f'accuracy of test set: {sgd.score(X_test, y_test)}')\n\nsgd_prediction = sgd.predict(test_feature)\nsgd_prediction\n\n\n# Gradient Boosting Classifier==============\n\ngradientboost = GradientBoostingClassifier(random_state=0)\ngradientboost.fit(X_train, y_train)\nprint('='*20)\nprint('GradientBoostingClassifier')\nprint(f'accuracy of train set: {gradientboost.score(X_train, y_train)}')\nprint(f'accuracy of test set: {gradientboost.score(X_test, y_test)}')\n\ngradientboost_prediction = gradientboost.predict(test_feature)\ngradientboost_prediction\n\n\n# XGBClassifier==============\n\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nprint('='*20)\nprint('XGB Classifier')\nprint(f'accuracy of train set: {xgb.score(X_train, y_train)}')\nprint(f'accuracy of test set: {xgb.score(X_test, y_test)}')\n\n# LGBMClassifier==============\n\nlgbm = LGBMClassifier()\nlgbm.fit(X_train, y_train)\nprint('='*20)\nprint('LGBM Classifier')\nprint(f'accuracy of train set: {lgbm.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lgbm.score(X_test, y_test)}')\n\n# CatBoostClassifier==============\n\ncatboost = CatBoostClassifier()\ncatboost.fit(X_train, y_train)\nprint('='*20)\nprint('CatBoost Classifier')\nprint(f'accuracy of train set: {catboost.score(X_train, y_train)}')\nprint(f'accuracy of test set: {catboost.score(X_test, y_test)}')\n\n# VotingClassifier==============\n\nfrom sklearn.ensemble import VotingClassifier\n\n# voting に使う分類器を用意する\nestimators = [\n  (\"rf\", rf),\n  (\"svc\", svc),\n  (\"lsvc\", lsvc),\n  (\"knn\", knn),\n  (\"decisiontree\", decisiontree),\n  (\"sgd\", sgd),\n  (\"gradientboost\", gradientboost),\n]\n\nvote = VotingClassifier(estimators=estimators)\nvote.fit(X_train, y_train)\nprint('='*20)\nprint('VotingClassifier')\nprint(f'accuracy of train set: {vote.score(X_train, y_train)}')\nprint(f'accuracy of test set: {vote.score(X_test, y_test)}')\n\nvote_prediction = vote.predict(test_feature)\nvote_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}