{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n%matplotlib inline \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.feature_selection import VarianceThreshold, RFE, SelectKBest, chi2\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nsns.set_style('whitegrid')\npd.set_option('display.max_columns', None) # display all columns\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nsample = pd.read_csv(\"../input/sample_submission.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Exploration\ntest.head()\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Drop \"OutcomeSubtype\" feature, not used in test set\ntrain.drop(\"OutcomeSubtype\", axis = 1, inplace = True)\n\n### Get target\ntarget = train[\"OutcomeType\"]\n\n### Drop \"OutcomeType\" in train, now train and test are in same structure\ntrain.drop(\"OutcomeType\", axis = 1, inplace = True)  # already used as target\ntrain[\"ID\"] = train[\"AnimalID\"]\ntrain.drop(\"AnimalID\", axis = 1, inplace = True)     # unique, independent\ntarget.value_counts()\ntrain.shape"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### set index for train and test\ntrain.set_index('ID', inplace=True)\ntest.set_index('ID', inplace=True)\ntrain.shape\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Combine to data\ndata = pd.concat([train, test])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### data cleaning\ndata_cl = data.copy()\ndata_cl[\"SexuponOutcome\"][\"A667395\"] = \"Neutered Male\"\n\n# Color\ncolor_counts = data_cl[\"Color\"].value_counts()\nrare_colors = color_counts[color_counts <= 20].index\ndata_cl.loc[data_cl[\"Color\"].isin(rare_colors), \"Color\"] = \"Other\"\n\n# Breed\nbreed_counts = data_cl[\"Breed\"].value_counts()\nrare_breeds = breed_counts[breed_counts <= 20].index\ndata_cl.loc[data_cl[\"Breed\"].isin(rare_breeds), \"Breed\"] = \"Other\""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Deal with Name later\n#data_cl.loc[data_cl[\"Name\"].isnull(), \"Name\"] = \"NoName\"\n#name_counts = data_cl[\"Name\"].value_counts()\n#len(name_counts[name_counts >= 3])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# drop \"Name\" and \"DateTime\" temporarily\ndata_cl.drop(\"Name\", axis=1, inplace=True)\ndata_cl.drop(\"DateTime\", axis=1, inplace=True)\ndata_cl.shape\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Encode categorical variables\ncategorial_cols = [\"AnimalType\", \"SexuponOutcome\", \"AgeuponOutcome\", \"Breed\", \"Color\"]\n\nfor cc in categorial_cols:\n    dummies = pd.get_dummies(data_cl[cc])\n    dummies = dummies.add_prefix(\"{}#\".format(cc))\n    data_cl.drop(cc, axis=1, inplace=True)\n    data_cl = data_cl.join(dummies)\n    \ndata_cl.shape"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Feature Selection\n\n# Seperate to train for validation\nX = data_cl.iloc[:26729]\nmytest = data_cl.iloc[26729:]\n\n### Use LabelEncoder to encode target labels to numeric\ntarget.value_counts()\nle = LabelEncoder()\nle.fit([\"Adoption\",\"Died\",\"Euthanasia\",\"Return_to_owner\",\"Transfer\"])\nY = pd.Series(data = le.transform(target), name = 'target')\n\n'''\n# Variance Threshold\nthreshold = 0.9\nvt = VarianceThreshold().fit(X)\nfeat_var_threshold = data_cl.columns[vt.variances_ > threshold * (1-threshold)]\nfeat_var_threshold\n\n# RandomForest\nrf = RandomForestClassifier().fit(X, Y)\nfeature_imp = pd.DataFrame(rf.feature_importances_, index = X.columns, columns=[\"importance\"])\nfeat_imp_20 = feature_imp.sort_values(\"importance\", ascending = False).head(20).index\nfeat_imp_20\n\n\n# Recursive Feature Elimination\nrfe = RFE(LogisticRegression(), 20).fit(X, Y)\nfeature_rfe_scoring = pd.DataFrame({\n        'feature' : X.columns,\n        'score' : rfe.ranking_\n    })\n\nfeat_rfe_20 = feature_rfe_scoring[feature_rfe_scoring['score'] == 1]['feature'].values\nfeat_rfe_20\n\n\n# Final feature selection\nfeatures = np.hstack([feat_var_threshold, feat_imp_20])\nfeatures = np.unique(features)\n'''"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Evaluation\nseed = 7\nprocessors=1\nnum_folds=3\nnum_instances=len(X)\nscoring='log_loss'\n\nkfold = KFold(n=num_instances, n_folds=num_folds, random_state=seed)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Prepare some basic models\nmodels = []\n#models.append(('LR', LogisticRegression()))\n#models.append(('LDA', LinearDiscriminantAnalysis()))\n\n#models.append(('CART', DecisionTreeClassifier()))\n#models.append(('NB', GaussianNB()))\n#models.append(('K-NN', KNeighborsClassifier(n_neighbors=5)))\n#models.append(('SVC', SVC(probability=True)))\n\n# Evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring, n_jobs=processors)\n    results.append(cv_results)\n    names.append(name)\n    print(\"{0}: ({1:.3f}) +/- ({2:.3f})\".format(name, cv_results.mean(), cv_results.std()))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"'''\ncategorial_cols = ['AnimalType', 'SexuponOutcome']\nfor cc in categorial_cols:\n    dummies = pd.get_dummies(data_cl[cc])\n    dummies = dummies.add_prefix(\"{}#\".format(cc))\n    data_cl.drop(cc, axis=1, inplace=True)\n    data\n'''\n\n'''\n### get dummies binary features\ndummies = pd.get_dummies(data['AnimalType'])\ndummies = dummies.add_prefix(\"{}#\".format('AnimalType'))\ndummies2 = pd.get_dummies(data['SexuponOutcome'])\ndummies2 = dummies2.add_prefix(\"{}#\".format('SexuponOutcome'))\ndummies = pd.concat([dummies, dummies2], axis = 1)\n\ndummies.shape\n'''"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Split to train and test from data\n#mytrain = dummies.iloc[:26729]\n#mytest = dummies.iloc[26729:]\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### Use LabelEncoder to encode target labels to numeric\n#target.value_counts()\n#le = LabelEncoder()\n#le.fit([\"Adoption\",\"Died\",\"Euthanasia\",\"Return_to_owner\",\"Transfer\"])\n#mytarget = pd.Series(data = le.transform(target), name = 'target')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### LR not suitable? maybe, i am newbee-.-\n#lr = LogisticRegression(solver = \"lbfgs\", multi_class = \"multinomial\")\n#lr = LogisticRegression()\n#lr.fit(X, Y)\n#result = lr.predict_proba(mytest)\n\n\n### GBRT\ngbrt = GradientBoostingClassifier(n_estimators=50, learning_rate=0.05, max_depth=5).fit(X, Y)\n#result = gbrt.predict_proba(mytest)\n### DecisionTreeClassifier first \n#dt = DecisionTreeClassifier()\n#dt.fit(mytrain,mytarget)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"result = gbrt.predict_proba(mytest)\nresult"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"submission = pd.DataFrame()\nsubmission[\"ID\"] = test.index\nsubmission[\"Adoption\"] = result[:, 0]\nsubmission[\"Died\"] = result[:, 1]\nsubmission[\"Euthanasia\"] = result[:, 2]\nsubmission[\"Return_to_owner\"] = result[:, 3]\nsubmission[\"Transfer\"] = result[:, 4]\n\nsubmission.to_csv(\"sub.csv\", index = False)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#print(check_output([\"tail\", \"sub.csv\"]).decode(\"utf8\"))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}