{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Stan and multinomial logistic regression\n\nI wanted to learn [Stan](http://mc-stan.org/) for this competition, so I thought I'd share my code in case someone else was interested in tinkering with probabilistic programming. I'll post three sections: my Stan model, the Python code that wraps it, and a utility file that makes working with Stan a bit less painful. Judging by my ranking, this isn't a very good model, but hopefully someone finds it interesting.\n"},{"cell_type":"markdown","metadata":{},"source":"# The Stan code\n\nI got this from the [Stan reference (PDF)](https://github.com/stan-dev/stan/releases/download/v2.9.0/stan-reference-2.9.0.pdf), and renamed the variables.\n\n    data {\n      int class_count; \n      int instance_count; \n      int feature_count; \n      int labels[instance_count]; \n      vector[feature_count] train_data[instance_count]; \n    }\n\n    parameters {\n      matrix[class_count, feature_count] beta; \n    }\n\n    model {\n      for (c in 1:class_count)\n        beta[c] ~ normal(0,5);\n      for (i in 1:instance_count)\n        labels[i] ~ categorical_logit(beta * train_data[i]);\n    }"},{"cell_type":"markdown","metadata":{},"source":"#The Python file"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pystan\nimport pickle\nimport os.path, time\nimport numpy as np\nimport pandas as pd\nfrom stan_utils import *\n\nage_transforms = {'1 year': 12, '2 years': 24, '3 weeks': .75, '1 month': 1, '5 months': 5, '4 years': 48, '3 months': 3, '2 weeks': .5, '2 months': 2, '10 months': 10, '6 months': 6, '5 years': 60, '7 years': 84, '3 years': 36, '4 months': 4, '12 years': 48, '9 years': 9 * 12, '6 years': 72, '1 weeks': .25, '11 years': 11*12, '4 weeks': 1, '7 months': 7*12, '8 years': 8*12, '11 months': 11, '4 days': .12, '9 months': 9, '8 months': 8, '15 years': 15*12, '10 years': 10*12, '1 week': .25, '0 years': 0, '14 years': 14*12, '3 days': .12, '6 days': .20, '5 days': .18, '5 weeks': 1.25, '2 days': .04, '16 years': 16*12, '1 day': .02, '13 years': 13*12, '17 years': 17*12, '18 years': 18*12, '19 years': 19*12, '20 years': 20*12, '22 years': 22*12 }\n\nconversion_maps = {}\n\ndef make_conversion_maps(train, test):\n    for column in train.columns:\n        if column == 'id' or column == 'datetime':\n            continue\n\n        values = train[column].unique()\n\n        if column in test.columns:\n            try:\n                values = np.hstack((test[column].unique(), values))\n            except ValueError as e:\n                print('e', e)\n                pass\n\n        indices = range(len(values))\n        conversion_maps[column] = dict(zip(values, indices))\n\n    return conversion_maps\n\ndef append_percentage_dead(df):\n    percentages = []\n\n    i = 0\n    total = df.shape[0]\n    for index, row in df.iterrows():\n        i += 1\n        if i % 1500 == 0:\n            print('percent dead: ', i/total)\n\n        animal_type = row['animal_type']\n        age = row['age_at_outcome']\n\n        if animal_type == 'Cat':\n            percentages.append(float(age) / (180.0))\n        else:\n            percentages.append(float(age) / (138.0))\n\n    df['percent_dead'] = percentages\n\n    return df\n\ndef numericize_column(df, column):\n    unique_values = df[column].unique()\n    indices = range(len(unique_values))\n\n    conversion_map = conversion_maps[column]\n\n    return df.applymap(lambda x: 1+int(conversion_map[x]) if x in conversion_map else x)\n\ndef prep_all_data(df):\n    df = df.applymap(lambda x: x if (x not in age_transforms) else age_transforms[x]); print('map applied.')\n    df = append_percentage_dead(df).drop(['name'], axis=1); print('percent dead done.')\n    try:\n        df = numericize_column(df, 'outcome')\n    except KeyError:\n        pass\n\n    df = df.fillna(0)\n    df = numericize_column(df, 'animal_type'); print('animal_type done.')\n    df = numericize_column(df, 'sex_at_outcome')\n    df = numericize_column(df, 'breed')\n    df = numericize_column(df, 'color')\n    df = df.fillna(0)\n    return df\n\ndef fit_data(all_data, features):\n    train_data = all_data[:train_size]\n    train_labels = train_data['outcome']\n\n    stan_model = get_model()\n\n    data = {\n        'class_count': len(np.unique(all_data['outcome'])),\n        'instance_count': train_size,\n        'feature_count': len(features),\n        'labels': train_labels,\n        'train_data': train_data[features].as_matrix()\n    }\n\n    fit = stan_model.sampling(\n        data=data,\n        iter=100,\n        chains=4\n    )\n\n    beta = np.mean(fit.extract()['beta'], axis=0)\n\n    return beta\n\ndef print_validation_accuracy(data, beta, features):\n    successes = []\n\n    i = 0\n    total = data.shape[0]\n    for index, instance in data.iterrows():\n        i += 1\n        if i % 1500 == 0:\n            print('validation accuracy: ', i/total)\n\n        label = instance['outcome']\n        scores = beta.dot(instance[features])\n        prediction = np.argmax(scores) + 1\n        successes.append(1 if prediction == label else 0)\n\n    print('Validation accuracy:', np.mean(successes))\n\ndef make_test_predictions(features):\n    test_data = prep_all_data(pd.read_csv('test.csv'))[features]\n\n    predictions = []\n\n    i = 0\n    total = test_data.shape[0]\n    for index, instance in test_data.iterrows():\n        i += 1\n        if i % 1500 == 0:\n            print('test_predictions', i/total)\n\n        try:\n            scores = beta.dot(instance[features])\n            prediction = np.argmax(scores) + 1\n            predictions.append(prediction)\n        except TypeError as e:\n            print('instance, features', instance, features)\n            predictions.append(1)\n            print('e', e)\n\n    predictions = pd.DataFrame(predictions)\n    numbers_to_labels = {value:key for key, value in conversion_maps['outcome'].items()}\n    predictions = predictions.applymap(lambda x: numbers_to_labels[x-1])\n\n    return predictions\n\ndef write_to_file(predictions):\n    # Write to file\n    output = pd.read_csv('sample_submission.csv', ',')\n    output['Adoption'] = 0\n\n    for index, row in output.iterrows():\n        label = predictions.iloc[[index]]\n        output.set_value(index, label, 1)\n\n    output = output.set_index('ID')\n\n    output.to_csv('actual_submission.csv')\n\ntrain_size = 200\n\noriginal_data = pd.read_csv('train.csv', ','); print('csv read.')\n\nprint(len(original_data[original_data['outcome'] == 'Adoption']) / len(original_data))\nconversion_maps = make_conversion_maps(original_data, pd.read_csv('test.csv'))\nall_data = prep_all_data(original_data)\n\nfeatures = ['percent_dead', 'animal_type', 'sex_at_outcome']\n\nbeta = fit_data(all_data, features)\n\nprint_validation_accuracy(all_data[train_size:train_size + 10000], beta, features)\n\npredictions = make_test_predictions(features)\n\nwrite_to_file(predictions)"},{"cell_type":"markdown","metadata":{},"source":"#`stan_utils.py`\nThis file caches your Stan model, and only recompiles when it has been changed."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import os.path, time, pystan\nimport pickle\n\n\ndef compile_model():\n    with open('model.stan', 'r') as my_file:\n        model_code = my_file.read()\n\n    stan_model = pystan.StanModel(model_code=model_code)\n\n    print('Compilation finished, writing to pickle.')\n\n    with open('model.pkl', 'wb') as f:\n        pickle.dump(stan_model, f)\n\n    return stan_model\n\ndef get_model():\n    try:\n        model_edited = os.path.getmtime('model.stan')\n        pickle_edited = os.path.getmtime('model.pkl')\n\n        if model_edited > pickle_edited:\n            print('Model has been changed, recompiling.')\n            return compile_model()\n\n        print('Trying pre-compiled model.')\n        return pickle.load(open('model.pkl', 'rb'))\n\n    except (FileNotFoundError, EOFError) as exception:\n        print('Pre-compiled model not found. Compiling model.')\n\n        return compile_model()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}