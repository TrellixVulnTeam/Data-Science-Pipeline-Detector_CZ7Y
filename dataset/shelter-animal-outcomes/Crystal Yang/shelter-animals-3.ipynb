{"cells":[{"metadata":{"_uuid":"5f923c9fb68d48f23788ab6acca0b18ce7cc8c26"},"cell_type":"markdown","source":"### 1 - Shelter Animals part 3\nIn [part 2](https://github.com/yscyang1/ExploringDataScience/blob/master/6-ShelterAnimals2.ipynb) of the my shelter animal competition analysis, we saw that I have probably maxed out the value of random forests for the minimal amount of pre-processing I did.  That isn't to say that random forests are now useless for this data set, but instead, it is time to start digging deeper into the data itself.  \n\nFirst, lets import the usual libraries and read in the training set from the feather file."},{"metadata":{"trusted":true,"_uuid":"cad4e003eb7dc2aadce0723a8bc9d5da8c778426"},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4feca72b8a527e8cc65659a7757992ea95fbc1f6"},"cell_type":"code","source":"train_df = pd.read_feather(\"../input/shelter/train_df\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec145b38f86092d14cba455e5e72d2e47832b84b"},"cell_type":"markdown","source":"### 2 - Finding the Most Important Features\nScikit-Learn's random forests have a handy feature that tells you the importance of each feature, which is crucial to data analysis and undersatnding how your random forest (or any  model) is making predictions.  \n\nTo find out which features were most important, first lets use a subset of the training data to speed things up."},{"metadata":{"trusted":true,"_uuid":"d480f0e84d1447455b8737ed63e9a1cb1a98c426"},"cell_type":"code","source":"def get_subset(df, train_percent=.6, validate_percent=.2, copy = True, seed=None):\n    if copy:\n        df_copy = df.copy()\n    perm = np.random.RandomState(seed).permutation(df_copy.index)\n    length = len(df_copy.index)\n    train_end = int(train_percent * length)\n    validate_end = int(validate_percent * length) + train_end\n    train = df_copy.iloc[perm[:train_end]]\n    validate = df_copy.iloc[perm[train_end:validate_end]]\n    test = df_copy.iloc[perm[validate_end:]]\n    \n    return train, validate, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3bd13f1574fc5de9665226c7d42a032fd2558fb"},"cell_type":"code","source":"train_speed, val_speed, test_speed = get_subset(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97ef29ca80f6aa13d24a6e3b14620523d983dce9"},"cell_type":"code","source":"X_train_speed = train_speed.drop(['Outcome1', 'Outcome2'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfe37a7a0b2bc1dcbd29009b39fc1429f1557bbb"},"cell_type":"code","source":"y_train_speed = train_speed['Outcome1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6619bcdb208bf8adccb84a0847380400d5f1faac"},"cell_type":"code","source":"X_val_speed = val_speed.drop(['Outcome1', 'Outcome2'], axis = 1)\ny_val_speed = val_speed['Outcome1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"775c20345373d520a409e3542026c139d2b6cb3b"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf57f494272b673acf36ff5c1f6840ae58a3c890"},"cell_type":"code","source":"def print_score(model, X_t, y_t, X_v, y_v, oob = False):\n    print('Training Score: {}'.format(model.score(X_t, y_t)))\n    print('Validation Score: {}'.format(model.score(X_v, y_v)))\n    if oob:\n        if hasattr(model, 'oob_score_'):\n            print(\"OOB Score:{}\".format(model.oob_score_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c6a3a8d6a622534e9ee2d276933cac3eb04df35"},"cell_type":"markdown","source":"Next, create a random forest.  I've chosen to use the hyperparameters that yielded the best predictions from my last post.  "},{"metadata":{"trusted":true,"_uuid":"ef268b25f179c6210ca339f527f4aa30ba820b85"},"cell_type":"code","source":"rf_speed = RandomForestClassifier(n_estimators=60, min_samples_leaf=7, max_features=0.3, min_samples_split= 20, bootstrap=False, n_jobs=-1)\nrf_speed.fit(X_train_speed, y_train_speed)\nprint_score(rf_speed, X_train_speed, y_train_speed, X_val_speed, y_val_speed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15e1d2de19087348fc13f61b3c2bf33f50020d19"},"cell_type":"markdown","source":"Finally, we can use the random forest's feature importances function to reveal the top features to pay attention to.  I've written a function to display feature importance in a dataframe in descending order."},{"metadata":{"trusted":true,"_uuid":"1bd6aa3d8f754849c73f83faf5fab568ae22c17d"},"cell_type":"code","source":"def get_feat_imp(model, df):\n    tmp = pd.DataFrame({'Feature':  np.array(df.columns), 'Importance': np.array(model.feature_importances_)})\n    return tmp.sort_values(by = ['Importance'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28021180e1c20bb61f11ae4bc27212cef2b6ce54"},"cell_type":"code","source":"if_df = get_feat_imp(rf_speed, X_train_speed)\nif_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3007e1d6fe16f962091421a5388f1a9a60a2bbfb"},"cell_type":"markdown","source":"The importance starts off at ~0.25, but very quickly drops off.  A bar graph emphasizes this point."},{"metadata":{"trusted":true,"_uuid":"aea0c11fbd4adf17ac83f3ad0bb91b3fdad4fa1b"},"cell_type":"code","source":"if_df.plot('Feature', 'Importance', kind = 'barh',legend=False, figsize=(10,6))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02b44a0afd6cf9d384c60561c928cb8e69e165d6"},"cell_type":"markdown","source":"Based on this bar graph, if I remove everything with importance > 0.01 (basically everything of lower importance than Datemonth), then accuracy and feature importance of the random forest model shouldn't change."},{"metadata":{"trusted":true,"_uuid":"405a190bf7052893f397b146a3b703b011547010"},"cell_type":"code","source":"train_if, val_if, _ = get_subset(train_df, seed = 55)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf3049b9c76569263aa8b8cb8e95be66e6052ee4"},"cell_type":"code","source":"X_train_if = train_if[if_df[if_df['Importance']>0.01]['Feature'].values]\nX_val_if = val_if[if_df[if_df['Importance']>0.01]['Feature'].values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30151bebd310ce405f7bb9244418723c439aa7d2"},"cell_type":"code","source":"y_train_if = train_if['Outcome1']\ny_val_if = val_if['Outcome1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f84e28bed966e3b87a2d9dd8e8b56c380269258e"},"cell_type":"code","source":"rf_if = RandomForestClassifier(n_estimators=60, min_samples_leaf=7, max_features=0.3, min_samples_split= 20, bootstrap=False, n_jobs=-1)\nrf_if.fit(X_train_if, y_train_if)\nprint_score(rf_if, X_train_if, y_train_if, X_val_if, y_val_if)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba484fa140c96bac1452cb614b4871194f736b7e"},"cell_type":"code","source":"rf_speed_fi = get_feat_imp(rf_if, X_train_if)\nprint(rf_speed_fi.head())\nrf_speed_fi.plot('Feature', 'Importance', kind = 'barh',legend=False, figsize=(10,6))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a1f7f3403c1434d0840d9ba65db3c791c71ebdc"},"cell_type":"markdown","source":"Indeed, the training and validation accuracies as well as the bar plot don't have significant changes.  \n\nThe values spit out from the feature importance function give us relative importance to other features, but what does each feature mean for the accuracy of our model?  One way to test this is to shuffle the values of a feature and then running it through the same random forest model.  I've written a function, shuffle_col, that takes in a dataframe and the column name to be shuffled, and spits out a new dataframe with the shuffled column.  The original dataframe will remain the same."},{"metadata":{"trusted":true,"_uuid":"6cd0b0276a462ebe6a2f842af96a2e05f1884575"},"cell_type":"code","source":"from sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c24298381521693aea2364ea49cd804c8918b60e"},"cell_type":"code","source":"def shuffle_col(df, col_name):\n    df_copy = df.copy()\n    # Reset index of copy because index from get_subset wasn't reset, causes nan problems later\n    df_copy.reset_index(inplace=True, drop=True)\n    df_new = df_copy.drop(col_name, axis=1)\n    shuf = shuffle(df[col_name])\n    shuf.reset_index(inplace=True, drop=True)\n    df_new[col_name] = shuf\n    return df_new","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33f9f1ac84b8535c15d80aa68157de5458bff827"},"cell_type":"markdown","source":"First, I'll try shuffling the sex column, since that was the most important feature.  I expect shuffling this column would have the biggest drop in accuracy, and going down the list (age, datehour, name, animal, etc) would have smaller and smaller impacts until it minimally affects the validation score."},{"metadata":{"trusted":true,"_uuid":"ade64692cb1cd2ac029c41fd45caeb135119ca85"},"cell_type":"code","source":"shuf_df = shuffle_col(X_train_if, 'Sex')\nrf_if.fit(shuf_df, y_train_if)\nprint_score(rf_if, shuf_df, y_train_if, X_val_if, y_val_if)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ae3357cddf3e86e1cb33154f84defdd2179c953"},"cell_type":"markdown","source":"Wow, that validation score dropped dramatically, by a good 30%.  Shuffling the age column also has a pretty big accuracy drop (~20%), and as predicted, shuffling of the subsequent columns have lower effect on the accuracy of the validation set."},{"metadata":{"trusted":true,"_uuid":"1c8ddba51349c04fdd8415faf34c97b9890a5767"},"cell_type":"code","source":"shuf_df = shuffle_col(X_train_if, 'Age')\nrf_if.fit(shuf_df, y_train_if)\nprint_score(rf_if, shuf_df, y_train_if, X_val_if, y_val_if)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a70edf7831efba8b5d514af25f3f5bb9ad9d0ef2"},"cell_type":"code","source":"shuf_df = shuffle_col(X_train_if, 'Datehour')\nrf_if.fit(shuf_df, y_train_if)\nprint_score(rf_if, shuf_df, y_train_if, X_val_if, y_val_if)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a1f15f4e45da1b67550197052fda3e040bd0096"},"cell_type":"code","source":"shuf_df = shuffle_col(X_train_if, 'Name')\nrf_if.fit(shuf_df, y_train_if)\nprint_score(rf_if, shuf_df, y_train_if, X_val_if, y_val_if)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9033b65b905781eb2c7f1c42576e31d5957d36a6"},"cell_type":"code","source":"shuf_df = shuffle_col(X_train_if, 'Breed')\nrf_if.fit(shuf_df, y_train_if)\nprint_score(rf_if, shuf_df, y_train_if, X_val_if, y_val_if)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22fe71d9018c9fdcb34099a28148843b33777c34"},"cell_type":"markdown","source":"#### 2.1 - A Deeper Dive into Important Features\nWhat if there is a specific category in one of the features that is important, rather than the features as a whole?  For example, when I look at the top five most common names, almost 5000 of them are labeled as 5048 (you guessed it, its a null value).  And plotting the outcomes of the unnamed vs the top 3 most popular names show different outcome probabilities, where the unnamed are far more likely to be transferred whereas the named are more likely to be adopted or returned.  In this case, it is more likely that the better random forest split is if the name is equal to 5048 instead of greater or less than 5048.  "},{"metadata":{"trusted":true,"_uuid":"339396f7379539da6a16ce56113b3a34717157d6"},"cell_type":"code","source":"train_speed['Name'].value_counts(ascending = False)[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c2cf7bca0560f72efa7222bbb232c93e291c9c9"},"cell_type":"code","source":"fig, ((axis1, axis2), (axis3, axis4)) = plt.subplots(2,2,figsize=(10,7))\norder = ['Transfer', 'Adoption', 'Return_to_owner', 'Euthanasia', 'Died']\n\nsns.countplot(x = 'Name', hue = 'Outcome1', data = train_speed[train_speed['Name']==5048], hue_order= order, ax = axis1)\nsns.countplot(x = 'Name', hue = 'Outcome1', data = train_speed[train_speed['Name']==540], hue_order=order, ax = axis2)\nsns.countplot(x = 'Name', hue = 'Outcome1', data = train_speed[train_speed['Name']==4542], hue_order=order, ax = axis3)\nsns.countplot(x = 'Name', hue = 'Outcome1', data = train_speed[train_speed['Name']==1305], hue_order=order, ax = axis4)\n\naxis2.get_legend().remove()\naxis3.get_legend().remove()\naxis4.get_legend().remove()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87237238d247099d52b23383b83e53b47008d5cb"},"cell_type":"markdown","source":"Something Jeremy suggests is to one hot encode categorical data that has a small number of categories.  For example, sex has only 5 categories, but name has more than 4k names, so it wouldn't be practical to one hot encode this feature.  "},{"metadata":{"trusted":true,"_uuid":"0e922960d08b5662ed31cd79dcbe52f050eb34d8"},"cell_type":"code","source":"print('Number of categories in Sex: {}'.format(train_if['Sex'].nunique()))\nprint('Categories in Sex: {}'.format(train_if['Sex'].unique()))\nprint('Number of categories in Name: {}'.format(train_if['Name'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58a52801d0c7f293de4868053008280cf8a9c48e"},"cell_type":"markdown","source":"I've written a function called oneHotEncode, which will take the dataframe and the max number of categories you want to encode.  For example, the column Sex has categories 0, 1, 3, 4, 5.  If i set my max_cat to be 6, then the function will encode the Sex category and create new columns called Sex_0, Sex_1, Sex_3, etc.  But it will not do so for the column Name because it has more than 6 categories."},{"metadata":{"trusted":true,"_uuid":"034508f151b9d671cdd23192e0c095cc72837a73"},"cell_type":"code","source":"def oneHotEncode(df, max_cat):\n    for col in df.columns.values:\n        if df[col].nunique() < max_cat:\n            test = pd.get_dummies(df[col], prefix = col)\n            df = pd.concat([df, test], axis=1)\n        df.drop(col, axis = 1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c3da4abc9081c63c36ccff8faae96b22117214d"},"cell_type":"code","source":"tmp = oneHotEncode(train_if[['Name', 'Animal', 'Sex', 'Age', 'Breed', 'Color']], 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8a36d0ef63e5518b5d0144b2f9726ccf0dea645"},"cell_type":"code","source":"train_if2 = pd.concat([train_if, tmp], axis = 1)\ntrain_if2.drop(['Sex', 'Animal'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1a0ea1a5c0857a3c0b7f2f61c907e529119dc2f"},"cell_type":"code","source":"tmp = oneHotEncode(val_if[['Name', 'Animal', 'Sex', 'Age', 'Breed', 'Color']], 6)\nval_if2 = pd.concat([val_if, tmp], axis = 1)\nval_if2.drop(['Animal', 'Sex'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"644b71078357bfb43afdb5259a00e98eff19a36f"},"cell_type":"markdown","source":"Recreating my training and validation sets to find most important features.  "},{"metadata":{"trusted":true,"_uuid":"6fbdd735a9767c7edd86f58d47004805a1bf43bc"},"cell_type":"code","source":"X_train_if2 = train_if2.drop(['Outcome1', 'Outcome2'], axis = 1)\ny_train_if2 = train_if2['Outcome1']\nX_val_if2 = val_if2.drop(['Outcome1', 'Outcome2'], axis = 1)\ny_val_if2 = val_if2['Outcome1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"780af865f46acba7513fb653a695b48faeffd5a0"},"cell_type":"code","source":"rf_if2 = RandomForestClassifier(n_estimators=60, min_samples_leaf=7, max_features=0.3, min_samples_split= 20, bootstrap=False, n_jobs=-1)\nrf_if2.fit(X_train_if2, y_train_if2)\nprint_score(rf_if2, X_train_if2, y_train_if2, X_val_if2, y_val_if2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1bc66b91778ad65273c8474d0d0a63ba1270a7f"},"cell_type":"markdown","source":"We see that both training and validation score decreased by a little, so it seems one hot encoding didn't help.  \n\nAs for the top five most important features, age, datehour, and name are still in there, but two of the sex categories also reached the top five.  Also note that the numbers in the feature importance chart are also important.  Before one hot encoding, sex and age had an importance of 0.256 and 0.244 respectively.  After one hot encoding, in the top five, sex got split into categories and have importances of less than 0.1, while age has a slightly smaller importance of 0.233.  As it stands, there is really only one staggeringly important feature instead of two, potentially accounting for the decrease in training and validation set scores.\n\nI've also tried encoding for nameless animals, and while this encoding made it to the top five important features, it only had an importance of 0.087388, and the training and validation scores improved by about 0.005.  "},{"metadata":{"trusted":true,"_uuid":"86e76a7ff3d11408e1a17c2612a2b1c98647c849"},"cell_type":"code","source":"rf_speed_fi2 = get_feat_imp(rf_if2, X_train_if2)\nprint(rf_speed_fi2.head())\nrf_speed_fi2.plot('Feature', 'Importance', kind = 'barh',legend=False, figsize=(10,6))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a5b5e2e96a3d6b2e15b664416a12eb1fa95bfa1"},"cell_type":"markdown","source":"In the case that one hot encoding does increase the validation score, it is still important to check if the one hot encoding increases the score on the test dataset, since it doesn't always improve the model.  "},{"metadata":{"_uuid":"070392c4cd499fb0f131f9e3dd74094d401d3d92"},"cell_type":"markdown","source":"### 8 - Submitting to Kaggle\nAfter removing the unimportant features and using one hot encoding, I submitted to the Kaggle leaderboard again, and got a score of 0.77713, placing me at 550.  This is two places lower than my last attempt.  It was a good exercise to take a deep dive into feature importance, but unfortunately it didn't seem to help in this case, as I didn't see any telltale signs such as strong correlation between features, redundant variables, etc.  "}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}