{"cells":[{"cell_type":"markdown","metadata":{},"source":"In this script I tried to split both training and test dataset into cats and dogs. Separate classifiers are then trained for each cat/dog dataset. The two classifiers are used to predict the outcome for the test dataset. Finally all results are combined into a single DataFrame and saved as a .csv files.\n\nThe main finding is that the prediction model for cat dataset is really high (with GradientBoostingClassifier, the loss is about 0.5) while for the dog dataset, the loss is about 0.918. The combined (all test dataset) loss is about 0.74."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\n#import data\nshelter_train = pd.read_csv(\"../input/train.csv\")\nshelter_train_outcome = shelter_train[\"OutcomeType\"]\nshelter_test = pd.read_csv(\"../input/test.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Create separate dog and cat database\n#########################################################################################################\n\ndog_train = shelter_train[shelter_train[\"AnimalType\"]==\"Dog\"]\ndog_train = dog_train.reset_index()\ndog_train.drop(\"AnimalType\", axis=1, inplace=True)\ndog_train.drop(\"index\", axis=1, inplace=True)\ndog_train_outcome = dog_train[\"OutcomeType\"]\ndog_train.drop(\"OutcomeType\", axis=1, inplace=True)\ndog_test = shelter_test[shelter_test[\"AnimalType\"]==\"Dog\"]\ndog_test = dog_test.reset_index()\ndog_test.drop(\"AnimalType\", axis=1, inplace=True)\ndog_test.drop(\"index\", axis=1, inplace=True)\n\ncat_train = shelter_train[shelter_train[\"AnimalType\"]==\"Cat\"]\ncat_train = cat_train.reset_index()\ncat_train.drop(\"AnimalType\", axis=1, inplace=True)\ncat_train.drop(\"index\", axis=1, inplace=True)\ncat_train_outcome = cat_train[\"OutcomeType\"]\ncat_train.drop(\"OutcomeType\", axis=1, inplace=True)\ncat_test = shelter_test[shelter_test[\"AnimalType\"]==\"Cat\"]\ncat_test = cat_test.reset_index()\ncat_test.drop(\"AnimalType\", axis=1, inplace=True)\ncat_test.drop(\"index\", axis=1, inplace=True)\n\n#keep ID\ndog_test_ID = dog_test[\"ID\"].as_matrix()\ndog_test_ID = np.array([dog_test_ID])\ndog_test_ID = dog_test_ID.T\ndog_test.drop(\"ID\", axis=1, inplace=True)\ncat_test_ID = cat_test[\"ID\"].as_matrix()\ncat_test_ID = np.array([cat_test_ID])\ncat_test_ID = cat_test_ID.T\ncat_test.drop(\"ID\", axis=1, inplace=True)\n\n"},{"cell_type":"markdown","metadata":{},"source":"The hypothesis is that the OutcomeType distribution is different between cats and dogs, as seen below. This is the main reason why I try to build different classifiers for cats' and dogs' dataset."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Hypothesis Plotting\n#########################################################################################################\nplot = True\n\nif plot == True: \n\t#plot correlation between each feature and OutcomeType\n\taxis = {\n\t\t\t\"AgeuponOutcome\",\n\t\t\t#\"Breed\",\n\t\t\t#\"Color\",\n\t\t\t#\"SexuponOutcome\",\n\t\t\t}\n\tcount = 0\n\tfor ax in axis:\n\t\tx = dog_train[ax]\n\t\ty = dog_train_outcome\n\t\tplt.figure(count)\n\t\tplt.title(\"Dog\" + ax)\n\t\tsns.countplot(x=x, hue=y)\n\t\tcount = count + 1\n\n\tfor ax in axis:\n\t\tx = cat_train[ax]\n\t\ty = cat_train_outcome\n\t\tplt.figure(count)\n\t\tplt.title(\"Cat\" + ax)\n\t\tsns.countplot(x=x, hue=y)\n\t\tcount = count + 1\n\n\tx = shelter_train[\"AnimalType\"]\n\ty = shelter_train_outcome\n\tplt.figure(count)\n\tplt.title(\"AnimalType\")\n\tsns.countplot(x=x, hue=x)\n\n\t#plt.show()\n\n"},{"cell_type":"markdown","metadata":{},"source":"Create new features from the existing dimensions:    \n1. AgeuponOutcome = Age in days  \n2. Breed = Whether the animals are mixed-breed or not  \n3. Color = Simplified color  \n4. Year = Year of admission  \n5. Month = Month of admission  \n6. Day = Day of admission  \n7. Hour = Hour of admission  \n8. Minute = Minute of admission  \n9. Virginity = Unknown (0), Neutered (1), Intact (2)  \n10. Sex = Unknown(0), Male(1), Female(2)  \n11. has_name = Whether the animal has a name (1) or not (0)  \n12. hairgroup = Whether the animal has short hair (0), long hair (1), or others (2)  \n13. aggressiveness =  \nFrom most to less aggressive: Pitbull (1), Rottweiler (2), Husky-type (3), German Shepherd (4) , Alaskan Malamute (5), Doberman pinscher (6), chow chow (7), Great Danes (8), Boxer (9), Akita (10), others (11)\nallergic.  \nFrom most to less allergic-causing: Akita (1), Alaskan Malamute (2), American Eskimo (3), Corgi (4), Chow-chow (5), German Shepherd (6), Great Pyrenees (7), Labrador (8), Retriever (9), Husky (10), others (11)   \n14. weight =  \nWith weight below 100 lbs (1): Pitbull (55-65 lbs), Husky-type (66 lbs), Doberman pinscher (65-90lbs), Boxer (70 lbs), Akita (45 kg), chow chow (70 lbs).  \nWith weight above 100 lbs (2): Rottweiler (100-130 lbs), German Shepherd (100 lbs), Alaskan Malamute (100 lbs), Great Danes (200pounds).  \nUnknown weight (3)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n####Pre-Processing, mostly dropping and altering data\n#########################################################################################################\ndef pre_processing(shelter_train, shelter_test, animal_type):\n\t#########################################################\n\t#### Drop ID, OutcomeType, OutcomeSubType\n\t#########################################################\n\t#ID: Drop\n\tshelter_train.drop(\"AnimalID\", axis=1, inplace=True)\n\t# shelter_test.drop(\"ID\", axis=1, inplace=True) -> Keep this for tagging later\n\n\t#OutcomeSubType: Drop\n\tshelter_train.drop(\"OutcomeSubtype\", axis=1, inplace=True)\n\n\t#########################################################\n\t#### Fetch Year, Month, Day, Hour, Minute from DateTime\n\t#########################################################\n\ttime_train = pd.to_datetime(shelter_train[\"DateTime\"])\n\ttime_test = pd.to_datetime(shelter_test[\"DateTime\"])\n\n\tshelter_train[\"Year\"] = time_train.dt.year\n\tshelter_test[\"Year\"] = time_test.dt.year\n\tshelter_train[\"Month\"] = time_train.dt.month\n\tshelter_test[\"Month\"] = time_test.dt.month\n\tshelter_test[\"Day\"] = time_test.dt.day\n\tshelter_train[\"Day\"] = time_train.dt.day\n\tshelter_test[\"Hour\"] = time_test.dt.hour\n\tshelter_train[\"Hour\"] = time_train.dt.hour\n\tshelter_test[\"Minute\"] = time_test.dt.minute\n\tshelter_train[\"Minute\"] = time_train.dt.minute\n\n\t#drop DateTime\n\tshelter_train.drop(\"DateTime\", axis=1, inplace=True)\n\tshelter_test.drop(\"DateTime\", axis=1, inplace=True)\n\n\t#########################################################\n\t#### Convert SexuponOutcome to Virginity and Sex\n\t#########################################################\n\n\t# Virginity\n\t# fill in missing data with mode\n\tshelter_train[\"SexuponOutcome\"].fillna(\"Spayed Female\", inplace=True)\n\tshelter_test[\"SexuponOutcome\"].fillna(\"Spayed Female\", inplace=True)\n\n\tdef intact_group(sex):\n\t\ttry:\n\t\t\tintact_type = sex.split()\n\t\texcept:\n\t\t\treturn 0\n\t\tif intact_type[0] == \"Neutered\" or intact_type[0] ==  \"Spayed\":\t\t\n\t\t\treturn 1\n\t\telif intact_type[0] == \"Intact\":\n\t\t\treturn 2\n\t\telse:\n\t\t\treturn 0\n\n\tshelter_train[\"Virginity\"] = shelter_train[\"SexuponOutcome\"].apply(intact_group)\n\tshelter_test[\"Virginity\"] = shelter_test[\"SexuponOutcome\"].apply(intact_group)\n\n\t# Sex\n\tdef sex_group(sexs):\n\t\ttry:\n\t\t\tsex_type = sexs.split()\n\t\texcept:\n\t\t\treturn 0\n\t\t#categorize\n\t\tif sex_type[0] == \"Unknown\":\n\t\t\treturn 0\n\t\telif sex_type[1] == \"Male\":\n\t\t\treturn 1\n\t\telif sex_type[1] == \"Female\":\n\t\t\treturn 2\n\t\telse:\n\t\t\treturn 0\n\n\tshelter_train[\"Sex\"] = shelter_train[\"SexuponOutcome\"].apply(sex_group)\n\tshelter_test[\"Sex\"] = shelter_test[\"SexuponOutcome\"].apply(sex_group)\n\n\tshelter_train.drop(\"SexuponOutcome\", axis=1, inplace=True)\n\tshelter_test.drop(\"SexuponOutcome\", axis=1, inplace=True)\n\n\t#########################################################\n\t#### Convert Name to has_name\n\t#########################################################\n\tdef check_has_name(name):\n\t\tif type(name) is str:\n\t\t\treturn 1\n\t\telse: #if name is NaN\n\t\t\treturn 0\n\n\t#has_name: create new column for has_name\n\tshelter_train[\"has_name\"] = shelter_train[\"Name\"].apply(check_has_name)\n\tshelter_test[\"has_name\"] = shelter_test[\"Name\"].apply(check_has_name)\n\t#drop the name column\n\tshelter_train.drop(\"Name\", axis=1, inplace=True)\n\tshelter_test.drop(\"Name\", axis=1, inplace=True)\n\n\t#########################################################\n\t#### Convert Age to Age in days\n\t#########################################################\n\t#Age: fill missing data in Age, assume NaN = 1 year (modus value)\n\tshelter_train[\"AgeuponOutcome\"].fillna(\"1 month\", inplace=True)\n\tshelter_test[\"AgeuponOutcome\"].fillna(\"1 month\", inplace=True)\n\t#convert age to age group, author arbitrarily decides\n\tdef age_group(age):\n\t\ttry:\n\t\t\tage_list = age.split() #\"2 days\" -> [\"2\", \"days\"]\n\t\texcept:\n\t\t\treturn None\n\t\tages = int(age_list[0])\n\t\tif(age_list[1].find(\"s\")): #weeks->week, days->day\n\t\t\tage_list[1] = age_list[1].replace(\"s\",\"\")\n\t\tif age_list[1] == \"day\":\n\t\t\treturn ages\n\t\telif (age_list[1] == \"week\"):\n\t\t\treturn ages*7\n\t\telif (age_list[1] == \"month\"):\n\t\t\treturn ages*30\n\t\telif (age_list[1] == \"year\"):\n\t\t\treturn ages*365\n\n\t#replace AgeuponOutcome with Age group\n\tshelter_train[\"AgeuponOutcome\"] = shelter_train[\"AgeuponOutcome\"].apply(age_group)\n\tshelter_test[\"AgeuponOutcome\"] = shelter_test[\"AgeuponOutcome\"].apply(age_group)\n\t#########################################################\n\t#### Convert Breed to Hair, Aggressiveness, Weight, BreedType\n\t#########################################################\n\n\t#hair group (for cats)\n\tdef hair_group(breed):\n\t\tif breed.find(\"Shorthair\") != -1:\n\t\t\treturn 0\n\t\telif breed.find(\"Longhair\") != -1:\n\t\t\treturn 1\n\t\telse:\n\t\t\treturn 2\n\n\tshelter_train[\"Hairgroup\"] = shelter_train[\"Breed\"].apply(hair_group)\n\tshelter_test[\"Hairgroup\"] = shelter_test[\"Breed\"].apply(hair_group)\n\n\t#aggressiveness based on breed type. Most dangerous breeds:\n\t# Pitbull (55-65 lbs), Rottweiler (100-130 lbs), Husky-type (66 lbs), German\n\t# Shepherd (100 lbs) , Alaskan Malamute (100 lbs), Doberman pinscher (65-90lbs),\n\t# chow chow (70 lbs), Great Danes (200pounds), Boxer (70 lbs), Akita (45 kg)\n\tdef aggressive(breed):\n\t\tif breed.find(\"Pit Bull\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Rottweiler\") != -1:\n\t\t\treturn 2#1\n\t\telif breed.find(\"Husky\") != -1:\n\t\t\treturn 3#1\n\t\telif breed.find(\"Shepherd\") != -1:\n\t\t\treturn 4#1\n\t\telif breed.find(\"Malamute\") != -1:\n\t\t\treturn 5#1\n\t\telif breed.find(\"Doberman\") != -1:\n\t\t\treturn 6#1\n\t\telif breed.find(\"Chow\") != -1:\n\t\t\treturn 7#1\n\t\telif breed.find(\"Dane\") != -1:\n\t\t\treturn 8#1\n\t\telif breed.find(\"Boxer\") != -1:\n\t\t\treturn 9#1\n\t\telif breed.find(\"Akita\") != -1:\n\t\t\treturn 10#1\n\t\telse:\n\t\t\treturn 11#2\n\n\tif (animal_type == \"Dog\"):\n\t\tshelter_train[\"Aggresiveness\"] = shelter_train[\"Breed\"].apply(aggressive)\n\t\tshelter_test[\"Aggresiveness\"] = shelter_test[\"Breed\"].apply(aggressive)\n\n\t#Most allergic breeds:\n\t#Akita, Alaskan Malamute, American Eskimo, Corgi, Chow-chow, German\n\t#Shepherd, Great Pyrenees, Labrador, Retriever, Husky\n\tdef allergic(breed):\n\t\tif breed.find(\"Akita\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Malamute\") != -1:\n\t\t\treturn 2#1\n\t\telif breed.find(\"Eskimo\") != -1:\n\t\t\treturn 3#1\n\t\telif breed.find(\"Corgi\") != -1:\n\t\t\treturn 4#1\n\t\telif breed.find(\"Chow\") != -1:\n\t\t\treturn 5#1\n\t\telif breed.find(\"Shepherd\") != -1:\n\t\t\treturn 6#1\n\t\telif breed.find(\"Pyrenees\") != -1:\n\t\t\treturn 7#1\n\t\telif breed.find(\"Labrador\") != -1:\n\t\t\treturn 8#1\n\t\telif breed.find(\"Retriever\") != -1:\n\t\t\treturn 9#1\n\t\telif breed.find(\"Husky\") != -1:\n\t\t\treturn 10#1\n\t\telse:\n\t\t\treturn 11#2\n\n\tif (animal_type == \"Dog\"):\n\t\tshelter_train[\"Allergic\"] = shelter_train[\"Breed\"].apply(allergic)\n\t\tshelter_test[\"Allergic\"] = shelter_test[\"Breed\"].apply(allergic)\n\n\t#weight based on breed type. Most dangerous breeds:\n\t# Below 100 lbs: Pitbull (55-65 lbs), Husky-type (66 lbs), Doberman pinscher (65-90lbs), Boxer (70 lbs), Akita (45 kg), chow chow (70 lbs)\n\t# Above 100 lbs: Rottweiler (100-130 lbs), German Shepherd (100 lbs), Alaskan Malamute (100 lbs), Great Danes (200pounds), \n\tdef weight(breed):\n\t\tif breed.find(\"Pit Bull\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Husky\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Doberman\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Boxer\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Akita\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Chow\") != -1:\n\t\t\treturn 1\n\t\telif breed.find(\"Rottweiler\") != -1:\n\t\t\treturn 2\n\t\telif breed.find(\"Shepherd\") != -1:\n\t\t\treturn 2\n\t\telif breed.find(\"Malamute\") != -1:\n\t\t\treturn 2\n\t\telif breed.find(\"Dane\") != -1:\n\t\t\treturn 2\n\t\telse:\n\t\t\treturn 3\n\n\tif (animal_type == \"Dog\"):\n\t\tshelter_train[\"Weight\"] = shelter_train[\"Breed\"].apply(weight)\n\t\tshelter_test[\"Weight\"] = shelter_test[\"Breed\"].apply(weight)\n\n\t# #fetch breed type\n\t# def breed_group(breed_input):\n\t# \tbreed = str(breed_input)\n\t# \tif (' ' in breed) == False:\n\t# \t\treturn breed #only 1 word\n\t# \tbreed_list = breed.split()\n\t# \ttry:\n\t# \t\treturn breed_list[2] #fetch last word, for 1 words breed\n\t# \texcept:\n\t# \t\treturn breed_list[1] #fetch last word, for 2 words breed\n\t# \treturn breed\n\n\tdef breed_group(breed_input):\n\t\tbreed = str(breed_input)\n\t\tif (' ' in breed) == False:\n\t\t\tbr =  breed #only 1 word\n\t\telse:\n\t\t\tbreed_list = breed.split()\n\t\t\ttry:\n\t\t\t\tbr = breed_list[2] #fetch last word, for 1 words breed\n\t\t\texcept:\n\t\t\t\tbr = breed_list[1] #fetch last word, for 2 words breed\n\t\tif (br == \"Mix\"):\n\t\t\treturn 0\n\t\telse:\n\t\t\treturn 1\n\t\treturn 1\n\n\tshelter_train[\"Breed\"] = shelter_train[\"Breed\"].apply(breed_group)\n\tshelter_test[\"Breed\"] = shelter_test[\"Breed\"].apply(breed_group)\n\t# ### convert each unique label to unique integers\n\t# intval, label = pd.factorize(shelter_train[\"Breed\"], sort=True)\n\t# shelter_train[\"Breed\"] = pd.DataFrame(intval)\n\t# del intval, label\n\t# intval, label = pd.factorize(shelter_test[\"Breed\"], sort=True)\n\t# shelter_test[\"Breed\"] = pd.DataFrame(intval)\n\t# del intval, label\n\n\t#########################################################\n\t#### Fetch First word of Color\n\t#########################################################\n\n\t# Color Intact\n\tdef color_group(color):\n\t\ttry:\n\t\t\tcolor_type = color.split()\n\t\texcept:\n\t\t\treturn \"unknown\"\n\t\treturn str(color_type[0])\n\n\tshelter_train[\"Color\"] = shelter_train[\"Color\"].apply(color_group)\n\tshelter_test[\"Color\"] = shelter_test[\"Color\"].apply(color_group)\n\t#### convert each unique label to unique integers\n\tintval, label = pd.factorize(shelter_train[\"Color\"], sort=True)\n\tshelter_train[\"Color\"] = pd.DataFrame(intval)\n\tdel intval, label\n\tintval, label = pd.factorize(shelter_test[\"Color\"], sort=True)\n\tshelter_test[\"Color\"] = pd.DataFrame(intval)\n\tdel intval, label\n\t#Color: Drop\n\t# shelter_train.drop(\"Color\", axis=1, inplace=True)\n\t# shelter_test.drop(\"Color\", axis=1, inplace=True)\n\n\tprint(shelter_train.head())\n\treturn shelter_train, shelter_test\n\ndog_train, dog_test = pre_processing(dog_train, dog_test, \"Dog\")\ncat_train, cat_test = pre_processing(cat_train, cat_test, \"Cat\")\n"},{"cell_type":"markdown","metadata":{},"source":"Plot processed data, optional."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Plot Pre-Processed Data\n#########################################################################################################\nplot = True\n\nif plot == True: \n\t#plot correlation between each feature and OutcomeType\n\taxis = {\n\t\t\t\"AgeuponOutcome\",\n\t\t\t\"Hour\",\n\t\t\t#\"Minute\",\n\t\t\t\"Virginity\",\n\t\t\t}\n\tcount = 0\n\tfor ax in axis:\n\t\tx = dog_train[ax]\n\t\ty = dog_train_outcome\n\t\ty = y.reset_index()\n\t\ty = y[\"OutcomeType\"]\n\t\tplt.figure(count)\n\t\tplt.title(\"Dog\" + ax)\n\t\tsns.countplot(x=x, hue=y)\n\t\tcount = count + 1\n\n\tfor ax in axis:\n\t\tx = cat_train[ax]\n\t\ty = cat_train_outcome\n\t\ty = y.reset_index()\n\t\ty = y[\"OutcomeType\"]\n\t\tplt.figure(count)\n\t\tplt.title(\"Cat\" + ax)\n\t\tsns.countplot(x=x, hue=y)\n\t\tcount = count + 1\n\n\tplt.show()\n\n"},{"cell_type":"markdown","metadata":{},"source":"I tried to use PCA, but the results were not better. Moreover it's hard to interpret the result with PCA, therefore I commented it out. I left it here for reference."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### PCA\n#########################################################################################################\n# from sklearn.decomposition import PCA\n# n = 12\n# pca_train = PCA(n_components=n)\n# pca_test = PCA(n_components=n)\n# pca_train.fit(dog_train)\n# pca_test.fit(dog_test)\n\n# dog_train = pd.DataFrame(pca_train.transform(dog_train))\n# dog_test = pd.DataFrame(pca_test.transform(dog_test))\n\n"},{"cell_type":"markdown","metadata":{},"source":"Split the dataset with cross-validation."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Split Cross-Validation Dataset\n#########################################################################################################\nfrom sklearn.cross_validation import train_test_split\ndog_X_train, dog_X_val, dog_y_train, dog_y_val = train_test_split(dog_train, dog_train_outcome, test_size=0.3)\ncat_X_train, cat_X_val, cat_y_train, cat_y_val = train_test_split(cat_train, cat_train_outcome, test_size=0.3)\n\n"},{"cell_type":"markdown","metadata":{},"source":"Comment out the classifiers to compare their performance. I found that Gradient Boosting Classifier performs the best."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Prediction Model\n#########################################################################################################\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, log_loss\n\nclassifiers = [\n    # KNeighborsClassifier(100),\n    # SVC(max_iter=1000, probability=True, kernel='rbf', degree=20),\n    # SVC(gamma=2, C=1),\n    # DecisionTreeClassifier(max_depth=3),\n    # RandomForestClassifier(max_depth=5, n_estimators=500, max_features=1),\n    # AdaBoostClassifier(),\n    # GaussianNB(),\n    # QuadraticDiscriminantAnalysis(),\n    # LogisticRegression(),\n    GradientBoostingClassifier()\n    # GradientBoostingClassifier(learning_rate=0.05, min_samples_split=50, max_depth=8)\n    # GradientBoostingClassifier(learning_rate=0.005, n_estimators=3000, min_samples_split=600, min_samples_leaf=30, max_depth=12, subsample=0.85)\n    ]\n\nprint(\"DOG\")\nfor classifier in classifiers:\n\tdog_log = classifier \n\tdog_log.fit(dog_X_train, dog_y_train)\n\n\tshow_validation = True\n\n\tif (show_validation == True):\n\t\tdog_y_probs = dog_log.predict_proba(dog_X_val)\n\t\tdog_y_pred = dog_log.predict(dog_X_val)\n\t\tprint(type(classifier))\n\t\tprint(\"accuracy_score:\", accuracy_score(dog_y_val, dog_y_pred))\n\t\tprint(\"log_loss:\", log_loss(dog_y_val, dog_y_probs))\n\telif (show_validation == False):\n\t\tdog_y_probs = dog_log.predict_proba(dog_X_train)\n\t\tdog_y_pred = dog_log.predict(dog_X_train)\n\t\tprint(type(classifier))\n\t\tprint(\"accuracy_score:\", accuracy_score(dog_y_train, dog_y_pred))\n\t\tprint(\"log_loss:\", log_loss(dog_y_train, dog_y_probs))\n\nprint(\"CAT\")\nfor classifier in classifiers:\n\tcat_log = classifier\n\tcat_log.fit(cat_X_train, cat_y_train)\n\n\tshow_validation = True\n\t# log knows how many classes are there idn y_train\n\tif (show_validation == True):\n\t\tcat_y_probs = cat_log.predict_proba(cat_X_val)\n\t\tcat_y_pred = cat_log.predict(cat_X_val)\n\t\tprint(type(classifier))\n\t\tprint(\"accuracy_score:\", accuracy_score(cat_y_val, cat_y_pred))\n\t\tprint(\"log_loss:\", log_loss(cat_y_val, cat_y_probs))\n\telif (show_validation == False):\n\t\tprint(type(classifier))\n\t\tprint(\"accuracy_score:\", accuracy_score(cat_y_train, cat_y_pred))\n\t\tprint(\"log_loss:\", log_loss(cat_y_train, cat_y_probs))\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Model Fitting for Dog\n#########################################################################################################\n#fit dog data\ndog_log.fit(dog_train, dog_train_outcome)\nprint(dog_log.classes_)\ndog_y_probs = dog_log.predict_proba(dog_test)\ndog_test_result = np.append(dog_test_ID, dog_y_probs, axis=1)\n\n#plot feature importance\n\nplt.figure(0)\nplt.title(\"Feature Importance\")\nprint(dog_log.feature_importances_)\nprint(dog_train.columns)\nimportance = dog_log.feature_importances_\nsns.barplot(y=dog_train.columns, x=importance)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Model Fitting for Cat\n#########################################################################################################\n\n#fit cat data\ncat_log.fit(cat_train, cat_train_outcome)\nprint(cat_log.classes_)\ncat_y_probs = cat_log.predict_proba(cat_test)\ncat_test_result = np.append(cat_test_ID, cat_y_probs, axis=1)\n\n#plot feature importance\nplt.figure(1)\nplt.title(\"Feature Importance\")\nprint(cat_log.feature_importances_)\nprint(cat_train.columns)\nimportance = cat_log.feature_importances_\nsns.barplot(y=cat_train.columns, x=importance)\n\n#plt.show()\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#########################################################################################################\n#### Combine All Prediction\n#########################################################################################################\ny_probs = np.append(dog_test_result, cat_test_result, axis=0)\ny_probs = y_probs[y_probs[:,0].argsort()]\ny_probs = y_probs[:,1:]\nprint(y_probs)\n\nresults = pd.read_csv(\"../input/sample_submission.csv\")\n\n#each result has their corresponding probabilistic value\nresults[\"Adoption\"] = y_probs[:,0]\nresults[\"Died\"] = y_probs[:,1]\nresults[\"Euthanasia\"] = y_probs[:,2]\nresults[\"Return_to_owner\"] = y_probs[:,3]\nresults[\"Transfer\"] = y_probs[:,4]\n\nresults.to_csv(\"split_animal.csv\",index = False)\n\n\n"},{"cell_type":"markdown","metadata":{},"source":"Reference (Thanks for the inspirations!):  \n1. https://www.kaggle.com/mrisdal/shelter-animal-outcomes/quick-dirty-randomforest   \n2. https://www.kaggle.com/uchayder/shelter-animal-outcomes/take-a-look-at-the-data  \n3. https://www.kaggle.com/xenocide/shelter-animal-outcomes/shelter-animal-random-forest/notebook  \n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}