{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\n\nimport sklearn as sk\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import cross_validate\n\nimport xgboost\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load and process test data\npd.set_option('display.max_colwidth', -1)\npath = '/kaggle/input/data-science-bowl-2019/'\ntest = pd.read_csv(path+'test.csv',parse_dates=[\"timestamp\"],dtype = {'event_count':np.int16,'event_code':np.int16})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def AssessmentScore(df):\n    s1 = df[(df.title=='Bird Measurer (Assessment)') & (df.event_code==4110)].event_data.apply(lambda x: x.find('\"correct\":true')>-1)\n    s2 = df[(df.type=='Assessment') & (df.title!='Bird Measurer (Assessment)') & (df.event_code==4100)].event_data.apply(lambda x: x.find('\"correct\":true')>-1)\n    s1.name = 'correct'\n    s2.name = 'correct'\n    s1 = s1.append(s2).sort_index()\n    return df.join(s1)\n\ndef TimeDifference(df):\n    gb = df.loc[:,['installation_id','timestamp']].groupby('installation_id',as_index=False)\n    store = gb.diff()\n    store.index = df.index\n    store = store.rename(columns = {'timestamp':'dt'})\n    store.dt = store.dt-pd.to_datetime(0,utc=True)\n    store.dt = store.dt.dt.total_seconds()\n    # store.dt = store.dt.astype(np.float32)\n    return df.join(store)\n\ndef GameSessionStats(df):\n    gb = df.loc[:,['game_session','dt']].groupby('game_session')\n    store = gb.sum()\n    store.columns = ['game_session_time']\n    return df.reset_index().merge(store, how='left', on='game_session').set_index('index')\n\ndef InstallationIdStats(df):\n    subset = df.loc[:,['installation_id','game_session','title']]\n    titles = subset.title.unique()\n    subset = subset.drop_duplicates()\n    for title in titles:\n        subset[title] = (subset.title==title).apply(lambda x: np.uint8(x))\n    subset = subset.drop(columns = 'title')\n    \n    gb = subset.groupby(['installation_id'])\n    store = gb.cumsum().join(subset.installation_id)\n    store = store.groupby('installation_id').shift(periods=1,fill_value=0)\n    store = store.drop(columns='installation_id').join(subset.loc[:,['installation_id','game_session']])\n    return df.reset_index().merge(store, how='left', on=['installation_id','game_session']).set_index('index')\n\ndef ExtendTrainData(df):\n    # find the game_sessions where Assessments are taken\n    titles = df.title.unique()\n    col_list = ['installation_id','game_session','title','timestamp','dt']+list(titles)\n    test_out = df.loc[:,col_list].groupby('installation_id').last().reset_index()\n    \n    # convert title cumcounts into integer\n    for title in titles:\n        test_out[title] = test_out[title].apply(np.uint8)\n        \n    # calculate num_correct and num_incorrect\n    subset = df[(df.correct==True) | (df.correct==False)]\n    out = subset.loc[:,['installation_id','game_session']].drop_duplicates()\n    \n    gb = subset.loc[:,['game_session','installation_id','correct','event_id']].groupby(['game_session','installation_id','correct'])\n    store = gb.count().unstack().fillna(value=0)\n    # cleanup column names\n    store.columns = store.columns.to_flat_index()\n    new_cols=[]\n    for t in store.columns:\n        if True in t:\n            new_cols.append('num_correct')\n        else:\n            new_cols.append('num_incorrect')\n    store.columns = new_cols\n    store = store.reset_index()\n    # merge into out\n    out = out.merge(store.drop(columns='installation_id'), how='left',on='game_session')\n    \n    # calc accuracy and accuracy group\n    out['accuracy'] = out.num_correct/(out.num_correct+out.num_incorrect)\n    def CalcAccuracyGroup(x):\n        if x == 1:\n            return 3\n        elif x==0.5:\n            return 2\n        elif x==0:\n            return 0\n        else:\n            return 1\n    out['accuracy_group'] = out.accuracy.apply(CalcAccuracyGroup)\n    \n    # accuracy group statistics\n#    store = out.loc[:,['installation_id','accuracy']].groupby('installation_id').shift(1)\n    store = pd.DataFrame({'installation_id': out.installation_id,'accuracy': out.accuracy})\n    gb = store.groupby('installation_id')\n    out['acc_sum'] = gb.cumsum()\n    out['acc_min'] = gb.cummin()\n    out['acc_max'] = gb.cummax()\n    out['acc_cnt'] = gb.cumcount()+1\n    out['acc_avg'] = out['acc_sum']/out['acc_cnt']\n    \n#    store = out.loc[:,['installation_id','accuracy_group']].groupby('installation_id').shift(1)\n    store = pd.DataFrame({'installation_id': out.installation_id,'accuracy_group': out.accuracy_group})\n    gb = store.loc[:,['installation_id','accuracy_group']].groupby('installation_id')\n    out['acc_gr_sum'] = gb.cumsum()\n    out['acc_gr_min'] = gb.cummin()\n    out['acc_gr_max'] = gb.cummax()\n    out['acc_gr_cnt'] = gb.cumcount()+1\n    out['acc_gr_avg'] = out['acc_gr_sum']/out['acc_gr_cnt']\n\n    out['acc_min'] = out.acc_min.fillna(value=-1)\n    out['acc_max'] = out.acc_max.fillna(value=-1)\n    out['acc_avg'] = out.acc_avg.fillna(value=-1)\n    out['acc_gr_min'] = out.acc_gr_min.fillna(value=-1)\n    out['acc_gr_max'] = out.acc_gr_max.fillna(value=-1)\n    out['acc_gr_avg'] = out.acc_gr_avg.fillna(value=-1)\n    \n    out = out.drop(columns=['num_correct','num_incorrect','acc_sum','acc_cnt','acc_gr_sum','acc_gr_cnt'])\n    \n    out = out.groupby('installation_id').last()\n    out = out.drop(columns = ['game_session','accuracy','accuracy_group'])\n    \n    test_out = test_out.merge(out, how='left',on='installation_id')\n    test_out = test_out.fillna(value=-1)\n    \n    return test_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = AssessmentScore(test)\ntest = TimeDifference(test)\ntest = GameSessionStats(test)\ntest = InstallationIdStats(test)\ntest = ExtendTrainData(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype_dict={\n    'Welcome to Lost Lagoon!': np.uint8, \n    'Magma Peak - Level 1': np.uint8,\n    'Sandcastle Builder (Activity)': np.uint8, \n    'Slop Problem': np.uint8, \n    'Scrub-A-Dub': np.uint8,\n    'Tree Top City - Level 1': np.uint8, \n    'Ordering Spheres': np.uint8, \n    'All Star Sorting': np.uint8,\n    'Costume Box': np.uint8, \n    'Fireworks (Activity)': np.uint8, \n    '12 Monkeys': np.uint8,\n    'Tree Top City - Level 2': np.uint8, \n    'Flower Waterer (Activity)': np.uint8, \n    'Pirate\\'s Tale': np.uint8,\n    'Mushroom Sorter (Assessment)': np.uint8, \n    'Air Show': np.uint8, \n    'Treasure Map': np.uint8,\n    'Tree Top City - Level 3': np.uint8, \n    'Crystals Rule': np.uint8, \n    'Rulers': np.uint8,\n    'Bug Measurer (Activity)': np.uint8, \n    'Bird Measurer (Assessment)': np.uint8,\n    'Watering Hole (Activity)': np.uint8, \n    'Magma Peak - Level 2': np.uint8, \n    'Dino Drink': np.uint8,\n    'Bubble Bath': np.uint8, \n    'Bottle Filler (Activity)': np.uint8, \n    'Dino Dive': np.uint8,\n    'Crystal Caves - Level 1': np.uint8, \n    'Chow Time': np.uint8, \n    'Cauldron Filler (Assessment)': np.uint8,\n    'Balancing Act': np.uint8, \n    'Crystal Caves - Level 2': np.uint8, \n    'Crystal Caves - Level 3': np.uint8,\n    'Chicken Balancer (Activity)': np.uint8,\n    'Lifting Heavy Things': np.uint8,\n    'Pan Balance': np.uint8,\n    'Honey Cake': np.uint8,\n    'Happy Camel': np.uint8,\n    'Cart Balancer (Assessment)': np.uint8,\n    'Heavy, Heavier, Heaviest': np.uint8,\n    'Egg Dropper (Activity)': np.uint8,\n    'Chest Sorter (Assessment)': np.uint8,\n    'Leaf Leader': np.uint8,\n    'dt': np.float64,\n    'acc_min':np.float32, \n    'acc_max':np.float32, \n    'acc_avg':np.float32,\n    'acc_gr_min':np.float32, \n    'acc_gr_max':np.float32, \n    'acc_gr_avg':np.float32\n}\n\ntrain_dtype_dict = {\n    'accuracy': np.float32,\n    'accuracy_group':np.int8, \n}\n\ntrain_dtype_dict.update(dtype_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# load extended data\npath = '/kaggle/input/2019datasciencebowl-featureengineering-raw/'\ntrain = pd.read_csv(path+'train_extend.csv',parse_dates=['timestamp'],dtype=train_dtype_dict)\n#path = '/kaggle/input/2019datasciencebowl-featureengineering-test-raw/'\n#test = pd.read_csv(path+'test_extend.csv',parse_dates=['timestamp'],dtype=dtype_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocess data\ndef preprocess_train(df):\n    # parse timestamp\n    df['MM']=df.timestamp.dt.month.astype(np.uint8)\n    df['DD']=df.timestamp.dt.day.astype(np.uint8)\n    df['dayofweek']=df.timestamp.dt.dayofweek.astype(np.uint8)\n    df['HH']=df.timestamp.dt.hour.astype(np.uint8)\n    \n    # Encode Title\n    title_le = LabelEncoder()\n    title_le.fit(df.title.unique())\n    df.title = title_le.transform(df.title).astype(np.uint8)\n    \n    # finalize output\n    Y = df.accuracy_group\n    label = df.loc[:,['installation_id','game_session']]\n    X = df.drop(columns = ['game_session','installation_id','accuracy','accuracy_group','timestamp'])\n    return X, Y, label ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocess data\ndef preprocess_test(df):\n    # parse timestamp\n    df['MM']=df.timestamp.dt.month.astype(np.uint8)\n    df['DD']=df.timestamp.dt.day.astype(np.uint8)\n    df['dayofweek']=df.timestamp.dt.dayofweek.astype(np.uint8)\n    df['HH']=df.timestamp.dt.hour.astype(np.uint8)\n    \n    # Encode Title\n    title_le = LabelEncoder()\n    title_le.fit(df.title.unique())\n    df.title = title_le.transform(df.title).astype(np.uint8)\n    \n    # finalize output\n    label = df.loc[:,['installation_id','game_session']]\n    X = df.drop(columns = ['game_session','installation_id','timestamp'])\n    return X, label ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, train_Y, train_label = preprocess_train(train)\ntest_X, test_label = preprocess_test(test)\ntest_X = test_X.loc[:,train_X.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(train_X, train_Y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgboost.XGBClassifier(\n    max_depth=5, learning_rate=0.1, n_estimators=70, \n    verbosity=1, \n    objective='multi:softmax', booster='gbtree', tree_method='auto', \n    n_jobs=1, \n    gamma=0, \n    min_child_weight=1, max_delta_step=0, \n    subsample=1, \n    colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, \n    reg_alpha=0, reg_lambda=1, \n    scale_pos_weight=1, \n    base_score=0.5, \n    random_state=0, \n    missing=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,Y_train,eval_metric='mlogloss')\nY_pred = model.predict(X_val)\nprint(cohen_kappa_score(Y_pred,Y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ModelTuning():\n    max_depth = list(range(3,8))\n    num_est = list(range(50,130,10))\n    lr = [0.3,0.2,0.1,0.05,0.01]\n    kappa = []\n    for N in num_est:\n        model = xgboost.XGBClassifier(max_depth=5,n_estimators=N,learning_rate=0.1,objective='multi:softmax')\n        cv = cross_validate(model,X=train_X, y=train_Y, cv=5, scoring='balanced_accuracy',fit_params={'eval_metric':'auc'})#, sk.metrics.make_scorer(cohen_kappa_score))\n        #model.fit(X_train,Y_train)\n        #Y_pred = model.predict(X_val)\n        #kappa.append(cohen_kappa_score(Y_pred,Y_val))\n        print(N,np.mean(cv['test_score']))\n        kappa.append(np.mean(cv['test_score']))\n    sns.scatterplot(x=num_est,y=kappa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgboost.XGBClassifier(\n    max_depth=5, learning_rate=0.1, n_estimators=70, \n    verbosity=1, \n    objective='multi:softmax', booster='gbtree', tree_method='auto', \n    n_jobs=1, \n    gamma=0, \n    min_child_weight=1, max_delta_step=0, \n    subsample=1, \n    colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, \n    reg_alpha=0, reg_lambda=1, \n    scale_pos_weight=1, \n    base_score=0.5, \n    random_state=0, \n    missing=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_X,train_Y,eval_metric='mlogloss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = model.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame({'installation_id':test_label.installation_id, 'accuracy_group':test_predict})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}