{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport json\nfrom pandas.io.json import json_normalize\n\nimport os\ndirectory = \"/kaggle/input/data-science-bowl-2019/\"\noutdir = \"\"\nfor dirname, _, filenames in os.walk(directory):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load and analyze the specs data\nspecs = pd.read_csv(directory +\"specs.csv\")  \nprint(\"no of rows\", specs.count())\nspecs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#load and analyze the test data\ntest = pd.read_csv(directory + \"test.csv\")\nprint(test.count(axis=0))\ntest.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load and analyze the submission data\nsubmission = pd.read_csv(directory + \"sample_submission.csv\")\nprint(submission.count(axis=0))\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#in the training set, learn more about data\n#load the full train.csv\n\ntrain = pd.read_csv(directory +\"train.csv\")\nprint(len(train.index))\ntrain.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#load and analyze the labels data\ntrain_labels = pd.read_csv(directory + \"train_labels.csv\")\nprint(train_labels.count())\ntrain_labels.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#we will create  a function that will build all features\n#this will be used for train and test data\n#the caller of this function shall pass the basic feature rows and the dataset from which to extract features\ndef create_features(features,dataset):\n    ftr = dataset[(dataset.type == 'Assessment')&(dataset.event_code == 2000)] # all game_session start rows\n    ftr_1 = dataset[(dataset.type == 'Assessment')&((dataset.event_code == 4100)|(dataset.event_code == 4110))]\n    ftr_1 = ftr_1[((ftr_1.event_code == 4100) & (ftr_1.title != 'Bird Measurer (Assessment)')) | \n                             ((ftr_1.event_code == 4110) & (ftr_1.title == 'Bird Measurer (Assessment)'))]\n    #collected all assessment rows\n    ftr_subset = ftr.loc[:,('installation_id','game_session','event_code')]\n    ftr_1_subset = ftr_1.loc[:,('installation_id','game_session','event_code')]\n    ftr_1_subset.reset_index(inplace=True)\n    ftr_1_subset.set_index(['installation_id','game_session'],inplace=True)\n    ftr_subset = ftr_subset.join(ftr_1_subset,on=('installation_id','game_session'),rsuffix='_4100')\n    ftr_subset= ftr_subset[ftr_subset['event_code_4100'].isna()==False]\n    ftr_subset.drop(columns=['index','event_code_4100'],inplace=True)\n    gpby = ftr_subset.groupby(['installation_id','game_session']).count()\n    gpby = gpby.groupby(['installation_id']).count()\n    features = features.join(gpby,on='installation_id',rsuffix='_with4100')\n    features.rename(columns={'event_code_with4100':'total_2000_w_4100'},inplace=True)\n    #if NaN is in total_2000_w_4100, then it means that there is no attempt\n    features.loc[:,'total_2000_w_4100'].fillna(0,inplace=True)\n\n    gpby = ftr_subset.groupby(['installation_id']).count()\n    features = features.join(gpby,on='installation_id',rsuffix='_withall4100')\n    features.rename(columns={'event_code_withall4100':'total_4100'},inplace=True)\n    features.drop(columns=['game_session_withall4100'],inplace=True)\n    features.loc[:,'total_4100'].fillna(0,inplace=True)\n\n    #now find the gametime count (since gametime is cum time from start)\n    subset = dataset.loc[:,('installation_id','title','game_time')]\n    addl_ftr = subset.groupby(['installation_id','title']).count()\n    addl_ftr.reset_index(inplace=True)\n    addl_ftr.set_index(['installation_id','title'],inplace=True)\n    addl_ftr = addl_ftr.unstack(1)\n    features=features.join(addl_ftr,on=('installation_id'),rsuffix='_addl')\n\n    features = pd.get_dummies(features,prefix='cat',columns=['world','title'])\n    features.reset_index(inplace=True)\n    \n    features.drop(columns=['event_id','timestamp',\n                                'event_data','event_count','event_code',\n                                'game_time','type',\n                                'cat_CRYSTALCAVES','cat_MAGMAPEAK',\n                                'cat_TREETOPCITY',],inplace=True)\n    features.fillna(0,inplace=True)\n\n    #lets build the count of  accuracy_group for each install_id+title\n    #build the temp from train_filtered, and fill \"correct\" from \"event_data\"\n\n    temp = dataset[(dataset.type == 'Assessment') & ((dataset.event_code == 4100) | (dataset.event_code == 4110))]\n    parsed_df = pd.concat([json_normalize(json.loads(js)) for js in temp['event_data']])\n    temp.loc[:,'correct'] = parsed_df['correct'].to_numpy()\n\n    #remove temp rows with 4100 and Bird Measurer\n    temp = temp[((temp.event_code == 4100) & (temp.title != 'Bird Measurer (Assessment)')) | \n                             ((temp.event_code == 4110) & (temp.title == 'Bird Measurer (Assessment)'))]\n\n    temp_subset = temp.loc[:,('installation_id','title','game_session','correct','type')]\n    temp_gpby = temp_subset.groupby(['installation_id','title','game_session','correct'],observed=True).count()\n    temp_gpby = temp_gpby.unstack(-1)\n\n    temp_gpby.fillna(0,inplace=True)\n    temp_gpby['accuracy']=temp_gpby[('type',True)]/(temp_gpby[('type',False)]+temp_gpby[('type',True)])\n    temp_gpby.drop('type',axis=1,level=0,inplace=True)\n    temp_gpby.columns = temp_gpby.columns.get_level_values(0)\n\n    temp_gpby.head()\n    temp_gpby =pd.get_dummies(temp_gpby,columns=['accuracy'])\n    temp_gpby_copy = temp_gpby.copy(deep=True)\n    length = len(temp_gpby.columns)-3\n    for i in range(length):\n        temp_gpby.drop(temp_gpby.columns[1],axis=1,inplace=True)\n    temp_gpby_copy.drop(temp_gpby_copy.columns[[0,length+1,length+2]],axis=1,inplace=True)    \n    temp_gpby['accuracy_grp1'] = temp_gpby_copy.sum(axis=1)\n    temp_gpby=temp_gpby.groupby(['installation_id','title']).sum()\n    temp_gpby = temp_gpby.unstack(-1)\n    temp_gpby.columns = [' '.join(col).strip() for col in temp_gpby.columns.values]\n    temp_gpby.fillna(-1,inplace=True)\n    #now join train_features to temp_gpby\n    features = features.join(temp_gpby,on=['installation_id'],rsuffix='_more')\n    features.reset_index(inplace=True)\n    features.drop(columns=['index','level_0'],inplace=True)\n    features.fillna(-1,inplace=True)\n    return features\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#now prep the train and test data to call create_features\n\n#train data\ntrain['timestamp'] =pd.to_datetime(train['timestamp'])\ntemp = train[(train.type == 'Assessment') & ((train.event_code == 4100) | (train.event_code == 4110))]\ntrain_filtered_2 = temp[((temp.event_code == 4100) & (temp.title != 'Bird Measurer (Assessment)')) | \n                         ((temp.event_code == 4110) & (temp.title == 'Bird Measurer (Assessment)'))]\n#this has only 4100s, now find last 4100\ntrain_filtered_2_subset = train_filtered_2.loc[:,('installation_id','timestamp')]\ntrain_filtered_2_gpby = train_filtered_2_subset.groupby(['installation_id']).max()\ntrain_filtered_2_gpby.reset_index(inplace=True)\ntrain_filtered_2_gpby.set_index('installation_id',inplace=True)\ntrain_filtered_3 = train_filtered_2.join(train_filtered_2_gpby,on=('installation_id'),rsuffix='_max')\ntrain_filtered_3 = train_filtered_3[train_filtered_3.timestamp == train_filtered_3.timestamp_max]\ntrain_filtered_3_subset = train_filtered_3.loc[:,('installation_id','game_session')]\n#now find the 2000 with  this game_session and get its timestamp;\ntrain_filtered_4 = train[(train.event_code== 2000)&(train.type=='Assessment')]\ntrain_filtered_4.set_index(['installation_id','game_session'],inplace=True)\ntrain_features = train_filtered_3_subset.join(train_filtered_4,on=('installation_id','game_session'),rsuffix='_r')\ntrain_features.set_index(['installation_id'],inplace=True)\ntrain_filtered = train.join(train_features,on=['installation_id'],rsuffix=\"_max\")\n#now remove all NaN rows in col 'timestamp_max' since they are not in train_features\ntrain_filtered = train_filtered[train_filtered['timestamp_max'].isna()== False]\n#and remove all rows with timestamp> timestamp_max\ntrain_filtered = train_filtered[train_filtered.timestamp <= train_filtered.timestamp_max]\n#now train_filtered has all rows of interest matching test dataset\n\ntrain_features.reset_index(inplace=True)\ntrain_features = create_features(train_features,train_filtered)\n\n#now build the train_y from train_features and train_labels\ntrain_y_subset = train_features.loc[:,('installation_id','game_session','event_code')]\ntrain_y_subset2 = train_labels.loc[:,('installation_id','game_session','accuracy_group')]\ntrain_y_subset2.set_index(['installation_id','game_session'],inplace=True)\ntrain_y = train_y_subset.join(train_y_subset2,on=['installation_id','game_session'],rsuffix='_r')\ntrain_inst_id=train_features['installation_id']\n\n#now for the test data\ntemp_test = test[(test.type == 'Assessment') & ((test.event_code == 4100) | (test.event_code == 4110))]\n\ntemp_test = temp_test[((temp_test.event_code == 4100) & (temp_test.title != 'Bird Measurer (Assessment)')) | \n                         ((temp_test.event_code == 4110) & (temp_test.title == 'Bird Measurer (Assessment)'))]\ntemp_test['timestamp'] =pd.to_datetime(temp_test['timestamp'])\n#temp_test has all 4100 events\n\n#in test data, find all last 2000 - these are the feature rows\ntest['timestamp'] =pd.to_datetime(test['timestamp'])\ntest_ftr = test[(test.type == 'Assessment') & (test.event_code == 2000)]\n\n#now take only the max timestamp for each inst_id \ntest_ftr_subset = test_ftr.loc[:,('installation_id','timestamp')]\ntest_gpby = test_ftr_subset.groupby(['installation_id']).max()\ntest_gpby.reset_index(inplace=True)\ntest_gpby.set_index(['installation_id'],inplace=True)\ntest_features = test_ftr.join(test_gpby,on=('installation_id'),rsuffix='_max')\ntest_features =test_features.loc[test_features['timestamp']== test_features['timestamp_max']]\ntest_features.drop(columns=['timestamp_max'],inplace=True)\n\ntest_features =create_features(test_features,test)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_features.to_csv(outdir+'test_features.csv')\ntrain_features.to_csv(outdir+'train_features.csv')\ntrain_y.to_csv(outdir+'train_y.csv')\ntest_inst_id = test_features['installation_id']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_features.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#now remove the unrequired columns\ntrain_features.drop(columns=['installation_id','game_session','total_2000_w_4100',\n                                         'total_4100'],inplace=True)\ntest_features.drop(columns=['installation_id','game_session','total_2000_w_4100',\n                                         'total_4100'],inplace=True)\ntrain_y.drop(columns=['installation_id','game_session','event_code'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, cohen_kappa_score, make_scorer\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbc_params = {\n    \"learning_rate\":[0.01,0.05,0.1,0.2,0.5],\n    \"n_estimators\":[128,256],\n    \"max_leaf_nodes\":[2,4],\n    \"random_state\":[0]    \n}\n\ncks = make_scorer(cohen_kappa_score,weights=\"quadratic\")\nGBclf = GradientBoostingClassifier()\nGScv = GridSearchCV(GBclf,param_grid = gbc_params,cv=5,scoring=cks)\nGScv.fit(train_features,train_y.iloc[:,0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"GScv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#now score the test set and submit\nresult = GScv.predict(test_features)\nresults = pd.DataFrame(data=result)\nresults['installation_id']=test_inst_id.values\nresults.rename(columns={0:'accuracy_group'},inplace=True)\nresults.to_csv(outdir+'submission.csv',index=False)\nresults.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"nbformat":4,"nbformat_minor":1}