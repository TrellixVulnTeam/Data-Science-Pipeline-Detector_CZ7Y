{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm #progress bars with support for jupyter notebooks\nimport datetime as dt\n\nimport matplotlib.pyplot as plt\n\ntqdm.pandas(desc=\"my bar!\")\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_union(x,y):\n    \"\"\"\n    takes two lists and returns their union with only unique elements.  No ordering.\n\n    *x expands x, {*x} makes a set, *{*x} expands the set.\n    \"\"\"\n    return [*({*x}.union({*y}))]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# right way to do this is probably three different functions with usecols argument...\ndef keep_cols(cols,col):\n    return col in cols\n\ndef read_data():\n    print('Reading train.csv.')\n    train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\n    print('Read train.csv with {} rows and {} columns.'.format(train.shape[0],train.shape[1]))\n\n    print('Reading test.csv.')\n    test = pd.read_csv('../input/data-science-bowl-2019/test.csv', usecols=['event_id'])\n    print('Read test.csv with {} rows and {} columns.'.format(test.shape[0],test.shape[1]))\n\n    print('Reading train_labels.csv.')\n    train_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\n    print('Read train_labels.csv with {} rows and {} columns.'.format(train_labels.shape[0],train_labels.shape[1]))\n\n#    print('Reading specs.csv.')\n#    specs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\n#    print('Read specs.csv with {} rows and {} columns.'.format(specs.shape[0],specs.shape[1]))\n\n    return train, test, train_labels, #specs\ntrain, test, train_labels = read_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## Filter out all the installations which never complete an assessment\n# Sorting by event_code is definitely not enough.\n# I don't think 'Assessment' is -- user could start an event of 'type' 'Assessment' and not finish it\ntrain = train.reset_index(drop=True).groupby('installation_id').filter(\n    lambda x : len(x[((x['event_code'] == 4100) | (x['event_code'] == 4110)) & (x['type'] == 'Assessment')].index) > 0)\n\ntrain.drop(columns=['event_code'], inplace=True)\n\n\n## 'pattern' to detect successful assessments\n# (originally had r'string' here for \"raw string\" -- not necessary!  only for backslashes)\npattern = '\"correct\":true'\ntrain['correct_assessment'] = train['event_data'].str.contains(pattern)\ntrain.drop(columns = ['event_data'], inplace=True) # no further use\n\n## Double-check that 'True' only appears on assessments!\ntrain[train['correct_assessment'] == True]['title'].unique()\n# !!!\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## An example of feature engineering that we don't do:\n# make a dict {event_id -> event_info entries to keep}!\n# good project for next time!\nprint(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assessment_titles = {*list(train[train['type'] == 'Assessment']['title'])}\ntrain.drop(columns=['title'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event_ids = unique_union(train['event_id'],test['event_id'])\nworlds = {*list(train['world'])}\n\n## recover memory\n# TODO: it's principled but silly to bring in test for 'world' and 'type'...\ndel test\n\n\n# number the lists\nworlds_map = {x:i for (x,i) in zip(worlds, np.arange(len(worlds)))}\n\nevent_ids_map = {x:i for (x,i) in zip(event_ids, np.arange(len(event_ids)))}\n\ntypes_map = {'Clip': 0, 'Activity': 1, 'Game': 2, 'Assessment': 3}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change from text labels to int labels via maps\n# TODO: could this be one pass?\n# (uses apply: https://stackoverflow.com/a/44648068)\ntrain['world'] = train['world'].map(worlds_map)\ntrain['event_id'] = train['event_id'].map(event_ids_map)\ntrain['type'] = train['type'].map(types_map)\n\n#test['world'] = test['world'].map(worlds_map)\n#test['event_id'] = test['event_id'].map(event_ids_map)\n#test['type'] = test['type'].map(types_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Want a column 'session_number' which measures not just time in-app but real time \n## since starting.\n## This seems better than 'game_session' which counts something like turning the app on and off\n## This is the most active 'feature engineering' -- worth it?\n\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\n#test['timestamp'] = pd.to_datetime(test['timestamp'])\n# replaces 'timestamp' with 'session_number'\n\n\n#TODO: make one pass?\ndef times_to_numbers(data):\n    ## DROP_TIME is the number of seconds between distinct sessions\n    # TODO: treat this as a hyperparameter!\n    DROP_TIME = 900\n    # sort by timestamp\n    data_sorted = data.groupby('installation_id').apply(lambda x : x.sort_values(by=['timestamp']))\n    # 'end_of_session' is a bool which denotes whether the event is the last in a session\n    data_sorted['end_of_session'] = ((data_sorted['timestamp'].shift(periods=-1) - data_sorted['timestamp']).map(lambda x : x.total_seconds()) > DROP_TIME)\n    # get session number by adding up 'end_of_session'\n    data_sorted['session_number'] = data_sorted.groupby(level=0)['end_of_session'].cumsum()\n    # don't need the rest of it\n    data_sorted = data_sorted.drop(columns = ['timestamp','end_of_session', 'game_session'])\n    return data_sorted\n\n# apply\ntrain = times_to_numbers(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## TODO: move up\ntrain = train.drop(columns='event_count')\n\n## Need to scale down 'game_time'\n# kind of makes sense for it to have a similar scale to 'session_number'?\nmax_game_time = train['game_time'].max()\nprint('max_game_time: ' + str(max_game_time))\nmax_session_num = train['session_number'].max()\nprint('max_session_num: ' + str(max_session_num))\n### scales 'game_time' to be smaller\n# Usually need to subtract min but the min is zero.\n# everything will get shifted by 1 anyway...\nLIMEROBOT_NORM = 1000 # this is what limerobot used...\ndef scale_game_time(gt):\n   #return gt  / max_game_time\n   return gt / LIMEROBOT_NORM \n\n## to support masking\n# TODO: how important is this if we're not using an official Masking layer?\n# TODO: make one pass\ntrain['event_id'] = train['event_id'].transform(lambda x : x + 1)\ntrain['type'] = train['type'].transform(lambda x : x + 1)\ntrain['world'] = train['world'].transform(lambda x : x + 1)\ntrain['game_time'] = train['game_time'].transform(lambda x : scale_game_time(x))\ntrain['session_number'] = train['session_number'].transform(lambda x : x + 1)\ntrain['correct_assessment'] = train['correct_assessment'].transform(lambda x : 1 if x else -1) # to avoid mask?  not sure about this one.\n\n## TODO: use this construction above!\ntrain_ids = set(train['installation_id'].unique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_columns = list(train.columns)\ndel original_columns[1]\nprint(\"Original columns:\")\nprint(original_columns)\n# (when we apply this permutation we'll have already dropped 'installation_id' so ignored below)\n# ['event_id', 'game_time','type','world','correct_assessment','session_number']\n# we want\n# ['game_time', 'session_number', 'correct_assessment', 'event_id', 'type','world']\n\n# permutation written as [f(0),f(1),f(2),f(3),f(4),f(5)] under the permutation\npermutation = [3,0,4,5,2,1]\nidx = np.empty_like(permutation)\nidx[permutation] = np.arange(len(permutation))\n# used below when we pipe pandas into numpy:\n\nnew_columns = [original_columns[i] for i in idx]\nprint(\"Want: \\n['game_time', 'session_number', 'correct_assessment', 'event_id', 'type', 'world']\")\nprint(\"New columns:\")\nprint(new_columns)\n## splits [0,1,2,3,4,5] into [[0,1,2],3,4,5]\n# and https://discourse.julialang.org/t/reshape-a-1-d-array-into-an-array-of-different-size-arrays/25999\nn = [3,1,1,1]\nsplit_points = np.cumsum(n[0:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## sequences need to be of the same length\n# what should it be?\n# note that we have already filtered out players who did not take any assessments!\ntrain['installation_id'].value_counts().describe(percentiles=[.25, .5, .75, .9, .99])\n\nplt.figure();\ntrain['installation_id'].value_counts().hist(bins=60)\nplt.xticks([0, 2000, 13000, 60000], rotation=45)\n\nprint(train['installation_id'].value_counts().describe(percentiles=[.25,.33,.5,.66,.75]))\n\n## Cuts off a lot of the long tail\nSEQ_LENGTH = 2000\n# originally had SEQ_LENGTH = 13000\n# cutting to 2000 cuts training time by 75%, seems worth it\n# another interesting hyperparameter to play with!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### time to work with train_labels\nimport feather\n## two ways we could do this:\n#   1) take the max accuracy group.  in other words, take the best result.\n#   2) take the last accuracy group.  in other words, take the most recent result.\n# I think 2) makes more sense since our goal is predict the next result, not the \"average\" result\n# (Q: what does it mean for the app if these heavily diverge?)\n\n# 'last_session' is the id of the most recent session for an ('installation_id', 'title')\ntrain_labels['last_session'] = train_labels.groupby(['installation_id','title'])['game_session'].tail(n=1)\n# keep only the most recent sessions\ntrain_labels = train_labels[train_labels['game_session'] == train_labels['last_session']]\n# actually only one label per (installation, title)?\nprint(train_labels.groupby(['installation_id'])['title']\n      .apply(lambda x : x.duplicated())\n      .any())\n# yes\n\n# TODO: 3rd finish uses 'num_correct' and 'num_incorrect'\ntrain_labels.drop(columns =['game_session','last_session', 'num_correct','num_incorrect', 'accuracy'], inplace=True)\n\n## assessment: 'installation_id's which took the assessment\ntook_assessment_ids_map = {activity: list(\n    train_labels[(train_labels['title'] == activity)]['installation_id']) \n                           for activity in assessment_titles}\n\n## fill in assessments not taken\ntitle_index  = pd.MultiIndex.from_product([train_labels['installation_id'].unique(), assessment_titles],names=['installation_id','title'])#, names=['installation_id', 'title'])\n# TODO: can't be right to have set_index.reindex!\nfilled_train_labels = train_labels.set_index(['installation_id','title']).reindex(index=title_index, fill_value=0).reset_index()\nfeather.write_dataframe(filled_train_labels, \"train_labels_processed.fth\")\n# want to fill in all assessments for each session\n# so create data frame with the same 'game_session', 'installation_id' and fill in known values\n# rest are zero","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We're done with train!  write it\nfeather.write_dataframe(train, \"train_processed.fth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# writing records that will be useful elsewhere\nimport pickle\nwith open('event_ids_map.pkl', 'wb') as file:\n    pickle.dump(event_ids_map, file)\n    \nwith open('took_assessments_map.pkl', 'wb') as file:\n    pickle.dump(took_assessment_ids_map, file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Make nice numpy arrays\n\n## make a directory if it's not already there\nimport os\ntry:\n    os.mkdir('data')\n# if FileExistsError AND the file is a directory -- good, move on\n# otherwise, something screwy is happening!  stop everything\n# all kinds of concurrency issues here, but not an issue for us\nexcept FileExistsError: \n    if not os.path.isdir('data'):\n        raise\n\n\nrow = np.array([np.array([0,0,0]), np.array([0]), np.array([0]), np.array([0])], dtype=object)\n\n# one-hot encodes 'accuracy_group' \ndef my_dumb_one_hot(num):\n    if num == 0:\n        return np.array([1,0,0,0])\n    elif num == 1:\n        return np.array([0,1,0,0])\n    elif num == 2:\n        return np.array([0,0,1,0])\n    elif num == 3:\n        return np.array([0,0,0,1])\n   \nfor activity in tqdm(took_assessment_ids_map):\n    relevant_ids = took_assessment_ids_map[activity]\n    X0 = np.empty([len(relevant_ids), SEQ_LENGTH, 3])\n    X1 = np.empty([len(relevant_ids), SEQ_LENGTH])\n    X2 = np.empty([len(relevant_ids), SEQ_LENGTH])\n    X3 = np.empty([len(relevant_ids), SEQ_LENGTH])\n    y = np.empty([len(relevant_ids), 4])\n    j = 0\n    for an_id in tqdm(relevant_ids):\n        # fill a new array with rows of zeros\n        Xentry = np.tile(row, (SEQ_LENGTH,1))\n        # to form id_array: take train for a particular id, drop the id, make into numpy\n        # fix type, cut off/pad at SEQ_LENGTH\n        id_array = train.loc[an_id].drop(columns = 'installation_id').to_numpy().astype(int)[-SEQ_LENGTH:]\n        \n        # permute columns to be correct\n        id_array[:] = id_array[:,idx]\n        \n        # TODO: should be a way to do this in numpy without explicit loop\n        for i in np.arange(id_array.shape[0]):\n            Xentry[i,:] = np.split(id_array[i], split_points, axis=0)\n        \n        # now we have an array like\n        # [\n        #  [[x,y,z],a,b,c]\n        #  ...\n        #  [[x,y,z],a,b,c]\n        # ]\n        # but we want four arrays like:\n        # [[x,y,z],...,[x,y,z]], [a...], [b...], [c...]\n        X0[j] = np.vstack(Xentry[:,0])\n        X1[j] = Xentry[:,1].astype(int)\n        X2[j] = Xentry[:,2].astype(int)\n        X3[j] = Xentry[:,3].astype(int)\n        # now find the label and one-hot encode it\n        y_temp = filled_train_labels.set_index(['installation_id','title']).loc[(an_id, activity)]\n        y_temp = y_temp[0]\n        y_temp = my_dumb_one_hot(y_temp)\n        # add it to the array of labels\n        y[j] = y_temp \n        \n        # TODO: determine if this is a necessary evil\n        j = j +1\n        \n    np.savez_compressed(os.path.join('data', 'X_' + activity + '.npz'), x0=X0, x1=X1, x2=X2, x3=X3)\n   \n    np.save(os.path.join('data', 'Y_' + activity + '.npy'), y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# need to do the same for test_labels, but we also need to compute test_labels!\n\n\ncorrect_pattern = r'\"correct\":true'\nincorrect_pattern = r'\"correct\":false'\ntest['correct_assessment'] = test['event_data'].str.contains(correct_pattern)\ntest[test['correct_assessment'] == True]['title'].unique()\ntest['incorrect_assessment'] = test['event_data'].str.contains(incorrect_pattern)\ntest[test['incorrect_assessment'] == True]['title'].unique()\n\n\ntest_labels = test[test['title'].str.contains('Assessment')].query('event_code == 4100 | event_code == 4110').drop(columns=['type','world','event_count','game_time','event_id','event_code','title_event_code']).reset_index(drop=True)\ntest_labels['title'] = test_labels['title'].map(activities_map)\n\n\n\ntest_labels['max_session'] = test_labels.reset_index(drop=True).groupby(['installation_id','title'])['session_number'].transform(max)\n## TODO: rewrite with get?\ndef fn(df):\n    if df[df['incorrect_assessment'] == False].index.empty:\n        return 3000000 # TODO: do better\n    else:\n        return sum(df.loc[: df[(df['incorrect_assessment'] == False)].index[0] , :]['incorrect_assessment'])\n\ndef fn2(ser):\n    df = ser.to_frame(name='incorrect_assessment')\n    return fn(df)\n    \ntest_labels['until_correct'] = test_labels.groupby(['installation_id','session_number','title'])['incorrect_assessment'].transform(fn2)\naccuracy_groups_map = {0: 3, 1: 2, 3000000: 0}\n# 'default' is 1 -- it counts for 3 or more tries, i.e. 2 or more incorrect attempts\ntest_labels['accuracy_group'] = test_labels['until_correct'].map(lambda x : accuracy_groups_map.get(x, 1) )\ntest_labels = test_labels.drop(columns=['event_data','incorrect_assessment','correct_assessment','until_correct'])\ntest_labels = test_labels[test_labels['session_number'] == test_labels['max_session']]\n# actually this isn't enough -- one can take the same assessment multiple times in a session!\ntest_labels = test_labels.groupby(['installation_id','title']).last().drop(columns =['session_number','max_session'])\n\ntitle_index  = pd.MultiIndex.from_product([test_labels.index.levels[0], assessment_codes], names=['installation_id', 'title'])\ntest_labels = test_labels.reindex(title_index, fill_value=0)\nfeather.write_dataframe(test_labels, \"test_labels_processed.fth\")\n\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"test = test.drop(columns=['title', 'incorrect_assessment','title_event_code','event_code','title_event_code','event_count'])\n\ntest['event_id'] = test['event_id'].transform(lambda x : x + 1)\ntest['type'] = test['type'].transform(lambda x : x + 1)\ntest['world'] = test['world'].transform(lambda x : x + 1)\ntest['game_time'] = test['game_time'].transform(lambda x : x + 1)\ntest['session_number'] = test['session_number'].transform(lambda x : x + 1)\ntest['correct_assessment'] = test['correct_assessment'].transform(lambda x : 1 if x else -1) # to avoid mask?  not sure about this one.\n\n\ntest_ids = set(test['installation_id'].unique())\ntest = test.reset_index(drop=True)\nfor an_id in tqdm(test_ids):\n    id_array = test.groupby('installation_id').get_group(an_id).drop(columns = ['event_data','installation_id']).to_numpy().astype(int)\n    id_array[:] = id_array[:,idx] # idx defined when we did this to train_ids\n    new_array = np.empty((id_array.shape[0],4), dtype=object) # TODO: understand whether dtype=object is fishy or not\n    # could maybe use something fancy from numpy but let's just loop\n    for i in np.arange(id_array.shape[0]):\n        new_array[i,:] = np.split(id_array[i], split_points, axis=0)\n\n    np.save(os.path.join('data','test_' + an_id + \".npy\"),\n            new_array\n           )\nfeather.write_dataframe(test, \"test_processed.fth\")\n\nimport pickle\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}