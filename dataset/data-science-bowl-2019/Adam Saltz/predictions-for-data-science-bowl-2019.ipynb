{"cells":[{"metadata":{"_uuid":"36e0380a-afeb-4977-8671-903e2add6e58","_cell_guid":"347be282-513d-4999-ba8a-a145e87fbedb","trusted":true},"cell_type":"code","source":"# For example, here's several helpful packages to load in \nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.notebook import tqdm #progress bars with support for jupyter notebooks\nimport datetime as dt\nimport keras as ks\nimport tensorflow as tf\n\nimport sklearn.preprocessing as sklpp\nimport gc\nimport collections\nimport os\nimport pickle\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\ndef unique_union(x,y):\n    \"\"\"\n    takes two lists and returns their union with only unique elements.  No ordering.\n\n    *x expands x, {*x} makes a set, *{*x} expands the set.\n    \"\"\"\n    return [*({*x}.union({*y}))]\n\nwith open('../input/preprocessor-for-data-bowl-2019/event_ids_map.pkl', 'rb') as open_file:\n    event_ids_map = pickle.load(open_file)\n\nworlds_map = {'TREETOPCITY': 0, 'MAGMAPEAK': 1, 'NONE': 2, 'CRYSTALCAVES': 3} #{x:i for (x,i) in zip(worlds, np.arange(len(worlds)))}\nassessment_titles = ['Chest Sorter (Assessment)',\n 'Cart Balancer (Assessment)',\n 'Cauldron Filler (Assessment)',\n 'Mushroom Sorter (Assessment)',\n 'Bird Measurer (Assessment)']\ntypes_map = {'Clip': 0, 'Activity': 1, 'Game': 2, 'Assessment': 3}\ntypes = ['Clip', 'Activity', 'Game', 'Assessment']\n\n# TODO: reduce runs\ndef times_to_numbers(data):\n    # DROP_TIME is the number of seconds between distinct sessions\n## DROP_TIME is the number of seconds between distinct sessions\n    # TODO: treat this as a hyperparameter!\n    DROP_TIME = 900\n    # sort by timestamp\n    data_sorted = data.sort_values(by=['timestamp'])\n    # 'end_of_session' is a bool which denotes whether the event is the last in a session\n    data_sorted['end_of_session'] = ((data_sorted['timestamp'].shift(periods=-1) - data_sorted['timestamp']).map(lambda x : x.total_seconds()) > DROP_TIME)\n    # get session number by adding up 'end_of_session'\n    data_sorted['session_number'] = data_sorted.groupby(level=0)['end_of_session'].cumsum()\n    # don't need the rest of it\n    data_sorted = data_sorted.drop(columns = ['timestamp','end_of_session'])\n    \n    #data_sorted.iloc[-1]['game_time'] = data_sorted.iloc[-2]['game_time']\n    return data_sorted\n\npattern = '\"correct\":true'\n\ndef assessment_to_num(a_bool):\n    if a_bool:\n        return 1\n    else:\n        return (-1)\n\ndef scale_game_time(gt):\n   max_session_num = 114.0\n   max_game_time = 306910249\n   #return (gt * max_session_num) / max_game_time\n   LIMEROBOT_NORM = 1000 # this is what limerobot used...\n   return gt / LIMEROBOT_NORM \n\n    \nlast_assessment_map = {}\n\ncolumns_to_keep = ['installation_id', 'world', 'type', 'event_data', 'event_id', 'timestamp', 'game_time', 'title']\ntest_converters = {'world': lambda x : worlds_map.get(x, -1) + 1,\n                   'type': lambda x : types_map.get(x,-1) + 1,\n                   'event_id': lambda x : event_ids_map.get(x,-1) + 1,\n                   'event_data': lambda x : assessment_to_num(pattern in x),\n                   'game_time': lambda x : scale_game_time(int(x)) + 1,\n                   'timestamp': pd.to_datetime}\n\n\n\nSEQ_LENGTH = 2000\n\n# and https://discourse.julialang.org/t/reshape-a-1-d-array-into-an-array-of-different-size-arrays/25999\nn = [3,1,1,1]\nsplit_points = np.cumsum(n[0:-1])\n\n# get the models\nfrom tensorflow.keras import layers, Model, losses\n\nassessments = ['Chest Sorter (Assessment)', 'Cart Balancer (Assessment)', 'Mushroom Sorter (Assessment)', 'Bird Measurer (Assessment)', 'Cauldron Filler (Assessment)']\n\nmodels = {assessment:tf.keras.models.load_model('../input/fork-of-data-science-bowl-model-1f2596/' + assessment + '.h5', \n                                                custom_objects={\n                                                    'SEQ_LENGTH': SEQ_LENGTH, \n                                                    'model_params': {\n                                                          'LEARNING_RATE': 0.001, #default is 0.001\n                                                          'LOSS_FN': tf.keras.losses.CategoricalCrossentropy(),\n                                                          'METRICS': ['categorical_accuracy'],\n                                                          'CLIP_NORM': 1,\n                                                          'DENSE_DROPOUT': 0.1},\n                                                    'tf.keras.losses': tf.keras.losses,\n                                                    'my_optimizer': tf.keras.optimizers.Adam(learning_rate=.001,  \n                                                                beta_1=0.9, \n                                                                beta_2=0.999, \n                                                                amsgrad=True,\n                                                                clipnorm = 1)\n                                                }) for assessment in assessments}\n\ndef prepare_batch_for_prediction(batch):\n    def prepare_for_prediction(df):\n        row = np.array([np.array([0,0,0]), np.array([0]), np.array([0]), np.array([0])], dtype=object)\n        X0 = np.empty([SEQ_LENGTH, 3])\n        X1 = np.empty([SEQ_LENGTH])\n        X2 = np.empty([SEQ_LENGTH])\n        X3 = np.empty([SEQ_LENGTH])\n        Xentry = np.tile(row, (SEQ_LENGTH,1))\n        #print(df)\n        id_array = df.to_numpy().astype(int)[-SEQ_LENGTH:]\n        #id_array[:] = id_array[:,idx]\n        # could maybe use something fancy from numpy but let's just loop\n        for i in np.arange(id_array.shape[0]):\n            Xentry[i,:] = np.split(id_array[i], split_points, axis=0)\n        # TODO: make this batch-y instead of silly reshaping\n        #X0 = np.vstack(Xentry[:,0]).reshape([SEQ_LENGTH,3]).astype(float) # TODO: why astype??\n        X0 = np.vstack(Xentry[:,0]).astype(float)#.reshape([SEQ_LENGTH,3]).astype(float) # TODO: why astype??\n        X1 = Xentry[:,1].astype(int).reshape([SEQ_LENGTH]) # this has event_id -- last one is the \n        X2 = Xentry[:,2].astype(int).reshape([SEQ_LENGTH])\n        X3 = Xentry[:,3].astype(int).reshape([SEQ_LENGTH])\n        return [X0, X1, X2, X3]\n    XX0, XX1, XX2, XX3 = [], [], [], []\n    for df in batch:\n       X0, X1, X2, X3 = prepare_for_prediction(df)\n       XX0.append(X0) #TODO: make this less hacky!\n       XX1.append(X1)\n       XX2.append(X2)\n       XX3.append(X3)\n    return XX0, XX1, XX2, XX3\n    #return [prepare_for_prediction(df) for df in batch]\n\nimport csv\ndef process_row(row):\n        row[0] = test_converters['event_id'](row[0])\n        row[2] = test_converters['timestamp'](row[2])\n        row[3] = test_converters['event_data'](row[3])\n        row[9] = test_converters['type'](row[9])\n        row[10] = test_converters['world'](row[10])\n        title = row[8]\n        indices_to_keep = [4,7,2,3,0,9,10]\n        row = [row[i] for i in indices_to_keep]\n        return row, str(title)\nMAX_BATCH_SIZE = 32\nwith open('unsorted_submission.csv', 'w') as submission_file:\n     submission_file.write(\"installation_id,accuracy_group\" + \"\\n\")\n\nwith open('../input/data-science-bowl-2019/test.csv', 'r') as csvfile:\n    csvreader = csv.reader(csvfile)\n    next(csvreader)# header row\n    header = ['game_time', 'timestamp', 'correct_assessment', 'event_id', 'type','world']\n    # note that 'timestamp' is not the eventual column name -- times_to_numbers changes it\n    # to 'game_session'\n    a_row, last_title = process_row(next(csvreader))\n    rows = [a_row]\n    last_ID = a_row[0]\n    batch = {assessment: [] for assessment in assessments}\n    for row in csvreader:\n        the_row, the_title = process_row(row)\n        ID = the_row[0]\n        if ID == last_ID:\n            rows.append(the_row)\n            last_title = the_title\n        else:\n            last_ID = ID\n            \n            assessment = last_title\n            predict_ID = rows[0][0]\n            rows = [row[1:] for row in rows] # drop 'installation_id'\n            # TODO: couldn't we drop this when we add it?  doesn't seem pressing\n            #print(\"Found a frame.\")\n            df = pd.DataFrame.from_records(rows, columns=header)\n            df = times_to_numbers(df)\n            \n            batch[assessment].append((predict_ID, df))\n            if len(batch[assessment]) == MAX_BATCH_SIZE:\n                IDs = [pair[0] for pair in batch[assessment]]\n                dfs = prepare_batch_for_prediction([pair[1] for pair in batch[assessment]])\n                predictions_raw = models[assessment].predict_on_batch(dfs)\n                predictions = [np.argmax(prediction) for prediction in predictions_raw]\n                with open('unsorted_submission.csv', 'a') as submission_file:\n                    for (i,j) in zip(IDs, predictions):\n                        submission_file.write(i + ',' + str(j) + '\\n')\n                del batch[assessment]\n                gc.collect()\n                batch[assessment] = [] #TODO: determine if this is better than just = []\n              #  i+=1\n             #   print(\"Predicted on batch \" + str(i) + \".\")\n            \n            rows = [the_row]\n            last_title = the_title\n            last_ID = ID\n    \n    # need to pass the last rows to a batch\n    assessment = last_title\n    predict_ID = rows[0][0]\n    rows = [row[1:] for row in rows]\n    df = pd.DataFrame.from_records(rows, columns=header)\n    df = times_to_numbers(df)\n    batch[assessment].append((predict_ID, df))\n    \n    # predict for those remaining in batch\n    for assessment in batch:\n        if batch[assessment]:\n            IDs = [pair[0] for pair in batch[assessment]]\n            dfs = prepare_batch_for_prediction([pair[1] for pair in batch[assessment]])\n            predictions_raw = models[assessment].predict_on_batch(dfs)\n            predictions = [np.argmax(prediction) for prediction in predictions_raw]\n            with open('unsorted_submission.csv', 'a') as submission_file:\n                for (i,j) in zip(IDs, predictions):\n                    submission_file.write(i + ',' + str(j) + '\\n')\n            batch[assessment] = []     ## TODO: bad repetition!","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fc278b1-62a7-4bb7-93f6-693876818f52","_cell_guid":"f1f7e84a-7182-4778-aaaf-00c10fc0af24","trusted":true},"cell_type":"code","source":"with open('unsorted_submission.csv', 'r') as unsorted_submission:\n    with open('submission.csv', 'w') as submission_file:\n        header = next(unsorted_submission)\n        submission_file.write(header)\n        for row in sorted(unsorted_submission):\n            submission_file.write(row)","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}