{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom time import time\nimport pickle\nimport datetime as dt\nfrom imblearn.over_sampling import RandomOverSampler\nfrom scipy.sparse import csc_matrix\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\ntrain_label = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nsample_df =  pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\ntest = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n\n# Data Merging for train data\ntrain_df = pd.merge(\n                    train, train_label, how = 'right',\n                    on = ['game_session','installation_id']\n                    )\n\n#train_df = train_df.merge(specs, left_on = 'event_id',  right_on = 'event_id', how = \"left\")\n\n# merge test data\n#test_df = test.merge(specs, left_on = 'event_id', right_on = 'event_id', how = \"left\")\n\ntest_df = test.copy()\n\n\nkeep_columns_train = [\n                      'timestamp',\n                      'event_count',\n                      'event_code',\n                      'event_data',\n                      'game_time',\n                      'world',\n                      'title_y',\n                   \n                     ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl = preprocessing.LabelEncoder()\nsc = preprocessing.StandardScaler()\n\n\ndef preprocess_train(data, keep_columns_train):\n    \n    data= data[keep_columns_train]\n    \n    \n    data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n\n    data[\"month\"] = data[\"timestamp\"].dt.month\n    data[\"dayOfMonth\"] = data[\"timestamp\"].dt.day\n    #data[\"week\"] = data[\"timestamp\"].dt.week\n    \n    #data[\"weekday\"] = data[\"timestamp\"].dt.weekday\n    data[\"hour\"] = data[\"timestamp\"].dt.hour\n    data[\"minute\"] = data[\"timestamp\"].dt.minute\n    \n    \n    data = data.drop(columns = ['timestamp'])\n    \n    \n    # standardisation\n    #data[['game_time']] = sc.fit_transform(data[['game_time']])\n    \n    '''\n    for f in data.columns:\n        if data[f].dtype=='object':\n            print(f)\n            lbl.fit(data[f].values)\n            data[f] = lbl.transform(data[f].values)\n            print('pass')\n            \n    '''\n    # Label Encoder\n    lbl.fit(data['world'].values)\n    data['world'] = lbl.transform(data['world'].values)\n    \n    \n    \n    lbl.fit(data['title_y'].values)\n    data['title_y'] = lbl.transform(data['title_y'].values)\n    \n\n    data['data_str_length'] = data['event_data'].str.len()\n    data = data.drop(columns=['event_data'])\n    \n\n    data = data.rename(columns={\"title_y\": \"title\"})\n    \n    #data = data.fillna(-999)\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_df['accuracy_group']\ntrain_df_processed = preprocess_train(train_df, keep_columns_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_df_processed, y, test_size = 0.15,random_state = 999)\nclf = xgb.XGBClassifier(\n                            \n                        n_estimators=500,\n                        min_child_weight = 1,\n                        max_depth=6,\n                        verbosity = 1,\n                        n_jobs=8,                                              \n                        scale_pos_weight=1.025,\n                        tree_method='hist',\n                        objective = 'multi:softmax',\n                        num_class = 4,\n                        predictor='cpu_predictor',\n                        colsample_bytree = 0.66,\n                        subsample = 1,\n                        gamma = 0,\n                        learning_rate=0.15,\n                        num_parallel_tree = 1,    \n                       )\n\n\nclf.fit(X_train, y_train, eval_metric=\"merror\", early_stopping_rounds=100,\n                    eval_set=[(X_train, y_train), (X_valid, y_valid)],verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Importance\n\nprint(clf.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\nfeat_importances.nlargest(len(X_train.columns)).plot(kind='bar',fontsize = 15)\nplt.rcParams[\"figure.figsize\"] = (20,20)\nplt.xlabel(\"Attributes\", fontsize=20)\nplt.ylabel(\"Relative Importance\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_columns_test = [\n    \n                     'timestamp',\n                     'event_count',\n                     'event_code',\n                     'event_data',\n                     'game_time',\n                     'world',\n                     'title'\n                   \n                    ]\n\ndef preprocess_test(data, keep_columns_test):\n    \n    \n    data = data[keep_columns_test]\n    \n    data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n\n    data[\"month\"] = data[\"timestamp\"].dt.month\n    data[\"dayOfMonth\"] = data[\"timestamp\"].dt.day\n    #data[\"week\"] = data[\"timestamp\"].dt.week\n    \n    #data[\"weekday\"] = data[\"timestamp\"].dt.weekday\n    data[\"hour\"] = data[\"timestamp\"].dt.hour\n    data[\"minute\"] = data[\"timestamp\"].dt.minute\n    \n    \n    data = data.drop(columns = ['timestamp'])\n    \n    # standardisation\n    data[['game_time']] = sc.fit_transform(data[['game_time']])\n    \n    \n    # Label Encoder\n    lbl.fit(data['world'].values)\n    data['world'] = lbl.transform(data['world'].values)\n    \n    lbl.fit(data['title'].values)\n    data['title'] = lbl.transform(data['title'].values)  \n    \n    \n    '''\n    \n    for f in data.columns:\n        if data[f].dtype=='object':\n            print(f)\n            lbl.fit(data[f].values)\n            data[f] = lbl.transform(data[f].values)\n            \n    '''\n    data['data_str_length'] = data['event_data'].str.len()\n    data = data.drop(columns=['event_data'])\n    \n    #data = data = data.fillna(-999)\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_processed = preprocess_test(test_df, keep_columns_test)\n\npreds = clf.predict(test_df_processed)\n\nsubmission = test[['installation_id']]\nsubmission['accuracy_group'] = preds\n\nsubmission = submission.groupby(['installation_id']).agg(lambda x: x.iloc[-1]).reset_index()\nsubmission = submission.astype({\"accuracy_group\": int})\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}