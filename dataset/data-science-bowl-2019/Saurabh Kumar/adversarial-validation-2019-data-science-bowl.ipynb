{"cells":[{"metadata":{"_uuid":"fb854c39da7d8fc6e098c22086fcdb9602779616"},"cell_type":"markdown","source":"For more details :\nhttp://fastml.com/adversarial-validation-part-one/\nhttps://www.kaggle.com/konradb/adversarial-validation-and-other-scary-terms\nhttps://www.kaggle.com/ogrellier/adversarial-validation-and-lb-shakeup\n\nBasic data processing from:\nhttps://www.kaggle.com/shahules/xgboost-feature-selection-dsbowl\n\n**Some code snippet below is from other past competition kernels , but now I don't remember the owner, if you are the one please mention in comment and I will add your credit here :)**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Load libraries\nimport numpy as np\nimport pandas as pd\nimport gc\nimport datetime\nfrom scipy.stats import mode\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom sklearn import preprocessing\n# Params\nNFOLD = 5\nDATA_PATH = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nkeep_cols = ['event_id', 'game_session', 'installation_id', 'event_count',\n             'event_code','title' ,'game_time', 'type', 'world','timestamp']\ntrain=pd.read_csv('../input/data-science-bowl-2019/train.csv',usecols=keep_cols)\ntrain_labels=pd.read_csv('../input/data-science-bowl-2019/train_labels.csv',\n                         usecols=['installation_id','game_session','accuracy_group'])\ntest=pd.read_csv('../input/data-science-bowl-2019/test.csv',usecols=keep_cols)\nsubmission=pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_req=(set(train.installation_id.unique()) - set(train_labels.installation_id.unique()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_new=~train['installation_id'].isin(not_req)\ntrain.where(train_new,inplace=True)\ntrain.dropna(inplace=True)\ntrain['event_code']=train.event_code.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_time_features(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['month'] = df['timestamp'].dt.month\n    df['hour'] = df['timestamp'].dt.hour\n    df['year'] = df['timestamp'].dt.year\n    df['dayofweek'] = df['timestamp'].dt.dayofweek\n    df['weekofyear'] = df['timestamp'].dt.weekofyear\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_features=['month','hour','year','dayofweek','weekofyear']\ndef prepare_data(df):\n    df=extract_time_features(df)\n    \n    df=df.drop('timestamp',axis=1)\n    #df['timestamp']=pd.to_datetime(df['timestamp'])\n    #df['hour_of_day']=df['timestamp'].map(lambda x : int(x.hour))\n    \n\n    join_one=pd.get_dummies(df[['event_code','installation_id','game_session']],\n                            columns=['event_code']).groupby(['installation_id','game_session'],\n                                                            as_index=False,sort=False).agg(sum)\n\n    agg={'event_count':sum,'game_time':['sum','mean'],'event_id':'count'}\n\n    join_two=df.drop(time_features,axis=1).groupby(['installation_id','game_session']\n                                                   ,as_index=False,sort=False).agg(agg)\n    \n    join_two.columns= [' '.join(col).strip() for col in join_two.columns.values]\n    \n\n    join_three=df[['installation_id','game_session','type','world','title']].groupby(\n                ['installation_id','game_session'],as_index=False,sort=False).first()\n    \n    join_four=df[time_features+['installation_id','game_session']].groupby(['installation_id',\n                'game_session'],as_index=False,sort=False).agg(mode)[time_features].applymap(lambda x: x.mode[0])\n    \n    join_one=join_one.join(join_four)\n    \n    join_five=(join_one.join(join_two.drop(['installation_id','game_session'],axis=1))). \\\n                        join(join_three.drop(['installation_id','game_session'],axis=1))\n    \n    return join_five\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"join_train=prepare_data(train)\ncols=list(join_train.columns)[2:-3]\njoin_train[cols]=join_train[cols].astype('int16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"join_test=prepare_data(test)\ncols=list(join_test.columns)[2:-3]\njoin_test[cols]=join_test[cols].astype('int16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=list(join_test.columns[2:-12])\ncols.append('event_id count')\ncols.append('installation_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=join_test[['event_count sum','game_time mean','game_time sum',\n    'installation_id']].groupby('installation_id',as_index=False,sort=False).agg('mean')\n\ndf_two=join_test[cols].groupby('installation_id',as_index=False,\n                               sort=False).agg('sum').drop('installation_id',axis=1)\n\ndf_three=join_test[['title','type','world','installation_id']].groupby('installation_id',\n         as_index=False,sort=False).last().drop('installation_id',axis=1)\n\ndf_four=join_test[time_features+['installation_id']].groupby('installation_id',as_index=False,sort=False). \\\n        agg(mode)[time_features].applymap(lambda x : x.mode[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train=pd.merge(train_labels,join_train,on=['installation_id','game_session'],\n                                         how='left').drop(['game_session'],axis=1)\n\n#final_test=join_test.groupby('installation_id',as_index=False,sort=False).last().drop(['game_session','installation_id'],axis=1)\nfinal_test=(df.join(df_two)).join(df_three.join(df_four)).drop('installation_id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=final_train[['event_count sum','game_time mean','game_time sum','installation_id']]. \\\n    groupby('installation_id',as_index=False,sort=False).agg('mean')\n\ndf_two=final_train[cols].groupby('installation_id',as_index=False,\n                                 sort=False).agg('sum').drop('installation_id',axis=1)\n\ndf_three=final_train[['accuracy_group','title','type','world','installation_id']]. \\\n        groupby('installation_id',as_index=False,sort=False). \\\n        last().drop('installation_id',axis=1)\n\ndf_four=join_train[time_features+['installation_id']].groupby('installation_id',as_index=False,sort=False). \\\n        agg(mode)[time_features].applymap(lambda x : x.mode[0])\n\n\n\nfinal_train=(df.join(df_two)).join(df_three.join(df_four)).drop('installation_id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfinal=pd.concat([final_train,final_test])\nencoding=['type','world','title']\nfor col in encoding:\n    lb=LabelEncoder()\n    lb.fit(final[col])\n    final[col]=lb.transform(final[col])\n    \nfinal_train=final[:len(final_train)]\nfinal_test=final[len(final_train):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train.shape,final_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(final_train.columns) - set(final_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors = list(final_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.drop('accuracy_group', axis=1,inplace=True)\n# Mark train as 1, test as 0\nfinal_train['target'] = 1\nfinal_test['target'] = 0\n\n# Concat dataframes\nn_train = final_train.shape[0]\ndf = pd.concat([final_train, final_test], axis = 0)\ndel final_train, final_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('accuracy_group',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors.remove('accuracy_group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c17503acbf649cc5b5df9e09b300b4557f677d6"},"cell_type":"code","source":"# Prepare for training\n\n# Shuffle dataset\ndf = df.iloc[np.random.permutation(len(df))]\ndf.reset_index(drop = True, inplace = True)\n\n# Get target column name\ntarget = 'target'\n\n# lgb params\nlgb_params = {\n        'boosting': 'gbdt',\n        'application': 'binary',\n        'metric': 'auc', \n        'learning_rate': 0.1,\n        'num_leaves': 32,\n        'max_depth': 8,\n        'bagging_fraction': 0.7,\n        'bagging_freq': 5,\n        'feature_fraction': 0.7,\n}\n\n# Get folds for k-fold CV\nfolds = KFold(n_splits = NFOLD, shuffle = True, random_state = 0)\nfold = folds.split(df)\n    \neval_score = 0\nn_estimators = 0\neval_preds = np.zeros(df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6099aa185a9d5313f9f4541438d8b4387508a552"},"cell_type":"code","source":"# Run LightGBM for each fold\nfor i, (train_index, test_index) in enumerate(fold):\n    print( \"\\n[{}] Fold {} of {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), i+1, NFOLD))\n    train_X, valid_X = df[predictors].values[train_index], df[predictors].values[test_index]\n    train_y, valid_y = df[target].values[train_index], df[target].values[test_index]\n\n    dtrain = lgb.Dataset(train_X, label = train_y,\n                          feature_name = list(predictors)\n                          )\n    dvalid = lgb.Dataset(valid_X, label = valid_y,\n                          feature_name = list(predictors)\n                          )\n        \n    eval_results = {}\n    \n    bst = lgb.train(lgb_params, \n                         dtrain, \n                         valid_sets = [dtrain, dvalid], \n                         valid_names = ['train', 'valid'], \n                         evals_result = eval_results, \n                         num_boost_round = 5000,\n                         early_stopping_rounds = 100,\n                         verbose_eval = 100)\n    \n    print(\"\\nRounds:\", bst.best_iteration)\n    print(\"AUC: \", eval_results['valid']['auc'][bst.best_iteration-1])\n\n    n_estimators += bst.best_iteration\n    eval_score += eval_results['valid']['auc'][bst.best_iteration-1]\n   \n    eval_preds[test_index] += bst.predict(valid_X, num_iteration = bst.best_iteration)\n    \nn_estimators = int(round(n_estimators/NFOLD,0))\neval_score = round(eval_score/NFOLD,6)\n\nprint(\"\\nModel Report\")\nprint(\"Rounds: \", n_estimators)\nprint(\"AUC: \", eval_score)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9be534b35a88366312600f4d74808452b983cd5d"},"cell_type":"code","source":"# Feature importance\nlgb.plot_importance(bst, max_num_features = 20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d5823908008e583509eee00842644bc8dd21900"},"cell_type":"markdown","source":"As we can see, the separation is almost perfect - which strongly suggests that the train / test rows are very easy to distinguish. **Meaning the distribution of Train and Test is not the same**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}