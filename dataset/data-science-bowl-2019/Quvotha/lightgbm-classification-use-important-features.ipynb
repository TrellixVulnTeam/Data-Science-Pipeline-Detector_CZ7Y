{"cells":[{"metadata":{"id":"FlYuE_qwxvaD","colab_type":"text"},"cell_type":"markdown","source":"- Do not use future data for prediction  \nIt means, if I predict `accuracy_group` of assessment done at \"2019-10-10 13:00:00\" for example, only the data I can use are ones which have timestamp before \"2019-10-10 13:00:00\". In this example, off course, future data means those which have timestamp over \"2019-10-10 13:00:00\".  \nUsing future data for predition sometimes cause of overfitting, and what more important is such prediction is not feasible in production environment. I know that competition rule dose not prohibit it, but I believe feasibility, meaning you can perform the same prediction in their production environment, is essential for any ML attempts including Kaggle competition.  "},{"metadata":{"id":"jrPWhQYHEjQU","colab_type":"code","outputId":"46e40547-3c74-4627-e14e-4502ce5c5e7b","executionInfo":{"status":"ok","timestamp":1579536392592,"user_tz":-540,"elapsed":1828,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":160},"trusted":true},"cell_type":"code","source":"import os\nfor c in os.walk(os.getcwd()):\n  print(c)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"nbYxOpBpxvaF","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport json\nimport gc\nfrom tqdm import tqdm\nimport os.path\nimport os\n# from sklearn.metrics import make_scorer, cohen_kappa_score\nimport lightgbm as lgb\n# from sklearn.svm import LinearSVC\n# from sklearn.preprocessing import StandardScaler, RobustScaler\n# from collections import Counter, defaultdict\n# import random\n# from sklearn.impute import SimpleImputer\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.decomposition import PCA\nimport random\nfrom collections import Counter, defaultdict\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"id":"ZnmDLTsvGRHJ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"PATH_TRAIN = '../input/data-science-bowl-2019/train.csv'\nPATH_TRAIN_LABELS = '../input/data-science-bowl-2019/train_labels.csv'\nPATH_TRAIN_FEATURES = '../input/possible-features/possible_features_train.csv'\nPATH_DROPPED_COLUMNS = '../input/possible-features/dropped_columns.csv'\nPATH_SPECS = '../input/data-science-bowl-2019/specs.csv'\nPATH_TEST = '../input/data-science-bowl-2019/test.csv'\nPATH_TEST_FEATURES = '../input/possible-features/possible_features_test.csv'\nPATH_FEATURE_IMPORTANCES_ALL = '../input/possible-features/feature_importances_all.csv'\nPATH_FEATURE_IMPORTANCES_DROP_LN = '../input/possible-features/feature_importances_drop_ln.csv'\nPATH_FEATURE_IMPORTANCES_LN_ONLY = '../input/possible-features/feature_importances_ln_only.csv'\nLUCKY_NUMBERS = [8, 42, 777, 2020]\nN_ATTEMPTS_DUMMY = -1\nACCURACY_GROUP_DUMMY = -1","execution_count":null,"outputs":[]},{"metadata":{"id":"8eTq_VW6xvaI","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 512)\npd.set_option('display.max_rows', 1000)\npd.options.display.float_format = '{:.2f}'.format\nplt.rcParams[\"figure.figsize\"] = (20, 10)","execution_count":null,"outputs":[]},{"metadata":{"id":"g8CEp0ClxvaM","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def read_train_or_test(train=True,\n                       filepath_train=PATH_TRAIN,\n                       filepath_test=PATH_TEST,\n                       format_timestamp='%Y-%m-%dT%H:%M:%S.%fZ'):\n    \n    if train:\n        filepath = filepath_train\n    else:\n        filepath = filepath_test\n    df = pd.read_csv(filepath)\n    df.timestamp = pd.to_datetime(df.timestamp, format=format_timestamp)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"id":"jX5IP0APxvaO","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def read_train_labels(filepath=PATH_TRAIN_LABELS):\n    train_labels =  pd.read_csv(filepath)\n    return train_labels","execution_count":null,"outputs":[]},{"metadata":{"id":"QHWNTqk-sQ-a","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def calc_accuracy_group(row, dummy=N_ATTEMPTS_DUMMY, \n                        num_correct='num_correct',\n                        num_incorrect='num_incorrect'):\n    if row[num_correct] == dummy and row[num_incorrect] == dummy:\n        return dummy\n    elif row[num_correct] == 0:\n        return 0\n    elif row[num_correct] == 1 and row[num_incorrect] == 0:\n        return 3\n    elif row[num_correct] == 1 and row[num_incorrect] == 1:\n        return 2\n    elif row[num_correct] == 1 and row[num_incorrect] >= 2:\n        return 1\n    else:\n        return np.nan","execution_count":null,"outputs":[]},{"metadata":{"id":"iGx4GTMssVoQ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def calc_num_incorrect_class(row, dummy=N_ATTEMPTS_DUMMY,num_incorrect='num_incorrect'):\n    if row[num_incorrect] == N_ATTEMPTS_DUMMY:\n        return str(N_ATTEMPTS_DUMMY)\n    elif row[num_incorrect] == 0:\n        return 'No error'\n    elif row[num_incorrect] == 1:\n        return '1 error'\n    elif row[num_incorrect] >= 2:\n        return '2 or more errors'\n    else:\n        return 'Unexpected value given'","execution_count":null,"outputs":[]},{"metadata":{"id":"PZXHV-oxxvaP","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_session_time_info(df,\n                          installation_id='installation_id',\n                          game_session='game_session',\n                          timestamp='timestamp', \n                          game_time='game_time',\n                          session_start_time='session_start_time',\n                          session_end_time='session_end_time',\n                          first_session='first_session',\n                          duration='duration',\n                          session_interval='session_interval'\n                         ):\n    \"\"\"\n    - Start and end time of a session:\n      A session's start(end) time is minimum(maximum) timestamp in dataset.\n    - Duration:\n      Maximum 'game_time' by each 'game_session', unit is converted into seconds.\n    - Session Interval:\n      Elapsed seconds between the session's start time and previous \n      one's end time. The order of game sessions are determined by their \n      start time. The value will be np.nan for the first session of each\n      'installation_id'.\n    \"\"\"\n    # Start and end time and duration of session\n    summary = df.groupby([installation_id, game_session]) \\\n                .agg({timestamp:[min,max], game_time:max}) \\\n                .reset_index()\n    summary.columns = [installation_id, game_session,\n                       session_start_time, session_end_time, duration]\n    summary[duration] = summary[duration] / 1000  # milliseconds --> seconds\n    # Interval between session and previous one\n    summary = summary.sort_values(by=[installation_id, session_start_time], \n                                  ascending=True)\n    summary_shift = summary.shift(1)\n    summary['previous_'+installation_id] = summary_shift[installation_id]\n    summary['previous_'+session_end_time] = summary_shift[session_end_time]\n    summary[first_session] = ~(summary[installation_id]==summary['previous_'+installation_id])\n    summary.loc[~(summary[installation_id]==summary['previous_'+installation_id]),\n                'previous_'+session_end_time] = np.nan\n    summary[session_interval] = (summary[session_start_time]\n                                 - summary['previous_'+session_end_time]\n                                ).dt.total_seconds()\n    summary.drop(columns=['previous_'+installation_id, \n                          'previous_'+session_end_time], inplace=True)\n    return summary.reset_index() \\\n                  .drop(columns='index')","execution_count":null,"outputs":[]},{"metadata":{"id":"yFzVd7BtxvaR","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_title_code_count(df):\n    \n    \"\"\"\n    Count up each value's appearances of `title_code`.\n    `title_code` is a column created by concatenating `title` and `event_code`.\n    Columns are separated by character given by `sep`.\n    A value will not be counted if `event_code`= 2000 because it means start game, \n    and thus appears in all sessions. Additionaly, a value will not be counted \n    if it does not appear in both training and test data, in other words only the value \n    which appears both in training and test data will be counted. It is because \n    such a value cannot be used for modeling and prediction. \n    \"\"\"\n    # Number of appearances of 'title_code'\n    title_code_count = pd.crosstab(df.game_session, df.title_code)\n    return title_code_count.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"id":"5r786CR5wtKQ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_event_code_count(df):\n    event_code_count = pd.crosstab(df.game_session, df.event_code)\n    event_code_count.rename(columns = lambda x: 'event_code_' + str(x), inplace=True)\n    return event_code_count.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"id":"xEABrGAAxvaT","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_title_type_world(df,\n                         installation_id='installation_id',\n                         game_session='game_session',\n                         title='title', \n                         type_='type', \n                         world='world'):\n    # title, world, type of session.\n    type_world_title = df.drop_duplicates(subset=game_session, keep='first') \\\n                         .loc[:, [game_session, type_, world, title]]\n    return type_world_title","execution_count":null,"outputs":[]},{"metadata":{"id":"D0yZKRgfxvaU","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def count_attempts(df, \n                   title='title',\n                   game_session='game_session',\n                   event_data='event_data',\n                   event_code='event_code',\n                   type_='type',\n                   columns_name=['game_session',\n                                 'num_correct',\n                                 'num_incorrect']\n                  ):\n    # Assessment attempts are captured in event_code 4100 for all \n    # assessments except for Bird Measurer, which uses event_code 4110.\n    df_reduce = df[\n        ((df[title]=='Bird Measurer (Assessment)')     & (df[event_code]==4110))\n        | ((df[title]=='Chest Sorter (Assessment)')    & (df[event_code]==4100))\n        | ((df[title]=='Cauldron Filler (Assessment)') & (df[event_code]==4100))\n        | ((df[title]=='Cart Balancer (Assessment)')   & (df[event_code]==4100))\n        | ((df[title]=='Mushroom Sorter (Assessment)') & (df[event_code]==4100))]\n    game_sessions = df_reduce[game_session].unique()\n    n_attempts = {}\n    for gs in game_sessions:\n        session_data = df_reduce[df_reduce[game_session]==gs].reset_index()\n        sesssion_title = session_data.loc[0, title]\n        num_correct, num_incorrect = 0, 0\n        for ed in session_data[event_data]:\n            json_data = json.loads(ed)\n            if 'correct' in json_data.keys():\n                correct = json_data['correct']\n                if not type(correct)==bool:\n                    raise TypeError('correct type is expected to be bool but is not at %s, value is %s' % (gs, correct))\n                if correct:\n                    num_correct += 1\n                else:\n                    num_incorrect += 1\n        n_attempts[gs] = [num_correct, num_incorrect]\n\n    count_attempts = pd.DataFrame.from_dict(n_attempts, orient='index')\n    count_attempts = count_attempts.reset_index()\n    count_attempts.columns = columns_name    \n    return count_attempts.set_index(game_session).sort_index()","execution_count":null,"outputs":[]},{"metadata":{"id":"GW9PByd9tdM7","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_session_database(df, label):\n    # time information\n    time_info = get_session_time_info(df)\n    time_info.loc[time_info.session_interval < 0, 'session_interval'] = 0\n    time_info.set_index('game_session', inplace=True)\n    # title, type, world\n    session_category = get_title_type_world(df)\n    session_category.set_index('game_session', inplace=True)\n    # event_code\n    event_code_count = get_event_code_count(df)\n    event_code_count.set_index('game_session', inplace=True)\n    # title-event_code\n    title_code_count = get_title_code_count(df)\n    title_code_count.set_index('game_session', inplace=True)\n    # number of attemption to assessment\n    num_attempts = label.loc[:, ['game_session',\n                                 'num_correct', \n                                 'num_incorrect', \n                                 'accuracy_group', \n                                 'num_incorrect_class']]\n    num_attempts.set_index('game_session', inplace=True)\n    # merge data frames into single dataframe\n    game_sessions = session_category.join(time_info) \\\n                                    .join(num_attempts) \\\n                                    .join(title_code_count) \\\n                                    .join(event_code_count) \\\n                                    .sort_index()\n    return game_sessions","execution_count":null,"outputs":[]},{"metadata":{"id":"I2KNSjZ1xvaW","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def extract_targets(test,\n                    installation_id='installation_id',\n                    game_session='game_session',\n                    timestamp='timestamp',\n                    title='title',\n                    type_='type'):\n    assessments = test.loc[test[type_]=='Assessment']\n    return assessments.loc[assessments.groupby([installation_id])[timestamp].idxmax(),\n                          [installation_id, game_session, title]]","execution_count":null,"outputs":[]},{"metadata":{"id":"cSm1pJsFxvaY","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def retrieve_past_sessions(game_sessions, \n                           session_id,\n                           game_session='game_session',\n                           installation_id='installation_id',\n                           session_end_time='session_end_time',\n                           session_start_time='session_start_time'):\n    id_and_start_time = game_sessions.loc[session_id]\n    installation_id_ = id_and_start_time[installation_id]\n    session_start_time_ = id_and_start_time[session_start_time]\n    past_session_data = game_sessions[\n        (game_sessions[installation_id] == installation_id_)\n        & (game_sessions[session_end_time] < session_start_time_)\n    ]\n    return past_session_data.index","execution_count":null,"outputs":[]},{"metadata":{"id":"sLe0TdY8xvaa","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def agg_by_key(df,\n               keyfield,\n               list_of_values,\n               agg_fields=['duration', 'session_interval'],\n               agg_funcs=['sum', 'max', 'median', 'count', 'mean']):\n    agg_args = {}\n    if type(agg_fields) in (list, tuple):\n        for agg_field in agg_fields:\n            agg_args[agg_field] = agg_funcs\n    else:\n        agg_args[agg_fields] = agg_funcs\n    agg_columns = [(agg_field, agg_func)\n                       for agg_field in agg_fields\n                       for agg_func in agg_funcs]\n    agg_results = {}\n    df_group = df.groupby([keyfield]).agg(agg_args)\n    for value in list_of_values:\n        if not value in df_group.index:\n            for agg_column in agg_columns:\n                agg_results['_'.join([value,\n                                      agg_column[0],\n                                      agg_column[1]])] = 0\n        else:\n            for agg_column in agg_columns:\n                agg_results['_'.join([value,\n                                      agg_column[0],\n                                      agg_column[1]])] = df_group.loc[value, agg_column]\n    return agg_results","execution_count":null,"outputs":[]},{"metadata":{"id":"Lo2edlvOxvab","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def add_session_aggregate_columns(dataset, labels,\n                                  titles, types, worlds, \n                                  event_codes, title_codes, assessment_titles,\n                                  accuracy_groups, num_incorrect_classses\n                                  ):\n    # summrize each game_session appeared in train.csv\n    game_sessions = get_session_database(dataset, labels)\n    data = labels.set_index('game_session')\n    for gs in data.index:\n        data.loc[gs, 'session_start_time'] = game_sessions.loc[gs, 'session_start_time']\n        data.loc[gs, 'session_end_time'] = game_sessions.loc[gs, 'session_end_time']\n        past_session_ids = retrieve_past_sessions(game_sessions, gs)\n        if past_session_ids.shape[0] < 1:\n            data.loc[gs, 'first_session'] = True\n            continue\n        data.loc[gs, 'first_session'] = False\n        # count past game_sessions\n        past_data = game_sessions.loc[past_session_ids]\n        data.loc[gs, 'past_session_count'] = past_data.shape[0]\n        # aggregate time fields\n        data.loc[gs, 'duration_sum'] = past_data.duration.sum()\n        data.loc[gs, 'duration_max'] = past_data.duration.max()\n        data.loc[gs, 'duration_min'] = past_data.duration.min()\n        data.loc[gs, 'duration_mean'] = past_data.duration.mean()\n        data.loc[gs, 'duration_median'] = past_data.duration.median()\n        data.loc[gs, 'session_interval_sum'] = past_data.session_interval.sum()\n        data.loc[gs, 'session_interval_max'] = past_data.session_interval.max()\n        data.loc[gs, 'session_interval_min'] = past_data.session_interval.min()\n        data.loc[gs, 'session_interval_mean'] = past_data.session_interval.mean()\n        data.loc[gs, 'session_interval_median'] = past_data.session_interval.median()\n        # aggregate past attempts\n        data.loc[gs, 'num_attemmpts'] = past_data[past_data.title.isin(assessment_titles)].shape[0]\n        data.loc[gs, 'num_correct_sum'] = past_data.num_correct.sum()\n        data.loc[gs, 'num_incorrect_sum'] = past_data.num_incorrect.sum()\n        data.loc[gs, 'num_incorrect_mean'] = past_data.num_incorrect.mean()\n        data.loc[gs, 'num_incorrect_median'] = past_data.num_incorrect.median()\n        agg_by_assessment = agg_by_key(past_data,\n                                       'title',\n                                       assessment_titles,\n                                       agg_fields=['num_correct', 'num_incorrect'],\n                                       agg_funcs=['sum', 'count', 'median'])\n        for k, v in agg_by_assessment.items():\n            if k == 'count_num_incorrect':\n                continue\n            data.loc[gs, k] = v\n\n        agg_by_title = agg_by_key(past_data, 'title', titles)\n        for k, v in agg_by_title.items():\n            data.loc[gs, k] = v\n        \n        agg_by_type = agg_by_key(past_data, 'type', types)\n        for k, v in agg_by_type.items():\n            data.loc[gs, k] = v\n\n        agg_by_world = agg_by_key(past_data, 'world', worlds) \n        for k, v in agg_by_world.items():\n            data.loc[gs, k] = v\n\n        title_code_count_sum = past_data[title_codes].sum()\n        for col in title_codes:\n            data.loc[gs, col] = title_code_count_sum[col]\n\n        event_code_count_sum = past_data[event_codes].sum()\n        for col in event_codes:\n            data.loc[gs, col] = event_code_count_sum[col]\n\n        past_scores = past_data[past_data.type=='Assessment']\n        if past_scores.shape[0] < 0:\n            data.loc[gs, 'first_assessment'] = True\n            continue\n        data.loc[gs, 'first_assessment'] = False\n        for value in accuracy_groups:\n            past_scores2 = past_scores[past_scores.accuracy_group==value]\n            data.loc[gs, '_'.join(['accuracy_group', str(value), 'count'])] \\\n                    = past_scores2.shape[0]\n            for assess_title in assessment_titles:\n                data.loc[gs, '_'.join([assess_title, 'accuracy_group', str(value), 'count'])] \\\n                    = past_scores2[past_scores2.title==assess_title].shape[0]\n\n        for value in num_incorrect_classses:\n            past_scores2 = past_scores[past_scores.num_incorrect_class==value]\n            data.loc[gs, '_'.join(['num_incorrect_class', str(value), 'count'])] \\\n                    = past_scores2.shape[0]\n            for assess_title in assessment_titles:\n                data.loc[gs, '_'.join(\n                    [assess_title, 'num_incorrect_class', str(value), 'count'])] \\\n                            = past_scores2[past_scores2.title==assess_title].shape[0]\n\n    return data\n","execution_count":null,"outputs":[]},{"metadata":{"id":"788z55dor6ai","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def add_many_columns(features, columns_to_drop=None, corr_threshold=0.90):\n    \"\"\"\n    Drop columns unuseful for build ML model, in order to reduce dimension.\n    If unuseful column are given their name by columns_to_drop, they are dropped.\n    If not, unuseful columns are to be serched by following way;\n    1. accuracy will be dropped always. \n    2. Any numeric columns whose variance is 0.\n    3. When strong correlated pairs of numeric columns are found, the one whose column \n       index is bigger, will be dropped.\n    \"\"\"\n\n    # Add log columns for each numeric column.\n    for numeric_column in features.select_dtypes('number').columns:\n        if numeric_column in ('num_correct', 'num_incorrect', 'accuracy', 'accuracy_group'):\n            continue\n        features['ln_'+numeric_column] = features[numeric_column].apply(\n            lambda x: np.nan if x==0 else np.log(x))\n    # Explode datetime fields\n    # PBS KIDS Family Event At O'Neill Public Library\n    event_datetime = pd.to_datetime('2019-09-27 11:00:00')\n    for dt_column in features.select_dtypes('datetime').columns:\n        features[dt_column+'_before_event'] = features[dt_column].apply(\n            lambda x: 1 if x < event_datetime else 0\n        )\n        features[dt_column+'_month'] = features[dt_column].dt.month\n        features[dt_column+'_hour'] = features[dt_column].dt.hour\n        features[dt_column+'_year'] = features[dt_column].dt.year\n        features[dt_column+'_dayofweek'] = features[dt_column].dt.dayofweek\n        features[dt_column+'_dayofyear'] = features[dt_column].dt.dayofyear\n    # Drop unuseful columns\n    if not columns_to_drop:  # Search columns to drop\n        columns_to_drop = []\n        # Drop always\n        features.drop(columns='accuracy', inplace=True)\n        columns_to_drop.append('accuracy')\n        # Search and drop numeric columns whose variance is 0\n        zero_variances = []\n        for numeric_column in features.select_dtypes('number').columns:\n            if numeric_column in ('num_correct', 'num_incorrect', 'accuracy_group'):\n                continue\n            variance = features[numeric_column].var()\n            if variance==0 or np.isnan(variance):\n                zero_variances.append(numeric_column)\n        features.drop(columns=zero_variances, inplace=True)\n        columns_to_drop.extend(zero_variances)\n        # Search pairs of highly correlated columns and drop the one of them\n        corr_matrix = features.corr().fillna(0).abs()\n        indices = np.where(np.triu(corr_matrix, k=1) > corr_threshold)\n        highly_correlated = []\n        for col_index in list(set(indices[1])):\n            col_name = features.columns[col_index]\n            if col_name not in ('num_correct', 'num_incorrect', 'accuracy_group'):\n                highly_correlated.append(col_name)\n        features.drop(columns=highly_correlated, inplace=True)\n        columns_to_drop.extend(highly_correlated)\n    else:\n        features.drop(columns=columns_to_drop, inplace=True)\n\n    return(features, columns_to_drop)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"c2_kOq7LuO0K","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def qwk(y1, y2):\n    return cohen_kappa_score(y1, y2, weights='quadratic',labels=[0,1,2,3])","execution_count":null,"outputs":[]},{"metadata":{"id":"cm8w-ZAlvFoH","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Refference:\n# https://blog.amedama.jp/entry/lightgbm-custom-metric\n# (2020-01-19)\ndef evaluate_by_qwk(preds, train, n_labels=4):\n    y_actual = train.get_label().astype('int')  # label's original dtype is float !!\n    reshaped_preds = preds.reshape(n_labels, len(preds) // n_labels)\n    y_pred = np.argmax(reshaped_preds, axis=0)\n    # name, result, is_higher_better\n    return 'qwk', qwk(y_pred, y_actual), True","execution_count":null,"outputs":[]},{"metadata":{"id":"-kv2eGt9mH0f","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\ndef stratified_group_k_fold(X, y, groups, k, seed=None):\n    labels_num = np.max(y) + 1\n    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n    y_distr = Counter()\n    for label, g in zip(y, groups):\n        y_counts_per_group[g][label] += 1\n        y_distr[label] += 1\n\n    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n    groups_per_fold = defaultdict(set)\n\n    def eval_y_counts_per_fold(y_counts, fold):\n        y_counts_per_fold[fold] += y_counts\n        std_per_label = []\n        for label in range(labels_num):\n            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n            std_per_label.append(label_std)\n        y_counts_per_fold[fold] -= y_counts\n        return np.mean(std_per_label)\n    \n    groups_and_y_counts = list(y_counts_per_group.items())\n    random.Random(seed).shuffle(groups_and_y_counts)\n\n    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n        best_fold = None\n        min_eval = None\n        for i in range(k):\n            fold_eval = eval_y_counts_per_fold(y_counts, i)\n            if min_eval is None or fold_eval < min_eval:\n                min_eval = fold_eval\n                best_fold = i\n        y_counts_per_fold[best_fold] += y_counts\n        groups_per_fold[best_fold].add(g)\n\n    all_groups = set(groups)\n    for i in range(k):\n        train_groups = all_groups - groups_per_fold[i]\n        test_groups = groups_per_fold[i]\n\n        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n\n        yield train_indices, test_indices","execution_count":null,"outputs":[]},{"metadata":{"id":"d74ZSn-fxvad","colab_type":"code","outputId":"4686422d-3966-4c3a-c29e-46fcde48c51b","executionInfo":{"status":"ok","timestamp":1579537417695,"user_tz":-540,"elapsed":217,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":52},"trusted":true},"cell_type":"code","source":"%%time\ntrain_labels = read_train_labels()\ntrain_labels['num_incorrect_class'] = train_labels.apply(calc_num_incorrect_class, axis=1)\n\n# drop 'installation_id's which do not exist in labels.\ntrain = read_train_or_test()\ntrain = train[train.installation_id.isin(train_labels.installation_id.unique())]\ntrain['title_code'] = train.title.str.cat(train.event_code.astype(str), sep='-')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"viNZaS6Oj2pF","colab_type":"code","outputId":"fce8db48-ecd1-4be0-837a-83c51d2a1730","executionInfo":{"status":"ok","timestamp":1579537417697,"user_tz":-540,"elapsed":194,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":52},"trusted":true},"cell_type":"code","source":"%%time\ntest = read_train_or_test(train=False)\ntest['title_code'] = test.title.str.cat(test.event_code.astype(str), sep='-')\nnum_attempts = count_attempts(test)\ntest_labels = pd.merge(test.drop_duplicates(subset='game_session'), num_attempts.reset_index(), \n                       on='game_session')\ntest_labels['num_incorrect_class'] = test_labels.apply(calc_num_incorrect_class, axis=1)\ntest_labels['accuracy'] = test_labels.num_correct / (test_labels.num_correct \n                                                     + test_labels.num_incorrect)\ntest_labels['accuracy_group'] = test_labels.apply(calc_accuracy_group, axis=1)\ntest_labels = test_labels.loc[:, train_labels.columns]\n# Identify game seesions to be predicted its accuracy_group.\npred_targets = extract_targets(test)\npred_targets['num_correct'] = N_ATTEMPTS_DUMMY\npred_targets['num_incorrect'] = N_ATTEMPTS_DUMMY\npred_targets['accuracy'] = np.nan\npred_targets['accuracy_group'] = pred_targets.apply(calc_accuracy_group, axis=1)\npred_targets['num_incorrect_class'] = pred_targets.apply(calc_num_incorrect_class, axis=1)\ntest_labels = pd.concat([test_labels, pred_targets], sort=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"5rskGmAWoDrS","colab_type":"code","outputId":"cbbe9868-725d-4487-b614-e702854f854f","executionInfo":{"status":"ok","timestamp":1579537417697,"user_tz":-540,"elapsed":175,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":210},"trusted":true},"cell_type":"code","source":"display(test_labels.num_incorrect_class.value_counts())\ndisplay(test_labels.accuracy_group.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"b8o3AkXa3sYe","colab_type":"code","outputId":"4f5fa5a8-90dc-4bd2-972b-51f5c8441a9c","executionInfo":{"status":"ok","timestamp":1579537417698,"user_tz":-540,"elapsed":164,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":318},"trusted":true},"cell_type":"code","source":"%%time\nassessment_titles = list(\n    set(train_labels.title.tolist()) \n    and set(test_labels.title.tolist()))\naccuracy_groups = list(set(train_labels.accuracy_group.tolist()))\nnum_incorrect_classes = list(set(train_labels.num_incorrect_class.tolist()))\ntitles = list(\n    set(train.title.tolist()) \n    and set(test.title.tolist()))\ntypes = list(\n    set(train.type.tolist()) \n    and set(test.type.tolist()))\nworlds = list(\n    set(train.world.tolist()) \n    and set(test.world.tolist()))\ntrain_exclude_2000 = train[~(train.event_code==2000)]\ntest_exclude_2000 = test[~(test.event_code==2000)]\ntitle_codes = list(\n    set(train_exclude_2000.title_code.tolist())\n    and set(test_exclude_2000.title_code.tolist()))\nevent_codes = list(\n    set(train_exclude_2000.event_code.tolist())\n    and set(test_exclude_2000.event_code.tolist()))\nevent_codes = ['event_code_'+str(eve_cd) for eve_cd in event_codes]\nprint(f'\\naccuracy groups = {accuracy_groups}')\nprint(f'\\nnum_incorrect classses = {num_incorrect_classes}')\nprint(f'\\ntitles = {titles}')\nprint(f'\\ntypes = {types}')\nprint(f'\\nworlds = {worlds}')\nprint(f'\\ntitle_codes = {title_codes}')\nprint(f'\\nevent_codes = {event_codes}')\ndel train_exclude_2000, test_exclude_2000\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"h9h3e6S-zDAz","colab_type":"code","outputId":"8214c218-1a2f-4723-9e0d-9f86fbc5c997","executionInfo":{"status":"ok","timestamp":1579537417699,"user_tz":-540,"elapsed":145,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":70},"trusted":true},"cell_type":"code","source":"%%time\nif os.path.isfile(PATH_TRAIN_FEATURES):\n    print(f'{PATH_TRAIN_FEATURES} has been found')\n    features_train = pd.read_csv(PATH_TRAIN_FEATURES,\n                                 parse_dates=['session_start_time', 'session_end_time'])\n    dropped_columns = pd.read_csv(PATH_DROPPED_COLUMNS)\nelse:\n    print(f'{PATH_TRAIN_FEATURES} has not been found')\n    features_train = add_session_aggregate_columns(train, train_labels, \n                                                   titles, types, worlds, \n                                                   event_codes, title_codes, assessment_titles, \n                                                   accuracy_groups, num_incorrect_classes)\n    features_train = features_train.reset_index()\n    features_train.fillna(0, inplace=True)\n    features_train, columns_to_drop = add_many_columns(features_train)\n    features_train.to_csv(PATH_TRAIN_FEATURES, index=False)\n    pd.DataFrame({'droppd_column':columns_to_drop}).to_csv(PATH_DROPPED_COLUMNS, index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"HbgTrZ6CsWwM","colab_type":"code","outputId":"de9836e4-091d-4204-aaf4-f0fefdc098b8","executionInfo":{"status":"ok","timestamp":1579537417699,"user_tz":-540,"elapsed":129,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":87},"trusted":true},"cell_type":"code","source":"%%time\n# Quick test\ntest_features_exists = os.path.isfile(PATH_TEST_FEATURES)\ntest_features_exists = False  # Uncomment when commit and submission\nif test_features_exists:\n    print(f'{PATH_TEST_FEATURES} has been found')\n    features_test = pd.read_csv(PATH_TEST_FEATURES,\n                                parse_dates=['session_start_time', 'session_end_time'])\nelse:\n    print(f'{PATH_TEST_FEATURES} has not been found')\n    features_test = add_session_aggregate_columns(test, test_labels, \n                                                  titles, types, worlds, \n                                                  event_codes, title_codes, assessment_titles, \n                                                  accuracy_groups, num_incorrect_classes)\n    features_test = features_test.reset_index()\n    features_test.fillna(0, inplace=True)\n    features_test, columns_to_drop = add_many_columns(\n        features_test, columns_to_drop=dropped_columns.droppd_column.tolist()\n        )\n    features_test.to_csv(PATH_TEST_FEATURES, index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"s5YuqDXl5U3l","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# separate test set and prediction target set\nfeatures_target = features_test[features_test.game_session.isin(pred_targets.game_session)]\nfeatures_test = features_test[~(features_test.game_session.isin(pred_targets.game_session))]","execution_count":null,"outputs":[]},{"metadata":{"id":"NwVk9vfx4Npx","colab_type":"code","outputId":"368357a4-8c51-48ca-a155-fa5508b85fe4","executionInfo":{"status":"ok","timestamp":1579537417700,"user_tz":-540,"elapsed":112,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":70},"trusted":true},"cell_type":"code","source":"print(f'shape of features in training set is {features_train.shape}')\nprint(f'shape of features in test set is {features_test.shape}')\nprint(f'shape of features in prediction target set is {features_target.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"KehvvjOUI-9B","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Impute null values for numeric columns.\n# If numeric column has null value and that column is natural log of other numeric column \n# ('column name start with 'ln_*'), inpute the minimum value of that column.\n# If numeric column has null value and that column is NOT natural log type, impute 0.\nfor df in (features_train, features_test, features_target):\n    for column in df.select_dtypes('number').columns:\n        if df[column].isnull().sum() > 0:\n            if column[0:3] == 'ln_':\n                impute_value = df[column].min()\n            else:\n                impute_value = 0\n            df[column].fillna(impute_value, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"f6h3q4HsAMcJ","colab_type":"code","outputId":"df9c2f72-e5d6-456f-f6f7-87a5587d9ddc","executionInfo":{"status":"ok","timestamp":1579537417701,"user_tz":-540,"elapsed":89,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"sorted(features_train.dtypes.tolist()) == sorted(features_test.dtypes.tolist())","execution_count":null,"outputs":[]},{"metadata":{"id":"QZxmdmvQBwvx","colab_type":"code","outputId":"2c0bb917-df65-4235-942a-a105eec24fac","executionInfo":{"status":"ok","timestamp":1579537417703,"user_tz":-540,"elapsed":73,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"sorted(features_train.dtypes.tolist()) == sorted(features_target.dtypes.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train, test, train_labels, test_labels\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"IdZ-Lhi5QlPX","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# def classifyByLinearSVC(train, test, pred_target,\n#                         reduce_demension_by_pca = True,\n#                         random_states=LUCKY_NUMBERS,\n#                         unuseful_columns = ['game_session', \n#                                             'installation_id', \n#                                             'num_incorrect_class', \n#                                             'first_assessment',\n#                                             'session_start_time',\n#                                             'session_end_time',\n#                                             'num_correct',\n#                                             'num_incorrect'\n#                                             ]):\n    \n#     def transform_features(X_train, X_test, reduce_demension_by_pca,\n#                            base_assessment_title='Cauldron Filler (Assessment)',\n#                            ):\n#         # Create scaler\n#         scaler = RobustScaler()\n#         scaler.fit(X_train.select_dtypes('number'))\n#         # Transform train set\n#         # -- scale numeric columns\n#         X_train_transformed = pd.DataFrame(\n#             scaler.transform(X_train.select_dtypes('number')),\n#             columns = X_train.select_dtypes('number').columns)   \n#         # -- explode non-numeric columns to dummy fields\n#         X_train_dummies = pd.get_dummies(X_train.select_dtypes('object')).reset_index(drop=True)\n#         drop_dummy_column = 'title_'+base_assessment_title\n#         if drop_dummy_column in X_train_dummies.columns.tolist():\n#             X_train_dummies.drop(columns=drop_dummy_column, inplace=True)\n#         X_train_transformed = X_train_transformed.join(X_train_dummies)\n#         # Transform test set\n#         X_test_transformed = pd.DataFrame(\n#             scaler.transform(X_test.select_dtypes('number')),\n#             columns = X_test.select_dtypes('number').columns)\n#         X_test_dummies = pd.get_dummies(X_test.select_dtypes('object')).reset_index(drop=True)      \n#         if drop_dummy_column in X_test_dummies.columns.tolist():\n#             X_test_dummies.drop(columns=drop_dummy_column, inplace=True)\n#         X_test_transformed = X_test_transformed.join(X_test_dummies)\n#         # reduce demension\n#         if reduce_demension_by_pca:\n#             pca = PCA(n_components=0.90, svd_solver='full')\n#             X_train_transformed = pca.fit_transform(X_train_transformed)\n#             X_test_transformed = pca.transform(X_test_transformed)\n#         else:\n#             pca = None\n#         return X_train_transformed, X_test_transformed, pca\n    \n#     # Cross validation\n#     groups = train.installation_id\n#     folds = 5\n#     # Separate features and targets\n#     # -- train set\n#     train = train.drop(columns=unuseful_columns)\n#     X_train = train.drop(columns='accuracy_group')\n#     y_train = train.loc[:, 'accuracy_group']\n#     # -- test set (used for scoring model's performance)\n#     test = test.drop(columns=unuseful_columns)\n#     X_test = train.drop(columns='accuracy_group')\n#     y_test = train.loc[:, 'accuracy_group']\n#     # -- prediction target\n#     pred_target = pred_target.drop(columns=unuseful_columns)\n#     X_target = pred_target.drop(columns='accuracy_group')\n#     # Grid search parameters\n#     grid_params = [\n#         (penalty, loss, c, random_state) \n#             for penalty in ['l2']\n#             for loss in ['hinge', 'squared_hinge']\n#             for c in [i/10 for i in range(1, 11)]\n#             for random_state in random_states]\n#     iteration, best_iteration, best_score= 0, 0, -1\n#     for params in grid_params:\n#         print(f'---------- Grid search iteration {iteration} ----------')\n#         print(params)\n#         qwk_scores = []\n#         for idx_dev, idx_valid in stratified_group_k_fold(X_train, y_train, \n#                                                           groups, folds, seed=42):\n#             X_dev = X_train.iloc[idx_dev, :]\n#             y_dev = y_train.iloc[idx_dev]\n#             X_valid = X_train.iloc[idx_valid, :]\n#             y_valid = y_train.iloc[idx_valid]           \n            \n#             # transform features\n#             X_dev_transformed, X_valid_transformed, pca = transform_features(\n#                 X_dev, X_valid, reduce_demension_by_pca\n#             )\n#             linearsvc = LinearSVC(penalty = params[0], \n#                                   loss = params[1], \n#                                   C=params[2], \n#                                   random_state=params[3],\n#                                   max_iter = 5000\n#             )\n#             linearsvc.fit(X_dev_transformed, y_dev)\n#             y_pred = linearsvc.predict(X_valid_transformed)\n#             qwk_score = qwk(y_valid, y_pred)\n#             print(f'QWK = {qwk_score}')\n#             qwk_scores.append(qwk_score)\n#         # Scoring this grid search results\n#         print(f'---------- End of iteration {iteration} ----------')\n#         score = sum(qwk_scores) / len(qwk_scores)\n#         if score > best_score:\n#             print(f'Update best score: {best_score} --> {score}')\n#             best_iteration = iteration\n#             best_score = score\n#         else:\n#             print(f'No update in this iteration, socre: {score}')\n#         iteration = iteration + 1\n#     # Refit using all train set with best parameters\n#     scaler = StandardScaler()\n#     scaler.fit(X_train.select_dtypes('number'))\n#     X_train_transformed, X_test_transformed, pca = transform_features(\n#         X_train, X_test, reduce_demension_by_pca\n#         )\n#     best_params = grid_params[best_iteration]\n#     linearsvc = LinearSVC(penalty = best_params[0], \n#                           loss = best_params[1], \n#                           C=best_params[2], \n#                           random_state=best_params[3],\n#                           max_iter = 5000)\n#     linearsvc.fit(X_train_transformed, y_train)\n#     y_pred_test = linearsvc.predict(X_test_transformed)\n#     qwk_score = qwk(y_vaild, y_pred_test)\n#     # Prediction\n#     X_train_transformed, X_target_transformed, pca = transform_features(\n#         X_train, X_target, reduce_demension_by_pca\n#         )\n#     y_pred = linearsvc.predict(X_target_transformed)\n#     results = {\n#         'model':linersvc, \n#         'prediction':y_pred,\n#         'qwk':qwk_score,\n#         'y_pred_test':y_pred_test,\n#         'best_params':best_params,\n#         'pca':pca\n#     }\n#     return results\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classifyBylightGBM(train, test, pred_target, grid_params,\n                       useful_columns,\n                       random_states=LUCKY_NUMBERS):\n    # Cross validation\n    groups = train.installation_id\n    folds = 5\n    # Separate features and targets\n    y_train = train.accuracy_group\n    X_train = train.loc[:,useful_columns]\n    y_test = test.accuracy_group\n    X_test = test.loc[:,useful_columns]\n    X_target = pred_target.loc[:,useful_columns]\n    # Converte category\n    le = LabelEncoder()\n    X_train.title = le.fit_transform(X_train.title)\n    X_test.title = le.transform(X_test.title)\n    X_target.title = le.transform(X_target.title)\n    # Rename columns to avoid following error\n    # LightGBMError: Do not support special JSON characters in feature name.\n    X_train.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in X_train]\n    X_test.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in X_test]\n    X_target.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in X_target]\n    # Grid search parameters\n    iteration, best_iteration, best_score= 0, 0, -9999999999\n    for params in grid_params:\n        print(f'---------- Grid search iteration {iteration} ----------')\n        print(params)\n        qwk_scores = []\n        for idx_dev, idx_valid in stratified_group_k_fold(X_train, y_train, \n                                                          groups, folds, seed=42):\n            X_dev = X_train.iloc[idx_dev, :]\n            y_dev = y_train.iloc[idx_dev]\n            X_valid = X_train.iloc[idx_valid, :]\n            y_valid = y_train.iloc[idx_valid]           \n            lgb_dev = lgb.Dataset(X_dev, y_dev)\n            lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_dev)\n            evals_result = {}\n            model = lgb.train(params,\n                              lgb_dev,\n                              num_boost_round=10000,\n                              early_stopping_rounds=50,\n                              valid_sets=[lgb_valid, lgb_dev],\n                              valid_names=['valid', 'dev'],\n                              evals_result=evals_result,\n                              feval=evaluate_by_qwk\n                             )\n            \n            y_pred_proba = model.predict(X_valid, num_iteration=model.best_iteration)\n            y_pred = np.argmax(y_pred_proba, axis=1)\n            qwk_score = qwk(y_pred, np.array(y_valid))\n            print(f'QWK = {qwk_score}')\n            qwk_scores.append(qwk_score)\n        # Scoring this grid search results\n        print(f'---------- End of iteration {iteration} ----------')\n        score = sum(qwk_scores) / len(qwk_scores)\n        if score > best_score:\n            print(f'Update best score: {best_score} --> {score}')\n            best_iteration = iteration\n            best_score = score\n        else:\n            print(f'No update in this iteration, socre: {score}')\n        iteration = iteration + 1\n        \n    # Refit using all train set with best parameters\n    best_params = grid_params[best_iteration]\n    print(f'best hyper parameter set is {best_params}')\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)\n    \n    evals_result = {}\n    model = lgb.train(best_params,\n                      lgb_train,\n                      num_boost_round=10000,\n                      early_stopping_rounds=50,\n                      valid_sets=[lgb_test, lgb_train],\n                      valid_names=['test', 'train'],\n                      feval=evaluate_by_qwk)\n    y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)\n    y_pred = np.argmax(y_pred_proba, axis=0)\n    try:\n        qwk_score = qwk(y_pred, np.array(y_test))\n    except:\n        qwk_score = -1\n    print(f'QWK = {qwk_score}')\n    y_pred_proba = model.predict(X_target, num_iteration=model.best_iteration)\n    y_pred = np.argmax(y_pred_proba, axis=1)\n    results = {\n        'model':model, \n        'prediction':y_pred,\n        'qwk':qwk_score,\n        'best_params':best_params\n    }\n    return results","execution_count":null,"outputs":[]},{"metadata":{"id":"pqTH5aA0s87Z","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# def rankFeatureImportancesByRandomForest(train, test, \n#                                          unuseful_columns=['game_session', \n#                                                            'installation_id', \n#                                                            'num_incorrect_class', \n#                                                            'first_assessment',\n#                                                            'session_start_time',\n#                                                            'session_end_time',\n#                                                            'num_correct',\n#                                                            'num_incorrect'],\n#                                          use_ln_and_base = 'both'  # 'both', 'ln_only', 'drop_ln' \n#                                          ):\n#     # Preprocessing\n#     le = LabelEncoder()\n#     train.title = le.fit_transform(train.title)\n#     test.title = le.transform(test.title)\n#     y_train = train.accuracy_group\n#     X_train = train.drop(columns=unuseful_columns)\n#     X_train = X_train.drop(columns='accuracy_group')\n#     y_test = test.accuracy_group\n#     X_test = test.drop(columns=unuseful_columns)\n#     X_test = X_test.drop(columns='accuracy_group')\n#     # Select columns to be ranked its importance\n#     if use_ln_and_base == 'both':\n#         pass\n#     elif use_ln_and_base == 'ln_only':\n#         for column in X_train.columns:\n#             if column[0:3] == 'ln_':\n#                 if column[3:] in X_train.columns.tolist():  # sometimes dropped already\n#                     X_train = X_train.drop(columns=column[3:])\n#                     X_test = X_test.drop(columns=column[3:])\n#     elif use_ln_and_base == 'drop_ln':\n#         for column in X_train.columns:      \n#             if column[0:3] == 'ln_':\n#                 X_train = X_train.drop(columns=column)\n#                 X_test = X_test.drop(columns=column)\n#     else:\n#         raise ValueError()\n#     # Number of trees in random forest\n#     n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 20)]\n#     # Maximum number of levels in tree\n#     max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n#     max_depth.append(None)\n#     # Minimum number of samples required to split a node\n#     min_samples_split = [8, 16, 32]\n#     # Minimum number of samples required at each leaf node\n#     min_samples_leaf = [2, 4, 6]\n#     # Method of selecting samples for training each tree\n#     bootstrap = [True, False]\n#     # Create the random grid\n#     random_grid = {'n_estimators': n_estimators,\n#                    'max_depth': max_depth,\n#                    'min_samples_split': min_samples_split,\n#                    'min_samples_leaf': min_samples_leaf,\n#                    'bootstrap': bootstrap}\n#     clf = RandomForestClassifier()\n#     rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n#                                    n_iter = 100, cv = 3, verbose=1, random_state=42, \n#                                    n_jobs = -1, refit=True)\n#     # Fit the random search model\n#     rf_random.fit(X_train, y_train)\n#     model = rf_random.best_estimator_\n#     y_pred_train = model.predict(X_train)\n#     y_pred_test = model.predict(X_test)\n#     print(f'QWK: Train set={qwk(y_train, y_pred_train)}, Test set={qwk(y_test, y_pred_test)}')\n#     importances = pd.DataFrame(data=model.feature_importances_)\n#     importances['feature'] = X_train.columns.tolist()\n#     importances.columns = ['score', 'feature']\n#     importances.score = 1000 * importances.score\n#     importances['ranking'] = importances.score.rank(ascending=False)\n#     return importances","execution_count":null,"outputs":[]},{"metadata":{"id":"Nw6gFovSs_CO","colab_type":"code","outputId":"6da39516-2412-434b-c391-00c4d708bd49","executionInfo":{"status":"ok","timestamp":1579536784823,"user_tz":-540,"elapsed":35,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"trusted":true},"cell_type":"code","source":"# %%time\n# ranking = rankFeatureImportancesByRandomForest(features_train, features_test)\n# ranking.to_csv('./work/feature_importances_all.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"X8A2FxrjtBlb","colab_type":"code","outputId":"72b73a18-48ca-4c36-9286-993da687fe07","executionInfo":{"status":"ok","timestamp":1579536784823,"user_tz":-540,"elapsed":26,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":122},"trusted":true},"cell_type":"code","source":"# %%time\n# ranking = rankFeatureImportancesByRandomForest(features_train, features_test, use_ln_and_base='ln_only')\n# ranking.to_csv('./work/feature_importances_ln_only.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"zutbgHHptDil","colab_type":"code","outputId":"4efbb748-a4d8-4945-a9e5-c3c7e59bd9bf","executionInfo":{"status":"ok","timestamp":1579536817712,"user_tz":-540,"elapsed":32905,"user":{"displayName":"Tomoki Kubota","photoUrl":"","userId":"15534886521571433432"}},"colab":{"base_uri":"https://localhost:8080/","height":122},"trusted":true},"cell_type":"code","source":"# %%time\n# rankFeatureImportancesByRandomForest(features_train, features_test, use_ln_and_base='drop_ln')\n# ranking.to_csv('./work/feature_importances_drop_ln.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances_all = pd.read_csv(PATH_FEATURE_IMPORTANCES_ALL)\nimportances_drop_ln = pd.read_csv(PATH_FEATURE_IMPORTANCES_LN_ONLY)\nimportances_no_ln = pd.read_csv(PATH_FEATURE_IMPORTANCES_DROP_LN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances_all.sort_values('ranking')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances_drop_ln.sort_values('ranking')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances_no_ln.sort_values('ranking')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"might_be_important_01 = importances_all[importances_all.score>=2.00].feature\nmight_be_important_02 = importances_drop_ln[importances_drop_ln.score>=2.00].feature\nmight_be_important_03 = importances_no_ln[importances_no_ln.score>=2.00].feature\n# probably_imporant_features = list(\n#     set(might_be_important_01.tolist())\n#     & set(might_be_important_02.tolist())\n#     & set(might_be_important_03.tolist())\n# )\nprobably_imporant_features = importances_all[importances_all.score>=3.00].feature\nprint(f'Use {len(probably_imporant_features)} features')\nprint(sorted(probably_imporant_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_params = [\n    {'max_depth':md, 'min_data_in_leaf':mdil, 'num_leaves':nl, 'reg_alpha':ra,\n     'objective': 'multiclass', 'num_class': 4, 'verbosity': -1}\n        for md in [5, 6, 7, 8]\n        for mdil in [25, 50, 75]\n        for nl in [int(0.7 * 2**5), int(0.7 * 2**6), int(0.7 * 2**7), int(0.7 * 2**8)]\n        for ra in [0.1, 0.3, 0.5]\n]\nfor param in grid_params:\n    print(param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.externals import joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = classifyBylightGBM(features_train, features_test, features_target,\n                             grid_params, probably_imporant_features)\n\n# Content in results (dictionary)\n#         'model':lgb, \n#         'prediction':y_pred,\n#         'qwk':qwk_score,\n#         'y_pred_test':y_pred_test,\n#         'best_params':best_params,\nlightgbm = results['model']\njoblib.dump(lightgbm, 'lightgbm.pkl', compress=True)\nfeatures_target['prediction'] = results['prediction']\nsubmission = pd.merge(pred_targets, \n                      features_target.loc[:, ['installation_id', 'prediction']])\nsubmission = submission.loc[:, ['installation_id', 'prediction']]\nsubmission.columns = ['installation_id', 'accuracy_group']\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(results['best_params'])\ndisplay(submission.accuracy_group.value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"id":"cDOOEr_UvUf9","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# def classifyByKNN(train, test, pred_target, useful_features,\n#                   reduce_demension_by_pca = True,\n#                   random_states=LUCKY_NUMBERS):\n    \n#     def transform_features(X_train, X_test, reduce_demension_by_pca,\n#                            base_assessment_title='Cauldron Filler (Assessment)',\n#                            ):\n#         # Create scaler\n#         scaler = RobustScaler()\n#         scaler.fit(X_train.select_dtypes('number'))\n#         # Transform train set\n#         # -- scale numeric columns\n#         X_train_transformed = pd.DataFrame(\n#             scaler.transform(X_train.select_dtypes('number')),\n#             columns = X_train.select_dtypes('number').columns)   \n#         # -- explode non-numeric columns to dummy fields\n#         X_train_dummies = pd.get_dummies(X_train.select_dtypes('object')).reset_index(drop=True)\n#         drop_dummy_column = 'title_'+base_assessment_title\n#         if drop_dummy_column in X_train_dummies.columns.tolist():\n#             X_train_dummies.drop(columns=drop_dummy_column, inplace=True)\n#         X_train_transformed = X_train_transformed.join(X_train_dummies)\n#         # Transform test set\n#         X_test_transformed = pd.DataFrame(\n#             scaler.transform(X_test.select_dtypes('number')),\n#             columns = X_test.select_dtypes('number').columns)\n#         X_test_dummies = pd.get_dummies(X_test.select_dtypes('object')).reset_index(drop=True)      \n#         if drop_dummy_column in X_test_dummies.columns.tolist():\n#             X_test_dummies.drop(columns=drop_dummy_column, inplace=True)\n#         X_test_transformed = X_test_transformed.join(X_test_dummies)\n#         # reduce demension\n#         if reduce_demension_by_pca:\n#             pca = PCA(n_components=0.90, svd_solver='full')\n#             X_train_transformed = pca.fit_transform(X_train_transformed)\n#             X_test_transformed = pca.transform(X_test_transformed)\n#         else:\n#             pca = None\n#         return X_train_transformed, X_test_transformed, pca\n    \n#     # Cross validation\n#     groups = train.installation_id\n#     folds = 5\n#     # Separate features and targets\n#     train = train.drop(columns=unuseful_columns)\n#     X_train = train.loc[:, useful_columns]\n#     y_train = train.loc[:, 'accuracy_group']\n#     X_test = train.loc[:, useful_columns]\n#     y_test = train.loc[:, 'accuracy_group']\n#     # -- prediction target\n#     X_target = pred_target.loc[:, useful_columns]\n    \n#     le = LabelEncoder()\n#     X_train = le.fit_transform(X_train)\n#     X_test = le.transform(X_test)\n#     X_target = le.transform(X_target)\n\n#     # Grid search parameters\n#     grid_params = [k for k in range (3,11)]\n#     iteration, best_iteration, best_score= 0, 0, -1\n#     for params in grid_params:\n#         print(f'---------- Grid search iteration {iteration} ----------')\n#         print(params)\n#         qwk_scores = []\n#         for idx_dev, idx_valid in stratified_group_k_fold(X_train, y_train, \n#                                                           groups, folds, seed=42):\n#             X_dev = X_train.iloc[idx_dev, :]\n#             y_dev = y_train.iloc[idx_dev]\n#             X_valid = X_train.iloc[idx_valid, :]\n#             y_valid = y_train.iloc[idx_valid]           \n            \n#             # transform features\n#             X_dev_transformed, X_valid_transformed, pca = transform_features(\n#                 X_dev, X_valid, reduce_demension_by_pca\n#             )\n#             linearsvc = KNeighborsClassifier(n_neighbors=params)\n#             linearsvc.fit(X_dev_transformed, y_dev)\n#             y_pred = linearsvc.predict(X_valid_transformed)\n#             qwk_score = qwk(y_valid, y_pred)\n#             print(f'QWK = {qwk_score}')\n#             qwk_scores.append(qwk_score)\n#         # Scoring this grid search results\n#         print(f'---------- End of iteration {iteration} ----------')\n#         score = sum(qwk_scores) / len(qwk_scores)\n#         if score > best_score:\n#             print(f'Update best score: {best_score} --> {score}')\n#             best_iteration = iteration\n#             best_score = score\n#         else:\n#             print(f'No update in this iteration, socre: {score}')\n#         iteration = iteration + 1\n#     # Refit using all train set with best parameters\n#     scaler = StandardScaler()\n#     scaler.fit(X_train.select_dtypes('number'))\n#     X_train_transformed, X_test_transformed, pca = transform_features(\n#         X_train, X_test, reduce_demension_by_pca\n#         )\n#     best_params = grid_params[best_iteration]\n#     linearsvc = KNeighborsClassifier(n_neighbors=best_params)\n#     linearsvc.fit(X_train_transformed, y_train)\n#     y_pred_test = linearsvc.predict(X_test_transformed)\n#     qwk_score = qwk(y_vaild, y_pred_test)\n#     # Prediction\n#     X_train_transformed, X_target_transformed, pca = transform_features(\n#         X_train, X_target, reduce_demension_by_pca\n#         )\n#     y_pred = linearsvc.predict(X_target_transformed)\n#     results = {\n#         'model':linersvc, \n#         'prediction':y_pred,\n#         'qwk':qwk_score,\n#         'y_pred_test':y_pred_test,\n#         'best_params':best_params,\n#         'pca':pca\n#     }\n#     return results\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"Add possible features and training.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":1}