{"cells":[{"metadata":{},"cell_type":"markdown","source":"1.特徴量の作成  \n  1. `game_session` 毎の集計データを作成。例として以下のような項目を集計。  \n    - プレイ時間等の連続変数（平均、最大といった基本的な集計）。  \n    - `title`, `world`, `type` といった `game_session` 毎に1つだけの値を持つカテゴリ変数  \n      - 加えて `type` = 'Assessment' （つまり Assessment 受講）に関してはその時のスコアも集計する  \n    - 'title` と `event_code' の組み合わせといった1つの `game_session` で様々な値を持つカテゴリ変数  \n    \n  2. Assessment を1度以上受講しているユーザ (≈`installation_id` を期待） に対して、受講より過去の 'game_session' の集計値より特徴量を作成する。  \n    - 連続変数に対して移動平均値、中央値、最大値、etc...  \n      - 上記に関しては更に `title` や `world` といったカテゴリ変数別の集計項目も追加。`title` = XXX に対するプレイ時間の合計とか。  \n      - Assessment の受講履歴は `title` 別に正解／不正解、不正解のカテゴリ（独自に追加、\"No error\" \"1 error\" \"2 errors or more\" みたいに）を作成、カテゴリ別でも正解／不正解の集計    \n    - 連続変数系の特徴量に関しては、それらの自然対数の特徴量も追加  \n      - 0 は np.nan になり厄介なので最小値で補正。  \n      \n  3. 不要な特徴量を削る  \n    - 1000個を超える特徴量が出来てしまったが「分散0」みたいなゴミは除外。  \n    - 相関係数が高いペアが居る連続変数は片方を削除。それでも750くらい残った。  \n    - この時点で残り時間が少ない！適当に RandomForestClassifer を使い、`feature_importance` が一定値以上の特徴量を全部突っ込む、という荒っぽいやり方で妥協。  \n\n2. モデリング  \n  1. 使用するアルゴリズム  \n    - 最終的には LightGBM.   \n    - SVC, K-Neighbor も少し試したが、時間の制約で深く試せない。  \n  2. 工夫：過学習だけは防ぎたい！  \n    - train.csv より作成した特徴量に対して 5-hold Stratified-Group K-hold.  \n      - 教師ラベルで Stratified し`installation_id` で Group.  \n      - ある `installation_id` が訓練データと検証データの両方に登場すると Cross Validation のスコアが過大評価されるのでは？と懸念した。  \n      - Stratified-Group K-hold のコードはコピペで拝借（先人に感謝）。  \n    - test.csv より複数回 Assessment を受講した `installation_id` を抽出。その人たちのデータをテストデータに使用してモデルのフィット感を試した。  \n\n3. 個人的な反省  \n  - 特徴量エンジニアリングにもっと時間を割きたかった\n  - submit エラー多すぎて無駄が多い（1回数時間要するsubmitを15回、成功は6回だけ、データ分析どうこう以前の問題）\n  - 純粋にコーディングの生産性が低い（やりたい事の量＞（あまりに高い壁）＞出来る事の量）\n  - フルスクラッチにこだわり過ぎた\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}