{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this competition from Kaggle\n\nIn this dataset, you are provided with game analytics for the PBS KIDS Measure Up! app. In this app, children navigate a map and complete various levels, which may be activities, video clips, games, or assessments. Each assessment is designed to test a child's comprehension of a certain set of measurement-related skills. There are five assessments: Bird Measurer, Cart Balancer, Cauldron Filler, Chest Sorter, and Mushroom Sorter.\n\nThe intent of the competition is to use the gameplay data to forecast how many attempts a child will take to pass a given assessment (an incorrect answer is counted as an attempt). Each application install is represented by an installation_id. This will typically correspond to one child, but you should expect noise from issues such as shared devices. In the training set, you are provided the full history of gameplay data. In the test set, we have truncated the history after the start event of a single assessment, chosen randomly, for which you must predict the number of attempts. Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment.\n\nThe outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data):\n\n3: the assessment was solved on the first attempt\n2: the assessment was solved on the second attempt\n1: the assessment was solved after 3 or more attempts\n0: the assessment was never solved\n\nThe file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set. Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110. If the attempt was correct, it contains \"correct\":true."},{"metadata":{},"cell_type":"markdown","source":"### Inspiration / References for this piece:\n\nErik Bruin's extensive EDA and baseline kernel [https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline](http://) \n\nGabriel Preda's detailed data exploration plots https://www.kaggle.com/gpreda/2019-data-science-bowl-eda#Data-exploration\n\nGuillaume Martin's memory reduction function in this kernel - https://www.kaggle.com/gemartin/load-data-reduce-memory-usage. "},{"metadata":{},"cell_type":"markdown","source":"We start by importing the necessary libraries "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import VarianceThreshold\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data input\n\nReading all the data files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntrain_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')\nspecs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\nsample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Important to note that the files have taken 1 min 20s to be read. As Kaggle points out this is a synchronous rerun code competition and the private test set has approximately 8MM rows. We should be mindful of memory in your notebooks to avoid submission errors.\n\n# Data Formatting"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 11 features and 11 million rows in the train data \nFrom Kaggle, these are the main data files which contain the gameplay events.\n\n* event_id - Randomly generated unique identifier for the event type. Maps to event_id column in specs table.\n* game_session - Randomly generated unique identifier grouping events within a single game or video play session.\n* timestamp - Client-generated datetime\n* event_data - Semi-structured JSON formatted string containing the events parameters. Default fields are: event_count, event_code, and game_time; otherwise fields are determined by the event type.\n* installation_id - Randomly generated unique identifier grouping game sessions within a single installed application instance.\n* event_count - Incremental counter of events within a game session (offset at 1). Extracted from event_data.\n* event_code - Identifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from event_data.\n* game_time - Time in milliseconds since the start of the game session. Extracted from event_data.\n* title - Title of the game or video.\n* type - Media type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'.\n* world - The section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length/Height), 'MAGMAPEAK' (Capacity/Displacement), 'CRYSTALCAVES' (Weight)."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The test data also contains around 11 million rows and the same 11 features"},{"metadata":{},"cell_type":"markdown","source":"As Kaggle mentioned that only assessments are used in the testing criteria, it makes no sense to retain installation ids that do not contain an assessment"},{"metadata":{"trusted":true},"cell_type":"code","source":"assessed_only = train[train.type == 'Assessment'].drop_duplicates(subset='installation_id')[['installation_id']]\ntrain = train[train.installation_id.isin(assessed_only['installation_id'])]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This has reduced the train data to 8 million rows. \n\nTo understand how the data comes together, we will see if there are any common installation ids in the test and train "},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(train.installation_id.unique()) & (set(test.installation_id.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok that's good this means kids (or kids sharing devices with the same installation_id) that are in the train are not present in the test. \nWhat about game session? Are there any common values in train and test?"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(train.game_session.unique()) & (set(test.game_session.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"None, again. How about event_ids?"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(train.event_id.unique()) & (set(test.event_id.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We understand that event_ids are randomly generated identifiers for event type. To understand what events are we can look into the specs data from which the identifier maps the event related info"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_colwidth = 150\nspecs.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, so these are all events triggered within the app. Some examples include:\n* When the player hovers mouse over an interactive object\n* When the player clicks on the help button\n* When the player picks a mushroom in the resource area\n\nTherefore it makes sense that there are 365 events that are common to both train and test. Further more, Kaggle also defines the variable in the specs.csv\n\n* event_id - Global unique identifier for the event type. Joins to event_id column in events table.\n* info - Description of the event.\n* args - JSON formatted string of event arguments. Each argument contains:\n* name - Argument name.\n* type - Type of the argument (string, int, number, object, array).\n* info - Description of the argument.\n\nBefore getting into the data analysis part, we need to beware of memory usage.\nI found a memory reduction function in this kernel - https://www.kaggle.com/gemartin/load-data-reduce-memory-usage. All credits go to Guillaume Martin."},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype.name\n\n        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_mem_usage(specs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_mem_usage(train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration \n\nPlotting event code by row counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\n\nsns.countplot(x='event_code',data=train, palette = 'Blues_d',\n              order = train['event_code'].value_counts().index).set_title('Count by Event Code - Train')\nplt.xticks(rotation=90,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\n\nsns.countplot(x='event_code',data=test, palette = 'Blues_d',\n              order = test['event_code'].value_counts().index).set_title('Count by Event Code - Test')\nplt.xticks(rotation=90,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The event code is heavily skewed. This will cause us problems when making them dummy variables. We will deal with them later.\n\nWe also notice another field event_count, can we find out which event code has the highest event counts?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('event_code')[['event_count']].agg('sum').sort_values(by = 'event_count',ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Event 4070 seems to have the highest event count. What about the test data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.groupby('event_code')[['event_count']].agg('sum').sort_values(by = 'event_count',ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok that's more or less similar. Let's now look at the train labels data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So this data contains our target variable - the accuracy group.\n\nKaggle mentions that this file demonstrates how to compute the ground truth for the assessments in the training set."},{"metadata":{},"cell_type":"markdown","source":"We can also take out installation_ids that don't have the target variable in the train labels data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.installation_id.isin(train_labels.installation_id.unique())]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now the train data has reduced to 7 million rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Are there any missing values in the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There appears to be no missing values in the data. \n\nIn order to understand the data better, we plot out some of the variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1.5,palette = 'Blues_d')\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,6))\n\n\nsns.countplot(x='type',data=train,\n              order = train['type'].value_counts().index).set_title('Count by game type - Train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1.5,palette = 'Blues_d')\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,6))\n\n\nsns.countplot(x='type',data=test,\n              order = test['type'].value_counts().index).set_title('Count by game type - Test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This thread (https://www.kaggle.com/c/data-science-bowl-2019/discussion/115034) contains some information about the different types of content. \n\nEach content type can be loosely thought of as corresponding to a phase of the learning cycle.\n\nClips\nVideos are intended to expose the kid to a topic or a problem solving approach. Videos typically model or explain things. There is no interactive component to videos. Clips can further be classified into:\n- Interstitials: short transitional videos between worlds or sections of the world, in which the protagonists of the adventure (Del, Dot and Dee) are seen exploring the island. Aside from the introductory video titled 'Welcome To The Lost Lagoon!', these can be identified by the title specifying the world and the relevant section (e.g. 'Crystal Caves - Level 1'). These videos merely hint to the subject matter.\n- Longer clips (2-3 minutes in length): these videos explain an important subject or approach with the help of familiar characters from the PBS KIDS world. Typically these videos have been excerpted from longer television episodes.\n\nKeep in mind in the dataset only the start of the video playback is captured. Therefore there are far fewer events corresponding to clips than there are to games or assessments. That does not mean clips are less popular! Also, lack of interactivity notwithstanding, there is good evidence that video contributes significantly to learning outcomes.\n\nActivities\nActivities are open-ended mini-games that allow kids to practice their skills in an environment that mimics real life play patterns to support “messing about”. Activities do not have a defined goal, but they do typically model cause and effect. We sometimes refer to Activities as 'sandboxes' or 'toys'.\n\nGames\nThese are the typical video games most people are familiar with. Games help kids practice their skills with the goal of solving a specific problem. Each challenge may belong to a progressively more challenging round (marked in the data), and multiple rounds may be grouped into levels. Games do not end until the player finishes the game or decides to exit the play session. If a final goal is achieved, there is usually an option to replay the entire game from the start.\n\nAssessments\nAssessments are interactives that are designed specifically with the goal of measuring a player’s knowledge of the subject matter. Metrics that represent the intrinsic knowledge of the user are typically derived either from first principles rooted in childhood educational psychometry or from a posteriori data observations. One such (simple) metric might be the number of incorrect answers leading to the assessment solution, but many others can be formulated."},{"metadata":{},"cell_type":"markdown","source":"There are some interesting points to note here:\n\n* The reason why our plot has far fewer clips count than other contents is becuse there are less events for videos as the dataset only captures the start of a video\n* Since games help kids practice their skills, we may be able to say that kids who frequently replay / easily progress through games have a higher chance of getting a correct answer in the assessment at the first attempt\n\nSo what about worlds?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\n\nsns.countplot(x='world',data=train,\n             order = train['world'].value_counts().index).set_title('Count by World - Train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\n\nsns.countplot(x='world',data=test,\n             order = test['world'].value_counts().index).set_title('Count by World - Test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Magma peak seems to be having the highest count in both the train and test sets - not sure why?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\n\nsns.countplot(y='title',data=train,palette = 'Blues_d',\n             order = train['title'].value_counts().index).set_title('Count by Title - Train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\n\nsns.countplot(y='title',data=test,palette = 'Blues_d',\n             order = test['title'].value_counts().index).set_title('Count by Title - Test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There seems to be a lot of titles. Let's plan later on how to one-hot encode these values for our model. Also for some reason, Bottle Filler and Scrub-A-Dub seems to be the most frequent title in train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nsns.countplot(y='title',data=train_labels,palette = 'Blues_d',\n             order = train_labels['title'].value_counts().index).set_title('Count by Assessment - Train labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nsns.countplot(y='accuracy_group',data=train_labels,palette = 'Blues_d',\n             order = train_labels['accuracy_group'].value_counts().index).set_title('Count by Accuracy Group - Train labels')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok so obviously there are lots of incorrect answers before a successful result in an assessment. \n\nNow, to understand the time stamp field, we'll plot the outcomes. Converting timestamp to datetime"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And plotting the day of the week counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nsns.countplot(x=train['timestamp'].dt.dayofweek,data=train,palette = 'Blues_d').set_title('Count by Day of the Week - Train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nsns.countplot(x=test['timestamp'].dt.dayofweek,data=test,palette = 'Blues_d').set_title('Count by Day of the Week - Test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0 denotes Monday, 1 denotes Tuesday and so on...\n\nTrain and test looks slightly different. There is a slightly higher count during Fridays and Saturdays in the train data. However in the test, Fridays are much more higher.\n\nNow, to look at hour of day..."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nsns.countplot(x=train['timestamp'].dt.hour,data=train,palette = 'Blues_d').set_title('Count by Hour of the Day - Train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nsns.countplot(x=test['timestamp'].dt.hour,data=test,palette = 'Blues_d').set_title('Count by Hour of the Day - Test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is an obvious pattern here, the graph shows lesser usage in the early hours of the day up until noon time."},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.sort_values('timestamp')\ntest=test.sort_values('timestamp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\n\nsns.countplot(x=train['timestamp'].dt.date,data=train,palette = 'Blues_d').set_title('Count by Date - Train')\nplt.xticks(rotation=90,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\n\nsns.countplot(x=test['timestamp'].dt.date,data=test,palette = 'Blues_d').set_title('Count by Date - Test')\nplt.xticks(rotation=90,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By plotting count by date range, we don't really see a huge trend in the train. The graph looks pretty standard. However in test there is an obvious peak during August"},{"metadata":{},"cell_type":"markdown","source":"To prepare the data, we need to join the train and train labels. Also need to format the train and test datasets to feed into the model"},{"metadata":{},"cell_type":"markdown","source":"We will perform a left join with train and train_labels using installation_id and game_session. Let's drop all other colums in the train labels other than the ones we require i.e. game_session, installation_id and accuracy_group (our target variable). Once joined, let's look into the number of rows to ensure that we performed the join successfully"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new train data should have the same number of rows as shown above"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = pd.merge(train, train_labels.filter(['game_session','installation_id','accuracy_group'],axis=1), on=['installation_id','game_session'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok so we have the same number of rows and added the accuracy group added\n\n# Feature Engineering\n\nNow we will write a function to prepare the train and test datasets. We also need to perform one hot encoding to the dataset. Before we worry about too many dummy variables, let's look into the number of unique values for the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Title and event code will cause problems for us as they contain several values that need to be converted to dummy variables. Maybe we can group the smaller ones?"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_events = train.groupby(['event_code'])['event_code'].count().rename('count').reset_index().sort_values('count', ascending=False)\ngrouped_events['perc'] = grouped_events['count'] / grouped_events['count'].sum()\ngrouped_events","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_events_test = test.groupby(['event_code'])['event_code'].count().rename('count').reset_index().sort_values('count', ascending=False)\ngrouped_events_test['perc'] = grouped_events_test['count'] / grouped_events_test['count'].sum()\ngrouped_events_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there are several smaller events that can be merged together as 'other'. To make things easier let's make the following grouping:\n\nIt will also be good to test the same in the test data and check if the main events are the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"set(grouped_events.head(6).event_code).intersection(grouped_events_test.head(6).event_code)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Any event_code other than 4070, 4030, 3010, 3110, 4020, 2020 can be grouped together as 'other' or any dummy event_code like '0000'. Let's first convert them into strings."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['event_code'] = train['event_code'].apply(str)\ntest['event_code'] = test['event_code'].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_events = grouped_events.head(6).event_code\ntrain[~train.event_code.isin(main_events)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we should apply the same logic to the title field"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_titles = train.groupby(['title'])['title'].count().rename('count').reset_index().sort_values('count', ascending=False)\ngrouped_titles['perc'] = grouped_titles['count'] / grouped_titles['count'].sum()\ngrouped_titles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_titles_test = test.groupby(['title'])['title'].count().rename('count').reset_index().sort_values('count', ascending=False)\ngrouped_titles_test['perc'] = grouped_titles_test['count'] / grouped_titles_test['count'].sum()\ngrouped_titles_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(grouped_titles.head(6).title) & set(grouped_titles_test.head(6).title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_titles = grouped_titles.head(6).title\ntrain[~train.title.isin(main_titles)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(df):\n    \n    # Adding all the time columns\n    df['month'] = df['timestamp'].dt.month\n    df['hour'] = df['timestamp'].dt.hour\n    df['year'] = df['timestamp'].dt.year\n    df['dayofweek'] = df['timestamp'].dt.dayofweek\n    \n    # drop any unnecessary columns\n    df = df.drop(['timestamp','event_data','game_session','event_id'], axis = 1)\n    \n    # merge all smaller event codes / titles together\n    df.loc[(~df.event_code.isin(main_events),'event_code')]='0000'\n    df.loc[(~df.title.isin(main_titles),'title')]='Other'\n    \n    # convert into dummy variables\n    dummies = pd.get_dummies(df[['type','title','world','event_code']])\n    \n    # drop unnecessary columns\n    df = df.drop(['type','title', 'world','event_code'], axis = 1)\n    df = pd.concat([df, dummies], axis=1)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prep = prepare_data(train)\ntest_prep = prepare_data(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%whos DataFrame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Baseline model - to be continued..."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}