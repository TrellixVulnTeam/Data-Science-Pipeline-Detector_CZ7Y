{"cells":[{"metadata":{},"cell_type":"markdown","source":"##Attribution##\nMost of preprocessing and feature engineering taken from:\nhttps://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline\n##### What has changed##\nTrying an approach with NeuralNet using Softmax - multiclass classification\n###What to expect####\n0.455"},{"metadata":{},"cell_type":"markdown","source":"# Table of contents\n\n* [1. Understanding the train data](#1.-Understanding-the-train-data)\n* [2. Understanding the test set](#2.-Understanding-the-test-set)\n* [3. Understanding and visualizing the train labels](#3.-Understanding-and-visualizing-the train-labels)\n* [4. Feature engineering](#4.-Feature-engineering)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport matplotlib.pylab as plt\nimport calendar\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.model_selection import GroupKFold\nfrom typing import Any\nfrom numba import jit\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\nfrom itertools import product\nimport copy\nimport time\n\nimport random\nseed = 1234\nrandom.seed(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npath_data = '/kaggle/input/data-science-bowl-2019/'\ntrain = pd.read_csv(path_data+'train.csv')\ntrain_labels = pd.read_csv(path_data+'train_labels.csv')\ntest = pd.read_csv(path_data+'test.csv')\nspecs = pd.read_csv(path_data+'specs.csv')\nsample_submission = pd.read_csv(path_data+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Understanding the train data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(train[\"event_id\"].unique())\n#train[\"event_id\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 11 million rows and just 11 columns. However, Kaggle provided the following note: Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment.\n\nAs there is no point in keeping training data that cannot be used for training anyway, I am getting rid of the installation_ids that never took an assessment\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_id = train[train.type == \"Assessment\"][['installation_id']].drop_duplicates()\ntrain = pd.merge(train, keep_id, on=\"installation_id\", how=\"inner\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, we have now lost about 3 million rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of unique installations in our \"smaller\" train set is now 4242."},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_id.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.world.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will first visualize some of the existing columns."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 16})\n\nfig = plt.figure(figsize=(12,10))\nax1 = fig.add_subplot(211)\nax1 = sns.countplot(y=\"type\", data=train, color=\"blue\", order = train.type.value_counts().index)\nplt.title(\"number of events by type\")\n\nax2 = fig.add_subplot(212)\nax2 = sns.countplot(y=\"world\", data=train, color=\"blue\", order = train.world.value_counts().index)\nplt.title(\"number of events by world\")\n\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.title.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 12})\n\nfig = plt.figure(figsize=(12,10))\nse = train.title.value_counts().sort_values(ascending=True)\nse.plot.barh()\nplt.title(\"Event counts by title\")\nplt.xticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will now add some new columns based on the timestamp, and visualize these."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_time(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['date'] = df['timestamp'].dt.date\n    df['month'] = df['timestamp'].dt.month\n    df['hour'] = df['timestamp'].dt.hour\n    df['dayofweek'] = df['timestamp'].dt.dayofweek\n    return df\n    \ntrain = get_time(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below your see the counts by date. By the way, I have wasted a lot of time on trying to fix the weird ticks on the x-axis, but this seems a bug: https://github.com/matplotlib/matplotlib/issues/13183"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nse = train.groupby('date')['date'].count()\nse.plot()\nplt.title(\"Event counts by date\")\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When looking at the day of the week, we see no major difference. Of course, we are talking about kids who don't have to go to work ;-)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nse = train.groupby('dayofweek')['dayofweek'].count()\nse.index = list(calendar.day_abbr)\nse.plot.bar()\nplt.title(\"Event counts by day of week\")\nplt.xticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When looking at the numbers by hour of the day, I find the distribution a little bit strange. Kids seem up late at night and don't do much early in the morning. Has this something to do with time zones perhaps?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nse = train.groupby('hour')['hour'].count()\nse.plot.bar()\nplt.title(\"Event counts by hour of day\")\nplt.xticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Understanding the test set\n\nFrom Kaggle: For each installation_id represented in the test set, you must predict the accuracy_group of the last assessment for that installation_id."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.installation_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 1.1 million rows on a thousand unique installation_ids in the test set. Below, you can see that we have this same amount of rows in the sample submission. This means that there are no installation_ids without assessment in the test set indeed."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another thing that I would like to check is if there is any overlap with regards to installation_id's in the train and test set. As you can see, there are no installation_id's that appear in both train and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"set(list(train.installation_id.unique())).intersection(set(list(test.installation_id.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What about the date ranges?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test['timestamp'] = pd.to_datetime(test['timestamp'])\nprint(f'The date range in train is: {train.timestamp.dt.date.min()} to {train.timestamp.dt.date.max()}')\nprint(f'The date range in test is: {test.timestamp.dt.date.min()} to {test.timestamp.dt.date.max()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The date range is more or less the same, so we are talking about a dataset that seems (randomly) split on installation_id. Well actually \"sort of\" as Kaggle seems to have done this on installation_id's with assessments first, and added the \"left-overs\" with no assessments taken to the train set."},{"metadata":{},"cell_type":"markdown","source":"# 3. Understanding and visualizing the train labels"},{"metadata":{},"cell_type":"markdown","source":"The outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data):\n\n3: the assessment was solved on the first attempt\n\n2: the assessment was solved on the second attempt\n\n1: the assessment was solved after 3 or more attempts\n\n0: the assessment was never solved\n\n\nI started by visualizing some of these columns"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 22})\n\nplt.figure(figsize=(12,6))\nsns.countplot(y=\"title\", data=train_labels, color=\"blue\", order = train_labels.title.value_counts().index)\nplt.title(\"Counts of titles\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below, you can see that a lot of Chest Sorter assessments were never solved. Bird Measurer also seems hard with a relatively small amount solved on the first attempt."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 16})\n\nse = train_labels.groupby(['title', 'accuracy_group'])['accuracy_group'].count().unstack('title')\nse.plot.bar(stacked=True, rot=0, figsize=(12,10))\nplt.title(\"Counts of accuracy group\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the match between the train dataframe and the train_labels dataframe is not straightforward, it tried to figure out how these dataframes are to be matched by focussing on just one particular installation_id."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels[train_labels.installation_id == \"0006a69f\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From Kaggle: The file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set. Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110. If the attempt was correct, it contains \"correct\":true.\n\nHowever, in the first version I already noticed that I had one attempt too many for this installation_id when mapping the rows with the train_labels for. It turns out that there are in fact also assessment attemps for Bird Measurer with event_code 4100, which should not count (see below). In this case that also makes sense as this installation_id already had a pass on the first attempt"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train.event_code == 4100) & (train.installation_id == \"0006a69f\") & (train.title == \"Bird Measurer (Assessment)\")]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we exclude the Bird Measurer/4100 rows we get the correct match with the numbers in train_labels for this installation_id (4 correct, 12 incorrect)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train.installation_id == \"0006a69f\") & ((train.type == \"Assessment\") & (train.title == 'Bird Measurer (Assessment)') & (train.event_code == 4110) |\n                                               (train.type == \"Assessment\") & (train.title != 'Bird Measurer (Assessment)') & (train.event_code == 4100))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the question arises: Could there be installation_id's who did assessments (we have already taken out the ones who never took one), but without results in the train_labels? As you can see below, yes there are 628 of those."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[~train.installation_id.isin(train_labels.installation_id.unique())].installation_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can not train on those installation_id's anyway, I am taking them out of the train set. This reduces our train set further from 8.3 million rows to 7.7 million."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.installation_id.isin(train_labels.installation_id.unique())]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"Basically what we need to do is to compose aggregated features for each session of which we know the train label. Before I get started, I am quickly checking if game_session alone is the unique identifier in train_labels indeed."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(f'Number of rows in train_labels: {train_labels.shape[0]}')\nprint(f'Number of unique game_sessions in train_labels: {train_labels.game_session.nunique()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_labels.installation_id.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, now that we have that confirmed, I my first step was initially to start by looking for values that are always the same for a game_session in the train dataframe. It turns out that the only one is world. I also checked if some of the datetime variables were unique, but this is not always the case (events within a session may cross midnight).\n\nOf course, on Kaggle it is not always necessary to reinvent the wheel. I knew that I would have to iterate over all the rows and add features that only look at what happened up to the moment at which the an installation_id starts a particluar assessment. I found out that Massoud Hosseinali already posted fantastic code on how to do that in this kernel: https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model. Thanks Massoud, and all credit go to you! As Bruno Aquino reused this code and already added some comments, I am actually using his code.\n\nAs I figured out that datetime variables cannot be matched uniquely to the train_labels, I am starting again with a train dataframe as it originally was (except for keeping timestamp as datetime). The huge code chunck below contains the function to generate features for each row in train_labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['date', 'month', 'hour', 'dayofweek'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Credits go to Andrew Lukyanenko\n\ndef encode_title(train, test, train_labels):\n    # encode title\n    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n    # make a list with all the unique 'titles' from the train and test set\n    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n    # make a list with all the unique 'event_code' from the train and test set\n    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n    # make a list with all the unique worlds from the train and test set\n    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n    # create a dictionary numerating the titles\n    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n    # replace the text titles with the number titles from the dict\n    train['title'] = train['title'].map(activities_map)\n    test['title'] = test['title'].map(activities_map)\n    train['world'] = train['world'].map(activities_world)\n    test['world'] = test['world'].map(activities_world)\n    train_labels['title'] = train_labels['title'].map(activities_map)\n    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    \n    \n    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n\n# get usefull dict with maping encode\ntrain, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n\ncategoricals = ['session_title']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Credits go to Massoud Hosseinali\n\ndef get_data(user_sample, test_set=False):\n    '''\n    The user_sample is a DataFrame from train or test where the only one \n    installation_id is filtered\n    And the test_set parameter is related with the labels processing, that is only requered\n    if test_set=False\n    '''\n    # Constants and parameters declaration\n    last_activity = 0\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    \n    # news features: time spent in each activity\n    time_spent_each_act = {actv: 0 for actv in list_of_user_activities}\n    event_code_count = {eve: 0 for eve in list_of_event_code}\n    last_session_time_sec = 0\n    \n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    counter = 0\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    durations = []\n    \n    # itarates through each session of one instalation_id\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        # get some sessions information\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_title_text = activities_labels[session_title] #from Andrew\n        \n        # get current session time in seconds\n        if session_type != 'Assessment':\n            time_spent = int(session['game_time'].iloc[-1] / 1000)\n            time_spent_each_act[activities_labels[session_title]] += time_spent\n        \n        # for each assessment, and only this kind off session, the features below are processed\n        # and a register are generated\n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            # copy a dict to use as feature template, it's initialized with some itens: \n            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n            features = user_activities_count.copy()\n            features.update(time_spent_each_act.copy())\n            features.update(event_code_count.copy())\n            # get installation_id for aggregated features\n            features['installation_id'] = session['installation_id'].iloc[-1] #from Andrew\n            # add title as feature, remembering that title represents the name of the game\n            features['session_title'] = session['title'].iloc[0] \n            # the 4 lines below add the feature of the history of the trials of this player\n            # this is based on the all time attempts so far, at the moment of this assessment\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            # the time spent in the app so far\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            # the accurace is the all time wins divided by the all time attempts\n            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            # a feature of the current accuracy categorized\n            # it is a counter of how many times this player was in each accuracy group\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            accuracy_groups[features['accuracy_group']] += 1\n            # mean of the all accuracy groups of this player\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n            features['accumulated_actions'] = accumulated_actions\n            \n            # there are some conditions to allow this features to be inserted in the datasets\n            # if it's a test set, all sessions belong to the final dataset\n            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n            # that means, must exist an event_code 4100 or 4110\n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n                \n            counter += 1\n        \n        # this piece counts how many actions was made in each event_code so far\n        n_of_event_codes = Counter(session['event_code'])\n        \n        for key in n_of_event_codes.keys():\n            event_code_count[key] += n_of_event_codes[key]\n\n        # counts how many actions the player has done so far, used in the feature of the same name\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type\n    # if test_set=True, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in train_set, all assessments are kept\n    return all_assessments","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make this a little bit easier to understand, I am first using the function on one installation_id as an example (same one as used as an example before). Below, I have only displayed the last bunch of columns of the resulting dataframe. As you can see, five rows have been created for this installation_id."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_id = train[train.installation_id == \"0006a69f\"]\nsample_id_data = get_data(sample_id) #returns a list\nsample_df = pd.DataFrame(sample_id_data)\nsample_df.iloc[:,-10:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we compare this to the train_labels, you can see that the accuracy_group values are the same so features have been added for all game_session id's. However more importantly, by comparing the accumulated_uncorrect_attempts with num_incorrect, you will see that **only activities before the start of that particular session have been accumulated**."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels[train_labels.installation_id == \"0006a69f\"].iloc[:, [0, 1, -3, -1]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the code below the function is applied to each installation_id in the train dataset.\n\nCompared to the original code I changed the total. In the original code this was set at 17,000. However, since I reduced the train dataframe, I only have 3614 of those left (train.installation_id.nunique()=3614). In addition, I had issues with incorrect rendering of the tdqm bar, and solved this by adding position=0. I also turns out that possible to add a description, which is nice to have."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Credits go to Massoud Hosseinali\n\n#The get_data function is applied to each installation_id and added to the compile_data list\ncompiled_data = []\n# tqdm is the library that draws the status bar below\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n    # user_sample is a DataFrame that contains only one installation_id\n    compiled_data += get_data(user_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Credits go to Massoud Hosseinali\n\n#Compiled_data is converted into a DataFrame and deleted to save memmory\nreduce_train = pd.DataFrame(compiled_data)\ndel compiled_data\nreduce_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reduce_train.head()\nreduce_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to do the same thing for the test set. Parameter test_set=True leads to accuracy_group=0 and only the last assessment is kept (so only one row per installation_id)."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"new_test = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n    a = get_data(user_sample, test_set=True)\n    new_test.append(a)\n    \nreduce_test = pd.DataFrame(new_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Baseline Model\n\nIn this competition,regression with rounding of coefficients is clearly the way to go as explained by Andrew Lukyanenko in his excellent kernel: https://www.kaggle.com/artgor/quick-and-dirty-regression\n\nStep 1: Just get it working....\n\nCredits for this section go to Andrew. I have only made small changes, and are basically just using other (less actually) features. As I was just focused on getting it to work, I changed the test and train set into the names that Andrew uses (reduce_train and reduce_test)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(reduce_train, reduce_test):\n    for df in [reduce_train, reduce_test]:\n        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n        \n        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n        \n        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n        \n    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n    #features = [x for x in features if x not in ['accuracy_group', 'installation_id']] + ['acc_' + title for title in assess_titles]\n    features = [x for x in features if x not in ['accuracy_group', 'installation_id']]\n    return reduce_train, reduce_test, features\n# call feature engineering function\nreduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = reduce_train['accuracy_group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train.shape\n#print(features)\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GroupKFold is chosen for cross validation as we want all sessions of an installation_id to end up in either train or valid. See also the RegressorModel class."},{"metadata":{"trusted":true},"cell_type":"code","source":"#cols_to_drop = ['game_session', 'installation_id', 'timestamp', 'accuracy_group', 'timestampDate']\ncols_to_drop = [ 'installation_id', 'accuracy_group']\n#X =reduce_train.drop(cols_to_drop, axis=1)\nX =reduce_train[features]\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_y = np_utils.to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(dummy_y).head()\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD, Adam, RMSprop\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.callbacks import ReduceLROnPlateau\npd.DataFrame(dummy_y).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dim= X.shape[1]\nprint('input_dim is:', input_dim)\npd.DataFrame(X).head(5)\nfeatures = X.columns\nX.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n@jit\ndef qwk(a1, a2):\n    \"\"\"\n    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n\n    :param a1:\n    :param a2:\n    :param max_rat:\n    :return:\n    \"\"\"\n    max_rat = 3\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n\n\ndef eval_qwk_lgb(y_true, y_pred):\n    \"\"\"\n    Fast cappa eval function for lgb.\n    \"\"\"\n\n    y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n    return 'cappa', qwk(y_true, y_pred), True\n\n\ndef eval_qwk_lgb_regr(y_true, y_pred):\n    \"\"\"\n    Fast cappa eval function for lgb.\n    \"\"\"\n    y_pred[y_pred <= 1.12232214] = 0\n    y_pred[np.where(np.logical_and(y_pred > 1.12232214, y_pred <= 1.73925866))] = 1\n    y_pred[np.where(np.logical_and(y_pred > 1.73925866, y_pred <= 2.22506454))] = 2\n    y_pred[y_pred > 2.22506454] = 3\n\n    # y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n\n    return 'cappa', qwk(y_true, y_pred), True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n##############################################################################################\n\nfrom keras.callbacks import Callback\nclass roc_callback(Callback):\n    def __init__(self,training_data,validation_data):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x)\n        roc = qwk(self.y, y_pred)\n        #roc = eval_qwk_lgb(self.y, y_pred)\n        y_pred_val = self.model.predict(self.x_val)\n        roc_val = qwk(self.y_val, y_pred_val)\n        #roc_val = eval_qwk_lgb(self.y_val, y_pred_val)\n        #print('\\rqwk: %s - qwk_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n        print('\\rqwk: %s - qwk_val: %s' % (str(roc),str(roc_val)),end=100*' '+'\\n')\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\n#pd.DataFrame(X).head(5)\n\nmodel = Sequential()\nmodel.add(Dense(221, input_dim=input_dim,kernel_initializer='random_normal', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(111,activation='tanh'))\n#model.add(Dense(163, input_dim=input_dim, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4, activation='softmax'))\n# Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#model.fit(X,dummy_y, batch_size = 32, epochs = 50,validation_split=0.2)\n\ntrain_x, valid_x , train_y, valid_y = train_test_split(X, dummy_y, test_size=0.2, random_state=2020)\nfrom keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.008)\n\n# checkpoint\nfilepath='/kaggle/working/best_weights.hdf5'\n#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\"\"\"\nmodel.fit(train_x, train_y, batch_size = 32, epochs = 100,validation_data=(valid_x, valid_y),\n               callbacks=[reduce_lr,roc_callback(training_data=(train_x, train_y),validation_data=(valid_x, valid_y)),early_stopping],verbose=1)\n\nmodel.fit(train_x, train_y, batch_size = 32, epochs = 100,validation_data=(valid_x, valid_y),\n               callbacks=[checkpoint,roc_callback(training_data=(train_x, train_y),validation_data=(valid_x, valid_y)),early_stopping],verbose=1)\n\"\"\"\nmodel.fit(train_x, train_y, batch_size = 8, epochs = 100,validation_data=(valid_x, valid_y),\n               callbacks=[roc_callback(training_data=(train_x, train_y),validation_data=(valid_x, valid_y)),early_stopping],verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.load_weights(filepath)\npreds = model.predict(sc.transform(reduce_test[features]))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(preds).head(200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(preds).head(100).idxmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['accuracy_group'] = pd.DataFrame(preds).idxmax(axis=1).astype(int)\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(50)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"167cd628d66b4a68ae4e76a35480b1af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Installation_id: 100%","description_tooltip":null,"layout":"IPY_MODEL_f4a0c40472c24cedb6e15f9fdb9c2245","max":3614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fcce3871303041999861190b979998ce","value":3614}},"2dd5ec3bdb4949289139dd797d7dc59b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"38944963798a4b10a4a359e72d3a9066":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4e8d1006917438596b4e3eb9941bd21","placeholder":"​","style":"IPY_MODEL_afab0a8d7f5a458e8dee4e32f1da6bd0","value":" 1000/1000 [00:42&lt;00:00, 23.74it/s]"}},"6fa125483e2c4144b655fc2f91a018cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86d9fb7deaeb4a92975765341223f7c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb39274d6cb7483e8ea980b8c10c4abb","IPY_MODEL_38944963798a4b10a4a359e72d3a9066"],"layout":"IPY_MODEL_ec3f63a4a7bf4f45934ae97a957d038c"}},"8802f6a239d4435db813f7cd4a5ab4e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_167cd628d66b4a68ae4e76a35480b1af","IPY_MODEL_9e5cd5d553f44f53ad9286c46c140c86"],"layout":"IPY_MODEL_d88d395319be42e1a5adf2b57974dbb5"}},"9e5cd5d553f44f53ad9286c46c140c86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0753b7984e14c9b98af5e9a6a0d92c0","placeholder":"​","style":"IPY_MODEL_a58663bc14bf444b802f1523e0e5643f","value":" 3614/3614 [04:41&lt;00:00, 12.84it/s]"}},"a58663bc14bf444b802f1523e0e5643f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afab0a8d7f5a458e8dee4e32f1da6bd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0753b7984e14c9b98af5e9a6a0d92c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d88d395319be42e1a5adf2b57974dbb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4e8d1006917438596b4e3eb9941bd21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb39274d6cb7483e8ea980b8c10c4abb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Installation_id: 100%","description_tooltip":null,"layout":"IPY_MODEL_6fa125483e2c4144b655fc2f91a018cf","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2dd5ec3bdb4949289139dd797d7dc59b","value":1000}},"ec3f63a4a7bf4f45934ae97a957d038c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4a0c40472c24cedb6e15f9fdb9c2245":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcce3871303041999861190b979998ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":1}