{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install fastai==0.7.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.structured import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import *\nfrom sklearn.ensemble import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nfrom tqdm import tqdm_notebook as tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option(\"display.expand_frame_repr\", False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/data-science-bowl-2019'\nPATH_W = '/kaggle/working'\n\npath = pathlib.Path(PATH)\npath_w = pathlib.Path(PATH_W)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls {path}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head -n 300000 {path}/'train.csv' > {path_w}/'sample_train.csv'\n!head -n 300000 {path}/'specs.csv' > {path_w}/'sample_specs.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train = pd.read_csv(path_w/'sample_train.csv')\nsample_specs = pd.read_csv(path_w/'sample_specs.csv')\ntrain_labels = pd.read_csv(path/'train_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\ntrain_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\ntest = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\nsubmission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.query('game_session==\"0848ef14a8dc6892\" & event_code!=4110')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find out how the train_labels is calculated? and find out a way to apply it on entire data\n\nAfter analysis of data findings\n1. look at the analysis below\n2. Therer is some connection between specs_labels and train_labels. \n3. Find out how many attemps in total were made by one particular installation_id and then compare the session of it with session present in train_labels\n\nFrom the above analysis I can conclude that:\n1. Read the documentation carefully.\n2. Doc states that We need to find no. of attempts that would be required for a given installation id.\n3. Each Intallation id has multiple session id which may have one type of assessment or many type of assessment.\n4. The Ground truth label is calculated in such a way that for each intallation id there would be multiple session id. We need to calculate ground truth for each of those session ids. Ground truth i.e. no. of attempts taken can be calculated by observing the value of event_code = 4100 (4110 for Bird Assessment) and event_data contains correect = true(tells us if attempt was correct or not). \n\nIf we find 4100 and correct=true as first occurance then group = 3.\n\nIf we find 4100 and correct=true as Second occurance then group = 2.\n\nIf we find 4100 and correct=true as Third occurance then group = 1.\n\nIf no 4100then group =0\n"},{"metadata":{},"cell_type":"markdown","source":"keep count of num_correct, num_incorrect\n\nacc = num_correct/num_correct+incorrect\n\nacc_group"},{"metadata":{"trusted":true},"cell_type":"code","source":"#The following code copied from https://www.kaggle.com/artgor/quick-and-dirty-regression\n\ndef read_data():\n    print('Reading train.csv file....')\n    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\n    print('Reading test.csv file....')\n    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n\n    print('Reading train_labels.csv file....')\n    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n\n    print('Reading specs.csv file....')\n    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n\n    print('Reading sample_submission.csv file....')\n    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n    return train, test, train_labels, specs, sample_submission\n\ndef encode_title(train, test, train_labels):\n    # encode title\n    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n    # make a list with all the unique 'titles' from the train and test set\n    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n    # make a list with all the unique 'event_code' from the train and test set\n    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n    # make a list with all the unique worlds from the train and test set\n    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n    # create a dictionary numerating the titles\n    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n    # replace the text titles with the number titles from the dict\n    train['title'] = train['title'].map(activities_map)\n    test['title'] = test['title'].map(activities_map)\n    train['world'] = train['world'].map(activities_world)\n    test['world'] = test['world'].map(activities_world)\n    train_labels['title'] = train_labels['title'].map(activities_map)\n    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    \n    \n    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n\ndef get_data(user_sample, test_set=False):\n    '''\n    The user_sample is a DataFrame from train or test where the only one \n    installation_id is filtered\n    And the test_set parameter is related with the labels processing, that is only requered\n    if test_set=False\n    '''\n    # Constants and parameters declaration\n    last_activity = 0\n    \n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    \n    # new features: time spent in each activity\n    last_session_time_sec = 0\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy = 0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0\n    accumulated_actions = 0\n    counter = 0\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    durations = []\n    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n    \n    # itarates through each session of one instalation_id\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        # get some sessions information\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_title_text = activities_labels[session_title]\n                    \n            \n        # for each assessment, and only this kind off session, the features below are processed\n        # and a register are generated\n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            # copy a dict to use as feature template, it's initialized with some itens: \n            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n            features = user_activities_count.copy()\n            features.update(last_accuracy_title.copy())\n            features.update(event_code_count.copy())\n            features.update(event_id_count.copy())\n            features.update(title_count.copy())\n            features.update(title_event_code_count.copy())\n            features.update(last_accuracy_title.copy())\n            \n            # get installation_id for aggregated features\n            features['installation_id'] = session['installation_id'].iloc[-1]\n            # add title as feature, remembering that title represents the name of the game\n            features['session_title'] = session['title'].iloc[0]\n            # the 4 lines below add the feature of the history of the trials of this player\n            # this is based on the all time attempts so far, at the moment of this assessment\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            # the time spent in the app so far\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            # the accurace is the all time wins divided by the all time attempts\n            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            last_accuracy_title['acc_' + session_title_text] = accuracy\n            # a feature of the current accuracy categorized\n            # it is a counter of how many times this player was in each accuracy group\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            accuracy_groups[features['accuracy_group']] += 1\n            # mean of the all accuracy groups of this player\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n            features['accumulated_actions'] = accumulated_actions\n            \n            # there are some conditions to allow this features to be inserted in the datasets\n            # if it's a test set, all sessions belong to the final dataset\n            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n            # that means, must exist an event_code 4100 or 4110\n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n                \n            counter += 1\n        \n        # this piece counts how many actions was made in each event_code so far\n        def update_counters(counter: dict, col: str):\n                num_of_session_count = Counter(session[col])\n                for k in num_of_session_count.keys():\n                    x = k\n                    if col == 'title':\n                        x = activities_labels[k]\n                    counter[x] += num_of_session_count[k]\n                return counter\n            \n        event_code_count = update_counters(event_code_count, \"event_code\")\n        event_id_count = update_counters(event_id_count, \"event_id\")\n        title_count = update_counters(title_count, 'title')\n        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n\n        # counts how many actions the player has done so far, used in the feature of the same name\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type \n                        \n    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in the train_set, all assessments goes to the dataset\n    return all_assessments\n\ndef get_train_and_test(train, test):\n    compiled_train = []\n    compiled_test = []\n    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n        compiled_train += get_data(user_sample)\n    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n        test_data = get_data(user_sample, test_set = True)\n        compiled_test.append(test_data)\n    reduce_train = pd.DataFrame(compiled_train)\n    reduce_test = pd.DataFrame(compiled_test)\n    categoricals = ['session_title']\n    return reduce_train, reduce_test, categoricals\n\n# read data\ntrain, test, train_labels, specs, sample_submission = read_data()\n# get usefull dict with maping encode\ntrain, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n# tranform function to get the train and test set\nreduce_train, reduce_test, categoricals = get_train_and_test(train, test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(reduce_train, reduce_test):\n    for df in [reduce_train, reduce_test]:\n        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n        #df['installation_duration_std'] = df.groupby(['installation_id'])['duration_mean'].transform('std')\n        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n        \n        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n        \n        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n        #df['installation_event_code_count_std'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('std')\n        \n    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n    features = [x for x in features if x not in ['accuracy_group', 'installation_id']] + ['acc_' + title for title in assess_titles]\n   \n    return reduce_train, reduce_test, features\n# call feature engineering function\nreduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_copy_train = reduce_train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_encode = list(range(len(temp_copy_train.installation_id.unique())))\n# temp_copy_train.installation_id.unique()\ninstallation_id_int_encoding = {x:y for x,y in zip(temp_copy_train.installation_id.unique(),int_encode)}\ninstallation_id_int_encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_installation_codes = []\nfor x in temp_copy_train.installation_id:\n    all_installation_codes.append(installation_id_int_encoding[x])\n    \nall_installation_codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_copy_train['installation_id'] = all_installation_codes\ntemp_copy_train.installation_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats(temp_copy_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removoing the y_fld from reduce_train\ny_trn = temp_copy_train['accuracy_group']\ndf_trn = temp_copy_train.drop('accuracy_group',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_vals(a,n): return a[:n],a[n:]\n\nn_valid = 5307\nn_train = len(df_trn) - n_valid\nX_train, X_valid = split_vals(df_trn,n_train)\ny_train, y_valid = split_vals(y_trn,n_train)\nraw_train, raw_valid = split_vals(reduce_train,n_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hypothesis:\n1. Follow this method mentioned in this notebook = https://www.kaggle.com/keyurparalkar/a-new-baseline-for-dsb-2019-catboost-model/edit"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_train = sample_train.query('(event_code==4100 | event_code==4110) & type==\"Assessment\"')\nlen(sample_train.game_session.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def label_assign(sample_trn,game_sess_id):\n#     sample_df = defaultdict(lambda: '')\n# #     [sample_df[i] for i in list(sample_trn.columns)]\n    \n#     game_sess = sample_trn.groupby('game_session',sort=False)\n#     #unique sess ids\n#     sess_grps = list(game_sess.groups.keys())\n\n#     #getting all rows of first group i.e. first session\n#     f_grp = game_sess.get_group(game_sess_id)\n\n#     #correct and icorrect attempts count\n#     num_corr = 0\n#     num_incorr = 0\n\n#     #printing attempted rows \n#     attempts = f_grp.query('event_code==4100 | event_code==4110')['event_data']\n#     num_attempts = len(attempts)\n#     num_corr = attempts.str.contains('true').sum()\n#     temp = 0\n#     if(num_corr>1):\n#         temp = num_corr\n#         num_corr=1\n\n#     num_incorr = attempts.str.contains('false').sum()\n\n#     #calculating the accuracy\n#     acc = num_corr/(num_corr+num_incorr)\n# #     print(acc)\n#     if(acc < 0.5):\n#         acc_grp = 1\n#     elif(acc == 0.5):\n#         acc_grp = 2\n#     elif(acc == 1):\n#         acc_grp = 3\n#     elif(acc == 0):\n#         acc_grp = 0\n#     else:\n#         acc_grp = 0\n        \n        \n#     sample_df['num_correct'] = num_corr\n#     sample_df['num_incorrect'] = num_incorr\n#     sample_df['accuracy'] = acc\n#     sample_df['accuracy_group'] = acc_grp\n    \n#     return sample_df, game_sess.groups[game_sess_id]    #ssample dict, indexes of all the rows of the groupby clause","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_train['num_correct'] = 0\n# sample_train['num_incorrect'] = 0\n# sample_train['accuracy'] = 0\n# sample_train['accuracy_group'] = 0\n\n# temp_1 = label_assign(sample_train,'cace4c493ac347e3')\n# temp_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y = sample_train.loc[temp_1[1]].query('event_code==4100 | event_code==4110')\n# y_indexes = y.loc[y['event_data'].str.contains('true')].index\n# false_idxs = y.loc[y['event_data'].str.contains('false')].index\n\n# #values for true indices\n# sample_train.loc[y_indexes,'num_correct'] = temp_1[0]['num_correct']\n# sample_train.loc[y_indexes,'num_incorrect'] = temp_1[0]['num_incorrect']\n# sample_train.loc[y_indexes,'accuracy'] = temp_1[0]['accuracy']\n# sample_train.loc[y_indexes,'accuracy_group'] = temp_1[0]['accuracy_group']\n\n# # #values for false indices\n# # sample_train.loc[false_idxs,'num_correct'] = 0\n# # sample_train.loc[false_idxs,'num_incorrect'] = 0\n# # sample_train.loc[false_idxs,'accuracy'] = 0\n# # sample_train.loc[false_idxs,'accuracy_group'] = 0\n\n# # #values for indices other than event_code 4100 and 4110\n# # other_idxs = sample_train.query('(event_code!=4100 | event_code!=4110) & game_session==\"cace4c493ac347e3\"').index\n# # sample_train.loc[other_idxs,'num_correct'] = 0\n# # sample_train.loc[other_idxs,'num_incorrect'] = 0\n# # sample_train.loc[other_idxs,'accuracy'] = 0\n# # sample_train.loc[other_idxs,'accuracy_group'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_train['num_correct'] = 0\n# sample_train['num_incorrect'] = 0\n# sample_train['accuracy'] = 0\n# sample_train['accuracy_group'] = 0\n\n# # code for labeling all the game_sessions:\n# all_sess_grps = list(sample_train.groupby('game_session',sort=False).groups.keys())\n# for sess in tqdm(all_sess_grps,total=len(all_sess_grps)):\n#     temp_1 = label_assign(sample_train,str(sess))\n#     y = sample_train.loc[temp_1[1]].query('event_code==4100 | event_code==4110')\n#     y_indexes = y.loc[y['event_data'].str.contains('true')].index\n#     false_idxs = y.loc[y['event_data'].str.contains('false')].index\n\n#     #values for true indices\n#     sample_train.loc[y_indexes,'num_correct'] = temp_1[0]['num_correct']\n#     sample_train.loc[y_indexes,'num_incorrect'] = temp_1[0]['num_incorrect']\n#     sample_train.loc[y_indexes,'accuracy'] = temp_1[0]['accuracy']\n#     sample_train.loc[y_indexes,'accuracy_group'] = temp_1[0]['accuracy_group']\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train.to_feather({path_w}/'saved_sample_trn_raw')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the above code it will match all the game session from above 8k.\nProblem is in training set wewill have multiple game_session which will match sample_labels. It will match all the game_session which will have event_code==4100 and 4110. It will also match game_session where event_code is not equal to 4100 and 4110 "},{"metadata":{},"cell_type":"markdown","source":"Now to combine our ground-truth's obtained above with given training dataset. Please be advised that to following below steps:\n1. From the given train.csv filter out all the rows with event_code == 4100 or event_code==4110 and type Assessment.\n2. From the above methods to obtain sample_labels combine it with train.csv based on merge function on column game_session."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Creating a print_score function for calculating evaluation metrics score and accuracy on train and validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_score(m):\n    results = [cohen_kappa_score(y_train,m.predict(X_train),weights='quadratic'),cohen_kappa_score(y_valid,m.predict(X_valid),weights='quadratic'),\n               m.score(X_train,y_train),m.score(X_valid,y_valid)]\n    print(\"Scores = \",results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating RandomForestClassifier model"},{"metadata":{"trusted":true},"cell_type":"code","source":"set_rf_samples(5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier(min_samples_leaf=3,max_features=0.5)\nmodel.fit(df_trn,y_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(df_trn,y_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Creating model on larger data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(path/'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.query('(event_code==4100 | event_code==4110) & type==\"Assessment\"')\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_count = defaultdict(lambda :0)\nincorr_count = defaultdict(lambda :0)\ntitle = defaultdict(lambda :'')\ngame_sess = defaultdict(lambda :'')\ninstall_id = defaultdict(lambda :'')\n\nfor idx in train_data.index:\n    row = train_data.loc[idx]\n    title[row.game_session] = row.title\n    game_sess[row.game_session] = row.game_session\n    install_id[row.game_session] = row.installation_id\n    #import pdb; pdb.set_trace()\n\n    if(row.event_code==4100):\n        if('true' in row.event_data):\n            corr_count[row.game_session] +=1\n        else:\n            incorr_count[row.game_session] +=1\n            \n    elif(row.event_code==4110):\n        if('true' in row.event_data):\n            corr_count[row.game_session] +=1\n        else:\n            incorr_count[row.game_session] +=1     \n        \nlabels = pd.DataFrame({'game_session':game_sess,'installation_id':install_id,'title':title,'num_correct':corr_count\n                              ,'num_incorrect':incorr_count},index=None)\nlabels.fillna(value=0,inplace=True)\nlabels.reset_index(inplace=True)\nlabels.drop(columns='index',inplace=True)\n\naccuracy = labels.num_correct/(labels.num_correct+labels.num_incorrect)\nlabels['accuracy'] = accuracy \n\ntemp = []\nfor x in labels.index:\n    row = labels.loc[x]\n    if(row.num_correct==1):\n        temp.append(3)\n    elif(row.num_correct==2):\n        temp.append(2)\n    elif(row.num_correct>=3):\n        temp.append(1)\n    elif(row.num_correct==0):\n        temp.append(0)\n        \nlabels['accuracy_group'] = temp\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_w_gt = pd.merge(left=train_data,right=labels,on='game_session',how='left')\ntrain_w_gt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_w_gt.drop(columns='event_data',inplace=True)\ntrain_w_gt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_datepart(train_w_gt,fldname='timestamp')\ntrain_w_gt.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats(train_w_gt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trn, y_trn, nas = proc_df(train_w_gt,y_fld='accuracy_group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_vals(a,n): return a[:n],a[n:]\n\nn_valid = 1200\nn_train = len(train_w_gt) - n_valid\nX_train, X_valid = split_vals(df_trn,n_train)\ny_train, y_valid = split_vals(y_trn,n_train)\nraw_train, raw_valid = split_vals(train_w_gt,n_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_rf_samples(50000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=10,min_samples_leaf=3,max_features=0.5,n_jobs=-1)\nmodel.fit(X_train,y_train)\nprint_score(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}