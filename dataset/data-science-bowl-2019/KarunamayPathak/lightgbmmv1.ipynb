{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Data Reading\ntrain=pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\ntrain_labels=pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\ntest=pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\nspec=pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\nprint(train_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head( )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count of unique installation ids\ntrain.installation_id.unique( ).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy group distribution across different titles\nassesments=train_labels['title'].unique( ).tolist( )\nplt.figure(figsize=(15,8))\nfor asset in assesments:\n    # Subset by assesment type\n    subset = train_labels[train_labels['title'] == asset]\n    \n    # Draw the density plot\n    sns.distplot(train_labels['accuracy_group'], hist = False, kde = True,\n                 kde_kws = {'shade': True, 'linewidth': 3},label =asset)\n\n# Plot formatting\nplt.legend(prop={'size': 16}, title = 'Assesment type')\nplt.title('Density Plot with Assesment category')\nplt.xlabel('accuracy_group')\nplt.ylabel('Density')\nplt.show( )\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy group distribution of  incorrect answers\nplt.figure(figsize=(15,8))\nfg = sns.FacetGrid(data=train_labels,hue='accuracy_group',size=4,aspect=3)\nfg.map(plt.scatter, 'accuracy_group','num_correct').add_legend()\nplt.show( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy group distribution of  incorrect answers\nplt.figure(figsize=(15,8))\nfg = sns.FacetGrid(data=train_labels,hue='accuracy_group',size=4,aspect=3)\nfg.map(plt.scatter, 'accuracy_group','num_incorrect').add_legend()\nplt.show( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating some new feature try some new features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class featureE:\n    def __init__(self):\n        self.count=0\n    def get_time(self,df):\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n        df['date'] = df['timestamp'].dt.date\n        df['month'] = df['timestamp'].dt.month\n        df['hour'] = df['timestamp'].dt.hour\n        df['dayofweek'] = df['timestamp'].dt.dayofweek\n        return df\n    def get_object_columns(self,df, columns):\n        df = df.groupby(['installation_id', columns])['event_id'].count().reset_index()\n        df = df.pivot_table(index = 'installation_id', columns = [columns], values = 'event_id')\n        df.columns = list(df.columns)\n        df.fillna(0, inplace = True)\n        return df\n    def get_numeric_columns(self,df, column):\n        df = df.groupby('installation_id').agg({f'{column}': ['mean', 'sum', 'std']})\n        df.fillna(0, inplace = True)\n        df.columns = [f'{column}_mean', f'{column}_sum', f'{column}_std']\n        return df\n    def get_numeric_columns_2(self,df, agg_column, column):\n        df = df.groupby(['installation_id', agg_column]).agg({f'{column}': ['mean', 'sum', 'std']}).reset_index()\n        df = df.pivot_table(index = 'installation_id', columns = [agg_column], values = [col for col in df.columns if col not in ['installation_id', 'type']])\n        df.fillna(0, inplace = True)\n        df.columns = list(df.columns)\n        return df\n    def get_correct_incorrect(self,df):\n        df = df.groupby(['title'])['num_correct', 'num_incorrect'].agg({'num_correct': ['mean', 'std'], 'num_incorrect': ['mean', 'std']}).reset_index()\n        df.columns = ['title', 'num_correct_mean', 'num_correct_std', 'num_incorrect_mean', 'num_incorrect_std']\n        return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns for feature engineering\n#calling the feature class\nd=featureE( )\nnumerical_columns = ['game_time', 'event_count']\ncategorical_columns = ['type', 'world']\n#creating features from time stamp\nnumerical_columns_single = ['hour', 'dayofweek', 'month', 'event_id_count', 'event_code_count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get time features\ntrain =d.get_time(train)\ntest =d.get_time(test)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#grouping by cout for getting unique pairs\ndef count_segments(train, test, cols):\n    for col in cols:\n        for df in [train, test]:\n            df[f'{col}_count'] = df.groupby([col])['timestamp'].transform('count')\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_segments(train, test, ['event_id', 'event_code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#passing train and test for aggregation and feature creation\ndftrain = pd.DataFrame({'installation_id': train['installation_id'].unique()})\ndftrain.set_index('installation_id', inplace = True)\ndftest = pd.DataFrame({'installation_id': test['installation_id'].unique()})\ndftest.set_index('installation_id', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bringing numerical columns\nfor i in numerical_columns:\n    dftrain = dftrain.merge(d.get_numeric_columns(train, i), left_index = True, right_index = True)\n    dftest = dftest.merge(d.get_numeric_columns(test, i), left_index = True, right_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Brining categorical columns\nfor i in categorical_columns:\n        dftrain = dftrain.merge(d.get_object_columns(train, i), left_index = True, right_index = True)\n        dftest = dftest.merge(d.get_object_columns(test, i), left_index = True, right_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#categorical columns grouping\nfor i in categorical_columns:\n        for j in numerical_columns:\n            dftrain = dftrain.merge(d.get_numeric_columns_2(train, i, j), left_index = True, right_index = True)\n            dftest = dftest.merge(d.get_numeric_columns_2(test, i, j), left_index = True, right_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting columns related time stamp of operations\nfor i in numerical_columns_single:\n        dftrain = dftrain.merge(d.get_numeric_columns(train, i), left_index = True, right_index = True)\n        dftest = dftest.merge(d.get_numeric_columns(test, i), left_index = True, right_index = True)\n         \ndftrain.reset_index(inplace = True)\ndftest.reset_index(inplace = True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for grouping getting the mode accuracy group of titles--assuming title has unique map\nlabels_map = dict(train_labels.groupby('title')['accuracy_group'].agg(lambda x:x.value_counts().index[0]))\n# merge target\nlabels = train_labels[['installation_id', 'title', 'accuracy_group']]\n# merge with correct incorrect\ncorr_inc = d.get_correct_incorrect(train_labels)\nlabels = labels.merge(corr_inc, how = 'left', on = 'title')\n# replace title with the mode\nlabels['title'] = labels['title'].map(labels_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For test set assiging  mode accuracy group to get correct_incorrect\ndftest['title'] = test.groupby('installation_id').last()['title'].reset_index(drop = True)\ndftest = dftest.merge(corr_inc, how = 'left', on = 'title')\ndftest.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# map title to convert title to numeric variable\ndftest['title'] = dftest['title'].map(labels_map)\ndftest.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing final train data as compatible to test data\n# join train with labels\ndftrain = labels.merge(dftrain, on = 'installation_id', how = 'left')\ndftrain = dftrain[[col for col in dftest.columns] + ['accuracy_group']]\nprint('We have {} training rows'.format(dftrain.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of accuracy group in data\nplt.figure(figsize=(15,5))\nsns.countplot(dftrain['accuracy_group'])\nplt.ylabel(\"Count\")\nplt.title(\"Accuracy group counts\", y=1, fontdict={\"fontsize\": 20});","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Formulating as a classification problem---","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initial set of Xs\nInFeature=dftrain.drop(['installation_id','accuracy_group'],axis=1).columns.tolist( )\nprint(InFeature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Will do first level feature selection using Random Forest method -recursively ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train - test split- 80/20\nX = dftrain[InFeature].values\ny =dftrain['accuracy_group'].values.flatten()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\nprint(f\"Original data shapes: {X_train.shape, X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# from sklearn.pipeline import make_pipline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\nfrom sklearn.feature_selection import RFE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#RFE-recursive feture engineering\nrfc = RandomForestClassifier(n_estimators=455,min_samples_split=10,min_samples_leaf=100,max_features='auto', max_depth=10, bootstrap=False,class_weight=\"balanced\")\nsel_rfe_tree = RFE(estimator=rfc, n_features_to_select=20, step=1)\nX_train_rfe_tree = sel_rfe_tree.fit_transform(X_train, y_train)\nprint(sel_rfe_tree.get_support())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top20 features\nRFEtop20=[InFeature[i] for i in range(0,len(InFeature)) if(sel_rfe_tree.ranking_[i]==1)]\nprint(RFEtop20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trying lightgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train and test split\nX = dftrain[RFEtop20].values\ny = dftrain['accuracy_group'].values.flatten()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\nprint(f\"Original data shapes: {X_train.shape, X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(X_train)\nx_test = sc.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(X_train)\nx_test = sc.transform(X_test)\nimport lightgbm as lgb\nd_train = lgb.Dataset(x_train, label=y_train)\nparams = {}\nparams['learning_rate'] = 0.001\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'multiclass'\nparams['num_classes'] = 4\nparams['metric'] = 'multi_logloss'\nparams['sub_feature'] = 0.8\nparams['num_leaves'] = 50\nparams['min_data'] = 100\nparams['max_depth'] = 10\nclf = lgb.train(params, d_train, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions on train data\npredstrain = clf.predict(x_train)\npredstest = clf.predict(x_test)\npredictionsTR = []\nfor x in predstrain:\n    predictionsTR.append(np.argmax(x))\npredictionsTE=[ ]\nfor x in predstest:\n    predictionsTE.append(np.argmax(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scoring on train data\nprint(\"Train-F1-score-\",f1_score(predictionsTR,y_train,average='weighted'))\nprint(\"Test-F1-score-\",f1_score(predictionsTE,y_test,average='weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions on test data for submission\nxtestfinal=dftest[RFEtop20].values\npredstest = clf.predict(xtestfinal)\npredicttest=[ ]\nfor x in predstest:\n    predicttest.append(np.argmax(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=dftest[['installation_id']]\ndf['accuracy_group']=predicttest\ndf.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission=pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\nsample_submission=sample_submission[['installation_id']]\nsample_submission.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission result\nsubmission= sample_submission.merge(df, on = 'installation_id')\nsubmission.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}