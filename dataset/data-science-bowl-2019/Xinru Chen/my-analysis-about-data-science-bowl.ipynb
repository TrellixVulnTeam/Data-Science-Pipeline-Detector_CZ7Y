{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport calendar\nimport matplotlib.pylab as plt # pyplot + numpy\nfrom IPython.display import HTML # display HTML\nimport warnings\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport datetime\nfrom time import time\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.model_selection import GroupKFold # K fold \nfrom typing import Any\nfrom numba import jit\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\nfrom itertools import product\nimport copy\nimport time\n\nimport random\nseed = 1234\nrandom.seed(seed)\nnp.random.seed(seed)\n\n\nimport os\nimport json\nimport matplotlib.pyplot as plt2\nfrom tqdm import tqdm_notebook as tqdm\n%matplotlib inline\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\npd.set_option('max_columns', 100)\nwarnings.filterwarnings('ignore')\nsns.set_style('darkgrid')\nmy_pal = sns.color_palette(n_colors=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls -GFlash ../input/data-science-bowl-2019/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# original variable for multiple analysis\ntrain_original = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntrain_labels_original = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\ntest_original = pd.read_csv('../input/data-science-bowl-2019/test.csv')\nspecs_original = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\nsample_submission_original = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\ntrain = copy.deepcopy(train_original)\ntrain_labels = copy.deepcopy(train_labels_original)\ntest = copy.deepcopy(test_original)\nspecs = copy.deepcopy(specs_original)\nsample_submission = copy.deepcopy(sample_submission_original)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\ntrain_df = copy.deepcopy(train_original)\ntrain_labels_df = copy.deepcopy(train_labels_original)\ntest_df = copy.deepcopy(test_original)\nspecs_df = copy.deepcopy(specs_original)\nsample_submission_df = copy.deepcopy(sample_submission_original)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\ntrain_df2 = copy.deepcopy(train_original)\ntrain_labels_df2 = copy.deepcopy(train_labels_original)\ntest_df2 = copy.deepcopy(test_original)\nspecs_df2 = copy.deepcopy(specs_original)\nsample_submission_df2 = copy.deepcopy(sample_submission_original)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_id = train_df2[train.type == 'Assessment'][['installation_id']].drop_duplicates()\ntrain_df2 = pd.merge(train, keep_id, on='installation_id', how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth', 800)\nspecs_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum() / data.isnull().count() * 100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return np.transpose(tt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(missing_data(train_df))\ndisplay(missing_data(test_df))\ndisplay(missing_data(train_labels_df))\ndisplay(missing_data(specs_df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unique Values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return np.transpose(tt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(unique_values(train_df))\ndisplay(unique_values(test_df))\ndisplay(unique_values(train_labels_df))\ndisplay(unique_values(specs_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    most_frequent_items = []\n    freqs = []\n    for col in data.columns:\n        most_frequent_item = data[col].value_counts().index[0]\n        freq = data[col].value_counts().values[0]\n        most_frequent_items.append(most_frequent_item)\n        freqs.append(freq)\n    tt['Most frequenct item'] = most_frequent_items\n    tt['Frequency'] = freqs\n    tt['Percent from total'] = np.round(freqs / total * 100, 3)\n    return (np.transpose(tt))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(most_frequent_values(train_df))\ndisplay(most_frequent_values(test_df))\ndisplay(most_frequent_values(train_labels_df))\ndisplay(most_frequent_values(specs_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1, 1, figsize=(4*size, 4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if size > 2:\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x() + p.get_width() / 2., height + 3, '{:1.2f}%'.format(100*height/total), ha='center')\n    plt.show()\n    \n# this function is used to count the number of a specified feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(plot_count('title', 'title (first most frequent 20 values - train)', train_df, size=4))\ndisplay(plot_count('title', 'title (first most frequent 20 values - test)', test_df, size=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('title', 'title - train_labels', train_labels_df, size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('accuracy', 'accuracy - train_labels', train_labels_df, size=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('accuracy_group', 'accuracy_group - train_labels', train_labels_df, size=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('num_correct', 'num_correct - train_labels', train_labels_df, size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('num_incorrect', 'num_incorrect - train_labels', train_labels_df, size=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extract features from train/event_data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train_df = train_df.sample(100000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train_df.iloc[0]['event_data']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nextracted_event_data = pd.io.json.json_normalize(sample_train_df['event_data'].apply(json.loads)) # normalize json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"extracted_event_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(extracted_event_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def existing_data(data):\n    total = data.isnull().count() - data.isnull().sum()\n    percent = 100 - (data.isnull().sum() / data.isnull().count() * 100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    tt = pd.DataFrame(tt.reset_index())\n    \n    return tt.sort_values(['Total'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_event_data = existing_data(extracted_event_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_event_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nsns.set(style='darkgrid')\nax = sns.barplot(x='Percent', y='index', data=stat_event_data.head(40), color='gold')\nplt.title('Most frequent features in event_data')\nplt.ylabel('Features')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extract features from specs/args**"},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_df.iloc[0]['args']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_args_extracted = pd.DataFrame()\nfor i in range(0, specs_df.shape[0]):\n    for item in json.loads(specs_df.args[i]):\n        new_df = pd.DataFrame({'event_id': specs_df['event_id'][i],\\\n                               'info': specs_df['info'],\\\n                               'args_name': item['name'],\\\n                               'args_type': item['type'],\\\n                               'args_info': item['info']}, index=[i]\n                              )\n        specs_args_extracted = specs_args_extracted.append(new_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Extracted args from specs: {specs_args_extracted.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_args_extracted.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = specs_args_extracted.groupby(['event_id'])['event_id'].count() # event - number of arguments per event\ndf = pd.DataFrame({'event_id': tmp.index, 'count': tmp.values})\nplt.figure(figsize=(6, 4))\nsns.set(style='darkgrid')\nax = sns.distplot(df['count'], kde=True, hist=True, bins=30)\nplt.title('Distribution of number of arguments per event_id')\nplt.xlabel('Number of arguments'); plt.ylabel('Density'); plt.show()\n# it is a plot about the density of arguments per event","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('args_name', 'args_name (first 20 most frequent values) - specs', specs_args_extracted, size=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('args_type', 'args_type (first 20 most frequent values) - specs', specs_args_extracted, size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('args_info', 'args_info (first 20 most frequent values) - specs', specs_args_extracted, size=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Merged data distribution**"},{"metadata":{},"cell_type":"markdown","source":"Extract time features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_time_features(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['date'] = df['timestamp'].dt.date\n    df['month'] = df['timestamp'].dt.month\n    df['year'] = df['timestamp'].dt.year\n    df['hour'] = df['timestamp'].dt.hour\n    df['dayofweek'] = df['timestamp'].dt.dayofweek\n    df['weekofyear'] = df['timestamp'].dt.weekofyear\n    df['dayofyear'] = df['timestamp'].dt.dayofyear\n    df['quarter'] = df['timestamp'].dt.quarter\n    df['is_month_start'] = df['timestamp'].dt.is_month_start\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = extract_time_features(train_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = extract_time_features(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('year', 'year - train', train_df, size=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('is_month_start', 'is_month_start - train', train_df, size=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('month', 'month - train', train_df, size=2)\n# do the same with rest of the date info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = ['game_time', 'month', 'dayofweek', 'hour']\ncategorical_columns = ['type', 'world']\n\ncomp_train_df = pd.DataFrame({'installation_id': train_df['installation_id'].unique()})\ncomp_train_df.set_index('installation_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_numeric_columns(df, column):\n    df = df.groupby('installation_id').agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std', 'skew']})\n    df[column].fillna(df[column].mean(), inplace=True)\n    df.columns = [f'{column}_mean', f'{column}_sum', f'{column}_min', f'{column}_max', f'{column}_std', f'{column}_skew']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for numerical_column in numerical_columns:\n    comp_train_df = comp_train_df.merge(get_numeric_columns(train_df, numerical_column), left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'comp_train shape: {comp_train_df.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for some reason the dataframe I produces has game_time_xx_y, droping it and renaming game_time_xx_x to game_time_x\n# comp_train_df.drop(columns=['game_time_mean_y', 'game_time_sum_y', 'game_time_min_y',\n#        'game_time_max_y', 'game_time_std_y', 'game_time_skew_y'], inplace=True)\ncomp_train_df.rename({'game_time_mean_x': 'game_time_mean', 'game_time_sum_x': 'game_time_sum', 'game_time_min_x': 'game_time_min',\n       'game_time_max_x': 'game_time_max', 'game_time_std_x': 'game_time_std', 'game_time_skew_x': 'game_time_skew'}, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels_df.groupby('title')['accuracy_group'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this part I don't understand\nlabels_map = dict(train_labels_df.groupby('title')['accuracy_group'].agg(lambda x: x.value_counts().index[0])) \n# value_counts gets frequencies for different accuracy_group, and get the first value??\nlabels = train_labels_df[['installation_id', 'title', 'accuracy_group']]\nlabels['title'] = labels['title'].map(labels_map)\ncomp_train_df = labels.merge(comp_train_df, on='installation_id', how='left')\nprint('We have {} training rows'.format(comp_train_df.shape[0]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'comp_train_df shape: {comp_train_df.shape}')\nfor feature in comp_train_df.columns.values[3: 20]:\n    print(f'{feature} unique values: {comp_train_df[feature].nunique()}') # dataframe.nunique => series, series => integer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('title', 'title - compound train', comp_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('accuracy_group', 'accuracy_group - compound train', comp_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\n_titles = comp_train_df['title'].unique() # pandas.series.unique => array of unique values\nplt.title('Distribution of log(game time mean) values (grouped by title) in the comp train')\nfor _title in _titles:\n    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title] # find rows where the titles are the same\n    sns.distplot(np.log(red_comp_train_df['game_time_mean']), kde=True, label=f'title: {_title}')\nplt.legend()\nplt.show()\n\n# do the same with different stats features such as game_time_skew, hour_mean, hour_std etc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train label analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.groupby('accuracy_group')['game_session'].count().plot(kind='barh', figsize=(15, 5), title='Target (accuracy group)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# don't really understand how pairplot works\nsns.pairplot(train_labels, hue='accuracy_group')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**train analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change event_id and game_session from hex into integer\ntrain['event_id_as_int'] = train['event_id'].apply(lambda x : int(x, 16))\ntrain['game_session_as_int'] = train['game_session'].apply(lambda x : int(x, 16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time Stamp"},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train['timestamp'][0]) # timestamp is string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['timestamp'], test['timestamp'] = pd.to_datetime(train['timestamp']), pd.to_datetime(test['timestamp']) # convert string into datetime\ntrain['date'], train['hour'], train['weekday_name'] = train['timestamp'].dt.date, train['timestamp'].dt.hour, train['timestamp'].dt.weekday_name\ntest['date'], test['hour'], test['weekday_name'] = test['timestamp'].dt.date, test['timestamp'].dt.hour, test['timestamp'].dt.weekday_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train data has shape: {train.shape}')\nprint(f'Test data has shape: {test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns # train has two more columns - \"game_session_as_int\" and \"event_id_as_int\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('date')['event_id'].agg('count').plot(figsize=(15, 3), title='Number of Event Observations by Date', color='blue')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('hour')['event_id'].agg('count').plot(figsize=(15, 3), title='Number of Event Observations by Date', color='blue')\nplt.show()\n# can see that during 15 - 20 more activities than 5 - 10 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('weekday_name')['event_id'].agg('count').plot(figsize=(15, 3), title='Number of Event Observations by Date', color='blue')\nplt.show()\n# can see that Friday has most activities","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Event data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['event_data'][4])\nprint(train['event_data'][5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"installation_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['installation_id'].nunique() # number of unique installation ids ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('installation_id').count()['event_id'].plot(kind='hist', bins=40, color='pink', figsize=(15, 5), title='Count of Observations by installation_id')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('installation_id').count()['event_id'].apply(np.log1p).plot(kind='hist', bins=40, color='pink', figsize=(15, 5), title='Log(Count) of Observations by installation_id')\nplt.show()\n\n# why log(count)? ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('installation_id').count()['event_id'].sort_values(ascending=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.query('installation_id == \"f1c21eda\"').set_index('timestamp')['event_code'].plot(figsize=(15, 5), title='installation_id #f1c21eda event Id - event code vs time', style='.', color='orange')\nplt.show()\n\n# this graph is not natural, the interface could be installed by a bot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"event_code"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('event_code').count()['event_id'].sort_values().plot(kind='bar', figsize=(15, 5), title='Count of different event codes.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Game_time"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['game_time'].apply(np.log1p).plot(kind='hist', bins=100, title='Log Transform of game_time', color='gold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Game/Video titles"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('title')['event_id'].count().sort_values().plot(kind='barh', title='Count of Observation by Game/Video title', figsize=(15, 15))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Game/Video Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('type')['event_id'].count().sort_values().plot(kind='barh', figsize=(15, 4), title='Count by Type', color='turquoise')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"World"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('world')['event_id'].count().sort_values().plot(kind='bar', figsize=(15, 4), title='Count by World', color='gold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_game_time'] = train['game_time'].apply(np.log1p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\nsns.catplot(x='type', y='log_game_time', data=train.sample(10000), alpha=0.5, ax=ax)\nax.set_title('Distribution of log(game_time) by Type')\nplt.close()\nplt.show()\n\nfig, ax = plt.subplots(figsize=(15, 5))\nsns.catplot(x='world', y='log_game_time', data=train.sample(10000), alpha=0.5, ax=ax)\nax.set_title('Distribution of log(game_time) by World')\nplt.close()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**specs.csv**"},{"metadata":{"trusted":true},"cell_type":"code","source":"specs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs.iloc[0][-2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Baseline Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain['cleared'] = True\ntrain.loc[train['event_data'].str.contains('false') & train['event_code'].isin([4100, 4110]), 'cleared'] = False # why 4100-4110\n\ntest['cleared'] = True\ntest.loc[test['event_data'].str.contains('false') & test['event_code'].isin([4100, 4110]), 'cleared'] = False # why 4100-4110\n\naggs = {'hour':['max', 'min', 'mean'], 'cleared': ['mean']}\n\ntrain_aggs = train.groupby('installation_id').agg(aggs)\ntest_aggs = test.groupby('installation_id').agg(aggs)\n\ntrain_aggs = train_aggs.reset_index()\ntest_aggs = test_aggs.reset_index()\n\ntrain_aggs.columns = ['_'.join(col).strip() for col in train_aggs.columns.values]\ntest_aggs.columns = ['_'.join(col).strip() for col in test_aggs.columns.values]\n\ntrain_aggs = train_aggs.rename(columns={'installation_id_' : 'installation_id'})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_aggs.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_aggs.merge(train_labels[['installation_id', 'accuracy_group']], how='left')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}