{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json\nimport gc\n\nimport dask\nimport dask.dataframe as dd\nfrom dask.diagnostics import ProgressBar\nfrom dask.distributed import Client, progress\npbar = ProgressBar()\npbar.register()\n\nimport statsmodels\nimport seaborn as sns\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport numexpr \nnumexpr.set_num_threads(1)\n\nimport os\ndef print_log(string):\n    os.system(f'echo \\\"{string}\\\"')\n    print(string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset():\n    print_log(\"Loading dataset ...\")\n    data_dtype = {\"world\": \"category\", \"type\": \"category\", \"title\": \"category\", \"event_code\": \"category\", \"game_session\": \"category\",\n               \"event_count\": \"uint8\", \"game_time\": \"uint32\",\n               \"event_data\": \"str\", \"event_id\": \"category\", \"installation_id\": \"category\"}\n    df_train = pd.read_csv(\"../input/data-science-bowl-2019/train.csv\", parse_dates=[\"timestamp\"], dtype=data_dtype)\n    \n    assessment_attempt_query = \"((event_code=='4100' & title!='Bird Measurer (Assessment)') | (event_code=='4110' & title=='Bird Measurer (Assessment)'))\"\n    attempts_query = \"type=='Assessment' & \" +  assessment_attempt_query\n    ids = df_train.query(attempts_query).installation_id.unique().tolist()\n    df_train = df_train[df_train.installation_id.isin(ids)].sort_values([\"installation_id\", \"timestamp\"])\n    gc.collect()\n    \n    print_log(\"Grouping each game session by Assessment ...\")\n    # List of Assessment game sessions with an accuracy group\n    df_train_labels = pd.read_csv(\"../input/data-science-bowl-2019/train_labels.csv\")\n    assessment_gs_labels = df_train_labels.game_session.tolist()\n\n    # Construct a map of game_session to index (e.g 0,1,2...,n)\n    df_train = df_train.reset_index().drop(columns=[\"index\"])\n    gs_index_map = df_train[df_train.game_session.isin(assessment_gs_labels)]\\\n        .groupby([\"game_session\"]).tail(1).reset_index()\\\n        .set_index(\"game_session\")[\"index\"].to_dict()\n    gs_index_map.update({0: 0})\n    \n    # Create a map of game_session to labeled accuracy group (e.g 0,1,2,3)\n    gs_accgroup_map = df_train_labels.set_index(\"game_session\")\n    \n    # Same with assessment_gs_labels but preserves ordering of game_session per installation_id\n    game_session_list = list(gs_index_map.keys())\n    game_session_list.insert(0, 0)\n    \n    # Construct a dataframe which tells what group of indexes in the dataset will be used to evaluate a given Assessment\n    df_gs_map = pd.Series(game_session_list).to_frame().rename(columns={0: \"start_gs\"})\n    df_gs_map[\"game_session\"] = df_gs_map.start_gs.shift(-1)\n    df_gs_map[\"accuracy_group\"] = df_gs_map.game_session.map(gs_accgroup_map.accuracy_group.to_dict())\n    df_gs_map[\"start_gs\"] = df_gs_map.start_gs.map(gs_index_map)\n    df_gs_map[\"end_gs\"] = df_gs_map.start_gs.shift(-1)\n    df_gs_map = df_gs_map[:-2]\n    \n    # Construct a series for which Assessment game session each index belongs to \n    # Counts how many game session for each group of indexes to be created\n    print_log(\"Creating gs_to_eval variable ...\")\n    gs_list = list()\n    for i, row in enumerate(df_gs_map.itertuples()):\n        quantity = int(row.end_gs-row.start_gs)\n        quantity = quantity + (1 if i==0 else 0)\n        gs_list.extend([row.game_session]*quantity)\n    df_gs_to_eval = pd.Series(gs_list).to_frame()\n    gc.collect()\n    \n    # Concatenate the series into the dataset and map the accuracy group accordingly\n    df_train = pd.concat([df_train, df_gs_to_eval], axis=1).rename(columns={0: \"gs_to_eval\"})\n    df_train[\"accuracy_group\"] = df_train[\"gs_to_eval\"].map(gs_accgroup_map.accuracy_group.to_dict()).astype(\"category\")\n\n    return df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nclass PropExtractor():\n    def __init__(self, prop):\n        self.prop = prop\n    \n    def extract_bool(self, event_data):\n        prop = re.findall(r\"(?<=\" + self.prop + \"\\\"\\:)\\s?\\w+\", event_data)\n        if len(prop) > 0:\n            return 1 if prop[0].strip()==\"true\" else 0\n        else:\n            return -1\n        \n    def extract_int(self, event_data):\n        prop = re.findall(r\"(?<=\" + self.prop + \"\\\"\\:)\\s?\\d+\", event_data)\n        if len(prop) > 0:\n            return int(prop[0].strip())\n        else:\n            return -1\n        \n    def extract_string(self, event_data):\n        prop = re.findall(r\"(?<=\" + self.prop + \"\\\"\\:\\\")\\s?\\w+\", event_data)\n        if len(prop) > 0:\n            return prop[0].strip()\n        else:\n            return \"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_args(df_train):\n    print_log(\"Extracting media_type ...\")\n    argsint = [\"level\", \"misses\", \"dwell_time\", \"round\", \"duration\", \"total_duration\"]\n    df_train[\"media_type\"] = df_train.event_data.map(PropExtractor(\"media_type\").extract_string).astype(\"category\")\n    \n    print_log(\"Extracting correct ...\")\n    df_train[\"correct\"] = df_train.event_data.map(PropExtractor(\"correct\").extract_bool).astype(\"int8\")\n    \n    for args in argsint:\n        print_log(\" \".join([\"Extracting\", str(args), \"...\"]))\n        df_train[args] = df_train.event_data.map(PropExtractor(args).extract_int)\n        \n    return df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_prev_assessment(df_train):\n    gs_list = df_train.gs_to_eval.unique().tolist()\n    gs_with_prev_assess = df_train[(df_train[\"type\"]==\"Assessment\") & ~df_train.game_session.isin(gs_list)].groupby([\"gs_to_eval\"]).head(1).gs_to_eval.tolist()\n    df_train[\"has_prev_assessment\"] = False\n    df_train.loc[df_train.gs_to_eval.isin(gs_with_prev_assess), \"has_prev_assessment\"] = True\n    \n    return df_train\n\ndef add_difficult(df_train):\n    df_specs = pd.read_csv(\"../input/data-science-bowl-2019/specs.csv\")\n    df_specs[\"is_difficult\"] = False\n    df_specs.loc[df_specs[\"info\"].str.contains(\"difficult\"), \"is_difficult\"] = True\n\n    df_train[\"is_difficult\"] = False\n    event_id_difficult = df_specs[df_specs.is_difficult].event_id.tolist()\n    df_train.loc[df_train.event_id.isin(event_id_difficult), \"is_difficult\"] = True\n    \n    return df_train \n\ndef add_clip_duration(df_train):\n    df_media = pd.read_csv(\"../input/data-science-bowl-2019-media-sequence/media_sequence.csv\")\n    clip_duration_map = df_media.set_index(\"title\").duration.to_dict()\n\n    df_train.loc[df_train[\"type\"]=='Clip', \"duration\"] = df_train[df_train[\"type\"]=='Clip'].title.map(clip_duration_map)\n    df_train[\"prev_ts\"] = df_train.timestamp.shift(-1)\n    df_train[\"clip_runtime\"] = (df_train.prev_ts - df_train.timestamp).dt.total_seconds()\n\n    completed_clips = (df_train[\"type\"]==\"Clip\") & ((df_train.clip_runtime > df_train.duration) | (df_train.clip_runtime <= 0))\n    df_train.loc[completed_clips, \"clip_runtime\"] =  df_train[completed_clips].duration\n    df_train[\"is_completed\"] =  False\n    df_train.loc[completed_clips, \"is_completed\"] =  True\n    \n    return df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_cap_val = dict()\ndef remove_outliers(df, col, extreme=None):\n#     q1 = df[col].quantile(0.25)\n#     q3 = df[col].quantile(0.75)\n    \n#     iqr = q3 - q1\n#     iqr_multiplier = extreme if extreme else 1.5\n#     lower_limit = q1 - (iqr_multiplier*iqr)\n#     upper_limit = q3 + (iqr_multiplier*iqr)\n    \n#     iqr_lower_filter = df[col] >= lower_limit\n#     iqr_upper_filter = df[col] <= upper_limit\n#     iqr_filter = iqr_lower_filter & iqr_upper_filter\n#     outliers = df[~iqr_filter]\n    \n#     df = df.copy()\n#     df.loc[df[col] < lower_limit, col] = lower_limit\n#     df.loc[df[col] > upper_limit, col] = upper_limit\n#     outlier_cap_val[col] = (lower_limit, upper_limit)\n    \n#     outlier_percent = len(outliers)/(len(df))*100\n#     print(\"Percentage of oultiers for\", col, \":\", outlier_percent)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def handle_outliers(df_train):\n    \n    df_correct = remove_outliers(df_correct, \"correct\")\n    df_correct = remove_outliers(df_correct, \"round\")\n#     df_level = remove_outliers(df_level, \"level_min\")\n#     df_level = remove_outliers(df_level, \"level_max\")\n    df_level = remove_outliers(df_level, \"level_mean\")\n    \n#     df_misses = remove_outliers(df_misses, \"misses_sum\")\n#     df_misses = remove_outliers(df_misses, \"misses_mean\")\n#     df_misses = remove_outliers(df_misses, \"misses_max\")\n    df_misses = remove_outliers(df_misses, \"miss_rate_gs\")\n#     df_misses = remove_outliers(df_misses, \"miss_rate_round\")\n\n#     df_dwell = remove_outliers(df_dwell, \"dwell_time_max\")\n#     df_dwell = remove_outliers(df_dwell, \"dwell_time_sum\")\n    df_dwell = remove_outliers(df_dwell, \"dwell_time_mean\")\n    \n    df_correct = remove_outliers(df_correct, \"drag_time\")\n    df_correct = remove_outliers(df_correct, \"has_prev_assessment\")\n#     df_correct = remove_outliers(df_correct, \"correct_ratio_drag_duration\")\n\n    df_media_playback = remove_outliers(df_media_playback, \"total_duration\")\n    df_media_playback = remove_outliers(df_media_playback, \"is_interrupted\")\n    \n#     df_clip = remove_outliers(df_clip, \"clip_runtime\")\n#     df_clip = remove_outliers(df_clip, \"is_completed\")\n\n#     for col in df_eventcode.columns:\n#         df_eventcode = remove_outliers(df_eventcode, col, extreme=3.0)\n\n#     df_correct = remove_outliers(df_correct, \"duration\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accumulate(df, col, op):\n    gs_to_eval = df[\"gs_to_eval\"].to_dict()\n    if op == \"mean\":\n        df = df.groupby([\"installation_id\"])[[col]].expanding().mean().reset_index()\n    elif op == \"sum\":\n        df = df.groupby([\"installation_id\"])[[col]].expanding().sum().reset_index()\n    df[\"gs_to_eval\"] = df[\"level_1\"].map(gs_to_eval)\n    df = df.drop(columns=[\"level_1\"]).groupby([\"gs_to_eval\"]).tail(1).set_index(\"gs_to_eval\")[[col]]\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Capped outliers\ndef correct_game_agg(df_train):\n    df_correct = df_train[(df_train[\"type\"]==\"Game\") & (df_train.correct!=-1)]\n    \n    max_rounds = df_correct.groupby([\"installation_id\", \"title\", \"game_session\"]).tail(1)\n    max_rounds = max_rounds.groupby([\"installation_id\"]).mean()[\"round\"]\n    df_correct = df_correct.groupby([\"installation_id\"]).mean().drop(columns=[\"round\"])\n    df_correct = df_correct.join(max_rounds)[[\"correct\", \"round\"]]\n    \n    return df_correct\n\n# Capped outliers\ndef level_agg(df_train):\n    df_level = df_train[df_train.level != -1]\n    \n    df_level = df_level.groupby([\"installation_id\", \"game_session\"]).tail(1)\\\n        .groupby([\"installation_id\"]).agg([\"min\", \"max\", \"mean\"])\n    df_level.columns = [\"_\".join(col) for col in df_level.columns]\n    df_level = df_level.reset_index().set_index(\"installation_id\")[[\"level_mean\"]]\n    \n    return df_level\n\n# Capped outliers\ndef media_playback_agg(df_train):\n    df_media_playback = df_train[(df_train.media_type!=\"\") & ((df_train[\"type\"]==\"Game\") | (df_train[\"type\"]==\"Activity\"))]\n\n    df_media_playback[\"is_interrupted\"] = df_media_playback.total_duration == -1\n    df_media_playback.loc[df_media_playback.is_interrupted, \"total_duration\"] = df_media_playback[df_media_playback.is_interrupted].duration\n    \n    num_isinterrupted = df_media_playback.groupby([\"installation_id\"]).mean().is_interrupted\n    df_media_playback = df_media_playback.groupby([\"installation_id\", \"title\", \"media_type\", \"game_session\"], observed=True).sum().reset_index()\n    df_media_playback = df_media_playback.groupby([\"installation_id\", \"title\", \"media_type\"], observed=True).mean().reset_index()\n    df_media_playback = df_media_playback.groupby([\"installation_id\"], observed=True).sum()\n    df_media_playback = df_media_playback.drop(columns=[\"is_interrupted\"]).join(num_isinterrupted)\n    df_media_playback = df_media_playback[[\"total_duration\", \"is_interrupted\"]]\n    \n    return df_media_playback\n\ndef misses_assess_agg(df_train):\n    df_misses = df_train[(df_train.misses!=-1) & (df_train[\"type\"]==\"Assessment\")]\n    return misses_agg(df_misses, \"assess\")\n    \ndef misses_game_agg(df_train):\n    df_misses = df_train[(df_train.misses!=-1) & ((df_train[\"type\"]==\"Game\") | (df_train[\"type\"]==\"Activity\"))]\n    return misses_agg(df_misses, \"game\")\n    \n# Capped outliers\ndef misses_agg(df_misses, prefix):\n    df_misses = df_misses.sort_values([\"installation_id\", \"game_session\"])\n\n    avg_miss_per_round = df_misses.groupby([\"installation_id\", \"round\"], observed=True).mean()[[\"misses\"]].reset_index()\n    total_avg_miss_per_round = avg_miss_per_round.groupby([\"installation_id\"]).sum()[[\"misses\"]]\n    max_round_per_gs = avg_miss_per_round.groupby([\"installation_id\"]).tail(1).set_index([\"installation_id\"])[[\"round\"]]\n    miss_rate_per_max_round = total_avg_miss_per_round.join(max_round_per_gs)\n    miss_rate_per_max_round[\"miss_rate_round\"] = miss_rate_per_max_round[\"misses\"] / miss_rate_per_max_round[\"round\"]\n    miss_rate_per_max_round = miss_rate_per_max_round.drop(columns=[\"misses\", \"round\"])\n\n    total_miss_per_gs = df_misses.groupby([\"installation_id\", \"game_session\"], observed=True).sum()[[\"misses\"]]\n    max_round_per_local_gs = df_misses.groupby([\"installation_id\", \"game_session\"], observed=True).tail(1).set_index([\"installation_id\", \"game_session\"])[[\"round\"]]\n    avg_miss_per_local_gs_round = total_miss_per_gs.join(max_round_per_local_gs)\n    avg_miss_per_local_gs_round[\"miss_rate_gs\"] = avg_miss_per_local_gs_round[\"misses\"] / avg_miss_per_local_gs_round[\"round\"]\n    avg_miss_per_local_gs_round = avg_miss_per_local_gs_round.groupby([\"installation_id\"]).mean().drop(columns=[\"misses\", \"round\"])\n    \n    df_misses = df_misses.groupby([\"installation_id\"], observed=True).agg([\"sum\", \"mean\", \"max\"])[[\"misses\"]]\n    df_misses.columns = ['_'.join(col) for col in df_misses.columns]\n    df_misses = df_misses.join(avg_miss_per_local_gs_round).join(miss_rate_per_max_round)[[\"miss_rate_gs\"]]\n    \n    df_misses.columns = [\"_\".join([prefix, col]) for col in df_misses.columns]\n    \n    return df_misses\n\n# Capped outliers\ndef dwell_time_agg(df_train):\n    df_dwell = df_train[df_train.dwell_time!=-1]\n    \n    df_dwell = df_dwell.groupby([\"installation_id\"], observed=True).agg([\"max\", \"sum\", \"mean\"])\n    df_dwell.columns = [\"_\".join(col) for col in df_dwell.columns]\n    df_dwell = df_dwell[[\"dwell_time_mean\"]]\n    \n    return df_dwell\n\ndef clip_runtime_agg(df_train):\n    df_clip = df_train[df_train[\"type\"]=='Clip']\n\n    num_completed = df_clip.groupby([\"installation_id\"]).mean().is_completed\n    df_clip = df_clip.groupby([\"installation_id\", \"title\"], observed=True).mean()\n    df_clip = df_clip.groupby([\"installation_id\"]).sum()\n    df_clip = df_clip.drop(columns=[\"is_completed\"]).join(num_completed)\n    df_clip = df_clip[[\"clip_runtime\", \"is_completed\"]]\n    \n    return df_clip\n\ndef is_difficult_agg(df_train): \n    df_difficult = df_train.groupby([\"installation_id\"]).mean()[[\"is_difficult\"]]\n    return df_difficult\n\ndef event_code_agg(df_train):\n    df_eventcode = df_train.groupby([\"installation_id\", \"event_code\"]).count()[[\"event_count\"]].fillna(np.nan).reset_index()\\\n            .pivot(columns=\"event_code\", index=\"installation_id\", values=[\"event_count\"])\n    df_eventcode.columns = [\"_\".join(col) for col in df_eventcode.columns]\n    for col in df_eventcode.columns:\n        df_eventcode = remove_outliers(df_eventcode, col, extreme=3.0)\n    \n    return df_eventcode\n\n# Capped outliers\ndef assessment_agg(df_train):\n    gs_list = df_train.gs_to_eval.unique().tolist()\n    df_assessment = df_train[(df_train[\"type\"]==\"Assessment\") & ~df_train.game_session.isin(gs_list)]\n    \n    df_assessment_count = df_assessment.groupby([\"installation_id\", \"game_session\"]).head(1)\n    df_assessment_count = df_assessment_count.groupby([\"installation_id\"]).sum()[[\"has_prev_assessment\"]]\n    \n    df_correct = df_assessment[(df_train.correct!=-1)]\n    df_correct = remove_outliers(df_correct, \"duration\")\n    drag_time = df_correct[df_correct.duration!=-1].groupby([\"installation_id\"]).mean()[[\"duration\"]].rename(columns={\"duration\":\"drag_time\"})\n    df_correct = df_correct.groupby([\"installation_id\"]).mean().rename(columns={\"correct\": \"correct_assessment\"})\n    df_correct = df_correct.join(drag_time)[[\"correct_assessment\", \"drag_time\"]]\n    \n    df_correct = df_correct.join(df_assessment_count)\n    \n    return df_correct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def aggregate_data(df_train):\n    print_log(\"Aggregating variables by player ...\")\n    df_train_data = pd.read_csv(\"../input/data-science-bowl-2019/train_labels.csv\")\n    df_train_data = df_train_data[[\"game_session\", \"installation_id\", \"accuracy_group\"]]\n#     df_train_data = df_train.groupby([\"gs_to_eval\"]).head(1).set_index(\"gs_to_eval\")[[\"accuracy_group\", \"installation_id\"]]\n    df_train_data = df_train_data.merge(correct_game_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(level_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(media_playback_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(misses_game_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(misses_assess_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(dwell_time_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(clip_runtime_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(is_difficult_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(event_code_agg(df_train), on='installation_id', how='left')\n    df_train_data = df_train_data.merge(assessment_agg(df_train).fillna(0), on='installation_id', how='left')\n    \n    df_train_data = df_train_data.drop(columns=[\"event_count_2010\", \"event_count_2035\", \"event_count_2075\", \n                                                \"event_count_3010\", \"event_count_3020\", \"event_count_3021\",\n                                                \"event_count_2040\", \"event_count_2050\", \"event_count_2030\",\n                                               \"event_count_2020\", \"event_count_4235\", \"event_count_5010\",\n                                               \"event_count_2000\"])\n    return df_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution_mean(df_train_data):\n    df_train_labels = pd.read_csv(\"../input/data-science-bowl-2019/train_labels.csv\")\n    class_min = df_train_labels.accuracy_group.value_counts().min()\n    sampled_gs = df_train_labels.groupby([\"accuracy_group\"]).apply(lambda x: x.sample(class_min, random_state=1)).game_session.tolist()\n    df_train_sample = df_train_data.reset_index()[df_train_data.reset_index().gs_to_eval.isin(sampled_gs)]\n\n    variable_num = len(df_train_sample.columns)-2\n    f, ax = plt.subplots(variable_num,2,figsize=(25,7*variable_num))\n    for i, col in enumerate(df_train_sample.columns[2:]):\n        df_plot = df_train_sample[~df_train_sample[col].isnull()]\n        sns.boxenplot(x=col, y=\"accuracy_group\", data=df_plot, ax=ax[i, 0])\n        sns.pointplot(x=col, y=\"accuracy_group\", data=df_plot, ax=ax[i, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.api.types import is_numeric_dtype\ndef print_missing_percent(df_train_data):\n    for col in df_train_data.columns:\n        if(is_numeric_dtype(df_train_data[col])):\n            print(col, \"Percentage of missing values:\", df_train_data[col].isnull().mean(), \"====\",\"Minimum value:\", df_train_data[col].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_missing_values(df_train_data):\n    df_train_data[\"correct\"] = df_train_data[\"correct\"].fillna(-1)\n#     df_train_data[\"correct_ratio_round\"] = df_train_data[\"correct_ratio_round\"].fillna(-1)\n\n#     df_train_data[\"level_min\"] = df_train_data[\"level_min\"].fillna(-1)\n#     df_train_data[\"level_max\"] = df_train_data[\"level_max\"].fillna(-1)\n    df_train_data[\"level_mean\"] = df_train_data[\"level_mean\"].fillna(-1)\n\n#     df_train_data[\"game_misses_sum\"] = df_train_data[\"game_misses_sum\"].fillna(-1)\n#     df_train_data[\"game_misses_mean\"] = df_train_data[\"game_misses_mean\"].fillna(-1)\n#     df_train_data[\"game_misses_max\"] = df_train_data[\"game_misses_max\"].fillna(-1)\n    df_train_data[\"game_miss_rate_gs\"] = df_train_data[\"game_miss_rate_gs\"].fillna(-1)\n#     df_train_data[\"game_miss_rate_round\"] = df_train_data[\"game_miss_rate_round\"].fillna(-1)\n\n#     df_train_data[\"assess_misses_sum\"] = df_train_data[\"assess_misses_sum\"].fillna(-1)\n#     df_train_data[\"assess_misses_mean\"] = df_train_data[\"assess_misses_mean\"].fillna(-1)\n#     df_train_data[\"assess_misses_max\"] = df_train_data[\"assess_misses_max\"].fillna(-1)\n    df_train_data[\"assess_miss_rate_gs\"] = df_train_data[\"assess_miss_rate_gs\"].fillna(-1)\n#     df_train_data[\"assess_miss_rate_round\"] = df_train_data[\"assess_miss_rate_round\"].fillna(-1)\n\n#     df_train_data[\"dwell_time_max\"] = df_train_data[\"dwell_time_max\"].fillna(-1)\n    df_train_data[\"dwell_time_mean\"] = df_train_data[\"dwell_time_mean\"].fillna(-1)\n#     df_train_data[\"dwell_time_sum\"] = df_train_data[\"dwell_time_sum\"].fillna(-1)\n\n    df_train_data[\"is_completed\"] = df_train_data[\"is_completed\"].fillna(-1)\n    df_train_data[\"correct_assessment\"] = df_train_data[\"correct_assessment\"].fillna(-1)\n    df_train_data[\"drag_time\"] = df_train_data[\"drag_time\"].fillna(-1)\n#     df_train_data[\"correct_ratio_drag_duration\"] = df_train_data[\"correct_ratio_drag_duration\"].fillna(-1)\n\n    df_train_data[\"total_duration\"] = df_train_data[\"total_duration\"].fillna(0)\n    df_train_data[\"is_interrupted\"] = df_train_data[\"is_interrupted\"].fillna(0)\n    df_train_data[\"round\"] = df_train_data[\"round\"].fillna(0)\n    df_train_data[\"clip_runtime\"] = df_train_data[\"clip_runtime\"].fillna(0)\n    df_train_data[\"has_prev_assessment\"] = df_train_data[\"has_prev_assessment\"].fillna(0)\n\n    event_code_cols = [col for col in df_train_data.columns if \"event_count\" in col] \n    df_train_data[event_code_cols] = df_train_data[event_code_cols].fillna(0)\n    \n    plt.figure(figsize=(30, 30))\n    sns.heatmap(df_train_data.corr(), annot=True, fmt=\".1f\").set_title(\"Correlational Matrix\")\n    \n    return df_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compile_train_data():\n    df_train = load_dataset()\n    gc.collect()\n    df_train = extract_args(df_train)\n    gc.collect()\n    print_log(\"Adding additional variables\")\n    df_train = add_clip_duration(df_train)\n    gc.collect()\n    df_train = add_difficult(df_train)\n    gc.collect()\n    df_train = add_prev_assessment(df_train)\n    gc.collect()\n    df_train_data = aggregate_data(df_train)\n    gc.collect()\n#     plot_distribution_mean(df_train_data)\n#     print_missing_percent(df_train_data)\n#     df_train_data = fill_missing_values(df_train_data)\n#     gc.collect()\n    \n    return df_train_data\n\ndf_train_data = compile_train_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_index_map = df_train[df_train.game_session==df_train.gs_to_eval].groupby([\"gs_to_eval\"]).head(1).reset_index().set_index(\"gs_to_eval\")[[\"index\"]]\ngs_index_map[\"index\"] = gs_index_map[\"index\"] - 1\ngs_index_map = gs_index_map[\"index\"].to_dict()\nid_index_map = df_train.groupby([\"installation_id\"]).head(1).reset_index().set_index(\"installation_id\")[\"index\"].to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 30))\nsns.heatmap(df_train_data.drop(columns=[\"installation_id\"]).corr(), annot=True, fmt=\".1f\").set_title(\"Correlational Matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.experimental import enable_hist_gradient_boosting  # noqa\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_validate, learning_curve, GroupKFold\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, cohen_kappa_score, make_scorer\nfrom sklearn.model_selection import train_test_split\n\ndef validate_model(rfc, X_train, y_train, groups):\n    scoring_list = {\"accuracy\": make_scorer(accuracy_score), \n                    \"precision_weighted\": make_scorer(precision_score, average=\"weighted\"), \n                    \"recall_weighted\": make_scorer(recall_score, average=\"weighted\"), \n                    \"f1_weighted\": make_scorer(f1_score, average=\"weighted\"), \n                    \"quadratic_kappa\": make_scorer(cohen_kappa_score, weights=\"quadratic\")}\n    scores = cross_validate(rfc, X_train, y_train, \n                            cv=GroupKFold(3).split(X_train, y_train, groups=groups),\n                            scoring=scoring_list, return_train_score=True, n_jobs=-1)\n#     print(\"Accuracy score (train set):\", np.mean(scores[\"train_accuracy\"]))\n#     print(\"Accuracy score (validation set):\", np.mean(scores[\"test_accuracy\"]), \"\\n\")\n    \n#     print(\"Precision score (train set):\", np.mean(scores[\"train_precision_weighted\"]))\n#     print(\"Precision score (validation set):\", np.mean(scores[\"test_precision_weighted\"]), \"\\n\")\n    \n#     print(\"Recall score (train set):\", np.mean(scores[\"train_recall_weighted\"]))\n#     print(\"Recall score (validation set):\", np.mean(scores[\"test_recall_weighted\"]), \"\\n\")\n    \n#     print(\"F1 score (train set):\", np.mean(scores[\"train_f1_weighted\"]))\n#     print(\"F1 score (validation set):\", np.mean(scores[\"test_f1_weighted\"]), \"\\n\")\n    \n    print(\"Quadratic Kappa score (train set):\", np.mean(scores[\"train_quadratic_kappa\"]))\n    print(\"Quadratic Kappa score (validation set):\", np.mean(scores[\"test_quadratic_kappa\"]))\n\ndfx_train = df_train_data.drop(columns=[\"accuracy_group\", \"game_session\", \"installation_id\"]).to_numpy()\ndfy_train = df_train_data[\"accuracy_group\"].to_numpy().ravel()\ncweights = dict(zip(range(4), compute_class_weight(class_weight=\"balanced\", classes=np.unique(dfy_train), y=dfy_train)))\nkappa_score = make_scorer(cohen_kappa_score, weights=\"quadratic\")\n\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nencoder.fit(df_train_data.installation_id.unique().tolist())\nid_groups = encoder.transform(df_train_data.installation_id.values)\n\nfor train_index, test_index in GroupKFold().split(dfx_train, dfy_train, groups=id_groups):\n    X_train, X_test = dfx_train[train_index], dfx_train[train_index]\n    y_train, y_test = dfy_train[train_index], dfy_train[train_index]\n    rfc = HistGradientBoostingClassifier(loss=\"categorical_crossentropy\", learning_rate=0.1, max_iter=100, max_depth=None, l2_regularization=1,\n                                        max_bins=255, scoring=kappa_score, validation_fraction=0.25, verbose=0, random_state=1)\n    validate_model(rfc, X_train, y_train, id_groups[train_index])\n    \n    rfc.fit(X_train, y_train)\n    preds = rfc.predict(X_test)\n    print(\"Quadratic Kappa score: (test set)\", cohen_kappa_score(y_test, preds, weights=\"quadratic\"), \"====\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\ndef plot_learning_curve(rfc, X, y, groups, scoring):\n    sns.set()\n    train_sizes = list(range(707, int(len(y)*0.8), 707))\n    rfc_curve = learning_curve(rfc, X, y, train_sizes=train_sizes, n_jobs=-1, cv=GroupKFold(5).split(X, y, groups=groups), random_state=1, scoring=scoring, verbose=4)\n\n    df_lcurve = pd.DataFrame(0, columns=[\"training_size\", \"score\", \"type\"], index=range(len(train_sizes)*2))\n    iteration_run = list(rfc_curve[0])\n    iteration_run.extend(rfc_curve[0])\n    df_lcurve[\"training_size\"] = iteration_run\n\n    score_run = [np.mean(col) for col in rfc_curve[1]]\n    score_run.extend([np.mean(col) for col in rfc_curve[2]])\n    df_lcurve[\"score\"] = score_run\n    df_lcurve[\"type\"] = \"train\"\n    df_lcurve.loc[len(train_sizes):,\"type\"] = \"validation\"\n\n    g = sns.relplot(kind=\"line\", y=\"score\", x=\"training_size\", data=df_lcurve, hue=\"type\", style=\"type\", markers=True, dashes=False)\n    g.fig.suptitle(\" \".join([str(scoring), \"Performance over Training size\"]))\n    g.fig.set_figwidth(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################ Grid Search ################\nfrom sklearn.model_selection import GridSearchCV\nrfc = HistGradientBoostingClassifier(loss=\"categorical_crossentropy\", max_iter=100, n_iter_no_change=25, scoring=kappa_score, validation_fraction=0.25, verbose=4, random_state=1)\nparam_grid = {\"max_bins\": [9, 10, 11], \"l2_regularization\": [0, 0.01, 0.015], \"max_bins\": [9, 10, 11], \"max_depth\": [5, 6, 7]}\ngsc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring=kappa_score, n_jobs=-1, verbose=4, cv=GroupKFold(3).split(dfx_train, dfy_train, groups=id_groups))\ngrid_result = gsc.fit(dfx_train, dfy_train)\ngrid_result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = HistGradientBoostingClassifier(loss=\"categorical_crossentropy\", learning_rate=0.1, max_iter=100, n_iter_no_change=25, max_depth=6, l2_regularization=0.01,\n                                        max_bins=9, scoring=kappa_score, validation_fraction=0.25, verbose=4, random_state=1)\nvalidate_model(rfc, dfx_train, dfy_train, id_groups)\nplot_learning_curve(rfc, dfx_train, dfy_train, id_groups, kappa_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfor train_index, test_index in GroupKFold(5).split(dfx_train, dfy_train, groups=id_groups):\n    X_train, X_test = dfx_train[train_index], dfx_train[train_index]\n    y_train, y_test = dfy_train[train_index], dfy_train[train_index]\n    rfc = HistGradientBoostingClassifier(loss=\"categorical_crossentropy\", learning_rate=0.1, max_iter=100, n_iter_no_change=25,\n                                         max_depth=6, l2_regularization=0.01, max_bins=9, scoring=kappa_score, \n                                         validation_fraction=0.25, verbose=0, random_state=1)\n    rfc.fit(X_train, y_train)\n    preds = rfc.predict(X_test)\n    print(\"Quadratic Kappa score: (test set)\", cohen_kappa_score(y_test, preds, weights=\"quadratic\"))\n    print(\"ROC Area Under Curve Score: \", roc_auc_score(y_test, rfc.predict_proba(X_test), multi_class=\"ovo\"), \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from joblib import dump\nrfc = HistGradientBoostingClassifier(loss=\"categorical_crossentropy\", learning_rate=0.1, max_iter=100, n_iter_no_change=25,\n                                         max_depth=6, l2_regularization=0.01, max_bins=9, scoring=kappa_score, validation_fraction=0.25, \n                                         verbose=4, random_state=1)\nrfc.fit(dfx_train, dfy_train)\ndump(rfc, \"rfc_accgroup_model.joblib\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}