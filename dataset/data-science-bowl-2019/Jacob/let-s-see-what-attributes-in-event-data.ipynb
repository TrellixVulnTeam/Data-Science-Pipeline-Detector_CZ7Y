{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This Kernel is a start point to analyze attributes of events\n\nThe `event_data` column is informative, but hard to break down, especially with the time and memory limitation.\nThis kernel gives a chunk-wise data loading and the distribution of attributes in both train and test data."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport gc\nimport ast\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('max_columns', 100)\npd.set_option('max_rows', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_csv = '/kaggle/input/data-science-bowl-2019/train.csv'\ntest_csv = '/kaggle/input/data-science-bowl-2019/test.csv'\nspecs_csv = '/kaggle/input/data-science-bowl-2019/specs.csv'\n\nall_train_event_attributes, all_test_event_attributes = [], []\ntrain_count, test_count = 0, 0\nfor chunk in pd.read_csv(train_csv,chunksize=10000):\n    chunk_attributes = chunk['event_data'].apply(lambda x: list(json.loads(x).keys()))\n    all_train_event_attributes.extend([y for x in chunk_attributes.to_list() for y in x])\n    train_count += chunk.shape[0]\n    \nfor chunk in pd.read_csv(test_csv,chunksize=10000):\n    chunk_attributes = chunk['event_data'].apply(lambda x: list(json.loads(x).keys()))\n    all_test_event_attributes.extend([y for x in chunk_attributes.to_list() for y in x])\n    test_count += chunk.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncount_train = Counter(all_train_event_attributes)\ncount_test = Counter(all_test_event_attributes)\n\ndef get_count_df(count_dict, total):\n    df = pd.DataFrame.from_dict(count_dict, orient='index')\n    df['attribute']=df.index\n    df.columns = ['count', 'attribute']\n    df.sort_values(by=['count'], axis=0, ascending=False, inplace=True)\n    df['pct'] = df['count'] / total\n    return df\n\ncount_train_df = get_count_df(count_train, train_count)\ncount_test_df = get_count_df(count_test, test_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 30))\nsns.set(style='whitegrid')\nax = sns.barplot(x='pct', y='attribute', data=count_train_df.head(50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 30))\nsns.set(style='whitegrid')\nax = sns.barplot(x='pct', y='attribute', data=count_test_df.head(50))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### to check the attributes to which events, we can check spec table"},{"metadata":{"trusted":true},"cell_type":"code","source":"specs = pd.read_csv(specs_csv)\nspecs_parse = lambda _col:str([x['name'] for x in json.loads(_col)])\nspecs['attribute_list'] = specs['args'].apply(lambda _col: specs_parse(_col))\nspecs.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}