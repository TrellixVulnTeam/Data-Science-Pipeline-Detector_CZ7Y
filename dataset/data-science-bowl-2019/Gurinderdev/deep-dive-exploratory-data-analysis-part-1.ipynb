{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport json\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n%matplotlib inline\n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cd '/kaggle/input/data-science-bowl-2019'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the data into a pandas dataframe\ntrain = pd.read_csv('train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task at hand \nPredicting the learning curve of children from a learning app. \nSpecificly how many attempts would a child take to pass an exam!\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Lay of the land:\nThe data is from a mobile app - measure up -  which aims to imporve quant skills in kids.- pretty noble I say. \n\nWe can access the online version of the app here : https://measureup.pbskids.org/\n\nHow does it look:  https://drive.google.com/open?id=1auGJpXesLS1GjatwUVrVpwBVwZwNJzhl\n\n"},{"metadata":{},"cell_type":"markdown","source":"# What data files are we given \n\n* Train\n* Test\n* train_labels\n* Specs"},{"metadata":{},"cell_type":"markdown","source":"In this first part of the Deep Dive series, we will cover the train data in detail."},{"metadata":{},"cell_type":"markdown","source":"# Overview of column names \n- **Installation id** refers to one child- the user of the app. Shared devices can create noise\n- **Game id** referes to a session \n- **Event data**- JSON format of all information about a speicific event. this is helpful in understanding what all happened. Has a lot of information. \n- **Event count** will track sequence within a game. So one can recreate the actions a user took. Starts from 1 and keeps increasing by 1 for every event. \n- **Event_code** refers to speicific actions - All the finite distinct actions that can take place are given  by a distinct code. \n- **World** refers to the various game environments.\n- **Title** gives various activities that can happen in a world. \n- **Type** Media type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'.\n- Assessment data is captured in another file called train_label\n    The train label gives us the accuracy group which is what we need to predict."},{"metadata":{},"cell_type":"markdown","source":"# Snapshot of Number and unique values of the train data "},{"metadata":{"trusted":true},"cell_type":"code","source":"no_unique ={}\nunique_values = {}\ndataframes ={}\n\nfor col in train.columns:\n    no_unique[col] = train[col].nunique()\n    if no_unique[col] <11:\n        unique_values[col] = train[col].unique()\n    else: \n        unique_values[col] = 'Too many to list.Eg: {}'.format(train[col].unique()[:4])\n    \n    dataframes[col] = pd.DataFrame([{\n         'column_name' : col\n     ,   'no_unique_values' : no_unique[col]\n    ,   'unique_values' : unique_values[col]\n    \n    }], index = [col])\n\ndf_unique = pd.concat([dataframes[col] for col in train.columns], ignore_index = True)\ndf_unique.sort_values(by = 'no_unique_values').reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Column name: World\n\nWhen we enter the game we have an option to enter one of 3 worlds- \n* Tree world\n* Magma Peak\n* Crystal Caves\n\nthe data also shows 'None' - This is the opening screen ( the one in the pic) - when no world is chosen.\n\nOpening Pic: https://drive.google.com/open?id=1H_OZ9MjOMWEsnXKlb_sh2VP-QyqCCjte"},{"metadata":{},"cell_type":"markdown","source":"# What can we say about the \"worlds\"\n"},{"metadata":{},"cell_type":"markdown","source":"# Data distribution of 'worlds\"\n\n* the max number of observations have 'None' which simply corresponds to the starting screen before a world is selected\n* the different worlds are nearly equal in number of observation , however, the max is for Magma Peak... may be the volcono is what kids find attractive :) "},{"metadata":{"trusted":true},"cell_type":"code","source":"g =train.groupby('world')\nx = g['installation_id'].nunique()\nx.reset_index().plot.bar(x ='world' , y = 'installation_id' )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# which world is played the most \n\n* While the games are nearly equally instaled there is a huge gap in the game time. \n* Magmapeak is the clear leader in this regard followed by Cystal Caves and a very close third Tree Top city."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # which world is the played the most \ng['game_time'].sum().reset_index().plot.bar(x ='world' , y = 'game_time' )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Column name: Type\n\nWithin a world  there can be multiple levels and different Activities , video clips, games, or assessments. Each world comes with a map that outlines what a user can do. \n\n- The map gives an idea of the various elements that one can encounter in a specific world. \n- This example is for Treetop City - Image of Map:   https://drive.google.com/open?id=1Yi0lb-naqFq7H1kkfh4fUeYjaypDH_OG\n    \nThe child can choose to do all or one of them. It is not mandatory to follow the sequence. \n\n\n\nImage of an Activity: An activity or any of the other types show up as a pop-up above the virtual kids in the game:\nhttps://drive.google.com/open?id=1NIl3fMpul6HzJaoOrNXWJBKta7UGwafK\n\nAnother way to look at Type is that it is a major classification of how time is spent by the child with his/her engagement with the game\nThere are 4 of them:\n   * Activity \n   * Clip\n   * Assessment\n   * Game "},{"metadata":{},"cell_type":"markdown","source":"Before we look deeper into Types let look at the interaction of 'Types' with \"Worlds\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# # what is the breakup of game and type \nx = train.groupby(['type','world' ])['game_time'].sum().sort_values()\n\n# build a dataframe that has all the types with worlds and corresponding sum of time\ntype_ = train.type.unique()\ndf ={}\nfor t in type_:\n    df[t] = (x.get(t).reset_index()).set_index('world').rename(columns = {'game_time':t})\ndf_f = pd.concat([df[t] for t in type_ ] , ignore_index = False , axis = 1, sort = True)\ndf_f = df_f.fillna(0)\n\n# get individual series as we want to create a chart with all of the differnt types \nworlds = list(df_f.index)\nclip = list(df_f.iloc[:,0])\nActivity =  list(df_f.iloc[:,1])\nGame =  list(df_f.iloc[:,2])\nAssessment = list( list(df_f.iloc[:,3]))\ndel worlds[2]\ndel clip[2]\ndel Activity[2]\ndel Game[2]\ndel Assessment[2]\n\n# plot the chart \nplt.xlabel('Worlds')\nplt.ylabel('Time')\nplt.title('Time spent by each activity in different Worlds')\n\nplt.plot(worlds, clip , label = 'Clip')\nplt.plot(worlds, Activity , label = 'Activity')\nplt.plot(worlds, Game, label = 'Game' )\nplt.plot(worlds, Assessment , label = 'Assessment')\nplt.legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time spent on differnt 'Types' in different 'Worlds'\n**Game**\n* Maximum time for any type is on '**Game**' --- this is to be expected -- that is the purpouse right \n* There seems to an issue with 'Tree-Top-City'. The other two worlds are close together for Game\n    \n**Activity**\n* The **activity** is a close second to the 'Game' -- understanding activites may be very important for us\n* Here Crystal Caves deviates from the others as in the other worlds the time spent between Games and Activity is comparable but not for Crystal Caves.\n    \n**Assessment**\n \n * The time for assessment seems to be 4-6% of the overall time spent by the users. \n * There seeems to be higher time spent on Tree Top city and the lowest appears to be Magmapeak. It would be interseting to find out why. Are one of the games easier / more difficult than the others. It is important given that the overall data was more for Magmapeak \n* while we can say nothing now, it will be good to investigate later.\n \n**Clip**\n \n * the data shows 0 for all the worlds. Hmm why is that\n "},{"metadata":{},"cell_type":"markdown","source":"# Number of observations for different Types\n- The graph is a break-down of the number of sessions for each type\n- around 9% of the data is assessment - which looks like a good estimate of what would actualy go on.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# how many game sessions were spent on the different types\ntypes_ = list(train.groupby('type')['game_session'].count().sort_values().index)\nvalues = list(train.groupby('type')['game_session'].count().sort_values())\nplt.xlabel('Types')\nplt.ylabel('Number of Sessions')\nplt.title('Breakdown of Sessions by Type')\nplt.plot(types_ , values)\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Columns - Event_Count / Event_Code / Game Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the charts\n\ni = 0\nplt.figure()\n\nfor column in list(train.describe().columns):\n    i += 1\n    ax_gen  = 'ax'+str(i)\n    fig_gen = 'fig'+ str(i)\n    fig_gen , ax_gen = plt.subplots()  \n    ax_gen.hist(x = train[column].dropna())        \n    ax_gen.hist(x = train[column].dropna())\n    ax_gen.set_title(column)\n#     plt.tight_layout()\n#     ax_gen.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Event_count**\n - Event count captures how many different actions are taking place in a session. It is a way to track the sequence of events that any child would have taken in any speicific game session. \n - As a ballmark if there are too many events may be it is not effective learning. As most of the events are when there is a prompt for not doing the right thing. For example: if i have to arrange 3 things in the right sequence based on height of the items. If i arrange it in 3 tries it is the best, but if i need some guidance, the prompt would go off and then i would need to rearrange it again...all this time the even_count would keep increasing by 1. \n - Most of the games have under 70 event_count. There is a steep fall off from the 70 mark and it keeps decreasing exponentialy -- which is to be expected\n \n**Event Code**\n- There are 42 unique codes. \n- There seems to be some concentration around key codes\n- These codes would need to be looked at with respect to the differnt activities and worlds. \n\n**Game Time**\n\n- There is a step fall off in game time. This is expected as most sessions would end within a reasonsable time. \n\n\n "},{"metadata":{},"cell_type":"markdown","source":"Thank you for taking the time to read this Kernel."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}