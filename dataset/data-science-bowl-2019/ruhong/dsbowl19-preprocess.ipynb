{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import os\nimport re\nimport random\nimport gc\nimport warnings\nfrom collections import namedtuple\nfrom math import sqrt\nimport json\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport sklearn\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import cohen_kappa_score, make_scorer, mean_squared_error, accuracy_score\nfrom sklearn.model_selection import GridSearchCV, PredefinedSplit\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom scipy.stats import ks_2samp\n\npd.show_versions()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def _log(str):\n    os.system(f'echo \\\"{str}\\\"')\n    print(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"INPUT_ROOT = '../input/data-science-bowl-2019'\nJOIN_KEY = ['installation_id', 'game_session', 'title']\nTARGET = 'accuracy_group'\nFEATURES = {\n    'event_id', \n    'game_session', \n    'timestamp', \n    'installation_id', \n    'event_count',\n    'event_code', \n    'game_time', \n    'title', \n    'type', \n    'world',\n    'event_data'\n}\nEVENT_CODES = ['2000', '2010', '2020', '2025', '2030', '2035', '2040', '2050', '2060', '2070', '2075', '2080', '2081', '2083', '3010', '3020', '3021', '3110', '3120', '3121', '4010', '4020', '4021', '4022', '4025', '4030', '4031', '4035', '4040', '4045', '4050', '4070', '4080', '4090', '4095', '4100', '4110', '4220', '4230', '4235', '5000', '5010']\nSEED = 31","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def _init():\n    # Characters such as empty strings '' or numpy.inf are considered NA values\n    pd.set_option('use_inf_as_na', True)\n    pd.set_option('display.max_columns', 999)\n    pd.set_option('display.max_rows', 999)\n    \n    \n_init()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\n\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"RANDOM_VALUES = []\nfor _ in range(4000):\n    RANDOM_VALUES.append(random.random())\n    \n_log(f'RANDOM_VALUES={RANDOM_VALUES[:20]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk(INPUT_ROOT):\n    for filename in filenames:\n        _log(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"%%time\ntrain_raw = pd.read_csv(f'{INPUT_ROOT}/train.csv', usecols=FEATURES)\ntrain_labels = pd.read_csv(f'{INPUT_ROOT}/train_labels.csv', usecols=JOIN_KEY + [TARGET])\ntest_raw = pd.read_csv(f'{INPUT_ROOT}/test.csv', usecols=FEATURES)\ntrain_labels.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add labels to train data"},{"metadata":{"trusted":false},"cell_type":"code","source":"def _remove_unlabelled_data(train_raw, train_labels):\n    return train_raw[train_raw['installation_id'].isin(train_labels['installation_id'].unique())]\n\n\ntrain_raw = _remove_unlabelled_data(train_raw, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ndef _add_labels(train_raw, train_labels, on):\n    return pd.merge(train_raw, train_labels, on=on, how='left')\n\n\ntrain_raw = _add_labels(train_raw, train_labels, on=JOIN_KEY)\ndel train_labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract event data JSON"},{"metadata":{"trusted":false},"cell_type":"code","source":"def _concat_columns(df1, df2):\n    \"\"\"Concatenate the columns of two pandas dataframes in the order of the operands.\n    Both dataframes must have the same number of rows.\n    \"\"\"\n    assert len(df1) == len(df2)\n    res = pd.concat([df1, df2.reindex(df1.index)], axis=1, join='inner')\n    assert len(res) == len(df1)\n    return res\n    \n\ndef _extract_event_data(df, keep_cols, chunk_size=1000000):\n    res = pd.DataFrame()\n    _len = len(df)\n    for i in tqdm(range(0, _len, chunk_size)):\n        if i + chunk_size < _len:\n            chunk = df[i:i + chunk_size].copy()\n        else:\n            chunk = df[i:].copy()\n        ed = pd.io.json.json_normalize(chunk['event_data'].apply(json.loads)).add_prefix('ed.')\n        ed = ed[keep_cols].astype(np.float32)\n        chunk = _concat_columns(chunk, ed)\n        # sort=False because not all rows have same fields in event_data\n        res = pd.concat([res, chunk], ignore_index=True, sort=False)\n    # this line is too slow and OOM error!\n    #res[keep_cols] = res[keep_cols].fillna(-1).astype(np.float32)\n    assert len(df) == len(res)\n    return res\n\n\n#keep_cols = ['ed.duration', 'ed.level', 'ed.round', 'ed.correct', 'ed.misses','ed.weight', 'ed.total_duration']\n#keep_cols = ['ed.identifier', 'ed.duration', 'ed.level', 'ed.round', 'ed.correct', 'ed.misses','ed.weight', 'ed.total_duration', 'ed.source']\n#train_raw = _extract_event_data(train_raw, keep_cols)\n#test_raw = _extract_event_data(test_raw, keep_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_raw.info(max_cols=999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_raw.info(max_cols=999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# All event ids in test set also exist in train set\n#test_set = set(test_raw['event_id'])\n#train_set = set(train_raw['event_id'])\n#vs = test_set - train_set\n#_log(f'{len(vs)} event_ids exist in test set but not train set.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"EVENT_IDS = sorted(list(set(train_raw['event_id']) | set(test_raw['event_id'])))\n_log(f'{len(EVENT_IDS)} EVENT_IDS={EVENT_IDS}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"TITLES = test_raw['title'].unique()\ntest_raw['title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"TYPES = test_raw['type'].unique()\ntest_raw['type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"WORLDS = test_raw['world'].unique()\ntest_raw['world'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#test_raw['ed.source'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#test_raw['ed.identifier'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vs = sorted(train_raw['event_code'].unique())\n_log(f'{len(vs)} train_raw type={vs}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n_prev = pd.to_datetime(pd.Series(['2019-08-06T05:22:41.147000000'])).astype(np.int64).values[0]\n_next = pd.to_datetime(pd.Series(['2019-08-06T05:22:41.147000001'])).astype(np.int64).values[0]\nassert _next - _prev == 1\n\n\ndef _transform_timestamp(df):\n    vs = pd.to_datetime(df['timestamp'])\n    df['timestamp'] = vs\n    assert df['timestamp'].notna().all()\n    df['timestamp_int'] = vs.astype(np.int64)\n    assert df['timestamp_int'].notna().all()\n\n\n_transform_timestamp(train_raw)\n_transform_timestamp(test_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ndef _set_string_type(df, cols):\n    df[cols] = df[cols].astype(str)\n    return df\n\n\ncols = ['event_code', 'timestamp']\ntrain_raw = _set_string_type(train_raw, cols=cols)\ntest_raw = _set_string_type(test_raw, cols=cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ndef _sort_it(df):\n    return df.sort_values(by=['installation_id', 'timestamp'])\n\n\n#train_raw = _sort_it(train_raw)\n#test_raw = _sort_it(test_raw)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multiple accuracy groups per installation id\nIn the training set, you are provided the full history of gameplay data. In the test set, we have truncated the history after the start event of a single assessment, chosen randomly, for which you must predict the number of attempts. Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment."},{"metadata":{"trusted":false},"cell_type":"code","source":"vs = train_raw[train_raw[TARGET].notna()].groupby('installation_id', as_index=False)[TARGET].nunique()\nvs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-test split not by time\nBoth train and test sets span the same time period."},{"metadata":{"trusted":false},"cell_type":"code","source":"#_log(f'train_raw[timestamp] is from {train_raw.timestamp.min()} to {train_raw.timestamp.max()}')\n#_log(f'test_raw[timestamp] is from {test_raw.timestamp.min()} to {test_raw.timestamp.max()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#vs = train_raw[(train_raw['installation_id'] == '0006a69f') & (train_raw[TARGET].notna())].groupby(['game_session', 'title', TARGET], as_index=False)['timestamp'].max()\n#vs = sorted(vs['timestamp'].values) \n#vs","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#tmp = test_raw.groupby(['world', 'type'], as_index=False)['game_time'].quantile([.25, .5, .75], interpolation='lower')\n#tmp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_raw.info(max_cols=999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_raw.info(max_cols=999)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":false},"cell_type":"code","source":"def _key(s):\n    return re.sub(r'[\\W\\s]', '', s).lower()\n\n\ndef _timestamp_cutoffs(df, TARGET):\n    res = df[df[TARGET].notna()].copy().groupby(['game_session', 'title', TARGET], as_index=False)['timestamp_int'].max()\n    res = sorted(res['timestamp_int'].values)\n    return res\n\n    \ndef _target_variable(df, TARGET):\n    vs = df[TARGET].copy().dropna().unique()\n    assert len(set(vs)) == 1\n    return vs[0]\n    \n\ndef _group_stats(df, col, titles, types, worlds, suffix):\n    \"\"\"Get percentile stats\"\"\"\n    res = {}\n    _percentiles = [0.25, 0.5, 0.75]\n    defaults = {}\n    qs = df[col].quantile(_percentiles, interpolation='lower').to_numpy()\n    for i, q in enumerate(qs):\n        percentile = f'p{int(_percentiles[i] * 100)}'\n        defaults[percentile] = q\n        k = f'{col}_{percentile}{suffix}'\n        res[k] = np.float32([q])\n    \n    # initialize values\n    for p in _percentiles:\n        percentile = f'p{int(p * 100)}'\n        for w in worlds:\n            for t in types:\n                k = f'{col}_{percentile}_{_key(w)}_{_key(t)}{suffix}'\n                res[k] = np.float32([defaults[percentile]])\n\n        for t in titles:\n            k = f'{col}_{percentile}_{_key(t)}{suffix}' \n            res[k] = np.float32([defaults[percentile]])\n\n    if len(worlds) != 0 and len(types) != 0:\n        tmp = df.groupby(['world', 'type'], as_index=False)[col].quantile(_percentiles, interpolation='lower')\n        i = 0\n        for row in tmp.itertuples(index=False):\n            percentile = f'p{int(_percentiles[i % 3] * 100)}'\n            k = f'{col}_{percentile}_{_key(row[0])}_{_key(row[1])}{suffix}'\n            i += 1\n            if k in res and not np.isnan(row[2]):\n                res[k] = np.float32([row[2]])\n    \n    if len(titles) != 0:\n        tmp = df.groupby(['title'], as_index=False)[col].quantile(_percentiles, interpolation='lower')\n        i = 0\n        for row in tmp.itertuples(index=False):\n            percentile = f'p{int(_percentiles[i % 3] * 100)}'\n            k = f'{col}_{percentile}_{_key(row[0])}{suffix}'\n            i += 1\n            if k in res and not np.isnan(row[1]):\n                res[k] = np.float32([row[1]])\n    return res    \n    \n\ndef _game_session_stats(df, col, titles, types, worlds, suffix):\n    \"\"\"Deprecated.\"\"\"\n    res = {}\n    _default = -1\n    # initialize values\n    k = f'{col}_gamesession_p50{suffix}'\n    res[k] = np.float32([_default])\n    for w in worlds:\n        for t in types:\n            k = f'{col}_gamesession_{_key(w)}_{_key(t)}_p50{suffix}'\n            res[k] = np.float32([_default])\n\n    for t in titles:\n        k = f'{col}_gamesession_{_key(t)}_p50{suffix}' \n        res[k] = np.float32([_default])\n\n    tmp = df.groupby(['game_session'], as_index=False)[col].quantile(.75, interpolation='lower')\n    k = f'{col}_gamesession_p50{suffix}'\n    if k in res and not tmp[col].isna().all():\n        v = tmp[col].median()\n        res[k] = np.float32([v])\n\n    if len(worlds) != 0 and len(types) != 0:\n        tmp = df.groupby(['game_session', 'world', 'type'], as_index=False)[col].quantile(.75, interpolation='lower')\n        tmp.dropna(subset=[col], inplace=True)\n        tmp = tmp.groupby(['world', 'type'], as_index=False)[col].median()\n        for row in tmp.itertuples(index=False):\n            k = f'{col}_gamesession_{_key(row[0])}_{_key(row[1])}_p50{suffix}'\n            if k in res:\n                res[k] = np.float32([row[2]])\n\n    if len(titles) != 0:\n        tmp = df.groupby(['game_session', 'title'], as_index=False)[col].quantile(.75, interpolation='lower')\n        tmp.dropna(subset=[col], inplace=True)\n        tmp = tmp.groupby(['title'], as_index=False)[col].median()\n        for row in tmp.itertuples(index=False):\n            k = f'{col}_gamesession_{_key(row[0])}_p50{suffix}'\n            if k in res:\n                res[k] = np.float32([row[1]])\n    \n    #qs = vs.quantile([0.25, 0.5, 0.75], interpolation='lower').to_numpy()    \n    return res\n\n\ndef _count(df, col, values, suffix):\n    res = {}\n    for v in values:\n        res[f'{col}_{_key(v)}{suffix}'] = np.int32([0])\n    \n    if len(values) != 0:\n        tmp = df.groupby([col], as_index=False).count()\n        for row in tmp.itertuples(index=False):\n            res[f'{col}_{_key(row[0])}{suffix}'] = np.int32([row[1]])\n    \n    return res\n    \n\ndef _event_id_features(df, event_ids, titles, types, worlds, suffix):\n    res = {}\n    # initialize counts\n    for eid in event_ids:\n        res[f'eid_{eid}{suffix}'] = np.int32([0])      \n        for w in worlds:\n            for t in types:\n                res[f'eid_{eid}_{_key(w)}_{_key(t)}{suffix}'] = np.int32([0])\n            \n        for t in titles:\n            res[f'eid_{eid}_{_key(t)}{suffix}'] = np.int32([0])\n                      \n    tmp = df.groupby(['event_id'], as_index=False).count()\n    for row in tmp.itertuples(index=False):\n        res[f'eid_{row[0]}{suffix}'] = np.int32([row[1]])\n        \n    if len(worlds) != 0 and len(types) != 0:\n        tmp = df.groupby(['event_id', 'world', 'type'], as_index=False).count()\n        for row in tmp.itertuples(index=False):\n            k = f'eid_{row[0]}_{_key(row[1])}_{_key(row[2])}{suffix}'\n            if k in res:\n                res[k] = np.int32([row[3]])\n\n    if len(titles) != 0:\n        tmp = df.groupby(['event_id', 'title'], as_index=False).count()\n        for row in tmp.itertuples(index=False):\n            k = f'eid_{row[0]}_{_key(row[1])}{suffix}'\n            if k in res:\n                res[k] = np.int32([row[2]])\n        \n    return res\n\n\ndef _event_code_features(df, event_codes, titles, types, worlds, suffix):\n    res = {}\n    # initialize counts\n    for code in event_codes:\n        res[f'event_{code}{suffix}'] = np.int32([0])\n        for w in worlds:\n            for t in types:\n                res[f'event_{code}_{_key(w)}_{_key(t)}{suffix}'] = np.int32([0])\n            \n        for t in titles:\n            res[f'event_{code}_{_key(t)}{suffix}'] = np.int32([0])\n        \n    tmp = df.groupby(['event_code'], as_index=False).count()\n    for row in tmp.itertuples(index=False):\n        res[f'event_{row[0]}{suffix}'] = np.int32([row[1]])\n        \n    if len(worlds) != 0 and len(types) != 0:\n        tmp = df.groupby(['event_code', 'world', 'type'], as_index=False).count()\n        for row in tmp.itertuples(index=False):\n            k = f'event_{row[0]}_{_key(row[1])}_{_key(row[2])}{suffix}'\n            if k in res:\n                res[k] = np.int32([row[3]])\n\n    if len(titles) != 0:\n        tmp = df.groupby(['event_code', 'title'], as_index=False).count()\n        for row in tmp.itertuples(index=False):\n            k = f'event_{row[0]}_{_key(row[1])}{suffix}'\n            if k in res:\n                res[k] = np.int32([row[2]])\n        \n    return res\n\n\ndef _event_data_features(df, suffix):\n    res = {}\n    res[f'ed_duration{suffix}'] = np.int32(df['ed.duration'].fillna(0).max())\n    res[f'ed_total_duration{suffix}'] = np.int32(df['ed.total_duration'].fillna(0).max())\n    res[f'ed_level{suffix}'] = np.int32(df['ed.level'].fillna(0).max())\n    res[f'ed_round{suffix}'] = np.int32(df['ed.round'].fillna(0).max())\n    res[f'ed_correct{suffix}'] = np.int32(df['ed.correct'].fillna(0).max())\n    res[f'ed_misses{suffix}'] = np.int32(df['ed.misses'].fillna(0).max())\n    res[f'ed_weight{suffix}'] = np.int32(df['ed.weight'].fillna(0).max())\n    res[f'ed_source_resources{suffix}'] = np.int32([sum(df['ed.source'] == 'resources')])\n    res[f'ed_source_right{suffix}'] = np.int32([sum(df['ed.source'] == 'right')])\n    res[f'ed_source_left{suffix}'] = np.int32([sum(df['ed.source'] == 'left')])\n    res[f'ed_source_scale{suffix}'] = np.int32([sum(df['ed.source'] == 'scale')])\n    res[f'ed_source_middle{suffix}'] = np.int32([sum(df['ed.source'] == 'middle')])\n    res[f'ed_source_heaviest{suffix}'] = np.int32([sum(df['ed.source'] == 'Heaviest')])\n    res[f'ed_source_heavy{suffix}'] = np.int32([sum(df['ed.source'] == 'Heavy')])\n    res[f'ed_source_lightest{suffix}'] = np.int32([sum(df['ed.source'] == 'Lightest')])\n    n = 0\n    for i in range(1, 13):\n        n += sum(df['ed.source'] == str(i))\n    res[f'ed_source_numbered{suffix}'] = np.int32([n])\n    res[f'ed_id_dot{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Dot_', regex=False))])\n    res[f'ed_id_buddy{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Buddy_', regex=False))])\n    res[f'ed_id_cleo{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Cleo_', regex=False))])\n    res[f'ed_id_mom{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Mom_', regex=False))])\n    res[f'ed_id_sid{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('sid_', regex=False))])\n    positives = {'Dot_SoCool', 'Dot_GreatJob', 'ohWow', 'wowSoCool', 'thatLooksSoCool', 'tub_success', \n                 'water_success', 'soap_success', 'Dot_Amazing', 'Dot_WhoaSoCool', 'Dot_ThatsIt', 'youDidIt_1305',\n                 'SFX_completedtask', 'Cleo_AmazingPowers', 'RIGHTANSWER1', 'Dot_Awesome', 'greatJob_1306', 'YouDidIt',\n                 'RIGHTANSWER3', 'RIGHTANSWER2', 'INSTRCOMPLETE', 'AWESOME', 'WayToGoTeam', 'Dot_NiceWorkAllMatch',\n                 'GreatFlying', 'WeDidItOneRoundLeft', 'Cleo_AweOfYourSkills', 'Dot_NiceWork'}\n    n_pos = 0\n    for p in positives:\n        n_pos += sum(df['ed.identifier'].str.contains(p, regex=False))\n    res[f'ed_id_positive{suffix}'] = np.int32([n_pos])\n    negatives = {'Dot_Uhoh', 'Dot_UhOh', 'Dot_NeedTryAgain', 'IncorrectTooHeavy', 'Dot_GoLower', 'Buddy_TryDifferentNest',\n                 'Cleo_BowlTooLight', 'Dot_GoHigher', 'Dot_SoLow', 'Dot_SoHigh', 'Dot_WhoopsTooShort', 'IncorrectTooLight',\n                 'NOT_THAT_HEAVY', 'Dot_UhOhTooTall', 'ADD_MORE_WEIGHT', 'wrong1', 'tryAgain1', 'Dot_TryWeighingAgain',\n                 'Cleo_RememberHeavierBowl', 'Dot_Whoops', 'Dot_NotBalanced', 'Mom_TooManyContainers',\n                 'WrongOver', 'Mom_TooMuchWater', 'Dot_ThatBucketNotRight', 'Dot_TryAgain', 'wrongFewer', 'WrongBetweenCliff',\n                 'Mom_NeedMoreContainers', 'Dot_Try', 'Dot_HmTooSmall'}\n    n_neg = 1\n    for ne in negatives:\n        n_neg += sum(df['ed.identifier'].str.contains(ne, regex=False))\n    res[f'ed_id_negative{suffix}'] = np.int32([n_neg])\n    res[f'ed_id_positive_ratio{suffix}'] = np.float32([n_pos / n_neg])\n    return res\n    \n    \ndef _worlds_picked():\n    return ['MAGMAPEAK', 'TREETOPCITY', 'CRYSTALCAVES']\n\n\ndef _titles_picked():\n    return ['Cauldron Filler (Assessment)', 'Mushroom Sorter (Assessment)', 'Bird Measurer (Assessment)',\n            'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)'\n           ]\n    \n\ndef _types_picked():\n    return ['Assessment', 'Game']\n    \n        \ndef _features_map(df, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS, suffix=''):\n    res = {}\n    worlds = _worlds_picked()\n    titles = _titles_picked()\n    types = _types_picked()\n    #cols = ['game_time', 'event_count', 'ed.duration', 'ed.level', 'ed.round','ed.correct','ed.misses','ed.weight','ed.total_duration']\n    #for col in cols:\n     #   res.update(_group_stats(df, col, titles=titles, types=types, worlds=worlds, suffix=suffix))\n    \n    res.update(_count(df, col='type', values=TYPES, suffix=suffix))\n    res.update(_count(df, col='world', values=WORLDS, suffix=suffix))\n    res.update(_count(df, col='title', values=TITLES, suffix=suffix))\n    res.update(_event_code_features(df, EVENT_CODES, titles=titles, types=types, worlds=worlds, suffix=suffix))\n    res.update(_event_id_features(df, EVENT_IDS, titles=titles, types=types, worlds=worlds, suffix=suffix))\n    #res.update(_event_data_features(df, suffix))\n    return res\n\n\ndef _features(df, installation_id, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS):\n    res = {}\n    if TARGET in df.columns:\n        res[TARGET] = np.int16([_target_variable(df, TARGET)])\n    res['installation_id'] = [installation_id]    \n    res.update(_features_map(df, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS))\n    return pd.DataFrame.from_dict(res)\n\n\ndef _preprocess(raw, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS):\n    res = pd.DataFrame()\n    raw = raw.set_index('installation_id', drop=False)\n    iids = raw['installation_id'].unique()\n    prev_len = None\n    prev_cols = None\n    rv = 0\n    for iid in tqdm(iids):\n        whole = raw.loc[[iid]].copy()  # double square brackets return a Dataframe!\n        whole = whole.set_index('timestamp_int', drop=False)\n        dfs = []\n        if TARGET in whole.columns:\n            # train set: each installation id may contribute one or more examples.\n            _prev = pd.to_datetime(pd.Series(['1999-01-01T05:22:41.147000000'])).astype(np.int64).values[0]\n            for _curr in _timestamp_cutoffs(whole, TARGET):\n                df = whole.loc[_prev + 1:_curr]\n                dfs.append(df)\n                _prev = _curr\n        else:\n            # test set: each installation id contributes one example.\n            dfs.append(whole)\n        j = -1\n        if len(dfs) > 1:\n            j = int(RANDOM_VALUES[rv])\n            rv += 1\n        for i, df in enumerate(dfs):\n            if TARGET in df.columns:\n                installation_id = f'{iid}_{i + 1}'\n            else:\n                installation_id = iid\n            ex = _features(df, installation_id, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)\n            if TARGET in df.columns:\n                if i == j:\n                    ex['_is_val'] = 0  # validation set\n                else:\n                    ex['_is_val'] = -1\n            prev_len = len(ex.columns) if prev_len is None else prev_len\n            prev_cols = set(ex.columns) if prev_cols is None else prev_cols\n            if len(ex.columns) != prev_len:\n                _diff = set(ex.columns) - prev_cols\n                raise ValueError(f'Number of columns must be the same. Difference found={_diff}')\n            prev_len = len(ex.columns)\n            res = pd.concat([res, ex], ignore_index=True)\n    return res\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test = _preprocess(test_raw, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.info(max_cols=9999)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"assert test.notna().all(axis=None)\ndel test_raw\ngc.collect()\ntest.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FE: train set"},{"metadata":{"trusted":false},"cell_type":"code","source":"# budget of 4 seconds per iteration, or 4 hours total.\ntrain = _preprocess(train_raw, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.info(max_cols=9999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"assert train.notna().all(axis=None)\ntmp = train.groupby(['_is_val'], as_index=False)['installation_id'].count()\nassert tmp.iloc[1]['installation_id'] >= 2000\ntmp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del train_raw, tmp\ngc.collect()\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.to_parquet('train.parquet')\ntest.to_parquet('test.parquet')\n_log(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Standardization"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ntrain = pd.read_parquet('train.parquet')\ntest = pd.read_parquet('test.parquet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def _log_transform(df, cols):\n    df[cols] = np.float32(np.log(df[cols] + 1))\n\n\n#cols = list(set(test.columns.values) - {'installation_id'})\n#_log_transform(train, cols)\n#_log_transform(test, cols)\n#train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ndef _scaling(dfs, cols, scaler=None):\n    scaler = sklearn.preprocessing.RobustScaler() if scaler is None else scaler\n    scaler.fit(dfs[0][cols])\n    for df in dfs:\n        df[cols] = np.float32(scaler.transform(df[cols]))\n        assert df.notna().all(axis=None)\n\n\n#scaler = sklearn.preprocessing.PowerTransformer()\ncols = list(set(test.columns.values) - {'installation_id', '_is_val'})\n_scaling([train, test], cols)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.to_parquet('train_scaled.parquet')\ntest.to_parquet('test_scaled.parquet')\n_log(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature selection\n[KS Test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ntrain = pd.read_parquet('train_scaled.parquet')\ntest = pd.read_parquet('test_scaled.parquet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def _select_features(df1, df2, features, alpha):\n    res = []\n    for f in tqdm(features):\n        if ks_2samp(df1[f], df2[f]).pvalue > alpha:\n            res.append(f)\n    return res\n\n\nALPHA = 0.2\nfeatures = set(test.columns.values) - {'installation_id', '_is_val'}\nPREDICTORS = _select_features(train, test, features, ALPHA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dropped = sorted(list(features - set(PREDICTORS)))\nPREDICTORS = sorted(PREDICTORS)\n_log(f'alpha={ALPHA}, keep {len(PREDICTORS)}/{len(features)} features, drop {len(dropped)} features.\\nkeep={PREDICTORS}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dropped features"},{"metadata":{"trusted":false},"cell_type":"code","source":"_log(f'drop={dropped}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Model\nApproach: Stacking two models\n1. Binary classification - was the assessment solved or not?\n1. Regression on the number of attempts taken to solve the assessment\n\nReason: `accuracy_group` labels '1', '2' and '3' are ordinal but not '0'. See https://www.kaggle.com/c/data-science-bowl-2019/discussion/124836"},{"metadata":{"trusted":false},"cell_type":"code","source":"train['is_solved'] = -1\ntrain['solved_attempts'] = -1\ntrain.loc[train[TARGET] == 0, ['is_solved']] = 0\ntrain.loc[train[TARGET] != 0, ['is_solved']] = 1\ntrain.loc[train[TARGET] == 3, ['solved_attempts']] = 1\ntrain.loc[train[TARGET] == 2, ['solved_attempts']] = 2\ntrain.loc[train[TARGET] == 1, ['solved_attempts']] = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classify whether assessment was solved or not"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ncls_name = 'c/lgb/gbdt'\ny_train_cls = train['is_solved']\nx_train_cls = train[PREDICTORS]\np_split = PredefinedSplit(test_fold=train['_is_val'].values)\nmodel = lgb.LGBMClassifier(n_estimators=10000, reg_alpha=1, objective='binary', boosting_type='gbdt')\npipe = Pipeline([('model', model)])\nparam_grid = {\n    'model__learning_rate': [0.001],\n    'model__min_child_samples': [100],\n    'model__colsample_bytree': [0.01]\n}\ncls = GridSearchCV(pipe, cv=p_split, param_grid=param_grid, scoring='f1')\n#cv.fit(x_train, y_train, model__early_stopping_rounds=200, model__verbose=500)\ncls.fit(x_train_cls, y_train_cls)\nassert cls.best_estimator_['model'].n_classes_ == 2\n_log(f\"\"\"F1 {cls_name}\nbest_score_={cls.best_score_:.5f}\nbest_params_={cls.best_params_}\nn_features={cls.best_estimator_['model'].n_features_}\n\"\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgb.plot_importance(cls.best_estimator_['model'], max_num_features=100, figsize=(10, 30), title=f'{cls_name} feature importance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nclsd_name = 'c/lgb/dart'\nmodel = lgb.LGBMClassifier(n_estimators=10000, reg_alpha=1, objective='binary', boosting_type='dart')\npipe = Pipeline([('model', model)])\nparam_grid = {\n    'model__learning_rate': [0.001],\n    'model__min_child_samples': [100],\n    'model__colsample_bytree': [0.5]\n}\nclsd = GridSearchCV(pipe, cv=p_split, param_grid=param_grid, scoring='f1')\n#cv.fit(x_train, y_train, model__early_stopping_rounds=200, model__verbose=500)\nclsd.fit(x_train_cls, y_train_cls)\nassert clsd.best_estimator_['model'].n_classes_ == 2\n_log(f\"\"\"F1 {clsd_name}\nbest_score_={clsd.best_score_:.5f}\nbest_params_={clsd.best_params_}\nn_features={clsd.best_estimator_['model'].n_features_}\n\"\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgb.plot_importance(clsd.best_estimator_['model'], max_num_features=100, figsize=(10, 30), title=f'{clsd_name} feature importance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ndef _random_forest_classifier(x_train_cls, y_train_cls):\n    model = RandomForestClassifier(n_estimators=4000, max_features='log2')\n    pipe = Pipeline([('model', model)])\n    param_grid = {\n        'model__max_depth': [4],\n        'model__min_samples_leaf': [40]\n    }\n    rfc = GridSearchCV(pipe, cv=FOLDS, param_grid=param_grid, scoring='f1')\n    rfc.fit(x_train_cls, y_train_cls)\n    assert rfc.best_estimator_['model'].n_classes_ == 2\n    return rfc\n\n\n#rfc = _random_forest_classifier(x_train_cls, y_train_cls)\n#_log(f\"\"\"F1 RandomForestClassifier\n#best_score_={rfc.best_score_:.5f}\n#best_params_={rfc.best_params_}\n#n_features={rfc.best_estimator_['model'].n_features_}\n#\"\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression on the number of attempts to solve the assessment"},{"metadata":{"trusted":false},"cell_type":"code","source":"def _rmse(y, y_pred):\n    return sqrt(mean_squared_error(y, y_pred))\n\n\nSCORING = make_scorer(_rmse, greater_is_better = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp = train[train['is_solved'] == 1]\ny_train = tmp['solved_attempts']\nx_train = tmp[PREDICTORS]\np_split = PredefinedSplit(test_fold=tmp['_is_val'].values)\n\nsplit_df = tmp.groupby(['_is_val'], as_index=False)['installation_id'].count()\nassert split_df.iloc[1]['installation_id'] >= 1500\nsplit_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ncv_name = 'r/lgb/gbdt'\nmodel = lgb.LGBMRegressor(n_estimators=10000, reg_alpha=1, boosting_type='gbdt')\npipe = Pipeline([('model', model)])\nparam_grid = {\n    'model__learning_rate': [0.001],\n    'model__min_child_samples': [100],\n    'model__colsample_bytree': [0.1]\n}\ncv = GridSearchCV(pipe, cv=p_split, param_grid=param_grid, scoring=SCORING)\n#cv.fit(x_train, y_train, model__early_stopping_rounds=200, model__verbose=500)\ncv.fit(x_train, y_train)\n_log(f\"\"\"RMSE {cv_name}\nbest_score_={cv.best_score_:.5f}\nbest_params_={cv.best_params_}\nn_features={cv.best_estimator_['model'].n_features_}\n\"\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# plot_metric only works with early stopping rounds\n#lgb.plot_metric(cv.best_estimator_['model'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgb.plot_importance(cv.best_estimator_['model'], max_num_features=100, figsize=(10, 30), title=f'{cv_name} feature importance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ncvd_name = 'r/lgb/dart'\nmodel = lgb.LGBMRegressor(n_estimators=20000, reg_alpha=1, boosting_type='dart')\npipe = Pipeline([('model', model)])\nparam_grid = {\n    'model__learning_rate': [0.001],\n    'model__min_child_samples': [100],\n    'model__colsample_bytree': [0.5]\n}\ncvd = GridSearchCV(pipe, cv=p_split, param_grid=param_grid, scoring=SCORING)\n#cv.fit(x_train, y_train, model__early_stopping_rounds=200, model__verbose=500)\ncvd.fit(x_train, y_train)\n_log(f\"\"\"RMSE {cvd_name}\nbest_score_={cvd.best_score_:.5f}\nbest_params_={cvd.best_params_}\nn_features={cvd.best_estimator_['model'].n_features_}\n\"\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgb.plot_importance(cvd.best_estimator_['model'], max_num_features=100, figsize=(10, 30), title=f'{cvd_name} feature importance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ndef _random_forest_regressor(x_train, y_train):\n    model = RandomForestRegressor(n_estimators=4000, max_features='log2')\n    pipe = Pipeline([('model', model)])\n    param_grid = {\n        'model__max_depth': [4],\n        'model__min_samples_leaf': [40]\n    }\n    rfr = GridSearchCV(pipe, cv=FOLDS, param_grid=param_grid, scoring=SCORING)\n    rfr.fit(x_train, y_train)\n    return rfr\n\n\n#rfr = _random_forest_regressor(x_train, y_train)\n#_log(f\"\"\"RMSE RandomForestRegressor\n#best_score_={rfr.best_score_:.5f}\n#best_params_={rfr.best_params_}\n#n_features={rfr.best_estimator_['model'].n_features_}\n#\"\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict out of fold"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nBlendModel = namedtuple('BlendModel', ['model', 'name', 'weight'])\n\ndef _is_solved(score):\n    if score >= 0.755:\n        return 1\n    return 0\n\n\ndef _solved_attempts(score):\n    if score >= 2.2:\n        return 3\n    if score >= 1.35:\n        return 2\n    return 1\n\n\ndef _predict(df, classifiers, regressors):\n    res = df[['installation_id']].copy()\n    res[TARGET] = np.nan\n    x_cls = df[PREDICTORS]\n    res['is_solved'] = 0\n    for m in classifiers:\n        col = f'is_solved_{m.name}'\n        res[col] = m.model.predict_proba(x_cls)[:,1]\n        res['is_solved'] += res[col] * m.weight\n    \n    res['is_solved'] = np.int16(res['is_solved'].map(_is_solved))\n    iids = set(res[res['is_solved'] == 1]['installation_id'].values)\n    cols = ['installation_id'] + PREDICTORS\n    tmp = df[df['installation_id'].isin(iids)][cols].copy()\n    x = tmp[PREDICTORS]\n    cols = ['installation_id', 'solved_attempts_raw', 'solved_attempts']\n    tmp['solved_attempts_raw'] = 0\n    for m in regressors:\n        col = f'solved_attempts_{m.name}'\n        cols.append(col)\n        tmp[col] = m.model.predict(x)\n        tmp['solved_attempts_raw'] += tmp[col] * m.weight\n        \n    tmp['solved_attempts'] = np.int16(tmp['solved_attempts_raw'].map(_solved_attempts))\n    tmp = tmp[cols]\n    res = res.merge(tmp, on='installation_id', how='left')\n    res.loc[res['is_solved'] == 0, [TARGET]] = 0\n    res.loc[(res['is_solved'] == 1) & (res['solved_attempts'] >= 3), [TARGET]] = 1\n    res.loc[(res['is_solved'] == 1) & (res['solved_attempts'] == 2), [TARGET]] = 2\n    res.loc[(res['is_solved'] == 1) & (res['solved_attempts'] <= 1), [TARGET]] = 3\n    assert res[TARGET].notna().all(axis=None)\n    res[TARGET] = np.int16(res[TARGET])\n    return res\n\n\nclassifiers=[\n    BlendModel(model=cls, weight=0.5, name=cls_name),\n    BlendModel(model=clsd, weight=0.5, name=clsd_name)\n]\nregressors=[\n    BlendModel(model=cv, weight=0.5, name=cv_name),\n    BlendModel(model=cvd, weight=0.5, name=cvd_name)\n]\noof = _predict(train, classifiers=classifiers, regressors=regressors)\noof.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.subplot(1, 2, 1)\nplt.title(f'is_solved_{cls_name}')\noof[f'is_solved_{cls_name}'].plot(kind='hist')\nplt.subplot(1, 2, 2)\nplt.title(f'is_solved_{clsd_name}')\noof[f'is_solved_{clsd_name}'].plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.subplot(1, 2, 1)\nplt.title(f'solved_attempts_{cv_name}')\noof[f'solved_attempts_{cv_name}'].plot(kind='hist')\nplt.subplot(1, 2, 2)\nplt.title(f'solved_attempts_{cvd_name}')\noof[f'solved_attempts_{cvd_name}'].plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"oof.sort_values(by=['installation_id'], inplace=True)\ntrain.sort_values(by=['installation_id'], inplace=True)\ny_true = train[TARGET]\ny_pred = oof[TARGET]\nkappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\nacc = accuracy_score(y_true, y_pred)\n_log(f'oof kappa={kappa:.5f}, acc={acc:.5f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict on Test set"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nsub = _predict(test, classifiers=classifiers, regressors=regressors)\nsub = sub[['installation_id', TARGET]]\nsample_sub = pd.read_csv(f'{INPUT_ROOT}/sample_submission.csv')\nassert sub['installation_id'].equals(sample_sub['installation_id'])\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.subplot(1, 3, 1)\nplt.title('test predict')\nsub[TARGET].plot(kind='hist')\nplt.subplot(1, 3, 2)\nplt.title('oof predict')\noof[TARGET].plot(kind='hist')\nplt.subplot(1, 3, 3)\nplt.title('oof truth')\ntmp = train[TARGET].copy()\ntmp = tmp.astype(int)\ntmp.plot(kind='hist')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)\n_log(os.listdir(\".\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}