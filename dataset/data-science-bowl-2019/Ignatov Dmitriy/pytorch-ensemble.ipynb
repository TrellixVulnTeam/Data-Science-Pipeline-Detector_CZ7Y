{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Environment preparation"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\nfrom tqdm import tqdm_notebook\n\nfrom sklearn.preprocessing import normalize\nfrom sklearn.model_selection import train_test_split\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtypes = {\n        'event_count' : 'uint16',\n        'event_code' : 'uint16',\n        'game_time' : 'uint32',\n        'title' : 'category',\n        'type' : 'category',\n        'world' : 'category',\n        'event_id' : 'category',\n        'game_session' : 'category',\n        'installation_id' : 'category'        \n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv', dtype = dtypes )\ndf_test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv', dtype = dtypes )\nspec = pd.read_csv( '/kaggle/input/data-science-bowl-2019/specs.csv', usecols = ['event_id'] )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lower case"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lower_str_columns(df):\n  col = ['title', 'type', 'world']\n\n  for col in col:\n    df[col] = df[col].str.lower().astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_str_columns(df_train)\nlower_str_columns(df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_encoding(df, spec = spec):\n  \n    print('Add features...')\n    \n    df['game_time'] = df['game_time'] / 1000\n    df['game_time'] = df['game_time'].astype('uint32')\n    \n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    df['incorrect_game_attempt'] = np.where( (df['event_data'].str.contains('\"correct\":false') \\\n                                          & (df['type']=='game')), 1, 0 ).astype('uint16')\n    \n    df['correct_game_attempt'] = np.where( (df['event_data'].str.contains('\"correct\":true') \\\n                                        & (df['type']=='game')), 1, 0 ).astype('uint16')\n    \n    df['day'] = df['timestamp'].dt.day_name().str.lower().astype('category')\n\n    df['phase_of_day'] = np.where( df['timestamp'].dt.hour.isin(range(6, 11)), 'morning', np.where( df['timestamp'].dt.hour.isin(range(11, 17)), 'day', np.where( df['timestamp'].dt.hour.isin(range(17, 23)), 'evening', 'night' ) ) )\n\n    df['phase_of_day'] = df['phase_of_day'].astype('category')  \n\n    print('One hot encoding 1 out of 6')\n    \n    df_world = pd.pivot_table(data = df.loc[ : , ['installation_id', 'game_session', 'world'] ].drop_duplicates(), \\\n                            index = ['installation_id','game_session'], \\\n                            columns = ['world'], \\\n                            aggfunc = len, \\\n                            fill_value = 0).add_prefix('world_').reset_index()\n    \n    col = df_world.select_dtypes('int64').columns.tolist()\n    df_world[col] = df_world[col].astype('uint8')  \n \n    print('One hot encoding 2 out of 6')\n    \n    df_type = pd.pivot_table(data = df.loc[ : , ['installation_id', 'game_session', 'type']].drop_duplicates(),\\\n                          index = ['installation_id','game_session'], \\\n                          columns = ['type'], \\\n                          fill_value = 0, \\\n                          aggfunc = len).add_prefix('type_').reset_index()\n\n    col = df_type.select_dtypes('int64').columns.tolist()\n    df_type[col] = df_type[col].astype('uint8')\n\n    sparse_matrix = pd.merge(df_world, df_type, on = ['installation_id','game_session'], how = 'right')\n\n    print('One hot encoding 3 out of 6')\n    \n    df_title = pd.pivot_table(data = df.loc[:, ['installation_id', 'game_session', 'title'] ].drop_duplicates(), \\\n                            index = ['installation_id','game_session'], \\\n                            columns = ['title'], \\\n                            fill_value = 0, \\\n                            aggfunc = len).add_prefix('title_').reset_index()\n\n    col = df_title.select_dtypes('int64').columns.tolist()\n    df_title[col] = df_title[col].astype('uint8')\n\n\n    sparse_matrix = pd.merge(sparse_matrix, df_title, on = ['installation_id','game_session'], how = 'right')\n\n    print('One hot encoding 4 out of 6')\n    \n    df_days = pd.pivot_table(data = df.loc[: , ['installation_id', 'game_session', 'day'] ].drop_duplicates(), \\\n                          index = ['installation_id','game_session'], \\\n                          columns = ['day'], \\\n                          fill_value = 0, \\\n                          aggfunc = len).add_prefix('day_').reset_index()\n\n    col = df_days.select_dtypes('int64').columns.tolist()\n    df_days[col] = df_days[col].astype('uint8')\n\n    sparse_matrix = pd.merge(sparse_matrix, df_days, on = ['installation_id','game_session'], how = 'right')\n\n    print('One hot encoding 5 out of 6')\n    \n    df_time = pd.pivot_table(data = df.loc[ : , ['installation_id', 'game_session', 'phase_of_day'] ].drop_duplicates(), \\\n                          index = ['installation_id', 'game_session'], \\\n                          columns = ['phase_of_day'], \\\n                          fill_value = 0, \\\n                          aggfunc = len).add_prefix('phase_').reset_index()\n\n    col = df_time.select_dtypes('int64').columns.tolist()\n    df_time[col] = df_time[col].astype('uint8')\n\n    sparse_matrix = pd.merge(sparse_matrix, df_time, on = ['installation_id','game_session'], how = 'right')\n\n    print('One hot encoding 6 out of 6')\n    \n    df_event_code = pd.pivot_table(data = df.loc[ : , ['installation_id', 'game_session', 'event_code'] ], \\\n                                index = ['installation_id', 'game_session'], \\\n                                columns = ['event_code'], \\\n                                fill_value = 0, \\\n                                aggfunc = len).add_prefix('code_').reset_index()\n\n    col = df_event_code.select_dtypes('int64').columns.tolist()\n    df_event_code[col] = df_event_code[col].astype('uint16')\n\n    sparse_matrix = pd.merge(sparse_matrix, df_event_code, on = ['installation_id','game_session'], how = 'right')\n\n    print('Сomputing game attempts...')\n    \n    col = ['installation_id','game_session']\n    df[col] = df[col].astype('object')\n\n    df_game_attempt = df.groupby(['installation_id','game_session'])['incorrect_game_attempt','correct_game_attempt'].sum().reset_index()\n\n    col = df_game_attempt.select_dtypes(['object']).columns.tolist()\n    df_game_attempt[col] = df_game_attempt[col].astype('category')\n    \n    sparse_matrix = pd.merge(sparse_matrix, df_game_attempt, on = ['installation_id','game_session'], how = 'right')\n    \n    print('Сomputing time session...')\n    \n    df_gametime = df.groupby(['installation_id','game_session'])['game_time','timestamp','event_count'].max().reset_index()\n    \n    col = ['installation_id','game_session']\n    df[col] = df[col].astype('category')\n\n    col = df_gametime.select_dtypes(['object']).columns.tolist()\n    df_gametime[col] = df_gametime[col].astype('category')\n\n    sparse_matrix = pd.merge(sparse_matrix, df_gametime, on = ['installation_id','game_session'], how = 'right')\n\n    print('One hot encoding of event id...')\n\n    spec['encode_event_id'] = np.arange(len(spec))\n\n    z = dict( zip ( spec['event_id'], spec['encode_event_id'] ) )\n\n    df['event_id'] = df['event_id'].map(z)\n\n    df_event_id = pd.pivot_table(data = df.loc[:, ['installation_id','game_session','event_id']], \\\n                              aggfunc = len, \\\n                              columns = ['event_id'], \\\n                              index = ['installation_id','game_session'], \\\n                              fill_value = 0).add_prefix('event_id_').reset_index()\n\n    col = df_event_id.select_dtypes('int64').columns.tolist()\n    df_event_id[col] = df_event_id[col].astype('uint16')\n    \n    sparse_matrix = pd.merge(sparse_matrix, df_event_id, on = ['installation_id','game_session'], how = 'left')\n\n    return sparse_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsparse_matrix = one_hot_encoding(df_train, spec = spec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsparse_matrix_test = one_hot_encoding(df_test, spec = spec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove disjoint columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def del_missing_columns(sparse_matrix, sparse_matrix_test):\n  \n  no_columns = set(sparse_matrix.columns.values) - set(sparse_matrix_test.columns.values)\n  sparse_matrix.drop(no_columns, axis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_missing_columns(sparse_matrix, sparse_matrix_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Count labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_accuracy(df, sparse_matrix):\n\n    df['incorrect_attempt'] = np.where( (df['event_data'].str.contains('\"correct\":false') ) \\\n                                                    & ( ( (df['title'] != \"bird measurer (assessment)\") & (df['event_code']==4100) ) | ( (df['title'] == \"bird measurer (assessment)\") & (df['event_code']==4110) ) ), 1, 0 ).astype('uint32')\n\n    df['correct_attempt'] = np.where( (df['event_data'].str.contains('\"correct\":true') ) \\\n                                                  & ( ( (df['title'] != \"bird measurer (assessment)\") & (df['event_code']==4100) ) | ( (df['title'] == \"bird Measurer (assessment)\") & (df['event_code']==4110) ) ), 1, 0).astype('uint32')\n\n    assessment_title = ['bird measurer (assessment)', 'mushroom sorter (assessment)', 'cauldron filler (assessment)', 'chest sorter (assessment)', 'cart balancer (assessment)']\n\n    col = ['installation_id', 'title', 'game_session']\n    df[col] = df[col].astype('object')\n\n    df_train_acc = df[ df['title'].isin(assessment_title)]\\\n    .groupby(['installation_id','title','game_session'])['incorrect_attempt','correct_attempt']\\\n    .sum().reset_index()\n    \n    col = ['installation_id','title','game_session']\n    df[col] = df[col].astype('category')\n    \n    col = df_train_acc.select_dtypes(['object']).columns.tolist()\n    df_train_acc[col] = df_train_acc[col].astype('category')\n    \n    df_train_acc['total_attempts'] = df_train_acc.apply(lambda x: x['incorrect_attempt'] + x['correct_attempt'], axis=1).astype('uint32')\n\n    df_train_acc['accuracy'] = np.where(df_train_acc['total_attempts'] > 0, np.around( (df_train_acc['correct_attempt'] / df_train_acc['total_attempts']), 1), 0).astype('float16')\n\n    df_train_acc['accuracy_group'] = np.where(df_train_acc['accuracy']==1, 3, np.where(df_train_acc['accuracy']==.5, 2, np.where(df_train_acc['accuracy']==0, 0, 1))).astype('uint8')\n\n    df_final = pd.merge(df_train_acc, sparse_matrix, on = ['installation_id','game_session'], how = 'right' )\n\n    col = df_final.select_dtypes('category').columns.values.tolist()\n    df_final[col] = df_final[col].astype('object')\n    \n    df_final = df_final.fillna(value=0)\n\n    convert_dict = { 'incorrect_attempt': 'uint32', 'correct_attempt': 'uint32', 'total_attempts': 'uint32', 'accuracy_group': 'uint8' }\n    df_final = df_final.astype(convert_dict)\n    \n    col = df_final.select_dtypes('object').columns.values.tolist()\n    df_final[col] = df_final[col].astype('category')\n    \n    del df_final['title']\n\n    return df_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf_count_acc_train = calculate_accuracy(df_train, sparse_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf_count_acc_test = calculate_accuracy(df_test, sparse_matrix_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset num session"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataset_history(df, is_train = True):\n  \n    id_session_attempt = df[df['total_attempts'] != 0]['game_session'].unique()\n\n    df = df.sort_values(['installation_id', 'timestamp'])\n\n    col_all = list(df.columns)\n\n    df['num_session'] = np.ones(len(df)).astype('uint32')\n\n    col = df.select_dtypes(['category']).columns.tolist()\n    df[col] = df[col].astype('object')\n\n    col_uin8 = df.select_dtypes(['uint8']).columns.tolist()\n    col_uin16 = df.select_dtypes(['uint16']).columns.tolist()\n    col_uin32 = df.select_dtypes(['uint32']).columns.tolist()\n    col_encode = col_uin8 + col_uin16 + col_uin32\n    df[col_encode] = df[col_encode].astype('int32')\n\n    print('Rolling sum num_session...')\n\n    num_session_groups = df.groupby('installation_id') \n\n    num_session = num_session_groups.rolling(len(df), on = 'game_session', min_periods = 0)['num_session'].sum().astype('uint32').reset_index()\n\n    col = df.select_dtypes(['object']).columns.tolist()\n    df[col] = df[col].astype('category')\n\n    df[col_uin8] = df[col_uin8].astype('uint8')\n    df[col_uin16] = df[col_uin16].astype('uint16')\n    df[col_uin32] = df[col_uin32].astype('uint32')\n\n    num_session['installation_id'] = num_session['installation_id'].astype('category')\n\n    df = pd.merge(df.loc[:, col_all], num_session, on = ['installation_id', 'game_session'], how = 'outer')\n\n    '''Сохраняем опыт предыдущих сессий'''\n\n    col_sum = list(df.select_dtypes(['float16', 'uint8', 'uint16', 'uint32']).columns)\n    no_history = ['num_session', 'accuracy', 'accuracy_group']\n    for column in no_history:\n        col_sum.remove(column)\n\n    col = df.select_dtypes(['category']).columns.tolist()\n    df[col] = df[col].astype('object')\n\n    df[col_encode] = df[col_encode].astype('int32')\n    \n    print('Rolling sum history...')\n\n    rolling_sum_group = df.groupby('installation_id') \n\n\n    rolling_sum = rolling_sum_group.rolling(len(df), on = 'num_session', min_periods = 0)[col_sum].sum().astype('uint32').reset_index()\n    \n    rolling_sum['installation_id'] = rolling_sum['installation_id'].astype('category')\n    rolling_sum['num_session'] = rolling_sum['num_session'].astype('uint32')\n    \n    df = pd.merge(df.loc[:, ['installation_id', 'timestamp', 'game_session', 'num_session', 'accuracy', 'accuracy_group'] ], rolling_sum, on = ['installation_id', 'num_session'], how = 'right')\n\n\n    if is_train:\n\n        df = df[df['game_session'].isin(id_session_attempt)]\n\n        df.drop(['timestamp', 'installation_id', 'game_session', 'incorrect_attempt', 'correct_attempt', 'total_attempts', 'accuracy'], axis='columns', inplace=True)\n\n    else: \n\n        df['installation_id'] = df['installation_id'].astype('object')\n        \n        df = df.sort_values(['installation_id','timestamp']).groupby(['installation_id'], as_index=False).last()\n\n        df['installation_id'] = df['installation_id'].astype('category')\n        \n        df.drop(['timestamp', 'game_session', 'incorrect_attempt', 'correct_attempt', 'total_attempts', 'accuracy'], axis='columns', inplace=True)\n\n        print('Есть значения Nan?:', df.isnull().values.any())\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf_final = dataset_history(df_count_acc_train, is_train = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf_final_test = dataset_history(df_count_acc_test, is_train = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataset(data, is_train = True):\n  \n  if is_train:\n    X = data.loc[:, data.columns != 'accuracy_group']\n  else:\n    X = data.loc[:, ((data.columns != 'accuracy_group') & (data.columns != 'installation_id') ) ]\n  \n  X = normalize(X, axis=0)\n  y = data['accuracy_group'].values \n\n  if is_train:\n  \n    train_stack = np.hstack((X, y[:, np.newaxis]))\n\n    train, val = train_test_split(train_stack, test_size = 0.25, stratify = train_stack[:, -1], random_state = 42)\n\n    X_train = torch.FloatTensor(train[:, :-1])\n    y_train = torch.LongTensor(train[:, -1])\n    X_val = torch.FloatTensor(val[:, :-1])\n    y_val = torch.LongTensor(val[:, -1])\n\n    data = {'train': X_train, 'val': X_val}\n    labels = {'train': y_train, 'val': y_val}\n  \n  else:\n    data = torch.FloatTensor(X)\n    labels = torch.LongTensor(y)\n  \n  return data, labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Batch Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_generator(X, y, batch_size, shuffle = True):\n    \n  if shuffle:\n    np.random.seed(42)\n    perm = np.random.permutation(len(X))\n    \n    for j in range(0, len(X), batch_size):\n      idx = perm[j : j + batch_size]\n      yield X[idx], y[idx]\n\n  else:\n    \n    for j in range(0, len(X), batch_size):\n      yield X[j : j + batch_size], y[j : j + batch_size]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_model(model_name, num_classes, num_features):\n\n    model = None\n    input_size = 0\n    torch.manual_seed(42)\n    np.random.seed(42)\n\n    if model_name == 'fc3':\n\n        \"\"\" fc: 3, layer_1: 475, layer_2: 238\n        \"\"\"\n        \n        D_in, H1, H2, D_out  = num_features, 475, 238, num_classes\n\n        model = nn.Sequential( \n                              nn.Linear(D_in, H1),\n                              nn.BatchNorm1d(H1),\n                              nn.ReLU(),\n                              nn.Linear(H1, H2),\n                              nn.BatchNorm1d(H2),\n                              nn.ReLU(),\n                              nn.Linear(H2, D_out),\n                             )\n\n    elif model_name == 'fc3do':\n\n        \"\"\" fc: 3, layer_1: 952, layer_2: 476, dropout: 0.5\n        \"\"\"\n        \n        D_in, H1, H2, D_out  = num_features, 952, 476, num_classes\n\n        model = nn.Sequential( \n                              nn.Linear(D_in, H1),\n                              nn.BatchNorm1d(H1),\n                              nn.ReLU(),\n                              nn.Dropout(p = 0.5),\n                              nn.Linear(H1, H2),\n                              nn.BatchNorm1d(H2),\n                              nn.ReLU(),\n                              nn.Dropout(p = 0.5),\n                              nn.Linear(H2, D_out),\n                             )\n    \n    elif model_name == \"fc2\":\n        \"\"\" fc: 2, layer_1: 1024, dropout: 0.5\n        \"\"\"\n        \n        D_in, H1, D_out  = num_features, 1024, num_classes\n\n        model = nn.Sequential( \n                              nn.Linear(D_in, H1),\n                              nn.BatchNorm1d(H1),\n                              nn.ReLU(),\n                              nn.Dropout(p = 0.5),\n                              nn.Linear(H1, D_out),\n                             )\n    \n    elif model_name == 'fc3b':\n        \"\"\" fc: 3, layer_1: 4096, layer_2: 2048, dropout: 0.5\n        \"\"\"\n        \n        D_in, H1, H2, D_out  = num_features, 4096, 2048, num_classes\n\n        model = nn.Sequential( \n                              nn.Linear(D_in, H1),\n                              nn.BatchNorm1d(H1),\n                              nn.ReLU(),\n                              nn.Dropout(p = 0.5),\n                              nn.Linear(H1, H2),\n                              nn.BatchNorm1d(H2),\n                              nn.ReLU(),\n                              nn.Dropout(p = 0.5),\n                              nn.Linear(H2, D_out),\n                             )\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, data, labels, criterion, optimizer, shuffle = True, num_epochs = 25, batch_size = 100):\n    since = time.time()\n\n    val_acc_history = []\n    val_loss_history = []\n    train_acc_history = []\n    train_loss_history = []\n    lr_find_lr = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in tqdm_notebook(range(num_epochs)):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  \n            else:\n                model.eval()   \n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, label in batch_generator(data[phase], labels[phase], batch_size, shuffle):\n                inputs = inputs\n                label = label\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n\n                  outputs = model(inputs)\n                  loss = criterion(outputs, label)\n\n                  _, preds = torch.max(outputs, 1)\n\n                if phase == 'train':  \n                  loss.backward()\n                  optimizer.step()\n                  scheduler.step()\n                  lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n                  lr_find_lr.append(lr_step)\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == label.data)\n\n            epoch_loss = running_loss / len(data[phase])\n            epoch_acc = running_corrects.double() / len(data[phase])\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n                val_loss_history.append(epoch_loss)\n            else:\n                train_acc_history.append(epoch_acc)\n                train_loss_history.append(epoch_loss)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    history_val = {'loss': val_loss_history, 'acc': val_acc_history}\n    history_train = {'loss': train_loss_history, 'acc': train_acc_history}\n\n    model.load_state_dict(best_model_wts)\n\n    return model, history_val, history_train, time_elapsed, lr_find_lr ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualization(train, val, is_loss = True):\n  \n  if is_loss:\n    plt.figure(figsize=(17,10))\n    plt.plot(train, label = 'Training loss')\n    plt.plot(val, label = 'Val loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n  \n  else:\n    plt.figure(figsize=(17,10))\n    plt.plot(train, label = 'Training acc')\n    plt.plot(val, label = 'Val acc')\n    plt.title('Training and validation acc')\n    plt.xlabel('Epochs')\n    plt.ylabel('Acc')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Form the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data, labels = dataset(df_final, is_train = True)\ndata_test, labels_test = dataset(df_final_test, is_train = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model-1 fc3mini"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'fc3'\nnum_classes = 4\nnum_features = 475\nbatch_size = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = initialize_model(model_name, num_classes, num_features)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_lr = 0.00001\nmax_lr = 0.003\n\nnum_epochs = 90\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model.parameters(), lr=0.000013, momentum=0.9, nesterov = True)\n\nstep_size = 2 * math.ceil( len(data['train']) / batch_size )\n\nscheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.9994, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\nlr_cycle = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3, history_val, history_train, time_elapsed, lr_find_lr = train_model(model, data, labels, criterion, optimizer, shuffle = True, num_epochs = num_epochs, batch_size = batch_size)\n\nval_loss += history_val['loss']\nval_acc += history_val['acc']\ntrain_loss += history_train['loss']\ntrain_acc += history_train['acc']\nlr_cycle += lr_find_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,10))\nplt.plot(lr_cycle);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_acc, val_acc, is_loss = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_loss, val_loss, is_loss = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model-2 fc3do"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'fc3do'\nnum_classes = 4\nnum_features = 475\nbatch_size = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = initialize_model(model_name, num_classes, num_features)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_lr = 0.0001\nmax_lr = 0.009\n\nnum_epochs = 72\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model.parameters(), lr=0.000013, momentum=0.9, nesterov = True)\n\nstep_size = 4 * math.ceil( len(data['train']) / batch_size )\n\nscheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.9999, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\nlr_cycle = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3do, history_val, history_train, time_elapsed, lr_find_lr = train_model(model, data, labels, criterion, optimizer, shuffle = True, num_epochs = num_epochs, batch_size = batch_size)\n\nval_loss += history_val['loss']\nval_acc += history_val['acc']\ntrain_loss += history_train['loss']\ntrain_acc += history_train['acc']\nlr_cycle += lr_find_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,10))\nplt.plot(lr_cycle);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_acc, val_acc, is_loss = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_loss, val_loss, is_loss = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model-3 fc2"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'fc2'\nnum_classes = 4\nnum_features = 475\nbatch_size = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = initialize_model(model_name, num_classes, num_features)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_lr = 0.00025\nmax_lr = 0.018\n\nnum_epochs = 90\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model.parameters(), lr=0.000013, momentum=0.9, nesterov = True)\n\nstep_size = 3 * math.ceil( len(data['train']) / batch_size )\n\nscheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.9993, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\nlr_cycle = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc2, history_val, history_train, time_elapsed, lr_find_lr = train_model(model, data, labels, criterion, optimizer, shuffle = True, num_epochs = num_epochs, batch_size = batch_size)\n\nval_loss += history_val['loss']\nval_acc += history_val['acc']\ntrain_loss += history_train['loss']\ntrain_acc += history_train['acc']\nlr_cycle += lr_find_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,10))\nplt.plot(lr_cycle);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_acc, val_acc, is_loss = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_loss, val_loss, is_loss = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model-4 fc3b"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'fc3b'\nnum_classes = 4\nnum_features = 475\nbatch_size = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = initialize_model(model_name, num_classes, num_features)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_lr = 0.0004\nmax_lr = 0.025\n\nnum_epochs = 10\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model.parameters(), lr=0.000013, momentum=0.9, nesterov = True)\n\nstep_size = 2 * math.ceil( len(data['train']) / batch_size )\n\nscheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.999, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\nlr_cycle = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3b, history_val, history_train, time_elapsed, lr_find_lr = train_model(model, data, labels, criterion, optimizer, shuffle = True, num_epochs = num_epochs, batch_size = batch_size)\n\nval_loss += history_val['loss']\nval_acc += history_val['acc']\ntrain_loss += history_train['loss']\ntrain_acc += history_train['acc']\nlr_cycle += lr_find_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,10))\nplt.plot(lr_cycle);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_acc, val_acc, is_loss = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization(train_loss, val_loss, is_loss = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submit"},{"metadata":{},"cell_type":"markdown","source":"### Prediction function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, data, labels, shuffle = False):\n    with torch.no_grad():\n        logits = []\n    \n        for inputs, label in batch_generator(data, labels, batch_size, shuffle):\n            inputs = inputs\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=1).numpy()\n    return probs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3_pred = predict(fc3, data_test, labels_test, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3do_pred = predict(fc3do, data_test, labels_test, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc2_pred = predict(fc2, data_test, labels_test, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3b_pred = predict(fc3b, data_test, labels_test, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3_class = np.argmax(fc3_pred, axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3do_class = np.argmax(fc3do_pred, axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc2_class = np.argmax(fc2_pred, axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3b_class = np.argmax(fc3b_pred, axis=1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_class = np.hstack(( fc3_class[:, np.newaxis], fc3do_class[:, np.newaxis], fc2_class[:, np.newaxis], fc3b_class[:, np.newaxis] ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Probabilities"},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3_prob = np.max(fc3_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3do_prob = np.max(fc3do_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc2_prob = np.max(fc2_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc3b_prob = np.max(fc3b_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Probability matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_prob = np.hstack((fc3_prob[:, np.newaxis], fc3do_prob[:, np.newaxis], fc2_prob[:, np.newaxis], fc3b_prob[:, np.newaxis] ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction Vector"},{"metadata":{"trusted":true},"cell_type":"code","source":"vector_pred = []\n\nfor i in range(matrix_class.shape[0]):\n  candidates, count_vote = np.unique(matrix_class[i], return_counts=True, axis=0)\n  candid_numvote = np.hstack((candidates[:, np.newaxis], count_vote[:, np.newaxis]))\n  if len(np.unique(count_vote)) == 1:\n    ind = np.argmax(matrix_prob[i])\n    vector_pred.append(int(matrix_class[i][ind]))\n  else:\n    max_num_vote = np.max(candid_numvote[:, 1])\n    candit_max_vote = candid_numvote[candid_numvote[:, 1] == max_num_vote]\n    if len(candit_max_vote[:, 0]) == 1:\n      vector_pred.append( int(candit_max_vote[:, 0]) )\n    else: \n      indx = [ np.where(matrix_class[0] == candit_max_vote[:, 0][i]) for i in range(len(candit_max_vote[:, 0])) ]\n      prob_cand = np.array( [ matrix_prob[i][indx[i]].sum() for i in range(len(indx)) ] )\n      matrix_choise = np.hstack((candit_max_vote, prob_cand[:, np.newaxis]))\n      if len(np.unique(matrix_choise[:, 2])) == 1:\n        vector_pred.append( int(matrix_choise[:, 0][0]) )\n      else:\n        indx_max_prob = np.argmax(matrix_choise[:, 2])\n        vector_pred.append( int(matrix_choise[:, 0][indx_max_prob]) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'installation_id': df_final_test['installation_id'].values, 'accuracy_group': vector_pred})\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['accuracy_group'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}