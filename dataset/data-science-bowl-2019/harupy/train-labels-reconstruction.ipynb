{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\n\ndef display(*dfs):\n    for df in dfs:\n        IPython.display.display(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')\nlabels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.head(), test.head(), labels.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_assessments(df):\n    is_assessment = (\n        (df['title'].eq('Bird Measurer (Assessment)') & df['event_code'].eq(4110)) |\n        (~df['title'].eq('Bird Measurer (Assessment)') & df['event_code'].eq(4100)) &\n        df['type'].eq('Assessment')\n    )\n    assessments = df[is_assessment].reset_index(drop=True)\n    assessments['correct'] = assessments['event_data'].str.extract(r'\"correct\":([^,]+)')\n    assessments['correct'] = assessments['correct'].map(lambda x: 1 if x == 'true' else 0)\n    return assessments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assessments_train = select_assessments(train)\nassessments_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def with_name(f, name):\n    f.__name__ = name\n    return f\n\n\ndef accuracy_group(acc):\n    if acc == 0:\n        return 0\n    elif acc == 1:\n        return 3\n    elif 0.5 <= acc < 1.0:\n        return 2\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggs = {'correct': [\n    with_name(lambda ser: (ser == 1).sum(), 'num_correct'),\n    with_name(lambda ser: (ser == 0).sum(), 'num_incorrect'),\n    with_name(lambda ser: ser.mean(), 'accuracy'),\n]}\n\nby = ['installation_id', 'title', 'game_session']\nstats = assessments_train.groupby(by).agg(aggs).reset_index()\nstats.columns = [col[1] if (col[1] != '') else col[0] for col in stats.columns] # flatten columns\nstats = stats.assign(accuracy_group=stats['accuracy'].map(accuracy_group).astype(np.int64))  # add accuracy group","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(\n    stats.sort_values(by).reset_index(drop=True).sort_index(axis=1),\n    labels.sort_values(by).reset_index(drop=True).sort_index(axis=1)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.testing import assert_frame_equal\n\nassert_frame_equal(\n    stats.sort_values(by).reset_index(drop=True).sort_index(axis=1),\n    labels.sort_values(by).reset_index(drop=True).sort_index(axis=1),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}