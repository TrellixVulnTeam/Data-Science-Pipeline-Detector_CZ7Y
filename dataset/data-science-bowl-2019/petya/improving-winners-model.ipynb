{"cells":[{"metadata":{},"cell_type":"markdown","source":"Greetings! This is my first Kaggle competition.\nI've taken an awesome notebook https://www.kaggle.com/sergeifironov/bowl-stabilize-coefs-cntrs-all5 by https://www.kaggle.com/sergeifironov and tried adding a few features.\nThe misses count from https://www.kaggle.com/bhavikapanara/2019-dsb-with-more-features-qwk-0-549 by https://www.kaggle.com/bhavikapanara worked pretty well and increased the private score to 0.563"},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile code_counts.py\nimport pandas as pd\nimport gc\nfrom tqdm import tqdm\ndef create_counters(fout):\n    fname = '/kaggle/input/data-science-bowl-2019/'+ fout +'.csv'\n    df = pd.read_csv(fname)[['timestamp','installation_id','event_code']]\n    \n    #cut off 90% for test purpose\n    #if fout == 'train': df = df[int(len(df)*0.9):]\n        \n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df = df.sort_values(['installation_id', 'timestamp']).reset_index(drop=True)\n    df['event_global_enc'] = (df['event_code'] == 2000).astype(int)  \n    df['event_global_enc'] = df.event_global_enc.cumsum()\n\n    agg_df = df.groupby(['event_global_enc','event_code']).agg({'timestamp':'count'}).reset_index()\n    agg_df.columns = ['event_global_enc','event_code','event_code_count']\n    del df\n    gc.collect()\n    \n    event_codes = ['2000','3010','3110','4020','4021','4030','4035','4070',\n                   '4090','2020','2030','2040','2050','2080','2083','3020',\n                   '3021','3120','3121','4010','2060','2070','4031','4025',\n                   '5000','5010','2081','2025','4022','2010','2035','4040',\n                   '4100','4110','4045','4095','4220','2075','4230','4235',\n                   '4080','4050']\n    dcts = []\n    for t,g in tqdm(agg_df.groupby('event_global_enc')):\n        dct = {'event_global_enc': t}\n        g.index = g['event_code']\n        g = g['event_code_count'].to_dict()\n        for k in event_codes:\n            dct['event_code_' + k] = g.get(int(k), 0)\n        dcts.append(dct)\n    pd.DataFrame(dcts).to_csv(fout + '_code_counts.csv', index=False)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile create_code_counters_train.py\n# from code_counts import create_counters\ncreate_counters('train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile create_code_counters_test.py\n# from code_counts import create_counters\ncreate_counters('test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%time \n# !python create_code_counters_train.py\n# !python create_code_counters_test.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_miss(x):\n    try:\n        return json.loads(x)['misses']\n    except:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"miss_cols = ['cum_misses']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile preproc.py\n\nimport numpy as np \nimport pandas as pd \nimport json\nfrom pandas.io.json import json_normalize\nimport seaborn as sns \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import TimeSeriesSplit, KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nimport functools\nfrom multiprocessing import Pool\nimport logging\nimport gc\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom tqdm import tqdm\nimport pickle\n\ndef load_csv(filename, fout):\n    df = pd.read_csv(filename)\n    \n    #if fout == 'train': df = df[int(len(df)*0.9):]\n    \n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df = df.sort_values(['installation_id', 'timestamp']).reset_index(drop=True)\n    \n    df['correct'] = df['event_data'].str.contains('\"correct\":true').astype(int)\n    df['incorrect'] = df['event_data'].str.contains('\"correct\":false').astype(int)\n    \n    def get_miss(x):\n        try:\n            return json.loads(x)['misses']\n        except:\n            return 0\n        \n    # we add misses counter \n    df['misses'] = df['event_data'].apply(get_miss)\n    grp = df[['installation_id', 'game_session', 'misses']].groupby(['installation_id', 'game_session'])\n    df['cum_misses'] = grp['misses'].transform(pd.Series.cumsum)\n\n    \n    df.drop(['event_data', 'misses'], axis=1, inplace=True)\n    gc.collect()\n    df['super_token'] = df['title'] + df['event_code'].astype(str)+df['correct'].astype(str)+df['incorrect'].astype(str)\n    df['super_token'] = df['super_token'].str.replace(' ','').str.replace('-','')\n    \n    df['attempt'] = (((df.event_code == 4100) & (df.title != 'Bird Measurer (Assessment)')) |\\\n                     ((df.event_code == 4110) & (df.title == 'Bird Measurer (Assessment)'))) &\\\n                    (df['type'] == 'Assessment')\n    df['attempt'] = df['attempt'].astype(int)\n    df['correct'] = df['correct'] * df['attempt']\n    df['incorrect'] = df['incorrect'] * df['attempt']\n    \n    df['start_event'] = (df['event_code'] == 2000).astype(int)  \n    df['start_assessment'] = (df['type'] == 'Assessment').astype(int) * df['start_event']\n    df['end_event'] = df.start_event.shift(-1, fill_value=1)\n    df['event_global_enc'] = df.start_event.cumsum()\n    gc.collect()\n    \n    agg_df = df.groupby('event_global_enc').agg({'installation_id':'first', 'correct': 'sum', 'incorrect': 'sum', 'timestamp': ['min','max']}).reset_index()\n    agg_df.columns = ['event_global_enc', 'installation_id', 'correct_attempts', 'incorrect_attempts', 'ts_min','ts_max']\n    agg_df['game_duration'] = (agg_df['ts_min'] - agg_df['ts_min'].shift(1)).dt.days*3600*24 +\\\n    (agg_df['ts_min'] - agg_df['ts_min'].shift(1)).dt.seconds +\\\n    (agg_df['ts_min'] - agg_df['ts_min'].shift(1)).dt.microseconds / 1e6\n    agg_df['gs'] = 1\n    agg_df['gs'] = agg_df.groupby('installation_id')['gs'].transform(pd.Series.cumsum)\n    agg_df.loc[agg_df.gs==1,'game_duration'] = 0\n    agg_df['game_duration'] = np.log1p(agg_df['game_duration'])\n        \n    aggcols = ['event_global_enc', 'correct_attempts', 'incorrect_attempts', 'game_duration']\n    df = df.merge(agg_df[aggcols], on='event_global_enc', how='left')\n    del agg_df\n    gc.collect()\n    \n    assessments = ['Bird Measurer (Assessment)', 'Cart Balancer (Assessment)', \n                   'Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)', 'Mushroom Sorter (Assessment)']\n    assessment_fts = []\n    for a in assessments:\n        feat1 = a.replace(' ','')+'_correct'\n        feat2 = a.replace(' ','')+'_incorrect'\n        assessment_fts.append(feat1)\n        assessment_fts.append(feat2)\n        df[feat1] = 0\n        df[feat2] = 0\n        df.loc[df.title == a,feat1] = df.loc[df.title==a].groupby(['installation_id'])['correct'].transform(pd.Series.cumsum)\n        df.loc[df.title == a,feat2] = df.loc[df.title==a].groupby(['installation_id'])['incorrect'].transform(pd.Series.cumsum)\n    \n    df['metric_point'] = df['start_assessment'] * (df.correct_attempts + df.incorrect_attempts > 0).astype(int)\n    df['metric_point_inference'] = df.installation_id != df.installation_id.shift(-1, fill_value='')\n    gc.collect()\n    \n    \n    ret_columns = ['installation_id', 'title', 'super_token', 'event_code', 'game_duration',\n                   'correct_attempts', 'incorrect_attempts', \n                   'metric_point', 'metric_point_inference', 'event_global_enc'\n                  ] + assessment_fts + miss_cols\n    df = df[ret_columns]\n    gc.collect()\n    \n    return df\n\ndef create_text_file(fname, fout):\n    train = load_csv(fname, fout)\n    \n    #if fout == 'test':\n    #    train['mp'] = train['metric_point']\n    #    train['mp'] = train.groupby(['installation_id'])['mp'].transform(pd.Series.cumsum)\n    #    train.loc[(train.metric_point == 1) & (train.mp > 1),'metric_point'] = 0\n    #    train.drop(['mp'], axis=1, inplace=True)\n    \n    train['event_idx'] = 1\n    train['event_idx'] = train.groupby(['installation_id'])['event_idx'].transform(pd.Series.cumsum)\n\n    texts = []\n    if fout == 'train':\n        labels = {}\n        for i,q in enumerate(train.super_token.unique()):\n            labels[q] = i + 1\n        with open('txt_labels.pickle', 'wb') as handle:\n            pickle.dump(labels,handle)\n    else:\n        with open('txt_labels.pickle', 'rb') as handle:\n            labels = pickle.load(handle)\n    train['super_token'] = train['super_token'].map(lambda x: labels.get(x, 0)).astype(np.int16)\n\n    for ix in tqdm(train.loc[train.metric_point_inference==1].index):\n        point_idx = train.iloc[ix].event_idx\n        texts.append(train.iloc[(ix-point_idx+1):(ix+1)]['super_token'].values.tolist())\n        \n    np.save(fout + '_mpi', np.array(texts))\n    \n    texts = []\n    for ix in tqdm(train.loc[train.metric_point==1].index):\n        point_idx = train.iloc[ix].event_idx\n        texts.append(train.iloc[(ix-point_idx+1):(ix+1)]['super_token'].values.tolist())\n    np.save(fout + '_mp', np.array(texts))\n        \n    assessments = ['Bird Measurer (Assessment)', 'Cart Balancer (Assessment)', \n               'Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)', 'Mushroom Sorter (Assessment)']\n    assessment_fts = []\n    for a in assessments:\n        feat1 = a.replace(' ','')+'_correct'\n        feat2 = a.replace(' ','')+'_incorrect'\n        feat3 = a.replace(' ','')+'_rate'\n        assessment_fts.append(feat1)\n        assessment_fts.append(feat2)\n        assessment_fts.append(feat3)\n        train[feat3] = 0\n        train.loc[train[feat1]+train[feat2] > 0,feat3] = train.loc[train[feat1]+train[feat2] > 0,feat1] / \\\n        (train.loc[train[feat1]+train[feat2] > 0,feat1] + train.loc[train[feat1]+train[feat2] > 0,feat2])\n        \n    train['assessment_rate'] = 0\n    train.loc[train.correct_attempts + train.incorrect_attempts > 0, 'assessment_rate'] = \\\n                  train.correct_attempts / (train.correct_attempts + train.incorrect_attempts)\n    \n    usefull_fts = ['installation_id', 'title', 'assessment_rate', \n                   'game_duration', 'correct_attempts', 'incorrect_attempts',\n                   'metric_point', 'metric_point_inference', 'event_global_enc'] + assessment_fts + miss_cols\n\n    train = train.loc[train.event_code == 2000, usefull_fts].reset_index(drop=True)\n    gc.collect()\n    \n    ecc = pd.read_csv(fout + '_code_counts.csv')\n    train = train.merge(ecc, on='event_global_enc', how='left').drop(['event_global_enc'], axis=1)\n    del ecc\n    gc.collect()\n    \n    train['event_idx'] = 1\n    train['event_idx'] = train.groupby(['installation_id'])['event_idx'].transform(pd.Series.cumsum)\n    \n    train['label'] = 0\n    train.loc[(train.incorrect_attempts >= 2) & (train.correct_attempts > 0),'label'] = 1\n    train.loc[(train.incorrect_attempts == 1) & (train.correct_attempts > 0),'label'] = 2\n    train.loc[(train.incorrect_attempts == 0) & (train.correct_attempts > 0),'label'] = 3\n    train['all_attempts'] = train.incorrect_attempts + train.correct_attempts\n    \n    train.to_csv(fout+'.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"miss_cols = ['cum_misses']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile text_processing_train.py\n\n# from preproc import create_text_file\n\ncreate_text_file('/kaggle/input/data-science-bowl-2019/train.csv', 'train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile text_processing_test.py\n\n# from preproc import create_text_file\n\ncreate_text_file('/kaggle/input/data-science-bowl-2019/test.csv', 'test')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%time\n# !python text_processing_train.py\n# !python text_processing_test.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile train_tfidf.py\n\nimport numpy as np \nimport gc\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom tqdm import tqdm\nimport pickle\nfrom scipy.sparse import save_npz\n\ntexts = np.load('train_mpi.npy',allow_pickle=True).tolist() + np.load('test_mpi.npy',allow_pickle=True).tolist()\nfor i,t in tqdm(enumerate(texts)):\n    texts[i] = ' '.join(['q' + str(q) for q in t])\nprint(len(texts), len(texts[0]), texts[0][:10])\n\nvectorizer = TfidfVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, \n                             lowercase=False, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, \n                             token_pattern='\\S+', ngram_range=(1, 3), max_df=0.99, min_df=100, max_features=None, \n                             vocabulary=None, binary=False, norm='l2', use_idf=True, \n                             smooth_idf=True, sublinear_tf=False)\nvectorizer.fit(texts)\ndel texts\ngc.collect()\n\nwith open('vectorizer.pickle', 'wb') as handle:\n    pickle.dump(vectorizer,handle)\n\nfor f in ['train_mp','test_mp','test_mpi']:\n    texts = np.load(f + '.npy',allow_pickle=True).tolist()\n    for i,t in tqdm(enumerate(texts)):\n        texts[i] = ' '.join(['q' + str(q) for q in t])\n    texts = vectorizer.transform(texts)\n    save_npz(f, texts)\n    del texts\n    gc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%time\n# !python train_tfidf.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from __future__ import absolute_import\n\nimport numpy as np \nimport pandas as pd \nimport json\nfrom pandas.io.json import json_normalize\nimport seaborn as sns \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import TimeSeriesSplit, KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nimport functools\nfrom multiprocessing import Pool\nimport logging\nimport gc\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom tqdm import tqdm_notebook\nimport scipy\nimport tensorflow as tf\nimport keras\nimport math\nimport random\nimport os\n\nSEED = 239\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntf.random.set_seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nq_train = scipy.sparse.load_npz('train_mp.npz')\nq_train_tst = scipy.sparse.load_npz('test_mp.npz')\n\nq_train = scipy.sparse.vstack([q_train, q_train_tst])\ndel q_train_tst\ngc.collect()\nq_test = scipy.sparse.load_npz('test_mpi.npz')\n\ntest = pd.read_csv('test.csv')\ntrain2 = pd.read_csv('train.csv')\n\nprint(train2.shape, test.shape, q_train.shape, q_test.shape,      train2.loc[train2.metric_point==1].shape, test.loc[test.metric_point==1].shape)\n\ntrain_ids = train2.installation_id.unique()\ntest_ids = test.loc[test.metric_point_inference==1,'installation_id'].values\ntrain2 = pd.concat([train2,test], sort=False, ignore_index=True).reset_index(drop=True)\ndel test\ngc.collect()\n\ntrain2['event_idx'] = 1\ntrain2['event_idx'] = train2.groupby(['installation_id'])['event_idx'].transform(pd.Series.cumsum)\n\nevent_codes = ['3010','3110','4020','4021','4030','4035',\n               '4090','2020','2030','2040','2050','2080','2083',\n               '3021','3120','4010','2060','2070','4031','4025',\n               '5000','5010','2081','2025','4022','2010','2035','4040',\n               '4100','4110','4045','4095','4220','2075','4230','4235',\n               '4080','4050']\n#event_codes = ['4070','3020','3121','4020','3120','2030','4035','4030']\ncode_counts_cols = ['event_code_' + q for q in event_codes]\n\nassessments = ['Bird Measurer (Assessment)', 'Cart Balancer (Assessment)', \n               'Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)', 'Mushroom Sorter (Assessment)']\nassessment_fts = ['BirdMeasurer(Assessment)_correct',\n 'BirdMeasurer(Assessment)_incorrect',\n 'BirdMeasurer(Assessment)_rate',\n 'CartBalancer(Assessment)_correct',\n 'CartBalancer(Assessment)_incorrect',\n 'CartBalancer(Assessment)_rate',\n 'CauldronFiller(Assessment)_correct',\n 'CauldronFiller(Assessment)_incorrect',\n 'CauldronFiller(Assessment)_rate',\n 'ChestSorter(Assessment)_correct',\n 'ChestSorter(Assessment)_incorrect',\n 'ChestSorter(Assessment)_rate',\n 'MushroomSorter(Assessment)_correct',\n 'MushroomSorter(Assessment)_incorrect',\n 'MushroomSorter(Assessment)_rate']\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nlabelers = {}\ncat_cols = ['title']\n\nprint(\"Process categorical features:\")\nfor col_name in cat_cols:\n    labelers[col_name] = {x:i+1 for i, x in enumerate(train2.loc[:, col_name].unique())}\n    train2[col_name] = train2[col_name].apply(lambda x: labelers[col_name].get(x, 0))\n    \ncat_sizes_map = {col_name: len(labeler)+1 for col_name, labeler in labelers.items()}\ncat_sizes_map\n\n#'correct_attempts',\ntrain2['correct_attempts'].fillna(0, inplace=True)\nnum_cols = ['incorrect_attempts','all_attempts','game_duration'] + assessment_fts + code_counts_cols + miss_cols\n\nfeat_scalers = {}\nhigh_cups = {}\nfor f in num_cols:\n    feat_scaler = MinMaxScaler(feature_range=(-1,1))\n    high_cup = np.percentile(train2.loc[train2.metric_point==1,f].values, 99)\n    high_cups[f] = high_cup\n    print(f, high_cup)\n    train2.loc[train2[f] > high_cup, f] = high_cup + 1\n    feat_scaler.fit(train2[f].fillna(0).astype(\"float32\").values.reshape(-1,1))\n    train2[f] = feat_scaler.transform(train2[f].fillna(0).astype(\"float32\").values.reshape(-1,1))\n    feat_scalers[f] = feat_scaler\nprint(high_cups)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# In[15]:\n\n\nfrom tqdm import tqdm_notebook\n\nfirst_dim = train2.loc[train2.metric_point==1,:].shape[0]\nseq_len = 64\nnum_cols = ['correct_attempts', 'incorrect_attempts', 'assessment_rate'] + code_counts_cols + miss_cols + ['game_duration', \n            'current_assessment_correct', 'current_assessment_incorrect', 'current_assessment_rate'] \n\nmatrix_titles = np.zeros((first_dim, seq_len))\nmatrix_numericals = np.zeros((first_dim, seq_len, len(num_cols)))\n\ninstids = train2.loc[train2.metric_point==1,'installation_id'].values\nj = 0\nfor ix in tqdm_notebook(train2.loc[train2.metric_point==1].index):\n    point_idx = train2.iloc[ix].event_idx\n    cur_title = train2.iloc[ix].title\n    f1 = np.min([point_idx, seq_len])\n    matrix_titles[j,(seq_len - f1):] = train2.iloc[(ix-f1+1):(ix+1)]['title'].values\n    for k, f in enumerate(num_cols[:-3]):\n        matrix_numericals[j,(seq_len - f1):,k] = train2.iloc[(ix-f1+1):(ix+1)][f].values\n    assessment_idx = 0\n    for ia,a in enumerate(assessments):\n        if labelers['title'][a] == cur_title:\n            assessment_idx = ia\n    cur_fts = [assessment_fts[3*assessment_idx], assessment_fts[3*assessment_idx+1],assessment_fts[3*assessment_idx+2]]\n    matrix_numericals[j,(seq_len - f1):,-3:] = train2.iloc[(ix-f1+1):(ix+1)][cur_fts].values\n    j += 1\nto_zero_cols_count = len(['correct_attempts', 'incorrect_attempts', 'assessment_rate'] + code_counts_cols)\nmatrix_numericals[:,-1,:to_zero_cols_count] = 0 #[[0]*to_zero_cols_count]*matrix_numericals.shape[0]\n#matrix_numericals[:,-6:,3:to_zero_cols_count] = 0 #[[0]*to_zero_cols_count]*matrix_numericals.shape[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%writefile train_model.py\n\n\n\n# In[16]:\n\n\ntest = pd.read_csv('test.csv')\n\ncat_cols = ['title']\nfor col_name in cat_cols:\n    test[col_name] = test[col_name].apply(lambda x: labelers[col_name].get(x, 0))\n\ntest['correct_attempts'].fillna(0, inplace=True)\nnum_cols = ['incorrect_attempts','game_duration']  + assessment_fts + code_counts_cols + miss_cols\nfor f in num_cols:\n    high_cup = high_cups[f]\n    test.loc[test[f] > high_cup, f] = high_cup + 1\n    test[f] = feat_scalers[f].transform(test[f].fillna(0).astype(\"float32\").values.reshape(-1,1))\n\n\n# In[17]:\n\n\nfirst_dim = test.loc[test.metric_point_inference==1,:].shape[0]\nseq_len = 64\nnum_cols = ['correct_attempts', 'incorrect_attempts', 'assessment_rate'] + code_counts_cols +  miss_cols+['game_duration', \n            'current_assessment_correct', 'current_assessment_incorrect', 'current_assessment_rate'] \n\nmatrix_titles_test = np.zeros((first_dim, seq_len))\nmatrix_numericals_test = np.zeros((first_dim, seq_len, len(num_cols)))\n\nj = 0\nfor ix in tqdm_notebook(test.loc[test.metric_point_inference==1,:].index):\n    point_idx = test.iloc[ix].event_idx\n    cur_title = test.iloc[ix].title\n    f1 = np.min([point_idx, seq_len])\n    matrix_titles_test[j,(seq_len - f1):] = test.iloc[(ix-f1+1):(ix+1)]['title'].values\n    for k, f in enumerate(num_cols[:-3]):\n        matrix_numericals_test[j,(seq_len - f1):,k] = test.iloc[(ix-f1+1):(ix+1)][f].values\n    assessment_idx = 0\n    for ia,a in enumerate(assessments):\n        if labelers['title'][a] == cur_title:\n            assessment_idx = ia\n    cur_fts = [assessment_fts[3*assessment_idx], assessment_fts[3*assessment_idx+1],assessment_fts[3*assessment_idx+2]]\n    matrix_numericals_test[j,(seq_len - f1):,-3:] = test.iloc[(ix-f1+1):(ix+1)][cur_fts].values\n    j += 1\n\nmatrix_numericals_test[:,-1,:to_zero_cols_count] = 0 #[[0]*to_zero_cols_count]*matrix_numericals_test.shape[0]\n#matrix_numericals_test[:,-6:,3:to_zero_cols_count] = 0\nprint(matrix_numericals_test.shape, matrix_titles_test.shape)\n\ndel test\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# In[18]:\n\n\nfrom sklearn.metrics import confusion_matrix\nfrom numba import jit \nfrom functools import partial\n\n\n@jit\ndef qwk3(a1, a2):\n    assert(len(a1) == len(a2))\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((4, ))\n    hist2 = np.zeros((4, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(4):\n        for j in range(4):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e     \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# In[19]:\n\n\n\nimport itertools\nfrom keras import Model\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.callbacks import *\nfrom keras import regularizers\nfrom keras import optimizers\nfrom keras import losses\nfrom keras import backend as K\nfrom keras.utils import Sequence\n\nfrom keras.backend.tensorflow_backend import set_session\nfrom sklearn.metrics import mean_squared_error, log_loss, mean_absolute_error\n\nimport scipy as sp\n\nclass FeatureSequence(Sequence):\n    def __init__(self, Xs, Ys, batch_size, shuffle=False):\n        self.Xs = Xs\n        self.Ys = Ys\n        self.batch_size = batch_size\n        \n        self.inx = np.arange(self.Xs[0].shape[0])\n        self.shuffle = shuffle \n        if self.shuffle:\n            np.random.shuffle(self.inx)\n\n\n    def __len__(self):\n        return math.ceil(self.inx.shape[0] / self.batch_size)\n\n    def __getitem__(self, i):\n        batch_inx = self.inx[i*self.batch_size:(i+1)*self.batch_size]\n        if self.Ys is None:\n            return [X[batch_inx] for X in self.Xs], None\n        return [X[batch_inx] for X in self.Xs], [Y[batch_inx] for Y in self.Ys]\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.inx)\n            \nclass OptimizedRounder(object):\n    def __init__(self, samples):\n        self.coef_ = 0\n        self.samples = np.array(samples).astype(np.int32)\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            else:\n                X_p[i] = 3\n        tts = []\n        for i in range(self.samples.shape[0]):\n            tts.append(qwk3(np.array(y)[self.samples[i]], np.array(X_p)[self.samples[i]]))\n        ll = np.median(tts)  \n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [1.12232214,1.73925866,2.22506454]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead',\n                                          options = {'maxiter':1e7, 'xatol':1e-4}\n                                         )\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            else:\n                X_p[i] = 3\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']\n            \nclass KappaEvaluationSeq(Callback):\n    def __init__(self, X_seq, Y, Y2, samples, name, interval=1):\n        super(Callback, self).__init__()\n\n        self.X_seq = X_seq\n        self.Y, self.Y2 = Y, Y2\n        self.samples = samples.astype(np.int32)\n        self.name = name\n        self.interval = interval\n    \n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred1 = self.model.predict_generator(self.X_seq, steps=len(self.X_seq), \n                                                            use_multiprocessing=False, workers=1, \n                                                            max_queue_size=2*4)\n            y_pred1 = y_pred1.ravel()\n            vmae = mean_absolute_error(self.Y, y_pred1)     \n            \n            optR = OptimizedRounder(self.samples)\n            optR.fit(y_pred1, self.Y)\n            coefficients = optR.coefficients()\n            y_pred = optR.predict(y_pred1, coefficients)     \n            tts = []\n            for i in range(self.samples.shape[0]):\n                tts.append(qwk3(np.array(self.Y)[self.samples[i]], np.array(y_pred.astype(int))[self.samples[i]]))\n            kapa = np.median(tts) \n            #kapa = qwk3(self.Y, y_pred.astype(int))\n            \n            logs[self.name+\"_kappa\"] = kapa\n            logs[self.name+\"_mae\"] = vmae\n            coefs = (\"[{:.4f},{:.4f},{:.4f}]\".format(coefficients[0],coefficients[1],coefficients[2]))\n            print((self.name+\"_kappa: {:.4f}; \"+self.name+\"_mae: {:.4f}; \"+coefs).format(kapa,vmae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras import backend as K\nfrom keras import initializers\nfrom keras import constraints\nfrom keras import regularizers\nfrom keras.engine import InputSpec, Layer\n\nclass Attention(Layer):\n    def __init__(self,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        \"\"\"\n        Keras Layer that implements an Attention mechanism for temporal data.\n        Supports Masking.\n        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n        # Input shape\n            3D tensor with shape: `(samples, steps, features)`.\n        # Output shape\n            2D tensor with shape: `(samples, features)`.\n        :param kwargs:\n        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n        The dimensions are inferred based on the output shape of the RNN.\n        Note: The layer has been tested with Keras 2.0.6\n        Example:\n            model.add(LSTM(64, return_sequences=True))\n            model.add(Attention())\n            # next add a Dense layer (for classification/regression) or whatever...\n        \"\"\"\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        # do not pass the mask to the next layers\n        return None\n\n    def call(self, x, mask=None):\n        eij = K.squeeze(K.dot(x, K.expand_dims(self.W)), axis=-1)\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx())\n\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]\n    \nclass AttentionWeightedAverage(Layer):\n    \"\"\"\n    Computes a weighted average of the different channels across timesteps.\n    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n    \"\"\"\n\n    def __init__(self, return_attention=False, **kwargs):\n        self.init = initializers.get('uniform')\n        self.supports_masking = True\n        self.return_attention = return_attention\n        super(AttentionWeightedAverage, self).__init__(** kwargs)\n\n    def build(self, input_shape):\n        self.input_spec = [InputSpec(ndim=3)]\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[2], 1),\n                                 name='{}_W'.format(self.name),\n                                 initializer=self.init)\n        self.trainable_weights = [self.W]\n        super(AttentionWeightedAverage, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        # computes a probability distribution over the timesteps\n        # uses 'max trick' for numerical stability\n        # reshape is done to avoid issue with Tensorflow\n        # and 1-dimensional weights\n        logits = K.dot(x, self.W)\n        x_shape = K.shape(x)\n        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n\n        # masked timesteps have zero weight\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            ai = ai * mask\n        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n        weighted_input = x * K.expand_dims(att_weights)\n        result = K.sum(weighted_input, axis=1)\n        if self.return_attention:\n            return [result, att_weights]\n        return result\n\n    def get_output_shape_for(self, input_shape):\n        return self.compute_output_shape(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        output_len = input_shape[2]\n        if self.return_attention:\n            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n        return (input_shape[0], output_len)\n\n    def compute_mask(self, input, input_mask=None):\n        if isinstance(input_mask, list):\n            return [None] * len(input_mask)\n        else:\n            return None\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# In[21]:\n\n\nfrom keras.callbacks import *\nimport math\nclass CyclicLR(Callback):\n    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n    The method cycles the learning rate between two boundaries with\n    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n    The amplitude of the cycle can be scaled on a per-iteration or \n    per-cycle basis.\n    This class has three built-in policies, as put forth in the paper.\n    \"triangular\":\n        A basic triangular cycle w/ no amplitude scaling.\n    \"triangular2\":\n        A basic triangular cycle that scales initial amplitude by half each cycle.\n    \"exp_range\":\n        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n        cycle iteration.\n    For more detail, please see paper.\n    \n    # Example\n        ```python\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., mode='triangular')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```\n    \n    Class also supports custom scaling functions:\n        ```python\n            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., scale_fn=clr_fn,\n                                scale_mode='cycle')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```    \n    # Arguments\n        base_lr: initial learning rate which is the\n            lower boundary in the cycle.\n        max_lr: upper boundary in the cycle. Functionally,\n            it defines the cycle amplitude (max_lr - base_lr).\n            The lr at any cycle is the sum of base_lr\n            and some scaling of the amplitude; therefore \n            max_lr may not actually be reached depending on\n            scaling function.\n        step_size: number of training iterations per\n            half cycle. Authors suggest setting step_size\n            2-8 x training iterations in epoch.\n        mode: one of {triangular, triangular2, exp_range}.\n            Default 'triangular'.\n            Values correspond to policies detailed above.\n            If scale_fn is not None, this argument is ignored.\n        gamma: constant in 'exp_range' scaling function:\n            gamma**(cycle iterations)\n        scale_fn: Custom scaling policy defined by a single\n            argument lambda function, where \n            0 <= scale_fn(x) <= 1 for all x >= 0.\n            mode paramater is ignored \n        scale_mode: {'cycle', 'iterations'}.\n            Defines whether scale_fn is evaluated on \n            cycle number or cycle iterations (training\n            iterations since start of cycle). Default is 'cycle'.\n    \"\"\"\n\n    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n                 gamma=1., scale_fn=None, scale_mode='cycle'):\n        super(CyclicLR, self).__init__()\n\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.step_size = step_size\n        self.mode = mode\n        self.gamma = gamma\n        if scale_fn == None:\n            if self.mode == 'triangular':\n                self.scale_fn = lambda x: 1.\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = lambda x: 1/(2.**(x-1))\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = lambda x: gamma**(x)\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n        self.clr_iterations = 0.\n        self.trn_iterations = 0.\n        self.history = {}\n\n        self._reset()\n\n    def _reset(self, new_base_lr=None, new_max_lr=None,\n               new_step_size=None):\n        \"\"\"Resets cycle iterations.\n        Optional boundary/step size adjustment.\n        \"\"\"\n        if new_base_lr != None:\n            self.base_lr = new_base_lr\n        if new_max_lr != None:\n            self.max_lr = new_max_lr\n        if new_step_size != None:\n            self.step_size = new_step_size\n        self.clr_iterations = 0.\n        \n    def clr(self):\n        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n        if self.scale_mode == 'cycle':\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n        else:\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n        \n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.learning_rate, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.learning_rate, self.clr())        \n            \n    def on_batch_end(self, epoch, logs=None):\n        \n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n\n        self.history.setdefault('learning_rate', []).append(K.get_value(self.model.optimizer.learning_rate))\n        self.history.setdefault('iterations', []).append(self.trn_iterations)\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        \n        K.set_value(self.model.optimizer.learning_rate, self.clr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from typing import Optional, Callable, List, Dict, MutableSequence\nfrom collections import OrderedDict\nfrom keras.optimizers import Optimizer\n\nCPU_CORES = 30\n\nclass StochasticEnsembling(Callback):\n\n    def __init__(self, seqs_dict: Dict[str, Sequence], cycle_len: int, iter_per_epoch: int,\n                 alpha1: float = 0.0, alpha2: float = 0.0, lr_schedule_mode: Optional[str] = None,\n                 swa_cycle_start_inx: int = -1, encoder_layers_out: List[str] = [],\n                 save_swa_model: bool = False, save_se_weights: bool = False,\n                 folder: str = \"\", model_name: str = \"\", verbose: int = 1):\n        \"\"\"\n        General implementation of Stochastic Weight Averaging (SWA) and Snapshot Ensembling (SE) with variety\n        of available LR schedules modes.\n        SWA   https://arxiv.org/abs/1803.05407\n        FGE   https://arxiv.org/abs/1802.10026\n        SE    https://arxiv.org/abs/1704.00109\n        CLR   https://arxiv.org/abs/1506.01186\n        CALR  https://arxiv.org/abs/1811.00641 (adapted)\n        :param seqs_dict: Dict of sequences and their names for predicting\n        :param cycle_len: length of the cycle\n        :param iter_per_epoch: iterations per epoch\n        :param alpha1: alpha1 param, usually max lr\n        :param alpha2: alpha2 param, usually min lr\n        :param lr_schedule_mode: one of of the [None, \"swa\", \"fge\", \"se\", \"clr\", \"clr2\", \"calr\"]\n        :param swa_cycle_start_inx: after which cycle start making snapshots and update SWA weights.\n                                If equals 0, makes it instantly before training\n        :param encoder_layers_out: list of encoder layers names to use as additional models outputs\n        :param save_se_weights: should weights of each snapshot be saved\n        :param save_swa_model: should SWA final model be saved\n        :param folder: saving directory\n        :param model_name: model name\n        :param verbose: verbose\n        \"\"\"\n        super(StochasticEnsembling, self).__init__()\n        self.alpha1 = alpha1\n        self.alpha2 = alpha2\n        self.cycle_len = cycle_len\n        self.iter_per_epoch = iter_per_epoch\n        self.iter_per_cycle = self.cycle_len * self.iter_per_epoch\n        self.cycle_num = 0\n        self.clr_iterations = 0\n        self.current_epoch = 0\n        self.lr_schedule_mode = lr_schedule_mode\n        self.swa_cycle_start_inx = swa_cycle_start_inx\n        self.encoder_layers_out = encoder_layers_out\n        self.model_wfo = None\n\n        self.model_counts = 0\n        self.seqs_dict = seqs_dict\n        self.probs_dict = {k: [] for k in self.seqs_dict.keys()}\n        self.features_dict = {k: [] for k in self.seqs_dict.keys()}\n\n        self.save_se_weights = save_se_weights\n        self.save_swa_model = save_swa_model\n        self.folder = folder\n        self.model_name = model_name\n        self.verbose = verbose\n\n        self.swa_weights = []\n\n    def on_train_begin(self, logs=None):\n        if self.save_se_weights:\n            self.model.save_weights(self.folder + self.model_name + \"_se_weights_init.h5\")\n\n        if self.swa_cycle_start_inx == 0:\n            self.snapshot_predict()\n            self.swa_weights = self.model.get_weights()\n            self.model_counts += 1\n\n    def on_train_end(self, logs=None):\n        if self.swa_cycle_start_inx >= 0:\n            self.model.set_weights(self.swa_weights)\n        if self.save_swa_model:\n            self.model.save(self.folder + self.model_name + \"_swa_model.h5\")\n\n        if len(self.encoder_layers_out) > 0:\n            self.model_wfo = Model(inputs=self.model.inputs,\n                                   outputs=self.model.outputs + [self.model.get_layer(name=layer_name).output\n                                                                 for layer_name in self.encoder_layers_out])\n\n            for seq_name, seq in self.seqs_dict.items():\n                pred_outs = self.model_wfo.predict_generator(seq, steps=len(seq),\n                                                             use_multiprocessing=False, workers=CPU_CORES,\n                                                             max_queue_size=2 * CPU_CORES + 2,\n                                                             verbose=0)\n                self.probs_dict[seq_name].append(pred_outs[0])\n                self.features_dict[seq_name] = pred_outs[1:]\n        else:\n            self.snapshot_predict()\n        self.model_counts += 1\n\n        for seq_name, probs in self.probs_dict.items():\n            self.probs_dict[seq_name] = np.concatenate(probs, axis=-1)\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.current_epoch = epoch\n        if self.lr_schedule_mode == \"se\":\n            lr = self._se_schedule()\n            K.set_value(self.model.optimizer.learning_rate, lr)\n            if self.verbose > 0:\n                print(\"Modifying learning rate to {}\".format(str(lr)))\n\n    def on_epoch_end(self, epoch, logs=None):\n        if (self.lr_schedule_mode == \"fge\") and (self._t_cycle() != 0.5):\n            return\n        elif self._t_cycle() != 1.0:\n            return\n\n        self.cycle_num += 1\n        if self.verbose > 0:\n            print(\"Latest lr: {:.5f}\".format(K.get_value(self.model.optimizer.learning_rate)))\n            if self.lr_schedule_mode == \"fge\":\n                print(\"Reached half of {} cycle\".format(str(self.cycle_num)))\n            else:\n                print(\"Reached {} cycle\".format(str(self.cycle_num)))\n\n        if self.save_se_weights:\n            self.model.save_weights(self.folder + self.model_name + \"_se_weights_\" + str(self.model_counts) + \".h5\")\n\n        if (self.swa_cycle_start_inx >= 0) and (self.cycle_num >= self.swa_cycle_start_inx):\n            self.snapshot_predict()\n            self.swa_weights_update()\n            self.model_counts += 1\n\n    def on_batch_begin(self, batch, logs=None):\n        self.clr_iterations += 1\n\n        if (self.lr_schedule_mode is None) or (self.lr_schedule_mode == \"se\"):\n            return\n\n        if self.lr_schedule_mode == \"clr\":\n            lr = self._clr_schedule()\n        elif self.lr_schedule_mode == \"clr2\":\n            lr = self._clr2_schedule()\n        elif self.lr_schedule_mode == \"calr\":\n            lr = self._calr_schedule()\n        elif self.lr_schedule_mode == \"fge\":\n            lr = self._fge_schedule()\n        elif self.lr_schedule_mode == \"swa\":\n            lr = self._swa_schedule()\n        else:\n            raise ValueError(\"Unknown schedule mode: \" + str(self.lr_schedule_mode))\n        K.set_value(self.model.optimizer.lr, lr)\n\n    def _swa_schedule(self):\n        return (1 - self._t_cycle()) * self.alpha1 + self._t_cycle() * self.alpha2\n\n    def _fge_schedule(self):\n        if self._t_cycle() <= 0.5:\n            return ((1.0 - 2.0 * self._t_cycle()) * self.alpha1) + (2.0 * self._t_cycle() * self.alpha2)\n        else:\n            return ((2.0 - 2.0 * self._t_cycle()) * self.alpha2) + ((2.0 * self._t_cycle() - 1.0) * self.alpha1)\n\n    def _se_schedule(self):\n        lr = math.pi * (self.current_epoch % self.cycle_len) / self.cycle_len\n        lr = self.alpha1 / 2 * (math.cos(lr) + 1)\n        return lr\n\n    def _clr_schedule(self):\n        if self._t_cycle() <= 0.5:\n            return ((1.0 - 2.0 * self._t_cycle()) * self.alpha2) + (2.0 * self._t_cycle() * self.alpha1)\n        else:\n            return ((2.0 - 2.0 * self._t_cycle()) * self.alpha1) + ((2.0 * self._t_cycle() - 1.0) * self.alpha2)\n\n    def _clr2_schedule(self):\n        decay = 1 / (2 ** self.cycle_num)\n        if self._t_cycle() <= 0.5:\n            return ((1.0 - 2.0 * self._t_cycle()) * self.alpha2) + (2.0 * self._t_cycle() * self.alpha1) * decay\n        else:\n            return ((2.0 - 2.0 * self._t_cycle()) * self.alpha1) * decay + ((2.0 * self._t_cycle() - 1.0) * self.alpha2)\n\n    def _calr_schedule(self):\n        decay = ((self.cycle_len + 1) / 10) ** (self.current_epoch % self.cycle_len)  # TODO find something better\n        if self._t_epoch() <= 0.5:\n            return ((1.0 - 2.0 * self._t_epoch()) * self.alpha2) + (2.0 * self._t_epoch() * self.alpha1) * decay\n        else:\n            return ((2.0 - 2.0 * self._t_epoch()) * self.alpha1) * decay + ((2.0 * self._t_epoch() - 1.0) * self.alpha2)\n\n    def _t_cycle(self):\n        return (((self.clr_iterations - 1) % self.iter_per_cycle) + 1) / self.iter_per_cycle\n\n    def _t_epoch(self):\n        return (((self.clr_iterations - 1) % self.iter_per_epoch) + 1) / self.iter_per_epoch\n\n    def snapshot_predict(self):\n        for seq_name, seq in self.seqs_dict.items():\n            self.probs_dict[seq_name].append(self.model.predict_generator(seq, steps=len(seq),\n                                                                          use_multiprocessing=False, workers=CPU_CORES,\n                                                                          max_queue_size=2 * CPU_CORES + 2,\n                                                                          verbose=0))\n\n    def swa_weights_update(self):\n        weights = self.model.get_weights()\n\n        if len(self.swa_weights) == 0:\n            self.swa_weights = weights\n            return\n\n        for i in range(0, len(self.swa_weights)):\n            self.swa_weights[i] = (self.swa_weights[i] * self.model_counts + weights[i]) / (self.model_counts + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_ids_list = train_ids.tolist()\ninstids = train2.loc[(train2.metric_point==1) & (train2.installation_id.isin(train_ids_list)),'installation_id'].values\ntrain_ids_list = train2.loc[(train2.metric_point==1)&(train2.installation_id.isin(train_ids_list))].installation_id.unique().tolist()\nprint(len(train_ids_list))\n\ninstids_unique = list(train_ids_list)\ninstids = train2.loc[(train2.metric_point==1),'installation_id'].values\n\ninstids2_unique = train2.installation_id.unique()\n\nseqlens = []\nfor qid in tqdm_notebook(train_ids_list):\n    seqlens.append(train2.loc[(train2.metric_point==1)&(train2.installation_id==qid),'metric_point'].sum())\nprint(len(seqlens), q_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# In[28]:\n\n\ntrain_ids_list = train2.loc[(train2.metric_point==1)&(train2.installation_id.isin(train_ids_list))].installation_id.unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# In[29]:\n\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nNFOLDS = 7\nfolds1 = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\nfolds2 = KFold(n_splits=NFOLDS, shuffle=True, random_state=239)\nfolds3 = KFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n\ninstids = train2.loc[(train2.metric_point==1),'installation_id'].values\n\nseq_len = 64\n#num_cols = ['correct_attempts', 'incorrect_attempts', 'time_df', 'event_duration', 'code_4070_count',  'code_2010_count']\nnum_cols = list(range(3+4+len(code_counts_cols)+len(miss_cols)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"num_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\ndef get_cat_emb(cat_name, cat_size, min_emb_size=2, max_emb_size=50, reg=regularizers.l2(3e-4)): # regularizers.l2(1e-4)\n    emb_size = 7\n    emb_inp = Input((seq_len,), name=cat_name+'_in')\n    #emb = Dropout(0.005)(emb_inp)\n    emb = Embedding(cat_size, emb_size, name=cat_name+'_emb', mask_zero=True)(emb_inp) #, embeddings_regularizer=reg\n    return emb_inp, emb\n    \ndef buildMixedModel(cat_cols, cat_sizes_map):\n    cat_inps = []\n    cat_embs = []\n    for cat_col in cat_cols:\n        emb_inp, emb = get_cat_emb(cat_col, cat_sizes_map[cat_col])\n        cat_inps.append(emb_inp)\n        cat_embs.append(emb)\n    \n    num_inp = Input((seq_len,len(num_cols)), name='num_inp')\n    text_inp = Input((q_train.shape[1],), name='text_inp')\n    x2 = text_inp\n    x2 = Dropout(0.5)(x2)\n    x2 = Dense(96, activation='relu')(x2)\n\n    cat_embs.append(num_inp)\n    x = Concatenate(axis=-1)(cat_embs)\n    \n    x = Bidirectional(GRU(64, return_sequences=True, recurrent_dropout=0.001, activation='relu'))(x)\n    #x = Flatten()(x)\n    #x = Dropout(0.5)(x)\n    #x = LSTM(64, return_sequences=True, recurrent_dropout=0.001, activation='relu')(x)\n    #x = Dropout(0.5)(x)\n    #x = LSTM(80, return_sequences=True, recurrent_dropout=0.001, activation='relu')(x)\n    #x = Flatten()(x)\n    x = AttentionWeightedAverage()(x)\n    x = Concatenate()([x,x2])\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation=\"relu\")(x)\n    x = Dropout(0.25)(x)\n    \n    output1 = Dense(1, activation=\"linear\", name=\"output1\")(x)\n\n    return Model(inputs=cat_inps + [num_inp,text_inp], outputs=[output1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel = buildMixedModel(cat_cols, cat_sizes_map)\nmodel.summary()\n\ntest_pred = np.zeros(matrix_titles_test.shape[0])\nraw_preds = np.zeros((matrix_titles_test.shape[0], 15))\n\nhistories = []\nmetrics_last_assessment_val = []\nmetrics_val = []\n\ndef get_inps(idxs):\n    inps = []\n    inps.append(matrix_titles[idxs, -seq_len:])\n    inps.append(matrix_numericals[idxs, -seq_len:, :][:,:,num_cols])\n    inps.append(q_train[idxs].todense())\n    return inps\n\ntest_seq = FeatureSequence([matrix_titles_test[:, -seq_len:],\n                            matrix_numericals_test[:, -seq_len:, :][:,:,num_cols], \n                            q_test.todense()], None, 128, shuffle=False)\n\n\ndef random_chs(a):\n    size = 1\n    replace = True\n    fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n    df = pd.DataFrame({'Group_Id':a})\n    q = df.groupby('Group_Id', as_index=False).apply(fn).reset_index()\n    q.columns = ['v0','v1','v2']\n    return q.v1.values.astype(int)\n\nifold = 0\ngcoefs = [0,0,0]\n\nfor folds in [folds1]:\n    for fold, (train_idxs, val_idxs) in enumerate(folds.split(instids)):\n        gc.collect()\n        K.clear_session()\n        gc.collect()    \n\n        smpls = np.array([np.arange(len(val_idxs))])\n\n        trn_seq = FeatureSequence(get_inps(train_idxs),\n                                  [train2.loc[(train2.metric_point == 1),'label'].values[train_idxs]], \n                                  128, shuffle=True)\n        val_seq = FeatureSequence(get_inps(val_idxs),\n                                  [train2.loc[(train2.metric_point == 1),'label'].values[val_idxs]], \n                                  len(val_idxs), shuffle=False)\n\n        Y = train2.loc[(train2.metric_point == 1),'label'].values[val_idxs]\n        Y2 = train2.loc[(train2.metric_point == 1),'all_attempts'].values[val_idxs]\n        kappa_metric = KappaEvaluationSeq(val_seq, Y, Y2, smpls, 'val')\n\n        model_file = 'model_' + str(fold) + '.pth'\n        early_stop = EarlyStopping(monitor='val_kappa', min_delta=0, patience=16, verbose=1, mode='max')\n        model_checkpoint = ModelCheckpoint(model_file, monitor='val_kappa', verbose=1, mode='max',\n                                           save_best_only=True, save_weights_only=False, period=1)\n        clr = CyclicLR(base_lr=0.00001, max_lr=0.001, step_size=4*math.ceil(len(trn_seq)), mode='triangular2')\n        model = buildMixedModel(cat_cols, cat_sizes_map)\n        opt=keras.optimizers.Adam(lr=0.001, clipnorm=1.0, clipvalue=1.0)\n        #opt = AdamW(weight_decay=0.015, beta_1=0.9, beta_2=0.999, batch_size=8,\n        #            samples_per_epoch=len(train_idxs), epochs=8,\n        #            clipnorm=0, clipvalue=0)\n\n        model.compile(optimizer=opt, loss=['mean_squared_error'])\n\n        seqs_dict = {\"val\": val_seq, \"test\": test_seq}\n\n        se = StochasticEnsembling(seqs_dict=seqs_dict, cycle_len=12, iter_per_epoch=len(trn_seq),\n                                  alpha1=0.005, alpha2=0.0005, lr_schedule_mode=\"clr\",\n                                  swa_cycle_start_inx=0, model_name=\"model\", verbose=1)\n\n        history = model.fit_generator(\n                generator=trn_seq, steps_per_epoch=len(trn_seq),\n                initial_epoch=0, epochs=24, shuffle=False, verbose=2,\n                callbacks=[kappa_metric, se],  #clr, model_checkpoint, early_stop\n                use_multiprocessing=False, workers=1, max_queue_size=2*4)\n\n        histories.append(history)\n\n        #model = load_model(model_file, custom_objects = {\n        #    'AttentionWeightedAverage': AttentionWeightedAverage\n        #})\n\n        qpred = (se.probs_dict[\"val\"][:,-2] + se.probs_dict[\"val\"][:,-3])/2.0\n\n        optR = OptimizedRounder(smpls) \n        optR.fit(qpred, Y)\n        coefficients = optR.coefficients()\n        for ic in range(3):\n            gcoefs[ic] += coefficients[ic] / NFOLDS\n        y_pred = optR.predict(qpred, coefficients)     \n\n        tts = []\n        for i in range(smpls.shape[0]):\n            tts.append(qwk3(np.array(Y)[smpls[i].astype(int)], np.array(y_pred.astype(int))[smpls[i].astype(int)]))\n        kapa = np.median(tts)     \n\n        pred1 = (se.probs_dict[\"test\"][:,-2] + se.probs_dict[\"test\"][:,-3])/2.0\n        \n        test_pred += pred1.ravel() / NFOLDS\n        \n        raw_preds[:,ifold] = pred1.ravel()\n        ifold += 1\n        \n        pred1 = optR.predict(pred1, coefficients).ravel().astype(int)\n\n        del model, kappa_metric, clr, model_checkpoint, early_stop, se\n        del trn_seq, val_seq, qpred, Y, y_pred\n        print(fold, kapa)\n        gc.collect()\n\n        metrics_val.append(kapa)\n\nnp.save('v24full', raw_preds)\n\nprint(np.mean(metrics_val))\n\noptR = OptimizedRounder([1])\ny_pred = optR.predict(test_pred, gcoefs).ravel()\n\nsubmission = pd.DataFrame({'installation_id':test_ids})\nsubmission['accuracy_group'] = y_pred.astype('int')\nsubmission.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 0.603 default oob kappa","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# !python train_model.py","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}