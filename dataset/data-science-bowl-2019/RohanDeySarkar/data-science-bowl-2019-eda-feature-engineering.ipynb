{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport matplotlib.pylab as plt\nimport calendar\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.model_selection import GroupKFold\nfrom typing import Any\nfrom numba import jit\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\nfrom itertools import product\nimport copy\nimport time\n\nimport random\nseed = 1234\nrandom.seed(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntrain_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')\nspecs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\nsample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'''Kaggle provided the following note: Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment.'''\n\nDeleting 'installation_id' which are not \"Assessment\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select all Assessment from installation_id\nkeep_id = train[train[\"type\"] == \"Assessment\"][\"installation_id\"].drop_duplicates()\n\ntrain = pd.merge(train, keep_id, on=\"installation_id\", how=\"inner\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_id.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 10))\n\nax1 = fig.add_subplot(211)\nax1 = sns.countplot(y=\"type\", data=train, order= train.type.value_counts().index)\nplt.title(\"number of events by type\")\n\nax2 = fig.add_subplot(212)\nax2 = sns.countplot(y=\"world\", data=train, order = train.world.value_counts().index)\nplt.title(\"number of events by world\")\nplt.tight_layout(pad=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\n\ntitle_count = train.title.value_counts().sort_values(ascending=True)\ntitle_count.plot.barh()\nplt.title(\"Event counts by title\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['timestamp'] = pd.to_datetime(train['timestamp'])\ntrain['date'] = train['timestamp'].dt.date\ntrain['month'] = train['timestamp'].dt.month\ntrain['hour'] = train['timestamp'].dt.hour\ntrain['dayofweek'] = train['timestamp'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\ndate = train.groupby('date')['date'].count()\ndate.plot()\nplt.xticks(rotation=90)\nplt.title(\"Event counts by date\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nday_of_week = train.groupby('dayofweek')['dayofweek'].count()\n# convert num -> category\nday_of_week.index = list(calendar.day_abbr)\nday_of_week.plot.bar()\nplt.title(\"Event counts by day of week\")\nplt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nhour = train.groupby('hour')['hour'].count()\nhour.plot.bar()\nplt.title(\"Event counts by hour of day\")\nplt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.installation_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no installation_ids without assessment in the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check if there is any overlap with regards to installation_id's in the train and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"set(list(train.installation_id.unique())).intersection(list(test.installation_id.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no installation_id's that appear in both train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['timestamp'] = pd.to_datetime(test['timestamp'])\n\nprint(f'The range of date in train is: {train.date.min()} to {train.date.max()}')\nprint(f'The range of date in test is: {test.timestamp.dt.date.min()} to {test.timestamp.dt.date.max()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train_labels dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train_labels.title, train_labels.accuracy_group)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"accuracy_group =>\n* 0: the assessment was never solved\n* 1: the assessment was solved after 3 or more attempts\n* 2: the assessment was solved on the second attempt\n* 3: the assessment was solved on the first attempt"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(y=\"title\", data=train_labels, order = train_labels.title.value_counts().index)\nplt.title(\"Counts of titles\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_labels.groupby(['accuracy_group', 'title'])['accuracy_group']\ndf.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"se = train_labels.groupby(['title', 'accuracy_group'])['accuracy_group'].count().unstack('title')\nse.plot.bar(stacked=True, rot=0, figsize=(12,10))\nplt.title(\"Counts of accuracy group\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"installation_id's who did assessments but without results in the train_labels (we have already taken out the ones who never took one)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[~train.installation_id.isin(train_labels.installation_id.unique())].installation_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cannot train on installation_id's anyway, so taking them out of the train set. This reduces train set from 8.3 million rows to 7.7 million."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.installation_id.isin(train_labels.installation_id.unique())]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'No. of rows in train_labels: {train_labels.shape[0]}')\nprint(f'Number of unique game_sessions in train_labels: {train_labels.game_session.nunique()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['date', 'month', 'hour', 'dayofweek'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_title(train, test, train_labels):\n    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n    \n    all_title_event_code = list(set(train['title_event_code'].unique()).union(test['title_event_code'].unique()))\n    \n    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n    \n    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n    \n    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n    \n    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n    \n    activities_map = dict(zip(list_of_user_activities, np,arange(len(list_of_user_activities))))\n    \n    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n    \n    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    \n    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n    \n    # replace title with its number from the dictionary\n    train['title'] = train['title'].map(activities_map)\n    test['title'] = test['title'].map(activities_map)\n    \n    train_labels['title'] = train_labels['title'].map(activities_map)\n    \n    train['world'] = train['world'].map(activities_world)\n    test['world'] = test['world'].map(activities_world)\n    \n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    \n    return train, test, train_labels, all_title_event_code, list_of_user_activities, list_of_event_code, list_of_event_id, activities_labels, assess_titles\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test, train_labels, all_title_event_code, list_of_user_activities, list_of_event_code, list_of_event_id, activities_labels, assess_titles = encode_title(train, test, train_labels)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}