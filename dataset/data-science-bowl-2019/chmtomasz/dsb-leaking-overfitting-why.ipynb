{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nimport gc\nfrom operator import add\nfrom tensorflow import feature_column\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import Model, Sequential\nfrom tensorflow.keras.layers import Dense, DenseFeatures, Input, BatchNormalization\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.metrics import Metric\nimport tensorflow.keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"def prepare_train_data(train_dataframe: pd.DataFrame, labels: pd.DataFrame) -> pd.DataFrame:\n    game_session_id_list = labels['game_session'].unique()\n\n    train_dataframe.drop(train_dataframe[~train_dataframe['game_session'].isin(game_session_id_list)].index, inplace=True)\n    train_grouped = train_dataframe.groupby('game_session').last()\n    train_event_codes = train_dataframe.groupby(['game_session', 'event_code'], as_index=False).size().unstack(fill_value=0)\n    train_dataframe = pd.merge(train_grouped, train_event_codes,\n                               left_on='game_session', right_on='game_session', how='left')\n    train_dataframe = pd.merge(train_dataframe, labels,\n                               left_on='game_session', right_on='game_session', how='left')\n    install_ids = train_dataframe.copy()\n    train_dataframe.drop(['game_session', 'event_id', 'timestamp', 'event_data', 'installation_id_x',\n                          'installation_id_y', 'title_y', 'num_correct', 'num_incorrect', 'accuracy'], inplace=True, axis=1)\n    return train_dataframe, install_ids","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"def prepare_features(dataframe: pd.DataFrame) -> []:\n    feature_columns = []\n\n    for header in dataframe.select_dtypes('number'):\n        feature_columns.append(feature_column.numeric_column(header))\n\n    title_x_one_hot = feature_column.categorical_column_with_vocabulary_list(\n        'title_x', dataframe.title_x.unique())\n    title_x_one_hot = feature_column.indicator_column(title_x_one_hot)\n    feature_columns.append(title_x_one_hot)\n\n    type_one_hot = feature_column.categorical_column_with_vocabulary_list(\n        'type', dataframe.type.unique())\n    type_one_hot = feature_column.indicator_column(type_one_hot)\n    feature_columns.append(type_one_hot)\n\n    world_one_hot = feature_column.categorical_column_with_vocabulary_list(\n        'world', dataframe.world.unique())\n    world_one_hot = feature_column.indicator_column(world_one_hot)\n    feature_columns.append(world_one_hot)\n\n    return feature_columns","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"def prepare_test_data(train_dataframe: pd.DataFrame) -> pd.DataFrame:\n\n    train_grouped = train_dataframe.groupby('game_session').last()\n    train_event_codes = train_dataframe.groupby(['game_session', 'event_code'], as_index=False).size().unstack(fill_value=0)\n    train_dataframe = pd.merge(train_grouped, train_event_codes,\n                               left_on='game_session', right_on='game_session', how='left')\n\n    train_dataframe.drop(['event_id', 'timestamp', 'event_data'\n                          ], inplace=True, axis=1)\n    return train_dataframe\n\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"def create_sequential_model(feature_layer) -> Sequential:\n    return tf.keras.Sequential([\n        feature_layer,\n        BatchNormalization(),\n        Dense(64, activation='relu'),\n        BatchNormalization(),\n        Dense(64, activation='relu'),\n        BatchNormalization(),\n        Dense(4, activation='softmax')\n    ])","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"def create_dataset(dataframe: pd.DataFrame, is_train: bool, batch_size=32, shuffle=True):\n\n    labels = dataframe.pop('accuracy_group')\n    labels = tf.keras.utils.to_categorical(labels, num_classes=4)\n    dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=len(dataframe))\n\n    return dataset.batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"def create_test_dataset(dataframe: pd.DataFrame, is_train: bool, batch_size=32, shuffle=True):\n\n    dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe)))\n\n\n    return dataset.batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def quadratic_kappa(actuals, preds, N=4):\n    \"\"\"This function calculates the Quadratic Kappa Metric used for Evaluation in the PetFinder competition\n    at Kaggle. It returns the Quadratic Weighted Kappa metric score between the actual and the predicted values \n    of adoption rating.\"\"\"\n    w = np.zeros((N,N))\n    O = confusion_matrix(actuals, preds)\n    for i in range(len(w)): \n        for j in range(len(w)):\n            w[i][j] = float(((i-j)**2)/(N-1)**2)\n    \n    act_hist=np.zeros([N])\n    for item in actuals: \n        act_hist[item]+=1\n    \n    pred_hist=np.zeros([N])\n    for item in preds: \n        pred_hist[item]+=1\n                         \n    E = np.outer(act_hist, pred_hist);\n    E = E/E.sum();\n    O = O/O.sum();\n    \n    num=0\n    den=0\n    for i in range(len(w)):\n        for j in range(len(w)):\n            num+=w[i][j]*O[i][j]\n            den+=w[i][j]*E[i][j]\n    return (1 - (num/den))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class CohenKappa(Metric):\n    \"\"\"\n    This metric is copied from TensorFlow Addons\n    \"\"\"\n    def __init__(self,\n                 num_classes,\n                 name='cohen_kappa',\n                 weightage=None,\n                 dtype=tf.float32):\n        super(CohenKappa, self).__init__(name=name, dtype=dtype)\n\n        if weightage not in (None, 'linear', 'quadratic'):\n            raise ValueError(\"Unknown kappa weighting type.\")\n        else:\n            self.weightage = weightage\n\n        self.num_classes = num_classes\n        self.conf_mtx = self.add_weight(\n            'conf_mtx',\n            shape=(self.num_classes, self.num_classes),\n            initializer=tf.keras.initializers.zeros,\n            dtype=tf.int32)\n    \n    def update_state(self, y_true, y_pred, sample_weight=None):\n        if len(y_true.shape) == 2:\n            y_true = tf.argmax(y_true, axis=1)\n        if len(y_pred.shape) == 2:\n            y_pred = tf.argmax(y_pred, axis=1)\n        \n        y_true = tf.cast(y_true, dtype=tf.int32)\n        y_pred = tf.cast(y_pred, dtype=tf.int32)\n        \n        if y_true.shape.as_list() != y_pred.shape.as_list():\n            raise ValueError(\n                \"Number of samples in y_true and y_pred are different\")\n\n        # compute the new values of the confusion matrix\n        new_conf_mtx = tf.math.confusion_matrix(\n            labels=y_true,\n            predictions=y_pred,\n            num_classes=self.num_classes,\n            weights=sample_weight)\n\n        # update the values in the original confusion matrix\n        return self.conf_mtx.assign_add(new_conf_mtx)\n    \n    def result(self):\n        nb_ratings = tf.shape(self.conf_mtx)[0]\n        weight_mtx = tf.ones([nb_ratings, nb_ratings], dtype=tf.int32)\n\n        # 2. Create a weight matrix\n        if self.weightage is None:\n            diagonal = tf.zeros([nb_ratings], dtype=tf.int32)\n            weight_mtx = tf.linalg.set_diag(weight_mtx, diagonal=diagonal)\n            weight_mtx = tf.cast(weight_mtx, dtype=tf.float32)\n\n        else:\n            weight_mtx += tf.range(nb_ratings, dtype=tf.int32)\n            weight_mtx = tf.cast(weight_mtx, dtype=tf.float32)\n\n            if self.weightage == 'linear':\n                weight_mtx = tf.abs(weight_mtx - tf.transpose(weight_mtx))\n            else:\n                weight_mtx = tf.pow((weight_mtx - tf.transpose(weight_mtx)), 2)\n            weight_mtx = tf.cast(weight_mtx, dtype=tf.float32)\n\n        # 3. Get counts\n        actual_ratings_hist = tf.reduce_sum(self.conf_mtx, axis=1)\n        pred_ratings_hist = tf.reduce_sum(self.conf_mtx, axis=0)\n\n        # 4. Get the outer product\n        out_prod = pred_ratings_hist[..., None] * \\\n                    actual_ratings_hist[None, ...]\n\n        # 5. Normalize the confusion matrix and outer product\n        conf_mtx = self.conf_mtx / tf.reduce_sum(self.conf_mtx)\n        out_prod = out_prod / tf.reduce_sum(out_prod)\n\n        conf_mtx = tf.cast(conf_mtx, dtype=tf.float32)\n        out_prod = tf.cast(out_prod, dtype=tf.float32)\n\n        # 6. Calculate Kappa score\n        numerator = tf.reduce_sum(conf_mtx * weight_mtx)\n        denominator = tf.reduce_sum(out_prod * weight_mtx)\n        kp = 1 - (numerator / denominator)\n        return kp\n    \n    def get_config(self):\n        \"\"\"Returns the serializable config of the metric.\"\"\"\n\n        config = {\n            \"num_classes\": self.num_classes,\n            \"weightage\": self.weightage,\n        }\n        base_config = super(CohenKappa, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def reset_states(self):\n        \"\"\"Resets all of the metric state variables.\"\"\"\n\n        for v in self.variables:\n            K.set_value(\n                v, np.zeros((self.num_classes, self.num_classes), np.int32))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"INPUT_PATH = '../../kaggle/input/data-science-bowl-2019/'","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"train = pd.read_csv(INPUT_PATH + 'train.csv')\nlabels = pd.read_csv(INPUT_PATH + 'train_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"train, install_ids = prepare_train_data(train, labels)\ntrain.columns = train.columns.astype(str)\ntrain_copy = train.copy()\ntrain_copy.drop('accuracy_group', inplace=True, axis=1)\nfeature_columns = prepare_features(train_copy)\ndel train_copy\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"feature_layer = DenseFeatures(feature_columns)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"gkf = GroupKFold(n_splits=5)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"models = []\nkappas = []","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"for train_idx, val_idx in gkf.split(train, groups=install_ids.installation_id_x):\n    train_dataset = create_dataset(train.iloc[train_idx].copy(), True, 1024, shuffle=True)\n    val_dataset = create_dataset(train.iloc[val_idx].copy(), True, 1024, shuffle=False)\n    model = create_sequential_model(feature_layer)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[CohenKappa(num_classes=4, weightage='quadratic')])\n    model.fit(train_dataset,\n          validation_data=val_dataset,\n          epochs=150, verbose=2)\n    models.append(model)\n    y_valid = install_ids.iloc[val_idx].copy()\n    y_pred = model.predict(val_dataset)\n    y_valid['preds'] = y_pred.argmax(axis=1)\n    y_valid = y_valid.groupby('installation_id_x').last()\n    kappa = quadratic_kappa(y_valid.accuracy_group, y_valid.preds)\n    kappas.append(kappa)\n        ","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"train.iloc[train_idx].to_csv('group_by_inst_id.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.iloc[val_idx].to_csv('val_group_by_inst_id.csv')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"print(kappas)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"quadratic_kappa(y_valid.accuracy_group, y_valid.preds)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"print(f'predicted accuracy_group distribution:\\n\\n{pd.Series(y_valid.preds).value_counts(normalize=True)} \\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"test = pd.read_csv(INPUT_PATH + 'test.csv')\ntest = test[test['type']=='Assessment']","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"test = prepare_test_data(test)\ntest.columns = test.columns.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.type.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['game_session'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"test.rename(columns={'title' : 'title_x'}, inplace=True)\n\ntest_dataset = create_test_dataset(test, True, 1024, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = None\nfor model in models:\n    if preds is None:\n        preds = model.predict(test_dataset)\n    else:\n        preds += model.predict(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'predicted accuracy_group distribution:\\n\\n{pd.Series(preds.argmax(axis=1)).value_counts(normalize=True)} \\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"results = test.copy()\nresults['target'] = preds.argmax(axis=1)\ntest = test.groupby('installation_id').last()\nsubmission = pd.read_csv(INPUT_PATH+'sample_submission.csv')\nresults = results.target.reset_index(drop=True)\nsubmission['accuracy_group'] = results\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"print(f'predicted accuracy_group distribution:\\n\\n{pd.Series(submission.accuracy_group).value_counts(normalize=True)} \\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"is_executing":false},"trusted":true},"cell_type":"code","source":"preds.argmax(axis=1)[:10]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":1}