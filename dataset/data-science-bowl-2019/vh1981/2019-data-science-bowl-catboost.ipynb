{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 2019 Data Science Bowl\n\n이 노트북은 다음 노트북 내용을 분석 및 정리한 것입니다 :\n    https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model\n   \n\n#### 요약 :\n1. 이벤트 목록을 각각의 session마다 accuracy_group을 구하는 함수를 만든다. ------ A(x)\n2. train 데이터를 위 함수(A)를 사용해서 변환한다. ------ a = A(train)\n3. a의 데이터에서 accuracy_group을 y, 나머지 항목을 X로 해서 model을 훈련한다.\n4. test데이터로 b = A(test)를 구해서 위 모델로 predict한다.\n\n\n#### Submission :\ntest_set의 각각의 installation_id에 존재하는 마지막 assessment마다 accuracy_group을 예측해야 한다.\n파일은 installation_id, accuracy_group의 두 column으로 이루어져 있어야 한다."},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport datetime\nfrom catboost import CatBoostClassifier\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\n\nimport subprocess\nfrom ast import literal_eval","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"submission 평가는 QWK(Quadratic Weighted Kappa)로 이루어진다.\n\n**Cohen's Kappa**\n\n    두 연구자간 동일한 결과를 내놓는지를 수치화하는 방법이다.\n    더 자세히 설명하면, 두 연구자 간 일치한 결과 중에서 우연히 일치할 가능성를 제외하고, 실제로 평가가 일치한 결과가 어느 정도인지 보여주는 지표이다.\n    nominal(category간 거리가 같은)한 범주에 사용된다.\n\n**Cohen's weighted Kappa**\n\n    Cohen's Kappa와는 다르게, ordinal(순서가 있는, 예를 들어 관절염의 5 단계(1:없음, 2:경증 ... 5:심각) 등을 표현 시) 변수를 대상으로 할 경우에는 Cohen's weighted Kappa를 사용한다.<br>\n    순서(또는 단계)가 있는 변수를 판단하므로 범주(카테고리)간 거리는 서로 다르고, 두 연구자간 결과가 다를 경우에도 다름의 크기에 가중치 차이가 있을 것이다.<br>\n    이런 식으로 각각 다른 비중(weight)를 두어 불일치 정도를 평가하는 것이다.\n\n    각 범주간 차이에 비중을 부여하는 방법으로는 값의 차이를 그대로 사용하는 linear 방법과, 제곱해서 사용하는 quadratic 방법이 있다.\n    (1과 3의 차이 : linear = 2, quadratic = 4)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ndef qwk(act,pred,n=4,hist_range=(0,3)):\n    '''\n    cohen's kappa는 두 데이터의 값 중 우연에 의해 일치하는 부분을 제외하고 \n    실제 평가에 의해 값이 일치하는 정도를 보여주는 지표이다.\n    범주간 차이의 비중을 제곱하므로 q(quadratic)가 붙은 것.\n    '''\n    O = confusion_matrix(act,pred)\n    O = np.divide(O,np.sum(O))\n    \n    W = np.zeros((n,n))\n    for i in range(n):\n        for j in range(n):\n            W[i][j] = ((i-j)**2)/((n-1)**2)\n            \n    act_hist = np.histogram(act,bins=n,range=hist_range)[0]\n    prd_hist = np.histogram(pred,bins=n,range=hist_range)[0]\n    \n    E = np.outer(act_hist,prd_hist)\n    E = np.divide(E,np.sum(E))\n    \n    num = np.sum(np.multiply(W,O))\n    den = np.sum(np.multiply(W,E))\n        \n    return 1-np.divide(num,den)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"필요한 csv 파일들을 읽어들인다."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\ntrain_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\ntest = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\nsubmission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode title\n# 'title' 항목을 activity라고 명명하고 0부터 시작하는 숫자 값으로 변환할 수 있는 dictionary를 만든다.\nlist_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\nactivities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n\n# train/test 데이터의 title을 숫자값으로 치환한다.\ntrain['title'] = train['title'].map(activities_map)\ntest['title'] = test['title'].map(activities_map)\ntrain_labels['title'] = train_labels['title'].map(activities_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"list_of_user_activities:\")\nprint(list_of_user_activities)\nprint(\"activities_map:\")\nprint(activities_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"activity(원래 title)마다 해당하는 win_code를 만든다.<br>\n'Bird Measurer (Assessment)'만 4110이고 나머지는 4100임"},{"metadata":{"trusted":true},"cell_type":"code","source":"win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\nwin_code[activities_map['Bird Measurer (Assessment)']] = 4110\nprint(win_code)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"no intersection between installation ids of train and test"},{"metadata":{},"cell_type":"markdown","source":"train데이터에서 accuracy_group 추출\n\nmake_session_data()는 각각의 installation_id에 해당하는 event를 분석해서 accuracy_group을 구하는 동작을 한다.<br>\ninstallation_id로 groupby()를 행한 sub dataframe을 인자로 넘긴다."},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_session_data(user_sample, test_set=False):\n    '''\n    user_sample : train.groupby('installation_id', sort=False)\n        installation_id로 묶인 뭉텅이    \n    \n    test_set 인 경우 마지막 assessment만 남긴다.\n    '''\n    last_activity = 0\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = [] # 모든 assessment 세션의 요약정보(accuracy_group을 포함한 여러 column이 있음)\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    counter = 0\n    durations = []\n    \n    for i, session in user_sample.groupby('game_session', sort=False): #game_session 기준으로 또 group \n        \"\"\"\n        session 기준으로 묶으면 한 session 에서 일어난 이벤트들이 나열된 dataframe을 얻을 수 있다.\n        결국 각각의 session마다 처리를 하는 code block임.\n        \"\"\"\n        # type : Clip/Activity/Assessment/Game\n        # title : 여기서는 숫자로 변경되어 있음\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        if test_set == True:\n            second_condition = True\n        else:\n            if len(session)>1:\n                second_condition = True\n            else:\n                second_condition= False\n        \n        # session_type이 Assessment인 경우만 필요하다.\n        # session이 Assessment(평가) 타입일 경우 여기 성공/실패 등의 정보가 있다.\n        # 'Assessment' 세션의 이벤트들을 분석해서 데이터를 생성한다.\n        if (session_type == 'Assessment') & (second_condition):\n            '''\n            'Assessment' 세션에서 일어난 이벤트들의 목록\n            '''\n            all_attempts = session.query(f'event_code == {win_code[session_title]}') #event_code가 win_code(하나빼고 4100)인 것을 모은다.\n            true_attempts = all_attempts['event_data'].str.contains('true').sum() # 성공횟수(event_data에 'true'문자열이 잇는가?)\n            false_attempts = all_attempts['event_data'].str.contains('false').sum() # 실패횟수(event_data에 'false'문자열이 잇는가?)\n            #print(\"\", all_attempts.shape[0], \"true:\", true_attempts, \"false:\", false_attempts)\n            features = user_activities_count.copy()\n            features['session_title'] = session_title\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)            \n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds) #마지막의 timestamp(2, 세번째 column)에서 처음을 빼서 session의 실행시간을 얻는다.\n            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n            # 정확도를 계산한다.\n            #print(\"true_attempts:\", true_attempts, \"false_attempts:\", false_attempts)\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            '''\n            accuracy_group:\n            session 기준으로 accuracy_group를 계산할 수 있다.\n                3: the assessment was solved on the first attempt\n                2: the assessment was solved on the second attempt\n                1: the assessment was solved after 3 or more attempts\n                0: the assessment was never solved\n                \n            코드를 보면 평균내서 하는 것 같은데, 아마 1개의 true와 0개 이상의 false 혹은\n            0개의 true와 여러개의 false가 있는 식인듯.\n            '''\n            if accuracy == 0: # 해결 못했다.\n                features['accuracy_group'] = 0\n            elif accuracy == 1: #실패가 없음\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5: # 한번 실패하고 성공\n                features['accuracy_group'] = 2\n            else: # 3번 이상 실패함.\n                features['accuracy_group'] = 1\n                \n            # update() : modify in place using non-NA values from another dataframe\n            # 같은 column이 있으면 넘어온 dataframe값으로 대체한다.\n            features.update(accuracy_groups)\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n            features['accumulated_actions'] = accumulated_actions\n            accumulated_accuracy_group += features['accuracy_group']\n            accuracy_groups[features['accuracy_group']] += 1\n            if test_set == True:\n                all_assessments.append(features)\n            else:\n                if true_attempts+false_attempts > 0:\n                    all_assessments.append(features)\n                \n            counter += 1\n\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type\n    \n    \"\"\"\n    FIXME: 여기는 check가 필요함.    \n    if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    \n    test 데이터의 경우 기기(installation_id)의 마지막 assessment의 accuracy_group을 예측해야 한다.\n    그러므로 마지막 assessment항목만 남기는 코드가 있는건데... \n    그러면 그 앞의 데이터들은 아무런 필요가 없는 것인지...?\n    다른 평가가 이루어진(Assessment이고 event_data에 true/false 있음) 세션도 많아서...\n    \n    일단 다른 커널들을 보면 아래처럼 처리(제거함)하는 것 같다.\n    점수가 높은 노트북들에서도 모두 날리므로 날리는것이 맞는듯.\n    날리는 노트북들:    \n        https://www.kaggle.com/artgor/quick-and-dirty-regression\n        https://www.kaggle.com/hengzheng/bayesian-optimization-seed-blending\n        \n    \"\"\"\n    if test_set:\n        return all_assessments[-1]\n    \n    # in the train_set, all assessments goes to the dataset\n    return all_assessments","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"make_session_data()함수로 train 데이터를 session에 대한 요약 정보(accuracy_group 항목 생성해서 포함) 데이터로 변환한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_assessment_group_data(df, is_test_set=False):\n    compiled_data = list() \n    total_cnt = df.installation_id.unique().shape[0]\n    for i, (ins_id, user_sample) in tqdm(enumerate(df.groupby('installation_id', sort=False)), total=total_cnt):        \n        sdata = make_session_data(user_sample, test_set=is_test_set)\n        \n        if type(sdata) is list:\n            compiled_data += sdata\n        else:\n            compiled_data.append(sdata)\n\n    newTrain = pd.DataFrame(compiled_data)    \n    return newTrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = make_assessment_group_data(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below are the features I have generated. Note that all of them are **prior** to each event. For example, the first row shows **before** this assessment, the player have watched 3 clips, did 3 activities, played 4 games and solved 0 assessments, so on so forth.\n\n**new_train columns:**\n\n- 'Clip'\n- 'Activity'\n- 'Assessment'\n- 'Game'\n- 'session_title'\n- 'accumulated_correct_attempts'\n- 'accumulated_uncorrect_attempts'\n- 'duration_mean'\n- 'accumulated_accuracy'\n- 'accuracy_group'\n- 0\n- 1\n- 2\n- 3\n- 'accumulated_accuracy_group'\n- 'accumulated_actions'"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\nprint(all_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- X: 'accuracy_group'를 제외한 모든것.\n- y: 'accuracy_group'"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\ncat_features = ['session_title'] #train의 'title' 항목\nX, y = new_train[all_features], new_train['accuracy_group']\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_classifier():\n    clf = CatBoostClassifier(\n        loss_function='MultiClass',    \n        task_type=\"CPU\",\n        learning_rate=0.01,\n        iterations=2000,\n        od_type=\"Iter\",\n        early_stopping_rounds=500,\n        random_seed=2019)\n    \n    return clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CV\nfrom sklearn.model_selection import KFold\noof = np.zeros(len(X))\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\n\ntraining_start_time = time()\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n    start_time = time()\n    print(f'Training on fold {fold+1}')\n    clf = make_classifier()\n    clf.fit(X.loc[trn_idx, all_features], y.loc[trn_idx], eval_set=(X.loc[test_idx, all_features], y.loc[test_idx]),\n                          use_best_model=True, verbose=500, cat_features=cat_features)\n    \n#     preds += clf.predict(X_test).reshape(len(X_test))/NFOLDS\n    oof[test_idx] = clf.predict(X.loc[test_idx, all_features]).reshape(len(test_idx))\n    \n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n    \nprint('-' * 30)\nprint('OOF QWK:', qwk(y, oof))\nprint('-' * 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that Cross validation is only for the feature engineering part and you don't actually need it if you want to submit the results. You can safely comment it out. \n\nCV로 하는 것은 사용하지 않고, 전체 데이터로 한번만 train한 모델을 사용한다고 한다.\n기존 이미지 판별 문제와는 다른 방법인 것 같은데... \n이상하네...?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model on all data once\nclf = make_classifier()\nclf.fit(X, y, verbose=500, cat_features=cat_features)\n\ndel X, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위 train 데이터를 생성하던 것과 동일한 방법으로 test데이터를 사용해서 생성한다."},{"metadata":{},"cell_type":"markdown","source":"## Submission\n\ntest 데이터로 input을 생성한다.<br>\ntrain과 동일한 방법을 사용하되, make_session_data()호출시 test_set=True 로 한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = make_assessment_group_data(test, is_test_set=True)\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_columns = X_test.columns.tolist()\nprint(len(test_columns), \"columns:\\n\", test_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test[all_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions on test set once\npreds = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pred를 accuracy_group으로 정해서 csv파일을 생성한다.<br>\nsubmission은 sample_submission.csv파일을 읽어들인 것인데, sample_submission의 installation_id 순서를 그대로 사용한다.<br>\n위에서 groupby(sort=False)여서 문제 없는듯."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['accuracy_group'] = np.round(preds).astype('int') #이 부분에 OptimizedRounder가 필요함.\nsubmission.to_csv('submission.csv', index=None)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['accuracy_group'].plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['accuracy_group'].plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(oof).plot(kind='hist')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}