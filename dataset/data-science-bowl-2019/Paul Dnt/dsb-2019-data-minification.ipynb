{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dataset Minification"},{"metadata":{},"cell_type":"markdown","source":"### The goal of this notebook is to offer a first preprocessing step so that you can manipulate this huuuuuuge dataset easily. The final dataframe is saved as a .pkl, which allows you to load it quickly!"},{"metadata":{},"cell_type":"markdown","source":"#### Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nfrom time import time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nN_ROWS = int(1e6)                     # number of rows = 11M\ntrain = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train.csv\", nrows=N_ROWS)\ntest = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/test.csv\", nrows=N_ROWS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_mem_usg = train.memory_usage().sum() / 1024 ** 2 \nprint(\"Memory usage of the train is : {:.1f} MB for now\".format(start_mem_usg))\nstart_mem_usg = test.memory_usage().sum() / 1024 ** 2 \nprint(\"Memory usage of the test is : {:.1f} MB for now\".format(start_mem_usg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring event_data column"},{"metadata":{},"cell_type":"markdown","source":"### `event_data` seems interesting. I think it is the main source of information.\n### The data is given in json format, so we'll parse it to be able to create columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_to_minify = [train, test]\nfor df in df_to_minify:\n    df['event_data'] = df['event_data'].apply(lambda x: json.loads(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event_data = train['event_data'].tolist()\nunique_keys = list()\nfor my_json in event_data:\n    unique_keys += my_json.keys()\n    \nunique_keys = list(set(unique_keys))\nprint('event_data contains {} new columns'.format(len(unique_keys)))\nprint('Some new columns are:', unique_keys[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ky in tqdm(unique_keys):\n    def give_me_keys(x):\n        try:\n            return x[ky]\n        except KeyError:\n            return np.nan\n    train[ky] = train['event_data'].apply(give_me_keys)\n    test[ky] = test['event_data'].apply(give_me_keys)\n    \n    \nprint('Train shape is:', train.shape)\nprint('Test shape is:', test.shape)\nstart_mem_usg = train.memory_usage().sum() / 1024 ** 2 \nprint(\"Memory usage of the train dataframe is : {:.1f} MB for now\".format(start_mem_usg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove columns which variance is very low or with too many missing values"},{"metadata":{},"cell_type":"markdown","source":"Please modify these two thresholds to fit your needs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use this filters if you want to drop columns with low variance or lot of nans\nVAR_FILTER = True\nNAN_FILTER = True\n\nVAR_THRESH = .1\nNAN_THRESH = .99\n\ncols_to_drop = list()\n\nif VAR_FILTER:\n    var_dict = train.std() <= VAR_THRESH\n    cols_to_drop += [k for k, v in var_dict.items() if v]\n\nif NAN_FILTER:\n    nan_dict = train.isna().mean() >= NAN_THRESH\n    cols_to_drop += [k for k, v in nan_dict.items() if v]\n\ncols_to_drop = list(set(cols_to_drop))\ntrain.drop(cols_to_drop, axis=1, inplace=True)\ntest.drop(cols_to_drop, axis=1, inplace=True)\n\nprint('We dropped {} columns'.format(len(cols_to_drop)))\nprint('Train shape is: ', train.shape)\nprint('Test shape is: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now that we've the information contained in event_data, we can drop it\ntry:\n    train.drop('event_data', axis=1, inplace=True)\n    test.drop('event_data', axis=1, inplace=True)\nexcept:\n    pass\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we will Label Encode some variable to stock them as small int (instead of objects)"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_to_label_encode = list()\nfor col in train.columns:\n    try:\n        if len(train[col].unique()) < 10:\n            col_to_label_encode.append(col)\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correspondance_dict = dict()\n\nfor col in col_to_label_encode:\n    try:\n        le = LabelEncoder()\n        train[col] = le.fit_transform(train[col])\n        test[col] = le.transform(test[col])\n\n        keys = le.classes_\n        values = le.transform(le.classes_)\n        dictionary = dict(zip(keys, values))\n        correspondance_dict[col] = dictionary\n\n    except:    # the variable is not label encodable\n        pass\n\ncorrespondance_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(props, log=False):\n    start_mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\", round(start_mem_usg, 2), \" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings and timestamps\n            \n            # Print current column type\n            if log: print(\"******************************\")\n            if log: print(\"Column: \",col)\n            if log: print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)            \n\n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            if log: print(\"dtype after: \",props[col].dtype)\n            if log: print(\"******************************\")\n    \n    mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage is now: \", round(mem_usg, 2), \" MB\")\n    print(\"This is \",round(100 * mem_usg / start_mem_usg, 2),\"% of the initial size\")\n    return props","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train, log=False)\ntest = reduce_mem_usage(test, log=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_pickle('train.pkl')\ntest.to_pickle('test.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}