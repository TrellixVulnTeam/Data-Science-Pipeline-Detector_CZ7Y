{"cells":[{"metadata":{},"cell_type":"markdown","source":"I have developed this code by studying a few other Kernels based on CatBoost and XGBoost models. This approach is based on preparing the training set where for each assessment session, the corresponding row contains details of user activities prior to that assessment, for example activities completed, time spent etc. The model is very simplistic and it is running fine on my laptop. But when I submit it, **I get error \"submission.csv\" not found** which is a bit disappointing. I have done a number of changes to reduce memory usage. The code runs fine on my laptop and also the commit process finishes in decent time. But that has not been of help. Moreover, the original Kernel from which I created this one was succesfully submitted from my machine but with my changes it fails. So, I am not able to get a public score. \n\nMy plan was to progressively add new features and improve the model, but without a public score I can't assess where I stand. I am quite new to Kaggle, this is my second submission. But have checked some of the basic things like format of submission.csv, also the code does not contain any specific reference to the size of the test file (which I believe could create a problem because the private test file is much larger). Can you please help me figure what I am doing wrong here? Thanks a lot! :)"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\nfrom scipy.stats import mode\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\n\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom matplotlib import pyplot\nimport shap\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font size=4 color='violet'> Reading and understanding our data</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nkeep_cols = ['game_session', 'installation_id','event_code', 'title', 'game_time', 'type']\ntrain=pd.read_csv('../input/data-science-bowl-2019/train.csv',usecols=keep_cols)\ntrain_labels=pd.read_csv('../input/data-science-bowl-2019/train_labels.csv',\n                         usecols=['installation_id','game_session','accuracy_group'])\ntest=pd.read_csv('../input/data-science-bowl-2019/test.csv',usecols=keep_cols)\nsubmission=pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_req=(set(train.installation_id.unique()) - set(train_labels.installation_id.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new=~train['installation_id'].isin(not_req)\ntrain.where(train_new,inplace=True)\ntrain.dropna(inplace=True)\ntrain['event_code']=train.event_code.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_id =('8be4aedf',  '5d21020f',  'bfddcc77',  '75857694', 'b4738558', '2db60743', 'a5ac9b55', '3d214090', '50c78eb8', '48166507', '3713a3ae')\n# test_new=test[test['installation_id'].isin(test_id)]\n# test=test_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activityTypes= train[['title','type']].drop_duplicates()\n#list_of_activities = list(set(train['title'].value_counts().index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getFeatures(userData, isTest):\n    counter = 0\n    #test_set=False\n    session_List=[]\n\n    for i, (ins_id, user_sample) in enumerate(userData.groupby('installation_id', sort=False)):\n        session_type_counter = dict({'Clip':0, 'Activity': 0, 'Game': 0, 'Assessment': 0})\n        time_spent = 0\n        clipTime=0\n        activityTime=0\n        gameTime=0\n        assessmentTime=0\n\n        activityLog = dict()\n        for i, row in activityTypes.iterrows():\n            activityLog[row['title']]=0\n            activityLog[row[\"title\"]+\"Time\"]=0\n           # if (\"Assessment\" in row['title']):\n            #    activityLog[row[\"title\"]+\"Solved\"]=0\n\n\n        for i, session in user_sample.groupby('game_session', sort=False):\n            session_type = session['type'].iloc[0]\n            session_title = session['title'].iloc[0]\n            session_id = session['game_session'].iloc[0]\n            processAssessment=False\n            if (isTest) & (len(session)==1) & (session_type == 'Assessment'):\n                processAssessment = True\n                #print('checkpoint1 ', session_type, '  ', len(session), ' ', session_id)\n            elif (~isTest) & (len(session) > 1):\n                processAssessment = True\n            else:\n                processAssessment= False\n            \n\n            #if (session_type == 'Assessment'):\n                #all_attempts = session.query(f'event_code == {activity_correct_event_code[session_title]}')\n                #true_attempts = all_attempts['event_data'].str.contains('true').sum()\n                #false_attempts = all_attempts['event_data'].str.contains('false').sum()\n\n            if (session_type == 'Assessment') & (processAssessment):\n                Dict1 =dict({'installation_id': session['installation_id'].iloc[0]})\n                Dict1['game_session']=session['game_session'].iloc[0]\n\n                # Dict1['type']=session['type'].iloc[0]\n                Dict1['title']=session['title'].iloc[0]\n                Dict1['priorClips']=session_type_counter['Clip']\n                Dict1['priorActivity']=session_type_counter['Activity']\n                Dict1['priorGames']=session_type_counter['Game']\n                Dict1['priorAssessments']=session_type_counter['Assessment']\n                #Dict1['session_time']= session['game_time'].max()\n                #Dict1['total_prior_time']=time_spent\n    #            Dict1['avgclipTime']=clipTime/session_type_counter['Clip']\n    #            Dict1['avgactivityTime']=activityTime/session_type_counter['Activity']\n    #            Dict1['avggameTime']= gameTime/session_type_counter['Game']\n    #            Dict1['avgassessmentTime']=assessmentTime/session_type_counter['Assessment']\n                Dict1.update(activityLog)\n                if (isTest):\n                    session_List.append(Dict1)\n                else:\n                    #if all_attempts > 0:\n                    session_List.append(Dict1)\n                              \n            if len(session)>1:\n                    session_type_counter[session_type]+=1\n                    time_spent+=session['game_time'].max()\n                    activityLog[session_title]+=1\n                    activityLog[session_title+\"Time\"]+=session['game_time'].max()\n\n                    if(session_type==\"Clip\"):\n                        clipTime+=session['game_time'].max()\n                    elif(session_type==\"Game\"):\n                        gameTime+=session['game_time'].max()\n                    elif(session_type==\"Activity\"):\n                        activityTime+=session['game_time'].max()\n                    elif(session_type==\"Assessment\"):\n                        assessmentTime+=session['game_time'].max()\n                       # if true_attempts > 0:\n                        #    activityLog[session_title+\"Solved\"]+=1\n    processedDf=pd.DataFrame(session_List)\n    return processedDf\n# featuresDf.head(20)\n# print(len(session_List))\n# featuresDf=pd.DataFrame(session_List)\n# featuresDf.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train = getFeatures(train, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test = getFeatures(test, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train=pd.merge(train_labels, final_train, on=['game_session', 'installation_id'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_columns=['game_session', 'installation_id']\ndrop_columns=['num_correct', 'num_incorrect', 'accuracy']\ncat_columns=['title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train.drop(id_columns, axis=1, inplace=True)\n#final_train.drop(drop_columns, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test.drop(id_columns, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final=pd.concat([final_train,final_test])\nencoding=['title']\nfor col in encoding:\n    lb=LabelEncoder()\n    lb.fit(final[col])\n    final[col]=lb.transform(final[col])\n    \nfinal_train=final[:len(final_train)]\nfinal_test=final[len(final_train):]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=final_train.drop('accuracy_group',axis=1)\ny_train=final_train['accuracy_group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(X_train,y_train,final_test,n_splits=3):\n    scores=[]\n    pars = {\n        'colsample_bytree': 0.8,                 \n        'learning_rate': 0.08,\n        'max_depth': 10,\n        'subsample': 1,\n        'objective':'multi:softprob',\n        'num_class':4,\n        'eval_metric':'mlogloss',\n        'min_child_weight':3,\n        'gamma':0.25,\n        'n_estimators':500\n    }\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    y_pre=np.zeros((len(final_test),4),dtype=float)\n    final_test=xgb.DMatrix(final_test.drop('accuracy_group',axis=1))\n\n\n    for train_index, val_index in kf.split(X_train, y_train):\n        train_X = X_train.iloc[train_index]\n        val_X = X_train.iloc[val_index]\n        train_y = y_train[train_index]\n        val_y = y_train[val_index]\n        xgb_train = xgb.DMatrix(train_X, train_y)\n        xgb_eval = xgb.DMatrix(val_X, val_y)\n\n        xgb_model = xgb.train(pars,\n                      xgb_train,\n                      num_boost_round=1000,\n                      evals=[(xgb_train, 'train'), (xgb_eval, 'val')],\n                      verbose_eval=False,\n                      early_stopping_rounds=20\n                     )\n\n        val_X=xgb.DMatrix(val_X)\n        pred_val=[np.argmax(x) for x in xgb_model.predict(val_X)]\n        score=cohen_kappa_score(pred_val,val_y,weights='quadratic')\n        scores.append(score)\n        print('choen_kappa_score :',score)\n\n        pred=xgb_model.predict(final_test)\n        y_pre+=pred\n\n    pred = np.asarray([np.argmax(line) for line in y_pre])\n    print('Mean score:',np.mean(scores))\n    \n    return xgb_model,pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model,pred=model(X_train,y_train,final_test,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.DataFrame({'installation_id':submission.installation_id,'accuracy_group':pred})\nsub.to_csv('submission.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size=5 color='violet'>Feature Selection</font>\n\nWe will use    module of xgboost to plot the feature importances and see what features  our model think are important for making prediction.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nxgb.plot_importance(xgb_model, max_num_features=50, height=0.5, ax=ax,importance_type='gain')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are three methods to measure feature_importances in xgboost.They are :\n- `weight` : The total number of times this feature was used to split the data across all trees.\n- `Cover` :The number of times a feature is used to split the data across all trees weighted by the number of training data points that go through those splits.\n- `Gain` : The average loss reduction gained when using this feature for splitting in trees.\n\nWe used `Gain` in the above example and the model says when it used `event_code_2030` the loss on average was reduced by 8%."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nxgb.plot_importance(xgb_model, max_num_features=50, height=0.5, ax=ax,importance_type='weight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we considered weight,the model says that is used `game_time mean` 1035 times to split the data across the trees.\n\nhmmm...so how what can we conclude from above figures?\nWe will find out...."},{"metadata":{"trusted":true},"cell_type":"code","source":"# shap_values = shap.TreeExplainer(xgb_model).shap_values(X_train)\n# shap.summary_plot(shap_values, X_train, plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shap.summary_plot(shap_values[3], X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shap.summary_plot(shap_values[0], X_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# X_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=.1)\n# model = XGBClassifier()\n# model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# threshold = np.sort(model.feature_importances_)[40:]\n# for thresh in threshold:\n#     # select features using threshold\n#     selection = SelectFromModel(model, threshold=thresh, prefit=True)\n#     select_X_train = selection.transform(X_train)\n#     # train model\n#     selection_model = XGBClassifier()\n#     selection_model.fit(select_X_train, y_train)\n#     # eval model\n#     select_X_test = selection.transform(X_test)\n#     y_pred = selection_model.predict(select_X_test)\n#     predictions = [round(value) for value in y_pred]\n#     accuracy = cohen_kappa_score(y_test, predictions)\n#     print(\"Thresh=%.3f, n=%d, cohen kappa score: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n    \n    \n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}