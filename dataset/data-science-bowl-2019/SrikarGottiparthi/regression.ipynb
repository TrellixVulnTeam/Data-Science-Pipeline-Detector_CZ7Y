{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import GradientBoostingRegressor \nfrom sklearn.ensemble import GradientBoostingClassifier\nimport seaborn as sns\nfrom scipy.optimize import minimize\nfrom scipy import optimize\nimport datetime as dt\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport gc\n\nfor root, dirs, files in os.walk('/kaggle/input'):\n    for file in files:\n        if file.endswith(\".csv\"):\n            print(os.path.join(root, file))\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# train.event_data.str.findall(r\"duration': '(.+?)'\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_colwidth = 200\n\nsample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\ntrain_labels =  pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\ntest = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\ntrain = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n\nspecs = reduce_mem_usage(specs)\ntrain_labels = reduce_mem_usage(train_labels)\ntest = reduce_mem_usage(test)\ntrain = reduce_mem_usage(train)\n\n\n# media_sequence = pd.read_csv(\"../input/dsb2019-external-data/media_sequence.csv\")\ntest['timestamp'] = pd.to_datetime(test['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'].values)#using .'values' will remove tzinfo\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntrain['timestamp'] = pd.to_datetime(train['timestamp'].values)\n\n# specs to DF\na = []\n\n\nfor i in range(len(specs.args)):\n    lst = json.loads(specs['args'][i])\n    args = pd.DataFrame(lst)\n    args['event_id'] = specs.event_id[i]\n    args['desc'] = specs['info'][i]\n    a.append(args)\n    \nspecs = pd.concat(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# filtered_train = train[train.type == \"Assessment\"]\n# print(test.installation_id.nunique()) # 1000 unique installation id in test\n# print(sum(test.groupby(['installation_id'])['game_session'].nunique() ==1)) # 17 installation ids for wich there is no previous assessment data\n# print(train.installation_id.nunique()) #17000 in train #4242 with assessments in train\n# print(sum(train.groupby(['installation_id'])['game_session'].nunique() ==1) ) #1463 have only one assessment\n# print(sum(train.installation_id.isin(test.installation_id.unique()))) # No test installation id is in train\n\n# filtered_train[['title','world']].drop_duplicates() # world > title hierarchy\n\n### assesments are not repeated after clearing it in the same session\n# train_labels[(train_labels.accuracy == 0.5) & (train_labels.accuracy_group != 2)]\n\n# print(sum(train.event_data.str.contains('\"correct\":true')))\n# print(sum(train.event_data.str.contains('\"correct\":false')))\n# train[train.event_data.str.contains('\"correct\":false')].groupby('type').count()\n# # train.groupby(['installation_id','game_session'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"media_sequence = pd.read_csv(\"../input/dsb2019-external-data/media_sequence.csv\")\nmedia_sequence = reduce_mem_usage(media_sequence)\nmedia_sequence = media_sequence.merge(train[['world','title']].drop_duplicates(),on = 'title',how = 'left')\nmedia_sequence['sequence'] = pd.Series(media_sequence.index)\nmedia_sequence['world_sequence'] = media_sequence.groupby(['world'])['sequence'].rank().astype('int')\nmedia_sequence['world_type_sequence'] = media_sequence.groupby(['world','type'])['sequence'].rank().astype('int')\nmedia_sequence = media_sequence.drop(['type','world','sequence'],axis = 1).rename(columns = {'duration':'clip_length'})\nmedia_sequence['clip_length'] = media_sequence['clip_length']*1000\n\n\ntrain = train.merge(media_sequence,on  = ['title'],how = 'left')\ntest = test.merge(media_sequence,on  = ['title'],how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# event_id_code_mapped = pd.concat([train[['event_id','event_code']].drop_duplicates(),test[['event_id','event_code']].drop_duplicates()])\\\n#                          .drop_duplicates()\n                                 \n# args_by_event = specs[['name','type','event_id']].merge(event_id_code_mapped, on = ['event_id'],how = 'left')\\\n#                                                  .drop(['event_id'],axis = 1).drop_duplicates()\n# event_codes = args_by_event.event_code.unique()\n\n# a = []\n\n# for event in event_codes:\n#     sub = train[train.event_code == event]\n#     print(str(event) + '---' +str(sub.shape))\n#     args = args_by_event[args_by_event.event_code == event]['name']\n#     args = list(set(args) - set(['event_count','event_code','game_time','description']))\n#     sub1  = sub['event_data'].apply(json.loads).apply(pd.Series)\n#     a.append(reduce_mem_usage(sub1))\n#     print(args)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collect previous events data for each installation_id and game_session\n# Create features at an installation_id + game_session\n# for any given installation_id + game_session, collect all the interaction info before current game_session\n# Consider all train instead of only Assesmyent types for pre data\n# rank game_sessions per installation_id in chronological order\n# accuracies in each game/ assessment\n# installation_id, game_session, title, world, avg_time_prev, avg_events_prev, avg_clip_time_prev, avg_game_time_prev, avg_accuracy_prev, \ndef fetch_column_from_json( df,extract_key, text_col_name = 'event_data',dtype = 'int' ):\n    find_string = str('\"')+ extract_key + str('\":')\n    \n    exists = df[text_col_name].str.find(find_string) != -1\n    df['temp'] = ''\n    df['temp'][exists]=  df[text_col_name].apply(lambda x : x[x.find(find_string) + len(find_string) : len(x)-1])\n    \n    if (dtype == 'str') : \n        df[extract_key] = ''\n    else :\n        df[extract_key] = np.NaN\n        \n    df[extract_key][exists]= df['temp'][exists].apply(lambda x : x[:x.find(',')]).astype(dtype)\n\n    df = df.drop(['temp'],axis = 1)\n    return(df)\n\n\ndef extract_features (df):\n    \n    # all events with accuracy data in \"event data json\"\n    # df = fetch_column_from_json(df, 'correct', dtype = 'str')\n# df = fetch_column_from_json(df, 'total_duration')\n# # df = fetch_column_from_json(df, 'duration')\n# df = fetch_column_from_json(df, 'round')\n# df = fetch_column_from_json(df, 'media_type',dtype = 'str')\n# df = fetch_column_from_json(df, 'correct',dtype = 'str')\n# df = fetch_column_from_json(df, 'misses',dtype = 'int')\n# df = fetch_column_from_json(df, 'dwell_time',dtype = 'int')\n\n    df['accurate'] = 0\n    df.loc[df.event_data.str.contains('\"correct\":true'),'accurate'] = 1\n    df['inaccurate'] = 0\n    df.loc[df.event_data.str.contains('\"correct\":false'),'inaccurate'] = 1 \n\n    # only final accuracy for calculating train labels\n    df['num_correct'] = 0\n    df.loc[((df.event_data.str.contains('\"correct\":true')) & (df.event_code .isin([4100,4110]))),'num_correct'] = 1\n    df['num_incorrect'] = 0\n    df.loc[((df.event_data.str.contains('\"correct\":false'))& (df.event_code .isin([4100,4110]))),'num_incorrect'] = 1 \n\n\n    df['prev_game_time'] = df.groupby(['installation_id','game_session'])['game_time'].shift(1)\n    df['game_time'] = df['game_time'] - df['prev_game_time']\n    df = df.drop(['prev_game_time'],axis = 1)\n\n    df = df.join(pd.get_dummies(df.event_code))\n    reduce_mem_usage(df)\n\n\n    grouped_by_session = df.groupby(['installation_id','game_session'])\n\n    session_info = df[['installation_id','game_session','type','world','title','clip_length','world_sequence']].drop_duplicates()\n    #add worldtypesequence\n\n\n    ####################################################\n    ###extract time features\n    session_start = grouped_by_session['timestamp'].min().reset_index().rename(columns = {'timestamp': 'start_time'})\n    session_end = grouped_by_session['timestamp'].max().reset_index().rename(columns = {'timestamp': 'end_time'})\n    session_times = session_start.merge(session_end,on = ['installation_id','game_session'])\\\n                            .sort_values(['installation_id','start_time'])\n    session_info = session_info.merge(session_times,on = ['installation_id','game_session'],how= 'left')\n    session_info['prev_start_time'] = session_info.groupby(['installation_id'])['start_time'].shift(1)\n    session_info['prev_end_time'] = session_info.groupby(['installation_id'])['end_time'].shift(1)\n    session_info['gap_time'] = (session_info['start_time'] - session_info['prev_end_time']).astype('timedelta64[ms]')\n    session_info['game_time'] = (session_info['end_time']- session_info['start_time']).astype('timedelta64[ms]')\n    session_info = session_info.drop(['prev_start_time','prev_end_time'], axis = 1)\n    session_info['day_of_week'] = session_info['start_time'].dt.day_name()\n    session_info['hour_of_day'] = session_info['start_time'].dt.hour\n    # order sessions by chronological order\n    session_info['rank'] = session_info.groupby(['installation_id'])['start_time'].apply(lambda x: x.rank())\n\n\n    ##########################################\n    event_code_cols = pd.get_dummies(df.event_code).columns\n    for event_code in event_code_cols:\n        df[event_code] = df[event_code]*df['game_time']\n        event_code_info = grouped_by_session[event_code].sum().reset_index()\n        session_info = session_info.merge(event_code_info, on = ['installation_id','game_session'],how = 'left')\n\n    del df\n    gc.collect()\n    # count of events, total session time and accuracy by each session \n    \n    event_counts =  grouped_by_session['event_count'].max().reset_index()\n    session_info = session_info.merge(event_counts,on = ['installation_id','game_session'] , how = 'left')\n    \n    accuracy =  grouped_by_session['accurate','inaccurate','num_correct','num_incorrect'].sum().reset_index()\n    session_info = session_info.merge(accuracy, on = ['installation_id','game_session'],how = 'left')\n\n\n#     session_info['clips_perc_watched'] = session_info['actual_duration']/session_info['clip_length']\n\n    # print (sum(session_info.game_time[session_info.type == 'Clip'])) # No gametime available on clips\n\n    session_info = session_info.sort_values(['installation_id','start_time'])\n\n    onehot_type = pd.get_dummies(session_info.type)\n    session_info = session_info.join(onehot_type)\n\n    onehot_world = pd.get_dummies(session_info.world)\n    session_info = session_info.join(onehot_world)\n\n    session_info['game_event_count'] = session_info.event_count * session_info.Game\n    session_info['activity_event_count'] = session_info.event_count * session_info.Activity\n    session_info['assessment_event_count'] = session_info.event_count * session_info.Assessment\n    session_info['clip_event_count'] = session_info.event_count * session_info.Clip\n\n    session_info['game_session_time'] = session_info.game_time * session_info.Game\n    session_info['activity_session_time'] = session_info.game_time * session_info.Activity\n    session_info['assessment_session_time'] = session_info.game_time * session_info.Assessment\n    session_info['clip_session_time'] = session_info.game_time * session_info.Clip\n\n    session_info['game_accurate'] = session_info.accurate * session_info.Game\n    session_info['assessment_accurate'] = session_info.accurate * session_info.Assessment\n    session_info['game_inaccurate'] = session_info.inaccurate * session_info.Game\n    session_info['assessment_inaccurate'] = session_info.inaccurate * session_info.Assessment\n\n   \n\n    def get_pre_data(colname,df):\n        new_colname = \"prev_\"+ str(colname)\n        df[new_colname] = (df.groupby(['installation_id'])[colname].cumsum()) - (df[colname])\n        df = df.drop(colname,axis =1)\n        print(new_colname)\n        return(df)\n\n\n    for event_code in event_code_cols:\n        session_info = get_pre_data(event_code,session_info)\n        \n#    session_info = get_pre_data('clip_length',session_info)\n#     session_info = get_pre_data('clip_session_time',session_info)\n#     session_info['clips_fraction_watched'] = session_info['prev_clip_session_time']/session_info['prev_clip_length']\n#     session_info['clips_fraction_watched'][session_info['clips_fraction_watched'] .isna()] = 0 \n\n    \n    #Collect previous events data for each installation_id and game_session\n\n    \n\n    session_info['prev_event_count'] = (session_info.groupby(['installation_id'])['event_count'].cumsum()) - (session_info.event_count)\n    session_info['prev_game_time'] = (session_info.groupby(['installation_id'])['game_time'].cumsum()) -(session_info.game_time)\n    session_info['prev_accurate'] = (session_info.groupby(['installation_id'])['accurate'].cumsum()) - (session_info.accurate)\n    session_info['prev_inaccurate'] = (session_info.groupby(['installation_id'])['inaccurate'].cumsum()) - (session_info.inaccurate)\n\n    session_info['prev_clip'] = (session_info.groupby(['installation_id'])['Clip'].cumsum()) - (session_info.Clip)\n    session_info['prev_activity'] = (session_info.groupby(['installation_id'])['Activity'].cumsum()) - (session_info.Activity)\n    session_info['prev_game'] = (session_info.groupby(['installation_id'])['Game'].cumsum()) - (session_info.Game)\n    session_info['prev_assessment'] = (session_info.groupby(['installation_id'])['Assessment'].cumsum()) - (session_info.Assessment)\n\n    session_info['prev_session_count'] = session_info['prev_clip']+session_info['prev_activity'] + \\\n                                            session_info['prev_game']+session_info['prev_assessment']\n\n    session_info['prev_assessment_game_time'] = (session_info.groupby(['installation_id'])['assessment_session_time'].cumsum()) - (session_info.assessment_session_time)\n    session_info['prev_assessment_event_count'] = (session_info.groupby(['installation_id'])['assessment_event_count'].cumsum()) - (session_info.assessment_event_count)\n    session_info['prev_assessment_accurate'] = (session_info.groupby(['installation_id'])['assessment_accurate'].cumsum()) - (session_info.assessment_accurate)\n    session_info['prev_assessment_inaccurate'] = (session_info.groupby(['installation_id'])['assessment_inaccurate'].cumsum()) - (session_info.assessment_inaccurate)\n\n    session_info['prev_game_game_time'] = (session_info.groupby(['installation_id'])['game_session_time'].cumsum()) - (session_info.game_session_time)\n    session_info['prev_game_event_count'] = (session_info.groupby(['installation_id'])['game_event_count'].cumsum()) - (session_info.game_event_count)\n    session_info['prev_game_accurate'] = (session_info.groupby(['installation_id'])['game_accurate'].cumsum()) - (session_info.game_accurate)\n    session_info['prev_game_inaccurate'] = (session_info.groupby(['installation_id'])['game_inaccurate'].cumsum()) - (session_info.game_inaccurate)\n\n    session_info['prev_activity_game_time'] = (session_info.groupby(['installation_id'])['activity_session_time'].cumsum()) - (session_info.activity_session_time)\n    session_info['prev_activity_event_count'] = (session_info.groupby(['installation_id'])['activity_event_count'].cumsum()) - (session_info.activity_event_count)\n\n\n\n    session_info = session_info[session_info.type == 'Assessment']\n\n    session_info['prev_num_correct'] = (session_info.groupby(['installation_id'])['num_correct'].cumsum()) - (session_info.num_correct)\n    session_info['prev_num_incorrect'] = (session_info.groupby(['installation_id'])['num_incorrect'].cumsum()) - (session_info.num_incorrect)\n\n    session_info['prev_mean_accuracy'] = session_info['prev_num_correct']/(session_info['prev_num_correct']+session_info['prev_num_incorrect'])\n    session_info['prev_mean_accuracy'][session_info['prev_mean_accuracy'] .isna()]= 0\n\n    session_info['prev_game_accuracy'] = session_info['prev_game_accurate']/(session_info['prev_game_accurate']+session_info['prev_game_inaccurate'])\n    session_info['prev_game_accuracy'][session_info['prev_game_accuracy'] .isna()] = 0\n\n    session_info['prev_assessment_accuracy'] = session_info['prev_assessment_accurate']/(session_info['prev_assessment_accurate']+session_info['prev_assessment_inaccurate'])\n    session_info['prev_assessment_accuracy'][session_info['prev_assessment_accuracy'] .isna()] = 0\n\n    session_info['mean_session_time'] = session_info['prev_game_time']/session_info['prev_session_count']\n    session_info['mean_session_time'][session_info['mean_session_time'] .isna()] = 0\n\n    session_info['mean_game_session_time'] = session_info['prev_game_game_time']/session_info['prev_game']\n    session_info['mean_game_session_time'][session_info['mean_game_session_time'] .isna()] = 0\n\n    session_info['mean_assessment_session_time'] = session_info['prev_assessment_game_time']/session_info['prev_assessment']\n    session_info['mean_assessment_session_time'][session_info['mean_assessment_session_time'] .isna()] = 0\n\n    session_info['mean_activity_session_time'] = session_info['prev_activity_game_time']/session_info['prev_activity']\n    session_info['mean_activity_session_time'][session_info['mean_activity_session_time'] .isna()] = 0\n\n    session_info['mean_event_count'] = session_info['prev_event_count']/session_info['prev_session_count']\n    session_info['mean_event_count'][session_info['mean_event_count'] .isna()] = 0\n\n    session_info['mean_game_event_count'] = session_info['prev_game_event_count']/session_info['prev_game']\n    session_info['mean_game_event_count'][session_info['mean_game_event_count'] .isna()] = 0\n    session_info['mean_assessment_event_count'] = session_info['prev_assessment_event_count']/session_info['prev_assessment']\n    session_info['mean_assessment_event_count'][session_info['mean_assessment_event_count'] .isna()] = 0\n    session_info['mean_activity_event_count'] = session_info['prev_activity_event_count']/session_info['prev_activity']\n    session_info['mean_activity_event_count'][session_info['mean_activity_event_count'] .isna()] = 0\n\n\n    session_info['avg_time_per_event'] = session_info['mean_session_time']/session_info['mean_event_count']\n    session_info['avg_time_per_event'][session_info['avg_time_per_event'] .isna()] = 0\n\n\n    onehot_title = pd.get_dummies(session_info.title)\n    #     onehot_title.columns = ['bird','cart','cauldron', 'chest', 'mushroom']\n    session_info = session_info.join(onehot_title)\n    \n    return(session_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exclusions = ['installation_id', 'game_session', 'type', 'title', 'world',\\\n           'start_time','end_time','world_sequence', 'rank', 'event_count', 'game_time', 'accurate','num_correct',\\\n           'inaccurate','num_incorrect', 'Activity', 'Assessment', 'Clip', 'Game', \\\n           'NONE', 'game_event_count',\\\n           'activity_event_count', 'assessment_event_count', 'game_session_time',\\\n           'activity_session_time', 'assessment_session_time', 'game_accurate',\\\n           'assessment_accurate', 'game_inaccurate', 'assessment_inaccurate','clip_event_count','day_of_week','gap_time','clip_length']\n\nresponse = 'accuracy_group'\n\ntrain_session_info = extract_features(train)\n\ndel train\ngc.collect()\n\n# create features from test\ntest_session_info = extract_features(test)\ndel test\ngc.collect()\n\n# pick only the latest rows\ntest_session_info['latest']=test_session_info.groupby(['installation_id'])['start_time'].apply(lambda x: x.rank(ascending =False))\ntest_features = test_session_info[test_session_info.latest == 1].drop(['latest'],axis = 1)\n\n# pick only completed assessments for labels from test\ntest_labelled_set = test_session_info[test_session_info.latest != 1].drop(['latest'],axis = 1)\ntest_labelled_set['accuracy'] =  test_labelled_set.num_correct/(test_labelled_set.num_correct+test_labelled_set.num_incorrect)\ntest_labelled_set = test_labelled_set[-test_labelled_set.accuracy.isna()]\ntest_labelled_set['accuracy_group'] = 0\ntest_labelled_set['accuracy_group'] [test_labelled_set.accuracy == 1] = 3\ntest_labelled_set['accuracy_group'] [test_labelled_set.accuracy == 0.5] = 2\ntest_labelled_set['accuracy_group'] [(test_labelled_set.accuracy >0) & (test_labelled_set.accuracy <0.5)] = 1\ntest_labelled_set = test_labelled_set.drop(['accuracy'],axis =1).drop(exclusions,axis = 1)\n\n\ntrain_labelled_set = train_session_info.merge(train_labels[['installation_id','game_session',  response]],\\\n                                         on = ['installation_id','game_session'],how = 'inner')\\\n                                 .drop(exclusions,axis = 1)\n\nlabelled_set = pd.concat([train_labelled_set,test_labelled_set],sort = False)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":" #GBM algorithm\n# from sklearn import cross_validation, metrics   #Additional scklearn functions\n# from sklearn.model_selection import GridSearchCV\ndef scale_features(features):\n    cols = features.columns\n    scaler = MinMaxScaler()\n    scaler.fit(features)\n    scaled_features = pd.DataFrame(scaler.transform(features))\n    scaled_features.columns = cols\n    return(scaled_features)\n\n\n\n\n\nfeatures_train, features_validation, target_train, target_validation = (train_test_split(labelled_set.drop(response,axis =1),\n                                                                                labelled_set[response], test_size=0.2, \n                                                                                                 random_state=0))\n    \nfeature_list = list(features_train.columns)\n    \n# features_train = scale_features(features_train)\n\ngbm = GradientBoostingRegressor(random_state = 0, n_estimators = 5000 , verbose = 1,\\\n                             n_iter_no_change = 100, learning_rate = 0.01, validation_fraction = 0.2)\n\ngbm.fit(features_train,target_train)\n\n# classifier = GradientBoostingClassifier(n_estimators = 500,learning_rate = 0.1,  random_state = 0,verbose =1, n_iter_no_change =100) \n\n# classifier.fit(features_train,target_train)\n\n# # preds = classifier.predict(features_validation)\n# # preds = np.round(gbm.predict(features_validation),0)\n\n# kappa = cohen_kappa_score(target_validation,preds, weights = 'quadratic')\n# kappa\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify_accuracy_group(pred, threshold_1, threshold_2,threshold_3):\n    pred[pred > threshold_3 ] = 3\n    pred[(pred > threshold_2) & (pred <= threshold_3)] = 2\n    pred[(pred > threshold_1) & (pred <= threshold_2)] = 1\n    pred[pred <= threshold_1] = 0\n    return(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nthresh = pd.DataFrame(gbm.predict(features_validation),target_validation).reset_index()\nthresh.columns = ['class','val']\nprint(thresh.groupby(['class'])['val'].mean())\nplt.figure(figsize=(10, 6))\nsns.distplot(thresh.val[thresh['class'] == 0])\nsns.distplot(thresh.val[thresh['class'] == 1])\nsns.distplot(thresh.val[thresh['class'] == 2])\nsns.distplot(thresh.val[thresh['class'] == 3])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def obj_fun(x):\n#     preds = classify_accuracy_group(gbm.predict(features_validation),x[0],x[1],x[2])\n#     return(1 - cohen_kappa_score(target_validation,preds, weights = 'quadratic'))\n\n# init = [0.5,1.5,2.5]\n\n# res = minimize(obj_fun,init,method='nelder-mead',\n#                 options={'xatol': 1e-8, 'disp': True})\n\n# res.x\n\n# bounds = [(0.1,3),(0.1,3),(0.1,3)]\n\n# optimize.shgo(obj_fun, bounds,n=200, iters=5,sampling_method='sobol')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = classify_accuracy_group(gbm.predict(features_validation),0.9999,1.5,2.19)\n# preds = np.round(gbm.predict(features_validation),0)\n\nkappa = cohen_kappa_score(target_validation,preds, weights = 'quadratic')\nkappa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = classify_accuracy_group(gbm.predict(features_train),0.9999,1.5,2.19)\n# preds = np.round(gbm.predict(features_validation),0)\n\nkappa = cohen_kappa_score(target_train,preds, weights = 'quadratic')\nkappa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh = pd.DataFrame(gbm.predict(features_train),target_train).reset_index()\nthresh.columns = ['class','val']\nthresh.groupby(['class'])['val'].mean()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.distplot(thresh.val[thresh['class'] == 0])\nsns.distplot(thresh.val[thresh['class'] == 1])\nsns.distplot(thresh.val[thresh['class'] == 2])\nsns.distplot(thresh.val[thresh['class'] == 3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(target_validation,classify_accuracy_group(gbm.predict(features_validation),0.9999,1.5,2.19)) #labels = target_validation.accuracy_group.unique()\ncm\nplt.figure(figsize=(10, 6))\nsns.heatmap(cm,annot=True,fmt = 'd',cbar=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cm = confusion_matrix(target_validation,classify_accuracy_group(lgb_reg.predict(features_validation),0.89,1.7,2.21)) #labels = target_validation.accuracy_group.unique()\n# cm\n# plt.figure(figsize=(10, 6))\n# sns.heatmap(cm,annot=True,fmt = 'd',cbar=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = list(gbm.feature_importances_)\nfeature_importances = [(feature, round(importance, 4)) for feature, importance in zip(feature_list, importances)]\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n\nfig, ax = plt.subplots(figsize=(15,15))\n\nfeat_imp = pd.DataFrame(feature_importances,columns = ['Feature','rel_imp'])\nax.barh(feat_imp['Feature'], feat_imp['rel_imp'], align='center')\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('importance')\nax.set_title('Feature importance')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission =  pd.DataFrame(test_features['installation_id'])\n\nsubmission['accuracy_group'] = classify_accuracy_group(gbm.predict(test_features.drop(exclusions,axis = 1)),0.9999,1.5,2.19).astype('int')\n\nsubmission.to_csv('submission.csv',index=False)\n\n# submission.groupby('accuracy_group').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # check if there are cases where level2 was played first\n# sub = train_session_info.groupby(['installation_id','title'])['session_start'].min().reset_index()\n\n# sub_sub = sub[sub.title == 'Bird Measurer (Assessment)'].merge(sub[sub.title == 'Mushroom Sorter (Assessment)'], \\\n#                                                                on = ['installation_id'],how = 'inner')\\\n            \n# sub_sub[sub_sub.session_start_x < sub_sub.session_start_y]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}