{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# library read in\n\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport matplotlib.pylab as plt\nimport calendar\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.model_selection import GroupKFold\nfrom typing import Any\nfrom numba import jit\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\nfrom itertools import product","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# load data\ntrain_clean = pd.read_csv('../input/data-reshaping-and-rudimentary-models/cleaned_variables.csv')\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')\n# specs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\nsample_submission = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce leakage\ntrain_clean.loc[train_clean.title == 'Bird Measurer (Assessment)', 'BM_tries'] -= 1\ntrain_clean.loc[train_clean.title == 'Cart Balancer (Assessment)', 'CB_tries'] -= 1\ntrain_clean.loc[train_clean.title == 'Cauldron Filler (Assessment)', 'CF_tries'] -= 1\ntrain_clean.loc[train_clean.title == 'Chest Sorter (Assessment)', 'CS_tries'] -= 1\ntrain_clean.loc[train_clean.title == 'Mushroom Sorter (Assessment)', 'MS_tries'] -= 1\n\ntrain_clean.loc[(train_clean.title == 'Bird Measurer (Assessment)') & (train_clean.assessment == \"Success\"), 'BM_passes'] -= 1\ntrain_clean.loc[(train_clean.title == 'Cart Balancer (Assessment)') & (train_clean.assessment == \"Success\"), 'CB_passes'] -= 1\ntrain_clean.loc[(train_clean.title == 'Cauldron Filler (Assessment)') & (train_clean.assessment == \"Success\"), 'CF_passes'] -= 1\ntrain_clean.loc[(train_clean.title == 'Chest Sorter (Assessment)') & (train_clean.assessment == \"Success\"), 'CS_passes'] -= 1\ntrain_clean.loc[(train_clean.title == 'Mushroom Sorter (Assessment)') & (train_clean.assessment == \"Success\"), 'MS_passes'] -= 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data cleaning (summary of exploration kernel)\n\n# make sure order is correct/logical (it currently seems to be sorted by game_time. Some events occur simultaneously, and such rows are randomly sorted so some of the event_counts are out of order). With below sorting, events are in chronological order by installation_id\ntest = test.sort_values([\"installation_id\",\"timestamp\",\"event_count\"]).reset_index()\n\n# create accurate indicator column of assessment success\ntest[\"successes\"] = pd.np.where((test.type == \"Assessment\") & ((test.event_code == 4100) | (test.event_code == 4110)), # consider assessment outcome event_codes (4100 and 4110)\n                             pd.np.where(((test.event_data.str.contains(\"\\\"correct\\\":true,\\\"caterpillars\\\"\")) & (test.title == \"Bird Measurer (Assessment)\")) | ((test.event_data.str.contains(\"\\\"correct\\\":true\")) & (test.event_code == 4100) & (test.title != \"Bird Measurer (Assessment)\")),\"Success\",# if a successful stage 1 Bird Measurer (event_code 4110) OR event_code 4100 in any other assessment (provided that the event_data has a 'correct' indicator), assessment was a success and counts towards accuracy measures\n                                         pd.np.where(((test.event_data.str.contains(\"\\\"correct\\\":true,\\\"hats\\\"\")) & (test.title == \"Bird Measurer (Assessment)\")), \"Success (not measured)\", # if a successful stage 2 Bird Measurer (event_code = 4100), assessment was a success but doesn't count towards accuracy measures \n                                                     pd.np.where(((test.event_data.str.contains(\"\\\"correct\\\":false,\\\"hats\\\"\")) & (test.title == \"Bird Measurer (Assessment)\")),\"Failure (not measured)\", # if a failed stage 2 Bird Measurer (event_code = 4100), assessment was a failure but doesn't count towards accuracy measures\n                                                                 \"Failure\")) # all remaining 4110 event_codes are failures\n                                        ),\n                                  \"No test\", # if not an assessment, straightforward) \n                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cumulative time in TREETOPCITY, MAGMAPEAK and CRYSTALCAVES\nTTC_time = []\nMP_time = []\nCC_time = []\n# cumulative sessions in each world\nTTC_events = []\nMP_events = []\nCC_events = []\n# cumulative attempts on Bird Measurer, Cart Balancer, Cauldron Filler, Chest Sorter and Mushroom Sorter\nBM_tries = []\nCB_tries = []\nCF_tries = []\nCS_tries = []\nMS_tries = []\n# total passes on each assessment\nBM_passes = []\nCB_passes = []\nCF_passes = []\nCS_passes = []\nMS_passes = []\n# assessment name\nass_title = []\n\n\n# create data frame of unique users, and keep track of rows for final merging\nuser_list = []\n# keep track of session id, for merging\nsession_list = []\n# keep track of timestamp, for further analysis\nsession_time = []\n# installation id lifetime\nID_lifetime = []\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# want a list of respondents - each takes a test next\n\ntest_users = test['installation_id'].unique()\n# 1000 users in the set\nfor user in tqdm(test_users):\n    user_list.append(user)\n    temp_data = test[test.installation_id == user]\n    # which assessment is being taken?\n    ass_title.append(temp_data.title[-1:].item())\n    session_list.append(temp_data.game_session[-1:].item())\n    session_time.append(temp_data.timestamp[-1:].item())\n    # for subsequent variables, we don't want to consider current assessment\n    temp_data.drop(temp_data.tail(1).index,inplace=True)\n    # considering all remaining, we can get all world and assessment tries/passes\n    BM_tries.append(temp_data[(temp_data.title == \"Bird Measurer (Assessment)\") & ((temp_data.successes == \"Success\") | (temp_data.successes == \"Success (not measured)\") | (temp_data.successes == \"Failure\") | (temp_data.successes == \"Failure (not measured)\"))].shape[0])\n    CB_tries.append(temp_data[(temp_data.title == \"Cart Balancer (Assessment)\") & ((temp_data.successes == \"Success\") | (temp_data.successes == \"Failure\"))].shape[0])\n    CF_tries.append(temp_data[(temp_data.title == \"Cauldron Filler (Assessment)\") & ((temp_data.successes == \"Success\") | (temp_data.successes == \"Failure\"))].shape[0])\n    CS_tries.append(temp_data[(temp_data.title == \"Chest Sorter (Assessment)\") & ((temp_data.successes == \"Success\") | (temp_data.successes == \"Failure\"))].shape[0])\n    MS_tries.append(temp_data[(temp_data.title == \"Mushroom Sorter (Assessment)\") & ((temp_data.successes == \"Success\") | (temp_data.successes == \"Failure\"))].shape[0])\n    BM_passes.append(temp_data[(temp_data.title == \"Bird Measurer (Assessment)\") & ((temp_data.successes == \"Success\") | (temp_data.successes == \"Success (not measured)\"))].shape[0])\n    CB_passes.append(temp_data[(temp_data.title == \"Cart Balancer (Assessment)\") & (temp_data.successes == \"Success\")].shape[0])\n    CF_passes.append(temp_data[(temp_data.title == \"Cauldron Filler (Assessment)\") & (temp_data.successes == \"Success\")].shape[0])\n    CS_passes.append(temp_data[(temp_data.title == \"Chest Sorter (Assessment)\") & (temp_data.successes == \"Success\")].shape[0])\n    MS_passes.append(temp_data[(temp_data.title == \"Mushroom Sorter (Assessment)\") & (temp_data.successes == \"Success\")].shape[0])\n    # for subsequent variables, filter to final row for each session\n    temp_data = temp_data.groupby(\"game_session\").tail(1)\n    TTC_time.append(sum(temp_data[temp_data.world == \"TREETOPCITY\"].game_time))\n    MP_time.append(sum(temp_data[temp_data.world == \"MAGMAPEAK\"].game_time))\n    CC_time.append(sum(temp_data[temp_data.world == \"CRYSTALCAVES\"].game_time))\n    TTC_events.append(sum(temp_data[temp_data.world == \"TREETOPCITY\"].event_count))\n    MP_events.append(sum(temp_data[temp_data.world == \"MAGMAPEAK\"].event_count))\n    CC_events.append(sum(temp_data[temp_data.world == \"CRYSTALCAVES\"].event_count))\n    ID_lifetime.append(sum(temp_data.game_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_variables = pd.DataFrame({'user': test_users,\n             'session': session_list,\n             'session_time': session_time,\n             'id_lifetime': ID_lifetime,\n             'TTC_time': TTC_time,\n             'MP_time': MP_time,\n             'CC_time': CC_time,\n             'TTC_events': TTC_events,\n             'MP_events': MP_events,\n             'CC_events': CC_events,\n             'BM_tries': BM_tries,\n             'CB_tries': CB_tries,\n             'CF_tries': CF_tries,\n             'CS_tries': CS_tries,\n             'MS_tries': MS_tries,\n             'BM_passes': BM_passes,\n             'CB_passes': CB_passes,\n             'CF_passes': CF_passes,\n             'CS_passes': CS_passes,\n             'MS_passes': MS_passes,\n             'title': ass_title})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try a super-straightforward model on whether an assessment is a pass or a fail, discarding time and only using events/tries/passes in previous efforts. Also, let's split it into 5 models, right off the bat."},{"metadata":{"trusted":true},"cell_type":"code","source":"# map response variable to numeric for xgboost\n\ntrain_clean.assessment[train_clean.assessment == \"Success\"] = 1\ntrain_clean.assessment[train_clean.assessment == \"Failure\"] = 0\n\ntrain_BM = train_clean[train_clean.title == \"Bird Measurer (Assessment)\"]\ntrain_CB = train_clean[train_clean.title == \"Cart Balancer (Assessment)\"]\ntrain_CF = train_clean[train_clean.title == \"Cauldron Filler (Assessment)\"]\ntrain_CS = train_clean[train_clean.title == \"Chest Sorter (Assessment)\"]\ntrain_MS = train_clean[train_clean.title == \"Mushroom Sorter (Assessment)\"]\ntest_BM = test[test.title == \"Bird Measurer (Assessment)\"]\ntest_CB = test[test.title == \"Cart Balancer (Assessment)\"]\ntest_CF = test[test.title == \"Cauldron Filler (Assessment)\"]\ntest_CS = test[test.title == \"Chest Sorter (Assessment)\"]\ntest_MS = test[test.title == \"Mushroom Sorter (Assessment)\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgboost\n\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_BM, y_BM = train_BM[['TTC_events','MP_events','CC_events','BM_tries','CB_tries',\n                       'CF_tries','CS_tries','MS_tries','BM_passes','CB_passes','CF_passes',\n                       'CS_passes','MS_passes']],train_BM['assessment']\nX_CB, y_CB = train_CB[['TTC_events','MP_events','CC_events','BM_tries','CB_tries',\n                       'CF_tries','CS_tries','MS_tries','BM_passes','CB_passes','CF_passes',\n                       'CS_passes','MS_passes']],train_CB['assessment']\nX_CF, y_CF = train_CF[['TTC_events','MP_events','CC_events','BM_tries','CB_tries',\n                       'CF_tries','CS_tries','MS_tries','BM_passes','CB_passes','CF_passes',\n                       'CS_passes','MS_passes']],train_CF['assessment']\nX_CS, y_CS = train_CS[['TTC_events','MP_events','CC_events','BM_tries','CB_tries',\n                       'CF_tries','CS_tries','MS_tries','BM_passes','CB_passes','CF_passes',\n                       'CS_passes','MS_passes']],train_CS['assessment']\nX_MS, y_MS = train_MS[['TTC_events','MP_events','CC_events','BM_tries','CB_tries',\n                       'CF_tries','CS_tries','MS_tries','BM_passes','CB_passes','CF_passes',\n                       'CS_passes','MS_passes']],train_MS['assessment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\n\nfrom sklearn.model_selection import train_test_split\n\nX_BM_train, X_BM_test, y_BM_train, y_BM_test = train_test_split(X_BM, y_BM, test_size=0.2, random_state=123)\nX_CB_train, X_CB_test, y_CB_train, y_CB_test = train_test_split(X_CB, y_CB, test_size=0.2, random_state=123)\nX_CF_train, X_CF_test, y_CF_train, y_CF_test = train_test_split(X_CF, y_CF, test_size=0.2, random_state=123)\nX_CS_train, X_CS_test, y_CS_train, y_CS_test = train_test_split(X_CS, y_CS, test_size=0.2, random_state=123)\nX_MS_train, X_MS_test, y_MS_train, y_MS_test = train_test_split(X_MS, y_MS, test_size=0.2, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(X_BM_train.BM_tries,y_BM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_reg_BM = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n                             max_depth = 5, alpha = 10, n_estimators = 10,scale_pos_weight = 3)\nxg_reg_CB = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n                             max_depth = 5, alpha = 10, n_estimators = 10)\nxg_reg_CF = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n                             max_depth = 5, alpha = 10, n_estimators = 10)\nxg_reg_CS = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n                             max_depth = 5, alpha = 10, n_estimators = 10,scale_pos_weight = 10)\nxg_reg_MS = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n                             max_depth = 5, alpha = 10, n_estimators = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_reg_BM.fit(X_BM_train,y_BM_train)\nxg_reg_CB.fit(X_CB_train,y_CB_train)\nxg_reg_CF.fit(X_CF_train,y_CF_train)\nxg_reg_CS.fit(X_CS_train,y_CS_train)\nxg_reg_MS.fit(X_MS_train,y_MS_train)\n\npreds_BM = xg_reg_BM.predict(X_BM_test)\npreds_CB = xg_reg_CB.predict(X_CB_test)\npreds_CF = xg_reg_CF.predict(X_CF_test)\npreds_CS = xg_reg_CS.predict(X_CS_test)\npreds_MS = xg_reg_MS.predict(X_MS_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_BM = np.sqrt(mean_squared_error(y_BM_test, preds_BM))\nprint(\"RMSE: %f\" % (rmse_BM))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_BM_test = X_BM_test.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_BM_test['preds'] = preds_BM\nX_BM_test['assessment'] = y_BM_test.reset_index().assessment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_BM_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(str(X_BM_test[X_BM_test.assessment == 0].preds.mean()) + \" \" + str(X_BM_test[X_BM_test.assessment == 1].preds.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test model on actual data\n\ntest_BM = test_variables[test_variables.title == \"Bird Measurer (Assessment)\"][['TTC_events','MP_events','CC_events','BM_tries','CB_tries','CF_tries','CS_tries','MS_tries','BM_passes',\n                                                                                'CB_passes','CF_passes','CS_passes','MS_passes']]\ntest_CB = test_variables[test_variables.title == \"Cart Balancer (Assessment)\"][['TTC_events','MP_events','CC_events','BM_tries','CB_tries','CF_tries','CS_tries','MS_tries','BM_passes',\n                                                                                'CB_passes','CF_passes','CS_passes','MS_passes']]\ntest_CF = test_variables[test_variables.title == \"Cauldron Filler (Assessment)\"][['TTC_events','MP_events','CC_events','BM_tries','CB_tries','CF_tries','CS_tries','MS_tries','BM_passes',\n                                                                                'CB_passes','CF_passes','CS_passes','MS_passes']]\ntest_CS = test_variables[test_variables.title == \"Chest Sorter (Assessment)\"][['TTC_events','MP_events','CC_events','BM_tries','CB_tries','CF_tries','CS_tries','MS_tries','BM_passes',\n                                                                                'CB_passes','CF_passes','CS_passes','MS_passes']]\ntest_MS = test_variables[test_variables.title == \"Mushroom Sorter (Assessment)\"][['TTC_events','MP_events','CC_events','BM_tries','CB_tries','CF_tries','CS_tries','MS_tries','BM_passes',\n                                                                                'CB_passes','CF_passes','CS_passes','MS_passes']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate accuracy groups\n\npreds_BM = xg_reg_BM.predict(test_BM)\npreds_CB = xg_reg_CB.predict(test_CB)\npreds_CF = xg_reg_CF.predict(test_CF)\npreds_CS = xg_reg_CS.predict(test_CS)\npreds_MS = xg_reg_MS.predict(test_MS)\n\nexp_no_tries = pd.DataFrame({'probs':np.concatenate((preds_BM,preds_CB,preds_CF,preds_CS,preds_MS))})\n\nexp_no_tries['exp_no'] = (1/exp_no_tries['probs']).round()\n\nconditions = [\n    (exp_no_tries['exp_no'] == 1),\n    (exp_no_tries['exp_no'] == 2),\n    (exp_no_tries['exp_no'] >= 3)]\nchoices = ['3', '2', '1']\nexp_no_tries['accuracy_group'] = np.select(conditions, choices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate accuracy groups by likely assessment efforts; expected tries to first success = 1/p\n\noutput = pd.DataFrame({'installation_id':[test_variables[test_variables.title == \"Bird Measurer (Assessment)\"].user.append(\n    test_variables[test_variables.title == \"Cart Balancer (Assessment)\"].user).append(\n    test_variables[test_variables.title == \"Cauldron Filler (Assessment)\"].user).append(\n    test_variables[test_variables.title == \"Chest Sorter (Assessment)\"].user).append(\n    test_variables[test_variables.title == \"Mushroom Sorter (Assessment)\"].user)][0],\n                      'accuracy_group':exp_no_tries['accuracy_group']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}