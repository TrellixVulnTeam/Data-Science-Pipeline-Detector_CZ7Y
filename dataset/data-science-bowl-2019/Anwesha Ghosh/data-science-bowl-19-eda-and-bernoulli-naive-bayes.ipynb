{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\ntrain_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#world is the section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. \n#Possible values are: \n#'NONE' (at the app's start screen), TREETOPCITY' (Length/Height), 'MAGMAPEAK' (Capacity/Displacement), 'CRYSTALCAVES' (Weight).\ntrain_df['world'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['installation_id'].unique()[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# game_session is a randomly generated unique identifier grouping events within a single game or video play session of any world.\ntrain_df[ train_df['installation_id']=='0001e90f'].groupby('game_session')['world'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[ train_df['installation_id']=='000447c4'].groupby('game_session')['world'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This means every time you start a game or a activity, it will be assigned a new game session. It does not depend on installation_id.\ntrain_df.loc[ train_df['game_session']=='a1ec58f109218255', ['title','timestamp']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[ train_df['game_session']=='f11eb823348bfa23', ['title','timestamp'] ].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#event_code - Identifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always \n#identifies the 'Start Game' event for all games. Extracted from event_data.\ntrain_df.loc[ train_df['game_session']=='f11eb823348bfa23', 'event_code'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[ train_df['game_session']=='a1ec58f109218255', 'event_code'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#event_id is a randomly generated unique identifier for the event type.\ntrain_df.loc[ (train_df['game_session']=='a1ec58f109218255') & (train_df['event_code']==4020), 'event_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[ (train_df['game_session']=='a1ec58f109218255') & (train_df['event_code']==4020)].head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[ (train_df['installation_id']=='0001e90f') & (train_df['event_code']==4020) & (train_df['title']=='Scrub-A-Dub') ].head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[ (train_df['game_session']=='ca8b415f34d12873') & (train_df['event_code']==4020)].head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So, this means as long as you play the same game or video or activity anytime, the event_id corresponding to an event_code will remain \n#same, even though the game_session will get changed. Once the title changes the event_id corresponding to an event_code will also change.\n#Now let's merge the train_df dataframe with train_labels dataframe.\nmerged = pd.merge( left = train_df, right = train_labels, on = ['installation_id', 'game_session', 'title'] )\nmerged.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set1 = train_df[train_df['type']=='Assessment']['installation_id'].unique()\nset2 = merged['installation_id'].unique()\ndiffset = set(set1) - set(set2)\nlen(diffset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It seems like there are some installation_id which took part in some assessment activity, but they were not recorded in train_labels table,\n#so I am assuming that may be these assessments are part of some demo activities shown to the children to demonstrate the working of the app.\nmerged.groupby('world')['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Again, TREETOPCITY' (Length/Height), 'MAGMAPEAK' (Capacity/Displacement), 'CRYSTALCAVES' (Weight).\n# If you notice the outcomes in this competition are grouped into 4 'accuracy_group' in the data labeled as:\n# 3: the assessment was solved on the first attempt. means accuracy = 1/(1+0) = 1 i.e. 1 correct after 0 incorrect attempt.\n# 2: the assessment was solved on the second attempt. means accuracy = 1/(1+1) = 0.5 i.e. 1 correct after 1 incorrect attempt.\n# 1: the assessment was solved after 3 or more attempts\n# 1/(1+2) i.e. 1 correct after 2 incorrect attempts or, 1/(1+3) or, 1/(1+4) ...means accuracy <= 0.333\n# 0: the assessment was never solved. means accuracy = 0/(0 + attempted any number of times)\nmerged.groupby(['accuracy_group', 'accuracy'])['num_incorrect'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.groupby(['world', 'title'])['accuracy_group'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Well it is quite intuitive that  'Chest Sorter (Assessment)' in CRYSTALCAVES require more effort than 'Cart Balancer (Assessment)'. \n#Since, the former one seems to have highest count of accuracy_group=0 while the later one is having highest count of accuracy_group=3 in\n#that world. Infact 'Chest Sorter (Assessment)' is having the highest count of accuracy_group=0 among all the assessments. Similarly, the\n#'Bird Measurer (Assessment)' in TREETOPCITY seems to have required more effort than 'Mushroom Sorter (Assessment)' which is actually\n#having the highest count of accuracy_group=3 among all other assessments. 'Cauldron Filler (Assessment)' on its own seems like a pretty \n#easy task since it is having a good number of accuracy_group=3 counts.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's load the test dataset.\ntest_df = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's create the template for submission dataframe. We will take each unique combination of 'installation_id' and 'title' from test dataframe\n#and put them into the 'combined' column of submission_df to be splitted upon later on.\ntemp = test_df.loc[ test_df['title'].str.contains('Assessment'), ['installation_id', 'title'] ]\ntemp['combined'] = temp['installation_id'].astype(str)+'_'+temp['title'].astype(str)\nsubmission_df = pd.DataFrame( columns = ['combined', 'accuracy_group'] )\nsubmission_df['combined'] = temp['combined'].unique()\ndel(temp)\nsubmission_df[['installation_id', 'title']] = submission_df['combined'].str.split('_', expand=True)\nsubmission_df = submission_df.drop('combined', axis=1)\nsubmission_df = submission_df[['installation_id', 'title', 'accuracy_group']]\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made \n#an attempt on at least one assessment.\ntest_df.loc[ (test_df['installation_id']=='00abaee7') & (test_df['world']=='TREETOPCITY'), 'title' ].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The assessment information of this installation_id for TREETOPCITY is not captured in the test dataset.\ntest_df.loc[ (test_df['installation_id']=='00abaee7') & (test_df['world']=='MAGMAPEAK'), 'title' ].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.loc[ (test_df['installation_id']=='00abaee7') & (test_df['world']=='CRYSTALCAVES'), 'title' ].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finally let's get started with the main part of the analysis. According to me the factor that should most influence the performance of a\n#student in assessments is whether he has properly understood the videos or lessons provided prior to that. So, we will basically determine\n#the maximum accuracy_group of a child corresponding to an assessment based on whether he has attended the previous lessons or not.\n#For that we will create a dataframe for each world with all the titles under the world as the columns, installation_id as the index.\n#The columns will be binary as to whether he has attended that lesson or not, except the Assessment columns which will contain the maximum\n#accuracy_group of that id for that assessment.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the maximum accuracy group of each id for each assessment in group1.\ngroup1 = merged.groupby( by=['title', 'installation_id'] )['accuracy_group'].max()\ngroup1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the temporary dataframe.\ncolumns = list( train_df.loc[ train_df['world']=='TREETOPCITY', 'title'].unique() )\nids = merged.loc[ merged['world']=='TREETOPCITY','installation_id'].unique()\ntreetop_df = pd.DataFrame( columns = columns, index=list( ids ) )\ntreetop_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the titles of a world attended by each id in group2.\ngroup2 = train_df.loc[ train_df['world']=='TREETOPCITY', ['installation_id', 'title']].groupby( by='installation_id' )\ngroup2    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill in the temporary dataframe with values from group1 and group2.\nfor i in ids:\n    gg = group2.get_group(i)\n    titles = gg['title'].unique()\n    for t in titles:\n        treetop_df.loc[i, t]=1\n    assessments = list( merged.loc[(merged['installation_id']==i) & (merged['world']=='TREETOPCITY'), 'title'].unique() )\n    for a in assessments:\n        treetop_df.loc[i, a] = group1[(a, i)]\ntreetop_df.head()            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill the null values with the minimum in the assessment columns and 0 elsewhere.\ntreetop_df.loc[ treetop_df['Bird Measurer (Assessment)'].isnull(), 'Bird Measurer (Assessment)' ] = min( treetop_df['Bird Measurer (Assessment)'] )\ntreetop_df.loc[ treetop_df['Mushroom Sorter (Assessment)'].isnull(), 'Mushroom Sorter (Assessment)' ] = min( treetop_df['Mushroom Sorter (Assessment)'] )\ntreetop_df = treetop_df.fillna(0)         \ntreetop_df.head()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treetop_df['Bird Measurer (Assessment)'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For modelling I will be using Bernoulli Naive Bayes as it deals with independent binary variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train the models on the temporary dataframe.\nfrom sklearn.naive_bayes import BernoulliNB\nbnb_tt1 = BernoulliNB()\nY_cols = ['Bird Measurer (Assessment)', 'Mushroom Sorter (Assessment)']\nX_cols = list( set(treetop_df.columns) - set(Y_cols) )\nX_train = treetop_df[ X_cols ]\nY_train = treetop_df['Mushroom Sorter (Assessment)']\nbnb_tt1.fit(X_train, Y_train)\nbnb_tt2 = BernoulliNB()\nY_train = treetop_df['Bird Measurer (Assessment)']\nbnb_tt2.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Delete the temporary dataframe and build another similar one from the test dataset on which the model will be tested.\ndel(treetop_df)\nids = test_df.loc[ (test_df['title']=='Bird Measurer (Assessment)') | (test_df['title']=='Mushroom Sorter (Assessment)'),'installation_id'].unique()\nfiltered_test = pd.DataFrame( columns = test_df.columns )\nfor i in ids:\n    temp = test_df[ test_df['installation_id']==i ]\n    filtered_test = pd.concat( [filtered_test, temp], axis=0, ignore_index=True )\ntreetop_test = pd.DataFrame( columns = columns, index=list( ids ) )\ngroup2 = filtered_test.loc[ filtered_test['world']=='TREETOPCITY', ['installation_id', 'title']].groupby( by='installation_id' )\nfor i in ids:\n    gg = group2.get_group(i)\n    titles = gg['title'].unique()\n    for t in titles:\n        treetop_test.loc[i, t]=1    \ntreetop_test = treetop_test.fillna(0)\ntreetop_test.head(3)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict the results and store them into the temporary dataframe build from test dataset.\nX_test = treetop_test[ X_cols ]\ntreetop_test['Mushroom Sorter (Assessment)'] = bnb_tt1.predict(X_test)\ntreetop_test['Bird Measurer (Assessment)'] = bnb_tt2.predict(X_test)\ntreetop_test[['Mushroom Sorter (Assessment)']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can accept these assumptions, the reason being suppose a child takes an assesssment and pass it after 4 or 5 attempts. But since he has \n#gone through the necessary videos or activities before taking the assessment, he feels like he is able to understand his mistakes and \n#will be able to do better the next time. So, the next time he tries he succeds at the 2nd attempt and eventually he will be able to pass\n#at the very first attempt. To make it easier, we have considered the maximum accuracy_group that a child can end up with, depending on\n#whether he has understood the lessons provided prior to that in terms of videos or activity. On the other hand, if a child has not gone\n#through the previous lessons or feels like an assessment is too tough for him to attempt any further then he will try no longer and end up\n#in the lowest accuracy_group mostly 0 or 1.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Copy the predictions from temporary dataframe to the submission_df dataframe.\nfor a in ['Mushroom Sorter (Assessment)', 'Bird Measurer (Assessment)']:\n    ids = submission_df.loc[ submission_df['title']==a, 'installation_id' ]\n    for i in ids:\n        submission_df.loc[ (submission_df['installation_id']==i) & (submission_df['title']==a), 'accuracy_group'] = treetop_test.loc[ i,a ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will do same for the other 2 worlds.\n#Create the temporary dataframe.\ncolumns = list( train_df.loc[ train_df['world']=='CRYSTALCAVES', 'title'].unique() )\nids = merged.loc[ merged['world']=='CRYSTALCAVES','installation_id'].unique()\ncrystal_df = pd.DataFrame( columns = columns, index=list( ids ) )\n#Get the titles of a world attended by each id in group2.\ngroup2 = train_df.loc[ train_df['world']=='CRYSTALCAVES', ['installation_id', 'title']].groupby( by='installation_id' )\n#Fill in the temporary dataframe with values from group1 and group2.\nfor i in ids:\n    gg = group2.get_group(i)\n    titles = gg['title'].unique()\n    for t in titles:\n        crystal_df.loc[i, t]=1\n    assessments = list( merged.loc[(merged['installation_id']==i) & (merged['world']=='CRYSTALCAVES'), 'title'].unique() )\n    for a in assessments:\n        crystal_df.loc[i, a] = group1[(a, i)]\n#Fill the null values with the minimum in the assessment columns and 0 elsewhere.        \ncrystal_df.loc[ crystal_df['Chest Sorter (Assessment)'].isnull(), 'Chest Sorter (Assessment)' ] = min( crystal_df['Chest Sorter (Assessment)'] )\ncrystal_df.loc[ crystal_df['Cart Balancer (Assessment)'].isnull(), 'Cart Balancer (Assessment)' ] = min( crystal_df['Cart Balancer (Assessment)'] )\ncrystal_df = crystal_df.fillna(0)\n#Train the models on the temporary dataframe.\nbnb_tt1 = BernoulliNB()\nY_cols = ['Chest Sorter (Assessment)', 'Cart Balancer (Assessment)']\nX_cols = list( set(crystal_df.columns) - set(Y_cols) )\nX_train = crystal_df[ X_cols ]\nY_train = crystal_df['Cart Balancer (Assessment)']\nbnb_tt1.fit(X_train, Y_train)\nbnb_tt2 = BernoulliNB()\nY_train = crystal_df['Chest Sorter (Assessment)']\nbnb_tt2.fit(X_train, Y_train)\n#Delete the temporary dataframe and build another similar one from the test dataset on which the model will be tested.\ndel(crystal_df)\nids = test_df.loc[ (test_df['title']=='Chest Sorter (Assessment)') | (test_df['title']=='Cart Balancer (Assessment)'),'installation_id'].unique()\nfiltered_test = pd.DataFrame( columns = test_df.columns )\nfor i in ids:\n    temp = test_df[ test_df['installation_id']==i ]\n    filtered_test = pd.concat( [filtered_test, temp], axis=0, ignore_index=True )\ncrystal_test = pd.DataFrame( columns = columns, index=list( ids ) ) \ngroup2 = filtered_test.loc[ filtered_test['world']=='CRYSTALCAVES', ['installation_id', 'title']].groupby( by='installation_id' )\nfor i in ids:\n    gg = group2.get_group(i)\n    titles = gg['title'].unique()\n    for t in titles:\n        crystal_test.loc[i, t]=1  \ncrystal_test = crystal_test.fillna(0)\ncrystal_test.head(3) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict the results and store them into the temporary dataframe build from test dataset.\nX_test = crystal_test[ X_cols ]\ncrystal_test['Cart Balancer (Assessment)'] = bnb_tt1.predict(X_test)\ncrystal_test['Chest Sorter (Assessment)'] = bnb_tt2.predict(X_test)\ncrystal_test[['Cart Balancer (Assessment)']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Copy the predictions from temporary dataframe to the submission_df dataframe.\nfor a in ['Cart Balancer (Assessment)', 'Chest Sorter (Assessment)']:\n    ids = submission_df.loc[ submission_df['title']==a, 'installation_id' ]\n    for i in ids:\n        submission_df.loc[ (submission_df['installation_id']==i) & (submission_df['title']==a), 'accuracy_group'] = crystal_test.loc[ i,a ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will do same for 'MAGMAPEAK' world.\n#Create the temporary dataframe.\ncolumns = list( train_df.loc[ train_df['world']=='MAGMAPEAK', 'title'].unique() )\nids = merged.loc[ merged['world']=='MAGMAPEAK','installation_id'].unique()\nmagma_df = pd.DataFrame( columns = columns, index=list( ids ) )\n#Get the titles of a world attended by each id in group2.\ngroup2 = train_df.loc[ train_df['world']=='MAGMAPEAK', ['installation_id', 'title']].groupby( by='installation_id' )\n#Fill in the temporary dataframe with values from group1 and group2.\nfor i in ids:\n    gg = group2.get_group(i)\n    titles = gg['title'].unique()\n    for t in titles:\n        magma_df.loc[i, t]=1\n    assessments = list( merged.loc[(merged['installation_id']==i) & (merged['world']=='MAGMAPEAK'), 'title'].unique() )\n    for a in assessments:\n        magma_df.loc[i, a] = group1[(a, i)]\n#Fill the null values with the minimum in the assessment columns and 0 elsewhere.        \nmagma_df.loc[ magma_df['Cauldron Filler (Assessment)'].isnull(), 'Cauldron Filler (Assessment)' ] = min( magma_df['Cauldron Filler (Assessment)'] )\nmagma_df = magma_df.fillna(0)\n#Train the models on the temporary dataframe.\nbnb_tt = BernoulliNB()\nY_cols = ['Cauldron Filler (Assessment)']\nX_cols = list( set(magma_df.columns) - set(Y_cols) )\nX_train = magma_df[ X_cols ]\nY_train = magma_df['Cauldron Filler (Assessment)']\nbnb_tt.fit(X_train, Y_train)\n#Delete the temporary dataframe and build another similar one from the test dataset on which the model will be tested.\ndel(magma_df)\nids = test_df.loc[ test_df['title']=='Cauldron Filler (Assessment)','installation_id'].unique()\nfiltered_test = pd.DataFrame( columns = test_df.columns )\nfor i in ids:\n    temp = test_df[ test_df['installation_id']==i ]\n    filtered_test = pd.concat( [filtered_test, temp], axis=0, ignore_index=True )\nmagma_test = pd.DataFrame( columns = columns, index=list( ids ) )\ngroup2 = filtered_test.loc[ filtered_test['world']=='MAGMAPEAK', ['installation_id', 'title']].groupby( by='installation_id' )\nfor i in ids:\n    gg = group2.get_group(i)\n    titles = gg['title'].unique()\n    for t in titles:\n        magma_test.loc[i, t]=1  \nmagma_test = magma_test.fillna(0)\nmagma_test.head(3)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict the results and store them into the temporary dataframe build from test dataset.\nX_test = magma_test[ X_cols ]\nmagma_test['Cauldron Filler (Assessment)'] = bnb_tt.predict(X_test)\nmagma_test[['Cauldron Filler (Assessment)']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Copy the predictions from temporary dataframe to the submission_df dataframe.\na = 'Cauldron Filler (Assessment)'\nids = submission_df.loc[ submission_df['title']==a, 'installation_id' ]\nfor i in ids:\n    submission_df.loc[ (submission_df['installation_id']==i) & (submission_df['title']==a), 'accuracy_group'] = magma_test.loc[ i,a ]                                                           ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#If all the predictions are made none of columns should contain null values.\nsubmission_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Store the submission dataframe to a csv file.\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Please don't forget to upvote if you atleast appreciate my efforts, leave alone the scores or results. It helps a lot! \n#Also feel free to comment. :)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}