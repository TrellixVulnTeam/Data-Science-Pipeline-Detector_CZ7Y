{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc, sys, os, math, random\nimport datetime\nimport json\nfrom pandas.io.json import json_normalize\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\n\n# pandas display option\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_row', 1500)\npd.set_option('max_colwidth', 150)\npd.set_option('display.float_format', '{:.2f}'.format)\n#pd.options.display.float_format = '{:,.3f}'.format","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# feature engineering functions\ndef get_object_columns(df, columns):\n    df = df.groupby(['installation_id', columns])['event_id'].count().reset_index()\n    df = df.pivot_table(index='installation_id', columns=[columns], values='event_id')\n    df.columns = list(df.columns)\n    df.fillna(0, inplace=True)\n    return df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')\ntrain_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\n#specs = pd.read_csv('../input/data-science-bowl-2019/specs.csv', converters={'args': json.loads})\n\ntrain = train[train['installation_id'].isin(train_labels['installation_id'].unique())]\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"## extract timestamp"},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in [train, test]:\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n#     df['_hour'] = df['timestamp'].dt.hour\n#     df['_dayofweek'] = df['timestamp'].dt.dayofweek\n    df['_is_weekend'] = np.where(((df['timestamp'].dt.day_name()=='Sunday')|(df['timestamp'].dt.day_name()=='Saturday')),1,0)\n    df['_phase_of_day'] = np.where(df['timestamp'].dt.hour.isin(range(6,12)),'Morning',np.where(df['timestamp'].dt.hour.isin(range(13,19)),'Evening','Night'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## pick collect value"},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in [train, test]:\n    is_assessment = (\n        (df['title'].eq('Bird Measurer (Assessment)') & df['event_code'].eq(4110)) |\n        (~df['title'].eq('Bird Measurer (Assessment)') & df['event_code'].eq(4100)) &\n        df['type'].eq('Assessment'))\n    df['correct'] = 0\n    df.loc[is_assessment & df['event_data'].str.contains('\"correct\":true'), 'correct'] = 1\n    df['incorrect'] = 0\n    df.loc[is_assessment & df['event_data'].str.contains('\"correct\":false'), 'incorrect'] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## accuracy group "},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_group(x):\n    '''\n    3: the assessment was solved on the first attempt\n    2: the assessment was solved on the second attempt\n    1: the assessment was solved after 3 or more attempts\n    0: the assessment was never solved\n    '''\n    if x['correct'] == 0:\n        return 0\n    if x['incorrect'] == 0:\n        return 3\n    elif x['incorrect'] == 1:\n        return 2\n    else:\n        return 1\n\ntrain_correct = train.groupby(['installation_id','game_session'])[['correct','incorrect']].sum().reset_index()\ntrain_correct['accuracy_group'] = train_correct.apply(accuracy_group, axis=1)\n\ntest_correct = test.groupby(['installation_id','game_session'])[['correct','incorrect']].sum().reset_index()\ntest_correct['accuracy_group'] = test_correct.apply(accuracy_group, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## summary events by session"},{"metadata":{"trusted":true},"cell_type":"code","source":"## drop assessment events\n#train = train.query(\"(type!='Assessment') | (event_count==1)\")\n#test = test.query(\"(type!='Assessment') | (event_count==1)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"as_event_id = [4070,4035,4030,4020,3020,3021,3120,3121,2030]\nis_event_in = (train['event_code'].isin(as_event_id))\ntrain.loc[is_event_in, 'event_code'] = train[is_event_in]['event_id']\nis_event_in = (test['event_code'].isin(as_event_id))\ntest.loc[is_event_in, 'event_code'] = test[is_event_in]['event_id']\n\n# for df in [train, test]:\n#     df['event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), df['title'], df['event_code']))\n\nevent_codes = list(train['event_code'].unique())\n\ngroup_cols = ['installation_id','game_session','type','event_code']\ntrain_session_events = train.groupby(group_cols, sort=False)['event_id'].count().unstack().reset_index().fillna(0)\n#train_session_events.loc[train_session_events['type'] == 'Assessment', event_codes] = 0\ntest_session_events = test.groupby(group_cols, sort=False)['event_id'].count().unstack().reset_index().fillna(0)\nfor c in [c for c in event_codes if c not in test_session_events.columns]: test_session_events[c] = 0\n#test_session_events.loc[test_session_events['type'] == 'Assessment', event_codes] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_session_events = pd.merge(train_session_events, train_correct)\ntest_session_events = pd.merge(test_session_events, test_correct)\n\ndel train_correct, test_correct","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## cumulative by installation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_session_events['_cumcount_inst_session'] = train_session_events.groupby(['installation_id'], sort=False).cumcount()\ntest_session_events['_cumcount_inst_session'] = test_session_events.groupby(['installation_id'], sort=False).cumcount()\n\ncumsum_events = train_session_events.groupby(['installation_id'], sort=False)[event_codes].cumsum()\ncumsum_events -= train_session_events[event_codes]\ntrain_session_events = train_session_events.drop(event_codes, axis=1).join(cumsum_events)\ntrain_session_events['_cumcount_inst_event'] = train_session_events[event_codes].sum(axis=1)\n\ncumsum_events = test_session_events.groupby(['installation_id'], sort=False)[event_codes].cumsum()\ncumsum_events -= test_session_events[event_codes]\ntest_session_events = test_session_events.drop(event_codes, axis=1).join(cumsum_events)\ntest_session_events['_cumcount_inst_event'] = test_session_events[event_codes].sum(axis=1)\n\ndel cumsum_events","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## events + last-data"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_event_cols = ['event_id','event_data','event_code','correct','incorrect']\n\ntrain_session_last = train.drop_duplicates(subset=['installation_id','game_session'], keep='last').drop(drop_event_cols, axis=1)\ntrain_session_last['timestamp'] = train.drop_duplicates(subset=['installation_id','game_session'], keep='first')['timestamp'].values\ntrain_sessions = pd.merge(train_session_events, train_session_last, how='left')\n\ntest_session_last = test.drop_duplicates(subset=['installation_id','game_session'], keep='last').drop(drop_event_cols, axis=1)\ntest_session_last['timestamp'] = test.drop_duplicates(subset=['installation_id','game_session'], keep='first')['timestamp'].values\ntest_sessions = pd.merge(test_session_events, test_session_last, how='left')\n\ndel train_session_last, test_session_last\ndel train_session_events, test_session_events","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## cumulative session by installation"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in ['event_count','game_time','correct','incorrect']:\n    grp = train_sessions.groupby(['installation_id'], sort=False)\n    train_sessions[f'_cumsum_inst_{c}'] = grp[c].cumsum()\n    train_sessions[f'_cumsum_inst_{c}'] -= train_sessions[c]\n\n    grp = test_sessions.groupby(['installation_id'], sort=False)\n    test_sessions[f'_cumsum_inst_{c}'] = grp[c].cumsum()\n    test_sessions[f'_cumsum_inst_{c}'] -= test_sessions[c]\n    \nfor c in ['event_count','game_time']:\n    grp = train_sessions.groupby(['installation_id'], sort=False)\n    train_sessions[f'_cummean_inst_{c}'] = train_sessions[f'_cumsum_inst_{c}'] / (grp[c].cumcount() + 1)\n    train_sessions[f'_cummax_inst_{c}'] = grp[c].cummax().shift(1)\n    train_sessions.loc[train_sessions['_cumcount_inst_session']==0, f'_cummax_inst_{c}'] = np.nan\n\n    grp = test_sessions.groupby(['installation_id'], sort=False)\n    test_sessions[f'_cummean_inst_{c}'] = test_sessions[f'_cumsum_inst_{c}'] / (grp[c].cumcount() + 1)\n    test_sessions[f'_cummax_inst_{c}'] = grp[c].cummax().shift(1)\n    test_sessions.loc[test_sessions['_cumcount_inst_session']==0, f'_cummax_inst_{c}'] = np.nan\n\ntrain_sessions['_cumsum_attempt'] = train_sessions['_cumsum_inst_correct'] + train_sessions['_cumsum_inst_incorrect']\ntrain_sessions['_cummean_inst_accuracy'] = train_sessions['_cumsum_inst_correct'] / train_sessions['_cumsum_attempt']\ntest_sessions['_cumsum_attempt'] = test_sessions['_cumsum_inst_correct'] + test_sessions['_cumsum_inst_incorrect']\ntest_sessions['_cummean_inst_accuracy'] = test_sessions['_cumsum_inst_correct'] / test_sessions['_cumsum_attempt']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## assessment accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_asmt_sessions = train_sessions[train_sessions['type'] == 'Assessment']\ntest_asmt_sessions = test_sessions[test_sessions['type'] == 'Assessment']\n\ngroup_cols = ['installation_id','title']\ntrain_asmt_sessions['_cumcount_inst_title'] = train_asmt_sessions.groupby(group_cols, sort=False)['game_session'].cumcount()\ntest_asmt_sessions['_cumcount_inst_title'] = test_asmt_sessions.groupby(group_cols, sort=False)['game_session'].cumcount()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## cappa 0.36\n# aggrigate accuracy by title\nacc_group_pct = train_labels.groupby('title').apply(lambda x: x['accuracy_group'].value_counts(normalize=True)).unstack()\nacc_group_pct.columns = [f'_pct_title_acc_group_{i}' for i in range(4)]\nacc_group_pct = acc_group_pct.reset_index()\n\nacc_group_pct['_pct_title_correct'] = acc_group_pct[[f'_pct_title_acc_group_{i}' for i in range(1,4)]].sum(axis=1)\n\ntrain_asmt_sessions = pd.merge(train_asmt_sessions, acc_group_pct, how='left')\ntest_asmt_sessions = pd.merge(test_asmt_sessions, acc_group_pct, how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_asmt_sessions['accuracy'] = ((train_asmt_sessions['correct']) / (train_asmt_sessions['correct'] + train_asmt_sessions['incorrect'])).fillna(0)\ntest_asmt_sessions['accuracy'] = ((test_asmt_sessions['correct']) / (test_asmt_sessions['correct'] + test_asmt_sessions['incorrect'])).fillna(0)\n\ntrain_asmt_sessions['_prev_asmt_accuracy'] = train_asmt_sessions.groupby(['installation_id'], sort=False)['accuracy'].shift(1)\ntest_asmt_sessions['_prev_asmt_accuracy'] = test_asmt_sessions.groupby(['installation_id'], sort=False)['accuracy'].shift(1)\n\ntrain_asmt_sessions['_prev_title_accuracy'] = train_asmt_sessions.groupby(['installation_id','title'], sort=False)['accuracy'].shift(1)\ntest_asmt_sessions['_prev_title_accuracy'] = test_asmt_sessions.groupby(['installation_id','title'], sort=False)['accuracy'].shift(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## accuracy by title"},{"metadata":{"trusted":true},"cell_type":"code","source":"key_cols = ['installation_id', 'game_session']\n\nsubset = pd.concat([train_asmt_sessions, test_asmt_sessions])\nlast_asmt_sessions = test_asmt_sessions.drop_duplicates(subset=['installation_id'], keep='last')[key_cols] # test only\nlast_asmt_sessions['last_session'] = 1\nsubset = pd.merge(subset, last_asmt_sessions, on=key_cols, how='left')\nsubset['last_session'].fillna(0, inplace=True)\nsubset = subset[subset['last_session'] != 1]\ndel last_asmt_sessions\nsubset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cappa 0.36\naggmap = {\n    'accuracy': ['mean','std'],\n    'correct': ['mean','std'],\n    'incorrect': ['mean','max','std']\n}\ntitle_asmt = subset.groupby(['title']).agg(aggmap)\ntitle_asmt.columns = [x[0] if not x[1] else f\"_{x[1]}_title_{x[0]}\" for x in title_asmt.columns]\ntitle_asmt = title_asmt.reset_index()\n\ntrain_asmt_sessions = pd.merge(train_asmt_sessions, title_asmt, on=['title'], how='left')\ntest_asmt_sessions = pd.merge(test_asmt_sessions, title_asmt, on=['title'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cappa 0.38\nacc_cumcnt_title_pct = subset.groupby(['title','_cumcount_inst_title']).apply(lambda x: x['accuracy_group'].value_counts(normalize=True)).unstack()\nacc_cumcnt_title_pct.columns = [f'_pct_title_acc_group_{i}' for i in range(4)]\nacc_cumcnt_title_pct = acc_cumcnt_title_pct.reset_index()\n\ntrain_asmt_sessions = pd.merge(train_asmt_sessions, acc_cumcnt_title_pct, how='left')\ntest_asmt_sessions = pd.merge(test_asmt_sessions, acc_cumcnt_title_pct, how='left')\n\ndel acc_cumcnt_title_pct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## cappa 0\nacc_onehot = pd.get_dummies(train_asmt_sessions['accuracy_group'], prefix='_cumsum_inst_acc_group')\ntrain_inst_acc_onehot = train_asmt_sessions[['installation_id']].join(acc_onehot)\ntrain_asmt_sessions = train_asmt_sessions.join(train_inst_acc_onehot.groupby(['installation_id'], sort=False).cumsum() - acc_onehot)\nfor c in acc_onehot.columns:\n    train_asmt_sessions['_pct' + c] = train_asmt_sessions[c] / train_asmt_sessions[acc_onehot.columns].sum(axis=1)\n\nacc_onehot = pd.get_dummies(test_asmt_sessions['accuracy_group'], prefix='_cumsum_inst_acc_group')\ntest_inst_acc_onehot = test_asmt_sessions[['installation_id']].join(acc_onehot)\ntest_asmt_sessions = test_asmt_sessions.join(test_inst_acc_onehot.groupby(['installation_id'], sort=False).cumsum() - acc_onehot)\nfor c in acc_onehot.columns:\n    test_asmt_sessions['_pct' + c] = test_asmt_sessions[c] / test_asmt_sessions[acc_onehot.columns].sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## time durations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## cappa 0.42\ntrain_asmt_sessions['_diff_asmt_seconds'] = train_asmt_sessions.groupby(['installation_id'], sort=False)['timestamp'].diff().dt.seconds\ntest_asmt_sessions['_diff_asmt_seconds'] = test_asmt_sessions.groupby(['installation_id'], sort=False)['timestamp'].diff().dt.seconds\n\ntime_diff = pd.Series(train_sessions.groupby(['installation_id'], sort=False)['timestamp'].diff().dt.seconds, name='_diff_session_seconds')\ntrain_time_diff = train_sessions[['installation_id','game_session']].join(time_diff)\ntrain_asmt_sessions = pd.merge(train_asmt_sessions, train_time_diff, how='left')\n\ntime_diff = pd.Series(test_sessions.groupby(['installation_id'], sort=False)['timestamp'].diff().dt.seconds, name='_diff_session_seconds')\ntest_time_diff = test_sessions[['installation_id','game_session']].join(time_diff)\ntest_asmt_sessions = pd.merge(test_asmt_sessions, test_time_diff, how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['_diff_game_time'] = train.groupby(['installation_id','game_session'], sort=False)['game_time'].diff()\ntrain.loc[train['type'] == 'Assessment', '_diff_game_time'] = 0\ntrain['_isnot_diff'] = (train['_diff_game_time'] != 0).astype(int)\n\ntest['_diff_game_time'] = test.groupby(['installation_id','game_session'], sort=False)['game_time'].diff()\ntest.loc[test['type'] == 'Assessment', '_diff_game_time'] = 0\ntest['_isnot_diff'] = (test['_diff_game_time'] != 0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## cappa 0.44\ncol_name = '_cummean_diff_event_seconds'\n\ntime_cummean = train.groupby(['installation_id'], sort=False)['_diff_game_time'].cumsum()\ntime_cummean = (time_cummean - train['_diff_game_time']) / train.groupby(['installation_id'], sort=False)['_isnot_diff'].cumsum()\nsubset = train[['installation_id','game_session']].join(pd.Series(time_cummean,name=col_name)).drop_duplicates(subset=['installation_id','game_session'], keep='last')\ntrain_asmt_sessions = pd.merge(train_asmt_sessions, subset, how='left')\n\ntime_cummean = test.groupby(['installation_id'], sort=False)['_diff_game_time'].cumsum()\ntime_cummean = (time_cummean - test['_diff_game_time']) / test.groupby(['installation_id'], sort=False)['_isnot_diff'].cumsum()\nsubset = test[['installation_id','game_session']].join(pd.Series(time_cummean,name=col_name)).drop_duplicates(subset=['installation_id','game_session'], keep='last')\ntest_asmt_sessions = pd.merge(test_asmt_sessions, subset, how='left')\n\ndel time_cummean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train, test, df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## aggregate by installation"},{"metadata":{"trusted":true},"cell_type":"code","source":"## cappa 0.41 + 0.04 = 0.45\n\ngroup_cols = ['installation_id','game_session','type']\n\nsubset = train_sessions.groupby(group_cols, sort=False)['game_session'].count().unstack().fillna(0)\nsubset = subset.groupby(['installation_id'], sort=False).cumsum()\nsubset.columns = [f\"_cumcount_inst_type_{x}\" for x in subset.columns]\ntrain_inst_cumsum = subset.reset_index()\n\nsubset = test_sessions.groupby(group_cols, sort=False)['game_session'].count().unstack().fillna(0)\nsubset = subset.groupby(['installation_id'], sort=False).cumsum()\nsubset.columns = [f\"_cumcount_inst_type_{x}\" for x in subset.columns]\ntest_inst_cumsum = subset.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## cappa 0.41\n\ndef diff_inst(df, cols, prefix='_is_diff_prev'):\n    pick_cols = ['installation_id','game_session']\n    subset = df[pick_cols + cols]\n    for col in cols:\n        subset[f'_prev_{col}'] = subset.groupby(['installation_id'], sort=False)[col].shift(1)\n        subset[f'{prefix}_{col}'] = (subset[col] != subset[f'_prev_{col}']).astype(int)\n        subset.drop([col, f'_prev_{col}'], axis=1, inplace=True)\n    return subset\n\n# subset = diff_inst(train_sessions, ['type','title'])\n# train_inst_sessions = pd.merge(train_inst_cumsum, subset, how='left')\n\n# subset = diff_inst(test_sessions, ['type','title'])\n# test_inst_sessions = pd.merge(test_inst_cumsum, subset, how='left')\n\n\n# train_inst_sessions['_cumsum_inst_diff_title'] = train_inst_sessions.groupby(['installation_id'], sort=False)['_is_diff_prev_title'].cumsum()\n# train_inst_sessions['_cumsum_inst_diff_title'] -= train_inst_sessions['_is_diff_prev_title']\n# test_inst_sessions['_cumsum_inst_diff_title'] = test_inst_sessions.groupby(['installation_id'], sort=False)['_is_diff_prev_title'].cumsum()\n# test_inst_sessions['_cumsum_inst_diff_title'] -= test_inst_sessions['_is_diff_prev_title']\n\n\nsubset = diff_inst(train_asmt_sessions, ['title'], prefix='_is_diff_prev_asmt')\ntrain_inst_sessions = pd.merge(train_inst_cumsum, subset, how='left')\n\nsubset = diff_inst(test_asmt_sessions, ['title'], prefix='_is_diff_prev_asmt')\ntest_inst_sessions = pd.merge(test_inst_cumsum, subset, how='left')\n\ndel train_inst_cumsum, test_inst_cumsum\ndel train_sessions, test_sessions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_asmt_sessions = pd.merge(train_asmt_sessions, train_inst_sessions, on=['installation_id','game_session'], how='left')\ntest_asmt_sessions = pd.merge(test_asmt_sessions, test_inst_sessions, on=['installation_id','game_session'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_inst_sessions, test_inst_sessions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_asmt_sessions[[c for c in train_asmt_sessions.columns if c not in event_codes]].head().sort_values(by=['installation_id','timestamp']).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_asmt_sessions.copy()\nX_test = test_asmt_sessions.copy()\n\nkey_cols = ['installation_id','game_session']\ntest_last_asmt_sessions = test_asmt_sessions.drop_duplicates(subset=['installation_id'], keep='last')[key_cols]\ntest_last_asmt_sessions['last_session'] = 1\nX_test = pd.merge(X_test, test_last_asmt_sessions, on=key_cols, how='left')\n\nX_train.append(X_test[X_test['last_session'] != 1].drop(['last_session'], axis=1))\nX_test = X_test[X_test['last_session'] == 1].drop(['last_session'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, bins = pd.qcut(X_train['_cumcount_inst_type_Assessment'], 5, retbins=True)\nbins[5] = np.inf\n\nX_train['_cumcount_inst_asmt_bin'] = pd.Series(pd.factorize(pd.cut(X_train['_cumcount_inst_type_Assessment'], bins=bins))[0], index=X_train.index)\nX_test['_cumcount_inst_asmt_bin'] = test_asmt_group = pd.Series(pd.factorize(pd.cut(X_test['_cumcount_inst_type_Assessment'], bins=bins))[0], index=X_test.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_group = X_train['installation_id']\nsubmission = X_test[['installation_id']]\n\ny_train_org = X_train.pop('accuracy_group')\ny_train = np.abs(y_train_org - 3) # for regression\n#y_train = y_train_org\nX_test = X_test.drop('accuracy_group', axis=1)\n\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = [\n    'installation_id',\n    'game_session',\n    'type',\n    'game_time',\n    'timestamp',\n    'event_count',\n    'accuracy',\n    'correct',\n    'incorrect'\n]\n\nfor col in X_train.columns.values:\n    counts = X_train[col].value_counts().iloc[0]\n    if (counts / X_train.shape[0]) >= 0.99:\n        drop_cols.append(col)\n\nX_train.drop(drop_cols, inplace=True, axis=1)\nX_test.drop(drop_cols, inplace=True, axis=1)\n    \ndrop_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sort([c for c in X_train.columns if c not in event_codes]).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndel train_asmt_sessions, test_asmt_sessions\n'''\n\ngc.collect()\n\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nenc_cols = []\nfor f, t in X_train.dtypes.iteritems():\n    if t == object:\n        enc_cols.append(f)\n        le = LabelEncoder()\n        le.fit(list(set(X_train[f].unique()).union(set(X_test[f].unique()))))\n        X_train[f] = le.transform(X_train[f].values).astype(int)\n        X_test[f] = le.transform(X_test[f].values).astype(int)\nprint(enc_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from numba import jit\nfrom functools import partial\nimport scipy as sp\n\n@jit\ndef qwk(a1, a2):\n    max_rat = 3\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n        return -qwk(y, X_p)\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n\n    def coefficients(self):\n        return self.coef_['x']\n\n\ndef div_by_sum(x):\n    return x / x.sum()\n\n\ndef print_divider(text):\n    print('\\n---------- {} ----------\\n'.format(text))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\nfrom collections import Counter\n\ndef eval_qwk_lgb_regr(y_true, y_pred):\n    y_pred = y_pred.get_label()\n    \"\"\"\n    Fast cappa eval function for lgb.\n    \"\"\"\n    dist = Counter(y_train)\n    for k in dist:\n        dist[k] /= len(y_train)\n    \n    acum = 0\n    bound = {}\n    for i in range(3):\n        acum += dist[i]\n        bound[i] = np.percentile(y_pred, acum * 100)\n\n    def classify(x):\n        if x <= bound[0]:\n            return 0\n        elif x <= bound[1]:\n            return 1\n        elif x <= bound[2]:\n            return 2\n        else:\n            return 3\n\n    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n\n    return 'cappa', qwk(y_true, y_pred), True\n#    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter, defaultdict\nfrom sklearn.utils import check_random_state\n\nclass RepeatedStratifiedGroupKFold():\n\n    def __init__(self, n_splits=5, n_repeats=1, random_state=None):\n        self.n_splits = n_splits\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        \n    # Implementation based on this kaggle kernel:\n    #    https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\n    def split(self, X, y=None, groups=None):\n        k = self.n_splits\n        def eval_y_counts_per_fold(y_counts, fold):\n            y_counts_per_fold[fold] += y_counts\n            std_per_label = []\n            for label in range(labels_num):\n                label_std = np.std(\n                    [y_counts_per_fold[i][label] / y_distr[label] for i in range(k)]\n                )\n                std_per_label.append(label_std)\n            y_counts_per_fold[fold] -= y_counts\n            return np.mean(std_per_label)\n            \n        rnd = check_random_state(self.random_state)\n        for repeat in range(self.n_repeats):\n            labels_num = np.max(y) + 1\n            y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n            y_distr = Counter()\n            for label, g in zip(y, groups):\n                y_counts_per_group[g][label] += 1\n                y_distr[label] += 1\n\n            y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n            groups_per_fold = defaultdict(set)\n        \n            groups_and_y_counts = list(y_counts_per_group.items())\n            rnd.shuffle(groups_and_y_counts)\n\n            for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n                best_fold = None\n                min_eval = None\n                for i in range(k):\n                    fold_eval = eval_y_counts_per_fold(y_counts, i)\n                    if min_eval is None or fold_eval < min_eval:\n                        min_eval = fold_eval\n                        best_fold = i\n                y_counts_per_fold[best_fold] += y_counts\n                groups_per_fold[best_fold].add(g)\n\n            all_groups = set(groups)\n            for i in range(k):\n                train_groups = all_groups - groups_per_fold[i]\n                test_groups = groups_per_fold[i]\n\n                train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n                test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n\n                yield train_indices, test_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold,StratifiedKFold,GroupKFold\nfrom sklearn.model_selection import StratifiedShuffleSplit,GroupShuffleSplit,TimeSeriesSplit\n\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'rmse',\n    #'eval_metric': 'cappa',\n    'learning_rate': 0.005,\n    'bagging_fraction': 0.90,\n    'feature_fraction': 0.75,\n    #'random_state': 42,\n}\n\nfit_params = {\n    'num_boost_round': 5000,\n    'verbose_eval': 1000,\n    'early_stopping_rounds': 100,\n}\n\nfi_split = np.zeros(X_train.shape[1])\nfi_gain = np.zeros(X_train.shape[1])\noof_pred = np.zeros(len(X_train))\npred_test = np.zeros(len(X_test))\ncoff_avg = np.zeros(3)\npred_n = np.zeros(len(X_train))\n\nNTIMES=5\nNFOLDS=5\n\n#for t in range(NTIMES):\nfor t in range(1):\n    print_divider(f'Time: {t+1}')\n\n    fold_enums = [\n        ('RepeatedStratifiedGroupKFold', list(RepeatedStratifiedGroupKFold(n_splits=NFOLDS, n_repeats=NTIMES).split(X_train, y_train, groups=train_group)))\n        #('StratifiedKFold', StratifiedKFold(n_splits=NFOLDS, shuffle=True).split(X_train, y_train)),\n        #('StratifiedShuffleSplit', StratifiedShuffleSplit(n_splits=NFOLDS).split(X_train, y_train)),\n        #('GroupKFold', GroupKFold(n_splits=NFOLDS).split(X_train, groups=train_group)),\n        #('GroupShuffleSplit', GroupShuffleSplit(n_splits=NFOLDS).split(X_train, groups=train_group)),\n        #('TimeSeriesSplit', TimeSeriesSplit(n_splits=NFOLDS).split(X_train, groups=train_asmt_group))\n    ]\n    \n    for fold_enum in fold_enums:\n        print_divider(f'{fold_enum[0]}')\n    \n        for fold_idx, (idx_trn, idx_val) in enumerate(fold_enum[1]):\n\n            print_divider(f'Fold: {fold_idx+1}')\n            n = len(fold_enums) * NTIMES * NFOLDS\n\n            X_trn, X_val = X_train.iloc[idx_trn], X_train.iloc[idx_val]\n            y_trn, y_val = y_train[idx_trn], y_train[idx_val]\n\n            d_trn = lgb.Dataset(X_trn, y_trn)\n            d_val = lgb.Dataset(X_val, y_val)\n            model = lgb.train(params, d_trn,\n                              valid_sets=[d_trn, d_val],\n                              valid_names=['train', 'valid'],\n                              #feval=eval_qwk_lgb_regr, \n                              categorical_feature=enc_cols,\n                              **fit_params)\n            fi_split += div_by_sum(model.feature_importance(importance_type='split')) / n\n            fi_gain += div_by_sum(model.feature_importance(importance_type='gain')) / n\n            pred_train = model.predict(X_trn)\n            pred_test += model.predict(X_test) / n\n            \n            oof_pred[idx_val] += model.predict(X_val)\n            pred_n[idx_val] += 1\n\n            optr = OptimizedRounder()\n            optr.fit(pred_train, y_trn)\n            coff_avg += optr.coefficients() / n\n            print('\\nround coefficients:', optr.coefficients())\n\n            del X_trn, y_trn, X_val, y_val\n            gc.collect()\n\nfeature_importances = pd.DataFrame()\n#feature_importances['feature'] = np.array(model.feature_name())\nfeature_importances['feature'] = np.array(X_train.columns)\nfeature_importances['average_split'] = fi_split\nfeature_importances['average_gain'] = fi_gain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_pred_round = optr.predict(oof_pred / pred_n, coff_avg)\nqwk(y_train, oof_pred_round)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_='''\nsub_preds = optr.predict(pred_test, coff_avg)\n'''\ndist = Counter(y_train)\nfor k in dist:\n    dist[k] /= len(y_train)\n\nacum = 0\nbound = {}\nfor i in range(3):\n    acum += dist[i]\n    bound[i] = np.percentile(pred_test, acum * 100)\nprint(bound)\n\ndef classify(x):\n    if x <= bound[0]:\n        return 0\n    elif x <= bound[1]:\n        return 1\n    elif x <= bound[2]:\n        return 2\n    else:\n        return 3\n    \nsub_preds = np.array(list(map(classify, pred_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances.sort_values(by='average_split', ascending=False, inplace=True)\nplt.figure(figsize=(12, 10))\nsns.barplot(data=feature_importances.head(30), x='average_split', y='feature')\nplt.title('TOP feature importance');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['accuracy_group'] = np.abs(sub_preds.astype('int') - 3)  # reverse regression value\n#submission['accuracy_group'] = sub_preds.astype('int')\nsubmission.to_csv('submission.csv', index=False)\n\nfig, ax = plt.subplots(1, 2, figsize=(13,4))\n\ny_train_org.value_counts().plot.bar(title='y_train', ax=ax[0])\nsubmission['accuracy_group'].value_counts().plot.bar(title='predict', ax=ax[1], color='limegreen')\nsubmission['accuracy_group'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}