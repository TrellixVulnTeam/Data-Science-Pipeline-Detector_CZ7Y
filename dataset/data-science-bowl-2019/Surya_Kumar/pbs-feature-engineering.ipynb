{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/pbs-eda/data_with_label\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df[df['world']==\"'TREETOPCITY'\"]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['world','type','timestamp','game_session','event_id','Unnamed: 0','installation_id','event_code'],axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\nimport statistics\ndef game_time(df1):\n    game_avg_time=[]\n    for i in range(df1.shape[0]):\n        game_avg_time.append(statistics.mean(ast.literal_eval(df1.iloc[i])))\n    return game_avg_time\ndef min_max(df1):\n    game_min_time=[]\n    game_max_time=[]\n    for i in range(df1.shape[0]):\n        temp=ast.literal_eval(df1.iloc[i])\n        game_min_time.append(min(temp))\n        game_max_time.append(max(temp))\n    return  game_min_time,game_max_time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['game_avg_time']=game_time(df['game_time'])\ndf['event_count_avg']=game_time(df['event_count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['game_start'],df['game_end']=min_max(df['game_time'])\ndf['event_count_min'],df['event_count_max']=min_max(df['event_count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['event_data','event_count','game_time'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\ndef normalize(X):\n    min_max_scaler = MinMaxScaler()\n    X_train_minmax = min_max_scaler.fit_transform(X)\n    return X_train_minmax\nfor i in ['num_correct','num_incorrect','game_avg_time','event_count_avg', 'game_start', 'game_end', 'event_count_min','event_count_max']:\n    df[i]=normalize(df[i].values.reshape(-1, 1))\n    df[i]=normalize(df[i].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.drop(['accuracy_group'],axis=1),df['accuracy_group'],test_size=0.33, stratify=df['accuracy_group'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe=OneHotEncoder()\nohe=ohe.fit(X_train.title.values.reshape(-1,1))\nohe_train=ohe.transform(X_train.title.values.reshape(-1,1)).toarray()\nohe_test=ohe.transform(X_test.title.values.reshape(-1,1)).toarray()\nohe_train_df=pd.DataFrame(ohe_train,columns=['Mushroom Sorter (Assessment)','Bird Measurer (Assessment)'])\nohe_test_df=pd.DataFrame(ohe_test,columns=['Mushroom Sorter (Assessment)','Bird Measurer (Assessment)'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=pd.concat([X_train,ohe_train_df],axis=1)\nX_test=pd.concat([X_test,ohe_train_df],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train.drop(['title'],axis=1)\nX_test=X_test.drop(['title'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nmnb = MultinomialNB(class_prior = [0.5, 0.5])\nparam={'alpha':[0.0001,0.001,0.01,0.1,1,10,100,1000]}\nclf=GridSearchCV(mnb,param,cv=3,scoring='roc_auc',return_train_score=True,n_jobs=-1)\nclf.fit(X_train,y_train)\nresult=pd.DataFrame.from_dict(clf.cv_results_)\nresult=result.sort_values(['param_alpha'])\ntrainauc=result['mean_train_score']\ntrainaucstd=result['std_train_score']\ncvauc=result['mean_test_score']\ncvaucstd=result['std_test_score']\nK=result['param_alpha']\nfor i in range(len(K)):\n K[i]=np.log10(K[i])\nplt.plot(K,trainauc,label='Train AUC')\nplt.plot(K,cvauc,label=\"CV AUC\")\nplt.scatter(K,trainauc,label='Train AUC Points')\nplt.scatter(K,cvauc,label='CV AUC Points')\nplt.legend()\nplt.xlabel(\"Alpha: hyperparametr\")\nplt.ylabel(\"AUC\")\nplt.title(\"Hyper parameter Vs AUC plot (Bag of words)\")\nplt.grid()\nplt.show()\nresult.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}