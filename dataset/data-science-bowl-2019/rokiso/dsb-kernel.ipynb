{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Regressors and Classification by Optimal Rounding\n**■Classification steps**<BR>\n**Step 1** Create Regressor Models : Create multiple train_datasets using `kFold` and create a regression model from each dataset. I used ** CatBoost **, ** XGBoost **, ** LightGBM **.<BR>\n**Step 2** Predict each Model<BR>\n**Step 3** Optimize Rounding Coefficients : The rounding coefficient is optimized using the average value of the prediction results of each model. Optimization uses `scipy.optimize.minimize()`.<BR>\n**Step 4** Final Classification"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os, sys\nimport datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.metrics import cohen_kappa_score\nimport category_encoders as ce\n\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom functools import partial\nimport scipy as sp              # for optimize.minimize()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Execution environment setting\nKaggle = True\n\nif Kaggle:\n    DIR = '../input/data-science-bowl-2019'\n    task_type = 'CPU'\nelse:\n    DIR = './data-science-bowl-2019'\n    task_type = 'GPU'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observe the data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv(os.path.join(DIR,'train.csv'))\n#train_labels = pd.read_csv(os.path.join(DIR,'train_labels.csv'))\n#specs = pd.read_csv(os.path.join(DIR,'specs.csv'))\ntest = pd.read_csv(os.path.join(DIR,'test.csv'))\n#media_seq = pd.read_csv(os.path.join('../input/dsb2019-external-data','media_sequence.csv'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#print('train:\\t\\t',train.shape)\n#print('train_labels:\\t',train_labels.shape)\n#print('specs:\\t\\t',specs.shape)\n#print('test:\\t\\t',test.shape)\n#print('media_seq:\\t\\t',media_seq.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. train"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#event_code_n = train['event_code'].nunique()\n#print(\"num of unique 'event_code':\", event_code_n)\n#print(\"'event_code': \",\n#      train['event_code'].min(), \"-\", train['event_code'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 'event_data' exsample\n#print(train['event_data'][40])\n#print(train['event_data'][41])\n#print(train['event_data'][43])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. train_labels"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#train_labels[['game_session','installation_id', 'title']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# unique 'title' list\n#train_labels['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. specs"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#specs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#specs.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 'info' exsample\n#print(specs['info'][0],'\\n')\n#print(specs['info'][6],'\\n')\n#print(specs['info'][7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 'args' exsample\n#print(specs['args'][0],'\\n')\n#print(specs['args'][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. test"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#test.head(8)\n#test['world'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#test[['event_id','game_session','installation_id',\n#       'title','type','world']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#' malke 'title' and 'event_code' list\ntitle_list = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\nevent_code_list = list(set(train['event_code'].value_counts().index).union(set(test['event_code'].value_counts().index)))\nevent_id_list = list(set(train['event_id'].value_counts().index).union(set(test['event_id'].value_counts().index)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make dict 'title to number(integer)'\ntitle2num = dict(zip(title_list, np.arange(len(title_list))))\n# meke dict 'number to title'\nnum2title = dict(zip(np.arange(len(title_list)), title_list))\n\n# meke dict 'title to win event_code'\n# (4100 except 'Bird Measurer' and 4110 for 'Bird Measurer')\ntitle2win_code = dict(zip(title2num.values(), (np.ones(len(title2num))).astype('int') * 4100))\ntitle2win_code[title2num['Bird Measurer (Assessment)']] = 4110","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert 'title to the number'\ntrain['title']  = train['title'].map(title2num)\ntest['title'] = test['title'].map(title2num)\n#train_labels['title'] = train_labels['title'].map(title2num)\n\n#Convert 'timestamp' to datetime\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(train['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = train[train['installation_id'].isin(train_labels['installation_id'].unique())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clip_time = {'Welcome to Lost Lagoon!':19,'Tree Top City - Level 1':17,'Ordering Spheres':61, 'Costume Box':61,\n        '12 Monkeys':109,'Tree Top City - Level 2':25, 'Pirate\\'s Tale':80, 'Treasure Map':156,'Tree Top City - Level 3':26,\n        'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18,\n        'Balancing Act':72, 'Lifting Heavy Things':118,'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19,\n        'Heavy, Heavier, Heaviest':61}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#user_sample = train[train['installation_id']=='0006a69f']\n#user_sample.head()\n#session = user_sample[user_sample['game_session'] == '2b9d5af79bcdb79f']\n#session.head()\n#num2title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clip_time[num2title[session.title.iloc[0]]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def agr_session(user_sample):\n    '''\n    user_sample : DataFrame from train/test group by 'installation_id'\n    '''\n    session_agr = []\n\n    for i, session in user_sample.groupby(['game_session'],sort = False):\n        session = session.sort_values('timestamp')\n        event_code_count = {code:0 for code in event_code_list}\n        event_codes = Counter(session['event_code'])\n        for key in event_codes.keys():\n            event_code_count[key] += event_codes[key]\n        session_grp = event_code_count.copy()\n        \n        event_id_count = {code:0 for code in event_id_list}\n        event_ids = Counter(session['event_id'])\n        for key in event_ids.keys():\n            event_id_count[key] += event_ids[key]\n        session_grp.update(event_id_count.copy())\n\n        session_grp['installation_id'] = session['installation_id'].iloc[0]\n        session_grp['game_session'] = session['game_session'].iloc[0]\n        session_title = session['title'].iloc[0]  # Game/Assessment/Activity/Clip\n        session_grp['title'] = session_title\n        session_type = session['type'].iloc[0]  # Game/Assessment/Activity/Clip\n        session_grp['type'] = session_type\n        session_grp['world'] = session['world'].iloc[0]\n        session_grp['timestamp_st'] = session.iloc[0,2]\n        session_grp['timestamp_en'] = session.iloc[-1,2]\n        session_grp['event_count'] = len(session)\n        if session_type == 'Clip':\n            session_grp['game_time_sum'] = clip_time[num2title[session_title]]*1000\n        else:\n            session_grp['game_time_sum'] = session['game_time'].iloc[-1]\n        game_time_diff = session['game_time'].diff(1)\n        game_time_diff_nonzero = game_time_diff[game_time_diff!=0][~game_time_diff.isnull()]\n        session_grp['game_time_nonzeros'] = len(game_time_diff_nonzero)\n        #session_grp['game_time_ave'] = game_time_diff.mean(skipna=True)\n        #session_grp['game_time_ave_nonzero'] = game_time_diff_nonzero.mean(skipna=True)\n        #session_grp['game_time_max'] = game_time_diff.max()\n        #session_grp['game_time_min_nonzero'] = game_time_diff_nonzero.min()\n        #session_grp['game_time_std'] = game_time_diff.std()\n        #session_grp['game_time_std_nonzero'] = game_time_diff_nonzero.std()\n        \n        if session_type == 'Assessment':\n            #search for event_code 4100(4110)\n            all_4100 = session.query(f'event_code == {title2win_code[session_title]}')\n            #numbers of win and losses\n            time_to_first_ans = all_4100['game_time'].min()\n            time_to_final_ans = all_4100['game_time'].max()\n            win_n = all_4100['event_data'].str.contains('true').sum()\n            loss_n = all_4100['event_data'].str.contains('false').sum()\n            accuracy = (win_n)/ (win_n + loss_n) if (win_n + loss_n) > 0 else 0\n            \n            if accuracy == 0:\n                accuracy_group = 0\n            elif accuracy == 1:\n                accuracy_group = 3\n            elif accuracy == 0.5:\n                accuracy_group = 2\n            else:\n                accuracy_group = 1\n\n        else:\n            time_to_first_ans = np.nan\n            time_to_final_ans = np.nan\n            win_n = np.nan\n            loss_n = np.nan\n            accuracy = np.nan\n            accuracy_group = np.nan\n        \n        session_grp['time_to_first_ans'] = time_to_first_ans\n        session_grp['time_to_final_ans'] = time_to_final_ans\n        session_grp['win_n'] = win_n\n        session_grp['loss_n'] = loss_n  \n        session_grp['accuracy'] = accuracy\n        session_grp['accuracy_group'] = accuracy_group\n        \n        session_agr.append(session_grp) \n    return session_agr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get_data function is applyed to each installation_id\ncompiled_data = []\ninstallation_n = train['installation_id'].nunique()\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby( \\\n                                     'installation_id', sort=False)),\n                                     total=installation_n):\n    # user_sample : DataFrame group by 'installation_id'\n    compiled_data += agr_session(user_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train\ntrain_agr = pd.DataFrame(compiled_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process test set, the same that was done with the train set\ncompiled_data = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id',sort=False),\n                                total=1000):\n    compiled_data += agr_session(user_sample)    \ntest_agr = pd.DataFrame(compiled_data)\ndel compiled_data\ndel test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ase = train_agr[train_agr['type']=='Assessment']\n#ase = ase[ase['installation_id']=='0006a69f']\n#e7e7db2a241eadcc\n#assess_hist = ase.iloc[0:2]\n#print(assess_hist)\n#assess_info = ase.iloc[1]\n#assess_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#assess_hist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#same_assess = assess_hist[assess_hist['title']==assess_info['title']]\n#\n#assess_hist['title']==assess_info['title']\n#same_assess = same_assess[same_assess['timestamp_st']<assess_info['timestamp_st']]\n#len(same_assess)\n#train_labels[train_labels['game_session']=='e7e7db2a241eadcc']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#types_count = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n#ase = train_agr[train_agr['type']=='Assessment']\n\n#user_sample = train_agr[train_agr['installation_id']=='0006a69f']\n#user_sample = user_sample.sort_values('timestamp_st')\n#assessment_inst = user_sample[user_sample['type']=='Assessment']\n#assess_time =assessment_inst.timestamp_st.iloc[0]\n#assess_sample = user_sample[user_sample['timestamp_st'] <= assess_time]\n#assess_sample = assess_sample.sort_values('timestamp_st')\n#assess_sample = assess_sample[assess_sample['timestamp_st'] < assess_time]\n\n#assess_sample\n#ase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#assess_sample[assess_sample['type']=='Activity'].event_count.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def change_dic_key(d,old_key,new_key,default_value=None):\n#    d[new_key] = d.pop(old_key,default_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#types_count = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n#for key in list(types_count.keys()):\n#    types_count[key+'_count'] = types_count[key]\n#    del types_count[key]\n#types_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(user_sample,train_set = True):\n    prep_data = []\n    user_sample = user_sample.sort_values('timestamp_st')\n   # print(user_sample.installation_id.iloc[0])\n    assessment_inst = user_sample[user_sample['type']=='Assessment']\n    accumu_accuracy_group = 0\n    accumu_accuracy=0\n    accumu_win_n = 0 \n    accumu_loss_n = 0 \n    counter=0\n    accuracy_groups = {0.0:0, 1.0:0, 2.0:0, 3.0:0}\n    durations = []\n    for assess_time in assessment_inst['timestamp_st']:\n        #print(assess_time)\n        assess_sample = user_sample[user_sample['timestamp_st'] <= assess_time]\n        assess_sample = assess_sample.sort_values('timestamp_st')\n\n        time_spent_each_title = {title:0 for title in title_list}\n        event_code_count = {code:0 for code in event_code_list}\n        event_id_count = {code:0 for code in event_id_list}\n        types_time = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n        world_time = {'MAGMAPEAK':0, 'NONE':0, 'CRYSTALCAVES':0, 'TREETOPCITY':0}\n        types_count = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n        world_count = {'MAGMAPEAK':0, 'NONE':0, 'CRYSTALCAVES':0, 'TREETOPCITY':0}\n        \n        assess_hist = assess_sample[assess_sample['type']=='Assessment']\n        assess_info = assess_hist.iloc[-1]\n        assess_count = len(assess_hist)\n        assess_sample = assess_sample[assess_sample['timestamp_st'] < assess_time]\n        for key in event_code_count.keys():\n            event_code_count[key] = assess_sample[key].sum()\n        for key in event_id_count.keys():\n            event_id_count[key] = assess_sample[key].sum()\n        for key in types_count.keys():\n            types_count[key] = assess_sample[assess_sample['type']==key].event_count.sum()\n        for key in list(types_count.keys()):\n            types_count[key+'_count'] = types_count[key]\n            del types_count[key]\n      \n        for key in world_count.keys():\n            world_count[key] = assess_sample[assess_sample['world']==key].event_count.sum()\n        for key in list(world_count.keys()):\n            world_count[key+'_count'] = world_count[key]\n            del world_count[key]\n\n        assess_sample = user_sample[user_sample['timestamp_st'] <= assess_time]\n        features = event_code_count.copy()\n        features.update(event_id_count.copy())\n        features.update(types_count.copy())\n        features.update(world_count.copy())\n        #features['installation_id'] = assess_info['installation_id']\n        features['title'] = assess_info['title']\n        features['world'] = assess_info['world']\n        features['assess_count'] = assess_count\n        features['unique_assess'] = assess_hist.title.nunique()\n        features['unique_title'] = assess_sample.title.nunique()\n        features['unique_world'] = assess_sample.world.nunique()\n        \n        features['dayofweek'] = assess_info['timestamp_st'].dayofweek\n        #features['weekofyear'] = assess_info['timestamp_st'].weekofyear\n        #features['month'] = assess_info['timestamp_st'].month\n        #features['day'] = assess_info['timestamp_st'].day\n        features['hour'] = assess_info['timestamp_st'].hour\n        #features['time_to_asess'] = (assess_sample['timestamp_st'].iloc[-1] - assess_sample['timestamp_st'].iloc[0]).seconds\n        interval = assess_sample['timestamp_st'].shift(-1)-assess_sample['timestamp_en']\n        t_seconds = lambda x: x.seconds\n        interval = interval.map(t_seconds)\n        if len(interval)==1:\n            interval_before_assess=0\n        else:\n            interval_before_assess=interval.iloc[-2]\n        \n        #features['interval_before_assess'] = interval_before_assess\n        features['interval_ave'] = interval.mean()\n        features['interval_min'] = interval.min()\n        features['interval_max'] = interval.max()\n\n        assess_sample = assess_sample[assess_sample['timestamp_st'] < assess_time]\n        features['session_count'] = len(assess_sample)\n        features['event_count_mean'] = assess_sample[assess_sample['event_count']>1]['event_count'].mean()\n        features['event_count_max'] = assess_sample[assess_sample['event_count']>1]['event_count'].max()\n        features['event_count_min'] = assess_sample[assess_sample['event_count']>1]['event_count'].min()\n        features['event_count_std'] = assess_sample[assess_sample['event_count']>1]['event_count'].std()\n        features['accum_actions'] = assess_sample.event_count.sum()\n        features['accum_game_time'] = assess_sample.game_time_sum.sum()\n        features['game_time_nonzero_count'] = assess_sample.game_time_nonzeros.sum()\n        \n        \n        game_time_title = assess_sample.groupby(['title'])['game_time_sum'].sum()\n        for key in game_time_title.keys():\n            time_spent_each_title[num2title[key]] += game_time_title[key]\n        features.update(time_spent_each_title.copy())\n        game_time_type = assess_sample.groupby(['type'])['game_time_sum'].sum()\n        for key in game_time_type.keys():\n            types_time[key] = game_time_type[key]\n        features.update(types_time.copy())\n\n        game_time_world = assess_sample.groupby(['world'])['game_time_sum'].sum()\n        for key in game_time_world.keys():\n            world_time[key] = game_time_world[key]\n        features.update(world_time.copy())\n        \n        features['accumu_win_n'] = accumu_win_n\n        features['accumu_loss_n'] = accumu_loss_n\n        accumu_win_n += assess_info['win_n']\n        accumu_loss_n += assess_info['loss_n']\n        \n        features.update(accuracy_groups)\n        #if (np.isnan(accuracy_groups[assess_info['accuracy_group']]))==False:\n        accuracy_groups[assess_info['accuracy_group']] += 1\n        features['accuracy_ave'] = accumu_accuracy / counter \\\n                                                if counter > 0 else 0\n        accumu_accuracy += assess_info['accuracy']\n        features['accuracy_group_ave'] = \\\n                    accumu_accuracy_group / counter if counter > 0 else 0\n        accumu_accuracy_group +=  assess_info['accuracy_group']\n        counter +=1\n        \n        if durations == []:\n            features['duration_mean'] = 0\n            features['duration_std'] = 0\n            features['duration_max'] = 0\n        else:\n            features['duration_mean'] = np.mean(durations)\n            features['duration_mean'] = np.std(durations)\n            features['duration_max'] = np.max(durations)\n\n        durations.append(assess_info['game_time_sum'])\n        \n        if assess_count > 1:\n            last_title = assess_hist['title'].iloc[-2]\n            last_win_n = assess_hist['win_n'].iloc[-2]\n            last_loss_n = assess_hist['loss_n'].iloc[-2]\n            last_accuracy = assess_hist['accuracy'].iloc[-2]\n            last_accuracy_group = assess_hist['accuracy_group'].iloc[-2]\n            interval_from_last_assess = ( assess_hist['timestamp_st'].iloc[-1] - assess_hist['timestamp_st'].iloc[-2] ).seconds\n        else:\n            last_title = np.nan\n            last_win_n = np.nan\n            last_loss_n = np.nan\n            last_accuracy = np.nan\n            last_accuracy_group = np.nan\n            interval_from_last_assess = np.nan\n\n        features['last_title'] = last_title\n        features['last_win_n'] = last_win_n\n        features['last_loss_n'] = last_loss_n\n        features['last_accuracy'] = last_accuracy\n        features['last_accuracy_group'] = last_accuracy_group\n        #features['interval_from_last_assess'] = interval_from_last_assess\n\n        #features['same_accuracy_ave']=0\n        #features['same_accuracy_max']=0\n        #features['same_accuracy_min']=0\n        features['same_accuracy_try']=0\n        features['same_accuracy_game_time']=0\n        features['same_accuracy_event_count']=0\n        if len(assess_hist)>1:\n            same_assess = assess_hist[assess_hist['title']==assess_info['title']]\n            same_assess = same_assess[same_assess['timestamp_st']<assess_info['timestamp_st']]\n            if len(same_assess)>0:\n                #features['same_accuracy_ave']=same_assess.accuracy.mean()\n                #features['same_accuracy_max']=same_assess.accuracy.max()\n                #features['same_accuracy_min']=same_assess.accuracy.min()\n                features['same_accuracy_try']=len(same_assess)\n                features['same_accuracy_game_time']=same_assess.game_time_sum.sum()\n                features['same_accuracy_event_count']=same_assess.event_count.sum()\n\n        \n        if train_set:\n            features['accuracy_group'] = assess_info['accuracy_group']\n        if train_set==False or (assess_info['win_n'] + assess_info['loss_n']) > 0:\n            prep_data.append(features)\n\n    if train_set==False:\n        return prep_data[-1]\n    return prep_data\n#features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data = preprocess_data(user_sample)\n#train_data.head()\ninstallation_n = train_agr['installation_id'].nunique()\ntrain_data = []\nfor ins_id, user_sample in tqdm(train_agr.groupby('installation_id',sort=False),\n                                total=installation_n):\n    train_data += preprocess_data(user_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data = pd.DataFrame(train_data)\n#train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.DataFrame(train_data)\ndel train_agr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby('accuracy_group').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process test set, the same that was done with the train set\ntest_data = []\nfor ins_id, user_sample in tqdm(test_agr.groupby('installation_id',sort=False),\n                                total=1000):\n    #print(user_sample.installation_id.iloc[0])\n    test_data.append(preprocess_data(user_sample,train_set = False))\ntest_data = pd.DataFrame(test_data)\n#del test_agr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all_features but 'accuracy_group', that is the label y\nall_features = [x for x in train_data.columns if x not in ['accuracy_group']]\n# categorical feature\ncategorical_features = ['world']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#object_cols = train_data.columns[train_data.dtypes == 'object']\n#for object_col in object_cols:\n#    train_data[object_col] = train_data[object_col].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_agr[test_agr['type']=='Assessment'].head(30)\n#user_sample = test_agr[test_agr['installation_id']=='12771ee9']\n#user_sample = user_sample.sort_values('timestamp_st')\n#assessment_inst = user_sample[user_sample['type']=='Assessment']\n\n#print(assessment_inst)\n \n#test_agr[test_agr['type']=='Assessment'].iloc[1]['accuracy_group'].isnan()\n#aa['accuracy_group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concatnate train and test data\ntemp_df = pd.concat([train_data[all_features], test_data[all_features]])\n#temp_df = temp_df.drop('day',axis=1)\n\n# encode\nencoder = ce.ordinal.OrdinalEncoder(cols = categorical_features)\ntemp_df = encoder.fit_transform(temp_df)\n#tarain_data = encoder.fit_transform(train_data)\n# dataset\nX, y = temp_df.iloc[:len(train_data),:], train_data['accuracy_group']\n#X, y = train_data[all_features], train_data['accuracy_group']\nX_test = temp_df.iloc[len(train_data):,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create multiple datasets to create multiple models (not for CV).\nNFOLDS = 5\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n#groups = X.installation_id\n#folds = GroupKFold(n_splits=NFOLDS)\n#X = X.drop('installation_id',axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM\nstart_time = time()\nlgb_models = []\nscores = []\n\nparams = {\n    'n_jobs': -1,\n    'seed': 42,\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n#     'num_iteration': 100,           # add\n    'metric': 'rmse',\n#     'eval_metric': 'cappa',\n    'feature_fraction':0.998495,    # add\n    'bagging_fraction': 0.872417,   # mod 0.8→, = subsample\n    'learning_rate': 0.02,\n    'feature_fraction': 0.9,        #   = colsample_bytree\n    'max_depth': 13,                # mod 10→\n    'num_leaves': 1028,             # mod   # 2^max_depth < num_leaves\n    'min_gain_to_split':0.085502,   # add\n    'min_child_weight':1.087712,    # add\n    'lambda_l1': 1,  \n    'lambda_l2': 1,\n    'verbose': 100,\n}\n\n# Train and make models\nfor fold, (train_ids, val_ids) in enumerate(folds.split(X,y)):\n#for fold, (train_ids, val_ids) in enumerate(folds.split(X,y,groups)):\n    print('● Fold :', fold+1,'/',NFOLDS)\n    train_set = lgb.Dataset(X.iloc[train_ids], y.iloc[train_ids],\n                           categorical_feature=categorical_features)\n    val_set = lgb.Dataset(X.iloc[val_ids], y.iloc[val_ids],\n                         categorical_feature=categorical_features)\n    model = lgb.train(params=params,\n                      train_set=train_set,\n                      valid_sets=[train_set, val_set],\n                      num_boost_round=5000,\n                      early_stopping_rounds=100,    # del\n                      verbose_eval=200\n                     )\n    lgb_models.append(model)\n    \nprint('\\nTime:', time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance  = pd.DataFrame(model.feature_importance(),index = train_set.feature_name, columns=['importance']).sort_values(by =  'importance',ascending=False)\nimportance[0:50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 15))\nlgb.plot_importance(model, max_num_features=50, ax=ax, importance_type='gain') # 'gaiのn'他に'split'がある。","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp = model.feature_importance(importance_type='gain') # importancをenumpy arrayで受け取る\nth =500\nuse_col = X.columns[imp > th]\nX = X[use_col]\nX_test = X_test[use_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM\nstart_time = time()\nlgb_models = []\nscores = []\n\nparams = {\n    'n_jobs': -1,\n    'seed': 42,\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n#     'num_iteration': 100,           # add\n    'metric': 'rmse',\n#     'eval_metric': 'cappa',\n    'feature_fraction':0.998495,    # add\n    'bagging_fraction': 0.872417,   # mod 0.8→, = subsample\n    'learning_rate': 0.02,\n    'feature_fraction': 0.9,        #   = colsample_bytree\n    'max_depth': 13,                # mod 10→\n    'num_leaves': 1028,             # mod   # 2^max_depth < num_leaves\n    'min_gain_to_split':0.085502,   # add\n    'min_child_weight':1.087712,    # add\n    'lambda_l1': 1,  \n    'lambda_l2': 1,\n    'verbose': 100,\n}\n\n# Train and make models\nfor fold, (train_ids, val_ids) in enumerate(folds.split(X,y)):\n#for fold, (train_ids, val_ids) in enumerate(folds.split(X,y,groups)):\n    print('● Fold :', fold+1,'/',NFOLDS)\n    train_set = lgb.Dataset(X.iloc[train_ids], y.iloc[train_ids],\n                           categorical_feature=categorical_features)\n    val_set = lgb.Dataset(X.iloc[val_ids], y.iloc[val_ids],\n                         categorical_feature=categorical_features)\n    model = lgb.train(params=params,\n                      train_set=train_set,\n                      valid_sets=[train_set, val_set],\n                      num_boost_round=5000,\n                      early_stopping_rounds=100,    # del\n                      verbose_eval=200\n                     )\n    lgb_models.append(model)\n    \nprint('\\nTime:', time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 15))\nlgb.plot_importance(model, max_num_features=50, ax=ax, importance_type='gain') # 'gaiのn'他に'split'がある。\n#use = test[test['installation_id']=='00abaee7']\n#use[use['type']=='Assessment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process test set, the same that was done with the train set\n#installation_n = train['installation_id'].nunique()\n#train_agr = pd.DataFrame()\n#for ins_id, user_sample in tqdm(train.groupby('installation_id',sort=False),\n#                                total=installation_n):\n#    train_agr = train_agr.append(agr_session(user_sample))\n#user_sample = train[train['installation_id']=='0006a69f']\n#train_agr = agr_session(user_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process test set, the same that was done with the train set\n#test_agr = pd.DataFrame()\n#for ins_id, user_sample in tqdm(test.groupby('installation_id',sort=False),\n#                                total=1000):\n#    test_agr = test_agr.append(agr_session(user_sample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data = preprocess_data(user_sample)\n#train_data.head()\n#installation_n = train_agr['installation_id'].nunique()\n#train_data = pd.DataFrame()\n#for ins_id, user_sample in tqdm(train_agr.groupby('installation_id',sort=False),\n#                                total=installation_n):\n#    train_data = train_data.append(preprocess_data(user_sample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_data = pd.DataFrame()\n#for ins_id, user_sample in tqdm(test_agr.groupby('installation_id',sort=False),\n#                                total=1000):\n#    test_data = test_data.append(preprocess_data(user_sample,False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create multiple datasets to create multiple models (not for CV).\n#NFOLDS = 5\n#folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\nstart_time = time()\nxgb_models = []\nscores = []\n\nparams = {\n    'max_depth': 9,                 # 6           # mod 10→9\n    'learning_rate': 0.01,          # = eta 0.1: [0,1]\n    'objective': 'reg:linear',                    # add\n    'n_estimators' : 300,           # 100\n    'subsample': 0.6,               # 1, (0,1]    # mod 0.8→0.6\n    'colsample_bytree': 1.0,        # 1, (0, 1]   # mod 0.8→1.0\n    'gamma': 0.0,                                 # add\n    'min_child_weight': 5,                        # add\n    'seed' : 42,\n}\n\n# Train and make models\nfor fold, (train_ids, val_ids) in enumerate(folds.split(X,y)):\n    print('● Fold :', fold+1,'/',NFOLDS)\n    dtrain = xgb.DMatrix(X.iloc[train_ids], y[train_ids])\n    dval = xgb.DMatrix(X.iloc[val_ids], y[val_ids])\n    model = xgb.train(params=params,\n                      dtrain=dtrain,\n                      num_boost_round=5000,\n                      evals=[(dtrain, 'train'), (dval, 'val')],\n                      early_stopping_rounds=100,\n                      verbose_eval=100\n                     )\n    xgb_models.append(model)\n    \nprint('Time:', time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# makes the model and set the parameters\ndef make_CatBoost(task_type):\n    model = CatBoostRegressor(\n        iterations=5000,\n        learning_rate=0.02,\n        loss_function='RMSE',\n        random_seed=42,\n        depth=10,                            # add\n        border_count=108,                    # add\n        bagging_temperature=2.348502,        # add\n        task_type=task_type,\n        early_stopping_rounds=200\n    )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CatBoost\nstart_time = time()\ncat_models = []\nscores = []\n\n# Train and make models\nfor fold, (train_ids, test_ids) in enumerate(folds.split(X, y)):\n    print('● Fold :', fold+1,'/',NFOLDS)\n    model = make_CatBoost(task_type)\n    #model.fit(X.loc[train_ids, all_features], y.loc[train_ids], \n    #          eval_set=(X.loc[test_ids, all_features], y.loc[test_ids]),\n    model.fit(X.loc[train_ids, use_col], y.loc[train_ids], \n              eval_set=(X.loc[test_ids, use_col], y.loc[test_ids]),\n              use_best_model=False,\n              verbose=500,\n              cat_features=categorical_features)    \n    cat_models.append(model)\n    \nprint('Time:', time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\n\n# CatBoost models\nfor model in cat_models:\n    pred = model.predict(X)\n    preds.append(pred)\n    \n# XGBoost models\nfor model in xgb_models:\n    pred = model.predict(xgb.DMatrix(X))\n    pred = pred.flatten()\n    preds.append(pred)\n    \n# LightGBM models\nfor model in lgb_models:\n    pred = model.predict(X,num_iteration=model.best_iteration)\n    pred = pred.reshape(len(X),1).flatten()\n    preds.append(pred)\n\ndf = pd.DataFrame(preds).T\ndf.columns = ['C1','C2','C3','C4','C5',   # CatBoost\n              'X1','X2','X3','X4','X5',   # XGBoost\n              'L1','L2','L3','L4','L5']   # LightGBM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the average value of each model pred\ndf['mean'] = df.mean(axis = 'columns')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class OptRounder(object):\n    def __init__(self):\n        self.res_ = []\n        self.coef_ = []\n        \n    def get_res(self):\n        return self.res_\n    \n    # objective function\n    def func(self, coef, X, y):\n        kappa = cohen_kappa_score(self.bincut(coef, X), y,\n                                  weights='quadratic')\n        return -kappa\n\n    def bincut(self, coef, X):\n        return pd.cut(X,\n                      [-np.inf] + list(np.sort(coef)) + [np.inf],\n                      labels = [0, 1, 2, 3])\n        \n    def fit(self, X, y):\n        pfunc = partial(self.func, X=X, y=y)\n        self.res_ = sp.optimize.minimize(fun = pfunc,           # objective func\n                                         x0 = [0.6, 1.5, 2.4],  # initial coef\n                                         method='nelder-mead')  # solver\n        self.coef_ = self.res_.x\n        \n    def predict(self, X, coef):\n        return self.bincut(coef, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptRounder()\noptR.fit(df['mean'].values.reshape(-1,), y)\nres = optR.get_res()        # Optimized result\n\nprint('●Iterations performed\\t:',res.nit)\nprint('●Optimized coefficients\\t:',res.x)\nprint('●Cohen Kappa score\\t:',-res.fun)\n\ncoefficients = res.x        # Optimized coefficients","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# final classification\ndf['predict'] = optR.predict(df['mean'].values, coefficients).astype(int)\n\ndf['y'] = y\ndf[['mean','predict','y']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['mean','predict','y']].plot(subplots=True,layout=(1, 3),\n                                figsize=(11, 3),kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# binning plot of 'pred' versus 'y'\ndf.plot.hexbin(x='y', y='predict', gridsize=(3,3),\n               sharex=False, title = \"binning 'pred' vs 'y'\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nfor model in cat_models:        # CatBoost\n    pred = model.predict(X_test)\n    preds.append(pred)\nfor model in xgb_models:        # XGBoost\n    pred = model.predict(xgb.DMatrix(X_test))\n    pred = pred.flatten()\n    preds.append(pred)\nfor model in lgb_models:        # LightGBM\n    pred = model.predict(X_test,num_iteration=model.best_iteration)\n    pred = pred.reshape(len(X_test),1).flatten()\n    preds.append(pred)\ndf_s = pd.DataFrame(preds).T\n\ndf_s['mean'] = df_s.mean(axis = 'columns')\n\n# Classification\ndf_s['pred'] = optR.predict(df_s['mean'].values, coefficients).astype(int)\n\nprint(df_s.shape)\ndf_s[['mean','pred']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s[['mean','pred']].plot(subplots=True, layout=(1, 2),\n                           figsize=(7, 3), kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\nsubmission['accuracy_group'] = df_s['pred']\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compile data\nBased on several kernels\n- Hosseinali: https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model\n- Bruno Aquino: https://www.kaggle.com/braquino/catboost-some-more-features"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Convert the raw data into processed features\n#def get_data(user_sample, test_set=False):\n#    '''\n#    user_sample : DataFrame from train/test group by 'installation_id'\n#    test_set    : related with the labels processing\n#    '''\n    # Constants and parameters declaration\n#    user_assessments = []\n#    last_type = 0\n#    types_count = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n#    time_first_activity = float(user_sample['timestamp'].values[0])\n#    time_spent_each_title = {title:0 for title in title_list}\n#    event_code_count = {code:0 for code in event_code_list}\n#    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    \n#    accumu_accuracy_group = 0\n#    accumu_accuracy=0\n#    accumu_win_n = 0 \n#    accumu_loss_n = 0 \n#    accumu_actions = 0\n#    counter = 0\n#    durations = []\n    \n    # group by 'game_session'\n#    for i, session in user_sample.groupby('game_session', sort=False):\n        # i      : game_session_id\n        # session: DataFrame from user_sample group by 'game_session'\n#        session_type = session['type'].iloc[0]  # Game/Assessment/Activity/Clip\n#        session_title = session['title'].iloc[0]\n        \n#        if session_type != 'Assessment':\n#            time_spent = int(session['game_time'].iloc[-1] / 1000)   # [sec]\n#            time_spent_each_title[num2title[session_title]] += time_spent\n        \n#        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100(4110)\n#            all_4100 = session.query(f'event_code == \\\n#                                         {title2win_code[session_title]}')\n            # numbers of wins and losses\n#            win_n = all_4100['event_data'].str.contains('true').sum()\n#            loss_n = all_4100['event_data'].str.contains('false').sum()\n\n            # init features and then update\n#            features = types_count.copy()\n#            features.update(time_spent_each_title.copy())\n#            features.update(event_code_count.copy())\n#            features['session_title'] = session_title\n#            features['accumu_win_n'] = accumu_win_n\n#            features['accumu_loss_n'] = accumu_loss_n\n#            accumu_win_n += win_n\n#            accumu_loss_n += loss_n\n            \n#            features['day_of_the_week'] = (session['timestamp'].iloc[-1]). \\\n#                                            strftime('%A')    # Mod 2019-11-17\n\n#            if durations == []:\n#                features['duration_mean'] = 0\n#            else:\n#                features['duration_mean'] = np.mean(durations)\n#            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n\n            # average of the all accuracy of this player\n#            features['accuracy_ave'] = accumu_accuracy / counter \\\n#                                                if counter > 0 else 0\n#            accuracy = win_n / (win_n + loss_n) \\\n#                                   if (win_n + loss_n) > 0 else 0\n#            accumu_accuracy += accuracy\n#            if accuracy == 0:\n#                features['accuracy_group'] = 0\n#            elif accuracy == 1:\n#                features['accuracy_group'] = 3\n#            elif accuracy == 0.5:\n#                features['accuracy_group'] = 2\n#            else:\n#                features['accuracy_group'] = 1\n#            features.update(accuracy_groups)\n#            accuracy_groups[features['accuracy_group']] += 1\n            # average of accuracy_groups of this player\n#            features['accuracy_group_ave'] = \\\n#                    accumu_accuracy_group / counter if counter > 0 else 0\n#            accumu_accuracy_group += features['accuracy_group']\n            \n            # how many actions the player has done in this game_session\n#            features['accumu_actions'] = accumu_actions\n            \n            # if test_set, all sessions belong to the final dataset\n            # elif train, needs to be passed throught this clausule\n#            if test_set or (win_n + loss_n) > 0:\n#                user_assessments.append(features)\n                \n#            counter += 1\n        \n        # how many actions was made in each event_code\n#        event_codes = Counter(session['event_code'])\n#        for key in event_codes.keys():\n#            event_code_count[key] += event_codes[key]\n\n        # how many actions the player has done\n#        accumu_actions += len(session)\n#        if last_type != session_type:\n#            types_count[session_type] += 1\n#            last_type = session_type\n            \n    # if test_set, only the last assessment must be predicted,\n    # the previous are scraped\n#    if test_set:\n#        return user_assessments[-1]\n#    return user_assessments","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1 : Create Regressor Models\nCreate multiple train_datasets using `kFold` and create a regression model from each dataset. I used ** CatBoost **, ** XGBoost **, ** LightGBM **."},{"metadata":{},"cell_type":"markdown","source":"### - CatBoost"},{"metadata":{},"cell_type":"markdown","source":"### -XGBoost"},{"metadata":{},"cell_type":"markdown","source":"## Step 2 : Predict each Model"},{"metadata":{},"cell_type":"markdown","source":"## Step 3 : Optimize Rounding Coefficients\nThe rounding coefficient is optimized using the average value of the prediction results of each model. Optimization uses `scipy.optimize.minimize()`."},{"metadata":{},"cell_type":"markdown","source":"## Step 4 : Final Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# final classification\n#df['predict'] = optR.predict(df['mean'].values, coefficients).astype(int)\n\n#df['y'] = y\n#df[['mean','predict','y']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df[['mean','predict','y']].plot(subplots=True,layout=(1, 3),\n#                                figsize=(11, 3),kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# binning plot of 'pred' versus 'y'\n#df.plot.hexbin(x='y', y='predict', gridsize=(3,3),\n#               sharex=False, title = \"binning 'pred' vs 'y'\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = []\n#for model in cat_models:        # CatBoost\n#    pred = model.predict(X_test)\n#    preds.append(pred)\n#for model in xgb_models:        # XGBoost\n#    pred = model.predict(xgb.DMatrix(X_test))\n#    pred = pred.flatten()\n#    preds.append(pred)\n#for model in lgb_models:        # LightGBM\n#    pred = model.predict(X_test,num_iteration=model.best_iteration)\n#    pred = pred.reshape(len(X_test),1).flatten()\n#    preds.append(pred)\n#df_s = pd.DataFrame(preds).T\n\n#df_s['mean'] = df_s.mean(axis = 'columns')\n\n# Classification\n#df_s['pred'] = optR.predict(df_s['mean'].values, coefficients).astype(int)\n\n#print(df_s.shape)\n#df_s[['mean','pred']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_s[['mean','pred']].plot(subplots=True, layout=(1, 2),\n#                           figsize=(7, 3), kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\n#submission['accuracy_group'] = df_s['pred']\n#submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}