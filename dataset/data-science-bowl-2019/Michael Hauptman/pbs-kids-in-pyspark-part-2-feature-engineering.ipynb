{"cells":[{"metadata":{},"cell_type":"markdown","source":"<table><tr><td><img src=\"https://spark.apache.org/images/spark-logo-trademark.png\"></td><td><img src=\"https://bento.cdn.pbs.org/hostedbento-prod/blog/20170114_200556_794501_pk-channel-16x9.jpeg\"></td></tr></table>"},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"This is the second part of my attempt to conduct the kaggle competition on PBS Kids prediction in PySpark, focused on feature engineering. I've not attempted much innovation in approach, rather adapt another public notebooks: '890 features' www.kaggle.com/braquino/890-features by Bruno Aquino https://www.kaggle.com/braquino.\n\nAs per Bruno's approach, the feature engineering will preserve the session data for the sessions involving an assessment, plus record 'year to date' performance across all sessions including those without an assessment. \n\nRegarding, Pyspark has been much faster for feature engineering than for the investigation in Part 1, as there is much less instantiation which suit's Spark's lazy evaluation approach. It was difficult to compare timings versus the mainstream Python approach used by Bruno as I didn't follow his approach entirely. But the process of manually creating featues in Python as per Bruno's workbook took 4.5 minutes versus less than a minute in Pyspark, even running on a single laptop. And worth noting though that Bruno's approach suffers from using 'for' loops for things like summation across a window and one-hot encoding, which I suspect slows things compared to using the built-in windowing and encoding functions with scikitlearn. I've similalry tried to use Pyspark's functions for these tasks.\n\nOne challenge I found in using Spark here was avoiding a stack overrun when applying'window' functions to calculate 'year to date' performance - windows function really doesn't like high dimension dataframes. I've avoided this by replacing for loops with list comprehension in my execution plan.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#you will need to install pyspark as it isn't part of the standard kaggle environment.  Make sure you set internet on for this workbook\n!pip install pyspark\n!pip install spark_sklearn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport psutil\n        \n# Any results you write to the current directory are saved as output.\nfrom scipy.stats import skew,norm\nfrom scipy import stats\n\n\nfrom pyspark.sql import SparkSession, Window \nfrom pyspark.sql.functions import col,when,unix_timestamp,to_date,min,max,isnull,count,concat_ws,lit,sum,\\\ninstr,datediff\nfrom pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType,TimestampType,\\\nBooleanType,LongType,FloatType,DoubleType,ArrayType\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer,OneHotEncoderEstimator,VectorAssembler,MinMaxScaler\\\n,PCA\nfrom pyspark.sql.functions import udf,pandas_udf, PandasUDFType,to_date\n\nfrom pyspark.ml import Pipeline\nimport json\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport spark_sklearn\nfrom collections import Counter\nfrom scipy import stats\n\nimport pyspark.sql.functions as F\n\n\n\npd.set_option('display.max_columns', 1000)\npd.option_context('mode.use_inf_as_na', True)\n\n%pylab inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Initialise the Spark context\nos.environ[\"PYSPARK_PYTHON\"]=\"python3\"\nos.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n\n#NumCores=psutil.cpu_count(logical=False) #Not necessary to manually set number of workers, just for clarity\n\nSpark = SparkSession\\\n.builder\\\n.master('local[4]')\\\n.appName(\"PBS_Kids_Spark\")\\\n.config(\"spark.executor.memory\", \"4g\") \\\n.config(\"spark.driver.memory\", \"14g\") \\\n.config(\"spark.memory.offHeap.enabled\",True)\\\n.config(\"spark.memory.offHeap.size\",\"10g\")\\\n.config(\"spark.driver.maxResultSize\",0)\\\n.config(\"spark.sql.execution.arrow.enabled\",True)\\\n.getOrCreate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Load data to DataFrames\n\nTrainDf=Spark.read.csv('../input/data-science-bowl-2019/train.csv',header=True,quote='\"',escape='\"') #quote and escape options required to parse double quotes\nTrainlabelsDf=Spark.read.csv('../input/data-science-bowl-2019/train_labels.csv',header=True,quote='\"',escape='\"')\nTestDf=Spark.read.csv('../input/data-science-bowl-2019/test.csv',quote='\"',header=True,escape='\"')\n\n#Load smaller files as panda Dfs\nSpecsDf=pd.read_csv('../input/data-science-bowl-2019/specs.csv')\nsample_submissionDf=pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#getting rid of the installation_ids that never took an assessment.  We saw these in Part 1\nTrainDf.createOrReplaceTempView(\"Train\")\nkeepidDf=Spark.sql(f'SELECT installation_id from Train WHERE type=\"Assessment\"').dropDuplicates()\nkeepidDf.createOrReplaceTempView(\"keepid\")\nColumns=','.join(['Train.'+a for a in TrainDf.columns])\nTrainDf=Spark.sql(f'SELECT {Columns} from Train INNER JOIN keepid ON Train.installation_id=keepid.installation_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop rows wih na\nTrainDf=TrainDf.na.drop()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"''' I've limited the size of the dataframe as kaggle machines don't really have enough HDD storage (<5Gb) to support Spark as a head node.  \nEspecially when I use Pyarrow to save the feature dataframe to parquet.  Hopefully you have access to a more powerful PC and can remove this '''\nTrainDf=TrainDf.limit(1000000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create flags"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Add indentifying column to Test and Train dfs\nTestDf=TestDf.withColumn('TestOrTrain',lit(\"Test\"))\nTrainDf=TrainDf.withColumn('TestOrTrain',lit(\"Train\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#identify test records\nTestRecordsDf=TestDf.groupBy('installation_id').agg(F.last('timestamp').alias('timestamp'))\nTestRecordsDf=TestRecordsDf.withColumn('TestFlag',lit(1))\nTrainDf=TrainDf.withColumn('TestFlag',lit(0))\n\nTestDf.createOrReplaceTempView(\"Test\")\nTestRecordsDf.createOrReplaceTempView(\"TestRecords\")\n\nTestDf=Spark.sql(f'SELECT *, \\\nTest.installation_id as id1,Test.timestamp as ts1,\\\nTestRecords.installation_id,TestRecords.timestamp \\\nfrom Test LEFT JOIN TestRecords \\\nON Test.installation_id=TestRecords.installation_id \\\nAND Test.timestamp=TestRecords.timestamp')\\\n.drop('installation_id','timestamp')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('ts1','timestamp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#stack the test and train dataframes for combined operations\nTestDf=TestDf.select(TrainDf.columns) #ensur esame column order\nCombinedDf=TrainDf.union(TestDf).repartition(3) \n\n#concatenate the events and codes\nCombinedDf = CombinedDf.withColumn('title_event_code',concat_ws('_',CombinedDf.title,CombinedDf.event_code))\n\n#concatenate the world and event type\nCombinedDf = CombinedDf.withColumn('world_type',concat_ws('_',CombinedDf.world,CombinedDf.type))\n\n#String encode a number of fields via a pipeline\n# ColumnsToEncode=['title','world','type','event_code','event_id']\n# indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\",handleInvalid='skip')\\\n#              for column in ColumnsToEncode ]\n# EncodePipeline = Pipeline(stages=indexers)\n# CombinedDf = EncodePipeline.fit(CombinedDf).transform(CombinedDf)\n\n\n#Flag the assessment tasks\nCombinedDf=CombinedDf.withColumn('win_code',when(\\\n                     ((col('event_code')=='4100')\\\n                      & (F.instr(CombinedDf['title'],'(Assessment)')>0)\\\n                      &(col('title')!='Bird Measurer (Assessment)')   )\\\n                      |\n                     ((col('event_code')=='4110') & (col('title')=='Bird Measurer (Assessment)'))\\\n                      |\n                      (col('TestFlag')==1)                           \n                    ,1).otherwise(0))\n\n#For assessment tasks, indicate if pass or fail\nCombinedDf=CombinedDf.withColumn('true_attempts',when(\\\n                     (col('win_code')==1)&(F.instr(CombinedDf['event_data'],'true')>0)\\\n                    ,1).otherwise(0))\nCombinedDf=CombinedDf.withColumn('false_attempts',when(\\\n                     (col('win_code')==1)&(F.instr(CombinedDf['event_data'],'false')>0)\\\n                    ,1).otherwise(0))\n\n#convert timestamp from string\nCombinedDf=CombinedDf.withColumn('timestamp',unix_timestamp(col('timestamp')\\\n                                                             , \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\").cast(\"timestamp\"))\n\n#Flag if session type changes for each installation\nwindowval = Window.partitionBy('installation_id').orderBy('timestamp')\nCombinedDf=CombinedDf.withColumn(\"ChangeSession\", when(\\\n                                                       (col('type')!=F.lag(col('type'), 1, 0).over(windowval)),True\n                                                      )\\\n                                                    .otherwise(False))\n\n#Show chaged session type\nCombinedDf=CombinedDf.withColumn('typeChange',when(\\\n                     (col('ChangeSession')==True),col('type')).otherwise('Unchanged'))\n\n#Ensure key variables are the proper type\nCombinedDf=CombinedDf.withColumn('game_time',col('game_time').cast(LongType()))\n#Cache as we'll be using CombinedDf a lot\nCombinedDf.cache() \n\n\nCombinedDf.createOrReplaceTempView(\"Combined\")\n\n\n#create frame of the 4 assessment titles\nlist_of_assess_titlesDf=Spark.sql(f'SELECT title from Combined WHERE type=\"Assessment\"').dropDuplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#get game data\n\n@udf('int')\ndef json_attribute(data,attribute='misses'):\n    try:\n        result =json.loads(data)[attribute]\n    except:\n        result =-1\n    \n    return result\n\n@udf('int')\ndef json_conditional_attribute(data,attribute='round'):\n    try:\n        result =json.loads(data)[attribute]\n    except:\n        result =-1\n    \n    return result\n\n\ngameDf=CombinedDf.where(col('type')=='Game').where(col('event_code')=='2030')\\\n    .select('installation_id','timestamp','event_data')\ngameDf=gameDf.withColumn('misses_cnt',json_attribute(col('event_data'),lit('misses')))\ngameDf=gameDf.withColumn('game_round',json_conditional_attribute(col('event_data'),lit('round')))\ngameDf=gameDf.withColumn('game_level',json_conditional_attribute(col('event_data'),lit('level')))\ngameDf=gameDf.drop('event_data')\n\nCombinedDf.createOrReplaceTempView(\"Combined\")\ngameDf.createOrReplaceTempView(\"game\")\n\nCombinedDf=Spark.sql(f'SELECT *, \\\nCombined.installation_id as id1,Combined.timestamp as ts1,\\\ngame.installation_id,game.timestamp \\\nfrom Combined LEFT JOIN game \\\nON Combined.installation_id=game.installation_id \\\nAND Combined.timestamp=game.timestamp')\\\n.drop('installation_id','timestamp')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('ts1','timestamp')\n\n\nCombinedDf=CombinedDf.fillna(0, subset=['misses_cnt'])\nCombinedDf=CombinedDf.fillna(-1, subset=['game_round','game_level'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert the raw data into processed features"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Record number of Title-event code pair (essentially one-hot encoding)\nAllSessionTimingTEDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"title_event_code\").count().na.fill(0)\n\n#Record number of type-world pair\nAllSessionTimingTWDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"world_type\").count().na.fill(0)\n\n# #Record  number of  event codes\nAllSessionTimingECDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"event_code\").count().na.fill(0)\n\n# #Record  number of  titles\nAllSessionTimingTtlDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"title\").count().na.fill(0)\n\n#Record  number of  event id\nAllSessionTimingEIDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"event_id\").count().na.fill(0)\n\n#Record  number of  world\nAllSessionTimingWDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"world\").count().na.fill(0)\n\n#Record  number of  types\nAllSessionTimingTypDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"type\").count().na.fill(0)\n\n#Record  number of  type changes\nAllSessionTimingTypCDf=CombinedDf.groupBy(\"installation_id\",\"game_session\").pivot(\"typeChange\").count().na.fill(0)\n\nColumnNames= ['Activity', 'Assessment', 'Clip', 'Game']  #rename to avoid confustion with AllSessionTimingTypDf\nNewColumnNames={'Activity':'ActivityC', 'Assessment':'AssessmentC', 'Clip':'ClipC', 'Game':'GameC'}\nfor Column in ColumnNames:\n    AllSessionTimingTypCDf=AllSessionTimingTypCDf.withColumnRenamed(Column,NewColumnNames[Column])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Record all assessment attempts and results by world\nAssess_Titles=list_of_assess_titlesDf.toPandas()[['title']].values.tolist()\nAssess_Titles=[x[0] for x in Assess_Titles]\n\nAllAssessmentDf=CombinedDf.select(\"installation_id\",\"game_session\",\"title\",\\\n                                \"true_attempts\",\"false_attempts\",\"timestamp\",\"win_code\")\nfor Assess_Title in Assess_Titles:\n    AllAssessmentDf=AllAssessmentDf.withColumn(Assess_Title+'True',\\\n                                    when(col('title')==Assess_Title,col('true_attempts'))\\\n                                                 .otherwise(0).cast(IntegerType()))\n    AllAssessmentDf=AllAssessmentDf.withColumn(Assess_Title+'False',\\\n                                    when(col('title')==Assess_Title,col('false_attempts'))\\\n                                                 .otherwise(0).cast(IntegerType()))\n    AllAssessmentDf=AllAssessmentDf.withColumn(Assess_Title+'AllAttemps',\\\n                                    when(col('title')==Assess_Title,col('true_attempts')+col('false_attempts'))\\\n                                                 .otherwise(0).cast(IntegerType()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sum occurences and assessment results by installation id and session"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#First get some miscellaeous session informantion\n\nMiscSessionInfoDf=CombinedDf.groupBy(\"installation_id\",\"game_session\")\\\n.agg(count('event_id').alias('NumEvents')\\\n    ,F.sum('win_code').alias('NumAssessmentAttempts')\n    ,min('timestamp').alias('StartTime')\\\n    ,max('timestamp').alias('EndTime')\\\n#     ,F.first(col(\"title_index\")).alias('session_title')\\\n    ,F.first(col(\"title\")).alias('r_session_title')\\\n    ,F.first(col(\"TestFlag\")).alias('TestFlag')\\\n    ,F.first(col(\"TestOrTrain\")).alias('TestOrTrain')\\\n     ,F.first(col(\"game_round\")).alias('game_round')\\\n     ,F.first(col(\"game_level\")).alias('game_level')\\\n     ,F.first(col(\"misses_cnt\")).alias('misses_cnt')\\\n     ,F.first(col(\"type\")).alias('Type')\\\n     ,F.first(col(\"World\")).alias('World')\\\n    ,(F.unix_timestamp(F.max('timestamp'))-F.unix_timestamp(F.min('timestamp'))).alias('SessionDuration'))\nMiscSessionInfoDf=MiscSessionInfoDf.withColumn('hour',F.hour(col('StartTime')))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#insert clip durations\nclip_time = {'Welcome to Lost Lagoon!':19,'Tree Top City - Level 1':17,'Ordering Spheres':61, 'Costume Box':61,\n        '12 Monkeys':109,'Tree Top City - Level 2':25, 'Pirate\\'s Tale':80, 'Treasure Map':156,'Tree Top City - Level 3':26,\n        'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18,\n        'Balancing Act':72, 'Lifting Heavy Things':118,'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19,\n        'Heavy, Heavier, Heaviest':61}\n\n@udf('int')\ndef insert_clip_duration(Type,session_title,SessionDuration):\n    if Type=='Clip':\n        return clip_time[session_title]\n    else:\n        return SessionDuration\n    \n\nMiscSessionInfoDf=MiscSessionInfoDf.withColumn('SessionDuration',\\\n                                    insert_clip_duration(col('Type'),col('r_session_title'),col('SessionDuration'))\\\n                                               .cast(IntegerType()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#sum occurences for each title-event code pair across each session \nSessionTimingTEDf=AllSessionTimingTEDf.groupby(\"installation_id\",\"game_session\").sum()\n#sum occurences for each world-type pair across each session \nSessionTimingTWDf=AllSessionTimingTWDf.groupby(\"installation_id\",\"game_session\").sum()\n#Same for title\nSessionTimingTtlDf=AllSessionTimingTtlDf.groupby(\"installation_id\",\"game_session\").sum()\n#Same for event id\nSessionTimingEIDf=AllSessionTimingEIDf.groupby(\"installation_id\",\"game_session\").sum()\n#Same for world\nSessionTimingWDf=AllSessionTimingWDf.groupby(\"installation_id\",\"game_session\").sum()\n#Same for type\nSessionTimingTypDf=AllSessionTimingTypDf.groupby(\"installation_id\",\"game_session\").sum()\n#Same for type change\nSessionTimingTypCDf=AllSessionTimingTypCDf.groupby(\"installation_id\",\"game_session\").sum()\n#Same for event code\nSessionTimingECDf=AllSessionTimingECDf.groupby(\"installation_id\",\"game_session\").sum()\n\n#Join the 7 occurence dataframes\nSessionTimingTEDf.createOrReplaceTempView(\"SessionTimingTE\")\nSessionTimingTWDf.createOrReplaceTempView(\"SessionTimingTW\")\nSessionTimingTtlDf.createOrReplaceTempView(\"SessionTimingTtl\")\nSessionTimingEIDf.createOrReplaceTempView(\"SessionTimingEI\")\nSessionTimingWDf.createOrReplaceTempView(\"SessionTimingW\")\nSessionTimingTypDf.createOrReplaceTempView(\"SessionTimingTyp\")\nSessionTimingTypCDf.createOrReplaceTempView(\"SessionTimingTypC\")\nSessionTimingECDf.createOrReplaceTempView(\"SessionTimingEC\")\nMiscSessionInfoDf.createOrReplaceTempView(\"MiscSessionInfo\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTimingTE.installation_id as id1,SessionTimingTE.game_session as gs1,\\\nSessionTimingTtl.installation_id,SessionTimingTtl.game_session \\\nfrom SessionTimingTE INNER JOIN SessionTimingTtl \\\nON SessionTimingTE.installation_id=SessionTimingTtl.installation_id \\\nAND SessionTimingTE.game_session=SessionTimingTtl.game_session')\\\n.drop('installation_id','game_session')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTiming.installation_id as id1,SessionTiming.game_session as gs1,\\\nSessionTimingTW.installation_id,SessionTimingTW.game_session \\\nfrom SessionTiming INNER JOIN SessionTimingTW \\\nON SessionTiming.installation_id=SessionTimingTW.installation_id \\\nAND SessionTiming.game_session=SessionTimingTW.game_session')\\\n.drop('installation_id','game_session')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTiming.installation_id as id1,SessionTiming.game_session as gs1,\\\nSessionTimingEI.installation_id,SessionTimingEI.game_session \\\nfrom SessionTiming INNER JOIN SessionTimingEI \\\nON SessionTiming.installation_id=SessionTimingEI.installation_id \\\nAND SessionTiming.game_session=SessionTimingEI.game_session')\\\n.drop('installation_id','game_session')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTiming.installation_id as id1,SessionTiming.game_session as gs1,\\\nSessionTimingW.installation_id,SessionTimingW.game_session \\\nfrom SessionTiming INNER JOIN SessionTimingW \\\nON SessionTiming.installation_id=SessionTimingW.installation_id \\\nAND SessionTiming.game_session=SessionTimingW.game_session')\\\n.drop('installation_id','game_session')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTiming.installation_id as id1,SessionTiming.game_session as gs1,\\\nSessionTimingTyp.installation_id,SessionTimingTyp.game_session \\\nfrom SessionTiming INNER JOIN SessionTimingTyp \\\nON SessionTiming.installation_id=SessionTimingTyp.installation_id \\\nAND SessionTiming.game_session=SessionTimingTyp.game_session')\\\n.drop('installation_id','game_session','agame_session','aid')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTiming.installation_id as id1,SessionTiming.game_session as gs1,\\\nSessionTimingTypC.installation_id,SessionTimingTypC.game_session \\\nfrom SessionTiming INNER JOIN SessionTimingTypC \\\nON SessionTiming.installation_id=SessionTimingTypC.installation_id \\\nAND SessionTiming.game_session=SessionTimingTypC.game_session')\\\n.drop('installation_id','game_session','agame_session','aid')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTiming.installation_id as id1,SessionTiming.game_session as gs1,\\\nSessionTimingEC.installation_id,SessionTimingEC.game_session \\\nfrom SessionTiming INNER JOIN SessionTimingEC \\\nON SessionTiming.installation_id=SessionTimingEC.installation_id \\\nAND SessionTiming.game_session=SessionTimingEC.game_session')\\\n.drop('installation_id','game_session','agame_session','aid')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")\n\nSessionTimingDf=Spark.sql(f'SELECT *, \\\nSessionTiming.installation_id as id1,SessionTiming.game_session as gs1,\\\nMiscSessionInfo.installation_id,MiscSessionInfo.game_session \\\nfrom SessionTiming INNER JOIN MiscSessionInfo \\\nON SessionTiming.installation_id=MiscSessionInfo.installation_id \\\nAND SessionTiming.game_session=MiscSessionInfo.game_session')\\\n.drop('installation_id','game_session','agame_session','aid')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionTimingDf.createOrReplaceTempView(\"SessionTiming\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Get running total of duration and assessments across installations and sessions"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwindowval = Window.partitionBy('installation_id').orderBy('StartTime')\n\n# get cumulative lag timings\nColumnsToSum=['SessionDuration']+SessionTimingDf.columns[:-14]+['misses_cnt']#Don't include key columns in summations\nlag_summed_cols = [F.sum(F.lag(col(Column), 1).over(windowval)).over(windowval).alias(Column+'LagCum') \\\n                     for Column in ColumnsToSum]#lag one session to avoid double counting cumulative and current session\n\nsession_title_cols=list(SessionTimingTtlDf.columns)[2:]\nmissing_cols = [x for x in SessionTimingDf.columns if x not in ColumnsToSum+session_title_cols]\\\n                        +['SessionDuration','misses_cnt']\n\n\nSessionTimingCumDf=SessionTimingDf.select(missing_cols+lag_summed_cols+session_title_cols).na.fill(0)\n\n#Get the start time of previous session:\nSessionTimingCumDf=SessionTimingCumDf\\\n.withColumn('PreviousSessStart',F.lag(col('StartTime'), 1).over(windowval))\n\n# get time since last session\nSessionTimingCumDf=SessionTimingCumDf\\\n.withColumn('TimeSinceLastSess'\\\n           ,F.unix_timestamp(col('StartTime'))-F.unix_timestamp(col('PreviousSessStart'))).na.fill(100000)\n\n# get cumulative count of sessions since last session\nSessionTimingCumDf=SessionTimingCumDf\\\n.withColumn(\"NumSessionsLagCum\", F.count(col('game_session')).over(windowval))\n\n\n\n#get rolling average duration\nSessionTimingCumDf=SessionTimingCumDf.withColumn('duration_lag_mean',\\\n                                    (col('SessionDurationLagCum')/col('NumSessionsLagCum')))\n\n#get rolling average #events\nSessionTimingCumDf=SessionTimingCumDf.withColumn('numevents_lag_mean',\\\n                                    (col('NumEventsLagCum')/col('NumSessionsLagCum')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#get some data on assessment sessions only\nAssessmentsDf=SessionTimingCumDf.filter((col('NumAssessmentAttempts')>0))\nAssessmentsDf=AssessmentsDf.withColumn('AssessmentDurationLag',F.lag(col('SessionDuration'), 1).over(windowval))\\\n            .na.fill(-1)\n\nAssessmentsDf=AssessmentsDf.select('installation_id','game_session','AssessmentDurationLag')\n\n#join the dataframes\nSessionTimingCumDf.createOrReplaceTempView(\"SessionTimingCum\")\nAssessmentsDf.createOrReplaceTempView(\"Assessments\")\n\nSessionTimingCumDf=Spark.sql(f'SELECT *, \\\nSessionTimingCum.installation_id as id1,SessionTimingCum.game_session as gs1,\\\nAssessments.installation_id,Assessments.game_session \\\nfrom SessionTimingCum LEFT JOIN Assessments \\\nON SessionTimingCum.installation_id=Assessments.installation_id \\\nAND SessionTimingCum.game_session=Assessments.game_session')\\\n.drop('installation_id','game_session','agame_session','aid')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#sum duration by type\nTypes=['Activity','Assessment','Clip','Game']\nfor Type in Types:\n    SessionTimingCumDf=SessionTimingCumDf.withColumn(Type+'Dur',\\\n                                when(col('Type')==Type,col('SessionDuration'))\\\n                                             .otherwise(0).cast(IntegerType()))\n#Get cum lag duration    \nColumnsToSum=[Type+'Dur' for Type in Types]#Don't include key columns in summations\nlag_summed_cols = [F.sum(F.lag(col(Column), 1).over(windowval)).over(windowval).alias(Column+'LagCum') \\\n                     for Column in ColumnsToSum]\n\n#get lag cum mean\nlag_mean_cols = [F.avg(F.lag(col(Column), 1).over(windowval)).over(windowval).alias(Column+'LagMean') \\\n                     for Column in ColumnsToSum]\n\n#get lag stddev\nlag_std_cols = [F.stddev(F.lag(col(Column), 1).over(windowval)).over(windowval).alias(Column+'LagStd') \\\n                     for Column in ColumnsToSum]\n\n#get lag max\nlag_max_cols = [F.max(F.lag(col(Column), 1).over(windowval)).over(windowval).alias(Column+'Lagmax') \\\n                     for Column in ColumnsToSum]\n\nSessionTimingCumDf=SessionTimingCumDf.select(SessionTimingCumDf.columns\\\n            +lag_summed_cols+lag_mean_cols+lag_std_cols+lag_max_cols).na.fill(0)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#get game data\nSessionTimingCumDf=SessionTimingCumDf.withColumn('game_missMeanLag',F.avg(F.lag(col('misses_cnt'), 1)\\\n                                    .over(windowval)).over(windowval)).na.fill(0)   \nSessionTimingCumDf=SessionTimingCumDf.withColumn('game_missStdLag',F.stddev(F.lag(col('misses_cnt'), 1)\\\n                                    .over(windowval)).over(windowval)).na.fill(0)    \n\nColumnsToLag=['game_round', 'game_level','misses_cnt']\nlag_cols = [F.lag(col(Column), 1).over(windowval).alias(Column+'Lag') \\\n                     for Column in ColumnsToLag]\nSessionTimingCumDf=SessionTimingCumDf.select(SessionTimingCumDf.columns+lag_cols)\nLaggedCols=[i+'Lag' for i in ColumnsToLag]\nSessionTimingCumDf=SessionTimingCumDf.fillna(-1, subset=LaggedCols)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#do the same for assessment data\nAssessmentDf=AllAssessmentDf.groupby(\"installation_id\",\"game_session\").sum()\nMiscAssessmentInfoDf=MiscSessionInfoDf.select(\"installation_id\",\"game_session\"\\\n                                              ,'StartTime','NumAssessmentAttempts')\n\nAssessmentDf.createOrReplaceTempView(\"Assessment\")\nMiscAssessmentInfoDf.createOrReplaceTempView(\"MiscAssessmentInfo\")\nSessionAssessmentDf=Spark.sql(f'SELECT *, \\\nAssessment.installation_id as id1,Assessment.game_session as gs1,\\\nMiscAssessmentInfo.installation_id as aid,MiscAssessmentInfo.game_session as agame_session \\\nfrom Assessment INNER JOIN MiscAssessmentInfo \\\nON Assessment.installation_id=MiscAssessmentInfo.installation_id \\\nAND Assessment.game_session=MiscAssessmentInfo.game_session')\\\n.drop('installation_id','game_session','agame_session','aid')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\nSessionAssessmentDf.createOrReplaceTempView(\"SessionAssessment\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#get lagged assessments\nColumnsToAdd=list(SessionAssessmentDf.columns)[:-4]+['NumAssessmentAttempts']#Don't include key columns in summation\nlag_summed_cols = [F.sum(F.lag(col(Column), 1, 0).over(windowval)).over(windowval).alias(Column+'LagCum') \\\n                     for Column in ColumnsToAdd]#lag one session to avoid double counting cumulative and current session\nmissing_cols = [i for i in SessionAssessmentDf.columns if i not in ColumnsToAdd]\n\n\nSessionAccuracyDf=SessionAssessmentDf.select(missing_cols+ColumnsToAdd+lag_summed_cols).na.fill(-1)\n\n@pandas_udf('int', PandasUDFType.SCALAR)\ndef Count_Trues(Unq,World):\n    return Unq+World","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Get time since last assessment\n#Get the start time of previous session:\nSessionAccuracyDf=SessionAccuracyDf\\\n.withColumn('PreviousSessStart',F.lag(col('StartTime'), 1).over(windowval))\n\n# get time since last session\nSessionAccuracyDf=SessionAccuracyDf\\\n.withColumn('TimeSinceLastAssess'\\\n           ,F.unix_timestamp(col('StartTime'))-F.unix_timestamp(col('PreviousSessStart'))).na.fill(100000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Get current accuracy\nfor Assess_Title in Assess_Titles:\n    SessionAccuracyDf=SessionAccuracyDf.withColumn(Assess_Title+\"Accy\",\\\n                                   (col(f'sum({Assess_Title}True)')\\\n                                     /col(f'sum({Assess_Title}AllAttemps)'))).na.fill(-1)\n    \nSessionAccuracyDf=SessionAccuracyDf.withColumn('AllAssessmentAccy',\\\n                                   (col(f'sum(true_attempts)')\\\n                                     /(col(f'sum(true_attempts)')+col(f'sum(false_attempts)')))).na.fill(-1)\n\n# Get cumulative lagged accuracy\nfor Assess_Title in Assess_Titles:\n    SessionAccuracyDf=SessionAccuracyDf.withColumn(Assess_Title+'AccyLagCum',\\\n                                   col(f'sum({Assess_Title}True)LagCum')\\\n                                     /col(f'sum({Assess_Title}AllAttemps)LagCum')).na.fill(-1)\n    \nSessionAccuracyDf=SessionAccuracyDf.withColumn('AllAssessmentAccyLagCum',\\\n                    col('sum(true_attempts)LagCum')\\\n                    /(col('sum(true_attempts)LagCum')+col('sum(false_attempts)LagCum'))\\\n                    ).na.fill(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Get lagged features\nColumnsToLag=['Cart Balancer (Assessment)Accy', 'Cauldron Filler (Assessment)Accy', 'Bird Measurer (Assessment)Accy',\n 'Mushroom Sorter (Assessment)Accy', 'Chest Sorter (Assessment)Accy', 'AllAssessmentAccy']\nlag_cols = [F.lag(col(Column), 1).over(windowval).alias(Column+'Lag') \\\n                     for Column in ColumnsToLag]\nSessionAccuracyDf=SessionAccuracyDf.select(SessionAccuracyDf.columns+lag_cols)\nLaggedCols=[i+'Lag' for i in ColumnsToLag]\nSessionAccuracyDf=SessionAccuracyDf.fillna(-1, subset=LaggedCols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Add accuracy_group for each world across each session\nAssess_Titles=list_of_assess_titlesDf.toPandas()[['title']].values.tolist()\nfor Assess_Title in Assess_Titles:\n    #Create accuracy group by world\n    SessionAccuracyDf=SessionAccuracyDf.withColumn(Assess_Title[0]+'_accuracy_group',\\\n         when((col(f'sum({Assess_Title[0]}True)')==0)\\\n          &(col(f'sum({Assess_Title[0]}False)')==0),'NoAssess'\\\n             ).otherwise(\\\n                       when((col(f'sum({Assess_Title[0]}True)')==1)\\\n                            &(col(f'sum({Assess_Title[0]}False)')==0),'3'\\\n                     ).otherwise(\\\n                            when((col(f'sum({Assess_Title[0]}True)')==1)\\\n                                 &(col(f'sum({Assess_Title[0]}False)')==1),'2'\\\n                                ).otherwise(when(col(f'sum({Assess_Title[0]}True)')==0,'0'\\\n                                                ).otherwise('1')\\\n                                ))))\n#Create overall accuracy group \nSessionAccuracyDf=SessionAccuracyDf.withColumn('all_accuracy_group',\\\n     when((col(f'sum(true_attempts)')==0)\\\n          &(col(f'sum(false_attempts)')==0),'NoAssess'\\\n         ).otherwise(\\\n                   when((col(f'sum(true_attempts)')==1).cast(BooleanType())\\\n                        &(col(f'sum(false_attempts)')==0),'3'\\\n                 ).otherwise(\\\n                        when((col(f'sum(true_attempts)')==1)\\\n                                 &(col(f'sum(false_attempts)')==1),'2'\\\n                                ).otherwise(when(col(f'sum(true_attempts)')==0,'0'\\\n                                                ).otherwise('1')\\\n                                ))))\nColumnsToLag=[Title[0]+'_accuracy_group' for Title in Assess_Titles]\n\n\n#Add lagged accuracies\nCondition=F.lag(col('all_accuracy_group'),1).over(windowval)!='NoAssess'\nSessionAccuracyDf=SessionAccuracyDf.withColumn(\"Lag_all_accuracy\", F.when(Condition\\\n                                    , F.lag(col('AllAssessmentAccy'),1).over(windowval)))\nSessionAccuracyDf=SessionAccuracyDf.withColumn(\"Lag_all_accuracy\"\\\n                            ,F.last(col('lag_all_accuracy'),ignorenulls=True).over(windowval))\\\n                            .na.fill(-1)\n\nfor Assess_Title in Assess_Titles:\n    Condition=F.lag(col(f'{Assess_Title[0]}_accuracy_group'),1).over(windowval)!='NoAssess'\n    SessionAccuracyDf=SessionAccuracyDf.withColumn(f'Lag_{Assess_Title[0]}_accuracy', F.when(Condition\\\n                                    , F.lag(col(f'{Assess_Title[0]}Accy'),1).over(windowval)))\n    SessionAccuracyDf=SessionAccuracyDf.withColumn(f'Lag_{Assess_Title[0]}_accuracy'\\\n                            ,F.last(col(f'lag_{Assess_Title[0]}_accuracy'),ignorenulls=True).over(windowval))\\\n                            .na.fill(-1)\n\n    \n#Create lagged accuracy group \nSessionAccuracyDf=SessionAccuracyDf.withColumn('Lag_all_accuracy_group',\\\n     when((col('Lag_all_accuracy')==0),0)\\\n            .otherwise(\\\n                   when((col('Lag_all_accuracy')==1),3\\\n                 ).otherwise(\\\n                        when((col('Lag_all_accuracy')==0.5),2\\\n                                ).otherwise(\\\n                                             when((col('Lag_all_accuracy')==-1),-1\\\n                                                  ).otherwise(1)\\\n                                ))))\nColumnsToLag=[Title[0]+'_accuracy_group' for Title in Assess_Titles]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Collate the various dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"SessionAccuracyDf=SessionAccuracyDf.drop('StartTime','NumAssessmentAttemptsLagCum'\\\n                                        ,'PreviousSessStart','TimeSinceLastSess')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Collate all details of assessment sessions - we will filter non-assessment sessions at the end.  \n\n#Join the frame with current session assessments\nSessionAccuracyDf.createOrReplaceTempView(\"SessionAccuracy\")\nSessionTimingCumDf.createOrReplaceTempView(\"SessionTimingCum\")\nreduce_CombinedDf=Spark.sql(f'SELECT *,\\\nSessionTimingCum.installation_id as id1,SessionTimingCum.game_session as gs1 \\\nfrom SessionTimingCum LEFT JOIN SessionAccuracy \\\nON SessionTimingCum.installation_id=SessionAccuracy.installation_id \\\nAND SessionTimingCum.game_session=SessionAccuracy.game_session').drop('installation_id','game_session')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')\n\n\nreduce_CombinedDf=reduce_CombinedDf.na.drop()\n\nreduce_CombinedDf.createOrReplaceTempView(\"reduce_Combined\")\n\n\n# # # #Remove non-assessment sessions - their data will be captured in the 'Cum' fields, we only want to focus on assessment sessions\nreduce_CombinedDf=reduce_CombinedDf.filter(reduce_CombinedDf['NumAssessmentAttempts']>0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#one-hot encode title \nSessionTitleDf=SessionTimingCumDf.groupBy(\"installation_id\",\"game_session\").pivot(\"r_session_title\").count().na.fill(0)\nSessionTitleDf.createOrReplaceTempView(\"SessionTitle\")\nreduce_CombinedDf.createOrReplaceTempView(\"reduce_Combined\")\nreduce_CombinedDf=Spark.sql(f'SELECT *,\\\nreduce_Combined.installation_id as id1,reduce_Combined.game_session as gs1 \\\nfrom reduce_Combined INNER JOIN SessionTitle \\\nON reduce_Combined.installation_id=SessionTitle.installation_id \\\nAND reduce_Combined.game_session=SessionTitle.game_session').drop('installation_id','game_session')\\\n.withColumnRenamed('id1','installation_id').withColumnRenamed('gs1','game_session')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_CombinedDf=reduce_CombinedDf.na.drop()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove '()'  etc as parquet doen't like spaces or \"()' in field names \nreduce_CombinedDf=reduce_CombinedDf.toDF(*(c.replace('(', '') for c in reduce_CombinedDf.columns))\nreduce_CombinedDf=reduce_CombinedDf.toDF(*(c.replace(')', '') for c in reduce_CombinedDf.columns))\nreduce_CombinedDf=reduce_CombinedDf.toDF(*(c.replace(',', '') for c in reduce_CombinedDf.columns))\nreduce_CombinedDf=reduce_CombinedDf.toDF(*(c.replace(' ', '') for c in reduce_CombinedDf.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Identify the features"},{"metadata":{"trusted":true},"cell_type":"code","source":"KeyColumns =['installation_id', 'game_session', 'StartTime', 'PreviousSessStart','TestOrTrain','Type','TestFlag','EndTime',\n 'r_session_title','World']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AccuracyGroupColumns =['CartBalancerAssessment_accuracy_group', 'CauldronFillerAssessment_accuracy_group'\\\n, 'BirdMeasurerAssessment_accuracy_group', 'MushroomSorterAssessment_accuracy_group'\\\n, 'ChestSorterAssessment_accuracy_group','all_accuracy_group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CurrentAssessmentColumns=['accuracy_group',\n 'NumAssessmentAttempts',\n 'sumtrue_attempts',\n 'sumfalse_attempts',\n 'sumCartBalancerAssessmentTrue',\n 'sumCartBalancerAssessmentFalse',\n 'sumCartBalancerAssessmentAllAttemps',\n 'sumCauldronFillerAssessmentTrue',\n 'sumCauldronFillerAssessmentFalse',\n 'sumCauldronFillerAssessmentAllAttemps',\n 'sumBirdMeasurerAssessmentTrue',\n 'sumBirdMeasurerAssessmentFalse',\n 'sumBirdMeasurerAssessmentAllAttemps',\n 'sumMushroomSorterAssessmentTrue',\n 'sumMushroomSorterAssessmentFalse',\n 'sumMushroomSorterAssessmentAllAttemps',\n 'sumChestSorterAssessmentTrue',\n 'sumChestSorterAssessmentFalse',\n 'sumChestSorterAssessmentAllAttemps',\n 'CartBalancerAssessmentAccy',\n 'CauldronFillerAssessmentAccy',\n 'BirdMeasurerAssessmentAccy',\n 'MushroomSorterAssessmentAccy',\n 'ChestSorterAssessmentAccy',\n 'AllAssessmentAccy',\n  'NumEvents','misses_cnt', 'game_round',\n 'game_level',\n 'SessionDuration','sum12Monkeys',\n 'sumAirShow',\n 'sumAllStarSorting',\n 'sumBalancingAct',\n 'sumBirdMeasurerAssessment',\n 'sumBottleFillerActivity',\n 'sumBubbleBath',\n 'sumBugMeasurerActivity',\n 'sumCartBalancerAssessment',\n 'sumCauldronFillerAssessment',\n 'sumChestSorterAssessment',\n 'sumChickenBalancerActivity',\n 'sumChowTime',\n 'sumCostumeBox',\n 'sumCrystalCaves-Level1',\n 'sumCrystalCaves-Level2',\n 'sumCrystalCaves-Level3',\n 'sumCrystalsRule',\n 'sumDinoDive',\n 'sumDinoDrink',\n 'sumEggDropperActivity',\n 'sumFireworksActivity',\n 'sumFlowerWatererActivity',\n 'sumHappyCamel',\n 'sumHeavyHeavierHeaviest',\n 'sumHoneyCake',\n 'sumLeafLeader',\n 'sumLiftingHeavyThings',\n 'sumMagmaPeak-Level1',\n 'sumMagmaPeak-Level2',\n 'sumMushroomSorterAssessment',\n 'sumOrderingSpheres',\n 'sumPanBalance',\n \"sumPirate'sTale\",\n 'sumRulers',\n 'sumSandcastleBuilderActivity',\n 'sumScrub-A-Dub',\n 'sumSlopProblem',\n 'sumTreasureMap',\n 'sumTreeTopCity-Level1',\n 'sumTreeTopCity-Level2',\n 'sumTreeTopCity-Level3',\n 'sumWateringHoleActivity',\n 'sumWelcometoLostLagoon!', 'ActivityDur',\n 'AssessmentDur',\n 'ClipDur',\n 'GameDur',\n 'sumwin_code'\n]      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols=[x for x in reduce_CombinedDf.columns if (x not in AccuracyGroupColumns) and (x not in KeyColumns) \\\n              and (x not in CurrentAssessmentColumns) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[x for x in feature_cols if not 'Lag' in x] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vectorise the features\nvectorAssembler = VectorAssembler(inputCols=feature_cols,outputCol='features',handleInvalid=\"skip\")\nassembledDf = vectorAssembler.transform(reduce_CombinedDf).drop(*feature_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert target labels to integers\ncols_to_convert = [col(Column).cast(IntegerType()) for Column in AccuracyGroupColumns]\n\nmissing_cols = [i for i in assembledDf.columns if i not in AccuracyGroupColumns]\n\nassembledDf=assembledDf.select(missing_cols+cols_to_convert)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And we have finally finished the feature engineering. Wow that took forever! Much time was spent learning how to do things in Pyspark, though to paraphrase Thomas Edison, data science is 90% data wrangling and 10% applying algorthms. Hopefully innovations like automated feature engineering will help here. https://towardsdatascience.com/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#This is the step that takes the longest and might test Kaggle machine's HDD\nassembledDf.write.mode(\"overwrite\").save('assembledDf.parquet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}