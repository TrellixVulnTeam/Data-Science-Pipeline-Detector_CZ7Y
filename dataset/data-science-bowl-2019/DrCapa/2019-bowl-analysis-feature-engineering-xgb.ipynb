{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Welcome to the Data Science Bowl Competition\nThis notebook is a starter code for all beginners and easy to understand. <br>\nWe focus on\n* a simple analysis of the data,\n* create new features,\n* encoding and \n* scale data,\n* prepare data for train.\n\nWe use categorical feature encoding techniques, compare <br>\nhttps://www.kaggle.com/drcapa/categorical-feature-encoding-challenge-xgb\n\nIn this kernel we consider the train data. For prediction we must repeate all operations also for the test data. <br>\nAfter that we define X_train and y_train.\nThe aim of the competition is to predict the target accuracy_group:\n* 3: the assessment was solved on the first attempt,\n* 2: the assessment was solved on the second attempt,\n* 1: the assessment was solved after 3 or more attempts,\n* 0: the assessment was never solved.\n\nTo predict the test data we use a XGB Classifier."},{"metadata":{},"cell_type":"markdown","source":"# Load Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy.special\nimport matplotlib.pyplot as plt\nimport os\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Show files in path"},{"metadata":{"trusted":true},"cell_type":"code","source":"path_in = '../input/data-science-bowl-2019/'\nos.listdir(path_in)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Train Data\nThere is a column with a datetime information. So we can load as datetime type by parse_dates=['timestamp']."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(path_in+'train.csv', parse_dates=['timestamp'])\ntrain_labels = pd.read_csv(path_in+'train_labels.csv')\nspecs_data = pd.read_csv(path_in+'specs.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Help Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_bar(data, name, width, lenght):\n    fig = plt.figure(figsize=(width, lenght))\n    ax = fig.add_subplot(111)\n    data_label = data[name].value_counts()\n    dict_train = dict(zip(data_label.keys(), ((data_label.sort_index())).tolist()))\n    names = list(dict_train.keys())\n    values = list(dict_train.values())\n    plt.bar(names, values)\n    ax.set_xticklabels(names, rotation=45)\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis & Overview\nFirst we do a simple analysis and show important kpis."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('# samples train_data:', len(train_data))\nprint('# samples train_labels:', len(train_labels))\nprint('# samples specs:', len(specs_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing data\n\nFortunately there are no missing data we have to deal."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing_train_data = [col for col in train_data.columns if train_data[col].isnull().any()]\ncols_with_missing_train_labels = [col for col in train_labels.columns if train_labels[col].isnull().any()]\ncols_with_missing_specs_data = [col for col in specs_data.columns if specs_data[col].isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cols_with_missing_train_data)\nprint(cols_with_missing_train_labels)\nprint(cols_with_missing_specs_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering\nThere are 3 keys:\n\n1) game_session, installation_id: to merge train data and train labels\n\n2) event_id: to merge train data and specs \n\nFor the idea of the feature engineering we reduce the train data and use a subset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data = train_data.loc[0: len(train_data.index)/233]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature event_id\nRandomly generated unique identifier for the event type. <br>\nThere are dublictated codes."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['event_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature game_session\nRandomly generated unique identifier grouping events within a single game or video play session. <br>\nThere are dublictated codes."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['game_session'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature timestamp\nIs the client-generated datetime. You can extract new features like month, day or hour. These are cyclic features which can be encoded. Additionally we create the feature weekend: 5 = saturday and 6 = sunday."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['month'] = train_data['timestamp'].dt.month\ntrain_data['day'] = train_data['timestamp'].dt.weekday\ntrain_data['hour'] = train_data['timestamp'].dt.hour\ntrain_data['weekend'] = np.where((train_data['day'] == 5) | (train_data['day'] == 6), 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_cyc = {'month' : 12, 'day' : 7, 'hour' : 24}\nfor feature in features_cyc.keys():\n    train_data[feature+'_sin'] = np.sin((2*np.pi*train_data[feature])/features_cyc[feature])\n    train_data[feature+'_cos'] = np.cos((2*np.pi*train_data[feature])/features_cyc[feature])\ntrain_data = train_data.drop(features_cyc.keys(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature event_data\nSemi-structured JSON formatted string containing the events parameters. Default fields are: event_count, event_code, and game_time; otherwise fields are determined by the event type. <br>\nNext we show how to encode the features of a dictionary. \nWithout loss of generality we consider only the feature *description*.\nIf you don't want to extract new features you can delete the column."},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_fields = ['description']\n# steps = 233\n# for i in range(steps):\n#     print('work on step: ', i+1)\n#     for encode_field in encode_fields:\n#         slice_from = i*len(train_data.index)/steps\n#         slice_to = (i+1)*len(train_data.index)/steps-1\n#         train_data.loc[slice_from:slice_to, encode_field] = train_data.loc[slice_from:slice_to, 'event_data'].apply(json.loads).apply(pd.Series)[encode_field]\ndel train_data['event_data']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature installation_id\nThe installation_id will typically correspond to one child.\nIt is dandomly generated unique identifier grouping game sessions within a single installed application instance."},{"metadata":{},"cell_type":"markdown","source":"### Feature event_count\n Incremental counter of events within a game session (offset at 1). Extracted from event_data."},{"metadata":{},"cell_type":"markdown","source":"### Feature event_code\nIdentifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from event_data."},{"metadata":{},"cell_type":"markdown","source":"### Feature game_time\nTime in milliseconds since the start of the game session. Extracted from event_data."},{"metadata":{},"cell_type":"markdown","source":"### Feature title\nTitle of the game or video. The feature title is a categorical feature with lot of categories. For the first we use a simple mapping."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar(train_data, 'title', 30, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_train_title = dict(zip(train_data['title'].value_counts().sort_index().keys(),\n                     range(1, len(train_data['title'].value_counts())+1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['title'] = train_data['title'].replace(map_train_title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature type\nMedia type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'. This is a categorical feature which we encode by one hot encoding technique."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar(train_data, 'type', 9, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.get_dummies(train_data, columns=['type'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature world\nThe section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length/Height), 'MAGMAPEAK' (Capacity/Displacement), 'CRYSTALCAVES' (Weight). This is a categorical feature which we encode by one hot encoding technique."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar(train_data, 'world', 9, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.get_dummies(train_data, columns=['world'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train labels\nThis dataset demonstrates how to compute the ground truth for the assessments in the training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature game_session\n Randomly generated unique identifier grouping events within a single game or video play session."},{"metadata":{},"cell_type":"markdown","source":"### Feature installation_id\nRandomly generated unique identifier grouping game sessions within a single installed application instance."},{"metadata":{},"cell_type":"markdown","source":"### Feature title\nThe feature title is a categorical feature. For the first we use a simple mapping."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar(train_labels, 'title', 9, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_label_title = dict(zip(train_labels['title'].value_counts().sort_index().keys(),\n                     range(1, len(train_labels['title'].value_counts())+1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['title'] = train_labels['title'].replace(map_label_title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature num_correct\nThis is a binary feature we can use without modification. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['num_correct'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature num_incorrect\nThis is a numerical feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_labels['num_incorrect'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature accuracy\nThis is a float fearure."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['accuracy'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature accuracy_group\nThis is the target we have to predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar(train_labels, 'accuracy_group', 8, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['accuracy_group'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Specs\nThis file gives the specification of the various event types."},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature event_id\nGlobal unique identifier for the event type."},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_data['event_id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature info\nDescription of the event. There are 168 different types of informations."},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_data['info'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature args\nJSON formatted string of event arguments. Each argument contains:\n* name - Argument name.\n* type - Type of the argument (string, int, number, object, array).\n* info - Description of the argument.\n\nSo what can we do with the information?"},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_data.loc[0, 'args']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge data\nFor the first step we only merge the train_data with the train_label by the key . "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.merge(train_data, train_labels,  how='right', on=['game_session','installation_id'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define X_train and y_train\nThe featrue accuracy_group is the target which is to predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"no_features = ['accuracy_group', 'event_id', 'game_session', 'timestamp','installation_id',\n              'accuracy', 'num_correct', 'num_incorrect']\nX_train = train_data[train_data.columns.difference(no_features)].copy(deep=False)\ny_train = train_data['accuracy_group']\n\ndel X_train['title_y']\nX_train = X_train.rename(columns = {'title_x': 'title'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train.index), len(train_data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define XGB Classifier\nFor the first step we use the XGB Classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier(objective ='multi:softmax',\n                      learning_rate = 0.2,\n                      max_depth = 16,\n                      n_estimators = 350,\n                      random_state=2020,\n                      num_class = 4)\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(path_in+'test.csv', parse_dates=['timestamp'])\nsamp_subm = pd.read_csv(path_in+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Test Data\nWe repeat the data preparation of the train set."},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" Extract new features from timestamp \"\"\"\ntest_data['month'] = test_data['timestamp'].dt.month\ntest_data['day'] = test_data['timestamp'].dt.weekday\ntest_data['hour'] = test_data['timestamp'].dt.hour\ntest_data['weekend'] = np.where((test_data['day'] == 5) | (test_data['day'] == 6), 1, 0)\n\n\"\"\" Encode cyclic features \"\"\"\nfeatures_cyc = {'month' : 12, 'day' : 7, 'hour' : 24}\nfor feature in features_cyc.keys():\n    test_data[feature+'_sin'] = np.sin((2*np.pi*test_data[feature])/features_cyc[feature])\n    test_data[feature+'_cos'] = np.cos((2*np.pi*test_data[feature])/features_cyc[feature])\ntest_data = test_data.drop(features_cyc.keys(), axis=1)\n\n\"\"\" Encode feature title \"\"\"\ntest_data['title'] = test_data['title'].replace(map_train_title)\n\n\"\"\" Encode feature type \"\"\"\ntest_data = pd.get_dummies(test_data, columns=['type'])\n\n\"\"\" Encode feature world \"\"\"\ntest_data = pd.get_dummies(test_data, columns=['world'])\n\n\"\"\" Delete feature event_data \"\"\"\ndel test_data['event_data']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define X_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_data[test_data.columns.difference(no_features)].copy(deep=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict y_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare y_test for output\nWe group the results by the installation_id and take the most frequent accuracy_group."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_temp = pd.DataFrame(y_test, index=test_data['installation_id'], columns=['accuracy_group'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_temp_grouped = y_temp.groupby(y_temp.index).agg(lambda x:x.value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write output"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'installation_id': y_temp_grouped.index,\n                       'accuracy_group': y_temp_grouped['accuracy_group']})\noutput.index = samp_subm.index\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output['accuracy_group'].value_counts().sort_index()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}