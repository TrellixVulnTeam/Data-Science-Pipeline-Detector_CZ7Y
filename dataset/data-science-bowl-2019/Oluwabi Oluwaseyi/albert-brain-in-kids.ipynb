{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input', topdown = True):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objs as pgo\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom wordcloud import WordCloud\n\ninit_notebook_mode(connected=True) \n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\npath = \"/kaggle/input/data-science-bowl-2019\"\ndf_sample_submission = pd.read_csv(f\"{path}/sample_submission.csv\")\ndf_specs = pd.read_csv(f\"{path}/specs.csv\")\ndf_test = pd.read_csv(f\"{path}/test.csv\")\ndf_train = pd.read_csv(f\"{path}/train.csv\")\ndf_train_labels = pd.read_csv(f\"{path}/train_labels.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_description(data):\n    return (data.describe())\n\ndef data_info(data):\n    return (data.info())\n\ndef data_head(data):\n    return (data.head())\n\ndef data_column(data):\n    return (data.column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_description(df_train)\ndata_info(df_train)\ndata_head(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Train Size: {0} \\n Test Size: {1}\" .format(df_train.shape, df_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_labels.head()\ndf_train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option(\"max_colwidth\", 150)\ndata_head(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option(\"max_colwidth\", 150)\ndata_head(df_specs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option(\"max_colwidth\", 150)\ndata_head(df_train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"df_train_installation_id: {df_train.installation_id.nunique()}\")\nprint(f\"df_train_labels_installation_id: {df_train_labels.installation_id.nunique()}\")\nprint(f\"df_test_installation_id: {df_test.installation_id.nunique()}\")\nprint(f\"test&submission_installation_id_check: {set(df_test.installation_id.unique()) == set(df_sample_submission.installation_id.unique())}\")\nprint(f\"train&test titles_check: {set(df_test.title.unique()) == set(df_train.title.unique())}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (total/data.isnull().count()*100)\n    missing_columns = pd.concat([total, percent], axis = 1, keys = [\"Total\", \"Percent\"])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    missing_columns[\"Types\"] = types\n    return(np.transpose(missing_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(df_specs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(df_train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Counting Rows in train set: {df_train.shape[0]}\")\nprint(f\"Counting Rows in train_labels set: {df_train_labels.shape[0]}\")\nprint(f\"Counting Rows in test set: {df_test.shape[0]}\")\nprint(f\"Counting Rows in specs set: {df_specs.shape[0]}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train.columns.values:\n    print(f\"Counts of Unique values in train_set ´{column}`: {df_train[column].nunique()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train_labels.columns.values:\n    print(f\"Counts of Unique values in train_labels ´{column}`: {df_train_labels[column].nunique()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_labels['title'].apply(lambda x: x if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_test.columns.values:\n    print(f\"Counts of Unique values in test_set ´{column}`: {df_test[column].nunique()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_specs.columns.values:\n    print(f\"Counts of Unique values in Specs ´{column}`: {df_specs[column].nunique()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\ntrace = go.Pie(labels = df_train['title'].value_counts().index,\n              values = df_train['title'].value_counts().values,\n              domain = {'x':[0.20,1]})\n\ndata = [trace]\nlayout = go.Layout(title = 'PieChat Distribution of titles in train_labels')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Pie(labels = df_train_labels['title'].value_counts().index,\n              values = df_train_labels['title'].value_counts().values,\n              domain = {'x':[0.20,1]})\n\ndata = [trace]\nlayout = go.Layout(title = 'PieChat Distribution of Titles in train_labels')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:30], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height/total),\n                ha=\"center\") \n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('title', 'title (first most frequent 30 values - train_labels)', df_train_labels, size=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Pie(labels = df_train['type'].value_counts().index,\n              values = df_train['type'].value_counts().values,\n              domain = {'x':[0.20,1]})\n\ndata = [trace]\nlayout = go.Layout(title = 'PieChat Distribution of type in train')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Pie(labels = df_test['type'].value_counts().index,\n              values = df_test['type'].value_counts().values,\n              domain = {'x':[0.20,1]})\n\ndata = [trace]\nlayout = go.Layout(title = 'PieChat Distribution of type in test')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Pie(labels = df_train['world'].value_counts().index,\n              values = df_train['world'].value_counts().values,\n              domain = {'x':[0.20,1]})\n\ndata = [trace]\nlayout = go.Layout(title = 'PieChat Distribution of world in train')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Pie(labels = df_test['world'].value_counts().index,\n              values = df_test['world'].value_counts().values,\n              domain = {'x':[0.20,1]})\n\ndata = [trace]\nlayout = go.Layout(title = 'PieChat Distribution of world in test')\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating a Sample as extracted sample of about 100000 rows**\nWe will then use json package to normalize the json files in the event_data column. The value in the column will be values associated with the keys"},{"metadata":{"trusted":true},"cell_type":"code","source":"extracted_samples_train = df_train.sample(100000)\ndata_head(extracted_samples_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"extracted_samples_train.iloc[0].event_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\nextracted_event_data_samples_train = pd.io.json.json_normalize(extracted_samples_train.event_data.apply(json.loads))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"extracted_event_data_shape: {extracted_event_data_samples_train.shape}\")\ndata_head(extracted_event_data_samples_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(extracted_event_data_samples_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Modifying the missing data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"extracted_event_data_samples_train.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def existing_data(data):\n    total = data.isnull().count() - data.isnull().sum()\n    percent = 100 - (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    tt = pd.DataFrame(tt.reset_index())\n    return(tt.sort_values(['Total'], ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_extracted_event_data_samples_train = existing_data(extracted_event_data_samples_train)\n\nplt.figure(figsize=(10, 10))\nsns.set(style='whitegrid')\nax = sns.barplot(x='Percent', y='index', data=stat_extracted_event_data_samples_train.head(50), color='blue')\nplt.title('Most frequent features in extracted_event_data_samples_train')\nplt.ylabel('features')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**extracting datas from df_specs**\nEach rows is a dictionary containg keys. these keys are name, type and info. we will generate new columns for this keys"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_specs.args[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nextracted_specs_args = pd.DataFrame()\nfor i in range(0, df_specs.shape[0]): \n    for arg_item in json.loads(df_specs.args[i]) :\n        new_df = pd.DataFrame({'event_id': df_specs['event_id'][i],\\\n                               'info':df_specs['info'][i],\\\n                               'args_name': arg_item['name'],\\\n                               'args_type': arg_item['type'],\\\n                               'args_info': arg_item['info']}, index=[i])\n        extracted_specs_args = extracted_specs_args.append(new_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"extracted args from specs: {extracted_specs_args.shape}\")\n\ndata_head(extracted_specs_args)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing the distribution of args in each rows**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = extracted_specs_args.groupby(['event_id'])['info'].count()\ndf = pd.DataFrame({'event_id':tmp.index, 'count': tmp.values})\nplt.figure(figsize=(6,4))\nsns.set(style='whitegrid')\nax = sns.distplot(df['count'],kde=True,hist=False, bins=40)\nplt.title('Distribution of number of arguments per event_id')\nplt.xlabel('Number of arguments'); plt.ylabel('Density'); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count('args_name', 'args_name (first most frequent 30 values - specs)', extracted_specs_args, size=6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Writing a function on timestamps in the training set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import Any\nimport re\n\ndef add_datepart(df: pd.DataFrame, field_name: str,\n                 prefix: str = None, drop: bool = True, time: bool = True, date: bool = True):\n    \"\"\"\n    Helper function that adds columns relevant to a date in the column `field_name` of `df`.\n    from fastai: https://github.com/fastai/fastai/blob/master/fastai/tabular/transform.py#L55\n    \"\"\"\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Is_month_end', 'Is_month_start']\n    if date:\n        attr.append('Date')\n    if time:\n        attr = attr + ['Hour', 'Minute']\n    for n in attr:\n        df[prefix + n] = getattr(field.dt, n.lower())\n    if drop:\n        df.drop(field_name, axis=1, inplace=True)\n    return df\n\n\ndef ifnone(a: Any, b: Any) -> Any:\n    \"\"\"`a` if `a` is not None, otherwise `b`.\n    from fastai: https://github.com/fastai/fastai/blob/master/fastai/core.py#L92\"\"\"\n    return b if a is None else a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from joblib import Parallel, delayed\nfrom collections import defaultdict\nimport copy\n\n\nclass FeatureGenerator(object):\n    def __init__(self, n_jobs=1, df=None, dataset: str = 'df_train'):\n        self.n_jobs = n_jobs\n        self.df = df\n        self.dataset = dataset\n\n    def read_chunks(self):\n        for id, user_sample in self.df.groupby('installation_id', sort=False):\n            yield id, user_sample\n\n    def get_features(self, row):\n        \"\"\"\n        Gets three groups of features: from original data and from read and imaginary parts of FFT.\n        \"\"\"\n        return self.features(row)\n\n    def features(self, id, user_sample):\n        user_data = []\n\n        accuracy_mapping = {0: 0, 1: 3, 0.5: 2}\n\n        user_stats = defaultdict(int)\n        user_stats['installation_id'] = user_sample['installation_id'].unique()[0]\n        user_stats['world'] = user_sample['world'].unique()[0]\n        user_stats['timestamp'] = user_sample['timestamp'].unique()[0]\n\n        temp_dict = defaultdict(int)\n        another_temp_dict = {}\n        another_temp_dict['durations'] = []\n        another_temp_dict['all_durations'] = []\n        another_temp_dict['durations_with_triers'] = []\n        another_temp_dict['mean_action_time'] = []\n        title_data = defaultdict(dict)\n\n        for i, session in user_sample.groupby('game_session', sort=False):\n            user_stats['last_ass_session_game_time'] = another_temp_dict['durations'][-1] if len(another_temp_dict['durations']) > 0 else 0\n            user_stats['last_session_game_time'] = another_temp_dict['all_durations'][-1] if len(another_temp_dict['all_durations']) > 0 else 0\n\n            # calculate some user_stats and append data\n            if session['trier'].sum() > 0 or self.dataset == 'df_test':\n                user_stats['session_title'] = session['title'].values[0]\n                accuracy = np.nan_to_num(session['correct'].sum() / session['trier'].sum())\n                if accuracy in accuracy_mapping.keys():\n                    user_stats['accuracy_group'] = accuracy_mapping[accuracy]\n                else:\n                    user_stats['accuracy_group'] = 1\n                user_stats['accumulated_accuracy_group'] = temp_dict['accumulated_accuracy_group'] / user_stats['counter'] if user_stats['counter'] > 0 else 0\n                temp_dict['accumulated_accuracy_group'] += user_stats['accuracy_group']\n                user_data.append(copy.copy(user_stats))\n\n            user_stats[session['type'].values[-1]] += 1\n            user_stats['accumulated_correct_attempts'] += session['correct'].sum()\n            user_stats['accumulated_uncorrect_attempts'] += session['trier'].sum() - session['correct'].sum()\n            event_code_counts = session['event_code'].value_counts()\n            for i, j in zip(event_code_counts.index, event_code_counts.values):\n                user_stats[i] += j\n\n            temp_dict['assessment_counter'] += 1\n            if session['title'].values[-1] in title_data.keys():\n                pass\n            else:\n                title_data[session['title'].values[-1]] = defaultdict(int)\n\n            title_data[session['title'].values[-1]]['duration_all'] += session['game_time'].values[-1]\n            title_data[session['title'].values[-1]]['counter_all'] += 1\n            #user_stats['duration'] += (session['timestamp'].values[-1] - session['timestamp'].values[0]) / np.timedelta64(1, 's')\n\n            user_stats['duration'] = (session.iloc[-1,2] - session.iloc[0,2]).seconds\n            if session['type'].values[0] == 'Assessment' and (len(session) > 1 or self.dataset == 'df_test'):\n                another_temp_dict['durations'].append(user_stats['duration'])\n                accuracy = np.nan_to_num(session['correct'].sum() / session['trier'].sum())\n                user_stats['accumulated_accuracy_'] += accuracy\n                user_stats['counter'] += 1\n                if user_stats['counter'] == 0:\n                    user_stats['accumulated_accuracy'] = 0\n                else:\n                    user_stats['accumulated_accuracy'] = user_stats['accumulated_accuracy_'] / user_stats['counter']\n\n                accuracy = np.nan_to_num(session['correct'].sum() / session['trier'].sum())\n\n                if accuracy in accuracy_mapping.keys():\n                    user_stats[accuracy_mapping[accuracy]] += 1\n                else:\n                    user_stats[1] += 1\n\n                user_stats['accumulated_actions'] += len(session)\n\n                if session['trier'].sum() > 0:\n                    user_stats['sessions_with_trier'] += 1\n                    another_temp_dict['durations_with_triers'].append(user_stats['duration'])\n\n                if session['correct'].sum() > 0:\n                    user_stats['sessions_with_correct_trier'] += 1\n                    \n                user_stats['title_duration'] = title_data[session['title'].values[-1]]['duration']\n                user_stats['title_counter'] = title_data[session['title'].values[-1]]['counter']\n                user_stats['title_mean_duration'] = user_stats['title_duration'] / user_stats['title_mean_duration']  if user_stats['title_mean_duration'] > 0 else 0\n\n                user_stats['title_duration_all'] = title_data[session['title'].values[-1]]['duration_all']\n                user_stats['title_counter_all'] = title_data[session['title'].values[-1]]['counter_all']\n                user_stats['title_mean_duration_all'] = user_stats['title_duration_all'] / user_stats['title_mean_duration_all']  if user_stats['title_mean_duration_all'] > 0 else 0\n                \n                title_data[session['title'].values[-1]]['duration'] += session['game_time'].values[-1]\n                title_data[session['title'].values[-1]]['counter'] += 1\n\n            elif (len(session) > 1 or self.dataset == 'df_test'):\n                another_temp_dict['all_durations'].append(user_stats['duration'])\n\n\n            if user_stats['duration'] != 0:\n                temp_dict['nonzero_duration_assessment_counter'] += 1\n            #user_stats['duration_mean'] = user_stats['duration'] / max(temp_dict['nonzero_duration_assessment_counter'], 1)\n            # stats from assessment sessions\n            user_stats['duration_mean'] = np.mean(another_temp_dict['durations'])\n            user_stats['duration_trier'] = np.mean(another_temp_dict['durations_with_triers'])\n\n            # stats from all sessions\n            user_stats['all_duration_mean'] = np.mean(another_temp_dict['all_durations'])\n            user_stats['all_accumulated_actions'] += len(session)\n            user_stats['mean_action_time'] = np.mean(another_temp_dict['mean_action_time'])\n            another_temp_dict['mean_action_time'].append(session['game_time'].values[-1] / len(session))\n\n\n        if self.dataset == 'df_test':\n            user_data = [user_data[-1]]\n\n        return user_data\n\n    def generate(self):\n        feature_list = []\n#         res = Parallel(n_jobs=self.n_jobs, backend='threading')(delayed(self.features)(id, user_sample)\n#                                                                 for id, user_sample in tqdm(self.read_chunks(),\n#                                                                                             total=self.df[\n#                                                                                                 'installation_id'].nunique()))\n        res = Parallel(n_jobs=self.n_jobs, backend='threading')(delayed(self.features)(id, user_sample)\n                                                                for id, user_sample in self.read_chunks())\n        for r in res:\n            for r1 in r:\n                feature_list.append(r1)\n        return pd.DataFrame(feature_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_train[\"trier\"] = 0\ndf_train.loc[(df_train[\"title\"]==\"Bird Measurer (Assessment)\")&(df_train[\"event_code\"]==4110),\"trier\"] = 1\ndf_train.loc[(df_train[\"type\"]==\"Assessment\")&(df_train[\"title\"]!=\"Bird Measurer (Assessment)\")&(df_train[\"event_code\"]==4100),\"trier\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from category_encoders.ordinal import OrdinalEncoder\n\ntitle_encode = OrdinalEncoder()\ntitle_encode.fit(list(set(df_train['title'].unique()).union(set(df_test['title'].unique()))));\nworld_encode = OrdinalEncoder()\nworld_encode.fit(list(set(df_train['world'].unique()).union(set(df_test['world'].unique()))));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['correct'] = None\ndf_train.loc[(df_train['trier'] == 1) & (df_train['event_data'].str.contains('\"correct\":true')), 'correct'] = True\ndf_train.loc[(df_train['trier'] == 1) & (df_train['event_data'].str.contains('\"correct\":false')), 'correct'] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['title'] = title_encode.transform(df_train['title'].values)\ndf_train['world'] = world_encode.transform(df_train['world'].values)\ndf_train = df_train.loc[df_train['installation_id'].isin(df_train_labels['installation_id'].unique())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nFG = FeatureGenerator(n_jobs=2, df=df_train)\ntrain_set = FG.generate()\ntrain_set = train_set.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_head(train_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"timestamp\"] = pd.to_datetime(df_train[\"timestamp\"])\n\nextracted_train_timestamp = add_datepart(df_train, \"timestamp\", drop = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_head(extracted_train_timestamp)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}