{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Regressors and Classification by Optimal Rounding\n**■Classification steps**<BR>\n**Step 1** Create Regressor Models : Create multiple train_datasets using `kFold`(**not for CV**) and create a regression model from each dataset. I used ** CatBoost **, ** XGBoost **, ** LightGBM ** and `kFold = 5`, so created 15 models. <BR>\n**Step 2** Predict each Model<BR>\n**Step 3** Optimize Rounding Coefficients : The rounding coefficients of each model is optimized using `scipy.optimize.minimize()`. And calculate the final coefficient by weighted average of the optimal coefficient of each model.<BR>\n**Step 4** Final Classification\n    \nVer.5 : Introduced weighted average to calculate final rounding coefficient."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os, sys\nimport datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.metrics import cohen_kappa_score\nimport category_encoders as ce\n\n# from catboost import CatBoostRegressor\nimport catboost as cat\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom functools import partial\nimport scipy as sp              # for optimize.minimize()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Execution environment setting\nKaggle = True\n\nif Kaggle:\n    DIR = '../input/data-science-bowl-2019'\n    task_type = 'CPU'\nelse:\n    DIR = './data-science-bowl-2019'\n    task_type = 'GPU'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observe the data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv(os.path.join(DIR,'train.csv'))\ntrain_labels = pd.read_csv(os.path.join(DIR,'train_labels.csv'))\nspecs = pd.read_csv(os.path.join(DIR,'specs.csv'))\ntest = pd.read_csv(os.path.join(DIR,'test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"print('train:\\t\\t',train.shape)\nprint('train_labels:\\t',train_labels.shape)\nprint('specs:\\t\\t',specs.shape)\nprint('test:\\t\\t',test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. train"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train[['event_id','game_session','installation_id',\n       'title','type','world']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"event_code_n = train['event_code'].nunique()\nprint(\"num of unique 'event_code':\", event_code_n)\nprint(\"'event_code': \",\n      train['event_code'].min(), \"-\", train['event_code'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 'event_data' exsample\nprint(train['event_data'][40])\nprint(train['event_data'][41])\nprint(train['event_data'][43])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. train_labels"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train_labels[['game_session','installation_id', 'title']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# unique 'title' list\ntrain_labels['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. specs"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"specs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"specs.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 'info' exsample\nprint(specs['info'][0],'\\n')\nprint(specs['info'][6],'\\n')\nprint(specs['info'][7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 'args' exsample\nprint(specs['args'][0],'\\n')\nprint(specs['args'][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. test"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"test.head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"test[['event_id','game_session','installation_id',\n       'title','type','world']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compile data\nBased on several kernels\n- Hosseinali: https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model\n- Bruno Aquino: https://www.kaggle.com/braquino/catboost-some-more-features\n- Heng Zheng: https://www.kaggle.com/hengzheng/bayesian-optimization-seed-blending"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# make 'title' and 'event_code' list\ntitle_list = list(set(train['title'].value_counts().index) \\\n                   .union(set(test['title'].value_counts().index)))\nevent_code_list = list(set(train['event_code'].value_counts().index) \\\n                   .union(set(test['event_code'].value_counts().index)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# makes dict 'title to number(integer)'\ntitle2num = dict(zip(title_list, np.arange(len(title_list))))\n# makes dict 'number to title'\nnum2title = dict(zip(np.arange(len(title_list)), title_list))\n# \nassess_titles = list(set(train[train['type'] == 'Assessment']['title'].\n                         value_counts().index).\n                         union(set(test[test['type'] == 'Assessment']['title'].\n                         value_counts().index)))\n# makes dict 'title to win event_code' \n# (4100 except 'Bird Measurer' and 4110 for 'Bird Measurer'))\ntitle2win_code = dict(zip(title2num.values() \\\n                    ,(np.ones(len(title2num))).astype('int') * 4100))\ntitle2win_code[title2num['Bird Measurer (Assessment)']] = 4110","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Convert 'title' to the number\ntrain['title'] = train['title'].map(title2num)\ntest['title'] = test['title'].map(title2num)\ntrain_labels['title'] = train_labels['title'].map(title2num)\n\n# Convert 'timestamp' to datetime\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Convert the raw data into processed features\ndef get_data(user_sample, test_set=False):\n    '''\n    user_sample : DataFrame from train/test group by 'installation_id'\n    test_set    : related with the labels processing\n    '''\n    # Constants and parameters declaration\n    user_assessments = []\n    last_type = 0\n    types_count_dc = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    time_spent_each_title_dc = {title:0 for title in title_list}\n    event_code_count_dc = {code:0 for code in event_code_list}\n    accuracy_groups_dc = {0:0, 1:0, 2:0, 3:0}\n    \n    accumu_accuracy_group = 0\n    accumu_accuracy=0\n    accumu_win_n = 0 \n    accumu_loss_n = 0 \n    accumu_actions = 0\n    counter = 0\n    durations = []\n    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}   ## add\n    \n    # group by 'game_session'\n    for game_id, session in user_sample.groupby('game_session', sort=False):\n        # game_id: game_session_id\n        # session: DataFrame from user_sample group by 'game_session'\n        session_type = session['type'].iloc[0]  # Game/Assessment/Activity/Clip\n        session_title = session['title'].iloc[0]        # session_title:int\n        session_title_text = num2title[session_title]   ## add\n        \n        if session_type != 'Assessment':\n            time_spent = int(session['game_time'].iloc[-1] / 1000)   # [sec]\n            time_spent_each_title_dc[num2title[session_title]] += time_spent\n        \n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100(4110)\n            all_4100_df = session.query(f'event_code == \\\n                                         {title2win_code[session_title]}')\n            # numbers of wins and losses\n            win_n = all_4100_df['event_data'].str.contains('true').sum()\n            loss_n = all_4100_df['event_data'].str.contains('false').sum()\n\n            # init features_dc and then update\n            features_dc = types_count_dc.copy()\n            features_dc.update(last_accuracy_title.copy())   ## add\n            features_dc.update(time_spent_each_title_dc.copy())\n            features_dc.update(event_code_count_dc.copy())\n            features_dc['session_title'] = session_title\n            features_dc['accumu_win_n'] = accumu_win_n\n            features_dc['accumu_loss_n'] = accumu_loss_n\n            accumu_win_n += win_n\n            accumu_loss_n += loss_n\n            \n            features_dc['installation_id'] = session['installation_id'].iloc[-1] # Mod 2019-12-20\n            features_dc['day_of_the_week'] = (session['timestamp'].iloc[-1]). \\\n                                              strftime('%a')    # Mod 2019-11-17\n\n            if durations == []:\n                features_dc['duration_mean'] = 0\n            else:\n                features_dc['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n\n            # average of the all accuracy of this player\n            features_dc['accuracy_ave'] = accumu_accuracy / counter \\\n                                                if counter > 0 else 0\n            accuracy = win_n / (win_n + loss_n) \\\n                                   if (win_n + loss_n) > 0 else 0\n            accumu_accuracy += accuracy\n            last_accuracy_title['acc_' + session_title_text] = accuracy    ## add\n            if accuracy == 0:\n                features_dc['accuracy_group'] = 0\n            elif accuracy == 1:\n                features_dc['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features_dc['accuracy_group'] = 2\n            else:\n                features_dc['accuracy_group'] = 1\n            features_dc.update(accuracy_groups_dc)\n            accuracy_groups_dc[features_dc['accuracy_group']] += 1\n            # average of accuracy_groups_dc of this player\n            features_dc['accuracy_group_ave'] = \\\n                    accumu_accuracy_group / counter if counter > 0 else 0\n            accumu_accuracy_group += features_dc['accuracy_group']\n            \n            # how many actions the player has done in this game_session\n            features_dc['accumu_actions'] = accumu_actions\n            \n            # if test_set, all sessions belong to the final dataset\n            # elif train, needs to be passed throught this clausule\n            if test_set or (win_n + loss_n) > 0:\n                user_assessments.append(features_dc)\n                \n            counter += 1\n        \n        # how many actions was made in each event_code\n        event_codes = Counter(session['event_code'])\n        for key in event_codes.keys():\n            event_code_count_dc[key] += event_codes[key]\n\n        # how many actions the player has done\n        accumu_actions += len(session)\n        if last_type != session_type:\n            types_count_dc[session_type] += 1\n            last_type = session_type\n            \n    # if test_set, only the last assessment must be predicted,\n    # the previous are scraped\n    if test_set:\n        return user_assessments[-1]\n    return user_assessments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# get_data function is applyed to each installation_id\ndef compile_data(df, test_set):\n    compiled_data = []\n    for ins_id, user_sample in tqdm(df.groupby('installation_id', sort=False),\n                                     total=df['installation_id'].nunique()):\n        # user_sample : DataFrame group by 'installation_id'\n        if test_set == False:\n            compiled_data += get_data(user_sample, test_set)\n        else:\n            compiled_test = get_data(user_sample, test_set)\n            compiled_data.append(compiled_test)\n            \n    compiled_df = pd.DataFrame(compiled_data)\n    del compiled_data\n    \n    # additional feature engineering\n    compiled_df['insta_session_count'] = compiled_df.groupby(['installation_id']) \\\n                                                            ['Clip'].transform('count')\n    compiled_df['insta_duration_mean'] = compiled_df.groupby(['installation_id']) \\\n                                                            ['duration_mean'].transform('mean')\n    compiled_df['insta_title_nunique'] = compiled_df.groupby(['installation_id']) \\\n                                                            ['session_title'].transform('nunique')\n    compiled_df.drop('installation_id', axis=1, inplace=True)\n    # convert day_of_the_week to int\n    compiled_df['day_of_the_week'] = compiled_df['day_of_the_week'].map(\n        {'Mon':1, 'Tue': 2, 'Wed':3, 'Thu':4, 'Fri':5,'Sat':6, 'Sun':7})\n    \n    return compiled_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# compile train data\nnew_train = compile_data(train, test_set = False).copy()\nprint(new_train.shape)\nnew_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# compile test data\nnew_test = compile_data(test, test_set = True).copy()\nprint(new_test.shape)\nnew_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rejyect almost same features\nfeatures = new_train.columns\ncounter = 0\nto_remove = []\nfor f_a in features:\n    for f_b in features:\n        if f_a != f_b and f_a not in to_remove and f_b not in to_remove:\n            c = np.corrcoef(new_train[f_a], new_train[f_b])[0][1]\n            if c > 0.99:\n                counter += 1\n                to_remove.append(f_b)\n                print('{}: {} vs {} : Correlation= {}'.format(counter, f_a, f_b, c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(features))\nfeatures = [x for x in features if x not in to_remove]\nprint(len(features))\n\nnew_train = new_train[features]\nnew_test = new_test[features]\n\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# all_features but 'accuracy_group', that is the label y\nall_features = [x for x in new_train.columns if x not in ['accuracy_group']]\n# categorical feature\ncategorical_features = ['session_title','day_of_the_week']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode categorical_features to integer(for use with LightGB,XGBoost,etc)\n\n# concatnate train and test data\ntemp_df = pd.concat([new_train[all_features], new_test[all_features]])\n# encode\nencoder = ce.ordinal.OrdinalEncoder(cols = categorical_features)\ntemp_df = encoder.fit_transform(temp_df)\n# dataset\nX, y = temp_df.iloc[:len(new_train),:].copy(), new_train['accuracy_group'].copy()\nX_test = temp_df.iloc[len(new_train):,:].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"del train,test,new_train, new_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1 : Create Regressor Models\nCreate multiple train_datasets using `kFold` and create a regression model from each dataset. I used ** CatBoost **, ** XGBoost **, ** LightGBM **."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create multiple datasets to create multiple models (not for CV).\nNFOLDS = 5\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CatBoost\nstart_time = time()\ncat_models = []\nscores = []\n\nparams = {\n    'learning_rate': 0.02,\n    'loss_function': 'RMSE',\n    'random_seed': 42,\n    'depth': 11,                            # 10\n    'border_count': 37,                     # 108\n    'bagging_temperature': 2.348502,        # \n    'task_type': task_type,\n}\n\n# Train and make models\nfor fold, (train_ids, val_ids) in enumerate(folds.split(X,y)):\n    print('● Fold :', fold+1,'/',NFOLDS)\n    dtrain = cat.Pool(X.iloc[train_ids], y[train_ids],\n                     cat_features=categorical_features)\n    dval = cat.Pool(X.iloc[val_ids], y[val_ids],\n                   cat_features=categorical_features)\n    model = cat.train(params=params,\n                      dtrain=dtrain,\n                      eval_set=dval,        # =evals\n                      iterations=5000,      # =num_boost_round\n                      early_stopping_rounds=100,\n                      verbose=200\n                     )\n    cat_models.append(model)\n    \nprint('Time:', time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### -XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\nstart_time = time()\nxgb_models = []\nscores = []\n\nparams = {\n    'max_depth': 6,                     # 6,10,9\n    'learning_rate': 0.01,              # =eta 0.1: [0,1]\n    'objective': 'reg:squarederror',    # 'reg:linear'\n    'n_estimators' : 300,               # 100\n    'subsample': 0.79,                  # 1,0.8,0.6    # 1, (0,1]    \n    'colsample_bytree': 1.0,            # 1,0.8,1.0    # 1, (0, 1]   \n    'gamma': 0.14,                      # 0.0\n    'min_child_weight': 3,              # 5\n    'seed' : 42,\n}\n\n# Train and make models\nfor fold, (train_ids, val_ids) in enumerate(folds.split(X,y)):\n    print('● Fold :', fold+1,'/',NFOLDS)\n    dtrain = xgb.DMatrix(X.iloc[train_ids], y[train_ids])\n    dval = xgb.DMatrix(X.iloc[val_ids], y[val_ids])\n    model = xgb.train(params=params,\n                      dtrain=dtrain,\n                      num_boost_round=5000,\n                      evals=[(dtrain, 'train'), (dval, 'val')],\n                      early_stopping_rounds=100,\n                      verbose_eval=200\n                     )\n    xgb_models.append(model)\n    \nprint('Time:', time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM\nstart_time = time()\nlgb_models = []\nscores = []\n\nparams = {\n    'n_jobs': -1,\n    'seed': 42,\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'rmse',\n    'feature_fraction': 0.95,        # 0.998, 0.967\n    'bagging_fraction': 0.85,        # 0.8, 0.872    =subsample\n    'learning_rate': 0.01,\n    'max_depth': 14,                 # 10,13\n    'num_leaves': 957,               # 1024,440    # 2^max_depth < num_leaves ?\n    'min_gain_to_split': 0.096104,   # 0.086, 0.053\n    'min_child_weight': 1.189104,    # 1.087, 1.497\n    'lambda_l1': 1.8,                # 1.0\n    'lambda_l2': 1.5,                # 1.0\n}\n\n# Train and make models\nfor fold, (train_ids, val_ids) in enumerate(folds.split(X,y)):\n    print('● Fold :', fold+1,'/',NFOLDS)\n    train_set = lgb.Dataset(X.iloc[train_ids], y[train_ids],\n                           categorical_feature=categorical_features)\n    val_set = lgb.Dataset(X.iloc[val_ids], y[val_ids],\n                         categorical_feature=categorical_features)\n    model = lgb.train(params=params,\n                      train_set=train_set,\n                      valid_sets=[train_set, val_set],\n                      num_boost_round=5000,\n                      early_stopping_rounds=100,\n                      verbose_eval=100\n                     )\n    lgb_models.append(model)\n    \nprint('\\nTime:', time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2 : Predict each Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\n\n# CatBoost models\nfor model in cat_models:\n    pred = model.predict(X)\n    preds.append(pred)\n    \n# XGBoost models\nfor model in xgb_models:\n    pred = model.predict(xgb.DMatrix(X))\n    pred = pred.flatten()\n    preds.append(pred)\n    \n# LightGBM models\nfor model in lgb_models:\n    pred = model.predict(X,num_iteration=model.best_iteration)\n    pred = pred.reshape(len(X),1).flatten()\n    preds.append(pred)\n\nreg_df = pd.DataFrame(preds).T\nreg_df.columns = ['C1','C2','C3','C4','C5',   # CatBoost\n                  'X1','X2','X3','X4','X5',   # XGBoost\n                  'L1','L2','L3','L4','L5']   # LightGBM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the average value of each model pred\nreg_df['mean'] = reg_df.mean(axis = 'columns')\nreg_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3 : Optimize Rounding Coefficients\nThe rounding coefficient is optimized using the average value of the prediction results of each model. Optimization uses `scipy.optimize.minimize()`.\n\nThe rounding coefficients of each model is optimized using `scipy.optimize.minimize()`. And calculate the final coefficient by weighted average of the optimal coefficient of each model."},{"metadata":{"trusted":true},"cell_type":"code","source":"class OptRounder(object):\n    def __init__(self):\n        self.res_ = []\n        self.coef_ = []\n        \n    def get_res(self):\n        return self.res_\n    \n    # objective function\n    def func(self, coef, X, y):\n        kappa = cohen_kappa_score(self.bincut(coef, X), y,\n                                  weights='quadratic')\n        return -kappa\n\n    def bincut(self, coef, X):\n        return pd.cut(X,\n                      [-np.inf] + list(np.sort(coef)) + [np.inf],\n                      labels = [0, 1, 2, 3])\n        \n    def fit(self, X, y):\n        pfunc = partial(self.func, X=X, y=y)\n        self.res_ = sp.optimize.minimize(fun = pfunc,           # objective func\n                                         x0 = [0.7, 1.5, 2.3],  # initial coef\n                                         method='nelder-mead')  # solver\n        self.coef_ = self.res_.x\n        \n    def predict(self, X, coef):\n        return self.bincut(coef, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptRounder()\n\n# Optimize each model's coef\ncoef = []\nfor col in tqdm(reg_df.columns[:-1]):\n    optR.fit(reg_df[col].values.reshape(-1,), y)\n    res = optR.get_res()\n    coef.append(np.append(res.x, -res.fun))  # Optimized coef & kappa\n\ncoef_df = pd.DataFrame(coef,\n                       columns = ['coef0','coef1','coef2','kappa'],\n                       index = reg_df.columns[:-1])\ncoef_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficients average weighted by kappa for each model\ncoefficients = []\nfor col in coef_df.columns[:-1]:\n    coefficients.append(np.average(np.array(coef_df[col]),\n                                   weights=np.array(coef_df['kappa'])))\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4 : Final Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# final classification\nreg_df['predict'] = optR.predict(reg_df['mean'].values,\n                                 coefficients).astype(int)\n\nreg_df['y'] = y\nkappa = cohen_kappa_score(reg_df['predict'], y, weights='quadratic')\nprint('●Cohen Kappa score (traind X):',kappa)\nreg_df[['mean','predict','y']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_df[['mean','predict','y']].plot(subplots=True,layout=(1, 3),\n                                    figsize=(11, 3),kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# binning plot of 'pred' versus 'y'\nreg_df.plot.hexbin(x='y', y='predict', gridsize=(3,3),\n                   sharex=False, title = \"binning 'pred' vs 'y'\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nfor model in cat_models:        # CatBoost\n    pred = model.predict(X_test)\n    preds.append(pred)\nfor model in xgb_models:        # XGBoost\n    pred = model.predict(xgb.DMatrix(X_test))\n    pred = pred.flatten()\n    preds.append(pred)\nfor model in lgb_models:        # LightGBM\n    pred = model.predict(X_test,num_iteration=model.best_iteration)\n    pred = pred.reshape(len(X_test),1).flatten()\n    preds.append(pred)\ndf_s = pd.DataFrame(preds).T\n\ndf_s['mean'] = df_s.mean(axis = 'columns')\n\n# Classification\ndf_s['pred'] = optR.predict(df_s['mean'].values, coefficients).astype(int)\n\nprint(df_s.shape)\ndf_s[['mean','pred']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s[['mean','pred']].plot(subplots=True, layout=(1, 2),\n                           figsize=(7, 3), kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\nsubmission['accuracy_group'] = df_s['pred']\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}