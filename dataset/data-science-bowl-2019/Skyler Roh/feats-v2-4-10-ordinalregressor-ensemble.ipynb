{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom ml_metrics import quadratic_weighted_kappa\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\nfrom joblib import Parallel, delayed\nimport multiprocessing\n\ndef applyParallel(dfGrouped, func):\n    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(name, group) for name, group in dfGrouped)\n    return pd.DataFrame(retLst)\n\n###\n# def get_last_event(group):\n#     return group.sort_values('timestamp', ascending=False).iloc[0]\n# last_events = test.groupby('installation_id').apply(get_last_event).event_id.value_counts()\n# print(last_events.index) # ['7ad3efc6', '3bfd1a65', '90d848e0', '5b49460a', 'f56e0afc']\n###\nlast_event_before_assessment = {'Cauldron Filler (Assessment)': '90d848e0',\n                                'Cart Balancer (Assessment)': '7ad3efc6',\n                                'Mushroom Sorter (Assessment)': '3bfd1a65',\n                                'Bird Measurer (Assessment)': 'f56e0afc',\n                                'Chest Sorter (Assessment)': '5b49460a'}\n\nmedia_seq = pd.read_csv('../input/dsb-feats-v2/media_sequence.csv')\nclips_seq = media_seq[media_seq.type=='Clip']\nclip_times = dict(zip(clips_seq.title, clips_seq.duration))\n\n\ndef read_data():\n    print('Reading train.csv file....')\n    train = pd.read_csv('train.csv')\n    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\n    print('Reading test.csv file....')\n    test = pd.read_csv('test.csv')\n    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n\n    print('Reading train_labels.csv file....')\n    train_labels = pd.read_csv('train_labels.csv')\n    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n\n    print('Reading specs.csv file....')\n    specs = pd.read_csv('specs.csv')\n    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n    return train, test, train_labels, specs\n\n\ndef get_worst_score(group):\n    return group.sort_values('accuracy_group').iloc[0]\n\n\ndef is_assessment(titles_series):\n    def is_assessment_title(title):\n        return \"assessment\" in title.lower()\n    return titles_series.apply(lambda x: is_assessment_title(x))\n\ndef num_unique_days(timestamps):\n    return pd.to_datetime(timestamps).apply(lambda x: x.date()).unique().size\n\n\ndef days_since_first_event(timestamps):\n    dates = pd.to_datetime(timestamps).apply(lambda x: x.date())\n    return (dates.max() - dates.min()).days\n\n\ndef get_events_before_game_session(events, game_session, assessment_title):\n    if not (game_session or assessment_title):\n        return events\n    else:\n        assessment_event = last_event_before_assessment.get(assessment_title)\n        game_session_index = events.index[(events.game_session == game_session) & \\\n                                           (events.event_id.isin([assessment_event] if assessment_event else last_event_before_assessment.values()))]\n        return events.loc[:game_session_index[-1]]\n\n\ndef get_clip_duration_features(events):\n    clips = events[events.type=='Clip']\n    if clips.empty:\n        game_time = 0\n        skip_rate = 0\n        avg_watch_length = 0\n    else:\n        game_time = clips.apply(lambda x: min(x.ts_diff, clip_times.get(x.title)), axis=1).sum()\n        skip_rate = clips.apply(lambda x: x.ts_diff < clip_times.get(x.title), axis=1).mean()\n        avg_watch_length = clips.apply(lambda x: min(x.ts_diff / clip_times.get(x.title), 1), axis=1).mean()\n    return pd.Series([game_time, skip_rate, avg_watch_length], \n                     index=['clip_game_time', 'clip_skip_rate', 'clip_avg_watch_length'],\n                     dtype=float)\n    \ndef group_by_game_session_and_sum(events, columns):\n    \"\"\"\n    some columns are rolling counts by game session,\n    take the max value of each game session then sum for totals\n    \"\"\"\n    series = pd.Series(dtype=int)\n    for c in columns:\n        # set beginning values for each type to 0\n        for stype in ['activity', 'game', 'assessment', 'clip']:\n            series[stype+'_'+c] = 0\n        series['total_'+c] = 0 \n        \n        # get session type and total values and add to running total\n        for session_id, session in events.groupby('game_session'):\n            session_type = session['type'].iloc[0].lower()\n            session_value = session[c].max() / 1000.0 if c=='game_time' else session[c].max()\n            series[session_type+'_'+c] += session_value\n            series['total_'+c] += session_value\n        if c=='game_time':\n            series = series.drop(labels='clip_'+c)\n            series = series.append(get_clip_duration_features(events))\n    return series\n\n\ndef summarize_events(events):\n    \"\"\"\n    takes a dataframe of events and returns a pd.Series with aggregate/summary values\n    \"\"\"\n    events = events.sort_values('ts').reset_index()\n    events['ts_diff'] = -events.ts.diff(-1).dt.total_seconds()\n    numeric_rows = ['event_count', 'game_time']\n    aggregates = group_by_game_session_and_sum(events, numeric_rows)\n    aggregates['num_unique_days'] = num_unique_days(events['timestamp'])\n    aggregates['elapsed_days'] = days_since_first_event(events['timestamp'])\n    aggregates['last_world'] = events.tail(1)['world'].values[0]\n    aggregates['last_assessment'] = events[is_assessment(events['title'])].tail(1)['title'].values[0]\n    aggregates['assessments_taken'] = events['title'][events.event_id.isin(last_event_before_assessment.values())].value_counts()\n    aggregates['type_counts'] = events[['game_session', 'type']].drop_duplicates()['type'].value_counts()\n    aggregates['title_counts'] = events[['game_session', 'title']].drop_duplicates()['title'].value_counts()\n    aggregates['event_code_counts'] = events.event_code.value_counts()\n    aggregates['event_id_counts'] = events.event_id.value_counts()\n    aggregates['unique_game_sessions'] = events.game_session.unique().size\n    return aggregates\n\n\ndef summarize_events_before_game_session(name, events):\n    if not isinstance(name, (list,tuple)) or len(name)==1:\n        # for test data\n        game_session=None\n        assessment=None\n        name_series = pd.Series([name], index=['installation_id'])\n    else:\n        installation_id, game_session, assessment = name\n        name_series = pd.Series(name, index=['installation_id', 'game_session_y', 'title_y'])\n    \n    events = events.rename(columns={'game_session_x': 'game_session', 'title_x': 'title'}, errors='ignore')\n    events_before = get_events_before_game_session(events, game_session, assessment)\n    aggregates = summarize_events(events_before)\n    try:\n        labels = events[['num_correct', 'num_incorrect', 'accuracy', 'accuracy_group']].iloc[0] \\\n            .append(name_series)\n        row = aggregates.append(labels)\n    except KeyError:\n        row = aggregates.append(name_series)\n        # print(\"no label columns, just returning features\")\n    return row\n\n\ndef expand_count_features(features):\n    print('**expanding event type count features**')\n    expanded_type_counts = features.type_counts.apply(pd.Series).fillna(0)\n    # rename the type count columns\n    expanded_type_counts.columns = [c.lower()+'_ct' for c in expanded_type_counts.columns]\n    \n    print('**expanding title count features**')\n    expanded_title_counts = features.title_counts.apply(pd.Series).fillna(0)\n    # rename the type count columns\n    expanded_title_counts.columns = [c.lower().replace(' ', '_')+'_ct' for c in expanded_title_counts.columns]\n\n    print('**expanding event code count features**')\n    expanded_event_code_counts = features.event_code_counts.apply(pd.Series).fillna(0)\n    # rename the event_code count columns\n    expanded_event_code_counts.columns = ['event_{}_ct'.format(int(c)) for c in expanded_event_code_counts.columns]\n    # non_zero_event_code_counts \n    for ec in expanded_event_code_counts.columns:\n        expanded_event_code_counts['non_zero_'+ec] = (expanded_event_code_counts[ec] > 0).astype(int)\n    \n    print('**expanding event id count features**')\n    expanded_event_id_counts = features.event_id_counts.apply(pd.Series).fillna(0)\n    # rename the event_id count columns\n    expanded_event_id_counts.columns = ['eid_{}_ct'.format(c) for c in expanded_event_id_counts.columns]\n    \n    expanded_assessments_taken = features.assessments_taken.apply(pd.Series).fillna(0)\n    \n    feats = pd.concat([features.drop(['type_counts', 'title_counts', 'event_code_counts', 'event_id_counts', 'assessments_taken'], axis=1), expanded_type_counts, expanded_title_counts, expanded_event_code_counts, expanded_event_id_counts, expanded_assessments_taken], axis=1)\n    return feats\n\n\ndef split_features_and_labels(df):\n    labels_df = df[['title_y', 'num_correct', 'num_incorrect',\n                    'accuracy', 'accuracy_group', 'installation_id', 'game_session_y']].copy()\n    feats_df = df.drop(\n        ['title_y', 'num_correct', 'num_incorrect', 'game_session_y',\n         'accuracy', 'accuracy_group'], axis=1)\n    return feats_df, labels_df\n\n\ndef basic_user_features_transform(train_data, train_labels=None):\n    data = train_data[['event_id', 'game_session', 'timestamp', 'installation_id', 'event_count', 'event_code',\n                       'game_time', 'title', 'type', 'world']]\n    data['ts'] = pd.to_datetime(data.timestamp)\n    if train_labels is not None:\n        train_w_labels = data.merge(train_labels, on='installation_id')\n        groups = train_w_labels.groupby(['installation_id', 'game_session_y', 'title_y'])\n    else:\n        groups = data.groupby(['installation_id'])\n    # game session y is index 1 of the group name\n    # passing none to game session is for eval data, does not subset any of the data for each installation_id\n    print('**getting user features before each training assessment**')\n    features = applyParallel(groups,\n                             lambda name, group: summarize_events_before_game_session(name, group))\n    \n    expanded_features = expand_count_features(features)\n    \n\n    if train_labels is not None:\n        return split_features_and_labels(expanded_features)\n    else:\n        return expanded_features, None\n\ndef get_data_processing_pipe(feats, log_features, categorical_features):\n    # We create the preprocessing pipelines for both numeric and categorical data.\n    numeric_features = [c for c in feats.columns if c not in log_features+categorical_features+['installation_id']]\n\n    numeric_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(fill_value=0, strategy='constant')),\n        ('scaler', StandardScaler())])\n\n    numeric_log_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(fill_value=0, strategy='constant')),\n        ('log_scale', FunctionTransformer(np.log1p)),\n        ('scaler', StandardScaler())])\n\n    categorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\n    preprocessor = ColumnTransformer(\n        remainder='drop',\n        transformers=[\n            ('num', numeric_transformer, numeric_features),\n            ('num_log', numeric_log_transformer, log_features),\n            ('cat', categorical_transformer, categorical_features)])\n\n    return preprocessor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import clone\nimport numpy as np\nfrom collections import Counter\n\n        \nclass OrdinalRegressor():    \n    def __init__(self, clf, **kwargs):\n        self.clf = clf(**kwargs)\n#         self.dist = None\n        self.threshold_optimizer = OptimizedRounder([0,1,2,3])\n        \n    def fit(self, X, y, **fit_params):\n#         self.dist = Counter(y)\n#         for k in self.dist:\n#             self.dist[k] /= y.size\n        self.clf.fit(X, y, **fit_params)\n        self.threshold_optimizer.fit(self.predict(X), y)\n    \n    def predict(self, X, **predict_params):\n        pred = self.clf.predict(X)\n        if predict_params.get('classify'):\n            return self.classify(pred)\n        return pred\n    \n    def set_params(self, **kwargs):\n        self.clf = self.clf.set_params(**kwargs)\n        \n    def classify(self, pred):\n#         acum = 0\n#         bound = {}\n#         for i in range(3):\n#             acum += self.dist[i]\n#             bound[i] = np.percentile(pred, acum * 100)\n#         # print('y_classify bounds:', bound)\n        \n#         def classify_example(x):\n#             if x <= bound[0]:\n#                 return 0\n#             elif x <= bound[1]:\n#                 return 1\n#             elif x <= bound[2]:\n#                 return 2\n#             else:\n#                 return 3\n        \n#         return list(map(classify_example, pred))\n        return self.threshold_optimizer.predict(pred)\n    \n    def predict_and_classify(self, X):\n        return self.classify(self.predict(X))\n    \n    def predict_proba(self, X):\n        return self.predict_and_classify(X)\n    \n    def decision_function(self, X):\n        return self.predict_and_classify(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom functools import partial\nfrom sklearn.metrics import cohen_kappa_score\nimport scipy as sp\nimport numpy as np\n\nclass OptimizedRounder(object):\n    def __init__(self, labels):\n        self.coef_ = 0\n        self.labels = labels\n    \n    def _kappa_loss(self, coef, X, y):\n#         print(coef)\n        if len(set(coef)) != len(coef):\n            return 0\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = self.labels)\n        return -cohen_kappa_score(y, preds, weights = 'quadratic')\n    \n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = [0.5, 1.5, 2.5]\n        constraints = ({'type': 'ineq', 'fun' : lambda x: x[1] - x[0] - 0.001},\n                       {'type': 'ineq', 'fun' : lambda x: x[2] - x[1] - 0.001})\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'COBYLA', constraints=constraints)\n    \n    def predict(self, X, coef=None):\n        coef = coef if coef else self.coefficients()\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = self.labels)\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats = installation_features = pd.read_csv(\"../input/dsb-feats-v2/installation_features_v2.csv\")\nlabels = installation_labels = pd.read_csv(\"../input/dsb-feats-v2/installation_labels_v2.csv\")\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(feats.shape)\nprint(labels.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.svm import SVC \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, cohen_kappa_score\nimport xgboost as xgb\nfrom sklearn.utils import class_weight\nfrom sklearn.ensemble import VotingRegressor\nimport tensorflow as tf\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef build_model(input_shape=[538], hidden_units=[64], learning_rate=0.003, dropout=0, l1=0, l2=0, epochs=20):\n    model = keras.Sequential([\n        layers.Input(input_shape)\n    ])\n    for hu in hidden_units:\n        model.add(layers.Dense(hu, activation=tf.keras.layers.LeakyReLU(), kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n        model.add(layers.Dropout(dropout))\n    model.add(layers.Dense(1))\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\n    model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n    return model\n\nclass KerasRegressor_v2(KerasRegressor):\n    def __init__(self, build_fn, **kwargs):\n        super().__init__(build_fn, **kwargs)\n        self._estimator_type = \"regressor\"\n\n\n# feature_pipe=features.get_data_processing_pipe(feats,log_features=['game_time', 'event_count'], categorical_features=['last_world', 'last_assessment'])\nfeature_pipe=get_data_processing_pipe(feats,\n                                               log_features=list(filter(lambda c: c.startswith('event') or \n                                                                                  c.endswith('event_count') or\n                                                                                  c.endswith('game_time') or\n                                                                                  c.startswith('eid_'), \n                                                                        feats.columns)), \n                                               categorical_features=['last_world', 'last_assessment'])\n\nxgb_params = {'colsample_bytree': 0.3, \n              'learning_rate': 0.03, \n              'max_depth': 7, \n              'n_estimators': 300, \n              'reg_alpha': 10, \n              'subsample': 0.8}\nmlp_params = {\n    'dropout': 0.1,\n    'epochs': 20,\n    'hidden_units': (128, 128),\n    'l1': 0.001,\n    'l2': 0.0,\n    'learning_rate': 0.0001,\n}  \n\n\nordinal_pipe = Pipeline(steps=[\n    ('preprocess', feature_pipe),\n    ('clf', OrdinalRegressor(VotingRegressor, estimators=[('xgb', xgb.XGBRegressor(**xgb_params)), \n                                                          ('mlp', KerasRegressor_v2(build_model, **mlp_params))],\n                                              weights=(0.7,0.3)))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_feats, _ = basic_user_features_transform(test)\n\nfor c in feats.columns:\n    if c not in test_feats.columns:\n        test_feats[c] = 0\n        \ninstallation_ids = test_feats.installation_id\ntest_X = test_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_pipe.fit(feats[sorted(feats.columns)], labels.accuracy_group)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = ordinal_pipe.predict(test_X[sorted(feats.columns)], **{'classify': True})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({'installation_id':installation_ids, 'accuracy_group':test_predict}).to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"test_predict.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}