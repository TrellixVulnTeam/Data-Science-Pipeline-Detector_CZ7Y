{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\npd.set_option('display.max_colwidth', -1)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***\n## Some facts about the provided datasets\nThe train_labels.csv has 3,614 unique installation id while train.csv has 17,000 unique installation id. <br>\nThe test.csv and sample_submission.csv file have 1000 same unique installation id. <br>\nI'll combine the test.csv and train.csv for model training. <br>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_y_test_sample = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\ndf_specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\ndf_x_train = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train.csv\")\ndf_y_train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\ndf_x_train = df_x_train.loc[df_x_train['installation_id'].isin(df_y_train['installation_id'].unique())]\ndf_x_test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\ndf_x_train = pd.concat([df_x_train,df_x_test])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## This Session Looks at Where the Assessments take place <br>\nActivities in each world is training different skills. <br>\nCRYSTALCAVES - Weight <br>\nMAGMAPEAK - Capacity <br>\nTREETOPCITY - Weight and Length <br>\n\nAssessments take places in different world is testing different skills.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_x_train.loc[df_x_train['type']=='Assessment'].groupby(\n        by=['world','title'], as_index=False\n        ).count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above test shows that the training data will have balanced training cases. Certain Assessments might have correlation between them. <br>\nCRYSTALCAVES  Cart Balancer (Assessment)       Weight <br>\nCRYSTALCAVES  Chest Sorter (Assessment)        Weight <br>\nMAGMAPEAK     Cauldron Filler (Assessment)     Capacity <br>\nTREETOPCITY   Mushroom Sorter (Assessment)     Length <br>\nTREETOPCITY   Bird Measurer (Assessment)       Length <br>\n<br>\nShould we train three models for assessments in three worlds or should we combine them all and train by random forest? How about test both and see which score higher?"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering <br>\n1. Time spent in the world where the assessment takes place. Usually the assessment takes place right after the training inside that world. Game session is created by title - Needs to group by world before the assessment take place; <br>\n   For activities use duration, for clips use count;\n2. Time spent in each assessment session;\n3. Number of previous participation in similar assessment;"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_duration = df_x_train.groupby(\n    by=['type','installation_id','game_session','world','title'], as_index=False\n        ).aggregate({'timestamp': ['min', 'max']}\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_duration['duration'] = pd.to_datetime(df_train_duration[\"timestamp\"][\"max\"]) -pd.to_datetime(df_train_duration[\"timestamp\"][\"min\"])\ndf_train_duration.columns=['type','installation_id','game_session','world','title','timestamp_min','timestamp_max','duration']\ndf_train_duration['timestamp_min']=pd.to_datetime(df_train_duration['timestamp_min'])\ndf_train_duration['timestamp_max']=pd.to_datetime(df_train_duration['timestamp_max'])\ndf_train_duration.sort_values(by=[\"installation_id\",\"world\",\"timestamp_min\"],inplace=True)\ndf_train_duration = df_train_duration.loc[df_train_duration['world'].isin(['MAGMAPEAK', 'TREETOPCITY', 'CRYSTALCAVES'])]\ndf_train_duration.reset_index(inplace=True)\ndf_train_duration.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Count cumulative clips, activity/game duration before each assessment by installation_id and world"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_duration['clip_count']=0\ndf_train_duration['cum_duration'] = df_train_duration.loc[0].duration\ndf_train_duration['pre_assess'] = 0\nfor i,row in df_train_duration.iterrows():\n    if(i==0 or (row['installation_id'] != df_train_duration.loc[i-1].installation_id) or (row['world'] != df_train_duration.loc[i-1].world)):\n        if(row.type == 'Clip'):\n            df_train_duration.at[i,'clip_count'] = 1\n    else: \n        if(row.type == 'Clip'):\n            df_train_duration.at[i,'clip_count'] = df_train_duration.loc[i-1]['clip_count'] +1\n        else:\n            df_train_duration.at[i,'clip_count'] = df_train_duration.loc[i-1]['clip_count'] \n        df_train_duration.at[i,'cum_duration'] = row.duration + df_train_duration.loc[i-1]['cum_duration']\n        if(row.type=='Assessment'):\n            df_train_duration.at[i,'pre_assess'] = df_train_duration.loc[i-1]['pre_assess'] + 1\n        else:\n            df_train_duration.at[i,'pre_assess'] = df_train_duration.loc[i-1]['pre_assess']\ndf_train_duration= df_train_duration.loc[df_train_duration['type']=='Assessment']\ndf_train_duration.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_event = df_x_train.loc[df_x_train['type']=='Assessment']\ndf_train_event = df_train_event[df_train_event['event_code'].isin(['4100','4110'])].reset_index()\ndf_train_event['correct'] = pd.io.json.json_normalize(df_train_event.event_data.apply(json.loads))[\"correct\"]\n\ndf_train_event=df_train_event.groupby(\n    by=['installation_id','game_session','world','title','event_code','correct'], as_index=False\n).count()\n\ndf_train_event=df_train_event.pivot_table(index=['installation_id','game_session','world','title'], columns='correct', values='event_id'\n                             ).reset_index()\ndf_train_event=df_train_event.fillna(0)\ndf_train_event.columns=['installation_id','game_session','world','title','nbr_false','nbr_true']\ndf_train_event['total'] = df_train_event['nbr_true'] + df_train_event['nbr_false']\ndf_train_event['accuracy'] = df_train_event['nbr_true']/df_train_event['total']\nbins = [-0.01,0, 0.49, 0.5, 1]\ngroup_names = [0,1,2,3]\ndf_train_event['group'] = pd.cut(df_train_event['accuracy'], bins, labels=group_names)\nresult = pd.merge(df_train_duration, df_train_event, how='left', on=['installation_id','game_session','world','title'])\nresult = result[['installation_id','game_session','world','title','duration','clip_count','cum_duration','pre_assess','group']]\nresult['pre_assess'] = result['pre_assess']+1\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['nbr_duration'] = [x.seconds for x in result['duration']]\nresult['nbr_cumduration'] = [x.seconds for x in result['cum_duration']]\ntrain = result[result['group']>=0]\npred =  result[result['group'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier\nimport eli5\nfrom eli5.sklearn import PermutationImportance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_TREE= train[train['world']=='TREETOPCITY']\ntrain_MAGM=train[train['world']=='MAGMAPEAK']\ntrain_CRYS=train[train['world']=='CRYSTALCAVES']\npred_TREE= pred[pred['world']=='TREETOPCITY']\npred_MAGM=pred[pred['world']=='MAGMAPEAK']\npred_CRYS=pred[pred['world']=='CRYSTALCAVES']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create target object and call it y\ndef model_train(train,pred):\n    y = train.group\n    # Create X\n    features = ['nbr_duration','clip_count','nbr_cumduration','pre_assess']\n    X = train[features]\n    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n    forest_model = RandomForestClassifier(n_estimators=10, random_state=1)\n    forest_model.fit(train_X, train_y)\n    val_predictions = forest_model.predict(val_X)\n\n    val_mae = mean_absolute_error(val_predictions, val_y)\n    val_accuracy = accuracy_score(val_predictions, val_y)\n    pred_y = forest_model.predict(pred[features])\n    print(val_mae, val_accuracy)\n    return pred_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_TREE_y= model_train(train_TREE,pred_TREE)\npred_MAGM_y=model_train(train_MAGM,pred_MAGM)\npred_CRYS_y=model_train(train_CRYS,pred_CRYS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_TREE['accuracy_group'] = pred_TREE_y.astype(int)\npred_MAGM['accuracy_group'] = pred_MAGM_y.astype(int)\npred_CRYS['accuracy_group'] = pred_CRYS_y.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_final = pd.concat([pred_TREE,pred_MAGM,pred_CRYS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.merge(df_y_test_sample[['installation_id']],pred_final[['installation_id','accuracy_group']],how='left',on=['installation_id'])\nsubmit.drop_duplicates(subset=None, keep='first', inplace=True)\nsubmit.drop_duplicates(subset=['installation_id'], keep='first', inplace=True)\nsubmit.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}