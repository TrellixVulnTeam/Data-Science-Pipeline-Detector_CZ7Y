{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center;font-size:30px;\" > Kids Measure Up! Learning Analysis </h1>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# List of Contents :\n* Description\n* Problem Statement\n* Source of Data\n* Business Objectives and Constrains\n* Data Overview\n* Features in the Dataset\n* Mapping Real World Problem to Machine Learning Problem\n* Performance Metric"},{"metadata":{},"cell_type":"markdown","source":"# Description"},{"metadata":{},"cell_type":"markdown","source":"Early learning apps are now becoming very popular for kids (age 3-5 yrs) to learn the basic concepts like length, height , weight and colors etc. PCB Kids Measure app is one of the most popular learning apps across the United-State which is funded by the U.S. department of education. This App allows kids to learn in a fun way by playing games and watching video and can see their most favourite cartoon so they love to come again and again.\n\n\n<br>Data Science Bowl is the world's largest Data Science competition and announces a challenging task each year allowing competitors to solve problems for social good. PCB Kids Measure app is their fifth competition which is presented by Booz Allen Hamilton and Kaggle.\n\n\nhttps://www.kaggle.com/c/data-science-bowl-2019/overview"},{"metadata":{},"cell_type":"markdown","source":"# problem Statement\nThe task is to predict the number of attempts that a child will take to pass the given Assessment using gameplay data."},{"metadata":{},"cell_type":"markdown","source":"# Source of Data\n\nData set is available in the form of four csv files which are train.csv, test.csv, specs.csv and train_labels.csv.\n\nRefer : https://www.kaggle.com/c/data-science-bowl-2019/data"},{"metadata":{},"cell_type":"markdown","source":"# Business Objectives and Constrain\n### latency Requirement\nNo strict latency constrain but prediction within an hour is preferable.\n### Effect of misclassification\nMisclassification will couse bad customer experience and it might recude number of installation_id in future.\n### Performance Objectives\nPredict the data with correct class as many as possible with high precision and high recall."},{"metadata":{},"cell_type":"markdown","source":"# Data Overview\nData is available in the form of four csv files and brief desciption is below :\n### train.csv\n<pre>\n<b>File size</b> - 3.16 GB<br />\n<b>Number of entry</b> - 11.3 M<br />\n<b>Number of Columns</b> - 11 <br />\n<b>Name of Columns</b> - {'event_id','game_session','time_stamp','event_data','installation_id','event_count','event_code','game_time','title','type','world'}<br />\n<b>Number of unique installation_id</b> - 17000 <br />\n</pre>\n\n### test.csv\n<pre>\n<b>File size</b> - 379.87 MB<br />\n<b>Number of entry</b> - 1.1 M<br />\n<b>Number of Columns</b> - 11 <br />\n<b>Name of Columns</b> - {'event_id','game_session','time_stamp','event_data','installation_id','event_count','event_code','game_time','title','type','world'}<br />\n<b>Number of unique installation_id</b> - 1000 <br />\n</pre>\n\n### specs.csv\n<pre>\n<b>File size</b> - 399.29 KB <br />\n<b>Number of entry</b> - 386 <br />\n<b>Number of Columns</b> - 3 <br />\n<b>Name of Columns</b> - {'event_id','info','arg'}<br />\n</pre>\n\n### train_labels.csv\n<pre>\n<b>File size</b> - 1.01 MB <br />\n<b>Number of entry</b> - 17690 <br />\n<b>Number of Columns</b> - 7 <br />\n<b>Name of Columns</b> - {'game_session','installation_id','title','num_correct','num_incorrect','accuracy','accuracy_group'}<br />\n</pre>"},{"metadata":{},"cell_type":"markdown","source":"# Features in the data set\nThis reference blog helps me alot to understand the features of the data set.\n\n<u>https://medium.com/@boxinthemiddle/pbs-kids-measure-up-learning-analytics-part-1-9facbdafcdb5</u>\n\n### train.csv and test.csv"},{"metadata":{},"cell_type":"markdown","source":"<table border=\"1\">\n\t<tr>\n\t\t<th style=\"text-align:center\">Field Name</th>\n\t\t<th style=\"text-align:center\">Description</th>\n\t</tr>\n    <tr>\n        <td style=\"text-align:left\">event_id</td>\n        <td style=\"text-align:left\">Randomly generated unique identifier for the event type. Maps to event_id\n                                    column in specs table. Total number of unique event _id is 384.\n        </td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">game_session</td>\n        <td style=\"text-align:left\">game_session is randomly generated id for specific installation_id.\n                                    Game_session will not change until the user regines And when he/she comes to                                       play next time a new session will be allotted to them.\n        </td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">time_stamp</td>\n        <td style=\"text-align:left\">it is the record of the actual time when the game was playing and \n                                    the time is in the format of yyyy-mm-ddThh:mm:ss.mmmZ.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">event_data</td>\n        <td style=\"text-align:left\">Semi-structured JSON formatted string containing the events parameters.\n                                    Default fields are: event_count</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">installation_id</td>\n        <td style=\"text-align:left\">Unique for each installation and it represent a user.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">event_count</td>\n        <td style=\"text-align:left\">Counts of number of games played after starting game_session</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">event_code</td>\n        <td style=\"text-align:left\"> Identifier of the event 'class'. Unique per game, but may be duplicated across                                      games. E.g. event code '2000' always identifies the 'Start Game' event for all                                      games. Extracted from event_data.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">game_time</td>\n        <td style=\"text-align:left\">Time in milliseconds since the start of the game session. Extracted from                                           event_data.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">title</td>\n        <td style=\"text-align:left\">Title of the game or video.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">type</td>\n        <td style=\"text-align:left\">Media type of the game or video. Possible values are:\n            <ol>\n                <li> <strong>Game</strong> - game is task based . In order to go on to the next level a user has to                                          <br>finish the task for that level. </li>\n                <li> <strong>Clip</strong> - user will finish the task where concept or rules are explained in a                                            <br>short video. </li>\n                <li> <strong>Activity</strong> - This is comparatively long where children do not have any specific                                          <br>task . They can finish the activity when they are done. </li>\n                <li> <strong>Assessment</strong> - The user will reach an assessment after finishing several games                                          <br>, clips and activity. Assessment can be thought of as a fun exam where                                        <br>user will use all the skills which they have learnt in previous.</li>\n           </ol>\n        </td>\n    </tr> \n    <tr>\n        <td style=\"text-align:left\">worls</td>\n        <td style=\"text-align:left\">Specific set of measurement.\n           <ol>\n                <li> <strong>None</strong> - At the apps start screen </li>\n                <li> <strong>TREETOPCITY</strong> - for height and length retaled skills. </li>\n                <li> <strong>MAGMAPEAK</strong> - for capacity related skills. </li>\n                <li> <strong>CRYSTALCAVES</strong> - for weights related skills</li>\n           </ol>\n        </td>\n    </tr>\n</table>"},{"metadata":{},"cell_type":"markdown","source":"### specs.csv\nThis file contains specification of various event types."},{"metadata":{},"cell_type":"markdown","source":"<table border='1'>\n    <tr>\n        <th style=\"text-align:center\">Field Name</th>\n        <th style=\"text-align:center\">Description</th>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">event_id</td>\n        <td style=\"text-align:left\">Global unique identifier for the event type. Joins to event_id column in events                                     table.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">info</td>\n        <td style=\"text-align:left\">Description of the event</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">args</td>\n        <td style=\"text-align:left\">JSON formatted string of event arguments. Each argument contains:\n        <ol>\n            <li><strong>name</strong> - Argument name.</li>\n            <li><strong>type</strong> - Type of the argument (string, int, number, object, array).</li>\n            <li><strong>info</strong> - Description of the argument.</li>\n        </ol>\n        </td>\n    </tr>\n    \n</table>"},{"metadata":{},"cell_type":"markdown","source":"### train_labels.csv\nThe file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set. Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110. If the attempt was correct, it contains \"correct\":true."},{"metadata":{},"cell_type":"markdown","source":"<table border='1'>\n    <tr>\n        <th style=\"text-align:center\">Field Name</th>\n        <th style=\"text-align: center\">Description</th>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\"> game_session</td>\n        <td style=\"text-align:left\">game_session is randomly generated id for specific installation_id.\n            Game_session will not change until the user regines\n            And when he/she comes to play next time a new session will be allotted to them.\n        </td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">installation_id</td>\n        <td style=\"text-align:left\">Unique for each installation and it represent a user.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">title</td>\n        <td style=\"text-align:left\">Title of the game or video.</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">num_correct</td>\n        <td style=\"text-align:left\">number of True(correct) counts for an Assessment event having event_code = 4100 \n                and 4110. Only bird measurer Assessment has event_code 4110</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">num_incorrect</td>\n        <td style=\"text-align:left\">number of False(incorrect) counts for an Assessment event having event_code =                                       4100 and 4110. Only bird measurer Assessment has event_code 4110</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">accuracy</td>\n        <td style=\"text-align:left\">it is ratio of num_correct and (num_correct + num_incorrect)</td>\n    </tr>\n    <tr>\n        <td style=\"text-align:left\">accuracy_group</td>\n        <td style=\"text-align:left\">The outcomes in this competition are grouped into 4 groups \n            <br>(labeled accuracy_group in the data):\n            <ol>\n                <li><strong>3</strong>: the assessment was solved on the first attempt</li>\n                <li><strong>2</strong>: the assessment was solved on the second attempt</li>\n                <li><strong>1</strong>: the assessment was solved after 3 or more attempts</li>\n                <li><strong>0</strong>: the assessment was never solved</li>\n            </ol>\n        </td>\n    </tr>\n</table>"},{"metadata":{},"cell_type":"markdown","source":"# Mapping Real world problem to Machine Learning problem"},{"metadata":{},"cell_type":"markdown","source":"### Type of Machine Learning Problem\nThis is multiclass classification task. For given query data we need to predict the number of attempts that the user will take to pass the assessment and decide accuracy_group accordingly. "},{"metadata":{},"cell_type":"markdown","source":"# Performance Metrics (Quadratic Weighted Kappa (QWK))"},{"metadata":{},"cell_type":"markdown","source":"Final score is evaluated using quadratic weighted kappa (QWK) which is measure of agreement between actual and predicted class. The range of this metric is generally 0 to 1. If QWK is 1 means actual and predicted class matches perfectly and if QWK is 0 means agreement happened by chance. QWK value can also take negative value which means the prediction is worse than by chance. QWK is calculated by \n\nNumber of classes is $N=4$ in this task\n\n$$ \\kappa = 1 - \\frac{\\sum_{i,j} w_{i,j} O_{i,j}}{\\sum_{i,j} w_{i,j} E_{i,j}} $$\n\nwhere $w_{i,j}$ is \n$$ w_{i,j} = \\frac{(i-j)^2}{(N-1)^2} $$\n\n$O$ is N-by-N matrix which is nothing but confusion matrix.\nActual_value_counts and predicted_value_counts are 1-by-N dimensional vector which is histogram of actula class and predicted class . $E$ is N-by-N matrix which is outer product of Actual_value_counts,predicted_value_counts.\n\nhttps://www.kaggle.com/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps"},{"metadata":{},"cell_type":"markdown","source":"# Load required libreries and methods "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import confusion_matrix\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data files"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\ntest = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\ntrain_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\nsample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('training data shape',train.shape)\nprint('test data shape',test.shape)\n\nunique_id_train = len(train['installation_id'].unique())\nunique_id_test = len(test['installation_id'].unique())\n\nprint('number of unique installation_id in training data' ,unique_id_train)\nprint('number of unique installation_id in test data' ,unique_id_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n### training data cleaning"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# reference : https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline\n# Some of the installation_id from training data do not attempt for Assessment even for a single time.\n# First we will get rid of those ids as we will not able to predict the class.\nrequired_id = train[train['type'] == \"Assessment\"]['installation_id'].drop_duplicates()\ntrain = pd.merge(train, required_id , on=\"installation_id\", how=\"inner\")\n\nunique_id_train = len(train['installation_id'].unique())\n\nprint('training data shape',train.shape)\nprint('number of unique installation_id in training data',unique_id_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Number of training data reduced to 8.2 M from 11.3 M and number of installation_id reduced to 4242 from 17000."},{"metadata":{},"cell_type":"markdown","source":"### test data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# In test data also we have some installation id that attempt for Assessment but corresponding event_code is not 4100 or 4110(Bird Measurer)\ntest[(test['installation_id']=='017c5718') & (test['type']=='Assessment')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Though event type is Assessment but corresponding event_code is not 4100 or 4110 . So we won't able to predict the class for this installation_id.\nwe can simply remove those id or we need to make an assumption. I assumed that those ids belongs to class 0"},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n### Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference : https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline\n# In the reference blog they have used two separate function for featurization. I slightly modified and compressed it in only one function.\ndef get_features(installation_id , dataframe_for_an_id , test_flag=False):\n    '''\n    \n    This function will calculate features for train and test data. \n    It will create 4 columns for four unique world(including None) and\n    will create 44 columns for 44 unique title and\n    will create 4 columns for four unique type and\n    will create 42 columns for 42 unique event_code and\n    will create 6 more columns for 'total_duration','total_action','correct_count','incorrect_count','accuracy','accuracy_group'\n               ---\n        total  100 columns \n    \n    except total_duration, accuracy and accuracy_group all other features is number of counts of those feature in a game_session\n    if test_flag is True then return last entry of list \n    '''\n    # temp_dict initialized with keys (100 columns) and value = 0\n    features = []\n    features.extend(list(set(train['world'].unique()).union(set(test['world'].unique())))) # all unique worlds in train and test data\n    features.extend(list(set(train['title'].unique()).union(set(test['title'].unique())))) # all unique title in train and test data\n    features.extend(list(set(train['type'].unique()).union(set(test['type'].unique())))) # all unique type in train and test data\n    features.extend(list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))) # all unique event_code in train and test data \n    features.extend(['total_duration','total_action','correct_count','incorrect_count','accuracy','accuracy_group'])\n    temp_dict = dict.fromkeys(features,0)\n    list_of_features = []\n    \n    \n    def get_all_attempt(sample_df):\n        '''\n        This fuction will return the dataframe which is used to calculate accuracy_group\n        '''\n        if sample_df['title'].iloc[0] != 'Bird Measurer (Assessment)':\n            all_attempt = sample_df.query('event_code == 4100')\n        elif sample_df['title'].iloc[0] == 'Bird Measurer (Assessment)':\n            all_attempt = sample_df.query('event_code == 4110')\n        return all_attempt\n    \n    for i, sample_df in dataframe_for_an_id.groupby(by = ['game_session']):\n        # sample_df is groupby object \n        # In sample_df 'type','title' and 'world' will not change so first entry of those column is piced\n        temp_dict['installation_id'] = installation_id\n        temp_type = sample_df['type'].iloc[0]\n        temp_title = sample_df['title'].iloc[0]\n        temp_world = sample_df['world'].iloc[0]\n        temp_event_code = Counter(sample_df['event_code'].values)\n\n        session_size = len(sample_df)\n\n        temp_dict[temp_type]+=session_size\n        temp_dict[temp_title]+=session_size    # corresponding type , title and world is incremented by session size\n        temp_dict[temp_world]+=session_size                 \n\n        for code, code_count in temp_event_code.items():    # corresponding event_code is incremented\n            temp_dict[code]+= code_count                  \n            \n        duration_in_sec = float(sample_df['game_time'].iloc[-1])/1000   # total_duration is duration of game_session in seconds\n        temp_dict['total_duration'] += duration_in_sec\n        \n        action_count_in_game_session = session_size     # total number of action performed in game_session\n        temp_dict['total_action'] += action_count_in_game_session  \n        \n        isAssessment = temp_type == 'Assessment'\n        isBirdMeasureAssessment = isAssessment and temp_title == 'Bird Measurer (Assessment)'\n        isAssessment_with_code4110 = isBirdMeasureAssessment and 4110 in list(sample_df['event_code'])\n        isNonBirdMeasureAssessment = isAssessment and temp_title != 'Bird Measurer (Assessment)'\n        isAssessment_with_code4100 = isNonBirdMeasureAssessment and 4100 in list(sample_df['event_code'])\n        \n        criterion_to_accuracy_group = isAssessment_with_code4110 or isAssessment_with_code4100 \n        \n        \n        if test_flag and isAssessment and (criterion_to_accuracy_group == False):\n            temp_dict['accuracy'] = 0           # there are lots of installation_id in test data that attempt for\n            temp_dict['accuracy_group'] = 0     # Assessment but not with event_code 4100 or 4110\n            list_of_features.append(temp_dict)  # So I assumed those id belongs to class 0\n            \n            \n        if criterion_to_accuracy_group == False:\n            continue\n        \n        # below section is only performed when criterion_to_accuracy_group is True\n        \n        all_attempt = get_all_attempt(sample_df)\n        correct_count = all_attempt['event_data'].str.contains('true').sum()     \n        incorrect_count = all_attempt['event_data'].str.contains('false').sum()\n        temp_dict['correct_count'] = correct_count  \n        temp_dict['incorrect_count'] = incorrect_count\n\n        if correct_count == 0 and incorrect_count == 0:\n            temp_dict['accuracy'] = 0\n        else:\n            temp_dict['accuracy'] = correct_count/(correct_count + incorrect_count)\n\n        if temp_dict['accuracy']==1:\n            temp_dict['accuracy_group']=3\n        elif temp_dict['accuracy']==0.5:\n            temp_dict['accuracy_group']=2\n        elif temp_dict['accuracy']==0:\n            temp_dict['accuracy_group']=0\n        else :\n            temp_dict['accuracy_group']=1\n\n        list_of_features.append(temp_dict)\n        temp_dict = dict.fromkeys(features,0)\n        \n        \n    if test_flag:                    # If given data is from test data then return only the last entry of the list\n        return list_of_features[-1]\n    \n    return list_of_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference : https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline\n# below is testing code to check whether get_features function works properly for training data\nsample_df = train[train.installation_id == \"0006a69f\"]\nlist_of_feature = get_features(\"0006a69f\",sample_df)\nlist_of_feature\ntemp_df = pd.DataFrame(list_of_feature)\ntemp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference : https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline\n# below is testing code to check whether get_features function works properly for test data\nsample_df = train[train.installation_id == \"0006a69f\"]\nlist_of_feature = get_features('0006a69f',sample_df,True)\nlist_of_feature\ntemp_df = pd.DataFrame(list_of_feature,index=[0])\ntemp_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* All good , get_features function is working"},{"metadata":{},"cell_type":"markdown","source":"\n#### Prepare training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# reference : https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline\nfinal_training_data_list = []\ntraining_groupby_id = train.groupby(by=['installation_id']) \n\nfor installation_id , df_with_unique_id in tqdm(training_groupby_id):\n    final_training_data_list.extend(get_features(installation_id,df_with_unique_id))\n\nfinal_training_data = pd.DataFrame(final_training_data_list)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_training_data = pd.read_csv('/kaggle/input/final-training-data/final_training_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('featurized training data shape :',final_training_data.shape)\nfinal_training_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### preparing test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# reference : https://www.kaggle.com/erikbruin/data-science-bowl-2019-eda-and-baseline\nfinal_test_data_list = []\ntest_groupby_id = test.groupby(by=['installation_id'])\nfor installation_id , df_with_unique_id in tqdm(test_groupby_id):\n    final_test_data_list.append(get_features(installation_id,df_with_unique_id,True))\nfinal_test_data = pd.DataFrame(final_test_data_list)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test_data = pd.read_csv('/kaggle/input/final-test-data/final_test_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('featurized test data shape :',final_test_data.shape)\nfinal_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Classification Model\n# XGBClassifier\n* I have used XBGClassifier a lot and almost every time it performs best as compared to other linear model when data set contains less number of fetures. This is why I am choosing XGBClassifier to start with.\n\n### Train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nimport time\nfrom sklearn.metrics import make_scorer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference : https://www.kaggle.com/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps\n\ndef calculate_QWK(actual_label,predicted_label):\n    '''\n    this function will calculate quadratic weighted kappa given actual \n    and predicted label array.\n    '''\n    N = 4 # unique labels\n    hist_actual_label = np.zeros(N)\n    hist_predicted_label = np.zeros(N)\n    w = np.zeros((N,N))\n    numerator = 0       # w and O\n    denominator = 0     # w and E\n    \n    conf_mat = confusion_matrix(actual_label,predicted_label)\n\n    for i in actual_label:               # this part will calculate histogram for actual and predicted label\n        hist_actual_label[i]+=1\n    for j in predicted_label:\n        hist_predicted_label[j]+=1\n\n    E = np.outer(hist_actual_label, hist_predicted_label)  # E is N-by-N matrix which is outer product of \n                                                           # histogram of actual and predicted label    \n    for i in range(N):                   # w is N-by-N matrix which is calculated by the given expression\n        for j in range(N):\n            w[i][j] = (i-j)**2/((N-1)**2)\n\n    E = E/E.sum()\n    O = conf_mat/conf_mat.sum()  # normalize confusion matrix and E\n\n    for i in range(N):\n        for j in range(N):                # this section calculates numerator and denominator \n            numerator+=w[i][j]*O[i][j]\n            denominator+=w[i][j]*E[i][j]\n\n    kappa = 1-numerator/denominator\n    \n    return kappa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## testing code for function calculate_QWK()\nactual_label_temp = np.array([0,3,2,3,1,0,2,1,2,1,0])\npredicted_label_temp = np.array([0,3,2,3,1,0,2,1,2,1,0])\nprint('QWK when actual_label and predicted_label are same is :',calculate_QWK(actual_label_temp,predicted_label_temp))\n\nactual_label_temp = np.array([0,3,0,3,2,0,3,1,2,3,0])\npredicted_label_temp = np.array([0,3,2,3,1,0,2,1,2,1,0])\nprint('QWK when actual_label and predicted_label are different is :',calculate_QWK(actual_label_temp,predicted_label_temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_training_data.copy()\nX_test = final_test_data.copy()\ny = X['accuracy_group'].values\ny_test = X_test['accuracy_group'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## if we include features 'correct_count','incorect_count' and 'accuracy' to train a model then\n## it will become a trvial task like if-else condition to predict the label that we dont want. \n## we calculated 'correct_count','incorect_count' and 'accuracy' to get the label of training  and test data but\n## we want our model to predict the label without those feature thats why we will remove those feature.\n\nX = X.drop(['correct_count','incorrect_count','accuracy','accuracy_group','installation_id'], axis=1)\nX_test = X_test.drop(['correct_count','incorrect_count','accuracy','accuracy_group','installation_id'],axis =1)\n\nX_train, X_cv, y_train, y_cv = train_test_split(X, y,stratify=y,test_size=0.2)\nX_train = X_train.values\nX_cv = X_cv.values\nX_test = X_test.values\n\nprint('size of training data and labels :',X_train.shape,y_train.shape)\nprint('size of cv data and labels :',X_cv.shape,y_cv.shape)\nprint('size of test data and labels :',X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## train a very simple XGBClassifier base model with default parameter\nstart = time.time()\nmodel = XGBClassifier()\nmodel.fit(X_train,y_train)\n\nactual_label = y_test\npredicted_label = model.predict(X_test)\n\nprint('Quadratic weighted kappa with simple base model :',calculate_QWK(actual_label,predicted_label))\nprint('time: ',time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even for very simple baseline model we are getting very good result for test data. (QWK = 0.85)"},{"metadata":{},"cell_type":"markdown","source":"## hyper parameter tuning for XGBClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n# reference : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer\n'''\nstart = time.time()\nparams = {'max_depth':[3,4,5,6,7],\n          'min_child_weight':[0.01,0.1,1,10],\n          'n_estimators':[50,100,200,500]}\n\nQWK_scorer = make_scorer(calculate_QWK, greater_is_better=True)\n\nmodel  = xgb.XGBClassifier(booster='gbtree')\ngrid = RandomizedSearchCV(model, param_distributions=params, scoring = QWK_scorer, \\\n                    n_jobs=-1,cv=5,return_train_score=True) \n                                                \ngrid.fit(X_train,y_train) \n\nmodel = grid.best_estimator_\nmodel.fit(X_train,y_train)\n\nprint('time taken to train the model in sec:',time.time() - start)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"actual_label = y_train\npredicted_label = model.predict(X_train)\nprint('Quadratic weighed kappa for training data is :',calculate_QWK(actual_label,predicted_label))\n\nactual_label = y_cv\npredicted_label = model.predict(X_cv)\nprint('Quadratic weighed kappa for cross validation data is :',calculate_QWK(actual_label,predicted_label))\n\nactual_label = y_test\npredicted_label = model.predict(X_test)\nprint('Quadratic weighed kappa for test data is :',calculate_QWK(actual_label,predicted_label))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submitting solution"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame(data = final_test_data['installation_id'],columns=['installation_id'])\nmy_submission['accuracy_group'] = predicted_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = 0\nfor i in range(len(sample_submission)):\n    if sample_submission['installation_id'][i]==my_submission['installation_id'][i]:\n        k+=1\n    else:\n        print(sample_submission['installation_id'][i])\n        print(my_submission['installation_id'][i])\nprint(k)\ntype(sample_submission['accuracy_group'][0])==type(my_submission['accuracy_group'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_test_df = final_test_data.reset_index()\ncomp_test_df = comp_test_df[['installation_id']]\ncomp_test_df['accuracy_group'] = predicted_label\nsample_submission.drop('accuracy_group', inplace = True, axis = 1)\nsample_submission = sample_submission.merge(comp_test_df, on = 'installation_id')\nsample_submission.to_csv('submission.csv', index = False)\nprint('done !')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}