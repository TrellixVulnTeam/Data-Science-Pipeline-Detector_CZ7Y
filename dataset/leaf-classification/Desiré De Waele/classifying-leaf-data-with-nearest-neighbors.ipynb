{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"dc95189f-97e9-bf0a-d5b0-7f197f3dc8db"},"source":"# Nearest Neighbors\nIn this notebook, I will create a simple nearest neighbors model to classify the leaves dataset as provided by Kaggle. I make use of euclidean distances, k nearest neighbors, log loss as a metric and cross validation.\n\n* **Proccessing Data**\n    * Loading Dada\n    * Extract features & labels\n    * Normalize Features\n    * Training & Validation Split\n* **Nearest Neighbors**\n    * Euclidean Distances\n    * K Nearest Neighbors\n    * Probability Dataframe\n    * Predictions\n    * Log Loss Metric\n    * Cross-Validation\n    * Probabilities Testing Set"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d613868-0116-c2c2-fb04-50d4e21537a0"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"_cell_guid":"d4f9dd6f-0670-b164-33f8-b2f878234125"},"source":"# Proccess Data\n## Loading Data\nFirst, the train and test data is loaded into a pandas dataframe."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"901cce4e-d0bd-7564-c09a-19268c58bade"},"outputs":[],"source":"data = pd.read_csv('../input/train.csv', index_col=0)\ntestData = pd.read_csv('../input/test.csv', index_col=0)\ndata.head(6)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b5695232-d582-6d6d-b3c8-83d23917d2f2"},"source":"## Extract features & labels\nWe shuffle the data in this early stadium, to avoid index influence when splitting into training and validation sets. Next, the training labels and features are being separated."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b8f299a-b89c-a8cf-29cb-bc52f0a57361"},"outputs":[],"source":"data = data.sample(frac=1)\nfeatures = data[data.columns[1:193]]\nlabels = data['species']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43477e14-6519-e23c-9ddc-4b3ca526dc7a"},"outputs":[],"source":"features.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f1d6d741-d574-eff3-6066-789ffe7bcee9"},"source":"## Normalize Features\nThe training and testing features are being normalized."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91ba8691-377f-80f9-de97-0039f1d15a2a"},"outputs":[],"source":"features = features / np.linalg.norm(features, axis=0)\ntestData = testData / np.linalg.norm(testData, axis=0)\nfeatures.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"42b3bc5e-ef25-3a24-5ad9-b6357f5d2021"},"source":"## Training & Validation Split\nTo test some later helper functions, we split the training data into a train and validation set. Later, we'll do this again via cross-validation. For now, we put aside one tenth for validation. As we shuffled already, we can just split via indeces."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"310818d0-ddfe-7ba7-25fe-3d48ae6d2770"},"outputs":[],"source":"trainFeatures = features.iloc[:891,:]\nvalidFeatures = features.iloc[891:,:]\ntrainLabels =  labels.iloc[:891]\nvalidLabels = labels.iloc[891:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"29b96d8e-77e3-f6b9-758d-1b9b2b47f1b2"},"source":"# Nearest Neighbors\n## Euclidean Distances\nLet's say we want to get the closest neighbor in the training set for the datapoint with index 1 in the validation set. We create a function to calculate all euclidean distances between this query on the one hand, and all training points on the other. Then, we take a look at the label of the training point with the lowest distance. The label turns out to be the same as the label of the query."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9bb1153-263e-c509-bbae-9c73e86a1e91"},"outputs":[],"source":"#Computes distance(s) between a query and training point(s)\ndef computeDistances(trainData, query):\n    distances = np.sqrt(np.sum((trainData - query)**2, axis=1))\n    return distances\ndistances = computeDistances(trainFeatures, validFeatures.iloc[1,:])\ntrainLabels.loc[distances.argmin()]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf3b59d2-519a-19a2-2fb1-3cf4e77a4dfd"},"outputs":[],"source":"validLabels.iloc[1]"},{"cell_type":"markdown","metadata":{"_cell_guid":"cde3cc91-ac4f-8020-1ea4-c8682ed76ab6"},"source":"## K Nearest Neighbors\nNow, we would like a given number (k) of close neighbors, representing a probability distribution. All k nearest neighbors are equally weighted, each with a probability of 1/k. We create a function that, for a given query, returns a dictionary with the closest neighbors and their probabilities as the value."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47642074-1292-99ca-7fca-9765dfe50d6a"},"outputs":[],"source":"def getNearestNeighbors(trainFeatures, trainLabels, query, k):\n    distances = computeDistances(trainFeatures, query)\n    lowestTen = distances.sort_values().head(k).index\n    results = dict()\n    for x in trainLabels[lowestTen]:\n        if x not in results:\n            results[x] = 1/float(k)\n        else:\n            results[x] += 1/float(k)\n    return results"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2264e707-e528-c546-b9b3-e7968a826e33"},"outputs":[],"source":"getNearestNeighbors(trainFeatures, trainLabels, validFeatures.iloc[1,:], 10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"624c97d8-2b18-1c4c-9b2f-b23e453ccf8e"},"source":"So in this instance with k=10, each 0.1 acts as a 'vote' for that leaf class."},{"cell_type":"markdown","metadata":{"_cell_guid":"87527548-d305-e9f5-6fbe-d2a7e98df105"},"source":"## Probability Dataframe\nThe purpose of the following, is to generate dictionaries as above for all queries in a validation or test set, and to collect the probabilities in one dataframe. First, we store all the unique leaf classes in alphabetical order for this dataframe. We initiate this probability dataframe with all zeros. Then, we loop per query through the closest neighbors, adjusting the appropriate position in the probability dataframe."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ebef5c10-266b-2793-7da1-2f0547d5b5fc"},"outputs":[],"source":"def getProbabilities(trainFeatures, trainLabels, testFeatures, k):\n    leaves = np.unique(data.species.sort_values().values)\n    probabilities = pd.DataFrame(0, index=testFeatures.index, columns=leaves)\n    for index, query in zip(testFeatures.index, testFeatures.values):\n        for key, value in getNearestNeighbors(trainFeatures, trainLabels, query, k).items():\n            probabilities.loc[index, key] = value\n    return probabilities"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"435bd6ff-2c52-f2db-48a5-7e199cb193a2"},"outputs":[],"source":"getProbabilities(trainFeatures, trainLabels, validFeatures, 100).head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b45b651d-ba97-bb71-76a1-0f20c5f59f30"},"source":"Here we used a massive k-value, just to view some probabilities. Note that each row will sum to one, as it forms a probability distribution of the 99 leaf classes."},{"cell_type":"markdown","metadata":{"_cell_guid":"fce78f29-72dd-6676-6fc4-6017a3ba69a9"},"source":"## Predictions\nBased on the probabilites, we are now interested in the leaf class with the highest probabilty, as this one would of course be our prediction if we had to make one. So we generate a probability dataframe, and return the leaf class with the highest probability per row."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2aae265-6797-9aab-1473-7982956a5962"},"outputs":[],"source":"def getPredictions(trainFeatures, trainLabels, testFeatures, k):\n    testProbabilities = getProbabilities(trainFeatures, trainLabels, testFeatures, k)\n    return testProbabilities.idxmax(axis = 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"216f7f7e-6c24-88df-0d5e-9fcb5d70e934"},"outputs":[],"source":"validPredictions = getPredictions(trainFeatures, trainLabels, validFeatures, 10)\nvalidPredictions.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"02b37a6b-e206-ff10-558e-d7a0c3fffabb"},"source":"The above leaf classes are our predictions for the first five validation leaves, based on ten nearest neighbors. We'll see next that the log loss is a more interesting metric, but at the point, we could calculate the accuracy as well. We just check how many times the our prediction corresponds with the label, and divide this number by the total number of labels."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62bff194-f8c5-fa4f-23e7-18a0ad0e19f6"},"outputs":[],"source":"accuracy = sum(validPredictions==validLabels)/float(len(validLabels))\naccuracy"},{"cell_type":"markdown","metadata":{"_cell_guid":"e8ba61d7-1351-5e5d-a10f-1e3b739ebf20"},"source":"## Log Loss Metric\nThe log loss is the metric uses at Kaggle, and accounts for (un)certainty. This is the formula, where L is the number of query leaves, C is the number of leaf classes, y is a binary value indicating whether leaf l actually belongs to class c (1 of so, 0 if not), and p is the probability that leaf l belongs to class c.\n\n$$\\text{logloss} = -\\frac{1}{L}\\sum_{l=1}^L\\sum_{c=1}^C{y_{lc}log(p_{lc})}$$"},{"cell_type":"markdown","metadata":{"_cell_guid":"1889646d-a53c-299a-3f8e-5219a9516dea"},"source":"Here we implement the log loss function for a given training and validation set. Note that we substitute extreme values (0 and 1) in the probability matrix by very close values (0.0...01 and 0.99...) to make the log working."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d2792b0-2baf-cba7-2a2c-3e5b16178aa7"},"outputs":[],"source":"def getLogLoss(trainFeatures, trainLabels, validFeatures, validLabels, k):\n    leaves = np.unique(data.species.sort_values().values)\n    validProbabilities = getProbabilities(trainFeatures, trainLabels, validFeatures, k)\n    totalLoss = 0\n    for index, row in zip(validProbabilities.index, validProbabilities.values):\n        bools = np.zeros(99)\n        bools[np.where(leaves==validLabels.loc[index])] = 1\n        probs = np.zeros(len(row))\n        for i, x in enumerate(row):\n            probs[i] = np.log(max(min(x,1-10**-15),10**-15))\n        totalLoss += sum(bools*probs)\n    logLoss = totalLoss / -len(validProbabilities.values)\n    return logLoss"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0818e386-81fb-eac6-47a7-95280aa51a02"},"outputs":[],"source":"for i in range(15):\n    print('k = ' + str(i+1) + ': ' + str(getLogLoss(trainFeatures, trainLabels, validFeatures, validLabels, i+1)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"2954d28e-3b1f-76f6-b782-d7e2e0f77c0c"},"source":"Here we calculated the logloss for 10 different values of k."},{"cell_type":"markdown","metadata":{"_cell_guid":"64a403ce-8a09-8d30-d4e6-899e65253806"},"source":"## Cross-Validation\nThe log loss as calculated above is quite heavily influenced by the choice of the test and validations split, though. By cross-validation, we reduce this variation. For a given number of folds, we run a logLoss on shifting validation sets. We then take the average of theses losses as our final logloss. The function takes the original features and labels as arguments."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7dcb7b04-e25f-91dd-6fc3-a9b67ff33eab"},"outputs":[],"source":"def crossValidation(features, labels, folds, k):\n    n = len(features)\n    totalLoss = 0\n    for i in range(folds):\n        start = int((n*i)/folds)\n        end = int((n*(i+1))/folds)\n        validFeatures = features.iloc[start:end,:]   \n        validLabels = labels.iloc[start:end]   \n        trainFeatures = features.iloc[0:start,:].append(features.iloc[end:n,:])        \n        trainLabels = labels.iloc[0:start].append(labels.iloc[end:n])        \n        totalLoss += getLogLoss(trainFeatures, trainLabels, validFeatures, validLabels, k)\n    averageLoss = totalLoss / folds\n    return averageLoss"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3cdfa8c4-790d-d16e-9dac-0583de0a3ac0"},"outputs":[],"source":"lossAll = np.zeros(15)\nfor i in range(15):\n    lossAll[i] = crossValidation(features, labels, folds=10, k=i+1)\n    print('k = ' + str(i+1) + ': ' + str(lossAll[i]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"5794b937-aeb4-1280-7364-f52825ef49be"},"source":"Here we did the same as above, but with cross-validation (folding the data 10 times). The differenses are: (1) the values are much more stable and will be similar when rerun, (2) the calculation takes longer as, per k-value, the logLoss is calculated ten times. We can simply visualize these numbers to see that a k-value of about 5 results in the lowest logloss."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d12af0d-61d8-a7d9-af41-2cc7972a147c"},"outputs":[],"source":"plt.plot(range(1, 16),lossAll, 'r')\nplt.xlabel('# Nearest Neighbors = k')\nplt.ylabel('logLoss')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f84eeeaf-283d-ea3a-232a-5a376a8cb44c"},"source":"## Probabilities Testing Set\nGiven the loglosses calculated above, we create a probability dataframe with k=5, based on all of the training data, for the test set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52f8a548-6436-9f2c-a938-e173d8247ab1"},"outputs":[],"source":"submission = getProbabilities(features, labels, testData, 5)\nsubmission.head()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}