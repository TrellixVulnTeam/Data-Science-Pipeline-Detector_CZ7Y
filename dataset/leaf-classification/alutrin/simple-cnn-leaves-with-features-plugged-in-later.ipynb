{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"43270a6a-d7d2-55eb-be70-e06e6e89a87f"},"source":"Train on the images with convolutions and then add the rest of the features when going to the FC nets"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31198acf-02a0-a813-0965-5eb95ecd2671"},"outputs":[],"source":"%matplotlib inline\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers.core import Flatten, Dense, Dropout, Lambda\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.optimizers import Adam\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing import image\nfrom PIL import Image\n\nfrom numpy import array\nimport numpy as np\n\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nbatch_size = 64;\ndim = 20;"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1eae2e50-1a80-0d7b-1864-d594ab352b0b"},"outputs":[],"source":"trainRows = pd.read_csv('../input/train.csv')\ntestRows = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b218919-b00c-a982-dccc-6edab09c464a"},"outputs":[],"source":"xAll = np.empty((len(trainRows['id']), dim, dim, 1)) \nprint(xAll.shape)\ni = 0\nfor id in trainRows['id']:\n    filename = \"../input/images/\"+str(id)+\".jpg\"\n    im = Image.open(filename)\n    im.thumbnail([dim, dim])\n    im = array(im)\n    height, width = im.shape\n    \n    #calculate destination coordinates\n    h1 = int((dim - height) / 2)\n    h2 = h1 + height\n    w1 = int((dim - width) / 2)\n    w2 = w1 + width\n    \n    xAll[i, h1:h2, w1:w2, 0] = im\n    i += 1\n    \nprint(xAll.shape)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07560412-4bfb-bb1b-bb1a-2aa2122cf91c"},"outputs":[],"source":"yAll = trainRows.pop('species')\nyAll = LabelEncoder().fit(yAll).transform(yAll)\nyAll = to_categorical(yAll)\nyAll.shape\ntrainRows.pop('id')\nfeaturesAll = StandardScaler().fit(trainRows).transform(trainRows)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2f35871-848c-1ba7-7cb9-80910274e92a"},"outputs":[],"source":"#start with a simple FC layer\n\nmeanX = xAll.mean().astype(np.float32)\nstdX = xAll.std().astype(np.float32)\n\ndef normalize(x): \n    return (x-meanX)/stdX\n\ndef enrich(x):\n    #take a flattened image array and add the additional parameters\n    return ('foo')\n\nmodel = Sequential([\n    Lambda(normalize, input_shape=(dim,dim,1)),\n        Convolution2D(16,3,3, activation='elu'),\n        Convolution2D(16,3,3, activation='elu'),\n        MaxPooling2D(),\n        Convolution2D(32,3,3, activation='elu'),\n        ZeroPadding2D((1, 1)),\n        Convolution2D(32,3,3, activation='elu'),\n        MaxPooling2D(),\n        Flatten(),\n        Dense(20, activation='elu'),\n        Dense(yAll.shape[1], activation='softmax')\n    ])\nmodel.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3d52914-ce82-73f3-2c41-639664432491"},"outputs":[],"source":"#split test and validation\nsss = StratifiedShuffleSplit(n_splits=1, train_size=0.7, random_state=0)\ntrainIndex, valIndex = next(sss.split(xAll, yAll))\nxTrain, yTrain = xAll[trainIndex], yAll[trainIndex]\nfeaturesTrain = featuresAll[trainIndex]\nxVal, yVal = xAll[valIndex], yAll[valIndex]\nfeaturesVal = featuresAll[valIndex]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"765673ef-87bf-852e-e2d8-bae7fb3e1fe3"},"outputs":[],"source":"print(xTrain.shape)\nprint(yTrain.shape)\nprint(xVal.shape)\nprint(yVal.shape)\nprint(featuresTrain.shape)\nprint(featuresVal.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fbaa36a6-4657-07dd-d67d-b8b0c64935fe"},"outputs":[],"source":"generator = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3, \n                                     height_shift_range=0.08, zoom_range=0.08)\ntrainBatches = generator.flow(xTrain, yTrain, batch_size=batch_size)\nvalBatches = generator.flow(xVal, yVal, batch_size=batch_size)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"432f28f4-8353-1a96-6c7a-69892c8b0432"},"outputs":[],"source":"model.fit_generator(trainBatches, trainBatches.n, nb_epoch=1, \n                    validation_data=valBatches, nb_val_samples=valBatches.n)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}