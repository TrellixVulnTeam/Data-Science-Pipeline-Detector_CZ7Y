{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CNN for classifier， Do not use image Data\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nclass Data_Clean(object):\n    def __init__(self):\n        self.numerical_data, self.num_test_data = self.read_numerical_data()\n        self.id, self.species, self.num_train, self.test_id, self.test_num = self.split_numerical_data()\n\n    def split_numerical_data(self):\n        #将numerical data划分为id, species,和训练集\n        id = self.numerical_data.pop('id')\n        species = self.numerical_data.pop('species')\n        species = LabelEncoder().fit(species).transform(species)\n        species = to_categorical(species, num_classes=99)\n        self.numerical_data = StandardScaler().fit(self.numerical_data).transform(self.numerical_data)\n\n        test_id = self.num_test_data.pop('id')\n        num_test_data = StandardScaler().fit(self.num_test_data).transform(self.num_test_data)\n        return id, species, self.numerical_data, test_id, num_test_data\n\n    def read_numerical_data(self):\n        root = \"../input\"\n        data = pd.read_csv('%s/train.csv' %root)\n        test_data = pd.read_csv('%s/test.csv' %(root))\n        return data, test_data\n\n    def run(self):\n        ##Check the data\n        # print('id:', self.id.loc[0])\n        # print('species:', self.species[0])\n        # print('feature:', self.num_train[0])\n        # plt.imshow(self.image_data[0].reshape(960, 960), cmap='gray')\n        # plt.show()\n        return self.species, self.num_train, self.test_num, self.test_id\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ReduceLROnPlateau\n\nclass CNN(object):\n    def __init__(self, num_train, num_vali, species_train, species_vali, num_test, test_id):\n        self.num_train = num_train\n        self.num_vali = num_vali\n        self.species_train = species_train\n        self.species_vali = species_vali\n        self.num_test = num_test\n        self.test_id = test_id\n\n    def define_CNN(self):\n        model = Sequential()  #0.9798\n        model.add(Dense(512, activation='relu', input_dim=192))\n        model.add(Dropout(0.25))\n        model.add(Dense(512, activation='relu'))\n        model.add(Dropout(0.25))\n        model.add(Dense(99, activation='softmax'))\n        self.model = model\n\n\n    def RMSprop(self, batch_size, epoch):\n        optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-8, decay=0.0)\n        self.model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n        self.model.fit(self.num_train, self.species_train, batch_size=batch_size, epochs=epoch,\n                       validation_data=(self.num_vali, self.species_vali), verbose=2, callbacks=[learning_rate_reduction])\n\n    def make_predict(self):\n        ypred_prob = self.model.predict(self.num_test)\n        root = \"../input\"\n        labels = sorted(pd.read_csv(os.path.join(root, 'train.csv')).species.unique())\n        ypred = pd.DataFrame(ypred_prob, index = self.test_id, columns=labels)\n        print(ypred.head(2))\n        fp = open('submit.csv', 'w')\n        fp.write(ypred.to_csv())\n\n    def run(self):\n        self.define_CNN()\n        self.RMSprop(batch_size = 128, epoch=100)\n        self.make_predict()\n\n\nif __name__ == '__main__':\n    data_clean = Data_Clean()\n    species, num, num_test,  test_id = data_clean.run()\n    #划分训练集和测试集\n    species_train, species_vali, num_train, num_vali = train_test_split(species, num, test_size=0.1, random_state=26)\n\n    #搭建CNN模型，看看CNN对图像的分类情况\n    cnn = CNN(num_train, num_vali,species_train, species_vali, num_test, test_id)\n    cnn.run()\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}