{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"05d34c74-de29-128a-de17-993fe6365f36"},"source":"**Getting the Right Classifier**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a2aadfe2-7527-4860-9987-24a50728bc09"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef warn(*args, **kwargs): pass\nimport warnings\nwarnings.warn = warn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# from subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1550b8fb-1bf8-8a13-1db9-2e55abb43218"},"outputs":[],"source":"# Swiss army knife function to organize the data\n\ndef encode(train, test):\n    le = LabelEncoder().fit(train.species) \n    labels = le.transform(train.species)           # encode species strings\n    classes = list(le.classes_)                    # save column names for submission\n    test_ids = test.id                             # save test ids for submission\n    \n    train = train.drop(['species', 'id'], axis=1)  \n    test = test.drop(['id'], axis=1)\n    \n    return train, labels, test, test_ids, classes\n\ntrain, labels, test, test_ids, classes = encode(train, test)\ntrain.head(1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d999039-d989-4a63-b056-a330e53e5e02"},"outputs":[],"source":"sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n\nfor train_index, test_index in sss:\n    X_train, X_test = train.values[train_index], train.values[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6907122d-8d72-83c9-fb01-cf19e2404304"},"outputs":[],"source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    NuSVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis()]\n\n# Logging for Visual Comparison\nlog_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\nlog = pd.DataFrame(columns=log_cols)\n\nfor clf in classifiers:\n    clf.fit(X_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    train_predictions = clf.predict(X_test)\n    acc = accuracy_score(y_test, train_predictions)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_predictions = clf.predict_proba(X_test)\n    ll = log_loss(y_test, train_predictions)\n    print(\"Log Loss: {}\".format(ll))\n    \n    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\"*30)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ab69c67-df98-ff1d-4eb7-b30053a19e06"},"outputs":[],"source":"sns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n\nplt.xlabel('Accuracy %')\nplt.title('Classifier Accuracy')\nplt.show()\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n\nplt.xlabel('Log Loss')\nplt.title('Classifier Log Loss')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0595fff5-fd40-a68c-102e-dafbef1f4ec3"},"outputs":[],"source":"# Predict Test Set\nfavorite_clf = LinearDiscriminantAnalysis()\nfavorite_clf.fit(X_train, y_train)\ntest_predictions = favorite_clf.predict_proba(test)\n\n# Format DataFrame\nsubmission = pd.DataFrame(test_predictions, columns=classes)\nsubmission.insert(0, 'id', test_ids)\nsubmission.reset_index()\n\n# Export Submission\nsubmission.to_csv('submission.csv', index = False)\nsubmission.tail()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78088b7c-a779-ba22-ed26-68d789ee78e8"},"outputs":[],"source":"from subprocess import check_output\nprint(check_output([\"ls\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16cfa3e6-559f-7884-56d1-25b63908bc2f"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}