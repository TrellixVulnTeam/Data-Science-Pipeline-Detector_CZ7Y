{"cells":[{"metadata":{"_uuid":"bb57b05a-f44e-4e3f-9d1c-2e097e38bd61","_cell_guid":"64cb162f-754d-4504-b161-580e134c1818","trusted":true},"cell_type":"markdown","source":"## Loading Libraries & setup"},{"metadata":{"_uuid":"3eb0cc9f-d665-4895-be53-83186182c13f","_cell_guid":"d75fb006-3f15-4f37-9056-79bd0008ba9d","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport time\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a55e5c6-a649-408e-93d8-61fa7b5d498b","_cell_guid":"2bfc4dfb-f6ae-4b06-9fa0-67138d10c06b","trusted":true},"cell_type":"markdown","source":"Define methods\n- to plot images by id and by species (related to training examples)\n- to (re)load data form csv files (train, test or predictions)"},{"metadata":{"_uuid":"e6df0ce5-2939-4a06-aee2-237e4f31fbe4","_cell_guid":"bc66e4d6-ef75-47a3-8359-c4157e86f0d4","trusted":true},"cell_type":"code","source":"def plot_img(img):\n    plt.imshow(img, cmap='gray')\n    plt.axis(\"off\")\n    plt.show()\n    \ndef plot_img_by_id(id, species = ''):\n    src = './LeafClassification/' + str(id) + '.jpg'\n    img = imread(src)\n    plt.imshow(img, cmap='gray')\n    plt.suptitle('Predicted species: ' + species)\n    plt.axis(\"off\")\n    plt.show()\n    \ndef plot_img_by_species(species):\n    ldir = './training_data/' + str(species) + '/'\n    plt.figure(figsize=(28,28))\n    #plt.suptitle('Predicted species: ' + species)\n    x, y = len(os.listdir(ldir)), 1\n     \n    i = 1\n    print(species)\n    for d in os.listdir(ldir):\n        src = ldir + d\n        img = imread(src)\n        \n        plt.subplot(y, x, i)\n        plt.imshow(img, cmap='gray')\n        plt.axis(\"off\")\n        i += 1\n            \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ade89e1b-b99f-4c9a-b6c8-3afd4711f1d3","_cell_guid":"0d6732dd-4cd4-4762-81c9-68e5bbb5bf79","trusted":true},"cell_type":"code","source":"# method to reload data\ndef reload_data():\n    # Load test & train datasets\n    train_data = pd.read_csv(\"train.csv\")\n    test_data = pd.read_csv(\"test.csv\")\n    df = [train_data, test_data]\n    df = pd.concat(df, axis=0, sort=False)\n    \n    return train_data, test_data, df\n\n# load predictions\ndef load_pred():\n    # id should be index\n    pred = pd.read_csv(\"predictions.csv\", index_col='id')\n    return pred\n\ntrain_data, test_data, df = reload_data()\n# for backup reason\ntrain_data_copy, test_data_copy, df = reload_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fef1a08-ac03-4d80-a255-b72142d1395d","_cell_guid":"d32a9468-6881-472a-9d9a-1d40305e1b0f","trusted":true},"cell_type":"code","source":"print(train_data.shape)\ntrain_data.describe()\ntrain_data.head()\n\nprint(df.shape)\ndf.describe()\ndf.head()\n\nprint(test_data.shape)\ntest_data.describe()\ntest_data.head()","execution_count":0,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Move files into applicable folder, a training_data and test_data folder will be created.\nThe training_data folder will contain a subfolder for each species containing all images."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Source file \nsourcefolder = os.getcwd() + '/'\nsubdirs = ['/training_data/', '/test_data/']\nlabeldirs = train_data['species'].unique()\n\nfor subdir in subdirs:\n   \n    newdir_parent = '.' + subdir#+ labldir\n    if not os.path.exists(newdir_parent):\n        print(newdir_parent)\n        os.mkdir(newdir_parent)\n    \n    ##### merge df and images; seperate according to df['species']; put image in species folder;\n    \n    for labldir in labeldirs:    \n    # create label subdirectories\n        newdir_child = newdir_parent + labldir\n        #print(newdir_child)\n        if not os.path.exists(newdir_child) and subdir == '/training_data/':\n            #print(newdir_child)\n            os.mkdir(newdir_child)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# move train data info folder\nfor i, val in train_data.iterrows():\n    cdir = val['species']\n    fname = int(val['id'])\n    src = './LeafClassification/' + str(fname) + '.jpg'\n    dst = sourcefolder + '/training_data/' + str(cdir) + '/' + str(fname) + '.jpg'\n    #print(i, int(val['id']), val['species'])\n    #print('src: ' + str(src))\n    #print('dst:' + str(dst))\n    copyfile(src, dst)\n\n# move test data into folder    \nfor i, val in test_data.iterrows():\n    fname = int(val['id'])\n    src = './LeafClassification/' + str(fname) + '.jpg'\n    dst = sourcefolder + '/test_data/' + str(fname) + '.jpg'\n    #print(i, int(val['id']))\n    #print('src: ' + str(src))\n    #print('dst:' + str(dst))\n    copyfile(src, dst)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8dd7a23f-a63f-4c03-aefc-e2b8c7d6d73d","_cell_guid":"d5d95659-bb12-4b65-9705-7a9357df05ba","trusted":true},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"_uuid":"f2882989-8acd-41ec-9a34-ee6f581c2184","_cell_guid":"a82828c5-213e-4bdd-bedc-2dcb2e7d394a","trusted":true},"cell_type":"code","source":"# remove column 'id' from train data und save in variable train_id\ntrain_id = train_data.pop('id')\ntest_id = test_data.pop('id')\n\n# remove column 'species' from train data und save in variable train_y, then transform into categorical\ntrain_y = train_data.pop('species')\ntrain_y = LabelEncoder().fit(train_y).transform(train_y)\ntrain_y = to_categorical(train_y)\n\n#scale training data\ntrain_x = StandardScaler().fit(train_data).transform(train_data)\ntest_x = StandardScaler().fit(test_data).transform(test_data)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## retain class balances\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.2,random_state=12345)\ntrain_index, val_index = next(iter(sss.split(train_x, train_y)))\nx_train, x_val = train_x[train_index], train_x[val_index]\ny_train, y_val = train_y[train_index], train_y[val_index]\nprint(\"x_train dim: \",x_train.shape)\nprint(\"x_val dim:   \",x_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling: Build Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dim = train_x.shape[1]\nEPOCHS = 100\nbatch_size = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(1024,input_dim=input_dim))\nmodel.add(Dropout(0.2))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(512))\nmodel.add(Dropout(0.3))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(99))\nmodel.add(Activation('softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile model\nmodel.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit model\nstart = time.time()\nhistory = model.fit(train_x,train_y,validation_data=(x_val, y_val),batch_size=batch_size,epoch=EPOCHS,verbose=0)\nend = time.time()\nprint(round((end-start),2), \"seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot accuracy and loss for check on training"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n#plt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='lower right')\nplt.show()\n\nprint('-'*50)\nprint('Training accuracy: ' + str(max(history.history['acc'])))\nprint('Validation accuracy: ' + str(max(history.history['val_acc'])))\nprint('-'*50)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n#plt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper right')\nplt.show()\n\nprint('-'*50)\nprint('Training loss: ' + str(min(history.history['loss'])))\nprint('Validation loss: ' + str(min(history.history['val_loss'])))\nprint('-'*50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_y = model.predict_proba(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species = train_data_copy.species.unique()\npredict_out = pd.DataFrame(predict_y,index=test_id,columns=sorted(species))\npredict_out['predicted species'] = predict_out.idxmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_out.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Iterate over a limited amount of prediction images am compare training images and predicted test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check predicted with training data\ncheck_limit = 2\nfor (i,val) in predict_out.iterrows():\n    plot_img_by_id(i, species = val['predicted species']) # i is should be same as val['id']\n    print('-'*50)\n    plot_img_by_species(val['predicted species'])\n    check_limit -= 1\n    if check_limit <= 0:\n        break\n        \n#plot_img_by_id(4, species = 'Quercus_Agrifolia')\n#plot_img_by_species('Quercus_Agrifolia')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save model & predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.save_weights('./models/leaf_classification_weights_best.h5')\nmodel.save('./models/leaf_classification_model_best.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# write file to csv\nfp = open('predictions_neuralnetwork_1.csv','w')\nfp.write(predict_out.to_csv())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}