{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f233b788-b106-605a-0ca0-8bf857c4b696"},"source":"Since I'm beginner, I've decided to explore what seems to be the easiest of ML algorythms for classification: Logistic Regression. Since I still have to fully understand how to find the best parameters for the regularization process, I've decided to give a try to the LogisticRegressionCV. This implementation apparently will try to select the best hyperparameters.\n\nIf anyone would like to share information on how to select the regularization parameter, please leave a comment below :)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4cec602-8fc3-3b64-9206-b7cc86552899"},"outputs":[],"source":"import pandas as pd\nimport time\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.linear_model import LogisticRegressionCV\n\ndef encode_df(train, test):\n    le = LabelEncoder().fit(train.species) \n    labels = le.transform(train.species)           # encode species strings\n    classes = list(le.classes_)                    # save column names for submission\n    test_ids = test.id                             # save test ids for submission\n    \n    train = train.drop(['species', 'id'], axis=1)  \n    test = test.drop(['id'], axis=1)\n    \n    cols_s = [c for c in train.columns if 'shape' in c]\n    cols_t = [c for c in train.columns if 'texture' in c]\n    cols_m = [c for c in train.columns if 'margin' in c]\n    cols_st = [c for c in train.columns if ('shape' in c or 'texture' in c)]\n    cols_mt = [c for c in train.columns if ('margin' in c or 'texture' in c)]\n    cols_sm = [c for c in train.columns if ('margin' in c or 'shape' in c)]\n\n    train_set = [train[cols_s], train[cols_m], train[cols_t], train[cols_st], train[cols_sm], train[cols_mt], train]\n    test_set = [test[cols_s], test[cols_m], test[cols_t], test[cols_st], test[cols_sm], test[cols_mt], test]\n    \n    feat_order = [\"Shape\", \"Margin\", \"Texture\", \"Shape-Texture\", \"Shape-Margin\", \"Margin-Texture\", \"All Features\"]\n    \n    return labels, test_ids, classes, train_set, test_set, feat_order\n\n# load the data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nlabels, test_ids, classes, train_set, test_set, feat_order = encode_df(train, test)\n\n# Logging for Visual Comparison\nlog_cols=[\"Features\", \"Accuracy\", \"Log Loss\", \"Score\", \"Elapsed Time\"]\nlogFrame = pd.DataFrame(columns=log_cols)\n\ni = 0\nfor tr, te in zip(train_set, test_set):\n    log_row = []\n    log_row.append(feat_order[i])\n    print(\"=\"*30)\n    print(feat_order[i])\n    i += 1\n\n    sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n    for train_index, test_index in sss:\n        X_train, X_test = tr.values[train_index], tr.values[test_index]\n        y_train, y_test = labels[train_index], labels[test_index]\n        \n    start_t = time.clock()\n    logist_regr = LogisticRegressionCV()\n    logist_regr.fit(X_train, y_train)\n    train_predictions = logist_regr.predict(X_test)\n    acc = accuracy_score(y_test, train_predictions)\n    log_row.append(acc)\n    train_predictions = logist_regr.predict_proba(X_test)\n    ll = log_loss(y_test, train_predictions)\n    log_row.append(ll)\n    log_row.append(logist_regr.score(X_test, y_test))\n    end_t = time.clock()\n    log_row.append(end_t - start_t)\n    \n    log_entry = pd.DataFrame([log_row], columns=log_cols)\n    logFrame = logFrame.append(log_entry)  "},{"cell_type":"markdown","metadata":{"_cell_guid":"eb224b76-ec86-8601-8eb2-494b5799a98c"},"source":"The Results\n===========\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f96dd5b-3542-1995-3d85-d8ec61c4913e"},"outputs":[],"source":"p1 = logFrame.plot(kind='barh', x=\"Features\", y=\"Accuracy\", legend=False, color=\"green\")\np1.set_xlabel(\"Accuracy\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"4576f52d-58a7-7b74-6898-3849b74f7f3c"},"source":"The results are quite clear: seems like Shape is not very useful. Margin and also Texture performs a lot better than Shape. Combining Shape with Margin or with Texture only sligthly improve the accuracy of the prediction. A better combination is Margin with Texture. Combining all three feautures only slightly improve the accuracy."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac7614e9-627b-3530-43d8-fca2ff6e28e7"},"outputs":[],"source":"p2 = logFrame.plot(kind='barh', x=\"Features\", y=\"Log Loss\", legend=False, color=\"darkorange\")\np2.set_xlabel(\"Log Loss\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4fd543e-3728-11e2-7902-d8c790024cf8"},"outputs":[],"source":"p3 = logFrame.plot(kind='barh', x=\"Features\", y='Elapsed Time', legend=False, color=\"royalblue\")\np3.set_xlabel(\"Elapsed Time [s]\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"90967fae-0112-63cc-f259-4d975f8a2729"},"source":"This is interesting: the elapsed time are way different from what I've got when i ran the script in my PC. This is probably due to the server overload.\nIn this list I'm going to show the elapsed time on my computer:\n\n - All features: 27.58s\n - Margin-Texture: 25.05s\n - Shape-Margin: 34.50s\n - Shape-Texture: 36.62s\n - Texture: 28.67s\n - Margin: 27.88s\n - Shape: 7.64s"},{"cell_type":"markdown","metadata":{"_cell_guid":"0a47086e-d547-b84c-6a97-c7880cb4a7e8"},"source":"Questions\n---------\n\n 1. Why is Shape permorming so bad?\n 2. Why the combination Shape-Texture and Shape-Margin take a lot longer\n    to compute than Margin-Texture?\n 3. Is there a way to predict if a feature will be usefull to the model\n    before running the model?\n\nPlease, feel free to add your opinion."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}