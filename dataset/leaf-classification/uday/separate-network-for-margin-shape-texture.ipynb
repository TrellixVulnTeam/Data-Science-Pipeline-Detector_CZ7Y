{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b357caf5-cda8-05c9-511b-283ad9ab7391"},"source":"###Merged keras NN with separate network for margin, shape and texture features "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d72eb32-db08-2702-cdf1-2e6a2e0f7b1b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94901936-0a82-89c7-a4f5-92f7a0a11fde"},"outputs":[],"source":"# import required libraries \n%pylab inline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\n# from sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras.models import Sequential, Merge\nfrom keras.layers import Dense,Dropout,Activation\nfrom keras.utils.np_utils import to_categorical\n#from keras.callbacks import EarlyStopping"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d04cd6ed-e0d6-a46b-9194-3e8630d6fe2e"},"outputs":[],"source":"data = pd.DataFrame.from_csv('../input/train.csv')\ny = data['species']\ny = LabelEncoder().fit(y).transform(y)\ny_cat = to_categorical(y)\n\nmargin = data.columns[1:65]\nmargin = data[margin].as_matrix()\nmargin = StandardScaler().fit(margin).transform(margin)\nshape = data.columns[65:129]\nshape = data[shape].as_matrix()\nshape = StandardScaler().fit(shape).transform(shape)\ntexture = data.columns[129:193]\ntexture = data[texture].as_matrix()\ntexture = StandardScaler().fit(texture).transform(texture)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8e62f2a-f226-e623-4345-ecc96276614f"},"outputs":[],"source":"# Define separate model for each meta feature and its 64 values \nmodelMargin = Sequential()\nmodelMargin.add(Dense(128, input_dim=64, activation='relu'))\nmodelMargin.add(Dropout(0.7))\n\nmodelShape = Sequential()\nmodelShape.add(Dense(128, input_dim=64, activation='relu'))\nmodelShape.add(Dropout(0.7))\n\nmodelTexture = Sequential()\nmodelTexture.add(Dense(128, input_dim=64, activation='relu'))\nmodelTexture.add(Dropout(0.7))\n\n# merge all models\nmerged = Merge([modelMargin, modelShape, modelTexture], mode='concat')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df1a3ff4-0238-ce18-6a3d-7f49546f4a93"},"outputs":[],"source":"model = Sequential()\nmodel.add(merged)\nmodel.add(Dense(99, activation='softmax'))\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(\n    [margin, shape, texture], \n    y_cat, \n    nb_epoch=350,\n    batch_size=32,\n    validation_split=0.1,\n    verbose=0\n)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63dabd43-3396-d47f-0e2d-3358c51a5bb5"},"outputs":[],"source":"# summarize history for loss\n## Plotting the loss with the number of iterations\n\nplt.semilogy(history.history['loss'])\nplt.semilogy(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7480faf-8030-711c-54f9-466eff9b0396"},"outputs":[],"source":"## read test file\ntest1 = pd.read_csv('../input/test.csv')\ntest = pd.DataFrame.from_csv('../input/test.csv')\nindex = test1.pop('id')\n# index = test['id']\n\ntestMargin = test[test.columns[0:64]].as_matrix()\ntestShape = test[test.columns[64:128]].as_matrix()\ntestTexture = test[test.columns[128:192]].as_matrix()\n\ntestMargin = StandardScaler().fit(testMargin).transform(testMargin)\ntestShape = StandardScaler().fit(testShape).transform(testShape)\ntestTexture = StandardScaler().fit(testTexture).transform(testTexture)\n\nyPred = model.predict_proba(\n    [testMargin, testShape, testTexture]\n)\n\n# ## Converting the test predictions in a dataframe as depicted by sample submission\ncolumns = data['species'].unique()\nyPred = pd.DataFrame(yPred, index=index, columns=sort(columns))\nfp = open('merged_nn2.csv','w')\nfp.write(yPred.to_csv())"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}