{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nsys.path = [\n    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n] + sys.path","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks.hooks import *\nfrom fastai.callbacks import *\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score,confusion_matrix\nimport matplotlib.image as image\nfrom tqdm.notebook import tqdm\nimport os\nimport gc\nimport zipfile\nimport openslide\nimport cv2\nfrom PIL import Image\nimport skimage.io as sk\nimport warnings\n# from torchsummary import summary\nfrom sys import getsizeof\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 8\nnum_workers = 4\nTRAIN = '/kaggle/input/prostate-cancer-grade-assessment/train_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sld = os.listdir(TRAIN)\nsld = [x[:-5] for x in sld]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_duplicates = pd.read_csv('../input/duplicates-panda/duplicates.csv')\nduplicate_files = df_duplicates['file2'].tolist()\ndf = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/train.csv')\ndf = df[df['image_id'].isin(sld)]\ndf = df[~df['image_id'].isin(duplicate_files)]\ndf.columns = ['fn', 'data_provider', 'isup_grade', 'gleason_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_tiles(img, mode=0):\n        result = []\n        h, w, c = img.shape\n        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n        img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n        img3 = img2.reshape(\n            img2.shape[0] // tile_size,\n            tile_size,\n            img2.shape[1] // tile_size,\n            tile_size,\n            3\n        )\n\n        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n        if len(img) < n_tiles:\n            img3 = np.pad(img3,[[0,N-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n        img3 = img3[idxs]\n        for i in range(len(img3)):\n            result.append({'img':img3[i], 'idx':i})\n        return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TiffImageItemList(ImageList):\n    def open(self,fn):\n        path = '/kaggle/input/prostate-cancer-grade-assessment/train_images/'\n        fl = path + str(fn)+'.tiff'\n        img = sk.MultiImage(fl)[1]\n        res = get_tiles(img)\n        imgs = []\n        for i in range(36):\n            im = res[i%len(res)]['img']\n            imgs.append(im)\n        imgs = np.array(imgs)\n        final_image = np.concatenate(np.array([np.concatenate(imgs[j:j+6],axis=1).astype(np.uint8) for j in range(0,36,6)]),axis=0)\n        final_image = cv2.resize(final_image, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n        \n        return vision.Image(pil2tensor(final_image,np.float32).div_(255))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (TiffImageItemList.from_df(df,path='',cols='fn')\n                          .split_by_rand_pct()\n                          .label_from_df(cols='isup_grade')\n                          .transform(get_transforms())\n                          .databunch(num_workers=4,bs=batch_size)\n                          .normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_img = data\nlen(data_img.train_ds), len(data_img.valid_ds), data_img.classes, data_img.train_ds[0][0].data.shape,data_img.c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kp = KappaScore()\nkp.weights = 'quadratic'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import model as enet\npretrained_model = {\n    'efficientnet-b3': '../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth'\n}\n\nenet_type = 'efficientnet-b3'\nout_dim = 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arch = enetv2(enet_type, out_dim=out_dim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(data_img, arch , metrics = [kp] , model_dir = '/kaggle/working/').to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('../input/prostate-cancer-efnetb3-fastai-custom-datablock/best_model_ft');\nlearn = learn.to_fp32()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/test.csv')\ndf.columns = ['image_id', 'data_provider', 'isup_grade', 'gleason_score']\ndata_dir = '../input/prostate-cancer-grade-assessment'\nimage_folder = os.path.join(data_dir, 'test_images')\nis_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\nimage_folder = image_folder if is_test else os.path.join(data_dir, 'train_images')\n\ntest = test_df if is_test else df.sample(n=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_test(fn,image_folder):     \n    path2 = image_folder +'/'\n    fl = path2 + str(fn)+'.tiff'\n    img = sk.MultiImage(fl)[1]\n    res = get_tiles(img)\n    imgs = []\n    for i in range(36):\n        im = res[i%len(res)]['img']\n        imgs.append(im)\n    imgs = np.array(imgs)\n    final_image = np.concatenate(np.array([np.concatenate(imgs[j:j+6],axis=1).astype(np.uint8) for j in range(0,36,6)]),axis=0)\n    final_image = cv2.resize(final_image, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n    return vision.Image(pil2tensor(final_image,np.float32).div_(255))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_name = test.image_id.values\npred = np.zeros(len(ts_name))\n    \nfor j in tqdm(range(len(ts_name))):\n    ans = int(learn.predict(image_test(ts_name[j],image_folder))[0])\n    pred[j] = ans\n        \nout = pd.DataFrame({'image_id':ts_name,'isup_grade':pred.astype(int)})\nout.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}