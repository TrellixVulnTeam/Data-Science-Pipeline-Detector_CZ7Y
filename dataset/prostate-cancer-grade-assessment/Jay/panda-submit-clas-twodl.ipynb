{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/pretrainedmodels\n!pip install /kaggle/input/pytorchimagemodels120\n!pip install /kaggle/input/efficientnet\n#!pip install /kaggle/input/pytorch-lightning-075/pytorch_lightning-0.7.5-py3-none-any.whl\n!pip install /kaggle/input/pytorch-lightning-081-whl/pytorch_lightning-0.8.1-py3-none-any.whl\n!pip install /kaggle/input/warmup\n!pip install /kaggle/input/albumentations\n#!pip install /kaggle/input/threadpoolctl-file/threadpoolctl-2.0.0-py3-none-any.whl\n#!pip install /kaggle/input/batchgenerators-edited\n!pip install /kaggle/input/imagecodecs/imagecodecs-2020.5.30-cp37-cp37m-manylinux2014_x86_64.whl\n!pip install /kaggle/input/tifffile/tifffile-2020.6.3-py3-none-any.whl\n!pip install /kaggle/input/panda-code-2\n\n!mkdir -p /root/.cache/torch/checkpoints/\n!cp /kaggle/input/efficientnetb0355c32eb/efficientnet-b0-355c32eb.pth /root/.cache/torch/checkpoints\n!cp /kaggle/input/my-efficientnetb008094119/my_efficientnet-b0-08094119.pth /root/.cache/torch/checkpoints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cat ../input/panda-code-2/kaggle_version.txt\n#hello world","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nfrom pathlib import Path\nimport torch\nfrom torch.utils.data import DataLoader as DataLoaderPytorch\nfrom tqdm import tqdm\nimport pandas as pd\n\nfrom panda.libs.model_loading import get_ckpt_path_from_dir\nfrom panda.models.classification_model import ClassificationModel\nfrom panda.data.tile_dataset import TileDataset\nfrom panda.libs.utils import flatten_2D_list\nfrom panda.data.transformations import get_transforms_classification\n\n    \ndef load_models(exp_names):\n    #model_dir = log_path / exp_name  # local\n    models = []\n    for exp_name in exp_names:\n        model_dir = Path(\"../input/panda-code-2/trained_models\") / exp_name  # kaggle\n        nr_checkpoints = 1\n        model_path = get_ckpt_path_from_dir(model_dir, nr=nr_checkpoints)\n        model_pathes = model_path if type(model_path) is list else [model_path]\n        for model_path in model_pathes:\n            print(f\"model_path: {model_path}\")\n            model = ClassificationModel.load_from_checkpoint(str(model_path))\n            model.eval()\n            model.to(device)\n            models.append(model)\n    return models\n    \n    \n# Remember to add _f0\n\n#exp_name = \"2umOr_wa0_all_bl0_ep100_f0\"\n#exp_name = \"2um_wa0_all_ep100_f0\"\n#exp_name = \"2umOr_wa0_ep70_f0\"\n#exp_names = [\"2umOr_wa0_bs10_ep50_f0\"]\n#exp_names = [\"2umOr_wa0_bs10_ep50_f3\"]\n#exp_names = [\"2umOr_wa0_bs10_ep50_f0\", \"2umOr_wa0_bs10_ep50_f1\", \"2umOr_wa0_bs10_ep50_f2\", \"2umOr_wa0_bs10_ep50_f3\",\n#            \"2umOr_wa0_bs10_ep50_f4\"]\n#exp_names = [\"2umOr_wa0_bs12_ep70_f0\", \"2umOr_wa0_bs12_ep70_f1\", \"2umOr_wa0_bs12_ep70_f2\", \"2umOr_wa0_bs12_ep70_f3\",\n#            \"2umOr_wa0_bs12_ep70_f4\"]\n#exp_names = [\"2umOr_wa0_bs10_ep70_f0\", \"2umOr_wa0_bs10_ep70_f1\", \"2umOr_wa0_bs10_ep70_f2\", \"2umOr_wa0_bs10_ep70_f3\",\n#            \"2umOr_wa0_bs10_ep70_f4\"]\n#exp_names = [f\"2umOr_wa0_bs12_ep30_bc1_hs1_inL_f{f}\" for f in range(5)]\n#exp_names = [f\"2umOr_wa0_bs12_ep50_bc1_hs1_inL_f{f}\" for f in range(5)]\n#exp_names = [f\"2umOr_wa0_bs12_ep70_bc1_hs1_inM_f{f}\" for f in range(5)]\n\n#exp_names = [f\"2umOr_wa0_cp1_f{f}\" for f in range(5)]\n#exp_names = [f\"2umOr_wa0_bs12_ep30_f{f}\" for f in range(5)]\n#exp_names = [f\"1umOr_wa0_ts512_bs3_ep20_f{f}\" for f in range(5)]\n#exp_names = [f\"1umOr_wa0_ts512_bs3_f{f}\" for f in range(5)]\n#exp_names = [f\"1umOr_wa0_ts512_bs3_f3\"]\n\n#exp_names = [f\"2umOr_wa0_bs12_ep30_f{f}\" for f in range(5)]\n#exp_names = [f\"1um_f3\"]\n#exp_names = [f\"1um_st1_f3\"]\n#exp_names = [f\"1um_do5_f3\"]\n#exp_names = [f\"1um_ep1_f3\"]\n#exp_names = [f\"1um_opRAd_f3\"]\n#exp_names = [f\"1um_bc1_hs1_inM_f3\"]\n#exp_names = [f\"1um_st1_bc1_hs1_inM_f3\"]\n#exp_names = [f\"1um_wd1e-6_f3\"]\n#exp_names = [f\"1um_st1_bhM_do5_ed1_opRAd_wd1e-6_gpu8_ep30_f3\"]\n#exp_names = [f\"1um_st1_bhM_do5_ed1_f3\"]  # ep30 von 50\n#exp_names = [f\"1um_st1_bhM_do5_ed1_opRAd_wd1e-6_ep30_f3\"]\n#exp_names = [f\"1um_st1_bhM_do5_ed1_opRAd_wd1e-6_cp1_ep30_f3\"]\n#exp_names = [f\"1um_st1_do5_f3\"]  # ep30 von 30\n#exp_names = [f\"1um_st1_bhM_mfR1_FIX_f3\"]\n#exp_names = [f\"1um_st1_bhM_mfR25_FIX_f3\"]\n#exp_names = [f\"1um_st1_bhM_mfR10_ep30_FIX_f3\"]\n#exp_names = [f\"1um_st1_bhM_mfR10_FIX_f3\"]\n\n#exp_names = [f\"1um_bhM_run2_f{f}\" for f in range(5)]\n#exp_names = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)]\n# This together with tta=6 resulted in error\n#exp_names = [f\"1um_bhM_run2_f{f}\" for f in range(5)] + [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)]\n#exp_names = [f\"1um_bhM_mfRP_ep20_f3\"]\n#exp_names = [f\"1um_bhM_mHy_ep20_f3\"]\n\n#exp_names = [f\"1um_bhM_fb1_f3\"]\n#exp_names = [f\"1um_st1_bhM_do4_wd1e-6_ed1_mfRP_ep50_f3\"]\n#exp_names = [f\"1um_bhM_mfRP_ep25_ed1_f3\"]\n\n#exp_names = [f\"1um_bhM_mfRP_ep40_f3\"]\n#exp_names = [f\"1um_bhM_mfRP_ep40_run2_f{f}\" for f in range(5)]\n#exp_names = [\"1um_st1_f3\", \"1um_wd1e-6_f3\", \"1um_st1_bhM_do4_wd1e-6_ed1_mfRP_ep50_f3\",\n#            \"1um_bhM_mfRP_ep25_ed1_f3\", \"1um_bhM_mfRP_ep40_f3\"] + [f\"1um_bhM_run2_f{f}\" for f in range(5)]\n#exp_names = [f\"1um_bhM_cm20_f3\"]\n#exp_names = [f\"1um_bhM_ag4_ep20_f3\"]\n\n#exp_names = [f\"1um_bhM_cm20_mrK_f3\"]\n#exp_names = [f\"1um_bhM_mfRP_ep40_mrK_f3\"]\n#exp_names = [f\"1um_bhM_mfRP_ep40_mrK_ts460_f3\"]\n\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_so1_eq1_po1_eiH_inH_bl1_rg1_ic1_f3\"]\n#exp_names = [f\"1um_bhM_cm20_mrK_f{f}\" for f in range(5)]\n#exp_names = [f\"1um_bhM_mHy_ep40_ag4_mrK_f3\"]\n\n#exp_names = [f\"1um_bhM_cm20_f3\"]  # ts712\n#exp_names = [f\"1um_bhM_mfRP_cm20_mrK_f3\"]\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_ls01_f3\"]\n\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_ep25_f3\"]\n#exp_names = [f\"1um_bhM_augAll_mfRP_mrK_ep25_f3\"]\n#exp_names = [f\"1um_bhM_cm25_augAll_f3\"]\n\n#exp_names = [f\"1um_bhM_run2_f{f}\" for f in range(5)]  # round before sum\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_ep25_f3\"]  # round before sum\n#exp_names = [f\"1um_bhM_cm20_run2_f{f}\" for f in range(5)]\n\n#exp_names = [f\"1um_bhM_run2_f{f}\" for f in range(5)]  # two tile modes\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_ep25_f3\"]  # two tile modes\n#exp_names = [f\"1um_bhM_cm20_top3_f3\"]\n\n#exp_names = [f\"1um_bhM_mHy_ep40_ag4_mrK_augAll_f3\"]\n#exp_names = [f\"1um_bhM_cm20_mrK_ts620_f3\"]\n\n#exp_names = [f\"1um_bhM_reg2_ep25_mfP_f3\"]\n#exp_names = [f\"1um_bhM_reg2_ep25_mfPF_f3\"]\n\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_ep25_ts256_f3\"]\n#exp_names = [f\"1um_bhM_reg2_ep25_mfRP_f3\"]\n#exp_names = [f\"1um_bhM_reg2_mfPSo_mrK_ep25_f3\"]\n\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_ep25_RgIcBl_f3\"]\n#exp_names = [f\"1um_bhM_reg2_mfRP_mrK_lr6e-4_f3\"]\n\n#exp_names = [f\"1um_bhM_reg2_ep25_mfRP_run2_f{f}\" for f in range(5)]\n#exp_names = [f\"1um_bhM_cm20_gpu1_f3\"]\n#exp_names = [f\"1um_bhM_reg2_ep25_mfRPF_f3\"]\n\n#exp_names = [f\"1um_bhM_cm20_mfNoDiff2_gpu2_f3\"]\n#exp_names = [f\"1um_bhM_ep10_mfNoDiff2_gpu2_f3\"]\n#exp_names = [f\"1um_bhM_cm20_mfNoDiff3_gpu2_f3\"]\n\n#exp_names = [f\"1um_bhM_cm20_reg2_RgIcBl_gpu2_f3\"]\n#exp_names = [f\"1um_bhM_cm20_gpu4_f3\"]\n#exp_names = [f\"1um_bhM_cm20_il1_f3\"]\n\n#exp_names = [f\"1um_bhM_ep15_cm40_reg2_RgIcBl_biMid_f3\"]\n#exp_names = [f\"1umOr_bhM_cm20_f3\"]\n#exp_names = [f\"1um_bhM_run2_f3\", f\"1um_bhM_run2_se1111_f3\", f\"1um_bhM_run2_se2222_f3\"]\n\n#exp_names = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)]  # rbs\n#exp_names = [f\"1um_bhM_cm20_st1_ts256_f3\"]  # rbs\n#exp_names = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)]  # rbens\n\n#exp_names = [f\"1um_bhM_cm20_st1_f3\"]\n#exp_names = [f\"1um_bhM_ep20_cm40_reg2_RgIcBlM_f{f}\" for f in range(5)]\n#exp_names = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_f{f}\" for f in range(5)]\n\n#exp_names_256 = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_f{f}\" for f in range(5)]\n#exp_names_512 = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)]\n\n#exp_names_256 = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_f{f}\" for f in range(5)] + [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_se2222_f{f}\" for f in range(5)]\n#exp_names_512 = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)] + [f\"1um_bhM_cm20_mrK_f{f}\" for f in range(5)]\n\n#exp_names_256 = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_f{f}\" for f in range(5)] + [f\"1um_bhM_reg2_ep25_mfPv2_RgIcBl_ts256_f{f}\" for f in range(5)]\n#exp_names_512 = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)]\n\n#exp_names_256 = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_f{f}\" for f in range(5)] + [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_se2222_f{f}\" for f in range(5)]\n#exp_names_512 = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)] + [f\"1um_bhM_cm40_st1_se1111_f{f}\" for f in range(5)]\n\n#exp_names_256 = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_f{f}\" for f in range(5)] + [f\"1um_bhM_reg2_ep25_mfP_RgIcBl_ts256_f{f}\" for f in range(5)]\n#exp_names_512 = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)] + [f\"1um_bhM_cm40_st1_se1111_f{f}\" for f in range(5)]\n\n#exp_names_256 = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_f{f}\" for f in range(5)] + [f\"1um_bhM_reg2_ep25_mfPv2_RgIcBl_ts256_f{f}\" for f in range(5)]\n#exp_names_512 = [f\"1um_st1_bhM_run2_f{f}\" for f in range(5)] + [f\"1um_bhM_cm20_mrK_reg2_RgIcBl_f{f}\" for f in range(5)]\n\nexp_names_256 = [f\"1um_bhM_reg2_ep25_mfRP_RgIcBl_ts256_se2222_f{f}\" for f in range(5)]\nexp_names_512 = [f\"1um_bhM_cm20_mrK_reg2_RgIcBl_f{f}\" for f in range(5)]\n\n\n# local\n#from panda.libs.utils import get_project_pathes\n#_, log_path, data_dir = get_project_pathes()\n#df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n#df_test = None\n\n# kaggle\ndata_dir = Path('../input/prostate-cancer-grade-assessment')\ndf_train = pd.read_csv(data_dir / 'train.csv')\ndf_test = pd.read_csv(data_dir / 'test.csv')\n\nimage_folder = data_dir / 'test_images'\nis_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\nimage_folder = image_folder if is_test else data_dir / 'train_images'\ndf = df_test if is_test else df_train.loc[:5]\n\nprint(f\"is_test: {is_test}\")\n\n#todo: adapt\n\n# Works with tta_nr=1\n#input_type = \"tiff_2um\"\n#batch_size = 8\n#num_workers = 4\n\n# Works with tta_nr=4\n#input_type = \"tiff_2um\"\n#batch_size = 4\n#num_workers = 2\n\n# Works with tta_nr=1\ninput_type = \"tiff_1um\"  # might be fast enough when faster drive -> copy part of train_images to ssd\nbatch_size = 2\nnum_workers = 2\n\ntta_nr = 1\n#tta_nr = 4\n#tta_nr = 6  # might need too much RAM\n\ntile_mode = 0\n#tile_mode = \"rand\"\n    \nhead_type = \"normal\"  # normal | hydra\n    \n\ndevice = torch.device('cuda')\nmodels_256 = load_models(exp_names_256)\nmodels_512 = load_models(exp_names_512)\n\n#todo important: change\n# normalize = models[0].hparams.normalize\nnormalize = False\n    \nif tta_nr > 1:\n    tfs_tile_train, tfs_all_train, _, _ = get_transforms_classification(False, False, False, \n                                                                        False, False, False,\n                                                                        prob=0.5, intensity=\"mid\", normalize=normalize)\n    \n    # Use color augmentations in TTA\n    #tfs_tile_train, tfs_all_train, _, _ = get_transforms_classification(True, True, False, \n    #                                                                    False, False, False,\n    #                                                                    prob=0.5, intensity=\"mid\", normalize=normalize)\nelse:\n    tfs_tile_train, tfs_all_train = None, None\n        \n        \n#tile_size = models[0].hparams.tile_size\n#tile_size = 512  # 712\n#n_tiles = models[0].hparams.n_tiles\n#n_tiles = 8**2  # 6**2\n\ndataset_256 = TileDataset(image_folder, df, 256, 256, 144, tile_mode=tile_mode,\n                      transform_tile=None, transform_all=None, invert=False,\n                      inference=True, input_type=input_type, overwrite_image_folder=False, tta_nr=tta_nr,\n                      normalize=normalize)\nloader_256 = DataLoaderPytorch(dataset_256, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\ndataset_512 = TileDataset(image_folder, df, 512, 512, 36, tile_mode=tile_mode,\n                      transform_tile=None, transform_all=None, invert=False,\n                      inference=True, input_type=input_type, overwrite_image_folder=False, tta_nr=tta_nr,\n                      normalize=normalize)\nloader_512 = DataLoaderPytorch(dataset_512, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\nlogits = []\nwith torch.no_grad():\n    for idx, data_both in enumerate(zip(loader_256, loader_512)):\n        data_256 = data_both[0]\n        data_512 = data_both[1]\n        logits_batch_ens = []  # [nr_models, bs, nr_classes]\n        \n        for model in models_256:\n            data = data_256\n            for tta_idx in range(tta_nr):\n                if tta_nr > 1:\n                    data_tta = data[\"data\"][tta_idx].to(device)\n                else:\n                    data_tta = data[\"data\"].to(device)\n                data_raw = model(data_tta)\n                if head_type == \"hydra\":\n                    data_raw = data_raw[0]  # select karo head\n                logits_batch = data_raw.sigmoid().cpu().numpy()  # [bs, nr_classes]\n                logits_batch_ens.append(logits_batch)\n                \n        for model in models_512:\n            data = data_512\n            for tta_idx in range(tta_nr):\n                if tta_nr > 1:\n                    data_tta = data[\"data\"][tta_idx].to(device)\n                else:\n                    data_tta = data[\"data\"].to(device)\n                data_raw = model(data_tta)\n                if head_type == \"hydra\":\n                    data_raw = data_raw[0]  # select karo head\n                logits_batch = data_raw.sigmoid().cpu().numpy()  # [bs, nr_classes]\n                logits_batch_ens.append(logits_batch)\n        logits_batch_ens = np.array(logits_batch_ens)   # [nr_models*TTA, bs, 5]\n        \n        #todo: adapt\n        #logits_batch_ens = logits_batch_ens.round()  # use this if want to round before ensemble\n        \n        logits_batch_ens = logits_batch_ens.mean(axis=0)  # mean over models and tta (=ensemble)            \n        logits.append(logits_batch_ens)\n\nlogits = np.concatenate(logits, axis=0)  # [nr_batches* [bs, classes]] -> [nr_batches*bs, classes]\n\n#todo: adapt\n#logits = logits.round()  # use this if want to round before sum\n    \npreds = logits.sum(axis=1).round()  # sum across classes dimension\n\ndf['isup_grade'] = preds.astype(int)\ndf[['image_id', 'isup_grade']].to_csv('submission.csv', index=False)\nprint(df.head())\nprint()\nprint(df.isup_grade.value_counts())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}