{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n#from efficientnet_pytorch import EfficientNet\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport sys\npackage_path = '../input/efficientnetpytorch/'\nsys.path.append(package_path)\n\nfrom efficientnet_pytorch import EfficientNet\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function, absolute_import\nimport os\nimport sys\nimport time\nimport datetime\nimport argparse\nimport os.path as osp\nimport numpy as np\nimport random\nfrom PIL import Image\nimport tqdm\nimport cv2\nimport csv\nimport math\nimport torchvision as tv\nimport torchvision\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nfrom sklearn.metrics import f1_score\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nfrom tensorboardX import SummaryWriter\nimport skimage.io","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name_file='../input/prostate-cancer-grade-assessment/test.csv'\ndata_dir = '../input/prostate-cancer-grade-assessment'\nimage_folder = os.path.join(data_dir, 'test_images')\nis_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\nimage_folder = image_folder if is_test else os.path.join(data_dir, 'train_images')\n\ncsv_file=csv.reader(open(name_file,'r'))\ncontent=[]\nfor line in csv_file:\n    print(line[0]) #打印文件每一行的信息\n    content.append(line[0]+'.tiff')\ncontent=content[1:]\nif not is_test:\n    content.append('002a4db09dad406c85505a00fb6f6144.tiff')  #0\n    content.append('007433133235efc27a39f11df6940829.tiff')  #0\n    content.append('0018ae58b01bdadc8e347995b69f99aa.tiff')  #4\n    content.append('0076bcb66e46fb485f5ba432b9a1fe8a.tiff')  #3\n    content.append('003d4dd6bd61221ebc0bfb9350db333f.tiff')  #1\n    content=content[3:]\nprint(content)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.nn.parameter import Parameter\n\ndef gem(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM,self).__init__()\n        self.p = Parameter(torch.ones(1)*p)\n        self.eps = eps\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)       \n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_tiles_combine(img,mode=0):\n    images = np.ones((1536, 1536, 3))*255\n    \n    h, w, c = img.shape\n    result_all=[]\n    pad_h = (256 - h % 256) % 256 + ((256 * mode) // 2)\n    pad_w = (256 - w % 256) % 256 + ((256 * mode) // 2)\n    #print(pad_h,pad_w,c)\n    img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], 'constant',constant_values=255)\n    windows=[256,256,256,256,192,192,128]\n    x_start=0\n    for i in range(len(windows)):\n        result = []\n        window_size=windows[i]\n        for x in range((h+pad_h)//window_size):\n            for y in range((w+pad_w)//window_size):\n                tile=img2[x*window_size:(x+1)*window_size,y*window_size:(y+1)*window_size]\n                result.append([x,y,tile.sum()])\n        #print(len(result))\n        result.sort(key=lambda ele:ele[2])\n        result=result[:1536//window_size]\n        #print(len(result),result)\n        for y in range(min(1536//window_size,len(result))):\n            xx=result[y][0]\n            yy=result[y][1]\n            result_all.append([xx,yy])\n            images[x_start:x_start+window_size,y*window_size:(y+1)*window_size]=\\\n                img2[xx*window_size:(xx+1)*window_size,yy*window_size:(yy+1)*window_size].copy()\n            img2[xx*window_size:(xx+1)*window_size,yy*window_size:(yy+1)*window_size]=255\n        x_start=x_start+windows[i]\n    return images \nclass panda_dataset_combine(Dataset):\n    \"\"\"docstring for data\"\"\"\n    def __init__(self, txt_path,transform=None):\n        imgs = []\n        for img in txt_path:\n            imgs.append(img)\n        self.imgs = imgs\n        self.transform = transform\n    def __getitem__(self, index):\n        fn = self.imgs[index]\n        tif_name=fn\n        #img = Image.open('./train_images_png/'+fn+'_aug.png').convert('RGB') \n        img_name=tif_name[:-5]\n        print(image_folder+'/'+tif_name)\n        img=skimage.io.MultiImage(image_folder+'/'+tif_name)[1]\n        images=get_tiles_combine(img)\n        images2=get_tiles_combine(img,mode=2)\n        \n        \n        #cv2.imwrite('a.png',images)\n        #cv2.imwrite('b.png',images2)\n        #images = Image.open('a.png').convert('RGB')\n        #images2 = Image.open('b.png').convert('RGB')\n        #images=cv2.imread('a.png')\n        #images2=cv2.imread('b.png')\n        #images=cv2.cvtColor(images,cv2.COLOR_BGR2RGB)\n        #images2=cv2.cvtColor(images2,cv2.COLOR_BGR2RGB)\n        \n        \n        #images=255-images\n        images=images.astype(np.float32)\n        images=cv2.cvtColor(images,cv2.COLOR_BGR2RGB)\n        #print(images.shape)\n        #images = images.transpose(2, 0, 1)\n        #images=images/255\n        #img=images\n        #img = Image.fromarray(images)\n        \n        #images2=255-images2\n        images2=images2.astype(np.float32)\n        images2=cv2.cvtColor(images2,cv2.COLOR_BGR2RGB)\n        #print(images2.shape)\n        #images = images.transpose(2, 0, 1)\n        #images2=images2/255\n        \n        \n        images3=cv2.flip(images,0)\n        images4=cv2.flip(images2,0)\n        images5=cv2.flip(images,1)\n        images6=cv2.flip(images2,1)\n        #size1=1024\n        \n        images = Image.fromarray(np.uint8(images))\n        images2 = Image.fromarray(np.uint8(images2))\n        images3 = Image.fromarray(np.uint8(images3))\n        images4 = Image.fromarray(np.uint8(images4))\n        images5 = Image.fromarray(np.uint8(images5))\n        images6 = Image.fromarray(np.uint8(images6))\n        \n        if self.transform is not None:\n            img = self.transform(images)\n            img2= self.transform(images2)\n            img3= self.transform(images3)\n            img4= self.transform(images4)\n            img5= self.transform(images5)\n            img6= self.transform(images6)\n        #print('ok')\n        #return img_name,img,img2\n        return img_name,img,img2,img3,img4,img5,img6\n    def __len__(self):\n        return len(self.imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 8\nnum_workers = 4\n\ndef get_tiles(img, mode=0):\n    result = []\n    h, w, c = img.shape\n    pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n    pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n    img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], 'constant',constant_values=255)\n    img3 = img2.reshape(\n        img2.shape[0] // tile_size,\n        tile_size,\n        img2.shape[1] // tile_size,\n        tile_size,\n        3\n    )\n\n    img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n    n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n    if len(img3) < n_tiles:\n        img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n    img3 = img3[idxs]\n    for i in range(len(img3)):\n        result.append({'img':img3[i], 'idx':i})\n    return result, n_tiles_with_info >= n_tiles\n\nclass panda_dataset(Dataset):\n    \"\"\"docstring for data\"\"\"\n    def __init__(self, txt_path,transform=None):\n        imgs = []\n        for img in txt_path:\n            imgs.append(img)\n        self.imgs = imgs\n        self.transform = transform\n    def __getitem__(self, index):\n        fn = self.imgs[index]\n        tif_name=fn\n        #img = Image.open('./train_images_png/'+fn+'_aug.png').convert('RGB') \n        img_name=tif_name[:-5]\n        print(image_folder+'/'+tif_name)\n        img=skimage.io.MultiImage(image_folder+'/'+tif_name)[1]\n        tiles,flag=get_tiles(img)\n        tiles2,flag2=get_tiles(img,mode=2)\n        idxes = list(range(n_tiles))\n        n_row_tiles = int(np.sqrt(n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((image_size, image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                h1 = h * image_size\n                w1 = w * image_size\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n        images=255-images\n        images=images.astype(np.float32)\n        images=cv2.cvtColor(images,cv2.COLOR_BGR2RGB)\n        print(images.shape)\n        #images = images.transpose(2, 0, 1)\n        images=images/255\n        #img=images\n        #img = Image.fromarray(images)\n        \n        images2 = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n                if len(tiles2) > idxes[i]:\n                    this_img = tiles2[idxes[i]]['img']\n                else:\n                    this_img = np.ones((image_size, image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                h1 = h * image_size\n                w1 = w * image_size\n                images2[h1:h1+image_size, w1:w1+image_size] = this_img\n        images2=255-images2\n        images2=images2.astype(np.float32)\n        images2=cv2.cvtColor(images2,cv2.COLOR_BGR2RGB)\n        print(images2.shape)\n        #images = images.transpose(2, 0, 1)\n        images2=images2/255\n        \n        images3=cv2.flip(images,0)\n        images4=cv2.flip(images2,0)\n        images5=cv2.flip(images,1)\n        images6=cv2.flip(images2,1)\n        \n        \n        images_com=get_tiles_combine(img)\n        images_com2=get_tiles_combine(img,mode=2)\n        \n        \n        images_com=images_com.astype(np.float32)\n        images_com=cv2.cvtColor(images_com,cv2.COLOR_BGR2RGB)\n\n        images_com2=images_com2.astype(np.float32)\n        images_com2=cv2.cvtColor(images_com2,cv2.COLOR_BGR2RGB)\n        #print(images2.shape)\n        #images = images.transpose(2, 0, 1)\n        #images2=images2/255\n        images_com3=cv2.flip(images_com,0)\n        images_com4=cv2.flip(images_com2,0)\n        images_com5=cv2.flip(images_com,1)\n        images_com6=cv2.flip(images_com2,1)\n        #size1=1024\n        \n\n\n        images_com = Image.fromarray(np.uint8(images_com))\n        images_com2 = Image.fromarray(np.uint8(images_com2))\n        images_com3 = Image.fromarray(np.uint8(images_com3))\n        images_com4 = Image.fromarray(np.uint8(images_com4))\n        images_com5 = Image.fromarray(np.uint8(images_com5))\n        images_com6 = Image.fromarray(np.uint8(images_com6))\n        \n        \n        if self.transform is not None:\n            img = self.transform(images)\n            img2= self.transform(images2)\n            img3= self.transform(images3)\n            img4= self.transform(images4)\n            img5= self.transform(images5)\n            img6= self.transform(images6)\n            \n            \n            img_com=self.transform(images_com)\n            img_com2= self.transform(images_com2)\n            img_com3= self.transform(images_com3)\n            img_com4= self.transform(images_com4)\n            img_com5= self.transform(images_com5)\n            img_com6= self.transform(images_com6)\n            #img3= self.transform(images3)\n        #print('ok')\n        imgs=[img,img2,img3,img4,img5,img6]\n        imgs_com=[img_com,img_com2,img_com3,img_com4,img_com5,img_com6]\n        return img_name,imgs,imgs_com\n    def __len__(self):\n        return len(self.imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\ndef load_para_dict(model1):\n    state_dict_1=torch.load(model1)\n    new_state_dict = OrderedDict()\n    for k, v in state_dict_1.items():\n        if 'module' in k:\n            name = k[7:] # add `module.`\n        else:\n            name=k\n        new_state_dict[name] = v\n    return new_state_dict\ndef get_preds(arr):\n    mask = arr == 0\n    return np.clip(np.where(mask.any(1), mask.argmax(1), 6) - 1, 0, 5)\n\ninit_coef = [0.5, 1.5, 2.5, 3.5, 4.5]\ndef get_preds_reg(arr,coef=init_coef):\n    X_p = np.copy(arr.detach().cpu())\n    for i, pred in enumerate(X_p):\n        if pred < coef[0]:\n            X_p[i] = 0\n        elif pred >= coef[0] and pred < coef[1]:\n            X_p[i] = 1\n        elif pred >= coef[1] and pred < coef[2]:\n            X_p[i] = 2\n        elif pred >= coef[2] and pred < coef[3]:\n            X_p[i] = 3\n        elif pred >= coef[3] and pred < coef[4]:\n            X_p[i] = 4\n        else:\n            X_p[i] = 5\n    return X_p\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nimg=skimage.io.MultiImage(image_folder+'/'+'0a0f8e20b1222b69416301444b117678.tiff')[1]\ntiles,flag=get_tiles(img)\ntiles2,flag2=get_tiles(img,mode=2)\n#tiles2,flag=get_tiles(img,mode=2)\nidxes = list(range(n_tiles))\nn_row_tiles = int(np.sqrt(n_tiles))\nimages = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\nfor h in range(n_row_tiles):\n    for w in range(n_row_tiles):\n        i = h * n_row_tiles + w\n        if len(tiles) > idxes[i]:\n            this_img = tiles[idxes[i]]['img']\n        else:\n            this_img = np.ones((image_size, image_size, 3)).astype(np.uint8) * 255\n        this_img = 255 - this_img\n        h1 = h * image_size\n        w1 = w * image_size\n        images[h1:h1+image_size, w1:w1+image_size] = this_img\nimages=255-images\n\nimages=images.astype(np.float32)\nimages=cv2.cvtColor(images,cv2.COLOR_BGR2RGB)\nimages=images/255\n#images = images.transpose(2, 0, 1)\nprint(images.shape)\n\n\nimages2 = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\nfor h in range(n_row_tiles):\n    for w in range(n_row_tiles):\n        i = h * n_row_tiles + w\n        if len(tiles2) > idxes[i]:\n            this_img = tiles2[idxes[i]]['img']\n        else:\n            this_img = np.ones((image_size, image_size, 3)).astype(np.uint8) * 255\n        this_img = 255 - this_img\n        h1 = h * image_size\n        w1 = w * image_size\n        images2[h1:h1+image_size, w1:w1+image_size] = this_img\nimages2=255-images2\nimages2=images2.astype(np.float32)\nimages2=cv2.cvtColor(images2,cv2.COLOR_BGR2RGB)\nprint(images2.shape)\n#images = images.transpose(2, 0, 1)\nimages2=images2/255\n\n\nimages3 = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\nfor h in range(n_row_tiles):\n    for w in range(n_row_tiles):\n        i = h * n_row_tiles + w\n        if len(tiles) > idxes[i]:\n            this_img = tiles[idxes[i]]['img']\n        else:\n            this_img = np.ones((image_size, image_size, 3)).astype(np.uint8) * 255\n        this_img = 255 - this_img\n        h1 = h * image_size\n        w1 = w * image_size\n        images3[h1:h1+image_size, w1:w1+image_size] = this_img\nimages3=255-images3\nimages3=images3.astype(np.float32)\nimages3=cv2.cvtColor(images3,cv2.COLOR_BGR2RGB)\nimages3=cv2.flip(images3,1)\nprint(images3.shape)\n#images = images.transpose(2, 0, 1)\nimages3=images3/255\n\nimport matplotlib.pyplot as plt\nplt.figure()\n#img = Image.fromarray(images)\nprint(type(images))\nplt.imshow(images)\n\nplt.figure()\nplt.imshow(images2)\n\nplt.figure()\nplt.imshow(images3)\n\nplt.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.nn.parameter import Parameter\n\ndef gem(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM,self).__init__()\n        self.p = Parameter(torch.ones(1)*p)\n        self.eps = eps\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)       \n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\nclass SwishImplementation(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * torch.sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = torch.sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass MemoryEfficientSwish(nn.Module):\n    def forward(self, x):\n        return SwishImplementation.apply(x)\n\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\nclass isupnet(nn.Module):\n    def __init__(self, num_classes,base_model, **kwargs):\n        super(isupnet, self).__init__()\n        \n        \n        self.base_model_name=base_model\n        self.avg_pooling=GeM(p=3)\n        self.max_pooling=nn.AdaptiveMaxPool2d(1)\n        if base_model[0]=='e':\n            #self.base = EfficientNet.from_pretrained(base_model)\n            \n            self.base = EfficientNet.from_name(base_model)\n            feature = self.base._fc.in_features\n        else:\n            base_net=torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext50_32x4d_ssl')\n            feature = base_net.fc.in_features\n            self.base=nn.Sequential(*list(base_net.children())[:-2])  \n        self.fc = nn.Linear(in_features=2*feature,out_features=feature,bias=True)\n        self.classifiers = nn.Linear(in_features=feature, out_features=num_classes)\n        self.sigmoid = MemoryEfficientSwish()\n        self.dropout=nn.Dropout(0.4)\n        self.bn=nn.BatchNorm1d(feature)\n\n    def freeze_base(self):\n        for p in self.base.parameters():\n            p.requires_grad = False\n\n    def unfreeze_all(self):\n        for p in self.parameters():\n            p.requires_grad = True\n    def forward(self, x1):\n        bs=x1.size(0)\n        if self.base_model_name[0]=='e':\n            x2 = self.base.extract_features(x1)\n            feat1=self.avg_pooling(x2)\n            feat2=self.max_pooling(x2)\n            feat1=feat1.view(bs,-1)\n            feat2=feat2.view(bs,-1)\n            feat=torch.cat([feat1,feat2],1)\n            \n            feat = self.fc(feat)\n            #feat = self.sigmoid(feat)\n            #feat = self.bn(feat)\n            feat = self.dropout(feat)\n            ys = self.classifiers(feat)\n\n            #ys=self.sigmoid(ys)\n        else:\n            '''\n            x=x1\n            x=x.view(bs,3,-1,224,224)\n            x=x.permute(0,2,1,3,4).contiguous()\n            shape = [36,3,224,224]\n            #print(x.shape)\n            n = x.shape[1]\n            x = x.view(-1,shape[1],shape[2],shape[3])\n            #print(x.shape)\n            #x: bs*N x 3 x 128 x 128\n            x = self.base(x)\n            #x: bs*N x C x 4 x 4\n            shape = x.shape\n            #print(shape)\n            #concatenate the output for tiles into a single map\n            x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n              .view(-1,shape[1],shape[2]*n,shape[3])\n            #x: bs x C x N*4 x 4\n            #print(x.shape)\n            '''\n            x=self.base(x1)\n            feat1=self.avg_pooling(x)\n            feat2=self.max_pooling(x)\n            feat1=feat1.view(bs,-1)\n            feat2=feat2.view(bs,-1)\n            feat=torch.cat([feat1,feat2],1)\n            \n            feat = self.fc(feat)\n            #feat = self.sigmoid(feat)\n            #feat = self.bn(feat)\n            feat = self.dropout(feat)\n            ys = self.classifiers(feat)\n            #x: bs x n\n        \n\n        return ys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nif __name__ == '__main__':\n\n    use_gpu = torch.cuda.is_available()\n    if use_gpu:\n        cudnn.benchmark = True\n        torch.cuda.manual_seed_all(0)\n    else:\n        print(\"Currently using CPU (GPU is highly recommended)\")\n\n\n    transform2 = transforms.Compose([\n            #transforms.Resize((512, 512)),\n            #transforms.ColorJitter(brightness=20,contrast=0.2,saturation=20,hue=0.1),\n            transforms.ToTensor(), # 转为Tensor\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n                             ]) \n\n\n\n    test_data=panda_dataset(content,transform2)\n    #net=Baseline_single(num_classes=5)\n    #net = EfficientNet.from_pretrained(args.model)\n    net = EfficientNet.from_name('efficientnet-b0')\n    feature = net._fc.in_features\n    net._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net._avg_pooling=GeM()\n    net1 = EfficientNet.from_name('efficientnet-b0')\n    feature = net1._fc.in_features\n    net1._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net1._avg_pooling=GeM()\n    net2 = EfficientNet.from_name('efficientnet-b0')\n    feature = net2._fc.in_features\n    net2._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net2._avg_pooling=GeM()\n    net3 = EfficientNet.from_name('efficientnet-b0')\n    feature = net3._fc.in_features\n    net3._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net3._avg_pooling=GeM()\n    net4 = EfficientNet.from_name('efficientnet-b0')\n    feature = net4._fc.in_features\n    net4._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net4._avg_pooling=GeM()\n    net5 = EfficientNet.from_name('efficientnet-b0')\n    feature = net5._fc.in_features\n    net5._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net5._avg_pooling=GeM()\n    \n    net6 = EfficientNet.from_name('efficientnet-b0')\n    feature = net6._fc.in_features\n    net6._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net6._avg_pooling=GeM()\n    \n    net7 = EfficientNet.from_name('efficientnet-b0')\n    feature = net7._fc.in_features\n    net7._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net7._avg_pooling=GeM()\n    nets=[net,net1,net2,net3,net4,net5,net6,net7]\n    #net8=isupnet(num_classes=6,base_model='efficientnet-b0')\n    '''\n    net8 = EfficientNet.from_name('efficientnet-b0')\n    feature = net8._fc.in_features\n    net8._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net8._avg_pooling=GeM()\n    '''\n    if use_gpu:\n        net=net.cuda()\n        net1=net1.cuda()\n        net2=net2.cuda()\n        net3=net3.cuda()\n        net4=net4.cuda()\n        net5=net5.cuda()\n        net6=net6.cuda()\n        net7=net7.cuda()\n        #net8=net8.cuda()\n    net.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_combine_efficientnet-b0_0.00032_adam_4_bce_karmax_gem_1536_augt_845_kar8731.pkl'))\n    net1.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.0003_adam_3_bce_maxest_aug_gem_8624.pkl'))\n    net2.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.0003_adam_1_bce_maxest_gem_8647.pkl'))\n    net3.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.00032_adam_4_bce_maxest_aug_gem_8616.pkl'))\n    net4.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.00032_adam_4_bce_maxest_augb_gem_867.pkl'))    \n    net5.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_256_efficientnet-b0_0.00032_adam_4_bce_karmax_gem_1536_augb_kar8843_8647.pkl'))    \n    net6.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_combine_efficientnet-b0_0.00032_adam_4_bce_karmax_gem_1536_naugt_nbal_kar8928_8725.pkl'))\n    net7.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_256_efficientnet-b0_0.00032_adam_0_bce_karmax_gem_1536_augb_kar8741_8567.pkl'))\n    #net8.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_combine_efficientnet-b0_0.00032_adam_1_bce_karmax_gem_1536_naugt_nbal_kar8953_8707.pkl'))\n    print(net._avg_pooling.p)\n    #net._avg_pooling=nn.AdaptiveAvgPool2d(1)\n    dataloader_test=DataLoader(\n        test_data,batch_size=1, shuffle = False, num_workers= 5)\n    idx=0\n    max_correct=0\n    with open('/kaggle/working/submission.csv',\"a+\", newline='')as f:\n        f_csv = csv.writer(f)\n        f_csv.writerow(['image_id','isup_grade'])\n    with torch.no_grad():\n        net.eval()\n        net1.eval()\n        net2.eval()\n        net3.eval()\n        net4.eval()\n        net5.eval()\n        net6.eval()\n        net7.eval()\n        #net8.eval()\n        total=0\n        total_loss=0\n        correct=0\n        for id,item in enumerate(dataloader_test):\n            print('id ',id)            \n            name,datas,datas_com=item\n            if use_gpu:\n                for i in range(len(datas)):\n                    datas[i]=datas[i].cuda()\n                    datas_com[i]=datas_com[i].cuda()\n                #data3=data3.cuda()\n            print(datas[0].size())\n            outs=[]\n            for i in range(len(nets)):\n                if i==0 or i== 6:\n                    for j in range(len(datas_com)):\n                        outs.append(nets[i](datas_com[j]))\n                else:\n                    for j in range(len(datas_com)):\n                        outs.append(nets[i](datas[j]))\n            out=outs[0]\n            for i in range(1,len(outs)):\n                out=out+outs[i]\n            \n            out=out/len(outs)\n            #out=(out3_0+out3_1+out4_1+out4_0)/4\n            #out=(out0_0+out0_1+out0_2)/3\n            print(out)\n            predicted=get_preds((torch.sigmoid(out) > 0.5).cpu().numpy())\n            #_, predicted = torch.max(out, 1)\n            hh=[str(name[0]),str(predicted[0])]\n            print(hh)\n            with open('/kaggle/working/submission.csv',\"a+\", newline='')as f:\n                f_csv = csv.writer(f)\n                f_csv.writerow(hh)\n    print(pd.read_csv('/kaggle/working/submission.csv').isup_grade.value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nif __name__ == '__main__':\n\n    use_gpu = torch.cuda.is_available()\n    if use_gpu:\n        cudnn.benchmark = True\n        torch.cuda.manual_seed_all(0)\n    else:\n        print(\"Currently using CPU (GPU is highly recommended)\")\n\n\n    transform2 = transforms.Compose([\n            #transforms.Resize((512, 512)),\n            #transforms.ColorJitter(brightness=20,contrast=0.2,saturation=20,hue=0.1),\n            transforms.ToTensor(), # 转为Tensor\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n                             ]) \n\n\n\n    test_data=panda_dataset(content,transform2)\n    net = EfficientNet.from_name('efficientnet-b0')\n    feature = net._fc.in_features\n    net._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net._avg_pooling=GeM()\n    net1 = EfficientNet.from_name('efficientnet-b0')\n    feature = net1._fc.in_features\n    net1._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net1._avg_pooling=GeM()\n    net2 = EfficientNet.from_name('efficientnet-b0')\n    feature = net2._fc.in_features\n    net2._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net2._avg_pooling=GeM()\n    net3 = EfficientNet.from_name('efficientnet-b0')\n    feature = net3._fc.in_features\n    net3._fc = nn.Linear(in_features=feature,out_features=6,bias=True)\n    net3._avg_pooling=GeM()\n    if use_gpu:\n        net=net.cuda()\n        net1=net1.cuda()\n        net2=net2.cuda()\n        net3=net3.cuda()\n    net.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.00032_adam_4_bce_maxest_aug_gem_8711.pkl'))\n    net1.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.0003_adam_3_bce_maxest_aug_gem_8624.pkl'))\n    net2.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.0003_adam_1_bce_maxest_gem_8647.pkl'))\n    net3.load_state_dict(load_para_dict('/kaggle/input/pandamodels/model_36_256_256_efficientnet-b0_0.00032_adam_4_bce_maxest_aug_gem_8616.pkl'))\n    print(net3._avg_pooling.p)\n    #net._avg_pooling=nn.AdaptiveAvgPool2d(1)\n    dataloader_test=DataLoader(\n        test_data,batch_size=1, shuffle = False, num_workers= 3)\n    idx=0\n    max_correct=0\n    with open('/kaggle/working/submission.csv',\"a+\", newline='')as f:\n        f_csv = csv.writer(f)\n        f_csv.writerow(['image_id','isup_grade'])\n    \n    with torch.no_grad():\n        net.eval()\n        net1.eval()\n        net2.eval()\n        net3.eval()\n        total=0\n        total_loss=0\n        correct=0\n        for id,item in enumerate(dataloader_test):\n            print('id ',id)            \n            name,data,data2=item\n            if use_gpu:\n                data=data.cuda()\n                data2=data2.cuda()\n            #print(data.size())\n            feature=[]\n            out0_0=net(data)\n            feature.append(out0_0)\n            out0_1=net(data2)\n            feature.append(out0_1)\n            out1_0=net1(data)\n            feature.append(out1_0)\n            out1_1=net1(data2)\n            feature.append(out1_1)\n            out2_0=net2(data)\n            feature.append(out2_0)\n            out2_1=net2(data2)\n            feature.append(out2_1)\n            out3_0=net3(data)\n            feature.append(out3_0)\n            out3_1=net3(data2)\n            feature.append(out3_1)\n            #out1=net1(data)\n            out_fea=feature[0].detach().cpu().numpy()[0]\n            for i in range(1,8):\n                out_fea=np.hstack((out_fea,feature[i].detach().cpu().numpy()[0]))\n                \n            out_fea_str=''\n            for x in out_fea:\n                out_fea_str=out_fea_str+str(x)+'\\t'\n            out=(out0_0+out0_1+out1_0+out1_1+out2_0+out2_1+out3_0+out3_1)/8\n            #out=(out0_0+out0_1+out1_0+out1_1+out2_0+out2_1)/6\n            print(out)\n            predicted=get_preds((torch.sigmoid(out) > 0.5).cpu().numpy())\n            #_, predicted = torch.max(out, 1)\n            hh=[name[0],str(predicted[0]),out_fea_str]\n            print(hh)\n            with open('/kaggle/working/bce_xg_data.csv',\"a+\", newline='')as f:\n                f_csv = csv.writer(f)\n                f_csv.writerow(hh)\n    bst = xgb.Booster(model_file='/kaggle/input/pandamodels/model_xg.txt')\n    bst.save_model('/kaggle/working/model_xg_new.txt')\n    bst = xgb.Booster(model_file='/kaggle/working/model_xg_new.txt')\n    data=[]\n    label=[]\n    name=[]\n    reader = csv.reader(open('/kaggle/working/bce_xg_data.csv','r'))\n    cnt=0\n\n    for line in reader:\n        data.append(line[2].split('\\t')[:-1])\n        label.append(int(line[1]))\n        name.append(line[0])\n        #print(line[3].split('\\t')[:-1])\n        cnt=cnt+1\n    for x in range(len(data)):\n        for y in range(len(data[x])):\n            data[x][y]=float(data[x][y])\n    valid_X=np.array(data)\n    dtest=xgb.DMatrix(valid_X)\n    y_pred = bst.predict(dtest)\n    ll=y_pred.shape[0]\n    for i in range(ll):\n        pred=y_pred[i]\n        hh=[name[i],str(int(pred))]\n        print(hh)\n        with open('/kaggle/working/submission.csv',\"a+\", newline='')as f:\n            f_csv = csv.writer(f)\n            f_csv.writerow(hh)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nprint(type(data),data)\ndata=np.array(data)\nvalid_X=data\ndtest=xgb.DMatrix(valid_X)\n'''\n#print(ll)\n#print(pd.read_csv('/kaggle/working/submission.csv').isup_grade.value_counts())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}