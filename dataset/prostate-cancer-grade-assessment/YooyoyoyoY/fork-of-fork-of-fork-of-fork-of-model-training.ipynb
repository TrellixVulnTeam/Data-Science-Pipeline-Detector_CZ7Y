{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install tensorflow==2.3.0","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-22T15:39:32.448928Z","iopub.execute_input":"2022-03-22T15:39:32.449292Z","iopub.status.idle":"2022-03-22T15:40:39.076686Z","shell.execute_reply.started":"2022-03-22T15:39:32.449249Z","shell.execute_reply":"2022-03-22T15:40:39.075827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basics / Data manipulation\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport os\nimport glob\nimport shutil\n\n# Visualization\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport skimage.io\n\n# ML\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import models\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\n\n#Use this to check if the GPU is configured correctly\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:39.080274Z","iopub.execute_input":"2022-03-22T15:40:39.080571Z","iopub.status.idle":"2022-03-22T15:40:45.103667Z","shell.execute_reply.started":"2022-03-22T15:40:39.080545Z","shell.execute_reply":"2022-03-22T15:40:45.102247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data\n10k+ of .tiff images\n*    **80%** for training \n*    **20%** for internal testing\n            *  10% Validation\n            *  10% Testing","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Checking if GPU is being used","metadata":{"editable":false}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n    strategy = tf.distribute.MirroredStrategy()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-22T15:40:45.105482Z","iopub.execute_input":"2022-03-22T15:40:45.105768Z","iopub.status.idle":"2022-03-22T15:40:45.130265Z","shell.execute_reply.started":"2022-03-22T15:40:45.105721Z","shell.execute_reply":"2022-03-22T15:40:45.129483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model \nThe model will have the follow configuration:\n______________\n1st layer: NASNetMobile (224, 224, 3) input images\n______________\n2nd layer: GlobalMaxPooling2D\n______________\n3rd layer: Dropout with learning rate = 2e-5\n______________\n4th layer: Denser layer x 6 that will classify the image","metadata":{"editable":false}},{"cell_type":"code","source":"base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n#print(base_model.summary())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-22T15:40:45.131685Z","iopub.execute_input":"2022-03-22T15:40:45.13223Z","iopub.status.idle":"2022-03-22T15:40:51.35018Z","shell.execute_reply.started":"2022-03-22T15:40:45.132196Z","shell.execute_reply":"2022-03-22T15:40:51.349469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(base_model)\nbase_model.trainable = True\nmodel.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n# Avoid overfitting\nmodel.add(layers.Dropout(rate=0.5))\nmodel.add(layers.Dense(2, activation=\"softmax\", name=\"fc_out\"))\n\nmodel.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=optimizers.RMSprop(lr=2e-5),\n    metrics=[\"acc\"])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:51.354837Z","iopub.execute_input":"2022-03-22T15:40:51.355064Z","iopub.status.idle":"2022-03-22T15:40:52.217895Z","shell.execute_reply.started":"2022-03-22T15:40:51.35504Z","shell.execute_reply":"2022-03-22T15:40:52.217227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unzipping The Files\nThe original images have been transformed into tiled mosaics. Each image_id has 8 mosaic variations; the variations have been grouped into their seperate own zips\nto work within a Kaggle restriction of  max 5 GB in ./kaggle/working & and max 20 GB in ./kaggle/tmp while training.csv + validation.csv + testing.csv are seperate & global. \n\nThe dataset has been split 90% Training, 7.5% Validation, and 2.5% Internal Testing. If you want to use all 10% of the data for Validation, just merge the appropriate dataframes & zipfile contents. \n\nOnly unzip a single variation at a time! The notebook will fail if you use up all the space in ./kaggle/working and your model will not be saved! If you need to move on to a different variation, delete the old files! You can unzip them again later, no problem.\n","metadata":{}},{"cell_type":"code","source":"NUMBER_OF_TRAINING_IMAGES = len(pd.read_csv('../input/8-fold-pc-dataset-gen-0-8/training.csv'))\nNUMBER_OF_VALIDATION_IMAGES = len(pd.read_csv('../input/8-fold-pc-dataset-gen-0-8/validation.csv'))\nNUMBER_OF_TESTING_IMAGES = len(pd.read_csv('../input/8-fold-pc-dataset-gen-0-8/testing.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:52.220776Z","iopub.execute_input":"2022-03-22T15:40:52.220996Z","iopub.status.idle":"2022-03-22T15:40:52.288205Z","shell.execute_reply.started":"2022-03-22T15:40:52.220972Z","shell.execute_reply":"2022-03-22T15:40:52.28746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TVT = [\"./train\", \"./validation\", \"./test\"]\nTVT = [\"./train\", \"./validation\"]\nOUT = [0, 1]\nOut = [\"/Positive\",\"/Negative\"]\nGLE = [\"/GLEASON_SCORE_[!0]+[!0]\", \"/GLEASON_SCORE_0+0\"]\n\ndef binarize():\n    for grouping in TVT:\n        for outcomes in OUT:\n            if not os.path.exists(grouping + Out[outcomes]):\n                os.makedirs(grouping + Out[outcomes])\n            for file in glob.iglob(grouping + GLE[outcomes] + \"/*\"):\n                os.replace(file, grouping + Out[outcomes] + \"/\" + file.split(\"/\")[3])\n            for folder in glob.iglob(grouping + GLE[outcomes]): \n                os.rmdir(folder)  \n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:52.289419Z","iopub.execute_input":"2022-03-22T15:40:52.289691Z","iopub.status.idle":"2022-03-22T15:40:52.299185Z","shell.execute_reply.started":"2022-03-22T15:40:52.289655Z","shell.execute_reply":"2022-03-22T15:40:52.298488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### CAUTION ###\n\nvariations = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n#variations = [\"A\"]\n\ndef zippity(variant):\n    print(f'Variation {variant}')\n    # Train\n    with zipfile.ZipFile(f'../input/8-fold-pc-dataset-gen-{variations.index(variant) + 1}-8-{variant.lower()}/train{variant}.zip','r') as z:\n        z.extractall(\".\")\n                    \n    # Valid\n    with zipfile.ZipFile(f'../input/8-fold-pc-dataset-gen-{variations.index(variant) + 1}-8-{variant.lower()}/validation{variant}.zip','r') as z:\n        z.extractall(\".\")\n                    \n    # Test\n#     with zipfile.ZipFile(\"../input/pc-data-dataset-gen/test.zip\",\"r\") as z:\n#         z.extractall(\".\")\n    binarize()\n    \n    for path in glob.glob(\"./*/GLEASON_SCORE_?+?/\"):\n        os.rmdir(path)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:52.300465Z","iopub.execute_input":"2022-03-22T15:40:52.300957Z","iopub.status.idle":"2022-03-22T15:40:52.311631Z","shell.execute_reply.started":"2022-03-22T15:40:52.300921Z","shell.execute_reply":"2022-03-22T15:40:52.310899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def zappity():\n    # Deleting image folders to avoid over-saturate the output\n    !rm -r train\n    !rm -r validation\n#     !rm -r test","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:52.314374Z","iopub.execute_input":"2022-03-22T15:40:52.314814Z","iopub.status.idle":"2022-03-22T15:40:52.321522Z","shell.execute_reply.started":"2022-03-22T15:40:52.314775Z","shell.execute_reply":"2022-03-22T15:40:52.320722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Additional Data Augmentation","metadata":{}},{"cell_type":"code","source":"image_gen = ImageDataGenerator(\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    rescale=1/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    fill_mode=\"nearest\",\n    preprocessing_function=tf.keras.applications.resnet50.preprocess_input)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:52.323005Z","iopub.execute_input":"2022-03-22T15:40:52.323476Z","iopub.status.idle":"2022-03-22T15:40:52.330189Z","shell.execute_reply.started":"2022-03-22T15:40:52.323442Z","shell.execute_reply":"2022-03-22T15:40:52.329222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample = plt.imread(\"../input/panda2/train_images/0005f7aaab2800f6170c399693a96917.png\")\n\n#plt.imshow(image_gen.random_transform(sample))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:52.33162Z","iopub.execute_input":"2022-03-22T15:40:52.331907Z","iopub.status.idle":"2022-03-22T15:40:52.341277Z","shell.execute_reply.started":"2022-03-22T15:40:52.331875Z","shell.execute_reply":"2022-03-22T15:40:52.340603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\ndef which_image_gen(which):\n    if(which == \"train\"):\n        which_gen = image_gen.flow_from_directory(\"./train\",\n                                                  target_size=(224, 224),\n                                                  batch_size=batch_size,\n                                                  class_mode=\"categorical\")\n        \n    \n    elif(which == \"valid\"):\n        which_gen = image_gen.flow_from_directory(\"./validation\",\n                                                  target_size=(224, 224),\n                                                  batch_size=batch_size,\n                                                  class_mode=\"categorical\")\n    \n#     elif(which == \"test\"):\n#         which_gen = image_gen.flow_from_directory(\"./test\",\n#                                                   target_size=(224, 224),\n#                                                   batch_size=batch_size,\n#                                                   class_mode=\"categorical\")\n    return which_gen\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:52.342903Z","iopub.execute_input":"2022-03-22T15:40:52.343119Z","iopub.status.idle":"2022-03-22T15:40:52.351269Z","shell.execute_reply.started":"2022-03-22T15:40:52.343098Z","shell.execute_reply":"2022-03-22T15:40:52.350442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for variety in variations:\n    zippity(variety)\n    \n    train_image_gen = which_image_gen(\"train\")\n    validation_image_gen = which_image_gen(\"valid\")\n#     test_image_gen = which_image_gen(\"test\")\n\n#     Flowing through directories to see the classes and the number of images\n#     print(image_gen.flow_from_directory(\"./train\"))\n#     print(image_gen.flow_from_directory(\"./validation\"))\n#     print(image_gen.flow_from_directory(\"./test\"))\n\n#     train_image_gen.class_indices\n#     validation_image_gen.class_indices\n#     test_image_gen.class_indices\n\n    results = model.fit(\n        train_image_gen,\n        steps_per_epoch=NUMBER_OF_TRAINING_IMAGES // batch_size,\n        epochs=50,\n        validation_data=validation_image_gen,\n        validation_steps=NUMBER_OF_VALIDATION_IMAGES // batch_size,\n        verbose=20,\n        use_multiprocessing=True,\n        workers=4)\n    \n    # Saving the synaptic weights of the model\n    model.save(\"./ResNet50-model.h5\")\n    \n    zappity()\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-22T15:40:52.352932Z","iopub.execute_input":"2022-03-22T15:40:52.353476Z","iopub.status.idle":"2022-03-22T15:41:37.126554Z","shell.execute_reply.started":"2022-03-22T15:40:52.353442Z","shell.execute_reply":"2022-03-22T15:41:37.125256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist_acc(hist):\n    plt.plot(hist.history[\"acc\"])\n    plt.plot(hist.history[\"val_acc\"])\n    plt.title(\"Model Accuracy\")\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Accuracy\", \"Validation Accuracy\"], loc=\"upper left\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:41:37.127695Z","iopub.status.idle":"2022-03-22T15:41:37.128305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist_loss(hist):\n    plt.plot(hist.history[\"loss\"])\n    plt.plot(hist.history[\"val_loss\"])\n    plt.title(\"Model Loss\")\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Loss\", \"Validation Loss\"], loc=\"upper left\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:41:37.129467Z","iopub.status.idle":"2022-03-22T15:41:37.130023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the synaptic weights of the model\nmodel.save(\"./ResNet50-model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:41:37.131069Z","iopub.status.idle":"2022-03-22T15:41:37.131647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df = pd.DataFrame({\"epoch\":[i + 1 for i in range(len(results.history[\"acc\"]))], \"acc\":results.history[\"acc\"], \"val_acc\":results.history[\"val_acc\"], \"loss\":results.history[\"loss\"], \"val_loss\":results.history[\"val_loss\"]})\nresults_df","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-22T15:41:37.132713Z","iopub.status.idle":"2022-03-22T15:41:37.133277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist_acc(results)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:41:37.134336Z","iopub.status.idle":"2022-03-22T15:41:37.134901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist_loss(results)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:41:37.135947Z","iopub.status.idle":"2022-03-22T15:41:37.136528Z"},"trusted":true},"execution_count":null,"outputs":[]}]}