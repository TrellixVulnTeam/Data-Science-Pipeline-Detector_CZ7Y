{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport copy\nfrom tqdm.notebook import tqdm\n\nimport time\nimport os\n\nimport cv2\nimport shutil\nimport glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T18:43:58.568029Z","iopub.execute_input":"2022-04-27T18:43:58.568318Z","iopub.status.idle":"2022-04-27T18:44:00.293724Z","shell.execute_reply.started":"2022-04-27T18:43:58.568289Z","shell.execute_reply":"2022-04-27T18:44:00.29275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(torch.__version__)\n# print(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:44:00.295402Z","iopub.execute_input":"2022-04-27T18:44:00.295648Z","iopub.status.idle":"2022-04-27T18:44:00.300606Z","shell.execute_reply.started":"2022-04-27T18:44:00.295618Z","shell.execute_reply":"2022-04-27T18:44:00.299591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_FOLDER = \"../input/prostate-cancer-grade-assessment/\"\nsample = BASE_FOLDER+\"sample_submission.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:44:00.302715Z","iopub.execute_input":"2022-04-27T18:44:00.303602Z","iopub.status.idle":"2022-04-27T18:44:00.311029Z","shell.execute_reply.started":"2022-04-27T18:44:00.303327Z","shell.execute_reply":"2022-04-27T18:44:00.310214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.ion()\ndf = pd.read_csv(BASE_FOLDER+\"train.csv\")\n\nlabels = list(dict.fromkeys(df['isup_grade']))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:44:00.312589Z","iopub.execute_input":"2022-04-27T18:44:00.313284Z","iopub.status.idle":"2022-04-27T18:44:00.366106Z","shell.execute_reply.started":"2022-04-27T18:44:00.313247Z","shell.execute_reply":"2022-04-27T18:44:00.365297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge_url(z, y):\n    path = os.listdir(z)\n    df[y] = [[('../input/prostate-cancer-grade-assessment/train_images/' + i) for a in df['image_id'] if (i.split('.')[0] == a)] for i in path]\n    df[y] = df[y].apply(lambda url: \" \".join(url))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:44:00.367141Z","iopub.execute_input":"2022-04-27T18:44:00.367378Z","iopub.status.idle":"2022-04-27T18:44:00.373358Z","shell.execute_reply.started":"2022-04-27T18:44:00.36735Z","shell.execute_reply":"2022-04-27T18:44:00.372394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = merge_url('../input/prostate-cancer-grade-assessment/train_images/', 'image_url')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:44:00.374642Z","iopub.execute_input":"2022-04-27T18:44:00.374934Z","iopub.status.idle":"2022-04-27T18:44:44.16303Z","shell.execute_reply.started":"2022-04-27T18:44:00.374894Z","shell.execute_reply":"2022-04-27T18:44:44.162079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge_mask():\n    df_mask = pd.DataFrame({'image_url':[], 'mask_url':[], 'image_id':[], 'data_provider':[], 'isup_grade':[], 'gleason_score':[]})\n    path1 = os.listdir('../input/prostate-cancer-grade-assessment/train_label_masks/')\n    for i in path1:\n        y=i.split('.')[0].split('_')[0]\n        for m,j,n,k,l in zip(df['image_url'], df['image_id'], df['data_provider'], df['isup_grade'], df['gleason_score']):\n            if str(y) == str(j):\n                df_mask=df_mask.append({'image_url':m, 'mask_url':'../input/prostate-cancer-grade-assessment/train_label_masks/' + i, 'image_id':j, 'data_provider':n, 'isup_grade':k, 'gleason_score':l}, ignore_index=True)\n                \n    return df_mask","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:44:44.165189Z","iopub.execute_input":"2022-04-27T18:44:44.165433Z","iopub.status.idle":"2022-04-27T18:44:44.17381Z","shell.execute_reply.started":"2022-04-27T18:44:44.165401Z","shell.execute_reply":"2022-04-27T18:44:44.172975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mask = merge_mask()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:44:44.175238Z","iopub.execute_input":"2022-04-27T18:44:44.175697Z","iopub.status.idle":"2022-04-27T18:47:17.725815Z","shell.execute_reply.started":"2022-04-27T18:44:44.175654Z","shell.execute_reply":"2022-04-27T18:47:17.724953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mask","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.727189Z","iopub.execute_input":"2022-04-27T18:47:17.72742Z","iopub.status.idle":"2022-04-27T18:47:17.751723Z","shell.execute_reply.started":"2022-04-27T18:47:17.727393Z","shell.execute_reply":"2022-04-27T18:47:17.751137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mask.loc[(df_mask['isup_grade'] == 2) & (df_mask['gleason_score'] == '4+3')]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.752729Z","iopub.execute_input":"2022-04-27T18:47:17.753041Z","iopub.status.idle":"2022-04-27T18:47:17.771814Z","shell.execute_reply.started":"2022-04-27T18:47:17.753014Z","shell.execute_reply":"2022-04-27T18:47:17.770927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mask.loc[8724,'isup_grade'] = 3","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.773465Z","iopub.execute_input":"2022-04-27T18:47:17.773919Z","iopub.status.idle":"2022-04-27T18:47:17.779059Z","shell.execute_reply.started":"2022-04-27T18:47:17.773875Z","shell.execute_reply":"2022-04-27T18:47:17.778277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mask['gleason_score'] = df_mask['gleason_score'].apply(lambda x: '0+0' if x == 'negative' else x)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.780554Z","iopub.execute_input":"2022-04-27T18:47:17.781006Z","iopub.status.idle":"2022-04-27T18:47:17.794515Z","shell.execute_reply.started":"2022-04-27T18:47:17.780963Z","shell.execute_reply":"2022-04-27T18:47:17.793483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isup_0 = df_mask[df_mask.isup_grade == 0]\nisup_1 = df_mask[df_mask.isup_grade == 1]\nisup_2 = df_mask[df_mask.isup_grade == 2]\nisup_3 = df_mask[df_mask.isup_grade == 3]\nisup_4 = df_mask[df_mask.isup_grade == 4]\nisup_5 = df_mask[df_mask.isup_grade == 5]\n\nprint(f'isup_0: {len(isup_0)}, isup_1: {len(isup_1)}, isup_2: {len(isup_2)}, isup_3: {len(isup_3)}, isup_4: {len(isup_4)}, isup_5: {len(isup_5)}')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.797403Z","iopub.execute_input":"2022-04-27T18:47:17.797748Z","iopub.status.idle":"2022-04-27T18:47:17.809711Z","shell.execute_reply.started":"2022-04-27T18:47:17.797719Z","shell.execute_reply":"2022-04-27T18:47:17.808918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isup_sam0 = isup_0.sample(n=1215)\nisup_sam1 = isup_1.sample(n=1215)\nisup_sam2 = isup_2.sample(n=1215)\nisup_sam3 = isup_3.sample(n=1215)\nisup_sam4 = isup_4.sample(n=1215)\nisup_sam5 = isup_5.sample(n=1215)\n\nframes = [isup_sam0, isup_sam1, isup_sam2, isup_sam3, isup_sam4, isup_sam5]\nbalanced_df = pd. concat(frames)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.810825Z","iopub.execute_input":"2022-04-27T18:47:17.81107Z","iopub.status.idle":"2022-04-27T18:47:17.827141Z","shell.execute_reply.started":"2022-04-27T18:47:17.811033Z","shell.execute_reply":"2022-04-27T18:47:17.826477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def overlay_mask_on_slide(df, center='radboud', alpha=0.8, max_size=(800, 800)):\n    \"\"\"Show a mask overlayed on a slide.\"\"\"\n    \n    data = df\n    for i, row in enumerate(data.iterrows()):\n        x = row[1][0]\n        slide = openslide.OpenSlide(x)\n        y = row[1][1]\n        mask = openslide.OpenSlide(y)\n        slide_data = slide.read_region((0,0), slide.level_count - 1, slide.level_dimensions[-1])\n        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n        mask_data = mask_data.split()[0]\n\n\n        # Create alpha mask\n        alpha_int = int(round(255*alpha))\n        if center == 'radboud':\n            alpha_content = np.less(mask_data.split()[0], 2).astype('uint8') * alpha_int + (255 - alpha_int)\n        elif center == 'karolinska':\n            alpha_content = np.less(mask_data.split()[0], 1).astype('uint8') * alpha_int + (255 - alpha_int)\n\n        alpha_content = PIL.Image.fromarray(alpha_content)\n        preview_palette = np.zeros(shape=768, dtype=int)\n\n        if center == 'radboud':\n            # Mapping: {0: background, 1: stroma, 2: benign epithelium, 3: Gleason 3, 4: Gleason 4, 5: Gleason 5}\n            preview_palette[0:18] = (np.array([0, 0, 0, 0.5, 0.5, 0.5, 0, 1, 0, 1, 1, 0.7, 1, 0.5, 0, 1, 0, 0]) * 255).astype(int)\n        elif center == 'karolinska':\n            # Mapping: {0: background, 1: benign, 2: cancer}\n            preview_palette[0:9] = (np.array([0, 0, 0, 0, 1, 0, 1, 0, 0]) * 255).astype(int)\n\n        mask_data.putpalette(data=preview_palette.tolist())\n        mask_rgb = mask_data.convert(mode='RGB')\n        overlayed_image = PIL.Image.composite(image1=slide_data, image2=mask_rgb, mask=alpha_content)\n        overlayed_image.thumbnail(size=max_size, resample=0)\n\n        slide.close()\n        mask.close()   \n\n        return overlayed_image","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.828204Z","iopub.execute_input":"2022-04-27T18:47:17.828527Z","iopub.status.idle":"2022-04-27T18:47:17.842508Z","shell.execute_reply.started":"2022-04-27T18:47:17.8285Z","shell.execute_reply":"2022-04-27T18:47:17.841769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = True\nimport os\nimport sys\nsys.path = [\n    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n] + sys.path","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:17.84353Z","iopub.execute_input":"2022-04-27T18:47:17.8442Z","iopub.status.idle":"2022-04-27T18:47:17.85952Z","shell.execute_reply.started":"2022-04-27T18:47:17.84416Z","shell.execute_reply":"2022-04-27T18:47:17.858605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom efficientnet_pytorch import model as enet\nimport albumentations\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom efficientnet_pytorch import EfficientNet","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:43.892618Z","iopub.execute_input":"2022-04-27T18:47:43.893404Z","iopub.status.idle":"2022-04-27T18:47:46.394914Z","shell.execute_reply.started":"2022-04-27T18:47:43.893354Z","shell.execute_reply":"2022-04-27T18:47:46.394227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/prostate-cancer-grade-assessment'\ndf_train = balanced_df\nimage_folder = os.path.join(data_dir, 'train_images')\n\n#kernel_type = 'how_to_train_effnet_b0_to_get_LB_0.86'\n\n#enet_type = 'efficientnet-b0'\nfold = 0\ntile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 2\nnum_workers = 4\nout_dim = 5\ninit_lr = 3e-4\nwarmup_factor = 10\n\nwarmup_epo = 1\nn_epochs = 1 if DEBUG else 30\ndf_train = df_train.sample(100).reset_index(drop=True) if DEBUG else df_train\n\ndevice = torch.device('cuda')\n\nprint(image_folder)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:46.396636Z","iopub.execute_input":"2022-04-27T18:47:46.396892Z","iopub.status.idle":"2022-04-27T18:47:46.412268Z","shell.execute_reply.started":"2022-04-27T18:47:46.396862Z","shell.execute_reply":"2022-04-27T18:47:46.411243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(5, shuffle=True, random_state=42)\ndf_train['fold'] = -1\nfor i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n    df_train.loc[valid_idx, 'fold'] = i\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:46.41372Z","iopub.execute_input":"2022-04-27T18:47:46.413985Z","iopub.status.idle":"2022-04-27T18:47:46.440574Z","shell.execute_reply.started":"2022-04-27T18:47:46.413944Z","shell.execute_reply":"2022-04-27T18:47:46.439877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = {\n    'efficientnet-b0': '../input/efficientnet-pytorch/efficientnet-b0-08094119.pth'\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:46.44165Z","iopub.execute_input":"2022-04-27T18:47:46.442256Z","iopub.status.idle":"2022-04-27T18:47:46.445689Z","shell.execute_reply.started":"2022-04-27T18:47:46.442225Z","shell.execute_reply":"2022-04-27T18:47:46.445116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:46.446771Z","iopub.execute_input":"2022-04-27T18:47:46.447142Z","iopub.status.idle":"2022-04-27T18:47:46.459688Z","shell.execute_reply.started":"2022-04-27T18:47:46.447112Z","shell.execute_reply":"2022-04-27T18:47:46.458632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tiles(img, mode=0):\n        result = []\n        h, w, c = img.shape\n        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n        img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n        img3 = img2.reshape(\n            img2.shape[0] // tile_size,\n            tile_size,\n            img2.shape[1] // tile_size,\n            tile_size,\n            3\n        )\n\n        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n        if len(img3) < n_tiles:\n            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n        img3 = img3[idxs]\n        for i in range(len(img3)):\n            result.append({'img':img3[i], 'idx':i})\n        return result, n_tiles_with_info >= n_tiles\n\n\nclass PANDADataset(Dataset):\n    def __init__(self,\n                 df,\n                 image_size,\n                 n_tiles=n_tiles,\n                 tile_mode=0,\n                 rand=False,\n                 transform=None,\n                ):\n\n        self.df = df.reset_index(drop=True)\n        self.image_size = image_size\n        self.n_tiles = n_tiles\n        self.tile_mode = tile_mode\n        self.rand = rand\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img_id = row.image_id\n        \n        tiff_file = os.path.join(image_folder, f'{img_id}.tiff')\n        image = skimage.io.MultiImage(tiff_file)[-2]\n        tiles, OK = get_tiles(image, self.tile_mode)\n\n        if self.rand:\n            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n        else:\n            idxes = list(range(self.n_tiles))\n\n        n_row_tiles = int(np.sqrt(self.n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n    \n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                if self.transform is not None:\n                    this_img = self.transform(image=this_img)['image']\n                h1 = h * image_size\n                w1 = w * image_size\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n\n        if self.transform is not None:\n            images = self.transform(image=images)['image']\n        images = images.astype(np.float32)\n        images /= 255\n        images = images.transpose(2, 0, 1)\n\n        label = np.zeros(5).astype(np.float32)\n        label[:row.isup_grade] = 1.\n        return torch.tensor(images), torch.tensor(label)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:00:32.189775Z","iopub.execute_input":"2022-04-27T19:00:32.190614Z","iopub.status.idle":"2022-04-27T19:00:32.214553Z","shell.execute_reply.started":"2022-04-27T19:00:32.190574Z","shell.execute_reply":"2022-04-27T19:00:32.213633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms_train = albumentations.Compose([\n    albumentations.Transpose(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    albumentations.HorizontalFlip(p=0.5),\n])\ntransforms_val = albumentations.Compose([])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:00:32.391287Z","iopub.execute_input":"2022-04-27T19:00:32.391801Z","iopub.status.idle":"2022-04-27T19:00:32.396639Z","shell.execute_reply.started":"2022-04-27T19:00:32.391745Z","shell.execute_reply":"2022-04-27T19:00:32.395959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_show = PANDADataset(df_train, image_size, n_tiles, 0, transform=transforms_train)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        img, label = dataset_show[idx]\n        axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n        axarr[p].set_title(str(sum(label)))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:00:32.62534Z","iopub.execute_input":"2022-04-27T19:00:32.625635Z","iopub.status.idle":"2022-04-27T19:00:33.256738Z","shell.execute_reply.started":"2022-04-27T19:00:32.6256Z","shell.execute_reply":"2022-04-27T19:00:33.255602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:00:11.041217Z","iopub.status.idle":"2022-04-27T19:00:11.042306Z","shell.execute_reply.started":"2022-04-27T19:00:11.042028Z","shell.execute_reply":"2022-04-27T19:00:11.042053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(loader, optimizer):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, target) in bar:\n        \n        data, target = data.to(device), target.to(device)\n        loss_func = criterion\n        optimizer.zero_grad()\n        logits = model(data)\n        loss = loss_func(logits, target)\n        loss.backward()\n        optimizer.step()\n\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n    return train_loss\n\n\ndef val_epoch(loader, get_output=False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    PREDS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            data, target = data.to(device), target.to(device)\n            logits = model(data)\n\n            loss = criterion(logits, target)\n\n            pred = logits.sigmoid().sum(1).detach().round()\n            LOGITS.append(logits)\n            PREDS.append(pred)\n            TARGETS.append(target.sum(1))\n\n            val_loss.append(loss.detach().cpu().numpy())\n        val_loss = np.mean(val_loss)\n\n    LOGITS = torch.cat(LOGITS).cpu().numpy()\n    PREDS = torch.cat(PREDS).cpu().numpy()\n    TARGETS = torch.cat(TARGETS).cpu().numpy()\n    acc = (PREDS == TARGETS).mean() * 100.\n    \n    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n\n    if get_output:\n        return LOGITS\n    else:\n        return val_loss, acc, qwk","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:58:11.988537Z","iopub.status.idle":"2022-04-27T18:58:11.989042Z","shell.execute_reply.started":"2022-04-27T18:58:11.988819Z","shell.execute_reply":"2022-04-27T18:58:11.988841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_idx = np.where((df_train['fold'] != fold))[0]\nvalid_idx = np.where((df_train['fold'] == fold))[0]\n\ndf_this  = df_train.loc[train_idx]\ndf_valid = df_train.loc[valid_idx]\n\ndataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\ndataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n\ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\n#model = enetv2(enet_type, out_dim=out_dim)\nmodel = model.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\nscheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\nscheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n\nprint(len(dataset_train), len(dataset_valid))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:56:15.471933Z","iopub.status.idle":"2022-04-27T18:56:15.472524Z","shell.execute_reply.started":"2022-04-27T18:56:15.472327Z","shell.execute_reply":"2022-04-27T18:56:15.472349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qwk_max = 0.\nbest_file = f'{kernel_type}_best_fold{fold}.pth'\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n    scheduler.step(epoch-1)\n\n    train_loss = train_epoch(train_loader, optimizer)\n    val_loss, acc, qwk = val_epoch(valid_loader)\n\n    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n    print(content)\n    with open(f'log_{kernel_type}.txt', 'a') as appender:\n        appender.write(content + '\\n')\n\n    if qwk > qwk_max:\n        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))\n        torch.save(model.state_dict(), best_file)\n        qwk_max = qwk\n\ntorch.save(model.state_dict(), os.path.join(f'{kernel_type}_final_fold{fold}.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:47:58.691047Z","iopub.status.idle":"2022-04-27T18:47:58.691383Z","shell.execute_reply.started":"2022-04-27T18:47:58.69122Z","shell.execute_reply":"2022-04-27T18:47:58.691237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train_validate_test_split(df, train_percent=.8, validate_percent=.15, seed=None):\n#     np.random.seed(seed)\n#     perm = np.random.permutation(df.index)\n#     m = len(df.index)\n#     train_end = int(train_percent * m)\n#     validate_end = int(validate_percent * m) + train_end\n#     train = df.iloc[perm[:train_end]]\n#     validate = df.iloc[perm[train_end:validate_end]]\n#     test = df.iloc[perm[validate_end:]]\n#     return train, validate, test","metadata":{"execution":{"iopub.status.busy":"2022-04-27T12:00:35.427889Z","iopub.execute_input":"2022-04-27T12:00:35.428136Z","iopub.status.idle":"2022-04-27T12:00:35.434545Z","shell.execute_reply.started":"2022-04-27T12:00:35.428103Z","shell.execute_reply":"2022-04-27T12:00:35.433679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def save_folder(df):\n#     save_mask_dir = '/kaggle/pc_detection/CoAtNet/'\n#     os.makedirs(save_mask_dir, exist_ok=True)\n#     for i, img_id in tqdm(enumerate(df.image_id)):\n#         src_dir = BASE_FOLDER + \"train_images\"\n#         dst_dir = save_mask_dir + \"df\"\n#         for jpgfile in glob.iglob(os.path.join(src_dir, img_id+\".tiff\")):\n#             shutil.copy(jpgfile, dst_dir)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T12:03:08.306005Z","iopub.execute_input":"2022-04-27T12:03:08.306288Z","iopub.status.idle":"2022-04-27T12:03:08.312904Z","shell.execute_reply.started":"2022-04-27T12:03:08.306258Z","shell.execute_reply":"2022-04-27T12:03:08.312092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom efficientnet_pytorch import model as enet\nimport albumentations\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm import tqdm\nimport pickle\nfrom PIL import Image\nfrom skimage.io import imread\nimport skimage.feature as skfeature\nimport sklearn\nimport os\nfrom efficientnet_pytorch import EfficientNet\n\nif len(sys.argv) == 1:\n    print('Specify GPU via parameter.')\n    exit(1)\n\nos.environ['CUDA_VISIBLE_DEVICES'] = sys.argv[1]\n\ndata_dir = '../input/prostate-cancer-grade-assessment'\ndf_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ndf_sub = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\nimage_folder = os.path.join(data_dir, 'train_images')\n\nkernel_type = 'model'\n\nenet_type = 'efficientnet-b0'\nfold = 0\ntile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 2\nnum_workers = 4\nout_dim = 5\ninit_lr = 3e-4\nwarmup_factor = 10\nwarmup_epo = 1\nn_epochs = 5 \ndf_train = df_train.sample(300).reset_index(drop=True)\nprint(df_train.shape)\neps = np.finfo(np.float32).eps\n\ndevice = torch.device('cuda')\n\nprint(image_folder)\n\nraw_image_ids = [s[:s.find('.')] for s in os.listdir(image_folder)]\ndf_train = df_train[df_train['image_id'].isin(raw_image_ids)].reset_index(drop=True)\nprint(df_train.shape)\n\nskf = StratifiedKFold(5, shuffle=True, random_state=42)\ndf_train['fold'] = -1\nfor i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n    df_train.loc[valid_idx, 'fold'] = i\n\npretrained_model = {\n    'efficientnet-b0': 'efficientnet-b0-08094119.pth'\n}\n\nclass enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x\n\ndef get_tiles(image_id, mode=0):\n    tiff_file = os.path.join(image_folder, f'{image_id}.tiff')\n    img = skimage.io.MultiImage(tiff_file)[-1]\n\n    result = []\n    h, w, c = img.shape    \n    pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n    pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n    img2 = np.pad(img, [[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n    img3 = img2.reshape(\n        img2.shape[0] // tile_size,\n        tile_size,\n        img2.shape[1] // tile_size,\n        tile_size,\n        3\n    )\n    img3 = img3.transpose(0, 2, 1, 3, 4).reshape(-1, tile_size, tile_size, 3)\n    n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n\n    if len(img3) < n_tiles:\n        img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]],mode='constant', constant_values=255)\n    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n    img3 = img3[idxs]\n\n    result = []\n    for i in range(len(img3)):\n        result.append({'img':img3[i], 'idx':i})\n    return result, n_tiles_with_info >= n_tiles\n\nclass PANDADataset(Dataset):\n    def __init__(self,\n                 df,\n                 image_size,\n                 n_tiles=n_tiles,\n                 tile_mode=0,\n                 rand=False,\n                 transform=None,\n                ):\n\n        self.df = df.reset_index(drop=True)\n        self.image_size = image_size\n        self.n_tiles = n_tiles\n        self.tile_mode = tile_mode\n        self.rand = rand\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img_id = row.image_id\n        \n        tiles, OK = get_tiles(img_id, self.tile_mode)\n\n        if self.rand:\n            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n        else:\n            idxes = list(range(self.n_tiles))\n\n        n_row_tiles = int(np.sqrt(self.n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n                h1 = h * image_size\n                w1 = w * image_size    \n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                if self.transform is not None:\n                    this_img = self.transform(image=this_img)['image']\n\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n\n        if self.transform is not None:\n            images = self.transform(image=images)['image']\n        images = images.astype(np.float32)\n        images /= 255\n        images = images.transpose(2, 0, 1)\n\n        label = np.zeros(5).astype(np.float32)\n        label[:row.isup_grade] = 1.\n        return torch.tensor(images), torch.tensor(label)\n\n\ntransforms_train = albumentations.Compose([\n    albumentations.Transpose(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    albumentations.HorizontalFlip(p=0.5),\n])\ntransforms_val = albumentations.Compose([])\n\ncriterion = nn.BCEWithLogitsLoss()\ndef train_epoch(loader, optimizer):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, target) in bar:\n        \n        data, target = data.to(device), target.to(device)\n        loss_func = criterion\n        optimizer.zero_grad()\n        logits = model(data)\n\n        loss = loss_func(logits, target)\n        loss.backward()\n        optimizer.step()\n\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n    return train_loss\n\n\ndef val_epoch(loader, confusion_matrix=False, get_output=False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    PREDS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            data, target = data.to(device), target.to(device)\n            logits = model(data)\n\n            loss = criterion(logits, target)\n\n            pred = logits.sigmoid().sum(1).detach().round()\n            LOGITS.append(logits)\n            PREDS.append(pred)\n            TARGETS.append(target.sum(1))\n\n            val_loss.append(loss.detach().cpu().numpy())\n        val_loss = np.mean(val_loss)\n\n    LOGITS = torch.cat(LOGITS).cpu().numpy()\n    PREDS = torch.cat(PREDS).cpu().numpy()\n    TARGETS = torch.cat(TARGETS).cpu().numpy()\n\n    acc = (np.clip(ROUND_PREDS, 0, 5) == TARGETS).mean()\n\n    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n\n    if get_output:\n        return LOGITS\n    else:\n        return val_loss, acc, qwk\n\ntrain_idx = np.where((df_train['fold'] != fold))[0]\nvalid_idx = np.where((df_train['fold'] == fold))[0]\n\ndf_this  = df_train.loc[train_idx]\ndf_valid = df_train.loc[valid_idx]\n\ndataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\ndataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n\ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\n# model = nn.DataParallel(model)\nmodel = model.to(device)\noptimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\nscheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\nscheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n\nprint(len(dataset_train), len(dataset_valid))\n\nqwk_max = 0.\nbest_file = 'model_{}_{}.pth'\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n    scheduler.step(epoch-1)\n\n    train_loss = train_epoch(train_loader, optimizer)\n    val_loss, acc, qwk = val_epoch(valid_loader, confusion_matrix=True)\n\n    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n    print(content)\n    with open(f'log_{kernel_type}.txt', 'a') as appender:\n        appender.write(content + '\\n')\n\n    if qwk > qwk_max:\n        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))\n        torch.save(model.state_dict(), best_file.format(sys.argv[1], qwk))\n        qwk_max = qwk\n\ntorch.save(model.state_dict(), os.path.join(f'{kernel_type}_final_fold{fold}.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T05:26:09.203187Z","iopub.execute_input":"2022-04-28T05:26:09.203466Z","iopub.status.idle":"2022-04-28T05:26:15.130902Z","shell.execute_reply.started":"2022-04-28T05:26:09.203431Z","shell.execute_reply":"2022-04-28T05:26:15.129129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install warmup-scheduler\n!pip install efficientnet-pytorch","metadata":{"execution":{"iopub.status.busy":"2022-04-28T05:25:48.342201Z","iopub.execute_input":"2022-04-28T05:25:48.342534Z","iopub.status.idle":"2022-04-28T05:26:09.200406Z","shell.execute_reply.started":"2022-04-28T05:25:48.342451Z","shell.execute_reply":"2022-04-28T05:26:09.199575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Successful Run","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:29:20.403266Z","iopub.execute_input":"2022-04-27T14:29:20.403654Z","iopub.status.idle":"2022-04-27T14:29:32.197886Z","shell.execute_reply.started":"2022-04-27T14:29:20.403598Z","shell.execute_reply":"2022-04-27T14:29:32.196812Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport math\nimport cv2\nimport PIL\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom tensorflow.keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nimport tensorflow as tf\nfrom tqdm import tqdm\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:59:18.229447Z","iopub.execute_input":"2022-04-28T13:59:18.229711Z","iopub.status.idle":"2022-04-28T13:59:18.84706Z","shell.execute_reply.started":"2022-04-28T13:59:18.229685Z","shell.execute_reply":"2022-04-28T13:59:18.846254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# There are two ways to load the data from the PANDA dataset:\n# Option 1: Load images using openslide\nimport openslide\n# Option 2: Load images using skimage (requires that tifffile is installed)\nimport skimage.io\n# General packages\nfrom IPython.display import display\n# Plotly for the interactive viewer (see last section)\nimport plotly.graph_objs as go\n# read images\nimport rasterio\n\nimport gc\nfrom random import randint","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:59:55.545325Z","iopub.execute_input":"2022-04-28T13:59:55.54586Z","iopub.status.idle":"2022-04-28T13:59:56.243712Z","shell.execute_reply.started":"2022-04-28T13:59:55.545815Z","shell.execute_reply":"2022-04-28T13:59:56.242873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:00:00.881645Z","iopub.execute_input":"2022-04-28T14:00:00.882392Z","iopub.status.idle":"2022-04-28T14:00:00.896687Z","shell.execute_reply.started":"2022-04-28T14:00:00.882352Z","shell.execute_reply":"2022-04-28T14:00:00.895736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 15\nTRAIN_VAL_RATIO = 0.27\nEPOCHS = 5\nLR = 0.00010409613402110064","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:01:32.897106Z","iopub.execute_input":"2022-04-28T14:01:32.89755Z","iopub.status.idle":"2022-04-28T14:01:32.90705Z","shell.execute_reply.started":"2022-04-28T14:01:32.897503Z","shell.execute_reply":"2022-04-28T14:01:32.906114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\ntest_df = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:00:07.459304Z","iopub.execute_input":"2022-04-28T14:00:07.459561Z","iopub.status.idle":"2022-04-28T14:00:07.511437Z","shell.execute_reply.started":"2022-04-28T14:00:07.459534Z","shell.execute_reply":"2022-04-28T14:00:07.51071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_validate_test_split(df, train_percent=.8, seed=None):\n    np.random.seed(seed)\n    perm = np.random.permutation(df.index)\n    m = len(df.index)\n    train_end = int(train_percent * m)\n    train = df.iloc[perm[:train_end]]\n    test = df.iloc[perm[train_end:]]\n    return train, test","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:01:36.32841Z","iopub.execute_input":"2022-04-28T14:01:36.328688Z","iopub.status.idle":"2022-04-28T14:01:36.334752Z","shell.execute_reply.started":"2022-04-28T14:01:36.328659Z","shell.execute_reply":"2022-04-28T14:01:36.333706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = train_validate_test_split(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:01:38.496274Z","iopub.execute_input":"2022-04-28T14:01:38.496541Z","iopub.status.idle":"2022-04-28T14:01:38.506593Z","shell.execute_reply.started":"2022-04-28T14:01:38.496512Z","shell.execute_reply":"2022-04-28T14:01:38.505794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(image_path, desired_size=224):\n    biopsy = openslide.OpenSlide(image_path)\n    im = np.array(biopsy.get_thumbnail(size=(desired_size,desired_size)))\n    im = Image.fromarray(im)\n    im = im.resize((desired_size,desired_size)) \n    im = np.array(im)\n    return im","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:02:13.953475Z","iopub.execute_input":"2022-04-28T14:02:13.953741Z","iopub.status.idle":"2022-04-28T14:02:13.95857Z","shell.execute_reply.started":"2022-04-28T14:02:13.953713Z","shell.execute_reply":"2022-04-28T14:02:13.957756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:02:19.838946Z","iopub.execute_input":"2022-04-28T14:02:19.839637Z","iopub.status.idle":"2022-04-28T14:02:19.842746Z","shell.execute_reply.started":"2022-04-28T14:02:19.839601Z","shell.execute_reply":"2022-04-28T14:02:19.842084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the number of training images from the target\\id dataset\nN = df_train.shape[0]\n# create an empty matrix for storing the images\nx_train = np.empty((N, 224, 224, 3), dtype=np.uint8)\n# loop through the images from the images ids from the target\\id dataset\n# then grab the cooresponding image from disk, pre-process, and store in matrix in memory\nfor i, image_id in enumerate(tqdm(df_train['image_id'])):\n    x_train[i, :, :, :] = preprocess_image(\n        f'../input/prostate-cancer-grade-assessment/train_images/{image_id}.tiff'\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:04:21.865612Z","iopub.execute_input":"2022-04-28T14:04:21.865903Z","iopub.status.idle":"2022-04-28T14:22:20.392067Z","shell.execute_reply.started":"2022-04-28T14:04:21.865871Z","shell.execute_reply":"2022-04-28T14:22:20.391378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.exists('/kaggle/pc_detection/test_data/'):\n    # do the same thing as the last cell but on the test\\holdout set\n    N = df_test[:3].shape[0]\n    x_test = np.empty((N, 224, 224, 3), dtype=np.uint8)\n    for i, image_id in enumerate(tqdm(df_test['image_id'][:3])):\n        x_test[i, :, :, :] = preprocess_image(\n            f'/kaggle/pc_detection/test_data/{image_id}.tiff'\n        )\nelse:\n    print(\"test images not found\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:07:28.379078Z","iopub.execute_input":"2022-04-28T15:07:28.379641Z","iopub.status.idle":"2022-04-28T15:07:28.528963Z","shell.execute_reply.started":"2022-04-28T15:07:28.379603Z","shell.execute_reply":"2022-04-28T15:07:28.528269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pre-processing the target (i.e. one-hot encoding the target)\ny_train = pd.get_dummies(df_train['isup_grade']).values\n\nprint(x_train.shape)\nprint(y_train.shape)\nif os.path.exists('/kaggle/pc_detection/test_data/'):\n    print(x_test.shape)\nelse:\n    print(\"test images not found\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:07:31.623429Z","iopub.execute_input":"2022-04-28T15:07:31.62397Z","iopub.status.idle":"2022-04-28T15:07:31.6327Z","shell.execute_reply.started":"2022-04-28T15:07:31.623933Z","shell.execute_reply":"2022-04-28T15:07:31.631868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_multi = np.empty(y_train.shape, dtype=y_train.dtype)\ny_train_multi[:, 5] = y_train[:, 5]\n\nfor i in range(4, -1, -1):\n    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i+1])\n\n# print(\"Original y_train:\", y_train.sum(axis=0))\n# print(\"Multilabel version:\", y_train_multi.sum(axis=0))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:59:32.674235Z","iopub.execute_input":"2022-04-28T14:59:32.674689Z","iopub.status.idle":"2022-04-28T14:59:32.683968Z","shell.execute_reply.started":"2022-04-28T14:59:32.674653Z","shell.execute_reply":"2022-04-28T14:59:32.683264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:22:37.987445Z","iopub.execute_input":"2022-04-28T14:22:37.98785Z","iopub.status.idle":"2022-04-28T14:22:37.99213Z","shell.execute_reply.started":"2022-04-28T14:22:37.987815Z","shell.execute_reply":"2022-04-28T14:22:37.991302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train_multi, \n    test_size=TRAIN_VAL_RATIO, \n    random_state=2020\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:22:43.033904Z","iopub.execute_input":"2022-04-28T14:22:43.034502Z","iopub.status.idle":"2022-04-28T14:22:43.410062Z","shell.execute_reply.started":"2022-04-28T14:22:43.034458Z","shell.execute_reply":"2022-04-28T14:22:43.409372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:22:47.202931Z","iopub.execute_input":"2022-04-28T14:22:47.20366Z","iopub.status.idle":"2022-04-28T14:22:47.207776Z","shell.execute_reply.started":"2022-04-28T14:22:47.203623Z","shell.execute_reply":"2022-04-28T14:22:47.206924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.15,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n    )\n\n# Using original generator\ndata_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2019)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:22:58.636609Z","iopub.execute_input":"2022-04-28T14:22:58.63686Z","iopub.status.idle":"2022-04-28T14:22:59.54007Z","shell.execute_reply.started":"2022-04-28T14:22:58.636833Z","shell.execute_reply":"2022-04-28T14:22:59.539141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.densenet import DenseNet121","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:23:02.435811Z","iopub.execute_input":"2022-04-28T14:23:02.436085Z","iopub.status.idle":"2022-04-28T14:23:02.440918Z","shell.execute_reply.started":"2022-04-28T14:23:02.436056Z","shell.execute_reply":"2022-04-28T14:23:02.440192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"densenet = DenseNet121(\n    weights='../input/input/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(224,224,3)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:23:04.350266Z","iopub.execute_input":"2022-04-28T14:23:04.351056Z","iopub.status.idle":"2022-04-28T14:23:09.672821Z","shell.execute_reply.started":"2022-04-28T14:23:04.35098Z","shell.execute_reply":"2022-04-28T14:23:09.672076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(LR=LR):\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.80))\n    model.add(layers.Dense(6, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=LR),\n        metrics=['accuracy']\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:23:09.674262Z","iopub.execute_input":"2022-04-28T14:23:09.674515Z","iopub.status.idle":"2022-04-28T14:23:09.681824Z","shell.execute_reply.started":"2022-04-28T14:23:09.67447Z","shell.execute_reply":"2022-04-28T14:23:09.680922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:23:10.92092Z","iopub.execute_input":"2022-04-28T14:23:10.921481Z","iopub.status.idle":"2022-04-28T14:23:10.92488Z","shell.execute_reply.started":"2022-04-28T14:23:10.921444Z","shell.execute_reply":"2022-04-28T14:23:10.924202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:23:12.372187Z","iopub.execute_input":"2022-04-28T14:23:12.372715Z","iopub.status.idle":"2022-04-28T14:23:13.145966Z","shell.execute_reply.started":"2022-04-28T14:23:12.372675Z","shell.execute_reply":"2022-04-28T14:23:13.145313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    data_generator,\n    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=(x_val, y_val)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:23:19.649847Z","iopub.execute_input":"2022-04-28T14:23:19.65052Z","iopub.status.idle":"2022-04-28T14:31:10.023201Z","shell.execute_reply.started":"2022-04-28T14:23:19.650474Z","shell.execute_reply":"2022-04-28T14:31:10.022471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['accuracy', 'val_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:31:10.024924Z","iopub.execute_input":"2022-04-28T14:31:10.025633Z","iopub.status.idle":"2022-04-28T14:31:10.714453Z","shell.execute_reply.started":"2022-04-28T14:31:10.025595Z","shell.execute_reply":"2022-04-28T14:31:10.713096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_FOLDER = \"../input/prostate-cancer-grade-assessment/\"\nsample = BASE_FOLDER+\"sample_submission.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:43:11.272424Z","iopub.execute_input":"2022-04-28T14:43:11.272683Z","iopub.status.idle":"2022-04-28T14:43:11.276223Z","shell.execute_reply.started":"2022-04-28T14:43:11.272655Z","shell.execute_reply":"2022-04-28T14:43:11.275524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport cv2\nimport shutil\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-04-28T14:43:58.585489Z","iopub.execute_input":"2022-04-28T14:43:58.585751Z","iopub.status.idle":"2022-04-28T14:43:58.589657Z","shell.execute_reply.started":"2022-04-28T14:43:58.585723Z","shell.execute_reply":"2022-04-28T14:43:58.588869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_folder(df):\n    save_mask_dir = '/kaggle/pc_detection/test_data/'\n    os.makedirs(save_mask_dir, exist_ok=True)\n    for i, img_id in tqdm(enumerate(df.image_id[:3])):\n        src_dir = BASE_FOLDER + \"train_images\"\n        dst_dir = save_mask_dir\n        for jpgfile in glob.iglob(os.path.join(src_dir, img_id+\".tiff\")):\n            shutil.copy(jpgfile, dst_dir)\n    print(dst_dir)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:04:40.405304Z","iopub.execute_input":"2022-04-28T15:04:40.405565Z","iopub.status.idle":"2022-04-28T15:04:40.411235Z","shell.execute_reply.started":"2022-04-28T15:04:40.405537Z","shell.execute_reply":"2022-04-28T15:04:40.410453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = save_folder(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:04:41.355868Z","iopub.execute_input":"2022-04-28T15:04:41.356316Z","iopub.status.idle":"2022-04-28T15:04:41.458167Z","shell.execute_reply.started":"2022-04-28T15:04:41.356279Z","shell.execute_reply":"2022-04-28T15:04:41.457414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test1 = df_test[:3]","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:15:35.560467Z","iopub.execute_input":"2022-04-28T15:15:35.560752Z","iopub.status.idle":"2022-04-28T15:15:35.564871Z","shell.execute_reply.started":"2022-04-28T15:15:35.560721Z","shell.execute_reply":"2022-04-28T15:15:35.563933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test1","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:15:37.087488Z","iopub.execute_input":"2022-04-28T15:15:37.087739Z","iopub.status.idle":"2022-04-28T15:15:37.096508Z","shell.execute_reply.started":"2022-04-28T15:15:37.087711Z","shell.execute_reply":"2022-04-28T15:15:37.095864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import randint\n\ntest_img_path = '/kaggle/pc_detection/test_data/'\n\nif os.path.exists(test_img_path):\n    y_test = model.predict(x_test)\n    y_test = y_test > 0.37757874193797547\n    y_test = y_test.astype(int).sum(axis=1) - 1\nelse:\n    y_test = [randint(0, 5) for i in range(3)]\n\ndf_test1['isup_grade_1'] = y_test\ndf_test1 = df_test1[[\"image_id\", \"isup_grade\", \"isup_grade_1\"]]\ndf_test1.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:15:39.427684Z","iopub.execute_input":"2022-04-28T15:15:39.429207Z","iopub.status.idle":"2022-04-28T15:15:39.495883Z","shell.execute_reply.started":"2022-04-28T15:15:39.429159Z","shell.execute_reply":"2022-04-28T15:15:39.494216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test1","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:15:40.689843Z","iopub.execute_input":"2022-04-28T15:15:40.69054Z","iopub.status.idle":"2022-04-28T15:15:40.698945Z","shell.execute_reply.started":"2022-04-28T15:15:40.690506Z","shell.execute_reply":"2022-04-28T15:15:40.698199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if os.path.exists('/kaggle/pc_detection/test_data/'):\n#     print(\"test images found.\")\n#     y_test = model.predict(x_test)\n#     y_test = y_test > 0.37757874193797547\n#     y_test = y_test.astype(int).sum(axis=1) - 1\n#     df_test1['isup_grade'] = y_test\n#     df_test1 = df_test[[\"image_id\",\"isup_grade\"]]\n#     df_test1.to_csv('submission.csv',index=False)\n# else: # if test is not available, just submit some random values\n#     print(\"test images not found, submitting random values.\")\n#     rand_preds = []\n#     for i in range(len(df_test1)):\n#         rand_preds.append(randint(0,5))\n#     df_test1['isup_grade_1'] = rand_preds\n#     df_test1 = df_test[[\"image_id\",\"isup_grade\", \"isup_grade_1\"]]\n#     df_test1.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:11:11.72153Z","iopub.execute_input":"2022-04-28T15:11:11.721801Z","iopub.status.idle":"2022-04-28T15:11:11.791938Z","shell.execute_reply.started":"2022-04-28T15:11:11.721773Z","shell.execute_reply":"2022-04-28T15:11:11.791259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test1","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:11:14.583244Z","iopub.execute_input":"2022-04-28T15:11:14.583522Z","iopub.status.idle":"2022-04-28T15:11:14.598941Z","shell.execute_reply.started":"2022-04-28T15:11:14.583492Z","shell.execute_reply":"2022-04-28T15:11:14.597889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/pc_detection/test_data/'))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:04:46.134191Z","iopub.execute_input":"2022-04-28T15:04:46.134724Z","iopub.status.idle":"2022-04-28T15:04:46.142166Z","shell.execute_reply.started":"2022-04-28T15:04:46.134688Z","shell.execute_reply":"2022-04-28T15:04:46.141485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nremoving_files = glob.glob('/kaggle/pc_detection/test_data/*.tiff')\nfor i in removing_files:\n    os.remove(i)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:04:22.487583Z","iopub.execute_input":"2022-04-28T15:04:22.48784Z","iopub.status.idle":"2022-04-28T15:04:22.493867Z","shell.execute_reply.started":"2022-04-28T15:04:22.487812Z","shell.execute_reply":"2022-04-28T15:04:22.492924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath = 'kagle/Denset/Dmodel/my_model.h5'\nmodel.save(filepath)\nnew_model = tf.keras.models.load_model(filepath)\nnew_model.summary()\n# tensorflow.keras.models.save_model(\n#     model,\n#     filepath\n# )","metadata":{"execution":{"iopub.status.busy":"2022-04-28T09:56:58.988539Z","iopub.execute_input":"2022-04-28T09:56:58.988831Z","iopub.status.idle":"2022-04-28T09:56:58.993863Z","shell.execute_reply.started":"2022-04-28T09:56:58.988802Z","shell.execute_reply":"2022-04-28T09:56:58.992952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(filepath)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T09:57:00.057925Z","iopub.execute_input":"2022-04-28T09:57:00.058255Z","iopub.status.idle":"2022-04-28T09:58:06.970599Z","shell.execute_reply.started":"2022-04-28T09:57:00.058213Z","shell.execute_reply":"2022-04-28T09:58:06.969529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model = tf.keras.models.load_model(filepath)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:01:40.227782Z","iopub.execute_input":"2022-04-28T10:01:40.228056Z","iopub.status.idle":"2022-04-28T10:02:05.019375Z","shell.execute_reply.started":"2022-04-28T10:01:40.228026Z","shell.execute_reply":"2022-04-28T10:02:05.018562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:02:05.03988Z","iopub.execute_input":"2022-04-28T10:02:05.040101Z","iopub.status.idle":"2022-04-28T10:02:05.10358Z","shell.execute_reply.started":"2022-04-28T10:02:05.04007Z","shell.execute_reply":"2022-04-28T10:02:05.102864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = True","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:35.478941Z","iopub.execute_input":"2022-04-28T10:41:35.479302Z","iopub.status.idle":"2022-04-28T10:41:35.48434Z","shell.execute_reply.started":"2022-04-28T10:41:35.479258Z","shell.execute_reply":"2022-04-28T10:41:35.483449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:36.260266Z","iopub.execute_input":"2022-04-28T10:41:36.261104Z","iopub.status.idle":"2022-04-28T10:41:51.22089Z","shell.execute_reply.started":"2022-04-28T10:41:36.261071Z","shell.execute_reply":"2022-04-28T10:41:51.219902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nsys.path = [\n    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n] + sys.path","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:51.22541Z","iopub.execute_input":"2022-04-28T10:41:51.225712Z","iopub.status.idle":"2022-04-28T10:41:51.231204Z","shell.execute_reply.started":"2022-04-28T10:41:51.225678Z","shell.execute_reply":"2022-04-28T10:41:51.230229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom efficientnet_pytorch import model as enet\nimport albumentations\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm import tqdm_notebook as tqdm","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:51.233293Z","iopub.execute_input":"2022-04-28T10:41:51.233802Z","iopub.status.idle":"2022-04-28T10:41:55.446477Z","shell.execute_reply.started":"2022-04-28T10:41:51.233756Z","shell.execute_reply":"2022-04-28T10:41:55.445387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/prostate-cancer-grade-assessment'\ndf_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\nimage_folder = os.path.join(data_dir, 'train_images')\n\nkernel_type = 'how_to_train_effnet_b0_to_get_LB_0.86'\n\nenet_type = 'efficientnet-b0'\nfold = 0\ntile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 64\nnum_workers = 2\nout_dim = 5\ninit_lr = 1e-1\nwarmup_factor = 10\n\nwarmup_epo = 1\nn_epochs = 1 if DEBUG else 30\ndf_train = df_train.sample(50).reset_index(drop=True) if DEBUG else df_train\n\n#device = torch.device('cuda')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(image_folder)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:15:47.069075Z","iopub.execute_input":"2022-04-28T11:15:47.069466Z","iopub.status.idle":"2022-04-28T11:15:47.169253Z","shell.execute_reply.started":"2022-04-28T11:15:47.069431Z","shell.execute_reply":"2022-04-28T11:15:47.1681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:15:47.80491Z","iopub.execute_input":"2022-04-28T11:15:47.805754Z","iopub.status.idle":"2022-04-28T11:15:47.815373Z","shell.execute_reply.started":"2022-04-28T11:15:47.805701Z","shell.execute_reply":"2022-04-28T11:15:47.814018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(5, shuffle=True, random_state=42)\ndf_train['fold'] = -1\nfor i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n    df_train.loc[valid_idx, 'fold'] = i\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:55.496888Z","iopub.execute_input":"2022-04-28T10:41:55.497298Z","iopub.status.idle":"2022-04-28T10:41:55.53325Z","shell.execute_reply.started":"2022-04-28T10:41:55.497241Z","shell.execute_reply":"2022-04-28T10:41:55.532368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" pretrained_model = {\n    'efficientnet-b0': '../input/efficientnet-pytorch/efficientnet-b0-08094119.pth'\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:55.534634Z","iopub.execute_input":"2022-04-28T10:41:55.534939Z","iopub.status.idle":"2022-04-28T10:41:55.539804Z","shell.execute_reply.started":"2022-04-28T10:41:55.534911Z","shell.execute_reply":"2022-04-28T10:41:55.538535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:55.541836Z","iopub.execute_input":"2022-04-28T10:41:55.542618Z","iopub.status.idle":"2022-04-28T10:41:55.553421Z","shell.execute_reply.started":"2022-04-28T10:41:55.542577Z","shell.execute_reply":"2022-04-28T10:41:55.552353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tiles(img, mode=0):\n        result = []\n        h, w, c = img.shape\n        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n        img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n        img3 = img2.reshape(\n            img2.shape[0] // tile_size,\n            tile_size,\n            img2.shape[1] // tile_size,\n            tile_size,\n            3\n        )\n\n        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n        if len(img3) < n_tiles:\n            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n        img3 = img3[idxs]\n        for i in range(len(img3)):\n            result.append({'img':img3[i], 'idx':i})\n        return result, n_tiles_with_info >= n_tiles\n\n\nclass PANDADataset(Dataset):\n    def __init__(self,\n                 df,\n                 image_size,\n                 n_tiles=n_tiles,\n                 tile_mode=0,\n                 rand=False,\n                 transform=None,\n                ):\n\n        self.df = df.reset_index(drop=True)\n        self.image_size = image_size\n        self.n_tiles = n_tiles\n        self.tile_mode = tile_mode\n        self.rand = rand\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img_id = row.image_id\n        \n        tiff_file = os.path.join(image_folder, f'{img_id}.tiff')\n        image = skimage.io.MultiImage(tiff_file)[-1]\n        tiles, OK = get_tiles(image, self.tile_mode)\n\n        if self.rand:\n            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n        else:\n            idxes = list(range(self.n_tiles))\n\n        n_row_tiles = int(np.sqrt(self.n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n    \n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                if self.transform is not None:\n                    this_img = self.transform(image=this_img)['image']\n                h1 = h * image_size\n                w1 = w * image_size\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n\n        if self.transform is not None:\n            images = self.transform(image=images)['image']\n        images = images.astype(np.float32)\n        images /= 255\n        images = images.transpose(2, 0, 1)\n\n        label = np.zeros(5).astype(np.float32)\n        label[:row.isup_grade] = 1.\n        return torch.tensor(images), torch.tensor(label)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:55.557081Z","iopub.execute_input":"2022-04-28T10:41:55.557899Z","iopub.status.idle":"2022-04-28T10:41:55.582127Z","shell.execute_reply.started":"2022-04-28T10:41:55.557852Z","shell.execute_reply":"2022-04-28T10:41:55.580821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms_train = albumentations.Compose([\n    albumentations.Transpose(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    albumentations.HorizontalFlip(p=0.5),\n])\ntransforms_val = albumentations.Compose([])","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:55.585764Z","iopub.execute_input":"2022-04-28T10:41:55.586048Z","iopub.status.idle":"2022-04-28T10:41:55.598106Z","shell.execute_reply.started":"2022-04-28T10:41:55.586006Z","shell.execute_reply":"2022-04-28T10:41:55.597119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_show = PANDADataset(df_train, image_size, n_tiles, 0, transform=transforms_train)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        img, label = dataset_show[idx]\n        axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n        axarr[p].set_title(str(sum(label)))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:41:55.602199Z","iopub.execute_input":"2022-04-28T10:41:55.602656Z","iopub.status.idle":"2022-04-28T10:43:25.533127Z","shell.execute_reply.started":"2022-04-28T10:41:55.6026Z","shell.execute_reply":"2022-04-28T10:43:25.532244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:43:25.534981Z","iopub.execute_input":"2022-04-28T10:43:25.535713Z","iopub.status.idle":"2022-04-28T10:43:25.540921Z","shell.execute_reply.started":"2022-04-28T10:43:25.535669Z","shell.execute_reply":"2022-04-28T10:43:25.539646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(loader, optimizer):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, target) in bar:\n        \n        data, target = data.to(device), target.to(device)\n        loss_func = criterion\n        optimizer.zero_grad()\n        logits = model(data)\n        loss = loss_func(logits, target)\n        loss.backward()\n        optimizer.step()\n\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n    return train_loss\n\n\ndef val_epoch(loader, get_output=False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    PREDS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            data, target = data.to(device), target.to(device)\n            logits = model(data)\n\n            loss = criterion(logits, target)\n\n            pred = logits.sigmoid().sum(1).detach().round()\n            LOGITS.append(logits)\n            PREDS.append(pred)\n            TARGETS.append(target.sum(1))\n\n            val_loss.append(loss.detach().cpu().numpy())\n        val_loss = np.mean(val_loss)\n\n    LOGITS = torch.cat(LOGITS).cpu().numpy()\n    PREDS = torch.cat(PREDS).cpu().numpy()\n    TARGETS = torch.cat(TARGETS).cpu().numpy()\n    acc = (PREDS == TARGETS).mean() * 100.\n    \n    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n\n    if get_output:\n        return LOGITS\n    else:\n        return val_loss, acc, qwk","metadata":{"execution":{"iopub.status.busy":"2022-04-28T10:43:25.542724Z","iopub.execute_input":"2022-04-28T10:43:25.544207Z","iopub.status.idle":"2022-04-28T10:43:25.567589Z","shell.execute_reply.started":"2022-04-28T10:43:25.544167Z","shell.execute_reply":"2022-04-28T10:43:25.56643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_idx = np.where((df_train['fold'] != fold))[0]\nvalid_idx = np.where((df_train['fold'] == fold))[0]\n\ndf_this  = df_train.loc[train_idx]\ndf_valid = df_train.loc[valid_idx]\n\ndataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\ndataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n\ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n\nmodel = enetv2(enet_type, out_dim=out_dim)\nmodel = model.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.1)\n#scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\n#scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=2, after_scheduler=scheduler_cosine)\n\nprint(len(dataset_train), len(dataset_valid))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:08:23.455483Z","iopub.execute_input":"2022-04-28T11:08:23.455865Z","iopub.status.idle":"2022-04-28T11:08:24.309335Z","shell.execute_reply.started":"2022-04-28T11:08:23.455833Z","shell.execute_reply":"2022-04-28T11:08:24.308343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_loader.dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:06:01.767872Z","iopub.execute_input":"2022-04-28T11:06:01.768831Z","iopub.status.idle":"2022-04-28T11:06:01.776333Z","shell.execute_reply.started":"2022-04-28T11:06:01.768756Z","shell.execute_reply":"2022-04-28T11:06:01.775418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.parameters","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:01:35.840168Z","iopub.execute_input":"2022-04-28T11:01:35.840946Z","iopub.status.idle":"2022-04-28T11:01:35.845755Z","shell.execute_reply.started":"2022-04-28T11:01:35.840885Z","shell.execute_reply":"2022-04-28T11:01:35.84458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qwk_max = 0.\nbest_file = f'{kernel_type}_best_fold{fold}.pth'\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n    #scheduler.step(epoch-1)\n\n    train_loss = train_epoch(train_loader, optimizer)\n    val_loss, acc, qwk = val_epoch(valid_loader)\n\n    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n    print(content)\n    with open(f'log_{kernel_type}.txt', 'a') as appender:\n        appender.write(content + '\\n')\n\n    if qwk > qwk_max:\n        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))\n        torch.save(model.state_dict(), best_file)\n        qwk_max = qwk\n\ntorch.save(model.state_dict(), os.path.join(f'{kernel_type}_final_fold{fold}.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:08:28.238517Z","iopub.execute_input":"2022-04-28T11:08:28.239406Z","iopub.status.idle":"2022-04-28T11:14:46.317897Z","shell.execute_reply.started":"2022-04-28T11:08:28.239371Z","shell.execute_reply":"2022-04-28T11:14:46.315632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-28T11:16:00.395156Z","iopub.execute_input":"2022-04-28T11:16:00.395809Z","iopub.status.idle":"2022-04-28T11:16:00.40383Z","shell.execute_reply.started":"2022-04-28T11:16:00.395771Z","shell.execute_reply":"2022-04-28T11:16:00.402578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:36:43.004787Z","iopub.execute_input":"2022-04-28T12:36:43.005603Z","iopub.status.idle":"2022-04-28T12:36:43.030204Z","shell.execute_reply.started":"2022-04-28T12:36:43.005506Z","shell.execute_reply":"2022-04-28T12:36:43.029507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nsys.path = [\n    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n] + sys.path","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:36:44.239286Z","iopub.execute_input":"2022-04-28T12:36:44.239538Z","iopub.status.idle":"2022-04-28T12:36:44.244074Z","shell.execute_reply.started":"2022-04-28T12:36:44.239511Z","shell.execute_reply":"2022-04-28T12:36:44.242981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import skimage.io\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom efficientnet_pytorch import model as enet\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:36:46.22778Z","iopub.execute_input":"2022-04-28T12:36:46.228503Z","iopub.status.idle":"2022-04-28T12:36:48.227062Z","shell.execute_reply.started":"2022-04-28T12:36:46.228464Z","shell.execute_reply":"2022-04-28T12:36:48.226264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/prostate-cancer-grade-assessment'\ndf_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ndf_sub = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n\nmodel_dir = '../input/panda-public-models'\nimage_folder = os.path.join(data_dir, 'test_images')\nis_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\nimage_folder = image_folder if is_test else os.path.join(data_dir, 'train_images')\n\ndf = df_test if is_test else df_train.loc[:10]\n\ntile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 8\nnum_workers = 4\n\ndevice = torch.device('cuda')\nprint(image_folder)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:36:54.650323Z","iopub.execute_input":"2022-04-28T12:36:54.650595Z","iopub.status.idle":"2022-04-28T12:36:54.700687Z","shell.execute_reply.started":"2022-04-28T12:36:54.650567Z","shell.execute_reply":"2022-04-28T12:36:54.699938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations\n\ntransforms_train = albumentations.Compose([\n    albumentations.Transpose(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    albumentations.HorizontalFlip(p=0.5),\n])\n\n\ntransforms_val = albumentations.Compose([])\n\ntransforms_val1 = albumentations.Compose([\n    albumentations.Transpose(p=1)\n])\n\ntransforms_val2 = albumentations.Compose([\n    albumentations.VerticalFlip(p=1)\n])\n\ntransforms_val3= albumentations.Compose([\n    albumentations.HorizontalFlip(p=1),\n])\n\ntransforms_val4= albumentations.Compose([\n    albumentations.Transpose(p=1),\n    albumentations.VerticalFlip(p=1),\n    albumentations.HorizontalFlip(p=1),\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:36:58.658033Z","iopub.execute_input":"2022-04-28T12:36:58.658365Z","iopub.status.idle":"2022-04-28T12:37:00.39077Z","shell.execute_reply.started":"2022-04-28T12:36:58.658329Z","shell.execute_reply":"2022-04-28T12:37:00.39005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tiles(img, mode=0):\n        result = []\n        h, w, c = img.shape\n        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n        img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n        img3 = img2.reshape(\n            img2.shape[0] // tile_size,\n            tile_size,\n            img2.shape[1] // tile_size,\n            tile_size,\n            3\n        )\n\n        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n        if len(img) < n_tiles:\n            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n        img3 = img3[idxs]\n        for i in range(len(img3)):\n            result.append({'img':img3[i], 'idx':i})\n        return result, n_tiles_with_info >= n_tiles\n\n\nclass PANDADataset(Dataset):\n    def __init__(self,\n                 df,\n                 image_size,\n                 n_tiles=n_tiles,\n                 tile_mode=0,\n                 rand=False,\n                 sub_imgs=False,\n                 transform=None\n                ):\n\n        self.df = df.reset_index(drop=True)\n        self.image_size = image_size\n        self.n_tiles = n_tiles\n        self.tile_mode = tile_mode\n        self.rand = rand\n        self.sub_imgs = sub_imgs\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img_id = row.image_id\n        \n        tiff_file = os.path.join(image_folder, f'{img_id}.tiff')\n        image = skimage.io.MultiImage(tiff_file)[-1]\n        tiles, OK = get_tiles(image, self.tile_mode)\n\n        if self.rand:\n            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n        else:\n            idxes = list(range(self.n_tiles))\n        idxes = np.asarray(idxes) + self.n_tiles if self.sub_imgs else idxes\n\n        n_row_tiles = int(np.sqrt(self.n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n    \n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                h1 = h * image_size\n                w1 = w * image_size\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n\n        if self.transform is not None:\n            images = self.transform(image=images)['image']\n            \n        images = images.astype(np.float32)\n        images /= 255\n        images = images.transpose(2, 0, 1)\n\n        return torch.tensor(images)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:38:32.300971Z","iopub.execute_input":"2022-04-28T12:38:32.301229Z","iopub.status.idle":"2022-04-28T12:38:32.323562Z","shell.execute_reply.started":"2022-04-28T12:38:32.301201Z","shell.execute_reply":"2022-04-28T12:38:32.322768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not is_test:\n    dataset_show = PANDADataset(df, image_size, n_tiles, 0)\n    from pylab import rcParams\n    rcParams['figure.figsize'] = 20,10\n    for i in range(2):\n        f, axarr = plt.subplots(1,5)\n        for p in range(5):\n            idx = np.random.randint(0, len(dataset_show))\n            img = dataset_show[idx]\n            axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n            axarr[p].set_title(str(idx))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:38:32.596274Z","iopub.execute_input":"2022-04-28T12:38:32.59688Z","iopub.status.idle":"2022-04-28T12:39:55.923716Z","shell.execute_reply.started":"2022-04-28T12:38:32.596819Z","shell.execute_reply":"2022-04-28T12:39:55.923079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val )  # mode == 0\nloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\ndataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val )  # mode == 2\nloader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\n\nLOGITS = []\nLOGITS2 = []\nLOGITS3 = []\nLOGITS4 = []\nwith torch.no_grad():\n    for data in tqdm(loader):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS.append(logits)\n        logits = models2[0](data)\n        LOGITS3.append(logits)\n        \n    for data in tqdm(loader2):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS2.append(logits)\n        logits = models2[0](data)\n        LOGITS4.append(logits)\n        \nLOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) / 4\nPREDS = LOGITS.sum(1).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:40:39.834459Z","iopub.execute_input":"2022-04-28T12:40:39.834711Z","iopub.status.idle":"2022-04-28T12:40:56.537246Z","shell.execute_reply.started":"2022-04-28T12:40:39.834683Z","shell.execute_reply":"2022-04-28T12:40:56.533829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/kaggle-efficientnet-repo/efficientnet-1.0.0-py3-none-any.whl\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport argparse\nimport os\nimport skimage.io\nfrom scipy.ndimage import measurements\nimport os\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras import layers as L\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.utils import to_categorical\nimport gc\nimport albumentations\ngc.enable()\n\n\n\nsz = 256\nN = 48\ndef tile(img):\n    result = []\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\ndef tile2(img):\n    result = []\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz + ((sz * 2) // 2), (sz - shape[1]%sz)%sz + ((sz * 2) // 2)\n    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = '../input/prostate-cancer-grade-assessment/train_images/'\nMASKS = '../input/prostate-cancer-grade-assessment/train_label_masks/'\nBASE_PATH = '../input/prostate-cancer-grade-assessment/'\ntrain = pd.read_csv(BASE_PATH + \"train.csv\")\ntrain.head()\n\nsub = pd.read_csv(\"../input/prostate-cancer-grade-assessment/sample_submission.csv\")\nsub.head()\n\ntest = pd.read_csv(\"../input/prostate-cancer-grade-assessment/test.csv\")\ntest.head()\n\nTEST = '../input/prostate-cancer-grade-assessment/test_images/'\n\n\nPRED_PATH = TEST \ndf = sub\nt_df = test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('../input/pandaenetb042x256x256x3/DenseNet121-48-full-epochs60.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions40 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image / 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions40.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions40 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image / 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions40.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions42 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image / 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions42.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions42 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image / 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions42.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n        \ndel model, dummy_data, sub, pred, train, isup, image\ndel patches1,patches2,patches3,patches4    \n\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PREDS = (1/5)*PREDS + (1/5)*PREDS1 + (1/5)*PREDS2 + (1/5)*PREDS3 + (1/5)*PREDS4\n\nFINAL = np.round( (6/10)*PREDS +\n                  (2/60)*np.array(predictions10) + (2/60)*np.array(predictions12) + \n                  (2/60)*np.array(predictions20) + (2/60)*np.array(predictions22) +\n                  (2/60)*np.array(predictions30) + (2/60)*np.array(predictions32) +\n                  (0.5/10)*np.array(predictions40) + (0.5/10)*np.array(predictions42) +\n                  (1/60)*np.array(predictions50) + (1/60)*np.array(predictions52) +\n                  (1/60)*np.array(predictions60) + (1/60)*np.array(predictions62) +\n                  (1/60)*np.array(predictions70) + (1/60)*np.array(predictions72) )\n\n\ndf['isup_grade'] = FINAL.astype(int)\ndf[['image_id', 'isup_grade']].to_csv('submission.csv', index=False)\nprint(df.head())\nprint()\nprint(df.isup_grade.value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:14:22.032145Z","iopub.execute_input":"2022-04-28T17:14:22.032409Z","iopub.status.idle":"2022-04-28T17:14:22.036038Z","shell.execute_reply.started":"2022-04-28T17:14:22.032381Z","shell.execute_reply":"2022-04-28T17:14:22.035167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_00 = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:08:49.184615Z","iopub.execute_input":"2022-04-28T17:08:49.185239Z","iopub.status.idle":"2022-04-28T17:08:49.197877Z","shell.execute_reply.started":"2022-04-28T17:08:49.185202Z","shell.execute_reply":"2022-04-28T17:08:49.197176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_00","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:08:56.673246Z","iopub.execute_input":"2022-04-28T17:08:56.67366Z","iopub.status.idle":"2022-04-28T17:08:56.692259Z","shell.execute_reply.started":"2022-04-28T17:08:56.673623Z","shell.execute_reply":"2022-04-28T17:08:56.691459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport math\nimport cv2\nimport PIL\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow_addons as tfa\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:14.058171Z","iopub.execute_input":"2022-04-29T12:25:14.058879Z","iopub.status.idle":"2022-04-29T12:25:21.48535Z","shell.execute_reply.started":"2022-04-29T12:25:14.058785Z","shell.execute_reply":"2022-04-29T12:25:21.484396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# There are two ways to load the data from the PANDA dataset:\n# Option 1: Load images using openslide\nimport openslide\n# Option 2: Load images using skimage (requires that tifffile is installed)\nimport skimage.io\n# General packages\nfrom IPython.display import display\n# Plotly for the interactive viewer (see last section)\nimport plotly.graph_objs as go\n# read images\nimport rasterio\n\nimport gc\nfrom random import randint\n\nimport cv2\nimport shutil\nimport glob\n\n\ndevice = tf.device('cuda')\ndevice\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:21.487309Z","iopub.execute_input":"2022-04-29T12:25:21.489183Z","iopub.status.idle":"2022-04-29T12:25:24.517412Z","shell.execute_reply.started":"2022-04-29T12:25:21.489111Z","shell.execute_reply":"2022-04-29T12:25:24.516396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nTRAIN_VAL_RATIO = 0.20\nEPOCHS = 5\nLR = 1e-1\nimage_size = 256\nn_classes = 6","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:24.519113Z","iopub.execute_input":"2022-04-29T12:25:24.519719Z","iopub.status.idle":"2022-04-29T12:25:24.525991Z","shell.execute_reply.started":"2022-04-29T12:25:24.519677Z","shell.execute_reply":"2022-04-29T12:25:24.524951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_FOLDER = \"../input/prostate-cancer-grade-assessment/\"","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:24.529017Z","iopub.execute_input":"2022-04-29T12:25:24.529798Z","iopub.status.idle":"2022-04-29T12:25:24.538784Z","shell.execute_reply.started":"2022-04-29T12:25:24.529739Z","shell.execute_reply":"2022-04-29T12:25:24.537497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1 = pd.read_csv(BASE_FOLDER + '/train.csv')\ntest_df = pd.read_csv(BASE_FOLDER + 'test.csv')\nprint(train_df1.shape)\nprint(test_df.shape)\ntrain_df1.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:24.54024Z","iopub.execute_input":"2022-04-29T12:25:24.541637Z","iopub.status.idle":"2022-04-29T12:25:24.595189Z","shell.execute_reply.started":"2022-04-29T12:25:24.541591Z","shell.execute_reply":"2022-04-29T12:25:24.594285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df1\nprint(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:24.596649Z","iopub.execute_input":"2022-04-29T12:25:24.598488Z","iopub.status.idle":"2022-04-29T12:25:24.61403Z","shell.execute_reply.started":"2022-04-29T12:25:24.598444Z","shell.execute_reply":"2022-04-29T12:25:24.613075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df.loc[8724,'isup_grade'] = 3","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:24.615324Z","iopub.execute_input":"2022-04-29T12:25:24.615813Z","iopub.status.idle":"2022-04-29T12:25:24.621196Z","shell.execute_reply.started":"2022-04-29T12:25:24.615769Z","shell.execute_reply":"2022-04-29T12:25:24.620021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['gleason_score'] = train_df['gleason_score'].apply(lambda x: '0+0' if x == 'negative' else x)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:24.623032Z","iopub.execute_input":"2022-04-29T12:25:24.623626Z","iopub.status.idle":"2022-04-29T12:25:24.637159Z","shell.execute_reply.started":"2022-04-29T12:25:24.623577Z","shell.execute_reply":"2022-04-29T12:25:24.635796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 0\nskf = StratifiedKFold(5, shuffle=True, random_state=42)\ntrain_df['fold'] = -1\nfor i, (train_idx, test_idx) in enumerate(skf.split(train_df, train_df['isup_grade'])):\n    train_df.loc[test_idx, 'fold'] = i\ntrain_df.head()\n\ntrain_idx = np.where((train_df['fold'] != fold))[0]\ntest_idx = np.where((train_df['fold'] == fold))[0]\n\ndf_train  = train_df.loc[train_idx]\ndf_test = train_df.loc[test_idx]","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:28.093259Z","iopub.execute_input":"2022-04-29T12:25:28.093587Z","iopub.status.idle":"2022-04-29T12:25:28.118454Z","shell.execute_reply.started":"2022-04-29T12:25:28.093554Z","shell.execute_reply":"2022-04-29T12:25:28.117554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train_validate_test_split(df, train_percent=.8, seed=None):\n#     np.random.seed(seed)\n#     perm = np.random.permutation(df.index)\n#     m = len(df.index)\n#     train_end = int(train_percent * m)\n#     train = df.iloc[perm[:train_end]]\n#     test = df.iloc[perm[train_end:]]\n#     return train, test\n\n# df_train, df_test = train_validate_test_split(train_df)dd","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:29.824628Z","iopub.execute_input":"2022-04-29T12:25:29.824907Z","iopub.status.idle":"2022-04-29T12:25:29.829301Z","shell.execute_reply.started":"2022-04-29T12:25:29.824877Z","shell.execute_reply":"2022-04-29T12:25:29.828327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(image_path, desired_size=image_size):\n    biopsy = openslide.OpenSlide(image_path)\n    im = np.array(biopsy.get_thumbnail(size=(desired_size,desired_size)))\n    im = Image.fromarray(im)\n    im = im.resize((desired_size,desired_size)) \n    im = np.array(im)\n    return im","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:30.529902Z","iopub.execute_input":"2022-04-29T12:25:30.530199Z","iopub.status.idle":"2022-04-29T12:25:30.536781Z","shell.execute_reply.started":"2022-04-29T12:25:30.530167Z","shell.execute_reply":"2022-04-29T12:25:30.535498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_folder(df):\n    save_mask_dir = '/kaggle/pc_detection/test_data/'\n    os.makedirs(save_mask_dir, exist_ok=True)\n    for i, img_id in tqdm(enumerate(df.image_id)):\n        src_dir = \"../input/panda-16x128x128-tiles-data/train\"\n        dst_dir = save_mask_dir\n        for jpgfile in glob.iglob(os.path.join(src_dir, img_id+\".tiff\")):\n            shutil.copy(jpgfile, dst_dir)\n    print(dst_dir)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:32.244503Z","iopub.execute_input":"2022-04-29T12:25:32.244796Z","iopub.status.idle":"2022-04-29T12:25:32.252012Z","shell.execute_reply.started":"2022-04-29T12:25:32.244767Z","shell.execute_reply":"2022-04-29T12:25:32.250566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = save_folder(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:32.797227Z","iopub.execute_input":"2022-04-29T12:25:32.797856Z","iopub.status.idle":"2022-04-29T12:25:33.803451Z","shell.execute_reply.started":"2022-04-29T12:25:32.797804Z","shell.execute_reply":"2022-04-29T12:25:33.802443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the number of training images from the target\\id dataset\nN = df_train.shape[0]\n# create an empty matrix for storing the images\nx_train = np.empty((N, image_size, image_size, 3), dtype=np.uint8)\n# loop through the images from the images ids from the target\\id dataset\n# then grab the cooresponding image from disk, pre-process, and store in matrix in memory\nfor i, image_id in enumerate(tqdm(df_train['image_id'])):\n    x_train[i, :, :, :] = preprocess_image(\n        f'../input/panda-16x128x128-tiles-data/train/{image_id}.tiff'\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:25:39.257282Z","iopub.execute_input":"2022-04-29T12:25:39.257943Z","iopub.status.idle":"2022-04-29T12:25:39.652193Z","shell.execute_reply.started":"2022-04-29T12:25:39.257905Z","shell.execute_reply":"2022-04-29T12:25:39.649908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.exists('/kaggle/pc_detection/test_data/'):\n    # do the same thing as the last cell but on the test\\holdout set\n    N = df_test.shape[0]\n    x_test = np.empty((N, image_size, image_size, 3), dtype=np.uint8)\n    for i, image_id in enumerate(tqdm(df_test['image_id'])):\n        x_test[i, :, :, :] = preprocess_image(\n            f'/kaggle/pc_detection/test_data/{image_id}.tiff'\n        )\n        \nelse:\n    print(\"test images not found\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:00:14.856824Z","iopub.execute_input":"2022-04-29T12:00:14.857099Z","iopub.status.idle":"2022-04-29T12:03:02.603319Z","shell.execute_reply.started":"2022-04-29T12:00:14.857069Z","shell.execute_reply":"2022-04-29T12:03:02.602098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pre-processing the target (i.e. one-hot encoding the target)\ny_train = pd.get_dummies(df_train['isup_grade']).values\ny_train.to(device)\nprint(x_train.shape)\nprint(y_train.shape)\nif os.path.exists('/kaggle/pc_detection/test_data/'):\n    print(x_test.shape)\nelse:\n    print(\"test images not found\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:58:27.430996Z","iopub.execute_input":"2022-04-29T11:58:27.431194Z","iopub.status.idle":"2022-04-29T11:58:27.45682Z","shell.execute_reply.started":"2022-04-29T11:58:27.43117Z","shell.execute_reply":"2022-04-29T11:58:27.455918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_multi = np.empty(y_train.shape, dtype=y_train.dtype)\ny_train_multi[:, 5] = y_train[:, 5]\n\n\nfor i in range(4, -1, -1):\n    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i+1])\n    y_train_multi.to(device)\n# print(\"Original y_train:\", y_train.sum(axis=0))\n# print(\"Multilabel version:\", y_train_multi.sum(axis=0))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:00:51.306173Z","iopub.execute_input":"2022-04-29T10:00:51.306855Z","iopub.status.idle":"2022-04-29T10:00:51.313606Z","shell.execute_reply.started":"2022-04-29T10:00:51.306818Z","shell.execute_reply":"2022-04-29T10:00:51.312963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train_multi, \n    test_size=TRAIN_VAL_RATIO, \n    random_state=2020\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:00:51.31507Z","iopub.execute_input":"2022-04-29T10:00:51.315388Z","iopub.status.idle":"2022-04-29T10:00:52.958747Z","shell.execute_reply.started":"2022-04-29T10:00:51.315354Z","shell.execute_reply":"2022-04-29T10:00:52.957987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.15,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n    )\n\n# Using original generator\ndata_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2019)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:00:52.960068Z","iopub.execute_input":"2022-04-29T10:00:52.960302Z","iopub.status.idle":"2022-04-29T10:00:57.174935Z","shell.execute_reply.started":"2022-04-29T10:00:52.960271Z","shell.execute_reply":"2022-04-29T10:00:57.174128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"densenet = DenseNet121(\n    weights='../input/input/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(image_size,image_size,3)\n)\n\ndensenet.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:00:57.176108Z","iopub.execute_input":"2022-04-29T10:00:57.176361Z","iopub.status.idle":"2022-04-29T10:01:03.244932Z","shell.execute_reply.started":"2022-04-29T10:00:57.176328Z","shell.execute_reply":"2022-04-29T10:01:03.244207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(LR=LR):\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.80))\n    model.add(layers.Dense(6, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=LR),\n        metrics=['accuracy',tfa.metrics.CohenKappa(num_classes=n_classes,weightage='quadratic')]\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:01:03.246028Z","iopub.execute_input":"2022-04-29T10:01:03.246262Z","iopub.status.idle":"2022-04-29T10:01:03.255078Z","shell.execute_reply.started":"2022-04-29T10:01:03.24623Z","shell.execute_reply":"2022-04-29T10:01:03.2526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.to(device)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:01:03.257984Z","iopub.execute_input":"2022-04-29T10:01:03.258434Z","iopub.status.idle":"2022-04-29T10:01:04.056633Z","shell.execute_reply.started":"2022-04-29T10:01:03.258399Z","shell.execute_reply":"2022-04-29T10:01:04.055192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    data_generator,\n    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=(x_val, y_val)\n)\nhistory.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:01:04.058815Z","iopub.execute_input":"2022-04-29T10:01:04.059313Z","iopub.status.idle":"2022-04-29T10:10:46.796272Z","shell.execute_reply.started":"2022-04-29T10:01:04.059268Z","shell.execute_reply":"2022-04-29T10:10:46.795533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['accuracy', 'val_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:16:07.609143Z","iopub.execute_input":"2022-04-29T10:16:07.609984Z","iopub.status.idle":"2022-04-29T10:16:08.068633Z","shell.execute_reply.started":"2022-04-29T10:16:07.609904Z","shell.execute_reply":"2022-04-29T10:16:08.067895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = df_test.isup_grade.values\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:16:38.268716Z","iopub.execute_input":"2022-04-29T10:16:38.269003Z","iopub.status.idle":"2022-04-29T10:16:38.281651Z","shell.execute_reply.started":"2022-04-29T10:16:38.268971Z","shell.execute_reply":"2022-04-29T10:16:38.280942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import randint\n\ntest_img_path = '/kaggle/pc_detection/test_data/'\n\nif os.path.exists(test_img_path):\n    y_test = model.predict(x_test)\n    y_test = y_test > 0.37757874193797547\n    y_test = y_test.astype(int).sum(axis=1) - 1\nelse:\n    n = len(df_test)\n    y_test = [randint(0, 5) for i in range(n)]\n\ndf_test['isup_grade_1'] = y_test\ndf_test = df_test[[\"image_id\", \"isup_grade\", \"isup_grade_1\"]]\ndf_test.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:16:45.414724Z","iopub.execute_input":"2022-04-29T10:16:45.415591Z","iopub.status.idle":"2022-04-29T10:16:52.025988Z","shell.execute_reply.started":"2022-04-29T10:16:45.415538Z","shell.execute_reply":"2022-04-29T10:16:52.024979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_true, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:16:52.029656Z","iopub.execute_input":"2022-04-29T10:16:52.029884Z","iopub.status.idle":"2022-04-29T10:16:52.042648Z","shell.execute_reply.started":"2022-04-29T10:16:52.029856Z","shell.execute_reply":"2022-04-29T10:16:52.041854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cohen_kappa_score(y_true, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:17:06.993116Z","iopub.execute_input":"2022-04-29T10:17:06.993697Z","iopub.status.idle":"2022-04-29T10:17:07.001461Z","shell.execute_reply.started":"2022-04-29T10:17:06.993662Z","shell.execute_reply":"2022-04-29T10:17:07.0005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:16:52.043991Z","iopub.execute_input":"2022-04-29T10:16:52.044733Z","iopub.status.idle":"2022-04-29T10:16:52.057787Z","shell.execute_reply.started":"2022-04-29T10:16:52.044676Z","shell.execute_reply":"2022-04-29T10:16:52.056919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/pc_detection/test_data/'))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:22:56.741797Z","iopub.execute_input":"2022-04-29T09:22:56.742145Z","iopub.status.idle":"2022-04-29T09:22:56.746222Z","shell.execute_reply.started":"2022-04-29T09:22:56.742107Z","shell.execute_reply":"2022-04-29T09:22:56.745586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nremoving_files = glob.glob('/kaggle/pc_detection/test_data/*.tiff')\nfor i in removing_files:\n    os.remove(i)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T12:26:02.306974Z","iopub.execute_input":"2022-04-29T12:26:02.307498Z","iopub.status.idle":"2022-04-29T12:26:02.334722Z","shell.execute_reply.started":"2022-04-29T12:26:02.307441Z","shell.execute_reply":"2022-04-29T12:26:02.333377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath = 'kagle/Denset/Dmodel/my_model.h5'\nmodel.save(filepath)\nnew_model = tf.keras.models.load_model(filepath)\nnew_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}