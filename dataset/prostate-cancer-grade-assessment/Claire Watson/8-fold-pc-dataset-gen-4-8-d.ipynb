{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install tensorflow==2.3.0","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:43.798298Z","iopub.execute_input":"2022-03-01T16:18:43.798876Z","iopub.status.idle":"2022-03-01T16:18:47.656047Z","shell.execute_reply.started":"2022-03-01T16:18:43.79884Z","shell.execute_reply":"2022-03-01T16:18:47.655116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basics / Data manipulation\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport os\n\n# Visualization\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport skimage.io\nfrom IPython.display import display, HTML\n\n# ML\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:47.658192Z","iopub.execute_input":"2022-03-01T16:18:47.658498Z","iopub.status.idle":"2022-03-01T16:18:48.464534Z","shell.execute_reply.started":"2022-03-01T16:18:47.658463Z","shell.execute_reply":"2022-03-01T16:18:48.462057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Folder paths\nTRAIN = '../input/prostate-cancer-grade-assessment/train_images'\nMASKS = '../input/prostate-cancer-grade-assessment/train_label_masks'\n\nOUT_TRAIN = './trainD.zip'\nOUT_VALIDATION = './validationD.zip'\nOUT_TEST = './testD.zip'\nOUT_MASKS_TRAIN = './masks_trainD.zip'\nOUT_MASKS_VALIDATION = './masks_validationD.zip'\nOUT_MASKS_TEST = './masks_testD.zip'\n\nBASE_FOLDER = \"/kaggle/input/prostate-cancer-grade-assessment/\"\n!ls {BASE_FOLDER}\nBASE_FOLDER2 =\"/kaggle/input/panda-tiles/\"\n!ls {BASE_FOLDER2}","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.465596Z","iopub.status.idle":"2022-03-01T16:18:48.465992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv(\"../input/8-fold-pc-dataset-gen-0-8/training.csv\", usecols=[\"image_id\", \"data_provider\", \"isup_grade\", \"gleason_score\"])\nvalidation_dataset = pd.read_csv(\"../input/8-fold-pc-dataset-gen-0-8/validation.csv\", usecols=[\"image_id\", \"data_provider\", \"isup_grade\", \"gleason_score\"])\ntest_dataset = pd.read_csv(\"../input/8-fold-pc-dataset-gen-0-8/testing.csv\", usecols=[\"image_id\", \"data_provider\", \"isup_grade\", \"gleason_score\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.467146Z","iopub.status.idle":"2022-03-01T16:18:48.467691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_IDs = train_dataset[\"image_id\"]\nvalidation_IDs = validation_dataset[\"image_id\"]\ntest_IDs = test_dataset[\"image_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.469073Z","iopub.status.idle":"2022-03-01T16:18:48.469517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_found_train = []\nnot_found_validation = []\nnot_found_test = []","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.47067Z","iopub.status.idle":"2022-03-01T16:18:48.47104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE_IMG = 112\nN = 16\ndef tile(img, mask):\n    result = []\n    shape = img.shape\n    pad0,pad1 = (SIZE_IMG - shape[0]%SIZE_IMG)%SIZE_IMG, (SIZE_IMG - shape[1]%SIZE_IMG)%SIZE_IMG\n    img = np.pad(img, [[pad0//2, pad0-pad0//2], [pad1//2, pad1 - pad1//2],[0,0]],\n                constant_values=255)\n    mask = np.pad(mask,[[pad0//2, pad0-pad0//2], [pad1//2,pad1-pad1//2], [0,0]],\n                constant_values=0)\n    img = img.reshape(img.shape[0]//SIZE_IMG, SIZE_IMG, img.shape[1]//SIZE_IMG,SIZE_IMG, 3)\n    img = img.transpose(0, 2, 1, 3, 4).reshape(-1, SIZE_IMG,SIZE_IMG,3)\n    mask = mask.reshape(mask.shape[0]//SIZE_IMG, SIZE_IMG,mask.shape[1]//SIZE_IMG, SIZE_IMG, 3)\n    mask = mask.transpose(0, 2, 1, 3, 4).reshape(-1, SIZE_IMG,SIZE_IMG, 3)\n    if len(img) < N:\n        mask = np.pad(mask, [[0, N-len(img)], [0, 0], [0, 0],[0, 0]], constant_values=0)\n        img = np.pad(img, [[0, N-len(img)],[0, 0],[0, 0], [0, 0]], constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0], -1).sum(-1))[: N]\n    img = img[idxs]\n    mask = mask[idxs]\n    \n    for i in range(len(img)):\n        result.append({'img':img[i], 'mask':mask[i], 'idx':i})\n\n    return result","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-01T16:18:48.471959Z","iopub.status.idle":"2022-03-01T16:18:48.472358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multiplyTiles(tiles):\n#     variationA = []\n#     variationB = []\n#     variationC = []\n      variationD = []\n#     variationE = []\n#     variationF = []\n#     variationG = []\n#     variationH = []\n    for t in range(len(tiles)):\n        \n        # Original Tile (A)\n        tile_a_img = tiles[t]['img']\n        tile_a_mask = tiles[t]['mask']\n        tile_a_idx = tiles[t]['idx']\n        tile_a = {\"img\": tile_a_img, \"mask\": tile_a_mask, \"idx\": tile_a_idx}\n        \n#         # Rotated Tiles (B, C, D)\n#         tile_b_img = np.rot90(tile_a_img)\n#         tile_b_mask = np.rot90(tile_a_mask)\n#         tile_b_idx = tile_a_idx\n#         tile_b = {\"img\": tile_b_img, \"mask\": tile_b_mask, \"idx\": tile_b_idx}\n        \n#         tile_c_img = np.rot90(np.rot90(tile_a_img))\n#         tile_c_mask = np.rot90(np.rot90(tile_a_mask))\n#         tile_c_idx = tile_a_idx\n#         tile_c = {\"img\": tile_c_img, \"mask\": tile_c_mask, \"idx\": tile_c_idx}\n        \n        tile_d_img = np.rot90(np.rot90(np.rot90(tile_a_img)))\n        tile_d_mask = np.rot90(np.rot90(np.rot90(tile_a_mask)))\n        tile_d_idx = tile_a_idx\n        tile_d = {\"img\": tile_d_img, \"mask\": tile_d_mask, \"idx\": tile_d_idx}\n        \n#         # Mirrored Original Tile (A:E)\n#         tile_e_img = np.fliplr(tile_a_img)\n#         tile_e_mask = np.fliplr(tile_a_mask)\n#         tile_e_idx = tile_a_idx\n#         tile_e = {\"img\": tile_e_img, \"mask\": tile_e_mask, \"idx\": tile_e_idx}        \n        \n#         # Mirrored Rotated Tiles (B:F, C:G, D:H)\n#         tile_f_img = np.fliplr(np.rot90(tile_a_img))\n#         tile_f_mask = np.fliplr(np.rot90(tile_a_mask))\n#         tile_f_idx = tile_a_idx\n#         tile_f = {\"img\": tile_f_img, \"mask\": tile_f_mask, \"idx\": tile_f_idx}\n        \n#         tile_g_img = np.fliplr(np.rot90(np.rot90(tile_a_img)))\n#         tile_g_mask = np.fliplr(np.rot90(np.rot90(tile_a_mask)))\n#         tile_g_idx = tile_a_idx\n#         tile_g = {\"img\": tile_g_img, \"mask\": tile_g_mask, \"idx\": tile_g_idx}\n        \n#         tile_h_img = np.fliplr(np.rot90(np.rot90(np.rot90(tile_a_img))))\n#         tile_h_mask = np.fliplr(np.rot90(np.rot90(np.rot90(tile_a_mask))))\n#         tile_h_idx = tile_a_idx\n#         tile_h = {\"img\": tile_h_img, \"mask\": tile_h_mask, \"idx\": tile_h_idx}        \n        \n        \n#         variationA.append(tile_a)\n#         variationB.append(tile_b)\n#         variationC.append(tile_c)\n        variationD.append(tile_d)\n#         variationE.append(tile_e)\n#         variationF.append(tile_f)\n#         variationG.append(tile_g)\n#         variationH.append(tile_h)\n        \n#        tile_set = [variationA, variationB, variationC, variationD, variationE, variationF, variationG, variationH]\n        tile_set = [variationD]\n\n    return tile_set","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.473549Z","iopub.status.idle":"2022-03-01T16:18:48.47393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concat_tile(im_list_2d):\n    return cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in im_list_2d])\n\ndef mosaic(tiles):\n\n    im1 = tiles[0][\"img\"]\n    im2 = tiles[1][\"img\"]\n    im3 = tiles[2][\"img\"]\n    im4 = tiles[3][\"img\"]\n\n    im5 = tiles[4][\"img\"]\n    im6 = tiles[5][\"img\"]\n    im7 = tiles[6][\"img\"]\n    im8 = tiles[7][\"img\"]\n\n    im9 = tiles[8][\"img\"]\n    im10 = tiles[9][\"img\"]\n    im11 = tiles[10][\"img\"]\n    im12 = tiles[11][\"img\"]\n\n    im13 = tiles[12][\"img\"]\n    im14 = tiles[13][\"img\"]\n    im15 = tiles[14][\"img\"]\n    im16 = tiles[15][\"img\"]\n\n    im_tile = concat_tile([[im1, im2, im3, im4],\n                           [im5, im6, im7, im8],\n                           [im9, im10, im11, im12],\n                           [im13, im14, im15, im16]])\n    return im_tile\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.474962Z","iopub.status.idle":"2022-03-01T16:18:48.475377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_dataset(ids, dataset_type):\n    if dataset_type == \"train\":\n        x_tot,x2_tot = [], []\n        with zipfile.ZipFile(OUT_TRAIN, 'w') as img_out,\\\n         zipfile.ZipFile(OUT_MASKS_TRAIN, 'w') as mask_out:\n            for gleason_score, id in enumerate(tqdm(ids)):\n                try:\n                    img = skimage.io.MultiImage(os.path.join(TRAIN,id+'.tiff'))[1]\n                    mask = skimage.io.MultiImage(os.path.join(MASKS,id+'_mask.tiff'))[1]\n                    tiles = tile(img,mask)\n\n                    #[tiles_A, tiles_B, tiles_C, tiles_D, tiles_E, tiles_F, tiles_G, tiles_H] = multiplyTiles(tiles)\n                    [tiles_D] = multiplyTiles(tiles)\n\n                    #tiles_D:    \n                    img = mosaic(tiles_D)\n                    x_tot.append((img/255.0).reshape(-1,3).mean(0))\n                    x2_tot.append(((img/255.0)**2).reshape(-1,3).mean(0))\n                    # If read with PIL RGB turns into BGR\n                    img = cv2.imencode('.png',cv2.cvtColor(img, cv2.COLOR_RGB2BGR))[1]\n                    # Uncomment to classify by ISUP GRADE \n                    # img_out.writestr(f'train/ISUP_GRADE_{train_dataset[\"isup_grade\"][isup_grade]}/{id}_{idx}.png', img)\n                    img_out.writestr(f'train/GLEASON_SCORE_{train_dataset[\"gleason_score\"][gleason_score]}/{id}-variationD.png', img)\n\n                except Exception as e:\n                    not_found_train.append(id)\n        print(f\"INFO: Not images found in train: {len(not_found_train)}\")\n        \n    elif dataset_type == \"valid\": \n        x_tot,x2_tot = [], []\n        with zipfile.ZipFile(OUT_VALIDATION, 'w') as img_out,\\\n         zipfile.ZipFile(OUT_MASKS_VALIDATION, 'w') as mask_out:\n            for gleason_score, id in enumerate(tqdm(ids)):\n                try:\n                    img = skimage.io.MultiImage(os.path.join(TRAIN,id+'.tiff'))[1]\n                    mask = skimage.io.MultiImage(os.path.join(MASKS,id+'_mask.tiff'))[1]\n                    tiles = tile(img,mask)\n                    img = mosaic(tiles)\n                    \n                    #[tiles_A, tiles_B, tiles_C, tiles_D, tiles_E, tiles_F, tiles_G, tiles_H] = multiplyTiles(tiles)\n                    [tiles_D] = multiplyTiles(tiles)\n                    \n                    #tiles_D:    \n                    img = mosaic(tiles_D)\n                    x_tot.append((img/255.0).reshape(-1,3).mean(0))\n                    x2_tot.append(((img/255.0)**2).reshape(-1,3).mean(0)) \n                    # If read with PIL RGB turns into BGR\n                    img = cv2.imencode('.png',cv2.cvtColor(img, cv2.COLOR_RGB2BGR))[1]\n                    # Uncomment to classify by ISUP GRADE \n                    # img_out.writestr(f'test/ISUP_GRADE_{train_dataset[\"isup_grade\"][isup_grade]}/{id}_{idx}.png', img)\n                    img_out.writestr(f'validation/GLEASON_SCORE_{validation_dataset[\"gleason_score\"][gleason_score]}/{id}-variationD.png', img)\n                    \n                except Exception as e:\n                    not_found_validation.append(id)\n\n        print(f\"INFO: Not images found in validation: {len(not_found_validation)}\")\n        \n    elif dataset_type == \"test\":  \n        x_tot,x2_tot = [], []\n        with zipfile.ZipFile(OUT_TEST, 'w') as img_out,\\\n         zipfile.ZipFile(OUT_MASKS_TEST, 'w') as mask_out:\n            for gleason_score, id in enumerate(tqdm(ids)):\n                try:\n                    img = skimage.io.MultiImage(os.path.join(TRAIN,id+'.tiff'))[1]\n                    mask = skimage.io.MultiImage(os.path.join(MASKS,id+'_mask.tiff'))[1]\n\n                    #[tiles_A, tiles_B, tiles_C, tiles_D, tiles_E, tiles_F, tiles_G, tiles_H] = multiplyTiles(tiles)\n                    [tiles_D] = multiplyTiles(tiles)\n\n                    #tiles_D:\n                    img = mosaic(tiles_D)\n                    x_tot.append((img/255.0).reshape(-1,3).mean(0))\n                    x2_tot.append(((img/255.0)**2).reshape(-1,3).mean(0)) \n                    # If read with PIL RGB turns into BGR\n                    img = cv2.imencode('.png',cv2.cvtColor(img, cv2.COLOR_RGB2BGR))[1]\n                    # Uncomment to classify by ISUP GRADE \n                    # img_out.writestr(f'test/ISUP_GRADE_{train_dataset[\"isup_grade\"][isup_grade]}/{id}_{idx}.png', img)\n                    img_out.writestr(f'test/GLEASON_SCORE_{test_dataset[\"gleason_score\"][gleason_score]}/{id}-variationD.png', img)\n\n                except Exception as e:\n                    not_found_test.append(id)\n\n        print(f\"INFO: Not images found in test: {len(not_found_test)}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.476655Z","iopub.status.idle":"2022-03-01T16:18:48.477013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_dataset(train_IDs, dataset_type='train')\ngenerate_dataset(validation_IDs, dataset_type='valid')\ngenerate_dataset(test_IDs, dataset_type='test')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-01T16:18:48.478065Z","iopub.status.idle":"2022-03-01T16:18:48.478474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Removing Lost/Corrupted Data","metadata":{}},{"cell_type":"code","source":"nf = open(\"not_found_train.txt\", \"w\")\nfor each in not_found_train:\n    nf.write(each)\n    nf.write(\"\\n\")\nnf.close()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.479549Z","iopub.status.idle":"2022-03-01T16:18:48.479934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nf = open(\"not_found_validation.txt\", \"w\")\nfor each in not_found_validation:\n    nf.write(each)\n    nf.write(\"\\n\")\nnf.close()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.481001Z","iopub.status.idle":"2022-03-01T16:18:48.481412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nf = open(\"not_found_test.txt\", \"w\")\nfor each in not_found_test:\n    nf.write(each)\n    nf.write(\"\\n\")\nnf.close()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:18:48.482438Z","iopub.status.idle":"2022-03-01T16:18:48.4828Z"},"trusted":true},"execution_count":null,"outputs":[]}]}