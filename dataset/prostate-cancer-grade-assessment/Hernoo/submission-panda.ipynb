{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nclass QuadraticWeightedKappa(tf.keras.metrics.Metric):\n    def __init__(self, maxClassesCount=6, name='Kappa', **kwargs):        \n        super(QuadraticWeightedKappa, self).__init__(name=name, **kwargs)\n        self.M = maxClassesCount\n\n        self.O = self.add_weight(name='O', initializer='zeros',shape=(self.M,self.M,), dtype=tf.int64)\n        self.W = self.add_weight(name='W', initializer='zeros',shape=(self.M,self.M,), dtype=tf.float32)\n        self.actualHist = self.add_weight(name='actHist', initializer='zeros',shape=(self.M,), dtype=tf.int64)\n        self.predictedHist = self.add_weight(name='predHist', initializer='zeros',shape=(self.M,), dtype=tf.int64)\n        \n        # filling up the content of W once\n        w = np.zeros((self.M,self.M),dtype=np.float32)\n        for i in range(0,self.M):\n            for j in range(0,self.M):\n                w[i,j] = (i-j)*(i-j) / ((self.M - 1)*(self.M - 1))\n        self.W.assign(w)\n    \n    def reset_states(self):\n        \n        #Resets all of the metric state variables.\n        #This function is called between epochs/steps,\n        #when a metric is evaluated during training.\n        \n        \n        # value should be a Numpy array\n        zeros1D = np.zeros(self.M)\n        zeros2D = np.zeros((self.M,self.M))\n        tf.keras.backend.batch_set_value([\n            (self.O, zeros2D),\n            (self.actualHist, zeros1D),\n            (self.predictedHist,zeros1D)\n        ])\n\n\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # shape is: Batch x 1\n        y_true = tf.reshape(y_true, [-1])\n        y_pred = tf.reshape(y_pred, [-1])\n\n        y_true_int = tf.cast(tf.math.round(y_true), dtype=tf.int64)\n        y_pred_int = tf.cast(tf.math.round(y_pred), dtype=tf.int64)\n\n        confM = tf.math.confusion_matrix(y_true_int, y_pred_int, dtype=tf.int64, num_classes=self.M)\n\n        # incremeting confusion matrix and standalone histograms\n        self.O.assign_add(confM)\n\n        cur_act_hist = tf.math.reduce_sum(confM, 0)\n        self.actualHist.assign_add(cur_act_hist)\n\n        cur_pred_hist = tf.math.reduce_sum(confM, 1)\n        self.predictedHist.assign_add(cur_pred_hist)\n\n    def result(self):\n        EFloat = tf.cast(tf.tensordot(self.actualHist,self.predictedHist, axes=0),dtype=tf.float32)\n        OFloat = tf.cast(self.O,dtype=tf.float32)\n        \n        # E must be normalized \"such that E and O have the same sum\"\n        ENormalizedFloat = EFloat / tf.math.reduce_sum(EFloat) * tf.math.reduce_sum(OFloat)\n\n        \n        return 1.0 - tf.math.reduce_sum(tf.math.multiply(self.W, OFloat))/tf.math.reduce_sum(tf.multiply(self.W, ENormalizedFloat))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tensorflow import keras\ntf.compat.v1.disable_eager_execution()\nmodel = keras.models.load_model('../input/panda-resnet50/resnet50/',custom_objects={'QuadraticWeightedKappa':QuadraticWeightedKappa})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport os\nimport cv2\nimport PIL\nimport random\nimport openslide\nimport skimage.io\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nfrom os import walk\nimport random\nfrom random import randrange\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"height = 512\nwidth = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"%load_ext line_profiler\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Functions\n## to get the % of different colors \ndef compute_statistics(image):\n    \n    #Args:\n    #    image                  numpy.array   multi-dimensional array of the form WxHxC\n    #\n    #Returns:\n    #    ratio_white_pixels     float         ratio of white pixels over total pixels in the image \n    \n    width, height = image.shape[0], image.shape[1]\n    num_pixels = width * height\n    \n    num_white_pixels = 0\n    \n    summed_matrix = np.sum(image, axis=-1)\n    # Note: A 3-channel white pixel has RGB (255, 255, 255)\n    num_white_pixels = np.count_nonzero((summed_matrix > 620)) #avoid too white and/or too blank\n    \n    ratio_white_pixels = num_white_pixels / num_pixels\n    \n    green_concentration = np.mean(image[1])\n    blue_concentration = np.mean(image[2])\n#     red_median = np.percentile(image[0],50)\n#     green_median = np.percentile(image[1],50)\n#     blue_median = np.percentile(image[2],50)\n#     return ratio_white_pixels, green_concentration, blue_concentration, red_median, green_median, blue_median\n    return ratio_white_pixels, green_concentration, blue_concentration\n#selection of the k-best regions\ndef select_k_best_regions(regions, k=20):\n    \n    #Args:\n    #    regions               list           list of 2-component tuples first component the region, \n    #                                         second component the ratio of white pixels\n    #                                         \n    #    k                     int            number of regions to select\n    \n    red_penalty=0\n    #regions = [x for x in regions if ((x[3] > 180 and x[4] > 180) and (((x[5]-red_penalty)>x[6]) or ((x[5]-red_penalty)>x[7])))] # x[3] is green concentration and 4 is blue \n    regions = [x for x in regions if (x[3] > 180 and x[4] > 180)] # x[3] is green concentration and 4 is blue \n    k_best_regions = sorted(regions, key=lambda tup: tup[2])[:k]\n    return k_best_regions\n#to retrieve from the top left pixel the full region\n\ndef get_k_best_regions(coordinates, image, window_size=512):\n    regions = {}\n    for i, tup in enumerate(coordinates):\n        x, y = tup[0], tup[1]\n        regions[i] = image[x : x+window_size, y : y+window_size, :]\n    \n    return regions\n\n#the slider\ndef generate_patches(slide_path, window_size=200, stride=128, k=20):\n    \n    image = np.array(skimage.io.MultiImage(slide_path)[-2])\n#     image = image\n    \n    max_width, max_height = image.shape[0], image.shape[1]\n    regions_container = []\n    i = 0\n    \n    while window_size + stride*i <= max_height:\n        j = 0\n        \n        while window_size + stride*j <= max_width:            \n            x_top_left_pixel = j * stride\n            y_top_left_pixel = i * stride\n            \n            patch = image[\n                x_top_left_pixel : x_top_left_pixel + window_size,\n                y_top_left_pixel : y_top_left_pixel + window_size,\n                :\n            ]\n            \n            ratio_white_pixels, green_concentration, blue_concentration = compute_statistics(patch)\n            \n            region_tuple = (x_top_left_pixel, y_top_left_pixel, ratio_white_pixels, green_concentration, blue_concentration)\n            regions_container.append(region_tuple)\n            #print(f' DEBUG : rmed :{red_median} gmed :{green_median} bmed : {blue_median}')\n            j += 1\n        \n        i += 1\n    \n    k_best_region_coordinates = select_k_best_regions(regions_container, k=k)\n    k_best_regions = get_k_best_regions(k_best_region_coordinates, image, window_size)\n    \n    return image, k_best_region_coordinates, k_best_regions\n\n\n#showing results \ndef display_images(regions, title):\n    fig, ax = plt.subplots(5, 4, figsize=(15, 15))\n    \n    for i, region in regions.items():\n        ax[i//4, i%4].imshow(region)\n    \n    fig.suptitle(title)\n    \n## glue to a unique picture\ndef glue_to_one_picture(image_patches, window_size=200, k=16):\n    side = int(np.sqrt(k))\n    image = np.zeros((side*window_size, side*window_size, 3), dtype=np.int16)\n        \n    for i, patch in image_patches.items():\n        x = i // side\n        y = i % side\n        image[\n            x * window_size : (x+1) * window_size,\n            y * window_size : (y+1) * window_size,\n            :\n        ] = patch\n    \n    return image\ndef _parse_function(filename, label, h=height, w=width, rotating=True): \n    image = tf.io.read_file(filename) #reading the image in the memory\n    #image = tfio.experimental.image.decode_tiff(image, index=0, name=None) # tiff to numpy 1/2\n    image = tf.io.decode_png(image,dtype=tf.dtypes.uint8, name=None)\n    if rotating==True :\n        sh=tf.shape(tf.io.read_file(filename))\n        print(f\"{sh}\")\n        width, height = image.shape[0],image.shape[1]\n        print(f\"w={width}, h={height}\")\n        image = tf.image.convert_image_dtype(image, tf.float32) # converting it 2/2\n#     \n    image = image/255 #normalisation\n    #image = tf.image.resize(image, [h, w]) #resize\n    image = tf.cast(image, tf.float32) # transforming into a tf.float object\n\n    return image, label\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"#V57\nimport pandas as pd\nimport gc #garbage collection\n\nWINDOW_SIZE = 128\nSTRIDE = 75\nK = 16\n\n\nif os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n    final_validation = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\n    data_dir = '../input/prostate-cancer-grade-assessment/test_images/'\nelse:\n    final_validation = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').sample(n=10)\n    data_dir = '../input/prostate-cancer-grade-assessment/train_images/'\n    \nimages = list(final_validation['image_id'])\n\n\ndf_np=pd.DataFrame(columns=['np_image'], index=np.arange(len(images))).fillna(0)\ndf_np['np_image']=df_np['np_image'].astype(object)\nfor i, img in enumerate(images):\n    url = data_dir + img + '.tiff'\n    image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n    glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n\n\n    #df_np.at[i,'np_image']=glued_image.reshape([-1, 1,512,512,3])\n    df_np.at[i,'np_image']=glued_image.reshape([-1,512,512,3])\nnp_image_from_df=np.stack(df_np['np_image'])/255\nfinal_validation_dataset = (\ntf.data.Dataset.from_tensor_slices(\n    (\n        np_image_from_df\n    )\n    )\n)\nfinal_validation_dataset_tens=final_validation_dataset\n\nisup_grade_data = model.predict(final_validation_dataset_tens).argmax(axis=-1).astype(int)\nmy_submission = pd.DataFrame({'image_id': final_validation.image_id, 'isup_grade': isup_grade_data})\n    \n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\n\n\"\"\"\n\n\nimport pandas as pd\nimport gc #garbage collection\n\nWINDOW_SIZE = 128\nSTRIDE = 128\nK = 16\n\n\n\nif os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n     #test to try out the prediction\n    final_validation = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\n    data_dir = '../input/prostate-cancer-grade-assessment/test_images/'\n    \"\"\"\n    test_dataset=pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\n    test_count=len(test_dataset.index)\n    final_validation = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').sample(n=test_count)\n    data_dir = '../input/prostate-cancer-grade-assessment/train_images/'\"\"\"\nelse:\n    final_validation = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').sample(n=1500)\n    data_dir = '../input/prostate-cancer-grade-assessment/train_images/'\n\nimages = list(final_validation['image_id'])\n\n\ndf_np=pd.DataFrame(columns=['np_image'], index=np.arange(len(images))).fillna(0)\ndf_np['np_image']=df_np['np_image'].astype(object)\ndef treat_images():\n    for i, img in enumerate(images):\n        url = data_dir + img + '.tiff'\n        image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n        glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n\n\n        #df_np.at[i,'np_image']=glued_image.reshape([-1, 1,512,512,3])\n        df_np.at[i,'np_image']=glued_image.reshape([-1,512,512,3])\n    np_image_from_df=np.stack(df_np['np_image']/255)\n    final_validation_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n            np_image_from_df\n        )\n        )\n    )\n    final_validation_dataset_tens=final_validation_dataset\n    isup_grade_data = model.predict(final_validation_dataset_tens).argmax(axis=-1).astype(int)\n    my_submission = pd.DataFrame({'image_id': final_validation.image_id, 'isup_grade': isup_grade_data})\n    # you could use any filename. We choose submission here\n    my_submission.to_csv('submission.csv', index=False)\ntreat_images()\n\"\"\"test to try out the image processing\n    #temporary test\n#     isup_grade_data = model.predict(final_validation_dataset_tens).argmax(axis=-1).astype(int)\n#     my_submission = pd.DataFrame({'image_id': final_validation.image_id, 'isup_grade': isup_grade_data})\n    my_submission = pd.DataFrame({'image_id': final_validation.image_id, 'isup_grade': 1})\n\"\"\" \"\"\"\n    \n    \n\n#%lprun -f treat_images treat_images()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"pd.read_csv('submission.csv')\"\"\"\n\nmy_submission = pd.DataFrame({'image_id': final_validation.image_id, 'isup_grade': 1})\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"#V58 direct TF\nimport numpy as np\nimport pandas as pd\nimport gc #garbage collection\nimport skimage.io\nWINDOW_SIZE = 128\nSTRIDE = 128\nK = 16\ndef parse(s):\n    return s, d[s]\n\ndef process_path(file_path):\n    print()\n#     a=lambda x: tf.py_function(parse, [x], [tf.string])\n    url=file_path.numpy()\n    print(url)\n    image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n    glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n    \n    # load the raw data from the file as a string\n#     img = tf.io.read_file(file_path)\n#     img = decode_img(img)\n    img = glued_image/255\n    img=tf.reshape(img, [1,512,512,3])\n#     img = img.reshape(-1,512,512,3)\n    \n    return img\n\ndef process_path(file_path):\n    url=file_path.numpy()\n    print(url)\n    glued_image=np.array(skimage.io.MultiImage('../input/prostate-cancer-grade-assessment/train_images/0005f7aaab2800f6170c399693a96917.tiff'))\n    img = glued_image/255\n    img=tf.reshape(img, [1,512,512,3])\n#     image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n#     glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n    return img\n\nif os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n    final_validation = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\n    data_dir = '../input/prostate-cancer-grade-assessment/test_images/'\nelse:\n    final_validation = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').sample(n=10)\n    data_dir = '../input/prostate-cancer-grade-assessment/train_images/'\nimages = list(final_validation['image_id']) \n# images = list(data_dir+final_validation['image_id']+'.tiff')\n# train_ds = tf.data.Dataset.from_generator(process_path, args=images, output_types=tf.float32, output_shapes = (1,512,512,3), )\nlist_ds = tf.data.Dataset.from_tensor_slices(data_dir+final_validation.image_id+'.tiff')\n\n#train_ds = list_ds.map(process_path)\n# train_ds = list_ds.map(lambda x: tf.numpy_function(func=process_path, inp=[x], Tout=tf.float32))\ntrain_ds = list_ds.map(\n    lambda path: tf.py_function(\n            func=process_path,\n            inp=[path],\n            Tout=[tf.string],\n    )\n)\nfinal_validation_dataset_tens=train_ds\n\nisup_grade_data = model.predict(final_validation_dataset_tens).argmax(axis=-1).astype(int)\nmy_submission = pd.DataFrame({'image_id': final_validation.image_id, 'isup_grade': isup_grade_data})\n    \n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndf_np=pd.DataFrame(columns=['np_image'], index=np.arange(len(images))).fillna(0)\ndf_np['np_image']=df_np['np_image'].astype(object)\nfor i, img in enumerate(images):\n    url = data_dir + img + '.tiff'\n    image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n    glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n\n\n    #df_np.at[i,'np_image']=glued_image.reshape([-1, 1,512,512,3])\n    df_np.at[i,'np_image']=glued_image.reshape([-1,512,512,3])\nnp_image_from_df=np.stack(df_np['np_image'])/255\nfinal_validation_dataset = (\ntf.data.Dataset.from_tensor_slices(\n    (\n        np_image_from_df\n    )\n    )\n)\n\nfinal_validation_dataset_tens=final_validation_dataset\n\nisup_grade_data = model.predict(final_validation_dataset_tens).argmax(axis=-1).astype(int)\nmy_submission = pd.DataFrame({'image_id': final_validation.image_id, 'isup_grade': isup_grade_data})\n    \n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\n\"\"\"\n# ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# for f in final_validation_dataset.take(1):\n#     print(f.numpy())\n#     plt.imshow(f.numpy().reshape(512,512,3))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}