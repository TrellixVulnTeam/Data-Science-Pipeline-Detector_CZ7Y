{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#inspired by https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#depedencies\nimport os\nimport cv2\nimport PIL\nimport random\nimport openslide\nimport skimage.io\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_number='NoLimit'\n\nif sample_number=='NoLimit':\n    train_df = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').reset_index(drop=True)\nelse:\n    train_df = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').reset_index(drop=True).sample(n=sample_number)\n\n    #train_df = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').sample(n=100, random_state=0).reset_index(drop=True)\n\nimages = list(train_df['image_id'])\nlen_image=len(images)\nlabels = list(train_df['isup_grade'])\ndata_dir = '../input/prostate-cancer-grade-assessment/train_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Functions\n## to get the % of different colors \ndef compute_statistics(image):\n    \"\"\"\n    Args:\n        image                  numpy.array   multi-dimensional array of the form WxHxC\n    \n    Returns:\n        ratio_white_pixels     float         ratio of white pixels over total pixels in the image \n    \"\"\"\n    width, height = image.shape[0], image.shape[1]\n    num_pixels = width * height\n    \n    num_white_pixels = 0\n    \n    summed_matrix = np.sum(image, axis=-1)\n    # Note: A 3-channel white pixel has RGB (255, 255, 255)\n    num_white_pixels = np.count_nonzero((summed_matrix > 620)) #avoid too white and/or too blank\n    \n    ratio_white_pixels = num_white_pixels / num_pixels\n    \n    green_concentration = np.mean(image[1])\n    blue_concentration = np.mean(image[2])\n#     red_median = np.percentile(image[0],50)\n#     green_median = np.percentile(image[1],50)\n#     blue_median = np.percentile(image[2],50)\n#     return ratio_white_pixels, green_concentration, blue_concentration, red_median, green_median, blue_median\n    return ratio_white_pixels, green_concentration, blue_concentration\n#selection of the k-best regions\ndef select_k_best_regions(regions, k=20):\n    \"\"\"\n    Args:\n        regions               list           list of 2-component tuples first component the region, \n                                             second component the ratio of white pixels\n                                             \n        k                     int            number of regions to select\n    \"\"\"\n    red_penalty=0\n    #regions = [x for x in regions if ((x[3] > 180 and x[4] > 180) and (((x[5]-red_penalty)>x[6]) or ((x[5]-red_penalty)>x[7])))] # x[3] is green concentration and 4 is blue \n    regions = [x for x in regions if (x[3] > 180 and x[4] > 180)] # x[3] is green concentration and 4 is blue \n    k_best_regions = sorted(regions, key=lambda tup: tup[2])[:k]\n    return k_best_regions\n#to retrieve from the top left pixel the full region\n\ndef get_k_best_regions(coordinates, image, window_size=512):\n    regions = {}\n    for i, tup in enumerate(coordinates):\n        x, y = tup[0], tup[1]\n        regions[i] = image[x : x+window_size, y : y+window_size, :]\n    \n    return regions\n\n#the slider\ndef generate_patches(slide_path, window_size=200, stride=128, k=20):\n    \n    image = np.array(skimage.io.MultiImage(slide_path)[-2])\n#     image = image\n    \n    max_width, max_height = image.shape[0], image.shape[1]\n    regions_container = []\n    i = 0\n    \n    while window_size + stride*i <= max_height:\n        j = 0\n        \n        while window_size + stride*j <= max_width:            \n            x_top_left_pixel = j * stride\n            y_top_left_pixel = i * stride\n            \n            patch = image[\n                x_top_left_pixel : x_top_left_pixel + window_size,\n                y_top_left_pixel : y_top_left_pixel + window_size,\n                :\n            ]\n            \n            ratio_white_pixels, green_concentration, blue_concentration = compute_statistics(patch)\n            \n            region_tuple = (x_top_left_pixel, y_top_left_pixel, ratio_white_pixels, green_concentration, blue_concentration)\n            regions_container.append(region_tuple)\n            #print(f' DEBUG : rmed :{red_median} gmed :{green_median} bmed : {blue_median}')\n            j += 1\n        \n        i += 1\n    \n    k_best_region_coordinates = select_k_best_regions(regions_container, k=k)\n    k_best_regions = get_k_best_regions(k_best_region_coordinates, image, window_size)\n    \n    return image, k_best_region_coordinates, k_best_regions\n\n\n#showing results \ndef display_images(regions, title):\n    fig, ax = plt.subplots(5, 4, figsize=(15, 15))\n    \n    for i, region in regions.items():\n        ax[i//4, i%4].imshow(region)\n    \n    fig.suptitle(title)\n    \n## glue to a unique picture\ndef glue_to_one_picture(image_patches, window_size=200, k=16):\n    side = int(np.sqrt(k))\n    image = np.zeros((side*window_size, side*window_size, 3), dtype=np.int16)\n        \n    for i, patch in image_patches.items():\n        x = i // side\n        y = i % side\n        image[\n            x * window_size : (x+1) * window_size,\n            y * window_size : (y+1) * window_size,\n            :\n        ] = patch\n    \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n#ex_url = data_dir + images[13] + '.tiff'\n#_, best_coordinates, best_regions = generate_patches(ex_url)\n#display_images(best_regions, 'Window size: 200, stride: 128')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install line_profiler\n# %load_ext line_profiler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#### \nWINDOW_SIZE = 128\nSTRIDE = 75\nK = 16\n#fig, ax = plt.subplots(30, 2, figsize=(20, 25))\nif os.path.exists('/kaggle/working/512x512x3'): \n    print('directory already created, skipping')\nelse:\n    os.mkdir('/kaggle/working/512x512x3')\ndef get_images(images):\n    for i, img in enumerate(images):\n        url = data_dir + img + '.tiff'\n        image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n        glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n\n        #ax[i][0].imshow(image)\n        #ax[i][0].set_title(f'{img} - Original - Label: {labels[i]}')\n\n        #ax[i][1].imshow(glued_image)\n        #ax[i][1].set_title(f'{img} - Glued - Label: {labels[i]}')\n        #glued_image=glued_image/255 #normalisation \n        print(f'Image #{i+1} processed out of {len_image}')\n        cv2.imwrite(f\"/kaggle/working/512x512x3/{img}.png\", glued_image)\nget_images(images)\n# %lprun -f compute_statistics generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n#fig.suptitle('From biopsy to glued patches')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#img=images[13]\n#url = data_dir + img + '.tiff'\n#image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n#import matplotlib.pyplot as plt\n#import matplotlib.image as mpimg\n#img=mpimg.imread(f\"/kaggle/working/testoutput/{img}.png\")\n#imgplot = plt.imshow(img)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bb=best_regions[0]\n#r,g,b=bb[:,:,0],bb[:,:,1],bb[:,:,2]\n#plt.imshow(bb)\n#print(f'{np.mean(r)},{np.mean(g)},{np.mean(b)}')\n#print(f'{np.percentile(r,80)},{np.percentile(g,80)},{np.percentile(b,80)}')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bb=best_regions[8]\n#r,g,b=bb[:,:,0],bb[:,:,1],bb[:,:,2]\n#plt.imshow(bb)\n#print(f'{np.mean(r)},{np.mean(g)},{np.mean(b)}')\n\n#print(f'{np.median(r)},{np.median(g)},{np.median(b)}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bb=best_regions[9]\n#r,g,b=bb[:,:,0],bb[:,:,1],bb[:,:,2]\n#plt.imshow(bb)\n#print(f'{np.mean(r)},{np.mean(g)},{np.mean(b)}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import imageio\n#imageio.imread(\"./512x512x3/5b5d7aa9b4ded22e5c6d59eaad75684f.png\")\n#plt.imshow(imageio.imread(\"./512x512x3/5b5d7aa9b4ded22e5c6d59eaad75684f.png\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}