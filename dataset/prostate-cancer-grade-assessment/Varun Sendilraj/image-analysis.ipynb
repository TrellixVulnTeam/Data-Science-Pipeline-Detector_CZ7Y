{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n       os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nimport openslide","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/prostate-cancer-grade-assessment/train.csv\").set_index('image_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Visualization\n--------------------------","metadata":{}},{"cell_type":"code","source":"train_img_path = \"/kaggle/input/prostate-cancer-grade-assessment/train_images\"\nlabel_path = \"/kaggle/input/prostate-cancer-grade-assessment/train_label_masks\"\n\ntrain_img = [img for img in os.listdir(train_img_path)]\ntrain_label = [label for label in os.listdir(label_path)]\n\ntrain_img = list(sorted(train_img))\ntrain_label = list(sorted(train_label))\n\nSIZE = 300\n\ndef preprocessing_img(img):\n    slide = openslide.OpenSlide(img)\n    img = np.array(slide.get_thumbnail(size=(SIZE, SIZE)))\n    img = Image.fromarray(img)\n    img = img.resize((SIZE, SIZE))\n    img = np.array(img)\n    return img\n\nimg_array = []\nfor i in range(10):\n    img = train_img_path + \"/\" + train_img[i]\n    img = preprocessing_img(img)\n    img_array.append(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_array[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_test = img_array[0]\nimg_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isup = train_df.iloc[0]['isup_grade']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre Processing","metadata":{}},{"cell_type":"markdown","source":"### Denoising image","metadata":{}},{"cell_type":"code","source":"import cv2\n\ndenoise = cv2.fastNlMeansDenoisingColored(img_test,None,10,10,7,21)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = plt.figure(figsize=(15,15))\nf.add_subplot(2, 1, 1).set_title(f'Original Image isup = {isup}')\nplt.imshow(img_array[0], cmap = \"gray\")\nf.add_subplot(2, 1, 2).set_title(f'Filtered Image isup = {isup}')\nplt.imshow(denoise, cmap = \"gray\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Not too sure if image denoising will be helpful so will not use it for now \n\n- Thinking that specific values of color in image may factor into calculation","metadata":{}},{"cell_type":"markdown","source":"## Image Processing","metadata":{}},{"cell_type":"code","source":"def RGB2HEX(color):\n    return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_image = cv2.resize(img_array[0], (600, 400), interpolation = cv2.INTER_AREA)\nmodified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom collections import Counter\nfrom skimage.color import rgb2lab, deltaE_cie76\n\n\nclf = KMeans(n_clusters =8)\nlabels = clf.fit_predict(modified_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts = Counter(labels)\n\ncenter_colors = clf.cluster_centers_\n# We get ordered colors by iterating through the keys\nordered_colors = [center_colors[i] for i in counts.keys()]\nhex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\nrgb_colors = [ordered_colors[i] for i in counts.keys()]\ndel counts[0]\ndel hex_colors[0]\n\nprint(counts)\nplt.figure(figsize = (8, 6))\nplt.pie(counts.values(), labels = hex_colors, colors = hex_colors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Display Function","metadata":{}},{"cell_type":"code","source":"def display(comp,name,ogName = \"Original Image isup\",img = img_test):\n    f = plt.figure(figsize=(15,15))\n    f.add_subplot(2, 1, 1).set_title(f'{ogName} = {isup}')\n    plt.imshow(img, cmap = \"gray\")\n    f.add_subplot(2, 1, 2).set_title(f'{name} isup = {isup}')\n    plt.imshow(comp, cmap = \"gray\")\n    return plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Sharpening\n<hr>","metadata":{}},{"cell_type":"code","source":"import cv2\nimg = cv2.blur(img_test, (3, 3))\n\nkernel = [\n            [-1, -1, -1],\n            [-1, 9, -1],\n            [-1, -1, -1]\n]\n\nkernel = np.array(kernel)\n\nsharpened = cv2.filter2D(img, -1, kernel)\n\ndisplay(sharpened, \"sharpened\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convolution kernel","metadata":{}},{"cell_type":"code","source":"\nkernel = [\n            [0, 1, 0],\n            [1, -4, 1],\n            [0, 1, 0]\n]\n\nkernel = np.array(kernel)\n\nfiltered = cv2.filter2D(sharpened, -1, kernel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = plt.figure(figsize=(15,15))\nf.add_subplot(2, 1, 1).set_title(f'Original Image isup = {isup}')\nplt.imshow(img_test, cmap = \"gray\")\nf.add_subplot(2, 1, 2).set_title(f'Filtered Image isup = {isup}')\nplt.imshow(filtered, cmap = \"gray\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Will use this filtered image for further analysis","metadata":{}},{"cell_type":"markdown","source":"### Image Segmentation","metadata":{}},{"cell_type":"code","source":"# Segmentation\ngray = cv2.cvtColor(filtered, cv2.COLOR_RGB2GRAY)\nret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = plt.figure(figsize=(15,15))\nf.add_subplot(2, 1, 1).set_title(f'Original Image isup = {isup}')\nplt.imshow(img_test, cmap = \"gray\")\nf.add_subplot(2, 1, 2).set_title(f'PreSegment Image isup = {isup}')\nplt.imshow(thresh, cmap = \"gray\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Further noise removal\nkernel = np.ones((3, 3), np.uint8)\nopening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n\n# sure background area\nsure_bg = cv2.dilate(opening, kernel, iterations=3)\n\n# Finding sure foreground area\ndist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\nret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n\n# Finding unknown region\nsure_fg = np.uint8(sure_fg)\nunknown = cv2.subtract(sure_bg, sure_fg)\n\n#Displaying segmented back ground\ndisplay(sure_bg, 'Segmented Background')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#will not use segmeted code from above but insteaf idetify unique clusters in the image\n\nimg_test = img_array[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Marker labelling\nret, markers = cv2.connectedComponents(thresh)\n\n# Add one to all labels so that sure background is not 0, but 1\nmarkers = markers + 1\n\n# Now, mark the region of unknown with zero\nmarkers[unknown == 255] = 0\n\nmarkers = cv2.watershed(img_test, markers)\nimg_test[markers == -1] = [255, 0, 0]\n\n# Displaying markers on the image\ndisplay(markers,  'Marked')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing Pipeline for new Image (ISUP 4)\n<hr>","metadata":{}},{"cell_type":"code","source":"isup4 = img_array[3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(isup4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isup = train_df.iloc[3]['isup_grade']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_image = cv2.resize(isup4, (600, 400), interpolation = cv2.INTER_AREA)\nmodified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)\n\n#color seperation\nclf = KMeans(n_clusters =8)\nlabels = clf.fit_predict(modified_image)\n\ncounts = Counter(labels)\n\ncenter_colors = clf.cluster_centers_\n# We get ordered colors by iterating through the keys\nordered_colors = [center_colors[i] for i in counts.keys()]\nhex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\nrgb_colors = [ordered_colors[i] for i in counts.keys()]\n\ndel counts[0]\ndel hex_colors[0]\n\nprint(counts)\nplt.figure(figsize = (8, 6))\nplt.pie(counts.values(), labels = hex_colors, colors = hex_colors)\n\nhex_colors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts.values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_image = isup4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_sharpening(image,ogImage):\n    img = cv2.blur(image, (3, 3))\n    kernel = [\n            [-1, -1, -1],\n            [-1, 9, -1],\n            [-1, -1, -1]\n    ]\n\n    kernel = np.array(kernel)\n    image = cv2.filter2D(img, -1, kernel)\n\n    return display(image, 'sharpened', f\"Original Image isup = {isup}\",ogImage ) \n\ndef convolution_kernel(image,ogImage):\n    kernel = [\n            [0, 1, 0],\n            [1, -4, 1],\n            [0, 1, 0]\n    ]\n\n    kernel = np.array(kernel)\n    image = cv2.filter2D(image, -1, kernel)\n\n\n    return display(image, 'Convolution Kernel',  f\"Original Image isup = {isup}\",ogImage) \n    \ndef segmentation(image,ogImage, num):\n    \n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n    # Further noise removal\n    kernel = np.ones((3, 3), np.uint8)\n    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n\n\n    # sure background area\n    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n\n    # Finding sure foreground area\n    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n\n    # Finding unknown region\n    sure_fg = np.uint8(sure_fg)\n    unknown = cv2.subtract(sure_bg, sure_fg)\n    \n    image = img_array[num]\n    # Marker labelling\n    ret, markers = cv2.connectedComponents(thresh)\n\n    # Add one to all labels so that sure background is not 0, but 1\n    markers = markers + 1\n\n    # Now, mark the region of unknown with zero\n    markers[unknown == 255] = 0\n\n    markers = cv2.watershed(img_test, markers)\n    image[markers == -1] = [255, 0, 0]\n\n    # Displaying markers on the image\n    return display(markers,  'Marked',  f\"Original Image isup = {isup}\",ogImage)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_sharpening(testing_image,isup4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convolution_kernel(testing_image,isup4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segmentation(testing_image,isup4,3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing for ISUP 1","metadata":{}},{"cell_type":"code","source":"isup1 = img_array[9]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isup = train_df.iloc[9]['isup_grade']\nplt.imshow(isup1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_image = cv2.resize(isup1, (600, 400), interpolation = cv2.INTER_AREA)\nmodified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)\n\n#color seperation\nclf = KMeans(n_clusters =8)\nlabels = clf.fit_predict(modified_image)\n\ncounts = Counter(labels)\n\ncenter_colors = clf.cluster_centers_\n# We get ordered colors by iterating through the keys\nordered_colors = [center_colors[i] for i in counts.keys()]\nhex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\nrgb_colors = [ordered_colors[i] for i in counts.keys()]\ndel counts[0]\ndel hex_colors[0]\n\nprint(counts)\n\nplt.figure(figsize = (8, 6))\nplt.pie(counts.values(), labels = hex_colors, colors = hex_colors)\n\nhex_colors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_image = isup1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_sharpening(testing_image,isup1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convolution_kernel(testing_image,isup1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segmentation(testing_image,isup1,9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}