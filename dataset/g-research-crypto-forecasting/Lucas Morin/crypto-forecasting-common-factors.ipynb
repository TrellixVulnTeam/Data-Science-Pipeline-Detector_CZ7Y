{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Crypto Forecasting - Feature engineering","metadata":{}},{"cell_type":"code","source":"import gresearch_crypto\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport pickle\n\nimport time\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nDEBUG = False","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:56.998641Z","iopub.execute_input":"2021-11-10T21:08:56.998995Z","iopub.status.idle":"2021-11-10T21:08:58.134899Z","shell.execute_reply.started":"2021-11-10T21:08:56.998904Z","shell.execute_reply":"2021-11-10T21:08:58.133891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training data is in the competition dataset as usual","metadata":{"papermill":{"duration":0.011622,"end_time":"2020-10-16T21:06:02.516712","exception":false,"start_time":"2020-10-16T21:06:02.50509","status":"completed"},"tags":[]}},{"cell_type":"code","source":"nrows = 100000 if DEBUG else None\n\ndtype={'Asset_ID': 'int8', 'Count': 'int32', 'row_id': 'int32', 'Count': 'int32',\n       'Open': 'float32', 'High': 'float32', 'Low': 'float32', 'Close': 'float32',\n       'Volume': 'float32', 'VWAP': 'float32'}\n\ntrain_df = pd.read_csv('../input/g-research-crypto-forecasting/train.csv', low_memory=False, dtype=dtype, nrows=nrows)\nasset_details = pd.read_csv('../input/g-research-crypto-forecasting/asset_details.csv')\n\n#create dictionnary of weights\ndict_weights = {}\nfor i in range(asset_details.shape[0]):\n    dict_weights[asset_details.iloc[i,0]] = asset_details.iloc[i,1]\n\n# remove rows with missing targets - DO THIS AT THE END\n# train_df = train_df[~train_df.Target.isna()]\n\n# replace infinite VWAP with close price\ntrain_df.VWAP = np.where(np.isinf(train_df.VWAP),train_df.Close,train_df.VWAP)\n\n#filter to avoid time leakage with the data \nfilter_leakage = pd.to_datetime(train_df['timestamp'], unit='s') < '2021-06-01 00:00:00'\ntrain_df = train_df[filter_leakage]","metadata":{"papermill":{"duration":0.273123,"end_time":"2020-10-16T21:06:02.800188","exception":false,"start_time":"2020-10-16T21:06:02.527065","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-10T21:08:58.137706Z","iopub.execute_input":"2021-11-10T21:08:58.138118Z","iopub.status.idle":"2021-11-10T21:08:58.626041Z","shell.execute_reply.started":"2021-11-10T21:08:58.138061Z","shell.execute_reply":"2021-11-10T21:08:58.625011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df.Asset_ID == 2].head()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:58.627974Z","iopub.execute_input":"2021-11-10T21:08:58.628305Z","iopub.status.idle":"2021-11-10T21:08:58.662212Z","shell.execute_reply.started":"2021-11-10T21:08:58.628263Z","shell.execute_reply":"2021-11-10T21:08:58.661068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ref_col = 'Close'","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:58.663743Z","iopub.execute_input":"2021-11-10T21:08:58.664085Z","iopub.status.idle":"2021-11-10T21:08:58.670152Z","shell.execute_reply.started":"2021-11-10T21:08:58.664042Z","shell.execute_reply":"2021-11-10T21:08:58.669084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Standardise prices\n\ndef standardise_prices(df,cols=['Open','High','Low','Close','VWAP'],by='Close'):\n    base = train_df[by].copy()\n    df['Open'] = train_df['Open'] / base\n    df['High'] = train_df['High'] / base\n    df['Low'] = train_df['Low'] /  base\n    df['Close'] = train_df['Close'] / base\n    df['VWAP'] = train_df['VWAP'] / base\n    df['Price'] = base\n    return df\n\ndef calc_dollar_features(df, by='Price'):\n    train_df['Volume_dollar'] = train_df['Volume']*train_df[by]\n    train_df['volume_per_trade'] = train_df['Volume']/train_df['Count']\n    train_df['dollar_per_trade'] = train_df['Volume_dollar']/train_df['Count']\n    return df\n\ntrain_df['weights'] = train_df.Asset_ID.map(dict_weights).astype('float32')\ntrain_df = standardise_prices(train_df)\ntrain_df = calc_dollar_features(train_df)\n\n# log returns and estimated volatilities\ntrain_df['log_ret'] = np.log(train_df.Close/train_df.Open)\ntrain_df['GK_vol'] = (1 / 2 * np.log(train_df.High / train_df.Low) ** 2 - \\\n    (2 * np.log(2) - 1) * np.log(train_df.Close / train_df.Open) ** 2).astype('float32')\ntrain_df['RS_vol'] = np.log(train_df.High/train_df.Close)*np.log(train_df.High/train_df.Open) + \\\n    np.log(train_df.Low/train_df.Close)*np.log(train_df.Low/train_df.Open)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:58.673171Z","iopub.execute_input":"2021-11-10T21:08:58.674206Z","iopub.status.idle":"2021-11-10T21:08:58.719414Z","shell.execute_reply.started":"2021-11-10T21:08:58.674155Z","shell.execute_reply":"2021-11-10T21:08:58.718716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Market Aggregation\n\ncode inspired from Slawek Biel work in optiver competition.","metadata":{}},{"cell_type":"code","source":"%%time\n\nfeatures_to_aggregate = ['Count','Open','High','Low','Close','Price','Volume','VWAP','Target','Volume_dollar','volume_per_trade','dollar_per_trade','log_ret','GK_vol','RS_vol']\n\nt, w, A_id = (train_df[col].values for col in ['timestamp','weights','Asset_ID'])\nids, index = np.unique(t, return_index=True)\n\nValues = train_df[features_to_aggregate].values\nsplits = np.split(Values, index[1:])\nsplits_w = np.split(w, index[1:])\nsplits_A_id = np.split(A_id, index[1:])\n\nout = []\n\nfor time_id, x, w, A_id in zip(ids.tolist(), splits, splits_w, splits_A_id):\n    outputs = np.float32(np.sum((x.T*w),axis=1)/sum(w))\n    outputs = np.tile(outputs, (len(w), 1))\n    out.append(outputs)\n    \nout = np.concatenate(out,axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:58.721297Z","iopub.execute_input":"2021-11-10T21:08:58.722042Z","iopub.status.idle":"2021-11-10T21:08:59.384169Z","shell.execute_reply.started":"2021-11-10T21:08:58.721994Z","shell.execute_reply":"2021-11-10T21:08:59.383033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[[s+'_M' for s in features_to_aggregate]] = out\n\ndel out, Values\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:59.385738Z","iopub.execute_input":"2021-11-10T21:08:59.385986Z","iopub.status.idle":"2021-11-10T21:08:59.537968Z","shell.execute_reply.started":"2021-11-10T21:08:59.385958Z","shell.execute_reply":"2021-11-10T21:08:59.53693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop([ref_col,ref_col+'_M'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:59.539713Z","iopub.execute_input":"2021-11-10T21:08:59.539972Z","iopub.status.idle":"2021-11-10T21:08:59.5654Z","shell.execute_reply.started":"2021-11-10T21:08:59.539942Z","shell.execute_reply":"2021-11-10T21:08:59.564122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:59.566813Z","iopub.execute_input":"2021-11-10T21:08:59.567071Z","iopub.status.idle":"2021-11-10T21:08:59.603218Z","shell.execute_reply.started":"2021-11-10T21:08:59.567042Z","shell.execute_reply":"2021-11-10T21:08:59.602128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# time encoding","metadata":{}},{"cell_type":"code","source":"def timestamp_to_date(timestamp):\n    return(datetime.fromtimestamp(timestamp))\n\nts = train_df.timestamp\nts = ts.apply(timestamp_to_date)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:59.604724Z","iopub.execute_input":"2021-11-10T21:08:59.605133Z","iopub.status.idle":"2021-11-10T21:08:59.769148Z","shell.execute_reply.started":"2021-11-10T21:08:59.605075Z","shell.execute_reply":"2021-11-10T21:08:59.768187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:59.770433Z","iopub.execute_input":"2021-11-10T21:08:59.770687Z","iopub.status.idle":"2021-11-10T21:08:59.78087Z","shell.execute_reply.started":"2021-11-10T21:08:59.770659Z","shell.execute_reply":"2021-11-10T21:08:59.779896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['sin_month'] = (np.sin(2 * np.pi * ts.dt.month/12)).astype('float32')\ntrain_df['cos_month'] = (np.cos(2 * np.pi * ts.dt.month/12)).astype('float32')\ntrain_df['sin_day'] = (np.sin(2 * np.pi * ts.dt.day/31)).astype('float32')\ntrain_df['cos_day'] = (np.cos(2 * np.pi * ts.dt.day/31)).astype('float32')\ntrain_df['sin_hour'] = (np.sin(2 * np.pi * ts.dt.hour/24)).astype('float32')\ntrain_df['cos_hour'] = (np.cos(2 * np.pi * ts.dt.hour/24)).astype('float32')\ntrain_df['sin_minute'] = (np.sin(2 * np.pi * ts.dt.minute/60)).astype('float32')\ntrain_df['cos_minute'] = (np.cos(2 * np.pi * ts.dt.minute/60)).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:59.782607Z","iopub.execute_input":"2021-11-10T21:08:59.782924Z","iopub.status.idle":"2021-11-10T21:08:59.908339Z","shell.execute_reply.started":"2021-11-10T21:08:59.782889Z","shell.execute_reply":"2021-11-10T21:08:59.907292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cut data set in five\n\nFirst step to build independant folds. the idea is to end with something like that:","metadata":{}},{"cell_type":"code","source":"# Generate the class/group data\n\ntime_ids = train_df.timestamp.unique()\n\nn_fold = 5\nsplits = 0.6\nntimes = len(time_ids)\n\nembargo_train_test = 60*24*30\nembargo_fold = 60*24*30\n\ntime_per_fold = (ntimes - 5*embargo_train_test - 5*embargo_fold)/5\ntrain_len = splits*time_per_fold \ntest_len = (1-splits)*time_per_fold\n\nfold_start = [np.int(i*(len(time_ids)+1)/5) for i in range(6)]\n\nfor i in range(n_fold):\n    time_folds = time_ids[fold_start[i]:fold_start[i+1]-1]\n    df_fold = train_df[train_df.timestamp.isin(time_folds)]\n    df_fold.to_parquet('df_fold_'+str(i)+'.parquet')\n    \ndel train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:08:59.90976Z","iopub.execute_input":"2021-11-10T21:08:59.91064Z","iopub.status.idle":"2021-11-10T21:09:00.314188Z","shell.execute_reply.started":"2021-11-10T21:08:59.910584Z","shell.execute_reply":"2021-11-10T21:09:00.312766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_folds","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:00.317412Z","iopub.execute_input":"2021-11-10T21:09:00.317743Z","iopub.status.idle":"2021-11-10T21:09:00.324365Z","shell.execute_reply.started":"2021-11-10T21:09:00.317709Z","shell.execute_reply":"2021-11-10T21:09:00.323256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:00.326033Z","iopub.execute_input":"2021-11-10T21:09:00.326566Z","iopub.status.idle":"2021-11-10T21:09:00.457944Z","shell.execute_reply.started":"2021-11-10T21:09:00.326519Z","shell.execute_reply":"2021-11-10T21:09:00.456581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lagged Features","metadata":{}},{"cell_type":"code","source":"%%time\n\nfeatures_to_lag = ['Price','Volume','VWAP','log_ret','RS_vol']\nlags = [2,5,15,30,60,120,300,1800,3750,10*24*60,30*24*60]\n\nfor fold in range(n_fold):\n    print('fold:'+str(fold))\n    df_fold = pd.read_parquet('df_fold_'+str(fold)+'.parquet')\n    \n    tmp = pd.DataFrame()\n    \n    for l in lags:\n        #print('lag:'+str(l))\n        tmp2 = df_fold[features_to_lag+['Asset_ID']].groupby('Asset_ID').transform(lambda s: s.rolling(l, min_periods=1).mean())\n        tmp2.columns = [str(c)+'_l_'+str(l) for c in tmp2.columns]\n        tmp = pd.concat([tmp,tmp2],axis=1)\n        \n    tmp.astype('float32').to_parquet('df_fold_'+str(fold)+'_lag.parquet')","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:00.459777Z","iopub.execute_input":"2021-11-10T21:09:00.460051Z","iopub.status.idle":"2021-11-10T21:09:03.42675Z","shell.execute_reply.started":"2021-11-10T21:09:00.460023Z","shell.execute_reply":"2021-11-10T21:09:03.425408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfeatures_to_lag = ['Price_M','Volume_M','VWAP_M','log_ret_M','RS_vol_M']\nlags = [2,5,15,30,60,120,300,1800,3750,10*24*60,30*24*60]\n\nfor fold in range(n_fold):\n    print('fold:'+str(fold))\n    df_fold = pd.read_parquet('df_fold_'+str(fold)+'.parquet')\n    \n    tmp = pd.DataFrame()\n    \n    for l in lags:\n        #print('lag:'+str(l))\n        tmp2 = df_fold[features_to_lag+['Asset_ID']].groupby('Asset_ID').transform(lambda s: s.rolling(l, min_periods=1).mean())\n        tmp2.columns = [str(c)+'_l_'+str(l) for c in tmp2.columns]\n        tmp = pd.concat([tmp,tmp2],axis=1)\n        \n    tmp.astype('float32').to_parquet('df_fold_'+str(fold)+'_lag_M.parquet')","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:03.429049Z","iopub.execute_input":"2021-11-10T21:09:03.429432Z","iopub.status.idle":"2021-11-10T21:09:06.26363Z","shell.execute_reply.started":"2021-11-10T21:09:03.429388Z","shell.execute_reply":"2021-11-10T21:09:06.262667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Beta Features","metadata":{}},{"cell_type":"code","source":"%%time\n\nfold = 0\nlags = [60,300,1800,3750,10*24*60,30*24*60]\n\nfor fold in range(n_fold):\n    print('fold:'+str(fold))\n    df_fold = pd.read_parquet('df_fold_'+str(fold)+'.parquet')\n    df_fold = df_fold[['Asset_ID','log_ret_M','log_ret']]\n    df_fold['log_ret_M2'] = df_fold['log_ret_M']**2\n    df_fold['log_ret_Mr'] = df_fold['log_ret_M']*df_fold['log_ret']\n    tmp = pd.DataFrame()\n    \n    for l in lags:\n        #print(l)\n        features_to_lag = ['log_ret_M2','log_ret_Mr']\n        #use min periods = l to match definition of target ?\n        tmp2 = df_fold[features_to_lag+['Asset_ID']].groupby('Asset_ID').transform(lambda s: s.rolling(l, min_periods=1).mean())\n        tmp2['beta'] = tmp2['log_ret_Mr'] / tmp2['log_ret_M2']\n        tmp2 = tmp2.drop(['log_ret_Mr','log_ret_M2'],axis=1)\n        \n        tmp2.columns = [str(c)+'_l_'+str(l) for c in tmp2.columns]\n        tmp = pd.concat([tmp,tmp2],axis=1)\n        tmp = tmp.loc[:,~tmp.columns.duplicated()]\n    \n    tmp.astype('float32').to_parquet('df_fold_'+str(fold)+'_beta.parquet')\n\ndel tmp2\ndel tmp","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:06.265283Z","iopub.execute_input":"2021-11-10T21:09:06.265815Z","iopub.status.idle":"2021-11-10T21:09:07.303177Z","shell.execute_reply.started":"2021-11-10T21:09:06.265767Z","shell.execute_reply":"2021-11-10T21:09:07.302167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\ndef sizeof_fmt(num, suffix='B'):\n    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n        if abs(num) < 1024.0:\n            return \"%3.1f %s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n\nfor name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n                         key= lambda x: -x[1])[:20]:\n    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:07.304552Z","iopub.execute_input":"2021-11-10T21:09:07.304821Z","iopub.status.idle":"2021-11-10T21:09:07.327108Z","shell.execute_reply.started":"2021-11-10T21:09:07.304794Z","shell.execute_reply":"2021-11-10T21:09:07.325912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del ts, df_fold, splits_w, splits_A_id, filter_leakage, ids, index, time_ids\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:07.328485Z","iopub.execute_input":"2021-11-10T21:09:07.328827Z","iopub.status.idle":"2021-11-10T21:09:07.479716Z","shell.execute_reply.started":"2021-11-10T21:09:07.328781Z","shell.execute_reply":"2021-11-10T21:09:07.478773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n                         key= lambda x: -x[1])[:20]:\n    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:07.481539Z","iopub.execute_input":"2021-11-10T21:09:07.481918Z","iopub.status.idle":"2021-11-10T21:09:07.501858Z","shell.execute_reply.started":"2021-11-10T21:09:07.481874Z","shell.execute_reply":"2021-11-10T21:09:07.500537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merge data","metadata":{}},{"cell_type":"code","source":"import os\n\ndict_fold = {}\n\nfor fold in range(n_fold):\n    print('fold:'+str(fold))\n    \n    df_fold = pd.read_parquet('df_fold_'+str(fold)+'.parquet')\n    time_ids = df_fold.timestamp.unique()\n    \n    test_train_len = len(time_ids) - embargo_train_test - embargo_fold\n    \n    train_start = embargo_fold + 1\n    train_end = embargo_fold + np.int(test_train_len*0.6) + 1\n    test_start = embargo_fold + np.int(test_train_len*0.6) + embargo_train_test + 1\n    test_end = len(df_fold.timestamp.unique())\n    \n    dict_fold['train_fold_'+str(fold)] = time_ids[train_start:train_end]\n    dict_fold['test_fold_'+str(fold)] = time_ids[test_start:test_end]\n\ndel df_fold","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:07.503946Z","iopub.execute_input":"2021-11-10T21:09:07.504275Z","iopub.status.idle":"2021-11-10T21:09:07.600093Z","shell.execute_reply.started":"2021-11-10T21:09:07.504242Z","shell.execute_reply":"2021-11-10T21:09:07.598873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scipy.stats.qmc.Halton","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:09:07.601641Z","iopub.execute_input":"2021-11-10T21:09:07.602015Z","iopub.status.idle":"2021-11-10T21:09:07.608691Z","shell.execute_reply.started":"2021-11-10T21:09:07.601968Z","shell.execute_reply":"2021-11-10T21:09:07.607082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfor fold in range(n_fold):\n    \n    df_train_fold = pd.DataFrame()\n    df_test_fold = pd.DataFrame()\n    \n    df_read = pd.read_parquet(\"df_fold_\"+str(fold)+'.parquet')\n    \n    ind_train = df_read.timestamp.isin(dict_fold['train_fold_'+str(fold)])\n    ind_test = df_read.timestamp.isin(dict_fold['test_fold_'+str(fold)])\n    \n    df_train_fold = df_read[ind_train]\n    df_test_fold = df_read[ind_test]\n    \n    for file in os.listdir('./'):\n        if file == \"df_fold_\"+str(fold)+'.parquet':\n            continue\n            \n        elif file.startswith(\"df_fold_\"+str(fold)):\n            print(file)\n            df_read = pd.read_parquet(file)\n            \n            df_train_read = df_read[ind_train]\n            df_test_read = df_read[ind_test]\n            \n            print(df_read.info())\n            df_train_fold = pd.concat([df_train_fold,df_train_read],axis=1)\n            df_train_fold = df_train_fold.loc[:,~df_train_fold.columns.duplicated()]\n            \n            df_test_fold = pd.concat([df_test_fold,df_test_read],axis=1)\n            df_test_fold = df_test_fold.loc[:,~df_test_fold.columns.duplicated()]\n            os.remove('./'+file)\n            \n    df_train_fold.to_parquet('train_fold_'+str(fold)+'.parquet')\n    df_test_fold.to_parquet('test_fold_'+str(fold)+'.parquet')","metadata":{"execution":{"iopub.status.busy":"2021-11-10T21:13:01.2893Z","iopub.execute_input":"2021-11-10T21:13:01.289709Z","iopub.status.idle":"2021-11-10T21:13:02.412372Z","shell.execute_reply.started":"2021-11-10T21:13:01.289668Z","shell.execute_reply":"2021-11-10T21:13:02.411236Z"},"trusted":true},"execution_count":null,"outputs":[]}]}