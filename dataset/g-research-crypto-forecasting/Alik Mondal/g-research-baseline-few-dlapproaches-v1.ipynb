{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img style = \"width:100%; height:auto;\" src = \"https://wallpapersmug.com/download/1920x1080/a8a1e4/coin-money-bitcoin.jpg\">\n<h1 style = \"text-align:center; background-color:black; color:white\"> G-Research | <i>BaseLine</i> | DNN, RNN + 1D-CNN  | <i>v1</i> </h1> ","metadata":{}},{"cell_type":"markdown","source":"All the given data after parsing & pre-processing are saved then loaded again, as this notebook is aimed at analysing performance of Basic DeepLearning Models | For forecasting only considering BTC  ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n'''\n\nBasically the training_dataset contains ~3.8 years of data points for each asset\nDuring Forecasting I have taken only 1 year worth of recent data (only for BTC)\n\n'''\n\n\ndf_asset_details = pd.read_csv('../input/g-research-crypto-forecasting/asset_details.csv')\nprint('df_asset_details: ',df_asset_details.shape)\ndf_sub_sample = pd.read_csv('../input/g-research-crypto-forecasting/example_sample_submission.csv')\nprint('sub_sample: ',df_sub_sample.shape)\ndf_sup_train = pd.read_csv('../input/g-research-crypto-forecasting/supplemental_train.csv').iloc[-5000000:]\nprint('sup_train: ',df_sup_train.shape)\ndf_train = pd.read_csv('../input/g-research-crypto-forecasting/train.csv').iloc[-5000000:]\nprint('train_shape: ', df_train.shape)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-02-03T20:56:39.368821Z","iopub.execute_input":"2022-02-03T20:56:39.369325Z","iopub.status.idle":"2022-02-03T20:57:55.774414Z","shell.execute_reply.started":"2022-02-03T20:56:39.369281Z","shell.execute_reply":"2022-02-03T20:57:55.773418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train_set_time_entry_range: ',df_train['timestamp'].iloc[0], ' - ', df_train['timestamp'].iloc[-1])\nprint()\nprint('Supplemetary_train_set_time_entry_range: ', df_sup_train['timestamp'].iloc[0], ' - ', df_sup_train['timestamp'].iloc[-1])","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:55.7764Z","iopub.execute_input":"2022-02-03T20:57:55.776665Z","iopub.status.idle":"2022-02-03T20:57:55.792549Z","shell.execute_reply.started":"2022-02-03T20:57:55.776634Z","shell.execute_reply":"2022-02-03T20:57:55.791554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp = pd.concat([df_train, df_sup_train], axis = 0 )\nprint('df_temp_before: ', df_temp.shape)\ndf_temp = df_temp.drop_duplicates()\nprint('df_temp_after: ', df_temp.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:55.794037Z","iopub.execute_input":"2022-02-03T20:57:55.794287Z","iopub.status.idle":"2022-02-03T20:58:28.188649Z","shell.execute_reply.started":"2022-02-03T20:57:55.794258Z","shell.execute_reply":"2022-02-03T20:58:28.187755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.sort_values('timestamp')\nprint('Train/Sup_set_time_entry_range: ',df_temp['timestamp'].iloc[0], ' - ', df_temp['timestamp'].iloc[-1])\nprint()\nprint(df_temp['timestamp'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:28.191045Z","iopub.execute_input":"2022-02-03T20:58:28.192041Z","iopub.status.idle":"2022-02-03T20:58:29.327736Z","shell.execute_reply.started":"2022-02-03T20:58:28.191989Z","shell.execute_reply":"2022-02-03T20:58:29.326662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizaton (~ Raw)","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_style('darkgrid')\n\nfig, axs = plt.subplots(1,1, figsize=(16,12), dpi = 80)\n\nsns.histplot(data = df_temp.Asset_ID, color='black', discrete=True, ax = axs, stat = 'density', kde=False)\nplt.legend()\n\nplt.tight_layout(pad=2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:29.32934Z","iopub.execute_input":"2022-02-03T20:58:29.329593Z","iopub.status.idle":"2022-02-03T20:58:36.865254Z","shell.execute_reply.started":"2022-02-03T20:58:29.329564Z","shell.execute_reply":"2022-02-03T20:58:36.864093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntimestamp - A timestamp for the minute covered by the row.\nAsset_ID - An ID code for the cryptoasset.\nCount - The number of trades that took place this minute.\nOpen - The USD price at the beginning of the minute.\nHigh - The highest USD price during the minute.\nLow - The lowest USD price during the minute.\nClose - The USD price at the end of the minute.\nVolume - The number of cryptoasset units traded during the minute.\nVWAP - The volume weighted average price for the minute.\nTarget - Residual log-return over 15 minute time-data. See the 'Prediction and Evaluation' section of this notebook for details of how the target is calculated.\n'''\nprint('Done!')","metadata":{"execution":{"iopub.execute_input":"2022-02-03T20:24:34.145923Z","iopub.status.busy":"2022-02-03T20:24:34.145693Z","iopub.status.idle":"2022-02-03T20:24:34.152448Z","shell.execute_reply":"2022-02-03T20:24:34.151453Z","shell.execute_reply.started":"2022-02-03T20:24:34.145898Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display\nprint('Asset_Details: ')\nprint()\ndisplay(df_asset_details.head())\nprint('Sample_Submission: ')\nprint()\ndisplay(df_sub_sample.head())\nprint('Supplementary_train_samples: ')\nprint()\ndisplay(df_sup_train.head())\nprint('Train_samples: ')\nprint()\ndisplay(df_train.head())\nprint('--'*20)\nasset_info = df_sup_train.groupby('Asset_ID')['timestamp'].agg('count')\nprint(asset_info)\nprint('--'*20)\nprint(df_train.info())\nprint('--'*20)\nprint(df_train.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:36.867106Z","iopub.execute_input":"2022-02-03T20:58:36.86738Z","iopub.status.idle":"2022-02-03T20:58:37.12878Z","shell.execute_reply.started":"2022-02-03T20:58:36.867348Z","shell.execute_reply":"2022-02-03T20:58:37.127849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel df_train\ngc.collect()\ndf_train = df_temp[:]\nasset_info = df_train.groupby('Asset_ID')['timestamp']\nprint(asset_info.agg('value_counts'))\nasset_info_time = asset_info.agg('unique')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:37.130174Z","iopub.execute_input":"2022-02-03T20:58:37.130432Z","iopub.status.idle":"2022-02-03T20:58:40.194502Z","shell.execute_reply.started":"2022-02-03T20:58:37.130401Z","shell.execute_reply":"2022-02-03T20:58:40.193542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\ninv_asset_dict = { key:value for key, value in zip(df_asset_details['Asset_ID'],df_asset_details['Asset_Name'])}\npprint(inv_asset_dict)\n\nasset_name = list(inv_asset_dict)\nprint('num_assets: ', len(asset_name))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:40.195725Z","iopub.execute_input":"2022-02-03T20:58:40.195975Z","iopub.status.idle":"2022-02-03T20:58:40.209831Z","shell.execute_reply.started":"2022-02-03T20:58:40.195938Z","shell.execute_reply":"2022-02-03T20:58:40.208502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asset_info_open = df_train.groupby('Asset_ID')['Open']\nasset_info_open = asset_info_open.agg(lambda x: list(x)) ## using anonymous function to form a list of all gropued \nasset_info_close = df_train.groupby('Asset_ID')['Close']\nasset_info_close = asset_info_close.agg(lambda x: list(x)) ## using anonymous function to form a list of all gropued \nasset_info_high = df_train.groupby('Asset_ID')['High']\nasset_info_high = asset_info_high.agg(lambda x: list(x)) ## using anonymous function to form a list of all gropued \nasset_info_low = df_train.groupby('Asset_ID')['Low']\nasset_info_low = asset_info_low.agg(lambda x: list(x)) ## using anonymous function to form a list of all gropued \n\n## Asset_IDs\nprint(asset_info_open.head())\nprint()\nprint(asset_info_close.head())\nprint()\nprint(asset_info_high.head())\nprint()\nprint(asset_info_low.head())\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:40.211372Z","iopub.execute_input":"2022-02-03T20:58:40.212259Z","iopub.status.idle":"2022-02-03T20:58:47.905531Z","shell.execute_reply.started":"2022-02-03T20:58:40.212216Z","shell.execute_reply":"2022-02-03T20:58:47.904616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#'''## EDA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint('**'*20,'1000 mins | 16.66 hrs data_represented', '**'*20)\nprint()\nsns.set_style('darkgrid')\nfig, axs = plt.subplots(7,2, figsize=(16,14))\nstep = 0\nfor i in range(2):\n    for j in range(7):\n        axs[j,i].set_title(inv_asset_dict.get(step))\n        axs[j,i].scatter(asset_info_time[step][:1000],asset_info_open[step][:1000], color='red', marker='.', label = 'Open')\n        axs[j,i].scatter(asset_info_time[step][:1000],asset_info_close[step][:1000], color = 'yellow', alpha = 0.2, marker='.', label='Close')\n        axs[j,i].legend()\n        axs[j,i].set_xlabel('time')\n        axs[j,i].set_ylabel('Open/Close Price')\n        step+=1\n\nplt.tight_layout(pad=2)\n#'''\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:47.909535Z","iopub.execute_input":"2022-02-03T20:58:47.909807Z","iopub.status.idle":"2022-02-03T20:58:54.201444Z","shell.execute_reply.started":"2022-02-03T20:58:47.909775Z","shell.execute_reply":"2022-02-03T20:58:54.200725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#'''\nprint('**'*20,'1000 mins | 16.66 hrs data_represented', '**'*20)\nprint()\nsns.set_style('darkgrid')\nfig, axs = plt.subplots(7,2, figsize=(16,14))\nstep = 0\nfor i in range(2):\n    for j in range(7):\n        axs[j,i].set_title(inv_asset_dict.get(step))\n        axs[j,i].plot(asset_info_time[step][:1000],asset_info_high[step][:1000], ',b' ,label = 'High')\n        axs[j,i].plot(asset_info_time[step][:1000],asset_info_low[step][:1000], ',r',label='Low')\n        axs[j,i].legend()\n        step+=1\nplt.tight_layout(pad=2)#'''\n\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:54.20269Z","iopub.execute_input":"2022-02-03T20:58:54.203157Z","iopub.status.idle":"2022-02-03T20:58:58.499482Z","shell.execute_reply.started":"2022-02-03T20:58:54.203114Z","shell.execute_reply":"2022-02-03T20:58:58.49859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asset_info_count = df_train.groupby('Asset_ID')['Count']\nasset_info_count = asset_info_count.agg(lambda x: list(x))\nasset_info_vol = df_train.groupby('Asset_ID')['Volume']\nasset_info_vol = asset_info_vol.agg(lambda x: list(x)) \n\nprint(asset_info_count.head())\nprint()\nprint(asset_info_vol.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:58.501197Z","iopub.execute_input":"2022-02-03T20:58:58.501927Z","iopub.status.idle":"2022-02-03T20:59:02.297212Z","shell.execute_reply.started":"2022-02-03T20:58:58.501877Z","shell.execute_reply":"2022-02-03T20:59:02.296292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#'''\nprint()\nprint('**'*20,'|| Trades/Transactions per minute ||', '**'*20)\nprint()\nsns.set_style('darkgrid')\nfig, axs = plt.subplots(7,2, figsize=(20,18))\nstep = 0\nfor i in range(2):\n    for j in range(7):\n        axs[j,i].set_title(inv_asset_dict.get(step))\n        axs[j,i].bar(asset_info_time[step][:1000],asset_info_count[step][:1000], edgecolor = 'black')\n        axs[j,i].set_xlabel('timestamps')\n        axs[j,i].set_ylabel('Trade_Count')\n        step+=1\nplt.tight_layout(pad=2)\nplt.show()\nprint()\nprint('**'*20,'|| Volume per minute ||', '**'*20)\nprint()\nfig, axs = plt.subplots(7,2, figsize=(20,18))\nstep = 0\nfor i in range(2):\n    for j in range(7):\n        axs[j,i].set_title(inv_asset_dict.get(step))\n        axs[j,i].bar(asset_info_time[step][:1000],asset_info_vol[step][:1000], edgecolor = 'black')\n        axs[j,i].set_xlabel('timestamps')\n        axs[j,i].set_ylabel('Volume')\n        step+=1\nplt.tight_layout(pad=2)\nplt.show()\n#'''\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:59:02.298471Z","iopub.execute_input":"2022-02-03T20:59:02.298704Z","iopub.status.idle":"2022-02-03T21:00:12.974617Z","shell.execute_reply.started":"2022-02-03T20:59:02.298675Z","shell.execute_reply":"2022-02-03T21:00:12.973413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asset_info_targ = df_train.groupby('Asset_ID')['Target']\nasset_info_targ = asset_info_targ.agg(lambda x: list(x)) \n\nprint(asset_info_targ.head())\nasset_dict = {value:key for key, value in inv_asset_dict.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:12.976956Z","iopub.execute_input":"2022-02-03T21:00:12.977261Z","iopub.status.idle":"2022-02-03T21:00:15.003124Z","shell.execute_reply.started":"2022-02-03T21:00:12.977227Z","shell.execute_reply":"2022-02-03T21:00:15.002098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#'''\nimport random\nprint()\nprint('**'*20,'|| Residualised Return per minute ||', '**'*20)\nprint()\n\ncolors = ['cyan','green','red','blue','gold','red','black','orange','magenta','deeppink','lime','slategray','yellow','darkviolet'] ## all possible colors \nname_plot = ['Bitcoin', 'Ethereum', 'Dogecoin']\n\n\nfig, axs = plt.subplots(1,1, figsize=(18,14))\n#axs[0].set_title(inv_asset_dict.get(step))\nfor name in name_plot:\n    #step = random.randint(0,len(list(asset_dict))-1) ## random_sample 3 coins\n    step = asset_dict.get(name)\n    axs.plot(asset_info_time[step][:10000],asset_info_targ[step][:10000], c=colors[step], label=inv_asset_dict.get(step))\naxs.set_xlabel('Timestamps')\naxs.set_ylabel('Res. Returns')\naxs.legend()\n#plt.tight_layout(pad=2)\nplt.show()\n#'''\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:15.005053Z","iopub.execute_input":"2022-02-03T21:00:15.005507Z","iopub.status.idle":"2022-02-03T21:00:15.650877Z","shell.execute_reply.started":"2022-02-03T21:00:15.00546Z","shell.execute_reply":"2022-02-03T21:00:15.649754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_temp.info())\nprint('**'*40)\nprint(df_temp.isnull().sum())\nprint('**'*40)\ndf_temp_2 = df_temp.fillna(method = 'ffill')\nprint(df_temp_2.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:15.652731Z","iopub.execute_input":"2022-02-03T21:00:15.65306Z","iopub.status.idle":"2022-02-03T21:00:16.64379Z","shell.execute_reply.started":"2022-02-03T21:00:15.653018Z","shell.execute_reply":"2022-02-03T21:00:16.64244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Better-Visualization (~preprocessed)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport gc\n\ndf_sep_dict = {}\n\nprint('df_temp_2_shape : ', df_temp_2.shape)\n\nfor key in list(asset_dict):\n    asset_dict = {value:key for key, value in inv_asset_dict.items()}\n    mid = asset_dict[key]\n    df_mid = df_temp_2[df_temp_2['Asset_ID'] == mid] \n    df_mid.index = df_mid.timestamp\n    df_mid = df_mid.drop('timestamp', axis = 1)\n    print(key+' _before : ')\n    print((df_mid.index[1:] - df_mid.index[:-1]).value_counts().head())\n    df_mid = df_mid.reindex(range(df_mid.index[0], df_mid.index[-1]+60, 60), method = 'pad') ## gap filling in the continumm to a constant value\n    print()\n    print(key+' _after : ')\n    print((df_mid.index[1:] - df_mid.index[:-1]).value_counts().head())\n    df_sep_dict[key] = df_mid\n    print('**'*20)\n\n\ndel df_train\ndel df_temp    \ndel df_temp_2\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:16.645308Z","iopub.execute_input":"2022-02-03T21:00:16.645565Z","iopub.status.idle":"2022-02-03T21:00:21.220707Z","shell.execute_reply.started":"2022-02-03T21:00:16.645535Z","shell.execute_reply":"2022-02-03T21:00:21.219378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#'''\nfig, axs = plt.subplots(7,2, figsize=(24,18))\n\nreq_name = ['Bitcoin', 'Ethereum','Dogecoin']\nfor step, i in enumerate(df_asset_details['Asset_Name'].tolist()):\n    if step < 7:\n        axs[step,0].plot(df_sep_dict[i].index, df_sep_dict[i].Close, ',k')\n        axs[step,0].set_title(i + ' (Complete_train_space) ')\n        axs[step,0].set_xlabel('Time_Axis')\n        axs[step,0].set_ylabel('Closing_Price')\n    else:\n        axs[step-7,1].plot(df_sep_dict[i].index, df_sep_dict[i].Close, ',k')\n        axs[step-7,1].set_title(i + ' (Complete_train_space) ')\n        axs[step-7,1].set_xlabel('Time_Axis')\n        axs[step-7,1].set_ylabel('Closing_Price')\n\nplt.tight_layout(pad=2)\nplt.show()\n\nprint()\nprint('**'*20, 'VWAP_plot (on_complete_trian_space)', \"**\"*20)\nprint()\n\nfig, axs = plt.subplots(7,2, figsize=(24,18))\n\nreq_name = ['Bitcoin', 'Ethereum','Dogecoin']\nfor step, i in enumerate(df_asset_details['Asset_Name'].tolist()):\n    if step < 7:\n        axs[step,0].plot(df_sep_dict[i].index, df_sep_dict[i].VWAP, 'b')\n        axs[step,0].set_title(i + ' (Complete_train_space) ')\n        axs[step,0].set_xlabel('Time_Axis')\n        axs[step,0].set_ylabel('Closing_Price')\n    else:\n        axs[step-7,1].plot(df_sep_dict[i].index, df_sep_dict[i].VWAP, 'b')\n        axs[step-7,1].set_title(i + ' (Complete_train_space) ')\n        axs[step-7,1].set_xlabel('Time_Axis')\n        axs[step-7,1].set_ylabel('Closing_Price')\n\nplt.tight_layout(pad=2)\nplt.show()\n#'''\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:21.224831Z","iopub.execute_input":"2022-02-03T21:00:21.225143Z","iopub.status.idle":"2022-02-03T21:00:31.591202Z","shell.execute_reply.started":"2022-02-03T21:00:21.2251Z","shell.execute_reply":"2022-02-03T21:00:31.589884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport warnings \nwarnings.filterwarnings('ignore')\n\ntpu  = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strat = tf.distribute.TPUStrategy(tpu)\n\nprint(\"Number of accelerators: \", tpu_strat.num_replicas_in_sync)","metadata":{"execution":{"iopub.execute_input":"2022-02-03T20:26:39.317579Z","iopub.status.busy":"2022-02-03T20:26:39.317325Z","iopub.status.idle":"2022-02-03T20:26:51.655416Z","shell.execute_reply":"2022-02-03T20:26:51.654802Z","shell.execute_reply.started":"2022-02-03T20:26:39.317553Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n''' Dumping the Data '''\n# dict_file = open('BTC_dict_data(last_btc_520k).pkl', 'wb')\n# pickle.dump(df_sep_dict['Bitcoin'], dict_file)\n# dict_file.close()\n\ndict_file = open('../input/520k-btc-only/BTC_dict_data(last_btc_520k).pkl', 'rb')\ndf_btc = pickle.load(dict_file)\ndict_file.close()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:31.592945Z","iopub.execute_input":"2022-02-03T21:00:31.59373Z","iopub.status.idle":"2022-02-03T21:00:32.640904Z","shell.execute_reply.started":"2022-02-03T21:00:31.593681Z","shell.execute_reply":"2022-02-03T21:00:32.639674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf_btc.index = pd.date_range('2020-12-28', periods = len(df_btc), freq='min') # use freq = 'min' to get minute data","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:32.642459Z","iopub.execute_input":"2022-02-03T21:00:32.642697Z","iopub.status.idle":"2022-02-03T21:00:32.650984Z","shell.execute_reply.started":"2022-02-03T21:00:32.642669Z","shell.execute_reply":"2022-02-03T21:00:32.650288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_btc.Close.plot(figsize=(16,12)) ## They daily update the data to recent one | last year data","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:32.652362Z","iopub.execute_input":"2022-02-03T21:00:32.653176Z","iopub.status.idle":"2022-02-03T21:00:41.526359Z","shell.execute_reply.started":"2022-02-03T21:00:32.653127Z","shell.execute_reply":"2022-02-03T21:00:41.524828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndf_btc.loc['2021-11-1':].Close.plot(figsize=(16,12)) #localising recent past \ndf_btc.iloc[-50000:].Close.plot(figsize=(16,12), c='r', alpha=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:41.529107Z","iopub.execute_input":"2022-02-03T21:00:41.529555Z","iopub.status.idle":"2022-02-03T21:00:43.602817Z","shell.execute_reply.started":"2022-02-03T21:00:41.529509Z","shell.execute_reply":"2022-02-03T21:00:43.601416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_col_order = ['Count','Open','High','Low','Volume','VWAP','Target','Close']\n\n\ndisplay(df_btc.head())\ndf_btc = df_btc.reindex(columns = new_col_order)\ndisplay(df_btc.head())\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:43.605363Z","iopub.execute_input":"2022-02-03T21:00:43.605841Z","iopub.status.idle":"2022-02-03T21:00:43.674711Z","shell.execute_reply.started":"2022-02-03T21:00:43.605807Z","shell.execute_reply":"2022-02-03T21:00:43.673046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_btc.iloc[-50000:].Close.plot(figsize=(10,8))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:43.677487Z","iopub.execute_input":"2022-02-03T21:00:43.677762Z","iopub.status.idle":"2022-02-03T21:00:46.321986Z","shell.execute_reply.started":"2022-02-03T21:00:43.677729Z","shell.execute_reply":"2022-02-03T21:00:46.32058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport gc\nimport math as mt\n\nseed = 28\nnp.random.seed(seed)\n\n\ndef Data_func(data, past, delay, minn, maxx = None, shuffle=False, batch_size=128, rate=6):\n    if maxx is None:\n        maxx = len(data) - delay -1\n    i = minn + past\n    batch_no = 1\n\n    while True:\n\n        if shuffle:\n            rows = np.random.randint(minn + past, maxx, size = batch_size)\n        else:\n            rows = np.arange(i, min(i + batch_size, maxx))\n        \n        i+=len(rows)\n        if i + batch_size > maxx: ## when you increase the past too much this statement gets executed at the first batch creation // add more data to overcome\n            break\n        \n        samples = np.zeros((len(rows), past // rate, data.shape[-1]))\n        targets = np.zeros((len(rows),))\n        cbase_preds = np.zeros((len(rows),))\n    \n        for j, row in enumerate(rows):\n            \n            indices = range(rows[j] - past, rows[j], rate) ## take every point\n            samples[j] = data[indices]\n            targets[j] = data[rows[j] + delay - 1][-1]\n       \n        if batch_no == 1:\n            print('im here')\n            new_sample = samples\n            new_targets = targets\n            print('Ini_samples: ', samples.shape, 'Ini_targets: ', targets.shape)\n        else:\n            new_sample = np.concatenate([new_sample, samples], axis=0)\n            new_targets = np.concatenate([new_targets, targets], axis=0)\n        batch_no+=1\n        \n    return new_sample, new_targets\n\ndef Baseline_func(data, past, delay, minn, maxx = None , shuffle=False, batch_size=128, rate=6):\n    if maxx is None:\n        maxx = len(data) - delay -1\n    i = minn + past\n    batch_no = 1\n\n    while True:\n\n        if shuffle:\n            rows = np.random.randint(minn + past, maxx, size = batch_size)\n        else:\n            rows = np.arange(i, min(i + batch_size, maxx))\n        \n        i+=len(rows)\n        if i + batch_size > maxx:\n            break\n        \n        cbase_preds = np.zeros((len(rows),))\n        \n        for j, row in enumerate(rows):\n            cbase_preds[j] = data[rows[j]][-1]\n            \n        if batch_no == 1:\n            new_cbase_preds = cbase_preds\n            print('Ini_cbase_pred: ', new_cbase_preds.shape)\n        else:\n            new_cbase_preds = np.concatenate([new_cbase_preds, cbase_preds], axis=0)\n        batch_no+=1\n        \n    return new_cbase_preds\n\n\n\n#'''    \nx_train = df_btc.iloc[-50000:].copy() ## Localising training => prediction space\n\nprint()\nx_train = x_train.to_numpy()\n\nprint('BTC_train: ',x_train.shape)\n\npast = 360 ## ==>> looks !1 but 6hrs days back \n\n''' The problem statement involves being able to predict next 15 mins (very much possible!) residualized returns | NO DELAY '''\n''' Target 15 datapoints from current point'''\ndelay = 0 ## Targeting after 15 mins | NOT correctt implementation \n\ntrain_split, test_split = 0.60, 0.25\ntrain_max = round(train_split * x_train.shape[0])\nval_max = (1-train_split)*x_train.shape[0]\ntest_max = round(test_split*val_max)\nval_max = round(val_max - test_max)\n\n''' use batch_size = 15 in accordance to the problem statement'''\nbs = 15\n\nmean = x_train[:train_max].mean(axis = 0)\nx_train -= mean\nstd = x_train[:train_max].std(axis = 0)\nx_train /= std\n\nval_steps =  (train_max+val_max) - (train_max+1) - past ## (-past) because no target values for last  720 points\ntest_steps = (train_max+val_max+test_max)-(train_max+val_max+1) - past\n\nprint('Train_Max: ', mt.floor(train_max),', Val_Max: ', mt.floor(val_max),', Test_Max: ', mt.floor(test_max))\nprint()\n#'''        \ntrain_data = Data_func(x_train, past, delay, minn = 0, maxx = train_max - 1, batch_size=bs, shuffle=True, rate=5) ## sampling data every 5 minutes\ncbase_train_data = Baseline_func(x_train, past, delay, minn = 0, maxx = train_max - 1, batch_size=bs, shuffle=True, rate=5) ## sampling data every 5 minutes\n\ntemp, _ = train_data\nprint('--'*20)\nprint('Done - Train_data: ', temp.shape)\nprint('Cbase_data: ', cbase_train_data.shape)\nprint('--'*20)\nval_data = Data_func(x_train, past, delay, minn = train_max+1, maxx = train_max + val_max - 1, batch_size=bs, rate=5)\ncbase_val_data = Baseline_func(x_train, past, delay, minn = train_max+1, maxx = train_max + val_max - 1, batch_size= bs, rate=5)\n\ntemp, _ = val_data \nprint('--'*20)\nprint('Done - Val_data: ', temp.shape)\nprint('Cbase_data: ', cbase_val_data.shape)\nprint('--'*20)\n#'''\ntest_data = Data_func(x_train, past, delay, minn = train_max+val_max+1, batch_size=bs, rate = 5)\ncbase_test_data = Baseline_func(x_train, past, delay, minn = train_max+val_max+1, batch_size= bs, rate = 5)\n\ntemp, _ = test_data\nprint('--'*20)\nprint('Done - Test_data: ', temp.shape)\nprint('Cbase_data: ', cbase_test_data.shape)\nprint('--'*20)\n\ntrain_sample, train_label = train_data ## sample contains return \nval_sample, val_label = val_data\ntest_sample, test_label = test_data\n\ndel temp\ndel train_data\ndel val_data\ndel test_data\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:00:46.324404Z","iopub.execute_input":"2022-02-03T21:00:46.325352Z","iopub.status.idle":"2022-02-03T21:02:11.275601Z","shell.execute_reply.started":"2022-02-03T21:00:46.325272Z","shell.execute_reply":"2022-02-03T21:02:11.274411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport gc\n\nprint('train_sample: ', train_sample.shape, 'train_label: ', train_label.shape)\ntr_dataset = tf.data.Dataset.from_tensor_slices((train_sample, train_label)).repeat().batch(bs) #.cache().prefetch(tf.data.AUTOTUNE) ## use repeat() before batching while using TPU\nval_dataset = tf.data.Dataset.from_tensor_slices((val_sample, val_label)).repeat().batch(bs) #.cache().prefetch(tf.data.AUTOTUNE)\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_sample, test_label)).repeat().batch(bs) #.cache().prefetch(tf.data.AUTOTUNE)\ndel train_sample \ndel train_label\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:11.277156Z","iopub.execute_input":"2022-02-03T21:02:11.27745Z","iopub.status.idle":"2022-02-03T21:02:12.645047Z","shell.execute_reply.started":"2022-02-03T21:02:11.277374Z","shell.execute_reply":"2022-02-03T21:02:12.644021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### CommonSense Model\nimport numpy as np\nfrom statsmodels.tools.eval_measures import meanabs, rmse\n\ntarget_std = np.std(val_label)\n\n'''always predicting the current return to be the 15 min later return '''\n\nprint('CommonSense - BaseLines - MAE -----')\nprint()\nprint('__Val__')\n## using present info (latest info) as our prediction after 'delay' mins\nprint('MAE: ',meanabs(cbase_val_data, val_label))\nprint('RMSE: ', rmse(cbase_val_data, val_label))\nprint()\nprint('__Test__')\n## using present info (latest info) as our prediction after 'delay' mins\nprint('MAE: ',meanabs(cbase_test_data, test_label))\nprint('RMSE: ', rmse(cbase_test_data, test_label))\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:12.648625Z","iopub.execute_input":"2022-02-03T21:02:12.649242Z","iopub.status.idle":"2022-02-03T21:02:12.678969Z","shell.execute_reply.started":"2022-02-03T21:02:12.6492Z","shell.execute_reply":"2022-02-03T21:02:12.67798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('darkgrid')\n\nfig, axs = plt.subplots(1,1, figsize = (15,8))\n\naxs.plot(np.arange(0,1500), cbase_test_data[:1500], label = 'Common_Baseline') \naxs.plot(np.arange(0,1500), test_label[:1500], label = 'Real_Data')\naxs.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:12.683709Z","iopub.execute_input":"2022-02-03T21:02:12.684424Z","iopub.status.idle":"2022-02-03T21:02:12.9639Z","shell.execute_reply.started":"2022-02-03T21:02:12.68436Z","shell.execute_reply":"2022-02-03T21:02:12.963227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### USE DNN and 1D_CNN + RNN","metadata":{}},{"cell_type":"code","source":"dnn_model = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=(72,8)),\n    tf.keras.layers.Dense(128, activation = 'linear'),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(128, activation = 'relu'),\n    tf.keras.layers.Dense(1)\n    \n])\nes = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\ndnn_model.compile(optimizer='Adam', loss='mse', metrics=['mae'])\ndnn_model.fit(tr_dataset, epochs=50, validation_data = val_dataset, validation_steps = val_steps, steps_per_epoch =128, callbacks=[es])\nprint('Training_Done ... ')","metadata":{"execution":{"iopub.execute_input":"2022-02-02T11:59:49.449572Z","iopub.status.busy":"2022-02-02T11:59:49.449008Z","iopub.status.idle":"2022-02-02T12:05:46.549982Z","shell.execute_reply":"2022-02-02T12:05:46.548985Z","shell.execute_reply.started":"2022-02-02T11:59:49.449529Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dnn_model = tf.keras.models.load_model('../input/all-models/dnn_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:12.965101Z","iopub.execute_input":"2022-02-03T21:02:12.965446Z","iopub.status.idle":"2022-02-03T21:02:14.409432Z","shell.execute_reply.started":"2022-02-03T21:02:12.965417Z","shell.execute_reply":"2022-02-03T21:02:14.408293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dnn_model.evaluate(val_dataset, steps=128))\nprint(dnn_model.evaluate(test_dataset, steps=128))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:14.410982Z","iopub.execute_input":"2022-02-03T21:02:14.411342Z","iopub.status.idle":"2022-02-03T21:02:16.077367Z","shell.execute_reply.started":"2022-02-03T21:02:14.411299Z","shell.execute_reply":"2022-02-03T21:02:16.07616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_data = [(sample, target) for sample, target in test_dataset.take(1)]\ntest_sample, test_target = test_pred_data[0] ## next 32 data-points | accounting for 32 mins prediction\nx_lin = np.arange(0,test_target.shape[0]) \ndef inv_norm(test_target):\n    test_target = np.ravel(test_target)\n    test_target = test_target * std[-1]\n    test_target = test_target + mean[-1]\n    return test_target\n\ntest_pred = dnn_model.predict(test_sample)\ninv_test_pred = inv_norm(test_pred)\n# test_pred_parent = inv_stdn(parent_model.predict(test_sample))\ninv_test_target = inv_norm(test_target)\n\nfig = plt.figure(figsize=(15,8))\nplt.plot(x_lin, inv_test_target, 'k', label = 'test')\nplt.plot(x_lin, inv_test_pred, 'r',  label = 'dnn_model')\n# plt.plot(x_lin, test_pred_parent, 'g', label = 'parent_model')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:16.080837Z","iopub.execute_input":"2022-02-03T21:02:16.081243Z","iopub.status.idle":"2022-02-03T21:02:16.578967Z","shell.execute_reply.started":"2022-02-03T21:02:16.081211Z","shell.execute_reply":"2022-02-03T21:02:16.578108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tools.eval_measures import meanabs\n\nprint('MAE: ', meanabs(inv_test_target, inv_test_pred))\nprint('Mean_target: ', np.mean(inv_test_target))\nprint('Mean_P_Error: ', (meanabs(inv_test_target, inv_test_pred) / np.mean(inv_test_target)) * 100, '%')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:16.580712Z","iopub.execute_input":"2022-02-03T21:02:16.581912Z","iopub.status.idle":"2022-02-03T21:02:16.590878Z","shell.execute_reply.started":"2022-02-03T21:02:16.581859Z","shell.execute_reply":"2022-02-03T21:02:16.590173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dnn_model.save('./dnn_model.h5')","metadata":{"execution":{"iopub.execute_input":"2022-02-02T12:05:49.46005Z","iopub.status.busy":"2022-02-02T12:05:49.459797Z","iopub.status.idle":"2022-02-02T12:05:49.528366Z","shell.execute_reply":"2022-02-02T12:05:49.527637Z","shell.execute_reply.started":"2022-02-02T12:05:49.46002Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_rnn_model = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=(72,8)),\n    tf.keras.layers.Conv1D(128, 5),\n    tf.keras.layers.Dense(264, activation='relu'),\n    tf.keras.layers.GRU(264, return_sequences=True),\n    tf.keras.layers.GRU(264),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1)\n]) \n\ncnn_rnn_model.compile(optimizer='Adam', loss='mse', metrics=['mae'])\ncnn_rnn_model.summary()\n\nes = tf.keras.callbacks.EarlyStopping(patience=5)\ncnn_rnn_model.fit(tr_dataset, epochs=20, validation_data = val_dataset, validation_steps = val_steps, steps_per_epoch =128, callbacks=[es])\nprint('Training_Done...')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_rnn_model = tf.keras.models.load_model('../input/all-models/cnn_rnn_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:16.592126Z","iopub.execute_input":"2022-02-03T21:02:16.592361Z","iopub.status.idle":"2022-02-03T21:02:17.551603Z","shell.execute_reply.started":"2022-02-03T21:02:16.592332Z","shell.execute_reply":"2022-02-03T21:02:17.550801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cnn_rnn_model.evaluate(val_dataset, steps=128))\nprint(cnn_rnn_model.evaluate(test_dataset, steps=128))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:17.553224Z","iopub.execute_input":"2022-02-03T21:02:17.553675Z","iopub.status.idle":"2022-02-03T21:02:42.079513Z","shell.execute_reply.started":"2022-02-03T21:02:17.553642Z","shell.execute_reply":"2022-02-03T21:02:42.078188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_rnn_model.save('./cnn_rnn_model.h5')\nprint('saved cnn_rnn_model')","metadata":{"execution":{"iopub.execute_input":"2022-02-03T20:28:15.028034Z","iopub.status.busy":"2022-02-03T20:28:15.027641Z","iopub.status.idle":"2022-02-03T20:28:15.142517Z","shell.execute_reply":"2022-02-03T20:28:15.141618Z","shell.execute_reply.started":"2022-02-03T20:28:15.027994Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_data = [(sample, target) for sample, target in test_dataset.take(1)]\ntest_sample, test_target = test_pred_data[0] ##after validation set => next 32 datapoints | accounting for next 32 min prediction\nx_lin = np.arange(0,test_target.shape[0]) \ndef inv_norm(test_target):\n    test_target = np.ravel(test_target)\n    test_target = test_target * std[-1]\n    test_target = test_target + mean[-1]\n    return test_target\n\ntest_pred = cnn_rnn_model.predict(test_sample)\ninv_test_pred = inv_norm(test_pred)\n# test_pred_parent = inv_stdn(parent_model.predict(test_sample))\ninv_test_target = inv_norm(test_target)\n\nfig = plt.figure(figsize=(15,8))\nplt.plot(x_lin, inv_test_target, 'k', label = 'test')\nplt.plot(x_lin, inv_test_pred, 'r',  label = 'dnn_model')\n# plt.plot(x_lin, test_pred_parent, 'g', label = 'parent_model')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:42.081444Z","iopub.execute_input":"2022-02-03T21:02:42.081726Z","iopub.status.idle":"2022-02-03T21:02:43.307162Z","shell.execute_reply.started":"2022-02-03T21:02:42.081689Z","shell.execute_reply":"2022-02-03T21:02:43.306145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('MAE: $ ' + str(meanabs(inv_test_target, inv_test_pred)))\nprint('Mean_target: $ ' + str(np.mean(inv_test_target)))\nprint('Mean_P_Error: ', (meanabs(inv_test_target, inv_test_pred) / np.mean(inv_test_target)) * 100, '%')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:43.308395Z","iopub.execute_input":"2022-02-03T21:02:43.308605Z","iopub.status.idle":"2022-02-03T21:02:43.315312Z","shell.execute_reply.started":"2022-02-03T21:02:43.308579Z","shell.execute_reply":"2022-02-03T21:02:43.314269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### EXtended PREDiction | For DNN Model","metadata":{}},{"cell_type":"code","source":"test_pred_data = [(sample, target) for sample, target in test_dataset.take(3)]\n\ntest_list, target_list = test_pred_data[0]\n\nfor x_test, x_test_target in test_pred_data[1:]:\n    test_list = tf.concat([test_list, x_test], axis=0)\n    target_list = tf.concat([target_list, x_test_target], axis=0)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:43.317145Z","iopub.execute_input":"2022-02-03T21:02:43.318252Z","iopub.status.idle":"2022-02-03T21:02:43.347868Z","shell.execute_reply.started":"2022-02-03T21:02:43.318197Z","shell.execute_reply":"2022-02-03T21:02:43.34715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_lin = np.arange(0,target_list.shape[0]) \ntest_pred = dnn_model.predict(test_list)\n\nprint('Prediction_Shape: ', test_pred.shape,'Target_Shape: ',target_list.shape)\n\ndef inv_norm(test_target):\n    test_target = np.ravel(test_target)\n    test_target = test_target * std[-1]\n    test_target = test_target + mean[-1]\n    return test_target\n\ninv_target_list = inv_norm(target_list)\ninv_test_pred = inv_norm(test_pred)\n\nfig = plt.figure(figsize=(15,8))\nplt.plot(x_lin, inv_target_list, 'k', label = 'test')\nplt.plot(x_lin, inv_test_pred, 'r',  label = 'dnn_model')\n# plt.plot(x_lin, test_pred_parent, 'g', label = 'parent_model')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:43.349236Z","iopub.execute_input":"2022-02-03T21:02:43.349839Z","iopub.status.idle":"2022-02-03T21:02:43.691692Z","shell.execute_reply.started":"2022-02-03T21:02:43.3498Z","shell.execute_reply":"2022-02-03T21:02:43.690775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tools.eval_measures import rmse\n\nprint('MAE: $ ' + str(meanabs(inv_target_list, inv_test_pred)))\nprint('Mean_target: $ ' + str(np.mean(inv_target_list)))\nprint('Mean_P_Error: ', (meanabs(inv_target_list, inv_test_pred) / np.mean(inv_target_list)) * 100, '%')\n\nprint('RMSE: $ ' + str(rmse(inv_target_list, inv_test_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:02:43.693572Z","iopub.execute_input":"2022-02-03T21:02:43.693829Z","iopub.status.idle":"2022-02-03T21:02:43.701959Z","shell.execute_reply.started":"2022-02-03T21:02:43.693791Z","shell.execute_reply":"2022-02-03T21:02:43.701104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SESSION STOPPER","metadata":{}},{"cell_type":"code","source":"import time\nfor i in range(50):\n    print('Time: ', i)\n    time.sleep(30*60)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T11:25:33.50067Z","iopub.status.idle":"2022-02-02T11:25:33.501584Z","shell.execute_reply":"2022-02-02T11:25:33.501307Z","shell.execute_reply.started":"2022-02-02T11:25:33.501279Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well thats it for now... next we will use Some advanced Sequential models & some financial models for gaining insights + forecasting  ","metadata":{}},{"cell_type":"code","source":"'''import gresearch_crypto as gs\nenv = gs.make_env()\niter_test = env.iter_test()\nfor (test_df, _) in iter_test:\n    sample_prediction_df['Target'] = 0  \n    env.predict(sample_prediction_df)'''","metadata":{"execution":{"iopub.status.busy":"2021-12-13T03:42:20.033281Z","iopub.status.idle":"2021-12-13T03:42:20.033932Z","shell.execute_reply":"2021-12-13T03:42:20.033693Z","shell.execute_reply.started":"2021-12-13T03:42:20.033666Z"}},"execution_count":null,"outputs":[]}]}