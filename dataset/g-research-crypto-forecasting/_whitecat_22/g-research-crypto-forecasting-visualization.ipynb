{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 各暗号資産につき一目均衡表を作成する（日足：2021/01/01-2021/06/13）","metadata":{}},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"# Install \"TA-Lib\"\n!cp ../input/talib/ta-lib-0.4.0-src.tar.gzh  ./ta-lib-0.4.0-src.tar.gz\n!tar -xzvf ta-lib-0.4.0-src.tar.gz > null\n!cd ta-lib && ./configure --prefix=/usr > null && make  > null && make install > null\n\n!cp ../input/talib/TA-Lib-0.4.21.tar.gzh TA-Lib-0.4.21.tar.gz\n!pip install TA-Lib-0.4.21.tar.gz\n!pip install ../input/talib/numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nimport talib as ta","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mplfinance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nimport time\n\nimport datetime\nimport math\n\nimport mplfinance as mpf\nimport talib as ta\nfrom decimal import Decimal, ROUND_HALF_UP\n\n# Warningの無効化\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n# データフレームcolumの全表示\npd.set_option(\"display.max_columns\", None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"df_asset_details = pd.read_csv(r\"../input/g-research-crypto-forecasting/asset_details.csv\").sort_values(\"Asset_ID\")\ndf_asset_details","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        # else:\n            # df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_csv_strict(file_name=\"/kaggle/input/g-research-crypto-forecasting/train.csv\"):\n    df = pd.read_csv(file_name).pipe(reduce_mem_usage)\n    df[\"datetime\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n    df = df[\"2021-01-01 00:00:00\" <= df[\"datetime\"]]\n    df = df[df[\"datetime\"] < \"2021-06-13 00:00:00\"]\n    df = df.sort_values(\"datetime\")\n    date = df[\"datetime\"]\n    df[\"day\"] = date.dt.strftime(\"%Y-%m-%d\")\n    #date = df.index\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = read_csv_strict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"code","source":"def convert_ohclv(df):\n\n    # まとめる足：分単位\n    chart_term = 1440    # \n\n    # 日付のリスト\n    origin_day = df.groupby(\"day\").mean().index\n\n    # 結果リスト\n    result_list = []\n\n    # 日付の繰り返し\n    for day in origin_day:\n\n        day_df = df[df[\"day\"] == day]\n\n        start_time = pd.to_datetime(day)\n        for i in range(math.ceil(len(day_df) / chart_term)):\n            end_time = start_time + datetime.timedelta(minutes=chart_term-1)\n            term_df = day_df[(day_df[\"datetime\"]>=start_time) & (day_df[\"datetime\"]<=end_time)]\n            if len(term_df) == 0:\n                continue\n\n            # 列ごとのデータ\n            open = term_df[\"Open\"].values[0]\n            close = term_df[\"Close\"].values[-1]\n            high = term_df.max()[\"High\"]\n            low = term_df.min()[\"Low\"]\n            volume = term_df.sum()[\"Volume\"]\n\n            result_list.append([start_time, open, high, low, close, volume])\n\n            # 次ループのために開始時間追加\n            start_time = start_time + datetime.timedelta(minutes=chart_term)\n\n    # 結果\n    result_df = pd.DataFrame(result_list)\n    result_df.columns = [\"datetime\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n    result_df = result_df.sort_values(\"datetime\")\n\n    # CSV書き込み\n    #result_df.to_csv(\"書き出すCSVファイルのパス\")\n    return result_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_stock_chart_image(df, asset_name):\n    # 基準線\n    high = df[\"High\"]\n    low = df[\"Low\"]\n\n    max26 = high.rolling(window=26).max()\n    min26 = low.rolling(window=26).min()\n\n    df[\"basic_line\"] = (max26 + min26) / 2\n\n    # 転換線\n    high9 = high.rolling(window=9).max()\n    low9 = low.rolling(window=9).min()\n\n    df[\"turn_line\"] = (high9 + low9) / 2\n\n    # 雲形\n    df[\"span1\"] = (df[\"basic_line\"] + df[\"turn_line\"]) / 2\n\n    high52 = high.rolling(window=52).max()\n    low52 = low.rolling(window=52).min()\n\n    df[\"span2\"] = (high52 + low52) / 2\n\n    # 遅行線\n    df[\"slow_line\"] = df[\"Close\"].shift(-25)\n\n    # ボリンジャーバンド用のdataframe追加\n    df[\"upper\"], df[\"middle\"], df[\"lower\"] = ta.BBANDS(\n        df[\"Close\"], timeperiod=25, nbdevup=2, nbdevdn=2, matype=0)\n\n    # MACD用のdataframe追加\n    df[\"macd\"], df[\"macdsignal\"], df[\"macdhist\"] = ta.MACD(\n        df[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n\n    # RSIデータフレーム追加\n    df[\"RSI\"] = ta.RSI(df[\"Close\"], timeperiod=25)\n\n    # 基準線、転換線、雲、遅行線の追加\n    apds = [mpf.make_addplot(df[\"upper\"], color=\"g\"),\n            mpf.make_addplot(df[\"middle\"], color=\"b\"),\n            mpf.make_addplot(df[\"lower\"], color=\"r\"),\n            mpf.make_addplot(df[\"macdhist\"], type=\"bar\",\n                             width=1.0, panel=1, color=\"gray\", alpha=0.5, ylabel=\"MACD\"),\n            mpf.make_addplot(df[\"RSI\"], panel=2,\n                             type=\"line\", ylabel=\"RSI\"),\n            mpf.make_addplot(df[\"basic_line\"]),  # 基準線\n            mpf.make_addplot(df[\"turn_line\"]),  # 転換線\n            mpf.make_addplot(df[\"slow_line\"]),  # 遅行線\n            ]\n\n    labels = [\"basic\", \"turn\", \"slow\", \"span\"]\n\n    fig, ax = mpf.plot(df, type=\"candle\", figsize=(16, 9), title=(asset_name),\n                       style=\"yahoo\", xrotation=0, volume=True, addplot=apds, returnfig=True,\n                       volume_panel=3, panel_ratios=(5, 2, 2, 1),\n                       fill_between=dict(\n                           y1=df[\"span1\"].values, y2=df[\"span2\"].values, alpha=0.5, color=\"gray\"),\n                       #savefig=f\"chart_{asset_id}.png\"\n                       )\n    ax[0].legend(labels)\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_Xy_and_model_for_asset(df_train, asset_id, asset_name):\n    df = df_train[df_train[\"Asset_ID\"] == asset_id]\n    df = convert_ohclv(df)\n    df = df.set_index(\"datetime\")\n    date = df.index\n    generate_stock_chart_image(df, asset_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for asset_id, asset_name in zip(df_asset_details[\"Asset_ID\"], df_asset_details[\"Asset_Name\"]):\n    print(f\"Visualizing for  {asset_name:<16} (ID={asset_id:<2})\")\n    get_Xy_and_model_for_asset(df_train, asset_id, asset_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}