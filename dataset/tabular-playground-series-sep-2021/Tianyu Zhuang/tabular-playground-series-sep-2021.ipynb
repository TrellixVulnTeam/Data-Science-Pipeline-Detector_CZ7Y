{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T05:27:53.768306Z","iopub.execute_input":"2021-09-09T05:27:53.768787Z","iopub.status.idle":"2021-09-09T05:27:53.784852Z","shell.execute_reply.started":"2021-09-09T05:27:53.768686Z","shell.execute_reply":"2021-09-09T05:27:53.783635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport time\ndf_train = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv',index_col='id')\ndf_test =  pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/test.csv',index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:27:53.786666Z","iopub.execute_input":"2021-09-09T05:27:53.787008Z","iopub.status.idle":"2021-09-09T05:28:39.495382Z","shell.execute_reply.started":"2021-09-09T05:27:53.786972Z","shell.execute_reply":"2021-09-09T05:28:39.494206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func_null(df):\n    \"Statistic the proportion of missing values\"\n    df_null = pd.DataFrame()\n    df_null['count'] = df.isnull().sum()\n    df_null['pct'] = df_null['count']/df.shape[0]\n    df_null['pct'] = df_null['pct']*100\n    df_null = df_null.sort_values(by='count',ascending=False)\n    return df_null\nfunc_null(df_train)\n#func_null(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:28:39.497578Z","iopub.execute_input":"2021-09-09T05:28:39.497988Z","iopub.status.idle":"2021-09-09T05:28:39.805553Z","shell.execute_reply.started":"2021-09-09T05:28:39.497943Z","shell.execute_reply":"2021-09-09T05:28:39.804533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = df_train.copy()\ndata_test = df_test.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:28:39.807188Z","iopub.execute_input":"2021-09-09T05:28:39.807537Z","iopub.status.idle":"2021-09-09T05:28:40.620928Z","shell.execute_reply.started":"2021-09-09T05:28:39.807503Z","shell.execute_reply":"2021-09-09T05:28:40.619697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quantitative = data_train.columns.tolist()\nquantitative.remove('claim')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:28:40.622593Z","iopub.execute_input":"2021-09-09T05:28:40.622914Z","iopub.status.idle":"2021-09-09T05:28:40.628277Z","shell.execute_reply.started":"2021-09-09T05:28:40.622882Z","shell.execute_reply":"2021-09-09T05:28:40.627102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['N_missing'] = data_train[quantitative].isnull().sum(axis=1)\ndata_test['N_missing'] = data_test[quantitative].isnull().sum(axis=1)\nquantitative.append('N_missing')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:28:40.629731Z","iopub.execute_input":"2021-09-09T05:28:40.630042Z","iopub.status.idle":"2021-09-09T05:28:41.610796Z","shell.execute_reply.started":"2021-09-09T05:28:40.630014Z","shell.execute_reply":"2021-09-09T05:28:41.609582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer,KNNImputer\nfrom sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler,QuantileTransformer\n\nimp = SimpleImputer(missing_values=np.nan,strategy='constant')\n#imp = KNNImputer()\ndata_train = pd.DataFrame(data=imp.fit_transform(data_train[quantitative]),columns=data_train[quantitative].columns,index=data_train.index)\ndata_test = pd.DataFrame(data=imp.transform(data_test[quantitative]),columns=data_test[quantitative].columns,index=data_test.index)\npreprocessing = StandardScaler()\ndata_train = pd.DataFrame(data=preprocessing.fit_transform(data_train[quantitative]),columns=data_train[quantitative].columns,index=data_train.index)\ndata_test = pd.DataFrame(data=preprocessing.transform(data_test[quantitative]),columns=data_test[quantitative].columns,index=data_test.index)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:28:41.612646Z","iopub.execute_input":"2021-09-09T05:28:41.613051Z","iopub.status.idle":"2021-09-09T05:28:53.4682Z","shell.execute_reply.started":"2021-09-09T05:28:41.613004Z","shell.execute_reply":"2021-09-09T05:28:53.467078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quantitative.remove('N_missing')\ndata_train['min_row'] = data_train[quantitative].min(axis=1)\ndata_train['max_row'] = data_train[quantitative].max(axis=1)\ndata_train['mean_row'] = data_train[quantitative].mean(axis=1)\ndata_train['std_row'] = data_train[quantitative].std(axis=1)\n\ndata_test['min_row'] = data_test[quantitative].min(axis=1)\ndata_test['max_row'] = data_test[quantitative].max(axis=1)\ndata_test['mean_row'] = data_test[quantitative].mean(axis=1)\ndata_test['std_row'] = data_test[quantitative].std(axis=1)\n\nquantitative = quantitative + ['N_missing','min_row','max_row','mean_row','std_row']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split,cross_val_score\nimport lightgbm as lgb\n\nprint('start cross-validation !!!')\nX_train = data_train[quantitative]\nX_test = data_test[quantitative]\ny = df_train['claim']\n\nmodel = lgb.LGBMClassifier()\nstart=time.time()\nt_0 = cross_val_score(model,X_train,y,cv=3,scoring='roc_auc')\nprint('param_trial_RMSE:%.4f'%(t_0.mean()))\nend=time.time()\nprint('Running time: %s Seconds'%(end-start))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:28:53.470498Z","iopub.execute_input":"2021-09-09T05:28:53.470917Z","iopub.status.idle":"2021-09-09T05:29:11.22473Z","shell.execute_reply.started":"2021-09-09T05:28:53.470874Z","shell.execute_reply":"2021-09-09T05:29:11.223734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = data_train[quantitative]\nX_test = data_test[quantitative]\ny = df_train['claim']\n\nmodel_1 = lgb.LGBMClassifier()\nmodel_1.fit(X_train,y)\npreds_y1 = model_1.predict_proba(X_test)[:,1]\ndict_0 = {\n    'id':data_test.index.to_numpy(),\n    'claim':preds_y1\n}\nresult = pd.DataFrame(dict_0)\nresult.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T05:29:11.22629Z","iopub.execute_input":"2021-09-09T05:29:11.226684Z","iopub.status.idle":"2021-09-09T05:29:18.097256Z","shell.execute_reply.started":"2021-09-09T05:29:11.226642Z","shell.execute_reply":"2021-09-09T05:29:18.095438Z"},"trusted":true},"execution_count":null,"outputs":[]}]}