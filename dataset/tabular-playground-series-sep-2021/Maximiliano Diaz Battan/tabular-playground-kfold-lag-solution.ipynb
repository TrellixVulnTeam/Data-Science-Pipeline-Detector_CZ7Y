{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> - | Notebook resume</div>\n\n<p style=\"font-size:16px; font-family:verdana; line-height: 1.7em; margin-left:20px\">  \nHello Kagglers, I created this notebook because I experienced a lot of lag when trying to work on this competition within the Kaggle notebooks, and found that it was caused by the size of the datasets, if the original datasets are deleted, the lag disappears. That's why I made this notebook that resizes the original dataset (train and test), and also splits it into folds (train) and saves them as parquet files, a much better and more efficient file type. For it to work properly you need to delete the original dataset and replace it with these files, after deleting the lag is gone. I hope this notebook has been useful to you. I've also made the datasets public in case you don't want to do this, just search the datasets for the train test lag solution playground or click here <a href=\"https://www.kaggle.com/maxdiazbattan/playground-train-test-kfold-parquet\">[link]</a>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import model_selection","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T12:16:23.882648Z","iopub.execute_input":"2022-04-12T12:16:23.883022Z","iopub.status.idle":"2022-04-12T12:16:24.887351Z","shell.execute_reply.started":"2022-04-12T12:16:23.882921Z","shell.execute_reply":"2022-04-12T12:16:24.886111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:16:24.889775Z","iopub.execute_input":"2022-04-12T12:16:24.890335Z","iopub.status.idle":"2022-04-12T12:16:56.80023Z","shell.execute_reply.started":"2022-04-12T12:16:24.890283Z","shell.execute_reply":"2022-04-12T12:16:56.799252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:16:56.801836Z","iopub.execute_input":"2022-04-12T12:16:56.802208Z","iopub.status.idle":"2022-04-12T12:17:13.208638Z","shell.execute_reply.started":"2022-04-12T12:16:56.802125Z","shell.execute_reply":"2022-04-12T12:17:13.20712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage before optimization is: {:.2f} MB'.format(start_mem))\n    print('Memory usage after optimization is:  {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:17:13.212127Z","iopub.execute_input":"2022-04-12T12:17:13.213772Z","iopub.status.idle":"2022-04-12T12:17:13.229398Z","shell.execute_reply.started":"2022-04-12T12:17:13.21372Z","shell.execute_reply":"2022-04-12T12:17:13.228703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:16px; font-family:verdana; line-height: 1.7em\">   \nThis function it's from this notebook <a href=\"https://www.kaggle.com/rinnqd/reduce-memory-usage\">[link]</a>, I had to used it because the memory usage it's very high with this particular dataset. All the credits to Firas, was a very clever solution.</p>","metadata":{}},{"cell_type":"code","source":"skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ntrain['kfold'] = -1\ny = train.claim\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X=train, y=y)):\n    train.loc[test_idx,'kfold'] = fold","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:17:13.230685Z","iopub.execute_input":"2022-04-12T12:17:13.231523Z","iopub.status.idle":"2022-04-12T12:17:13.546074Z","shell.execute_reply.started":"2022-04-12T12:17:13.231471Z","shell.execute_reply":"2022-04-12T12:17:13.545256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:17:13.547497Z","iopub.execute_input":"2022-04-12T12:17:13.547729Z","iopub.status.idle":"2022-04-12T12:17:37.217051Z","shell.execute_reply.started":"2022-04-12T12:17:13.547701Z","shell.execute_reply":"2022-04-12T12:17:37.215975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:17:37.218283Z","iopub.execute_input":"2022-04-12T12:17:37.218519Z","iopub.status.idle":"2022-04-12T12:17:51.285266Z","shell.execute_reply.started":"2022-04-12T12:17:37.218491Z","shell.execute_reply":"2022-04-12T12:17:51.284222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_parquet('train_kfold_reduced.parquet', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:17:51.286776Z","iopub.execute_input":"2022-04-12T12:17:51.287115Z","iopub.status.idle":"2022-04-12T12:17:59.563418Z","shell.execute_reply.started":"2022-04-12T12:17:51.28707Z","shell.execute_reply":"2022-04-12T12:17:59.562609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_parquet('test_reduced.parquet', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:17:59.564496Z","iopub.execute_input":"2022-04-12T12:17:59.564705Z","iopub.status.idle":"2022-04-12T12:18:04.575662Z","shell.execute_reply.started":"2022-04-12T12:17:59.564679Z","shell.execute_reply":"2022-04-12T12:18:04.574748Z"},"trusted":true},"execution_count":null,"outputs":[]}]}