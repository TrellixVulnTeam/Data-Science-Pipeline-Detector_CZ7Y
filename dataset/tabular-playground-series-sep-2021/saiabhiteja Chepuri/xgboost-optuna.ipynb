{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport optuna \nimport sklearn\nfrom lightgbm import LGBMClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom optuna.samplers import TPESampler\nfrom optuna.visualization import plot_optimization_history,plot_param_importances\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom xgboost import XGBClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-09-20T10:46:38.240452Z","iopub.execute_input":"2021-09-20T10:46:38.240868Z","iopub.status.idle":"2021-09-20T10:46:41.438137Z","shell.execute_reply.started":"2021-09-20T10:46:38.240785Z","shell.execute_reply":"2021-09-20T10:46:41.43712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")\ndftest = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-20T10:46:41.442882Z","iopub.execute_input":"2021-09-20T10:46:41.445141Z","iopub.status.idle":"2021-09-20T10:47:22.352631Z","shell.execute_reply.started":"2021-09-20T10:46:41.445096Z","shell.execute_reply":"2021-09-20T10:47:22.351746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [x for x in df.columns if x not in ['id','claim']]\n\ndf['n_missing'] = df[useful_features].isna().sum(axis=1)\ndftest['n_missing'] = dftest[useful_features].isna().sum(axis =1)\n\ndf['std'] = df[useful_features].std(axis=1)\ndftest['std'] = dftest[useful_features].std(axis=1)\n\ndf['max'] = df[useful_features].max(axis=1)\ndftest['max'] = dftest[useful_features].max(axis=1)\n\ndf['min'] = df[useful_features].min(axis=1)\ndftest['min'] = dftest[useful_features].min(axis=1)\n\n#filling remaing values using mean \ndf[useful_features] = df[useful_features].fillna(df[useful_features].mean())\ndftest[useful_features] = dftest[useful_features].fillna(df[useful_features].mean())\n\n#scaling all the values using standard scaler \nsc = MinMaxScaler()\ndf[useful_features] = sc.fit_transform(df[useful_features])\ndftest[useful_features] = sc.transform(dftest[useful_features])\n\nuseful_features = [x for x in df.columns if x not in ['id','claim']]\n\nX = df[useful_features].values\ny = df['claim'].values","metadata":{"execution":{"iopub.status.busy":"2021-09-20T10:47:22.354085Z","iopub.execute_input":"2021-09-20T10:47:22.354419Z","iopub.status.idle":"2021-09-20T10:48:14.922196Z","shell.execute_reply.started":"2021-09-20T10:47:22.354383Z","shell.execute_reply":"2021-09-20T10:48:14.921292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    #empty list for training and testing roc_scores\n    train_score = []\n    test_score = []\n    \n    #optunas parameters suggestion\n\n    param_grid = {\n              'objective': 'binary:logistic',\n              'use_label_encoder': False,\n              'n_estimators': trial.suggest_int('n_estimators', 500, 20000),\n              'learning_rate': trial.suggest_discrete_uniform('learning_rate',0.01,0.1,0.01),\n              'subsample': trial.suggest_discrete_uniform('subsample', 0.3, 1.0, 0.1),\n              'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree',0.3,1.0, 0.1),\n              'max_depth': trial.suggest_int('max_depth', 2, 20),\n              'booster': 'gbtree',\n              'gamma': trial.suggest_uniform('gamma',1.0,10.0),\n              'reg_alpha': trial.suggest_int('reg_alpha',50,100),\n              'reg_lambda': trial.suggest_int('reg_lambda',50,100),\n              'random_state': 42,\n                 }\n    #cross validation using StratifiedKfold\n    \n    fold = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\n    \n    for train_id,test_id in fold.split(df[useful_features],df['claim']):\n        \n        \n        \n        #training and testing data\n        xtrain ,xtest = X[train_id],X[test_id]\n        ytrain,ytest = y[train_id],y[test_id]\n        \n        #model instance \n        model = XGBClassifier(**param_grid,\n                               tree_method='gpu_hist', \n                                  predictor='gpu_predictor')\n        \n        #fitting the model\n        model.fit(xtrain, ytrain, \n                  verbose=500,\n                 eval_set=[(xtest,ytest)],\n                  eval_metric=['logloss','auc'],\n                 early_stopping_rounds=500)\n        \n        #predicting train and test data\n        test_pred = model.predict_proba(xtest)[:, 1]\n        train_pred = model.predict_proba(xtrain)[:,1] \n        \n        #appending into the list\n        train_score.append(roc_auc_score(ytrain,train_pred))\n        test_score.append(roc_auc_score(ytest,test_pred))\n        \n        #printing the scores\n        print(\"Train roc_auc_score is {}\".format(roc_auc_score(ytrain,train_pred)))\n        print(\"Test roc_auc_score is {}\".format(roc_auc_score(ytest,test_pred)))\n        \n        #returning mean score\n    return np.mean(test_score)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T05:23:23.348897Z","iopub.execute_input":"2021-09-20T05:23:23.349229Z","iopub.status.idle":"2021-09-20T05:23:23.363688Z","shell.execute_reply.started":"2021-09-20T05:23:23.349198Z","shell.execute_reply":"2021-09-20T05:23:23.362595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize',sampler=TPESampler(), study_name='xgb_optuna')\nstudy.optimize(objective, n_trials = 25)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T05:23:25.615661Z","iopub.execute_input":"2021-09-20T05:23:25.615974Z","iopub.status.idle":"2021-09-20T05:27:26.309497Z","shell.execute_reply.started":"2021-09-20T05:23:25.615942Z","shell.execute_reply":"2021-09-20T05:27:26.305263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of trails : {}\".format(len(study.trials)))\nprint(\"Best parameters :\")\nprint(study.best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_optimization_history(study)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_param_importances(study)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nxgb_params = {'objective': 'binary:logistic',\n              'use_label_encoder': False,\n                'n_estimators': 11904, \n              'learning_rate': 0.06999999999999999 , \n              'subsample': 0.7, \n              'colsample_bytree': 1.0, \n              'max_depth': 2,\n              'gamma':2.358054251805544, \n              'reg_alpha': 59, \n              'reg_lambda': 71,\n             'booster': 'gbtree',\n             'random_state': 42}","metadata":{"execution":{"iopub.status.busy":"2021-09-20T10:50:45.211081Z","iopub.execute_input":"2021-09-20T10:50:45.21143Z","iopub.status.idle":"2021-09-20T10:50:45.21719Z","shell.execute_reply.started":"2021-09-20T10:50:45.2114Z","shell.execute_reply":"2021-09-20T10:50:45.216337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#xgbclassifier\n#1st model\noof = np.zeros(df.shape[0])\n\nxgb_preds = []\ntest_score = []\ntrain_score = []\nfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\n\n\nfor train_id,test_id in fold.split(df[useful_features],df['claim']):\n        \n        \n        \n        #training and testing data\n        xtrain ,xtest = X[train_id],X[test_id]\n        ytrain,ytest = y[train_id],y[test_id]\n        x_test_data = dftest[useful_features].values\n        \n        #model instance \n        model = XGBClassifier(**xgb_params, \n                tree_method='gpu_hist', \n                predictor='gpu_predictor')\n        \n        #fitting the model\n        model.fit(xtrain, ytrain, \n                  verbose=500,\n                 eval_set=[(xtest,ytest)],\n                  eval_metric=['logloss','auc'],\n                 early_stopping_rounds=500)\n        \n        #predicting train and test data\n        test_pred = model.predict_proba(xtest)[:, 1]\n        train_pred = model.predict_proba(xtrain)[:,1] \n        oof[test_id] = model.predict_proba(xtest)[:,1]\n        \n        test_auc = roc_auc_score(ytest, test_pred)\n        train_auc = roc_auc_score(ytrain,train_pred)\n        \n        #appending into the list\n        train_score.append(train_auc)\n        test_score.append(test_auc)\n        \n        #printing the scores\n        print(\"Train roc_auc_score is {}\".format(train_auc))\n        print(\"Test roc_auc_score is {}\".format(test_auc))\n        \n        xgb_preds.append(model.predict_proba(x_test_data)[:,-1])\n          \nprint(\"all folds done\")\nprint(\"Average train auc : {} with standard devation : {}\".format(np.mean(train_score),np.std(train_score)))\nprint(\"Average test auc : {} with standard devation : {}\".format(np.mean(test_score),np.std(test_score)))\nxgb_preds = np.mean(np.column_stack(xgb_preds), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T10:51:27.931728Z","iopub.execute_input":"2021-09-20T10:51:27.93205Z","iopub.status.idle":"2021-09-20T11:05:12.725855Z","shell.execute_reply.started":"2021-09-20T10:51:27.93202Z","shell.execute_reply":"2021-09-20T11:05:12.725003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')\nsample['claim'] = xgb_preds\nsample.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:05:12.727474Z","iopub.execute_input":"2021-09-20T11:05:12.727834Z","iopub.status.idle":"2021-09-20T11:05:14.130889Z","shell.execute_reply.started":"2021-09-20T11:05:12.727797Z","shell.execute_reply":"2021-09-20T11:05:14.130048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_pd = pd.DataFrame()\noof_pd['id'] = df['id']\noof_pd.set_index('id',inplace = True)\noof_pd['xgb_1'] = oof\noof_pd.to_csv('xgb_train_minmax.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:05:14.132422Z","iopub.execute_input":"2021-09-20T11:05:14.132743Z","iopub.status.idle":"2021-09-20T11:05:17.066602Z","shell.execute_reply.started":"2021-09-20T11:05:14.132704Z","shell.execute_reply":"2021-09-20T11:05:17.065733Z"},"trusted":true},"execution_count":null,"outputs":[]}]}