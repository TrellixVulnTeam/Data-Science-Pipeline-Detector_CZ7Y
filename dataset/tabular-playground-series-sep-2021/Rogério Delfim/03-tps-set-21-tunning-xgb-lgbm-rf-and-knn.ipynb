{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 div class='alert alert-success'><center> TPS-Set: Tunning Hyperparameters (XGB, Catb and LGBM )\n </center></h1>\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/26480/logos/header.png?t=2021-04-09-00-57-05)","metadata":{}},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\">  0. IMPORTAÇÕES </div>","metadata":{}},{"cell_type":"markdown","source":"## 0.1. Bibliotecas","metadata":{}},{"cell_type":"code","source":"import time\nimport warnings\nimport os\nimport re\nimport gc\nimport random\nimport glob\nimport optuna\nimport sklearn.exceptions\nimport plotly","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:38.133826Z","iopub.execute_input":"2021-09-14T01:17:38.134168Z","iopub.status.idle":"2021-09-14T01:17:38.139086Z","shell.execute_reply.started":"2021-09-14T01:17:38.134137Z","shell.execute_reply":"2021-09-14T01:17:38.138197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas               as pd\nimport numpy                as np\nimport matplotlib.pyplot    as plt \nimport seaborn              as sns\nimport joblib               as jb","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:38.917956Z","iopub.execute_input":"2021-09-14T01:17:38.918285Z","iopub.status.idle":"2021-09-14T01:17:38.922831Z","shell.execute_reply.started":"2021-09-14T01:17:38.918251Z","shell.execute_reply":"2021-09-14T01:17:38.921807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!conda install catboost","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:39.63821Z","iopub.execute_input":"2021-09-14T01:17:39.638555Z","iopub.status.idle":"2021-09-14T01:17:39.643375Z","shell.execute_reply.started":"2021-09-14T01:17:39.638522Z","shell.execute_reply":"2021-09-14T01:17:39.642532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn             as nn","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:40.410269Z","iopub.execute_input":"2021-09-14T01:17:40.410613Z","iopub.status.idle":"2021-09-14T01:17:40.415113Z","shell.execute_reply.started":"2021-09-14T01:17:40.410581Z","shell.execute_reply":"2021-09-14T01:17:40.414105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm             as lgb\nimport catboost             as ctb\nimport xgboost              as xgb","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:41.153779Z","iopub.execute_input":"2021-09-14T01:17:41.154104Z","iopub.status.idle":"2021-09-14T01:17:41.158719Z","shell.execute_reply.started":"2021-09-14T01:17:41.154075Z","shell.execute_reply":"2021-09-14T01:17:41.157761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection       import train_test_split,StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.preprocessing         import QuantileTransformer\nfrom sklearn                       import metrics\nfrom sklearn.ensemble              import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:42.430248Z","iopub.execute_input":"2021-09-14T01:17:42.430691Z","iopub.status.idle":"2021-09-14T01:17:42.440682Z","shell.execute_reply.started":"2021-09-14T01:17:42.430649Z","shell.execute_reply":"2021-09-14T01:17:42.439476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from optuna.samplers               import TPESampler\nfrom optuna.visualization          import plot_edf\nfrom optuna.visualization          import plot_optimization_history\nfrom optuna.visualization          import plot_parallel_coordinate\nfrom optuna.visualization          import plot_param_importances\nfrom optuna.visualization          import plot_slice\nfrom optuna.visualization          import plot_intermediate_values\nfrom optuna.visualization          import plot_contour","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:43.414962Z","iopub.execute_input":"2021-09-14T01:17:43.415278Z","iopub.status.idle":"2021-09-14T01:17:43.420599Z","shell.execute_reply.started":"2021-09-14T01:17:43.415248Z","shell.execute_reply":"2021-09-14T01:17:43.419633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir Data\n!mkdir Data/pkl\n!mkdir Data/sumbmission\n!mkdir model\n!mkdir model/preds\n!mkdir model/optuna","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-14T01:17:44.835095Z","iopub.execute_input":"2021-09-14T01:17:44.835532Z","iopub.status.idle":"2021-09-14T01:17:48.737334Z","shell.execute_reply.started":"2021-09-14T01:17:44.835482Z","shell.execute_reply":"2021-09-14T01:17:48.736366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.2. Funções","metadata":{}},{"cell_type":"code","source":"def jupyter_setting():\n    \n    %matplotlib inline\n     \n    pd.options.display.max_columns = None\n    \n    optuna.logging.set_verbosity(optuna.logging.WARNING)\n      \n    warnings.filterwarnings(action='ignore')\n    warnings.simplefilter('ignore')\n    warnings.filterwarnings('ignore')\n    warnings.filterwarnings('ignore', category=DeprecationWarning)\n    warnings.filterwarnings('ignore', category=FutureWarning)\n    warnings.filterwarnings('ignore', category=RuntimeWarning)\n    warnings.filterwarnings('ignore', category=UserWarning)\n    warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n    #pd.set_option('display.max_rows', 150)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.max_colwidth', None)\n\n    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n    #sns.palplot(sns.color_palette(icecream))\n    \n    return icecream\n\nicecream = jupyter_setting()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:48.739569Z","iopub.execute_input":"2021-09-14T01:17:48.739972Z","iopub.status.idle":"2021-09-14T01:17:48.753097Z","shell.execute_reply.started":"2021-09-14T01:17:48.739926Z","shell.execute_reply":"2021-09-14T01:17:48.752088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) / start_mem\n            )\n        )\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:48.75507Z","iopub.execute_input":"2021-09-14T01:17:48.755713Z","iopub.status.idle":"2021-09-14T01:17:48.770288Z","shell.execute_reply.started":"2021-09-14T01:17:48.755674Z","shell.execute_reply":"2021-09-14T01:17:48.769354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.rcParams['font.size'] = 12\n    plt.title('Precision Recall vs threshold')\n    plt.xlabel('Threshold')\n    plt.legend(loc=\"lower left\")\n    \n    plt.grid(True)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:49.015407Z","iopub.execute_input":"2021-09-14T01:17:49.015768Z","iopub.status.idle":"2021-09-14T01:17:49.021404Z","shell.execute_reply.started":"2021-09-14T01:17:49.015737Z","shell.execute_reply":"2021-09-14T01:17:49.020409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_precision_vs_recall(precisions, recalls):\n    plt.plot(recalls[:-1], precisions[:-1], \"b-\", label=\"Precision\")\n    \n    plt.rcParams['font.size'] = 12\n    plt.title('Precision vs recall')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    # plt.legend(loc=\"lower left\")\n    \n    plt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:50.288321Z","iopub.execute_input":"2021-09-14T01:17:50.288701Z","iopub.status.idle":"2021-09-14T01:17:50.295093Z","shell.execute_reply.started":"2021-09-14T01:17:50.288669Z","shell.execute_reply":"2021-09-14T01:17:50.293831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef plot_roc_curve(fpr, tpr, label=None):\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr, \"r-\", label=label)\n    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.rcParams['font.size'] = 12\n    plt.title('XGBR ROC curve for TPS 09')\n    plt.xlabel('False Positive Rate (1 - Specificity)')\n    plt.ylabel('True Positive Rate (Sensitivity)')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:51.37522Z","iopub.execute_input":"2021-09-14T01:17:51.375573Z","iopub.status.idle":"2021-09-14T01:17:51.382292Z","shell.execute_reply.started":"2021-09-14T01:17:51.375541Z","shell.execute_reply":"2021-09-14T01:17:51.380957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_df_cv(path):\n\n    name_file_pkl     = glob.glob(path + '*.pkl.z')\n    dic_preds_mdl_pkl = dict()\n\n    for p_name in name_file_pkl:    \n        y_model_pkl_name_col  = p_name.replace(path, '').replace('.pkl.z','') \n        y_model_pkl           = jb.load(p_name)   \n\n        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n\n    return pd.DataFrame(dic_preds_mdl_pkl)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:55.659438Z","iopub.execute_input":"2021-09-14T01:17:55.659749Z","iopub.status.idle":"2021-09-14T01:17:55.666384Z","shell.execute_reply.started":"2021-09-14T01:17:55.65972Z","shell.execute_reply":"2021-09-14T01:17:55.665585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def graf_corr(df):\n    \n    df = df.corr().round(5)\n\n    # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n    mask = np.zeros_like(df)\n    mask[np.triu_indices_from(mask)] = True\n\n    # Making a plot\n    plt.figure(figsize=(16,16))\n    ax = sns.heatmap(df, annot=True, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n\n    ax.set_title(\"Mapa de calor de correlação das variável\", fontsize=17)\n\n    plt.setp(ax.get_xticklabels(), \n             rotation      = 90, \n             ha            = \"right\",\n             rotation_mode = \"anchor\", \n             weight        = \"normal\")\n\n    plt.setp(ax.get_yticklabels(), \n             weight        = \"normal\",\n             rotation_mode = \"anchor\", \n             rotation      = 0, \n             ha            = \"right\");\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:56.834445Z","iopub.execute_input":"2021-09-14T01:17:56.834837Z","iopub.status.idle":"2021-09-14T01:17:56.841557Z","shell.execute_reply.started":"2021-09-14T01:17:56.834805Z","shell.execute_reply":"2021-09-14T01:17:56.840645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlation(dataset, threshold):\n\n    col_corr    = set()  # Conjunto de todos os nomes de colunas correlacionadas\n    corr_matrix = dataset.corr()\n    \n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # estamos interessados no valor coeficiente absoluto\n                colname = corr_matrix.columns[i]        # obtendo o nome da coluna\n                col_corr.add(colname)\n    \n    return col_corr","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:17:57.978262Z","iopub.execute_input":"2021-09-14T01:17:57.978637Z","iopub.status.idle":"2021-09-14T01:17:57.986259Z","shell.execute_reply.started":"2021-09-14T01:17:57.978595Z","shell.execute_reply":"2021-09-14T01:17:57.985313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.3. Carregar Dados","metadata":{}},{"cell_type":"code","source":"path = '/content/drive/MyDrive/kaggle/07. Tabular Playground Series - Ago 2021/'\npath = '../input/tpsset21-001/'","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:18:00.267162Z","iopub.execute_input":"2021-09-14T01:18:00.267491Z","iopub.status.idle":"2021-09-14T01:18:00.271042Z","shell.execute_reply.started":"2021-09-14T01:18:00.267461Z","shell.execute_reply":"2021-09-14T01:18:00.270214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3_train     = jb.load(path + 'df3_train.pkl.z')\ndf3_test      = jb.load(path + 'df3_test.pkl.z')\ndf_submission = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')\n\ndf3_train.shape, df3_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:18:38.681931Z","iopub.execute_input":"2021-09-14T01:18:38.682352Z","iopub.status.idle":"2021-09-14T01:18:59.444697Z","shell.execute_reply.started":"2021-09-14T01:18:38.682316Z","shell.execute_reply":"2021-09-14T01:18:59.443599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:19:16.678057Z","iopub.execute_input":"2021-09-14T01:19:16.678373Z","iopub.status.idle":"2021-09-14T01:19:16.79917Z","shell.execute_reply.started":"2021-09-14T01:19:16.678344Z","shell.execute_reply":"2021-09-14T01:19:16.798374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3_train.info() , df3_test.info()  ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:19:18.247768Z","iopub.execute_input":"2021-09-14T01:19:18.248108Z","iopub.status.idle":"2021-09-14T01:19:18.280209Z","shell.execute_reply.started":"2021-09-14T01:19:18.248077Z","shell.execute_reply":"2021-09-14T01:19:18.279464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.3.1. Reduzindo memória\ntaken from: https://www.kaggle.com/bextuychiev/how-to-work-w-million-row-datasets-like-a-pro","metadata":{}},{"cell_type":"code","source":"df3_train = reduce_memory_usage(df3_train)\ndf3_test  = reduce_memory_usage(df3_test)\n\ndf3_train.shape, df3_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:19:20.91824Z","iopub.execute_input":"2021-09-14T01:19:20.918744Z","iopub.status.idle":"2021-09-14T01:19:48.458075Z","shell.execute_reply.started":"2021-09-14T01:19:20.91869Z","shell.execute_reply":"2021-09-14T01:19:48.457321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3_train.info(), df3_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:20:29.313903Z","iopub.execute_input":"2021-09-14T01:20:29.31423Z","iopub.status.idle":"2021-09-14T01:20:29.338678Z","shell.execute_reply.started":"2021-09-14T01:20:29.3142Z","shell.execute_reply":"2021-09-14T01:20:29.337631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\"> 1.  TUNNING </div>","metadata":{}},{"cell_type":"code","source":"X      = df3_train.drop(['claim'], axis=1)    \ny      = df3_train[\"claim\"].copy()\nX_test = df3_test\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, \n                                                      y, \n                                                      test_size    = 0.2, \n                                                      shuffle      = True, \n                                                      stratify     = y,\n                                                      random_state = 12359)\n\n\n\nprint(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X.shape, y.shape, X_test.shape) ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:20:32.597145Z","iopub.execute_input":"2021-09-14T01:20:32.597514Z","iopub.status.idle":"2021-09-14T01:20:34.793292Z","shell.execute_reply.started":"2021-09-14T01:20:32.59748Z","shell.execute_reply":"2021-09-14T01:20:34.792268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler       = QuantileTransformer(output_distribution='normal' , random_state=0)\nX_test_sc_qt = pd.DataFrame(scaler.fit_transform(X_test), columns = X_test.columns)\n\nX_test_sc_qt.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:20:36.847377Z","iopub.execute_input":"2021-09-14T01:20:36.847751Z","iopub.status.idle":"2021-09-14T01:20:54.696391Z","shell.execute_reply.started":"2021-09-14T01:20:36.847721Z","shell.execute_reply":"2021-09-14T01:20:54.695589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1. Classe Tunning ","metadata":{}},{"cell_type":"code","source":"path = ''\n\nclass TunningModels(nn.Module):\n\n    def __init__(self, name_model, X_trn_, y_trn_, X_ts_, feature_=None, seed_=12359):\n        \n        super(TunningModels,self).__init__() \n        \n        self.name_clf  = name_model\n        self.X_trn     = X_trn_\n        self.y_trn     = y_trn_\n        self.X_ts      = X_ts_         \n        self.feature   = feature_\n        self.seed      = seed_\n        \n    def recover_prediction_first_level():\n        \n        preds_train1 = glob.glob(\"model/train/*.pkl.z\")\n        preds_test   = glob.glob(\"model/test/*.pkl.z\")\n        preds_val1   = glob.glob(\"model/valid/*.pkl.z\")\n\n        df_train1     = []\n        scores_traint = dict()\n\n        for p_name in preds_train1:    \n            p    = jb.load(p_name)\n            p_df = pd.DataFrame(p, columns=[p_name.replace('model/train\\\\', '')])    \n            df_train1.append(p_df)    \n            scores_traint[p_name] = f1_score(y_train1, (p_df>.5))\n\n        df_val1     = [] \n        scores_val1 = dict()\n        for p_name in preds_val1:    \n            p    = jb.load(p_name)\n            p_df = pd.DataFrame(p, columns=[p_name.replace('model/valid\\\\', '')])    \n            df_val1.append(p_df)    \n            scores_val1[p_name] = f1_score(y_val1, (p_df>.5))\n\n        df_test     = [] \n        scores_test = dict()\n        for p_name in preds_test:    \n            p         = jb.load(p_name)\n            p_df_test = pd.DataFrame(p, columns=[p_name.replace('model/test\\\\', '')])    \n            df_test.append(p_df_test)\n\n        df_train1 = pd.concat(df_train1, axis=1)\n        df_val1   = pd.concat(df_val1, axis=1)\n        df_test   = pd.concat(df_test, axis=1)\n\n        return df_train1, df_val1, df_test.shape\n        \n    def delete_files(namefile):\n\n        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna']\n\n        for path_ in path:\n            for raiz, diretorios, arquivos in os.walk(path_):\n                for arquivo in arquivos:\n                    if arquivo.startswith(namefile):\n                        os.remove(os.path.join(raiz, arquivo))\n \n    def logging_callback(study, frozen_trail):\n        prev_best = study.user_attrs.get('prev_best', None)\n        if prev_best != study.best_value:\n            study.set_user_attr('prev_best', study.best_value)\n            print(f\"Trail {frozen_trail.number} finished with best value {frozen_trail.value}\")\n\n    def cross_valid(model, model_name_, X_, y_, X_test_, type_model=1, \n                    feature=None, seed=None, tunning=1):\n    \n        n_splits    = 5\n        n_repeats   = 1\n        y_hat_test  = None\n        auc         = []\n        lloss       = []\n        f1          = []\n\n        if feature!=None:         \n            X_      = X_[feature]\n            X_test_ = X_test_[feature]\n        \n        kf = RepeatedStratifiedKFold(n_splits     = n_splits, \n                                     n_repeats    = n_repeats,                                   \n                                     random_state = seed)\n        \n        # https://stackoverflow.com/questions/65318931/stratifiedkfold-vs-kfold-in-scikit-learn\n        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n            \n\n        clf_name = model.__class__.__name__\n\n        print('='*70)\n        print('Training model: {}'.format(clf_name))\n        print('='*70)\n        \n        scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n        \n        cols_model_base = ['fe_f50_zero', 'fe_f5_zero', 'fe_n_missing', 'cluster', \n                           'fe_std', 'f105', 'f102', 'f22', 'f79', 'f106', 'f71', \n                           'f77', 'f69']\n\n        for fold, (train_idx, valid_idx) in enumerate(kf.split(X_, y_, groups=y_)): \n\n            # Obtenha os dados de treino e \n            # validação através de indice\n            X_trn, y_trn = X_.iloc[train_idx], y_.iloc[train_idx]\n            X_val, y_val = X_.iloc[valid_idx], y_.iloc[valid_idx]\n\n            # Scaler \n            X_trn  = pd.DataFrame(scaler.fit_transform(X_trn), columns=X_trn.columns)\n            X_val  = pd.DataFrame(scaler.fit_transform(X_val), columns=X_val.columns)\n\n            # Treinar o modelo baseline\n                        \n            #params_md_baseline = {'random_state': 0,          \n            #                      'predictor'   : 'gpu_predictor',\n            #                      'tree_method' : 'gpu_hist',\n            #                      'eval_metric' : 'auc'}\n            #\n            #model_base = xgb.XGBClassifier(**params_md_baseline)\n            #model_base.fit(X_trn[cols_model_base], y_trn)\n#\n            #threshold = .5\n#\n            #y_hat_prob_tr_mb = (model_base.predict_proba(X_trn[cols_model_base])[:, 1]>threshold).astype(int) \n            #y_hat_prob_vl_mb = (model_base.predict_proba(X_val[cols_model_base])[:, 1]>threshold).astype(int) \n            #y_hat_prob_ts_mb = (model_base.predict_proba(X_test_[cols_model_base])[:, 1]>threshold).astype(int) \n#\n            #X_trn['fe_md_baseline']   = y_hat_prob_tr_mb \n            #X_val['fe_md_baseline']   = y_hat_prob_vl_mb\n            #X_test_['fe_md_baseline'] = y_hat_prob_ts_mb\n\n            # Crie e ajuste um novo modelo \n            # usando os melhores parâmetros.        \n            if type_model==1:\n                model.fit(X_trn, y_trn,\n                          eval_set              = [(X_val, y_val)],                          \n                          early_stopping_rounds = 100 ,\n                          verbose               = False)\n                \n            if type_model==2:\n                model.fit(X_trn, y_trn)\n\n            # Predição na validação\n            y_hat_val_prob = model.predict_proba(X_val)[:, 1]\n            y_hat_val      = (y_hat_val_prob >.5).astype(int) \n\n            # Métricas \n            auc_      = metrics.roc_auc_score(y_val, y_hat_val_prob)                    \n            f1_score_ = metrics.f1_score(y_val, y_hat_val)        \n            log_loss_ = metrics.log_loss(y_val, y_hat_val_prob)\n            \n            # Salvar as métricas\n            auc.append(auc_)\n            f1.append(f1_score_)\n            lloss.append(log_loss_)\n\n            # Use o modelo treinado para \n            # 1 / n_splits das previsões de saída.\n            if y_hat_test is None:        \n                y_hat_test  = model.predict_proba(X_test_)[:, 1]        \n            else:        \n                y_hat_test  += model.predict_proba(X_test_)[:, 1]\n\n            msg = 'Fold {}/{} AUC: {:2.5f} - F1: {:2.5f} - L. loss: {:2.5f}'\n            print(msg.format(fold+1, n_splits*n_repeats, auc_, f1_score_, log_loss_))\n\n            gc.collect()\n\n        y_hat_test /= (n_splits*n_repeats)\n        auc_mean    = np.mean(auc)\n        auc_std     = np.std(auc)\n        lloss_mean  = np.mean(lloss)\n        f1_mean     = np.mean(f1)\n        msg         = '[Mean Fold] AUC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - L. Loss: {:.5f}'\n        \n        # \n        if tunning==1:\n            path_name = path + 'model/preds/' + model_name_.format(auc_mean, seed)                        \n            jb.dump(y_hat_test, path_name)\n            score = auc_mean\n        else: \n            score = y_hat_test\n            \n        gc.collect()\n\n        print('-'*70)\n        print(msg.format(auc_mean, auc_std, f1_mean, lloss_mean))\n        print('='*70)\n        print('')\n                    \n        return score \n        \n    def xgb(self, trial):\n                \n        params = {'n_estimators'      : trial.suggest_int('n_estimators', 1000, 10000),\n                  'max_depth'         : trial.suggest_int('max_depth', 3, 10),            \n                  'min_child_weight'  : trial.suggest_int('min_child_weight', 10, 250),\n                  'subsample'         : trial.suggest_uniform('subsample', .65, .90),\n                  'colsample_bynode'  : trial.suggest_uniform('colsample_bynode', .65, .8),                              \n                  'learning_rate'     : trial.suggest_uniform('learning_rate', 0.01, 0.3),\n                  'colsample_bytree'  : trial.suggest_uniform('colsample_bytree', 0.3, 0.85),\n                  'reg_lambda'        : trial.suggest_int('reg_lambda', 2, 100),             \n                  'reg_alpha'         : trial.suggest_int('reg_alpha', 1, 50),             \n                  'eta'               : trial.suggest_uniform('eta', 0.01, 0.13),\n                  'alpha'             : trial.suggest_uniform('alpha', .3, .7), \n                  'gamma'             : trial.suggest_uniform('alpha', 10.7, 15.5), \n                 }\n                \n                        \n        mdl = xgb.XGBClassifier(**params, \n                                objective         = 'binary:logistic',                  \n                                predictor         = 'gpu_predictor',\n                                tree_method       = 'gpu_hist',\n                                eval_metric       = 'auc', \n                                random_state      = self.seed  \n                               )\n        \n        random     = str(np.random.rand(1)[0]).replace('.','')\n        name_model = self.name_clf + '_auc_{:2.5f}_{}_' + random + '.pkl.z'  \n        \n        score = TunningModels.cross_valid(model         = mdl, \n                                          model_name_   = name_model,\n                                          X_            = self.X_trn, \n                                          y_            = self.y_trn,  \n                                          X_test_       = self.X_ts,\n                                          type_model    = 2, \n                                          feature       = self.feature,\n                                          seed          = self.seed)\n             \n        return score\n   \n    def lgb(self, trial):\n        \n        params = {'learning_rate'     : trial.suggest_float('learning_rate', 1e-5, 0.1),               \n                  'max_depth'         : trial.suggest_int('max_depth', 3, 12),\n                  'n_estimators'      : trial.suggest_int('n_estimators', 500, 10000),\n                  'num_leaves'        : trial.suggest_int('num_leaves', 8, 356),\n                  'min_child_samples' : trial.suggest_int('min_child_samples', 2, 3000),\n                  'feature_fraction'  : trial.suggest_uniform('feature_fraction', 0.75, 0.95),\n                  'bagging_fraction'  : trial.suggest_uniform('bagging_fraction', 0.75, 0.95),\n                  'bagging_freq'      : trial.suggest_int('bagging_freq', 3, 7),\n                  'reg_alpha'         : trial.suggest_int('reg_alpha', .1, .90),\n                  'reg_lambda'        : trial.suggest_int('reg_lambda', 1e-5, 1e-2),                   \n                  'lambda_l1'         : trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n                  'lambda_l2'         : trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),           \n                }\n        \n        # Add a callback for pruning.\n        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n        \n        mdl = lgb.LGBMClassifier(**params, \n                                 objective     = 'binary',                   \n                                 metric        = 'auc',\n                                 verbosity     = -1,\n                                 boosting_type = 'gbdt',\n                                 class_weight  = 'balanced',\n                                 #callbacks     = [pruning_callback],\n                                 random_state  = self.seed, \n                                 n_jobs        = -1,\n                                 device       = 'gpu',                                 \n                                )\n        \n        random     = str(np.random.rand(1)[0]).replace('.','')\n        name_model = self.name_clf + '_auc_{:2.5f}_{}_' + random + '.pkl.z'  \n        \n        score = TunningModels.cross_valid(model         = mdl, \n                                          model_name_   = name_model,\n                                          X_            = self.X_trn, \n                                          y_            = self.y_trn,  \n                                          X_test_       = self.X_ts,\n                                          type_model    = 1, \n                                          feature       = self.feature,\n                                          seed          = self.seed)\n        \n        return score\n    \n    def ctb(self, trial):\n                \n        params = {\n                  'n_estimators'              : trial.suggest_int('n_estimators', 1000, 7000),\n                  'max_depth'                  : trial.suggest_int('max_depth', 2, 12),\n                  'iterations'                : trial.suggest_int('iterations', 1000, 7000),\n                  'od_wait'                   : trial.suggest_int('od_wait', 500, 2000),\n                  'learning_rate'             : trial.suggest_uniform('learning_rate', 1e-5, 0.1),\n                  'reg_lambda'                : trial.suggest_uniform('reg_lambda',1e-5, 1e-2),\n                  'subsample'                 : trial.suggest_uniform('subsample', 0, 1),\n                  'random_strength'           : trial.suggest_uniform('random_strength', 10, 50),\n                  'depth'                     : trial.suggest_int('depth', 3, 12),\n                  'min_data_in_leaf'          : trial.suggest_int('min_data_in_leaf', 1, 30),\n                  'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 15),\n                }\n        \n        mdl = ctb.CatBoostClassifier(**params, \n                                     eval_metric  = 'AUC',\n                                     task_type    = 'GPU',\n                                    )\n              \n        random     = str(np.random.rand(1)[0]).replace('.','')\n        name_model = self.name_clf + '_auc_{:2.5f}_{}_' + random + '.pkl.z'  \n        \n        score = TunningModels.cross_valid(model         = mdl, \n                                          model_name_   = name_model,\n                                          X_            = self.X_trn, \n                                          y_            = self.y_trn,  \n                                          X_test_       = self.X_ts,\n                                          type_model    = 1, \n                                          feature       = self.feature,\n                                          seed          = self.seed)\n        \n        return score\n    \n    \n    def rf(self, trial):\n                \n        params = {'max_depth'           : trial.suggest_int('max_depth', 4, 12),\n                  'n_estimators'        : trial.suggest_int('n_estimators', 10, 1000),\n                  'max_samples'         : trial.suggest_int('max_samples', 50 , 1200), \n                  #'min_sample_split'    : trial.suggest_int('min_sample_split', 100 , 1000),\n                  #'max_terminal_nodes'  : trial.suggest_float('max_terminal_nodes', .01 , .8),                  \n                  #'min_samples_lea'     : trial.suggest_int('min_samples_lea', 100 , 1000),\n                  'max_features'        : trial.suggest_float('max_features', .65 , .9), \n                }\n     \n            \n        mdl = rf_model = RandomForestClassifier(**params, n_jobs=-1)\n                      \n        random     = str(np.random.rand(1)[0]).replace('.','')\n        name_model = self.name_clf + '_auc_{:2.5f}_{}_' + random + '.pkl.z'  \n        \n        score = TunningModels.cross_valid(model         = mdl, \n                                          model_name_   = name_model,\n                                          X_            = self.X_trn, \n                                          y_            = self.y_trn,  \n                                          X_test_       = self.X_ts,\n                                          type_model    = 2, \n                                          feature       = self.feature,\n                                          seed          = self.seed)\n        \n        return score\n    \n     \n    def knn(self, trial):\n                \n        params = {'n_neighbors' : trial.suggest_int('n_neighbors', 4, 500),\n                  #'metric'      : trial.suggest_categorical ('max_samples', ['euclidean', 'minkowski','seuclidean'])\n                }\n        \n        mdl = KNeighborsClassifier(**params)\n        \n        random     = str(np.random.rand(1)[0]).replace('.','')\n        name_model = self.name_clf + '_auc_{:2.5f}_{}_' + random + '.pkl.z'  \n        \n        feature= ['fe_n_missing', 'fe_f5_zero', 'fe_f50_zero', 'fe_mean',\n                  'fe_median', 'fe_std', 'fe_skew', 'cluster']\n        \n        score = TunningModels.cross_valid(model         = mdl, \n                                          model_name_   = name_model,\n                                          X_            = self.X_trn, \n                                          y_            = self.y_trn,  \n                                          X_test_       = self.X_ts,\n                                          type_model    = 2, \n                                          feature       = feature,\n                                          seed          = self.seed)\n        \n        return score","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:20:57.990286Z","iopub.execute_input":"2021-09-14T01:20:57.990647Z","iopub.status.idle":"2021-09-14T01:20:58.043838Z","shell.execute_reply.started":"2021-09-14T01:20:57.990616Z","shell.execute_reply":"2021-09-14T01:20:58.042631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vamos aplicar o scaler nos dados de teste. ","metadata":{}},{"cell_type":"markdown","source":"## 1.2. XGB","metadata":{}},{"cell_type":"markdown","source":"### 1.2.1. Tunning ","metadata":{}},{"cell_type":"code","source":"# %%time\n# \n# SEED = 12359 \n# \n# name_model_xgb = 'xgb_001_tun'\n# TunningModels.delete_files(name_model_xgb)\n#     \n# # Inicialize a classe do modelo de otimização\n# modelOpt = TunningModels(name_model = name_model_xgb, \n#                          X_trn_     = X, \n#                          y_trn_     = y, \n#                          X_ts_      = X_test_sc_qt,                                     \n#                          feature_   = None)\n# \n# study_xgb = optuna.create_study(direction = 'maximize',\n#                                 sampler   = optuna.samplers.TPESampler(seed=SEED),\n#                                 pruner    = optuna.pruners.MedianPruner(n_warmup_steps=10),\n#                                 study_name= 'xgb_tuning'\n#                                ) \n# \n# study_xgb.optimize(modelOpt.xgb, \n#                    n_trials  = 10, \n#                   )\n# \n# auc_best_xgb = study_xgb.best_value \n# params_xgb   = study_xgb.best_params \n# path_name    = path + 'model/optuna/' + name_model_xgb + '_{:2.5f}.pkl.z'.format(auc_best_xgb) \n# \n# print('')\n# print('Best average accuracy: {:2.5f}'.format(auc_best_xgb))\n# print('Best parameters: {}'.format(params_xgb))\n# \n# jb.dump(study_xgb, path_name)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:01.548548Z","iopub.execute_input":"2021-09-14T01:21:01.549Z","iopub.status.idle":"2021-09-14T01:21:01.554297Z","shell.execute_reply.started":"2021-09-14T01:21:01.548963Z","shell.execute_reply":"2021-09-14T01:21:01.553187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora vamos recuperar os melhores parametros do tunning para treinar um modelo.","metadata":{}},{"cell_type":"code","source":"#params_xgb","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:02.577767Z","iopub.execute_input":"2021-09-14T01:21:02.578105Z","iopub.status.idle":"2021-09-14T01:21:02.581863Z","shell.execute_reply.started":"2021-09-14T01:21:02.578074Z","shell.execute_reply":"2021-09-14T01:21:02.580927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.2. Analise de hiperparâmetros","metadata":{}},{"cell_type":"markdown","source":"- Visualize the optimization history","metadata":{}},{"cell_type":"code","source":"#plot_optimization_history(study_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:04.089028Z","iopub.execute_input":"2021-09-14T01:21:04.089363Z","iopub.status.idle":"2021-09-14T01:21:04.093059Z","shell.execute_reply.started":"2021-09-14T01:21:04.089332Z","shell.execute_reply":"2021-09-14T01:21:04.092155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Visualize the learning curves of the trials","metadata":{}},{"cell_type":"code","source":"#plot_intermediate_values(study_xgb)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-14T01:21:05.180064Z","iopub.execute_input":"2021-09-14T01:21:05.180406Z","iopub.status.idle":"2021-09-14T01:21:05.184003Z","shell.execute_reply.started":"2021-09-14T01:21:05.180369Z","shell.execute_reply":"2021-09-14T01:21:05.182895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- isualize relacionamentos de parâmetros de alta dimensão. ","metadata":{}},{"cell_type":"code","source":"#plot_parallel_coordinate(study_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:06.273808Z","iopub.execute_input":"2021-09-14T01:21:06.27413Z","iopub.status.idle":"2021-09-14T01:21:06.277767Z","shell.execute_reply.started":"2021-09-14T01:21:06.2741Z","shell.execute_reply":"2021-09-14T01:21:06.276845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Selecione os parâmetros para visualizar.","metadata":{}},{"cell_type":"code","source":"#plot_parallel_coordinate(study_xgb, params=[\"max_depth\", \"n_estimators\", 'reg_lambda'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:07.794023Z","iopub.execute_input":"2021-09-14T01:21:07.794355Z","iopub.status.idle":"2021-09-14T01:21:07.797982Z","shell.execute_reply.started":"2021-09-14T01:21:07.79432Z","shell.execute_reply":"2021-09-14T01:21:07.797079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Visualize relacionamentos de hiperparâmetros.","metadata":{}},{"cell_type":"code","source":"#plot_contour(study_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:08.904344Z","iopub.execute_input":"2021-09-14T01:21:08.904747Z","iopub.status.idle":"2021-09-14T01:21:08.908072Z","shell.execute_reply.started":"2021-09-14T01:21:08.904713Z","shell.execute_reply":"2021-09-14T01:21:08.907229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Selecione os parâmetros para visualizar.","metadata":{}},{"cell_type":"code","source":"#plot_contour(study_xgb, params=[\"max_depth\", \"n_estimators\", 'reg_lambda'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:10.300685Z","iopub.execute_input":"2021-09-14T01:21:10.301009Z","iopub.status.idle":"2021-09-14T01:21:10.304841Z","shell.execute_reply.started":"2021-09-14T01:21:10.300979Z","shell.execute_reply":"2021-09-14T01:21:10.303917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Visualize hiperparâmetros individuais como gráfico de fatias.","metadata":{}},{"cell_type":"code","source":"#plot_slice(study_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:11.761854Z","iopub.execute_input":"2021-09-14T01:21:11.762177Z","iopub.status.idle":"2021-09-14T01:21:11.765589Z","shell.execute_reply.started":"2021-09-14T01:21:11.762147Z","shell.execute_reply":"2021-09-14T01:21:11.764742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Selecione os parâmetros para visualizar.","metadata":{}},{"cell_type":"code","source":"#plot_slice(study_xgb, params=[\"max_depth\", \"n_estimators\", 'reg_lambda'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:13.324556Z","iopub.execute_input":"2021-09-14T01:21:13.324902Z","iopub.status.idle":"2021-09-14T01:21:13.331148Z","shell.execute_reply.started":"2021-09-14T01:21:13.324873Z","shell.execute_reply":"2021-09-14T01:21:13.330255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Visualize as importâncias dos parâmetros.  ","metadata":{}},{"cell_type":"code","source":"#plot_param_importances(study_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:14.785719Z","iopub.execute_input":"2021-09-14T01:21:14.786059Z","iopub.status.idle":"2021-09-14T01:21:14.790231Z","shell.execute_reply.started":"2021-09-14T01:21:14.786029Z","shell.execute_reply":"2021-09-14T01:21:14.789103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Quais hiperparâmetros estão afetando a duração do ensaio com a importância dos hiperparâmetros.","metadata":{}},{"cell_type":"code","source":"#optuna.visualization.plot_param_importances(study_xgb, \n#                                            target=lambda t: t.duration.total_seconds(), \n#                                            target_name=\"duration\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:16.271689Z","iopub.execute_input":"2021-09-14T01:21:16.272038Z","iopub.status.idle":"2021-09-14T01:21:16.276054Z","shell.execute_reply.started":"2021-09-14T01:21:16.272005Z","shell.execute_reply":"2021-09-14T01:21:16.274998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Visualize a função de distribuição empírica","metadata":{}},{"cell_type":"code","source":"#plot_edf(study_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:17.98082Z","iopub.execute_input":"2021-09-14T01:21:17.981151Z","iopub.status.idle":"2021-09-14T01:21:17.985138Z","shell.execute_reply.started":"2021-09-14T01:21:17.98112Z","shell.execute_reply":"2021-09-14T01:21:17.983995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.3. Modelo Final","metadata":{}},{"cell_type":"code","source":"#%%time\n#model_xgb_001 = xgb.XGBClassifier(**params_xgb, \n#                                  objective         = 'binary:logistic',                  \n#                                  predictor         = 'gpu_predictor',\n#                                  tree_method       = 'gpu_hist',\n#                                  eval_metric       = 'auc', \n#                                  random_state      = SEED\n#                                 )\n#\n#y_hat_test_xgb_001 = TunningModels.cross_valid(model       = model_xgb_001, \n#                                               model_name_ = name_model_xgb, \n#                                               X_          = X_train, \n#                                               y_          = y_train, \n#                                               X_test_     = X_test_sc_qt, \n#                                               type_model  = 1, \n#                                               feature     = None,\n#                                               seed        = SEED, \n#                                               tunning     = 0\n#                                               )\n#\n#model_xgb = model_xgb_001.fit(X_train, y_train)\n#y_hat_xgb = model_xgb.predict(X_valid)\n#\n#print(metrics.classification_report(y_valid, y_hat_xgb))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:19.417588Z","iopub.execute_input":"2021-09-14T01:21:19.41792Z","iopub.status.idle":"2021-09-14T01:21:19.421764Z","shell.execute_reply.started":"2021-09-14T01:21:19.417891Z","shell.execute_reply":"2021-09-14T01:21:19.420919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#metrics.plot_confusion_matrix(model_xgb, \n#                              X_valid, \n#                              y_valid,\n#                              cmap   = 'inferno')\n#plt.title('Confusion matrix')\n#plt.grid(False)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:20.201596Z","iopub.execute_input":"2021-09-14T01:21:20.201942Z","iopub.status.idle":"2021-09-14T01:21:20.20672Z","shell.execute_reply.started":"2021-09-14T01:21:20.201902Z","shell.execute_reply":"2021-09-14T01:21:20.20567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Precision Recall versus the decision threshold","metadata":{}},{"cell_type":"code","source":"#y_pred = y_hat_xgb\n#y_true = y_valid\n#precisions, recalls, thresholds = metrics.precision_recall_curve(y_true, y_pred)\n#\n#plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:22.184723Z","iopub.execute_input":"2021-09-14T01:21:22.185057Z","iopub.status.idle":"2021-09-14T01:21:22.188753Z","shell.execute_reply.started":"2021-09-14T01:21:22.185026Z","shell.execute_reply":"2021-09-14T01:21:22.18753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_precision_vs_recall(precisions, recalls)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:23.251494Z","iopub.execute_input":"2021-09-14T01:21:23.251846Z","iopub.status.idle":"2021-09-14T01:21:23.256294Z","shell.execute_reply.started":"2021-09-14T01:21:23.251815Z","shell.execute_reply":"2021-09-14T01:21:23.255349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ROC curve\n","metadata":{}},{"cell_type":"code","source":"#y_true=y_valid\n#y_pred=y_hat_xgb\n#\n#fpr, tpr, thresholds = metrics. roc_curve(y_true, y_pred)\n#\n#plot_roc_curve(fpr, tpr, label=\"XGB\")\n#plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:24.675183Z","iopub.execute_input":"2021-09-14T01:21:24.67554Z","iopub.status.idle":"2021-09-14T01:21:24.680626Z","shell.execute_reply.started":"2021-09-14T01:21:24.675508Z","shell.execute_reply":"2021-09-14T01:21:24.679376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.4. Gerar Submission","metadata":{}},{"cell_type":"code","source":"#submission = pd.DataFrame({'id': df_submission.id, 'loss': y_hat_test_xgb_001})\n#submission.to_csv(path + 'Data/sumbmission/001_xgx_submission_tunning.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:26.445011Z","iopub.execute_input":"2021-09-14T01:21:26.445361Z","iopub.status.idle":"2021-09-14T01:21:26.449211Z","shell.execute_reply.started":"2021-09-14T01:21:26.44533Z","shell.execute_reply":"2021-09-14T01:21:26.447884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3. LGBM","metadata":{}},{"cell_type":"markdown","source":"### 1.3.1. Tunning ","metadata":{}},{"cell_type":"code","source":"# %%time\n# SEED = 12359 \n# \n# name_model_lgb = 'lgb_001_tun'\n# TunningModels.delete_files(name_model_lgb)\n#     \n# # Inicialize a classe do modelo de otimização\n# modelOpt = TunningModels(name_model = name_model_lgb, \n#                          X_trn_     = X, \n#                          y_trn_     = y, \n#                          X_ts_      = X_test_sc_qt,                                     \n#                          feature_   = None)\n# \n# study_lgb = optuna.create_study(direction = 'maximize',\n#                                 sampler   = optuna.samplers.TPESampler(seed=SEED),\n#                                 pruner    = optuna.pruners.MedianPruner(n_warmup_steps=10),\n#                                 study_name= 'lgbm_tuning'\n#                                ) \n# \n# study_lgb.optimize(modelOpt.lgb,n_trials=10)\n# \n# auc_best_lgb = study_lgb.best_value \n# params_lgb   = study_lgb.best_params \n# path_name    = path + 'model/optuna/' + name_model_lgb + '_{:2.5f}.pkl.z'.format(auc_best_lgb) \n# \n# print('')\n# print('Best average accuracy: {:2.5f}'.format(auc_best_lgb))\n# print('Best parameters: {}'.format(params_lgb))\n# \n#jb.dump(study_lgb, path_name)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:28.713888Z","iopub.execute_input":"2021-09-14T01:21:28.714238Z","iopub.status.idle":"2021-09-14T01:21:28.717978Z","shell.execute_reply.started":"2021-09-14T01:21:28.714208Z","shell.execute_reply":"2021-09-14T01:21:28.717166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3.2. Analise de hiperparâmetros\n- referência: https://optuna.readthedocs.io/en/latest/tutorial/10_key_features/005_visualization.html","metadata":{}},{"cell_type":"markdown","source":"**- Visualize o histórico de otimização.**","metadata":{}},{"cell_type":"code","source":"#plot_optimization_history(study_lgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:30.692127Z","iopub.execute_input":"2021-09-14T01:21:30.692473Z","iopub.status.idle":"2021-09-14T01:21:30.696288Z","shell.execute_reply.started":"2021-09-14T01:21:30.692441Z","shell.execute_reply":"2021-09-14T01:21:30.695199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**- Visualize relacionamentos de parâmetros de alta dimensão.**","metadata":{}},{"cell_type":"code","source":"#plot_parallel_coordinate(study_lgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:32.131049Z","iopub.execute_input":"2021-09-14T01:21:32.131401Z","iopub.status.idle":"2021-09-14T01:21:32.135612Z","shell.execute_reply.started":"2021-09-14T01:21:32.131371Z","shell.execute_reply":"2021-09-14T01:21:32.134499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_parallel_coordinate(study_lgb, params=['max_depth','learning_rate', 'num_leaves'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:33.257063Z","iopub.execute_input":"2021-09-14T01:21:33.257383Z","iopub.status.idle":"2021-09-14T01:21:33.261123Z","shell.execute_reply.started":"2021-09-14T01:21:33.257353Z","shell.execute_reply":"2021-09-14T01:21:33.259978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**- Visualize hiperparâmetros individuais como gráfico de fatias.**","metadata":{}},{"cell_type":"code","source":"#plot_slice(study_lgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:34.490368Z","iopub.execute_input":"2021-09-14T01:21:34.490729Z","iopub.status.idle":"2021-09-14T01:21:34.496453Z","shell.execute_reply.started":"2021-09-14T01:21:34.4907Z","shell.execute_reply":"2021-09-14T01:21:34.495431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_slice(study_lgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:35.515697Z","iopub.execute_input":"2021-09-14T01:21:35.516038Z","iopub.status.idle":"2021-09-14T01:21:35.520863Z","shell.execute_reply.started":"2021-09-14T01:21:35.516007Z","shell.execute_reply":"2021-09-14T01:21:35.5197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**- Selecione os parâmetros para visualizar.**","metadata":{}},{"cell_type":"code","source":"#plot_slice(study_lgb, params=['max_depth','learning_rate', 'num_leaves'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:36.844126Z","iopub.execute_input":"2021-09-14T01:21:36.844479Z","iopub.status.idle":"2021-09-14T01:21:36.847711Z","shell.execute_reply.started":"2021-09-14T01:21:36.844444Z","shell.execute_reply":"2021-09-14T01:21:36.846897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**- Visualize as importâncias dos parâmetros.**","metadata":{}},{"cell_type":"code","source":"#optuna.visualization.plot_param_importances(study_lgb, \n#                                            target=lambda t: t.duration.total_seconds(), \n#                                            target_name=\"duration\"\n#                                           )","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:38.716574Z","iopub.execute_input":"2021-09-14T01:21:38.71693Z","iopub.status.idle":"2021-09-14T01:21:38.720815Z","shell.execute_reply.started":"2021-09-14T01:21:38.7169Z","shell.execute_reply":"2021-09-14T01:21:38.719912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**- Saiba quais hiperparâmetros estão afetando a duração do ensaio com a importância dos hiperparâmetros.**","metadata":{}},{"cell_type":"code","source":"#plot_param_importances(study_lgb, \n#                       target      = lambda t: t.duration.total_seconds(),\n#                       target_name = \"duration\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:39.874256Z","iopub.execute_input":"2021-09-14T01:21:39.874626Z","iopub.status.idle":"2021-09-14T01:21:39.877952Z","shell.execute_reply.started":"2021-09-14T01:21:39.874594Z","shell.execute_reply":"2021-09-14T01:21:39.877031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**- Visualize a função de distribuição empírica.**","metadata":{}},{"cell_type":"code","source":"#plot_edf(study_lgb)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:41.671675Z","iopub.execute_input":"2021-09-14T01:21:41.672021Z","iopub.status.idle":"2021-09-14T01:21:41.67588Z","shell.execute_reply.started":"2021-09-14T01:21:41.671991Z","shell.execute_reply":"2021-09-14T01:21:41.674919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3.3. Modelo Final","metadata":{}},{"cell_type":"code","source":"#%%time\n#model_lgb_001      = lgb.LGBMClassifier(**params_lgb,\n#                                        objective     = 'binary',                   \n#                                        metric        = 'auc',\n#                                        verbosity     = -1,\n#                                        boosting_type = 'gbdt',\n#                                        class_weight  = 'balanced',                                        \n#                                        random_state  = SEED, \n#                                        n_jobs        = -1,\n#                                        device       = 'gpu',                                 \n#                                        )\n#                                        \n#y_hat_test_lgb_001 = TunningModels.cross_valid(model       = model_lgb_001, \n#                                               model_name_ = name_model_lgb, \n#                                               X_          = X_train, \n#                                               y_          = y_train, \n#                                               X_test_     = X_test_sc_qt, \n#                                               type_model  = 1, \n#                                               feature     = None,\n#                                               seed        = SEED, \n#                                               tunning     = 0\n#                                               )\n#\n#model_lgb = model_lgb_001.fit(X_train, y_train)\n#y_hat_lgb = model_lgb.predict(X_valid)\n\n#print(metrics.classification_report(y_valid, y_hat_lgb))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:43.292842Z","iopub.execute_input":"2021-09-14T01:21:43.293166Z","iopub.status.idle":"2021-09-14T01:21:43.297583Z","shell.execute_reply.started":"2021-09-14T01:21:43.293137Z","shell.execute_reply":"2021-09-14T01:21:43.296548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3.2. Analise","metadata":{}},{"cell_type":"code","source":"#metrics.plot_confusion_matrix(model_lgb, \n#                              X_valid, \n#                              y_valid,\n#                              cmap   = 'inferno')\n#plt.title('Confusion matrix')\n#plt.grid(False)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:45.15669Z","iopub.execute_input":"2021-09-14T01:21:45.157028Z","iopub.status.idle":"2021-09-14T01:21:45.161025Z","shell.execute_reply.started":"2021-09-14T01:21:45.156997Z","shell.execute_reply":"2021-09-14T01:21:45.160038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3.3. Gerar Submission","metadata":{}},{"cell_type":"code","source":"#submission = pd.DataFrame({'id': df_submission.id, 'loss': y_hat_test_lgb_001})\n#submission.to_csv(path + 'Data/sumbmission/001_lgb_submission_tunning.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:47.604972Z","iopub.execute_input":"2021-09-14T01:21:47.605291Z","iopub.status.idle":"2021-09-14T01:21:47.610312Z","shell.execute_reply.started":"2021-09-14T01:21:47.605261Z","shell.execute_reply":"2021-09-14T01:21:47.608962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.4. RF","metadata":{}},{"cell_type":"markdown","source":"### 1.4.1. Tunning ","metadata":{}},{"cell_type":"code","source":"#%%time\n#SEED = 12359 \n#\n#name_model_rf = 'rf_001_tun'\n#TunningModels.delete_files(name_model_rf)\n#    \n#modelOpt = TunningModels(name_model = name_model_rf, \n#                         X_trn_     = X, \n#                         y_trn_     = y, \n#                         X_ts_      = X_test_sc_qt,                                     \n#                         feature_   = None)\n#\n#study_rf = optuna.create_study(direction = 'maximize',\n#                            sampler   = optuna.samplers.TPESampler(seed=SEED),\n#                            pruner    = optuna.pruners.MedianPruner(n_warmup_steps=10),\n#                            study_name= 'rf_tuning'\n#                           ) \n#\n#study_rf.optimize(modelOpt.rf, n_trials=10)\n#\n#auc_best_rf = study_rf.best_value \n#params_rf   = study_rf.best_params \n#path_name    = path + 'model/optuna/' + name_model_rf + '_{:2.5f}.pkl.z'.format(auc_best_rf) \n#\n#print('')\n#print('Best average accuracy: {:2.5f}'.format(auc_best_rf))\n#print('Best parameters: {}'.format(params_rf))\n#print('')\n\n#jb.dump(study_rf, path_name)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:50.027641Z","iopub.execute_input":"2021-09-14T01:21:50.027982Z","iopub.status.idle":"2021-09-14T01:21:50.032317Z","shell.execute_reply.started":"2021-09-14T01:21:50.027952Z","shell.execute_reply":"2021-09-14T01:21:50.031273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4.2. Modelo Final","metadata":{}},{"cell_type":"code","source":"#model_rf_001      = RandomForestClassifier(**params_rf)\n#y_hat_test_rf_001 = TunningModels.cross_valid(model       = model_rf_001, \n#                                               model_name_ = name_model_rf, \n#                                               X_          = X_train, \n#                                               y_          = y_train, \n#                                               X_test_     = X_test_sc_qt, \n#                                               type_model  = 2, \n#                                               feature     = None,\n#                                               seed        = SEED, \n#                                               tunning     = 0\n#                                               )\n#\n#model_rf = model_rf_001.fit(X_train, y_train)\n#y_hat_rf = model_rf.predict(X_valid)\n#\n#print(metrics.classification_report(y_valid, y_hat_rf))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:52.945023Z","iopub.execute_input":"2021-09-14T01:21:52.945352Z","iopub.status.idle":"2021-09-14T01:21:52.949494Z","shell.execute_reply.started":"2021-09-14T01:21:52.945322Z","shell.execute_reply":"2021-09-14T01:21:52.94852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4.2. Analise","metadata":{}},{"cell_type":"code","source":"#metrics.plot_confusion_matrix(model_rf, \n#                              X_valid, \n#                              y_valid,\n#                              cmap   = 'inferno')\n#plt.title('Confusion matrix')\n#plt.grid(False)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:54.239513Z","iopub.execute_input":"2021-09-14T01:21:54.239875Z","iopub.status.idle":"2021-09-14T01:21:54.243967Z","shell.execute_reply.started":"2021-09-14T01:21:54.239845Z","shell.execute_reply":"2021-09-14T01:21:54.242876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4.3. Gerar Submission","metadata":{}},{"cell_type":"code","source":"#submission = pd.DataFrame({'id': df_submission.id, 'loss': y_hat_test_rf_001})\n#submission.to_csv(path + 'Data/sumbmission/001_rf_submission_tunning.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:21:55.506091Z","iopub.execute_input":"2021-09-14T01:21:55.506432Z","iopub.status.idle":"2021-09-14T01:21:55.510384Z","shell.execute_reply.started":"2021-09-14T01:21:55.506386Z","shell.execute_reply":"2021-09-14T01:21:55.509351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.kaggle.com/vishwas21/tps-sep-21-tuning-xgb-catb-lgbm-and-stacking#Tuning-Light-GBM-Classifier-using-Optuna","metadata":{}},{"cell_type":"markdown","source":"# 15. Ensable ","metadata":{}},{"cell_type":"markdown","source":"Para ensable vamos utilizar as previsões geradas nos processos anteriores, que foram comentados, pois na versão anterior no notebook não foi processado até o final, como quero saber o resultado e ter uma ideia como estou estou na competião vamos gerar as submissões. ","metadata":{}},{"cell_type":"markdown","source":"## 15.1. Recuparar as submissions  ","metadata":{}},{"cell_type":"code","source":"#df_sub_lgb = pd.read_csv('../input/tpsset21003/001_lgb_submission_tunning.csv')\n#df_sub_xgb  = pd.read_csv('../input/tpsset21003/001_xgx_submission_tunning.csv')\n#\n#df_sub_lgb.shape, df_sub_xgb.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:00.961202Z","iopub.execute_input":"2021-09-14T01:22:00.961549Z","iopub.status.idle":"2021-09-14T01:22:00.965394Z","shell.execute_reply.started":"2021-09-14T01:22:00.961518Z","shell.execute_reply":"2021-09-14T01:22:00.964457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 15.1.2. Predição com a média ponderada","metadata":{}},{"cell_type":"code","source":"#submission = pd.DataFrame({'id': df_submission.id, 'claim': df_sub_lgb.claim})\n#submission.to_csv(path + 'Data/sumbmission/001_lgb_submission_01.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:02.852736Z","iopub.execute_input":"2021-09-14T01:22:02.853056Z","iopub.status.idle":"2021-09-14T01:22:02.857352Z","shell.execute_reply.started":"2021-09-14T01:22:02.853029Z","shell.execute_reply":"2021-09-14T01:22:02.856498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_ensable_01 = df_sub_lgb.claim * 0.8 + df_sub_xgb.claim * .2\n#y_pred_ensable_01\n\n# score kaggle: 0.81359 com .5\n# scare kagle: 0.81631 ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:03.656153Z","iopub.execute_input":"2021-09-14T01:22:03.65649Z","iopub.status.idle":"2021-09-14T01:22:03.66197Z","shell.execute_reply.started":"2021-09-14T01:22:03.65646Z","shell.execute_reply":"2021-09-14T01:22:03.661043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 15.3.1. Gerar Submission","metadata":{}},{"cell_type":"code","source":"#submission = pd.DataFrame({'id': df_submission.id, 'claim': y_pred_ensable_01})\n#submission.to_csv(path + 'Data/sumbmission/001_ensable_submission_02.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:05.300324Z","iopub.execute_input":"2021-09-14T01:22:05.300665Z","iopub.status.idle":"2021-09-14T01:22:05.305531Z","shell.execute_reply.started":"2021-09-14T01:22:05.300637Z","shell.execute_reply":"2021-09-14T01:22:05.304524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 15.2. Recuparar dataset\nAqui vamos recupar todas a previsões realizadas na validação cruzada para gerar uma nova submission.","metadata":{}},{"cell_type":"code","source":"df_cv_1 = get_df_cv('../input/tpsset21002/')\ndf_cv_2 = get_df_cv('../input/psset21003/')\ndf_cv_1.shape, df_cv_2.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:07.015068Z","iopub.execute_input":"2021-09-14T01:22:07.015403Z","iopub.status.idle":"2021-09-14T01:22:08.045352Z","shell.execute_reply.started":"2021-09-14T01:22:07.015371Z","shell.execute_reply":"2021-09-14T01:22:08.044369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_cv = pd.concat([df_cv_1, df_cv_2], axis=1)\ndf_cv.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:26:19.482206Z","iopub.execute_input":"2021-09-14T01:26:19.482566Z","iopub.status.idle":"2021-09-14T01:26:19.519627Z","shell.execute_reply.started":"2021-09-14T01:26:19.482533Z","shell.execute_reply":"2021-09-14T01:26:19.51886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como podemos observar, temos 22 previsões realizadas na validação cruzada, é a mesma coisa que dizer que temos 22 modelos, vamos dar uma olhada no dataset.","metadata":{}},{"cell_type":"code","source":"df_cv.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:10.895637Z","iopub.execute_input":"2021-09-14T01:22:10.895955Z","iopub.status.idle":"2021-09-14T01:22:10.934236Z","shell.execute_reply.started":"2021-09-14T01:22:10.895924Z","shell.execute_reply":"2021-09-14T01:22:10.933251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 15.2.1. Descritiva ","metadata":{}},{"cell_type":"code","source":"df_cv.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:12.933818Z","iopub.execute_input":"2021-09-14T01:22:12.934145Z","iopub.status.idle":"2021-09-14T01:22:13.505801Z","shell.execute_reply.started":"2021-09-14T01:22:12.934114Z","shell.execute_reply":"2021-09-14T01:22:13.504745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cv.mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:14.712281Z","iopub.execute_input":"2021-09-14T01:22:14.712648Z","iopub.status.idle":"2021-09-14T01:22:14.816025Z","shell.execute_reply.started":"2021-09-14T01:22:14.712616Z","shell.execute_reply":"2021-09-14T01:22:14.814987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': df_submission.id, 'claim': df_cv.mean(axis=1) })\nsubmission.to_csv(path + 'Data/sumbmission/001_ensable_submission_05.csv', index=False) ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:17.65354Z","iopub.execute_input":"2021-09-14T01:22:17.653901Z","iopub.status.idle":"2021-09-14T01:22:19.504646Z","shell.execute_reply.started":"2021-09-14T01:22:17.653871Z","shell.execute_reply":"2021-09-14T01:22:19.503571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 15.2.3. Correlação","metadata":{}},{"cell_type":"code","source":"graf_corr(df_cv)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:24.139914Z","iopub.execute_input":"2021-09-14T01:22:24.140241Z","iopub.status.idle":"2021-09-14T01:22:29.24735Z","shell.execute_reply.started":"2021-09-14T01:22:24.14021Z","shell.execute_reply":"2021-09-14T01:22:29.246301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Temos muitas previsões autocorrelacionadas, vamos fazer a exclusão de algumas. ","metadata":{}},{"cell_type":"code","source":"corr_features = correlation(df_cv, 0.999)\nlen(set(corr_features))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:32.645543Z","iopub.execute_input":"2021-09-14T01:22:32.645911Z","iopub.status.idle":"2021-09-14T01:22:33.952797Z","shell.execute_reply.started":"2021-09-14T01:22:32.64588Z","shell.execute_reply":"2021-09-14T01:22:33.951738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(corr_features)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:37.032357Z","iopub.execute_input":"2021-09-14T01:22:37.032712Z","iopub.status.idle":"2021-09-14T01:22:37.040669Z","shell.execute_reply.started":"2021-09-14T01:22:37.032683Z","shell.execute_reply":"2021-09-14T01:22:37.039817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cv.drop(labels=corr_features, axis=1, inplace=True)\n\ngraf_corr(df_cv)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:41.932536Z","iopub.execute_input":"2021-09-14T01:22:41.932884Z","iopub.status.idle":"2021-09-14T01:22:43.735905Z","shell.execute_reply.started":"2021-09-14T01:22:41.932854Z","shell.execute_reply":"2021-09-14T01:22:43.735093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cv.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:43.737299Z","iopub.execute_input":"2021-09-14T01:22:43.737738Z","iopub.status.idle":"2021-09-14T01:22:43.74459Z","shell.execute_reply.started":"2021-09-14T01:22:43.737705Z","shell.execute_reply":"2021-09-14T01:22:43.743435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 15.4.1. Gerar Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'id': df_submission.id, 'claim': df_cv.mean(axis=1)})\nsubmission.to_csv(path + 'Data/sumbmission/001_ensable_submission_06.csv', index=False) \n\n# submissão no kaggle: 0.81154 ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:51.855238Z","iopub.execute_input":"2021-09-14T01:22:51.8556Z","iopub.status.idle":"2021-09-14T01:22:53.462167Z","shell.execute_reply.started":"2021-09-14T01:22:51.855567Z","shell.execute_reply":"2021-09-14T01:22:53.461176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': df_submission.id, 'claim': df_cv.filter(regex=r'auc_0.81', axis=1).mean(axis=1) })\nsubmission.to_csv(path + 'Data/sumbmission/001_ensable_submission_07.csv', index=False) \n\n# submissão no kaggle: 0.81154  ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:22:55.386298Z","iopub.execute_input":"2021-09-14T01:22:55.386662Z","iopub.status.idle":"2021-09-14T01:22:56.937351Z","shell.execute_reply.started":"2021-09-14T01:22:55.386631Z","shell.execute_reply":"2021-09-14T01:22:56.936295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}