{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 div class='alert alert-success'><center> TPS-Set: ponto de partida (EDA, linha de base)</center></h1>\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/26480/logos/header.png?t=2021-04-09-00-57-05)","metadata":{}},{"cell_type":"markdown","source":"> ","metadata":{}},{"cell_type":"markdown","source":"# Descrição de dados\n\nPara esta competição, você vai prever se um cliente fez uma reclamação sobre uma apólice de seguro. A verdade fundamental claimtem valor binário, mas uma previsão pode ser qualquer número de 0.0 para 1.0, representando a probabilidade de uma reclamação. Os recursos neste conjunto de dados foram tornados anônimos e podem conter valores ausentes.\narquivos\n\n- `train.csv`: os dados de treinamento com o alvo claimcoluna\n- `test.csv`: o conjunto de teste; você estará prevendo o claimpara cada linha neste arquivo\n- `sample_submission.csv`:  um arquivo de envio de amostra no formato correto\n","metadata":{"ExecuteTime":{"end_time":"2021-09-01T01:35:59.61749Z","start_time":"2021-09-01T01:35:59.599481Z"}}},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\">  0. IMPORTAÇÕES </div> \n","metadata":{}},{"cell_type":"code","source":"import warnings\nimport random\nimport os\nimport gc","metadata":{"ExecuteTime":{"end_time":"2021-09-01T05:07:19.930452Z","start_time":"2021-09-01T05:07:19.912454Z"},"scrolled":true,"execution":{"iopub.status.busy":"2021-09-05T01:06:59.984799Z","iopub.execute_input":"2021-09-05T01:06:59.985113Z","iopub.status.idle":"2021-09-05T01:06:59.990896Z","shell.execute_reply.started":"2021-09-05T01:06:59.985086Z","shell.execute_reply":"2021-09-05T01:06:59.989998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas            as pd\nimport numpy             as np\nimport matplotlib.pyplot as plt \nimport seaborn           as sns\nimport joblib            as jb","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:51.729585Z","start_time":"2021-09-01T04:40:32.553769Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:02.127221Z","iopub.execute_input":"2021-09-05T01:07:02.127563Z","iopub.status.idle":"2021-09-05T01:07:02.132074Z","shell.execute_reply.started":"2021-09-05T01:07:02.127536Z","shell.execute_reply":"2021-09-05T01:07:02.131045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas            as pd\nimport numpy             as np\nimport matplotlib.pyplot as plt \nimport seaborn           as sns\nimport joblib            as jb\nimport matplotlib.pyplot as plt","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:51.74535Z","start_time":"2021-09-01T04:40:51.73235Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:11.677964Z","iopub.execute_input":"2021-09-05T01:07:11.678432Z","iopub.status.idle":"2021-09-05T01:07:11.687598Z","shell.execute_reply.started":"2021-09-05T01:07:11.678388Z","shell.execute_reply":"2021-09-05T01:07:11.686316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.preprocessing   import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, QuantileTransformer\nfrom sklearn.impute          import SimpleImputer\nfrom sklearn                 import metrics","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:54.078929Z","start_time":"2021-09-01T04:40:51.74835Z"},"execution":{"iopub.status.busy":"2021-09-05T01:41:08.54776Z","iopub.execute_input":"2021-09-05T01:41:08.548199Z","iopub.status.idle":"2021-09-05T01:41:08.55268Z","shell.execute_reply.started":"2021-09-05T01:41:08.548161Z","shell.execute_reply":"2021-09-05T01:41:08.551857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost               as xgb","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:54.613876Z","start_time":"2021-09-01T04:40:54.080927Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:13.954254Z","iopub.execute_input":"2021-09-05T01:07:13.954576Z","iopub.status.idle":"2021-09-05T01:07:13.958515Z","shell.execute_reply.started":"2021-09-05T01:07:13.954546Z","shell.execute_reply":"2021-09-05T01:07:13.957427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.2. Funções\nAqui centralizamos todas as funções desenvolvidas durante o projeto para melhor organização do código.","metadata":{"ExecuteTime":{"end_time":"2021-09-01T01:59:41.449318Z","start_time":"2021-09-01T01:59:41.430318Z"}}},{"cell_type":"code","source":"def jupyter_setting():\n    \n    %matplotlib inline\n      \n    #os.environ[\"WANDB_SILENT\"] = \"true\" \n    #plt.style.use('bmh') \n    #plt.rcParams['figure.figsize'] = [20,15]\n    #plt.rcParams['font.size']      = 13\n     \n    pd.options.display.max_columns = None\n    #pd.set_option('display.expand_frame_repr', False)\n\n    warnings.filterwarnings(action='ignore')\n    warnings.simplefilter('ignore')\n    warnings.filterwarnings('ignore')\n    #warnings.filterwarnings(category=UserWarning)\n    \n    pd.set_option('display.max_rows', 150)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.max_colwidth', None)\n\n    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n    #sns.palplot(sns.color_palette(icecream))\n    \n    return icecream\n\nicecream = jupyter_setting()\n\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n#warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# Colors\ndark_red = \"#b20710\"\nblack    = \"#221f1f\"\ngreen    = \"#009473\"\nmyred    = '#CD5C5C'\nmyblue   = '#6495ED'\nmygreen  = '#90EE90'\n\ncols= [myred, myblue,mygreen]","metadata":{"ExecuteTime":{"end_time":"2021-09-01T05:07:51.494487Z","start_time":"2021-09-01T05:07:51.480488Z"},"code_folding":[0],"execution":{"iopub.status.busy":"2021-09-05T01:07:17.011422Z","iopub.execute_input":"2021-09-05T01:07:17.011763Z","iopub.status.idle":"2021-09-05T01:07:17.023975Z","shell.execute_reply.started":"2021-09-05T01:07:17.011717Z","shell.execute_reply":"2021-09-05T01:07:17.022635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:56.558907Z","start_time":"2021-09-01T04:40:21.917Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:18.545812Z","iopub.execute_input":"2021-09-05T01:07:18.546159Z","iopub.status.idle":"2021-09-05T01:07:18.550711Z","shell.execute_reply.started":"2021-09-05T01:07:18.546129Z","shell.execute_reply":"2021-09-05T01:07:18.549613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def missing_zero_values_table(df):\n        mis_val         = df.isnull().sum()\n        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n                                                     0 : 'Valores ausentes', \n                                                     1 : '% de valores totais'})\n        \n        mz_table['Tipo de dados'] = df.dtypes\n        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n                                     sort_values('% de valores totais', ascending=False)\n        \n        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n            \n        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n        \n        return mz_table.reset_index()","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:56.559917Z","start_time":"2021-09-01T04:40:22.398Z"},"code_folding":[0],"execution":{"iopub.status.busy":"2021-09-05T01:07:20.037049Z","iopub.execute_input":"2021-09-05T01:07:20.037434Z","iopub.status.idle":"2021-09-05T01:07:20.043684Z","shell.execute_reply.started":"2021-09-05T01:07:20.037405Z","shell.execute_reply":"2021-09-05T01:07:20.042846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def describe(df):\n    var = df.columns\n\n    # Medidas de tendência central, média e mediana \n    ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n    ct2 = pd.DataFrame(df[var].apply(np.median)).T\n\n    # Dispensão - str, min , max range skew, kurtosis\n    d1 = pd.DataFrame(df[var].apply(np.std)).T\n    d2 = pd.DataFrame(df[var].apply(min)).T\n    d3 = pd.DataFrame(df[var].apply(max)).T\n    d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n    d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n    d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n    d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n\n    # concatenete \n    m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n    m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n    \n    return m","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:56.560909Z","start_time":"2021-09-01T04:40:22.847Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:21.439612Z","iopub.execute_input":"2021-09-05T01:07:21.440079Z","iopub.status.idle":"2021-09-05T01:07:21.449558Z","shell.execute_reply.started":"2021-09-05T01:07:21.440035Z","shell.execute_reply":"2021-09-05T01:07:21.448421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def graf_bar_churn(df, col, title, xlabel, ylabel, tol = 0):\n    \n    #ax    = df.groupby(['churn_cat'])['churn_cat'].count()\n    ax     = df    \n    colors = cols\n    \n    if tol == 0: \n        total  = sum(ax)\n        ax = (ax).plot(kind    ='bar',\n                   stacked = True,\n                    width = .5,\n                   rot     = 0,\n                   color   = colors)\n    else:\n        total  = tol     \n        \n        ax = (ax).plot(kind    ='bar',\n                       stacked = True,\n                       width = .5,\n                       rot     = 0,figsize = (10,6),\n                       color   = colors)\n\n    #ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n    \n    #y_fmt = tick.FormatStrFormatter('%.0f') \n    #ax.yaxis.set_major_formatter(y_fmt)\n\n    title   = title + ' \\n'\n    xlabel  = '\\n ' + xlabel \n    ylabel  = ylabel + ' \\n'\n    \n    ax.set_title(title  , fontsize=22)\n    ax.set_xlabel(xlabel, fontsize=13)\n    ax.set_ylabel(ylabel, fontsize=13)    \n\n    min = [0,23000000]\n    #ax.set_ylim(min)\n    \n    for i in ax.patches:\n        # get_width pulls left or right; get_y pushes up or down\n        width, height = i.get_width(), i.get_height()\n        x, y = i.get_xy()        \n        \n        ax.annotate(str(round((i.get_height() * 100.0 / total), 1) )+'%', \n                    (i.get_x()+.3*width, \n                     i.get_y()+.5*height),\n                     color   = 'white',\n                     weight = 'bold',\n                     size   = 14)","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:40:56.561912Z","start_time":"2021-09-01T04:40:23.39Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:22.66007Z","iopub.execute_input":"2021-09-05T01:07:22.660401Z","iopub.status.idle":"2021-09-05T01:07:22.669597Z","shell.execute_reply.started":"2021-09-05T01:07:22.660372Z","shell.execute_reply":"2021-09-05T01:07:22.668551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.3. Carregar Dados\nExistem 2 conjuntos de dados que são usados na análise, eles são o conjunto de dados de treinamento e de teste. O principal uso do conjunto de dados de treino é treinar os modelos e usá-lo para prever o conjunto de dados de teste. \n\nEnquanto o arquivo de envio de amostra é usado para informar os participantes sobre a inscrição prevista para a competição. ","metadata":{}},{"cell_type":"code","source":"path = '/content/drive/MyDrive/kaggle/07. Tabular Playground Series - Ago 2021/'\npath = '../input/tabular-playground-series-sep-2021/'","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:41:51.573615Z","start_time":"2021-09-01T04:41:51.440651Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:24.823661Z","iopub.execute_input":"2021-09-05T01:07:24.82403Z","iopub.status.idle":"2021-09-05T01:07:24.828153Z","shell.execute_reply.started":"2021-09-05T01:07:24.824Z","shell.execute_reply":"2021-09-05T01:07:24.827153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_row  = pd.read_csv(path + 'train.csv', index_col='id')\ndf_test_row   = pd.read_csv(path + 'test.csv',index_col='id')\ndf_submission = pd.read_csv(path + 'sample_solution.csv')\n\ndf_train_row.shape, df_test_row.shape, df_submission.shape","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:43:00.468408Z","start_time":"2021-09-01T04:42:37.230683Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:28.044614Z","iopub.execute_input":"2021-09-05T01:07:28.044982Z","iopub.status.idle":"2021-09-05T01:07:57.555843Z","shell.execute_reply.started":"2021-09-05T01:07:28.044951Z","shell.execute_reply":"2021-09-05T01:07:57.555067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\">  1.0. EDA  </div> ","metadata":{}},{"cell_type":"code","source":"df1_train = df_train_row.copy()\ndf1_test  = df_test_row.copy()","metadata":{"ExecuteTime":{"end_time":"2021-09-01T04:43:00.88368Z","start_time":"2021-09-01T04:43:00.472422Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:57.557285Z","iopub.execute_input":"2021-09-05T01:07:57.557623Z","iopub.status.idle":"2021-09-05T01:07:58.065231Z","shell.execute_reply.started":"2021-09-05T01:07:57.557588Z","shell.execute_reply":"2021-09-05T01:07:58.064384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.2. Dimensão do DataSet","metadata":{"ExecuteTime":{"end_time":"2021-09-01T02:06:11.945295Z","start_time":"2021-09-01T02:06:11.941294Z"}}},{"cell_type":"code","source":"print('TREINO')\nprint('Number of Rows: {}'.format(df1_train.shape[0]))\nprint('Number of Columns: {}'.format(df1_train.shape[1]), end='\\n\\n')\n\nprint('TESTE')\nprint('Number of Rows: {}'.format(df1_test.shape[0]))\nprint('Number of Columns: {}'.format(df1_test.shape[1]))","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:51:55.097793Z","start_time":"2021-09-01T03:51:54.991345Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:58.067062Z","iopub.execute_input":"2021-09-05T01:07:58.067421Z","iopub.status.idle":"2021-09-05T01:07:58.075758Z","shell.execute_reply.started":"2021-09-05T01:07:58.067385Z","shell.execute_reply":"2021-09-05T01:07:58.0748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.3. Tipo de Dados","metadata":{}},{"cell_type":"code","source":"df1_train.info()","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:51:56.677272Z","start_time":"2021-09-01T03:51:56.04688Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:58.077605Z","iopub.execute_input":"2021-09-05T01:07:58.078016Z","iopub.status.idle":"2021-09-05T01:07:58.099446Z","shell.execute_reply.started":"2021-09-05T01:07:58.077979Z","shell.execute_reply":"2021-09-05T01:07:58.098425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1_train.dtypes","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:51:56.693275Z","start_time":"2021-09-01T03:51:56.680233Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:58.100799Z","iopub.execute_input":"2021-09-05T01:07:58.101167Z","iopub.status.idle":"2021-09-05T01:07:58.11436Z","shell.execute_reply.started":"2021-09-05T01:07:58.101127Z","shell.execute_reply":"2021-09-05T01:07:58.11342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1_test.info()","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:51:57.225133Z","start_time":"2021-09-01T03:51:57.199097Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:58.11563Z","iopub.execute_input":"2021-09-05T01:07:58.116209Z","iopub.status.idle":"2021-09-05T01:07:58.136239Z","shell.execute_reply.started":"2021-09-05T01:07:58.116164Z","shell.execute_reply":"2021-09-05T01:07:58.135451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1_test.dtypes","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:51:57.600033Z","start_time":"2021-09-01T03:51:57.574994Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:58.137406Z","iopub.execute_input":"2021-09-05T01:07:58.137768Z","iopub.status.idle":"2021-09-05T01:07:58.151932Z","shell.execute_reply.started":"2021-09-05T01:07:58.137701Z","shell.execute_reply":"2021-09-05T01:07:58.15108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.4. Idenficar Variáveis Ausentes (NA)\nVamos verificar os valores ausentes em cada variável conjunto de treinono e teste.","metadata":{}},{"cell_type":"code","source":"missing = missing_zero_values_table(df1_train)\nmissing[:].style.background_gradient(cmap='Reds')","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:51:59.088074Z","start_time":"2021-09-01T03:51:58.473884Z"},"execution":{"iopub.status.busy":"2021-09-05T01:07:58.155696Z","iopub.execute_input":"2021-09-05T01:07:58.156077Z","iopub.status.idle":"2021-09-05T01:07:58.60327Z","shell.execute_reply.started":"2021-09-05T01:07:58.156048Z","shell.execute_reply":"2021-09-05T01:07:58.602476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing = missing_zero_values_table(df1_test)\nmissing[:].style.background_gradient(cmap='Reds')","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:51:59.597652Z","start_time":"2021-09-01T03:51:59.297652Z"},"execution":{"iopub.status.busy":"2021-09-05T01:11:04.257521Z","iopub.execute_input":"2021-09-05T01:11:04.257862Z","iopub.status.idle":"2021-09-05T01:11:04.493349Z","shell.execute_reply.started":"2021-09-05T01:11:04.257832Z","shell.execute_reply":"2021-09-05T01:11:04.492421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`**NOTA:**`\n\n- O máximo de valor ausente em uma observação é 14 e o mais baixo é nenhum valor ausente.\nCuriosamente, a distribuição de valor ausente (base de linha) é exatamente a mesma entre o conjunto de dados de treino e teste.\n\n- Embora haja cerca de 2% de valor ausente em cada recurso, há cerca de 38% das observações (base de linha) que não tem valores ausentes.\n\n- No reverso, existem 62% das observações com valor faltante.\n\n- 1 a 3 valores ausentes nas observações a constituem cerca de 41% do total de observações.","metadata":{}},{"cell_type":"markdown","source":"### 1.1.6. Estatística Descritiva\nAbaixo estão as estatísticas básicas para cada variável que contém informações sobre contagem, média, desvio padrão, mínimo, 1º quartil, mediana, 3º quartil e máximo.","metadata":{}},{"cell_type":"code","source":"df_num = df1_train.select_dtypes(np.number)\ndf_cat = df1_train.select_dtypes(exclude=[np.number])\n\ndf_num.shape, df_cat.shape\n\nprint('Temos {} variávies numéricas e {} categóricas.'.format(df_num.shape[1], df_cat.shape[1]))","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:52:03.594866Z","start_time":"2021-09-01T03:52:03.096368Z"},"execution":{"iopub.status.busy":"2021-09-05T01:11:10.671908Z","iopub.execute_input":"2021-09-05T01:11:10.672909Z","iopub.status.idle":"2021-09-05T01:11:10.96895Z","shell.execute_reply.started":"2021-09-05T01:11:10.672859Z","shell.execute_reply":"2021-09-05T01:11:10.967574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.1.6.1. Atributos Numéricos","metadata":{}},{"cell_type":"code","source":"df_summary = describe(df1_train.select_dtypes(np.number).copy())\ndf_summary.sample(10)","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:52:46.920189Z","start_time":"2021-09-01T03:52:05.327572Z"},"execution":{"iopub.status.busy":"2021-09-05T01:11:17.039205Z","iopub.execute_input":"2021-09-05T01:11:17.039521Z","iopub.status.idle":"2021-09-05T01:11:53.83411Z","shell.execute_reply.started":"2021-09-05T01:11:17.039491Z","shell.execute_reply":"2021-09-05T01:11:53.83332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Análise Gráfica","metadata":{}},{"cell_type":"markdown","source":"### 1.2.1. Correlação\nVamos examinar a correlação entre as variáveis.","metadata":{}},{"cell_type":"code","source":"df = df1_train.corr().round(5)\n\n# Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\nmask = np.zeros_like(df)\nmask[np.triu_indices_from(mask)] = True\n\n# Making a plot\nplt.figure(figsize=(16,16))\nax = sns.heatmap(df, annot=False, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n\nax.set_title(\"Mapa de calor de correlação das variável\", fontsize=17)\n\nplt.setp(ax.get_xticklabels(), \n         rotation      = 90, \n         ha            = \"right\",\n         rotation_mode = \"anchor\", \n         weight        = \"normal\")\n\nplt.setp(ax.get_yticklabels(), \n         weight        = \"normal\",\n         rotation_mode = \"anchor\", \n         rotation      = 0, \n         ha            = \"right\");","metadata":{"ExecuteTime":{"end_time":"2021-09-01T02:24:48.232229Z","start_time":"2021-09-01T02:24:07.687714Z"},"execution":{"iopub.status.busy":"2021-09-05T01:12:04.876296Z","iopub.execute_input":"2021-09-05T01:12:04.876631Z","iopub.status.idle":"2021-09-05T01:12:39.278266Z","shell.execute_reply.started":"2021-09-05T01:12:04.876599Z","shell.execute_reply":"2021-09-05T01:12:39.27746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como podemos ver, a correlação está entre ~-0,05 e ~0,02, o que é muito pequeno. Portanto, as variáveis são fracamente correlacionados. \n\nExistem alguns recursos com correlação relativamente baixa com o valor alvo, mesmo em comparação com outros recursos, isso pode sugerir uma exclusão dessas variáveis.","metadata":{}},{"cell_type":"code","source":"df[(df[\"claim\"]>-0.001) & (df[\"claim\"]<0.001)][\"claim\"]","metadata":{"ExecuteTime":{"end_time":"2021-09-01T02:28:36.419011Z","start_time":"2021-09-01T02:28:36.398996Z"},"execution":{"iopub.status.busy":"2021-09-05T01:13:43.450684Z","iopub.execute_input":"2021-09-05T01:13:43.451049Z","iopub.status.idle":"2021-09-05T01:13:43.459212Z","shell.execute_reply.started":"2021-09-05T01:13:43.451018Z","shell.execute_reply":"2021-09-05T01:13:43.458206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.2. Distribuição","metadata":{}},{"cell_type":"markdown","source":"#### 1.2.2.1. Target\nVamos ver as ocorrências de números individuais do conjunto de dados de treino.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5, 5))\n\npie = ax.pie([len(df1_train), len(df1_test)],\n             labels   = [\"Train dataset\", \"Test dataset\"],\n             colors   = [\"salmon\", \"teal\"],\n             textprops= {\"fontsize\": 15},\n             autopct  = '%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Comparação de comprimento do conjunto de dados \\n\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","metadata":{"ExecuteTime":{"end_time":"2021-09-01T02:30:39.896717Z","start_time":"2021-09-01T02:30:39.615485Z"},"execution":{"iopub.status.busy":"2021-09-05T01:13:50.372068Z","iopub.execute_input":"2021-09-05T01:13:50.372384Z","iopub.status.idle":"2021-09-05T01:13:50.483554Z","shell.execute_reply.started":"2021-09-05T01:13:50.372354Z","shell.execute_reply":"2021-09-05T01:13:50.482786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O número de pessoas que não reclamam e reclamam (0 e 1) é quase igual a 480.404 e 477.515, respectivamente. Em termos de porcentagem, tanto as pessoas que afirmam quanto não afirmam ficam em torno de 50%, neste caso não precisamos tratamento para dados desbalanceados. ","metadata":{}},{"cell_type":"markdown","source":"Referência: https://www.kaggle.com/desalegngeb/sept-2021-tps-eda-model","metadata":{}},{"cell_type":"code","source":"L    = len(df1_train.columns[0:60])\nnrow = int(np.ceil(L/6))\nncol = 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\nfig.subplots_adjust(top=0.95)\ni = 1\n\nfor feature in df1_train.columns[0:60]:\n    \n    plt.subplot(nrow, ncol, i)\n    \n    ax = sns.kdeplot(df1_train[feature], shade=True, color='salmon',  alpha=0.5, label='train')\n    ax = sns.kdeplot(df1_test[feature], shade=True, color='teal',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    \n    i += 1\n    \nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T01:14:51.069321Z","iopub.execute_input":"2021-09-05T01:14:51.069723Z","iopub.status.idle":"2021-09-05T01:21:03.918728Z","shell.execute_reply.started":"2021-09-05T01:14:51.069682Z","shell.execute_reply":"2021-09-05T01:21:03.917974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTA:**\n\n- Os conjuntos de treinamento e teste têm aproximadamente as mesmas distribuições em termos de variáveis;\n- Temos poucas variáveis com distribuições normais;\n- A maioria das variáveis tem distribuições distorcidas.\n\nPrecisamos pensar em como fazer tudo isso normalmente distribuído se decidirmos usar modelos não baseados em árvore.\n\n> A verificação da correlação não revelou relações significativas entre as características (a maioria estava entre 0,02 e -0,05).\n","metadata":{}},{"cell_type":"markdown","source":"#### 1.2.2.1. Detecção de Outlier","metadata":{}},{"cell_type":"markdown","source":"##### 1.2.2.1.1. Data Train ","metadata":{}},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/suharkov/sep-2021-playground-eda-no-model-for-now\ndf_plot = ((df1_train - df1_train.min())/(df1_train.max() - df1_train.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\n\nfor i, (x) in enumerate([(1,30), (30,60), (60,90), (90,120)]): \n    sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]);","metadata":{"execution":{"iopub.status.busy":"2021-09-05T01:21:43.052851Z","iopub.execute_input":"2021-09-05T01:21:43.053207Z","iopub.status.idle":"2021-09-05T01:22:07.754436Z","shell.execute_reply.started":"2021-09-05T01:21:43.053162Z","shell.execute_reply":"2021-09-05T01:22:07.753643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 1.2.2.1.2. Data Test","metadata":{}},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/suharkov/sep-2021-playground-eda-no-model-for-now\ndf_plot = ((df1_test - df1_test.min())/(df1_test.max() - df1_test.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\n\nfor i, (x) in enumerate([(1,30), (30,60), (60,90), (90,120)]): \n    sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]);","metadata":{"execution":{"iopub.status.busy":"2021-09-05T01:22:09.916716Z","iopub.execute_input":"2021-09-05T01:22:09.917069Z","iopub.status.idle":"2021-09-05T01:22:23.93997Z","shell.execute_reply.started":"2021-09-05T01:22:09.917041Z","shell.execute_reply":"2021-09-05T01:22:23.9392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**`NOTA:`**\n\nAcima observamos que temos muitos outliers em ambos conjunto de dados, no processamento vamos trartá-los.","metadata":{}},{"cell_type":"markdown","source":"#### 1.2.2.3. Claim\nA variável alvo tem um valor de 0 a 1 que indica pessoas que não reclamam e reclamam o seguro. Vamos verificar a distribuição da variável de reclamação (claim).","metadata":{"ExecuteTime":{"end_time":"2021-09-01T02:55:35.142949Z","start_time":"2021-09-01T02:55:35.135917Z"}}},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nax = sns.countplot(x=df1_train['claim'], palette='viridis')\nax.set_title('Distribuição da variável Clain', fontsize=20, y=1.05)\n\nsns.despine(right=True)\nsns.despine(offset=10, trim=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T01:33:23.901575Z","iopub.execute_input":"2021-09-05T01:33:23.901946Z","iopub.status.idle":"2021-09-05T01:33:24.218184Z","shell.execute_reply.started":"2021-09-05T01:33:23.901916Z","shell.execute_reply":"2021-09-05T01:33:24.217261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O número de pessoas que não reclamam e reclamam (0 e 1) é quase igual a 480.404 e 477.515, respectivamente. Em termos de porcentagem, tanto as pessoas que afirmam quanto não afirmam ficam em torno de 50%, neste caso não precisamos tratamento para dados desbalanceados.","metadata":{"ExecuteTime":{"end_time":"2021-09-01T02:35:21.692656Z","start_time":"2021-09-01T02:35:21.687617Z"}}},{"cell_type":"markdown","source":"#### 1.2.2.4. Variáveis preditoras  vs Target.","metadata":{}},{"cell_type":"markdown","source":"Referência: https://www.kaggle.com/desalegngeb/sept-2021-tps-eda-model","metadata":{}},{"cell_type":"code","source":"L    = len(df1_train.columns[0:60])\nnrow = int(np.ceil(L/6))\nncol = 6\ni    = 1\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\nfig.subplots_adjust(top=0.95)\n\nfor feature in df1_train.columns[0:60]:\n    \n    plt.subplot(nrow, ncol, i)\n    \n    ax = sns.kdeplot(df1_train[feature], \n                     shade    = True, \n                     palette  = 'viridis',  \n                     alpha    = 0.5, \n                     hue      = df1_train['claim'], \n                     multiple = \"stack\")\n    \n    plt.xlabel(feature, fontsize=9)\n    \n    i += 1\n    \nplt.suptitle('DistPlot: Variável de treino vs target', fontsize=20)\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:58:32.470046Z","start_time":"2021-09-01T03:58:18.265564Z"},"execution":{"iopub.status.busy":"2021-09-05T01:34:00.863331Z","iopub.execute_input":"2021-09-05T01:34:00.863662Z","iopub.status.idle":"2021-09-05T01:38:24.872079Z","shell.execute_reply.started":"2021-09-05T01:34:00.863632Z","shell.execute_reply":"2021-09-05T01:38:24.871093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\">  2.0. Modelo Baseline XGB </div> \n\nNesta etapa, treinaremos nosso modelo XGBClassifier de linha de base simples. Existem valores ausentes em nossos dados. Vamos preenchê-los com uma média e dimensionar todos os dados.","metadata":{"ExecuteTime":{"end_time":"2021-09-01T03:59:06.751308Z","start_time":"2021-09-01T03:59:06.743311Z"}}},{"cell_type":"code","source":"gc.collect()","metadata":{"ExecuteTime":{"end_time":"2021-09-01T05:09:23.648253Z","start_time":"2021-09-01T05:09:23.456252Z"},"execution":{"iopub.status.busy":"2021-09-05T01:38:24.873777Z","iopub.execute_input":"2021-09-05T01:38:24.874288Z","iopub.status.idle":"2021-09-05T01:38:25.108505Z","shell.execute_reply.started":"2021-09-05T01:38:24.874212Z","shell.execute_reply":"2021-09-05T01:38:25.107532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X    = df1_train.drop('claim', axis=1)\ny    = df1_train['claim']\ncols = X.columns\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size    = 0.2,\n                                                      shuffle      = True, \n                                                      stratify     = y,\n                                                      random_state = 0)\n\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape ","metadata":{"ExecuteTime":{"end_time":"2021-09-01T05:09:31.224404Z","start_time":"2021-09-01T05:09:25.712614Z"},"execution":{"iopub.status.busy":"2021-09-05T01:38:25.110518Z","iopub.execute_input":"2021-09-05T01:38:25.111083Z","iopub.status.idle":"2021-09-05T01:38:26.947994Z","shell.execute_reply.started":"2021-09-05T01:38:25.111043Z","shell.execute_reply":"2021-09-05T01:38:26.946888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nX_train = pd.DataFrame(imputer.fit_transform(X_train),  columns=cols)\nX_valid = pd.DataFrame(imputer.fit_transform(X_valid),  columns=cols)\nX_test  = pd.DataFrame(imputer.fit_transform(df1_test),  columns=cols)","metadata":{"ExecuteTime":{"end_time":"2021-09-01T05:09:38.09473Z","start_time":"2021-09-01T05:09:33.521371Z"},"execution":{"iopub.status.busy":"2021-09-05T01:40:30.257968Z","iopub.execute_input":"2021-09-05T01:40:30.258315Z","iopub.status.idle":"2021-09-05T01:40:33.34456Z","shell.execute_reply.started":"2021-09-05T01:40:30.258286Z","shell.execute_reply":"2021-09-05T01:40:33.343721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T01:40:34.519717Z","iopub.execute_input":"2021-09-05T01:40:34.520083Z","iopub.status.idle":"2021-09-05T01:40:34.629329Z","shell.execute_reply.started":"2021-09-05T01:40:34.520053Z","shell.execute_reply":"2021-09-05T01:40:34.628323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'random_state': 0,\n          'predictor'   : 'gpu_predictor',\n          'tree_method' : 'gpu_hist',\n          'eval_metric' : 'auc'}\n\nmodel_baseline = xgb.XGBClassifier(**params)\n\nscalers = [None, StandardScaler(), RobustScaler(), MinMaxScaler(), \n           MaxAbsScaler(), QuantileTransformer(output_distribution='normal', random_state=0)]\n\nfor scaler in scalers: \n    \n    if scaler!=None:\n        X_train_s = scaler.fit_transform(X_train)\n        X_valid_s = scaler.fit_transform(X_valid)\n    else:\n        X_train_s = X_train\n        X_valid_s = X_valid\n                \n    model_baseline.fit(X_train_s, y_train, verbose = False)\n    y_hat = model_baseline.predict_proba(X_valid_s)[:, 1]\n    \n    fpr, tpr, thresholds = metrics.roc_curve(y_valid, y_hat)\n    \n    auc = metrics.auc(fpr, tpr)\n    print('Validaçao AUC: {:2.5f} => {}'.format(auc, scaler))","metadata":{"ExecuteTime":{"end_time":"2021-09-01T05:09:51.904845Z","start_time":"2021-09-01T05:09:38.097558Z"},"execution":{"iopub.status.busy":"2021-09-05T01:41:20.804813Z","iopub.execute_input":"2021-09-05T01:41:20.805136Z","iopub.status.idle":"2021-09-05T01:42:35.062501Z","shell.execute_reply.started":"2021-09-05T01:41:20.805107Z","shell.execute_reply":"2021-09-05T01:42:35.061489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Com scaler StandarScaler obtivemos uma AUC de `0.73511`, vamos fazer uma validação cruzada com as normalizações.","metadata":{}},{"cell_type":"code","source":"%%time\n\ngc.collect()\n\nscalers = [None, StandardScaler(), RobustScaler(), MinMaxScaler(), \n           MaxAbsScaler(), QuantileTransformer(output_distribution='normal', random_state=0)]\n\nfor scaler in scalers: \n\n    FOLDS               = 5\n    df_submission.claim = 0\n    auc                 = []\n    lloss               = []\n    f1                  = []\n\n    kfold               = KFold(n_splits = FOLDS, random_state = 0, shuffle = True)\n    \n    if scaler!=None:\n        X_ts = scaler.fit_transform(X_test.copy())\n    else:\n        X_ts = X_test.copy()\n\n    print('='*80)\n    print('Scaler: {}'.format(scaler))\n    print('='*80)\n\n    for i, (train_idx, test_idx) in enumerate(kfold.split(X_train)):\n\n        i+=1\n        \n        X_tr, y_tr = X_train.iloc[train_idx], y_train.iloc[train_idx]\n        X_vl, y_vl = X_train.iloc[test_idx], y_train.iloc[test_idx]\n\n        # Scaler\n        if scaler!=None:    \n            X_tr = scaler.fit_transform(X_tr)\n            X_vl = scaler.fit_transform(X_vl)                \n\n        model = xgb.XGBClassifier(**params)\n\n        model.fit(X_tr, y_tr)\n\n        y_hat_prob = model.predict_proba(X_vl)[:, 1]\n        y_hat      = (y_hat_prob >.5).astype(int) \n        \n        fpr, tpr, thresholds = metrics.roc_curve(y_vl, y_hat_prob)\n                 \n        log_loss_     = metrics.log_loss(y_vl, y_hat_prob)                \n        f1_score_     = metrics.f1_score(y_vl, y_hat)        \n        auc_          = metrics.auc(fpr, tpr)    \n                \n        print('[Fold {}] AUC: {:.5f} - F1: {:.5f} - L. LOSS: {:.5f}'.format(i, auc_, f1_score_, log_loss_))\n\n        df_submission.claim += model.predict_proba(X_ts)[:, 1] / FOLDS\n\n        f1.append(f1_score_)\n        lloss.append(log_loss_)\n        auc.append(auc_)\n\n    auc_mean   = np.mean(auc)\n    auc_std    = np.std(auc)\n    lloss_mean = np.mean(lloss)\n    f1_mean    = np.mean(f1)\n    \n    print('-'*80)\n    print('[Mean Fold] AUC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - L. LOSS: {:.5f}'.format(auc_mean,\n                                                                                       auc_std,\n                                                                                       f1_mean, \n                                                                                       lloss_mean))\n    print('='*80)\n    print('')\n    \n    # Gerar o arquivo de submissão \n    name_file_submission = '001_xgb_submission_baseline_' + str(scaler).lower()[:4] + '.csv'\n    df_submission.to_csv(name_file_submission, index = False)\n    \n    #gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T01:57:43.126521Z","iopub.execute_input":"2021-09-05T01:57:43.126871Z","iopub.status.idle":"2021-09-05T02:03:53.942004Z","shell.execute_reply.started":"2021-09-05T01:57:43.126839Z","shell.execute_reply":"2021-09-05T02:03:53.941202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Na validação cruzada obtivemos uma `AUC` de `0.77727` com um desvio padrão de `0.00149` sem fazer o scaler, vamos gerar um arquivo para submissão. ","metadata":{}},{"cell_type":"markdown","source":"**`Nota:`**\n\nNa validação cruzada que foi realizada, mostra que não fazer a normalização temos a melhor AUC, porém abaixo podemos observar que a melhor scaler na submissão foi de 0.69320 com a StanderScaler, abaixo um resumo:    \n\n- AUC: 0.64631 => Sem normalização \n- AUC: 0.67258 => RobustScaler \n- AUC: `0.69320` => StanderScaler \n- AUC: 0.60872 => MinMaxScaler \n- AUC: 0.63037 => MaxAbsScaler ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\">\n\nNa validação cruzada obtivemos uma `AUC` de `0.77727` com um desvio padrão de `0.00149` sem fazer o scaler, vamos gerar um arquivo para submissão. \n    \n    \n**Nota:**\n   \nNa validação cruzada que foi realizada, mostra que não fazer a normalização temos a melhor AUC, porém abaixo podemos observar que a melhor scaler na submissão foi de 0.69320 com a StanderScaler, abaixo um resumo:        \n- AUC: 0.64631 => Sem normalização \n- AUC: 0.67258 => RobustScaler \n- AUC: 0.69320 => StanderScaler \n- AUC: 0.60872 => MinMaxScaler \n- AUC: 0.63037 => MaxAbsScaler \n      \nAcrescentei na validação o scaler QuantileTransformer que teve uma AUC de 0.72080, batendo o StanderScaler na validação e o no kaggle com AUC de `0.74479` que é melhor que a validação realizada neste notebook.\n    ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}