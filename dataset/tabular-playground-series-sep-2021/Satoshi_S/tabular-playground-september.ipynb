{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-20T15:57:20.925805Z","iopub.execute_input":"2021-09-20T15:57:20.926199Z","iopub.status.idle":"2021-09-20T15:57:20.94215Z","shell.execute_reply.started":"2021-09-20T15:57:20.926121Z","shell.execute_reply":"2021-09-20T15:57:20.941064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#referred to https://www.kaggle.com/satorushibata/optimize-lightgbm-hyperparameter-with-optuna-gpu to use gpu.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries\n\nimport numpy as np\nfrom collections import Counter\nimport pandas as pd\nimport lightgbm as lgbm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score,accuracy_score,log_loss\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\n#optimizer \n\nfrom functools import partial\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2021-09-20T15:57:25.099105Z","iopub.execute_input":"2021-09-20T15:57:25.099454Z","iopub.status.idle":"2021-09-20T15:57:28.195209Z","shell.execute_reply.started":"2021-09-20T15:57:25.099425Z","shell.execute_reply":"2021-09-20T15:57:28.194196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the training data \n\ntrain = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\",index_col =0)\ntest = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\",index_col =0)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T15:57:28.868428Z","iopub.execute_input":"2021-09-20T15:57:28.868756Z","iopub.status.idle":"2021-09-20T15:58:10.362543Z","shell.execute_reply.started":"2021-09-20T15:57:28.86872Z","shell.execute_reply":"2021-09-20T15:58:10.361635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for improving score according to the discussion (https://www.kaggle.com/c/tabular-playground-series-sep-2021/discussion/270206 ) \ntrain[\"nan_count\"] =train.isnull().sum(axis=1)\ntest[\"nan_count\"] =test.isnull().sum(axis=1)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T15:58:17.198754Z","iopub.execute_input":"2021-09-20T15:58:17.199089Z","iopub.status.idle":"2021-09-20T15:58:17.537847Z","shell.execute_reply.started":"2021-09-20T15:58:17.199056Z","shell.execute_reply":"2021-09-20T15:58:17.536885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#separate targets \ny = train['claim']\nfeatures = train.drop(['claim'],axis=1)\n\ntrain.shape\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-20T15:58:23.94871Z","iopub.execute_input":"2021-09-20T15:58:23.949033Z","iopub.status.idle":"2021-09-20T15:58:24.221295Z","shell.execute_reply.started":"2021-09-20T15:58:23.949002Z","shell.execute_reply":"2021-09-20T15:58:24.22031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_mean = features.mean()\nfeatures_std = features.std()\nfeatures_norm = (features - features_mean) /features_std\n\ntest_mean = test.mean()\ntest_std = test.std()\ntest_norm = (test - test_mean) /test_std\ntest_norm.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:01:35.543884Z","iopub.execute_input":"2021-09-20T16:01:35.544268Z","iopub.status.idle":"2021-09-20T16:01:37.122798Z","shell.execute_reply.started":"2021-09-20T16:01:35.544229Z","shell.execute_reply":"2021-09-20T16:01:37.121844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split the date to train and test\nX_train,X_test,y_train,y_test = train_test_split(features_norm,y,test_size =0.3,random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:00:11.658356Z","iopub.execute_input":"2021-09-20T16:00:11.658678Z","iopub.status.idle":"2021-09-20T16:00:13.272722Z","shell.execute_reply.started":"2021-09-20T16:00:11.658649Z","shell.execute_reply":"2021-09-20T16:00:13.271845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get names of columns with missing values\n#cols_with_missing = [col for col in X_train.columns\n#                     if X_train[col].isnull().any()]\n#len(cols_with_missing)\n\n#118 columns include Nan values.","metadata":{"execution":{"iopub.status.busy":"2021-09-07T22:29:03.5437Z","iopub.execute_input":"2021-09-07T22:29:03.544119Z","iopub.status.idle":"2021-09-07T22:29:03.54881Z","shell.execute_reply.started":"2021-09-07T22:29:03.544069Z","shell.execute_reply":"2021-09-07T22:29:03.54768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing_val_count_by_column = (features.isnull().sum())\n#print(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2021-09-07T22:29:03.550158Z","iopub.execute_input":"2021-09-07T22:29:03.55046Z","iopub.status.idle":"2021-09-07T22:29:03.560592Z","shell.execute_reply.started":"2021-09-07T22:29:03.550417Z","shell.execute_reply":"2021-09-07T22:29:03.559233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#an extension to imputation \n\n#X_train_plus = X_train.copy()\n#X_test_plus = X_test.copy()\n\n#cols_with_missing = [col for col in X_train.columns\n#                     if X_train[col].isnull().any()]\n\n#make new columns indicationg what will be imputed\n#for col in cols_with_missing:\n#    X_train_plus[col +'_was_missing'] =X_train_plus[col].isnull()\n#    X_test_plus[col +'_was_missing'] = X_test_plus[col].isnull()\n\n#from sklearn.impute import SimpleImputer\n\n#my_imputer = SimpleImputer()\n#imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n#imputed_X_test = pd.DataFrame(my_imputer.transform(X_test_plus))\n\n#Imputation removed column name; put them back\n#imputed_X_train.columns = X_train_plus.columns\n#imputed_X_test.columns = X_test_plus.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-07T22:31:51.909464Z","iopub.execute_input":"2021-09-07T22:31:51.909873Z","iopub.status.idle":"2021-09-07T22:33:07.80888Z","shell.execute_reply.started":"2021-09-07T22:31:51.909837Z","shell.execute_reply":"2021-09-07T22:33:07.807672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing_val_percents_by_column = features.isnull().sum()/len(features)\n#print(missing_val_percents_by_column)\n\n#for i in range(len(missing_val_percents_by_column)):\n#    print(missing_val_percents_by_column[i])\n# missing val percents of all the columns are closed to 1.6%\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reffered to https://www.kaggle.com/andreshg/xgboost-optuna-hyperparameter-tunning for hyperparameter tuning","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial,X,y, name='xgb'):\n    params = param = {\n        'tree_method':'gpu_hist',  \n        'lambda': trial.suggest_loguniform(\n            'lambda', 1e-3, 10.0\n        ),\n        'alpha': trial.suggest_loguniform(\n            'alpha', 1e-3, 10.0\n        ),\n        'colsample_bytree': trial.suggest_categorical(\n            'colsample_bytree', [0.5,0.6,0.7,0.8,0.9,1.0]\n        ),\n        'subsample': trial.suggest_categorical(\n            'subsample', [0.6,0.7,0.8,1.0]\n        ),\n        'learning_rate': trial.suggest_categorical(\n            'learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]\n        ),\n        'n_estimators': trial.suggest_categorical(\n            \"n_estimators\", [150, 200, 300, 3000]\n        ),\n        'max_depth': trial.suggest_categorical(\n            'max_depth', [4,5,7,9,11,13,15,17]\n        ),\n        'random_state': 42,\n        'min_child_weight': trial.suggest_int(\n            'min_child_weight', 1, 300\n        ),\n    }\n\n    model =  XGBRegressor(**params)\n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=50,verbose=False)\n\n\n    train_score = np.round(np.sqrt(mean_squared_error(y_train, model.predict(X_train))), 5)\n    test_score = np.round(np.sqrt(mean_squared_error(y_test, model.predict(X_test))), 5)\n                  \n    print(f'TRAIN RMSE : {train_score} || TEST RMSE : {test_score}')\n                  \n    return test_score","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:02:01.852809Z","iopub.execute_input":"2021-09-20T16:02:01.853139Z","iopub.status.idle":"2021-09-20T16:02:01.866729Z","shell.execute_reply.started":"2021-09-20T16:02:01.853107Z","shell.execute_reply":"2021-09-20T16:02:01.86146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\n#optimize = partial(objective,X=X_train,y=y_train)\n\n#study_lgbm = optuna.create_study(direction ='minimize')\n#study_lgbm.optimize(optimize,n_trials=50)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:02:06.077813Z","iopub.execute_input":"2021-09-20T16:02:06.078138Z","iopub.status.idle":"2021-09-20T17:31:49.003487Z","shell.execute_reply.started":"2021-09-20T16:02:06.078108Z","shell.execute_reply":"2021-09-20T17:31:49.002695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(f\"\\tBest value (rmse): {study_lgbm.best_value:.5f}\")\n#print(f\"\\tBest params:\")\n\n#for key, value in study_lgbm.best_params.items():\n#   print(f\"\\t\\t{key}: {value}\")\n    \n\n#Best value (rmse): 0.40686\n#\tBest params:\n#\t\tlambda: 1.7503469572793253\n#\t\talpha: 0.044038476141827085\n#\t\tcolsample_bytree: 0.8\n#\t\tsubsample: 0.7\n#\t\tlearning_rate: 0.016\n#\t\tn_estimators: 3000\n#\t\tmax_depth: 5\n#\t\tmin_child_weight: 104","metadata":{"execution":{"iopub.status.busy":"2021-09-20T17:32:44.591272Z","iopub.execute_input":"2021-09-20T17:32:44.591597Z","iopub.status.idle":"2021-09-20T17:32:44.597979Z","shell.execute_reply.started":"2021-09-20T17:32:44.591568Z","shell.execute_reply":"2021-09-20T17:32:44.59718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#setting parameters\nparams={\n'lambda': 1.7503469572793253,\n'alpha': 0.044038476141827085,\n'colsample_bytree': 0.8,\n'subsample': 0.7,\n'learning_rate': 0.016,\n'n_estimators': 3000,\n'max_depth': 5,\n'min_child_weight': 1043}","metadata":{"execution":{"iopub.status.busy":"2021-09-20T17:34:16.85356Z","iopub.execute_input":"2021-09-20T17:34:16.853886Z","iopub.status.idle":"2021-09-20T17:34:16.858868Z","shell.execute_reply.started":"2021-09-20T17:34:16.853858Z","shell.execute_reply":"2021-09-20T17:34:16.858059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =  XGBRegressor(**params,tree_method='gpu_hist')\nmodel.fit(X_train,y_train)\n\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T17:34:21.126628Z","iopub.execute_input":"2021-09-20T17:34:21.126948Z","iopub.status.idle":"2021-09-20T17:35:35.212583Z","shell.execute_reply.started":"2021-09-20T17:34:21.126918Z","shell.execute_reply":"2021-09-20T17:35:35.211844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy = accuracy_score(y_pred,y_test)\n#accuracy1 = roc_auc_score(y_pred,y_test)\n#print('LightGBM Model accuracy socre: {0:0.4f}'.format(accuracy))\n#print('LightGBM Model accuracy socre: {0:0.4f}'.format(accuracy1))\n\n#regression model score\nmean_squared_error(y_test,y_pred,squared=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-20T17:37:31.573655Z","iopub.execute_input":"2021-09-20T17:37:31.573984Z","iopub.status.idle":"2021-09-20T17:37:31.585313Z","shell.execute_reply.started":"2021-09-20T17:37:31.573952Z","shell.execute_reply":"2021-09-20T17:37:31.584453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Making submittion.csv\n                          \npredictions = model.predict(test_norm)\noutput=pd.DataFrame({'Id' : test.index,'claim':predictions})\noutput.to_csv('submission.csv', index =False)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T17:38:48.183435Z","iopub.execute_input":"2021-09-20T17:38:48.183781Z","iopub.status.idle":"2021-09-20T17:39:24.111475Z","shell.execute_reply.started":"2021-09-20T17:38:48.183747Z","shell.execute_reply":"2021-09-20T17:39:24.110611Z"},"trusted":true},"execution_count":null,"outputs":[]}]}