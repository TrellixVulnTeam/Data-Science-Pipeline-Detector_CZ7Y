{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import data\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-13T04:07:55.758398Z","iopub.execute_input":"2021-09-13T04:07:55.758838Z","iopub.status.idle":"2021-09-13T04:07:55.850326Z","shell.execute_reply.started":"2021-09-13T04:07:55.758744Z","shell.execute_reply":"2021-09-13T04:07:55.849284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import basic library\nfrom sklearn.impute import SimpleImputer\nfrom IPython.display import display\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostRegressor\nfrom catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:07:55.852539Z","iopub.execute_input":"2021-09-13T04:07:55.853163Z","iopub.status.idle":"2021-09-13T04:08:01.56015Z","shell.execute_reply.started":"2021-09-13T04:07:55.853087Z","shell.execute_reply":"2021-09-13T04:08:01.559149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import train & test data\ntrain = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\")\nsample = pd.read_csv(\"../input/tabular-playground-series-sep-2021/sample_solution.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:08:01.561911Z","iopub.execute_input":"2021-09-13T04:08:01.562292Z","iopub.status.idle":"2021-09-13T04:08:43.000831Z","shell.execute_reply.started":"2021-09-13T04:08:01.56225Z","shell.execute_reply":"2021-09-13T04:08:42.999725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# information about test and train data\ndisplay(train.info())\ndisplay(test.info())","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:08:43.003168Z","iopub.execute_input":"2021-09-13T04:08:43.003443Z","iopub.status.idle":"2021-09-13T04:08:43.057466Z","shell.execute_reply.started":"2021-09-13T04:08:43.003392Z","shell.execute_reply":"2021-09-13T04:08:43.056346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic structure of train data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:08:43.059467Z","iopub.execute_input":"2021-09-13T04:08:43.05978Z","iopub.status.idle":"2021-09-13T04:08:43.103914Z","shell.execute_reply.started":"2021-09-13T04:08:43.059741Z","shell.execute_reply":"2021-09-13T04:08:43.102488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 120 columns in train data ","metadata":{}},{"cell_type":"code","source":"# basic structure of train data 2\ntrain.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:09:13.245625Z","iopub.execute_input":"2021-09-13T04:09:13.246009Z","iopub.status.idle":"2021-09-13T04:09:17.563187Z","shell.execute_reply.started":"2021-09-13T04:09:13.245979Z","shell.execute_reply":"2021-09-13T04:09:17.562008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The train data is twice as large as the test data.\n- Both data have identical columns, except that the train data has a claim column.\n- I'll have to check the structure of the data more deeply.","metadata":{}},{"cell_type":"code","source":"# number of misssing values by feature\nprint(\"number of misssing values by feature\")\ntrain.isnull().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:09:28.046334Z","iopub.execute_input":"2021-09-13T04:09:28.050837Z","iopub.status.idle":"2021-09-13T04:09:28.314363Z","shell.execute_reply.started":"2021-09-13T04:09:28.050301Z","shell.execute_reply":"2021-09-13T04:09:28.313166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data missing values\nnull_values_train = []\nfor col in train.columns:\n    c = train[col].isna().sum()\n    pc = np.round((100 * (c)/len(train)), 2)            \n    dict1 ={\n        'Features' : col,\n        'null_train (count)': c,\n        'null_trian (%)': '{}%'.format(pc)\n    }\n    null_values_train.append(dict1)\nDF1 = pd.DataFrame(null_values_train, index=None).sort_values(by='null_train (count)',ascending=False)\n\n\n# test_data missing values\nnull_values_test = []\nfor col in test.columns:\n    c = test[col].isna().sum()\n    pc = np.round((100 * (c)/len(test)), 2)            \n    dict2 ={\n        'Features' : col,\n        'null_test (count)': c,\n        'null_test (%)': '{}%'.format(pc)\n    }\n    null_values_test.append(dict2)\nDF2 = pd.DataFrame(null_values_test, index=None).sort_values(by='null_test (count)',ascending=False)\n\n\ndf = pd.concat([DF1, DF2], axis=1)\ndf#.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:09:32.93245Z","iopub.execute_input":"2021-09-13T04:09:32.932763Z","iopub.status.idle":"2021-09-13T04:09:33.396518Z","shell.execute_reply.started":"2021-09-13T04:09:32.932725Z","shell.execute_reply":"2021-09-13T04:09:33.39521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf[\"n_missing\"] = train.drop([\"id\", \"claim\"], axis=1).isna().sum(axis=1)\ndf[\"claim\"] = train[\"claim\"].copy()\n\nfig, ax = plt.subplots(figsize=(12,5))\nax.hist(df[df[\"claim\"]==0][\"n_missing\"],\n        bins=40, edgecolor=\"black\",\n        color=\"darkseagreen\", alpha=0.7, label=\"claim is 0\")\nax.hist(df[df[\"claim\"]==1][\"n_missing\"],\n        bins=40, edgecolor=\"black\",\n        color=\"darkorange\", alpha=0.7, label=\"claim is 1\")\nax.set_title(\"Missing values distributionin in each target class\", fontsize=20, pad=15)\nax.set_xlabel(\"Missing values per row\", fontsize=14, labelpad=10)\nax.set_ylabel(\"Amount of rows\", fontsize=14, labelpad=10)\nax.legend(fontsize=14)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:09:42.105803Z","iopub.execute_input":"2021-09-13T04:09:42.106205Z","iopub.status.idle":"2021-09-13T04:09:43.394872Z","shell.execute_reply.started":"2021-09-13T04:09:42.106172Z","shell.execute_reply":"2021-09-13T04:09:43.393927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\" train data\")\nprint(f' Number of rows: {train.shape[0]}\\n Number of columns: {train.shape[1]}\\n No of missing values: {sum(train.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:10:13.185661Z","iopub.execute_input":"2021-09-13T04:10:13.186071Z","iopub.status.idle":"2021-09-13T04:10:13.440788Z","shell.execute_reply.started":"2021-09-13T04:10:13.186022Z","shell.execute_reply":"2021-09-13T04:10:13.439379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\" test data\")\nprint(f' Number of rows: {test.shape[0]}\\n Number of columns: {test.shape[1]}\\n No of missing values: {sum(test.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:10:14.167364Z","iopub.execute_input":"2021-09-13T04:10:14.167677Z","iopub.status.idle":"2021-09-13T04:10:14.298988Z","shell.execute_reply.started":"2021-09-13T04:10:14.167632Z","shell.execute_reply":"2021-09-13T04:10:14.297898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- there are 1820782 missing values\n- proportion of missising value between test and train are very similar\n- There is a small percentage of null values based on each column, but overall, the percentage of null values is huge.\n- It is an amount that cannot be ignored.","metadata":{}},{"cell_type":"code","source":"# looking at Claim column\nfig, ax = plt.subplots(figsize=(6, 6))\n\nbars = ax.bar(train[\"claim\"].value_counts().index,\n              train[\"claim\"].value_counts().values,              \n              edgecolor=\"black\",\n              width=0.4)\nax.set_title(\"Claim (target) values distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Claim (target) value\", fontsize=14, labelpad=10)\nax.set_xticks(train[\"claim\"].value_counts().index)\nax.tick_params(axis=\"both\", labelsize=14)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train[\"claim\"].value_counts().values/(len(train)/100)],\n                 padding=5, fontsize=15)\nax.bar_label(bars, [f\"{x:2d}\" for x in train[\"claim\"].value_counts().values],\n                 padding=-30, fontsize=15)\nax.margins(0.2, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:11:15.116461Z","iopub.execute_input":"2021-09-13T04:11:15.11676Z","iopub.status.idle":"2021-09-13T04:11:15.396707Z","shell.execute_reply.started":"2021-09-13T04:11:15.11673Z","shell.execute_reply":"2021-09-13T04:11:15.395573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# proportion of no null in each row\ntrain1 = train[train.isna().sum(axis=1)==0]\nprint(\"proportion of no null data : %.2f\" %(len(train1)/len(train)*100))\nprint(\"number of claim 1 in no null data : %d\" %(len(train1[train1['claim']==0])))\nprint(\"number of claim 0 in no null data : %d\" %(len(train1[train1['claim']==1])))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:11:20.844168Z","iopub.execute_input":"2021-09-13T04:11:20.844486Z","iopub.status.idle":"2021-09-13T04:11:21.52172Z","shell.execute_reply.started":"2021-09-13T04:11:20.844458Z","shell.execute_reply":"2021-09-13T04:11:21.520536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6, 6))\n\nbars = ax.bar(train1[\"claim\"].value_counts().index,\n              train1[\"claim\"].value_counts().values,              \n              edgecolor=\"black\",\n              width=0.4)\nax.set_title(\"Claim (target) values distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Claim (target) value\", fontsize=14, labelpad=10)\nax.set_xticks(train1[\"claim\"].value_counts().index)\nax.tick_params(axis=\"both\", labelsize=14)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train1[\"claim\"].value_counts().values/(len(train1)/100)],\n                 padding=5, fontsize=15)\nax.bar_label(bars, [f\"{x:2d}\" for x in train1[\"claim\"].value_counts().values],\n                 padding=-30, fontsize=15)\nax.margins(0.2, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:11:26.129616Z","iopub.execute_input":"2021-09-13T04:11:26.129967Z","iopub.status.idle":"2021-09-13T04:11:26.394733Z","shell.execute_reply.started":"2021-09-13T04:11:26.129923Z","shell.execute_reply":"2021-09-13T04:11:26.393779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The claim rate in train data is half and half.\n- Only 37% of the data without null values is intact.\n- Interestingly, the claim rate of the intact data is completely different from the previous train data.\n- In other words, it means that there are a lot of null values in the data with claim 1.\n- With this in mind, you will have to deal with null values.","metadata":{}},{"cell_type":"code","source":"target = train.pop('claim')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:11:32.420987Z","iopub.execute_input":"2021-09-13T04:11:32.421339Z","iopub.status.idle":"2021-09-13T04:11:32.430163Z","shell.execute_reply.started":"2021-09-13T04:11:32.421309Z","shell.execute_reply":"2021-09-13T04:11:32.428729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ = train[0:9579]\ntest_ = test[0:4934]","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:11:32.776016Z","iopub.execute_input":"2021-09-13T04:11:32.776616Z","iopub.status.idle":"2021-09-13T04:11:32.782386Z","shell.execute_reply.started":"2021-09-13T04:11:32.776582Z","shell.execute_reply":"2021-09-13T04:11:32.780951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# distribution of Features f1 to f60\nL = len(train.columns[0:60])\nnrow= int(np.ceil(L/6))\nncol= 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\n#ax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in train.columns[0:60]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, color='cyan',  alpha=0.5, label='train')\n    ax = sns.kdeplot(test_[feature], shade=True, color='darkblue',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:11:36.132407Z","iopub.execute_input":"2021-09-13T04:11:36.132703Z","iopub.status.idle":"2021-09-13T04:11:53.586216Z","shell.execute_reply.started":"2021-09-13T04:11:36.132674Z","shell.execute_reply":"2021-09-13T04:11:53.585391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# distribution of Features f61 to f118\nL = len(train.columns[60:])\nnrow= int(np.ceil(L/6))\nncol= 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\n#ax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in train.columns[60:]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, color='cyan',  alpha=0.5, label='train')\n    ax = sns.kdeplot(test_[feature], shade=True, color='darkblue',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:11:59.041324Z","iopub.execute_input":"2021-09-13T04:11:59.041617Z","iopub.status.idle":"2021-09-13T04:12:16.37643Z","shell.execute_reply.started":"2021-09-13T04:11:59.041587Z","shell.execute_reply":"2021-09-13T04:12:16.374954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# outlier of train data\ndf_plot = ((train - train.min())/(train.max() - train.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\nsns.boxplot(data = df_plot.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_plot.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_plot.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_plot.iloc[:, 90:120], ax = ax[3])","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:12:16.378705Z","iopub.execute_input":"2021-09-13T04:12:16.379033Z","iopub.status.idle":"2021-09-13T04:12:45.613476Z","shell.execute_reply.started":"2021-09-13T04:12:16.378994Z","shell.execute_reply":"2021-09-13T04:12:45.608215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# outlier of test data\ndf_plot = ((test - test.min())/(test.max() - test.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\nsns.boxplot(data = df_plot.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_plot.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_plot.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_plot.iloc[:, 90:119], ax = ax[3])","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:12:45.615824Z","iopub.execute_input":"2021-09-13T04:12:45.616192Z","iopub.status.idle":"2021-09-13T04:13:03.263714Z","shell.execute_reply.started":"2021-09-13T04:12:45.616153Z","shell.execute_reply":"2021-09-13T04:13:03.262639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation of train\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix')\nsns.heatmap(corr, mask = mask, cmap = 'Spectral_r', linewidths = .5)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:13:03.265717Z","iopub.execute_input":"2021-09-13T04:13:03.266103Z","iopub.status.idle":"2021-09-13T04:13:40.38803Z","shell.execute_reply.started":"2021-09-13T04:13:03.266059Z","shell.execute_reply":"2021-09-13T04:13:40.387001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation of train\ncorr = test.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix')\nsns.heatmap(corr, mask = mask, cmap = 'Spectral_r', linewidths = .5)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T04:13:40.390688Z","iopub.execute_input":"2021-09-13T04:13:40.39105Z","iopub.status.idle":"2021-09-13T04:14:00.939127Z","shell.execute_reply.started":"2021-09-13T04:13:40.391007Z","shell.execute_reply":"2021-09-13T04:14:00.938123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The distribution of test and train data is very similar.\n- The distribution of outliers shows different shapes in several columns but most have a similar distribution.\n- The correlation between the two data is also similar.\n- Overall test data and train data seem similar.","metadata":{}}]}