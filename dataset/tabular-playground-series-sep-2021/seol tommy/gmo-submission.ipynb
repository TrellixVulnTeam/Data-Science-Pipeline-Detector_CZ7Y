{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T08:13:25.677978Z","iopub.execute_input":"2021-09-13T08:13:25.678237Z","iopub.status.idle":"2021-09-13T08:13:25.713986Z","shell.execute_reply.started":"2021-09-13T08:13:25.67821Z","shell.execute_reply":"2021-09-13T08:13:25.713193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.kaggle.com/tolight20/tps-gmo-tolight20\n\n## Comparison analysis\n\n- From there CatBoost was best model\n- Best imputation was quantile 0.75\n- And extra feature improved AUC score\n- So let's Start by that","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport sklearn\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostRegressor\nfrom catboost import CatBoostClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Calling the Data sets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\")\nsample_solution = pd.read_csv(\"../input/tabular-playground-series-sep-2021/sample_solution.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns=['id','claim']).copy()\ny = train['claim'].copy()\ntest_data = test.drop(columns=['id']).copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data preprocessing","metadata":{}},{"cell_type":"code","source":"# Data preprocessing functions\ndef get_stats_per_row(data):\n    features = [x for x in data.columns.values if x[0]==\"f\"] \n    # n_missing is the number of null value in a row\n    data['n_missing'] = data[features].isna().sum(axis=1)\n    \n    data['max_row'] = data[features].max(axis=1)\n    data['min_row'] = data[features].min(axis=1)\n    data['std'] = data[features].std(axis=1)\n    \n    # If the difference between the mean and the median was large, the median function was used.\n    # If the difference is small the quantile function was used.\n    # Quantile function has better than mean function.\n    median_set = ['f9', 'f12', 'f26', 'f27', 'f28', 'f32', 'f33', 'f35', 'f62', 'f74', 'f82', 'f86', 'f98', 'f108', 'f116']\n    for col_name in features:\n        if col_name in median_set:\n            data[col_name].fillna(data[col_name].median(), inplace=True)\n        else:\n            data[col_name].fillna(data[col_name].quantile(0.75), inplace=True)\n            \n    # Multiply feature is the feature that multiply all values in a row\n    data['multiply'] = 1\n    for feature in features:\n        data['multiply'] = data[feature] * data['multiply']\n    \n    return data\n\nX = get_stats_per_row(X)\ntest_data = get_stats_per_row(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create preprocessing pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\npipeline = Pipeline([\n    ('scale', StandardScaler())\n])\n\nX = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\ntest_data = pd.DataFrame(columns=test_data.columns, data=pipeline.transform(test_data))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model parameter\nbest_params = {\n    'iterations': 15585, \n    'objective': 'CrossEntropy', \n    'bootstrap_type': 'Bernoulli', \n    'od_wait': 1144, \n    'learning_rate': 0.023575206684596582, \n    'reg_lambda': 36.30433203563295, \n    'random_strength': 43.75597655616195, \n    'depth': 7, \n    'min_data_in_leaf': 11, \n    'leaf_estimation_iterations': 1, \n    'subsample': 0.8227911142845009,\n    'task_type' : 'GPU',\n    'devices' : '0',\n    'verbose' : 0\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Modeling","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_curve, auc\nfrom catboost import CatBoostClassifier\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\n\npred_tmp = []\nscores = []\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n\n    model = CatBoostClassifier(**best_params)\n    model.fit(X_train, y_train)\n\n    # validation prediction\n    pred_valid = model.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\")\n    print('::'*20)\n    \n    # test prediction\n    y_hat = model.predict_proba(test_data)[:,1]\n    pred_tmp.append(y_hat)\n    \nprint(f\"Overall Validation Score: {np.mean(scores)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average predictions over all folds\npredictions = np.mean(np.column_stack(pred_tmp),axis=1)\n\n# Create submission file\nsample_solution['claim'] = predictions\nsample_solution.to_csv('./catb_baseline.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}