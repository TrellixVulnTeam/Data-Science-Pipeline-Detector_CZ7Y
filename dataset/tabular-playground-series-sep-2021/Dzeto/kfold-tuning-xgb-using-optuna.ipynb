{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Hey Everyone, In this notebook, we'll see how we can use optuna for hyperparameter tuning and how to use KFolds to make a prediction !!\n## Let's go !!","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ntrain_data=pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ntest_data=pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nss=pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:25.624774Z","iopub.execute_input":"2021-09-03T11:14:25.625189Z","iopub.status.idle":"2021-09-03T11:14:52.475858Z","shell.execute_reply.started":"2021-09-03T11:14:25.625154Z","shell.execute_reply":"2021-09-03T11:14:52.474901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\ntrain_data['fold']=-1\nkf=KFold(n_splits=5,shuffle=True,random_state=42)\nfor fold,(ti,vi) in enumerate(kf.split(train_data)):\n    train_data.loc[vi,'fold']=fold","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:52.477448Z","iopub.execute_input":"2021-09-03T11:14:52.477816Z","iopub.status.idle":"2021-09-03T11:14:52.61023Z","shell.execute_reply.started":"2021-09-03T11:14:52.477778Z","shell.execute_reply":"2021-09-03T11:14:52.609303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.fold.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:52.612199Z","iopub.execute_input":"2021-09-03T11:14:52.612615Z","iopub.status.idle":"2021-09-03T11:14:52.628307Z","shell.execute_reply.started":"2021-09-03T11:14:52.612573Z","shell.execute_reply":"2021-09-03T11:14:52.627509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:52.629951Z","iopub.execute_input":"2021-09-03T11:14:52.630315Z","iopub.status.idle":"2021-09-03T11:14:56.426144Z","shell.execute_reply.started":"2021-09-03T11:14:52.630278Z","shell.execute_reply":"2021-09-03T11:14:56.425112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:56.427676Z","iopub.execute_input":"2021-09-03T11:14:56.428062Z","iopub.status.idle":"2021-09-03T11:14:56.525663Z","shell.execute_reply.started":"2021-09-03T11:14:56.428019Z","shell.execute_reply":"2021-09-03T11:14:56.52471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:56.527014Z","iopub.execute_input":"2021-09-03T11:14:56.527378Z","iopub.status.idle":"2021-09-03T11:14:56.533846Z","shell.execute_reply.started":"2021-09-03T11:14:56.527341Z","shell.execute_reply":"2021-09-03T11:14:56.532733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(data=train_data,x='id',y='claim')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:56.535257Z","iopub.execute_input":"2021-09-03T11:14:56.535677Z","iopub.status.idle":"2021-09-03T11:14:56.879953Z","shell.execute_reply.started":"2021-09-03T11:14:56.53564Z","shell.execute_reply":"2021-09-03T11:14:56.879165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=train_data,x='claim')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:56.88352Z","iopub.execute_input":"2021-09-03T11:14:56.883786Z","iopub.status.idle":"2021-09-03T11:14:57.034672Z","shell.execute_reply.started":"2021-09-03T11:14:56.88376Z","shell.execute_reply":"2021-09-03T11:14:57.033711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize data\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\ntraindf=train_data.copy()\ntestdf=test_data.copy()\nfrom sklearn.preprocessing import StandardScaler\nuseful_cols=[col for col in testdf.columns if (col!='id' and col !='fold')] \n\nfor col in useful_cols:\n    mean_=traindf[col].mean()\n    std_=traindf[col].std()\n    traindf[col]=(traindf[col]-mean_)/std_\n    testdf[col]=(testdf[col]-mean_)/std_ \n#     min_=traindf[col].min()\n#     max_ =traindf[col].max()\n#     traindf[col]=(traindf[col]-min_)/(max_-min_)\n#     testdf[col]=(testdf[col]-min_)/(max_-min_)\n    \n#     traindf[col]=traindf[col].fillna(traindf[col].mean())\n#     testdf[col]=testdf[col].fillna(traindf[col].mean())\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:57.036707Z","iopub.execute_input":"2021-09-03T11:14:57.037185Z","iopub.status.idle":"2021-09-03T11:14:58.67452Z","shell.execute_reply.started":"2021-09-03T11:14:57.037142Z","shell.execute_reply":"2021-09-03T11:14:58.673623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdf.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:58.675817Z","iopub.execute_input":"2021-09-03T11:14:58.676161Z","iopub.status.idle":"2021-09-03T11:14:58.781041Z","shell.execute_reply.started":"2021-09-03T11:14:58.676125Z","shell.execute_reply":"2021-09-03T11:14:58.780055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Its good that the two classes are pretty balanced","metadata":{}},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\n\n# lets first define a function that'll help us know how good/bad our model is doing\ndef get_scores(y_preds,y):\n    return {\n        'Accuracy':metrics.accuracy_score(y_preds,y),\n        'Precision':metrics.precision_score(y_preds,y),\n        'Recall':metrics.recall_score(y_preds,y),\n        'F1':metrics.f1_score(y_preds,y),\n        'ROC_AUC': metrics.roc_auc_score(y_preds,y)\n    }","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:58.782364Z","iopub.execute_input":"2021-09-03T11:14:58.782753Z","iopub.status.idle":"2021-09-03T11:14:58.788438Z","shell.execute_reply.started":"2021-09-03T11:14:58.782713Z","shell.execute_reply":"2021-09-03T11:14:58.787524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:58.789968Z","iopub.execute_input":"2021-09-03T11:14:58.79031Z","iopub.status.idle":"2021-09-03T11:14:58.798271Z","shell.execute_reply.started":"2021-09-03T11:14:58.790275Z","shell.execute_reply":"2021-09-03T11:14:58.797405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=traindf[useful_cols]\ny=traindf['claim']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:14:58.7995Z","iopub.execute_input":"2021-09-03T11:14:58.79997Z","iopub.status.idle":"2021-09-03T11:15:00.074056Z","shell.execute_reply.started":"2021-09-03T11:14:58.799932Z","shell.execute_reply":"2021-09-03T11:15:00.073111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model):\n    model_=model\n    model_.fit(X_train,y_train)\n    y_preds=model_.predict(X_val)\n    return model_,get_scores(y_preds,y_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.075338Z","iopub.execute_input":"2021-09-03T11:15:00.075727Z","iopub.status.idle":"2021-09-03T11:15:00.082082Z","shell.execute_reply.started":"2021-09-03T11:15:00.07569Z","shell.execute_reply":"2021-09-03T11:15:00.07977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Here I created a list of models and trained all of them to see how are they performing","metadata":{}},{"cell_type":"code","source":"model_list=[\n            DecisionTreeClassifier(random_state=42), \n            RandomForestClassifier(random_state=42),\n            XGBClassifier(random_state=42,tree_method='gpu_hist'), \n            LGBMClassifier(random_state=42), \n            LogisticRegression(random_state=42),\n            svm.SVC(random_state=42),\n            CatBoostClassifier(random_state=42,verbose=100),\n            AdaBoostClassifier(random_state=42)\n           ]\nmodel_names=['Decision Tree', 'Random Forest', 'XG Boost', 'Light GBM', 'Logistic Regression','SVM','CatBoost','AdaBoost']\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.083534Z","iopub.execute_input":"2021-09-03T11:15:00.083963Z","iopub.status.idle":"2021-09-03T11:15:00.095873Z","shell.execute_reply.started":"2021-09-03T11:15:00.083927Z","shell.execute_reply":"2021-09-03T11:15:00.095071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Now lets train all the models and see how are they doing\n# model_store=[]\n# scores = pd.DataFrame(columns=['Name','Accuracy','Precision',\n#                                 'Recall',\n#                                 'F1',\n#                                 'ROC_AUC'])\n# for i in range(len(model_list)):\n#     model,score=train_model(model_list[i])\n#     scores.loc[i]=[model_names[i]]+list(score.values())\n#     model_store.append(model)\n#     print(model_list[i], ' done')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.098435Z","iopub.execute_input":"2021-09-03T11:15:00.098718Z","iopub.status.idle":"2021-09-03T11:15:00.108851Z","shell.execute_reply.started":"2021-09-03T11:15:00.098694Z","shell.execute_reply":"2021-09-03T11:15:00.108001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# figure, axis = plt.subplots(2, 3)\n# figure.set_figheight(15)\n# figure.set_figwidth(20)\n\n# for i in range(2):\n#     for j in range(3):\n#         axis[i,j].set_xlim([.3,.9])\n        \n# axis[0, 0].barh(scores['Name'],scores['Accuracy'],height=.5)\n# axis[0, 0].set_title(\"Accuracy Score\")\n  \n# axis[0, 1].barh(scores['Name'],scores['Precision'],height=.5)\n# axis[0, 1].set_title(\"Precision\")\n\n# axis[1, 0].barh(scores['Name'],scores['Recall'],height=.5)\n# axis[1, 0].set_title(\"Recall\")\n\n# axis[1, 2].barh(scores['Name'],scores['F1'],height=.5)\n# axis[1, 2].set_title(\"F1\")\n\n# axis[0, 2].barh(scores['Name'],scores['ROC_AUC'],height=.5)\n# axis[0, 2].set_title('ROC_AUC')\n\n# axis[1, 1].set_visible(False)\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.109848Z","iopub.execute_input":"2021-09-03T11:15:00.110092Z","iopub.status.idle":"2021-09-03T11:15:00.119067Z","shell.execute_reply.started":"2021-09-03T11:15:00.11007Z","shell.execute_reply":"2021-09-03T11:15:00.118227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning using optuna ","metadata":{}},{"cell_type":"code","source":"import optuna\nimport sklearn\ndef objective(trial):\n    score=0\n    n_estimators = trial.suggest_int('n_estimators', 10, 1000)\n    max_depth = trial.suggest_int('max_depth', 1, 27)\n    reg_lambda = trial.suggest_loguniform('reg_lambda', 0.1, 5)\n    alpha = trial.suggest_loguniform('alpha', .1, 5)\n    min_child_weight= trial.suggest_loguniform('min_child_weight', 1, 50)\n    clf = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth,\n                        reg_lambda=reg_lambda,alpha=alpha,min_child_weight=min_child_weight, \n                        tree_method='gpu_hist',random_state=42)\n    clf.fit(X_train[useful_cols],y_train)\n    preds=clf.predict(X_val[useful_cols])\n    return metrics.roc_auc_score(preds,y_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.120193Z","iopub.execute_input":"2021-09-03T11:15:00.120455Z","iopub.status.idle":"2021-09-03T11:15:00.129764Z","shell.execute_reply.started":"2021-09-03T11:15:00.120432Z","shell.execute_reply":"2021-09-03T11:15:00.12893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=10)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.131035Z","iopub.execute_input":"2021-09-03T11:15:00.131406Z","iopub.status.idle":"2021-09-03T11:15:00.140446Z","shell.execute_reply.started":"2021-09-03T11:15:00.131369Z","shell.execute_reply":"2021-09-03T11:15:00.139669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_params=study.best_trial.params\nbest_params={'n_estimators': 433, 'max_depth': 27, \n             'reg_lambda': 0.5955576227964456, 'alpha': 3.8018858996918654, \n             'min_child_weight': 5.2345922504984905}","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.143335Z","iopub.execute_input":"2021-09-03T11:15:00.143643Z","iopub.status.idle":"2021-09-03T11:15:00.148868Z","shell.execute_reply.started":"2021-09-03T11:15:00.143618Z","shell.execute_reply":"2021-09-03T11:15:00.148036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Finally predict for each KFold and take mean to get final submission\nimport sklearn\npredictions=[]\nfor i in range(5):\n    train=traindf.loc[traindf.fold!=i]\n    val=traindf.loc[traindf.fold==i]\n    Xtrain=train[useful_cols]\n    ytrain=train['claim']\n    Xval=val[useful_cols]\n    yval=val['claim']\n    clf = XGBClassifier(**best_params, tree_method='gpu_hist', random_state=i)\n    clf.fit(Xtrain,ytrain)\n    preds=clf.predict_proba(testdf[useful_cols])[:,1]\n    predictions.append(preds)\n    print('fold ' +str(i), get_scores(clf.predict(Xval),yval))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:15:00.150255Z","iopub.execute_input":"2021-09-03T11:15:00.150688Z","iopub.status.idle":"2021-09-03T11:15:14.301033Z","shell.execute_reply.started":"2021-09-03T11:15:00.150654Z","shell.execute_reply":"2021-09-03T11:15:14.298956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=np.mean(predictions,axis=0)\nss['claim']=preds\nss.to_csv('submission,csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:59:32.116196Z","iopub.execute_input":"2021-09-03T10:59:32.116572Z","iopub.status.idle":"2021-09-03T10:59:32.12244Z","shell.execute_reply.started":"2021-09-03T10:59:32.116526Z","shell.execute_reply":"2021-09-03T10:59:32.121631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}