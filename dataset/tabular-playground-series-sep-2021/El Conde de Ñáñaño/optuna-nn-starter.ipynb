{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Help from here: https://github.com/optuna/optuna-examples/blob/main/tensorflow/tensorflow_eager_simple.py\n#'''''''''''''': https://optuna.readthedocs.io/en/stable/_modules/optuna/integration/tfkeras.html#TFKerasPruningCallback","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TIMEOUT = 4.5 * (60**2)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:05:31.288438Z","iopub.execute_input":"2021-09-20T16:05:31.288743Z","iopub.status.idle":"2021-09-20T16:05:31.299427Z","shell.execute_reply.started":"2021-09-20T16:05:31.288675Z","shell.execute_reply":"2021-09-20T16:05:31.298223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sys\nimport os\nfrom time import time\n\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nimport gc\nimport joblib\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T02:36:18.555946Z","iopub.execute_input":"2021-09-21T02:36:18.556343Z","iopub.status.idle":"2021-09-21T02:36:23.330872Z","shell.execute_reply.started":"2021-09-21T02:36:18.556307Z","shell.execute_reply":"2021-09-21T02:36:23.330025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom optuna.integration import TFKerasPruningCallback\nfrom optuna.trial import TrialState","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:36:23.332222Z","iopub.execute_input":"2021-09-21T02:36:23.332556Z","iopub.status.idle":"2021-09-21T02:36:24.546247Z","shell.execute_reply.started":"2021-09-21T02:36:23.332521Z","shell.execute_reply":"2021-09-21T02:36:24.54534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train = pd.read_feather('/kaggle/input/embeddings-from-daes-with-tensorflow/train_daeta_500_3_0.15_0.1_5')\n#test =  pd.read_feather('/kaggle/input/embeddings-from-daes-with-tensorflow/test_daeta_500_3_0.15_0.1_5')\ntrain = pd.read_feather('/kaggle/input/september-feather/train_rg_min')\ntest =  pd.read_feather('/kaggle/input/september-feather/test_rg_min')\n\nss = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv')\nFEATURES = [feat for feat in train.columns if 'f' in feat] + ['nan_count']\nTARGET = 'claim'","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:36:24.547845Z","iopub.execute_input":"2021-09-21T02:36:24.548304Z","iopub.status.idle":"2021-09-21T02:36:32.150102Z","shell.execute_reply.started":"2021-09-21T02:36:24.548259Z","shell.execute_reply":"2021-09-21T02:36:32.149261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating the data for optuna to train and validate\nnp.random.seed(42)\ntrain_percent = .8\nX_msk = np.random.choice(a=[True, False], size=int(train.shape[0]), replace=True, p=[.8,.2])\n\nX = train.loc[X_msk,FEATURES].values\ny = train.loc[X_msk, TARGET].values\n\nval_X = train.loc[~X_msk,FEATURES].values\nval_y = train.loc[~X_msk, TARGET].values","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:05:52.45249Z","iopub.execute_input":"2021-09-20T16:05:52.452862Z","iopub.status.idle":"2021-09-20T16:05:56.391496Z","shell.execute_reply.started":"2021-09-20T16:05:52.452829Z","shell.execute_reply":"2021-09-20T16:05:56.390657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##################################################################\n#Special layers\n##################################################################\nclass CutMix(tf.keras.layers.Layer):\n    '''\n    Implementation of CutMix\n    Args\n    _____\n    noise: (R in [0,1)) probability that a value is not sampled from distribution\n    Application\n    ____________\n    CM = CutMix(.2)\n    x = tf.reshape(tf.range(0,10, dtype=tf.float32), (5,2))\n    print(x.numpy())\n    y = CM(x,True)\n    print(y.numpy())\n    '''\n    def __init__(self, noise, **kwargs):\n        super(CutMix, self).__init__(**kwargs)\n        self.noise = noise\n\n    def get_config(self):\n        config = super(CutMix, self).get_config()\n        config.update({\"noise\": self.noise})\n        return config\n\n    def call(self, inputs, training=None):\n        if training:\n            shuffled = tf.stop_gradient(tf.random.shuffle(inputs))\n            #print(shuffled.numpy())\n\n            msk = tf.keras.backend.random_bernoulli(tf.shape(inputs), p=1 - self.noise, dtype=tf.float32)\n            #print(msk)\n            return msk * inputs + (tf.ones_like(msk) - msk) * shuffled\n        return inputs\n\nclass MixUp(tf.keras.layers.Layer):\n    '''\n    Implementation of MixUp\n    Args\n    _____\n    alpha: (R in [0,1)) percentage of random sample to input  used\n    Application\n    ____________\n    MU = MixUp(.1)\n    x = tf.reshape(tf.range(0,10, dtype=tf.float32), (5,2))\n    y = MU(x)\n    print(x.numpy())\n    print(y.numpy())\n    '''\n    def __init__(self, alpha, **kwargs):\n        super(MixUp, self).__init__(**kwargs)\n        self.alpha = alpha\n        self.alpha_constant = tf.constant(self.alpha)\n        self.one_minus_alpha = tf.constant(1.) - self.alpha\n\n    def get_config(self):\n        config = super(MixUp, self).get_config()\n        config.update({\"alpha\": self.alpha})\n        return config\n\n    def call(self, inputs, training=None):\n        if training:\n            shuffled = tf.stop_gradient(tf.random.shuffle(inputs))\n            #print(shuffled.numpy())\n            return self.alpha_constant * inputs + self.one_minus_alpha * shuffled\n        return inputs\n    \nclass ResnetBlockTabular(tf.keras.Model):\n    def __init__(self, output_dim, **kwargs):\n        '''\n        output_dim: (int) dimension of output dense layer. \n        NOTE: if output_dim == input_dim, this is a ResNetIdentityBlock\n        '''\n        super(ResnetBlockTabular, self).__init__(**kwargs)\n        self.output_dim = output_dim\n    \n    def build(self, input_shape):\n        if self.output_dim == input_shape[-1]:\n            self.Dense1 = None\n        else:\n            self.Dense1 = tf.keras.layers.Dense(output_dim)\n\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.relu1 = tf.keras.layers.ReLU()\n        self.dense2 = tf.keras.layers.Dense(self.output_dim)\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.relu2 = tf.keras.layers.ReLU()\n        self.dense3 = tf.keras.layers.Dense(self.output_dim)\n    \n    def call(self, input_tensor, training=False):\n        if self.Dense1 is not None:\n            input_tensor = self.Dense1(input_tensor)\n        \n        x = self.bn1(input_tensor)\n        x = self.relu1(x)\n        x = self.dense2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.dense3(x)\n        \n        return x + input_tensor","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:05:56.393668Z","iopub.execute_input":"2021-09-20T16:05:56.39424Z","iopub.status.idle":"2021-09-20T16:05:56.410478Z","shell.execute_reply.started":"2021-09-20T16:05:56.394201Z","shell.execute_reply":"2021-09-20T16:05:56.409695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ff(num_input_columns, BLOCKS, drop_rate, cutmix_noise, mixup_alpha, optimizer, block_sizes =None):\n    \n    if block_sizes is None:\n        block_sizes = [num_input_columns for _ in range(BLOCKS)]\n    else:\n        if len(block_sizes) !=BLOCKS:\n            print(f'block_sizes has {len(block_sizes)} blocks.  Needs {BLOCKS}.')\n    \n    #Input\n    inp = tf.keras.layers.Input(num_input_columns)\n    x = CutMix(noise = cutmix_noise)(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = ResnetBlockTabular(output_dim = block_sizes[0], name=f'Resnet_0')(x)\n    x = MixUp(alpha= mixup_alpha)(x)\n    \n    for i in range(1,BLOCKS):\n        x = ResnetBlockTabular(output_dim = block_sizes[i], name=f'Resnet_{i}')(x)\n        x = tf.keras.layers.Dropout(drop_rate)(x)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    \n    \n    model.compile(optimizer=optimizer,\n                  loss=tf.keras.losses.BinaryCrossentropy(),\n                  metrics=[tf.keras.metrics.AUC()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:05:56.411397Z","iopub.execute_input":"2021-09-20T16:05:56.411645Z","iopub.status.idle":"2021-09-20T16:05:56.424862Z","shell.execute_reply.started":"2021-09-20T16:05:56.411599Z","shell.execute_reply":"2021-09-20T16:05:56.424058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#DELETE THIS.  JUST CHECKING THE EVALUATE FUNCTION\noptimizer = tf.keras.optimizers.Adam()\nmodel = ff(num_input_columns=len(FEATURES), BLOCKS=3, drop_rate=.1, cutmix_noise=.3, mixup_alpha=.2, optimizer=optimizer)\nmodel.evaluate(X,y, batch_size=10000)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:05:56.427095Z","iopub.execute_input":"2021-09-20T16:05:56.427445Z","iopub.status.idle":"2021-09-20T16:05:56.439335Z","shell.execute_reply.started":"2021-09-20T16:05:56.427411Z","shell.execute_reply":"2021-09-20T16:05:56.438585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ES = tf.keras.callbacks.EarlyStopping(monitor='val_auc', min_delta=0, patience=20, verbose=0, mode='max')\ndef objective(trial):\n    #from https://github.com/optuna/optuna-examples/blob/main/keras/keras_integration.py\n    # Clear clutter from previous session graphs.\n    tf.keras.backend.clear_session()\n    batch_size = trial.suggest_categorical('batch_size', [512,1024])\n    epochs = 200\n    \n    ###################################\n    # Generate our trial model.\n    ###################################\n    #Model Architecture specifications\n    num_input_columns= len(FEATURES)\n    BLOCKS = trial.suggest_int(\"BLOCKS\", 1, 10) \n    drop_rate= trial.suggest_float(\"drop_rate\", 0, .2, )\n    \n    #Sum of cutmix and mixup <=.5\n    cutmix_noise= trial.suggest_float(\"cutmix_noise\", 0., .5)\n    mixup_alpha=trial.suggest_float(\"mixup_alpha\", 0., .5 - cutmix_noise)\n    \n    #Model Optimizer Specifications\n    #Copy pasted from https://github.com/optuna/optuna-examples/blob/main/tensorflow/tensorflow_eager_simple.py\n    #Thanks y'all!\n    kwargs = {}\n    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n    optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n    if optimizer_selected == \"RMSprop\":\n        kwargs[\"learning_rate\"] = trial.suggest_float(\n            \"rmsprop_learning_rate\", 1e-5, 1e-1, log=True\n        )\n        kwargs[\"decay\"] = trial.suggest_float(\"rmsprop_decay\", 0.85, 0.99)\n        kwargs[\"momentum\"] = trial.suggest_float(\"rmsprop_momentum\", 1e-5, 1e-1, log=True)\n    elif optimizer_selected == \"Adam\":\n        kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-5, 1e-1, log=True)\n    elif optimizer_selected == \"SGD\":\n        kwargs[\"learning_rate\"] = trial.suggest_float(\n            \"sgd_opt_learning_rate\", 1e-5, 1e-1, log=True\n        )\n        kwargs[\"momentum\"] = trial.suggest_float(\"sgd_opt_momentum\", 1e-5, 1e-1, log=True)\n\n    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n    \n    model = ff(num_input_columns, BLOCKS, drop_rate, cutmix_noise, mixup_alpha, optimizer)\n\n    # Fit the model on the training data.\n    # The KerasPruningCallback checks for pruning condition every epoch.\n    model.fit(\n        X,\n        y,\n        batch_size=batch_size,\n        callbacks=[ES, TFKerasPruningCallback(trial, \"val_auc\")],\n        epochs=epochs,\n        validation_data=(val_X, val_y),\n        verbose=1,\n    )\n\n    # Evaluate the model accuracy on the validation set.\n    score = model.evaluate(val_X, val_y, batch_size=10000,verbose=0)\n    return score[1]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:05:56.442281Z","iopub.execute_input":"2021-09-20T16:05:56.442563Z","iopub.status.idle":"2021-09-20T16:05:56.45551Z","shell.execute_reply.started":"2021-09-20T16:05:56.442538Z","shell.execute_reply":"2021-09-20T16:05:56.454459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, timeout = TIMEOUT) #Optimize for 5 hours.  Let's waste our gpu quota!\n#study.optimize(objective, n_trials=5)\npruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\ncomplete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\nprint(\"Study statistics: \")\nprint(\"  Number of finished trials: \", len(study.trials))\nprint(\"  Number of pruned trials: \", len(pruned_trials))\nprint(\"  Number of complete trials: \", len(complete_trials))\n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Value: \", trial.value)\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T16:05:56.456947Z","iopub.execute_input":"2021-09-20T16:05:56.457277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joblib.dump(study, \"study.pkl\")\n#To regain this study: study = joblib.load(\"study.pkl\") #https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-save-and-resume-studies","metadata":{},"execution_count":null,"outputs":[]}]}