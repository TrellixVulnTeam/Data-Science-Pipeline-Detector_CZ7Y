{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to get a good score?  TPS September 2021 (competition)\n### Following the next steps ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nraw_train =  pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\nraw_test = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\n\n# Making a copy of raw data\ntrain = raw_train.copy()\ntest = raw_test.copy()\n\n# Shape\nprint(\"train shape :\" , train.shape)\nprint(\"test shape :\" , test.shape)\n\n# Split target and remove de id column  in both dataset\ntarget = raw_train.claim\ntrain.drop(['id','claim'], axis = 1, inplace = True)\ntest.drop('id', axis = 1, inplace = True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T20:46:18.574241Z","iopub.execute_input":"2021-09-08T20:46:18.57454Z","iopub.status.idle":"2021-09-08T20:46:50.728324Z","shell.execute_reply.started":"2021-09-08T20:46:18.574465Z","shell.execute_reply":"2021-09-08T20:46:50.727085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features Engineering and Cleaning","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nfeatures = train.columns\n\ntrain['n_missing'] = train[features].isna().sum(axis=1)\ntest['n_missing'] = test[features].isna().sum(axis=1)\n\ntrain['std'] = train[features].std(axis=1)\ntest['std'] = test[features].std(axis=1)\n\nsi = SimpleImputer(strategy ='mean')\ntrain[features] = si.fit_transform(train[features])\ntest[features] = si.transform(test[features])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T20:46:50.730632Z","iopub.execute_input":"2021-09-08T20:46:50.730899Z","iopub.status.idle":"2021-09-08T20:47:24.031281Z","shell.execute_reply.started":"2021-09-08T20:46:50.730873Z","shell.execute_reply":"2021-09-08T20:47:24.030721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\n\nparams = {   \n               'objective': 'binary',\n               'boosting_type': 'gbdt',\n               'num_leaves': 6,\n               'max_depth': 2,\n               'learning_rate': 0.1,\n               'n_estimators': 40000,\n               'reg_alpha': 25.0,\n               'reg_lambda': 76.7,\n               'bagging_seed': 42, \n               'feature_fraction_seed': 42,\n               'n_jobs': 4,\n               'subsample': 0.98,\n               'subsample_freq': 1,\n               'colsample_bytree': 0.69,\n               'min_child_samples': 54,\n               'min_child_weight': 256,\n}\n\npreds_valid_f = {}\npreds_test = []\ntotal_auc = []\n\nkf = KFold(n_splits=5,random_state=0,shuffle=True)\n\nfor fold,(train_index, valid_index) in enumerate(kf.split(train,target)):\n\n    X_train,X_valid = train.loc[train_index], train.loc[valid_index]\n    y_train,y_valid = target.loc[train_index], target.loc[valid_index]\n    \n    # Preprocessing\n    index_valid  = X_valid.index.tolist()\n    #--------------------------------------------------------\n    # model\n    model = lgb.LGBMClassifier(**params,random_state = 0)\n    model.fit(X_train, y_train,\n              verbose=False,\n              # These three parameters will stop training before a model starts overfitting \n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=300,\n              )\n    # oof\n    preds_valid = model.predict_proba(X_valid)[:,1]\n    #--------------------------------------------------------\n    preds_test.append(model.predict_proba(test)[:,1])\n    #--------------------------------------------------------\n    preds_valid_f.update(dict(zip(index_valid, preds_valid)))\n\n    # Getting score for a fold model\n    fold_auc = roc_auc_score(y_valid, preds_valid)\n    print(f\"Fold {fold} roc_auc_score: {fold_auc}\")\n    # Total rmse\n    total_auc.append(fold_auc)\n    \nprint(f\"mean roc_auc_score: {np.mean(total_auc)}, std: {np.std(total_auc)}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-08T20:47:47.980258Z","iopub.execute_input":"2021-09-08T20:47:47.980542Z","iopub.status.idle":"2021-09-08T20:54:11.166706Z","shell.execute_reply.started":"2021-09-08T20:47:47.980518Z","shell.execute_reply":"2021-09-08T20:54:11.164482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': raw_test.id,\n                       'claim': np.mean(preds_test, axis = 0)})\noutput.to_csv('preds.csv', index=False)\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T20:47:26.203252Z","iopub.status.idle":"2021-09-08T20:47:26.203567Z"},"trusted":true},"execution_count":null,"outputs":[]}]}