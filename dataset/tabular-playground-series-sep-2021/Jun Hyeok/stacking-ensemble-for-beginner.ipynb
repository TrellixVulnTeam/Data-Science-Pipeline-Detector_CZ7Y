{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **TPS - Sep 2021**\n\n## **XGBoost & LightGBM & CatBoost Stacking**","metadata":{"id":"yba_b5k2ApdA"}},{"cell_type":"markdown","source":"### Thank you for visiting my notebook :)\n### This notebook is for beginner like me **who wants to study stacking ensemble!**","metadata":{}},{"cell_type":"markdown","source":"#### **Stacking Ensemble** is a nice technique for forwarding you score.\n#### As you can see below image, Stacking Ensemble needs some models for classification and meta-model for final prediction!","metadata":{}},{"cell_type":"markdown","source":"#### Here's what you need to do.\n**Step1. Make your train, test data for training & prediction (Preprocessing)**\n\n**Step2. Select some models for making stacking datasets!! (Train models and Making Datasets)**\n\n**Step3. Select final model for meta-model!**\n\n**Step4. With your meta-model, Train & Predict with stacking datasets ;)**","metadata":{}},{"cell_type":"markdown","source":"![Stacking Ensemble](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier_files/stackingclassification_overview.png)","metadata":{}},{"cell_type":"markdown","source":"# **Import Library**","metadata":{"id":"KkUs7_7Y40xD"}},{"cell_type":"code","source":"import gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","metadata":{"id":"eXnAmO_x4L95","execution":{"iopub.status.busy":"2021-09-03T13:04:34.459073Z","iopub.execute_input":"2021-09-03T13:04:34.45952Z","iopub.status.idle":"2021-09-03T13:04:37.98178Z","shell.execute_reply.started":"2021-09-03T13:04:34.459423Z","shell.execute_reply":"2021-09-03T13:04:37.980737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load Data**","metadata":{"id":"Q_5xEu0c4-9x"}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\n\nall_data = pd.concat([train, test])","metadata":{"id":"UOd2JVjX4HJ5","outputId":"73241446-8707-49ce-a8a8-e34f34ea4da5","execution":{"iopub.status.busy":"2021-09-03T13:04:37.983499Z","iopub.execute_input":"2021-09-03T13:04:37.983912Z","iopub.status.idle":"2021-09-03T13:05:20.444183Z","shell.execute_reply.started":"2021-09-03T13:04:37.98387Z","shell.execute_reply":"2021-09-03T13:05:20.443142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data2 = all_data.drop(columns = ['id', 'claim'])\nall_data2","metadata":{"id":"T2m7I66N4soy","outputId":"120e2390-5862-4870-f3b9-42870a483411","execution":{"iopub.status.busy":"2021-09-03T13:05:20.44597Z","iopub.execute_input":"2021-09-03T13:05:20.446329Z","iopub.status.idle":"2021-09-03T13:05:21.863522Z","shell.execute_reply.started":"2021-09-03T13:05:20.446299Z","shell.execute_reply":"2021-09-03T13:05:21.862374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Handle missing values**\n\n*   We can use mean values to handle missing values.\n*   Or, we can predict missing values with clean data.\n","metadata":{"id":"rZNlLb7L5CPp"}},{"cell_type":"markdown","source":"### **Distribution of Missing values**","metadata":{"id":"-1jFxECd8jbB"}},{"cell_type":"code","source":"# Distribution\n\nplt.figure(figsize = (12, 6))\nmissing_values = all_data2.isnull().sum()[:-1]\nsns.histplot(missing_values, color='violet');\nplt.show()\n\nprint('\\n')\nprint('-------- Distribution of Missing values --------')\nprint('Min:', missing_values.min())\nprint('Max:', missing_values.max())\nprint('Mean:', missing_values.mean())\nprint('------------------------------------------------')","metadata":{"id":"d1LMyuIG5IMJ","outputId":"dc554321-217a-4432-d87e-ce99c842991b","execution":{"iopub.status.busy":"2021-09-03T13:05:21.865363Z","iopub.execute_input":"2021-09-03T13:05:21.865734Z","iopub.status.idle":"2021-09-03T13:05:22.495666Z","shell.execute_reply.started":"2021-09-03T13:05:21.865696Z","shell.execute_reply":"2021-09-03T13:05:22.49466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Generation\n\n*   Thanks to BIZEN's notebook, we can use those missing value counts for feature! [Check BIZEN's Notebook!](https://www.kaggle.com/hiro5299834/tps-sep-2021-single-lgbm)\n\n*   **I made Missing-Value's One-Hot Encoded columns for training missing value(Y/N)**","metadata":{}},{"cell_type":"code","source":"all_data2['n_missing'] = all_data2.isna().sum(axis=1)\nall_data2['std'] = all_data2.std(axis=1)\nall_data2['min'] = all_data2.min(axis=1)\nall_data2['max'] = all_data2.max(axis=1)\nall_data2","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:05:22.4971Z","iopub.execute_input":"2021-09-03T13:05:22.497515Z","iopub.status.idle":"2021-09-03T13:05:28.956504Z","shell.execute_reply.started":"2021-09-03T13:05:22.497474Z","shell.execute_reply":"2021-09-03T13:05:28.95558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"miss_one_hot = all_data2.iloc[:, :118].isna()\nmiss_one_hot.columns = [f'missing_f_{i}' for i in range(118)]\nmiss_one_hot","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:05:28.957754Z","iopub.execute_input":"2021-09-03T13:05:28.958097Z","iopub.status.idle":"2021-09-03T13:05:29.530519Z","shell.execute_reply.started":"2021-09-03T13:05:28.958068Z","shell.execute_reply":"2021-09-03T13:05:29.529651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data3 = pd.concat([all_data2, miss_one_hot], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:05:29.531877Z","iopub.execute_input":"2021-09-03T13:05:29.532386Z","iopub.status.idle":"2021-09-03T13:05:30.912425Z","shell.execute_reply.started":"2021-09-03T13:05:29.532345Z","shell.execute_reply":"2021-09-03T13:05:30.911348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del all_data, all_data2, test, miss_one_hot\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:05:30.915306Z","iopub.execute_input":"2021-09-03T13:05:30.915684Z","iopub.status.idle":"2021-09-03T13:05:31.050474Z","shell.execute_reply.started":"2021-09-03T13:05:30.915643Z","shell.execute_reply":"2021-09-03T13:05:31.049511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train2 = all_data3[:len(train)]\ntest2 = all_data3[len(train):]\ny = train['claim']","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:05:31.052331Z","iopub.execute_input":"2021-09-03T13:05:31.052702Z","iopub.status.idle":"2021-09-03T13:05:31.062161Z","shell.execute_reply.started":"2021-09-03T13:05:31.052666Z","shell.execute_reply":"2021-09-03T13:05:31.061289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:05:31.063493Z","iopub.execute_input":"2021-09-03T13:05:31.063863Z","iopub.status.idle":"2021-09-03T13:05:31.189241Z","shell.execute_reply.started":"2021-09-03T13:05:31.063822Z","shell.execute_reply":"2021-09-03T13:05:31.188355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\nsi = SimpleImputer()\n\ntrain2.iloc[:, :118] = si.fit_transform(sc.fit_transform(train2.iloc[:, :118]))\ntest2.iloc[:, :118] = si.fit_transform(sc.fit_transform(test2.iloc[:, :118]))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:05:31.192363Z","iopub.execute_input":"2021-09-03T13:05:31.192636Z","iopub.status.idle":"2021-09-03T13:06:20.675713Z","shell.execute_reply.started":"2021-09-03T13:05:31.192611Z","shell.execute_reply":"2021-09-03T13:06:20.674663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modeling**","metadata":{"id":"jipIzFV0afem"}},{"cell_type":"markdown","source":"### **Stacking Data Loader**","metadata":{}},{"cell_type":"code","source":"def Stacking_Data_Loader(model, model_name, x_train, y_train, x_test, fold):\n    '''\n    Put your train, test datasets and fold value!\n    This function returns train, test datasets for stacking ensemble :)\n    '''\n\n    stk = StratifiedKFold(n_splits = fold, random_state = 42, shuffle = True)\n    \n    # Declaration Pred Datasets\n    train_fold_pred = np.zeros((x_train.shape[0], 1))\n    test_pred = np.zeros((x_test.shape[0], fold))\n    \n    for counter, (train_index, valid_index) in enumerate(stk.split(x_train, y_train)):\n        x_train, y_train = train2.iloc[train_index], y[train_index]\n        x_valid, y_valid = train2.iloc[valid_index], y[valid_index]\n\n        print('------------ Fold', counter+1, 'Start! ------------')\n        if model_name == 'cat':\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n        elif model_name == 'xgb':\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric = 'auc', verbose = 500, early_stopping_rounds = 200)\n        else:\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric = 'auc', verbose = 100, early_stopping_rounds = 200)\n            \n        print('------------ Fold', counter+1, 'Done! ------------')\n        \n        train_fold_pred[valid_index, :] = model.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n        test_pred[:, counter] = model.predict_proba(x_test)[:, 1]\n    \n    test_pred_mean = np.mean(test_pred, axis = 1).reshape(-1, 1)\n\n    print('Done!')\n    \n    return train_fold_pred, test_pred_mean","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:06:20.67721Z","iopub.execute_input":"2021-09-03T13:06:20.677591Z","iopub.status.idle":"2021-09-03T13:06:20.688504Z","shell.execute_reply.started":"2021-09-03T13:06:20.677549Z","shell.execute_reply":"2021-09-03T13:06:20.68765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Modeling**","metadata":{}},{"cell_type":"markdown","source":"#### Model's HyperParameters\n* LGBM2 Param : https://www.kaggle.com/hiro5299834/tps-sep-2021-single-lgbm\n* Cat2 Param : https://www.kaggle.com/mlanhenke/tps-09-single-catboostclassifier-0-81676\n\nThanks for Sharing!","metadata":{}},{"cell_type":"code","source":"lgb1_params = {\n    'objective': 'binary',\n    'n_estimators': 10000,\n    'random_state': 42,\n    'learning_rate': 0.095,\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 10.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n    'device' : 'gpu',\n    'max_depth' : 3,\n    'num_leaves' : 7\n}\n\nlgb2_params = {\n    'max_depth' : 3,\n    'num_leaves' : 7,\n    'n_estimators' : 5000,\n    'colsample_bytree' : 0.3,\n    'subsample' : 0.5,\n    'random_state' : 42,\n    'reg_alpha' : 18,\n    'reg_lambda' : 17,\n    'learning_rate' : 0.095,\n    'device' : 'gpu',\n    'objective' : 'binary'\n}\n\nxgb1_params = {\n      'tree_method' : 'gpu_hist', \n      'learning_rate' : 0.01,\n      'n_estimators' : 50000,\n      'colsample_bytree' : 0.3,\n      'subsample' : 0.75,\n      'reg_alpha' : 19,\n      'reg_lambda' : 19,\n      'max_depth' : 5, \n      'predictor' : 'gpu_predictor'\n}\n\ncat1_params = {\n     'depth' : 5,\n     'grow_policy' : 'SymmetricTree',\n     'l2_leaf_reg' : 3.0,\n     'random_strength' : 1.0,\n     'learning_rate' : 0.02,\n     'iterations' : 10000,\n     'loss_function' : 'CrossEntropy',\n     'eval_metric' : 'AUC',\n     'use_best_model' : True,\n     'early_stopping_rounds' : 200,\n     'task_type' : 'GPU',\n     'verbose' : 1000,\n}\n\ncat2_params = {\n    'iterations': 15585, \n    'objective': 'CrossEntropy', \n    'bootstrap_type': 'Bernoulli', \n    'learning_rate': 0.023575206684596582, \n    'reg_lambda': 36.30433203563295, \n    'random_strength': 43.75597655616195, \n    'depth': 7, \n    'min_data_in_leaf': 11, \n    'leaf_estimation_iterations': 1, \n    'subsample': 0.8227911142845009,\n    'task_type' : 'GPU',\n    'eval_metric' : 'AUC',\n    'verbose' : 1000,\n    'early_stopping_rounds' : 200,\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:06:20.689956Z","iopub.execute_input":"2021-09-03T13:06:20.690524Z","iopub.status.idle":"2021-09-03T13:06:20.702233Z","shell.execute_reply.started":"2021-09-03T13:06:20.690486Z","shell.execute_reply":"2021-09-03T13:06:20.701316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_1 = LGBMClassifier(**lgb1_params)\nlgbm_2 = LGBMClassifier(**lgb2_params)\n\n# xgb = XGBClassifier(**xgb1_params)\n\n# cat_1 = CatBoostClassifier(**cat1_params)\n# cat_2 = CatBoostClassifier(**cat2_params)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:06:20.703448Z","iopub.execute_input":"2021-09-03T13:06:20.703827Z","iopub.status.idle":"2021-09-03T13:06:20.714944Z","shell.execute_reply.started":"2021-09-03T13:06:20.703773Z","shell.execute_reply":"2021-09-03T13:06:20.714063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del all_data3\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:06:20.716132Z","iopub.execute_input":"2021-09-03T13:06:20.716533Z","iopub.status.idle":"2021-09-03T13:06:20.852169Z","shell.execute_reply.started":"2021-09-03T13:06:20.716493Z","shell.execute_reply":"2021-09-03T13:06:20.851183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Stacking**\n\n* Making train, test prediction array!\n* Concat 5 arrays in 1 dataset\n* Thanks to kenneth Q's nice notebook (https://www.kaggle.com/kennethquisado/xgboost-10fold-cv-blend)","metadata":{}},{"cell_type":"code","source":"# cat1_train, cat1_test = Stacking_Data_Loader(cat_1, 'cat', train2, y, test2, 5)\n# del cat_1\n# gc.collect()\n\n# cat2_train, cat2_test = Stacking_Data_Loader(cat_2, 'cat', train2, y, test2, 5)\n# del cat_2\n# gc.collect()\n\nlgbm1_train, lgbm1_test = Stacking_Data_Loader(lgbm_1, 'lgbm', train2, y, test2, 5)\ndel lgbm_1\ngc.collect()\n\nlgbm2_train, lgbm2_test = Stacking_Data_Loader(lgbm_2, 'lgbm', train2, y, test2, 5)\ndel lgbm_2\ngc.collect()\n\n# xgb_train, xgb_test = Stacking_Data_Loader(xgb, 'xgb', train2, y, test2, 5)\n# del xgb\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:06:20.854726Z","iopub.execute_input":"2021-09-03T13:06:20.855255Z","iopub.status.idle":"2021-09-03T13:57:43.676768Z","shell.execute_reply.started":"2021-09-03T13:06:20.855225Z","shell.execute_reply":"2021-09-03T13:57:43.675851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Final Stacking Datasets!**","metadata":{}},{"cell_type":"code","source":"stack_x_train = np.load('../input/catboost-xgboost-stacking-datasets/stack_x_train.npy')\nstack_x_test = np.load('../input/catboost-xgboost-stacking-datasets/stack_x_test (1).npy')\n\nstack_x_train = np.concatenate((stack_x_train, lgbm1_train, lgbm2_train), axis = 1)\nstack_x_test = np.concatenate((stack_x_test, lgbm1_test, lgbm2_test), axis = 1)\n\nstack_x_train","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:57:48.554229Z","iopub.execute_input":"2021-09-03T13:57:48.554604Z","iopub.status.idle":"2021-09-03T13:57:49.357957Z","shell.execute_reply.started":"2021-09-03T13:57:48.554572Z","shell.execute_reply":"2021-09-03T13:57:49.357119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stack_x_train = np.concatenate((cat1_train, cat2_train, xgb_train, lgbm1_train, lgbm2_train), axis = 1)\n# stack_x_test = np.concatenate((cat1_test, cat2_test, xgb_test, lgbm1_test, lgbm2_test), axis = 1)\n# stack_x_train","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:57:43.678284Z","iopub.execute_input":"2021-09-03T13:57:43.678656Z","iopub.status.idle":"2021-09-03T13:57:43.838619Z","shell.execute_reply.started":"2021-09-03T13:57:43.678619Z","shell.execute_reply":"2021-09-03T13:57:43.837115Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stk = StratifiedKFold(n_splits = 5)\n\ntest_pred = 0\nfold = 1\ntotal_auc = 0\n\nfor train_index, valid_index in stk.split(stack_x_train, y):\n    x_train, y_train = stack_x_train[train_index], y[train_index]\n    x_valid, y_valid = stack_x_train[valid_index], y[valid_index]\n    \n    lr = LogisticRegression(n_jobs = -1, random_state = 42, C = 1000, max_iter = 1000)\n    lr.fit(x_train, y_train)\n    \n    valid_pred = lr.predict_proba(x_valid)[:, 1]\n    test_pred += lr.predict_proba(stack_x_test)[:, 1]\n    auc = roc_auc_score(y_valid, valid_pred)\n    total_auc += auc / 5\n    print('Fold', fold, 'AUC :', auc)\n    fold += 1\n    \nprint('Total AUC score :', total_auc)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T13:57:53.081285Z","iopub.execute_input":"2021-09-03T13:57:53.081751Z","iopub.status.idle":"2021-09-03T13:58:15.259202Z","shell.execute_reply.started":"2021-09-03T13:57:53.081712Z","shell.execute_reply":"2021-09-03T13:58:15.257059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission!**","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')\nsub['claim'] = test_pred\nsub.to_csv('sub.csv', index = 0)","metadata":{"id":"txo_UHFX8e7V","execution":{"iopub.status.busy":"2021-09-03T13:58:18.692344Z","iopub.execute_input":"2021-09-03T13:58:18.692716Z","iopub.status.idle":"2021-09-03T13:58:20.351732Z","shell.execute_reply.started":"2021-09-03T13:58:18.69268Z","shell.execute_reply":"2021-09-03T13:58:20.350818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Done!\n\n\n## If you think this notebook is helpful for you, Please do not forget upvote!","metadata":{}}]}