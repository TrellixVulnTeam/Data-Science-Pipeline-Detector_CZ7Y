{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T18:19:16.279232Z","iopub.execute_input":"2021-09-09T18:19:16.279682Z","iopub.status.idle":"2021-09-09T18:19:16.29632Z","shell.execute_reply.started":"2021-09-09T18:19:16.279582Z","shell.execute_reply":"2021-09-09T18:19:16.2954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:28:48.391616Z","iopub.execute_input":"2021-09-09T18:28:48.39196Z","iopub.status.idle":"2021-09-09T18:29:20.439355Z","shell.execute_reply.started":"2021-09-09T18:28:48.39193Z","shell.execute_reply":"2021-09-09T18:29:20.43848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop('claim', axis =1).copy()\ny = train.claim","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:19:55.360983Z","iopub.execute_input":"2021-09-09T18:19:55.361292Z","iopub.status.idle":"2021-09-09T18:19:56.197824Z","shell.execute_reply.started":"2021-09-09T18:19:55.361259Z","shell.execute_reply":"2021-09-09T18:19:56.196697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgbm\nfrom optuna.integration import LightGBMPruningCallback\nimport optuna  # pip install optuna\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:19:56.199249Z","iopub.execute_input":"2021-09-09T18:19:56.199536Z","iopub.status.idle":"2021-09-09T18:19:59.44517Z","shell.execute_reply.started":"2021-09-09T18:19:56.199508Z","shell.execute_reply":"2021-09-09T18:19:59.444228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\ndef objective(trial, X, y):\n    param_grid = {\n        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n        \"bagging_fraction\": trial.suggest_float(\n            \"bagging_fraction\", 0.2, 0.95, step=0.1\n        ),\n        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n        \"feature_fraction\": trial.suggest_float(\n            \"feature_fraction\", 0.2, 0.95, step=0.1\n        ),\n    }\n\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n\n    cv_scores = np.empty(5)\n    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_test = y[train_idx], y[test_idx]\n\n        model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n        model.fit(\n            X_train,\n            y_train,\n            eval_set=[(X_test, y_test)],\n            eval_metric=\"binary_logloss\",\n            early_stopping_rounds=100,\n            callbacks=[\n                LightGBMPruningCallback(trial, \"binary_logloss\")\n            ],  # Add a pruning callback\n        )\n        preds = model.predict_proba(X_test)\n        cv_scores[idx] = log_loss(y_test, preds)\n\n    return np.mean(cv_scores)\n    \nstudy = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\nfunc = lambda trial: objective(trial, X, y)\nstudy.optimize(func, n_trials=20)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T12:00:53.31491Z","iopub.execute_input":"2021-09-09T12:00:53.315257Z","iopub.status.idle":"2021-09-09T12:00:53.3261Z","shell.execute_reply.started":"2021-09-09T12:00:53.315226Z","shell.execute_reply":"2021-09-09T12:00:53.325072Z"}}},{"cell_type":"markdown","source":"print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\nprint(f\"\\tBest params:\")\n\nbest_params = study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:52:39.805057Z","iopub.execute_input":"2021-09-09T13:52:39.805486Z","iopub.status.idle":"2021-09-09T13:52:39.814831Z","shell.execute_reply.started":"2021-09-09T13:52:39.805429Z","shell.execute_reply":"2021-09-09T13:52:39.814106Z"}}},{"cell_type":"markdown","source":"best_params","metadata":{}},{"cell_type":"code","source":"best_params = {'n_estimators': 10000,\n 'learning_rate': 0.20731879670353354,\n 'num_leaves': 380,\n 'max_depth': 11,\n 'min_data_in_leaf': 200,\n 'lambda_l1': 100,\n 'lambda_l2': 70,\n 'min_gain_to_split': 10.725878344141766,\n 'bagging_fraction': 0.9,\n 'bagging_freq': 1,\n 'feature_fraction': 0.6000000000000001}\n\nfrom sklearn.metrics import mean_squared_error\nmodel = lgbm.LGBMClassifier(objective=\"binary\", **best_params)\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:19:59.446724Z","iopub.execute_input":"2021-09-09T18:19:59.447116Z","iopub.status.idle":"2021-09-09T18:28:37.612371Z","shell.execute_reply.started":"2021-09-09T18:19:59.447074Z","shell.execute_reply":"2021-09-09T18:28:37.610227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tt_predict = model.predict(test)\n\nsubmission['claim'] = tt_predict\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:28:37.613588Z","iopub.status.idle":"2021-09-09T18:28:37.613995Z"},"trusted":true},"execution_count":null,"outputs":[]}]}