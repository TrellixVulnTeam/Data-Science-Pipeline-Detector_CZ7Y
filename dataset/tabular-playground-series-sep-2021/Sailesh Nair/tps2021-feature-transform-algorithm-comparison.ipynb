{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)\n\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score,RandomizedSearchCV, GridSearchCV\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import QuantileTransformer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T08:32:06.620948Z","iopub.execute_input":"2021-09-09T08:32:06.621617Z","iopub.status.idle":"2021-09-09T08:32:08.21226Z","shell.execute_reply.started":"2021-09-09T08:32:06.621471Z","shell.execute_reply":"2021-09-09T08:32:08.211208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In the earlier notebook we did the [EDA](http://www.kaggle.com/saileshnair/tps202109-normal-and-quick-eda)","metadata":{}},{"cell_type":"code","source":"def plot_model_comparison(models,results,title):\n    \"\"\" \n        Compares the results of different models and plots box plots for the algorithms.\n        models: list of names of models\n        results: training results\n        title: title for the graph\n        \n    \"\"\"\n    fig = plt.figure()\n    fig.suptitle(title)\n    ax = fig.add_subplot(111)\n    plt.boxplot(results)\n    ax.set_xticklabels(models)\n    plt.show()\n\ndef timer(start_time=None):\n    \"\"\" \n        Helps  to keep track of time elapsed while training.\n        start time: if none then start time tracking\n                    if not none tracks time from start time         \n    \"\"\"\n    from datetime import datetime\n    if not start_time:\n        print(datetime.now())\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print(\"Time taken: %i hours %i minutes and %s seconds.\" % (thour, tmin, round(tsec, 2)))\n\ndef getbounds(col):\n    ''' \n    This function returns the upper bound and the lower bound using the IQR for the column \"col\".\n    '''\n    sorted(col)\n    q1,q3 = np.percentile(col,[25,75]) # quartailes\n    iqr = q3-q1 # inter quartile range\n    lb = q1 -(1.5*iqr) # lower bound\n    ub = q3 +(1.5*iqr) # upper bound\n    return lb,ub\n\ndef plothists(df):\n    '''\n    we'll use this function to iteratively plot the histplot for all columns of the df\n    '''\n    nrows = 30\n    ncols = 4\n    i = 0\n    fig, ax = plt.subplots(nrows, ncols, figsize = (40,120))\n    for row in range(nrows):\n        for col in range(ncols):\n            if i==118:\n                break\n            else:\n                sns.histplot(data = df.iloc[:, i], bins = 30, ax = ax[row, col]).set(ylabel = '')\n                i += 1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T08:32:08.213924Z","iopub.execute_input":"2021-09-09T08:32:08.214607Z","iopub.status.idle":"2021-09-09T08:32:08.230858Z","shell.execute_reply.started":"2021-09-09T08:32:08.214526Z","shell.execute_reply":"2021-09-09T08:32:08.229679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In this notebook I'm trying out how to transform the data into a normal distribution\n","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:32:08.233082Z","iopub.execute_input":"2021-09-09T08:32:08.233414Z","iopub.status.idle":"2021-09-09T08:32:41.923916Z","shell.execute_reply.started":"2021-09-09T08:32:08.233381Z","shell.execute_reply":"2021-09-09T08:32:41.922894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train.columns[1:-1]\ndf=train[features].copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:32:41.925624Z","iopub.execute_input":"2021-09-09T08:32:41.926159Z","iopub.status.idle":"2021-09-09T08:32:42.665146Z","shell.execute_reply.started":"2021-09-09T08:32:41.926121Z","shell.execute_reply":"2021-09-09T08:32:42.663975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:32:42.666659Z","iopub.execute_input":"2021-09-09T08:32:42.666995Z","iopub.status.idle":"2021-09-09T08:32:42.675929Z","shell.execute_reply.started":"2021-09-09T08:32:42.666957Z","shell.execute_reply":"2021-09-09T08:32:42.674946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:32:42.677236Z","iopub.execute_input":"2021-09-09T08:32:42.677675Z","iopub.status.idle":"2021-09-09T08:32:47.610595Z","shell.execute_reply.started":"2021-09-09T08:32:42.677645Z","shell.execute_reply":"2021-09-09T08:32:47.609405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:32:47.612119Z","iopub.execute_input":"2021-09-09T08:32:47.612553Z","iopub.status.idle":"2021-09-09T08:32:47.843227Z","shell.execute_reply.started":"2021-09-09T08:32:47.612491Z","shell.execute_reply":"2021-09-09T08:32:47.842273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Prepare Data\n## a) Data Cleaning\n## b) Data Transforms","metadata":{}},{"cell_type":"markdown","source":"### First let's take a look at imputation of the null values","metadata":{}},{"cell_type":"markdown","source":"#### The Simple Imputer is the quickest imputer. Other I have tried are\n+ KNNImputer() -  this uses the KNN to impute missing values\n+ IterativeImputer(random_state=21) - it is an experimental implementation of imputer in scikit learn - time consuming","metadata":{}},{"cell_type":"markdown","source":"#### Simple Imputer","metadata":{}},{"cell_type":"code","source":"si=SimpleImputer(strategy='median',copy=False)\nsi.fit_transform(df)\nidf=pd.DataFrame(data=df,columns=features)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:32:47.845868Z","iopub.execute_input":"2021-09-09T08:32:47.846183Z","iopub.status.idle":"2021-09-09T08:33:21.32217Z","shell.execute_reply.started":"2021-09-09T08:32:47.846151Z","shell.execute_reply":"2021-09-09T08:33:21.321081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idf.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:33:21.324444Z","iopub.execute_input":"2021-09-09T08:33:21.325181Z","iopub.status.idle":"2021-09-09T08:33:26.085484Z","shell.execute_reply.started":"2021-09-09T08:33:21.32514Z","shell.execute_reply":"2021-09-09T08:33:26.084151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idf.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:33:26.08713Z","iopub.execute_input":"2021-09-09T08:33:26.087445Z","iopub.status.idle":"2021-09-09T08:33:26.327825Z","shell.execute_reply.started":"2021-09-09T08:33:26.087412Z","shell.execute_reply":"2021-09-09T08:33:26.32693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We've taken care of the null values. \n#### Now to normalize we could use transformers like RobustScaler, PowerTransformer,  QuantileTransformer. In this Notebook I use QuantileTransformer.","metadata":{}},{"cell_type":"markdown","source":"+ **RobustScaler** This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n+ **Power Transformer + yeo-johnson method**:  Yeo-Johnson supports both positive or negative data.\n+ **Power Transformer + Box Cox method**:  Box-Cox requires input data to be strictly positive. First we need to treat oultliers. I capped the ouliers at the bounds. To remove the negative values I had to explicitely square the values for features containing negative values before applying this transformation.","metadata":{}},{"cell_type":"code","source":"#before transformation\nplothists(idf)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:33:26.32992Z","iopub.execute_input":"2021-09-09T08:33:26.330271Z","iopub.status.idle":"2021-09-09T08:35:25.006114Z","shell.execute_reply.started":"2021-09-09T08:33:26.330236Z","shell.execute_reply":"2021-09-09T08:35:25.004735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**QuantileTransformer** This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.","metadata":{}},{"cell_type":"code","source":"qt=QuantileTransformer(\n    n_quantiles=1000, \n    random_state=21,\n    output_distribution= 'normal',\n    copy=False)\nqt.fit_transform(idf)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:35:25.00789Z","iopub.execute_input":"2021-09-09T08:35:25.008385Z","iopub.status.idle":"2021-09-09T08:36:05.167982Z","shell.execute_reply.started":"2021-09-09T08:35:25.008344Z","shell.execute_reply":"2021-09-09T08:36:05.166725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qtidf=pd.DataFrame(data=idf,columns=features)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:36:05.169383Z","iopub.execute_input":"2021-09-09T08:36:05.169737Z","iopub.status.idle":"2021-09-09T08:36:05.174992Z","shell.execute_reply.started":"2021-09-09T08:36:05.169704Z","shell.execute_reply":"2021-09-09T08:36:05.173788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#after transformation\nplothists(qtidf)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:36:05.176628Z","iopub.execute_input":"2021-09-09T08:36:05.176941Z","iopub.status.idle":"2021-09-09T08:38:00.692327Z","shell.execute_reply.started":"2021-09-09T08:36:05.176913Z","shell.execute_reply":"2021-09-09T08:38:00.684755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now that the data is normalized, we can fit a model and check predictions. ","metadata":{}},{"cell_type":"markdown","source":"## 4. Evaluate Algorithms\n## a) Split-out validation dataset\n## b) Test options and evaluation metric\n## c) Compare Algorithms","metadata":{}},{"cell_type":"code","source":"X=qtidf.values\nY=train[['claim']].values","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:38:00.694055Z","iopub.execute_input":"2021-09-09T08:38:00.694452Z","iopub.status.idle":"2021-09-09T08:38:00.70344Z","shell.execute_reply.started":"2021-09-09T08:38:00.694413Z","shell.execute_reply":"2021-09-09T08:38:00.702389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scorer = \"roc_auc\"\nsplits = 5\nseed = 21","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:38:00.705119Z","iopub.execute_input":"2021-09-09T08:38:00.70557Z","iopub.status.idle":"2021-09-09T08:38:00.717623Z","shell.execute_reply.started":"2021-09-09T08:38:00.705507Z","shell.execute_reply":"2021-09-09T08:38:00.716431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.20,  random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:38:00.719063Z","iopub.execute_input":"2021-09-09T08:38:00.719385Z","iopub.status.idle":"2021-09-09T08:38:02.536879Z","shell.execute_reply.started":"2021-09-09T08:38:00.719355Z","shell.execute_reply":"2021-09-09T08:38:02.536139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:38:02.538039Z","iopub.execute_input":"2021-09-09T08:38:02.538521Z","iopub.status.idle":"2021-09-09T08:38:02.54476Z","shell.execute_reply.started":"2021-09-09T08:38:02.538469Z","shell.execute_reply":"2021-09-09T08:38:02.543709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('SGD', SGDClassifier(random_state=21)))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append((\"QDA\", QuadraticDiscriminantAnalysis()))\nmodels.append(('CART', DecisionTreeClassifier(max_depth=10,max_features = 10)))\nmodels.append(('NB', GaussianNB()))\nmodels.append((\"Neural Net\", MLPClassifier(alpha=1, max_iter=1000)))\nmodels","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:38:02.546404Z","iopub.execute_input":"2021-09-09T08:38:02.546784Z","iopub.status.idle":"2021-09-09T08:38:02.574273Z","shell.execute_reply.started":"2021-09-09T08:38:02.546752Z","shell.execute_reply":"2021-09-09T08:38:02.573151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=splits, shuffle=True,  random_state=seed)\n    start_time=timer(None)\n    cv_results = cross_val_score (model, x_train, y_train, cv=kfold,  scoring=scorer)\n    timer(start_time)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %5.2f (%5.2f)\" % (name, cv_results.mean()*100, \\\n                           cv_results.std()*100)\n    print(msg)\nresults_df = pd.DataFrame(results, index=names, \\\n                          columns='CV1 CV2 CV3 CV4 CV5 '.split())\nresults_df['CV Mean'] = results_df.iloc[:,0:splits].mean(axis=1)\nresults_df['CV Std Dev'] = results_df.iloc[:,0:splits].std(axis=1)\nresults_df.sort_values(by='CV Mean', ascending=False)*100","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:38:02.576017Z","iopub.execute_input":"2021-09-09T08:38:02.576328Z","iopub.status.idle":"2021-09-09T08:59:05.083451Z","shell.execute_reply.started":"2021-09-09T08:38:02.576298Z","shell.execute_reply":"2021-09-09T08:59:05.081972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title=\"Algorithms Comparison\"\nplot_model_comparison(names,results,title)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:59:05.085995Z","iopub.execute_input":"2021-09-09T08:59:05.08649Z","iopub.status.idle":"2021-09-09T08:59:05.312633Z","shell.execute_reply.started":"2021-09-09T08:59:05.086434Z","shell.execute_reply":"2021-09-09T08:59:05.311589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The best model seems to be Gaussian Naive Bayes. Lets do a submission and check","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameter Tuning the Gaussian Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"param_grid_nb = {\n    'var_smoothing': np.logspace(0,-9, num=100)\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:59:05.313744Z","iopub.execute_input":"2021-09-09T08:59:05.314139Z","iopub.status.idle":"2021-09-09T08:59:05.318209Z","shell.execute_reply.started":"2021-09-09T08:59:05.314108Z","shell.execute_reply":"2021-09-09T08:59:05.31756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time=timer(None)\nnb_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\nnb_grid.fit(x_train, y_train)\ntimer(start_time)\nprint(nb_grid.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:59:05.324688Z","iopub.execute_input":"2021-09-09T08:59:05.325131Z","iopub.status.idle":"2021-09-09T09:13:38.985323Z","shell.execute_reply.started":"2021-09-09T08:59:05.325095Z","shell.execute_reply":"2021-09-09T09:13:38.983835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = nb_grid.predict(x_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:13:38.987748Z","iopub.execute_input":"2021-09-09T09:13:38.988054Z","iopub.status.idle":"2021-09-09T09:13:39.409498Z","shell.execute_reply.started":"2021-09-09T09:13:38.988023Z","shell.execute_reply":"2021-09-09T09:13:39.408283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_pred.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:13:39.410862Z","iopub.execute_input":"2021-09-09T09:13:39.411183Z","iopub.status.idle":"2021-09-09T09:13:39.417401Z","shell.execute_reply.started":"2021-09-09T09:13:39.41115Z","shell.execute_reply":"2021-09-09T09:13:39.416064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test, y_pred), \": is the accuracy score\")\nfrom sklearn.metrics import precision_score\nprint(precision_score(y_test, y_pred), \": is the precision score\")\nfrom sklearn.metrics import recall_score\nprint(recall_score(y_test, y_pred), \": is the recall score\")\nfrom sklearn.metrics import f1_score\nprint(f1_score(y_test, y_pred), \": is the f1 score\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:13:39.419425Z","iopub.execute_input":"2021-09-09T09:13:39.419937Z","iopub.status.idle":"2021-09-09T09:13:39.743161Z","shell.execute_reply.started":"2021-09-09T09:13:39.419887Z","shell.execute_reply":"2021-09-09T09:13:39.741876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdf=pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\")\nsub_df=pd.read_csv(\"../input/tabular-playground-series-sep-2021/sample_solution.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:13:39.744975Z","iopub.execute_input":"2021-09-09T09:13:39.745406Z","iopub.status.idle":"2021-09-09T09:13:56.735474Z","shell.execute_reply.started":"2021-09-09T09:13:39.745359Z","shell.execute_reply":"2021-09-09T09:13:56.734311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(testdf.shape,sub_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:13:56.737131Z","iopub.execute_input":"2021-09-09T09:13:56.737606Z","iopub.status.idle":"2021-09-09T09:13:56.743708Z","shell.execute_reply.started":"2021-09-09T09:13:56.73753Z","shell.execute_reply":"2021-09-09T09:13:56.742381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdf.drop(columns=\"id\",inplace=True)\ntestdf.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:13:56.745425Z","iopub.execute_input":"2021-09-09T09:13:56.74592Z","iopub.status.idle":"2021-09-09T09:13:57.03581Z","shell.execute_reply.started":"2021-09-09T09:13:56.745872Z","shell.execute_reply":"2021-09-09T09:13:57.034723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"si.transform(testdf)\nqt.transform(testdf)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:13:57.037191Z","iopub.execute_input":"2021-09-09T09:13:57.037608Z","iopub.status.idle":"2021-09-09T09:14:14.645087Z","shell.execute_reply.started":"2021-09-09T09:13:57.037566Z","shell.execute_reply":"2021-09-09T09:14:14.644078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=testdf.values","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:14:14.646349Z","iopub.execute_input":"2021-09-09T09:14:14.646685Z","iopub.status.idle":"2021-09-09T09:14:14.652108Z","shell.execute_reply.started":"2021-09-09T09:14:14.646653Z","shell.execute_reply":"2021-09-09T09:14:14.650253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = nb_grid.predict_proba(test)\nprint(preds.shape)\npreds","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:14:14.653774Z","iopub.execute_input":"2021-09-09T09:14:14.654119Z","iopub.status.idle":"2021-09-09T09:14:15.822824Z","shell.execute_reply.started":"2021-09-09T09:14:14.654086Z","shell.execute_reply":"2021-09-09T09:14:15.821654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['claim'] = preds[:,0]\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:14:15.825286Z","iopub.execute_input":"2021-09-09T09:14:15.825751Z","iopub.status.idle":"2021-09-09T09:14:15.840173Z","shell.execute_reply.started":"2021-09-09T09:14:15.825701Z","shell.execute_reply":"2021-09-09T09:14:15.838776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission_gnb.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:14:15.841646Z","iopub.execute_input":"2021-09-09T09:14:15.84208Z","iopub.status.idle":"2021-09-09T09:14:17.741631Z","shell.execute_reply.started":"2021-09-09T09:14:15.842041Z","shell.execute_reply":"2021-09-09T09:14:17.740631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Kindly let me know if the approach , transformers, imputers, Algorithm Comparison were helpful for you with an upvote or comment to improve my understanding","metadata":{}}]}