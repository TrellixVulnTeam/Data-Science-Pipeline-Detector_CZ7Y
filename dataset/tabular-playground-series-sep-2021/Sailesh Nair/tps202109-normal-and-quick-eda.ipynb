{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement- \nTo predict whether a customer made a claim upon an insurance policy. The ground truth claim is binary valued, but a prediction may be any number from 0.0 to 1.0, representing the probability of a claim. The features in this dataset have been anonymized and may contain missing values.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# 1. Preparation","metadata":{}},{"cell_type":"markdown","source":"# a) Load libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:43:25.567208Z","iopub.execute_input":"2021-09-04T10:43:25.567648Z","iopub.status.idle":"2021-09-04T10:43:26.684237Z","shell.execute_reply.started":"2021-09-04T10:43:25.56755Z","shell.execute_reply":"2021-09-04T10:43:26.68331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# b) Load Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:43:50.017171Z","iopub.execute_input":"2021-09-04T10:43:50.017592Z","iopub.status.idle":"2021-09-04T10:44:21.205731Z","shell.execute_reply.started":"2021-09-04T10:43:50.017559Z","shell.execute_reply":"2021-09-04T10:44:21.204649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Summarize Data\n# a) Descriptive Statistics","metadata":{}},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:44.468139Z","iopub.execute_input":"2021-09-04T10:44:44.468539Z","iopub.status.idle":"2021-09-04T10:44:44.582249Z","shell.execute_reply.started":"2021-09-04T10:44:44.468505Z","shell.execute_reply":"2021-09-04T10:44:44.581357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:59.150137Z","iopub.execute_input":"2021-09-04T10:44:59.150542Z","iopub.status.idle":"2021-09-04T10:44:59.15588Z","shell.execute_reply.started":"2021-09-04T10:44:59.150505Z","shell.execute_reply":"2021-09-04T10:44:59.155135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:15.741114Z","iopub.execute_input":"2021-09-04T10:45:15.741696Z","iopub.status.idle":"2021-09-04T10:45:20.670695Z","shell.execute_reply.started":"2021-09-04T10:45:15.741644Z","shell.execute_reply":"2021-09-04T10:45:20.669631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of missing values\n(df.isnull().sum()/df.shape[0]*100)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:49:42.19927Z","iopub.execute_input":"2021-09-04T10:49:42.19967Z","iopub.status.idle":"2021-09-04T10:49:42.453563Z","shell.execute_reply.started":"2021-09-04T10:49:42.199639Z","shell.execute_reply":"2021-09-04T10:49:42.452479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation with the target\ndf.corr()[['claim']]","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:57:00.955385Z","iopub.execute_input":"2021-09-04T10:57:00.955904Z","iopub.status.idle":"2021-09-04T10:57:38.629423Z","shell.execute_reply.started":"2021-09-04T10:57:00.95586Z","shell.execute_reply":"2021-09-04T10:57:38.628365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Observations so far\n* Dataset is huge - 957919 rows, 120 columns\n* We have 118 feature columns excluding the id and target - claim column\n* All the feature columns have varied range of values\n* Missing values are constantly around 1.6% in each column! hmm, Should we drop?(I'm not for it) should we impute them somehow?? we'll ponder over it later..\n* As seen there is also not much of a correlation with the target variable. o-O","metadata":{}},{"cell_type":"markdown","source":"# b) Data visualizations","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(6, 1, figsize = (30,20))\nsns.boxplot(data = df.iloc[:, 1:20], ax = ax[0])\nsns.boxplot(data = df.iloc[:, 20:40], ax = ax[1])\nsns.boxplot(data = df.iloc[:, 40:60], ax = ax[2])\nsns.boxplot(data = df.iloc[:, 60:80], ax = ax[3])\nsns.boxplot(data = df.iloc[:, 80:100], ax = ax[4])\nsns.boxplot(data = df.iloc[:, 100:], ax = ax[5])","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:19:09.264131Z","iopub.execute_input":"2021-09-04T11:19:09.264646Z","iopub.status.idle":"2021-09-04T11:19:37.974024Z","shell.execute_reply.started":"2021-09-04T11:19:09.264612Z","shell.execute_reply":"2021-09-04T11:19:37.972773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This just confirms what we observed earlier that the ranges are so varied we cannot see the plots clearly.. So lets normalize the data for the visualization","metadata":{}},{"cell_type":"code","source":"features = df.columns[1:-1]\nfeat_df=df[features]\nn_df=((feat_df - feat_df.min())/(feat_df.max() - feat_df.min()))","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:19:37.975848Z","iopub.execute_input":"2021-09-04T11:19:37.976277Z","iopub.status.idle":"2021-09-04T11:19:38.96509Z","shell.execute_reply.started":"2021-09-04T11:19:37.976232Z","shell.execute_reply":"2021-09-04T11:19:38.964017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(6, 1, figsize = (30,20))\nsns.boxplot(data = n_df.iloc[:, 1:20], ax = ax[0])\nsns.boxplot(data = n_df.iloc[:, 20:40], ax = ax[1])\nsns.boxplot(data = n_df.iloc[:, 40:60], ax = ax[2])\nsns.boxplot(data = n_df.iloc[:, 60:80], ax = ax[3])\nsns.boxplot(data = n_df.iloc[:, 80:100], ax = ax[4])\nsns.boxplot(data = n_df.iloc[:, 100:], ax = ax[5])","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:19:38.966823Z","iopub.execute_input":"2021-09-04T11:19:38.967122Z","iopub.status.idle":"2021-09-04T11:20:07.454863Z","shell.execute_reply.started":"2021-09-04T11:19:38.967093Z","shell.execute_reply":"2021-09-04T11:20:07.453814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nrows = 30\nncols = 4\ni = 0\nfig, ax = plt.subplots(nrows, ncols, figsize = (40,120))\nfor row in range(nrows):\n    for col in range(ncols):\n        if i==118:\n            break\n        else:\n            sns.histplot(data = n_df.iloc[:, i], bins = 30, ax = ax[row, col]).set(ylabel = '')\n            i += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:20:07.456463Z","iopub.execute_input":"2021-09-04T11:20:07.456987Z","iopub.status.idle":"2021-09-04T11:22:00.471071Z","shell.execute_reply.started":"2021-09-04T11:20:07.456947Z","shell.execute_reply":"2021-09-04T11:22:00.470141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nfig, ax = plt.subplots(nrows, ncols, figsize = (40,120))\nfor row in range(nrows):\n    for col in range(ncols):\n        if i==118:\n            break\n        else:\n            sns.kdeplot(x = n_df.iloc[:, i], ax = ax[row, col]).set(ylabel = '')\n            i += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:22:00.472465Z","iopub.execute_input":"2021-09-04T11:22:00.472778Z","iopub.status.idle":"2021-09-04T11:31:06.117684Z","shell.execute_reply.started":"2021-09-04T11:22:00.472746Z","shell.execute_reply":"2021-09-04T11:31:06.116749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations from visualizations\n* We can clearly see from the visualisations that there are quite a few outliers - we will need a strategy to handle them\n* Also, we see that the distributions are non-gaussian, all kinds of skewness exists in the data. we have to work towards staandardizing this too\n* Yet, there are some columns that are following a gaussian pattern. to handle this we could use Scalers viz - Standard, Robust or MinMax and check with them later.","metadata":{}},{"cell_type":"markdown","source":"### Now an introduction to some tools that provide quick EDA - I'll be only sharing the codes on how to use them. Some take a lot of time and are also slow to use with the dataset being so huge. Take your pick","metadata":{}},{"cell_type":"markdown","source":"## 1. Sweetviz","metadata":{}},{"cell_type":"markdown","source":"> * import sweetviz\n> * my_report  = sweetviz.analyze([df,'Train'], target_feat='claim')\n> * my_report.show_html('FinalReport.html')","metadata":{}},{"cell_type":"code","source":"# !pip install sweetviz\nimport sweetviz\nmy_report = sweetviz.analyze([df,'Train'], target_feat='claim')\nmy_report.show_html('FinalReport.html')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:49:47.71908Z","iopub.execute_input":"2021-09-04T11:49:47.719611Z","iopub.status.idle":"2021-09-04T11:58:46.357067Z","shell.execute_reply.started":"2021-09-04T11:49:47.719492Z","shell.execute_reply":"2021-09-04T11:58:46.355991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [sweetviz report](./FinalReport.html)","metadata":{}},{"cell_type":"markdown","source":"## 2. Pandas Profiling\n\n### Since the data is huge pandas profiling took a lot of time and the report generated was also over 500mb on my local machine.Code is as below:","metadata":{}},{"cell_type":"markdown","source":"> * from pandas_profiling import ProfileReport\n> * profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n> * profile.to_file(\"PandasProfilingReport.html\")","metadata":{}},{"cell_type":"markdown","source":"## 3. D-Tale\n### quickest of the lot. It seemed like it hosted report on the machine and created the visulaizations as requested through the browser interface. You should definitely check it out! ","metadata":{}},{"cell_type":"markdown","source":"> * !pip install dtale\n> * import dtale\n> * d = dtale.show(df)\n> * d.open_browser()","metadata":{}},{"cell_type":"markdown","source":"### **** Thats it for this version! Do let me know your critiques through comments and/or appreciation through upvotes. TIA ****","metadata":{}}]}