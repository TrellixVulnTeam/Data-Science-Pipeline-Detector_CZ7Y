{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas            as pd\nimport numpy             as np\nimport seaborn           as sns\nimport matplotlib.pyplot as plt\nimport seaborn           as sns\nimport heapq\n\nfrom sklearn.model_selection   import train_test_split\nfrom sklearn.model_selection   import cross_val_score\nfrom sklearn.model_selection   import GridSearchCV\nfrom sklearn.decomposition     import IncrementalPCA\nfrom sklearn.preprocessing     import LabelEncoder\nfrom sklearn.preprocessing     import RobustScaler,MinMaxScaler,KBinsDiscretizer\nfrom sklearn.pipeline          import Pipeline\nfrom sklearn.linear_model      import LogisticRegression\nfrom sklearn.pipeline          import Pipeline\nfrom xgboost                   import XGBRegressor\nfrom sklearn.metrics           import roc_auc_score, make_scorer\n\nimport  os \n\n\n\ndef downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n\ndef grid_search_cv(X,y,test,param_grid):\n    auc = make_scorer(roc_auc_score, needs_proba=False)\n    print(\"Parameter grid:\\n{}\".format(param_grid))\n    grid_search = GridSearchCV(XGBRegressor(tree_method='gpu_hist'),param_grid,cv=5,verbose=20,n_jobs=4,scoring=auc)\n    grid_search.fit(X,y)\n\n\n    grid_search.best_estimator_.fit(X,y)   \n    y_test_pred = grid_search.best_estimator_.predict(test)\n\n    score = grid_search.best_score_\n    return score, y_test_pred\n\n\ntrain = pd.read_csv(\"/kaggle/input/tabular-playground-series-sep-2021/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/tabular-playground-series-sep-2021/test.csv\")\ntrain.head()\n\ntrain = downcast_dtypes(train)\ntest = downcast_dtypes(test)\n\n\nmissing_data_count = train.isnull().sum()\nprint(\"Missing Data in Training Set:\")\nprint(missing_data_count)\ntotal_data = np.product(train.shape)\ntotal_missing = missing_data_count.sum()\npercent_missing = (total_missing/total_data)*100\nprint(\"\\nPercentage of Missing Data:\")\nprint(percent_missing)\n\n\nsns.heatmap(train.isnull())\nplt.title(\"Missing Training Data\\n\")\nplt.show()\nfor col in train.columns[missing_data_count.to_numpy().nonzero()[0]]:\n        if train[col].dtype == 'object':\n            train[col] = train[col].fillna(train[col].mode()[0])\n        else:\n            train[col] = train[col].fillna(train[col].mean())\n\n\n\nmissing_data_count = test.isnull().sum()\nprint(\"Missing Data in Test Set:\")\nprint(missing_data_count)\nsns.heatmap(test.isnull())\nplt.title(\"Missing Test Data\\n\")\nplt.show()\nfor col in test.columns[missing_data_count.to_numpy().nonzero()[0]]:\n        if test[col].dtype == 'object':\n            test[col] = test[col].fillna(test[col].mode()[0])\n        else:\n            test[col] = test[col].fillna(test[col].mean())\n\n\nmissing_data_count = train.isnull().sum()\nprint(\"Missing Data in Training Set After the Data Engineering:\")\nprint(missing_data_count)\nsns.heatmap(train.isnull())\nplt.title(\"Missing Training Data After the Data Engineering:\\n\")\nplt.show()\nmissing_data_count = test.isnull().sum()\nprint(\"Missing Test Data After the Data Engineering:\")\nprint(missing_data_count)\nsns.heatmap(test.isnull())\nplt.title(\"Missing Test Data After the Data Engineering:\\n\")\nplt.show()\n\n\nobject_cols = []\nnumber_cols = []\nfor col in train.columns:\n    if (train[col].dtype == 'object'):\n        object_cols.append(col)\n    else:\n        number_cols.append(col)\nprint(\"Object Columns\")\nprint(object_cols)\nprint(\"Numerical Columns\")\nprint(number_cols)\n\n     \nprint(train.shape)\nprint(test.shape)\n    \ny = train['claim']\nX = train\nX.drop(['claim'],axis=1,inplace=True)\n\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    label_encoder.fit(X[col])\n    X[col] = label_encoder.transform(X[col])\n    test[col] = label_encoder.transform(test[col])\n\n\npca = IncrementalPCA()\nn_batches = 1000\nfor X_batch in np.array_split(X, n_batches):\n    pca.partial_fit(X_batch)\nprint(\"test4\")\ncumsum = np.cumsum(pca.explained_variance_ratio_)\nplt.plot(range(1,len(cumsum)+1),cumsum)\nplt.xlabel(\"Dimensions\") \nplt.ylabel(\"Explained Variance\") \nplt.show()\n\npipe = Pipeline([(\"scaler\", MinMaxScaler()),(\"pca\",IncrementalPCA(n_components=0.95,batch_size=1000))])\npipe.fit(X)\nX = pipe.transform(X)\ntest = pipe.transform(test)\n\n\n\n\nparam_grid = {'n_estimators': [500,1000,2000],\n             'learning_rate': [0.01,0.05,0.1]}\nprint(\"Parameter grid:\\n{}\".format(param_grid))\n\nscore_y, y_pred = grid_search_cv(X,y,test,param_grid)\nprint(\"Score is:\", score_y)\n\ntest_set = pd.read_csv(\"/kaggle/input/tabular-playground-series-sep-2021/test.csv\")\noutput  = pd.DataFrame({'id': test_set.id, 'claim': y_pred})\noutput.to_csv('my_submission_code9.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:23:28.56059Z","iopub.execute_input":"2021-12-20T18:23:28.561571Z"},"trusted":true},"execution_count":null,"outputs":[]}]}