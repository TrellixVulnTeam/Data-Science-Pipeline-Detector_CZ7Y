{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport plotly as py\nfrom statistics import mean\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom umap import UMAP\n\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom sklearn.ensemble import VotingClassifier\n\nimport optuna\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\npd.set_option('display.max_columns', None)\n#########################################################\ntrain = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nss = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-15T12:45:06.757605Z","iopub.execute_input":"2021-09-15T12:45:06.757936Z","iopub.status.idle":"2021-09-15T12:46:10.507335Z","shell.execute_reply.started":"2021-09-15T12:45:06.757906Z","shell.execute_reply":"2021-09-15T12:46:10.506391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results:**\n\n1. XGB solo result - 0.81771\n2. CB solo result - 0.81770\n3. LGBM solo result - 0.81795\n4. Voting result - 0.81791","metadata":{}},{"cell_type":"markdown","source":"# Basic information","metadata":{}},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T12:46:10.508753Z","iopub.execute_input":"2021-09-15T12:46:10.509102Z","iopub.status.idle":"2021-09-15T12:46:10.623722Z","shell.execute_reply.started":"2021-09-15T12:46:10.509064Z","shell.execute_reply":"2021-09-15T12:46:10.622782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = train.drop(['id', 'claim'], axis = 1).columns.tolist()\ndef info(data):\n    \n    print(f'Length of data: {len(data)}')\n    \n    print('')\n    \n    x = pd.Series([])\n    for i in data.columns.tolist():\n        x = x.append(pd.Series([data[i].dtypes]))\n    \n    print(x.value_counts().to_frame().reset_index().rename(columns={0: 'count', 'index': 'type'}))\n    \n    print('')\n    \n    flag = True\n    for i in cols:\n        if data[i].isna().sum() == 0:\n            flag = False\n            break\n            \n    print(f'All features have missing values: {flag}')\n    \n    list_na = []\n    for i in cols:\n        list_na.append(data[i].isna().sum())\n    print(f'Mean of missing values is {mean(list_na)} ({round((mean(list_na)/len(data)) * 100,2)}%)')\n    print(f'Max of missing values has {cols[list_na.index(max(list_na))]}: {max(list_na)} ({round((max(list_na)/len(data)) * 100,2)}%)')\n    print(f'Min of missing values has {cols[list_na.index(min(list_na))]}: {min(list_na)} ({round((min(list_na)/len(data)) * 100,2)}%)')\n\nprint('TRAINING DATASET INFORMATION')\nprint('')\ninfo(train)\nprint('---------------------------------------------')\nprint('TEST DATASET INFORMATION')\nprint('')\ninfo(test)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-15T12:46:10.625693Z","iopub.execute_input":"2021-09-15T12:46:10.626089Z","iopub.status.idle":"2021-09-15T12:46:11.675697Z","shell.execute_reply.started":"2021-09-15T12:46:10.626032Z","shell.execute_reply":"2021-09-15T12:46:11.674905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = (15, 71))\ncols = train.columns.tolist()[1:119]\nfor i in cols:\n    plt.subplot(24,5,cols.index(i)+1)\n    sns.set_style(\"white\")\n    plt.title(i, size = 12, fontname = 'monospace')\n    a = sns.kdeplot(train[i], color = '#f9ba32', linewidth = 1.3)\n    sns.kdeplot(test[i], color = '#426e86', linewidth = 1.3)\n    plt.ylabel('')\n    plt.xlabel('')\n    plt.xticks(fontname = 'monospace')\n    plt.yticks([])\n    for j in ['right', 'left', 'top']:\n        a.spines[j].set_visible(False)\n        a.spines['bottom'].set_linewidth(1.2)\n        \nfig.tight_layout(h_pad = 3)\n\nplt.figtext(0.335, 1.02, 'Distribution of features', color = '#2f3131', fontname = 'monospace', size = 25)\nplt.figtext(0.3, 1.01, 'train', color = '#f9ba32', fontname = 'monospace', size = 18)\nplt.figtext(0.66, 1.01, 'test', color = '#426e86', fontname = 'monospace', size = 18)\n\nplt.show()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-15T12:46:11.677292Z","iopub.execute_input":"2021-09-15T12:46:11.677661Z","iopub.status.idle":"2021-09-15T12:58:28.781961Z","shell.execute_reply.started":"2021-09-15T12:46:11.677622Z","shell.execute_reply":"2021-09-15T12:58:28.780858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 5))\nsns.set_style(\"white\")\nplt.title('Distribution of target', fontname = 'monospace', fontsize = 35, color = '#32384D', x = 0.5, y = 1.05)\na = sns.countplot(y = train['claim'], palette = (['#E29930', '#217CA3']))\na.set_yticklabels(['No claim', 'Claim'])\nplt.axhline(0.5, 0, 0.951, color = '#211F30')\nplt.xticks([])\nplt.yticks(fontname = 'monospace', fontsize = 18)\nplt.ylabel('')\nplt.xlabel('')\n\na.text(210000, 0.05, '50.2%', fontname = 'monospace', fontsize = 40, color = 'white')\na.text(210000, 1.05, '49.8%', fontname = 'monospace', fontsize = 40, color = 'white')\na.text(215000, 0.3, '(480 404)', fontname = 'monospace', fontsize = 20, color = 'white')\na.text(215000, 1.3, '(477 515)', fontname = 'monospace', fontsize = 20, color = 'white')\n\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n        \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-15T15:18:49.965073Z","iopub.execute_input":"2021-09-15T15:18:49.965406Z","iopub.status.idle":"2021-09-15T15:18:50.152084Z","shell.execute_reply.started":"2021-09-15T15:18:49.965375Z","shell.execute_reply":"2021-09-15T15:18:50.151039Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix = np.triu(train.drop('id', axis = 1).corr())\nplt.figure(figsize = (15, 12))\nsns.heatmap(train.drop('id', axis = 1).corr(), annot = False, cmap = 'Spectral', mask = matrix, vmin = -0.05, vmax = 0.05, linewidths = 0.1, linecolor = 'white', cbar = True)\nplt.xticks(size = 8, fontname = 'monospace')\nplt.yticks(size = 8, fontname = 'monospace')\nplt.figtext(0.77, 0.8, '''All 118 features and the target variable\nhave a very small\ncorrelation''', fontsize = 20, fontname = 'monospace', ha = 'right', color = '#f9ba32')\nplt.show()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-15T12:58:28.984061Z","iopub.execute_input":"2021-09-15T12:58:28.984584Z","iopub.status.idle":"2021-09-15T12:59:37.058912Z","shell.execute_reply.started":"2021-09-15T12:58:28.984545Z","shell.execute_reply":"2021-09-15T12:59:37.056425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = train.drop('id', axis = 1).corr()['claim'].reset_index().drop(index=[118])\nmin_corr = corr.min()[1]\nmax_corr = corr.max()[1]\ncorr.query(\"claim == @min_corr | claim == @max_corr\").rename(columns = {'index': 'feature'}).rename(index = {33: 'max_neg_correlation', 94: 'max_pos_correlation'})","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-15T12:59:37.060165Z","iopub.execute_input":"2021-09-15T12:59:37.060527Z","iopub.status.idle":"2021-09-15T13:00:10.147922Z","shell.execute_reply.started":"2021-09-15T12:59:37.060478Z","shell.execute_reply":"2021-09-15T13:00:10.147155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"features = train.columns.tolist()[1:119]\n\ntrain['n_missing'] = train[features].isna().sum(axis = 1)\ntest['n_missing'] = test[features].isna().sum(axis = 1)\n\ntrain['std'] = train[features].std(axis = 1)\ntest['std'] = test[features].std(axis = 1)\n\nfeatures += ['n_missing', 'std']\n\nimputer = SimpleImputer(strategy = 'mean')\nfor i in features:\n    train[i] = imputer.fit_transform(np.array(train[i]).reshape(-1,1))\n    test[i] = imputer.transform(np.array(test[i]).reshape(-1,1))\n\nsc = StandardScaler()\ntrain[features] = sc.fit_transform(train[features])\ntest[features] = sc.transform(test[features])\n\nX = train.drop(['id', 'claim'], axis = 1)\ny = train['claim']\ntest.drop('id', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T13:00:10.150355Z","iopub.execute_input":"2021-09-15T13:00:10.150721Z","iopub.status.idle":"2021-09-15T13:01:00.801908Z","shell.execute_reply.started":"2021-09-15T13:00:10.150685Z","shell.execute_reply":"2021-09-15T13:01:00.800881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Memory optimization. It would be nice to convert the data to float16, but the XGB for some reason does not support this format. The function is taken from [here](https://www.kaggle.com/rinnqd/reduce-memory-usage)","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-15T13:01:00.803586Z","iopub.execute_input":"2021-09-15T13:01:00.803917Z","iopub.status.idle":"2021-09-15T13:01:00.815856Z","shell.execute_reply.started":"2021-09-15T13:01:00.803882Z","shell.execute_reply":"2021-09-15T13:01:00.814543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_mem_usage(train)\nreduce_mem_usage(X)\nreduce_mem_usage(test)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-15T13:01:00.817112Z","iopub.execute_input":"2021-09-15T13:01:00.817718Z","iopub.status.idle":"2021-09-15T13:01:42.727502Z","shell.execute_reply.started":"2021-09-15T13:01:00.81768Z","shell.execute_reply":"2021-09-15T13:01:42.724788Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UMAP","metadata":{}},{"cell_type":"code","source":"#umap = UMAP(n_components = 2, n_neighbors = 10, min_dist = 0.99).fit_transform(train.drop(['id', 'claim'], axis = 1).sample(150000, random_state = 228), train['claim'].sample(150000, random_state = 228))\n\nplt.figure(figsize=(15, 12))\nscu = sns.scatterplot(x = umap[:, 0], y = umap[:, 1], hue = train['claim'].sample(150000, random_state = 228), palette = ['#f9ba32','#426e86'], s = 5, edgecolor = 'none', alpha = 0.4)\nplt.xticks([])\nplt.yticks([])\nfor i in ['right', 'left', 'top', 'bottom']:\n    scu.spines[i].set_visible(False)\nplt.legend(ncol = 2, borderpad = 1, frameon = True, fontsize = 11)\nscu.text(-4.6, 6.4, '''n_components = 2\nn_neighbors = 10\nmin_dist = 0.99''', fontname = 'monospace', fontsize = 12, color = 'black')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-15T15:24:05.63302Z","iopub.execute_input":"2021-09-15T15:24:05.63337Z","iopub.status.idle":"2021-09-15T15:24:08.52563Z","shell.execute_reply.started":"2021-09-15T15:24:05.633338Z","shell.execute_reply":"2021-09-15T15:24:08.524624Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB","metadata":{}},{"cell_type":"code","source":"def objective(trial, data = X, target = y):\n\n    params = {\n        'max_depth': trial.suggest_int('max_depth', 2, 8),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n        'n_estimators': trial.suggest_int('n_estimators', 10000, 50000),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 500),\n        'gamma': trial.suggest_float('gamma', 0.0001, 1.0, log = True),\n        'alpha': trial.suggest_float('alpha', 0.0001, 10.0, log = True),\n        'lambda': trial.suggest_float('lambda', 0.0001, 10.0, log = True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n        'tree_method': 'gpu_hist',\n        'booster': 'gbtree',\n        'random_state': 228,\n        'use_label_encoder': False,\n        'eval_metric': 'auc'\n    }\n    \n    model = XGBClassifier(**params)\n    scores = []\n    k = StratifiedKFold(n_splits = 2, random_state = 228, shuffle = True)\n    for i, (trn_idx, val_idx) in enumerate(k.split(X, y)):\n        \n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 300, verbose = False)\n        \n        tr_preds = model.predict_proba(X_train)[:,1]\n        tr_score = roc_auc_score(y_train, tr_preds)\n        \n        val_preds = model.predict_proba(X_val)[:,1]\n        val_score = roc_auc_score(y_val, val_preds)\n\n        scores.append((tr_score, val_score))\n        \n        print(f\"Fold {i+1} | AUC: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n    \n    return scores['validation score'].mean()\n\nstudy = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 300)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-07T12:56:06.509235Z","iopub.execute_input":"2021-09-07T12:56:06.509609Z","iopub.status.idle":"2021-09-07T12:56:39.826952Z","shell.execute_reply.started":"2021-09-07T12:56:06.509563Z","shell.execute_reply":"2021-09-07T12:56:39.824331Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean AUC on 2 folds - 0.81532\n# esr - 300\nparamsXGB = {'max_depth': 3, 'learning_rate': 0.005702659398906191, 'n_estimators': 22404, 'min_child_weight': 25, 'gamma': 0.00010151247994797229, 'alpha': 7.148020356730985, 'lambda': 0.1378423649746119, 'colsample_bytree': 0.7969227570988136, 'subsample': 0.6382893449313995,\n             'tree_method': 'gpu_hist',\n             'booster': 'gbtree',\n             'random_state': 228,\n             'use_label_encoder': False,\n             'eval_metric': 'auc'}\n# Solo result - 0.81771","metadata":{"execution":{"iopub.status.busy":"2021-09-15T13:04:34.612629Z","iopub.execute_input":"2021-09-15T13:04:34.613157Z","iopub.status.idle":"2021-09-15T13:04:34.61885Z","shell.execute_reply.started":"2021-09-15T13:04:34.613119Z","shell.execute_reply":"2021-09-15T13:04:34.618067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\npredictions = np.zeros(len(test))\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = XGBClassifier(**paramsXGB)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 300)\n    \n    predictions += model.predict_proba(test)[:,1] / folds.n_splits ","metadata":{"execution":{"iopub.status.busy":"2021-09-06T18:16:30.371213Z","iopub.execute_input":"2021-09-06T18:16:30.371568Z","iopub.status.idle":"2021-09-06T18:28:06.20435Z","shell.execute_reply.started":"2021-09-06T18:16:30.371539Z","shell.execute_reply":"2021-09-06T18:28:06.20337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss['claim'] = predictions\nss.to_csv('xgb1', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T18:28:45.595836Z","iopub.execute_input":"2021-09-06T18:28:45.596177Z","iopub.status.idle":"2021-09-06T18:28:47.136066Z","shell.execute_reply.started":"2021-09-06T18:28:45.596132Z","shell.execute_reply":"2021-09-06T18:28:47.135173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost","metadata":{}},{"cell_type":"code","source":"def objective(trial, data = X, target = y):\n    \n    params = {\n        'depth': trial.suggest_int('depth', 2, 6),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2),\n        'iterations': trial.suggest_int('iterations', 10000, 50000),\n        'max_bin': trial.suggest_int('max_bin', 1, 300),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.0001, 1.0, log = True),\n        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n        'leaf_estimation_method': trial.suggest_categorical('leaf_estimation_method', ['Newton', 'Gradient']),\n        'bootstrap_type': 'Bernoulli',\n        'random_seed': 228,\n        'loss_function': 'Logloss',\n        'eval_metric': 'AUC',\n        'task_type': 'GPU'\n    }\n    \n    model = CatBoostClassifier(**params)\n    scores = []\n    k = StratifiedKFold(n_splits = 2, random_state = 228, shuffle = True)\n    for i, (trn_idx, val_idx) in enumerate(k.split(X, y)):\n        \n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 300, verbose = False)\n        \n        tr_preds = model.predict_proba(X_train)[:,1]\n        tr_score = roc_auc_score(y_train, tr_preds)\n        \n        val_preds = model.predict_proba(X_val)[:,1]\n        val_score = roc_auc_score(y_val, val_preds)\n\n        scores.append((tr_score, val_score))\n        \n        print(f\"Fold {i+1} | AUC: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n    \n    return scores['validation score'].mean()\n\nstudy = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 300)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T19:05:54.205673Z","iopub.execute_input":"2021-09-06T19:05:54.206058Z","iopub.status.idle":"2021-09-06T19:50:29.691474Z","shell.execute_reply.started":"2021-09-06T19:05:54.206027Z","shell.execute_reply":"2021-09-06T19:50:29.688275Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean AUC on 2 folds - 0.81518\n# esr - 300\nparamsCB = {'depth': 3, 'learning_rate': 0.017585381726501453, 'iterations': 11636, 'max_bin': 461, 'min_data_in_leaf': 162, 'l2_leaf_reg': 0.02724781040038058, 'subsample': 0.6892384815879177, 'grow_policy': 'Depthwise', 'leaf_estimation_method': 'Gradient',\n            'bootstrap_type': 'Bernoulli',\n            'random_seed': 228,\n            'loss_function': 'Logloss',\n            'eval_metric': 'AUC',\n            'task_type': 'GPU' }\n# Solo result - 0.81770","metadata":{"execution":{"iopub.status.busy":"2021-09-15T13:04:34.620067Z","iopub.execute_input":"2021-09-15T13:04:34.620432Z","iopub.status.idle":"2021-09-15T13:04:34.629854Z","shell.execute_reply.started":"2021-09-15T13:04:34.620397Z","shell.execute_reply":"2021-09-15T13:04:34.628935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\npredictions = np.zeros(len(test))\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = CatBoostClassifier(**paramsCB)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 300)\n    \n    predictions += model.predict_proba(test)[:,1] / folds.n_splits ","metadata":{"execution":{"iopub.status.busy":"2021-09-06T19:51:28.803209Z","iopub.execute_input":"2021-09-06T19:51:28.803542Z","iopub.status.idle":"2021-09-06T20:42:11.547564Z","shell.execute_reply.started":"2021-09-06T19:51:28.803511Z","shell.execute_reply":"2021-09-06T20:42:11.546682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss['claim'] = predictions\nss.to_csv('cb1', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T20:43:05.59929Z","iopub.execute_input":"2021-09-06T20:43:05.599605Z","iopub.status.idle":"2021-09-06T20:43:07.14062Z","shell.execute_reply.started":"2021-09-06T20:43:05.599576Z","shell.execute_reply":"2021-09-06T20:43:07.139687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM","metadata":{}},{"cell_type":"code","source":"def objective(trial, data = X, target = y):\n\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 1000, 15000),\n        'max_depth': trial.suggest_int('max_depth', 2, 3),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 50, 500),\n        'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 200),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'random_state': 228,\n        'metric': 'auc',\n        'device_type': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n    }\n    \n    model = LGBMClassifier(**params)\n    scores = []\n    k = StratifiedKFold(n_splits = 2, random_state = 228, shuffle = True)\n    for i, (trn_idx, val_idx) in enumerate(k.split(X, y)):\n        \n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 300, verbose = False)\n        \n        tr_preds = model.predict_proba(X_train)[:,1]\n        tr_score = roc_auc_score(y_train, tr_preds)\n        \n        val_preds = model.predict_proba(X_val)[:,1]\n        val_score = roc_auc_score(y_val, val_preds)\n\n        scores.append((tr_score, val_score))\n        \n        print(f\"Fold {i+1} | AUC: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n    \n    return scores['validation score'].mean()\n\nstudy = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T21:18:23.419738Z","iopub.execute_input":"2021-09-06T21:18:23.420115Z","iopub.status.idle":"2021-09-06T22:05:23.323708Z","shell.execute_reply.started":"2021-09-06T21:18:23.420082Z","shell.execute_reply":"2021-09-06T22:05:23.321018Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean AUC on 2 folds - 0.8151\nparamsLGBM = {'n_estimators': 11990, 'max_depth': 3, 'learning_rate': 0.016501612373246877, 'reg_alpha': 7.555087388180319, 'reg_lambda': 0.9534606245427513, 'num_leaves': 155, 'min_data_per_group': 177, 'min_child_samples': 150, 'colsample_bytree': 0.22781593823447946,\n            'boosting_type': 'gbdt',\n            'objective': 'binary',\n            'random_state': 228,\n            'metric': 'auc',\n            'device_type': 'gpu',\n            'gpu_platform_id': 0,\n            'gpu_device_id': 0}\n# Solo result - 0.81795","metadata":{"execution":{"iopub.status.busy":"2021-09-15T13:04:34.631035Z","iopub.execute_input":"2021-09-15T13:04:34.631386Z","iopub.status.idle":"2021-09-15T13:04:34.638562Z","shell.execute_reply.started":"2021-09-15T13:04:34.631352Z","shell.execute_reply":"2021-09-15T13:04:34.637865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\npredictions = np.zeros(len(test))\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = LGBMClassifier(**paramsLGBM)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 300)\n    \n    predictions += model.predict_proba(test)[:,1] / folds.n_splits ","metadata":{"execution":{"iopub.status.busy":"2021-09-07T09:27:44.084526Z","iopub.execute_input":"2021-09-07T09:27:44.084933Z","iopub.status.idle":"2021-09-07T10:53:51.131741Z","shell.execute_reply.started":"2021-09-07T09:27:44.084902Z","shell.execute_reply":"2021-09-07T10:53:51.13059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss['claim'] = predictions\nss.to_csv('lgbm1', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T10:54:05.329596Z","iopub.execute_input":"2021-09-07T10:54:05.329966Z","iopub.status.idle":"2021-09-07T10:54:05.337779Z","shell.execute_reply.started":"2021-09-07T10:54:05.329934Z","shell.execute_reply":"2021-09-07T10:54:05.336195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting time","metadata":{}},{"cell_type":"code","source":"xgb_model = XGBClassifier(**paramsXGB)\ncb_model = CatBoostClassifier(**paramsCB)\nlgbm_model = LGBMClassifier(**paramsLGBM)\n\n# XGB solo result - 0.81771\n# CB solo result - 0.81770\n# LGBM solo result - 0.81795","metadata":{"execution":{"iopub.status.busy":"2021-09-15T13:04:34.639771Z","iopub.execute_input":"2021-09-15T13:04:34.640316Z","iopub.status.idle":"2021-09-15T13:04:34.654975Z","shell.execute_reply.started":"2021-09-15T13:04:34.640273Z","shell.execute_reply":"2021-09-15T13:04:34.654126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 5, random_state = 228, shuffle = True)\n\npredictions = np.zeros(len(test))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = VotingClassifier(\n            estimators = [\n                ('xgb', xgb_model),\n                ('cb', cb_model),\n                ('lgbm', lgbm_model)       \n            ],\n            voting = 'soft',\n            weights = [0.3, 0.3, 0.4],\n            n_jobs = -1\n        )\n   \n    model.fit(X_train, y_train)\n    \n    predictions += model.predict_proba(test)[:,1] / folds.n_splits\n    \nss['claim'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-09-15T13:06:50.412177Z","iopub.execute_input":"2021-09-15T13:06:50.412653Z","iopub.status.idle":"2021-09-15T15:14:26.635456Z","shell.execute_reply.started":"2021-09-15T13:06:50.412617Z","shell.execute_reply":"2021-09-15T15:14:26.634319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss.to_csv('voting', index = False)\nss","metadata":{"execution":{"iopub.status.busy":"2021-09-15T15:14:26.640484Z","iopub.execute_input":"2021-09-15T15:14:26.642578Z","iopub.status.idle":"2021-09-15T15:14:28.415597Z","shell.execute_reply.started":"2021-09-15T15:14:26.642534Z","shell.execute_reply":"2021-09-15T15:14:28.414542Z"},"trusted":true},"execution_count":null,"outputs":[]}]}