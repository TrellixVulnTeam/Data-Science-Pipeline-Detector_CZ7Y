{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome to the September 2021 Tabular Playground Competition! #\n\nIn this competition, we predict whether a customer will make an insurance claim.\n\n# Step1: Import Helpful Libraries #","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-09-03T04:58:56.42002Z","iopub.execute_input":"2021-09-03T04:58:56.420314Z","iopub.status.idle":"2021-09-03T04:58:57.305668Z","shell.execute_reply.started":"2021-09-03T04:58:56.420243Z","shell.execute_reply":"2021-09-03T04:58:57.304836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Step2: Load Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\", index_col='id')\ntest = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\", index_col='id')\n\nFEATURES = list(df_train.columns[:-1])\nTARGET = df_train.columns[-1]\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T04:58:57.307154Z","iopub.execute_input":"2021-09-03T04:58:57.307483Z","iopub.status.idle":"2021-09-03T04:59:37.497125Z","shell.execute_reply.started":"2021-09-03T04:58:57.307449Z","shell.execute_reply":"2021-09-03T04:59:37.496263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target `'claim'` has binary outcomes: `0` for no claim and `1` for claim.","metadata":{}},{"cell_type":"code","source":"df_train.info()\ndf_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T04:59:37.498918Z","iopub.execute_input":"2021-09-03T04:59:37.499261Z","iopub.status.idle":"2021-09-03T04:59:41.405735Z","shell.execute_reply.started":"2021-09-03T04:59:37.499225Z","shell.execute_reply":"2021-09-03T04:59:41.404822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Value\nRefer to [TPS Sep 2021 single LGBM](https://www.kaggle.com/hiro5299834/tps-sep-2021-single-lgbm/notebook) by [@hiro5299834](https://www.kaggle.com/hiro5299834)","metadata":{}},{"cell_type":"code","source":"df_train['n_missing'] = df_train[FEATURES].isna().sum(axis=1)\ntest['n_missing'] = test[FEATURES].isna().sum(axis=1)\n\ndf_train['std'] = df_train[FEATURES].std(axis=1)\ntest['std'] = test[FEATURES].std(axis=1)\n\nFEATURES += ['n_missing', 'std']\nn_missing = df_train['n_missing'].copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T04:59:41.407342Z","iopub.execute_input":"2021-09-03T04:59:41.407847Z","iopub.status.idle":"2021-09-03T04:59:43.494138Z","shell.execute_reply.started":"2021-09-03T04:59:41.407806Z","shell.execute_reply":"2021-09-03T04:59:43.493239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[FEATURES] = df_train[FEATURES].fillna(df_train[FEATURES].mean())\ntest[FEATURES] = test[FEATURES].fillna(test[FEATURES].mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-03T04:59:43.495476Z","iopub.execute_input":"2021-09-03T04:59:43.49585Z","iopub.status.idle":"2021-09-03T04:59:46.689202Z","shell.execute_reply.started":"2021-09-03T04:59:43.495813Z","shell.execute_reply":"2021-09-03T04:59:46.688116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step3: Train Model #\n\nLet's try out a simple XGBoost model. This algorithm can handle missing values, but you could try imputing them instead.  We use `XGBClassifier` (instead of `XGBRegressor`, for instance), since this is a classification problem.","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nX = df_train.loc[:, FEATURES]\ny = df_train.loc[:, TARGET]\n\nfinal_predictions = []\nkf = KFold(n_splits=10, shuffle=True, random_state=42)\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=X)):\n    X_train = X.loc[train_indicies]\n    X_valid = X.loc[valid_indicies]\n    X_test = test.copy()\n    \n    y_train = y.loc[train_indicies]\n    y_valid = y.loc[valid_indicies]\n    \n    \n    scaler = StandardScaler()\n    X_train[FEATURES] = scaler.fit_transform(X_train[FEATURES])\n    X_valid[FEATURES] = scaler.transform(X_valid[FEATURES])\n    X_test[FEATURES] = scaler.transform(X_test[FEATURES])\n    \n    model = LGBMClassifier(\n        max_depth = 3,\n        num_leaves = 7,\n        n_estimators = 10000,\n        colsample_bytree = 0.3,\n        subsample = 0.5,\n        random_state = 42,\n        reg_alpha=18,\n        reg_lambda=17,\n        learning_rate = 0.095,\n        device = 'gpu',\n        objective= 'binary'\n    )\n    \n    model.fit(X_train, y_train,\n             verbose = False,\n             eval_set = [(X_train, y_train), (X_valid, y_valid)],\n             eval_metric = \"auc\",\n             early_stopping_rounds = 200)\n    \n    preds_valid = model.predict_proba(X_valid)[:,1]\n    preds_test = model.predict_proba(X_test)[:,1]\n    final_predictions.append(preds_test)\n    print(fold, roc_auc_score(y_valid, preds_valid))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T04:59:46.690502Z","iopub.execute_input":"2021-09-03T04:59:46.690872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Submission #\n\nOur predictions are binary 0 and 1, but you're allowed to submit probabilities instead. In scikit-learn, you would use the `predict_proba` method instead of `predict`.\n","metadata":{}},{"cell_type":"code","source":"preds = np.mean(np.column_stack(final_predictions), axis=1)\n\n# Make predictions\ny_pred = pd.Series(\n    preds,\n    index=X_test.index,\n    name=TARGET,\n)\n\n# Create submission file\ny_pred.to_csv(\"submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}