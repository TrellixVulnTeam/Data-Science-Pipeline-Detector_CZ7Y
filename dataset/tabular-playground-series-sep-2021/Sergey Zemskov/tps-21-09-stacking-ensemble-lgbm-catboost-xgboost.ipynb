{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <center>Tabular Playground Series - Sep 2021</center>\n### <center>Stacking solution (LightGBM + CatBoost + XGBoost)</center>\n\nThis notebook contains full solution to building stacking pipeline + evaluation of predictions.  \nIn this competition we predict whether a customer made a claim upon an insurance policy.\n\n#### Dataset:\nThe dataset is used for this competition is synthetic (and generated using a CTGAN), but based on a real dataset. The original dataset deals with predicting whether a claim will be made on an insurance policy.\n* 'f1' - 'f118' continuous features\n* 'claim' - binary valued target, but a prediction may be any number from 0.0 to 1.0, representing the probability of a claim.","metadata":{}},{"cell_type":"markdown","source":"### Import libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # plotting\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import Pool \nfrom sklearn import metrics\nimport shap as shap\nfrom tqdm import tqdm\n\npd.set_option('display.max_rows', 120)\npd.set_option('display.max_columns', 200)\n\nSEED = 91 # random seed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-04T20:54:34.338942Z","iopub.execute_input":"2021-10-04T20:54:34.339765Z","iopub.status.idle":"2021-10-04T20:54:34.348681Z","shell.execute_reply.started":"2021-10-04T20:54:34.339722Z","shell.execute_reply":"2021-10-04T20:54:34.347825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load data and first look","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/input/tabular-playground-series-sep-2021/' # you can use your own local path\n\nprint(f\"Files in directory {PATH.split('/')[-2]}:\")\nfor _, _, filenames in os.walk(PATH):\n    for filename in filenames:\n        print('  '+os.path.join(filename))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:54:34.350455Z","iopub.execute_input":"2021-10-04T20:54:34.351003Z","iopub.status.idle":"2021-10-04T20:54:34.370022Z","shell.execute_reply.started":"2021-10-04T20:54:34.350965Z","shell.execute_reply":"2021-10-04T20:54:34.369083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    df_train = pd.read_csv(PATH+'train.csv', index_col=0)\n    df_test = pd.read_csv(PATH+'test.csv', index_col=0)\n    print('All data has been loaded successfully!')\nexcept Exception as err:\n    print(repr(err))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:54:34.371683Z","iopub.execute_input":"2021-10-04T20:54:34.372251Z","iopub.status.idle":"2021-10-04T20:55:01.602196Z","shell.execute_reply.started":"2021-10-04T20:54:34.372213Z","shell.execute_reply":"2021-10-04T20:55:01.601447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_train = df_train.sample(frac=0.15, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:01.60434Z","iopub.execute_input":"2021-10-04T20:55:01.604595Z","iopub.status.idle":"2021-10-04T20:55:01.835226Z","shell.execute_reply.started":"2021-10-04T20:55:01.60456Z","shell.execute_reply":"2021-10-04T20:55:01.834321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_lenght_data = len(df_train) + len(df_test)\nprint(f\"train: {len(df_train)} ({100*len(df_train)/full_lenght_data:.0f}%)\")\nprint(f\"test:  {len(df_test)} ({100*len(df_test)/full_lenght_data:.0f}%)\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:01.836665Z","iopub.execute_input":"2021-10-04T20:55:01.836959Z","iopub.status.idle":"2021-10-04T20:55:01.842931Z","shell.execute_reply.started":"2021-10-04T20:55:01.836923Z","shell.execute_reply":"2021-10-04T20:55:01.842081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:01.844439Z","iopub.execute_input":"2021-10-04T20:55:01.845209Z","iopub.status.idle":"2021-10-04T20:55:01.864203Z","shell.execute_reply.started":"2021-10-04T20:55:01.845174Z","shell.execute_reply":"2021-10-04T20:55:01.863246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:01.865599Z","iopub.execute_input":"2021-10-04T20:55:01.866063Z","iopub.status.idle":"2021-10-04T20:55:01.884274Z","shell.execute_reply.started":"2021-10-04T20:55:01.866022Z","shell.execute_reply":"2021-10-04T20:55:01.88358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check if exist missing value","metadata":{}},{"cell_type":"code","source":"df_train.isnull().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:01.885281Z","iopub.execute_input":"2021-10-04T20:55:01.885972Z","iopub.status.idle":"2021-10-04T20:55:01.92533Z","shell.execute_reply.started":"2021-10-04T20:55:01.885937Z","shell.execute_reply":"2021-10-04T20:55:01.924544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"claim = 0: {len(df_train[df_train['claim'] == 0])} ({100*len(df_train[df_train['claim'] == 0])/len(df_train):.2f}%)\")\nprint(f\"claim = 1: {len(df_train[df_train['claim'] == 1])} ({100*len(df_train[df_train['claim'] == 1])/len(df_train):.2f}%)\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:01.926522Z","iopub.execute_input":"2021-10-04T20:55:01.926831Z","iopub.status.idle":"2021-10-04T20:55:02.058192Z","shell.execute_reply.started":"2021-10-04T20:55:01.926797Z","shell.execute_reply":"2021-10-04T20:55:02.057254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Feature engineering","metadata":{}},{"cell_type":"code","source":"def add_features(df: pd.DataFrame) -> pd.DataFrame:\n    df_new = df.copy()\n    features = [x for x in df.columns.values if x not in 'claim']\n\n    df_new['num_missing'] = df_new[features].isna().sum(axis=1)\n    df_new['num_missing_std'] = df_new[features].isna().std(axis=1).astype('float')\n    df_new['abs_sum'] = df_new[features].abs().sum(axis=1)\n    df_new['median'] = df_new[features].median(axis=1)\n    df_new['std'] = df_new[features].std(axis=1)\n    df_new['min'] = df_new[features].abs().min(axis=1)\n    df_new['max'] = df_new[features].abs().max(axis=1)\n    #df_new['sem'] = df_new[features].sem(axis=1)\n    df_new['avg'] = df_new[features].mean(axis=1)\n    \n    return df_new","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:02.061703Z","iopub.execute_input":"2021-10-04T20:55:02.061976Z","iopub.status.idle":"2021-10-04T20:55:02.075976Z","shell.execute_reply.started":"2021-10-04T20:55:02.061941Z","shell.execute_reply":"2021-10-04T20:55:02.074815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess nan values","metadata":{}},{"cell_type":"markdown","source":"Idea taken from www.kaggle.com/dlaststark/tps-sep-single-xgboost-model  \n\nI have modified the choices using the following rationale:\n* Mean: normal distribution  \n* Median: unimodal and skewed  \n* Mode: all other cases  ","metadata":{}},{"cell_type":"code","source":"def preprocess_na(df: pd.DataFrame) -> pd.DataFrame:\n    df_new = df.copy()\n    features = df.columns.tolist()\n    \n    fill_value_dict = {\n        'f1': 'Mean', \n        'f2': 'Median', \n        'f3': 'Median', \n        'f4': 'Median', \n        'f5': 'Mode', \n        'f6': 'Mean', \n        'f7': 'Median', \n        'f8': 'Median', \n        'f9': 'Median', \n        'f10': 'Median', \n        'f11': 'Mean', \n        'f12': 'Median', \n        'f13': 'Mean', \n        'f14': 'Median', \n        'f15': 'Mean', \n        'f16': 'Median', \n        'f17': 'Median', \n        'f18': 'Median', \n        'f19': 'Median', \n        'f20': 'Median', \n        'f21': 'Median', \n        'f22': 'Mean', \n        'f23': 'Mode', \n        'f24': 'Median', \n        'f25': 'Median', \n        'f26': 'Median', \n        'f27': 'Median', \n        'f28': 'Median', \n        'f29': 'Mode', \n        'f30': 'Median', \n        'f31': 'Median', \n        'f32': 'Median', \n        'f33': 'Median', \n        'f34': 'Mean', \n        'f35': 'Median', \n        'f36': 'Mean', \n        'f37': 'Median', \n        'f38': 'Median', \n        'f39': 'Median', \n        'f40': 'Mode', \n        'f41': 'Median', \n        'f42': 'Mode', \n        'f43': 'Mean', \n        'f44': 'Median', \n        'f45': 'Median', \n        'f46': 'Mean', \n        'f47': 'Mode', \n        'f48': 'Mean', \n        'f49': 'Mode', \n        'f50': 'Mode', \n        'f51': 'Median', \n        'f52': 'Median', \n        'f53': 'Median', \n        'f54': 'Mean', \n        'f55': 'Mean', \n        'f56': 'Mode', \n        'f57': 'Mean', \n        'f58': 'Median', \n        'f59': 'Median', \n        'f60': 'Median', \n        'f61': 'Median', \n        'f62': 'Median', \n        'f63': 'Median', \n        'f64': 'Median', \n        'f65': 'Mode', \n        'f66': 'Median', \n        'f67': 'Median', \n        'f68': 'Median', \n        'f69': 'Mean', \n        'f70': 'Mode', \n        'f71': 'Median', \n        'f72': 'Median', \n        'f73': 'Median', \n        'f74': 'Mode', \n        'f75': 'Mode', \n        'f76': 'Mean', \n        'f77': 'Mode', \n        'f78': 'Median', \n        'f79': 'Mean', \n        'f80': 'Median', \n        'f81': 'Mode', \n        'f82': 'Median', \n        'f83': 'Mode', \n        'f84': 'Median', \n        'f85': 'Median', \n        'f86': 'Median', \n        'f87': 'Median', \n        'f88': 'Median', \n        'f89': 'Median', \n        'f90': 'Mean', \n        'f91': 'Mode', \n        'f92': 'Median', \n        'f93': 'Median', \n        'f94': 'Median', \n        'f95': 'Median', \n        'f96': 'Median', \n        'f97': 'Mean', \n        'f98': 'Median', \n        'f99': 'Median', \n        'f100': 'Mode', \n        'f101': 'Median', \n        'f102': 'Median', \n        'f103': 'Median', \n        'f104': 'Median', \n        'f105': 'Median', \n        'f106': 'Median', \n        'f107': 'Median', \n        'f108': 'Median', \n        'f109': 'Mode', \n        'f110': 'Median', \n        'f111': 'Median', \n        'f112': 'Median', \n        'f113': 'Mean', \n        'f114': 'Median', \n        'f115': 'Median', \n        'f116': 'Mode', \n        'f117': 'Median', \n        'f118': 'Mean'\n    }\n\n\n    for col in tqdm(features):\n        if fill_value_dict.get(col)=='Mean':\n            fill_value = df_new[col].mean()\n        elif fill_value_dict.get(col)=='Median':\n            fill_value = df_new[col].median()\n        elif fill_value_dict.get(col)=='Mode':\n            fill_value = df_new[col].mode().iloc[0]\n    \n        df_new[col].fillna(fill_value, inplace=True)\n    \n    return df_new","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:02.077432Z","iopub.execute_input":"2021-10-04T20:55:02.078004Z","iopub.status.idle":"2021-10-04T20:55:02.115145Z","shell.execute_reply.started":"2021-10-04T20:55:02.077965Z","shell.execute_reply":"2021-10-04T20:55:02.114227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of features before preprocess: train_df={df_train.shape[1]} test_df={df_test.shape[1]}\")\n\ndf_train = add_features(df_train)\ndf_train = preprocess_na(df_train)\ndf_test = add_features(df_test)\ndf_test = preprocess_na(df_test)\n\nprint(f\"After: train_df={df_train.shape[1]} test_df={df_test.shape[1]}\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:02.116787Z","iopub.execute_input":"2021-10-04T20:55:02.117425Z","iopub.status.idle":"2021-10-04T20:55:11.715582Z","shell.execute_reply.started":"2021-10-04T20:55:02.11739Z","shell.execute_reply":"2021-10-04T20:55:11.714761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET = 'claim'\n\nX = df_train.copy()\ny = X.pop(TARGET)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:11.716958Z","iopub.execute_input":"2021-10-04T20:55:11.717226Z","iopub.status.idle":"2021-10-04T20:55:11.77504Z","shell.execute_reply.started":"2021-10-04T20:55:11.717193Z","shell.execute_reply":"2021-10-04T20:55:11.77432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I test StandartScaler, RobustScaler and MinMaxScaler. And last one gives better score. If you have thoughts why, please tell in comments.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=list(df_train.columns).remove(TARGET))\nX_test = pd.DataFrame(scaler.transform(df_test), columns=list(df_train.columns).remove(TARGET))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T20:55:11.776403Z","iopub.execute_input":"2021-10-04T20:55:11.776672Z","iopub.status.idle":"2021-10-04T20:55:12.784021Z","shell.execute_reply.started":"2021-10-04T20:55:11.776639Z","shell.execute_reply":"2021-10-04T20:55:12.783272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"code","source":"model_results = {'model': [], 'score': [], 'training_time': []}\n\ndef add_model_result(dic, model, score, time=None, fi=None):\n    '''Save results of every model'''\n    dic['model'].append(model)\n    dic['score'].append(score)\n    if time:\n        dic['training_time'].append(time)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:15:53.706455Z","iopub.execute_input":"2021-10-04T21:15:53.706735Z","iopub.status.idle":"2021-10-04T21:15:53.711785Z","shell.execute_reply.started":"2021-10-04T21:15:53.706699Z","shell.execute_reply":"2021-10-04T21:15:53.711044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    'XGB 1': { # https://www.kaggle.com/mlanhenke/tps-09-simple-blend-stacking-xgb-lgbm-catb\n        'model': XGBClassifier(\n            eval_metric='auc',\n            max_depth=4,\n            alpha=10,\n            subsample=0.65,\n            colsample_bytree=0.7,\n            colsample_bylevel = 0.8675692743597421,\n            objective='binary:logistic',\n            use_label_encoder=False,\n            learning_rate=0.012,\n            n_estimators=10000,\n            min_child_weight = 366,\n            tree_method='gpu_hist',\n            gpu_id=0,\n            predictor='gpu_predictor',\n            n_jobs=-1,\n        ),\n        'feature_importance': 0\n    },\n    \n    'XGB 2': { # https://www.kaggle.com/mlanhenke/tps-09-simple-blend-stacking-xgb-lgbm-catb\n        'model': XGBClassifier(\n            eval_metric='auc',\n            max_depth=3,\n            subsample=0.5,\n            colsample_bytree=0.5,\n            learning_rate=0.01187431306013263,\n            objective='binary:logistic',\n            use_label_encoder=False,\n            n_estimators=10000,\n            tree_method='gpu_hist',\n            gpu_id=0,\n            predictor='gpu_predictor',\n            n_jobs=-1,\n            seed=SEED\n        ),\n        'feature_importance': 0\n    },\n\n#     'LGBM 1': {\n#         'model': LGBMClassifier(\n#             num_leaves = 28,\n#             n_estimators = 3000,\n#             max_depth = 8,\n#             min_child_samples = 202,\n#             learning_rate = 0.11682677767413432,\n#             bagging_fraction = 0.5036513634677549,\n#             colsample_bytree = 0.7519268943195143,\n#             n_jobs = 4,\n#             random_seed = SEED\n#         ),\n#         'feature_importance': 0\n#     },\n\n#     'LGBM 2': { # https://www.kaggle.com/tensorchoko/tabular-sep-2021-lightgbm\n#         'model': LGBMClassifier(\n#             learning_rate = 0.03,\n#             num_iterations = 30000,\n#             objective ='binary',\n#             metric = 'binary_logloss',\n#             feature_pre_filter = False,\n#             lambda_l1 = 0.0,\n#             lambda_l2 = 0.0,\n#             num_leaves = 123,\n#             feature_fraction = 1.0,\n#             bagging_fraction = 1.0,\n#             bagging_freq = 0,\n#             min_child_samples = 20,\n#             n_jobs = 4,\n#             random_seed = SEED+1\n#         ),\n#         'feature_importance': 0\n#     },\n\n#     'LGBM 3': { # https://www.kaggle.com/mlanhenke/tps-09-simple-blend-stacking-xgb-lgbm-catb\n#         'model': LGBMClassifier(\n#             max_depth = 4,\n#             objective = 'binary',\n#             metric = 'auc',\n#             n_estimators = 5000,\n#             learning_rate = 0.1,\n#             reg_alpha = 18,\n#             reg_lambda = 17,\n#             num_leaves = 7,\n#             colsample_bytree = 0.3,\n#             device = 'gpu',\n#             n_jobs = 4,\n#             random_seed = SEED\n#         ),\n#         'feature_importance': 0\n#     },\n    \n    'LGBM 4': { # https://www.kaggle.com/realtimshady/single-simple-lightgbm\n        'model': LGBMClassifier(\n            max_depth = 4,\n            objective = 'binary',\n            metric = 'auc',\n            n_estimators = 30000,\n            learning_rate = 0.02,\n            reg_alpha = 25.2,\n            reg_lambda = 90,\n            num_leaves = 148,\n            subsample = 0.71,\n            subsample_freq = 1,\n            colsample_bytree = 0.98,\n            min_child_samples = 99,\n            min_child_weight = 152,\n            #n_jobs = 4,\n            device = 'gpu',\n            random_seed = 3407\n        ),\n        'feature_importance': 0\n    },\n\n    'LGBM 5': { # https://www.kaggle.com/hiro5299834/tps-sep-2021-single-lgbm\n        'model': LGBMClassifier(\n            objective = 'binary',\n            metric = 'AUC',\n            n_estimators = 20000, #20000,\n            learning_rate = 0.01, #5e-3,\n            subsample = 0.6,\n            subsample_freq = 1,\n            colsample_bytree = 0.4,\n            reg_alpha = 10.0,\n            reg_lambda = 1e-1,\n            min_child_weight = 256,\n            min_child_samples = 20,\n            importance_type = 'gain',\n            random_seed = SEED\n        ),\n        'feature_importance': 0\n    },\n\n    'LGBM 6': { # https://www.kaggle.com/towhidultonmoy/tuned-lightgbm\n        'model': LGBMClassifier(\n            objective = 'binary',\n            boosting_type = 'gbdt', #gbdt\n            num_leaves = 6, #6 #2^(max_depth)\n            max_depth = 2, #2  \n            learning_rate = 0.1, #0.1\n            n_estimators = 41000, #40000\n            reg_alpha = 25.0,\n            reg_lambda = 76.7,\n            bagging_seed = 7014, #42\n            feature_fraction_seed = 7014, #42\n            subsample = 0.985,\n            subsample_freq = 1,\n            colsample_bytree = 0.69,\n            min_child_samples = 54,\n            min_child_weight = 256,\n            device = 'gpu',\n            random_seed = SEED\n        ),\n        'feature_importance': 0\n    },\n    \n    'CatBoost 1': {\n        'model': CatBoostClassifier(\n            class_weights = [1,1.15],\n            depth = 7,\n            learning_rate = 0.02,\n            iterations = 16000,\n            bootstrap_type = 'Bernoulli',\n            subsample = 0.98,\n            task_type = 'GPU',\n            #thread_count = 4,\n            random_seed = 3407\n        ),\n        'feature_importance': 0\n    },\n\n    'CatBoost 2': { # https://www.kaggle.com/brendanartley/sep-21-tab-series-lgbm-optuna\n        'model': CatBoostClassifier(\n            iterations = 15585, \n            objective = 'CrossEntropy', \n            bootstrap_type = 'Bernoulli', \n            od_wait = 1144, \n            learning_rate = 0.023575206684596582, \n            reg_lambda = 36.30433203563295, \n            random_strength = 43.75597655616195, \n            depth = 7, \n            min_data_in_leaf = 11, \n            leaf_estimation_iterations = 1, \n            subsample = 0.8227911142845009,\n            task_type = 'GPU',\n            #thread_count = 4,\n            random_seed = SEED\n        ),\n        'feature_importance': 0\n    },\n    \n#     'CatBoost 3': { # https://www.kaggle.com/kennethquisado/xgboost-10fold-cv-blend\n#         'model': CatBoostClassifier(\n#             eval_metric = 'AUC',\n#             #n_estimators = 10000,\n#             max_depth = 6,\n#             learning_rate = 0.04,\n#             grow_policy = \"SymmetricTree\",\n#             l2_leaf_reg = 3.0,\n#             random_strength = 1.0,\n#             task_type = 'GPU',\n#             #thread_count = 4,\n#             random_seed = SEED+2\n#         ),\n#         'feature_importance': 0\n#     },\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:15:54.413989Z","iopub.execute_input":"2021-10-04T21:15:54.414439Z","iopub.status.idle":"2021-10-04T21:15:54.443527Z","shell.execute_reply.started":"2021-10-04T21:15:54.414404Z","shell.execute_reply":"2021-10-04T21:15:54.442673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_FOLD =  5\nkfold = KFold(n_splits = N_FOLD, random_state = SEED, shuffle = True)\n\nmodel_results_level0 = {'model': [], 'score': [], 'training_time': []}\npredicted_probabilities = pd.DataFrame(X.index, columns=['id'])\ntest_predicted_probabilities = pd.DataFrame(X_test.index, columns=['id'])\n\nfor m in models:\n    print(f\"{m}:\")\n    predictions_valid  = np.zeros(X.shape[0])\n    probabilities_valid = np.zeros(X.shape[0])\n    test_predicted_probabilities[m] = np.zeros(X_test.shape[0])\n    score = 0\n    \n    start_time = time.time()\n    # Iterate through each fold\n    for fold, (train_idx, valid_idx) in enumerate(kfold.split(X)):\n        X_train = X.iloc[train_idx]\n        X_valid = X.iloc[valid_idx]\n        y_train = y.iloc[train_idx]\n        y_valid = y.iloc[valid_idx]        \n\n        model = models[m]['model']\n        model.fit(X_train, y_train,\n                  eval_set = [(X_valid, y_valid)],\n                  early_stopping_rounds = 120,\n                  verbose = False\n                 )\n\n        # Mean of the predictions\n        test_predicted_probabilities[m] += model.predict_proba(X_test)[:,1] / N_FOLD\n\n        # Mean of feature importance\n        models[m]['feature_importance'] += model.feature_importances_ / N_FOLD\n\n        # Out of Fold predictions\n        predictions_valid[valid_idx] = model.predict(X_valid)\n        probabilities_valid[valid_idx] = model.predict_proba(X_valid)[:,1]\n        fold_score = metrics.roc_auc_score(y_valid, predictions_valid[valid_idx])\n        print(f\"Fold {fold} | ROC-AUC: {fold_score:.3f}\")\n\n        score += fold_score / N_FOLD\n\n    predicted_probabilities[m] = probabilities_valid\n    add_model_result(model_results_level0, m, score, time.time()-start_time)\n    print(f\"Overall ROC-AUC: {score:.6f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:15:54.862157Z","iopub.execute_input":"2021-10-04T21:15:54.862871Z","iopub.status.idle":"2021-10-04T21:36:32.817777Z","shell.execute_reply.started":"2021-10-04T21:15:54.862833Z","shell.execute_reply":"2021-10-04T21:36:32.817024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_results = pd.DataFrame(model_results_level0).sort_values('score', ascending=False)\nmodel_results","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:36:32.819392Z","iopub.execute_input":"2021-10-04T21:36:32.819652Z","iopub.status.idle":"2021-10-04T21:36:32.832976Z","shell.execute_reply.started":"2021-10-04T21:36:32.819618Z","shell.execute_reply":"2021-10-04T21:36:32.832147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_probabilities[TARGET] = y.reset_index()[TARGET]\npredicted_probabilities = predicted_probabilities.drop('id', axis=1)\npredicted_probabilities","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:36:32.834373Z","iopub.execute_input":"2021-10-04T21:36:32.834709Z","iopub.status.idle":"2021-10-04T21:36:32.863586Z","shell.execute_reply.started":"2021-10-04T21:36:32.834673Z","shell.execute_reply":"2021-10-04T21:36:32.86272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature importance","metadata":{}},{"cell_type":"code","source":"df_fi = pd.concat([pd.DataFrame(models[m]['feature_importance'], index=df_test.columns, columns=[m]) for m in models],\n                  axis=1)\ndf_fi = df_fi.fillna(0).apply(lambda x: x/sum(x)*100)\ndf_fi['overall'] = df_fi.apply(lambda x: sum(x), axis=1)\ndf_fi = df_fi.apply(lambda x: x/sum(x)*100)\ndf_fi.sort_values('overall', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:36:32.865645Z","iopub.execute_input":"2021-10-04T21:36:32.865904Z","iopub.status.idle":"2021-10-04T21:36:32.903438Z","shell.execute_reply.started":"2021-10-04T21:36:32.86587Z","shell.execute_reply":"2021-10-04T21:36:32.902802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Evaluation","metadata":{}},{"cell_type":"code","source":"TRESHOLD = 0.5 # treshold to decide claim or not","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:36:32.904617Z","iopub.execute_input":"2021-10-04T21:36:32.904857Z","iopub.status.idle":"2021-10-04T21:36:32.909379Z","shell.execute_reply.started":"2021-10-04T21:36:32.904826Z","shell.execute_reply":"2021-10-04T21:36:32.90847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17, 11))\nplt.subplots_adjust(hspace=0.5, wspace=0.3)\n#sns.set_palette(\"Spectral\")\nfor i, m in enumerate(models):\n    plt.subplot(3, 3, i+1)\n    predictions = predicted_probabilities[m].apply(lambda x: 1 if x > TRESHOLD else 0)\n    df_cm = pd.DataFrame(metrics.confusion_matrix(y, predictions), columns=np.unique(y), index = np.unique(y))\n    df_cm.index.name = 'Actual'\n    df_cm.columns.name = 'Predicted'\n    sns.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g')\n    plt.title(f\"{m} (acc={metrics.accuracy_score(y, predictions):.3f})\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:38:17.787839Z","iopub.execute_input":"2021-10-04T21:38:17.788099Z","iopub.status.idle":"2021-10-04T21:38:21.087357Z","shell.execute_reply.started":"2021-10-04T21:38:17.788069Z","shell.execute_reply":"2021-10-04T21:38:21.086646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot ROC curve\ndef plot_roc_curve(fpr=None, tpr=None):\n    \"\"\"Plot custom histogram\"\"\"\n    plt.figure(figsize=(5,5))\n    plt.title('ROC-curve', fontsize=16)\n    plt.xlabel('False Positive Rate', fontsize=14)\n    plt.ylabel('True Positive Rate', fontsize=14)\n    \n    plt.plot(fpr, tpr)\n\n    # ROC-curve of random model\n    plt.plot([0, 1], [0, 1], linestyle='--')\n    \n    plt.ylim([0.0, 1.0])\n    plt.xlim([0.0, 1.0])\n    plt.grid(True)\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:36:36.384315Z","iopub.execute_input":"2021-10-04T21:36:36.384635Z","iopub.status.idle":"2021-10-04T21:36:36.391936Z","shell.execute_reply.started":"2021-10-04T21:36:36.384599Z","shell.execute_reply":"2021-10-04T21:36:36.390903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\npredictions_valid = np.zeros((predicted_probabilities.shape[0],))\nprobabilities_valid = np.zeros(X.shape[0])\nfinal_predicted_probabilities = 0\nscore = 0\n\nX = predicted_probabilities[models.keys()]\ny = predicted_probabilities[TARGET]\n\nN_FOLD = 7\nkf = KFold(n_splits = N_FOLD, random_state = 99, shuffle = True)\n\n# Iterate through each fold\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n    X_train = X.iloc[train_idx]\n    X_valid = X.iloc[valid_idx]\n    y_train = y.iloc[train_idx]\n    y_valid = y.iloc[valid_idx] \n\n    model = LogisticRegression(C=0.55, solver='saga', penalty='elasticnet', l1_ratio=.15, max_iter=150, n_jobs=-1)\n    model.fit(X_train, y_train)\n    \n    # Mean of the predictions\n    final_predicted_probabilities += model.predict_proba(test_predicted_probabilities[models.keys()])[:,1] / N_FOLD\n    \n    # Out of Fold predictions\n    predictions_valid[valid_idx] = model.predict(X_valid)\n    probabilities_valid[valid_idx] = model.predict_proba(X_valid)[:,1]\n    fold_score = metrics.roc_auc_score(y_valid, predictions_valid[valid_idx])\n    print(f\"Fold {fold} | ROC-AUC: {fold_score:.3f}\")\n\n    score += fold_score / N_FOLD\n    \nprint(f\"Overall ROC-AUC: {score:.6f}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:57:58.90681Z","iopub.execute_input":"2021-10-04T21:57:58.907442Z","iopub.status.idle":"2021-10-04T21:58:03.663415Z","shell.execute_reply.started":"2021-10-04T21:57:58.907403Z","shell.execute_reply":"2021-10-04T21:58:03.660931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot final AUC-ROC","metadata":{}},{"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y, probabilities_valid)\nplot_roc_curve(fpr, tpr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:36:43.32464Z","iopub.execute_input":"2021-10-04T21:36:43.325053Z","iopub.status.idle":"2021-10-04T21:36:43.815377Z","shell.execute_reply.started":"2021-10-04T21:36:43.325018Z","shell.execute_reply":"2021-10-04T21:36:43.814673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.figure_factory as ff\nfig = ff.create_distplot([probabilities_valid], ['LogisticRegression'], bin_size=0.1, show_hist=False, show_rug=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:57:15.668537Z","iopub.execute_input":"2021-10-04T21:57:15.66923Z","iopub.status.idle":"2021-10-04T21:57:17.13436Z","shell.execute_reply.started":"2021-10-04T21:57:15.669186Z","shell.execute_reply":"2021-10-04T21:57:17.133661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Submit predictions","metadata":{}},{"cell_type":"markdown","source":"Save the probabilities of predictions to a CSV file","metadata":{}},{"cell_type":"code","source":"output = pd.DataFrame({'id': df_test.index,\n                        'claim': final_predicted_probabilities})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T21:12:11.535926Z","iopub.status.idle":"2021-10-04T21:12:11.53653Z","shell.execute_reply.started":"2021-10-04T21:12:11.536306Z","shell.execute_reply":"2021-10-04T21:12:11.536329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### _If you find it useful please upvote_\n### _Thank you!_","metadata":{}}]}