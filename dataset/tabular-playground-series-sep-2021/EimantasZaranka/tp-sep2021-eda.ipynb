{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Playground Series - Sep 2021\n\n## Dataset\n\nThe dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting whether a claim will be made on an insurance policy. Although the features are anonymized, they have properties relating to real-world features.\n\n## Data Description\n\nFor this competition, you will predict whether a customer made a claim upon an insurance policy. The ground truth claim is binary valued, but a prediction may be any number from 0.0 to 1.0, representing the probability of a claim. The features in this dataset have been anonymized and may contain missing values.\n\n## Evaluation\n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-03T14:21:37.244849Z","iopub.execute_input":"2021-09-03T14:21:37.245258Z","iopub.status.idle":"2021-09-03T14:21:37.257055Z","shell.execute_reply.started":"2021-09-03T14:21:37.245222Z","shell.execute_reply":"2021-09-03T14:21:37.255854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n\nsns.set(rc={f'figure.figsize':(12,10)})","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:21:39.405042Z","iopub.execute_input":"2021-09-03T14:21:39.405502Z","iopub.status.idle":"2021-09-03T14:21:40.537836Z","shell.execute_reply.started":"2021-09-03T14:21:39.405456Z","shell.execute_reply":"2021-09-03T14:21:40.53666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:21:41.707896Z","iopub.execute_input":"2021-09-03T14:21:41.708328Z","iopub.status.idle":"2021-09-03T14:21:41.714823Z","shell.execute_reply.started":"2021-09-03T14:21:41.708292Z","shell.execute_reply":"2021-09-03T14:21:41.713023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_filepath = '/kaggle/input/tabular-playground-series-sep-2021/train.csv'\ntest_filepath = '/kaggle/input/tabular-playground-series-sep-2021/test.csv'","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:21:42.057006Z","iopub.execute_input":"2021-09-03T14:21:42.057472Z","iopub.status.idle":"2021-09-03T14:21:42.063118Z","shell.execute_reply.started":"2021-09-03T14:21:42.057433Z","shell.execute_reply":"2021-09-03T14:21:42.061672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(train_filepath)\ntest_df = pd.read_csv(test_filepath)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:21:43.845863Z","iopub.execute_input":"2021-09-03T14:21:43.846486Z","iopub.status.idle":"2021-09-03T14:22:32.673825Z","shell.execute_reply.started":"2021-09-03T14:21:43.846448Z","shell.execute_reply":"2021-09-03T14:22:32.672087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = [col for col in train_df.columns if col not in ['id', 'claim']]","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:32.67693Z","iopub.execute_input":"2021-09-03T14:22:32.677411Z","iopub.status.idle":"2021-09-03T14:22:32.683355Z","shell.execute_reply.started":"2021-09-03T14:22:32.67736Z","shell.execute_reply":"2021-09-03T14:22:32.682352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explanatory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## First insights","metadata":{}},{"cell_type":"code","source":"full_dataset_size = train_df.shape[0] + test_df.shape[0]\nprint(f'Total size of both datasets: {full_dataset_size}')\nprint(f'Train data contains {train_df.shape[0]} rows ({round(train_df.shape[0]/full_dataset_size*100)}% of all data) and {train_df.shape[1]} columns')\nprint(f'Test data contains {test_df.shape[0]} rows ({round(test_df.shape[0]/full_dataset_size*100)}% of all data) and {test_df.shape[1]} columns')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:32.685488Z","iopub.execute_input":"2021-09-03T14:22:32.6861Z","iopub.status.idle":"2021-09-03T14:22:32.702287Z","shell.execute_reply.started":"2021-09-03T14:22:32.686055Z","shell.execute_reply":"2021-09-03T14:22:32.70124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd. set_option(\"display.max_columns\", None)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:32.703837Z","iopub.execute_input":"2021-09-03T14:22:32.704123Z","iopub.status.idle":"2021-09-03T14:22:32.715091Z","shell.execute_reply.started":"2021-09-03T14:22:32.704088Z","shell.execute_reply":"2021-09-03T14:22:32.714194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:32.716271Z","iopub.execute_input":"2021-09-03T14:22:32.716566Z","iopub.status.idle":"2021-09-03T14:22:32.867022Z","shell.execute_reply.started":"2021-09-03T14:22:32.716539Z","shell.execute_reply":"2021-09-03T14:22:32.865785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:32.868302Z","iopub.execute_input":"2021-09-03T14:22:32.868582Z","iopub.status.idle":"2021-09-03T14:22:33.003626Z","shell.execute_reply.started":"2021-09-03T14:22:32.868553Z","shell.execute_reply":"2021-09-03T14:22:33.00269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Total missing values in training set is {sum(train_df.isna().sum())}')\nprint(f'Total missing values in testing set is {sum(test_df.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:33.0051Z","iopub.execute_input":"2021-09-03T14:22:33.005661Z","iopub.status.idle":"2021-09-03T14:22:33.358946Z","shell.execute_reply.started":"2021-09-03T14:22:33.005624Z","shell.execute_reply":"2021-09-03T14:22:33.358222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:33.360799Z","iopub.execute_input":"2021-09-03T14:22:33.361302Z","iopub.status.idle":"2021-09-03T14:22:38.47793Z","shell.execute_reply.started":"2021-09-03T14:22:33.361257Z","shell.execute_reply":"2021-09-03T14:22:38.476816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:38.479487Z","iopub.execute_input":"2021-09-03T14:22:38.479917Z","iopub.status.idle":"2021-09-03T14:22:41.277312Z","shell.execute_reply.started":"2021-09-03T14:22:38.47987Z","shell.execute_reply":"2021-09-03T14:22:41.27654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['claim'].isna().value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:41.278412Z","iopub.execute_input":"2021-09-03T14:22:41.278836Z","iopub.status.idle":"2021-09-03T14:22:41.298933Z","shell.execute_reply.started":"2021-09-03T14:22:41.278803Z","shell.execute_reply":"2021-09-03T14:22:41.298075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outliers","metadata":{}},{"cell_type":"code","source":"'''\nGot inspiration from:\n1. https://www.kaggle.com/harshsharma511/titanic-eda-visualization-top-ensemble-models\n2. https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/\n'''\n\ndef outliers_itq_method(data, n, columns):\n    outlier_indices = []\n    \n    for col in columns:\n        q25, q75 = np.percentile(data[col], 25), np.percentile(data[col], 75)\n        iqr = q75 - q25\n        \n        cut_off = iqr * 1.5\n        lower, upper = q25 - cut_off, q75 + cut_off\n        \n        outliers = data[(data[col] < lower) | (data[col] > upper)].index\n        \n        outlier_indices.extend(outliers)\n        \n    outlier_indices = Counter(outlier_indices)\n    \n    final_outliers = list(k for k, v in outlier_indices.items() if v > n)\n    \n    return final_outliers","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:41.3003Z","iopub.execute_input":"2021-09-03T14:22:41.30085Z","iopub.status.idle":"2021-09-03T14:22:41.308282Z","shell.execute_reply.started":"2021-09-03T14:22:41.300817Z","shell.execute_reply":"2021-09-03T14:22:41.307525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_outliers = outliers_itq_method(train_df, 2, columns)\nprint(f'outliers found: {len(train_df_outliers)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:41.310252Z","iopub.execute_input":"2021-09-03T14:22:41.310655Z","iopub.status.idle":"2021-09-03T14:22:45.118329Z","shell.execute_reply.started":"2021-09-03T14:22:41.310623Z","shell.execute_reply":"2021-09-03T14:22:45.117538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Observations\n\n1. All features are of continues values in both datasets;\n2. Both datasets have 118 features and both contains id column. For this I will need to remove id column from train dataset and save id column from test dataset for later submissions;\n3. Total rows in both columns are over 1.4M with 957k in training data and 493k in test data;\n4. We have 1.8M missing values in training dataset and 936k missing values in testing dataset, will need to first, check how many columns have missing values in each row, then set a threshold and remove rows which exeeds the threshhold, lastyle prepare a pipeline for imputing values on remaining columns;\n5. Our target column is named claim;\n6. Some columns contains data which is small, some that is in thousands, will need to scale it. This applies to both datasets;\n7. Target columns has no missing values (which is nice);\n8. Using IQR outliers detection technique found no outliers;\n\n","metadata":{}},{"cell_type":"markdown","source":"## Dropping id columns","metadata":{}},{"cell_type":"code","source":"# saving testing data ids\nids = test_df['id'].copy()\n\n# dropping id columns\ntrain_df.drop('id', axis=1, inplace=True)\ntest_df.drop('id', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:45.119575Z","iopub.execute_input":"2021-09-03T14:22:45.119891Z","iopub.status.idle":"2021-09-03T14:22:45.591646Z","shell.execute_reply.started":"2021-09-03T14:22:45.119861Z","shell.execute_reply":"2021-09-03T14:22:45.590578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualisation","metadata":{}},{"cell_type":"markdown","source":"## 1. Claims count","metadata":{}},{"cell_type":"code","source":"sns.barplot(x=train_df['claim'].value_counts(), y=train_df['claim'], ci=False, orient='h')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:45.593115Z","iopub.execute_input":"2021-09-03T14:22:45.593517Z","iopub.status.idle":"2021-09-03T14:22:45.894923Z","shell.execute_reply.started":"2021-09-03T14:22:45.593477Z","shell.execute_reply":"2021-09-03T14:22:45.89384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations\nCan see that claims distribution is balanced meaning both approved and denied claims have similar entries, which approved claimes having very small advantage","metadata":{}},{"cell_type":"markdown","source":"## 2. Correlations","metadata":{}},{"cell_type":"code","source":"train_corr = train_df.corr()\n\nmask = np.triu(np.ones_like(train_corr, dtype=bool))\n\nsns.heatmap(train_corr, mask=mask, center=0, square=True, cbar_kws={'shrink':.5})","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:22:51.284261Z","iopub.execute_input":"2021-09-03T14:22:51.284709Z","iopub.status.idle":"2021-09-03T14:23:30.040552Z","shell.execute_reply.started":"2021-09-03T14:22:51.284671Z","shell.execute_reply":"2021-09-03T14:23:30.039691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations\n\nMajority of correlation is between -.01 and .01.","metadata":{}},{"cell_type":"markdown","source":"## 3. Distributions of features","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(59,2,figsize=(24,200))\n\nfor i, col in enumerate(columns):\n    sns.histplot(train_df[col].values, kde=True, ax=axis[(i // 2),(i % 2)]).set(title=str(i+1))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:23:30.04208Z","iopub.execute_input":"2021-09-03T14:23:30.042425Z","iopub.status.idle":"2021-09-03T14:35:53.719062Z","shell.execute_reply.started":"2021-09-03T14:23:30.042389Z","shell.execute_reply":"2021-09-03T14:35:53.717823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations\n\nMajority of features are skewed, so I will probobly will try log transformation before further scaling.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}