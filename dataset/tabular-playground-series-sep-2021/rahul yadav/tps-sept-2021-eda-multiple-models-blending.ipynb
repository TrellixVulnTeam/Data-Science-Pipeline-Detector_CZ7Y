{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<b>Problem Statement:</b> Calculating claim probability on an insurance policy.\n\n<b>Problem type:</b> A binary classification problem\n\n<b>Evaluation matrix:</b> Submissions are evaluated on area under the <b>ROC(receiver operating characteristic)</b> curve between the predicted probability and the observed target.","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Approach\">Approach to the problem</h2>\nIdea is to develop a generalized approach for solving any binary classification problem\n<ol>\n    <li>Performing exploratory data analysis.</li>\n    <ol>\n        <li><a href=\"#Target\">Understanding Target feature distribution</a></li>\n        <li><a href=\"#Corr\">Correlation check</a></li>\n        <li><a href=\"#TrainVisual\">Visualizing Training dataset</a></li>\n        <li><a href=\"#FeatureSummary\">Understanding Training dataset features</a></li>\n    </ol>\n    <li><a href=\"#FeatureEng\">Feature Engineering.</a></li> \n     <li>Data Preparation.</li>\n    <ol>\n        <li><a href=\"#MissingValues\">Handling missing values</a></li>\n    </ol>\n    <li>Training Linear and Gradient Boost Base models.</li>\n    <ol>\n        <li><a href=\"#LogisticRegression\">Logistic Regression</a></li>\n        <li><a href=\"#CatBoost\">CatBoost Classification</a></li>\n        <li><a href=\"#LGBM\">LGBM Classification</a></li>\n        <li><a href=\"#XGB\">XGBoost Classification</a></li>\n    </ol>\n    <li>Basic Blending.</li>\n    <ol>\n        <li><a href=\"#Ratios\">Calculating best blending Ratios (using training preditions to calculate blending ratios)</a></li>\n        <li><a href=\"#FinalPred\">Calculating blended prediction</a></li>\n    </ol>\n</ol>","metadata":{"execution":{"iopub.status.busy":"2021-09-05T14:25:32.600282Z","iopub.execute_input":"2021-09-05T14:25:32.600729Z","iopub.status.idle":"2021-09-05T14:25:32.614038Z","shell.execute_reply.started":"2021-09-05T14:25:32.600636Z","shell.execute_reply":"2021-09-05T14:25:32.612748Z"}}},{"cell_type":"markdown","source":"<h2>Required Libraries</h2>","metadata":{}},{"cell_type":"code","source":"#REQUIRED LIBRARIES\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier\n# from sklearn.model_selection import GridSearchCV\nfrom sklearn.decomposition import PCA\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score,accuracy_score\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.cluster import KMeans\n# import pickle\n# from sklearn.externals import joblib\n\n# import pandas_profiling as pp\n\nwarnings.filterwarnings('ignore')\ngc.enable()\n%matplotlib inline","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-15T10:44:28.55729Z","iopub.execute_input":"2021-09-15T10:44:28.557848Z","iopub.status.idle":"2021-09-15T10:44:31.299034Z","shell.execute_reply.started":"2021-09-15T10:44:28.557759Z","shell.execute_reply":"2021-09-15T10:44:31.297979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Available Files</h2>\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"#CHECKING ALL AVAILABLE FILES\npath='/kaggle/input/tabular-playground-series-sep-2021/'\ndata_files=list(os.listdir(path))\ndf_files=pd.DataFrame(data_files,columns=['file_name'])\ndf_files['size_in_mb']=df_files.file_name.apply(lambda x: round(os.path.getsize(path+x)/(1024*1024),2))\ndf_files['type']=df_files.file_name.apply(lambda x:'file' if os.path.isfile(path+x) else 'directory')\ndf_files['file_count']=df_files[['file_name','type']].apply(lambda x: 0 if x['type']=='file' else len(os.listdir(path+x['file_name'])),axis=1)\n\nprint('Following files are available under path:',path)\ndisplay(df_files)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-15T10:46:58.717538Z","iopub.execute_input":"2021-09-15T10:46:58.717902Z","iopub.status.idle":"2021-09-15T10:46:58.761538Z","shell.execute_reply.started":"2021-09-15T10:46:58.71787Z","shell.execute_reply":"2021-09-15T10:46:58.760799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>All Custom Functions for this Notebook</h2>\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"#ALL CUSTOM FUNCTIONS\n\n#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['null','unique_count','data_type','max/min','mean','median','mode','std','skewness','sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['unique_count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'max/min']=str(round(df_fa[col].max(),2))+'/'+str(round(df_fa[col].min(),2))\n            df.at[col,'mean']=round(df_fa[col].mean(),4)\n            df.at[col,'median']=round(df_fa[col].median(),4)\n            df.at[col,'mode']=round(df_fa[col].mode()[0],4)\n            df.at[col,'std']=round(df_fa[col].std(),4)\n            df.at[col,'skewness']=round(df_fa[col].skew(),4)\n        elif 'datetime64[ns]' in str(df_fa[col].dtype):\n            df.at[col,'max/min']=str(df_fa[col].max())+'/'+str(df_fa[col].min())\n        df.at[col,'sample_values']=list(df_fa[col].unique())\n    display(df_fa.head())      \n    return(df.fillna('-'))\n\n#PREDICTION FUNCTIONS\n\ndef claim_predictor(X,y,test,model,model_name):  \n\n    df_preds=pd.DataFrame()\n    df_preds_x=pd.DataFrame()\n    k=1\n    splits=5\n    avg_score=0\n\n    #CREATING STRATIFIED FOLDS\n    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\n    print('\\nStarting KFold iterations...')\n    for train_index,test_index in skf.split(X,y):\n        df_X=X[train_index,:]\n        df_y=y[train_index]\n        val_X=X[test_index,:]\n        val_y=y[test_index]\n       \n\n    #FITTING MODEL\n        model.fit(df_X,df_y)\n\n    #PREDICTING ON VALIDATION DATA\n        col_name=model_name+'xpreds_'+str(k)\n        preds_x=pd.Series(model.predict_proba(val_X)[:,1])\n        df_preds_x[col_name]=pd.Series(model.predict_proba(X)[:,1])\n\n    #CALCULATING ACCURACY\n        acc=roc_auc_score(val_y,preds_x)\n        print('Iteration:',k,'  roc_auc_score:',acc)\n        if k==1:\n            score=acc\n            best_model=model\n            preds=pd.Series(model.predict_proba(test)[:,1])\n            col_name=model_name+'preds_'+str(k)\n            df_preds[col_name]=preds\n        else:\n            preds1=pd.Series(model.predict_proba(test)[:,1])\n            preds=preds+preds1\n            col_name=model_name+'preds_'+str(k)\n            df_preds[col_name]=preds1\n            if score<acc:\n                score=acc\n                best_model=model\n        avg_score=avg_score+acc        \n        k=k+1\n    print('\\n Best score:',score,' Avg Score:',avg_score/splits)\n    #TAKING AVERAGE OF PREDICTIONS\n    preds=preds/splits\n    \n    print('Saving test and train predictions per iteration...')\n    df_preds.to_csv(model_name+'.csv',index=False)\n    df_preds_x.to_csv(model_name+'_.csv',index=False)\n    x_preds=df_preds_x.mean(axis=1)\n    return preds,best_model,x_preds \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-15T10:52:08.525396Z","iopub.execute_input":"2021-09-15T10:52:08.525876Z","iopub.status.idle":"2021-09-15T10:52:08.549945Z","shell.execute_reply.started":"2021-09-15T10:52:08.525845Z","shell.execute_reply":"2021-09-15T10:52:08.548733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#READING DATASET\n\ndf_train=pd.read_csv(path+'train.csv')\ndf_test=pd.read_csv(path+'test.csv')\ndf_submission=pd.read_csv(path+'sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:52:16.083891Z","iopub.execute_input":"2021-09-15T10:52:16.084261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Exploratory Data Analysis</h2>","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Target\">Understanding Target feature distribution</h2>\nLets visualize Target feature.\n\n<h4>Observation</h4>\nAs observations have almost equal count of claim and no claim observations, this is a Balanced dataset. \n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"#Understanding Target (claim) feature distribution\npie_labels=['Claim-'+str(df_train['claim'][df_train.claim==1].count()),'No Claim-'+\n            str(df_train['claim'][df_train.claim==0].count())]\npie_share=[df_train['claim'][df_train.claim==1].count()/df_train['claim'].count(),\n           df_train['claim'][df_train.claim==0].count()/df_train['claim'].count()]\nfigureObject, axesObject = plt.subplots(figsize=(6,6))\npie_colors=('orange','grey')\npie_explode=(.01,.01)\naxesObject.pie(pie_share,labels=pie_labels,explode=pie_explode,autopct='%.2f%%',colors=pie_colors,startangle=30,shadow=True)\naxesObject.axis('equal')\nplt.title('Percentage of Claim - No Claim Observations',color='blue',fontsize=12)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-14T04:26:21.896318Z","iopub.execute_input":"2021-09-14T04:26:21.896813Z","iopub.status.idle":"2021-09-14T04:26:22.150452Z","shell.execute_reply.started":"2021-09-14T04:26:21.896772Z","shell.execute_reply":"2021-09-14T04:26:22.149561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"Corr\">Correlation Check</h2>\nLets check if there are any correlated features. If two features are highly correlated we can remove one of the feature.\nThis will help in dimentionality reduction.\n\n<h4>Observation</h4>\nNo correlation is observed among Training dataset features.\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"#Correlation check\ncorr = df_train.iloc[:,1:].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Plotting correlation heatmap\nplt.subplots(figsize=(22,20))\nsns.heatmap(corr,mask=mask,xticklabels=corr.columns,yticklabels=corr.columns)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-12T19:31:02.441325Z","iopub.execute_input":"2021-09-12T19:31:02.441618Z","iopub.status.idle":"2021-09-12T19:31:43.621946Z","shell.execute_reply.started":"2021-09-12T19:31:02.441587Z","shell.execute_reply":"2021-09-12T19:31:43.620956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"TrainVisual\">Visualizating Training dataset</h2>\nWe are making use of PCA, dimentionality reduction technique to Visualize Training dataset.<br>\nVisualization is also helpful in understanding any grouping or patterns within dataset.\n<h4>Observation</h4>\nNo pattern or grouping observed in training dataset\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\nX=df_train.drop(['id','claim'],axis=1)\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n\nX_= imputer.fit_transform(X)\npca = PCA(n_components=3)\nprincipalComponents = pca.fit_transform(X_)\nprincipalDf = pd.DataFrame(data = principalComponents,columns = ['principal_component_1','principal_component_2','principal_component_3'])\nprincipalDf['claim']=df_train['claim']\n\nfig = plt.figure(figsize=(15,15))\nax = fig.add_subplot(111, projection = '3d')\n\nax.set_xlabel(\"principal_component_1\")\nax.set_ylabel(\"principal_component_2\")\nax.set_zlabel(\"principal_component_3\")\n\nsc=ax.scatter(xs=principalDf['principal_component_1'], ys=principalDf['principal_component_2'],\n              zs=principalDf['principal_component_3'],c=principalDf['claim'],cmap='OrRd')\nplt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-12T19:31:43.623247Z","iopub.execute_input":"2021-09-12T19:31:43.623553Z","iopub.status.idle":"2021-09-12T19:32:15.229866Z","shell.execute_reply.started":"2021-09-12T19:31:43.623524Z","shell.execute_reply":"2021-09-12T19:32:15.228544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:37.991427Z","iopub.execute_input":"2021-09-14T17:00:37.991881Z","iopub.status.idle":"2021-09-14T17:00:38.197665Z","shell.execute_reply.started":"2021-09-14T17:00:37.991844Z","shell.execute_reply":"2021-09-14T17:00:38.196783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X,X_\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T19:32:15.716631Z","iopub.execute_input":"2021-09-12T19:32:15.717154Z","iopub.status.idle":"2021-09-12T19:32:16.13573Z","shell.execute_reply.started":"2021-09-12T19:32:15.717109Z","shell.execute_reply":"2021-09-12T19:32:16.134609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"FeatureSummary\">Understanding Training dataset features</h2>\nUserstanding Training dataset features using basic statistical measures\n\n<h4>Observations</h4>\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', len(df_train.columns))\nfeature_summary(df_train)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-12T19:32:16.139139Z","iopub.execute_input":"2021-09-12T19:32:16.13957Z","iopub.status.idle":"2021-09-12T19:32:36.952646Z","shell.execute_reply.started":"2021-09-12T19:32:16.139526Z","shell.execute_reply":"2021-09-12T19:32:36.951623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_summary(df_submission)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T19:32:36.95432Z","iopub.execute_input":"2021-09-12T19:32:36.954594Z","iopub.status.idle":"2021-09-12T19:32:37.282545Z","shell.execute_reply.started":"2021-09-12T19:32:36.954567Z","shell.execute_reply":"2021-09-12T19:32:37.281544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:02:08.220953Z","iopub.execute_input":"2021-09-14T17:02:08.221432Z","iopub.status.idle":"2021-09-14T17:02:08.414007Z","shell.execute_reply.started":"2021-09-14T17:02:08.221396Z","shell.execute_reply":"2021-09-14T17:02:08.41318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"FeatureEng\">Feature Engineering</h2>\nCreating features using given features.\n\n<h4>Observations</h4>\nMissing value count per observation proved to be a very strong engineered feature for both linear and gradiant boost models\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\nfeatures=list(df_test.columns[1:])\n\ndf_train['n_missing'] = df_train[features].isna().sum(axis=1)\ndf_test['n_missing'] = df_test[features].isna().sum(axis=1)\n\ndf_train['std'] = df_train[features].std(axis=1)\ndf_test['std'] = df_test[features].std(axis=1)\n\ndf_train['mean'] = df_train[features].mean(axis=1)\ndf_test['mean'] = df_test[features].mean(axis=1)\n\ndf_train['max'] = df_train[features].max(axis=1)\ndf_test['max'] = df_test[features].max(axis=1)\n\ndf_train['min'] = df_train[features].min(axis=1)\ndf_test['min'] = df_test[features].min(axis=1)\n\ndf_train['kurt'] = df_train[features].kurtosis(axis=1)\ndf_test['kurt'] = df_test[features].kurtosis(axis=1)\n\nfeatures += ['n_missing', 'std','mean','max','min','kurt']","metadata":{"execution":{"iopub.status.busy":"2021-09-15T08:15:10.021026Z","iopub.execute_input":"2021-09-15T08:15:10.021418Z","iopub.status.idle":"2021-09-15T08:15:24.042457Z","shell.execute_reply.started":"2021-09-15T08:15:10.021386Z","shell.execute_reply":"2021-09-15T08:15:24.041377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"MissingValues\">Handling missing values</h2>\nThere are number of missing values in this dataset. We are replacing missing values for a feature with its mean.\n\n<h4>Observations</h4>\n\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\ndf_train[features] = df_train[features].fillna(df_train[features].mean())\ndf_test[features] = df_test[features].fillna(df_test[features].mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:12:21.584833Z","iopub.execute_input":"2021-09-14T17:12:21.585251Z","iopub.status.idle":"2021-09-14T17:12:27.394393Z","shell.execute_reply.started":"2021-09-14T17:12:21.585217Z","shell.execute_reply":"2021-09-14T17:12:27.39321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nscaler = StandardScaler()\ndf_train[features] = scaler.fit_transform(df_train[features])\ndf_test[features] = scaler.transform(df_test[features])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:12:32.620724Z","iopub.execute_input":"2021-09-14T17:12:32.621138Z","iopub.status.idle":"2021-09-14T17:13:34.125258Z","shell.execute_reply.started":"2021-09-14T17:12:32.621104Z","shell.execute_reply":"2021-09-14T17:13:34.123934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n","metadata":{}},{"cell_type":"code","source":"X=df_train.drop(['id','claim'],axis=1).to_numpy()\ny=df_train['claim'].values\ntest=df_test.drop(['id'],axis=1).to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:16:11.9948Z","iopub.execute_input":"2021-09-14T17:16:11.995252Z","iopub.status.idle":"2021-09-14T17:16:14.335971Z","shell.execute_reply.started":"2021-09-14T17:16:11.995217Z","shell.execute_reply":"2021-09-14T17:16:14.334733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_train,df_test,scaler\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:16:21.693646Z","iopub.execute_input":"2021-09-14T17:16:21.694036Z","iopub.status.idle":"2021-09-14T17:16:21.856132Z","shell.execute_reply.started":"2021-09-14T17:16:21.694002Z","shell.execute_reply":"2021-09-14T17:16:21.855362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape,y.shape,test.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:16:24.595775Z","iopub.execute_input":"2021-09-14T17:16:24.596347Z","iopub.status.idle":"2021-09-14T17:16:24.602935Z","shell.execute_reply.started":"2021-09-14T17:16:24.596298Z","shell.execute_reply":"2021-09-14T17:16:24.601689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"LogisticRegression\">LogisticRegression</h2>\nStarting with Basic Linear Model\n\n<h4>Observations</h4>\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\nmodel=LogisticRegression()\nprint('Logistic Regression parameters:\\n',model.get_params())\n\nlogistic_predictions,best_logistic_model,LRpreds=claim_predictor(X,y,test,model,'LR')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:16:29.777086Z","iopub.execute_input":"2021-09-14T17:16:29.777639Z","iopub.status.idle":"2021-09-14T17:17:33.349325Z","shell.execute_reply.started":"2021-09-14T17:16:29.777576Z","shell.execute_reply":"2021-09-14T17:17:33.347902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_predictions","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:17:56.58011Z","iopub.execute_input":"2021-09-14T17:17:56.580657Z","iopub.status.idle":"2021-09-14T17:17:56.589203Z","shell.execute_reply.started":"2021-09-14T17:17:56.580594Z","shell.execute_reply":"2021-09-14T17:17:56.588477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_feature_impt=pd.DataFrame()\ndf_feature_impt['features']=features\ndf_feature_impt['importance']=best_logistic_model.coef_[0]\n\ndf_feature_impt.sort_values(by=['importance'],inplace=True,ascending=False)\nplt.figure(figsize = (20,25))\nsns.barplot(x=df_feature_impt['importance'],y=df_feature_impt['features'],data=df_feature_impt);","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:18:09.203728Z","iopub.execute_input":"2021-09-14T17:18:09.204338Z","iopub.status.idle":"2021-09-14T17:18:11.544997Z","shell.execute_reply.started":"2021-09-14T17:18:09.204285Z","shell.execute_reply":"2021-09-14T17:18:11.543779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:18:46.97696Z","iopub.execute_input":"2021-09-14T17:18:46.977628Z","iopub.status.idle":"2021-09-14T17:18:47.195561Z","shell.execute_reply.started":"2021-09-14T17:18:46.977569Z","shell.execute_reply":"2021-09-14T17:18:47.194478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"CatBoost\">CatBoostClassifier</h2>\n\n<ul>\n    <li>We are using GPU for training this model</li>\n</ul>\n\n<h4>Hyperparameters picked up from below very informative notebook</h4>\nhttps://www.kaggle.com/mlanhenke/tps-09-simple-basic-stacking-lgbm-catb-xgb\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\ncatb_params = {\n    'eval_metric' : 'AUC',\n    'iterations': 15585, \n    'objective': 'CrossEntropy',\n    'bootstrap_type': 'Bernoulli', \n    'od_wait': 1144, \n    'learning_rate': 0.023575206684596582, \n    'reg_lambda': 36.30433203563295, \n    'random_strength': 43.75597655616195, \n    'depth': 7, \n    'min_data_in_leaf': 11, \n    'leaf_estimation_iterations': 1, \n    'subsample': 0.8227911142845009,\n   'task_type' : 'GPU',\n    'devices' : '0',\n    'verbose' : 0\n}\nmodel=CatBoostClassifier(**catb_params)\nprint('CatBoost paramters:\\n',model.get_params())\n\ncatb_predictions,best_catb_model,CBpreds=claim_predictor(X,y,test,model,'CB')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T06:28:32.30319Z","iopub.execute_input":"2021-09-13T06:28:32.30358Z","iopub.status.idle":"2021-09-13T06:59:36.943609Z","shell.execute_reply.started":"2021-09-13T06:28:32.303546Z","shell.execute_reply":"2021-09-13T06:59:36.94242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catb_predictions","metadata":{"execution":{"iopub.status.busy":"2021-09-13T03:12:19.680215Z","iopub.execute_input":"2021-09-13T03:12:19.680685Z","iopub.status.idle":"2021-09-13T03:12:19.690334Z","shell.execute_reply.started":"2021-09-13T03:12:19.68064Z","shell.execute_reply":"2021-09-13T03:12:19.689163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_feature_impt=pd.DataFrame()\ndf_feature_impt['features']=features\ndf_feature_impt['importance']=best_catb_model.feature_importances_\n\ndf_feature_impt.sort_values(by=['importance'],inplace=True,ascending=False)\nplt.figure(figsize = (10,25))\nsns.barplot(x=df_feature_impt['importance'],y=df_feature_impt['features'],data=df_feature_impt);","metadata":{"execution":{"iopub.status.busy":"2021-09-12T20:05:08.376089Z","iopub.execute_input":"2021-09-12T20:05:08.376427Z","iopub.status.idle":"2021-09-12T20:05:11.07685Z","shell.execute_reply.started":"2021-09-12T20:05:08.376398Z","shell.execute_reply":"2021-09-12T20:05:11.075637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T03:12:19.692541Z","iopub.execute_input":"2021-09-13T03:12:19.692963Z","iopub.status.idle":"2021-09-13T03:12:19.925642Z","shell.execute_reply.started":"2021-09-13T03:12:19.692917Z","shell.execute_reply":"2021-09-13T03:12:19.924215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"LGBM\">LGBMClassifier</h2>\n<ul>\n    <li>We are using GPU for training this model</li>\n</ul>\n    \n\n<h4>Hyperparameters picked up from below very informative notebook</h4>\nhttps://www.kaggle.com/mlanhenke/tps-09-simple-basic-stacking-lgbm-catb-xgb\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\nlgbm_params = {\n    'metric' : 'auc',\n    'objective' : 'binary',\n   'device_type': 'gpu', \n    'n_estimators': 10000, \n    'learning_rate': 0.12230165751633416, \n    'num_leaves': 1400, \n    'max_depth': 8, \n    'min_child_samples': 3100, \n    'reg_alpha': 10, \n    'reg_lambda': 65, \n    'min_split_gain': 5.157818977461183, \n    'subsample': 0.5, \n    'subsample_freq': 1, \n    'colsample_bytree': 0.2\n}\n\nmodel=lgb.LGBMClassifier(**lgbm_params)\nprint('LGBM parameters:\\n',model.get_params())\n\nlgb_predictions,best_lgb_model,LGBpreds=claim_predictor(X,y,test,model,'LGB')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T07:29:16.837895Z","iopub.execute_input":"2021-09-13T07:29:16.838328Z","iopub.status.idle":"2021-09-13T07:29:16.899666Z","shell.execute_reply.started":"2021-09-13T07:29:16.838238Z","shell.execute_reply":"2021-09-13T07:29:16.898091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_predictions","metadata":{"execution":{"iopub.status.busy":"2021-09-13T03:16:06.411737Z","iopub.execute_input":"2021-09-13T03:16:06.412029Z","iopub.status.idle":"2021-09-13T03:16:06.421806Z","shell.execute_reply.started":"2021-09-13T03:16:06.412002Z","shell.execute_reply":"2021-09-13T03:16:06.42075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_feature_impt=pd.DataFrame()\ndf_feature_impt['features']=features\ndf_feature_impt['importance']=best_lgb_model.feature_importances_\n\ndf_feature_impt.sort_values(by=['importance'],inplace=True,ascending=False)\nplt.figure(figsize = (10,25))\nsns.barplot(x=df_feature_impt['importance'],y=df_feature_impt['features'],data=df_feature_impt);","metadata":{"execution":{"iopub.status.busy":"2021-09-12T20:08:58.399141Z","iopub.execute_input":"2021-09-12T20:08:58.39943Z","iopub.status.idle":"2021-09-12T20:09:00.427507Z","shell.execute_reply.started":"2021-09-12T20:08:58.399401Z","shell.execute_reply":"2021-09-12T20:09:00.426417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"XGB\">XGBClassifier</h2>\n\n<ul>\n    <li>We are using GPU for training this model</li>\n</ul>\n\n<h4>Hyperparameters picked up from below very informative notebook</h4>\nhttps://www.kaggle.com/mlanhenke/tps-09-simple-basic-stacking-lgbm-catb-xgb\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\nxgb_params = {\n    'eval_metric': 'auc', \n    'objective': 'binary:logistic', \n   'tree_method': 'gpu_hist', \n   'gpu_id': 0, \n   'predictor': 'gpu_predictor', \n    'n_estimators': 10000, \n    'learning_rate': 0.01063045229441343, \n    'gamma': 0.24652519525750877, \n    'max_depth': 4, \n    'min_child_weight': 366, \n    'subsample': 0.6423040816299684, \n    'colsample_bytree': 0.7751264493218339, \n    'colsample_bylevel': 0.8675692743597421, \n    'lambda': 0, \n    'alpha': 10\n}\nmodel=xgb.XGBClassifier(**xgb_params)\nprint('XGB parameters:\\n',model.get_params())\n\nxgb_predictions,best_xgb_model,XGBpreds=claim_predictor(X,y,test,model,'XGB')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_predictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_feature_impt=pd.DataFrame()\ndf_feature_impt['features']=features\ndf_feature_impt['importance']=best_xgb_model.feature_importances_\n\ndf_feature_impt.sort_values(by=['importance'],inplace=True,ascending=False)\nplt.figure(figsize = (10,25))\nsns.barplot(x=df_feature_impt['importance'],y=df_feature_impt['features'],data=df_feature_impt);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Blending</h2>","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Ratios\">Calculating best blending Ratios (using training preditions to calculate blending ratios)</h2>\nWe are trying to calculate best blending ratio on trained dataset and then applying the same to predicted test values\n\n<h4>Observation</h4>\n<ul>\n    <li>This approach lead to selecting ratio 1.0 for best model and 0.0 for others.</li>\n    <li>If we observe results by above three models, we can conclude different models are working better than other on different part of dataset.Now how can we bring this to our blending strategy?</li>\n    <li>As changed blending strategy, we will try to find best blending ratio with each ratio greater than zero</li>\n</ul>\n\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"%%time\n# blending_ratios=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\nblending_ratios=[0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0]\nroc_final=0\nLR_ratio=0\nLGB_ratio=0\nCB_ratio=0\nXGG_ratio=0\nfor i in blending_ratios:\n    for j in blending_ratios:\n        for k in blending_ratios:\n            for l in blending_ratios:\n                if((i+j+k+l==1) and (i>0 and j>0 and k>0 and l>0)):\n                    roc_new=roc_auc_score(y,(LRpreds*i+LGBpreds*j+CBpreds*k+XGBpreds*l))\n                    print(\"LRratio: \",i,\" LGBratio: \",j,\" CBratio:\",k,\" XGBratio: \",l,\" ROCscore: \",roc_new)\n                    if roc_new>roc_final:\n                        roc_final=roc_new\n                        LR_ratio=i\n                        LGB_ratio=j\n                        CB_ratio=k\n                        XGB_ratio=l\nprint(\"Final Ratios, LR ratio: \",LR_ratio,\" LGB ratio: \",LGB_ratio,\" CB ratio:\",CB_ratio,\" XGB ratio: \",XGB_ratio,\" ROC score: \",roc_final)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T03:16:06.423262Z","iopub.execute_input":"2021-09-13T03:16:06.423585Z","iopub.status.idle":"2021-09-13T03:16:06.556414Z","shell.execute_reply.started":"2021-09-13T03:16:06.423553Z","shell.execute_reply":"2021-09-13T03:16:06.555362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"BlendPred\">Calculating blended prediction</h2>\n\n<br><a href=\"#Approach\">back to main menu</a>","metadata":{}},{"cell_type":"code","source":"df_submission['claim']=lgb_predictions*LGB_ratio+catb_predictions*CB_ratio+logistic_predictions*LR_ratio+xgb_predictions*XGB_ratio\n#CREATING SUMBISSION FILE\ndf_submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T03:16:06.557501Z","iopub.execute_input":"2021-09-13T03:16:06.557886Z","iopub.status.idle":"2021-09-13T03:16:07.265939Z","shell.execute_reply.started":"2021-09-13T03:16:06.557845Z","shell.execute_reply":"2021-09-13T03:16:07.264997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"execution":{"iopub.status.busy":"2021-09-12T20:09:02.312042Z","iopub.execute_input":"2021-09-12T20:09:02.312343Z","iopub.status.idle":"2021-09-12T20:09:02.32628Z","shell.execute_reply.started":"2021-09-12T20:09:02.312316Z","shell.execute_reply":"2021-09-12T20:09:02.325148Z"},"trusted":true},"execution_count":null,"outputs":[]}]}