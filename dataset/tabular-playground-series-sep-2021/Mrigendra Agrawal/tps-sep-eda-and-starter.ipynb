{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nsns.set_palette('Set2')\nsns.set_theme(style='darkgrid')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-02T20:52:11.391746Z","iopub.execute_input":"2021-09-02T20:52:11.392319Z","iopub.status.idle":"2021-09-02T20:52:14.242739Z","shell.execute_reply.started":"2021-09-02T20:52:11.392225Z","shell.execute_reply":"2021-09-02T20:52:14.241773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# About the Competition🚩\n<p style=\"font-size:15px\">Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, we've launched many Playground competitions that are more approachable than our Featured competitions and thus, more beginner-friendly.<br><br>\n\n\nThe goal of these competitions is to provide a fun, and approachable for anyone, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition. If you're an established competitions master or grandmaster, these probably won't be much of a challenge for you. We encourage you to avoid saturating the leaderboard.<br><br>\n\nFor this competition, you will predict whether a customer made a claim upon an insurance policy. The ground truth claim is binary valued, but a prediction may be any number from 0.0 to 1.0, representing the probability of a claim. The features in this dataset have been anonymized and may contain missing values.<br><br>\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 2.0em;\">\nThis month comptetion is a binary class classificaton in which we have to predict probiblities for   'claim' feature\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Data Description","metadata":{}},{"cell_type":"markdown","source":"<div style=\"font-size:15px\">\n We are given 3 csv files:-\n<ul>\n    <li><code>train.csv:</code> the training set</li>\n    <li><code>test.csv:</code> the test set</li>\n    <li><code>sample_submission.csv:</code> sample_submission file in submission format</li>\n</ul>    \n</div>","metadata":{}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"# Color Palette","metadata":{}},{"cell_type":"code","source":"sns.color_palette('Set2')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:52:14.244498Z","iopub.execute_input":"2021-09-02T20:52:14.24491Z","iopub.status.idle":"2021-09-02T20:52:14.251807Z","shell.execute_reply.started":"2021-09-02T20:52:14.244856Z","shell.execute_reply":"2021-09-02T20:52:14.251169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:52:14.253173Z","iopub.execute_input":"2021-09-02T20:52:14.253594Z","iopub.status.idle":"2021-09-02T20:52:53.651449Z","shell.execute_reply.started":"2021-09-02T20:52:14.253564Z","shell.execute_reply":"2021-09-02T20:52:53.650409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's see how train data looks like","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:52:53.653212Z","iopub.execute_input":"2021-09-02T20:52:53.653612Z","iopub.status.idle":"2021-09-02T20:52:53.693038Z","shell.execute_reply.started":"2021-09-02T20:52:53.653566Z","shell.execute_reply":"2021-09-02T20:52:53.692387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:52:53.694075Z","iopub.execute_input":"2021-09-02T20:52:53.694517Z","iopub.status.idle":"2021-09-02T20:52:53.713542Z","shell.execute_reply.started":"2021-09-02T20:52:53.694476Z","shell.execute_reply":"2021-09-02T20:52:53.71257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"basic train set statistics","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:52:53.714955Z","iopub.execute_input":"2021-09-02T20:52:53.715318Z","iopub.status.idle":"2021-09-02T20:52:58.658475Z","shell.execute_reply.started":"2021-09-02T20:52:53.715282Z","shell.execute_reply":"2021-09-02T20:52:58.657534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\" style=\"font-size:15px; font-family:verdana; line-height: 2.0em;\">\nOur train set is very diverse so scaling is necessary\n</div>","metadata":{}},{"cell_type":"markdown","source":"Let's check if missing values are present","metadata":{}},{"cell_type":"code","source":"def check_missing(df):\n    print(bool(df.isnull))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-02T20:52:58.659601Z","iopub.execute_input":"2021-09-02T20:52:58.659913Z","iopub.status.idle":"2021-09-02T20:52:58.664562Z","shell.execute_reply.started":"2021-09-02T20:52:58.659884Z","shell.execute_reply":"2021-09-02T20:52:58.663543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_missing(train)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:52:58.66665Z","iopub.execute_input":"2021-09-02T20:52:58.666915Z","iopub.status.idle":"2021-09-02T20:52:58.677392Z","shell.execute_reply.started":"2021-09-02T20:52:58.666889Z","shell.execute_reply":"2021-09-02T20:52:58.676447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"missing values are present we will need to deal with them before modeling","metadata":{}},{"cell_type":"code","source":"missing_values = pd.DataFrame(train.isna().sum())\nmissing_values.rename(columns={0:'missing_value'},inplace=True)\ndef train_missing_perecentage(idx):\n    return (idx/len(train))*100\nmissing_values['missing_value'] = missing_values.apply(train_missing_perecentage)\nfeatures = list(train.columns)\npercentage = []\nfor i in features:\n    percentage.append(float(missing_values.loc[str(i)]))\nmissing_values = pd.DataFrame({'Feature':features,'Percentage':percentage})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-02T20:52:58.68094Z","iopub.execute_input":"2021-09-02T20:52:58.681569Z","iopub.status.idle":"2021-09-02T20:52:58.92111Z","shell.execute_reply.started":"2021-09-02T20:52:58.681438Z","shell.execute_reply":"2021-09-02T20:52:58.920083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's look perecentage of missing value for each feature","metadata":{}},{"cell_type":"code","source":"px.scatter(data_frame=missing_values,x='Feature',y='Percentage',template='plotly_dark')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:52:58.922576Z","iopub.execute_input":"2021-09-02T20:52:58.922967Z","iopub.status.idle":"2021-09-02T20:53:00.04603Z","shell.execute_reply.started":"2021-09-02T20:52:58.922924Z","shell.execute_reply":"2021-09-02T20:53:00.045187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"it's safe to say around 1.6% of data is missing in every feature exception are Id and claim","metadata":{}},{"cell_type":"markdown","source":"Let's take a look at our target variable:- \"claim\"","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=train.claim,palette='Set2')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:00.047251Z","iopub.execute_input":"2021-09-02T20:53:00.04753Z","iopub.status.idle":"2021-09-02T20:53:00.263045Z","shell.execute_reply.started":"2021-09-02T20:53:00.047503Z","shell.execute_reply":"2021-09-02T20:53:00.262198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"target is evenly distributed so we can simply use K-Fold","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 2.0em;\">\nto quickly view detailed EDA on each features we can use pandas profiling\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install pandas-profiling\nfrom pandas_profiling import ProfileReport\nprof = ProfileReport(train,minimal=True) \nprof.to_file(output_file='train_output.html')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-02T20:53:00.26422Z","iopub.execute_input":"2021-09-02T20:53:00.264488Z","iopub.status.idle":"2021-09-02T20:53:17.925338Z","shell.execute_reply.started":"2021-09-02T20:53:00.264463Z","shell.execute_reply":"2021-09-02T20:53:17.923192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check how features correlate with each other","metadata":{}},{"cell_type":"code","source":"features = list(train.columns)\nfeatures.remove('id')\nfig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(train[features].corr(), annot=False, linewidths=.5, ax=ax,cmap=sns.color_palette('Set2',as_cmap=True))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:17.926409Z","iopub.status.idle":"2021-09-02T20:53:17.926803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 2.0em;\">\nUsually, we keep features that are highly correlated with our target variable and remove the reductant feature but in this case features are not highly correlated to each other\n</div>","metadata":{}},{"cell_type":"markdown","source":"Now let's check our test set","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:17.92775Z","iopub.status.idle":"2021-09-02T20:53:17.92813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:17.928935Z","iopub.status.idle":"2021-09-02T20:53:17.929328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:17.930021Z","iopub.status.idle":"2021-09-02T20:53:17.930396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check missing value in test set","metadata":{}},{"cell_type":"code","source":"check_missing(test)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:17.931211Z","iopub.status.idle":"2021-09-02T20:53:17.931616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = pd.DataFrame(test.isna().sum())\nmissing_values.rename(columns={0:'missing_value'},inplace=True)\ndef test_missing_perecentage(idx):\n    return (idx/len(test))*100\nmissing_values['missing_value'] = missing_values.apply(test_missing_perecentage)\nfeatures = list(test.columns)\npercentage = []\nfor i in features:\n    percentage.append(float(missing_values.loc[str(i)]))\nmissing_values = pd.DataFrame({'Feature':features,'Percentage':percentage})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-02T20:53:17.932465Z","iopub.status.idle":"2021-09-02T20:53:17.932822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's look at percentage of missing value in case of test set","metadata":{}},{"cell_type":"code","source":"px.scatter(data_frame=missing_values,x='Feature',y='Percentage',template='plotly_dark')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:17.933831Z","iopub.status.idle":"2021-09-02T20:53:17.934313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"it's safe to say around 1.6% of data is missing in every feature exception are Id","metadata":{}},{"cell_type":"markdown","source":"let's generate padnas profiling for test set","metadata":{}},{"cell_type":"code","source":"prof = ProfileReport(test,minimal=True) \nprof.to_file(output_file='test_output.html')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:53:17.935203Z","iopub.status.idle":"2021-09-02T20:53:17.935559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's see how different features correlate to each other in case of test set","metadata":{}},{"cell_type":"code","source":"features = list(test.columns)\nfeatures.remove('id')\nfig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(test[features].corr(), annot=False, linewidths=.5, ax=ax,cmap=sns.color_palette('Set2',as_cmap=True))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-02T20:53:17.936366Z","iopub.status.idle":"2021-09-02T20:53:17.936725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"Let's train a simple LightGBM Classifier and setup our Baseline for rest of the competition ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv',index_col='id')\ntest = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv',index_col='id')\nsample_submission = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')\nfeatures = list(train.columns)\nfeatures.remove('claim')\ntarget = ['claim']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-02T20:53:23.227151Z","iopub.execute_input":"2021-09-02T20:53:23.22749Z","iopub.status.idle":"2021-09-02T20:53:50.922192Z","shell.execute_reply.started":"2021-09-02T20:53:23.227461Z","shell.execute_reply":"2021-09-02T20:53:50.921247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"Hyperparameters are optimized using Optuna they can be further optimized by using better suggestions","metadata":{}},{"cell_type":"code","source":"params = {\n    'task': 'train',    \n    'objective': 'binary',\n    'verbose':-1,\n    'num_leaves': 111, \n    'learning_rate': 0.016206997849237542, \n    'n_estimators': 2641, \n    'min_child_samples': 22,\n}\nfolds = KFold(n_splits=5,shuffle=True,random_state=42)\nfor fold, (train_idx,valid_idx) in enumerate(folds.split(train)):\n    print(f'fold {fold} starting...')\n    fold_train = train.iloc[train_idx]\n    train_x = fold_train[features]\n    train_y = fold_train[target]\n    dtrain = lgb.Dataset(train_x,label=train_y)\n    \n    fold_valid = train.iloc[valid_idx]\n    valid_x = fold_valid[features]\n    valid_y = fold_valid[target]\n    dvalid = lgb.Dataset(valid_x,valid_y)\n    \n    model = lgb.train(params,train_set=dtrain, \n               valid_sets=dvalid,\n              early_stopping_rounds =200,\n                     verbose_eval=100)\n    oof = model.predict(valid_x)\n    score = roc_auc_score(valid_y,oof)\n    print(f\"Valid score for {fold} is: {score}\")\n    oof = pd.DataFrame({'id':valid_x.index,'claim':oof})\n    oof.to_csv(f'{fold}_oof.csv',index=False)\n    model.save_model(f'lightgbm_{fold}.txt')\n    print(f' fold {fold} completed')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T20:55:12.690791Z","iopub.execute_input":"2021-09-02T20:55:12.691155Z","iopub.status.idle":"2021-09-02T21:43:37.054035Z","shell.execute_reply.started":"2021-09-02T20:55:12.691098Z","shell.execute_reply":"2021-09-02T21:43:37.052211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"for fold in tqdm(range(5)):\n    model = lgb.Booster(model_file=f'./lightgbm_{fold}.txt')\n    preds = model.predict(test)\n    submission = sample_submission.copy()\n    submission['claim'] = preds\n    submission.to_csv(f'submission_{fold}.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:46:00.153916Z","iopub.execute_input":"2021-09-02T21:46:00.154287Z","iopub.status.idle":"2021-09-02T21:49:47.333495Z","shell.execute_reply.started":"2021-09-02T21:46:00.154254Z","shell.execute_reply":"2021-09-02T21:49:47.332464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blending","metadata":{}},{"cell_type":"code","source":"sub0 = pd.read_csv('./submission_0.csv')\nsub1 = pd.read_csv('./submission_1.csv')\nsub2 = pd.read_csv('./submission_2.csv')\nsub3 = pd.read_csv('./submission_3.csv')\nsub4 = pd.read_csv('./submission_4.csv')\ntarget = (sub0.claim + sub1.claim + sub2.claim + sub3.claim + sub4.claim)/5\nsub = sub0.copy()\nsub['claim'] = target\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:49:47.334781Z","iopub.execute_input":"2021-09-02T21:49:47.335033Z","iopub.status.idle":"2021-09-02T21:49:49.067121Z","shell.execute_reply.started":"2021-09-02T21:49:47.335005Z","shell.execute_reply":"2021-09-02T21:49:49.066207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"feature_importance =  model.feature_importance()\nfeature_importance = (feature_importance - feature_importance.min())/(feature_importance.max() - feature_importance.min())\nfeature_names = np.array(train_x.columns)\ndata={'feature_names':feature_names,'feature_importance':feature_importance}\ndf_plt = pd.DataFrame(data)\ndf_plt.sort_values(by=['feature_importance'], ascending=False,inplace=True)\nplt.figure(figsize=(20,40))\nsns.barplot(x=df_plt['feature_importance'], y=df_plt['feature_names'])\nplt.xlabel('FEATURE IMPORTANCE')\nplt.ylabel('FEATURE NAMES')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-02T21:49:49.068457Z","iopub.execute_input":"2021-09-02T21:49:49.068727Z","iopub.status.idle":"2021-09-02T21:49:50.677337Z","shell.execute_reply.started":"2021-09-02T21:49:49.0687Z","shell.execute_reply":"2021-09-02T21:49:50.676761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Possible Next Steps:-","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em;\">\n    📌Hyper Parameter Optimization<br>\n    📌Using Catboost, XGboost and maybe Neural Nets<br>\n    📌Feature Engineering<br>\n    📌Stacking<br>\n    📌Advanced Techniques like Psuedo Labelling, Gaussian optimization\n</div>","metadata":{}},{"cell_type":"markdown","source":"<h2><center>If you learned something new or forked the notebook then please don't forget to upvote<br>Thank You</center>\n</h2>","metadata":{}},{"cell_type":"markdown","source":"<h2><center>Work in Progress ... ⏳</center></h2>","metadata":{}}]}