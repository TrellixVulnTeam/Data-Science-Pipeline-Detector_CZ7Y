{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import roc_auc_score\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:37:28.78409Z","iopub.execute_input":"2021-09-30T18:37:28.784905Z","iopub.status.idle":"2021-09-30T18:37:31.932768Z","shell.execute_reply.started":"2021-09-30T18:37:28.784794Z","shell.execute_reply":"2021-09-30T18:37:31.931986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data and creating folds\n\nNo preprocessing is needed as we will be training out models on the out-of-fold predictions of our base models.","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nsample_solution = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')\n\ndf_train['kfold'] = -1\n\ny_train = df_train.claim\nX_train = df_train.drop('claim', axis=1)\n\nskf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (i_train, i_valid) in enumerate (skf.split(X_train, y_train)):\n    df_train.loc[i_valid, 'kfold'] = fold","metadata":{"execution":{"iopub.status.busy":"2021-09-30T20:50:04.793449Z","iopub.execute_input":"2021-09-30T20:50:04.793692Z","iopub.status.idle":"2021-09-30T20:50:32.207269Z","shell.execute_reply.started":"2021-09-30T20:50:04.793665Z","shell.execute_reply":"2021-09-30T20:50:32.20644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the out-of-fold and test predictions","metadata":{}},{"cell_type":"code","source":"m = 1\n\nfor i in range(20):\n    for s in range(5):\n        df_train_temp = pd.read_csv(f'../input/tps-09-2021-base-predictions/m{m}s{s}_valid_pred.csv')\n        df_test_temp = pd.read_csv(f'../input/tps-09-2021-base-predictions/m{m}s{s}_test_pred.csv')\n        df_train = df_train.merge(df_train_temp, on='id', how='left')\n        df_test = df_test.merge(df_test_temp, on='id', how='left')\n    preds_temp = [c for c in df_test.columns if f'm{m}' in c]\n    df_train[f'm{m}_mean_pred'] = df_train[preds_temp].mean(axis=1)\n    df_test[f'm{m}_mean_pred'] = df_test[preds_temp].mean(axis=1)\n    m += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-30T20:50:32.208918Z","iopub.execute_input":"2021-09-30T20:50:32.2092Z","iopub.status.idle":"2021-09-30T20:54:21.887349Z","shell.execute_reply.started":"2021-09-30T20:50:32.209154Z","shell.execute_reply":"2021-09-30T20:54:21.886379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tuning with Optuna","metadata":{}},{"cell_type":"code","source":"# seed = 0\n\n# features = [c for c in df_train.columns if 'mean' in c]\n# df_test = df_test[features]\n\n# def objective(trial):\n#     fold = 0\n#     params = {\n#         'num_leaves': trial.suggest_int('num_leaves', 2, 20),\n#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1000, 20000),\n#         'max_depth': trial.suggest_int('max_depth', 0, 4),\n#         'max_bin': trial.suggest_int('max_bin', 200, 400),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5),\n#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.00001, 50),\n#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.00001, 50),\n#         'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 4),\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.75, 0.9),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 1)        \n#     }\n\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        \n#     y_train = X_train.claim\n#     y_valid = X_valid.claim\n    \n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n    \n#     model = LGBMClassifier(\n#             objective='binary',\n#             tree_learner='serial',\n#             seed=seed,\n#             n_estimators=50000,\n#             **params)\n    \n#     model.fit(X_train,\n#               y_train,\n#               early_stopping_rounds=500,\n#               eval_set=[(X_valid, y_valid)],\n#               eval_metric='auc',\n#               callbacks=[LightGBMPruningCallback(trial, 'auc')],\n#               verbose=1000)\n    \n#     valid_pred = model.predict_proba(X_valid)[:,1]\n        \n#     auc = roc_auc_score(y_valid, valid_pred)\n#     return auc\n\n# for i in range(10):\n#     study = optuna.create_study(direction=\"maximize\")\n#     study.optimize(objective, n_trials=500)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training\n\nModel 1","metadata":{}},{"cell_type":"code","source":"features = [c for c in df_train.columns if 'mean' in c]\ndf_test = df_test[features]\n\ntest_preds = []\nvalid_preds = {}\nscores = []\n\nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n    \n    params = {'num_leaves': 16,\n              'min_data_in_leaf': 8056,\n              'max_depth': 0,\n              'max_bin': 355,\n              'learning_rate': 0.008529108246972048,\n              'lambda_l1': 9.855426024301865,\n              'lambda_l2': 3.584196138812915e-05,\n              'min_gain_to_split': 0.42289363518494794,\n              'feature_fraction': 0.42929842197137486,\n              'bagging_fraction': 0.8422719204115733,\n              'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=fold,\n        n_estimators=5000,\n        **params)\n    \n    model.fit(X_train,\n          y_train,\n          early_stopping_rounds=500,\n          eval_set=[(X_valid, y_valid)],\n          eval_metric='auc',\n          verbose=1000)\n    \n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n    \n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'pred_1']\nvalid_preds.to_csv(f'level1_valid_pred_1.csv', index=False)\n\nsample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.columns = ['id', f'pred_1']\nsample_solution.to_csv(f'level1_test_pred_1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:58:56.299787Z","iopub.execute_input":"2021-09-30T21:58:56.300226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nModel 2","metadata":{}},{"cell_type":"code","source":"test_preds = []\nvalid_preds = {}\nscores = []\n\nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n\n    params = {'num_leaves': 4,\n              'min_data_in_leaf': 11557,\n              'max_depth': 1,\n              'max_bin': 330,\n              'learning_rate': 0.009478273001225938,\n              'lambda_l1': 1.17273085019482e-05,\n              'lambda_l2': 1.1150847201215146,\n              'min_gain_to_split': 0.6849430970013546,\n              'feature_fraction': 0.17224803018739418,\n              'bagging_fraction': 0.8745864558511497,\n              'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=fold,\n        n_estimators=10000,\n        **params)\n    \n    model.fit(X_train,\n          y_train,\n          early_stopping_rounds=500,\n          eval_set=[(X_valid, y_valid)],\n          eval_metric='auc',\n          verbose=1000)\n    \n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n    \n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'pred_2']\nvalid_preds.to_csv(f'level1_valid_pred_2.csv', index=False)\n\nsample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.columns = ['id', f'pred_2']\nsample_solution.to_csv(f'level1_test_pred_2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:51:46.963299Z","iopub.execute_input":"2021-09-30T18:51:46.963546Z","iopub.status.idle":"2021-09-30T19:04:46.176791Z","shell.execute_reply.started":"2021-09-30T18:51:46.963517Z","shell.execute_reply":"2021-09-30T19:04:46.176012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model 3","metadata":{}},{"cell_type":"code","source":"test_preds = []\nvalid_preds = {}\nscores = []\n\nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n\n    params = {'num_leaves': 4,\n              'min_data_in_leaf': 1458,\n              'max_depth': 2,\n              'max_bin': 376,\n              'learning_rate': 0.006005480922506577,\n              'lambda_l1': 0.00021562065637690435,\n              'lambda_l2': 4.87408695501209,\n              'min_gain_to_split': 1.97067333984107,\n              'feature_fraction': 0.8666273347397625,\n              'bagging_fraction': 0.8743916816302966,\n              'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=fold,\n        n_estimators=10000,\n        **params)\n    \n    model.fit(X_train,\n          y_train,\n          early_stopping_rounds=500,\n          eval_set=[(X_valid, y_valid)],\n          eval_metric='auc',\n          verbose=1000)\n    \n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n    \n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'pred_3']\nvalid_preds.to_csv(f'level1_valid_pred_3.csv', index=False)\n\nsample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.columns = ['id', f'pred_3']\nsample_solution.to_csv(f'level1_test_pred_3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:04:46.178234Z","iopub.execute_input":"2021-09-30T19:04:46.17849Z","iopub.status.idle":"2021-09-30T19:19:19.980793Z","shell.execute_reply.started":"2021-09-30T19:04:46.178456Z","shell.execute_reply":"2021-09-30T19:19:19.980027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model 4","metadata":{}},{"cell_type":"code","source":"test_preds = []\nvalid_preds = {}\nscores = []\n\nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n    \n    params = {'num_leaves': 15,\n              'min_data_in_leaf': 6512,\n              'max_depth': 3,\n              'max_bin': 310,\n              'learning_rate': 0.004125972490699574,\n              'lambda_l1': 0.003690793308308078,\n              'lambda_l2': 0.3051576539377836,\n              'min_gain_to_split': 0.2990942549901452,\n              'feature_fraction': 0.918317541041119,\n              'bagging_fraction': 0.7574750171832634,'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=fold,\n        n_estimators=10000,\n        **params)\n    \n    model.fit(X_train,\n          y_train,\n          early_stopping_rounds=500,\n          eval_set=[(X_valid, y_valid)],\n          eval_metric='auc',\n          verbose=1000)\n    \n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n    \n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'pred_4']\nvalid_preds.to_csv(f'level1_valid_pred_4.csv', index=False)\n\nsample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.columns = ['id', f'pred_4']\nsample_solution.to_csv(f'level1_test_pred_4.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:19:19.983076Z","iopub.execute_input":"2021-09-30T19:19:19.983529Z","iopub.status.idle":"2021-09-30T19:38:46.697307Z","shell.execute_reply.started":"2021-09-30T19:19:19.983491Z","shell.execute_reply":"2021-09-30T19:38:46.696472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model 5","metadata":{}},{"cell_type":"code","source":"test_preds = []\nvalid_preds = {}\nscores = []\n\nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n\n    params = {'num_leaves': 20,\n              'min_data_in_leaf': 19960,\n              'max_depth': 4,\n              'max_bin': 331,\n              'learning_rate': 0.0019637756042711558,\n              'lambda_l1': 47.21817822491236,\n              'lambda_l2': 0.00045229975521610875,\n              'min_gain_to_split': 2.1533850359022284,\n              'feature_fraction': 0.10469850378121182,\n              'bagging_fraction': 0.8956146814653573,\n              'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=fold,\n        n_estimators=10000,\n        **params)\n    \n    model.fit(X_train,\n          y_train,\n          early_stopping_rounds=500,\n          eval_set=[(X_valid, y_valid)],\n          eval_metric='auc',\n          verbose=1000)\n    \n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n    \n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'pred_5']\nvalid_preds.to_csv(f'level1_valid_pred_5.csv', index=False)\n\nsample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.columns = ['id', f'pred_5']\nsample_solution.to_csv(f'level1_test_pred_5.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:38:46.698697Z","iopub.execute_input":"2021-09-30T19:38:46.698962Z","iopub.status.idle":"2021-09-30T19:51:33.696008Z","shell.execute_reply.started":"2021-09-30T19:38:46.69893Z","shell.execute_reply":"2021-09-30T19:51:33.695271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Re-loading the data and adding the meta-model predictions","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nsample_solution = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')\n\ndf_train['kfold'] = -1\n\ny_train = df_train.claim\nX_train = df_train.drop('claim', axis=1)\n\nskf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (i_train, i_valid) in enumerate (skf.split(X_train, y_train)):\n    df_train.loc[i_valid, 'kfold'] = fold\n    \ndf_train1 = pd.read_csv('level1_valid_pred_1.csv')\ndf_train2 = pd.read_csv('level1_valid_pred_2.csv')\ndf_train3 = pd.read_csv('level1_valid_pred_3.csv')\ndf_train4 = pd.read_csv('level1_valid_pred_4.csv')\ndf_train5 = pd.read_csv('level1_valid_pred_5.csv')\n\ndf_test1 = pd.read_csv('level1_test_pred_1.csv')\ndf_test2 = pd.read_csv('level1_test_pred_2.csv')\ndf_test3 = pd.read_csv('level1_test_pred_3.csv')\ndf_test4 = pd.read_csv('level1_test_pred_4.csv')\ndf_test5 = pd.read_csv('level1_test_pred_5.csv')\n\ndf_train = df_train.merge(df_train1, on='id', how='left')\ndf_train = df_train.merge(df_train2, on='id', how='left')\ndf_train = df_train.merge(df_train3, on='id', how='left')\ndf_train = df_train.merge(df_train4, on='id', how='left')\ndf_train = df_train.merge(df_train5, on='id', how='left')\n\ndf_test = df_test.merge(df_test1, on='id', how='left')\ndf_test = df_test.merge(df_test2, on='id', how='left')\ndf_test = df_test.merge(df_test3, on='id', how='left')\ndf_test = df_test.merge(df_test4, on='id', how='left')\ndf_test = df_test.merge(df_test5, on='id', how='left')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:51:33.697422Z","iopub.execute_input":"2021-09-30T19:51:33.697698Z","iopub.status.idle":"2021-09-30T19:52:01.537905Z","shell.execute_reply.started":"2021-09-30T19:51:33.697658Z","shell.execute_reply":"2021-09-30T19:52:01.537101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculating model weights with Optuna (does not work)\n\nI experimented with the calculation of model weight with Optuna, but couldn't get the percentages to add up to one.","metadata":{}},{"cell_type":"code","source":"# pred_1 = df_test1.pred_1\n# pred_2 = df_test2.pred_2\n# pred_3 = df_test3.pred_3\n# pred_4 = df_test4.pred_4\n# pred_5 = df_test5.pred_5\n\n# features = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n# df_test = df_test[features]\n\n# def objective(trial):\n    \n#     w_1 = trial.suggest_uniform('w1', 0, 1)\n#     w_2 = trial.suggest_uniform('w2', 0, 1)\n#     w_3 = trial.suggest_uniform('w3', 0, 1)\n#     w_4 = trial.suggest_uniform('w4', 0, 1)\n#     w_5 = trial.suggest_uniform('w5', 0, 1)\n\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n#     y_train = X_train.claim\n#     y_valid = X_valid.claim\n\n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n\n#     pred_1 = X_valid.pred_1\n#     pred_2 = X_valid.pred_2\n#     pred_3 = X_valid.pred_3\n#     pred_4 = X_valid.pred_4\n#     pred_5 = X_valid.pred_5\n\n#     pred = (w_1 * pred_1 + w_2 * pred_2 + w_3 * pred_3 + w_4 * pred_4 + w_5 * pred_5) / 5\n\n#     auc = roc_auc_score(y_valid, pred)\n    \n#     return auc\n\n# study = optuna.create_study(direction=\"maximize\")\n# study.optimize(objective, n_trials=400)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:37:04.458003Z","iopub.execute_input":"2021-09-30T13:37:04.458452Z","iopub.status.idle":"2021-09-30T13:37:15.711553Z","shell.execute_reply.started":"2021-09-30T13:37:04.458416Z","shell.execute_reply":"2021-09-30T13:37:15.710181Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tuning the level 2 model","metadata":{}},{"cell_type":"code","source":"# seed = 0\n\n# features = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n# df_test = df_test[features]\n\n# def objective(trial):\n#     fold = 0\n#     params = {\n#         'num_leaves': trial.suggest_int('num_leaves', 2, 20),\n#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1000, 20000),\n#         'max_depth': trial.suggest_int('max_depth', 0, 4),\n#         'max_bin': trial.suggest_int('max_bin', 200, 400),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5),\n#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.00001, 50),\n#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.00001, 50),\n#         'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 4),\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.75, 0.9),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 1)        \n#     }\n\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        \n#     y_train = X_train.claim\n#     y_valid = X_valid.claim\n    \n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n    \n#     model = LGBMClassifier(\n#             objective='binary',\n#             tree_learner='serial',\n#             seed=seed,\n#             n_estimators=50000,\n#             **params)\n    \n#     model.fit(X_train,\n#               y_train,\n#               early_stopping_rounds=500,\n#               eval_set=[(X_valid, y_valid)],\n#               eval_metric='auc',\n#               callbacks=[LightGBMPruningCallback(trial, 'auc')],\n#               verbose=1000)\n    \n#     valid_pred = model.predict_proba(X_valid)[:,1]\n        \n#     auc = roc_auc_score(y_valid, valid_pred)\n#     return auc\n\n# for i in range(1):\n#     study = optuna.create_study(direction=\"maximize\")\n#     study.optimize(objective, n_trials=5000)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:04:29.302018Z","iopub.execute_input":"2021-09-30T11:04:29.302291Z","iopub.status.idle":"2021-09-30T11:17:50.082136Z","shell.execute_reply.started":"2021-09-30T11:04:29.30226Z","shell.execute_reply":"2021-09-30T11:17:50.080125Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Level 2 model","metadata":{}},{"cell_type":"code","source":"features = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\ndf_test = df_test[features]\n\ntest_preds = []\nvalid_preds = {}\nscores = []\n\nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n    \n#     model = LogisticRegression()\n#     model.fit(X_train, y_train)\n\n    params = {'num_leaves': 20,\n              'min_data_in_leaf': 12875,\n              'max_depth': 0,\n              'max_bin': 268,\n              'learning_rate': 0.00480893584809694,\n              'lambda_l1': 0.00020929737984329072,\n              'lambda_l2': 0.0006179415934221924,\n              'min_gain_to_split': 2.7035405403285804,\n              'feature_fraction': 0.8117162013587371,\n              'bagging_fraction': 0.8175123327757648,\n              'bagging_freq': 1}\n    \n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=42,\n        n_estimators=10000,\n        **params)\n    \n    model.fit(X_train,\n          y_train,\n          early_stopping_rounds=500,\n          eval_set=[(X_valid, y_valid)],\n          eval_metric='auc',\n          verbose=1000)\n    \n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n    \n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T20:10:21.53848Z","iopub.execute_input":"2021-09-30T20:10:21.538735Z","iopub.status.idle":"2021-09-30T20:19:20.724684Z","shell.execute_reply.started":"2021-09-30T20:10:21.5387Z","shell.execute_reply":"2021-09-30T20:19:20.723903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating submission files","metadata":{}},{"cell_type":"code","source":"sample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T20:33:37.583179Z","iopub.execute_input":"2021-09-30T20:33:37.583499Z","iopub.status.idle":"2021-09-30T20:33:39.200779Z","shell.execute_reply.started":"2021-09-30T20:33:37.583466Z","shell.execute_reply":"2021-09-30T20:33:39.200012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n# df_test = df_test[features]\n\n# df_test['mean'] = df_test[features].mean(axis=1)\n\n# sample_solution.claim = df_test['mean']\n# sample_solution.to_csv(f'stack_blend.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T20:19:22.291859Z","iopub.execute_input":"2021-09-30T20:19:22.292741Z","iopub.status.idle":"2021-09-30T20:19:23.83487Z","shell.execute_reply.started":"2021-09-30T20:19:22.292701Z","shell.execute_reply":"2021-09-30T20:19:23.834083Z"},"trusted":true},"execution_count":null,"outputs":[]}]}