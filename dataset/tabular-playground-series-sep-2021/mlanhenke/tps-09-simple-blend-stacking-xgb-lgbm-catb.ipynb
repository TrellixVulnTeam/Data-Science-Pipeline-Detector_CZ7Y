{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <div style='background:#2b6684;color:white;padding:0.5em;border-radius:0.2em'>Introduction</div>","metadata":{}},{"cell_type":"markdown","source":"**Hi**,<br>\nthis is my current solution - a one stacked meta-learner or ensemble based on xgb, catboost and lgbm.<br><br>\n\nThe approach is relatively simple. <br>\nI just train different base models and save the oof_predictions to build a meta-set in the end.<br>\nAs my final (meta) learner I simple utilize a Logistic-Regression-Model to predict the probability.<br><br>\n\n**Thanks for checkin' out my notebook, if you like it or even copy some parts of it, be sure to leave an upvote.**<br>\n\nBest Regards.\n\nCheck out my other notebooks as well:\n- [[TPS-09] Optuna Study-CatBoostClassifier](https://www.kaggle.com/mlanhenke/tps-09-optuna-study-catboostclassifier)\n- [[TPS-09] Single CatBoostClassifier ](https://www.kaggle.com/mlanhenke/tps-09-single-catboostclassifier)\n- [[TPS-09] Spot-Check (XGB,LGBM, CATB GPU)](https://www.kaggle.com/mlanhenke/tps-09-spot-check-xgb-lgbm-catb-gpu)","metadata":{}},{"cell_type":"markdown","source":"## <div style='background:#2b6684;color:white;padding:0.5em;border-radius:0.2em'>Import Data</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T17:58:43.283709Z","iopub.execute_input":"2021-09-08T17:58:43.284462Z","iopub.status.idle":"2021-09-08T17:58:43.296351Z","shell.execute_reply.started":"2021-09-08T17:58:43.284351Z","shell.execute_reply":"2021-09-08T17:58:43.295375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# read dataframe\ndf_train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\n\nsample_submission = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:58:43.298307Z","iopub.execute_input":"2021-09-08T17:58:43.298641Z","iopub.status.idle":"2021-09-08T17:59:24.024069Z","shell.execute_reply.started":"2021-09-08T17:58:43.29861Z","shell.execute_reply":"2021-09-08T17:59:24.022498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style='background:#2b6684;color:white;padding:0.5em;border-radius:0.2em'>Preprocessing</div>","metadata":{}},{"cell_type":"code","source":"# prepare dataframe for modeling\nX = df_train.drop(columns=['id','claim']).copy()\ny = df_train['claim'].copy()\n\ntest_data = df_test.drop(columns=['id']).copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:59:24.025905Z","iopub.execute_input":"2021-09-08T17:59:24.026254Z","iopub.status.idle":"2021-09-08T17:59:24.940004Z","shell.execute_reply.started":"2021-09-08T17:59:24.026219Z","shell.execute_reply":"2021-09-08T17:59:24.939113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature-engineering\ndef get_stats_per_row(data):\n    data['mv_row'] = data.isna().sum(axis=1)\n    data['min_row'] = data.min(axis=1)\n    data['std_row'] = data.std(axis=1)\n    return data\n\nX = get_stats_per_row(X)\ntest_data = get_stats_per_row(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:59:24.941673Z","iopub.execute_input":"2021-09-08T17:59:24.942125Z","iopub.status.idle":"2021-09-08T17:59:28.706953Z","shell.execute_reply.started":"2021-09-08T17:59:24.942089Z","shell.execute_reply":"2021-09-08T17:59:28.706045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get skewed features to impute median instead of mean\nfrom scipy.stats import skew\n\ndef impute_skewed_features(data):\n    skewed_feat = data.skew()\n    skewed_feat = [*skewed_feat[abs(skewed_feat.values) > 1].index]\n\n    for feat in skewed_feat:\n        median = data[feat].median()\n        data[feat] = data[feat].fillna(median)\n        \n    return data\n\nX = impute_skewed_features(X)\ntest_data = impute_skewed_features(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:59:28.708277Z","iopub.execute_input":"2021-09-08T17:59:28.708667Z","iopub.status.idle":"2021-09-08T17:59:33.709582Z","shell.execute_reply.started":"2021-09-08T17:59:28.708631Z","shell.execute_reply":"2021-09-08T17:59:33.708685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create preprocessing pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\npipeline = Pipeline([\n    ('impute', SimpleImputer(strategy='mean')),\n    ('scale', StandardScaler())\n])\n\nX = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\ntest_data = pd.DataFrame(columns=test_data.columns, data=pipeline.transform(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:59:33.710805Z","iopub.execute_input":"2021-09-08T17:59:33.711129Z","iopub.status.idle":"2021-09-08T17:59:40.837185Z","shell.execute_reply.started":"2021-09-08T17:59:33.711096Z","shell.execute_reply":"2021-09-08T17:59:40.836274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style='background:#2b6684;color:white;padding:0.5em;border-radius:0.2em'>Modeling</div>","metadata":{}},{"cell_type":"code","source":"# helper functions\ndef get_auc(y_true, y_hat):\n    fpr, tpr, _ = roc_curve(y_true, y_hat)\n    score = auc(fpr, tpr)\n    return score","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-08T17:59:40.838472Z","iopub.execute_input":"2021-09-08T17:59:40.838817Z","iopub.status.idle":"2021-09-08T17:59:40.842843Z","shell.execute_reply.started":"2021-09-08T17:59:40.838781Z","shell.execute_reply":"2021-09-08T17:59:40.841959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"params taken from:\n- [catb1: my own optuna study](https://www.kaggle.com/mlanhenke/tps-09-optuna-study-catboostclassifier)\n- [Stacking Ensemble for Beginner](https://www.kaggle.com/junhyeok99/stacking-ensemble-for-beginner)","metadata":{}},{"cell_type":"code","source":"# best params\nlgbm1_params = {\n    'metric' : 'auc',\n    'max_depth' : 3,\n    'num_leaves' : 7,\n    'n_estimators' : 5000,\n    'colsample_bytree' : 0.3,\n    'subsample' : 0.5,\n    'random_state' : 42,\n    'reg_alpha' : 18,\n    'reg_lambda' : 17,\n    'learning_rate' : 0.095,\n    'device' : 'gpu',\n    'objective' : 'binary'\n}\n\nlgbm2_params = {\n    'metric' : 'auc',\n    'objective': 'binary',\n    'n_estimators': 10000,\n    'random_state': 42,\n    'learning_rate': 0.095,\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 10.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n    'device' : 'gpu',\n    'max_depth' : 3,\n    'num_leaves' : 7\n}\n\nlgbm3_params = {\n    'metric' : 'auc',\n    'objective' : 'binary',\n    'device_type': 'gpu', \n    'n_estimators': 10000, \n    'learning_rate': 0.12230165751633416, \n    'num_leaves': 1400, \n    'max_depth': 8, \n    'min_child_samples': 3100, \n    'reg_alpha': 10, \n    'reg_lambda': 65, \n    'min_split_gain': 5.157818977461183, \n    'subsample': 0.5, \n    'subsample_freq': 1, \n    'colsample_bytree': 0.2\n}\n\ncatb1_params = {\n    'eval_metric' : 'AUC',\n    'iterations': 15585, \n    'objective': 'CrossEntropy',\n    'bootstrap_type': 'Bernoulli', \n    'od_wait': 1144, \n    'learning_rate': 0.023575206684596582, \n    'reg_lambda': 36.30433203563295, \n    'random_strength': 43.75597655616195, \n    'depth': 7, \n    'min_data_in_leaf': 11, \n    'leaf_estimation_iterations': 1, \n    'subsample': 0.8227911142845009,\n    'task_type' : 'GPU',\n    'devices' : '0',\n    'verbose' : 0\n}\n\ncatb2_params = {\n    'eval_metric' : 'AUC',\n    'depth' : 5,\n    'grow_policy' : 'SymmetricTree',\n    'l2_leaf_reg' : 3.0,\n    'random_strength' : 1.0,\n    'learning_rate' : 0.1,\n    'iterations' : 10000,\n    'loss_function' : 'CrossEntropy',\n    'task_type' : 'GPU',\n    'devices' : '0',\n    'verbose' : 0\n}\n\nxgb1_params = {\n    'eval_metric' : 'auc',\n    'lambda': 0.004562711234493688, \n    'alpha': 7.268146704546314, \n    'colsample_bytree': 0.6468987558386358, \n    'colsample_bynode': 0.29113878257290376, \n    'colsample_bylevel': 0.8915913499148167, \n    'subsample': 0.37130229826185135, \n    'learning_rate': 0.021671163563123198, \n    'grow_policy': 'lossguide', \n    'max_depth': 18, \n    'min_child_weight': 215, \n    'max_bin': 272,\n    'n_estimators': 10000,\n    'random_state': 0,\n    'use_label_encoder': False,\n    'objective': 'binary:logistic',\n    'tree_method': 'gpu_hist',\n    'gpu_id': 0,\n    'predictor': 'gpu_predictor'\n}\n\nxgb2_params = dict(\n    eval_metric='auc',\n    max_depth=3,\n    subsample=0.5,\n    colsample_bytree=0.5,\n    learning_rate=0.01187431306013263,\n    n_estimators=10000,\n    n_jobs=-1,\n    use_label_encoder=False,\n    objective='binary:logistic',\n    tree_method='gpu_hist',\n    gpu_id=0,\n    predictor='gpu_predictor'\n)\n\nxgb3_params = {\n    'eval_metric': 'auc', \n    'objective': 'binary:logistic', \n    'tree_method': 'gpu_hist', \n    'gpu_id': 0, \n    'predictor': 'gpu_predictor', \n    'n_estimators': 10000, \n    'learning_rate': 0.01063045229441343, \n    'gamma': 0.24652519525750877, \n    'max_depth': 4, \n    'min_child_weight': 366, \n    'subsample': 0.6423040816299684, \n    'colsample_bytree': 0.7751264493218339, \n    'colsample_bylevel': 0.8675692743597421, \n    'lambda': 0, \n    'alpha': 10\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-08T18:20:00.393793Z","iopub.execute_input":"2021-09-08T18:20:00.394125Z","iopub.status.idle":"2021-09-08T18:20:00.410118Z","shell.execute_reply.started":"2021-09-08T18:20:00.394096Z","shell.execute_reply":"2021-09-08T18:20:00.409144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <div style='background:#3b606f;color:white;padding:0.5em;border-radius:0.2em'>Train Base Models</div>","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n# create list[tuples] of base_models\nmodels = [\n    ('lgbm1', LGBMClassifier(**lgbm1_params)),\n#     ('lgbm2', LGBMClassifier(**lgbm2_params)),\n    ('lgbm3', LGBMClassifier(**lgbm3_params)),\n    ('catb1', CatBoostClassifier(**catb1_params)),\n    ('catb2', CatBoostClassifier(**catb2_params)),\n    ('xgb1', XGBClassifier(**xgb1_params)),\n    ('xgb2', XGBClassifier(**xgb2_params)),\n    ('xgb3', XGBClassifier(**xgb3_params))\n]\n\n# create dictionaries to store predictions\noof_pred_tmp = dict()\ntest_pred_tmp = dict()\nscores_tmp = dict()\n\n# create cv\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n    # create train, validation sets\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n    # fit & predict all models on the same fold\n    for name, model in models:\n        if name not in scores_tmp:\n            oof_pred_tmp[name] = list()\n            oof_pred_tmp['y_valid'] = list()\n            test_pred_tmp[name] = list()\n            scores_tmp[name] = list()\n     \n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_valid,y_valid)],\n#             early_stopping_rounds=500,\n            verbose=0\n        )\n        \n        # validation prediction\n        pred_valid = model.predict_proba(X_valid)[:,1]\n        score = get_auc(y_valid, pred_valid)\n        \n        scores_tmp[name].append(score)\n        oof_pred_tmp[name].extend(pred_valid)\n        \n        print(f\"Fold: {fold + 1} Model: {name} Score: {score}\")\n        print('--'*20)\n        \n        # test prediction\n        y_hat = model.predict_proba(test_data)[:,1]\n        test_pred_tmp[name].append(y_hat)\n    \n    # store y_validation for later use\n    oof_pred_tmp['y_valid'].extend(y_valid)\n        \n# print overall validation scores\nfor name, model in models:\n    print(f\"Overall Validation Score | {name}: {np.mean(scores_tmp[name])}\")\n    print('::'*20)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T18:18:06.133245Z","iopub.execute_input":"2021-09-08T18:18:06.133627Z","iopub.status.idle":"2021-09-08T18:19:47.410091Z","shell.execute_reply.started":"2021-09-08T18:18:06.133594Z","shell.execute_reply":"2021-09-08T18:19:47.409067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <div style='background:#3b606f;color:white;padding:0.5em;border-radius:0.2em'>Simple Blending of Base Models</div>","metadata":{}},{"cell_type":"code","source":"# create df with base predictions on test_data\nbase_test_predictions = pd.DataFrame(\n    {name: np.mean(np.column_stack(test_pred_tmp[name]), axis=1) \n    for name in test_pred_tmp.keys()}\n)\n\n# save csv checkpoint\nbase_test_predictions.to_csv('./base_test_predictions.csv', index=False)\n\n# create simple average blend \nbase_test_predictions['simple_avg'] = base_test_predictions.mean(axis=1)\n\n# create submission file with simple blend average\nsimple_blend_submission = sample_submission.copy()\nsimple_blend_submission['claim'] = base_test_predictions['simple_avg']\nsimple_blend_submission.to_csv('./simple_blend_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T18:05:38.725502Z","iopub.execute_input":"2021-09-08T18:05:38.725842Z","iopub.status.idle":"2021-09-08T18:05:41.625072Z","shell.execute_reply.started":"2021-09-08T18:05:38.725806Z","shell.execute_reply":"2021-09-08T18:05:41.624222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create training set for meta learner based on the oof_predictions of the base models\noof_predictions = pd.DataFrame(\n    {name:oof_pred_tmp[name] for name in oof_pred_tmp.keys()}\n)\n\n# save csv checkpoint\noof_predictions.to_csv('./oof_predictions.csv', index=False)\n\n# get simple blend validation score\ny_valid = oof_predictions['y_valid'].copy()\ny_hat_blend = oof_predictions.drop(columns=['y_valid']).mean(axis=1)\nscore = get_auc(y_valid, y_hat_blend)\n\nprint(f\"Overall Validation Score | Simple Blend: {score}\")\nprint('::'*20)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T18:05:41.626325Z","iopub.execute_input":"2021-09-08T18:05:41.626696Z","iopub.status.idle":"2021-09-08T18:05:43.014215Z","shell.execute_reply.started":"2021-09-08T18:05:41.626659Z","shell.execute_reply":"2021-09-08T18:05:43.013222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <div style='background:#3b606f;color:white;padding:0.5em;border-radius:0.2em'>Train Meta Learner</div>","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import LogisticRegression\n\n# prepare meta_training set\nX_meta = oof_predictions.drop(columns=['y_valid']).copy()\ny_meta = oof_predictions['y_valid'].copy()\ntest_meta = base_test_predictions.drop(columns=['simple_avg']).copy()\n\nmeta_pred_tmp = []\nscores_tmp = []\n\n# create cv\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X_meta, y_meta)):\n    # create train, validation sets\n    X_train, y_train = X_meta.iloc[idx_train], y_meta.iloc[idx_train]\n    X_valid, y_valid = X_meta.iloc[idx_valid], y_meta.iloc[idx_valid]\n\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    \n    # validation prediction\n    pred_valid = model.predict_proba(X_valid)[:,1]\n    score = get_auc(y_valid, pred_valid)\n    scores_tmp.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\")\n    print('--'*20)\n    \n    # test prediction based on oof_set\n    y_hat = model.predict_proba(test_meta)[:,1]\n    meta_pred_tmp.append(y_hat)\n    \n# print overall validation scores\nprint(f\"Overall Validation Score | Meta: {np.mean(scores_tmp)}\")\nprint('::'*20)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T18:05:43.0156Z","iopub.execute_input":"2021-09-08T18:05:43.01617Z","iopub.status.idle":"2021-09-08T18:05:48.744183Z","shell.execute_reply.started":"2021-09-08T18:05:43.016122Z","shell.execute_reply":"2021-09-08T18:05:48.743123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# average meta predictions over each fold\nmeta_predictions = np.mean(np.column_stack(meta_pred_tmp), axis=1)\n\n# create submission file\nstacked_submission = sample_submission.copy()\nstacked_submission['claim'] = meta_predictions\nstacked_submission.to_csv('./stacked_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T18:05:48.74904Z","iopub.execute_input":"2021-09-08T18:05:48.751632Z","iopub.status.idle":"2021-09-08T18:05:50.402826Z","shell.execute_reply.started":"2021-09-08T18:05:48.751585Z","shell.execute_reply":"2021-09-08T18:05:50.401828Z"},"trusted":true},"execution_count":null,"outputs":[]}]}