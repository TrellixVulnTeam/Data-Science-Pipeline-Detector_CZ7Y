{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nnp.random.seed(0)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, minmax_scale, MaxAbsScaler, StandardScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\nfrom sklearn.decomposition import PCA\n","metadata":{"execution":{"iopub.status.busy":"2021-09-18T20:21:45.705883Z","iopub.execute_input":"2021-09-18T20:21:45.706191Z","iopub.status.idle":"2021-09-18T20:21:46.958593Z","shell.execute_reply.started":"2021-09-18T20:21:45.706165Z","shell.execute_reply":"2021-09-18T20:21:46.957599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ntestData = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\n\ntrainData.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T20:21:49.57641Z","iopub.execute_input":"2021-09-18T20:21:49.576698Z","iopub.status.idle":"2021-09-18T20:22:29.490431Z","shell.execute_reply.started":"2021-09-18T20:21:49.576671Z","shell.execute_reply":"2021-09-18T20:22:29.486882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainDataCopy = trainData.copy()\ntrainDataCopy = trainDataCopy.drop( 'id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T18:16:11.255773Z","iopub.execute_input":"2021-09-18T18:16:11.256431Z","iopub.status.idle":"2021-09-18T18:16:12.32393Z","shell.execute_reply.started":"2021-09-18T18:16:11.25639Z","shell.execute_reply":"2021-09-18T18:16:12.323195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_dataset(X_train, X_valid, y_train, y_valid, est, lrate, model_type):\n    if model_type == 'classifier':\n        model = XGBClassifier(n_estimators=est, learning_rate=lrate, n_jobs=4, tree_method='gpu_hist')\n    else:\n        model = XGBRegressor(n_estimators=est, learning_rate=lrate, n_jobs=4, tree_method='gpu_hist')\n\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    score = roc_auc_score(y_valid, preds)\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-09-18T20:23:10.071638Z","iopub.execute_input":"2021-09-18T20:23:10.071928Z","iopub.status.idle":"2021-09-18T20:23:10.079825Z","shell.execute_reply.started":"2021-09-18T20:23:10.071897Z","shell.execute_reply":"2021-09-18T20:23:10.07837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA sem a feature n_missing e todos os componentes\n","metadata":{}},{"cell_type":"code","source":"X = trainDataCopy.drop(['claim'], axis=1)\ny = trainDataCopy['claim']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='median')\nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transformação com melhores resultados\npca = PCA()\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor')) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA sem a feature n_missing e variância acumulada de 0.95\n","metadata":{}},{"cell_type":"code","source":"X = trainDataCopy.drop(['claim'], axis=1)\ny = trainDataCopy['claim']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transformação com melhores resultados\npca = PCA(0.95)\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor')) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA com a feature n_missing e todos os componentes\n","metadata":{}},{"cell_type":"code","source":"X = trainDataCopy.drop(['claim'], axis=1)\nX['n_missing'] = trainDataCopy.isnull().sum(axis=1)\ny = trainDataCopy['claim']\n","metadata":{"execution":{"iopub.status.busy":"2021-09-18T20:23:13.234982Z","iopub.execute_input":"2021-09-18T20:23:13.235718Z","iopub.status.idle":"2021-09-18T20:23:14.610541Z","shell.execute_reply.started":"2021-09-18T20:23:13.235678Z","shell.execute_reply":"2021-09-18T20:23:14.6095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transformação com melhores resultados\npca = PCA()\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor')) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","metadata":{"execution":{"iopub.status.busy":"2021-09-18T19:26:57.688074Z","iopub.execute_input":"2021-09-18T19:26:57.688896Z","iopub.status.idle":"2021-09-18T19:26:57.695141Z","shell.execute_reply.started":"2021-09-18T19:26:57.688837Z","shell.execute_reply":"2021-09-18T19:26:57.694216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA com a feature n_missing e variância acumulada de 0.95","metadata":{}},{"cell_type":"code","source":"X = trainDataCopy.drop(['claim'], axis=1)\nX['n_missing'] = trainDataCopy.isnull().sum(axis=1)\ny = trainDataCopy['claim']\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transformação com melhores resultados\npca = PCA(0.95)\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Arquivo de submissão da melhor abordagem","metadata":{}},{"cell_type":"code","source":"X = trainDataCopy.drop(['claim'], axis=1)\nX['n_missing'] = trainDataCopy.isnull().sum(axis=1)\ny = trainDataCopy['claim']\n\nimputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transformação com melhores resultados\npca = PCA()\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testDataCopy = testData.copy().drop('id', axis=1)\ntestDataCopy['n_missing'] = testData.isnull().sum(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='median')\nimputed_X_test = pd.DataFrame(imputer.fit_transform(testDataCopy))\nimputed_X_test.columns = testDataCopy.columns\n\nscl = QuantileTransformer(output_distribution='uniform')\npca = PCA()\nX_test_scaled = scl.fit_transform(imputed_X_test)\nX_test_pca = pca.fit_transform(X_test_scaled)\ncomponent_names = [f\"PC{i+1}\" for i in range(X_test_pca.shape[1])]\nX_test_pca = pd.DataFrame(X_test_pca, columns=component_names)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T18:42:10.229782Z","iopub.execute_input":"2021-09-18T18:42:10.230313Z","iopub.status.idle":"2021-09-18T18:43:33.379422Z","shell.execute_reply.started":"2021-09-18T18:42:10.230273Z","shell.execute_reply":"2021-09-18T18:43:33.37858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XGBRegressor(n_estimators=1500, learning_rate=0.02, n_jobs=4, tree_method='gpu_hist')\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test_pca)\nseries = pd.Series(preds, index=testData['id'].astype('int'), name='claim') \nseries.to_csv('output.csv')\nseries","metadata":{},"execution_count":null,"outputs":[]}]}