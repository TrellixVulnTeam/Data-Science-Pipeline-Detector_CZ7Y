{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-15T10:45:11.875254Z","iopub.execute_input":"2021-09-15T10:45:11.875704Z","iopub.status.idle":"2021-09-15T10:45:12.914334Z","shell.execute_reply.started":"2021-09-15T10:45:11.875588Z","shell.execute_reply":"2021-09-15T10:45:12.913108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv', index_col='id')\ntest_data = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:45:12.916254Z","iopub.execute_input":"2021-09-15T10:45:12.916698Z","iopub.status.idle":"2021-09-15T10:45:58.869253Z","shell.execute_reply.started":"2021-09-15T10:45:12.916651Z","shell.execute_reply":"2021-09-15T10:45:58.86815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:45:58.871539Z","iopub.execute_input":"2021-09-15T10:45:58.872048Z","iopub.status.idle":"2021-09-15T10:45:58.918365Z","shell.execute_reply.started":"2021-09-15T10:45:58.871997Z","shell.execute_reply":"2021-09-15T10:45:58.916612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that features have null values\ntrain_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:45:58.919912Z","iopub.execute_input":"2021-09-15T10:45:58.920197Z","iopub.status.idle":"2021-09-15T10:46:03.883099Z","shell.execute_reply.started":"2021-09-15T10:45:58.920169Z","shell.execute_reply":"2021-09-15T10:46:03.882074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Claim has no null values, so we use that number for total records\ntotal_records = len(train_data['claim'])\ntotal_records","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:46:03.884345Z","iopub.execute_input":"2021-09-15T10:46:03.884646Z","iopub.status.idle":"2021-09-15T10:46:03.891406Z","shell.execute_reply.started":"2021-09-15T10:46:03.884617Z","shell.execute_reply":"2021-09-15T10:46:03.890174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train_data.columns.drop('claim')\nlabel = ['claim']\nfeatures","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:46:03.893145Z","iopub.execute_input":"2021-09-15T10:46:03.893594Z","iopub.status.idle":"2021-09-15T10:46:03.907325Z","shell.execute_reply.started":"2021-09-15T10:46:03.893547Z","shell.execute_reply":"2021-09-15T10:46:03.906187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show percentage of missing values for each feature\n# Note low percentage of missing values \n[str(round(null_count/total_records*100,2))+ '%' for null_count in train_data[features].isnull().sum()]","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:46:03.908703Z","iopub.execute_input":"2021-09-15T10:46:03.909125Z","iopub.status.idle":"2021-09-15T10:46:04.415247Z","shell.execute_reply.started":"2021-09-15T10:46:03.909083Z","shell.execute_reply":"2021-09-15T10:46:04.41435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distributions of features\n# Many have right skew\nfeature_histograms = train_data[features].hist(figsize = (120, 640), bins=50, grid = False, xlabelsize=8, ylabelsize=8, layout = (101,4))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:46:04.417585Z","iopub.execute_input":"2021-09-15T10:46:04.417911Z","iopub.status.idle":"2021-09-15T10:46:55.859969Z","shell.execute_reply.started":"2021-09-15T10:46:04.417881Z","shell.execute_reply":"2021-09-15T10:46:55.858781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation heatmap\n# Roughly no correlation between features\nfig = plt.gcf()\nfig.set_size_inches(120, 120)\ncorrelations = train_data[features].corr()\nsns.heatmap(data=correlations, annot=True, cmap='mako')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:46:55.861571Z","iopub.execute_input":"2021-09-15T10:46:55.862021Z","iopub.status.idle":"2021-09-15T10:48:48.160959Z","shell.execute_reply.started":"2021-09-15T10:46:55.861988Z","shell.execute_reply":"2021-09-15T10:48:48.15963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Are there discrete features?\n# Blank array = no discrete features; all continuous\ndiscrete_cols = []\n\nfor col in features:\n    if np.array_equal(train_data[col].values, train_data[col].values.astype(int)):\n        discrete_cols.append(col)\nprint(discrete_cols)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:48:48.162799Z","iopub.execute_input":"2021-09-15T10:48:48.163203Z","iopub.status.idle":"2021-09-15T10:48:48.527699Z","shell.execute_reply.started":"2021-09-15T10:48:48.163165Z","shell.execute_reply":"2021-09-15T10:48:48.526555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for class imbalance\ncounts = train_data[label].value_counts()\ncounts","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:48:48.529252Z","iopub.execute_input":"2021-09-15T10:48:48.529686Z","iopub.status.idle":"2021-09-15T10:48:48.569401Z","shell.execute_reply.started":"2021-09-15T10:48:48.529641Z","shell.execute_reply":"2021-09-15T10:48:48.568717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classes are roughly balanced\nplt.bar([0,1], counts)\nplt.xticks(ticks=[0,1])","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:48:48.570589Z","iopub.execute_input":"2021-09-15T10:48:48.570934Z","iopub.status.idle":"2021-09-15T10:48:48.691503Z","shell.execute_reply.started":"2021-09-15T10:48:48.570905Z","shell.execute_reply":"2021-09-15T10:48:48.690378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data cleaning","metadata":{}},{"cell_type":"code","source":"# Have a column that counts nulls - https://www.kaggle.com/c/tabular-playground-series-sep-2021/discussion/270206 (TBD)\ntrain_data['num_of_nulls'] = train_data[features].isnull().sum(axis=1)\ntest_data['num_of_nulls'] = test_data[features].isnull().sum(axis=1)\n\ntrain_data['standard_deviations'] = train_data[features].std(axis=1)\ntest_data['standard_deviations'] = test_data[features].std(axis=1)\n\ntrain_data['min'] = train_data[features].min(axis=1)\ntest_data['min'] = train_data[features].min(axis=1)\n\ntrain_data['max'] = train_data[features].max(axis=1)\ntest_data['max'] = train_data[features].max(axis=1)\n\nfeatures = train_data.columns.drop('claim')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:48:48.692802Z","iopub.execute_input":"2021-09-15T10:48:48.693123Z","iopub.status.idle":"2021-09-15T10:48:55.977983Z","shell.execute_reply.started":"2021-09-15T10:48:48.693093Z","shell.execute_reply":"2021-09-15T10:48:55.976948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:48:55.979293Z","iopub.execute_input":"2021-09-15T10:48:55.979613Z","iopub.status.idle":"2021-09-15T10:48:56.164447Z","shell.execute_reply.started":"2021-09-15T10:48:55.979568Z","shell.execute_reply":"2021-09-15T10:48:56.162945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_data[features].values\ny = train_data[label].values\nX_test = test_data.values","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:48:56.166468Z","iopub.execute_input":"2021-09-15T10:48:56.167401Z","iopub.status.idle":"2021-09-15T10:48:57.206585Z","shell.execute_reply.started":"2021-09-15T10:48:56.1673Z","shell.execute_reply":"2021-09-15T10:48:57.205644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale values to roughly be in the same range\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)\nX_test = scaler.transform(X_test)\n\nX","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:48:57.207931Z","iopub.execute_input":"2021-09-15T10:48:57.208214Z","iopub.status.idle":"2021-09-15T10:49:00.70671Z","shell.execute_reply.started":"2021-09-15T10:48:57.208187Z","shell.execute_reply":"2021-09-15T10:49:00.705961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill in missing values with mean\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='mean')\nimputer.fit(X)\nX = imputer.transform(X)\nX_test = imputer.transform(X_test)\n\nX","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:49:00.707707Z","iopub.execute_input":"2021-09-15T10:49:00.708152Z","iopub.status.idle":"2021-09-15T10:49:04.121546Z","shell.execute_reply.started":"2021-09-15T10:49:00.708124Z","shell.execute_reply":"2021-09-15T10:49:04.120408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix skew with Yeo Johnson transformation (to address positive and negative values)\nfrom sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer(method='yeo-johnson', standardize=False)\npt.fit(X)\nX = pt.transform(X)\nX_test = pt.transform(X_test)\n\nX","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:49:04.12297Z","iopub.execute_input":"2021-09-15T10:49:04.123397Z","iopub.status.idle":"2021-09-15T10:53:59.16582Z","shell.execute_reply.started":"2021-09-15T10:49:04.123352Z","shell.execute_reply":"2021-09-15T10:53:59.164812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn unskewed features to dataframe so we can plot it on histograms\nunskewed_features = pd.DataFrame(data=X, columns=features)\n# Skews not fixed completely but, outliers aren't as extreme (fatter tails)\nunskewed_histograms = unskewed_features.hist(figsize = (120, 640), bins=50, grid = False, xlabelsize=8, ylabelsize=8, layout = (101,4))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:53:59.167656Z","iopub.execute_input":"2021-09-15T10:53:59.167975Z","iopub.status.idle":"2021-09-15T10:54:53.354825Z","shell.execute_reply.started":"2021-09-15T10:53:59.167945Z","shell.execute_reply":"2021-09-15T10:54:53.353696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline models","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import auc, roc_curve\n\n# This function takes the model and data and returns auc\ndef get_auc(model, X_train, y_train, X_val, y_val):\n    model.fit(X_train, y_train)\n    val_predictions = model.predict(X_val)\n    fpr, tpr, thresholds = roc_curve(y_val, val_predictions)\n    return auc(fpr, tpr)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:54:53.356504Z","iopub.execute_input":"2021-09-15T10:54:53.357345Z","iopub.status.idle":"2021-09-15T10:54:53.364352Z","shell.execute_reply.started":"2021-09-15T10:54:53.357293Z","shell.execute_reply":"2021-09-15T10:54:53.363013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X,y, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:54:53.365707Z","iopub.execute_input":"2021-09-15T10:54:53.366081Z","iopub.status.idle":"2021-09-15T10:54:54.946499Z","shell.execute_reply.started":"2021-09-15T10:54:53.366044Z","shell.execute_reply":"2021-09-15T10:54:54.945244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RGF (Regularized Greedy Forest) - https://www.kaggle.com/carlmcbrideellis/introduction-to-the-regularized-greedy-forest\n!pip install rgf_python","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:54:54.947986Z","iopub.execute_input":"2021-09-15T10:54:54.948301Z","iopub.status.idle":"2021-09-15T10:55:03.840818Z","shell.execute_reply.started":"2021-09-15T10:54:54.948271Z","shell.execute_reply":"2021-09-15T10:55:03.839589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With results, we can decide which models are worth tuning hyperparameters on\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom rgf.sklearn import FastRGFClassifier\nfrom catboost import CatBoostClassifier\n\nmodel_list = [CatBoostClassifier(eval_metric='AUC'), FastRGFClassifier(), LogisticRegression(), RandomForestClassifier(), XGBClassifier(), LGBMClassifier(objective='binary'), HistGradientBoostingClassifier()]\n\nfor model in model_list:\n    print('{model_name} AUC: {auc:.3f}'.format(model_name = str(model), auc = get_auc(model, X_train, y_train.ravel(), X_val, y_val.ravel())))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T11:06:47.708694Z","iopub.execute_input":"2021-09-15T11:06:47.709079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}