{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-01T06:18:00.630912Z","iopub.execute_input":"2021-09-01T06:18:00.631824Z","iopub.status.idle":"2021-09-01T06:18:00.665244Z","shell.execute_reply.started":"2021-09-01T06:18:00.631704Z","shell.execute_reply":"2021-09-01T06:18:00.663767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\ndata_dir = Path('../input/tabular-playground-series-sep-2021/')\n\ndf_train = pd.read_csv(\n    data_dir / \"train.csv\",\n    index_col='id',\n    nrows=25000,  # comment this row to use the full dataset\n)\n\nFEATURES = df_train.columns[:-1]\nTARGET = df_train.columns[-1]\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T06:18:13.818479Z","iopub.execute_input":"2021-09-01T06:18:13.818832Z","iopub.status.idle":"2021-09-01T06:18:15.007464Z","shell.execute_reply.started":"2021-09-01T06:18:13.818798Z","shell.execute_reply":"2021-09-01T06:18:15.006257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model**\n\nLet's try out a simple XGBoost model. This algorithm can handle missing values, but you could try imputing them instead. We use XGBClassifier (instead of XGBRegressor, for instance), since this is a classification problem.","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nX = df_train.loc[:, FEATURES]\ny = df_train.loc[:, TARGET]\n\nmodel = XGBClassifier(\n    max_depth=3,\n    subsample=0.5,\n    colsample_bytree=0.5,\n    n_jobs=-1,\n    # Uncomment if you want to use GPU. Recommended for whole training set.\n    #tree_method='gpu_hist',\n    random_state=0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T06:19:00.611724Z","iopub.execute_input":"2021-09-01T06:19:00.612153Z","iopub.status.idle":"2021-09-01T06:19:01.712495Z","shell.execute_reply.started":"2021-09-01T06:19:00.612121Z","shell.execute_reply":"2021-09-01T06:19:01.711459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation**\n\nThe evaluation metric is AUC, which stands for \"area under curve\". Run the next code cell to evaluate the model.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_validate\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndef score(X, y, model, cv):\n    scoring = [\"roc_auc\"]\n    scores = cross_validate(\n        model, X, y, scoring=scoring, cv=cv, return_train_score=True\n    )\n    scores = pd.DataFrame(scores).T\n    return scores.assign(\n        mean = lambda x: x.mean(axis=1),\n        std = lambda x: x.std(axis=1),\n    )\n\nscores = score(X, y, model, cv=2)\n\ndisplay(scores)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T06:19:46.020312Z","iopub.execute_input":"2021-09-01T06:19:46.020692Z","iopub.status.idle":"2021-09-01T06:20:11.17875Z","shell.execute_reply.started":"2021-09-01T06:19:46.020661Z","shell.execute_reply":"2021-09-01T06:20:11.177627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit on full training set\nmodel.fit(X, y)\n\nX_test = pd.read_csv(data_dir / \"test.csv\", index_col='id')\n\n# Make predictions\ny_pred = pd.Series(\n    model.predict(X_test),\n    index=X_test.index,\n    name=TARGET,\n)\n\n# Create submission file\ny_pred.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-01T06:20:19.535812Z","iopub.execute_input":"2021-09-01T06:20:19.536221Z","iopub.status.idle":"2021-09-01T06:20:59.937145Z","shell.execute_reply.started":"2021-09-01T06:20:19.536158Z","shell.execute_reply":"2021-09-01T06:20:59.935886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This is a simpler format to the approachable tabular dataset**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}