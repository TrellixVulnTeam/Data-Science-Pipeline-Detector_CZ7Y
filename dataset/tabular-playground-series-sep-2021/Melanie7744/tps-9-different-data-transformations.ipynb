{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How do different input data transformations affect model outcome?\nMy goal with this notebook is to find out how different data preprocessing techniques affect the model's evaluation metric.\n\n**My experiment:**\n* Use one model with a fixed set of hyperparameters. I chose LightGBM with these parameters:\n> lgb_params = {\n    'objective': 'binary',\n    'n_estimators': 1000,\n    'random_state': 29,\n    'learning_rate': 0.1,\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 10.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n}\n* Use exactly the same features\n* Fix the random state\n* Vary the preprocessing technique\n    * Step 1: replace missing values with column mean (rmv)\n    * Step 2: rvm + different scalers/transformers applied to all features\n    * Step 2a: rmv + StandardScaler \n    * Step 2b: rmv + MinMaxScaler\n    * Step 2c: rmv + RobustScaler\n    * Step 2d: rmv + PowerTransformer\n    * Step 2e: rmv + QuantileTransformer\n    * Step 3: rmv + different Scalers on different features\n    * Step 4a: rmv + adding categorical version of f40,f42,f65,f70,f75\n    * Step 4b: rmv + making f40,f42,f65,f70,f75 categorical\n   \n**My conclusions:**\n\n* My experiment did not have a big impact on the validation score. The best result gave using PowerTransformer on all features. The more experimental Steps 3 and 4 led to a worse score. \n* On the bright side, I finally learned how to use Pipelines for preprocessing.\n\n----\n**I'd appreciate your feedback and ideas. Let's share our knowledge so that we can all learn something new!**\n","metadata":{}},{"cell_type":"code","source":"#load libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb\nprint(\"LightGBM version:  {}\".format(lgb.__version__))\n\nimport matplotlib as plt\nprint(\"Matplotlib version:  {}\".format(plt.__version__))\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T09:08:49.070581Z","iopub.execute_input":"2021-09-21T09:08:49.071456Z","iopub.status.idle":"2021-09-21T09:08:49.086418Z","shell.execute_reply.started":"2021-09-21T09:08:49.071417Z","shell.execute_reply":"2021-09-21T09:08:49.085255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read input files\ndf_train = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")\ndf_test = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\")\nsample_submission = pd.read_csv(\"../input/tabular-playground-series-sep-2021/sample_solution.csv\")\n\nfeature_cols = [col for col in df_train.columns if col.startswith(\"f\")]\ntarget=df_train.claim","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:08:49.088255Z","iopub.execute_input":"2021-09-21T09:08:49.088875Z","iopub.status.idle":"2021-09-21T09:09:22.127428Z","shell.execute_reply.started":"2021-09-21T09:08:49.088832Z","shell.execute_reply":"2021-09-21T09:09:22.126549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Steps 1 and 2","metadata":{}},{"cell_type":"code","source":"# define preprocessing pipelines, different pipelines are used for the different steps\ncat_like_features = ['f40','f42','f65','f70','f75']\nnumeric_features = list(set(feature_cols).difference(cat_like_features)) # all features that are not in cat_like_features\n\nnumeric_transformer = Pipeline(steps=[\n       ('imputer', SimpleImputer(strategy='mean')), # replace all Nan with mean\n       ('scaler', PowerTransformer()) # scale the features, remove/change the scaler here for Steps 1 and 2\n        ]) \n\ncat_like_transformer = Pipeline(steps=[\n       ('imputer', SimpleImputer(strategy='mean')), \n       ('scaler', StandardScaler())\n        ]) \n\npreprocessor = ColumnTransformer(\n   transformers=[\n    ('numeric', numeric_transformer, numeric_features)\n   ,('cat_like', cat_like_transformer, cat_like_features)\n]) ","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:09:22.135158Z","iopub.execute_input":"2021-09-21T09:09:22.135461Z","iopub.status.idle":"2021-09-21T09:09:22.149984Z","shell.execute_reply.started":"2021-09-21T09:09:22.135432Z","shell.execute_reply":"2021-09-21T09:09:22.148737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dividing X, y into train and test data\nX = df_train[feature_cols]\ny = df_train.claim\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 29, stratify=y)\ndisplay(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:23:28.765543Z","iopub.execute_input":"2021-09-21T09:23:28.765894Z","iopub.status.idle":"2021-09-21T09:23:31.207946Z","shell.execute_reply.started":"2021-09-21T09:23:28.765861Z","shell.execute_reply":"2021-09-21T09:23:31.207133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train1 = numeric_transformer.fit_transform(X_train)\nX_val1 = numeric_transformer.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:23:31.20988Z","iopub.execute_input":"2021-09-21T09:23:31.210436Z","iopub.status.idle":"2021-09-21T09:26:48.052797Z","shell.execute_reply.started":"2021-09-21T09:23:31.210392Z","shell.execute_reply":"2021-09-21T09:26:48.051813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# most of the parameters I borrowed from BIZENs great notebook: https://www.kaggle.com/hiro5299834/tps-sep-2021-single-lgbm\n# this parameterset is kept fixed for my experiment\nlgb_params = {\n    'objective': 'binary',\n    'n_estimators': 1000,\n    'random_state': 29,\n    'learning_rate': 0.1,\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 10.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:26:48.054206Z","iopub.execute_input":"2021-09-21T09:26:48.054549Z","iopub.status.idle":"2021-09-21T09:26:48.060862Z","shell.execute_reply.started":"2021-09-21T09:26:48.054519Z","shell.execute_reply":"2021-09-21T09:26:48.059916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.LGBMClassifier(**lgb_params)\nmodel.fit( \n        X_train1, \n        y_train,\n        eval_set=[(X_val1, y_val)],\n        eval_names=['val'],\n        eval_metric='auc',\n        #early_stopping_rounds=30, # no early stopping for my experiment\n        verbose=100)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:26:48.062705Z","iopub.execute_input":"2021-09-21T09:26:48.062942Z","iopub.status.idle":"2021-09-21T09:28:59.495748Z","shell.execute_reply.started":"2021-09-21T09:26:48.062911Z","shell.execute_reply":"2021-09-21T09:28:59.494972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LGBM Results\n# Part 1\n# LGBM with no missing values (SimpleImputer(strategy='mean'))\n#[1000]\tval's auc: 0.790365\tval's binary_logloss: 0.576905\n\n# Part 2\n# LGBM with no missing values (SimpleImputer(strategy='mean')) and all features standard scaled\n#[1000]\tval's auc: 0.793513\tval's binary_logloss: 0.574752\n# LGBM with no missing values (SimpleImputer(strategy='mean')) and all features MinMax scaled\n#[1000]\tval's auc: 0.790635\tval's binary_logloss: 0.576583\n# LGBM with no missing values (SimpleImputer(strategy='mean')) and all features robust scaled\n#[1000]\tval's auc: 0.790691\tval's binary_logloss: 0.576554\n# LGBM with no missing values (SimpleImputer(strategy='mean')) and all features power transformed\n#[1000]\tval's auc: 0.791065\tval's binary_logloss: 0.576157\n# LGBM with no missing values (SimpleImputer(strategy='mean')) and all features quantile transformed, normal distribution\n#[1000]\tval's auc: 0.790998\tval's binary_logloss: 0.576303","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:28:59.498718Z","iopub.execute_input":"2021-09-21T09:28:59.499596Z","iopub.status.idle":"2021-09-21T09:28:59.504736Z","shell.execute_reply.started":"2021-09-21T09:28:59.499551Z","shell.execute_reply":"2021-09-21T09:28:59.50362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pred_val = model.predict_proba(X_val)[:,1]\n#pred_val[0:5] \n#roc_auc_score(y_val, pred_val) ","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:28:59.506204Z","iopub.execute_input":"2021-09-21T09:28:59.506531Z","iopub.status.idle":"2021-09-21T09:28:59.522523Z","shell.execute_reply.started":"2021-09-21T09:28:59.506481Z","shell.execute_reply":"2021-09-21T09:28:59.52182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Changing the preprocessing, different preprocessing for different features","metadata":{}},{"cell_type":"code","source":"X_train2 = preprocessor.fit_transform(X_train)\nX_val2 = preprocessor.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:28:59.523737Z","iopub.execute_input":"2021-09-21T09:28:59.524583Z","iopub.status.idle":"2021-09-21T09:32:08.740279Z","shell.execute_reply.started":"2021-09-21T09:28:59.524543Z","shell.execute_reply":"2021-09-21T09:32:08.739262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.LGBMClassifier(**lgb_params)\nmodel.fit( \n        X_train2, \n        y_train,\n        eval_set=[(X_val2, y_val)],\n        eval_names=['val'],\n        eval_metric='auc',\n        #early_stopping_rounds=30, # no early stopping for my experiment\n        verbose=100)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:32:08.741616Z","iopub.execute_input":"2021-09-21T09:32:08.741859Z","iopub.status.idle":"2021-09-21T09:34:20.38021Z","shell.execute_reply.started":"2021-09-21T09:32:08.741831Z","shell.execute_reply":"2021-09-21T09:34:20.379438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LGBM Results\n#[1000]\tval's auc: 0.790365\tval's binary_logloss: 0.576905 (from Part1)\n#[1000]\tval's auc: 0.791065\tval's binary_logloss: 0.576157 (from Part2, all power transformed)\n#[1000]\tval's auc: 0.790866\tval's binary_logloss: 0.576427 Power Transform on all \"non cat_like_features\"","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:34:20.383686Z","iopub.execute_input":"2021-09-21T09:34:20.383921Z","iopub.status.idle":"2021-09-21T09:34:20.388227Z","shell.execute_reply.started":"2021-09-21T09:34:20.383895Z","shell.execute_reply":"2021-09-21T09:34:20.387122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: make a few features categorical","metadata":{}},{"cell_type":"code","source":"# fill means before, otherwise there would be Nans in qcut\ndf_train[feature_cols] = df_train[feature_cols].fillna(df_train[feature_cols].mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:34:20.391899Z","iopub.execute_input":"2021-09-21T09:34:20.392315Z","iopub.status.idle":"2021-09-21T09:34:22.170722Z","shell.execute_reply.started":"2021-09-21T09:34:20.392283Z","shell.execute_reply":"2021-09-21T09:34:22.169812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Steps 4a, 4b: make categorical features, made auc worse, don't use\ndf_train['f40c'] = pd.cut(df_train['f40'], bins=2, labels=[0,1]).astype(int)\ndf_train['f42c'] = pd.cut(df_train['f42'], bins=3, labels=[0,1,2]).astype(int)\ndf_train['f65c'] = pd.cut(df_train['f65'], bins=2, labels=[0,1]).astype(int)\ndf_train['f70c'] = pd.cut(df_train['f70'], bins=2, labels=[0,1]).astype(int)\ndf_train['f75c'] = pd.cut(df_train['f75'], bins=2, labels=[0,1]).astype(int)\n# renew feature col list\nfeature_cols = [col for col in df_train.columns if col.startswith(\"f\")]","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:34:22.171731Z","iopub.execute_input":"2021-09-21T09:34:22.171948Z","iopub.status.idle":"2021-09-21T09:34:22.346136Z","shell.execute_reply.started":"2021-09-21T09:34:22.171923Z","shell.execute_reply":"2021-09-21T09:34:22.345095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dividing X, y into train and test data\nX = df_train[feature_cols]\ny = df_train.claim\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 29, stratify=y)\ndisplay(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:34:22.347224Z","iopub.execute_input":"2021-09-21T09:34:22.347441Z","iopub.status.idle":"2021-09-21T09:34:24.729639Z","shell.execute_reply.started":"2021-09-21T09:34:22.347416Z","shell.execute_reply":"2021-09-21T09:34:24.728692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.LGBMClassifier(**lgb_params)\nmodel.fit( \n        X_train, \n        y_train,\n        eval_set=[(X_val, y_val)],\n        eval_names=['val'],\n        eval_metric='auc',\n        #early_stopping_rounds=30, # no early stopping for my experiment\n        verbose=100)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:34:24.730891Z","iopub.execute_input":"2021-09-21T09:34:24.731216Z","iopub.status.idle":"2021-09-21T09:36:44.463027Z","shell.execute_reply.started":"2021-09-21T09:34:24.731186Z","shell.execute_reply":"2021-09-21T09:36:44.462065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LGBM Results\n#[1000]\tval's auc: 0.790365\tval's binary_logloss: 0.576905 (from Part 1)\n#[1000]\tval's auc: 0.789538\tval's binary_logloss: 0.577241 (adding categorical version of f40,f42,f65,f70,f75)\n#[1000]\tval's auc: 0.787255\tval's binary_logloss: 0.579993 (making f40,f42,f65,f70,f75 categorical)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:44.464888Z","iopub.execute_input":"2021-09-21T09:36:44.46517Z","iopub.status.idle":"2021-09-21T09:36:44.469353Z","shell.execute_reply.started":"2021-09-21T09:36:44.465132Z","shell.execute_reply":"2021-09-21T09:36:44.468284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pred_val = model.predict_proba(X_val)[:,1]\n#pred_val[0:5]  ","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:44.470662Z","iopub.execute_input":"2021-09-21T09:36:44.470895Z","iopub.status.idle":"2021-09-21T09:36:44.482541Z","shell.execute_reply.started":"2021-09-21T09:36:44.470868Z","shell.execute_reply":"2021-09-21T09:36:44.481582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understanding ROC curve\nadapted from: https://www.projectpro.io/recipes/plot-roc-curve-in-python","metadata":{}},{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:44.483689Z","iopub.execute_input":"2021-09-21T09:36:44.484099Z","iopub.status.idle":"2021-09-21T09:36:44.657974Z","shell.execute_reply.started":"2021-09-21T09:36:44.48407Z","shell.execute_reply":"2021-09-21T09:36:44.657159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.load_breast_cancer()\nX = dataset.data\ny = dataset.target","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:44.659317Z","iopub.execute_input":"2021-09-21T09:36:44.659827Z","iopub.status.idle":"2021-09-21T09:36:44.690814Z","shell.execute_reply.started":"2021-09-21T09:36:44.659786Z","shell.execute_reply":"2021-09-21T09:36:44.689705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:44.692174Z","iopub.execute_input":"2021-09-21T09:36:44.692469Z","iopub.status.idle":"2021-09-21T09:36:44.702629Z","shell.execute_reply.started":"2021-09-21T09:36:44.692435Z","shell.execute_reply":"2021-09-21T09:36:44.701697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_tree = RandomForestClassifier()\nclf_tree.fit(X_train, y_train) \ny_score1 = clf_tree.predict_proba(X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:44.704063Z","iopub.execute_input":"2021-09-21T09:36:44.704863Z","iopub.status.idle":"2021-09-21T09:36:45.003807Z","shell.execute_reply.started":"2021-09-21T09:36:44.704817Z","shell.execute_reply":"2021-09-21T09:36:45.003121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_score1[0:7]) # how confident the classifier is that the class is 1\nprint(y_test[0:7]) # the actual classes","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:45.005077Z","iopub.execute_input":"2021-09-21T09:36:45.005488Z","iopub.status.idle":"2021-09-21T09:36:45.013681Z","shell.execute_reply.started":"2021-09-21T09:36:45.005442Z","shell.execute_reply":"2021-09-21T09:36:45.012594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:45.015688Z","iopub.execute_input":"2021-09-21T09:36:45.015906Z","iopub.status.idle":"2021-09-21T09:36:45.023988Z","shell.execute_reply.started":"2021-09-21T09:36:45.015881Z","shell.execute_reply":"2021-09-21T09:36:45.022763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(false_positive_rate1)\nprint(true_positive_rate1)\nprint(threshold1)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:45.025684Z","iopub.execute_input":"2021-09-21T09:36:45.026048Z","iopub.status.idle":"2021-09-21T09:36:45.04453Z","shell.execute_reply.started":"2021-09-21T09:36:45.025997Z","shell.execute_reply":"2021-09-21T09:36:45.043387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploting ROC curves\nplt.subplots(1, figsize=(10,10))\nplt.title('Receiver Operating Characteristic - RandomForest')\nplt.plot([0, 1], ls=\"--\")\nplt.plot(false_positive_rate1, true_positive_rate1)\n\n#plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:45.046247Z","iopub.execute_input":"2021-09-21T09:36:45.046781Z","iopub.status.idle":"2021-09-21T09:36:45.32042Z","shell.execute_reply.started":"2021-09-21T09:36:45.04674Z","shell.execute_reply":"2021-09-21T09:36:45.319566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" print('roc_auc_score for Random Forest: ', roc_auc_score(y_test, y_score1))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:36:45.322244Z","iopub.execute_input":"2021-09-21T09:36:45.322556Z","iopub.status.idle":"2021-09-21T09:36:45.330307Z","shell.execute_reply.started":"2021-09-21T09:36:45.322516Z","shell.execute_reply":"2021-09-21T09:36:45.329494Z"},"trusted":true},"execution_count":null,"outputs":[]}]}