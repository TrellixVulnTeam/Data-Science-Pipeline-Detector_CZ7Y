{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Contents<a id=\"0\"></a>\n\n- [1. Abstract](#1)\n- [2. Modules](#2)\n- [3. Load Data](#3)\n  - [3.1 Pandas](#3.1)\n  - [3.2 Datatable](#3.2)\n  - [3.3 Statistics](#3.3)\n- [4. Preprocessing](#4)\n  - [4.1 Missing values](#4.1)\n  - [4.2 Standardization](#4.2)\n- [5. Cross Validation (K-Fold)](#5)\n  - [5.1 Numpy](#5.1)\n  - [5.2 Scikit Learn](#5.2)\n    - [5.2.1 train_test_split](#5.2.1)\n    - [5.2.2 K-Fold](#5.2.2)\n    - [5.2.3 StratifiedKFold](#5.2.3)\n    - [5.2.4 ShuffleSplit](#5.2.4)\n- [6. Modeling](#6)\n  - [6.1 LightGBM](#6.1)\n  - [6.2 CatBoost](#6.1)\n  - [6.3 XGBoost](#6.3)\n  - [6.4 Boosters with cross validation](#6.4)\n- [7. Hyperparameter](#7)\n  - [7.1 Optuna for LightGBM](#7.1)\n  - [7.2 Optuna for CatBoost](#7.2)\n  - [7.3 Optuna for XGBoost](#7.3)\n- [8. Quality of predictions](#8)\n- [9. Submission](#9)","metadata":{"_uuid":"47598866-e9ef-4109-b24a-ce1c5426405d","_cell_guid":"cce51632-ee35-4a4b-9541-89f11de08740","trusted":true}},{"cell_type":"markdown","source":"# 1. Abstract<a id=\"1\"></a>\n\nThese are my personal notes that I need each time when I run a machine learning model. I would like to share them with you and I hope it can be useful for you, even if it is a small help. I will try to update these notes over time.","metadata":{"_uuid":"8027e381-4d42-4749-8de5-dd6145577d13","_cell_guid":"9eedcea2-29f5-4736-b045-0c03958d6544","trusted":true}},{"cell_type":"markdown","source":"# 2. Modules<a id=\"2\"></a>","metadata":{"_uuid":"2f593ef6-bad0-4ba5-916a-1087c73b182c","_cell_guid":"8d072b03-66a9-46a2-ad62-61d1fde615b0","trusted":true}},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\nimport warnings\n\n# Scikit-learn\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import *\n\n# Boosters\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\n# Hyperparameter \nimport optuna\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\n\nDEMO=True\n\n# pd.set_option(\"max_rows\" , None)\n# pd.set_option(\"display.float_format\", lambda x: \"%.4f\" % x)\n# warnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"94bc5da5-cd54-4879-b3a4-2fc870e7be57","_cell_guid":"5ce9c9e2-807f-4053-aaca-1eaa0626b3ec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:53:28.569774Z","iopub.execute_input":"2021-09-28T14:53:28.570901Z","iopub.status.idle":"2021-09-28T14:53:30.728033Z","shell.execute_reply.started":"2021-09-28T14:53:28.570758Z","shell.execute_reply":"2021-09-28T14:53:30.72675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Load Data<a id=\"3\"></a>\n\nIt seems that Pandas load data slowly. One alternative is to use `datatable` and convert theme to `Pandas`. [Link](https://www.kaggle.com/bextuychiev/how-to-work-w-million-row-datasets-like-a-pro#Read-in-the-massive-dataset)","metadata":{"_uuid":"7c2deb75-7be3-4752-b7fd-39278de2b1c5","_cell_guid":"09cd5183-8ae3-4063-abb7-106fd4968958","trusted":true}},{"cell_type":"markdown","source":"## 3.1 Pandas<a id=\"3.1\"></a>","metadata":{"_uuid":"3f75b7e6-8921-40ea-91ba-77b86ecfb676","_cell_guid":"fdebd355-85f3-46c7-ab47-7d47d32d96c1","trusted":true}},{"cell_type":"code","source":"%%time\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"_uuid":"f13c70cb-9a45-4db4-b2d1-03487c80ccbb","_cell_guid":"1e53470b-31cb-4b1b-a170-75adbf8e97e9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:53:30.731554Z","iopub.execute_input":"2021-09-28T14:53:30.732234Z","iopub.status.idle":"2021-09-28T14:53:58.586478Z","shell.execute_reply.started":"2021-09-28T14:53:30.732192Z","shell.execute_reply":"2021-09-28T14:53:58.585213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (PRO) The id column disrupts the training so delete it\nif not DEMO:\n    train = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv').drop(columns=['id'])\n\n    train = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv', index_col=0)","metadata":{"_uuid":"f4dc7486-d4a9-442f-9020-70bca7b5d123","_cell_guid":"8f807592-a994-4b4f-8f12-70c1fa126d15","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:53:58.588036Z","iopub.execute_input":"2021-09-28T14:53:58.588734Z","iopub.status.idle":"2021-09-28T14:53:58.595618Z","shell.execute_reply.started":"2021-09-28T14:53:58.588685Z","shell.execute_reply":"2021-09-28T14:53:58.594149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Datatable<a id=\"3.2\"></a>\n\nTo learn more about Datatable [see this kaggle code](https://www.kaggle.com/sudalairajkumar/getting-started-with-python-datatable). Datatable `fread` documentation [is here](https://datatable.readthedocs.io/en/latest/api/dt/fread.html)","metadata":{"_uuid":"482bf80d-5f89-4846-8f60-2c60ef2cf314","_cell_guid":"b01a66c0-3e9d-4b9b-9d31-37d8838d2c95","trusted":true}},{"cell_type":"code","source":"%%time\ntrain = dt.fread(\"/kaggle/input/tabular-playground-series-sep-2021/train.csv\").to_pandas().drop(columns=['id'])\ntest = dt.fread(\"/kaggle/input/tabular-playground-series-sep-2021/test.csv\").to_pandas()\nsubmission = dt.fread('/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv').to_pandas()","metadata":{"_uuid":"f6832102-a09c-4fa5-8231-4ae318655932","_cell_guid":"dca07c91-0319-4b94-95ae-d0262d22c7b1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:53:58.597667Z","iopub.execute_input":"2021-09-28T14:53:58.598255Z","iopub.status.idle":"2021-09-28T14:54:04.700912Z","shell.execute_reply.started":"2021-09-28T14:53:58.598178Z","shell.execute_reply":"2021-09-28T14:54:04.699878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (PRO)\nif not DEMO:\n    train =dt.fread(\"/kaggle/input/tabular-playground-series-sep-2021/train.csv\", columns=lambda cols:[col.name not in (\"id\") for col in cols]).to_pandas()","metadata":{"_uuid":"56d2cb78-b8e4-413d-a087-6566ee01cb03","_cell_guid":"5227e5ad-6503-4df8-b2e9-be3494424f1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:04.703739Z","iopub.execute_input":"2021-09-28T14:54:04.70401Z","iopub.status.idle":"2021-09-28T14:54:04.711263Z","shell.execute_reply.started":"2021-09-28T14:54:04.703984Z","shell.execute_reply":"2021-09-28T14:54:04.708889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Statistics<a id=\"3.3\"></a>\n\nDisplay head of DataFrame is not normally legible. so we [transpose](https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/api/pandas.DataFrame.T.html) it.","metadata":{"_uuid":"193360d7-f57f-431a-959e-999f51c07d4c","_cell_guid":"2caa3871-67f0-4c33-bbcd-9d3047057da8","trusted":true}},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"88be6685-3bca-4031-a264-3ec1545a3b06","_cell_guid":"4f78b374-e710-4970-85d5-f70a71346ab7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:04.713136Z","iopub.execute_input":"2021-09-28T14:54:04.713453Z","iopub.status.idle":"2021-09-28T14:54:04.800213Z","shell.execute_reply.started":"2021-09-28T14:54:04.713396Z","shell.execute_reply":"2021-09-28T14:54:04.799248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (PRO)\ntrain.head().T","metadata":{"_uuid":"9bd0183f-69d9-4371-a086-c5e634a3382e","_cell_guid":"df04ba32-a22c-4d54-bb81-ad875ceda6bd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:04.801798Z","iopub.execute_input":"2021-09-28T14:54:04.802189Z","iopub.status.idle":"2021-09-28T14:54:04.838404Z","shell.execute_reply.started":"2021-09-28T14:54:04.802146Z","shell.execute_reply":"2021-09-28T14:54:04.837035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can't view all the columns and datatypes when we want print a concise summary of a DataFrame, we use `verbose` as argument to solve this problem","metadata":{"_uuid":"2554cc5d-ec0f-4b83-ab7d-ee8b0d1dec6a","_cell_guid":"14ebe1ae-a5a8-4de7-90db-e219ddd04a0d","trusted":true}},{"cell_type":"code","source":"train.info()","metadata":{"_uuid":"24776137-a357-4997-8108-4875894fce13","_cell_guid":"210f7d90-4aad-4c74-bc4a-40f8cd80c7df","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:04.840213Z","iopub.execute_input":"2021-09-28T14:54:04.841583Z","iopub.status.idle":"2021-09-28T14:54:04.864403Z","shell.execute_reply.started":"2021-09-28T14:54:04.841491Z","shell.execute_reply":"2021-09-28T14:54:04.862887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (PRO)\ntrain.info(verbose=True)","metadata":{"_uuid":"88d2ba41-bb65-4f62-9e9a-a01fd4c00bf3","_cell_guid":"3ffdc8cc-3323-48f9-8e56-c409e9c32c4e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:04.866025Z","iopub.execute_input":"2021-09-28T14:54:04.866699Z","iopub.status.idle":"2021-09-28T14:54:04.887127Z","shell.execute_reply.started":"2021-09-28T14:54:04.866656Z","shell.execute_reply":"2021-09-28T14:54:04.886008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It semble [transpose](https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/api/pandas.DataFrame.T.html) is good idea to show any other methods of DataFrame.","metadata":{"_uuid":"144cbded-4b10-4d39-b951-7cf6c8fe37aa","_cell_guid":"b94139d5-43e1-46f9-8484-0d60852e53cb","trusted":true}},{"cell_type":"code","source":"# (PRO)\ntrain.describe().T","metadata":{"_uuid":"0e06d813-ea70-4d38-b4fe-6330cd743eb7","_cell_guid":"53206d48-bb6d-41eb-b432-a92dca02b865","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:04.888288Z","iopub.execute_input":"2021-09-28T14:54:04.888691Z","iopub.status.idle":"2021-09-28T14:54:09.221034Z","shell.execute_reply.started":"2021-09-28T14:54:04.888656Z","shell.execute_reply":"2021-09-28T14:54:09.219939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (PRO)\ntrain.sample(4).T","metadata":{"_uuid":"607b932c-4989-4023-b4c4-63d15870a685","_cell_guid":"ca64719d-ba2b-42c1-a8cc-3dd52b8d875c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:09.223021Z","iopub.execute_input":"2021-09-28T14:54:09.223691Z","iopub.status.idle":"2021-09-28T14:54:09.277867Z","shell.execute_reply.started":"2021-09-28T14:54:09.223649Z","shell.execute_reply":"2021-09-28T14:54:09.276685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Preprocessing","metadata":{"_uuid":"7de9f274-64c6-483a-b70a-a01d3e3fa025","_cell_guid":"fbf1a3a2-380e-4a1d-a56f-1354a361d9c7","trusted":true}},{"cell_type":"markdown","source":"## 4.1 Missing values\n\nThese are the methods that can be used to fill in the null values or delete them","metadata":{"_uuid":"ae9c5b91-323f-4eb3-b373-aedf78e6b7ff","_cell_guid":"ea1ec186-b400-4bd4-b2a9-5d0f4af11044","trusted":true}},{"cell_type":"markdown","source":"### 4.1.1 Pandas<a id=\"4.1.1\"></a>","metadata":{"_uuid":"2be40ac1-978a-4885-9d13-51c0f6efd9cf","_cell_guid":"98357cf1-8f4f-439a-af75-c6432a38ebdd","trusted":true}},{"cell_type":"code","source":"train = train.fillna(0) # replace with 0\ntrain = train.fillna(train.mean()) # replace missing values using the mean along each column\ntrain = train.fillna(train.min()) # replace with the minimum value of each column \ntrain = train.fillna(train.max()) # replace with the maximum value of each column \ntrain = train.dropna()","metadata":{"_uuid":"46e5b977-b6e3-4053-a7fa-8e9b19afddeb","_cell_guid":"b4007d2a-6241-4cb7-b9da-76b941283b2b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:09.27977Z","iopub.execute_input":"2021-09-28T14:54:09.280158Z","iopub.status.idle":"2021-09-28T14:54:12.578656Z","shell.execute_reply.started":"2021-09-28T14:54:09.280115Z","shell.execute_reply":"2021-09-28T14:54:12.577579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.2 Scikit Learn<a id=\"4.1.2\"></a>","metadata":{"_uuid":"f1dd1191-8f20-4268-aa33-628280b0502d","_cell_guid":"c39b7827-e1dd-4873-b978-58dd1b4f5ba3","trusted":true}},{"cell_type":"code","source":"if not DEMO:\n    impute = SimpleImputer()\n    # Separate\n    impute.fit(train)\n    train = impute.transform(train)\n\n    # Together\n    train = impute.fit_transform(train)","metadata":{"_uuid":"5dfc084f-a3ea-4e67-aef5-98d976b5548b","_cell_guid":"16797223-2755-4826-9bde-a87aeef744ec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:22.981351Z","iopub.execute_input":"2021-09-28T14:54:22.981742Z","iopub.status.idle":"2021-09-28T14:54:22.987988Z","shell.execute_reply.started":"2021-09-28T14:54:22.981712Z","shell.execute_reply":"2021-09-28T14:54:22.986574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-danger\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"32\" height=\"32\" viewBox=\"0 0 32 32\">\n  <path d=\"M8.982 1.566a1.13 1.13 0 0 0-1.96 0L.165 13.233c-.457.778.091 1.767.98 1.767h13.713c.889 0 1.438-.99.98-1.767L8.982 1.566zM8 5c.535 0 .954.462.9.995l-.35 3.507a.552.552 0 0 1-1.1 0L7.1 5.995A.905.905 0 0 1 8 5zm.002 6a1 1 0 1 1 0 2 1 1 0 0 1 0-2z\"/>\n</svg>\n<b style=\"font-size: x-large;\">ATTENTION</b><br>\n    A good and accurate way to get lost data is <code>KNNImputer</code> but this operation is takes very time because Scikit learn does not support GPUs. No library has been created for KNNImputer class with GPU yet.\n</div>","metadata":{"_uuid":"20c2134f-1ff3-4b4e-a582-79a1c48531a1","_cell_guid":"9997fd88-9f34-46b4-98c2-577c120de659","trusted":true}},{"cell_type":"code","source":"if not DEMO:\n    impute = KNNImputer()\n    # Separate\n    impute.fit(train)\n    train = impute.transform(train)\n\n    # Together\n    train = impute.fit_transform(train)","metadata":{"_uuid":"950785dc-8010-4915-8744-a8fee3cd303f","_cell_guid":"8fadd4e8-2354-4a8d-b905-8f69d67b873f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:25.158192Z","iopub.execute_input":"2021-09-28T14:54:25.158535Z","iopub.status.idle":"2021-09-28T14:54:25.164721Z","shell.execute_reply.started":"2021-09-28T14:54:25.158504Z","shell.execute_reply":"2021-09-28T14:54:25.163217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.3 capability to handle missing\nSome models that have capability to handle missing value by default are:\n\n- XGBoost: [https://xgboost.readthedocs.io/en/latest/faq.html](https://xgboost.readthedocs.io/en/latest/faq.html)\n- LightGBM: [https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html)\n- Catboost: [https://catboost.ai/docs/concepts/algorithm-missing-values-processing.html](https://catboost.ai/docs/concepts/algorithm-missing-values-processing.html)","metadata":{"_uuid":"0756d2a5-e64c-4713-8556-62ce3bd8f6d6","_cell_guid":"e237cb7f-ea4d-4b89-b1ec-8470e30ce109","trusted":true}},{"cell_type":"markdown","source":"## 4.2 Standardization<a id=\"4.2\"></a>\n\nThe `StandardScaler` method uses the following formula\n\n![StandardScaler](https://raw.githubusercontent.com/akmeghdad/data-science-note/master/src/images/StandardScaler-formula.jpg)","metadata":{"_uuid":"e385e5c8-0979-401c-9ec9-b699e19d2b01","_cell_guid":"dc2a7d0b-f7e8-48e5-80bf-82979f11defb","trusted":true}},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\nz = StandardScaler()\n\n# Separate\nz.fit(train)\ntrain_z = z.transform(train)\n\n# Together\ntrain_z = z.fit_transform(train)","metadata":{"_uuid":"e2d15261-4fcd-4c52-b77d-08eee284902d","_cell_guid":"a269412c-7c77-4716-8b76-25ecc5ec11f4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:54:29.868801Z","iopub.execute_input":"2021-09-28T14:54:29.869099Z","iopub.status.idle":"2021-09-28T14:55:57.30028Z","shell.execute_reply.started":"2021-09-28T14:54:29.869069Z","shell.execute_reply":"2021-09-28T14:55:57.298592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `QuantileTransformer` method seems to be better. [link](https://www.kaggle.com/melanie7744/tps9-how-to-transform-your-data)","metadata":{"_uuid":"f4214115-f1e5-4d97-bf9f-17a88327210f","_cell_guid":"bd3dfc60-d04a-496a-bdaf-6ee493aeae94","trusted":true}},{"cell_type":"code","source":"# from sklearn.preprocessing import QuantileTransformer\nif not DEMO:\n    qt = QuantileTransformer(output_distribution = 'normal')\n    \n    # Separate\n    qt.fit(train.iloc[:,:-1])\n    train_qt = qt.transform(train.iloc[:,:-1])\n    test_qt = qt.transform(test)\n\n    # Together\n    train_qt = qt.fit_transform(train.iloc[:,:-1])\n    test_qt = qt.transform(test)","metadata":{"_uuid":"cc28880d-0116-4379-a56a-b109df063285","_cell_guid":"57ae2831-bc49-467f-bdba-843ae225a4e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:55:57.305103Z","iopub.execute_input":"2021-09-28T14:55:57.306233Z","iopub.status.idle":"2021-09-28T14:55:57.316896Z","shell.execute_reply.started":"2021-09-28T14:55:57.306188Z","shell.execute_reply":"2021-09-28T14:55:57.31561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Cross Validation (K-Fold)<a id=\"5\"></a>\n\nThere are several ways to split data. In the following, we consider the number of parts equal to 4. We put 25% of the data for testing and 75% for training.","metadata":{"_uuid":"b9766274-7215-4e7a-9cbd-e165001a9564","_cell_guid":"e8bcfc0e-b70d-4029-8d91-382b82327926","trusted":true}},{"cell_type":"code","source":"n_splits = 4\ny = train['claim']\nX = train.drop(columns=['claim'])","metadata":{"_uuid":"b3aa6a2e-c6b9-440b-8128-882b05a731d3","_cell_guid":"28bb9484-87f8-4307-8930-e733a91c1e6c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:55:57.318572Z","iopub.execute_input":"2021-09-28T14:55:57.319285Z","iopub.status.idle":"2021-09-28T14:55:57.692059Z","shell.execute_reply.started":"2021-09-28T14:55:57.319163Z","shell.execute_reply":"2021-09-28T14:55:57.691006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.1 Numpy<a id=\"5.1\"></a>","metadata":{"_uuid":"785b5295-5789-41ba-8be0-f6a4fc68f769","_cell_guid":"ca564f1c-6d7d-4f14-a0ad-14bc91f9dc23","trusted":true}},{"cell_type":"code","source":"X_test, X_train = np.split(X, [train.shape[0] // n_splits])\ny_test, y_train = np.split(y, [train.shape[0] // n_splits])","metadata":{"_uuid":"78c0e693-4bcf-4a70-af2a-98a2975a1e9d","_cell_guid":"04ead3cc-9a61-48c9-8a49-994b86f386a2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:55:57.69461Z","iopub.execute_input":"2021-09-28T14:55:57.695165Z","iopub.status.idle":"2021-09-28T14:55:58.395941Z","shell.execute_reply.started":"2021-09-28T14:55:57.695091Z","shell.execute_reply":"2021-09-28T14:55:58.394966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f' X_train.shape: {X_train.shape} \\n X_test.shape: {X_test.shape} \\n y_train.shape: {y_train.shape} \\n y_test.shape: {y_test.shape}')","metadata":{"_uuid":"abd50675-e3bc-4c7f-bb28-42f23b412539","_cell_guid":"c57831bf-fc66-4b03-9b8c-3e9eba605c9d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:55:58.3977Z","iopub.execute_input":"2021-09-28T14:55:58.398045Z","iopub.status.idle":"2021-09-28T14:55:58.405534Z","shell.execute_reply.started":"2021-09-28T14:55:58.398005Z","shell.execute_reply":"2021-09-28T14:55:58.404296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For better results, we can `shuffle` the data","metadata":{"_uuid":"949ae92e-87b1-487e-b548-1313030a05e2","_cell_guid":"cacaab2e-6e1a-4583-bede-218780365786","trusted":true}},{"cell_type":"code","source":"train = train.sample(frac=1).reset_index(drop=True)\ny = train['claim']\nX = train.drop(columns=['claim'])","metadata":{"_uuid":"ad9f7f16-f9b9-4008-8fa0-bf069c96cd8b","_cell_guid":"9f582b9b-d296-453e-96b3-2584151b8063","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:55:58.407111Z","iopub.execute_input":"2021-09-28T14:55:58.407975Z","iopub.status.idle":"2021-09-28T14:56:00.011076Z","shell.execute_reply.started":"2021-09-28T14:55:58.407936Z","shell.execute_reply":"2021-09-28T14:56:00.010081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Scikit Learn<a id=\"5.2\"></a>\n\nThe above two operations are performed in different ways\n\n### 5.2.1 train_test_split<a id=\"5.2.1\"></a>","metadata":{"_uuid":"1b4f0d53-cd54-4268-8550-84842b81f0f3","_cell_guid":"a04f598b-4a90-4d8f-a824-2eea0beafbb1","trusted":true}},{"cell_type":"code","source":"%%time\n# from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 / n_splits), random_state=59, shuffle=True)\nprint(f' X_train.shape: {X_train.shape} \\n X_test.shape: {X_test.shape} \\n y_train.shape: {y_train.shape} \\n y_test.shape: {y_test.shape}')","metadata":{"_uuid":"bf575c31-e39c-4d10-be50-3437d167dbb9","_cell_guid":"fc338fb2-ff0b-4e28-a09c-7a20e012cbc9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:56:45.845989Z","iopub.execute_input":"2021-09-28T14:56:45.84633Z","iopub.status.idle":"2021-09-28T14:56:46.902958Z","shell.execute_reply.started":"2021-09-28T14:56:45.846294Z","shell.execute_reply":"2021-09-28T14:56:46.901941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.2 K-Fold<a id=\"5.2.2\"></a>\n\nIn the following three methods, the splitting operation is repeated `n_splits` times.","metadata":{"_uuid":"2d58893e-e383-43e9-a695-1e6e0c97e578","_cell_guid":"dd36ce5b-7846-42a9-abe7-ae2f8efdb6df","trusted":true}},{"cell_type":"code","source":"%%time\n# from sklearn.model_selection import KFold\n\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=59)\n\nfor fold, (train_index, test_index) in enumerate(kf.split(X=X)):\n    X_train = X.iloc[train_index]\n    X_test = X.iloc[test_index]\n    y_train = y.iloc[train_index]\n    y_test = y.iloc[test_index]\n\n    print(f'\\n===== fold {fold} ====\\n X_train.shape: {X_train.shape} \\n X_test.shape: {X_test.shape} \\n y_train.shape: {y_train.shape} \\n y_test.shape: {y_test.shape}')","metadata":{"_uuid":"8281adca-ab10-4906-8c86-0f4c5b2cea3b","_cell_guid":"50164181-3a26-4fb3-9075-b960449ed416","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:57:05.593829Z","iopub.execute_input":"2021-09-28T14:57:05.594096Z","iopub.status.idle":"2021-09-28T14:57:07.672526Z","shell.execute_reply.started":"2021-09-28T14:57:05.594069Z","shell.execute_reply":"2021-09-28T14:57:07.671557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.3 StratifiedKFold<a id=\"5.2.3\"></a>","metadata":{"_uuid":"13d801c7-2e77-4e7f-9881-7119e28f3f0e","_cell_guid":"0280e3b5-968f-4782-af86-80c9d39e7cea","trusted":true}},{"cell_type":"code","source":"%%time\n# from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=59) \n\nfor train_index, test_index in skf.split(X=X, y=y):\n    X_train = X.iloc[train_index]\n    X_test = X.iloc[test_index]\n    y_train = y.iloc[train_index]\n    y_test = y.iloc[test_index]\n\n    print(f' X_train.shape: {X_train.shape} \\n X_test.shape: {X_test.shape} \\n y_train.shape: {y_train.shape} \\n y_test.shape: {y_test.shape}')","metadata":{"_uuid":"dcefb36a-3f2d-4a3c-86ce-7e592d252366","_cell_guid":"6358bd4c-1454-43f2-a6d1-6b2b13ee391d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:57:15.846871Z","iopub.execute_input":"2021-09-28T14:57:15.847675Z","iopub.status.idle":"2021-09-28T14:57:17.985959Z","shell.execute_reply.started":"2021-09-28T14:57:15.847643Z","shell.execute_reply":"2021-09-28T14:57:17.98487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.4 ShuffleSplit<a id=\"5.2.4\"></a>","metadata":{"_uuid":"b65e4b74-b74d-41cb-9576-cf7aec04cb66","_cell_guid":"b09c48e0-1185-423e-885f-f3ad860eeda1","trusted":true}},{"cell_type":"code","source":"%%time\n# from sklearn.model_selection import ShuffleSplit\n\nshs = ShuffleSplit(n_splits=n_splits, random_state=59)\n\nfor fold, (train_index, test_index) in enumerate(shs.split(X=X)):\n    X_train = X.iloc[train_index]\n    X_test = X.iloc[test_index]\n    y_train = y.iloc[train_index]\n    y_test = y.iloc[test_index]\n    \n    print(f'\\n===== fold {fold} ====\\n X_train.shape: {X_train.shape} \\n X_test.shape: {X_test.shape} \\n y_train.shape: {y_train.shape} \\n y_test.shape: {y_test.shape}')","metadata":{"_uuid":"b6b9816e-e794-4a4a-b9e7-16350cef1d50","_cell_guid":"52ab85b2-1e80-4047-94d8-d9fa6fbe34e0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-28T14:57:30.989341Z","iopub.execute_input":"2021-09-28T14:57:30.989692Z","iopub.status.idle":"2021-09-28T14:57:35.25248Z","shell.execute_reply.started":"2021-09-28T14:57:30.989662Z","shell.execute_reply":"2021-09-28T14:57:35.25126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The difference between the three methods: [(see here for more info)](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html)\n\n![kfold-StratifiedKFold](https://raw.githubusercontent.com/akmeghdad/data-science-note/master/src/images/model-selection-3-models-kfold.jpg)","metadata":{"_uuid":"6c6265bb-d2de-4c90-814f-c7c397943e78","_cell_guid":"ae53eaea-1278-4f9a-a18f-85029fc6dc4c","trusted":true}},{"cell_type":"markdown","source":"# 6 Modeling<a id=\"6\"></a>\n\nLightGBM, CatBoost and XGBoost are known as new ways to build models. Parameter settings are very important in these three methods. Only the basic parameters are listed here. \n\n## 6.1 LightGBM<a id='6.1'></a>\nOfficial documentations for parameters:\n- [https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n- [https://github.com/microsoft/LightGBM/blob/master/docs/Parameters.rst](https://github.com/microsoft/LightGBM/blob/master/docs/Parameters.rst)","metadata":{"_uuid":"a4994cfb-48c9-4663-8cbe-75c0b1cee5c1","_cell_guid":"cd1d65ef-24c7-4733-b279-39456e33f984","trusted":true}},{"cell_type":"code","source":"# from lightgbm import LGBMClassifier\nparameters = {\n    'objective' : 'binary',\n    'metric' : 'auc',\n    'device' : 'gpu'\n}\nmodel = LGBMClassifier(**parameters)\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_test, y_test)],\n    verbose=False\n    )\ny_predicted = model.predict_proba(X_test)","metadata":{"_uuid":"5a445934-4c1c-41ea-bfff-74036090dedd","_cell_guid":"56b285dd-36ed-4fc7-b6d9-9958f3728f76","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2 CatBoost<a id=\"6.2\"></a>\nOfficial documentation for parameters:\n- [https://catboost.ai/docs/concepts/python-reference_parameters-list.html#python-reference_parameters-list](https://catboost.ai/docs/concepts/python-reference_parameters-list.html#python-reference_parameters-list)","metadata":{"_uuid":"a42ef596-189f-457d-bad9-49434e5a644b","_cell_guid":"724ddb1c-3351-4bdd-9ede-d970e94c87b8","trusted":true}},{"cell_type":"code","source":"# from catboost import CatBoostClassifier\nparameters = {\n    'objective' : 'Logloss',\n    'eval_metric' : 'AUC',\n    'task_type' : 'GPU'\n}\n\nmodel = CatBoostClassifier(**parameters)\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_test, y_test)],\n    verbose=False\n    )\ny_predicted = model.predict_proba(X_test)","metadata":{"_uuid":"e14044eb-63f0-4115-836e-852fa750b6a6","_cell_guid":"a19fa7a7-09a5-4394-bad7-bc1e1721b1a9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.3 XGBoost<a id=\"6.3\"></a>\nOfficial documentation for parameters:\n- [https://xgboost.readthedocs.io/en/latest/parameter.html](https://xgboost.readthedocs.io/en/latest/parameter.html)","metadata":{"_uuid":"6eb88f40-84b5-4a3e-ac05-cd3547afe7fe","_cell_guid":"f14fdec5-cd7c-4365-8c53-8998557e4545","trusted":true}},{"cell_type":"code","source":"# from xgboost import XGBClassifier\nparameters = {\n    'objective': 'binary:logistic',\n    'eval_metric' : 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor'\n}\n\nmodel = XGBClassifier(**parameters)\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_test, y_test)],\n    verbose=False\n    )\ny_predicted = model.predict_proba(X_test)","metadata":{"_uuid":"6b12d361-4bf2-446e-a545-5144c6cdb519","_cell_guid":"5c2aed11-d992-4aec-870b-78e8230e778e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.4 Boosters with cross validation<a id=\"6.4\"></a>","metadata":{"_uuid":"b8e72e8a-d7f4-4b37-be19-018865bd33ea","_cell_guid":"2cf55504-8891-41ab-90c2-521141e27ec5","trusted":true}},{"cell_type":"code","source":"parameters = {\n    'objective': 'binary:logistic',\n    'eval_metric' : 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor'\n}\nmodel = XGBClassifier(**parameters)\n\nshs = ShuffleSplit(n_splits=n_splits, random_state=59)\n\nfor fold, (train_index, test_index) in enumerate(shs.split(X=X)):\n    X_train = X.iloc[train_index]\n    X_test  = X.iloc[test_index]\n    y_train = y.iloc[train_index]\n    y_test  = y.iloc[test_index]\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        verbose=False\n    )\n    y_predicted = model.predict(X_test)\n    \n    # print(f'fold: {fold} |  Score: {get_score_1(y_test, y_predicted)} \\n')","metadata":{"_uuid":"76dc10a7-e1e1-4c38-ab2b-c314885d74dc","_cell_guid":"8de6e65f-4f51-4fb3-9732-d66c46ff8aa1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Hyperparameter <a id=\"7\"></a>\nAs I said, parameters are very important in LightGBM, CatBoost and XGBoost methods. Optuna is one of the automatic hyperparameter optimization software framework.\n- [https://optuna.org](https://optuna.org)\n- [https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html)\n\n## 7.1 Optuna for LightGBM<a id=\"7.1\"></a>\n- [https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_simple.py](https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_simple.py)","metadata":{"_uuid":"5d201c15-435d-4bd1-8685-e64c4af4e322","_cell_guid":"bbb96deb-000e-4057-8cee-145ac7de0d6c","trusted":true}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 / n_splits), random_state=59, shuffle=True)","metadata":{"_uuid":"8514dded-5981-46d0-80d8-35efcb1f1b60","_cell_guid":"c6952061-945d-4007-a0be-ef5a801771b2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lgbm_objective(trial):\n    parameters = {\n        \"device\" : \"gpu\",\n        \"objective\": \"binary\",\n        \"metric\": \"binary_logloss\",\n        \"verbosity\": -1, # < 0: Fatal, = 0: Error (Warning), = 1: Info, > 1: Debug\n        \"boosting_type\": \"gbdt\", # gbdt, rf, dart, goss\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),# 0.1<-<1.0\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),# 0.1<-<1.0\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    \n    model = LGBMClassifier(**parameters)\n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)]\n        )\n    y_predicted = model.predict_proba(X_test)\n    \n    return roc_auc_score(y_test, y_predicted)","metadata":{"_uuid":"d2aeeea5-634b-4ce9-8578-4813aac70cbb","_cell_guid":"08504d13-a6ca-4798-988e-872f0ee75973","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\nlgbm_study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\nlgbm_study.optimize(lgbm_objective, n_trials=100)\n\nprint(\"Number of finished trials: {}\".format(len(lgbm_study.trials)))\n\nprint(\"Best trial for LGBM:\")\ntrial = lgbm_study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"_uuid":"eca485c4-0cad-4a24-8e74-0912f18de129","_cell_guid":"cd27636e-b54a-4875-a69a-d0f18debbc15","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.2 Optuna for CatBoost<a id=\"7.2\"></a>\n- [https://github.com/optuna/optuna-examples/blob/main/catboost/catboost_simple.py](https://github.com/optuna/optuna-examples/blob/main/catboost/catboost_simple.py)","metadata":{"_uuid":"0b5ca4a0-e264-47a4-825d-61859cc2b62b","_cell_guid":"bf4dd08f-d918-4e10-a646-fbe2b605047d","trusted":true}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 / n_splits), random_state=59, shuffle=True)","metadata":{"_uuid":"c41b10f6-9758-475c-8eff-ebed6cb7355a","_cell_guid":"f26fc0da-4b06-4b8b-94b3-29b450bde98e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def catboost_objective(trial):\n    parameters = {\n            \"eval_metric\" : \"AUC\",\n            \"task_type\" : \"GPU\",\n            \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n            \"depth\": trial.suggest_int(\"depth\", 1, 12),\n            \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n            \"bootstrap_type\": trial.suggest_categorical(\n                \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n            )\n        }\n\n    if parameters[\"bootstrap_type\"] == \"Bayesian\":\n        parameters[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n    elif parameters[\"bootstrap_type\"] == \"Bernoulli\":\n        parameters[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n        \n    model = CatBoostClassifier(**parameters)\n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        verbose=False,\n        early_stopping_rounds=100\n        )\n    y_predicted = model.predict_proba(X_test)\n    \n    return roc_auc_score(y_test, y_predicted)","metadata":{"_uuid":"ffa2cd15-2fef-4889-95d0-5a75fd9f1b68","_cell_guid":"10a9ee80-7ac1-4da1-85ff-175396057825","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\ncatboost_study = optuna.create_study(direction=\"maximize\", study_name=\"CatBoost Classifier\")\ncatboost_study.optimize(catboost_objective, n_trials=100)\n\nprint(\"Number of finished trials: {}\".format(len(catboost_study.trials)))\n\nprint(\"Best trial for CatBoost:\")\ntrial = catboost_study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"_uuid":"b1c158c8-29db-44e7-8724-d94806e1e27b","_cell_guid":"189ab458-5167-49ab-a434-f861800b68b9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.3 Optuna for XGBoost<a id=\"7.3\"></a>\n- [https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_simple.py](https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_simple.py)","metadata":{"_uuid":"99b282f0-4506-4cd7-8baa-c11d1be4aa24","_cell_guid":"208bb3ca-56ce-4266-acd9-d3e534affc19","trusted":true}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 / n_splits), random_state=59, shuffle=True)","metadata":{"_uuid":"7c55beda-5103-493e-a0fd-94d15ad4db1c","_cell_guid":"7d4f8b1d-fa6e-494f-b52b-d08ec44cb4f0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xgboost_objective(trial):\n    parameters = {\n        \"verbosity\": 0,\n        \"objective\": \"binary:logistic\",\n        \"predictor\": \"gpu_predictor\",\n        \"eval_metric\" : \"auc\",\n        # use exact for small dataset.\n        \"tree_method\": \"gpu_hist\",\n        # defines booster, gblinear for linear functions.\n        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n        # L2 regularization weight.\n        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n        # L1 regularization weight.\n        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n        # sampling ratio for training data.\n        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n        # sampling according to each tree.\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n    }\n\n    # maximum depth of the tree, signifies complexity of the tree.\n    parameters[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n    # minimum child weight, larger the term more conservative the tree.\n    parameters[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n    parameters[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n    # defines how selective algorithm is.\n    parameters[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n    parameters[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n\n    model = XGBClassifier(**parameters)\n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        verbose=False,\n        )\n    y_predicted = model.predict_proba(X_test)\n    \n    return roc_auc_score(y_test, y_predicted)","metadata":{"_uuid":"f6196bf3-15ea-48a4-b703-887b5ed19c90","_cell_guid":"02362da2-a8e9-40e0-ae6f-8f2e1464f299","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\nxgboost_study = optuna.create_study(direction=\"maximize\", study_name=\"XGBoost Classifier\")\nxgboost_study.optimize(xgboost_objective, n_trials=100)\n\nprint(\"Number of finished trials: {}\".format(len(xgboost_study.trials)))\n\nprint(\"Best trial for XGBoost:\")\ntrial = xgboost_study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"_uuid":"7765f9c1-39e5-479e-94e0-5ebe9add544d","_cell_guid":"1762e7de-4eb1-4043-9317-25ae3a04a0f0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Quality of predictions<a id=\"8\"></a>","metadata":{"_uuid":"5fba84a1-ba5b-4948-adcb-b835b40d7c13","_cell_guid":"57d34894-ad68-4f97-a045-5c807eb561b1","trusted":true}},{"cell_type":"code","source":"# from sklearn.metrics import *\ndef get_score_1(y_test, y_predicted):\n    fpr, tpr, _ = roc_curve(y_test, y_predicted[:, 1])\n    return auc(fpr, tpr)","metadata":{"_uuid":"4772e756-e5c2-4da4-a148-2a02e7c2bdf2","_cell_guid":"8c38e13d-2852-47c4-9dcd-ac0c7906ecd7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import *\ndef get_score_2(y_test, y_predicted):\n    return roc_auc_score(y_test, y_predicted[:, 1])","metadata":{"_uuid":"f8a5a470-0beb-4346-8b75-c4408e9ec471","_cell_guid":"7a3a54d3-ab3b-4c4d-bc93-6fcf48c79670","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import *\ndef get_accuracy_1(y_test, y_predicted):\n    labels_predicted = np.rint(y_predicted)\n    return accuracy_score(y_test, labels_predicted[:, 1])","metadata":{"_uuid":"d4493740-7670-40ba-aaba-6324f8f455bf","_cell_guid":"539f23dd-7ec9-4eb2-821a-11af8874d633","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Submission<a id=\"9\"></a>","metadata":{"_uuid":"75e985ad-ad86-45db-b6b9-92339ff11811","_cell_guid":"c516d5cd-4255-4102-8403-ab5bfb743e58","trusted":true}},{"cell_type":"code","source":"submission['claim'] = model.predict_proba(test)[:, 1]\nsubmission.to_csv('tps-0921-submit.csv', index = False)","metadata":{"_uuid":"6e0abc17-a7d7-4b7e-bffa-854ddce2365a","_cell_guid":"63016cc1-99a9-4bdf-a545-664719aba07a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}