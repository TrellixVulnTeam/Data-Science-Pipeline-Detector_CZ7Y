{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color:  #c1531f   \">Competition Description</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li > The dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting whether a claim will be made on an insurance policy. Although the features are anonymized, they have properties relating to real-world features.</li>\n> <li> For ideas on how to improve your score, check out the <a style=\"color:  black\" href=\"https://www.kaggle.com/learn/intro-to-machine-learning\" target=\"_blank\"> <u>Intro to Machine Learning</u></a> and <a style=\"color:  black\" href=\"https://www.kaggle.com/learn/intermediate-machine-learning\" target=\"_blank\">   <u>Intermediate Machine Learning</u></a> courses on Kaggle Learn.</li>\n></ul>\n></div>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color:  #c1531f   \">About the Notebook</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li > This notebook Sole purpose is Exploratory Data Analysis (EDA).</li>\n> <li> You can find Missing value imputation, distribution of variables and some decorations around them.</li>    \n> <li> This is very general EDA but can set a benchmark for other masterpieces which some of may create in future.</li>\n> <li> I didn't divide the data into train and test as the sole purpose of this was to carry out EDA.</li>\n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"\n<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Importing Required Libraries</li>","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# To impute missing Values\nfrom sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:21:43.537989Z","iopub.execute_input":"2021-09-03T05:21:43.538377Z","iopub.status.idle":"2021-09-03T05:21:43.543114Z","shell.execute_reply.started":"2021-09-03T05:21:43.538343Z","shell.execute_reply":"2021-09-03T05:21:43.542215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Setting up some parameters for Visualization, outputs etc</li>\n","metadata":{}},{"cell_type":"code","source":"# setting up the chart size and background\nplt.rcParams['figure.figsize'] = (16, 8)\nplt.style.use('fivethirtyeight')\n\n# for Interactive Shells\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:21:44.796971Z","iopub.execute_input":"2021-09-03T05:21:44.797619Z","iopub.status.idle":"2021-09-03T05:21:44.803644Z","shell.execute_reply.started":"2021-09-03T05:21:44.797572Z","shell.execute_reply":"2021-09-03T05:21:44.802644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Loading the data</li>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nsubmission_sample = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:21:46.934467Z","iopub.execute_input":"2021-09-03T05:21:46.934833Z","iopub.status.idle":"2021-09-03T05:22:34.176773Z","shell.execute_reply.started":"2021-09-03T05:21:46.934794Z","shell.execute_reply":"2021-09-03T05:22:34.175254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Looking at the first 5 rows of the data</li>","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T03:03:17.932409Z","iopub.execute_input":"2021-09-03T03:03:17.93281Z","iopub.status.idle":"2021-09-03T03:03:18.069119Z","shell.execute_reply.started":"2021-09-03T03:03:17.932777Z","shell.execute_reply":"2021-09-03T03:03:18.067992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Shape of the data</li>","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-03T02:21:30.784258Z","iopub.execute_input":"2021-09-03T02:21:30.784767Z","iopub.status.idle":"2021-09-03T02:21:30.793323Z","shell.execute_reply.started":"2021-09-03T02:21:30.784734Z","shell.execute_reply":"2021-09-03T02:21:30.792211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Checking Null Values</li>","metadata":{"execution":{"iopub.status.busy":"2021-09-03T02:22:08.614835Z","iopub.execute_input":"2021-09-03T02:22:08.615226Z","iopub.status.idle":"2021-09-03T02:22:08.622002Z","shell.execute_reply.started":"2021-09-03T02:22:08.615196Z","shell.execute_reply":"2021-09-03T02:22:08.620862Z"}}},{"cell_type":"code","source":"# Total Missing Values\ndf.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:30:59.957157Z","iopub.execute_input":"2021-09-03T05:30:59.957566Z","iopub.status.idle":"2021-09-03T05:31:00.206967Z","shell.execute_reply.started":"2021-09-03T05:30:59.957515Z","shell.execute_reply":"2021-09-03T05:31:00.205959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#printing only 70 columns with highest number of Null values\ndf.isnull().sum().sort_values(ascending = False).to_frame().head(70).rename({0:'Counts'}, axis = 1).T.style.background_gradient('crest')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:31:00.523268Z","iopub.execute_input":"2021-09-03T05:31:00.523661Z","iopub.status.idle":"2021-09-03T05:31:00.93148Z","shell.execute_reply.started":"2021-09-03T05:31:00.523628Z","shell.execute_reply":"2021-09-03T05:31:00.930446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Percentage of Null Values =(sum of null values / total number of rows) * 100</li>\n","metadata":{}},{"cell_type":"code","source":"#printing only 70 columns with highest percentage of Null values\ndisplay(round((df.isnull().sum() / (len(df.index)) * 100) , 2).sort_values(ascending = False).head(70).to_frame().rename({0:'%age'}, axis = 1).T.style.background_gradient('magma_r'))\nprint()\nmissing = (df.isnull().sum() / (len(df.index)) * 100).to_frame().reset_index().rename({0:'%age'}, axis = 1)\nax = sns.barplot(missing['index'],missing['%age'], palette  = 'magma_r')\nplt.title(\"Percentage of Missing Values\", fontsize = 20)\nplt.xticks(fontsize =7, rotation = 90)\nplt.xlabel(\"Variables\")\nplt.ylabel(\"Percentage of Missing Values\")\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:31:02.592682Z","iopub.execute_input":"2021-09-03T05:31:02.59307Z","iopub.status.idle":"2021-09-03T05:31:05.278355Z","shell.execute_reply.started":"2021-09-03T05:31:02.593007Z","shell.execute_reply":"2021-09-03T05:31:05.277328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color:  #c1531f   \">Observations:</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n    ><li > Overall we have <b>1.60%-1.64% </b> missing values and <b>variable f31</b> has the highest missing values percentage</li>\n    > <li> Total missing values:<b> 1820782 </b></li>\n    > <li> We can use <b>SimpleImputer</b> from sklearn to impute missing values. I'm selecting <b>Median</b> as the strategy, to take non parametric approach.</li>\n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Impute Missing Values</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li >As discussed we will use <b>SimpleImputer</b> from sklearn to impute missing values, with median as the strategy</li>\n></ul>\n></div>","metadata":{"execution":{"iopub.status.busy":"2021-09-03T02:41:42.239752Z","iopub.execute_input":"2021-09-03T02:41:42.240121Z","iopub.status.idle":"2021-09-03T02:41:42.248135Z","shell.execute_reply.started":"2021-09-03T02:41:42.240092Z","shell.execute_reply":"2021-09-03T02:41:42.246805Z"}}},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='median')\ndf_imputed = pd.DataFrame(imputer.fit_transform(df))\n\n# Imputation removed column names hence, getting back the names\ndf_imputed.columns = df.columns\n\n# Checking the final dataset for missing values again.\ndf_imputed.isnull().sum().sort_values(ascending = False).to_frame().reset_index().rename({0:'Count'}, axis =1).head(70).T.style.background_gradient('magma_r')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:31:52.339564Z","iopub.execute_input":"2021-09-03T05:31:52.340076Z","iopub.status.idle":"2021-09-03T05:32:23.323593Z","shell.execute_reply.started":"2021-09-03T05:31:52.340032Z","shell.execute_reply":"2021-09-03T05:32:23.322493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Describing the Data</li>\n","metadata":{}},{"cell_type":"code","source":"df_imputed.describe().style.background_gradient(cmap='bone_r')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:32:36.5181Z","iopub.execute_input":"2021-09-03T05:32:36.518499Z","iopub.status.idle":"2021-09-03T05:32:41.567219Z","shell.execute_reply.started":"2021-09-03T05:32:36.518462Z","shell.execute_reply":"2021-09-03T05:32:41.566348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Checking Correlations</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li >Since we have only numerical (Float) type variables we can directly check correlation and obtain some more insights.</li>\n></ul>\n></div>","metadata":{}},{"cell_type":"code","source":"df_imputed.corr()[['claim']].T.style.background_gradient('copper_r')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:32:44.213945Z","iopub.execute_input":"2021-09-03T05:32:44.214308Z","iopub.status.idle":"2021-09-03T05:33:22.097621Z","shell.execute_reply.started":"2021-09-03T05:32:44.214278Z","shell.execute_reply":"2021-09-03T05:33:22.096408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Observations</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li>Independent Variables have very low correlation with target variable (Claim)</li>\n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Outlier Detection</li>","metadata":{}},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/suharkov/sep-2021-playground-eda-no-model-for-now\ndf_plot = ((df_imputed - df_imputed.min())/(df_imputed.max() - df_imputed.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\nsns.boxplot(data = df_plot.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_plot.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_plot.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_plot.iloc[:, 90:120], ax = ax[3])","metadata":{"execution":{"iopub.status.busy":"2021-09-03T05:33:28.774446Z","iopub.execute_input":"2021-09-03T05:33:28.774805Z","iopub.status.idle":"2021-09-03T05:33:59.122741Z","shell.execute_reply.started":"2021-09-03T05:33:28.774777Z","shell.execute_reply":"2021-09-03T05:33:59.121718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Observations:</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li >There are many Outliers and must be treated before finalizing the model.</li>\n><li >Some ways could be to use Flooring, Capping methods etc.</li>\n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \">Distribution of Variables</li>","metadata":{}},{"cell_type":"code","source":"#Reference: https://www.kaggle.com/suharkov/sep-2021-playground-eda-no-model-for-now \nnrows = 20\nncols = 6\ni = 0\nfig, ax = plt.subplots(nrows, ncols, figsize = (25,75))\nfor row in range(nrows):\n    for col in range(ncols):\n        sns.histplot(data = df_imputed.iloc[:, i], bins = 50, ax = ax[row, col], palette  = 'bone_r').set(ylabel = '')\n        i += 1\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T03:54:50.985803Z","iopub.execute_input":"2021-09-03T03:54:50.986255Z","iopub.status.idle":"2021-09-03T03:56:49.577971Z","shell.execute_reply.started":"2021-09-03T03:54:50.986217Z","shell.execute_reply":"2021-09-03T03:56:49.576855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Observations</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li >Data has various kind of Distributions and is skewed in various cases.</li>\n><li >Some of them are even Gaussian, Binomial (target)</li>\n><li >Some ways to get around could be <b> Log Transformation, Outlier Treatment, Various Feature Engineering techniques </b> etc.</li>\n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Finally:</li>\n\n><div class=\"alert alert-info\" role=\"alert\">\n><ul style=\"font-family:cursive;font-size:20px;color:  #2025bd\">\n><li >Even I am beginner looking forward to learn something new. So let me know how can i improve this.</li>\n><li >If you like the notebook, kindly upvote so it is visible to most of us.</li>\n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"<li style=\"font-family:'Goudy Old Style';font-weight: bold;font-size:40px;color: #c1531f  \"> Thank you !!</li>","metadata":{}}]}