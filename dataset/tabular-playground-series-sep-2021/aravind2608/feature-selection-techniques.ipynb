{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-02T05:17:01.067912Z","iopub.execute_input":"2021-09-02T05:17:01.068309Z","iopub.status.idle":"2021-09-02T05:17:01.086458Z","shell.execute_reply.started":"2021-09-02T05:17:01.068216Z","shell.execute_reply":"2021-09-02T05:17:01.085543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:17:01.088156Z","iopub.execute_input":"2021-09-02T05:17:01.088618Z","iopub.status.idle":"2021-09-02T05:17:01.094001Z","shell.execute_reply.started":"2021-09-02T05:17:01.088581Z","shell.execute_reply":"2021-09-02T05:17:01.092748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:17:01.096335Z","iopub.execute_input":"2021-09-02T05:17:01.0966Z","iopub.status.idle":"2021-09-02T05:17:29.05899Z","shell.execute_reply.started":"2021-09-02T05:17:01.096576Z","shell.execute_reply":"2021-09-02T05:17:29.058165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:17:29.060564Z","iopub.execute_input":"2021-09-02T05:17:29.060885Z","iopub.status.idle":"2021-09-02T05:17:32.981329Z","shell.execute_reply.started":"2021-09-02T05:17:29.060845Z","shell.execute_reply":"2021-09-02T05:17:32.980394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  **We will start with handling missing values in the Dataset**","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()/len(df)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:17:32.982768Z","iopub.execute_input":"2021-09-02T05:17:32.983117Z","iopub.status.idle":"2021-09-02T05:17:33.195069Z","shell.execute_reply.started":"2021-09-02T05:17:32.98308Z","shell.execute_reply":"2021-09-02T05:17:33.194209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fill_mean = lambda col : col.fillna(col.mean())\ndf = df.apply(fill_mean)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:17:33.196291Z","iopub.execute_input":"2021-09-02T05:17:33.196662Z","iopub.status.idle":"2021-09-02T05:17:33.981888Z","shell.execute_reply.started":"2021-09-02T05:17:33.196625Z","shell.execute_reply":"2021-09-02T05:17:33.980982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:17:33.98311Z","iopub.execute_input":"2021-09-02T05:17:33.983523Z","iopub.status.idle":"2021-09-02T05:17:34.184829Z","shell.execute_reply.started":"2021-09-02T05:17:33.98348Z","shell.execute_reply":"2021-09-02T05:17:34.183862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* As you can see there are significant number of missing values that is around 2 % of the dataset. So, I replaced all missing values with **Mean**.","metadata":{}},{"cell_type":"markdown","source":"# Feature Selection\nAnd the next step is about finding the relation between independent variables. As there are too many independent features plotting heat map could make whole visualization messy so I tried printing the **Correlation coefficient** and checked by running loop.","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:17:34.18614Z","iopub.execute_input":"2021-09-02T05:17:34.186502Z","iopub.status.idle":"2021-09-02T05:18:07.077377Z","shell.execute_reply.started":"2021-09-02T05:17:34.186466Z","shell.execute_reply":"2021-09-02T05:18:07.076292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy \nfrom scipy.stats.stats import pearsonr\nfor i in range(1,118):\n    print(pearsonr(df['claim'], df['f'+ str(i)]))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:18:07.079631Z","iopub.execute_input":"2021-09-02T05:18:07.080124Z","iopub.status.idle":"2021-09-02T05:18:09.566778Z","shell.execute_reply.started":"2021-09-02T05:18:07.080084Z","shell.execute_reply":"2021-09-02T05:18:09.565814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = df.corr()\ncriteria = corr[ corr.iloc[:]>= 0.1 ]     \nprint(len(criteria))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:18:09.571005Z","iopub.execute_input":"2021-09-02T05:18:09.573162Z","iopub.status.idle":"2021-09-02T05:18:42.269324Z","shell.execute_reply.started":"2021-09-02T05:18:09.573115Z","shell.execute_reply":"2021-09-02T05:18:42.268443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see the count of Pearson Correlation Coefficient value greater tha 0.1 is 120, it indicates that no two independent features are significantly related so we cannot remove/drop any feature based on any **Correlation Coefficient**. \nSo, now I have tried feature selection using **Mutual Information** in classification problem statement. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(df.drop(labels=['claim', 'id'], axis=1),\n    df['claim'],\n    test_size=0.3,\n    random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:25:39.459531Z","iopub.execute_input":"2021-09-02T06:25:39.459864Z","iopub.status.idle":"2021-09-02T06:25:40.815119Z","shell.execute_reply.started":"2021-09-02T06:25:39.459837Z","shell.execute_reply":"2021-09-02T06:25:40.814277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\nmutual_info = mutual_info_classif(X_train, y_train)\nmutual_info","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:18:43.677186Z","iopub.execute_input":"2021-09-02T05:18:43.67755Z","iopub.status.idle":"2021-09-02T05:40:33.958043Z","shell.execute_reply.started":"2021-09-02T05:18:43.677515Z","shell.execute_reply":"2021-09-02T05:40:33.957238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"None of the feature have high mutual information with respect to dependent variable. So, I have tried checking for constant features using **Variance Threshold**. This could not be the effective way of removing features because the range of different independent features are very much different. So, I have just checked for constant values with variance threshold 0.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\nvar_thres=VarianceThreshold(threshold=0)\nvar_thres.fit(df)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:01:53.469467Z","iopub.execute_input":"2021-09-02T06:01:53.469895Z","iopub.status.idle":"2021-09-02T06:01:55.586094Z","shell.execute_reply.started":"2021-09-02T06:01:53.469861Z","shell.execute_reply":"2021-09-02T06:01:55.584709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_thres.get_support()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:04:28.031766Z","iopub.execute_input":"2021-09-02T06:04:28.032089Z","iopub.status.idle":"2021-09-02T06:04:28.039042Z","shell.execute_reply.started":"2021-09-02T06:04:28.03206Z","shell.execute_reply":"2021-09-02T06:04:28.038192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As nothing worked I proceeded with all independent features into my training model.","metadata":{}},{"cell_type":"code","source":"df['claim'].value_counts().sort_values(ascending=False).plot.bar(figsize=(10, 8))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T05:44:25.413558Z","iopub.execute_input":"2021-09-02T05:44:25.414007Z","iopub.status.idle":"2021-09-02T05:44:25.61015Z","shell.execute_reply.started":"2021-09-02T05:44:25.413963Z","shell.execute_reply":"2021-09-02T05:44:25.609291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\nscaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.fit(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:25:51.717086Z","iopub.execute_input":"2021-09-02T06:25:51.717471Z","iopub.status.idle":"2021-09-02T06:25:53.787193Z","shell.execute_reply.started":"2021-09-02T06:25:51.717431Z","shell.execute_reply":"2021-09-02T06:25:53.786282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier \nfrom sklearn.linear_model import LogisticRegression\nclf = DecisionTreeClassifier()\nclf.fit(scaled_X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:25:56.341102Z","iopub.execute_input":"2021-09-02T06:25:56.341435Z","iopub.status.idle":"2021-09-02T06:29:44.420998Z","shell.execute_reply.started":"2021-09-02T06:25:56.341387Z","shell.execute_reply":"2021-09-02T06:29:44.420206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = clf.predict_proba(X_test)\nprint(Y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:30:02.021444Z","iopub.execute_input":"2021-09-02T06:30:02.021785Z","iopub.status.idle":"2021-09-02T06:30:02.143406Z","shell.execute_reply.started":"2021-09-02T06:30:02.021743Z","shell.execute_reply":"2021-09-02T06:30:02.142461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint(roc_auc_score(y_test, Y_pred[:,0]))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:30:15.402797Z","iopub.execute_input":"2021-09-02T06:30:15.40312Z","iopub.status.idle":"2021-09-02T06:30:15.471797Z","shell.execute_reply.started":"2021-09-02T06:30:15.40309Z","shell.execute_reply":"2021-09-02T06:30:15.470852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1= pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nprint(df1.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:30:20.780255Z","iopub.execute_input":"2021-09-02T06:30:20.780594Z","iopub.status.idle":"2021-09-02T06:30:30.224232Z","shell.execute_reply.started":"2021-09-02T06:30:20.780564Z","shell.execute_reply":"2021-09-02T06:30:30.223157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fill_mean = lambda col : col.fillna(col.mean())\ndf1 = df1.apply(fill_mean)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:30:36.599881Z","iopub.execute_input":"2021-09-02T06:30:36.600182Z","iopub.status.idle":"2021-09-02T06:30:37.039086Z","shell.execute_reply.started":"2021-09-02T06:30:36.600153Z","shell.execute_reply":"2021-09-02T06:30:37.038199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test = np.array(df1.drop(['id'], axis = 1))\nscaled_Test = scaler.fit(Test)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:30:39.666114Z","iopub.execute_input":"2021-09-02T06:30:39.666447Z","iopub.status.idle":"2021-09-02T06:30:40.858427Z","shell.execute_reply.started":"2021-09-02T06:30:39.666396Z","shell.execute_reply":"2021-09-02T06:30:40.857394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_pred = clf.predict_proba(Test)\nprint(Test_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:30:52.961868Z","iopub.execute_input":"2021-09-02T06:30:52.962184Z","iopub.status.idle":"2021-09-02T06:30:53.166888Z","shell.execute_reply.started":"2021-09-02T06:30:52.962153Z","shell.execute_reply":"2021-09-02T06:30:53.16593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = pd.DataFrame()\ndf3['id'] = df1['id']\ndf3['claim'] = Test_pred[:, 0]\ndf3.to_csv('./result.csv', index= False)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T06:32:19.724277Z","iopub.execute_input":"2021-09-02T06:32:19.724616Z","iopub.status.idle":"2021-09-02T06:32:21.059549Z","shell.execute_reply.started":"2021-09-02T06:32:19.724584Z","shell.execute_reply":"2021-09-02T06:32:21.058498Z"},"trusted":true},"execution_count":null,"outputs":[]}]}