{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is based on `lukaszborecki's` great work in this competition:  \nhttps://www.kaggle.com/lukaszborecki/pytorch-fork-of-tps-09-nn  \n\n  This notebook plays around with:\n   - Adding scheduler/boilerplate\n   - Adding a Trainer object for training/evaluation\n   - Concating x and x_bin inputs\n   - Adding multi-sample dropout","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import GradScaler, autocast\nfrom sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.impute import SimpleImputer\nfrom fastai.losses import LabelSmoothingCrossEntropy, LabelSmoothingCrossEntropyFlat\nfrom fastai.layers import Mish\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\nfrom tqdm import tqdm\nfrom torchmetrics import AUROC\nimport gc, sys, random\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:27:34.656015Z","iopub.execute_input":"2021-09-20T14:27:34.656658Z","iopub.status.idle":"2021-09-20T14:27:34.664831Z","shell.execute_reply.started":"2021-09-20T14:27:34.656617Z","shell.execute_reply":"2021-09-20T14:27:34.662853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ntest_df =  pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\n\ntrain_df.set_index('id', inplace=True)\ntest_df.set_index('id', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:27:36.016872Z","iopub.execute_input":"2021-09-20T14:27:36.017545Z","iopub.status.idle":"2021-09-20T14:28:05.829586Z","shell.execute_reply.started":"2021-09-20T14:27:36.017508Z","shell.execute_reply":"2021-09-20T14:28:05.828579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_all(seed_value):\n    random.seed(seed_value) # Python\n    np.random.seed(seed_value) # cpu vars\n    torch.manual_seed(seed_value) # cpu  vars\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value) # gpu vars\n        torch.backends.cudnn.deterministic = True  #needed\n        torch.backends.cudnn.benchmark = False\n        \nseed_all(2021)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:49.781042Z","iopub.execute_input":"2021-09-20T14:17:49.78166Z","iopub.status.idle":"2021-09-20T14:17:49.792455Z","shell.execute_reply.started":"2021-09-20T14:17:49.781623Z","shell.execute_reply":"2021-09-20T14:17:49.791474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploration and Feature Engineering","metadata":{}},{"cell_type":"code","source":"train_df.claim.value_counts()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-20T14:17:49.797941Z","iopub.execute_input":"2021-09-20T14:17:49.798231Z","iopub.status.idle":"2021-09-20T14:17:49.82955Z","shell.execute_reply.started":"2021-09-20T14:17:49.798199Z","shell.execute_reply":"2021-09-20T14:17:49.828799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# null values in generated data shown to be useful\ntrain_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:49.833304Z","iopub.execute_input":"2021-09-20T14:17:49.833543Z","iopub.status.idle":"2021-09-20T14:17:50.100611Z","shell.execute_reply.started":"2021-09-20T14:17:49.833513Z","shell.execute_reply":"2021-09-20T14:17:50.099861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['sum_na'] = train_df.isna().sum(axis=1)\ntest_df['sum_na'] = test_df.isna().sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:50.104148Z","iopub.execute_input":"2021-09-20T14:17:50.104403Z","iopub.status.idle":"2021-09-20T14:17:50.426952Z","shell.execute_reply.started":"2021-09-20T14:17:50.104371Z","shell.execute_reply":"2021-09-20T14:17:50.426219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"class TabModel(nn.Module):\n    def __init__(self, act_fn = nn.SiLU(), dropout_num = 1):\n        super().__init__()\n        self.emb = nn.Embedding(96,18)\n        self.fc = nn.Linear(119*18, 30)\n        self.dropouts = nn.ModuleList([nn.Dropout(0.4) \n                                       for _ in range(dropout_num)])\n        self.fc1 = nn.Linear(119,30)\n        self.fc2 = nn.Linear(30*2,30) # concat layers\n        self.out = nn.Linear(30,1)\n        self.act_fn = act_fn\n        \n        torch.nn.init.xavier_normal_(self.out.weight)\n        torch.nn.init.xavier_normal_(self.emb.weight)\n        torch.nn.init.xavier_normal_(self.fc.weight)\n        torch.nn.init.xavier_normal_(self.fc1.weight)\n        torch.nn.init.xavier_normal_(self.fc2.weight)\n\n    def forward(self, x_bin, x):\n        x_bin = self.emb(x_bin)\n        x_bin = x_bin.view(-1,119*18)\n        x_bin = self.act_fn(self.fc(x_bin))\n        \n        x = self.act_fn(self.fc1(x))\n        x = torch.cat([x_bin,x], -1)\n        x = self.act_fn(self.fc2(x))\n        \n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                out = dropout(x)\n                out = self.out(out)\n        \n            else:\n                temp_out = dropout(x)\n                temp_out = self.out(temp_out)\n                out += temp_out\n                \n        out /= len(self.dropouts)\n\n        return torch.sigmoid(out)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:50.42838Z","iopub.execute_input":"2021-09-20T14:17:50.42863Z","iopub.status.idle":"2021-09-20T14:17:50.442634Z","shell.execute_reply.started":"2021-09-20T14:17:50.428599Z","shell.execute_reply":"2021-09-20T14:17:50.441929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"def preprocess_dataset(x, x_test, target = None):\n    if target:\n        x = x.copy().drop(target, 1)\n    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n    qt = QuantileTransformer(n_quantiles=96, output_distribution='normal')\n    bin_cat = KBinsDiscretizer(n_bins=96, encode='ordinal',strategy='uniform')\n    \n    x = imp.fit_transform(x)\n    x = qt.fit_transform(x)\n    x_bin = bin_cat.fit_transform(x)\n    \n    x_test = imp.transform(x_test)\n    x_test = qt.transform(x_test)\n    x_test_bin = bin_cat.transform(x_test)\n    \n    return x, x_bin, x_test, x_test_bin","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:50.443994Z","iopub.execute_input":"2021-09-20T14:17:50.444239Z","iopub.status.idle":"2021-09-20T14:17:50.452537Z","shell.execute_reply.started":"2021-09-20T14:17:50.444209Z","shell.execute_reply":"2021-09-20T14:17:50.45188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter:\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:50.453709Z","iopub.execute_input":"2021-09-20T14:17:50.454Z","iopub.status.idle":"2021-09-20T14:17:50.465708Z","shell.execute_reply.started":"2021-09-20T14:17:50.453949Z","shell.execute_reply":"2021-09-20T14:17:50.46495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=7, mode=\"max\", delta=0.001, verbose = None):\n        self.patience = patience\n        self.counter = 0\n        self.mode = mode\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n        self.verbose = verbose\n        if self.mode == \"min\":\n            self.val_score = np.Inf\n        else:\n            self.val_score = -np.Inf\n\n    def __call__(self, epoch_score, model, model_path):\n\n        if self.mode == \"min\":\n            score = -1.0 * epoch_score\n        else:\n            score = np.copy(epoch_score)\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model, model_path)\n        elif score < self.best_score: #  + self.delta\n            self.counter += 1\n            if self.verbose:\n                print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model, model_path)\n            self.counter = 0\n\n    def save_checkpoint(self, epoch_score, model, model_path):\n        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n            if self.verbose:\n                print('Validation score improved ({:.4f} --> {:.4f}). Saving model!'.format(self.val_score, epoch_score))\n                \n            torch.save(model.state_dict(), model_path)\n        self.val_score = epoch_score","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:50.46953Z","iopub.execute_input":"2021-09-20T14:17:50.469742Z","iopub.status.idle":"2021-09-20T14:17:50.482346Z","shell.execute_reply.started":"2021-09-20T14:17:50.469721Z","shell.execute_reply":"2021-09-20T14:17:50.481688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_bin, x_test, x_test_bin = preprocess_dataset(train_df, test_df, target = 'claim')\ny_train = train_df.claim.values","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:17:50.483723Z","iopub.execute_input":"2021-09-20T14:17:50.484549Z","iopub.status.idle":"2021-09-20T14:18:58.420346Z","shell.execute_reply.started":"2021-09-20T14:17:50.484513Z","shell.execute_reply":"2021-09-20T14:18:58.419566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class TabDataset(Dataset):\n    def __init__(self, x, x_bin, target = None):\n        super().__init__()\n        self.x = x\n        self.x_bin = x_bin\n        self.target = target\n        \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        x = self.x[idx, :]\n        x_bin = self.x_bin[idx, :]\n        \n        _dict = {'x': torch.tensor(x, dtype = torch.float),\n                 'x_bin': torch.tensor(x_bin, dtype = torch.long)}\n        \n        if self.target is not None:\n            target = self.target[idx].item()\n            _dict.update({'target': torch.tensor(target, dtype = torch.float)})\n        \n        return _dict","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:18:58.421576Z","iopub.execute_input":"2021-09-20T14:18:58.421845Z","iopub.status.idle":"2021-09-20T14:18:58.431453Z","shell.execute_reply.started":"2021-09-20T14:18:58.421813Z","shell.execute_reply":"2021-09-20T14:18:58.430485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, device, loss_fn, opt, scheduler = None):\n        self.model = model\n        self.device = device\n        self.loss_fn = loss_fn\n        self.opt = opt\n        self.scheduler = scheduler\n        \n    def fit_one_epoch(self, dl):\n        self.model.train()\n        losses = AverageMeter()\n        prog_bar = tqdm(enumerate(dl), total = len(dl), file=sys.stdout, leave = False)\n        \n        for bi, d in prog_bar:\n            x = d[\"x\"].to(self.device)\n            x_bin = d['x_bin'].to(self.device)\n            target = d['target'].to(self.device)\n            \n            out = self.model(x_bin, x)\n            loss = self.loss_fn(out.squeeze(-1), target)\n            prog_bar.set_description('loss: {:.2f}'.format(loss.item()))\n            losses.update(loss.item(), x.size(0))\n            loss.backward()\n            self.opt.step()\n            \n            if self.scheduler: \n                self.scheduler.step()\n                    \n            self.opt.zero_grad()\n            \n    def eval_one_epoch(self, dl, **kwargs):\n        self.model.eval()\n        losses = AverageMeter()\n        metric = AUROC()\n        prog_bar = tqdm(enumerate(dl), total = len(dl), file=sys.stdout, leave = False)\n        \n        for bi, d in prog_bar:  \n            x = d[\"x\"].to(self.device)\n            x_bin = d['x_bin'].to(self.device)\n            target = d['target'].to(self.device)\n            \n            with torch.no_grad():\n                out = self.model(x_bin, x)\n                loss = self.loss_fn(out.squeeze(-1), target)\n                if metric:\n                    auroc = metric(out.squeeze(-1), target.int())\n                \n                losses.update(loss.item(), x.size(0))\n        auroc = metric.compute()\n        print(f\"F{kwargs['fold']} E{kwargs['epoch']}  Valid Loss: {losses.avg:.4f}  AUROC Score: {auroc:.4f}\")\n        return auroc.cpu() if metric else losses.avg","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:18:58.433013Z","iopub.execute_input":"2021-09-20T14:18:58.433265Z","iopub.status.idle":"2021-09-20T14:18:58.449216Z","shell.execute_reply.started":"2021-09-20T14:18:58.433233Z","shell.execute_reply":"2021-09-20T14:18:58.448412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"class cfg:\n    bs = 1024\n    n_splits = 8\n    seed = 2021\n    epochs = 4\n    lr = 1e-4\n    checkpoint = lambda fold: f'model_{fold}.pt'\n    \nkfold = StratifiedKFold(n_splits = cfg.n_splits, \n                        random_state = cfg.seed, \n                        shuffle = True)\nsplits = [*kfold.split(X = x_train, y = y_train)]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:18:58.628928Z","iopub.execute_input":"2021-09-20T14:18:58.629206Z","iopub.status.idle":"2021-09-20T14:18:58.796403Z","shell.execute_reply.started":"2021-09-20T14:18:58.629173Z","shell.execute_reply":"2021-09-20T14:18:58.795608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:18:58.79779Z","iopub.execute_input":"2021-09-20T14:18:58.798075Z","iopub.status.idle":"2021-09-20T14:18:58.802556Z","shell.execute_reply.started":"2021-09-20T14:18:58.798042Z","shell.execute_reply":"2021-09-20T14:18:58.801726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataloaders(fold):\n    train_idx, valid_idx = splits[fold]\n    \n    _xtr, _xtr_bins, _ytr = x_train[train_idx], x_bin[train_idx], y_train[train_idx]\n    _xval, _xval_bins, _yval = x_train[valid_idx], x_bin[valid_idx], y_train[valid_idx]\n    \n    train_ds = TabDataset(x = _xtr, x_bin = _xtr_bins, target = _ytr)\n    valid_ds = TabDataset(x = _xval, x_bin = _xval_bins, target = _yval)\n                          \n    train_dl = DataLoader(train_ds, batch_size = cfg.bs, shuffle = True)\n    valid_dl = DataLoader(valid_ds, batch_size = cfg.bs, shuffle = False)\n    \n    return train_dl, valid_dl","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:18:58.804194Z","iopub.execute_input":"2021-09-20T14:18:58.804602Z","iopub.status.idle":"2021-09-20T14:18:58.813481Z","shell.execute_reply.started":"2021-09-20T14:18:58.804568Z","shell.execute_reply":"2021-09-20T14:18:58.812688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fold(fold, epochs):\n    train_dl, valid_dl = create_dataloaders(fold)\n    es = EarlyStopping(patience = 7, mode=\"max\", verbose = False)\n    \n    model = TabModel(dropout_num = 1).to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr = cfg.lr)\n    scheduler = OneCycleLR(opt, \n                           max_lr=1e-3, \n                           steps_per_epoch=len(train_dl),\n                           epochs = epochs)\n\n    trainer = Trainer(model, \n                      device, \n                      loss_fn=nn.BCELoss(), \n                      opt = opt,\n                      scheduler = scheduler,\n                     )\n    \n    for epoch in range(epochs):\n        trainer.fit_one_epoch(train_dl)\n        valid_loss = trainer.eval_one_epoch(valid_dl, fold = fold, epoch = epoch)\n        \n        es(valid_loss, trainer.model, model_path = cfg.checkpoint(fold))\n        \n        if es.early_stop:\n            break","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:22:20.819563Z","iopub.execute_input":"2021-09-20T14:22:20.81983Z","iopub.status.idle":"2021-09-20T14:22:20.827742Z","shell.execute_reply.started":"2021-09-20T14:22:20.8198Z","shell.execute_reply":"2021-09-20T14:22:20.826875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(cfg.n_splits):\n    train_fold(fold, cfg.epochs)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T14:22:23.273529Z","iopub.execute_input":"2021-09-20T14:22:23.273784Z","iopub.status.idle":"2021-09-20T14:25:08.47669Z","shell.execute_reply.started":"2021-09-20T14:22:23.273755Z","shell.execute_reply":"2021-09-20T14:25:08.476058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"y_pred = torch.zeros(len(x_test), 1).to(device)\ntest_ds = TabDataset(x_test, x_test_bin)\ntest_dl = DataLoader(test_ds, batch_size = cfg.bs, shuffle = False)\n\nwith torch.no_grad():\n    for fold in range(cfg.n_splits):\n        preds = []\n        model = TabModel(dropout_num = 1).to(device)\n        state_dict = cfg.checkpoint(fold)\n        model.load_state_dict(torch.load(state_dict))\n        model.eval()\n        \n        for d in test_dl:\n            x = d[\"x\"].to(device)\n            x_bin = d['x_bin'].to(device)\n            out = model(x_bin, x)\n            preds.append(out)\n            \n        preds = torch.vstack(preds)\n        y_pred += preds / cfg.n_splits","metadata":{"execution":{"iopub.status.busy":"2021-09-19T17:29:25.016669Z","iopub.execute_input":"2021-09-19T17:29:25.016964Z","iopub.status.idle":"2021-09-19T17:30:27.478112Z","shell.execute_reply.started":"2021-09-19T17:29:25.016929Z","shell.execute_reply":"2021-09-19T17:30:27.477382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')\nsub.iloc[:,1] = y_pred.cpu()\nsub = sub.set_index('id')\nsub.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-19T17:31:09.197267Z","iopub.execute_input":"2021-09-19T17:31:09.197526Z","iopub.status.idle":"2021-09-19T17:31:11.35407Z","shell.execute_reply.started":"2021-09-19T17:31:09.197499Z","shell.execute_reply":"2021-09-19T17:31:11.35325Z"},"trusted":true},"execution_count":null,"outputs":[]}]}