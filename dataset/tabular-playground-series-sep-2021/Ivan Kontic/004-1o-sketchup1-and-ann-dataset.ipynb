{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.038238,"end_time":"2021-08-22T18:32:36.509378","exception":false,"start_time":"2021-08-22T18:32:36.47114","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-08T17:10:40.872674Z","iopub.execute_input":"2021-09-08T17:10:40.873117Z","iopub.status.idle":"2021-09-08T17:10:40.895656Z","shell.execute_reply.started":"2021-09-08T17:10:40.873022Z","shell.execute_reply":"2021-09-08T17:10:40.894702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow, imread\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.impute import SimpleImputer\nimport scikitplot as skplt\n\nimport scipy.stats as stats\n\nimport lightgbm as lgb\nimport warnings\n\nimport optuna","metadata":{"papermill":{"duration":3.008247,"end_time":"2021-08-22T18:32:39.534747","exception":false,"start_time":"2021-08-22T18:32:36.5265","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-08T17:10:40.897324Z","iopub.execute_input":"2021-09-08T17:10:40.897677Z","iopub.status.idle":"2021-09-08T17:10:44.794466Z","shell.execute_reply.started":"2021-09-08T17:10:40.897646Z","shell.execute_reply":"2021-09-08T17:10:44.7934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"R_SEED = 37","metadata":{"papermill":{"duration":0.022481,"end_time":"2021-08-22T18:32:39.573273","exception":false,"start_time":"2021-08-22T18:32:39.550792","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-08T17:10:44.796183Z","iopub.execute_input":"2021-09-08T17:10:44.796512Z","iopub.status.idle":"2021-09-08T17:10:44.80101Z","shell.execute_reply.started":"2021-09-08T17:10:44.796482Z","shell.execute_reply":"2021-09-08T17:10:44.799503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Additional ann dataset\nMy excursion with neural net ended with bad result. In try to get something out of it, I collected data from layer before the last. So, version1 of this dataset has 32 features and version2 has 16 features. Dataset is [public](https://www.kaggle.com/ivankontic/0042-ann32ds-tps-sep-2021), if someone want to try.","metadata":{}},{"cell_type":"code","source":"submission_ex = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv')\ntrain_data_a = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv')\ntest_data_a  = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/test.csv')\ntrain_data_b = pd.read_csv('/kaggle/input/0042-ann32ds-tps-sep-2021/train_data_nn_features.csv')\ntest_data_b  = pd.read_csv('/kaggle/input/0042-ann32ds-tps-sep-2021/test_data_nn_features.csv')","metadata":{"papermill":{"duration":9.508118,"end_time":"2021-08-22T18:32:49.134464","exception":false,"start_time":"2021-08-22T18:32:39.626346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-08T17:10:44.802597Z","iopub.execute_input":"2021-09-08T17:10:44.80302Z","iopub.status.idle":"2021-09-08T17:11:39.776063Z","shell.execute_reply.started":"2021-09-08T17:10:44.802989Z","shell.execute_reply":"2021-09-08T17:11:39.774516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_data = train_data_a[['claim']].copy()\ntrain_data_a.drop(['id', 'claim'], axis=1, inplace=True)\nsubmit_data = test_data_a[['id']].copy()\ntest_data_a.drop(['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:39.77833Z","iopub.execute_input":"2021-09-08T17:11:39.778706Z","iopub.status.idle":"2021-09-08T17:11:40.454972Z","shell.execute_reply.started":"2021-09-08T17:11:39.778668Z","shell.execute_reply":"2021-09-08T17:11:40.453518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train_data_a, test_data_a])\nall_data.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:40.456623Z","iopub.execute_input":"2021-09-08T17:11:40.45696Z","iopub.status.idle":"2021-09-08T17:11:40.949726Z","shell.execute_reply.started":"2021-09-08T17:11:40.456927Z","shell.execute_reply":"2021-09-08T17:11:40.948566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_n_missing = all_data.isna().sum(axis=1)\nall_std = all_data.std(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:40.95133Z","iopub.execute_input":"2021-09-08T17:11:40.951704Z","iopub.status.idle":"2021-09-08T17:11:42.593982Z","shell.execute_reply.started":"2021-09-08T17:11:40.951669Z","shell.execute_reply":"2021-09-08T17:11:42.592885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data_normalized = StandardScaler().fit_transform(all_data)\nall_data = pd.DataFrame(all_data_normalized, columns=all_data.columns)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:42.596628Z","iopub.execute_input":"2021-09-08T17:11:42.596969Z","iopub.status.idle":"2021-09-08T17:11:47.31185Z","shell.execute_reply.started":"2021-09-08T17:11:42.596936Z","shell.execute_reply":"2021-09-08T17:11:47.310749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I decided to not do anything with missing values (for now). Let lgbm deal with it.","metadata":{}},{"cell_type":"code","source":"##### all_data['n_missing'] = all_n_missing\n##### all_data['std'] = all_std\n\n# imputer = SimpleImputer(strategy='constant', fill_value=0) # add_indicator=True, \n\n# old_features = list(all_data.columns)\n# all_data = pd.DataFrame(imputer.fit_transform(all_data))\n# features = old_features # + ['ind_for_' + str(e) for e in imputer.indicator_.features_]\n# all_data.columns = features","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:47.313805Z","iopub.execute_input":"2021-09-08T17:11:47.314219Z","iopub.status.idle":"2021-09-08T17:11:47.318693Z","shell.execute_reply.started":"2021-09-08T17:11:47.314174Z","shell.execute_reply":"2021-09-08T17:11:47.317598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_a, test_data_a = all_data.iloc[:train_data_a.shape[0],:].copy(), all_data.iloc[train_data_a.shape[0]:,:].copy()\n\nn_missing = all_n_missing[:train_data_a.shape[0]]","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:47.320276Z","iopub.execute_input":"2021-09-08T17:11:47.320815Z","iopub.status.idle":"2021-09-08T17:11:47.761106Z","shell.execute_reply.started":"2021-09-08T17:11:47.320759Z","shell.execute_reply":"2021-09-08T17:11:47.760039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Just experimenting\nMaybe some of pca components will be useful. PCA has been applied on ann dataset.","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=5)\npca.fit(pd.concat([train_data_b, test_data_b]))\ntrain_data_c = pd.DataFrame(pca.transform(train_data_b), columns=['pca_b_f' + str(i) for i in range(5)])\ntest_data_c = pd.DataFrame(pca.transform(test_data_b), columns=['pca_b_f' + str(i) for i in range(5)])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:47.762619Z","iopub.execute_input":"2021-09-08T17:11:47.763047Z","iopub.status.idle":"2021-09-08T17:11:52.920974Z","shell.execute_reply.started":"2021-09-08T17:11:47.763001Z","shell.execute_reply":"2021-09-08T17:11:52.919506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pca.explained_variance_ratio_)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:51:02.911165Z","iopub.execute_input":"2021-09-08T17:51:02.911628Z","iopub.status.idle":"2021-09-08T17:51:02.91733Z","shell.execute_reply.started":"2021-09-08T17:51:02.911592Z","shell.execute_reply":"2021-09-08T17:51:02.916188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### NaN","metadata":{}},{"cell_type":"code","source":"def plot_gmm(model, data, ax, c):\n    weights = model.weights_\n    means = model.means_\n    covars = model.covariances_\n\n    x = np.arange(np.min(data), np.max(data), (np.max(data) - np.min(data)) / 100)\n    for i in range(len(weights)):\n        ax.plot(x - 1, weights[i] * stats.norm.pdf(x,means[i],np.sqrt(covars[i])[0]), alpha = 0.7, linewidth = 3, color=c)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-08T17:11:52.922708Z","iopub.execute_input":"2021-09-08T17:11:52.923344Z","iopub.status.idle":"2021-09-08T17:11:52.933029Z","shell.execute_reply.started":"2021-09-08T17:11:52.923298Z","shell.execute_reply":"2021-09-08T17:11:52.931479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10, 5))\nax = fig.gca()\n\ndata0 = np.expand_dims(n_missing[target_data['claim'] == 0], axis=1)\ngm = GaussianMixture(n_components = 1, n_init = 5)\ngm.fit(data0)\nplot_gmm(gm, data0, ax, 'red')\n#---\ndata1 = np.expand_dims(n_missing[target_data['claim'] == 1], axis=1)\ngm = GaussianMixture(n_components = 1, n_init = 5)\ngm.fit(data1)\nplot_gmm(gm, data1, ax, 'blue')\n\nax.set_title('NaN_values')\nax.legend(['probability for 0', 'probability for 1'])\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-08T17:11:52.934696Z","iopub.execute_input":"2021-09-08T17:11:52.935395Z","iopub.status.idle":"2021-09-08T17:11:57.250948Z","shell.execute_reply.started":"2021-09-08T17:11:52.93533Z","shell.execute_reply":"2021-09-08T17:11:57.249931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Little more freely drawn graph, but it should be right.  \nAs we can see, if there are NaN in row, probability is on the side of 1s. I'll try later something with this probabilities.","metadata":{}},{"cell_type":"code","source":"train_data = pd.concat([train_data_a, train_data_b, train_data_c], axis=1)\ntest_data = pd.concat([test_data_a.reset_index(drop=True), test_data_b, test_data_c], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:57.254939Z","iopub.execute_input":"2021-09-08T17:11:57.25704Z","iopub.status.idle":"2021-09-08T17:11:58.180781Z","shell.execute_reply.started":"2021-09-08T17:11:57.256982Z","shell.execute_reply":"2021-09-08T17:11:58.179605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_data_a, train_data_b, train_data_c, test_data_a, test_data_b, test_data_c, all_data","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:11:58.183445Z","iopub.execute_input":"2021-09-08T17:11:58.183917Z","iopub.status.idle":"2021-09-08T17:11:58.193555Z","shell.execute_reply.started":"2021-09-08T17:11:58.183866Z","shell.execute_reply":"2021-09-08T17:11:58.192341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Run\nTwo models are trained, One on prepared dataset and one on number_of_missing array.  \nJust want to see how looks on graph.","metadata":{}},{"cell_type":"code","source":"params_1 = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting_type': 'gbdt',\n    'n_estimators': 20000,\n    'learning_rate': 0.005,\n    'num_leaves': 627, \n    'min_child_samples': 1952, \n    'feature_fraction': 0.4, \n    'bagging_fraction': 0.8,\n    'bagging_freq': 2,\n    'importance_type': 'gain'}\n\nparams_2 = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting_type': 'gbdt',\n    'n_estimators': 1000, \n    'learning_rate': 0.05, \n    'num_leaves': 89, \n    'min_child_samples': 48, \n    'feature_fraction': 0.35, \n    'bagging_fraction': 0.9, \n    'bagging_freq': 1}\n    \nmodel_1 = lgb.LGBMRegressor(**params_1,\n                          n_jobs=-1,\n                          random_state = R_SEED)\n\nmodel_2 = lgb.LGBMRegressor(**params_2,\n                          n_jobs=-1,\n                          random_state = R_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:14:24.431014Z","iopub.execute_input":"2021-09-08T17:14:24.43139Z","iopub.status.idle":"2021-09-08T17:14:24.439196Z","shell.execute_reply.started":"2021-09-08T17:14:24.431346Z","shell.execute_reply":"2021-09-08T17:14:24.437978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = R_SEED)\npred = []\nlgb_oof_1 = np.zeros(train_data.shape[0])\nlgb_oof_2 = np.zeros(train_data.shape[0])\n\nfor train_index, test_index in kfolds.split(X=train_data, y=n_missing):\n\n    X_train, X_val = train_data.iloc[train_index], train_data.iloc[test_index]\n    X_train_2, X_val_2 = np.expand_dims(n_missing[train_index], axis=1), np.expand_dims(n_missing[test_index], axis=1)\n    y_train, y_val = target_data.iloc[train_index], target_data.iloc[test_index]\n    \n    print(y_train.shape[0], y_train['claim'].sum())\n    \n    model_1.fit(\n        X_train, \n        np.ravel(y_train), \n        eval_metric = \"auc\", \n        eval_set = [(X_val, y_val)],\n        verbose = 100,\n        early_stopping_rounds = 500)\n    \n    oof_pred_1 = model_1.predict(X_val)\n    lgb_oof_1[test_index] = oof_pred_1\n        \n    _p = model_1.predict(test_data)\n    pred.append(_p)\n    \n    model_2.fit(\n        X_train_2, \n        np.ravel(y_train), \n        eval_metric = \"auc\", \n        eval_set = [(X_val_2, y_val)],\n        verbose = 100,\n        early_stopping_rounds = 200)\n    \n    oof_pred_2 = model_2.predict(X_val_2)\n    lgb_oof_2[test_index] = oof_pred_2\n    \nfinal_p = np.sum(pred, axis = 0) / len(pred)\n\nsubmit_data['claim'] = final_p\nsubmit_data.to_csv('submission.csv', index=False)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-08T17:14:24.641063Z","iopub.execute_input":"2021-09-08T17:14:24.64148Z","iopub.status.idle":"2021-09-08T17:30:39.258223Z","shell.execute_reply.started":"2021-09-08T17:14:24.641442Z","shell.execute_reply":"2021-09-08T17:30:39.257345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Curve is drawn with oof data","metadata":{}},{"cell_type":"code","source":"p_1 = [(1-e, e) for e in lgb_oof_1]\np_2 = [(1-e, e) for e in lgb_oof_2]\n\nfig = plt.figure(figsize = (10, 10))\nax = fig.gca()\n\nskplt.metrics.plot_roc(target_data.claim.values, p_1, plot_micro=False, plot_macro=False, classes_to_plot=[1], ax=ax, cmap='Reds')\n# skplt.metrics.plot_roc(target_data.claim.values, p_1, plot_micro=False, plot_macro=False, classes_to_plot=[0], ax=ax, cmap='ocean')\nskplt.metrics.plot_roc(target_data.claim.values, p_2, plot_micro=False, plot_macro=False, classes_to_plot=[1], ax=ax, cmap='Blues')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T17:30:39.259968Z","iopub.execute_input":"2021-09-08T17:30:39.260569Z","iopub.status.idle":"2021-09-08T17:30:45.119383Z","shell.execute_reply.started":"2021-09-08T17:30:39.26053Z","shell.execute_reply":"2021-09-08T17:30:45.118293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems a bit unnatural :). The blue one is of number_of_missing \"dataset\".  \nleft side is a bit to spacious. It's sign that we have in upper side mixing of 1s and 0s. So, part closer to 0 is better than part closer to 1 (as far as classification is concerned)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}