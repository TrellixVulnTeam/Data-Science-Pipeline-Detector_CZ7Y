{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries and Data import","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\n\nfrom matplotlib.lines import Line2D\n\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import IsolationForest\n\nimport optuna\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\n# import warnings\n# warnings.simplefilter(action='ignore', category=UserWarning)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-03T14:23:46.54111Z","iopub.execute_input":"2021-09-03T14:23:46.54144Z","iopub.status.idle":"2021-09-03T14:23:49.903646Z","shell.execute_reply.started":"2021-09-03T14:23:46.541343Z","shell.execute_reply":"2021-09-03T14:23:49.902746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the data\ntrain = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv', index_col='id')\ntest = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv', index_col='id')\nsample = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:23:49.906553Z","iopub.execute_input":"2021-09-03T14:23:49.906805Z","iopub.status.idle":"2021-09-03T14:24:31.937634Z","shell.execute_reply.started":"2021-09-03T14:23:49.906779Z","shell.execute_reply":"2021-09-03T14:24:31.936483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:31.939747Z","iopub.execute_input":"2021-09-03T14:24:31.94014Z","iopub.status.idle":"2021-09-03T14:24:32.00803Z","shell.execute_reply.started":"2021-09-03T14:24:31.940089Z","shell.execute_reply":"2021-09-03T14:24:32.007122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:32.009697Z","iopub.execute_input":"2021-09-03T14:24:32.0101Z","iopub.status.idle":"2021-09-03T14:24:32.073691Z","shell.execute_reply.started":"2021-09-03T14:24:32.010062Z","shell.execute_reply":"2021-09-03T14:24:32.072796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA\nEDA base on Notebook https://www.kaggle.com/maximkazantsev/tps-08-21-xgboost Thanks to @maximkazantsev","metadata":{}},{"cell_type":"code","source":"# Colors to be used for plots\n\ncolors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:32.075147Z","iopub.execute_input":"2021-09-03T14:24:32.075496Z","iopub.status.idle":"2021-09-03T14:24:32.080011Z","shell.execute_reply.started":"2021-09-03T14:24:32.075462Z","shell.execute_reply":"2021-09-03T14:24:32.079137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5, 5))\npie = ax.pie([len(train), len(test)],\n             labels=[\"Train dataset\", \"Test dataset\"],\n             colors=[\"salmon\", \"teal\"],\n             textprops={\"fontsize\": 15},\n             autopct='%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Dataset length comparison\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:32.081255Z","iopub.execute_input":"2021-09-03T14:24:32.081798Z","iopub.status.idle":"2021-09-03T14:24:32.197008Z","shell.execute_reply.started":"2021-09-03T14:24:32.081756Z","shell.execute_reply":"2021-09-03T14:24:32.196022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at the data","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:32.198344Z","iopub.execute_input":"2021-09-03T14:24:32.198698Z","iopub.status.idle":"2021-09-03T14:24:32.206254Z","shell.execute_reply.started":"2021-09-03T14:24:32.198663Z","shell.execute_reply":"2021-09-03T14:24:32.205482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:32.209058Z","iopub.execute_input":"2021-09-03T14:24:32.209599Z","iopub.status.idle":"2021-09-03T14:24:36.184533Z","shell.execute_reply.started":"2021-09-03T14:24:32.20956Z","shell.execute_reply":"2021-09-03T14:24:36.183746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:36.18646Z","iopub.execute_input":"2021-09-03T14:24:36.186811Z","iopub.status.idle":"2021-09-03T14:24:38.340413Z","shell.execute_reply.started":"2021-09-03T14:24:36.186773Z","shell.execute_reply":"2021-09-03T14:24:38.339623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking for Categorical Features","metadata":{}},{"cell_type":"code","source":"train.nunique().sort_values().head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:38.341689Z","iopub.execute_input":"2021-09-03T14:24:38.342022Z","iopub.status.idle":"2021-09-03T14:24:41.269207Z","shell.execute_reply.started":"2021-09-03T14:24:38.341986Z","shell.execute_reply":"2021-09-03T14:24:41.268217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No features looks like to be categorical","metadata":{}},{"cell_type":"code","source":"(train.claim ==1).sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:41.27052Z","iopub.execute_input":"2021-09-03T14:24:41.270968Z","iopub.status.idle":"2021-09-03T14:24:41.28869Z","shell.execute_reply.started":"2021-09-03T14:24:41.27093Z","shell.execute_reply":"2021-09-03T14:24:41.278728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check the distribuition of the Target:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5, 5))\npie = ax.pie([(train.claim ==0).sum(), (train.claim ==1).sum()],\n             labels=[\"0\", \"1\"],\n             colors=[\"orange\", \"blue\"],\n             textprops={\"fontsize\": 15},\n             autopct='%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Target distribuition\\n\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:41.290102Z","iopub.execute_input":"2021-09-03T14:24:41.290619Z","iopub.status.idle":"2021-09-03T14:24:41.39421Z","shell.execute_reply.started":"2021-09-03T14:24:41.290581Z","shell.execute_reply":"2021-09-03T14:24:41.393103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns == train.drop(columns=\"claim\").columns\nnum_attribs = test.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:41.395366Z","iopub.execute_input":"2021-09-03T14:24:41.3957Z","iopub.status.idle":"2021-09-03T14:24:41.663927Z","shell.execute_reply.started":"2021-09-03T14:24:41.395666Z","shell.execute_reply":"2021-09-03T14:24:41.662836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train.drop(\"claim\", axis=1), \n                test], axis=0)\ncolumns = num_attribs\n\ncols = 3\nrows = len(columns) // cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,rows*3), sharex=False)\n\nplt.subplots_adjust(hspace = 0.3)\ni=0\n\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            hist1 = axs[r, c].hist(train[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"deepskyblue\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Train Dataset\")\n            hist2 = axs[r, c].hist(test[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"palevioletred\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Test Dataset\")\n            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n            axs[r, c].tick_params(axis=\"y\", labelsize=13)\n            axs[r, c].tick_params(axis=\"x\", labelsize=13)\n            axs[r, c].grid(axis=\"y\")\n            axs[r, c].legend(fontsize=13)\n                                  \n        i+=1\n#plt.suptitle(\"Feature values distribution in both datasets\", y=0.99)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:24:41.665687Z","iopub.execute_input":"2021-09-03T14:24:41.666224Z","iopub.status.idle":"2021-09-03T14:25:21.220043Z","shell.execute_reply.started":"2021-09-03T14:24:41.666184Z","shell.execute_reply":"2021-09-03T14:25:21.219122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train and test dataset are quite well balanced","metadata":{}},{"cell_type":"markdown","source":"# Correlations","metadata":{}},{"cell_type":"code","source":"# Plot dataframe\ndf = train.corr().round(5)\n\n# Mask to hide upper-right part of plot as it is a duplicate\nmask = np.zeros_like(df)\nmask[np.triu_indices_from(mask)] = True\n\n# Making a plot\nplt.figure(figsize=(16,16))\nax = sns.heatmap(df, annot=False, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\nax.set_title(\"Feature correlation heatmap\", fontsize=17)\nplt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n         rotation_mode=\"anchor\", weight=\"normal\")\nplt.setp(ax.get_yticklabels(), weight=\"normal\",\n         rotation_mode=\"anchor\", rotation=0, ha=\"right\")\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:25:21.221175Z","iopub.execute_input":"2021-09-03T14:25:21.221525Z","iopub.status.idle":"2021-09-03T14:25:55.592431Z","shell.execute_reply.started":"2021-09-03T14:25:21.221486Z","shell.execute_reply":"2021-09-03T14:25:55.591625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a very low correlation between features","metadata":{}},{"cell_type":"markdown","source":"## Checking how many na values in train and test","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:43:35.04385Z","iopub.execute_input":"2021-09-01T12:43:35.044253Z","iopub.status.idle":"2021-09-01T12:43:35.048912Z","shell.execute_reply.started":"2021-09-01T12:43:35.044217Z","shell.execute_reply":"2021-09-01T12:43:35.047441Z"}}},{"cell_type":"code","source":"print(\"(train, test) na --> \",(train.isna().sum().sum(), test.isna().sum().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:25:55.593818Z","iopub.execute_input":"2021-09-03T14:25:55.594192Z","iopub.status.idle":"2021-09-03T14:25:55.8925Z","shell.execute_reply.started":"2021-09-03T14:25:55.594153Z","shell.execute_reply":"2021-09-03T14:25:55.891595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quite a lot Na Values to handle. This table require a data cleaning\n## Data cleaning","metadata":{}},{"cell_type":"markdown","source":"Visualizing wow many Na values for each column","metadata":{}},{"cell_type":"code","source":"print(\"% Train NA for each feature, min, max\")\ntrain_na = train.drop(columns=\"claim\").isna().sum()\ntest_na = test.isna().sum()\n\nprint(f\"There are a minimum of {train_na.min()/len(train)*100} % of NA Values in each features in TRAIN df \")\nprint(f\"There are a maximum of {train_na.max()/len(train)*100} % of NA Values in each features in TRAIN df \")\nprint(\"Test NA for each feature, min, max\")\nprint(f\"There are a minimum of {test_na.min()/len(test)*100} % of NA Values in each features in TEST df \")\nprint(f\"There are a maximum of {test_na.max()/len(test)*100} % of NA Values in each features in TEST df \")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:25:55.893808Z","iopub.execute_input":"2021-09-03T14:25:55.894337Z","iopub.status.idle":"2021-09-03T14:25:56.452758Z","shell.execute_reply.started":"2021-09-03T14:25:55.894295Z","shell.execute_reply":"2021-09-03T14:25:56.451841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if there are concentrated NA values in each id for Train and Test df\n\nna_counts_train = train.isna().sum(axis=1).sort_values(ascending = False).value_counts()\n\nfig, ax = plt.subplots(figsize=(16, 8))\n\nbars = ax.bar(na_counts_train.index,\n              na_counts_train.values,\n              color=colors,\n              edgecolor=\"black\")\nax.set_title(\"N° missing NA for each id in TRAIN db\", fontsize=20, pad=15)\nax.set_ylabel(\"Missing Values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"N°of missing values for each row\", fontsize=14, labelpad=10)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in na_counts_train.values/(len(train)/100)],\n                 padding=5, fontsize=10, rotation=90)\nax.margins(0.025, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:25:56.454046Z","iopub.execute_input":"2021-09-03T14:25:56.454588Z","iopub.status.idle":"2021-09-03T14:25:57.000942Z","shell.execute_reply.started":"2021-09-03T14:25:56.454545Z","shell.execute_reply":"2021-09-03T14:25:56.99998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some id with a maximum of 14 missing feature. ","metadata":{}},{"cell_type":"code","source":"na_counts_test = test.isna().sum(axis=1).sort_values(ascending = False).value_counts()\n\n\nfig, ax = plt.subplots(figsize=(16, 8))\n\nbars = ax.bar(na_counts_test.index,\n              na_counts_test.values,\n              color=colors,\n              edgecolor=\"black\")\nax.set_title(\"N° missing NA for each id in TEST db\", fontsize=20, pad=15)\nax.set_ylabel(\"Missing Values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"N° of id\", fontsize=14, labelpad=10)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in na_counts_test.values/(len(test)/100)],\n                 padding=5, fontsize=10, rotation=90)\nax.margins(0.025, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:25:57.00233Z","iopub.execute_input":"2021-09-03T14:25:57.002674Z","iopub.status.idle":"2021-09-03T14:25:57.375484Z","shell.execute_reply.started":"2021-09-03T14:25:57.002636Z","shell.execute_reply":"2021-09-03T14:25:57.374651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only the 37% of id have a full stack o features with no NA both in Train and Test set","metadata":{}},{"cell_type":"code","source":"print(\"Rows with more then 1 NA in TRAIN df:\")\nprint((train.isna().sum(axis=1)>0).value_counts())\nprint((train.isna().sum(axis=1)>0).value_counts()/len(train)*100)\nprint(\"\\nRows with more then 1 NA in TEST df:\")\nprint((test.isna().sum(axis=1)>0).value_counts())\nprint((test.isna().sum(axis=1)>0).value_counts()/len(test)*100)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:25:57.376671Z","iopub.execute_input":"2021-09-03T14:25:57.376999Z","iopub.status.idle":"2021-09-03T14:25:58.041139Z","shell.execute_reply.started":"2021-09-03T14:25:57.376956Z","shell.execute_reply":"2021-09-03T14:25:58.040118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns = \"claim\")\ny = train.claim\nX_test = test.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:39:25.179641Z","iopub.execute_input":"2021-09-03T14:39:25.179974Z","iopub.status.idle":"2021-09-03T14:39:25.599265Z","shell.execute_reply.started":"2021-09-03T14:39:25.179943Z","shell.execute_reply":"2021-09-03T14:39:25.598441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling data","metadata":{}},{"cell_type":"code","source":"x_Mm_scaler = MinMaxScaler()\nX = pd.DataFrame(x_Mm_scaler.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(x_Mm_scaler.transform(test), columns=test.columns)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:43:31.031316Z","iopub.execute_input":"2021-09-03T14:43:31.031691Z","iopub.status.idle":"2021-09-03T14:43:33.87876Z","shell.execute_reply.started":"2021-09-03T14:43:31.03166Z","shell.execute_reply":"2021-09-03T14:43:33.877907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:26:00.453702Z","iopub.execute_input":"2021-09-03T14:26:00.453981Z","iopub.status.idle":"2021-09-03T14:26:00.457974Z","shell.execute_reply.started":"2021-09-03T14:26:00.453953Z","shell.execute_reply":"2021-09-03T14:26:00.45713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    'n_estimators': 10000, \n 'learning_rate': 0.1, \n 'subsample': 0.6, \n 'colsample_bytree': 0.5, \n 'max_depth': 6, \n 'booster': 'gbtree', \n 'tree_method': 'gpu_hist', \n 'random_state': 42, \n 'n_jobs': 4}","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:49:06.822102Z","iopub.execute_input":"2021-09-03T14:49:06.822444Z","iopub.status.idle":"2021-09-03T14:49:06.828495Z","shell.execute_reply.started":"2021-09-03T14:49:06.822409Z","shell.execute_reply":"2021-09-03T14:49:06.827061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:43:37.962599Z","iopub.execute_input":"2021-09-03T14:43:37.962935Z","iopub.status.idle":"2021-09-03T14:43:38.026705Z","shell.execute_reply.started":"2021-09-03T14:43:37.962904Z","shell.execute_reply":"2021-09-03T14:43:38.025739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsplits = 6\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n    print(fold, f\"X_train = {X_train.shape} - y_train: {y_train.shape}\")\n    print(fold, f\"X_valid = {X_valid.shape} - y_valid: {y_valid.shape}\")\n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n              verbose=False)\n    print(\"fitted\")\n    preds += model.predict(X_test) / splits\n    print(preds.shape)\n    print(\"preds ok\")\n    model_fi += model.feature_importances_\n    print(\"model_fi ok\")\n    oof_preds[valid_indicies] = model.predict(X_valid)\n    print(oof_preds)\n    oof_preds[oof_preds < 0] = 0\n#     fold_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(np.array(y_valid).reshape(-1,1)), y_scaler.inverse_transform(np.array(oof_preds[valid_idx]).reshape(-1,1))))\n    fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_indicies]))\n    print(f\"Fold {fold} RMSE: {fold_rmse}\")\n#         print(f\"Trees: {model.tree_count_}\")\n    total_mean_rmse += fold_rmse / splits\nprint(f\"\\nOverall RMSE: {total_mean_rmse}\") ","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:43:46.826324Z","iopub.execute_input":"2021-09-03T14:43:46.826668Z","iopub.status.idle":"2021-09-03T14:48:25.406676Z","shell.execute_reply.started":"2021-09-03T14:43:46.826636Z","shell.execute_reply":"2021-09-03T14:48:25.405745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb public Score: \npredictions = pd.DataFrame()\npredictions[\"id\"] = test.index\npredictions[\"claim\"] = preds\n\npredictions.to_csv('submission_xgb_no_NA.csv', index=False, header=predictions.columns)\npredictions.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:49:28.856703Z","iopub.execute_input":"2021-09-03T14:49:28.857043Z","iopub.status.idle":"2021-09-03T14:49:30.163495Z","shell.execute_reply.started":"2021-09-03T14:49:28.857011Z","shell.execute_reply":"2021-09-03T14:49:30.162465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5, 5))\npie = ax.pie([(predictions.claim < 0.5).sum(), (predictions.claim >= 0.5).sum()],\n             labels=[\"0\", \"1\"],\n             colors=[\"orange\", \"blue\"],\n             textprops={\"fontsize\": 15},\n             autopct='%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Target distribuition\\n\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:50:49.055544Z","iopub.execute_input":"2021-09-03T14:50:49.055876Z","iopub.status.idle":"2021-09-03T14:50:49.139791Z","shell.execute_reply.started":"2021-09-03T14:50:49.055843Z","shell.execute_reply":"2021-09-03T14:50:49.138834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*****************\nWORK IN PROGRESS\n*****************\n## Filling NA values\nThere are some ML alghorithms that doesn't support the presence of NA values in dataframe. \nI'd like to verify the efficiency of several methods applying a untuned XGBR:\n\n* Filling all NA qith zeros\n* Filling all NA wth the mean value \n* Filling all NA with the median value for each features\n* Filling all NA with the median value for each features\n* Applying a ML algorith to search an appropriate Value [is it worth it???]\n\nXGBC can handle a DF with NA, so let's try to fit it without NA handler","metadata":{}},{"cell_type":"markdown","source":"# XGBC without NA handling","metadata":{}},{"cell_type":"code","source":"%%time\nsplits = 6\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n    print(fold, f\"X_train = {X_train.shape} - y_train: {y_train.shape}\")\n    print(fold, f\"X_valid = {X_valid.shape} - y_valid: {y_valid.shape}\")\n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n              verbose=False)\n    print(\"fitted\")\n    preds += model.predict(X_test) / splits\n    print(preds.shape)\n    print(\"preds ok\")\n    model_fi += model.feature_importances_\n    print(\"model_fi ok\")\n    oof_preds[valid_indicies] = model.predict(X_valid)\n    print(oof_preds)\n    oof_preds[oof_preds < 0] = 0\n#     fold_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(np.array(y_valid).reshape(-1,1)), y_scaler.inverse_transform(np.array(oof_preds[valid_idx]).reshape(-1,1))))\n    fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_indicies]))\n    print(f\"Fold {fold} RMSE: {fold_rmse}\")\n#         print(f\"Trees: {model.tree_count_}\")\n    total_mean_rmse += fold_rmse / splits\nprint(f\"\\nOverall RMSE: {total_mean_rmse}\") ","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:27:13.142742Z","iopub.status.idle":"2021-09-03T14:27:13.143124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBC with Zeros  NA values","metadata":{}},{"cell_type":"markdown","source":"We will use sklearn \"Simple Imputer\".\nWe will fit the SimpleImputer only in the Train Set. We will aplly it to both Train and Test set to avoid \nhttps://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:27:13.145409Z","iopub.status.idle":"2021-09-03T14:27:13.146178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer_zeros = SimpleImputer(strategy=\"constant\", fill_value = 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T14:27:13.147378Z","iopub.status.idle":"2021-09-03T14:27:13.148165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}