{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello everybody.","metadata":{}},{"cell_type":"markdown","source":"# Libraries and Data import","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\n\nfrom matplotlib.lines import Line2D\n\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.impute import SimpleImputer\n\nimport optuna\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\n# import warnings\n# warnings.simplefilter(action='ignore', category=UserWarning)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T07:24:54.982068Z","iopub.execute_input":"2021-09-08T07:24:54.982415Z","iopub.status.idle":"2021-09-08T07:24:58.387002Z","shell.execute_reply.started":"2021-09-08T07:24:54.982383Z","shell.execute_reply":"2021-09-08T07:24:58.386144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the data\ntrain = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv', index_col='id')\ntest = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv', index_col='id')\nsample = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:25:00.230858Z","iopub.execute_input":"2021-09-08T07:25:00.231223Z","iopub.status.idle":"2021-09-08T07:25:41.177282Z","shell.execute_reply.started":"2021-09-08T07:25:00.231193Z","shell.execute_reply":"2021-09-08T07:25:41.17634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NA values in train and test","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:43:35.04385Z","iopub.execute_input":"2021-09-01T12:43:35.044253Z","iopub.status.idle":"2021-09-01T12:43:35.048912Z","shell.execute_reply.started":"2021-09-01T12:43:35.044217Z","shell.execute_reply":"2021-09-01T12:43:35.047441Z"}}},{"cell_type":"code","source":"print(\"(train, test) na --> \",(train.isna().sum().sum(), test.isna().sum().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:26:06.179129Z","iopub.execute_input":"2021-09-08T07:26:06.179612Z","iopub.status.idle":"2021-09-08T07:26:06.494525Z","shell.execute_reply.started":"2021-09-08T07:26:06.179562Z","shell.execute_reply":"2021-09-08T07:26:06.49358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_na_train_df = train.drop(columns=\"claim\").isna().sum(axis = 1)\nprint(is_na_train_df.shape)\n\nis_na_test_df = test.isna().sum(axis = 1)\nprint(is_na_test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:26:28.195277Z","iopub.execute_input":"2021-09-08T07:26:28.195784Z","iopub.status.idle":"2021-09-08T07:26:28.743966Z","shell.execute_reply.started":"2021-09-08T07:26:28.195718Z","shell.execute_reply":"2021-09-08T07:26:28.742999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation: Siple Imputer + NA to median","metadata":{}},{"cell_type":"code","source":"x_Mm_scaler = MinMaxScaler()\nX = pd.DataFrame(x_Mm_scaler.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\ny = train.claim\nX_test = pd.DataFrame(x_Mm_scaler.transform(test), columns=test.columns)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:26:45.063325Z","iopub.execute_input":"2021-09-08T07:26:45.063667Z","iopub.status.idle":"2021-09-08T07:26:47.026281Z","shell.execute_reply.started":"2021-09-08T07:26:45.063637Z","shell.execute_reply":"2021-09-08T07:26:47.025376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer_zeros = SimpleImputer(strategy=\"median\")\nX = pd.DataFrame(imputer_zeros.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(imputer_zeros.transform(test), columns=test.columns)\nX = pd.DataFrame(x_Mm_scaler.fit_transform(X),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(x_Mm_scaler.transform(X_test), columns=test.columns)\nprint(\"(train, test) na --> \",(X.isna().sum().sum(), X_test.isna().sum().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:27:04.794586Z","iopub.execute_input":"2021-09-08T07:27:04.795016Z","iopub.status.idle":"2021-09-08T07:27:33.768572Z","shell.execute_reply.started":"2021-09-08T07:27:04.794972Z","shell.execute_reply":"2021-09-08T07:27:33.767479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[\"isNA\"] =is_na_train_df\nprint(X.shape)\nX_test[\"isNA\"] = is_na_test_df\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:28:33.566445Z","iopub.execute_input":"2021-09-08T07:28:33.566837Z","iopub.status.idle":"2021-09-08T07:28:33.608334Z","shell.execute_reply.started":"2021-09-08T07:28:33.566799Z","shell.execute_reply":"2021-09-08T07:28:33.607355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as pyplt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model_optuna_xgb(trial, X_train, X_valid, y_train, y_valid):\n    \"\"\"\n    A function to train a model using different hyperparamerters combinations provided by Optuna. \n    Loss of validation data predictions is returned to estimate hyperparameters effectiveness.\n    \"\"\"\n    preds = 0\n       \n    #A set of hyperparameters to optimize by optuna\n    xgb_params = {\n                 \"n_estimators\": trial.suggest_categorical('n_estimators', [10000]),\n                 \"learning_rate\": trial.suggest_float('learning_rate', 0.01, 0.8),\n                 \"subsample\": trial.suggest_float('subsample', 0.5, 0.95),\n                 \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.5, 0.95),\n                 \"max_depth\": trial.suggest_int(\"max_depth\", 5, 16),\n                 \"booster\": trial.suggest_categorical('booster', [\"gbtree\"]),\n                 \"tree_method\": trial.suggest_categorical('tree_method', [\"gpu_hist\"]),\n                 \"reg_lambda\": trial.suggest_float('reg_lambda', 2, 100),\n                 \"reg_alpha\": trial.suggest_float('reg_alpha', 1, 50),\n                 \"random_state\": trial.suggest_categorical('random_state', [42]),\n                 \"n_jobs\": trial.suggest_categorical('n_jobs', [4]),\n                    }\n\n    # Model loading and training\n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n              verbose=False)\n    \n    print(f\"Number of boosting rounds: {model.best_iteration}\")\n    oof = model.predict(X_valid)\n    oof[oof<0] = 0\n    \n    return np.sqrt(mean_squared_error(y_valid, oof))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:28:40.511551Z","iopub.execute_input":"2021-09-08T07:28:40.511909Z","iopub.status.idle":"2021-09-08T07:28:40.522353Z","shell.execute_reply.started":"2021-09-08T07:28:40.511874Z","shell.execute_reply":"2021-09-08T07:28:40.521374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nskf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n\n# Setting optuna verbosity to show only warning messages\n# If the line is uncommeted each iteration results will be shown\noptuna.logging.set_verbosity(optuna.logging.WARNING)\ntime_limit = 3600 * 2\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(lambda trial: train_model_optuna_xgb(trial, \n                                                X_train, \n                                                X_valid,\n                                                y_train, \n                                                y_valid),\n               n_trials = 100,\n               timeout=time_limit\n              )\n # Showing optimization results\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial parameters:', study.best_trial.params)\nprint('Best score:', study.best_value)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:29:06.359244Z","iopub.execute_input":"2021-09-08T07:29:06.359598Z","iopub.status.idle":"2021-09-08T07:29:51.20173Z","shell.execute_reply.started":"2021-09-08T07:29:06.359568Z","shell.execute_reply":"2021-09-08T07:29:51.200673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:30:12.341658Z","iopub.execute_input":"2021-09-08T07:30:12.342047Z","iopub.status.idle":"2021-09-08T07:30:12.347514Z","shell.execute_reply.started":"2021-09-08T07:30:12.342015Z","shell.execute_reply":"2021-09-08T07:30:12.346462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsplits = 6\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n    print(fold, f\"X_train = {X_train.shape} - y_train: {y_train.shape}\")\n    print(fold, f\"X_valid = {X_valid.shape} - y_valid: {y_valid.shape}\")\n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=100,\n              verbose=False)\n    print(\"fitted\")\n    preds += model.predict(X_test) / splits\n    print(preds.shape)\n    print(\"preds ok\")\n    model_fi += model.feature_importances_\n    print(\"model_fi ok\")\n    oof_preds[valid_indicies] = model.predict(X_valid)\n    print(oof_preds)\n    oof_preds[oof_preds < 0] = 0\n#     fold_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(np.array(y_valid).reshape(-1,1)), y_scaler.inverse_transform(np.array(oof_preds[valid_idx]).reshape(-1,1))))\n    fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_indicies]))\n    print(f\"Fold {fold} RMSE: {fold_rmse}\")\n#         print(f\"Trees: {model.tree_count_}\")\n    total_mean_rmse += fold_rmse / splits\nprint(f\"\\nOverall RMSE: {total_mean_rmse}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:30:14.459331Z","iopub.execute_input":"2021-09-08T07:30:14.459696Z","iopub.status.idle":"2021-09-08T07:35:18.429445Z","shell.execute_reply.started":"2021-09-08T07:30:14.459657Z","shell.execute_reply":"2021-09-08T07:35:18.428488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb public Score untuned and fast parameters: 0.76817\npredictions = pd.DataFrame()\npredictions[\"id\"] = test.index\npredictions[\"claim\"] = preds\n\npredictions.to_csv('submission_xgb_optimized.csv', index=False, header=predictions.columns)\npredictions.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:35:44.051251Z","iopub.execute_input":"2021-09-08T07:35:44.051598Z","iopub.status.idle":"2021-09-08T07:35:45.560551Z","shell.execute_reply.started":"2021-09-08T07:35:44.051566Z","shell.execute_reply":"2021-09-08T07:35:45.559717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final considerations:\nThis are the results of the simulation :<br>","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n# Define the model\n","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:51:52.000578Z","iopub.execute_input":"2021-09-08T07:51:52.001029Z","iopub.status.idle":"2021-09-08T07:51:52.00553Z","shell.execute_reply.started":"2021-09-08T07:51:52.000995Z","shell.execute_reply":"2021-09-08T07:51:52.004522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for plotting Confusion Matrix\n\n\ndef plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i in range (cm.shape[0]):\n        for j in range (cm.shape[1]):\n            plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:47:33.109839Z","iopub.execute_input":"2021-09-08T07:47:33.11036Z","iopub.status.idle":"2021-09-08T07:47:33.12627Z","shell.execute_reply.started":"2021-09-08T07:47:33.110314Z","shell.execute_reply":"2021-09-08T07:47:33.125393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feeding parameters in the CM Function\n\ncm = confusion_matrix(y_true=y, y_pred=oof_preds)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:51:58.565923Z","iopub.execute_input":"2021-09-08T07:51:58.566269Z","iopub.status.idle":"2021-09-08T07:52:02.421677Z","shell.execute_reply.started":"2021-09-08T07:51:58.566239Z","shell.execute_reply":"2021-09-08T07:52:02.420763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(oof_preds)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:27.793231Z","iopub.execute_input":"2021-09-08T07:50:27.793566Z","iopub.status.idle":"2021-09-08T07:50:27.798804Z","shell.execute_reply.started":"2021-09-08T07:50:27.793534Z","shell.execute_reply":"2021-09-08T07:50:27.798001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Labels for the CM\n\ncm_plot_labels = ['Negative','Positive']","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:07:05.147192Z","iopub.execute_input":"2021-09-08T08:07:05.147472Z","iopub.status.idle":"2021-09-08T08:07:05.157102Z","shell.execute_reply.started":"2021-09-08T08:07:05.14741Z","shell.execute_reply":"2021-09-08T08:07:05.156252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the CM\n\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:07:05.15876Z","iopub.execute_input":"2021-09-08T08:07:05.159111Z","iopub.status.idle":"2021-09-08T08:07:05.219888Z","shell.execute_reply.started":"2021-09-08T08:07:05.159068Z","shell.execute_reply":"2021-09-08T08:07:05.218527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc #for model evaluation\ny_true=y\ny_pred=oof_preds\nfpr, tpr, thresholds = roc_curve(y_true, y_pred)\n\nfig, ax = plt.subplots()\nax.plot(fpr, tpr)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for TPS 09')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:54:16.438416Z","iopub.execute_input":"2021-09-08T07:54:16.438835Z","iopub.status.idle":"2021-09-08T07:54:16.678372Z","shell.execute_reply.started":"2021-09-08T07:54:16.438798Z","shell.execute_reply":"2021-09-08T07:54:16.677283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}