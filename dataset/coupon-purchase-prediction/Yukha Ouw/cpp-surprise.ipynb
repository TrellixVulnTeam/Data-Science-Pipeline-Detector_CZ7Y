{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\npd.set_option('display.max_columns', None)\nimport itertools\nfrom surprise import Reader, Dataset\nfrom surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering\n\nfrom zipfile import ZipFile\n              \nimport time\nimport gc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_dir = '../input/coupon-purchase-prediction'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#unzip dataset\nwith ZipFile(os.path.join(ds_dir,\"coupon_detail_train.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"coupon_list_test.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"coupon_list_train.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"coupon_visit_train.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"sample_submission.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"user_list.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataset\ncd_train = pd.read_csv('coupon_detail_train.csv')\ncl_test = pd.read_csv('coupon_list_test.csv')\ncl_train = pd.read_csv('coupon_list_train.csv')\n#cv_train = pd.read_csv('coupon_visit_train.csv')\n#pref_loc = pd.read_csv(os.path.join(ds_dir,'prefecture_locations.csv'))\nsample_sub = pd.read_csv('sample_submission.csv')\nuser_list = pd.read_csv('user_list.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Translator\npref = pd.read_csv(os.path.join(dsdir,'pref.csv'),delimiter=';',index_col='jpn')\npref_office = pd.read_csv(os.path.join(dsdir,'pref_office.csv'),delimiter=';',index_col='jpn')\nsmall_area_name = pd.read_csv(os.path.join(dsdir,'small_area_name.csv'),delimiter=';',index_col='jpn')\nbig_area_name = pd.read_csv(os.path.join(dsdir,'big_area_name.csv'),delimiter=';',index_col='jpn')\ncapsule_text = pd.read_csv(os.path.join(dsdir,'capsule_text.csv'),delimiter=';',index_col='jpn')\ngenre_name = pd.read_csv(os.path.join(dsdir,'genre.csv'),delimiter=';',index_col='jpn')","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Translate JPN TO EN","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#CAPSULE TEXT\ncl_test.CAPSULE_TEXT = cl_test.CAPSULE_TEXT.replace(capsule_text.to_dict()['en'])\ncl_train.CAPSULE_TEXT = cl_train.CAPSULE_TEXT.replace(capsule_text.to_dict()['en'])\n\n#GENRE NAME\ncl_test.GENRE_NAME = cl_test.GENRE_NAME.replace(genre_name.to_dict()['en'])\ncl_train.GENRE_NAME = cl_train.GENRE_NAME.replace(genre_name.to_dict()['en'])\n\n#PREF NAME\ncl_test.ken_name = cl_test.ken_name.replace(pref.to_dict()['en'])\ncl_train.ken_name = cl_train.ken_name.replace(pref.to_dict()['en'])\npref_loc.PREF_NAME = pref_loc.PREF_NAME.replace(pref.to_dict()['en'])\nuser_list.PREF_NAME = user_list.PREF_NAME.replace(pref.to_dict()['en'])\n\n#PREFECTUAL_OFFICE\npref_loc.PREFECTUAL_OFFICE = pref_loc.PREFECTUAL_OFFICE.replace(pref_office.to_dict()['en'])\n\n#SMALL_AREA_NAME\ncd_train.SMALL_AREA_NAME = cd_train.SMALL_AREA_NAME.replace(small_area_name.to_dict()['en'])\ncl_test.small_area_name = cl_test.small_area_name.replace(small_area_name.to_dict()['en'])\ncl_train.small_area_name = cl_train.small_area_name.replace(small_area_name.to_dict()['en'])\n\n#large_area_name\ncl_test.large_area_name = cl_test.large_area_name.replace(big_area_name.to_dict()['en'])\ncl_train.large_area_name = cl_train.large_area_name.replace(big_area_name.to_dict()['en'])","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing and Convert Data to Surprise Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cd_train = cd_train[['PURCHASEID_hash','USER_ID_hash','COUPON_ID_hash']]\ncd_train = pd.merge(cd_train,cd_train.groupby(['USER_ID_hash', 'COUPON_ID_hash']).size().reset_index(name=\"PURCHASE_COUNT\"),left_on=['USER_ID_hash', 'COUPON_ID_hash'],right_on=['USER_ID_hash', 'COUPON_ID_hash'],how='left')\ncd_train.drop('PURCHASEID_hash',axis=1,inplace=True)\ncd_train['PURCHASE_COUNT'] = np.log(cd_train['PURCHASE_COUNT']+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_list = user_list[['USER_ID_hash']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cl_train = cl_train[['COUPON_ID_hash']]\ncl_test = cl_test[['COUPON_ID_hash']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Permutation of User-CouponTest\nclist = cl_test.COUPON_ID_hash.unique().tolist()\nulist = user_list.USER_ID_hash.unique().tolist()\n\nrelations = [r for r in itertools.product(ulist, clist)]\nrelations = pd.DataFrame(relations,columns=['USER_ID_hash', 'COUPON_ID_hash'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reader = Reader(rating_scale=(cd_train['PURCHASE_COUNT'].min()-0.5,cd_train['PURCHASE_COUNT'].max()+0.5))\ndata = Dataset.load_from_df(cd_train, reader)\ntrainset = data.build_full_trainset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(row):\n    return model.predict(row.USER_ID_hash,row.COUPON_ID_hash).est\n\ndef clean_prediction(row):\n    data = row.PURCHASED_COUPONS\n    data = str(\"\".join(str(data))[2:-2].replace(\"', '\",\" \"))\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"surprises = {\n    'SVD' : SVD(verbose=1,random_state=0),\n    'SVDpp' : SVDpp(verbose=1,random_state=0),\n    'SlopeOne' : SlopeOne(),\n    'NMF' : NMF(verbose=1,random_state=0),\n    'NormalPredictor' : NormalPredictor(),\n    'BaselineOnly_ALS' : BaselineOnly(verbose=1,bsl_options={'method':'als'}),\n    'BaselineOnly_SGD' : BaselineOnly(verbose=1,bsl_options={'method':'sgd'}),\n    'CoClustering' : CoClustering(verbose=1,random_state=0),\n    #'KNNBaseline_ALS' : KNNBaseline(verbose=1,bsl_options={'method':'als'}),\n    #'KNNBaseline_SGD' : KNNBaseline(verbose=1,bsl_options={'method':'sgd'}),\n    #'KNNBasic' : KNNBasic(verbose=1),\n    #'KNNWithMeans' : KNNWithMeans(verbose=1),\n    #'KNNWithZScore' : KNNWithZScore(verbose=1),\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit Predict Submission","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for key, item in surprises.items():\n    print(key)\n    model_name = key\n    start = time.time()\n    model = item.fit(trainset)\n    print(model_name,'Fit Time :',time.time()-start)\n\n    start = time.time()\n    submission = relations.copy()\n    submission['PURCHASE_COUNT'] = submission.apply(predict, axis=1)\n    print(model_name,'Predict Time :',time.time()-start)\n\n    submission.sort_values('PURCHASE_COUNT', ascending=False, inplace=True)\n    submission = submission.groupby(['USER_ID_hash']).head(10).reset_index()\n    submission = submission.groupby('USER_ID_hash')['COUPON_ID_hash'].apply(list).reset_index(name='PURCHASED_COUPONS')\n    submission['PURCHASED_COUPONS'] = submission.apply(clean_prediction, axis=1)\n    submission.to_csv('cpp_surprise_'+model_name+'.csv', index=False)\n    print(model_name,'Done')\n    \n    del submission\n    del model\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}