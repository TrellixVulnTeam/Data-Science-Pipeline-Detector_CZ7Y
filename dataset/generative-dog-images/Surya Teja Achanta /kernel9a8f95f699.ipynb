{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\n\nbatchSize = 64 \nimageSize = 64 \n\ndataset = dset.ImageFolder(root=\"../input/all-dogs/\",\n                               transform=transforms.Compose([\n                                   transforms.Resize(imageSize),\n                                   transforms.CenterCrop(imageSize),\n                                   transforms.ToTensor(),\n                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                               ]))\ndataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2)\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\nclass G(nn.Module):\n\n    def __init__(self):\n        super(G, self).__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(100, 1024, 4, 1, 0, bias = False),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias = False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 3, 1, 1,bias = True),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output\nnetG = G()\nnetG.apply(weights_init)\nnetG = netG.cuda()\n\nclass D(nn.Module):\n\n    def __init__(self):\n        super(D, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n            nn.LeakyReLU(0.2, inplace = True),\n            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace = True),\n            nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace = True),\n            nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace = True),\n            nn.Conv2d(512, 1024, 3, 1, 1, bias = True),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.2, inplace = True),\n            nn.Conv2d(1024, 1, 4, 1, 0, bias = False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output.view(-1)\n\ndef train(dataloader,netD,netG,optimizerD,optimizerG,criterion,total_epochs):\n    for epoch in range(total_epochs):\n        for i, data in enumerate(dataloader, 0):\n\n            netD.zero_grad()\n\n            real = data[0]\n            input = Variable(real.cuda())\n            target = Variable(torch.ones(input.size()[0]).cuda())\n            output = netD(input)\n            errD_real = criterion(output, target)\n\n            noise = Variable(torch.randn(input.size()[0], 100, 1, 1).cuda())\n            fake = netG(noise)\n            target = Variable(torch.zeros(input.size()[0]).cuda())\n            output = netD(fake.detach())\n            errD_fake = criterion(output, target)\n\n            errD = errD_real + errD_fake\n            errD.backward()\n            optimizerD.step()\n\n            netG.zero_grad()\n            target = Variable(torch.ones(input.size()[0]).cuda())\n            output = netD(fake)\n            errG = criterion(output, target)\n            errG.backward()\n            optimizerG.step()\n\n            if(i%20==0):\n                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, total_epochs, i, len(dataloader),(errD).item(), (errG).item()))\n        \n        #vutils.save_image(real, '%s/real_samples.png' % \"./results1\", normalize = True)\n        #fake = netG(noise)\n        #vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results1\", epoch), normalize = True)\n    \n    #save the trained weights for future reference\n    \"\"\"torch.save({\n                'epoch': epoch,\n                'seg_state_dict': netG.state_dict(),\n                'f_loss_d': errD_fake,\n                'r_loss_d': errD_real,\n                'r_loss_g': errG,\n                'disc_state_dict': netD.state_dict(),\n                }, 'checkpointWeights.pth')\n    \"\"\"\nnetD = D()\nnetD.apply(weights_init)\nnetD = netD.cuda()\ntotal_epochs = 200\n\ncriterion = nn.BCELoss()\noptimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n\ntrain(dataloader,netD,netG,optimizerD,optimizerG,criterion,total_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom torchvision.utils import save_image\nif not os.path.exists('../output_images'):\n    os.mkdir('../output_images')\nim_batch_size = 50\nn_images=10000\n\nfor i_batch in range(0, n_images, im_batch_size):\n    noise = Variable(torch.randn(im_batch_size, 100, 1, 1).cuda())\n    gen_images = netG(noise)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))\n        \nimport shutil\nshutil.make_archive('images', 'zip', '../output_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd kaggle/\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd all-dogs/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd all-dogs/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}