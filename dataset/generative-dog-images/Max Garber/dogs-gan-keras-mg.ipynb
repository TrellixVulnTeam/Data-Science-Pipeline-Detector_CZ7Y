{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xml.etree.ElementTree as ET \nimport matplotlib.pyplot as plt, zipfile \nfrom PIL import Image \n\nfrom tqdm import tqdm\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.initializers import RandomNormal, Constant\nfrom keras.layers import Input, Dense, Dropout, Flatten, Reshape , LeakyReLU, PReLU\nfrom keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, UpSampling2D, Conv2DTranspose,BatchNormalization\nfrom keras import regularizers\nfrom keras.optimizers import SGD, Adam\n\nimport time\nstart_time = time.time()\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"PATH = '../input/all-dogs/all-dogs/'\nimageNames = os.listdir(PATH)\n#print(images)\nimg = plt.imread(PATH + imageNames[np.random.randint(0,len(imageNames))])\nplt.imshow(img)\nprint(img.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_ANNO = '../input/annotation/Annotation/'\nbreeds = os.listdir(PATH_ANNO)\nimagesInput = np.zeros((len(imageNames)*2,64,64,3))\nimages_breed = []\ni = 0\nprint(imagesInput.shape)\nfor breed in breeds:\n    for dog in os.listdir(PATH_ANNO+breed):\n        tree = ET.parse(PATH_ANNO + breed + '/' + dog)\n        root = tree.getroot()\n        try: img = Image.open(PATH + root.find('filename').text +'.jpg')\n        except: continue\n        for obj in root.findall('object'):\n            bndbox = obj.find('bndbox')\n            xmin = int(bndbox.find('xmin').text)\n            ymin = int(bndbox.find('ymin').text)\n            xmax = int(bndbox.find('xmax').text)\n            ymax = int(bndbox.find('ymax').text)\n            img_crop = img.crop((xmin, ymin, xmax, ymax))\n            w = img_crop.size[0]; h = img_crop.size[1];\n            a=0; b=0\n            if w<h:\n                w2 = 64; h2 = int((64/w)*h)\n                #b = np.random.randint(0,(h2-64)) if (h2-64 > 0) else 0\n            else:\n                h2 = 64; w2 = int((64/h)*w)\n                #a = np.random.randint(0,(w2-64)) if (w2-64 > 0) else 0\n            img_crop = img_crop.resize((w2,h2), Image.ANTIALIAS)\n            img_crop = img_crop.crop((0+a, 0+b, 64+a, 64+b))\n            imagesInput[i,:,:,:] = np.asarray(img_crop)\n            images_breed.append(obj.find('name').text)\n            i += 1\nimagesInput = imagesInput[:i,:,:,:]        \nflip_imagesInput = np.flip(imagesInput,2)\nimagesInput = np.vstack((imagesInput,flip_imagesInput))\nimages_breed = images_breed + images_breed\nimagesInput = imagesInput / (255 / 2) - 1\nprint(imagesInput.shape,len(images_breed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnd = np.random.randint(0,imagesInput.shape[0])\nplt.imshow(imagesInput[rnd]/2 + .5)\nprint(imagesInput[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_img_full():    \n    imagesInput = np.zeros((len(imageNames),64,64,3))\n    i = 0\n    for i, dog in enumerate(imageNames):\n        img = Image.open(PATH + dog)\n        w = img.size[0]; h = img.size[1];\n        a=0; b=0\n        if w<h:\n            w2 = 64; h2 = int((64/w)*h)\n            b = np.random.randint(0,(h2-64)) if (h2-64 > 0) else 0\n        else:\n            h2 = 64; w2 = int((64/h)*w)\n            a = np.random.randint(0,(w2-64)) if (w2-64 > 0) else 0\n        img = img.resize((w2,h2), Image.ANTIALIAS)\n        img = img.crop((0+a, 0+b, 64+a, 64+b))\n        imagesInput[i,:,:,:] = np.asarray(img)\n    imagesInput = imagesInput / (255 / 2) - 1\n    print(imagesInput.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop = 0.1\ninit = RandomNormal(mean=0.0, stddev=0.02) #'glorot_uniform'#\n\ngen_input = Input(shape=(100,))\nx = Dense(1024, activation='relu',)(gen_input)\nx = BatchNormalization(momentum=0.8)(x)\nx = Reshape((4,4,64))(x)\n\nx = Conv2DTranspose(128, (3, 3),strides=(1, 1),padding='same',kernel_initializer=init)(x)\n#x = Conv2D(128, (3, 3), padding='same',kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)#momentum=0.8\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\n#x = UpSampling2D((2, 2))(x)\nx = Dropout(drop)(x, training=True)#(x, training=True)\n\n\nx = Conv2DTranspose(128, (3, 3),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\nx = Conv2DTranspose(128, (5,5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\n#x = Conv2D(128, (3, 3), padding='same',kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\n#x = UpSampling2D((2, 2))(x)\nx = Dropout(drop)(x, training=True)\n\nx = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same',kernel_initializer=init)(x)\nx = BatchNormalization()(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\n\nx = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same',kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\n#x = AveragePooling2D(pool_size=(2, 2),strides=(1, 1),padding='same')(x)\n\nx = Conv2D(3, (5, 5), activation='tanh', padding='same',kernel_initializer=init)(x)\n\ngenerator = Model(gen_input, x)\ngenerator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy')\ngenerator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inpt = np.random.random(100*2).reshape(2,100)\nimg = generator.predict(inpt)\nprint(img.shape)\nplt.imshow(img[0]/2+.5)\nplt.imshow(img[1]/2+.5)\n#print(img[1]/2+.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init = RandomNormal(mean=0.0, stddev=0.02)\ndrop = 0.0\ndis_input = Input(shape=(64,64,3,))\nx = Conv2D(32, (5, 5), padding='same',kernel_initializer=init)(dis_input)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = Conv2D(64, (5, 5), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = Conv2D(64, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = Conv2D(128, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = Conv2D(256, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = Conv2D(64, (3, 3), padding='valid',strides=(1, 1),kernel_initializer=init)(x)\n#x = LeakyReLU()(x)\n#x = BatchNormalization()(x)\n#x = Dropout(drop)(x)\n\nx = Conv2D(512, (3, 3), padding='same',strides=(1, 1),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = AveragePooling2D(pool_size=(2, 2),strides=(1, 1),padding='same')(x)\n\nx = Flatten()(x)\nx = Dense(1 , activation = \"sigmoid\")(x)\ndiscriminator = Model(dis_input, x)\ndiscriminator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy')\ndiscriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan_input = Input(shape=(100,))\ndiscriminator.trainable=False\nx = generator(gan_input)\nx = discriminator(x)\ngan = Model(gan_input, x)\ngan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\ngan.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_noise(batch_size=128):\n    noise = np.random.randn(batch_size,100)\n    #noise = np.random.normal(size = 100 * batch_size).reshape(batch_size,100)\n    # noise =  np.random.random(100 * batch_size).reshape(batch_size,100)\n    return noise ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(epochs=3, batch_size=256):\n    imagesProgress = np.zeros((epochs,64,64,3))\n    progress_noise = gen_noise(1)\n    for e in range(1,epochs+1):\n        #print(imagesInput.shape[0]//batch_size)\n        #print('Epoch:', e)\n        np.random.shuffle(imagesInput)\n        for b in tqdm(range(imagesInput.shape[0]//batch_size)):\n            noise = gen_noise(batch_size)\n            gen_imgs = generator.predict(noise)\n            real_imgs = imagesInput[b*batch_size:(b+1)*batch_size]\n            #X = np.concatenate([real_imgs, gen_imgs])\n            #y_dis = np.zeros(2*batch_size) \n            #y_dis[:batch_size] = .8 +  np.random.normal(loc=0, scale=.050)\n            \n            y_dis = np.ones(batch_size) - np.abs(np.random.normal(loc=.2, scale=.1))\n            #y_dis = 1 - y_dis if np.random.random() <= .05 else y_dis\n            discriminator.trainable=True\n            discriminator.train_on_batch(real_imgs,y_dis)\n            \n            y_dis.fill(0.0)\n            y_dis += np.abs(np.random.normal(loc=.2, scale=.1))\n            #y_dis = 1 - y_dis if np.random.random() <= .05 else y_dis\n            discriminator.trainable=True\n            discriminator.train_on_batch(gen_imgs,y_dis)\n                        \n            noise = gen_noise(batch_size//4)\n            #noise[:,np.random.randint(100)] += 1\n            y_gen = np.ones(batch_size//4) - .1\n            \n            discriminator.trainable=False\n            gan.train_on_batch(noise, y_gen)\n            inpt = np.random.random(100).reshape(1,100)\n                    \n        inpt = gen_noise(1)\n        i = np.random.randint(0,real_imgs.shape[0])\n        print('Epoch: ', e,\n        ' || Gen: ' , discriminator.predict(generator.predict(inpt))[0,0],\n        ' || Dog: ' , discriminator.predict(real_imgs[i:i+1])[0,0])\n        #print(np.average(y_dis))\n        imagesProgress[e-1,:,:,:] = generator.predict(progress_noise)[0]\n    return imagesProgress\ntry: imagesProgress\nexcept NameError: imagesProgress = np.zeros((0,64,64,3))\nimagesProgress = np.vstack((imagesProgress,training(epochs=36)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = 6 ; rows = min(6,(imagesProgress.shape[0] // columns) + 1);\nfig=plt.figure(figsize=(32, 5 * rows))\nj=0\nfor i in range(0 , min(36,imagesProgress.shape[0])):\n    fig.add_subplot(rows,columns,i+1)\n    plt.imshow(imagesProgress[int(j)]/2+.5)\n    j += max(1,imagesProgress.shape[0] / 36)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inpt = gen_noise(12)\n#inpt[:,np.random.randint(100)] += 1\nimg = generator.predict(inpt)\n#print(discriminator.predict(imagesInput[:10]))\n#print(discriminator.predict(img))\n#print(img[0,0,:10])\nfig=plt.figure(figsize=(32, 10))\ncolumns = 6 ; rows = 2;\nfor i in range(0 , columns * rows):\n    fig.add_subplot(rows,columns,i+1)\n    plt.imshow(img[i]/2+.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = zipfile.PyZipFile('images.zip', mode='w')\ninpt = gen_noise(10000)\nimgs = generator.predict(inpt) \nimgs = imgs + 1\nimgs = imgs / 2\nprint(imgs.shape)\nfor k in range(10000):\n    f = str(k)+'.png'\n    img = imgs[k,:,:,:]#.numpy()\n    tf.keras.preprocessing.image.save_img(\n        f,\n        img,\n        scale=True\n    )\n    z.write(f); os.remove(f)\nz.close()\n#!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inpt = gen_noise(10000)\n#img = generator.predict(inpt) \n#img = img + 1\n#img = img * (255 / 2)\n#np.array(img).min(), np.array(img).max()\n#if not os.path.exists('../tmp'):\n#    os.mkdir('../tmp')\n#for i in range(0,img.shape[0]):\n#    plt.imsave('../tmp/dog_'+ str (i)+'.png' , img[i].astype(np.uint8))\n#import shutil\n#shutil.make_archive('images', 'zip', '../tmp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(img[9].astype(np.uint8))\n#im = Image.fromarray(img[0].astype(np.uint8))\n#plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}