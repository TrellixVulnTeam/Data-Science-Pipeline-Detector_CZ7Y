{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DCGAN part\n\nUsing chainer framework.\n**I carefully select training data to use. 195 newly tagged data. Standing dog facing all the left.**\n\n## Book introduction:\n\n### \"Introduction to automatic content generation AI programming made with Chainer\" (2017) (Japanease only)\n\n![](https://images-na.ssl-images-amazon.com/images/I/51apXfWgJLL._SX350_BO1,204,203,200_.jpg)\n\n[This Book](https://www.amazon.co.jp/dp/4863542348/) was authored as an author by me."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import training, datasets, iterators, optimizers\nfrom chainer.training import extensions\nimport numpy as np\nimport os\nimport math\nfrom numpy import random\nfrom PIL import Image\n\nbatch_size = 10\nuses_device = 0\nimage_size = 128\nneuron_size = 64\nn_epochs = 10000\n\nstand_left = ['n02087046_2744.jpg','n02087046_924.jpg','n02087394_2319.jpg','n02087394_7254.jpg','n02087394_9695.jpg','n02088364_16881.jpg','n02088364_5147.jpg','n02088466_12388.jpg','n02088632_1463.jpg','n02088632_2145.jpg','n02089078_1174.jpg','n02089078_1735.jpg','n02089078_2542.jpg','n02089078_2574.jpg','n02089078_2921.jpg','n02089078_3923.jpg','n02089078_393.jpg','n02089078_877.jpg','n02089078_901.jpg','n02089867_2688.jpg','n02089867_3044.jpg','n02089867_3524.jpg','n02099267_1862.jpg','n02099267_198.jpg','n02099267_2121.jpg','n02099267_5073.jpg','n02099429_1234.jpg','n02099429_1377.jpg','n02099429_159.jpg','n02099429_1758.jpg','n02099429_2650.jpg','n02099429_2698.jpg','n02099429_2756.jpg','n02099429_355.jpg','n02099429_448.jpg','n02099429_537.jpg','n02099429_618.jpg','n02099601_1010.jpg','n02099601_3414.jpg','n02099849_501.jpg','n02100236_2392.jpg','n02100236_4723.jpg','n02100236_4755.jpg','n02100735_5713.jpg','n02100735_6660.jpg','n02100877_1062.jpg','n02101006_114.jpg','n02101006_751.jpg','n02101388_2142.jpg','n02101388_2324.jpg','n02101388_2522.jpg','n02101388_3003.jpg','n02101388_4229.jpg','n02101388_4632.jpg','n02101388_6081.jpg','n02102177_1520.jpg','n02102973_2449.jpg','n02102973_2805.jpg','n02102973_3584.jpg','n02105162_4569.jpg','n02105251_8643.jpg','n02106166_1460.jpg','n02106166_321.jpg','n02106166_6833.jpg','n02106550_6286.jpg','n02106662_10122.jpg','n02106662_15858.jpg','n02106662_1841.jpg','n02106662_21715.jpg','n02106662_26335.jpg','n02106662_27186.jpg','n02106662_4522.jpg','n02107142_15377.jpg','n02107142_16400.jpg','n02107142_16917.jpg','n02107142_278.jpg','n02107142_3094.jpg','n02107142_3171.jpg','n02107312_1586.jpg','n02107312_3449.jpg','n02107908_1855.jpg','n02107908_2365.jpg','n02108000_2357.jpg','n02108000_2536.jpg','n02108000_3207.jpg','n02108000_3305.jpg','n02108000_3500.jpg','n02108089_122.jpg','n02108089_14112.jpg','n02108089_5977.jpg','n02108422_3576.jpg','n02108422_3709.jpg','n02108422_5609.jpg','n02109047_10414.jpg','n02109047_1533.jpg','n02109047_16735.jpg','n02109047_2527.jpg','n02109047_2553.jpg','n02109047_32010.jpg','n02109047_34162.jpg','n02109047_4267.jpg','n02109525_7497.jpg','n02109961_1076.jpg','n02109961_1235.jpg','n02109961_5035.jpg','n02109961_997.jpg','n02110063_11887.jpg','n02110063_5676.jpg','n02110063_9112.jpg','n02110063_9259.jpg','n02110185_10967.jpg','n02110185_4294.jpg','n02110185_6263.jpg','n02110185_6850.jpg','n02110185_7936.jpg','n02110627_11819.jpg','n02110627_11875.jpg','n02110627_12077.jpg','n02110627_12973.jpg','n02110806_1485.jpg','n02110806_1577.jpg','n02110806_1637.jpg','n02110806_1639.jpg','n02110806_1902.jpg','n02110806_2497.jpg','n02110806_2627.jpg','n02110806_2995.jpg','n02110806_2997.jpg','n02110806_3008.jpg','n02110806_3966.jpg','n02110806_4024.jpg','n02110806_4142.jpg','n02110806_4242.jpg','n02110806_513.jpg','n02110806_581.jpg','n02111129_1014.jpg','n02111129_1181.jpg','n02111129_1429.jpg','n02111129_1684.jpg','n02111129_2047.jpg','n02111129_2359.jpg','n02111129_2400.jpg','n02111129_2594.jpg','n02111129_2620.jpg','n02111129_2700.jpg','n02111129_2750.jpg','n02111129_2881.jpg','n02111129_3087.jpg','n02111129_4305.jpg','n02111129_4698.jpg','n02111129_4725.jpg','n02111129_4958.jpg','n02111129_686.jpg','n02111277_13070.jpg','n02111277_5845.jpg','n02111277_5932.jpg','n02111277_6017.jpg','n02111277_980.jpg','n02112706_2149.jpg','n02112706_442.jpg','n02112706_473.jpg','n02112706_762.jpg','n02113978_131.jpg','n02113978_1823.jpg','n02113978_1868.jpg','n02113978_1939.jpg','n02113978_1970.jpg','n02113978_1983.jpg','n02113978_2143.jpg','n02113978_2441.jpg','n02113978_2707.jpg','n02113978_2798.jpg','n02113978_3419.jpg','n02113978_3722.jpg','n02113978_386.jpg','n02113978_903.jpg','n02113978_937.jpg','n02113978_961.jpg','n02113978_996.jpg','n02116738_10038.jpg','n02116738_10215.jpg','n02116738_10614.jpg','n02116738_1739.jpg','n02116738_8489.jpg','n02116738_8719.jpg']\n\nif uses_device >= 0:\n    import cupy as cp\n    import chainer.cuda\nelse:\n    cp = np\n\nclass DCGAN_Generator_NN(chainer.Chain):\n\n    def __init__(self):\n        w = chainer.initializers.Normal(scale=0.02, dtype=None)\n        super(DCGAN_Generator_NN, self).__init__()\n        with self.init_scope():\n            self.l0 = L.Linear(100, neuron_size * image_size * image_size // 8 // 8,\n                               initialW=w)\n            self.dc1 = L.Deconvolution2D(neuron_size, neuron_size // 2, 4, 2, 1, initialW=w)\n            self.dc2 = L.Deconvolution2D(neuron_size // 2, neuron_size // 4, 4, 2, 1, initialW=w)\n            self.dc3 = L.Deconvolution2D(neuron_size // 4, neuron_size // 8, 4, 2, 1, initialW=w)\n            self.dc4 = L.Deconvolution2D(neuron_size // 8, 3, 3, 1, 1, initialW=w)\n            self.bn0 = L.BatchNormalization(neuron_size * image_size * image_size // 8 // 8)\n            self.bn1 = L.BatchNormalization(neuron_size // 2)\n            self.bn2 = L.BatchNormalization(neuron_size // 4)\n            self.bn3 = L.BatchNormalization(neuron_size // 8)\n\n    def __call__(self, z):\n        shape = (len(z), neuron_size, image_size // 8, image_size // 8)\n        h = F.reshape(F.relu(self.bn0(self.l0(z))), shape)\n        h = F.relu(self.bn1(self.dc1(h)))\n        h = F.relu(self.bn2(self.dc2(h)))\n        h = F.relu(self.bn3(self.dc3(h)))\n        x = F.sigmoid(self.dc4(h))\n        return x\n\nclass DCGAN_Discriminator_NN(chainer.Chain):\n\n    def __init__(self):\n        w = chainer.initializers.Normal(scale=0.02, dtype=None)\n        super(DCGAN_Discriminator_NN, self).__init__()\n        with self.init_scope():\n            self.c0_0 = L.Convolution2D(3, neuron_size //  8, 3, 1, 1, initialW=w)\n            self.c0_1 = L.Convolution2D(neuron_size //  8, neuron_size // 4, 4, 2, 1, initialW=w)\n            self.c1_0 = L.Convolution2D(neuron_size //  4, neuron_size // 4, 3, 1, 1, initialW=w)\n            self.c1_1 = L.Convolution2D(neuron_size //  4, neuron_size // 2, 4, 2, 1, initialW=w)\n            self.c2_0 = L.Convolution2D(neuron_size //  2, neuron_size // 2, 3, 1, 1, initialW=w)\n            self.c2_1 = L.Convolution2D(neuron_size //  2, neuron_size, 4, 2, 1, initialW=w)\n            self.c3_0 = L.Convolution2D(neuron_size, neuron_size, 3, 1, 1, initialW=w)\n            self.l4 = L.Linear(neuron_size * image_size * image_size // 8 // 8, 1, initialW=w)\n            self.bn0_1 = L.BatchNormalization(neuron_size // 4, use_gamma=False)\n            self.bn1_0 = L.BatchNormalization(neuron_size // 4, use_gamma=False)\n            self.bn1_1 = L.BatchNormalization(neuron_size // 2, use_gamma=False)\n            self.bn2_0 = L.BatchNormalization(neuron_size // 2, use_gamma=False)\n            self.bn2_1 = L.BatchNormalization(neuron_size, use_gamma=False)\n            self.bn3_0 = L.BatchNormalization(neuron_size, use_gamma=False)\n\n    def __call__(self, x):\n        h = F.leaky_relu(self.c0_0(x))\n        h = F.dropout(F.leaky_relu(self.bn0_1(self.c0_1(h))),ratio=0.2)\n        h = F.dropout(F.leaky_relu(self.bn1_0(self.c1_0(h))),ratio=0.2)\n        h = F.dropout(F.leaky_relu(self.bn1_1(self.c1_1(h))),ratio=0.2)\n        h = F.dropout(F.leaky_relu(self.bn2_0(self.c2_0(h))),ratio=0.2)\n        h = F.dropout(F.leaky_relu(self.bn2_1(self.c2_1(h))),ratio=0.2)\n        h = F.dropout(F.leaky_relu(self.bn3_0(self.c3_0(h))),ratio=0.2)\n        return self.l4(h)\n\nclass DCGANUpdater(training.StandardUpdater):\n\n    def __init__(self, train_iter, optimizer, device):\n        super(DCGANUpdater, self).__init__(\n            train_iter,\n            optimizer,\n            device=device\n        )\n    \n    def loss_dis(self, dis, y_fake, y_real):\n        batchsize = len(y_fake)\n        L1 = F.sum(F.softplus(-y_real)) / batchsize\n        L2 = F.sum(F.softplus(y_fake)) / batchsize\n        loss = L1 + L2\n        return loss\n\n    def loss_gen(self, gen, y_fake):\n        batchsize = len(y_fake)\n        loss = F.sum(F.softplus(-y_fake)) / batchsize\n        return loss\n\n    def update_core(self):\n        batch = self.get_iterator('main').next()\n        src = self.converter(batch, self.device)\n        \n        optimizer_gen = self.get_optimizer('opt_gen')\n        optimizer_dis = self.get_optimizer('opt_dis')\n        gen = optimizer_gen.target\n        dis = optimizer_dis.target\n\n        rnd = random.uniform(-1, 1, (src.shape[0], 100))\n        rnd = cp.array(rnd, dtype=cp.float32)\n        \n        x_fake = gen(rnd)\n        y_fake = dis(x_fake)\n        y_real = dis(src)\n\n        optimizer_dis.update(self.loss_dis, dis, y_fake, y_real)\n        optimizer_gen.update(self.loss_gen, gen, y_fake)\n        \nmodel_gen = DCGAN_Generator_NN()\nmodel_dis = DCGAN_Discriminator_NN()\n\nif uses_device >= 0:\n    chainer.cuda.get_device_from_id(0).use()\n    chainer.cuda.check_cuda_available()\n    model_gen.to_gpu()\n    model_dis.to_gpu()\n\nimages = []\n\nimport cv2\n\nfor fn in stand_left:\n    if os.path.isfile(\"../input/all-dogs/all-dogs/\"+fn):\n        im = cv2.imread(\"../input/all-dogs/all-dogs/\"+fn)\n        im = cv2.resize(im, (image_size,image_size), cv2.INTER_CUBIC).astype(np.float32) / 255.0\n        images.append(im.transpose((2,0,1)))\n\ntrain_iter = iterators.SerialIterator(images, batch_size, shuffle=True)\n\noptimizer_gen = optimizers.Adam(alpha=0.0002, beta1=0.5)\noptimizer_gen.setup(model_gen)\noptimizer_dis = optimizers.Adam(alpha=0.0002, beta1=0.5)\noptimizer_dis.setup(model_dis)\n\nupdater = DCGANUpdater(train_iter, \\\n        {'opt_gen':optimizer_gen, 'opt_dis':optimizer_dis}, \\\n        device=uses_device)\ntrainer = training.Trainer(updater, (n_epochs, 'epoch'), out=\"result\")\ntrainer.extend(extensions.ProgressBar(update_interval=7400))\n\ntrainer.run()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Show the genetated images.\n\nGenerate an image from randomly generated vectors. Usually, it contains vectors that can be generated successfully here and vectors that can not be generated successfully. Because the image judged to be correct and the image judged to be wrong at the time of training are generated from the same distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nmodel = model_gen\nnum_generate = 200\n\nrnd_to_gen = random.uniform(-1, 1, (num_generate, 100, 1, 1))\nrnd = cp.array(rnd_to_gen, dtype=cp.float32)\n\nwith chainer.using_config('train', False):\n    result_gen = model(rnd)\n\ndata = np.zeros((640, 1280, 3), dtype=np.uint8)\n\nfor i in range(10):\n    for j in range(20):\n        dst = result_gen.data[i*10+j] * 255.0\n        if uses_device >= 0:\n            dst = chainer.cuda.to_cpu(dst)\n        tmp = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n        tmp[:,:,0] = dst[0]; tmp[:,:,1] = dst[1]; tmp[:,:,2] = dst[2]\n        data[i*64:i*64+64,j*64:j*64+64,:] = cv2.resize(tmp, (64,64), cv2.INTER_CUBIC)\nplt.figure(figsize=(40, 20), dpi=50)\nplt.imshow(cv2.cvtColor(data, cv2.COLOR_BGR2RGB))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metric Learning part\n\nSelect the plausible image from the list of images generated by DCGAN. This is similar to [Facenet](https://arxiv.org/abs/1503.03832), using images that are used for Metric Learning training by Triplet Loss and images that are not used as a pair, and extracts only generated images that are close in distance to the image used for training."},{"metadata":{"trusted":true},"cell_type":"code","source":"others = []\nfor fn in os.listdir(\"../input/all-dogs/all-dogs/\"):\n    if fn not in stand_left and os.path.isfile(\"../input/all-dogs/all-dogs/\"+fn):\n        im = cv2.imread(\"../input/all-dogs/all-dogs/\"+fn)\n        im = cv2.resize(im, (128,128), cv2.INTER_CUBIC).astype(np.float32) / 255.0\n        others.append(im.transpose((2,0,1)))\n        if len(others) >= 1000:\n            break\n\ntriplet_pos = [0,0]\ndef get_one(o=False):\n    global triplet_pos\n    im = images if o else others\n    ip = 0 if o else 1\n    data = im[triplet_pos[ip]]\n    triplet_pos[ip] = triplet_pos[ip]+1\n    if triplet_pos[ip] >= len(im):\n        triplet_pos[ip] = 0\n    return data\ndef get_one_triple():\n    a = (random.random() < 0.5)\n    c = get_one(a)\n    d = get_one(not a)\n    e = get_one(not a)\n    return (c,d,e)\n\nclass Triplet_NN(chainer.Chain):\n \n    def __init__(self):\n        super(Triplet_NN, self).__init__()\n        with self.init_scope():\n            self.layer1 = L.Convolution2D(3, 16, 3, 1, 1)\n            self.layer2 = L.Convolution2D(16, 16, 3, 1, 1)\n            self.layer3 = L.Convolution2D(16, 32, 3, 1, 1)\n            self.layer4 = L.Convolution2D(32, 32, 3, 1, 1)\n            self.layer5 = L.Linear(32*32*32, 2)\n \n    def __call__(self, x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = F.max_pooling_2d(x, 2)\n        x = F.relu(self.layer3(x))\n        x = F.relu(self.layer4(x))\n        x = F.max_pooling_2d(x, 2)\n        return self.layer5(x)\n\nclass TripletUpdater(training.StandardUpdater):\n \n    def __init__(self, optimizer, device):\n        self.loss_val = []\n        super(TripletUpdater, self).__init__(\n            None,\n            optimizer,\n            device=device\n        )\n \n    @property\n    def epoch(self):\n        return 0\n \n    @property\n    def epoch_detail(self):\n        return 0.0\n \n    @property\n    def previous_epoch_detail(self):\n        return 0.0\n \n    @property\n    def is_new_epoch(self):\n        return False\n        \n    def finalize(self):\n        pass\n    \n    def update_core(self):\n        batch_size = 1000\n        optimizer = self.get_optimizer('main')\n        anchor = []\n        positive = []\n        negative = []\n        for i in range(batch_size):\n            in_data = get_one_triple()\n            anchor.append(in_data[0])\n            positive.append(in_data[1])\n            negative.append(in_data[2])\n        anchor = cp.array(anchor)\n        positive = cp.array(positive)\n        negative = cp.array(negative)\n        model = optimizer.target\n        anchor_r = model(anchor)\n        positive_r = model(positive)\n        negative_r = model(negative)\n        optimizer.update(F.triplet, anchor_r, positive_r, negative_r)\n\nmodel_tri = Triplet_NN().to_gpu()\noptimizer = optimizers.Adam()\noptimizer.setup(model_tri)\nupdater = TripletUpdater(optimizer, device=0)\ntrainer = training.Trainer(updater, (1000, 'iteration'), out=\"result\")\ntrainer.run()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find four vectors that generate images close in distance to the training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"with chainer.using_config('train', False):\n    vectors_gen = model_tri(cp.array(result_gen.data)).data\nwith chainer.using_config('train', False):\n    vectors_train = model_tri(cp.array(images)).data\nmin_deltas = []\nmin_deltaindex = []\nfor vt in vectors_train:\n    md = np.inf\n    mnd_index = 0\n    for i in range(num_generate):\n        delta = np.sum(np.absolute(vt - vectors_gen[i]))\n        if delta < md:\n            md = delta\n            mnd_index = i\n    min_deltas.append(md)\n    min_deltaindex.append(mnd_index)\npi = np.argsort(min_deltas)\npicture1idx = min_deltaindex[pi[0]]\ngi = 1\nfor i in range(gi,len(pi)):\n    if min_deltaindex[pi[i]] != picture1idx:\n        picture2idx = min_deltaindex[pi[i]]\n        gi = i+1\n        break\nfor i in range(gi,len(pi)):\n    if min_deltaindex[pi[i]] != picture1idx and  min_deltaindex[pi[i]] != picture2idx:\n        picture3idx = min_deltaindex[pi[i]]\n        gi = i+1\n        break\nfor i in range(gi,len(pi)):\n    if min_deltaindex[pi[i]] != picture1idx and  min_deltaindex[pi[i]] != picture2idx and  min_deltaindex[pi[i]] != picture3idx:\n        picture4idx = min_deltaindex[pi[i]]\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The generated image is displayed while complementing the vectors between vector 1 and vector 2."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"model = model_gen\nrnd = np.zeros((num_generate, 100, 1, 1))\nfor i in range(num_generate):\n    rnd[i] = rnd_to_gen[picture1idx] + (rnd_to_gen[picture2idx] - rnd_to_gen[picture1idx]) * i / num_generate\nrnd = cp.array(rnd, dtype=cp.float32)\n\nwith chainer.using_config('train', False):\n    result = model(rnd)\n\ndata = np.zeros((640, 640, 3), dtype=np.uint8)\n\nfor i in range(10):\n    for j in range(10):\n        dst = result.data[i*10+j] * 255.0\n        if uses_device >= 0:\n            dst = chainer.cuda.to_cpu(dst)\n        tmp = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n        tmp[:,:,0] = dst[0]; tmp[:,:,1] = dst[1]; tmp[:,:,2] = dst[2]\n        data[i*64:i*64+64,j*64:j*64+64,:] = cv2.resize(tmp, (64,64), cv2.INTER_CUBIC)\nplt.figure(figsize=(20, 20), dpi=50)\nplt.imshow(cv2.cvtColor(data, cv2.COLOR_BGR2RGB))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The generated image is displayed while complementing the vectors between vector 3 and vector 4."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_gen\nrnd = np.zeros((num_generate, 100, 1, 1))\nfor i in range(num_generate):\n    rnd[i] = rnd_to_gen[picture3idx] + (rnd_to_gen[picture4idx] - rnd_to_gen[picture3idx]) * i / num_generate\nrnd = cp.array(rnd, dtype=cp.float32)\n\nwith chainer.using_config('train', False):\n    result = model(rnd)\n\ndata = np.zeros((640, 640, 3), dtype=np.uint8)\n\nfor i in range(10):\n    for j in range(10):\n        dst = result.data[i*10+j] * 255.0\n        if uses_device >= 0:\n            dst = chainer.cuda.to_cpu(dst)\n        tmp = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n        tmp[:,:,0] = dst[0]; tmp[:,:,1] = dst[1]; tmp[:,:,2] = dst[2]\n        data[i*64:i*64+64,j*64:j*64+64,:] = cv2.resize(tmp, (64,64), cv2.INTER_CUBIC)\nplt.figure(figsize=(20, 20), dpi=50)\nplt.imshow(cv2.cvtColor(data, cv2.COLOR_BGR2RGB))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create a submission image from the random sequence within four vectors."},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\nz = zipfile.PyZipFile('images.zip', mode='w')\ngenerated_num = 0\n\nsample = np.zeros((640, 640, 3), dtype=np.uint8)\nmodel = model_gen\nmn = np.min([rnd_to_gen[a] for a in (picture1idx,picture2idx,picture3idx,picture4idx)],axis=0).reshape((100,))\nmx = np.max([rnd_to_gen[a] for a in (picture1idx,picture2idx,picture3idx,picture4idx)],axis=0).reshape((100,))\nfor i in range(100):\n    data = np.zeros((64, 64, 3), dtype=np.uint8)\n\n    rnd = mn + (mx - mn) * np.random.rand(100, 100)\n    rnd = rnd.reshape((100, 100, 1, 1))\n    rnd = cp.array(rnd, dtype=cp.float32)\n\n    with chainer.using_config('train', False):\n        result = model(rnd)\n\n    for j in range(100):\n        dst = result.data[j] * 255.0\n        if uses_device >= 0:\n            dst = chainer.cuda.to_cpu(dst)\n        tmp = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n        tmp[:,:,0] = dst[0]; tmp[:,:,1] = dst[1]; tmp[:,:,2] = dst[2]\n        data = cv2.resize(tmp, (64,64), cv2.INTER_CUBIC)\n        f = str(generated_num)+'.png'\n        cv2.imwrite(f, data); z.write(f); os.remove(f)\n        generated_num += 1\n    sample[(i//10)*64:(i//10)*64+64,(i%10)*64:(i%10)*64+64,:] = data\nz.close()\nplt.figure(figsize=(20, 20), dpi=50)\nplt.imshow(cv2.cvtColor(sample, cv2.COLOR_BGR2RGB))\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}