{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport numpy as np  \nimport pandas as pd  \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image \nfrom torch.optim.lr_scheduler import StepLR , MultiStepLR \nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport PIL.Image\nimport numpy as np # linear algebra\nimport xml.etree.ElementTree as ET # for parsing XML\nimport matplotlib.pyplot as plt # to show images\nfrom PIL import Image # to read images \nfrom torch.nn.utils import spectral_norm\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Tensor transform\n# 64x64 images!\n\ndef find_mean_std():\n    transform = transforms.Compose([transforms.Resize(img_size),\n                                    transforms.CenterCrop(img_size),\n                                    transforms.ToTensor()])\n     \n    imagenet_data = datasets.ImageFolder(dog_data_dir, transform=transform) \n\n    data_loader = torch.utils.data.DataLoader(imagenet_data,\n                                              batch_size=batch_size,\n                                              shuffle=False,\n                                              num_workers=0) \n\n    mean = 0.\n    std = 0.\n    i =0\n    for images, _ in data_loader:\n        batch_samples = images.size(0)  \n        images = images.view(batch_size, images.size(1), -1)\n        mean += images.mean(2).sum(0)\n        std += images.std(2).sum(0)\n        i = i +1\n        if i % 1000 == 0:\n            print(str(i)+\"/\" +str(len(data_loader.dataset)) + \" mean: \"+str(mean/i)+ \" std: \"+str(std/i))\n\n    mean /= len(data_loader.dataset)\n    std /= len(data_loader.dataset)\n    return mean , std ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function to un-normalize and display an image\n\ndef unnormalize(img,mean,std):\n    img[0] = (img[0] * std[0]) + mean[0]  # unnormalize image = ((image * std) + mean) \n    img[1] = (img[1] * std[1]) + mean[1]\n    img[2] = (img[2] * std[2]) + mean[2] \n    return img\n    \ndef imshow(img): \n    img = transforms.ToPILImage()(img) \n    plt.imshow(img) \n\ndef display_img(images,is_unnormalize = True,pics = 20):\n    # plot the images in the batch, along with the corresponding labels\n    fig = plt.figure(figsize=(25, 4))\n    \n    x = int(math.floor(pics/10))\n    for idx in np.arange(pics):\n        ax = fig.add_subplot(x, pics/x, idx+1, xticks=[], yticks=[])\n        if is_unnormalize:\n            imshow(unnormalize(images[idx],mean,std ))\n        else:\n            img = images[idx].detach().cpu().numpy()\n            img = np.transpose(img, (1, 2, 0))\n            img = ((img + 1)*255 / (2)).astype(np.uint8)\n            plt.imshow(img) \n            #imshow(images[idx]) \n\ndef pre_process(images, _batch_size):   \n    print(images[0].name())\n    _new_batch_size = _batch_size\n    _images = torch.FloatTensor(_batch_size, 3, img_size, img_size )  \n    return _images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import transforms\n \nclass DatasetDog(Dataset): \n    \n    def __init__(self, file_path, transform=None,  transform_augmentations =None):\n        self.ys_mapping = {} \n        counter = 0 \n        for y in os.listdir('../input/annotation/Annotation/'): # list of all breeds:\n            index = y.find('-')\n            if index != -1:\n                index += 1  \n                if y not in self.ys_mapping:\n                    self.ys_mapping[y[:(index-1)] ] = [y[(index):], counter,y] \n                    counter = counter + 1\n          \n        self.transform = transform\n        self.transform_augmentations = transform_augmentations\n        \n        self.labels = []\n        self.imgs = []\n         \n        for dog_name in  os.listdir('../input/all-dogs/all-dogs/'):   \n            label = dog_name \n            i = label.find('_')\n            if i != -1:\n                i += 1 \n                label = label[:(i-1)] \n                if label in self.ys_mapping:\n                    label = self.ys_mapping[label] \n                else:\n                    label = [label,-1,\"\"]\n            else:\n                i = label.find('.') \n                if i != -1:\n                    label = [label[:(i-1)],-1,\"\"]\n                else:\n                    label = [label,-1,\"\"] \n            img = Image.open('../input/all-dogs/all-dogs/' + dog_name  )  \n            breed = label[2]\n            i = dog_name.find('.')  \n            if label != \"\" and i != -1 :   \n                annotation = '../input/annotation/Annotation/' + breed + '/' + dog_name[:(i)]\n                if  os.path.isfile(annotation):\n                    tree = ET.parse(annotation)\n                    root = tree.getroot()\n                    objects = root.findall('object')\n                    for o in objects: \n                        bndbox = o.find('bndbox') # reading bound box\n                        xmin = int(bndbox.find('xmin').text)\n                        ymin = int(bndbox.find('ymin').text)\n                        xmax = int(bndbox.find('xmax').text)\n                        ymax = int(bndbox.find('ymax').text)\n                        \n                        w = np.min((xmax - xmin, ymax - ymin))\n                        bbox = (xmin, ymin, xmin+w, ymin+w) \n                        img = img.crop(bbox) \n                                \n                        if np.mean(img) != 0:  \n                            self.labels.append(label)  \n                            if self.transform is not None: \n                                img = self.transform(img)\n                            \n                            self.imgs.append(img)\n                        #break  # select one dog per image\n                        \n       \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, index):    \n       \n        label = self.labels[index]\n        img = self.imgs[index]\n        \n        if self.transform_augmentations is not None: \n            img = self.transform_augmentations(img)#torchvision.transforms.functional.to_pil_image(image))\n            \n        #img = torch.from_numpy(np.asarray(img))  \n        #image = torch.from_numpy(np.array(img)) \n        #image = image[np.newaxis, :] \n        #image = image.permute(2, 0, 1)  \n            \n        return (img,label )  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(os.listdir(\"../input\")) \ndog_data_dir = \"../input\"\nimg_size = 64  \n\nbatch_size = 32\n\nmean = (0.5, 0.5, 0.5)#(0.4799, 0.4516, 0.3921)\nstd  = (0.5, 0.5, 0.5)#(0.2184, 0.2136, 0.2111) \n \ntransform = transforms.Compose([transforms.Resize(img_size),\n                                transforms.CenterCrop(img_size)])\n\n# Data augmentation and converting to tensors\nrandom_transforms = [transforms.RandomRotation(degrees=5)]\ntransform_augmentations = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n                                              #transforms.RandomApply(random_transforms, p=0.3), \n                                              transforms.ToTensor(),\n                                              transforms.Normalize(std  , mean)])\n\n \n\n#train_data = datasets.ImageFolder(dog_data_dir, transform=transform)     \ntrain_data = DatasetDog(dog_data_dir, transform=transform, transform_augmentations=transform_augmentations) \n  \n\ntrain_loader = torch.utils.data.DataLoader(train_data,\n                                           shuffle=True,\n                                           batch_size=batch_size,\n                                           num_workers=4)\n                                            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define tes data loader\ntest_dataset_loader = torch.utils.data.DataLoader(dataset=train_data,\n                                                  batch_size=20,\n                                                  shuffle=True)\n\n\n#for batch_i, (images, labels) in enumerate(train_loader):  \nimages, _ = iter(test_dataset_loader).next()   \n    #print('Scaled min: ', images.min())\n    #print('Scaled max: ', images.max())  \n    #print(batch_i)\ndisplay_img(images,False,20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PixelwiseNorm(nn.Module):\n    def __init__(self):\n        super(PixelwiseNorm, self).__init__()\n\n    def forward(self, x, alpha=1e-8):\n        \"\"\"\n        forward pass of the module\n        :param x: input activations volume\n        :param alpha: small number for numerical stability\n        :return: y => pixel normalized activations\n        \"\"\"\n        y = x.pow(2.).mean(dim=1, keepdim=True).add(alpha).sqrt()  # [N1HW]\n        y = x / y  # normalize the input x volume\n        return y\n\nclass MinibatchStdDev(nn.Module):\n    \"\"\"\n    Minibatch standard deviation layer for the discriminator\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        derived class constructor\n        \"\"\"\n        super(MinibatchStdDev, self).__init__()\n\n    def forward(self, x, alpha=1e-8):\n        \"\"\"\n        forward pass of the layer\n        :param x: input activation volume\n        :param alpha: small number for numerical stability\n        :return: y => x appended with standard deviation constant map\n        \"\"\"\n        batch_size, _, height, width = x.shape\n        # [B x C x H x W] Subtract mean over batch.\n        y = x - x.mean(dim=0, keepdim=True)\n        # [1 x C x H x W]  Calc standard deviation over batch\n        y = torch.sqrt(y.pow(2.).mean(dim=0, keepdim=False) + alpha)\n\n        # [1]  Take average over feature_maps and pixels.\n        y = y.mean().view(1, 1, 1, 1)\n\n        # [B x 1 x H x W]  Replicate over group and pixels.\n        y = y.repeat(batch_size,1, height, width)\n\n        # [B x C x H x W]  Append as new feature_map.\n        y = torch.cat([x, y], 1)\n        # return the computed values:\n        return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Generator(nn.Module):\n    def __init__(self, nz, nfeats, nchannels):\n        super(Generator, self).__init__()\n\n        # input is Z, going into a convolution\n        self.conv1 = spectral_norm(nn.ConvTranspose2d(nz, nfeats * 8, 4, 1, 0, bias=False))  \n        # state size. (nfeats*8) x 4 x 4\n        \n        self.conv2 = spectral_norm(nn.ConvTranspose2d(nfeats * 8, nfeats * 8, 4, 2, 1, bias=False)) \n        # state size. (nfeats*8) x 8 x 8\n        \n        self.conv3 = spectral_norm(nn.ConvTranspose2d(nfeats * 8, nfeats * 4, 4, 2, 1, bias=False)) \n        # state size. (nfeats*4) x 16 x 16\n        \n        self.conv4 = spectral_norm(nn.ConvTranspose2d(nfeats * 4, nfeats * 2, 4, 2, 1, bias=False)) \n        # state size. (nfeats * 2) x 32 x 32\n        \n        self.conv5 = spectral_norm(nn.ConvTranspose2d(nfeats * 2, nfeats, 4, 2, 1, bias=False)) \n        # state size. (nfeats) x 64 x 64\n        \n        self.conv6 = spectral_norm(nn.ConvTranspose2d(nfeats, nchannels, 3, 1, 1, bias=False)) \n        self.pixnorm = PixelwiseNorm()\n        \n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x)) \n        x = F.leaky_relu(self.conv2(x))\n        x = self.pixnorm(x)\n        x = F.leaky_relu(self.conv3(x))\n        x = self.pixnorm(x)\n        x = F.leaky_relu(self.conv4(x))\n        x = self.pixnorm(x)\n        x = F.leaky_relu(self.conv5(x))\n        x = self.pixnorm(x)\n        x = torch.tanh(self.conv6(x)) \n        return x\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, nchannels, nfeats,gan_method = \"standard\"):\n        super(Discriminator, self).__init__()\n        self.nfeats = nfeats\n        self.gan_method = gan_method\n        # input is (nchannels) x 64 x 64\n        self.conv1 = nn.Conv2d(nchannels, nfeats, 4, 2, 1, bias=False) \n        # state size. (nfeats) x 32 x 32\n        \n        self.conv2 = spectral_norm(nn.Conv2d(nfeats, nfeats * 2, 4, 2, 1, bias=False))\n        self.bn2 = nn.BatchNorm2d(nfeats * 2)\n        # state size. (nfeats*2) x 16 x 16\n        \n        self.conv3 = spectral_norm(nn.Conv2d(nfeats * 2, nfeats * 4, 4, 2, 1, bias=False))\n        self.bn3 = nn.BatchNorm2d(nfeats * 4)\n        # state size. (nfeats*4) x 8 x 8\n       \n        self.conv4 = spectral_norm(nn.Conv2d(nfeats * 4, nfeats * 8, 4, 2, 1, bias=False))\n        self.bn4 = nn.BatchNorm2d(nfeats * 8)\n        # state size. (nfeats*8) x 4 x 4\n         \n        #self.fc1 = nn.Linear(nfeats * 8 * 4 * 4,nfeats * 4 * 4 * 4)     \n        #self.fc2 = nn.Linear(nfeats * 4 * 4 * 4 ,1)    \n        #self.dropout = nn.Dropout(0.25) \n        self.batch_discriminator = MinibatchStdDev()\n\n        self.conv5 =  spectral_norm(nn.Conv2d(nfeats * 8+1, 1, 4, 1, 0, bias=False))\n        # state size. 1 x 1 x 1\n        \n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x), 0.2)\n        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\n        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)\n        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2) \n        x = self.batch_discriminator(x)  \n\n        #x = x.view(-1, 4 * 4 * self.nfeats*8)   \n        #x = F.leaky_relu(self.fc1(x)) \n        #x = self.dropout(x) \n        #x = torch.sigmoid(self.fc2(x))  \n        \n        if self.gan_method == \"standard\":  \n            x = torch.sigmoid(self.conv5(x))  \n        else:\n            x = self.conv5(x)\n            \n        return x.view(-1, 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init_normal(m):\n    \"\"\"\n    Applies initial weights to certain layers in a model .\n    The weights are taken from a normal distribution \n    with mean = 0, std dev = 0.02.\n    :param m: A module or layer in a network    \n    \"\"\"\n    # classname will be something like:\n    # `Conv`, `BatchNorm2d`, `Linear`, etc.\n    classname = m.__class__.__name__ \n    # TODO: Apply initial weights to convolutional and linear layers\n    # for every Linear layer in a model..\n    if  classname.find('Linear') != -1: \n        # apply a uniform distribution to the weights and a bias=0  \n        m.weight.data.normal_(0, 0.2)\n        m.bias.data.fill_(0)\n    elif classname.find('Conv2d') != -1 or \\\n         classname.find('ConvTranspose2d') != -1:\n        m.weight.data.normal_(0, 0.2) # no bais in Conv2d or ConvTranspose2d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_network(d_conv_dim, g_conv_dim, z_size,nchannels,gan_method):\n    # define discriminator and generator\n    \n    G = Generator(z_size, g_conv_dim, nchannels).to(device)\n    D = Discriminator(nchannels,d_conv_dim,gan_method).to(device)\n\n    # initialize model weights \n    #G.apply(weights_init_normal)\n    #D.apply(weights_init_normal)\n\n    print(D)\n    print()\n    print(G)\n    \n    return D, G","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if os.path.exists('./generator.pth'):  \n#    netG.load_state_dict(torch.load('generator.pth'))\n#if os.path.exists('./discriminator.pth'):     \n#    netD.load_state_dict(torch.load('discriminator.pth'))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim \n\n# Define model hyperparams\nd_conv_dim = 64\ng_conv_dim = 64\n \nnz = 256\ngan_method = \"standard\" # \"standard\" , \"lsgan\" , \"hingegan\" \"relativistic_standard\" \"average_relativistic_standard\"\n\ncriterion_BCELoss           = nn.BCELoss()\ncriterion_BCEWithLogitsLoss = torch.nn.BCEWithLogitsLoss() \ncriterion_MSELoss           = nn.MSELoss() \n\nnetD, netG = build_network(d_conv_dim, g_conv_dim, nz,3,gan_method) \n\n#if os.path.exists('./discriminator.pth'):     \n#    netD.load_state_dict(torch.load('discriminator.pth')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nnum_epochs = 600\nstep = 0  \n# keep track of loss and generated, \"fake\" samples\nsamples = []\nlosses = []\n \nprint_every = 500\n\nlr_d = 0.0002\nlr_g = 0.0002\n\nbeta1 = 0.5\n   \noptimizerD = optim.Adam(netD.parameters(), lr=lr_d, betas=(beta1, 0.999)) \noptimizerG = optim.Adam(netG.parameters(), lr=lr_g, betas=(beta1, 0.999))\n\nfixed_noise = torch.randn(25, nz, 1, 1, device=device)\n\nreal_label_const = 0.7\nfake_label_const = 0\nbatch_size = train_loader.batch_size\n\n\n#generate_fake_images_code = \"uniform\" \n  \n\n# step_size: at how many multiples of epoch you decay\n# step_size = 1, after every 1 epoch, new_lr = lr*gamma  \n\n# gamma = decaying factor\nschedulerD = StepLR(optimizerD, step_size=10, gamma=0.99)\nschedulerG = StepLR(optimizerG, step_size=10, gamma=0.99)\n\npace = int(num_epochs/6)\n\n# train the network\nfor epoch in range(num_epochs): \n     # Decay Learning Rate\n    \n    if(schedulerD.get_lr()[0] >= 0.00005 and schedulerG.get_lr()[0] >= 0.00005):\n        schedulerD.step()\n        schedulerG.step()\n    \n        \n\n    # Print Learning Rate\n    print('Epoch:', epoch,'LR G ', schedulerD.get_lr())\n    #print('Epoch:', epoch,'LR D ', schedulerG.get_lr())\n    print(datetime.datetime.now())\n    for batch_i, (train_images, train_labels) in enumerate(train_loader): \n        # ============================================\n        #           INIT & PRE-PROCESS \n        # ============================================\n        \n        # 1. Create batch \n        # Mostly necessary for the last one because if N might not be a multiple of batch_size \n        _batch_size = train_images.size(0)  \n      \n         # 2. Create unlabeled images \n        _images   = torch.FloatTensor(_batch_size, 3, img_size, img_size ) \n        _images.resize_as_(train_images).copy_(train_images) \n        _images   = train_images.to(device) \n       \t \n        # ============================================\n        #            TRAIN THE DISCRIMINATOR\n        # ============================================\n \n        netD.zero_grad()    \n   \n        # 1. Find real pred \n        d_real_pred  = netD(_images) \n\n        # 2. Create label\n        real_label   = torch.full((_batch_size, 1), real_label_const, device=device) + np.random.uniform(-0.1, 0.1)\n        fake_label   = torch.full((_batch_size, 1), fake_label_const, device=device) + np.random.uniform(0, 0.2)\n  \n        # 3. Find fake pred \n        # 3.1 Generate fake images   \n        noise = torch.randn(_batch_size, nz, 1, 1, device=device)\n        fake_images = netG(noise)  \n        # 3.2  Find fake pred          \n        d_fake_pred = netD(fake_images.detach()) \n        \n        # 4 Compute the discriminator losses \n        if gan_method == \"standard\":\n            criterion = torch.nn.BCELoss()  \n            d_real_loss = criterion(d_real_pred,real_label)\n            d_real_loss.backward() \n \n            d_fake_loss = criterion(d_fake_pred,fake_label) \n            d_fake_loss.backward()    \n            d_loss = d_real_loss + d_fake_loss\n            \n        elif gan_method == \"relativistic_standard\":\n            criterion = torch.nn.BCEWithLogitsLoss()\n            d_loss = criterion(d_real_pred - d_fake_pred, real_label)\n            d_loss.backward()  \n        \n        elif gan_method == \"average_relativistic_standard\":\n            criterion = torch.nn.BCEWithLogitsLoss()\n            d_loss = (criterion(d_real_pred - torch.mean(d_fake_pred), real_label) \\\n                     + criterion(d_fake_pred - torch.mean(d_real_pred), fake_label))/2 \n            d_loss.backward()  \n            \n        elif  gan_method == \"lsgan\":  \n            d_loss = ( torch.mean((d_real_pred - torch.mean(d_fake_pred) - real_label) ** 2) + \\\n                       torch.mean((d_fake_pred - torch.mean(d_real_pred) + real_label) ** 2))/2\n            d_loss.backward() \n            \n        elif gan_method == \"hingegan\":\n            d_loss = (torch.mean(torch.nn.ReLU()(1.0 - (d_real_pred - torch.mean(d_fake_pred)))) + \\\n                      torch.mean(torch.nn.ReLU()(1.0 + (d_fake_pred - torch.mean(d_real_pred)))))/2\n            d_loss.backward() \n     \n        # 5 Step  \n        optimizerD.step()\n        \n        \n               # =========================================\n        #            TRAIN THE GENERATOR\n        # =========================================\n        netG.zero_grad()\n \n        # 2. Create label\n        real_label   = torch.full((_batch_size, 1), real_label_const, device=device)  \n        fake_label   = torch.full((_batch_size, 1), fake_label_const, device=device) \n  \n        # 3. Find fake pred \n        g_fake_pred = netD(fake_images)\n        \n        # 3. Compute the generator losses \n        if gan_method == \"standard\":\n            criterion = torch.nn.BCELoss()   \n            g_loss = criterion(g_fake_pred,real_label)\n            g_loss.backward() \n        \n        else: \n            g_real_pred  =  netD(_images)   \n            if gan_method == \"relativistic_standard\":\n                criterion = torch.nn.BCEWithLogitsLoss()\n                g_loss = criterion(g_fake_pred  - g_real_pred, real_label)\n                g_loss.backward()  \n        \n            elif gan_method == \"average_relativistic_standard\":\n                criterion = torch.nn.BCEWithLogitsLoss()\n                g_loss = (criterion(g_real_pred - torch.mean(g_fake_pred), fake_label ) \\\n                         + criterion(g_fake_pred - torch.mean(g_real_pred), real_label))/2 \n                g_loss.backward()  \n            \n            elif  gan_method == \"lsgan\":  \n                g_loss = ( torch.mean((g_real_pred - torch.mean(g_fake_pred) + real_label) ** 2) + \\\n                           torch.mean((g_fake_pred - torch.mean(g_real_pred) - real_label) ** 2))/2\n                g_loss.backward() \n            \n            elif gan_method == \"hingegan\":\n                g_loss = (torch.mean(torch.nn.ReLU()(1.0 + (g_real_pred - torch.mean(g_fake_pred)))) + \\\n                          torch.mean(torch.nn.ReLU()(1.0 - (g_fake_pred - torch.mean(g_real_pred)))))/2\n                g_loss.backward() \n        \n        # 4 Step   \n        optimizerG.step()\n        \n        if step % print_every == 0: \n            # append discriminator loss and generator loss\n            losses.append((d_loss.item(), g_loss.item(),)) \n            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f '\n                  % (epoch + 1, num_epochs, batch_i, len(train_loader),\n                     d_loss.item(), g_loss.item()))   \n            \n        step += 1 \n    \n    #torch.save(netG.state_dict(), 'gan_generator.pth')\n    #torch.save(netD.state_dict(), 'gan_discriminator.pth')  \n    \n    ## AFTER EACH EPOCH##    \n    # generate and save sample, fake images\n    if epoch % 25 == 0 : \n        netG.eval() # for generating samples\n        noise = torch.randn(10, nz, 1, 1, device=device)\n        #noise = torch.randn(batch_size, nz, 1, 1, device=device) \n        fake_images = netG(noise).to(device)  \n        display_img(fake_images.to(\"cpu\"),False,10)\n        netG.train() # back to training mode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nlosses = np.array(losses)\nplt.plot(losses.T[0], label='Discriminator', alpha=0.5)\nplt.plot(losses.T[1], label='Generator', alpha=0.5)\nplt.title(\"Training Losses\")\nplt.legend()\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noise = torch.randn(20, nz, 1, 1, device=device)\ngen_images = netG(noise)\nimages = gen_images.to(\"cpu\").clone().detach() \n#images = images.numpy().transpose(0, 2, 3, 1)\nprint(images.size())         \nprint('Scaled min: ', images.min())\nprint('Scaled max: ', images.max()) \ndisplay_img(images,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('../output_images'):\n    os.mkdir('../output_images')\nim_batch_size = 50\nn_images=10000\ntotal_images = 0\nfor i_batch in range(0, n_images, im_batch_size):\n    #gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n    noise = torch.randn(im_batch_size, nz, 1, 1, device=device)\n \n    gen_images = netG(noise)    \n    total_images += gen_images.size()[0] \n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))\n\nprint(total_images)\nimport shutil\nshutil.make_archive('images', 'zip', '../output_images')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}