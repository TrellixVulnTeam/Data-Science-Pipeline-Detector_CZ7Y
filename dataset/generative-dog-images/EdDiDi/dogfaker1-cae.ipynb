{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\ndogs=os.listdir('/kaggle/input/generative-dog-images/all-dogs/all-dogs/')\ndogDir='/kaggle/input/generative-dog-images/all-dogs/all-dogs/'\ndogArray=[]\nfor indivDog in dogs:\n    img=Image.open(dogDir+indivDog)\n    img=img.resize((128,128), Image.ANTIALIAS)\n    img=np.array(img)\n    dogArray.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(dogArray[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dogArray=np.array(dogArray)/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ndef make_encoder(data):\n    conv0 = tf.layers.conv2d(inputs=data,filters=64,\n      kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n    pool0 = tf.layers.max_pooling2d(inputs=conv0, pool_size=[2, 2], strides=2)\n    \n    conv1 = tf.layers.conv2d(inputs=pool0,filters=128,\n      kernel_size=[3, 3],padding=\"same\",activation=tf.nn.relu)\n    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n    \n    conv2 = tf.layers.conv2d(inputs=pool1,filters=256,\n      kernel_size=[3, 3],padding=\"same\",activation=tf.nn.relu)\n    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n    \n    conv3 = tf.layers.conv2d(inputs=pool2,filters=256,\n      kernel_size=[2, 2],padding=\"same\",activation=tf.nn.relu)\n    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n    \n    conv4 = tf.layers.conv2d(inputs=pool3,filters=512,\n      kernel_size=[2, 2],padding=\"same\",activation=tf.nn.relu)\n    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n    \n    #conv5 = tf.layers.conv2d(inputs=pool4,filters=32,\n    #  kernel_size=[2, 2],padding=\"same\",activation=tf.nn.relu)\n    \n    flatpool4=tf.reshape(pool4,[-1,4*4*512])\n    flatpool5=tf.layers.dense(flatpool4,512)\n    encoded = tf.layers.dense(flatpool5, 64)\n    return encoded\n\ndef make_decoder(data):\n\n    x1=tf.layers.dense(data ,512)\n    x=tf.layers.dense(x1,4*4*512)\n    deconv0=tf.reshape(x,[-1,4,4,512])\n    \n    deConvFilter0 = tf.get_variable('filter0', shape = [2, 2, 256, 512], dtype = tf.float32)\n    deconv1 = tf.nn.conv2d_transpose(deconv0,filter = deConvFilter0,\n                              output_shape =tf.stack([tf.shape(data)[0], 8, 8, 256]),\n                              strides = [1, 2, 2, 1], padding = 'SAME')\n    \n    \n    deConvFilter1 = tf.get_variable('filter1', shape = [2, 2, 256, 256], dtype = tf.float32)\n    deconv2 = tf.nn.conv2d_transpose(deconv1,filter = deConvFilter1,\n                              output_shape =tf.stack([tf.shape(data)[0], 16, 16, 256]),\n                              strides = [1, 2, 2, 1], padding = 'SAME')\n    deconv2=tf.nn.relu(deconv2)\n    \n    deConvFilter2 = tf.get_variable('filter2', shape = [3, 3, 128, 256], dtype = tf.float32)\n    deconv3 = tf.nn.conv2d_transpose(deconv2,filter = deConvFilter2,\n                              output_shape =  tf.stack([tf.shape(data)[0], 32, 32, 128]),\n                              strides = [1, 2, 2, 1], padding = 'SAME')\n    deconv3=tf.nn.relu(deconv3)\n    \n    deConvFilter3 = tf.get_variable('filter3', shape = [3, 3, 64, 128], dtype = tf.float32)\n    deconv4 = tf.nn.conv2d_transpose(deconv3,filter = deConvFilter3,\n                              output_shape =  tf.stack([tf.shape(data)[0],64, 64, 64]),\n                              strides = [1, 2, 2, 1], padding = 'SAME')\n    \n    \n    deConvFilter4 = tf.get_variable('filter4', shape = [3, 3, 64, 64], dtype = tf.float32)\n    deconv5 = tf.nn.conv2d_transpose(deconv4,filter = deConvFilter4,\n                              output_shape =  tf.stack([tf.shape(data)[0],128, 128, 64]),\n                              strides = [1, 2, 2, 1], padding = 'SAME')\n    \n    \n    deConvFilter5 = tf.get_variable('filter5', shape = [3, 3, 3, 64], dtype = tf.float32)\n    decoded = tf.nn.conv2d_transpose(deconv5,filter = deConvFilter5,\n                              output_shape =  tf.stack([tf.shape(data)[0],128, 128, 3]),\n                              strides = [1, 1, 1, 1], padding = 'SAME')\n    \n    return tf.nn.relu(decoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_encoder = tf.make_template('encoder', make_encoder)\nmake_decoder = tf.make_template('decoder', make_decoder)\ninputDog = tf.placeholder(tf.float32, [None,128,128,3])\n\nhidden = make_encoder(inputDog)\nrecon = make_decoder(hidden)\nloss = tf.nn.l2_loss(recon - inputDog)  # L2 loss\ntraining = tf.train.AdamOptimizer(0.0001).minimize(loss)\n\nsess=tf.Session()\ninit=tf.global_variables_initializer()\nsess.run(init)\nbatchSize=64\navgLoss=0.0\n\nfor i in range(2):\n    for epoch in range(100):\n        avgLoss=0.0\n        for idx in range(int(dogArray.shape[0]/batchSize)-1):\n            temp=dogArray[idx*batchSize:(idx+1)*batchSize]\n            err,_=sess.run([loss,training],feed_dict={inputDog:temp})\n            avgLoss+=err\n        if (epoch+1)%100==0:\n            print(\"For epoch \"+str(i+1)+\" the error is: \"+str(avgLoss/int(dogArray.shape[0]/batchSize)-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    check=sess.run([hidden],feed_dict={inputDog:np.array([dogArray[i]])})\n    hids=tf.placeholder(tf.float32,shape=[None,64])\n    recs=make_decoder(hids)\n    a=sess.run(recs,feed_dict={hids:check[0]})\n    a=a*255\n    ax = plt.subplot2grid((5,5), (int(i/5),i%5))\n    cnter=int(str(55)+str(i+1))\n    a=a.astype(int)\n    ax.imshow(a[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}