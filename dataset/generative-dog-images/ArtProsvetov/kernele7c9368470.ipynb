{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport random\nfrom tqdm import tqdm\nimport shutil\n\nComputeLB = False\nDogsOnly = True\n\nimport numpy as np, pandas as pd, os\nimport xml.etree.ElementTree as ET \nimport matplotlib.pyplot as plt, zipfile \nfrom PIL import Image \n\n#ROOT = '../input/generative-dog-images/'\nROOT = '../input/'\n#if not ComputeLB: ROOT = '../input/'\nIMAGES = os.listdir(ROOT + 'all-dogs/all-dogs/')\nbreeds = os.listdir(ROOT + 'annotation/Annotation/') \n\nidxIn = 0; namesIn = []\nimagesIn = np.zeros((25000,64,64,3))\nimagesIn2 = np.zeros((25000,64,64))\n# CROP WITH BOUNDING BOXES TO GET DOGS ONLY\n# https://www.kaggle.com/paulorzp/show-annotations-and-breeds\nif DogsOnly:\n    for breed in breeds:\n        for dog in os.listdir(ROOT+'annotation/Annotation/'+breed):\n            try: img = Image.open(ROOT+'all-dogs/all-dogs/'+dog+'.jpg') \n            except: continue           \n            tree = ET.parse(ROOT+'annotation/Annotation/'+breed+'/'+dog)\n            root = tree.getroot()\n            objects = root.findall('object')\n            for o in objects:\n                bndbox = o.find('bndbox') \n                xmin = int(bndbox.find('xmin').text)\n                ymin = int(bndbox.find('ymin').text)\n                xmax = int(bndbox.find('xmax').text)\n                ymax = int(bndbox.find('ymax').text)\n                w = np.min((xmax - xmin, ymax - ymin))\n                img2 = img.crop((xmin, ymin, xmin+w, ymin+w))\n                img3 = img2\n                img3 = img3.transpose(Image.FLIP_LEFT_RIGHT)\n                img3 = img3.resize((64,64), Image.ANTIALIAS)\n                img3 = img3.convert('LA')\n                img2 = img2.resize((64,64), Image.ANTIALIAS)\n                imagesIn[idxIn,:,:,:] = np.asarray(img2)\n                imagesIn2[idxIn,:,:] = np.asarray(img3)[:,:,0]\n                #if idxIn%1000==0: print(idxIn)\n                namesIn.append(breed)\n                idxIn += 1\n    idx = np.arange(idxIn)\n    np.random.shuffle(idx)\n    imagesIn = imagesIn[idx,:,:,:]\n    imagesIn2 = imagesIn2[idx,:,:]\n    namesIn = np.array(namesIn)[idx]\n    \n# RANDOMLY CROP FULL IMAGES\nelse:\n    IMAGES = np.sort(IMAGES)\n    np.random.seed(810)\n    x = np.random.choice(np.arange(20579),10000)\n    np.random.seed(None)\n    for k in range(len(x)):\n        img = Image.open(ROOT + 'all-dogs/all-dogs/' + IMAGES[x[k]])\n        w = img.size[0]; h = img.size[1];\n        if (k%2==0)|(k%3==0):\n            w2 = 100; h2 = int(h/(w/100))\n            a = 18; b = 0          \n        else:\n            a=0; b=0\n            if w<h:\n                w2 = 64; h2 = int((64/w)*h)\n                b = (h2-64)//2\n            else:\n                h2 = 64; w2 = int((64/h)*w)\n                a = (w2-64)//2\n        img = img.resize((w2,h2), Image.ANTIALIAS)\n        img = img.crop((0+a, 0+b, 64+a, 64+b))    \n        imagesIn[idxIn,:,:,:] = np.asarray(img)\n        namesIn.append(IMAGES[x[k]])\n        #if idxIn%1000==0: print(idxIn)\n        idxIn += 1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img3.transpose(Image.FLIP_LEFT_RIGHT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(imagesIn2[101,:,:], cmap='Greys')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.imshow(Image.fromarray( (imagesIn[101]).astype('uint8').reshape((64,64))), cmap='Greys')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(Image.fromarray( (imagesIn[101]).astype('uint8').reshape((64,64,3))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, Reshape, Flatten, concatenate\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import SGD, Adam\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_discriminator(in_shape=(28,28,1)):\n    model = Sequential()\n# downsample\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n# classifier\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='sigmoid'))\n# compile model\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_discriminator(in_shape=(28,28,1), n_classes=10):\n\t# label input\n\tin_label = Input(shape=(1,))\n\t# embedding for categorical input\n\tli = Embedding(n_classes, 50)(in_label)\n\t# scale up to image dimensions with linear activation\n\tn_nodes = in_shape[0] * in_shape[1]\n\tli = Dense(n_nodes)(li)\n\t# reshape to additional channel\n\tli = Reshape((in_shape[0], in_shape[1], 1))(li)\n\t# image input\n\tin_image = Input(shape=in_shape)\n\t# concat label as a channel\n\tmerge = Concatenate()([in_image, li])\n\t# downsample\n\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n\tfe = LeakyReLU(alpha=0.2)(fe)\n\t# downsample\n\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n\tfe = LeakyReLU(alpha=0.2)(fe)\n\t# flatten feature maps\n\tfe = Flatten()(fe)\n\t# dropout\n\tfe = Dropout(0.4)(fe)\n\t# output\n\tout_layer = Dense(1, activation='sigmoid')(fe)\n\t# define model\n\tmodel = Model([in_image, in_label], out_layer)\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NNimage = 4096","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BUILD DISCRIMINATIVE NETWORK\n#dog = Input((12288,))\ndog = Input((NNimage,))\ndogName = Input((10000,))\n#x = Dense(12288, activation='sigmoid')(dogName)\nx = Dense(NNimage, activation='sigmoid')(dogName)\n#x = Reshape((2,12288,1))(concatenate([dog,x]))\nx = Reshape((2,NNimage,1))(concatenate([dog,x]))\nx = Conv2D(1,(2,1),use_bias=False,name='conv')(x)\ndiscriminated = Flatten()(x)\n\n# COMPILE\ndiscriminator = Model([dog,dogName], discriminated)\ndiscriminator.get_layer('conv').trainable = False\ndiscriminator.get_layer('conv').set_weights([np.array([[[[-1.0 ]]],[[[1.0]]]])])\ndiscriminator.compile(optimizer='adam', loss='binary_crossentropy')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRAINING DATA\n#NNimage = 12288\n#NNimage = 16384\ntrain_y = (imagesIn2[:10000,:,:]/255.).reshape((-1,NNimage))\ntrain_X = np.zeros((10000,10000))\nfor i in range(10000): train_X[i,i] = 1\nzeros = np.zeros((10000,NNimage))\n\n# TRAIN NETWORK\nlr = 0.5\nfor k in range(4):\n    annealer = LearningRateScheduler(lambda x: lr)\n    h = discriminator.fit([zeros,train_X], train_y, epochs = 20, batch_size=256, callbacks=[annealer], verbose=0)\n    print('Epoch',(k+1)*10,'/50 - loss =',h.history['loss'][-1] )\n    if h.history['loss'][-1]<0.530: lr = 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Epoch',(k+1)*10,'/50 - loss =',h.history['loss'][-1] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_generator(latent_dim):\n\tmodel = Sequential()\n\t# foundation for 7x7 image\n\tn_nodes = 128 * 7 * 7\n\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\tmodel.add(Reshape((7, 7, 128)))\n\t# upsample to 14x14\n\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# upsample to 28x28\n\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# generate\n\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same'))\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_generator(latent_dim, n_classes=120):\n\t# label input\n\tin_label = Input(shape=(1,))\n\t# embedding for categorical input\n\tli = Embedding(n_classes, 50)(in_label)\n\t# linear multiplication\n\tn_nodes = 7 * 7\n\tli = Dense(n_nodes)(li)\n\t# reshape to additional channel\n\tli = Reshape((7, 7, 1))(li)\n\t# image generator input\n\tin_lat = Input(shape=(latent_dim,))\n\t# foundation for 7x7 image\n\tn_nodes = 128 * 7 * 7\n\tgen = Dense(n_nodes)(in_lat)\n\tgen = LeakyReLU(alpha=0.2)(gen)\n\tgen = Reshape((7, 7, 128))(gen)\n\t# merge image gen and label input\n\tmerge = Concatenate()([gen, li])\n\t# upsample to 14x14\n\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n\tgen = LeakyReLU(alpha=0.2)(gen)\n\t# upsample to 28x28\n\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n\tgen = LeakyReLU(alpha=0.2)(gen)\n\t# output\n\tout_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n\t# define model\n\tmodel = Model([in_lat, in_label], out_layer)\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BUILD GENERATOR NETWORK\nseed = Input((10000,))\ngenerated = Dense(NNimage, activation='linear')(seed)\n\n# COMPILE\ngenerator = Model(seed, [generated,Reshape((10000,))(seed)])\ngenerator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gan.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.trainable=False    \ngan_input = Input(shape=(10000,))\nx = generator(gan_input)\ngan_output = discriminator(x)\n\n# COMPILE GAN\ngan = Model(gan_input, gan_output)\ngan.get_layer('model_1').get_layer('conv').set_weights([np.array([[[[-1 ]]],[[[255.]]]])])\ngan.compile(optimizer=Adam(5), loss='mean_squared_error')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = np.zeros((10000,10000))\nfor i in range(10000): train[i,i] = 1\nzeros = np.zeros((10000,NNimage))\n\n# TRAIN NETWORKS\nlr = 5.\n#for k in range(50):  \nfor k in range(20):\n    # BEGIN DISCRIMINATOR COACHES GENERATOR\n    annealer = LearningRateScheduler(lambda x: lr)\n    h = gan.fit(train, zeros, epochs = 1, batch_size=256, callbacks=[annealer], verbose=0)\n    if (k<10)|(k%5==4):\n        print('Epoch',(k+1)*10,'/500 - loss =',h.history['loss'][-1] )\n    if h.history['loss'][-1] < 25: lr = 1.\n    if h.history['loss'][-1] < 1.5: lr = 0.5\n        \n    # DISPLAY GENERATOR LEARNING PROGRESS\n    if k<10:        \n        plt.figure(figsize=(15,3))\n        for j in range(5):\n            xx = np.zeros((10000))\n            xx[np.random.randint(10000)] = 1\n            plt.subplot(1,5,j+1)\n            #img = generator.predict(xx.reshape((-1,10000)))[0].reshape((-1,64,64,3))\n            img = generator.predict(xx.reshape((-1,10000)))[0]\n            #img = Image.fromarray( (img).astype('uint8').reshape((64,64,3)))\n            #img = Image.fromarray( (img).astype('uint8').reshape((128,128)))\n            img = Image.fromarray( (img).astype('uint8').reshape((64,64)))\n            plt.axis('off')\n            plt.imshow(img, cmap='Greys')\n        plt.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nimport skimage\nfrom PIL import Image\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.util import crop, pad\nfrom skimage.morphology import label\nfrom skimage.color import rgb2gray, gray2rgb, rgb2lab, lab2rgb\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom keras.models import Model, load_model,Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Dense, UpSampling2D, RepeatVector, Reshape, Embedding\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42\nrandom.seed = seed\nnp.random.seed = seed\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inception = InceptionResNetV2(weights=None, include_top=True)\n# inception.load_weights('../input/image-colorization/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5')\n# inception.graph = tf.get_default_graph()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_WIDTH = 64\nIMG_HEIGHT = 64\nIMG_CHANNELS = 3\nINPUT_SHAPE=(IMG_HEIGHT, IMG_WIDTH, 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idxIn = 0; namesIn = []\nimagesIn = np.zeros((25000,64,64,3))\n\nIMAGES = np.sort(IMAGES)\n#np.random.seed(2019)\nx = np.random.choice(np.arange(20579),10000)\n#np.random.seed(None)\nfor k in range(len(x)):\n    img = Image.open(ROOT + 'all-dogs/all-dogs/' + IMAGES[x[k]])\n    w = img.size[0]; h = img.size[1];\n    if (k%2==0)|(k%3==0):\n        w2 = 100; h2 = int(h/(w/100))\n        a = 18; b = 0          \n    else:\n        a=0; b=0\n        if w<h:\n            w2 = 64; h2 = int((64/w)*h)\n            b = (h2-64)//2\n        else:\n            h2 = 64; w2 = int((64/h)*w)\n            a = (w2-64)//2\n    img = img.resize((w2,h2), Image.ANTIALIAS)\n    img = img.crop((0+a, 0+b, 64+a, 64+b))    \n    imagesIn[idxIn,:,:,:] = np.asarray(img)\n    namesIn.append(IMAGES[x[k]])\n    #if idxIn%1000==0: print(idxIn)\n    idxIn += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nimport sklearn.preprocessing\nL_enc = sklearn.preprocessing.LabelEncoder()\nlabels = L_enc.fit_transform(namesIn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = np.array(labels).reshape((len(labels),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Colorize():\n    in_label = Input(shape=(1,))\n    embed_input = Embedding(120, 1000)(in_label)\n    \n    \n    #Encoder\n    encoder_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1,))\n    encoder_output = Conv2D(32, (3,3), activation='relu', padding='same',strides=1)(encoder_input)\n    encoder_output = MaxPooling2D((2, 2), padding='same')(encoder_output)\n    encoder_output = Conv2D(32, (4,4), activation='relu', padding='same')(encoder_output)\n    encoder_output = Conv2D(32, (3,3), activation='relu', padding='same',strides=1)(encoder_output)\n    encoder_output = MaxPooling2D((2, 2), padding='same')(encoder_output)\n    encoder_output = Conv2D(64, (4,4), activation='relu', padding='same')(encoder_output)\n    encoder_output = Conv2D(64, (3,3), activation='relu', padding='same',strides=1)(encoder_output)\n    encoder_output = MaxPooling2D((2, 2), padding='same')(encoder_output)\n    encoder_output = Conv2D(64, (4,4), activation='relu', padding='same')(encoder_output)\n    encoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(encoder_output)\n    encoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(encoder_output)\n    \n    #Fusion\n    #fusion_output = RepeatVector(2 * 2)(embed_input) \n    fusion_output = Dense(4096, activation='relu')(embed_input) \n    fusion_output = Reshape(([8, 8, 64]))(fusion_output)\n    fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n    fusion_output = Conv2D(64, (1, 1), activation='relu', padding='same')(fusion_output)\n    \n    #Decoder\n    decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(fusion_output)\n    decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n    decoder_output = UpSampling2D((2, 2))(decoder_output)\n    decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n    decoder_output = UpSampling2D((2, 2))(decoder_output)\n    decoder_output = Conv2D(128, (4,4), activation='relu', padding='same')(decoder_output)\n    decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(decoder_output)\n    decoder_output = Conv2D(32, (2,2), activation='relu', padding='same')(decoder_output)\n    decoder_output = Conv2D(3, (3, 3), activation='tanh', padding='same')(decoder_output)\n    decoder_output = UpSampling2D((2, 2))(decoder_output)\n    return Model(inputs=[encoder_input, in_label], outputs=decoder_output)\n\nmodel = Colorize()\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = imagesIn / 256.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        shear_range=0.2,\n        zoom_range=0.2,\n        rotation_range=20,\n        horizontal_flip=True)\n\n# #Create embedding\n# def create_inception_embedding(grayscaled_rgb):\n#     def resize_gray(x):\n#         return resize(x, (299, 299, 3), mode='constant')\n#     grayscaled_rgb_resized = np.array([resize_gray(x) for x in grayscaled_rgb])\n#     grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n#     with inception.graph.as_default():\n#         embed = inception.predict(grayscaled_rgb_resized)\n#     return embed\n\n#Generate training data\ndef image_a_b_gen(dataset=X_train, batch_size = 20):\n    for batch in datagen.flow(dataset, batch_size=batch_size):\n        \n        X_batch = rgb2gray(batch)\n        \n        #label_batch = batch\n        #grayscaled_rgb = gray2rgb(X_batch)\n        lab_batch = rgb2lab(batch)\n        X_batch = lab_batch[:,:,:,0]\n        X_batch = X_batch.reshape(X_batch.shape+(1,))\n        Y_batch = lab_batch[:,:,:,1:] / 128\n        yield [X_batch, label_batch], Y_batch\n    \n\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5,\n                                            min_lr=0.00001)\nfilepath = \"Art_Colorization_Model.h5\"\ncheckpoint = ModelCheckpoint(filepath,\n                             save_best_only=True,\n                             monitor='loss',\n                             mode='min')\n\nmodel_callbacks = [learning_rate_reduction,checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_batch = rgb2gray(X_train)\nX_batch = X_batch.reshape(X_batch.shape+(1,))        \n#label_batch = batch\n#grayscaled_rgb = gray2rgb(X_batch)\n# lab_batch = rgb2lab(batch)\n# X_batch = lab_batch[:,:,:,0]\n# X_batch = X_batch.reshape(X_batch.shape+(1,))\n# Y_batch = lab_batch[:,:,:,1:] / 128\n# [X_batch, label_batch], Y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.fit([X_batch,labels],X_train,\n            epochs=6,\n            verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# BATCH_SIZE = 128\n# model.fit_generator(image_a_b_gen(X_train,BATCH_SIZE),\n#             epochs=2,\n#             verbose=1,\n#             steps_per_epoch=X_train.shape[0]/BATCH_SIZE,\n#              callbacks=model_callbacks\n#                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_rgb(img):\n    color_me_embed = np.array(np.random.randint(120))#create_inception_embedding([np.asarray(img)])\n    #color_me = np.array([img])\n    img = img.reshape((64,64,1))/256\n    #color_me = gray2rgb(img)\n    #color_me = gray2rgb(np.asarray(img))\n    #color_me = rgb2lab([color_me])[:,:,:,0]\n    #color_me = color_me.reshape(color_me.shape+(1,))\n    \n    color_me_embed = color_me_embed.reshape(1,1)\n    #print(color_me.shape)\n    output = model.predict([[img], color_me_embed.reshape(1,1)])\n    #output = output[0] * 256\n    #print(output)\n#     decoded_imgs = np.zeros((len(output),64, 64, 3))\n\n\n\n#     cur = np.zeros((64, 64, 3))\n#     cur[:,:,0] = color_me[0][:,:,0]\n#     cur[:,:,1:] = output[0]\n#    return lab2rgb(cur)\n    output = output*256.\n    return Image.fromarray( (output).astype('uint8').reshape((64,64,3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = imagesIn2[101,:,:]\nimg2 = get_rgb(img)\n#plt.imshow(Image.fromarray( (img2).astype('uint8').reshape((64,64,3))))\nplt.imshow(img2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,3))\nfor j in range(5):\n    xx = np.zeros((10000))\n    xx[np.random.randint(10000)] = 1\n    plt.subplot(1,5,j+1)\n    #img = generator.predict(xx.reshape((-1,10000)))[0].reshape((-1,64,64,3))\n    img = generator.predict(xx.reshape((-1,10000)))[0]\n    #img = Image.fromarray( (img).astype('uint8').reshape((64,64,3)))\n    #img = Image.fromarray( (img).astype('uint8').reshape((128,128)))\n    img = Image.fromarray( (img).astype('uint8').reshape((64,64)))\n    plt.axis('off')\n    plt.imshow(img, cmap='Greys')\n    plt.imshow(get_rgb(img))\nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DogGenerator:\n    index = 0   \n    def getDog(self,seed):\n        xx = np.zeros((10000))\n        #xx[self.index] = 0.70\n        #xx[np.random.randint(10000)] = 0.30\n        xx = np.zeros((10000))\n        xx[np.random.randint(10000)] = 1\n        #img = generator.predict(xx.reshape((-1,10000)))[0].reshape((64,64,3))\n        img = generator.predict(xx.reshape((-1,10000)))[0].reshape((64,64))\n        self.index = (self.index+1)%10000\n        return Image.fromarray( (img).astype('uint8').reshape((64,64)))\n    #Image.fromarray( img.astype('uint8') ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SAVE TO ZIP FILE NAMED IMAGES.ZIP\nz = zipfile.PyZipFile('images.zip', mode='w')\nd = DogGenerator()\nfor k in range(10000):\n    img = d.getDog(np.random.normal(0,1,100))\n    img = get_rgb(img)\n    \n    f = str(k)+'.png'\n    #img.save(f,'PNG'); z.write(f); os.remove(f)\n    cv2.imwrite(f, img); z.write(f); os.remove(f)\n    #if k % 1000==0: print(k)\nz.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimg = d.getDog(np.random.normal(0,1,100))\nimg = get_rgb(img)\nplt.imshow(img)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}