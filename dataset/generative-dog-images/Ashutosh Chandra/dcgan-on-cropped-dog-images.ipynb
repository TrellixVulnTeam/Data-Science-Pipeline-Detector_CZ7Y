{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport shutil\nimport glob\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as ET \nimport random\nimport torch\nfrom torch import nn\nimport torchvision\nfrom torchvision.utils import save_image\nimport torch.optim as optim\nfrom PIL import Image\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_images=\"../input/all-dogs/all-dogs/\"\nroot_annots=\"../input/annotation/Annotation/\"\n\nall_images=os.listdir(\"../input/all-dogs/all-dogs/\")\nprint(f\"Total images : {len(all_images)}\")\n\nbreeds = glob.glob('../input/annotation/Annotation/*')\nannotation=[]\nfor b in breeds:\n    annotation+=glob.glob(b+\"/*\")\nprint(f\"Total annotation : {len(annotation)}\")\n\nbreed_map={}\nfor annot in annotation:\n    breed=annot.split(\"/\")[-2]\n    index=breed.split(\"-\")[0]\n    breed_map.setdefault(index,breed)\n    \nprint(f\"Total Breeds : {len(breed_map)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(3,3))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    im=Image.open(os.path.join(root_images,all_images[i]))\n    plt.imshow(im)\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class opt:\n    dataroot=\"../cropped\"\n    workers=2\n    batchsize=128\n    imagesize=64\n    nz=100\n    ngf=64\n    ndf=64\n    nc=3\n    niter=400\n    lr=0.0001\n    beta1=0.5\n    ngpu=1\n    cuda=torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dog_loader(path):\n    image=Image.open(path)\n    impath=path.split(\"/\")[-1]\n    bpath=root_annots+str(breed_map[impath.split(\"_\")[0]])+\"/\"+str(impath.split(\".\")[0])\n    tree = ET.parse(bpath)\n    root = tree.getroot()\n    objects = root.findall('object')\n    for o in objects:\n        bndbox = o.find('bndbox') # reading bound box\n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n        \n    image=image.crop((xmin,ymin,xmax,ymax))\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean=0\nstd=1\n\n# The dataset\ndataset = torchvision.datasets.ImageFolder(\n    '../input/all-dogs/',\n    loader=dog_loader, # THE CUSTOM LOADER\n    transform=torchvision.transforms.Compose([\n        torchvision.transforms.Resize(64),\n        torchvision.transforms.CenterCrop(64),\n        torchvision.transforms.ColorJitter(0.1),\n        torchvision.transforms.RandomHorizontalFlip(0.2),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize((mean,mean,mean),(std,std,std))\n    ])\n)\n\n# Create the dataloader\ndataloader = torch.utils.data.DataLoader(dataset, \n                                        batch_size=opt.batchsize,\n                                         shuffle=True, \n                                         num_workers=opt.workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x,y in dataloader:\n    images=x.numpy().transpose(0,2,3,1)\n    plt.figure(figsize=(3,3))\n    for i in range(9):\n        plt.subplot(3,3,i+1)\n        plt.imshow(images[i])\n        plt.axis(\"off\")\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nz = opt.nz\nngf = opt.ngf\nndf = opt.ndf\nnc = opt.nc\nngpu = opt.ngpu\n   \ndevice = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, ngpu):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2,ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(ngf,nc, 4, 2, 1, bias=False),\n            nn.Sigmoid()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, ngpu):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output.view(-1, 1).squeeze(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"netG = Generator(ngpu).to(device)\nnetG.apply(weights_init)\n\nnetD = Discriminator(ngpu).to(device)\nnetD.apply(weights_init)\n\nprint(\"Discriminator and Generator Loaded\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.BCELoss()\n\nfixed_noise = torch.randn(opt.batchsize, nz, 1, 1, device=device)\nreal_label = 1\nfake_label = 0\n\n# setup optimizer\noptimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"derror_epoch=[]\ngerror_epoch=[]\nfor epoch in range(opt.niter):\n    derror_iter=0\n    gerror_iter=0\n    for i, data in enumerate(dataloader, 0):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        batch_size = real_cpu.size(0)\n        label = torch.full((batch_size,), real_label, device=device)\n\n        output = netD(real_cpu)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        # train with fake\n        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach())\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        derror_iter+=errD.item()\n        optimizerD.step()\n        \n        \n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake)\n        errG = criterion(output, label)\n        gerror_iter+=errG.item()\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n        \n#         if(i%70==0 and i!=0):\n#             print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f'\n#                   % (epoch, opt.niter, i, len(dataloader),\n#                      errD.item(), errG.item()))\n            \n    # accumulate error for each epoch\n    derror_epoch.append(derror_iter)\n    gerror_epoch.append(gerror_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\n        \n# discriminator loss\nplt.subplot(1,2,1)\nplt.plot(list(range(len(derror_epoch))),derror_epoch)\nplt.title(\"Discriminator Error\")\nplt.show()\n\n# generator loss\nplt.subplot(1,2,2)\nplt.plot(list(range(len(gerror_epoch))),gerror_epoch)\nplt.title(\"Generator Error\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_fake_images():\n    gen_z = torch.randn(10, nz, 1, 1, device=device)\n    gen_images = netG(gen_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    plt.figure(figsize=(10,10))\n    for i in range(9):\n        plt.subplot(3,3,i+1)\n        plt.imshow(images[i])\n\nplot_fake_images()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('../output_images'):\n    os.mkdir('../output_images')\nim_batch_size = 50\nn_images=10000\nfor i_batch in range(0, n_images, im_batch_size):\n    gen_z = torch.randn(im_batch_size, nz, 1, 1, device=device)\n    gen_images = netG(gen_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))\n\n\nimport shutil\nshutil.make_archive('images', 'zip', '../output_images')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}