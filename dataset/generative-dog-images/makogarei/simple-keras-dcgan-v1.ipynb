{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Beginer DCGAN LESSON"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/all-dogs/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Reshape\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers import Flatten, Dropout\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.optimizers import Adam\nimport math\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom keras.preprocessing import image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_list =os.listdir(\"../input/all-dogs/all-dogs/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../working\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(img_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_img = load_img('../input/all-dogs/all-dogs/n02085620_10074.jpg')\ntemp_img_array  = img_to_array(temp_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### show sample images"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_img_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_model():\n    model = Sequential()\n    model.add(Dense(input_dim=100, units=1024))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dense(32 * 32 * 128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Reshape((32, 32, 128), input_shape=(32 * 32 * 128,)))\n    model.add(UpSampling2D((2, 2)))\n    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(UpSampling2D((2, 2)))\n    model.add(Conv2D(3, (5, 5), padding=\"same\"))\n    model.add(Activation('tanh'))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_model():\n    model = Sequential()\n    model.add(Conv2D(64, (5,5), strides=(2, 2), input_shape=(128, 128, 3), padding=\"same\"))\n    model.add(LeakyReLU(0.2))\n    model.add(Conv2D(128, (5,5), strides=(2, 2)))\n    model.add(LeakyReLU(0.2))\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.5))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_images(generated_images):\n    total = generated_images.shape[0]\n    cols = int(math.sqrt(total))\n    rows = math.ceil(float(total)/cols)\n    width, height, ch= generated_images.shape[1:]\n    output_shape = (\n        height * rows,\n        width * cols,\n        ch\n    )\n    combined_image = np.zeros(output_shape)\n\n    for index, image in enumerate(generated_images):\n        i = int(index/cols)\n        j = index % cols\n        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[:, :, :]\n    return combined_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_IMAGE_PATH = '../input/all-dogs/all-dogs/'\n#GENERATED_IMAGE_PATH = '../images/'\nGENERATED_IMAGE_PATH = '../working/images/'\nGEN_GENERATED_IMAGE_PATH = '../gen_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 訓練データ読み込み\nimg_list = os.listdir(TRAIN_IMAGE_PATH)\nX_train = []\nfor img in img_list:\n    img = img_to_array(load_img(TRAIN_IMAGE_PATH+img, target_size=(128,128,3)))\n    # -1から1の範囲に正規化\n    img = (img.astype(np.float32) - 127.5)/127.5\n    X_train.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4Dテンソルに変換(データの個数, 128, 128, 3)\nX_train = np.array(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generatorとdiscriminatorを作成\ndiscriminator = discriminator_model()\nd_opt = Adam(lr=1e-5, beta_1=0.1)\ndiscriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n# discriminatorの重みを固定(dcganの中のみ)\ndiscriminator.trainable = False\ngenerator = generator_model()\n\ndcgan = Sequential([generator, discriminator])\ng_opt = Adam(lr=2e-4, beta_1=0.5)\ndcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\nBATCH_SIZE = 128\nNUM_EPOCH  = 200\n\nnum_batches = int(X_train.shape[0] / BATCH_SIZE)\nprint('Number of batches:', num_batches)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in tqdm(range(NUM_EPOCH)):\n    for index in range(num_batches):\n        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n        image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n        generated_images = generator.predict(noise, verbose=0, batch_size=BATCH_SIZE)\n\n#         # 生成画像を出力\n#         if (index+1) % (num_batches) == 0:\n#             image = combine_images(generated_images)\n#             image = image*127.5 + 127.5\n#             if not os.path.exists(GENERATED_IMAGE_PATH):\n#                 os.mkdir(GENERATED_IMAGE_PATH)\n#             Image.fromarray(image.astype(np.uint8)).save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n            \n        if not os.path.exists(GEN_GENERATED_IMAGE_PATH):\n            os.mkdir(GEN_GENERATED_IMAGE_PATH)\n        \n        if epoch == 200 and index > 59:\n            generated_images_v = generated_images*127.5 + 127.5    \n            for j in range(100):\n                Image.fromarray((generated_images_v[j]*127.5 + 127.5).astype(np.uint8)).save(GEN_GENERATED_IMAGE_PATH+\"%04d_%04d_%04d.png\" % (epoch, index,j))\n\n        # discriminatorを更新\n        X = np.concatenate((image_batch, generated_images))\n        # 訓練データのラベルが1、生成画像のラベルが0になるよう学習する\n        y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n        d_loss = discriminator.train_on_batch(X, y)\n\n        # generator更新\n        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n        # 生成画像をdiscriminatorにいれたときに\n        # 出力が1に近くなる(訓練画像と識別される確率が高くなる)ように学習する\n        g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n\n        print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(GENERATED_IMAGE_PATH))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\n#shutil.make_archive('images', 'zip', '../images/')\nshutil.make_archive('images', 'zip', '../gen_images/')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}