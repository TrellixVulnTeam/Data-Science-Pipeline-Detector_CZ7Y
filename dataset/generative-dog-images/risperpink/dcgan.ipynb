{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pickle as pkl\nimport matplotlib.pyplot as plt\n#Data\nimport os\nimport xml.etree.ElementTree as ET\n\nimport torch\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms\n\n# for testing only\nfrom tqdm import tqdm_notebook as tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def doggo_loader(path):\n    img = torchvision.datasets.folder.default_loader(path) # default loader\n    # Get bounding box\n    annotation_basename = os.path.splitext(os.path.basename(path))[0]\n    annotation_dirname = next(dirname for dirname in os.listdir('../input/annotation/Annotation/') if dirname.startswith(annotation_basename.split('_')[0]))\n    annotation_filename = os.path.join('../input/annotation/Annotation', annotation_dirname, annotation_basename)\n    tree = ET.parse(annotation_filename)\n    root = tree.getroot()\n    objects = root.findall('object')\n    for o in objects:\n        bndbox = o.find('bndbox')\n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n    bbox = (xmin, ymin, xmax, ymax)\n    \n    # return cropped image\n    return img.crop(bbox)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading data \ndef load_images(data_dir):\n    trans=transforms.Compose([transforms.Resize(64),\n                                 transforms.CenterCrop(64),\n                                 transforms.ToTensor()])\n\n    dog_trainset=datasets.ImageFolder(data_dir,transform=trans,loader=doggo_loader)\n    train_loader=torch.utils.data.DataLoader(dog_trainset,batch_size=128,shuffle=True,num_workers=0)\n    return train_loader\ndata_dir=\"../input/all-dogs/\"\ndog_trainloader=load_images(data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show images\ndef show_images(img):\n    img=img.numpy()\n    plt.imshow(np.transpose(img,(1,2,0)))\n#get one batch\ndataiter =iter(dog_trainloader)\nimages,_=dataiter.next()\n\n\nfig = plt.figure(figsize=(20, 4))\nplot_size=30\nfor idx in np.arange(plot_size):\n    ax = fig.add_subplot(2, plot_size/2, idx+1, xticks=[], yticks=[])\n    show_images(images[idx])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scale images to be between -1 and 1\ndef scalling(img):\n    img=(img*2)+(-1)\n    return img   \nmaxi=scalling(images[0]).max()\n\nmini=scalling(images[0]).min()\nmini,maxi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"USE_GPU=True\ntrain_on_gpu = torch.cuda.is_available()\nif not train_on_gpu:\n    print('No GPU found. Please use a GPU to train your neural network.')\nelse:\n    print('Training on GPU!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build model\n#discriminator\nconv_size=32\n\nclass Discriminator(nn.Module):\n    \n    def __init__(self, conv_size):\n        super(Discriminator,self).__init__()\n        self.conv_size=conv_size\n        self.dconv_layers=nn.Sequential(nn.Conv2d(3,conv_size,4,stride=2,padding=1,bias=False), \n                                    nn.LeakyReLU(negative_slope=0.2,inplace=True),\n                                    \n                                    nn.Conv2d(conv_size,conv_size*2,4,stride=2,padding=1,bias=False),\n                                    nn.BatchNorm2d(conv_size*2),\n                                    nn.LeakyReLU(negative_slope=0.2,inplace=True),\n                                          \n                                    nn.Conv2d(conv_size*2,conv_size*4,4,stride=2,padding=1,bias=False),\n                                    nn.BatchNorm2d(conv_size*4),\n                                    nn.LeakyReLU(negative_slope=0.2,inplace=True)\n                                    \n                                       \n                                   )\n\n        self.fc=nn.Sequential(nn.Linear(conv_size*4*4*4,1),\n                              nn.Sigmoid())\n\n    def forward(self,x,feature=False):\n       \n        x=self.dconv_layers(x)\n        features = x.view(-1,64)\n        #flatten\n        x=x.view(-1,self.conv_size*4*4*4)\n       \n        x=self.fc(x)\n        if feature:\n            return features,x\n        else:\n            return x\n        \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generator\nclass Generator(nn.Module):\n    def __init__(self,conv_size,latent_size):\n        super(Generator,self).__init__()\n        self.conv_size=conv_size\n        self.latent_size=latent_size\n        self.gfc=nn.Sequential(nn.Linear(latent_size,(conv_size*4)*4*4))\n        self.gconv_layers=nn.Sequential(nn.ConvTranspose2d(conv_size*4,conv_size*2,4,stride=2,padding=1,bias=False),\n                                        nn.BatchNorm2d(conv_size*2),\n                                        nn.ReLU(True),\n                                        \n                                        nn.ConvTranspose2d(conv_size*2,conv_size,4,stride=2,padding=1,bias=False),\n                                        nn.BatchNorm2d(conv_size),\n                                        nn.ReLU(True),\n                                        \n                                        nn.ConvTranspose2d(conv_size,3,4,stride=2,padding=1,bias=False))\n    def forward(self,x):\n        x=self.gfc(x)\n        #unflatten\n        x=x.view(-1, self.conv_size*4, 4, 4)\n       \n        x=self.gconv_layers(x)\n        x=torch.tanh(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G=Generator(conv_size,latent_size=100)\nD=Discriminator(conv_size)\nprint('G And D loaded')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def init_weights(m):\n    \n    \n    classname = m.__class__.__name__\n    \n    # TODO: Apply initial weights to convolutional and linear layers\n    #weights for a convolutional layers and linear layer\n    if hasattr(m,'weight') and (classname.find('Conv') != -1 or classname.find('Linear')  != -1):\n        \n        nn.init.normal_(m.weight.data,mean=0,std=0.02)\nD.apply(init_weights),G.apply(init_weights)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#real and fake loss\n#real loss\ndef real_loss(D_result,smooth=False):\n    batch_size=D_result.size(0)\n    #smoothen\n    if smooth:\n        labels=torch.ones(batch_size)*0.9\n          \n    else:\n        labels=torch.ones(batch_size)\n   \n    criterion=nn.BCEWithLogitsLoss()\n    if train_on_gpu and USE_GPU:\n        labels=labels.cuda()  \n        \n    loss=criterion(D_result.squeeze(),labels)\n    return loss\ndef fake_loss(D_result):\n    batch_size=D_result.size(0)\n    labels=torch.zeros(batch_size)\n    criterion=nn.BCEWithLogitsLoss()\n    if train_on_gpu and USE_GPU:\n        labels=labels.cuda()\n    loss=criterion(D_result.squeeze(),labels)\n    return loss\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_optim=optim.Adam(D.parameters(),lr=0.0002,betas=(0.5, 0.999))\ng_optim=optim.Adam(G.parameters(),lr=0.0002,betas=(0.5, 0.999))\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(d_optim, 'min',factor=0.5,patience=2)\nscheduler2 = optim.lr_scheduler.ReduceLROnPlateau(g_optim, 'min',factor=0.5,patience=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gaussian_noise(inputs, mean=0, stddev=0.01):\n    input = inputs.cpu()\n    input_array = input.data.numpy()\n\n    noise = np.random.normal(loc=mean, scale=stddev, size=np.shape(input_array))\n\n    out = np.add(input_array, noise)\n\n    output_tensor = torch.from_numpy(out)\n    \n    out = output_tensor.cuda()\n    out = out.float()\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_samples(epoch, samples):\n    fig, axes = plt.subplots(figsize=(16,4), nrows=2, ncols=8, sharey=True, sharex=True)\n    for ax, img in zip(axes.flatten(), samples[epoch]):\n        img = img.detach().cpu().numpy()\n        img = np.transpose(img, (1, 2, 0))\n        img = ((img + 1)*255 / (2)).astype(np.uint8)\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n        im = ax.imshow(img.reshape((32,32,3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=30\n#move models \ncriterionF=nn.MSELoss()\nif train_on_gpu and USE_GPU:\n    D.cuda()\n    G.cuda()\n#images generates\ngenerated=[]\nlosses=[]\nsample_size=10000\nz_size=100\nfixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\nfixed_z = torch.from_numpy(fixed_z).float()\nfor e in range(epochs):\n   \n    for ii ,(images,dog_trainloaders) in enumerate(dog_trainloader,0):\n        images=scalling(images)\n        #move images to gpu\n        \n        if train_on_gpu and USE_GPU:\n            images=images.cuda()\n       \n        \n       \n        #clear_gradients\n        d_optim.zero_grad()\n        #feed images to discriminator\n        d_out=D(images)\n        #compute discriminator loss on real images\n        r_loss=real_loss(d_out,smooth=True)\n\n        #generate fake images\n        fixed_z = np.random.uniform(-1, 1, size=(images.size(0), z_size))\n        fixed_z = torch.from_numpy(fixed_z).float()\n        if train_on_gpu and USE_GPU:\n            fixed_z=fixed_z.cuda()\n        G_out=G(fixed_z)\n        #compute discriminator loss on fake images\n        df_out1=D(G_out)\n        f_loss=fake_loss(df_out1)\n        \n        #total dicriminator loss\n        D_loss=r_loss+f_loss \n        D_loss.backward()\n        d_losses=D_loss.item()\n        \n        d_optim.step()\n        \n        z = np.random.uniform(-1, 1, size=(images.size(0), z_size))\n        z = torch.from_numpy(z).float()\n        if train_on_gpu and USE_GPU:\n            z=z.cuda()\n        #generator training\n        g_optim.zero_grad()\n        #generate fake images\n        FakeImages=G(z)\n        #feed to discriminator\n        ####### feature matching ########\n        feature_real,_ = D(images.detach(),feature=True)\n        feature_fake,output = D( FakeImages,feature=True)\n        feature_real = torch.mean(feature_real,0)\n        feature_fake = torch.mean(feature_fake,0)\n        G_loss = criterionF(feature_fake, feature_real.detach())\n        G_loss.backward()\n        g_optim.step()\n        g_losses=G_loss.item()\n        #scheduler.step(D_loss.item())\n        #scheduler2.step(G_loss.item())\n        \n    losses.append((d_losses,g_losses))   \n    print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n                        e+1, epochs, d_losses, g_losses))\n    \n    G.eval() # for generating samples    \n    samples_z = G(fixed_z)\n    generated.append(samples_z)\n   \n    G.train()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" with open('train_samples.pkl', 'wb') as f:\n        pkl.dump(generated, f)\n# Load samples from generator, taken while training\nwith open('train_samples.pkl', 'rb') as f:\n    samples = pkl.load(f)  \n_ = view_samples(-1, samples)    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}