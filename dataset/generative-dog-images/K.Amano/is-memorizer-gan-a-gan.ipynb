{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Memorizer_GAN\nI tried to implement Memoraizer_GAN. I feel resistance to this method being GAN.　Rather than generating a \"new\" image, it just seems to be reproducing an image embedded in the network.　This scheme is not Generative \"Adversarial\" Networks. I think it should be classified separately from GAN."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nfrom tqdm import tqdm, tqdm_notebook\nimport glob\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport xml.etree.ElementTree as ET\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, Reshape, Flatten\nfrom keras.layers import concatenate, UpSampling2D\nfrom keras.preprocessing.image import image, load_img, ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import SGD, Adam\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Constants"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"img_size = 64\nchannels = 3\nimg_shape = (img_size, img_size, channels)\n\ndim = img_size * img_size * channels     #","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR = os.getcwd()\nDIRimg = \"../input/all-dogs/all-dogs\"\nDIRanno = \"../input/annotation/Annotation\"\nDIRout = \"../output_images\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image data loading and clipping Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadImage(fPath, resize = True):\n    img = cv2.imread(fPath)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        # BGR to RGB\n    ok = True\n    if resize:\n        xmin,ymin,xmax,ymax = clipImage(fPath)        # clip to square\n        if xmin >= 0:                                 # exist Annotation\n            img = img[ymin:ymax, xmin:xmax, :]        # [h,w,c]\n            # Interpolation method\n            if xmax - xmin > img_size:\n                interpolation = cv2.INTER_AREA            # shrink\n            else:\n                interpolation = cv2.INTER_CUBIC           # expantion\n            img = cv2.resize(img, (img_size, img_size),\n                        interpolation = interpolation)    # resize\n        else:\n            ok = False\n    return ok, img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clipImage(fPath):\n    imgName = os.path.basename(fPath)[:-4].split(\"_\")\n    breed = imgName[0]\n    dog = imgName[1]\n    path = glob.glob(os.path.join(DIRanno, breed + \"*\", breed +\"_\" + dog))\n    if len(path) > 0:\n        tree = ET.parse(path[0])\n        root = tree.getroot()    # get <annotation>\n        size = root.find('size')\n        width = int(size.find('width').text)\n        height = int(size.find('height').text)\n#        objects = root.findall('object')      # ToDo: correspond multi objects\n#        for object in objects:\n        object = root.find('object')\n        bndbox = object.find('bndbox') \n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n\n        xmin = max(0, xmin - 4)        # 4 : margin\n        xmax = min(width, xmax + 4)\n        ymin = max(0, ymin - 4)\n        ymax = min(height, ymax + 4)\n\n        w = max(xmax - xmin, ymax - ymin, img_size)   # ideal w\n        \n        if w > min(width, height):\n            xmin = -1; ymin = -1; xmax = -1; ymax = -1;\n        else:\n            w = min(w, width, height)                     # available w\n    \n            if w > xmax - xmin:\n                xmin = min(max(0, xmin - int((w - (xmax - xmin))/2)), width - w)\n                xmax = xmin + w\n            if w > ymax - ymin:\n                ymin = min(max(0, ymin - int((w - (ymax - ymin))/2)), height - w)\n                ymax = ymin + w\n\n    else:\n        xmin = -1; ymin = -1; xmax = -1; ymax = -1;       # nothing Annotation\n        \n    return xmin,ymin,xmax,ymax","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert Images to Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_fNames = os.listdir(DIRimg)\n\n# train data\nx_train = np.zeros((len(all_fNames),img_size,img_size,3))\nj = 0\nfor i in tqdm(range(len(all_fNames))):\n    path = os.path.join(DIRimg, all_fNames[i])\n#    x_train[i] = loadImage(path)\n    ok, img = loadImage(path)\n    if ok:\n        x_train[j] = img\n        j += 1\n\nprint(j)\nx_train = x_train[:j] / 255.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Decoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"input = Input((10000,))\nx = Dense(2048, activation='elu')(input)\nx = Reshape((8,8,32))(x)\nx = Conv2D(128, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(64, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(32, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\n# COMPILE\ndecoder = Model(input, decoded)\ndecoder.compile(optimizer=Adam(lr=0.005), loss='binary_crossentropy')\n\n# DISPLAY ARCHITECTURE\ndecoder.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Decoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRAINING DATA\nids = np.random.randint(0,len(x_train),10000)\n#train_y = x_train[ids, :,:,:].reshape((-1,dim))\ntrain_y = x_train[ids, :,:,:]\ntrain_X = np.eye(10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRAIN NETWORK\nlr = 0.01\nbatch = 256; ep = 30; it = 10\nd_loss = []\n\nfor k in range(10):\n    annealer = LearningRateScheduler(lambda x: lr)\n    h = decoder.fit(train_X, train_y, epochs = ep, batch_size = batch,\n                    callbacks=[annealer], verbose=0)\n    d_loss.extend(h.history['loss'])\n    print('Epoch',(k+1)*ep,'/',ep*it,'  loss =',h.history['loss'][-1], '/ lr =',lr)\n    if h.history['loss'][-1] / h.history['loss'][0] > 0.99: lr = max(lr/2., 0.0005)\n\nplt.plot(d_loss)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Delete Training Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"del x_train, train_y, train_X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate Dog Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getDog(ids, mix_rate):\n    imgs = []\n    for id in ids:\n        xx = np.zeros((10000))\n        xx[id] = mix_rate\n        xx[np.random.randint(10000)] = 1.0 - mix_rate\n        imgs.append(decoder.predict(xx.reshape((-1,10000)))[0].reshape(img_shape))\n    return imgs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sumple_images(imgs, rows=3, cols=5, figsize=(12,10)):\n    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=figsize)\n    for indx, axis in enumerate(axes.flatten()):\n        img = image.array_to_img(imgs[indx])    # ndarray → PIL\n        imgplot = axis.imshow(img)\n#        axis.set_title(all_fNames[sample_ids[indx]])\n        axis.set_axis_off()\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = np.random.randint(0,10000, 35)\ng_imgs = getDog(ids, 0.99)\nsumple_images(g_imgs, rows=5, cols=7, figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"if os.path.exists(DIRout):\n    shutil.rmtree(DIRout)\nif not os.path.exists(DIRout):\n    os.mkdir(DIRout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 64\ne = batch\nid = list(range(10000))\n\nfor s in tqdm(range(0, 10000, batch)):\n    g_imgs = getDog(id[s:e], 0.99)\n    for j in range(batch):\n        img = image.array_to_img(g_imgs[j])    # ndarray → PIL\n        img.save(os.path.join(DIRout, 'image_' + str(s+j+1).zfill(5) + '.png'))\n        if s+j+1 == 10000:\n            break\n    e += batch\n    \nprint(len(os.listdir(DIRout)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.make_archive('images', 'zip', DIRout)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}