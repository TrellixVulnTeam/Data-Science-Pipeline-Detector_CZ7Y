{"cells":[{"metadata":{},"cell_type":"markdown","source":"Started on 2 July 2019\n\n**References:**\n1. https://www.kaggle.com/whizzkid/crop-images-using-bounding-box\n2. https://www.kaggle.com/guillaumedesforges/loading-the-cropped-dogs-seamlessly-with-pytorch\n3. https://www.kaggle.com/guillaumedesforges/usable-complete-data-loading-utility\n4. https://towardsdatascience.com/processing-xml-in-python-elementtree-c8992941efd2"},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The files are:\n* all-dogs.zip - All dog images contained in the [Stanford Dogs Dataset][1]\n* Annotations.zip - Class labels, bounding boxes\n\n#### The dataset is from the [Stanford Dogs Dataset][1]. It is useful to refer to the [webpage][1]. \n[1]: http://vision.stanford.edu/aditya86/ImageNetDogs/"},{"metadata":{},"cell_type":"markdown","source":"#### What I learned from scanning the [Stanford Dogs Dataset][1]:\n* There are 20,580 images. These are in the 'all-dogs' directory. The filename of the .jpg is the identifier.\n* There are 120 sub-folders in the 'Annotation' directory. Each sub-folder represents a dog breed, and there are ~150 to 200 annotation files in each folder and they correspond to the images in the 'all-dogs' directory via the same identifier filename.\n* The annotation files contain the dog breed labels and bounding boxes.\n* There are images with people in them. The bounding boxes in the respective annotation files define where the dogs are in the images.\n* There are also images with several dogs. For these, there will be more than one bounding box in the corresponding annotation file.\n[1]: http://vision.stanford.edu/aditya86/ImageNetDogs/"},{"metadata":{},"cell_type":"markdown","source":"# Load & crop images to bounding boxes"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import glob\nimage = glob.glob('../input/all-dogs/all-dogs/*')\nbreed = glob.glob('../input/annotation/Annotation/*')\nannot = glob.glob('../input/annotation/Annotation/*/*')\nprint(len(image), len(breed), len(annot))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Note:__ The number of images in the 'all-dogs' folder is 20579, which is one less than that in the 'Annotation' folder. Hmm.."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look at the content of an annotation file. I choose one with two dogs in the image, and\n# there are two bounding boxes specified. \n!cat ../input/annotation/Annotation/n02097658-silky_terrier/n02097658_98","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Function to extract bounding box values from annotation files.\nPython has a built-in library called ElementTree that has functions to read and manipulate XML files."},{"metadata":{"trusted":true},"cell_type":"code","source":"import xml.etree.ElementTree as ET","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bbox(annot):\n    \"\"\"\n    This extracts and returns values of bounding boxes\n    \"\"\"\n    xml = annot\n    tree = ET.parse(xml)\n    root = tree.getroot()\n    objects = root.findall('object')\n    bbox = []\n    for o in objects:\n        bndbox = o.find('bndbox')\n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n        bbox.append((xmin,ymin,xmax,ymax))\n    return bbox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test\nbbox = get_bbox('../input/annotation/Annotation/n02097658-silky_terrier/n02097658_98')\nprint(bbox[0], bbox[1], len(bbox))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image(annot):\n    \"\"\"\n    Retrieve the corresponding image given annotation file\n    \"\"\"\n    img_path = '../input/all-dogs/all-dogs/'\n    file = annot.split('/')\n    img_filename = img_path+file[-1]+'.jpg'\n    return img_filename","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's see some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i in range(12):\n    plt.subplot(3,4,i+1)\n    plt.axis(\"off\")\n    dog = get_image(annot[i])\n    im = Image.open(dog)\n    im = im.resize((64,64), Image.ANTIALIAS)\n    plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's compare the above when cropped to bounding boxes"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i in range(12):\n    bbox = get_bbox(annot[i])\n    dog = get_image(annot[i])\n    im = Image.open(dog)\n    for j in range(len(bbox)):\n        im = im.crop(bbox[j])\n        im = im.resize((64,64), Image.ANTIALIAS)\n    plt.subplot(3,4,i+1)\n    plt.axis(\"off\")\n    plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check the image with two dogs"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = '../input/annotation/Annotation/n02097658-silky_terrier/n02097658_98'\nbox = get_bbox(test)\ndog = get_image(test)\nim = Image.open(dog)\nplt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nfor j in range(len(box)):\n    im = Image.open(dog)\n    im = im.crop(box[j])\n    im = im.resize((64,64), Image.ANTIALIAS)\n    plt.subplot(1,2, j+1)\n    plt.axis(\"off\")\n    plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}