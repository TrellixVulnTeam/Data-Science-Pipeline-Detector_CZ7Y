{"cells":[{"metadata":{},"cell_type":"markdown","source":"<br>\n# Edited Tensorflow DCGAN"},{"metadata":{},"cell_type":"markdown","source":"### Load packages"},{"metadata":{"_uuid":"267d5504009eca2b809a2691131366baebe98436","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport time\nimport tensorflow as tf\nimport numpy as np\nfrom glob import glob\nimport datetime\nimport random\nimport PIL\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\n%matplotlib inline\nimport urllib\nimport tarfile\nimport xml.etree.ElementTree as ET\nfrom imageio import imread, imsave, mimsave\nimport shutil\nimport cv2\nimport glob\nfrom imageio import imread, imsave, mimsave","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load and Crop Data\n\nCheck this kernels:\n\n- [Crop images using bounding box](https://www.kaggle.com/whizzkid/crop-images-using-bounding-box)\n- [Dog Memorizer GAN](https://www.kaggle.com/cdeotte/dog-memorizer-gan)"},{"metadata":{"trusted":true},"cell_type":"code","source":"root_images = \"../input/generative-dog-images/all-dogs/all-dogs/\"\nroot_annots = \"../input/generative-dog-images/annotation/Annotation/\"\nINPUT_DATA_DIR=\"../input/generative-dog-images/all-dogs/all-dogs/\"\nIMG_DIR = \"images\"\nComputeLB = False\nDogsOnly = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Processing**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os\nimport xml.etree.ElementTree as ET \nimport matplotlib.pyplot as plt, zipfile \nfrom PIL import Image \nfrom glob import glob\n\nROOT = '../input/generative-dog-images/'\nif not ComputeLB: ROOT = '../input/'\nIMAGES = os.listdir(ROOT + 'all-dogs/all-dogs/')\nbreeds = os.listdir(ROOT + 'annotation/Annotation/') \n\nidxIn = 0; namesIn = []\nimagesIn = np.zeros((25000,64,64,3))\n\n# CROP WITH BOUNDING BOXES TO GET DOGS ONLY\n# https://www.kaggle.com/paulorzp/show-annotations-and-breeds\nif DogsOnly:\n    for breed in breeds:\n        for dog in os.listdir(ROOT+'annotation/Annotation/'+breed):\n            try: img = Image.open(ROOT+'all-dogs/all-dogs/'+dog+'.jpg') \n            except: continue           \n            tree = ET.parse(ROOT+'annotation/Annotation/'+breed+'/'+dog)\n            root = tree.getroot()\n            objects = root.findall('object')\n            for o in objects:\n                bndbox = o.find('bndbox') \n                xmin = int(bndbox.find('xmin').text)\n                ymin = int(bndbox.find('ymin').text)\n                xmax = int(bndbox.find('xmax').text)\n                ymax = int(bndbox.find('ymax').text)\n                w = np.min((xmax - xmin, ymax - ymin))\n                img2 = img.crop((xmin, ymin, xmin+w, ymin+w))\n                img2 = img2.resize((64,64), Image.ANTIALIAS)\n                imagesIn[idxIn,:,:,:] = np.asarray(img2)\n                #if idxIn%1000==0: print(idxIn)\n                namesIn.append(breed)\n                idxIn += 1\n    idx = np.arange(idxIn)\n    np.random.shuffle(idx)\n    imagesIn = imagesIn[idx,:,:,:]\n    namesIn = np.array(namesIn)[idx]\n    \n# RANDOMLY CROP FULL IMAGES\nelse:\n    x = np.random.choice(np.arange(20579),10000)\n    for k in range(len(x)):\n        img = Image.open(ROOT + 'all-dogs/all-dogs/' + IMAGES[x[k]])\n        w = img.size[0]\n        h = img.size[1]\n        sz = np.min((w,h))\n        a=0; b=0\n        if w<h: b = (h-sz)//2\n        else: a = (w-sz)//2\n        img = img.crop((0+a, 0+b, sz+a, sz+b))  \n        img = img.resize((64,64), Image.ANTIALIAS)   \n        imagesIn[idxIn,:,:,:] = np.asarray(img)\n        namesIn.append(IMAGES[x[k]])\n        if idxIn%1000==0: print(idxIn)\n        idxIn += 1\n    \n# DISPLAY CROPPED IMAGES\nx = np.random.randint(0,idxIn,25)\nfor k in range(5):\n    plt.figure(figsize=(15,3))\n    for j in range(5):\n        plt.subplot(1,5,j+1)\n        img = Image.fromarray( imagesIn[x[k*5+j],:,:,:].astype('uint8') )\n        plt.axis('off')\n        if not DogsOnly: plt.title(namesIn[x[k*5+j]],fontsize=11)\n        else: plt.title(namesIn[x[k*5+j]].split('-')[1],fontsize=11)\n        plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesIn.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n# Generator"},{"metadata":{},"cell_type":"markdown","source":"The **Generator** is:\n\n```100x1 → 1024x4x4 → 512x8x8 → 256x16x16 → 128x32x32 → 64x64x3```\n"},{"metadata":{"_uuid":"fc376df46433261bfeb643a95793718a9d969ed1","trusted":true},"cell_type":"code","source":"def generator(z, output_channel_dim, training):\n    with tf.variable_scope(\"generator\", reuse= not training):\n        \n        # 4x4x1024\n        fully_connected = tf.layers.dense(z, 4*4*1024)\n        fully_connected = tf.reshape(fully_connected, (-1, 4, 4, 1024))\n        fully_connected = tf.nn.leaky_relu(fully_connected)\n\n        # 4x4x1024 -> 8x8x512\n        trans_conv1 = tf.layers.conv2d_transpose(inputs=fully_connected,\n                                                 filters=512,\n                                                 kernel_size=[5,5],\n                                                 strides=[2,2],\n                                                 padding=\"SAME\",\n                                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                                 name=\"trans_conv1\")\n        batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1,\n                                                          training=training,\n                                                          epsilon=EPSILON,\n                                                          name=\"batch_trans_conv1\")\n        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1,\n                                           name=\"trans_conv1_out\")\n        \n        # 8x8x512 -> 16x16x256\n        trans_conv2 = tf.layers.conv2d_transpose(inputs=trans_conv1_out,\n                                                 filters=256,\n                                                 kernel_size=[5,5],\n                                                 strides=[2,2],\n                                                 padding=\"SAME\",\n                                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                                 name=\"trans_conv2\")\n        batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2,\n                                                          training=training,\n                                                          epsilon=EPSILON,\n                                                          name=\"batch_trans_conv2\")\n        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2,\n                                           name=\"trans_conv2_out\")\n        \n        # 16x16x256 -> 32x32x128\n        trans_conv3 = tf.layers.conv2d_transpose(inputs=trans_conv2_out,\n                                                 filters=128,\n                                                 kernel_size=[5,5],\n                                                 strides=[2,2],\n                                                 padding=\"SAME\",\n                                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                                 name=\"trans_conv3\")\n        batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3,\n                                                          training=training,\n                                                          epsilon=EPSILON,\n                                                          name=\"batch_trans_conv3\")\n        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3,\n                                           name=\"trans_conv3_out\")\n        \n\n        # 32x32x128 -> 64x64x64\n        trans_conv4 = tf.layers.conv2d_transpose(inputs=trans_conv3_out,\n                                                 filters=64,\n                                                 kernel_size=[5,5],\n                                                 strides=[2,2],\n                                                 padding=\"SAME\",\n                                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                                 name=\"trans_conv4\")\n        batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4,\n                                                          training=training,\n                                                          epsilon=EPSILON,\n                                                          name=\"batch_trans_conv4\")\n        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4,\n                                           name=\"trans_conv4_out\")\n        \n        # 64x64x64 -> 64x64x3\n        logits = tf.layers.conv2d_transpose(inputs=trans_conv4_out,\n                                            filters=3,\n                                            kernel_size=[5,5],\n                                            strides=[1,1],\n                                            padding=\"SAME\",\n                                            #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                            name=\"logits\")\n        out = tf.tanh(logits, name=\"out\")\n        return out","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Discriminator"},{"metadata":{"_uuid":"ba53a4bb09dbcd57d3e3392f74ccd054ecf23ecb","trusted":true},"cell_type":"code","source":"def discriminator(x, reuse):\n    with tf.variable_scope(\"discriminator\", reuse=reuse): \n        \n        # 64x64x3 -> 64x64x32\n        conv1 = tf.layers.conv2d(inputs=x,\n                                 filters=32,\n                                 kernel_size=[5,5],\n                                 strides=[1,1],\n                                 padding=\"SAME\",\n                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                 name='conv1')\n        batch_norm1 = tf.layers.batch_normalization(conv1,\n                                                    training=True,\n                                                    epsilon=EPSILON,\n                                                    name='batch_norm1')\n        conv1_out = tf.nn.leaky_relu(batch_norm1,\n                                     name=\"conv1_out\")\n        \n        # 64x64x32 -> 32x32x64\n        conv2 = tf.layers.conv2d(inputs=conv1_out,\n                                 filters=64,\n                                 kernel_size=[5, 5],\n                                 strides=[2, 2],\n                                 padding=\"SAME\",\n                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                 name='conv2')\n        batch_norm2 = tf.layers.batch_normalization(conv2,\n                                                    training=True,\n                                                    epsilon=EPSILON,\n                                                    name='batch_norm2')\n        conv2_out = tf.nn.leaky_relu(batch_norm2,\n                                     name=\"conv2_out\")\n        \n        # 32x32x64 -> 16x16x128\n        conv3 = tf.layers.conv2d(inputs=conv2_out,\n                                 filters=128,\n                                 kernel_size=[5, 5],\n                                 strides=[2, 2],\n                                 padding=\"SAME\",\n                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                 name='conv3')\n        batch_norm3 = tf.layers.batch_normalization(conv3,\n                                                    training=True,\n                                                    epsilon=EPSILON,\n                                                    name='batch_norm3')\n        conv3_out = tf.nn.leaky_relu(batch_norm3,\n                                     name=\"conv3_out\")\n        \n        # 16x16x128 -> 8x8x256\n        conv4 = tf.layers.conv2d(inputs=conv3_out,\n                                 filters=256,\n                                 kernel_size=[5, 5],\n                                 strides=[2, 2],\n                                 padding=\"SAME\",\n                                 #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                 name='conv4')\n        batch_norm4 = tf.layers.batch_normalization(conv4,\n                                                    training=True,\n                                                    epsilon=EPSILON,\n                                                    name='batch_norm4')\n        conv4_out = tf.nn.leaky_relu(batch_norm4,\n                                     name=\"conv4_out\")\n        \n        # 8x8x256 -> 4x4x512\n        \n        conv5 = tf.layers.conv2d(inputs=conv4_out,\n                                filters=512,\n                                kernel_size=[5, 5],\n                                strides=[2, 2],\n                                padding=\"SAME\",\n                                #kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n                                name='conv5')\n        batch_norm5 = tf.layers.batch_normalization(conv5,\n                                                    training=True,\n                                                    epsilon=EPSILON,\n                                                    name='batch_norm5')\n        conv5_out = tf.nn.leaky_relu(batch_norm5,\n                                     name=\"conv5_out\")\n\n        flatten = tf.reshape(conv5_out, (-1, 4*4*512))\n        logits = tf.layers.dense(inputs=flatten,\n                                 units=1,\n                                 activation=None)\n        out = tf.sigmoid(logits)\n        return out, logits","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loss and Optimizer"},{"metadata":{"_uuid":"8ef5bbb8e4d157577f1b15600aa64cb40289a754","trusted":true},"cell_type":"code","source":"def model_loss(input_real, input_z, output_channel_dim):\n    g_model = generator(input_z, output_channel_dim, True)\n\n    noisy_input_real = input_real + tf.random_normal(shape=tf.shape(input_real),\n                                                     mean=0.0,\n                                                     stddev=random.uniform(0.0, 0.1),\n                                                     dtype=tf.float32)\n    \n    d_model_real, d_logits_real = discriminator(noisy_input_real, reuse=False)\n    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n    \n    '''\n    g_loss = -tf.reduce_mean(d_model_fake)\n    disc_cost = tf.reduce_mean(d_model_fake) - tf.reduce_mean(d_model_real)\n    \n    alpha = tf.random_uniform(\n                    shape=[BATCH_SIZE,1], \n                    minval=0.,\n                    maxval=1.\n                )\n    differences = g_model - noisy_input_real\n    interpolates = noisy_input_real + (alpha*differences)\n    gradients = tf.gradients(discriminator(interpolates,reuse=True), [interpolates])[0]\n    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n    gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n    d_loss = disc_cost+ LAMBDA*gradient_penalty\n    '''\n    \n    # Train on soft t\n \n    \n    \n    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n                                                                         labels=tf.ones_like(d_model_real)*random.uniform(0.9, 1.0)))\n    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n                                                                         labels=tf.zeros_like(d_model_fake)*random.uniform(0.0, 0.1)))\n    d_loss = tf.reduce_mean(0.5 * (d_loss_real + d_loss_fake))\n    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n                                                                    labels=tf.ones_like(d_model_fake)))\n    return d_loss, g_loss","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01820b197de1b6d0ca39592043308557d941937a","trusted":true},"cell_type":"code","source":"def model_optimizers(d_loss, g_loss):\n    t_vars = tf.trainable_variables()\n    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n    \n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n    gen_updates = [op for op in update_ops if op.name.startswith('generator')]\n    \n    with tf.control_dependencies(gen_updates):\n        d_train_opt = tf.train.AdamOptimizer(learning_rate=LR_D, beta1=BETA1_D).minimize(d_loss, var_list=d_vars)\n        g_train_opt = tf.train.AdamOptimizer(learning_rate=LR_G, beta1=BETA1_G).minimize(g_loss, var_list=g_vars)  \n    return d_train_opt, g_train_opt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e8d59264d04344fd0c284c1d41193bd111d4c3f"},"cell_type":"code","source":"def model_inputs(real_dim, z_dim):\n    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real')\n    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n    learning_rate_G = tf.placeholder(tf.float32, name=\"lr_g\")\n    learning_rate_D = tf.placeholder(tf.float32, name=\"lr_d\")\n    return inputs_real, inputs_z, learning_rate_G, learning_rate_D","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_samples(sample_images, name, epoch):\n    figure, axes = plt.subplots(1, len(sample_images), figsize = (IMAGE_SIZE, IMAGE_SIZE))\n    for index, axis in enumerate(axes):\n        axis.axis('off')\n        image_array = sample_images[index].astype('uint8') \n        axis.imshow(image_array)\n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_samples(sample_images, name, epoch):\n    # save images\n    for index,img in enumerate(sample_images):\n        image = Image.fromarray(img.astype('uint8') )\n        image.save(name+\"_\"+str(epoch)+\"_\"+str(index)+\".png\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43677a2f90b65e39110c1f547a928bb1b5f9d892"},"cell_type":"code","source":"def test(sess, input_z, out_channel_dim, epoch):\n    example_z = np.random.uniform(-1, 1, size=[SAMPLES_TO_SHOW, input_z.get_shape().as_list()[-1]])\n    samples = sess.run(generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z})\n    sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples]\n    show_samples(sample_images, IMG_DIR + \"samples\", epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate (sess, input_z, out_channel_dim):\n    print (\">> Generating 10k images ...\")\n    for i in tqdm(range(100)):\n        example_z = np.random.uniform(-1, 1, size=[100, 100]).astype(np.float32)\n        imgs = sess.run(generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z})\n        imgs = [((img + 1.0) * 127.5).astype(np.uint8) for img in imgs]\n        for j in range(len(imgs)):\n            imsave(os.path.join(IMG_DIR, f'dog_{i}_{j}.png'), imgs[j])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ed8f1c378f936ac81ae89b35d5b6914cd6efbbb","trusted":true},"cell_type":"code","source":"def summarize_epoch(epoch, duration, sess, d_losses, g_losses, input_z, data_shape):\n    minibatch_size = int(data_shape[0]//BATCH_SIZE)\n    print(\"Epoch {}/{}\".format(epoch, EPOCHS),\n          \"\\nDuration: {:.5f}\".format(duration),\n          \"\\nD Loss: {:.5f}\".format(np.mean(d_losses[-minibatch_size:])),\n          \"\\nG Loss: {:.5f}\".format(np.mean(g_losses[-minibatch_size:])))\n    \n    fig, ax = plt.subplots()\n    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n    plt.plot(g_losses, label='Generator', alpha=0.6)\n    plt.title(\"Losses\")\n    plt.legend()\n    #plt.savefig(OUTPUT_DIR + \"losses_\" + str(epoch) + \".png\")\n    plt.show()\n    plt.close()\n    test(sess, input_z, data_shape[3], epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5977b8035723edd4a013406cb5376848d62dcc0a"},"cell_type":"code","source":"def get_batches(data):\n    batches = []\n    for i in range(int(data.shape[0]//BATCH_SIZE)):\n        batch = data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n        augmented_images = []\n        for img in batch:\n            image = Image.fromarray(img.astype('uint8'))\n            if random.choice([True, False]):\n                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n            augmented_images.append(np.asarray(image))  \n        batch = np.asarray(augmented_images)\n        normalized_batch = (batch / 127.5) - 1.0\n        batches.append(normalized_batch)\n    return batches","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir images\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"578f639e8a70bed5c797f0f4655d318f1a07f6fc"},"cell_type":"code","source":"def train(get_batches, data_shape, LR_G = 2e-4, LR_D = 0.0005):\n    input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], NOISE_SIZE)\n    d_loss, g_loss = model_loss(input_images, input_z, data_shape[3])\n    d_opt, g_opt = model_optimizers(d_loss, g_loss)\n    generator_epoch_loss = 0\n    train_d_losses = []\n    train_g_losses = []\n    generator_epoch_loss = 999\n    \n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        epoch = 0\n        iteration = 0\n        d_losses = []\n        g_losses = []\n        \n        for epoch in tqdm(range(EPOCHS)):        \n            epoch += 1\n            start_time = time.time()\n                \n            for batch_images in get_batches:\n                iteration += 1\n                batch_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, NOISE_SIZE))\n                _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: LR_D})\n                _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: LR_G})\n                d_losses.append(d_loss.eval({input_z: batch_z, input_images: batch_images}))\n                g_losses.append(g_loss.eval({input_z: batch_z}))\n\n            summarize_epoch(epoch, time.time()-start_time, sess, d_losses, g_losses, input_z, data_shape)\n            minibatch_size = int(data_shape[0]//BATCH_SIZE)\n            generator_epoch_loss = np.mean(g_losses[-minibatch_size:])\n            train_d_losses.append(np.mean(d_losses[-minibatch_size:]))\n            train_g_losses.append(np.mean(g_losses[-minibatch_size:]))\n            \n            if epoch == EPOCHS:\n                generate (sess, input_z, out_channel_dim=3)\n            \n    fig, ax = plt.subplots()\n    plt.plot(train_d_losses, label='Discriminator', alpha=0.5)\n    plt.plot(train_g_losses, label='Generator', alpha=0.5)\n    plt.title(\"Training Losses\")\n    plt.legend()\n    plt.savefig('train_losses.png')\n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hyperparameters**"},{"metadata":{"trusted":true,"_uuid":"86335745ed2e6b406839c5d85a1085aab276e73a"},"cell_type":"code","source":"IMAGE_SIZE = 64\nNOISE_SIZE = 100\nLR_D = 0.0008\nLR_G = 0.0004\nBATCH_SIZE = 32\nEPOCHS = 500\nBETA1_G = 0.5\nBETA1_D = 0.5\nWEIGHT_INIT_STDDEV = 0.02\nEPSILON = 0.00005\nSAMPLES_TO_SHOW = 5 # each epoch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training loop**"},{"metadata":{"_uuid":"1ee6349afccb4d2f29f36d6605dd2f156350821a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"start = time.time()\n\nprint(\">> Start training...\")\nwith tf.Graph().as_default():\n    train(get_batches(imagesIn), imagesIn.shape)\n    \nprint(\">> train time = \",time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n# Generated Dogs"},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.make_archive('images', 'zip', 'images')\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.rmtree('images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How can you improve this basic code?\n\n1. Data Augmentation\n2. Improve the Generator and Discriminator NN\n4. Use ```DogsOnly``` pictures. (but carefully)\n5. Use [All you need is GAN Hacks](https://www.kaggle.com/c/generative-dog-images/discussion/98595#latest-570614)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}