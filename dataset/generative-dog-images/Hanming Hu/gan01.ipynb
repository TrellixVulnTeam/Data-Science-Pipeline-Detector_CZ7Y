{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, array_to_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,LeakyReLU\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D,Reshape,Conv2DTranspose\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport shutil\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport warnings\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom keras.utils.vis_utils import plot_model\nfrom numpy import expand_dims\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy import vstack\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.datasets.mnist import load_data\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom matplotlib import pyplot\nimport zipfile\n\nwith zipfile.ZipFile(\"../input/generative-dog-images/all-dogs.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"/kaggle/temp/\")\n    \nwith zipfile.ZipFile(\"../input/generative-dog-images/Annotation.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"/kaggle/temp/\")","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:26.870145Z","iopub.execute_input":"2021-07-21T04:39:26.870598Z","iopub.status.idle":"2021-07-21T04:39:54.243656Z","shell.execute_reply.started":"2021-07-21T04:39:26.870494Z","shell.execute_reply":"2021-07-21T04:39:54.242759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = '/kaggle/temp/'\nepochs = 50\nbatch_size = 128\nimg_size = 64\nnoise_dim = 100\nWEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:54.245144Z","iopub.execute_input":"2021-07-21T04:39:54.245464Z","iopub.status.idle":"2021-07-21T04:39:54.251159Z","shell.execute_reply.started":"2021-07-21T04:39:54.245429Z","shell.execute_reply":"2021-07-21T04:39:54.250458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=ROOT, target_size=(img_size,img_size), classes = ['all-dogs'],batch_size = 16)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:54.252862Z","iopub.execute_input":"2021-07-21T04:39:54.253527Z","iopub.status.idle":"2021-07-21T04:39:54.723395Z","shell.execute_reply.started":"2021-07-21T04:39:54.253486Z","shell.execute_reply":"2021-07-21T04:39:54.721886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_list = []\nbatch_index = 0\n\nfrom tqdm import tqdm\nfor batch_index in tqdm(range(50)):\n    data = train.next()\n    data_list.append(data[0])\n\nimgs = np.asarray(data_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:54.724847Z","iopub.execute_input":"2021-07-21T04:39:54.725101Z","iopub.status.idle":"2021-07-21T04:39:57.202805Z","shell.execute_reply.started":"2021-07-21T04:39:54.725075Z","shell.execute_reply":"2021-07-21T04:39:57.201896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs = imgs.reshape(800,64,64,3)\nprint(imgs.shape)\nimgs = (imgs-127.5)/127.5","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:57.204275Z","iopub.execute_input":"2021-07-21T04:39:57.204782Z","iopub.status.idle":"2021-07-21T04:39:57.233553Z","shell.execute_reply.started":"2021-07-21T04:39:57.204727Z","shell.execute_reply":"2021-07-21T04:39:57.232245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_real(n_samples,img_array = imgs):\n  indexes = randint(0,img_array.shape[0],n_samples)\n  reals = img_array[indexes]\n  return reals","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:57.234924Z","iopub.execute_input":"2021-07-21T04:39:57.235269Z","iopub.status.idle":"2021-07-21T04:39:57.240361Z","shell.execute_reply.started":"2021-07-21T04:39:57.235231Z","shell.execute_reply":"2021-07-21T04:39:57.23932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build generator and return the model\ndef generator():\n  model = Sequential()\n  model.add(Dense(int(img_size/8)*int(img_size/8)*512, use_bias=False, input_shape=(100,),kernel_initializer=WEIGHT_INIT))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n\n  model.add(Reshape((int(img_size/8), int(img_size/8), 512)))\n  \n\n  model.add(Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False,kernel_initializer=WEIGHT_INIT))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n  \n\n  model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False,kernel_initializer=WEIGHT_INIT))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n\n  model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False,kernel_initializer=WEIGHT_INIT ))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n  model.add(Dense(3,activation = 'tanh',use_bias = False,kernel_initializer=WEIGHT_INIT))\n  opt = Adam(lr=1e-4)\n  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:59:34.80656Z","iopub.execute_input":"2021-07-21T04:59:34.806975Z","iopub.status.idle":"2021-07-21T04:59:34.817914Z","shell.execute_reply.started":"2021-07-21T04:59:34.806941Z","shell.execute_reply":"2021-07-21T04:59:34.816995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator():\n  model = tf.keras.Sequential()\n  model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same',\n                                    input_shape=[img_size, img_size, 3],kernel_initializer=WEIGHT_INIT))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n\n  model.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same',kernel_initializer=WEIGHT_INIT))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3)) \n\n  model.add(Conv2D(256, (4, 4), strides=(2, 2), padding='same',kernel_initializer=WEIGHT_INIT))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n\n  model.add(Flatten())\n  model.add(Dense(1))\n  opt = Adam(lr=1e-4)\n  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:59:37.965592Z","iopub.execute_input":"2021-07-21T04:59:37.965983Z","iopub.status.idle":"2021-07-21T04:59:37.975632Z","shell.execute_reply.started":"2021-07-21T04:59:37.965949Z","shell.execute_reply":"2021-07-21T04:59:37.974496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def GAN(d,g):\n    model = Sequential()\n    d.trainable = False\n    model.add(g)\n    model.add(d)\n    opt = Adam(lr=1e-4)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:59:44.915421Z","iopub.execute_input":"2021-07-21T04:59:44.915792Z","iopub.status.idle":"2021-07-21T04:59:44.921031Z","shell.execute_reply.started":"2021-07-21T04:59:44.915739Z","shell.execute_reply":"2021-07-21T04:59:44.919889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = generator()\ndiscriminator = discriminator()\ngan = GAN(discriminator,generator)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:59:47.655453Z","iopub.execute_input":"2021-07-21T04:59:47.65583Z","iopub.status.idle":"2021-07-21T04:59:47.968012Z","shell.execute_reply.started":"2021-07-21T04:59:47.655796Z","shell.execute_reply":"2021-07-21T04:59:47.96704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1000):\n  with tf.GradientTape() as gt, tf.GradientTape() as dt:\n    #generate with frozen generator\n    noise = tf.random.normal(shape = (batch_size,noise_dim))\n    generated_img = generator(noise)\n    #mix it with real inputs\n    real_img = get_real(batch_size)\n    input,output = vstack((generated_img,real_img)), vstack((np.zeros((batch_size,1)),np.ones((batch_size,1))))\n    #train discriminator\n    d_loss,_ = discriminator.train_on_batch(x = input, y = output)\n    #now train on the whole model\n    noise = tf.random.normal(shape = (batch_size,noise_dim))\n\n    result = np.ones(batch_size)\n    g_loss = gan.train_on_batch(noise, result)\n    print(f'epoch: {epoch}, d_loss: {d_loss}, g_loss: {g_loss}')","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:59:51.190214Z","iopub.execute_input":"2021-07-21T04:59:51.190559Z","iopub.status.idle":"2021-07-21T05:03:25.301163Z","shell.execute_reply.started":"2021-07-21T04:59:51.190525Z","shell.execute_reply":"2021-07-21T05:03:25.300185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.save('/g_model')","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:59.818631Z","iopub.status.idle":"2021-07-21T04:39:59.819239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom matplotlib import pyplot\nmodel = load_model('/g_model')\nnoise = tf.random.normal(shape = (25,100))\nx = model.predict(noise)\ndef save_plot(examples, n):\n\t# plot images\n  for i in range(n * n):\n    # define subplot\n    pyplot.subplot(n, n, 1 + i)\n    # turn off axis\n    pyplot.axis('off')\n    # plot raw pixel data\n    print(examples)\n    pyplot.imshow(examples[i, :, :, 0]*127.5+127.5)\n  pyplot.show()\nsave_plot(x, 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:39:59.820249Z","iopub.status.idle":"2021-07-21T04:39:59.820887Z"},"trusted":true},"execution_count":null,"outputs":[]}]}