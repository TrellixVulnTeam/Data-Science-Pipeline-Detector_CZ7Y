{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile\n\nwith zipfile.ZipFile(\"../input/generative-dog-images/all-dogs.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"/kaggle/temp/\")\n    \nwith zipfile.ZipFile(\"../input/generative-dog-images/Annotation.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"/kaggle/temp/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os,gc\nimport numpy as np\nfrom PIL import Image\nimport tensorflow as tf\nimport xml.etree.ElementTree as ET\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model, load_model\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Flatten,Dense, Input, Embedding, Conv2D, MaxPooling2D, Reshape, BatchNormalization,\\\nconcatenate, Conv2DTranspose, LeakyReLU\nfrom tensorflow.keras.initializers import RandomNormal\nimport time\nkernel_start = time.time()\nLIMIT = 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = \"/kaggle/temp/\"\nbreeds = os.listdir(ROOT + \"Annotation\")\nidxIn = 0; namesIn = []\nimagesIn = np.zeros((25000,80,80,3))\n# Extract data\nfor breed in breeds:\n    for dog in os.listdir(ROOT+'Annotation/'+breed):\n        try: img = Image.open(ROOT+'all-dogs/'+dog+'.jpg') \n        except: continue           \n        ww,hh = img.size\n        tree = ET.parse(ROOT+'Annotation/'+breed+'/'+dog)\n        root = tree.getroot()\n        objects = root.findall('object')\n        for o in objects:\n            bndbox = o.find('bndbox') \n            xmin = int(bndbox.find('xmin').text)\n            ymin = int(bndbox.find('ymin').text)\n            xmax = int(bndbox.find('xmax').text)\n            ymax = int(bndbox.find('ymax').text)\n            w = np.min((xmax - xmin, ymax - ymin))\n            # ADD PADDING TO CROPS\n            EXTRA = w//8\n            a1 = EXTRA; a2 = EXTRA; b1 = EXTRA; b2 = EXTRA\n            a1 = np.min((a1,xmin)); a2 = np.min((a2,ww-xmin-w))\n            b1 = np.min((b1,ymin)); b2 = np.min((b2,hh-ymin-w))\n            img2 = img.crop((xmin-a1, ymin-b1, xmin+w+a2, ymin+w+b2))\n            img2 = img2.resize((80,80), Image.ANTIALIAS)\n            imagesIn[idxIn,:,:,:] = np.asarray(img2)\n            namesIn.append(breed)                \n            #if idxIn%1000==0: print(idxIn)\n            idxIn += 1\n                \n#     idx = np.arange(idxIn)\n#     np.random.shuffle(idx)\n#     imageIN = imagesIn[idx,:,:,:]\n#     namesIn = np.array(namesIn)[idx]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.random.randint(0,idxIn,25)\nfor k in range(5):\n    plt.figure(figsize=(15,3))\n    for j in range(5):\n        plt.subplot(1,5,j+1)\n        img = Image.fromarray( imagesIn[x[k*5+j],:,:,:].astype('uint8') )\n        plt.axis('off')\n        plt.title(namesIn[x[k*5+j]].split('-')[1],fontsize=11)\n        plt.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FUNCTION FOR DATA AUGMENTATION\ndef flip(x: tf.Tensor, y:tf.Tensor) -> (tf.Tensor,tf.Tensor):\n    x = tf.image.random_flip_left_right(x)\n    return (x,y)\n\n# FUNCTION FOR DATA AUGMENTATION\ndef crop(x: tf.Tensor, y:tf.Tensor) -> (tf.Tensor,tf.Tensor):\n    x = tf.image.random_crop(x,size=[64,64,3])\n    return (x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nfor i in range(len(namesIn)):\n    namesIn[i] = namesIn[i].split('-')[1].lower()\nlabel = LabelEncoder()\nnamesIn = label.fit_transform(namesIn)\nnamesIn = namesIn[:idxIn]\nnamesIn = namesIn.astype(\"int8\")\nimagesIn = (imagesIn[:idxIn,:,:,:]-127.5)/127.5\nimagesIn = imagesIn.astype(\"float32\") # 3935\n# data pipeline\n# ds = tf.data.Dataset.from_tensor_slices((imageIN,nameIN)).map(flip).map(crop).batch(BATCH_SIZE, drop_remainder=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Z dim\nMAPS = 128\nnoise_dim = 128\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.initializers import RandomNormal\ninit = RandomNormal(mean=0.0, stddev=0.02)\n\ndef make_generator():\n    seed = tf.keras.Input(shape=((noise_dim,)))\n    label = tf.keras.Input(shape=((1,)))\n    x = layers.Embedding(120, 120, input_length=1,name='emb')(label)\n    x = layers.Flatten()(x)\n    x = layers.concatenate([seed,x])\n    x = layers.Dense(4*4*MAPS*8, use_bias=False)(x)\n    x = layers.Reshape((4, 4, MAPS*8))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    \n    x = layers.Conv2DTranspose(MAPS*4, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    \n    x = layers.Conv2DTranspose(MAPS*2, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    \n    x = layers.Conv2DTranspose(MAPS, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    \n    x = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False, activation='tanh')(x)\n\n    model = tf.keras.Model(inputs=[seed,label], outputs=x)    \n    return model\n\ngenerator = make_generator()\ngenerator.summary()\n# non trainable param  = 1/2  param from BatchNormalization = 1/2 * sum (dim[4th] * 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discriminator\ndef make_discriminator():\n    image = tf.keras.Input(shape=((64,64,3)))\n    label = tf.keras.Input(shape=((1,)))\n    x = layers.Embedding(120, 64*64, input_length=1)(label)\n    x = layers.Reshape((64,64,1))(x)\n    x = layers.concatenate([image,x])\n    \n    x = layers.Conv2D(MAPS, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Conv2D(MAPS*2, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Conv2D(MAPS*4, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Conv2D(MAPS*8, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(121, activation='sigmoid')(x)\n    x2 = layers.Dense(1, activation='linear')(x)\n    \n    model = tf.keras.Model(inputs=[image,label], outputs=[x,x2])\n    return model\n\ndiscriminator = make_discriminator()\ndiscriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Optimizer\nlr = tf.Variable(0.0002)\ngenerator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1 = 0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1 = 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DISPLAY_EVERY = 10\n\ndef display_images(model, test_input, labs):\n    predictions = model([test_input,labs], training=False)\n    fig = plt.figure(figsize=(16,4))\n    for i in range(predictions.shape[0]):\n        plt.subplot(2, 8, i+1)\n        plt.imshow( (predictions[i, :, :, :]+1.)/2. )\n        plt.axis('off')\n    plt.show()\n    \ndef generate_latent_points(latent_dim, n_samples):\n    return tf.random.truncated_normal((n_samples,latent_dim))\n\ndef train(epochs):\n    all_gl = np.array([]); all_dl = np.array([])\n    \n    for epoch in range(epochs):\n        start = time.time()\n        gl = []; dl = []\n           \n        idx = np.arange(idxIn)\n        np.random.shuffle(idx)\n        dataset = (tf.data.Dataset.from_tensor_slices((imagesIn[idx,:,:,:],namesIn[idx]))\n            .map(flip).map(crop).batch(BATCH_SIZE,drop_remainder=True))\n        \n        # TRAIN ACGAN\n        for i,image_batch in enumerate(dataset):\n            gg,dd = train_step(image_batch,generator,discriminator,\n                        generator_optimizer, discriminator_optimizer)\n            gl.append(gg); dl.append(dd)\n        all_gl = np.append(all_gl,np.array([gl]))\n        all_dl = np.append(all_dl,np.array([dl]))\n        \n        # EXPONENTIALLY DECAY LEARNING RATES\n        if epoch>180: learning_rate.assign(learning_rate*0.95)\n        \n        # DISPLAY PROGRESS\n        if epoch%DISPLAY_EVERY==0:\n            # PLOT EPOCH LOSS\n            plt.figure(figsize=(16,2))\n            plt.plot(np.arange(len(gl)),gl,label='Gen_loss')\n            plt.plot(np.arange(len(dl)),dl,label='Disc_loss')\n            plt.legend()\n            plt.title('Epoch '+str(epoch)+' Loss')\n            ymax = plt.ylim()[1]\n            plt.show()\n            \n            # PLOT ALL TIME LOSS\n            plt.figure(figsize=(16,2))\n            plt.plot(np.arange(len(all_gl)),all_gl,label='Gen_loss')\n            plt.plot(np.arange(len(all_dl)),all_dl,label='Disc_loss')\n            plt.legend()\n            plt.ylim((0,np.min([1.1*np.max(all_gl),2*ymax])))\n            plt.title('All Time Loss')\n            plt.show()\n\n            # DISPLAY IMAGES FROM TRAIN PROGRESS\n            seed = generate_latent_points(noise_dim, num_examples)\n            labs = tf.cast(120*tf.random.uniform((num_examples,1)),tf.int8)\n            display_images(generator, seed, labs)\n            \n            # PRINT STATS\n            print('EPOCH',epoch,'took',np.round(time.time()-start,1),'sec')\n            print('Gen_loss mean=',np.mean(gl),'std=',np.std(gl))\n            print('Disc_loss mean=',np.mean(dl),'std=',np.std(dl))\n            print('Learning rate = ',end='')\n            tf.print(discriminator_optimizer.lr)\n            \n        x = gc.collect()\n        tt = np.round( (time.time() - kernel_start)/60,1 )\n        if tt > LIMIT*60: break\n        \n                  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 250\nnum_examples = 16\n\n@ tf.function\ndef train_step(images,generator,discriminator,generator_optimizer,discriminator_optimizer):\n        \n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True,label_smoothing=0.4)\n    bce2 = tf.keras.losses.BinaryCrossentropy(from_logits=False,label_smoothing=0.4)\n    noise = tf.random.normal((32,128)) # update noise_dim here\n    labs = tf.cast(120*tf.random.uniform((32,)),tf.int32)\n    \n    # USE GRADIENT TAPE TO CALCULATE GRADIENTS\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:       \n        generated_images = generator([noise,labs], training=True)\n        real_cat, real_output = discriminator([images[0],images[1]], training=True)\n        fake_cat, fake_output = discriminator([generated_images,labs], training=True)\n    \n        # GENERATOR LOSS \n        gen_loss = (tf.reduce_mean( (real_output - tf.reduce_mean(fake_output,0) + tf.ones_like(real_output))**2,0 )\n        + tf.reduce_mean( (fake_output - tf.reduce_mean(real_output,0) - tf.ones_like(real_output))**2,0 ) )/2.\n        \n        # DISCRIMINATOR LOSS\n        disc_loss = bce(tf.ones_like(real_output), real_output) + bce(tf.zeros_like(fake_output), fake_output)           \n        real_cat2 = tf.one_hot(tf.cast(images[1],tf.int32),121,dtype=tf.int32)\n        fake_cat2 = tf.one_hot(120*tf.ones((32,),tf.int32),121,dtype=tf.int32)\n        disc_loss += bce2(real_cat2,real_cat) + bce2(fake_cat2,fake_cat) \n        \n    # BACK PROPAGATE ERROR\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n       \n    return gen_loss, disc_loss\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\ntrain(EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mse = tf.keras.losses.MeanSquaredError()\n\nprint('Display Random Dogs by Breed')\nprint()\nfor j in np.random.randint(0,120,25):\n    # GENERATE DOGS\n    seed = generate_latent_points(noise_dim, 10)\n    labs = tf.cast( j*np.ones((10,1)), tf.int8)\n    predictions = generator([seed,labs], training=False); d = 0   \n    # GET BREED NAME    \n    br = np.argwhere( namesIn==j ).flatten()\n    bd = label.inverse_transform(np.array([j]))[0].capitalize()\n    # CALCULATE VARIETY\n    for k in range(4): d += mse(predictions[k,:,:,:],predictions[k+1,:,:,:]) \n    d = np.round( np.array(d),1 )\n    if d<1.0: \n        print(bd,'had mode collapse. No display. (variety =',d,')')\n        continue\n    # DISPLAY DOGS\n    print(bd,'REAL DOGS on top. FAKE DOGS on bottom. (variety =',d,')')\n    plt.figure(figsize=(15,9))\n    for i in range(5):\n        plt.subplot(3,5,i+1)\n        plt.imshow( (imagesIn[br[i],:,:,:]+1.)/2. )\n        plt.axis('off')\n    for i in range(10):\n        plt.subplot(3,5,i+6)\n        plt.imshow( (predictions[i,:,:,:]+1.)/2. )\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}