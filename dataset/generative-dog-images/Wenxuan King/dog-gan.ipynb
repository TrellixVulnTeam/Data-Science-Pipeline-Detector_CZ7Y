{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow-gpu==2.0.0beta1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pathlib\nfrom PIL import Image\nimport numpy as np\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python import keras\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as ET\nimport glob\nfrom numpy import random\nimport zipfile\nAUTOTUNE = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = glob.glob('../input/all-dogs/all-dogs/*')\nbreed = glob.glob('../input/annotation/Annotation/*')\nannot = glob.glob('../input/annotation/Annotation/*/*')\nprint(len(image), len(breed), len(annot))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bbox(annot):\n    \"\"\"\n    This extracts and returns values of bounding boxes\n    \"\"\"\n    xml = annot\n    tree = ET.parse(xml)\n    root = tree.getroot()\n    objects = root.findall('object')\n    bbox = []\n    for o in objects:\n        bndbox = o.find('bndbox')\n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n        bbox.append((xmin,ymin,xmax,ymax))\n    return bbox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image(annot):\n    \"\"\"\n    Retrieve the corresponding image given annotation file\n    \"\"\"\n    img_path = '../input/all-dogs/all-dogs/'\n    file = annot.split('/')\n    img_filename = img_path+file[-1]+'.jpg'\n    return img_filename","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_x = 64\nn_c = 3\ndogs = np.zeros((len(image), n_x, n_x, n_c))\nprint(dogs.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in range(len(image)):\n    bbox = get_bbox(annot[a])\n    dog = get_image(annot[a])\n    if dog == '../input/all-dogs/all-dogs/n02105855_2933.jpg':   # this jpg is not in the dataset\n        continue\n    im = Image.open(dog)\n    im = im.crop(bbox[0])\n    im = im.resize((64,64), Image.ANTIALIAS)\n    dogs[a,:,:,:] = np.asarray(im) / 255. * 2 - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nn_images = 60\nselect = random.randint(low=0,high=dogs.shape[0],size=n_images)\nfor i, index in enumerate(select):  \n    plt.subplot(6, 10, i+1)\n    plt.imshow(dogs[index])\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nseed_dim = 100\nseed = tf.random.normal([batch_size, seed_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dogs = tf.cast(dogs, tf.float32)\ndataset = tf.data.Dataset.from_tensor_slices(dogs).batch(batch_size=batch_size).shuffle(len(image))\nsample = next(iter(dataset))\nsample.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build model\nclass Generator(keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = layers.Dense(4*4*512)\n        self.dconv1 = layers.Conv2DTranspose(256, 5, 2, padding='same')\n        self.bn1 = layers.BatchNormalization()\n        self.dconv2 = layers.Conv2DTranspose(128, 5, 2, padding='same')\n        self.bn2 = layers.BatchNormalization()\n        self.dconv3 = layers.Conv2DTranspose(64, 5, 2, padding='same')\n        self.bn3 = layers.BatchNormalization()\n        self.dconv4 = layers.Conv2DTranspose(3, 5, 2, padding='same')\n    def call(self, inputs, training=None):\n        x = self.fc1(inputs)\n        x = tf.reshape(x, [-1, 4, 4, 512])\n        x = tf.nn.leaky_relu(x)\n        x = self.dconv1(x)\n        x = self.bn1(x)\n        x = tf.nn.leaky_relu(x)\n        x = self.dconv2(x)\n        x = self.bn2(x)\n        x = tf.nn.leaky_relu(x)\n        x = self.dconv3(x)\n        x = self.bn3(x)\n        x = tf.nn.leaky_relu(x)\n        x = self.dconv4(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = layers.Conv2D(64, 5, 2, padding='same')\n        self.dp1 = layers.Dropout(0.3)\n        self.conv2 = layers.Conv2D(128, 5, 2, padding='same')\n        self.dp2 = layers.Dropout(0.3)\n        self.conv3 = layers.Conv2D(256, 5, 2, padding='same')\n        self.flat = layers.Flatten()\n        self.fc = layers.Dense(1)\n    def call(self, inputs, training=None):\n        x = self.conv1(inputs)\n        x = tf.nn.leaky_relu(x)\n        x = self.dp1(x)\n        x = self.conv2(x)\n        x = tf.nn.leaky_relu(x)\n        x = self.dp2(x)\n        x = self.conv3(x)\n        x = tf.nn.leaky_relu(x)\n        x = self.flat(x)\n        x = self.fc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define losses\ndef disc_loss(real_logits, fake_logits):\n    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(real_logits), logits=real_logits))\n    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(fake_logits), logits=fake_logits))\n    return real_loss + fake_loss\n\ndef gen_loss(fake_logits):\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(fake_logits), logits=fake_logits))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = Generator()\ndiscriminator = Discriminator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_optimizer = tf.optimizers.Adam(0.0001)\ndisc_optimizer = tf.optimizers.Adam(0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\ndef train_step(imgs):\n    noise = tf.random.normal([imgs.shape[0], seed_dim])\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        fake_img = generator(noise)\n        fake_logits = discriminator(fake_img, training=True)\n        real_logits = discriminator(imgs, training=True)\n        \n        g_loss = gen_loss(fake_logits)\n        d_loss = disc_loss(real_logits, fake_logits)\n    \n    gen_grads = gen_tape.gradient(g_loss, generator.trainable_variables)\n    disc_grads = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n    \n    gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n    disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_and_save_imgs(generator, seed, epoch):\n    pred = generator(seed)\n    for i in range(6):\n        plt.subplot(2,3,i+1)\n        plt.imshow(pred[i] * 127.5 + 127.5)\n        plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(dataset, epoches):\n    for epoch in range(epoches):\n        for imgs in dataset:\n            train_step(imgs)\n        if (epoch + 1) % 50 == 0:\n            generate_and_save_imgs(generator, seed, epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(dataset, epoches = 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save output\nz = zipfile.PyZipFile('images.zip', mode='w')\nfor d in range(10000):\n    img = generator(tf.random.normal([1, 100]))\n    img = tf.squeeze(img, axis=0)\n    img = img * 127.5 + 127.5\n    img = img.numpy()\n    img = Image.fromarray(img.astype('uint8'),'RGB')\n    f = str(d)+'.png'\n    img.save(f,'PNG')\n    z.write(f)\n    os.remove(f)\nz.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}