{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# INTRODUCTION\n\nNelson Mandela believed education was the most powerful weapon to change the world. But not every student has equal opportunities to learn. Effective policies and plans need to be enacted in order to make education more equitable—and perhaps your innovative data analysis will help reveal the solution.\n\nCurrent research shows educational outcomes are far from equitable. The imbalance was exacerbated by the COVID-19 pandemic. There's an urgent need to better understand and measure the scope and impact of the pandemic on these inequities.\n\nEducation technology company LearnPlatform was founded in 2014 with a mission to expand equitable access to education technology for all students and teachers. LearnPlatform’s comprehensive edtech effectiveness system is used by districts and states to continuously improve the safety, equity, and effectiveness of their educational technology. LearnPlatform does so by generating an evidence basis for what’s working and enacting it to benefit students, teachers, and budgets.\n\nIn this analytics competition, you’ll work to uncover trends in digital learning. Accomplish this with data analysis about how engagement with digital learning relates to factors like district demographics, broadband access, and state/national level policies and events. Then, submit a Kaggle Notebook to propose your best solution to these educational inequities.\n\nYour submissions will inform policies and practices that close the digital divide. With a better understanding of digital learning trends, you may help reverse the long-term learning loss among America’s most vulnerable, making education more equitable.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# PROBLEM STATEMENT\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America’s most vulnerable learners continue to grow.","metadata":{}},{"cell_type":"markdown","source":"# DATA PREPROCSSING\n\nWe are preparing packages and source data that will be used in the analysis process. Python packages that will be used in the analysis mainly are for data manipulation (numpy and pandas) and data visualization (matplotlib and seaborn). ","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport squarify\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom matplotlib import ticker\nimport seaborn as sns\n\n# setting up options\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\n\n#loading dataset\ndistricts = pd.read_csv('/kaggle/input/learnplatform-covid19-impact-on-digital-learning/districts_info.csv')\nproducts = pd.read_csv('/kaggle/input/learnplatform-covid19-impact-on-digital-learning/products_info.csv')\n\nfor dirname, _, filenames in os.walk('/kaggle/input/learnplatform-covid19-impact-on-digital-learning/engagement_data'):\n    for filename in filenames:\n        engagement_files = list(glob.glob(os.path.join(dirname,'*.*')))\n\nengagement = pd.DataFrame()\nfor file in engagement_files:\n    district_id = file[79:83]\n    engagement_file = pd.read_csv(file)\n    engagement_file['id'] = district_id\n    engagement = pd.concat([engagement, engagement_file], axis=0).reset_index(drop=True)\n\n#mapping for districts dataset\nmapping_1 = {\n    '[0, 0.2[': '0%-20%',\n    '[0.2, 0.4[': '20%-40%',\n    '[0.4, 0.6[': '40%-60%',\n    '[0.6, 0.8[': '60%-80%',\n    '[0.8, 1[': '80%-100%'}\n\nmapping_2 = {\n    '[4000, 6000[': '4000-6000',\n    '[6000, 8000[': '6000-8000',\n    '[8000, 10000[': '8000-10000',\n    '[10000, 12000[': '10000-12000',\n    '[12000, 14000[': '12000-14000',\n    '[14000, 16000[': '14000-16000',\n    '[16000, 18000[': '16000-18000',\n    '[18000, 20000[': '18000-20000',\n    '[20000, 22000[': '20000-22000',\n    '[22000, 24000[': '22000-24000',\n    '[32000, 34000[': '32000-34000'}\n\nmapping_3 = {\n    '[0.18, 1[': '18%-100%',\n    '[1, 2[': '100%-200%'\n}\n\ndistricts['pct_black/hispanic'] = districts['pct_black/hispanic'].map(mapping_1)\ndistricts['pct_free/reduced'] = districts['pct_free/reduced'].map(mapping_1)\ndistricts['county_connections_ratio'] = districts['county_connections_ratio'].map(mapping_3)\ndistricts['pp_total_raw'] = districts['pp_total_raw'].map(mapping_2)\n\n#separating category\nproducts[['Category', 'Subcategory']] = products['Primary Essential Function'].str.split('-', n=1, expand=True,)\nproducts = products.drop('Primary Essential Function', axis=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:40:31.11962Z","iopub.execute_input":"2022-06-30T15:40:31.120125Z","iopub.status.idle":"2022-06-30T15:48:32.147644Z","shell.execute_reply.started":"2022-06-30T15:40:31.120023Z","shell.execute_reply":"2022-06-30T15:48:32.146123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ncolors_blue = [\"#132C33\", \"#264D58\", '#17869E', '#51C4D3', '#B4DBE9']\ncolors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\ncolors_mix = [\"#17869E\", '#264D58', '#179E66', '#D35151', '#E9DAB4', '#E9B4B4', '#D3B651', '#6351D3']\ncolors_div = [\"#132C33\", '#17869E', '#DADADA', '#D35151', '#331313']\n\nsns.palplot(colors_blue)\nsns.palplot(colors_dark)\nsns.palplot(colors_red)\nsns.palplot(colors_mix)\nsns.palplot(colors_div)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:48:32.15017Z","iopub.execute_input":"2022-06-30T15:48:32.151267Z","iopub.status.idle":"2022-06-30T15:48:32.65055Z","shell.execute_reply.started":"2022-06-30T15:48:32.151231Z","shell.execute_reply":"2022-06-30T15:48:32.649028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA SET OVERVIEW\n\nThe overview is prepared to get the feel on data structure. It will also include a quick analysis on missing values, basic statistics and data manipulation. In general there will 3 datasets: engagement, districts and products","metadata":{}},{"cell_type":"markdown","source":"# ENGAGEMENT\n\nThe engagement data are aggregated at school district level, and each file represents data from one school district. The 4-digit file name represents district_id which can be used to link to district information in district_info. The lp_id can be used to link to product information in product_info.\n\nThis dataset consists of below information:\n\n--> **time:** date in \"YYYY-MM-DD\"\n\n--> **lp_id:** The unique identifier of the product\n\n--> **pct_access:** Percentage of students in the district have at least one page-load event of a given product and on a given day\n\n--> **engagement_index:** Total page-load events per one thousand students of a given product and on a given day\n\n**Observations:**\n\n--> There are 22,324,190 rows with 5 columns as mentioned above.\n\n--> This dataset contain missing value of 5,392,397 which come from lp_id of 541, pct_access of 13,447 and engagement_index 5,378,409. Missing value in the engagement_index can be considered big as it consist of 24.15% from total observation.","metadata":{}},{"cell_type":"code","source":"engagement.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:48:32.652445Z","iopub.execute_input":"2022-06-30T15:48:32.6533Z","iopub.status.idle":"2022-06-30T15:48:32.684103Z","shell.execute_reply.started":"2022-06-30T15:48:32.653243Z","shell.execute_reply":"2022-06-30T15:48:32.68265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows: {engagement.shape[0]};  Number of columns: {engagement.shape[1]}; No of missing values: {sum(engagement.isna().sum())}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:48:32.692352Z","iopub.execute_input":"2022-06-30T15:48:32.692983Z","iopub.status.idle":"2022-06-30T15:48:36.716707Z","shell.execute_reply.started":"2022-06-30T15:48:32.692914Z","shell.execute_reply":"2022-06-30T15:48:36.715341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of missing Values in every column:')\nprint(engagement.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:36.717964Z","iopub.execute_input":"2022-06-30T15:48:36.718263Z","iopub.status.idle":"2022-06-30T15:48:40.736844Z","shell.execute_reply.started":"2022-06-30T15:48:36.718232Z","shell.execute_reply":"2022-06-30T15:48:40.735466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BASIC STATISTICS\n\nBelow is the basic statistics for each variables which contain information on count, mean, standard deviation, minimum, 1st quartile, median, 3rd quartile and maximum.","metadata":{}},{"cell_type":"code","source":"engagement.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:40.73915Z","iopub.execute_input":"2022-06-30T15:48:40.739514Z","iopub.status.idle":"2022-06-30T15:48:45.640175Z","shell.execute_reply.started":"2022-06-30T15:48:40.73948Z","shell.execute_reply":"2022-06-30T15:48:45.638863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DISTRICTS\n\nThe district file includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. In this data set, LearnPlatform removed the identifiable information about the school districts. LearnPlatform also used an open source tool ARX (Prasser et al. 2020) to transform several data fields and reduce the risks of re-identification. For data generalization purposes some data points are released with a range where the actual value falls under. Additionally, there are many missing data marked as 'NaN' indicating that the data was suppressed to maximize anonymization of the dataset.\n\nThis dataset consists of below information:\n\n-->**** district_id:** The unique identifier of the school district\n\n--> **state:** The state where the district resides in\n\n--> **locale:** NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural.\n\n--> **pct_black/hispanic:** Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data.\n\n\n--> **pct_free/reduced:** Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\n\n--> **countyconnectionsratio:** ratio (residential fixed high-speed connections over 200 kbps in at least one direction/households) based on the county level data from FCC From 477 (December 2018 version).\n\n--> **pptotalraw:** Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource - Database on Schools (NERD$) project.\nThe expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.\n\n**OBSERVATIONS:**\n\nThere are 223 rows with 7 columns as mentioned above.\nThis dataset contain missing value of 442 which mainly come from pp_total_raw of 115, pct_free/reduced of 85 and county_connections_ratio of 71.","metadata":{}},{"cell_type":"code","source":"districts.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:45.641683Z","iopub.execute_input":"2022-06-30T15:48:45.642013Z","iopub.status.idle":"2022-06-30T15:48:45.656695Z","shell.execute_reply.started":"2022-06-30T15:48:45.641981Z","shell.execute_reply":"2022-06-30T15:48:45.65554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows: {districts.shape[0]};  Number of columns: {districts.shape[1]}; No of missing values: {sum(districts.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:45.658424Z","iopub.execute_input":"2022-06-30T15:48:45.65998Z","iopub.status.idle":"2022-06-30T15:48:45.668185Z","shell.execute_reply.started":"2022-06-30T15:48:45.659929Z","shell.execute_reply":"2022-06-30T15:48:45.666863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of missing Values in every column:')\nprint(districts.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:45.670546Z","iopub.execute_input":"2022-06-30T15:48:45.67105Z","iopub.status.idle":"2022-06-30T15:48:45.684034Z","shell.execute_reply.started":"2022-06-30T15:48:45.670999Z","shell.execute_reply":"2022-06-30T15:48:45.682786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 10))\n\nsns.countplot(y=\"state\",data=districts,order=districts.state.value_counts().index,palette=\"pastel\",linewidth=3)\nplt.title(\"State Distribution\",size=18)\n\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:54:50.043664Z","iopub.execute_input":"2022-06-30T15:54:50.044174Z","iopub.status.idle":"2022-06-30T15:54:52.747088Z","shell.execute_reply.started":"2022-06-30T15:54:50.04414Z","shell.execute_reply":"2022-06-30T15:54:52.746031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax  = plt.subplots(figsize=(5, 3))\nfig.suptitle('Locale Type Distribution', size = 5)\n\nlabels = list(districts.locale.value_counts().index)\nsizes = districts.locale.value_counts().values\nexplode = (0, 0, 0, 0.1)\n\nax.pie(sizes, explode=explode,startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.7, colors=[\"#FFFF33\",\"#ff9100\",\"#eaaa00\",\"#6d6875\"])\nax.add_artist(plt.Circle((0,0),0.3,fc='white'))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:56:49.218507Z","iopub.execute_input":"2022-06-30T15:56:49.219159Z","iopub.status.idle":"2022-06-30T15:56:49.584555Z","shell.execute_reply.started":"2022-06-30T15:56:49.219115Z","shell.execute_reply":"2022-06-30T15:56:49.583274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PRODUCTS\n\nThe product file includes information about the characteristics of the top 372 products with most users in 2020. The categories listed in this file are part of LearnPlatform's product taxonomy. Data were labeled by LearnPlatform team. Some products may not have labels due to being duplicate, lack of accurate url or other reasons.\n\nThis dataset consists of below information:\n\n--> **LP ID:** The unique identifier of the product\n\n--> **URL:** Web Link to the specific product\n\n--> **Product Name:** Name of the specific product\n\n--> **Provider/Company Name:** Name of the product provider\n\n--> **Sector(s):** Sector of education where the product is used\n\n--> **Category:** The basic function of the product. Products are first labeled as one of these three categories: LC = ----Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations.\nSubcategory: Each of these categories have multiple sub-categories with which the products were labeled\n\n**Observations:**\n\nThere are 372 rows with 7 columns as mentioned above.\nThis dataset contain missing value of 61 which mainly come from Sectors(s), Category, Subcategory with each of them has 20 missing values and 1 missing value on Provider/Company Name.","metadata":{}},{"cell_type":"code","source":"products.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:45.688483Z","iopub.execute_input":"2022-06-30T15:48:45.688827Z","iopub.status.idle":"2022-06-30T15:48:45.705449Z","shell.execute_reply.started":"2022-06-30T15:48:45.688794Z","shell.execute_reply":"2022-06-30T15:48:45.703909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows: {products.shape[0]};  Number of columns: {products.shape[1]}; No of missing values: {sum(products.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:45.707779Z","iopub.execute_input":"2022-06-30T15:48:45.708254Z","iopub.status.idle":"2022-06-30T15:48:45.718727Z","shell.execute_reply.started":"2022-06-30T15:48:45.708206Z","shell.execute_reply":"2022-06-30T15:48:45.717261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of missing Values in every column:')\nprint(products.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:48:45.720664Z","iopub.execute_input":"2022-06-30T15:48:45.721605Z","iopub.status.idle":"2022-06-30T15:48:45.730261Z","shell.execute_reply.started":"2022-06-30T15:48:45.721567Z","shell.execute_reply":"2022-06-30T15:48:45.729293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = products.groupby('Subcategory').count()[['LP ID']].sort_values(by=\"LP ID\", ascending=True)\n\nfig, ax = plt.subplots(figsize=(8, 14))\n\nbars0 = ax.barh(df.index, df['LP ID'], color=\"#179E66\", alpha=0.8, edgecolor=colors_dark[0])\n\nax.grid(axis='x', alpha=0.3)\nax.set_axisbelow(True)\nax.set_xlabel(\"Total Products\", fontsize=14, labelpad=10, fontweight='bold', color=colors_dark[0])\nax.set_ylabel(\"Subcategory\", fontsize=14, labelpad=10, fontweight='bold', color=colors_dark[0])\nxmin, xmax = ax.get_xlim()\nymin, ymax = ax.get_ylim()\n\nplt.text(s=\"About The Data | Products\", ha='left', x=xmin, y=ymax*1.08, fontsize=24, color=colors_dark[0])\nplt.text(s=\"Count of products by its functions\", ha='left', x=xmin, y=ymax*1.04, fontsize=24, fontweight='bold', color=colors_dark[0])\nplt.title(\"Most of products that is in this dataset belongs to Digital Learning Platforms\", loc='left', fontsize=13, color=colors_dark[1]) \n\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:48:45.731718Z","iopub.execute_input":"2022-06-30T15:48:45.732083Z","iopub.status.idle":"2022-06-30T15:48:46.362796Z","shell.execute_reply.started":"2022-06-30T15:48:45.732051Z","shell.execute_reply":"2022-06-30T15:48:46.361453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = products.groupby('Sector(s)').count()[['LP ID']].sort_values(by=\"LP ID\", ascending=False)\n\nfig, ax = plt.subplots(figsize=(14, 8))\n\nbars0 = ax.bar(df.index, df['LP ID'], color=\"#9E1717\", alpha=0.8, edgecolor=\"#9E1717\")\n\nax.grid(axis='y', alpha=0.3)\nax.set_axisbelow(True)\nax.set_xlabel(\"Total Products\", fontsize=14, labelpad=10, fontweight='bold', color=colors_dark[0])\nax.set_ylabel(\"Sector(s)\", fontsize=14, labelpad=10, fontweight='bold', color=colors_dark[0])\nxmin, xmax = ax.get_xlim()\nymin, ymax = ax.get_ylim()\n\n\nfor i, bar in enumerate(bars0) : \n    x=bar.get_x()\n    y=bar.get_height()\n    if i < 3 : \n        ax.text(\n        s=f\"{df.iloc[i].values[0]}\\nProducts\",\n        va='center', ha='center', \n        x=x+0.38, y=y/2,\n        color='white',\n        fontsize=18,\n        fontweight='bold')\n    else : \n        ax.text(\n        s=f\"{df.iloc[i].values[0]}\",\n        va='center', ha='center', \n        x=x+0.38, y=y+5,\n        color=colors_dark[0],\n        fontsize=14)\n        \n\nplt.text(s=\"About The Data | Products\", ha='left', x=xmin, y=ymax*1.16, fontsize=24, color=colors_dark[0])\nplt.text(s=\"Count of products by its Sector(s)\", ha='left', x=xmin, y=ymax*1.1, fontsize=24, fontweight='bold', color=colors_dark[0])\nplt.title(\"Most of products that is in this dataset belongs to PreK-12 sector\\nmeaning that most of the education services that exists in this dataset is for kindergarten to 12th grade students\", loc='left', fontsize=13, color=colors_dark[2]) \n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:48:46.364599Z","iopub.execute_input":"2022-06-30T15:48:46.364948Z","iopub.status.idle":"2022-06-30T15:48:46.667349Z","shell.execute_reply.started":"2022-06-30T15:48:46.364915Z","shell.execute_reply":"2022-06-30T15:48:46.665873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MERGING DATA SETS\n\nWe will merge engagement, districts and products datasets into 1 big dataset called combine that consist all of the information from all dataset and we will delete existing dataset to free up some memory","metadata":{}},{"cell_type":"code","source":"merged = engagement.copy()\nmerged['id'] = merged['id'].astype('int64') \nmerged = merged.merge(districts, left_on='id', right_on='district_id', how='left')\nmerged = merged.merge(products, left_on='lp_id', right_on='LP ID', how='left')\nmerged = merged.drop('district_id', axis=1)\nmerged = merged.drop('LP ID', axis=1)\nmerged['time'] = pd.to_datetime(merged['time'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:48:46.668962Z","iopub.execute_input":"2022-06-30T15:48:46.669332Z","iopub.status.idle":"2022-06-30T15:49:34.37883Z","shell.execute_reply.started":"2022-06-30T15:48:46.669267Z","shell.execute_reply":"2022-06-30T15:49:34.377029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:49:34.380383Z","iopub.execute_input":"2022-06-30T15:49:34.380718Z","iopub.status.idle":"2022-06-30T15:49:34.40556Z","shell.execute_reply.started":"2022-06-30T15:49:34.380686Z","shell.execute_reply":"2022-06-30T15:49:34.404246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows: {merged.shape[0]};  Number of columns: {merged.shape[1]}; No of missing values: {sum(merged.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:49:34.406844Z","iopub.execute_input":"2022-06-30T15:49:34.407269Z","iopub.status.idle":"2022-06-30T15:49:53.398412Z","shell.execute_reply.started":"2022-06-30T15:49:34.407188Z","shell.execute_reply":"2022-06-30T15:49:53.397158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of missing Values in every column:')\nprint(merged.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:49:53.400001Z","iopub.execute_input":"2022-06-30T15:49:53.400355Z","iopub.status.idle":"2022-06-30T15:50:12.445348Z","shell.execute_reply.started":"2022-06-30T15:49:53.400321Z","shell.execute_reply":"2022-06-30T15:50:12.444056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:25:15.727432Z","iopub.execute_input":"2022-06-30T16:25:15.728012Z","iopub.status.idle":"2022-06-30T16:25:23.352586Z","shell.execute_reply.started":"2022-06-30T16:25:15.727962Z","shell.execute_reply":"2022-06-30T16:25:23.351197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged['Provider/Company Name'].value_counts(dropna=False).shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:50:12.447241Z","iopub.execute_input":"2022-06-30T15:50:12.447619Z","iopub.status.idle":"2022-06-30T15:50:14.136671Z","shell.execute_reply.started":"2022-06-30T15:50:12.447585Z","shell.execute_reply":"2022-06-30T15:50:14.135188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VISUALIZATION","metadata":{}},{"cell_type":"markdown","source":"Engagement dataset represents on how many products (in a school district) that have been accessed by students in a daily basis for year 2020 with the total of 22 million product accessed in 2020. There are 8,646 products but only 368 products that have been successfully mapped using the products_info dataset, unmapped products are categorized as Unknown.\n\nTo make a little bit clearer:\n\n--> The dataset is presented in a daily basis.\n\n--> A product will only one product per school district if there is an accessed to the product.\n\nIn this part we will also find some analysis related to trend:\n\n--> We will look into the mean accessed products.\n\n--> How many products that have been used in a daily basis.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntemp = pd.DataFrame(merged.groupby(['time', 'id'])['time'].count())\ntemp = temp.rename(columns={\"time\":\"amount\"})\ntemp = temp.reset_index(drop=False)\ntemp = temp.groupby('time')['amount'].mean()\n\nbackground_color = \"#B4DBE9\"\nsns.set_palette(['dimgray']*400)\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(9, 1), facecolor='#B4DBE9')\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\n#graph\nax0 = sns.barplot(ax=ax0, x=temp.index, y=temp, zorder=2, linewidth=0.8, saturation=1)\nsummer = np.arange(np.datetime64(\"1970-06-01\"), np.datetime64(\"1970-08-24\"))\nax0.fill_between(summer, np.max(temp), color='#ffd514', alpha=0.5, zorder=2, linewidth=0)\nplt.axvline(np.datetime64(\"1970-02-12\"), color='#ffd514', alpha=0.5)\nplt.axvline(np.datetime64(\"1970-03-11\"), color='#ffd514', alpha=0.5)\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\nax0.grid(which='major', axis='x', zorder=0, color='#EEEEEE', lw=0.3)\nax0.grid(which='major', axis='y', zorder=0, color='#EEEEEE', lw=0.3)\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim() \nax0.text(x0, y1*1.11, 'Mean Daily Accessed Products', color='black', fontsize=7, ha='left', va='bottom', weight='bold')\nax0.text(x0, y1*1.1, 'After the summer holiday, there are an increased in accessed products', \n        color='#292929', fontsize=5, ha='left', va='top')\nax0.annotate(\"temporary\\nschool closures\", \n             xy=(np.datetime64(\"1970-02-12\"), 430), \n             xytext=(np.datetime64(\"1970-01-09\"), 380), \n             arrowprops=dict(arrowstyle=\"->\"), fontsize=5)\nax0.annotate(\"COVID-19\\nPandemic\", \n             xy=(np.datetime64(\"1970-03-11\"), 430), \n             xytext=(np.datetime64(\"1970-03-18\"), 350), \n             arrowprops=dict(arrowstyle=\"->\"), fontsize=5)\nax0.annotate(\"Summer Holiday\", \n             xy=(np.datetime64(\"1970-06-27\"), 350), \n             xytext=(np.datetime64(\"1970-06-27\"), 350), \n             fontsize=5)\n\n#format axis\nax0.set_xlabel(\"date\",fontsize=5, weight='bold')\nax0.set_ylabel(\"products\",fontsize=5, weight='bold')\n\n#format the ticks\nax0.tick_params('both', length=2, which='major', labelsize=5)\nmonths = mdates.MonthLocator()\nax0.xaxis.set_major_locator(months)\nax0.set_xticklabels(['Jan 2020', 'Feb 2020', 'Mar 2020', 'Apr 2020', 'May 2020', 'Jun 2020', 'Jul 2020', \n                     'Aug 2020', 'Sep 2020', 'Oct 2020', 'Nov 2010', 'Dec 2020'])\ny_format = ticker.FuncFormatter(lambda x, p: format(int(x), ','))\nax0.yaxis.set_major_formatter(y_format)\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:50:14.138633Z","iopub.execute_input":"2022-06-30T15:50:14.138996Z","iopub.status.idle":"2022-06-30T15:50:18.721352Z","shell.execute_reply.started":"2022-06-30T15:50:14.138963Z","shell.execute_reply":"2022-06-30T15:50:18.71995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(4, 3), facecolor='#DADADA')\ngs = fig.add_gridspec(1, 2)\ngs.update(wspace=1.1, hspace=1.5)\n\n##########PRODUCT##########\ntemp = pd.DataFrame(merged.groupby('Product Name', dropna=False)['engagement_index'].sum()/1000000).reset_index()\ntemp.columns = ['product', 'amount']\ntemp = temp.fillna('Unknown')\ntemp = temp.sort_values('amount', ascending=False)\ntemp = temp[0:10]\n\nbackground_color = \"#f6f5f5\"\ncolor_map = [\"blue\" for _ in range(75)]\ncolor_map[0] = \"#ffd514\"\nsns.set_palette(sns.color_palette(color_map))\n\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\n#graph\nax0_sns = sns.barplot(ax=ax0, y=temp['product'], x=temp['amount'], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1)\nax0_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.3)\nax0_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.3)\n\n#format axis\nax0_sns.set_xlabel(\"page-load (million)\",fontsize=3, weight='bold')\nax0_sns.set_ylabel(\"products\",fontsize=3, weight='bold')\nax0_sns.tick_params(labelsize=3, width=0.5, length=1.5)\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim()\nax0.text(x0, y1-0.45, 'Top 10 Products', fontsize=4, ha='left', va='top', weight='bold')\nax0.text(x0, y1-0.2, 'Top 10 products are controlled by Google LLC', fontsize=3, ha='left', va='top')\n\n# data label\nfor p in ax0.patches:\n    value = f'{p.get_width():,.0f}'\n    x = p.get_x() + p.get_width() + 55\n    y = p.get_y() + p.get_height() / 2 \n    ax0.text(x, y, value, ha='center', va='center', fontsize=2.7, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.3))\nx_format = ticker.FuncFormatter(lambda x, p: format(int(x), ','))\nax0.xaxis.set_major_formatter(x_format)\n\n##########PROVIDER##########\ntemp = pd.DataFrame(merged.groupby('Provider/Company Name', dropna=False)['engagement_index'].sum()/1000000).reset_index()\ntemp.columns = ['product', 'amount']\ntemp = temp.fillna('Unknown')\ntemp = temp.sort_values('amount', ascending=False)\ntemp = temp[0:10]\n\nbackground_color = \"#f6f5f5\"\ncolor_map = [\"blue\" for _ in range(75)]\ncolor_map[0] = \"#ffd514\"\nsns.set_palette(sns.color_palette(color_map))\n\nax0 = fig.add_subplot(gs[0, 1])\nax0.set_facecolor(background_color)\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\n#graph\nax0_sns = sns.barplot(ax=ax0, y=temp['product'], x=temp['amount'], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1)\nax0_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.3)\nax0_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.3)\n\n#format axis\nax0_sns.set_xlabel(\"page-load (million)\",fontsize=3, weight='bold')\nax0_sns.set_ylabel(\"providers\",fontsize=3, weight='bold')\nax0_sns.tick_params(labelsize=3, width=0.5, length=1.5)\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim()\nax0.text(x0, y1-0.47, 'Top 10 Providers', fontsize=4, ha='left', va='top', weight='bold')\nax0.text(x0, y1-0.2, 'Google LLC is the top provider for digital learning', fontsize=3, ha='left', va='top')\n\n# data label\nfor p in ax0.patches:\n    value = f'{p.get_width():,.0f}'\n    x = p.get_x() + p.get_width() + 130\n    y = p.get_y() + p.get_height() / 2 \n    ax0.text(x, y, value, ha='center', va='center', fontsize=2.7, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.3))\nx_format = ticker.FuncFormatter(lambda x, p: format(int(x), ','))\nax0.xaxis.set_major_formatter(x_format)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:50:18.72345Z","iopub.execute_input":"2022-06-30T15:50:18.72381Z","iopub.status.idle":"2022-06-30T15:50:24.523897Z","shell.execute_reply.started":"2022-06-30T15:50:18.723776Z","shell.execute_reply":"2022-06-30T15:50:24.522992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(4, 4), facecolor='#f6f5f5')\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.2, hspace=1.5)\n\n##########CATEGORY##########\ntemp = pd.DataFrame(merged.groupby(['Category'], dropna=False)['engagement_index'].sum()).reset_index()\ntemp.columns = ['description', 'amount']\ntemp = temp.fillna('Unknown')\ntemp = temp.sort_values('amount', ascending=False)\n\nbackground_color = \"#331313\"\ncolor_map = [\"blue\" for _ in range(75)]\ncolor_map[0] = \"#ffd514\"\nsns.set_palette(sns.color_palette(color_map))\n\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\n#graph\nax0.plot(temp['description'], temp['amount']/1000000, 'o--', color=\"#ffd514\", markersize=3, markeredgewidth=0, linewidth=0.5, zorder=4)\nax0.fill_between(temp['description'], temp['amount']/1000000, color=\"#d3d3d3\", zorder=3, alpha=0.5, linewidth=0)\nax0.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.2)\nax0.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.2)\n\n#format axis\nax0.set_xlabel(\"category\",fontsize=3, weight='bold')\nax0.set_ylabel(\"page-load (million)\",fontsize=3, weight='bold')\nax0.tick_params(labelsize=3, width=0.5, length=1.5)\nax0.yaxis.set_major_formatter(y_format)\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim()\nax0.text(x0, y1+285, 'Category & Page Load', fontsize=4, ha='left', va='top', weight='bold')\nax0.text(x0, y1+160, 'Most of the page-load come from Learning & Curriculum', fontsize=3, ha='left', va='top')\n\n##########SECTORS##########\ntemp = pd.DataFrame(merged.groupby(['Sector(s)'], dropna=False)['engagement_index'].sum()).reset_index()\ntemp.columns = ['description', 'amount']\ntemp = temp.fillna('Unknown')\ntemp = temp.sort_values('amount', ascending=False)\n\nbackground_color = \"#331313\"\ncolor_map = [\"dimgray\" for _ in range(75)]\ncolor_map[0] = \"#ffd514\"\nsns.set_palette(sns.color_palette(color_map))\n\nax0 = fig.add_subplot(gs[0, 1])\nax0.set_facecolor(background_color)\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\n#graph\nax0.plot(temp['description'], temp['amount']/1000000, 'o--', color=\"#ffd514\", markersize=3, markeredgewidth=0, linewidth=0.5, zorder=4)\nax0.fill_between(temp['description'], temp['amount']/1000000, color=\"#d3d3d3\", zorder=3, alpha=0.5, linewidth=0)\nax0.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.2)\nax0.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.2)\n\n#format axis\nax0.set_xlabel(\"sector\",fontsize=3, weight='bold')\nax0.set_ylabel(\"page-load (million)\",fontsize=3, weight='bold')\nax0.tick_params(labelsize=3, width=0.5, length=1.5)\nax0.yaxis.set_major_formatter(y_format)\nax0.set_xticklabels(['PreK-12;\\nHigher Ed;\\nCorporate', 'Unknown', 'PreK-12', \n                     'PreK-12;\\nHigher Ed', 'Corporate', 'Higher Ed;\\nCorporate'])\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim()\nax0.text(x0, y1+300, 'Sectors & Page Load', fontsize=4, ha='left', va='top', weight='bold')\nax0.text(x0, y1+150, 'PreK-12; Higher Ed; Corporate is dominating', fontsize=3, ha='left', va='top')\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:50:24.525301Z","iopub.execute_input":"2022-06-30T15:50:24.525828Z","iopub.status.idle":"2022-06-30T15:50:30.585801Z","shell.execute_reply.started":"2022-06-30T15:50:24.525794Z","shell.execute_reply":"2022-06-30T15:50:30.584611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged['time'] = pd.to_datetime(merged['time'], errors='coerce')\nmerged['month'] = merged['time'].dt.month","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:01:26.976998Z","iopub.execute_input":"2022-06-30T16:01:26.977497Z","iopub.status.idle":"2022-06-30T16:01:29.713036Z","shell.execute_reply.started":"2022-06-30T16:01:26.977461Z","shell.execute_reply":"2022-06-30T16:01:29.711803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"engagement_per_month=merged.groupby(['month'], as_index=False)['engagement_index'].mean()\nengagement_per_month=engagement_per_month.sort_values(by=['month'],ascending=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:01:33.888418Z","iopub.execute_input":"2022-06-30T16:01:33.888818Z","iopub.status.idle":"2022-06-30T16:01:34.741554Z","shell.execute_reply.started":"2022-06-30T16:01:33.888785Z","shell.execute_reply":"2022-06-30T16:01:34.740448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7,4))\n\nsns.lineplot(data=engagement_per_month, x=\"month\", y= \"engagement_index\", color='g')\nplt.title('Monthly Average Engagement in 2020 (All District)', size=10)\nplt.xlabel('Month',size=12)\n\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:07:55.487607Z","iopub.execute_input":"2022-06-30T16:07:55.488041Z","iopub.status.idle":"2022-06-30T16:07:56.29155Z","shell.execute_reply.started":"2022-06-30T16:07:55.487996Z","shell.execute_reply":"2022-06-30T16:07:56.29001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the category data base on average engagement index and sort it\ntop_category_platform=merged.groupby(['Category'], as_index=False)['engagement_index'].mean()\ntop_category_platform=top_category_platform.sort_values(by=['engagement_index'],ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:05:03.552578Z","iopub.execute_input":"2022-06-30T16:05:03.552985Z","iopub.status.idle":"2022-06-30T16:05:06.381776Z","shell.execute_reply.started":"2022-06-30T16:05:03.552951Z","shell.execute_reply":"2022-06-30T16:05:06.380387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_category_platform.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:05:21.205646Z","iopub.execute_input":"2022-06-30T16:05:21.206111Z","iopub.status.idle":"2022-06-30T16:05:21.218873Z","shell.execute_reply.started":"2022-06-30T16:05:21.206077Z","shell.execute_reply":"2022-06-30T16:05:21.217389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,4))\n\nsns.barplot(data=top_category_platform[:10], y=\"Category\", x= \"engagement_index\")\nplt.title('Top 10 Category Platform with the Most Average Daily Engagement in 2020 (All District)', size=18)\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:07:06.506452Z","iopub.execute_input":"2022-06-30T16:07:06.506874Z","iopub.status.idle":"2022-06-30T16:07:07.58097Z","shell.execute_reply.started":"2022-06-30T16:07:06.506841Z","shell.execute_reply":"2022-06-30T16:07:07.579589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the state data base on average engagement index\nstate_most_visit_lms = merged[merged['Category']=='SDO']\nstate_most_visit_lms = state_most_visit_lms.groupby(['state'], as_index=False)['engagement_index'].mean()\nstate_most_visit_lms = state_most_visit_lms.sort_values(by=['engagement_index'],ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:25:50.980392Z","iopub.execute_input":"2022-06-30T16:25:50.980999Z","iopub.status.idle":"2022-06-30T16:25:52.817435Z","shell.execute_reply.started":"2022-06-30T16:25:50.980952Z","shell.execute_reply":"2022-06-30T16:25:52.81603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,6))\n\nsns.barplot(data=state_most_visit_lms.head(5), x=\"state\", y= \"engagement_index\")\n\nplt.title('Top 5 State that Often Visited Learning Management Systems in 2020',size=18)\nplt.xlabel('state',size=14)\n\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nsns.despine()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:26:24.724607Z","iopub.execute_input":"2022-06-30T16:26:24.725036Z","iopub.status.idle":"2022-06-30T16:26:24.758512Z","shell.execute_reply.started":"2022-06-30T16:26:24.725002Z","shell.execute_reply":"2022-06-30T16:26:24.757062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,6))\n\nsns.barplot(data=state_most_visit_lms.tail(5), x=\"state\", y= \"engagement_index\")\n\nplt.title('Top 5 State that the Least Often Visited Learning Management Systems in 2020',size=18)\nplt.xlabel('State',size=14)\n\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nsns.despine()\nplt.gca().invert_xaxis()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:22:01.710813Z","iopub.execute_input":"2022-06-30T16:22:01.711277Z","iopub.status.idle":"2022-06-30T16:22:01.74804Z","shell.execute_reply.started":"2022-06-30T16:22:01.711241Z","shell.execute_reply":"2022-06-30T16:22:01.746063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(4, 4), facecolor='#DADADA')\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0.7, hspace=0.1)\n\n##########CORRELATION STATE##########\ntemp = merged[['time', 'state', 'engagement_index']]\ntemp['state'].fillna('Unknown', inplace=True)\ntemp = pd.DataFrame(temp.pivot_table(index='time', columns='state', values='engagement_index', \n                                     aggfunc='sum', dropna=False)).reset_index(drop=False)\n\nbackground_color = \"#f6f5f5\"\ncolors = [\"black\", \"#51C4D3\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\n#graph\nax0_sns = sns.heatmap(temp.corr(), ax=ax0, annot=True, square=True, xticklabels=True, yticklabels=True,\n            annot_kws={\"size\": 3}, cbar=False, cmap=colormap, linewidths=0.3, \n            linecolor='black', fmt='.1g')\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim()\nax0.text(x0, y1-1.1, \"Correlation Between State\", fontsize=5, ha='left', va='top', weight='bold')\nax0.text(x0, y1-0.5, 'BLUE indicates a high positive correlation', fontsize=3, ha='left', va='top')\n\n#axis\nax0_sns.set_xlabel(\"\")\nax0_sns.set_ylabel(\"\")\nax0_sns.tick_params(length=0, labelsize=3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:50:30.587114Z","iopub.execute_input":"2022-06-30T15:50:30.587539Z","iopub.status.idle":"2022-06-30T15:50:39.112055Z","shell.execute_reply.started":"2022-06-30T15:50:30.587501Z","shell.execute_reply":"2022-06-30T15:50:39.110814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(3, 3), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0.7, hspace=0.1)\n\n##########CORRELATION LOCALE##########\ntemp = merged[['time', 'locale', 'engagement_index']]\ntemp['locale'].fillna('Unknown', inplace=True)\ntemp = pd.DataFrame(temp.pivot_table(index='time', columns='locale', values='engagement_index', \n                                     aggfunc='sum', dropna=False)).reset_index(drop=False)\n\nbackground_color = \"#f6f5f5\"\ncolors = [\"black\", \"#6351D3\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\n#graph\n#matrix = np.triu(temp.corr())\nax0_sns = sns.heatmap(temp.corr(), ax=ax0, annot=True, square=True, xticklabels=True, yticklabels=True,\n            annot_kws={\"size\": 4}, cbar=False, cmap=colormap, linewidths=0.3, \n            linecolor='black', fmt='.1g')\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim()\nax0.text(x0, y1-0.38, \"Correlation Between Locale\", fontsize=6, ha='left', va='top', weight='bold')\nax0.text(x0, y1-0.2, 'Byzantine Night Blue indicates a high positive correlation', fontsize=4, ha='left', va='top')\n\n#axis\nax0_sns.set_xlabel(\"\")\nax0_sns.set_ylabel(\"\")\nax0_sns.tick_params(length=0, labelsize=3)","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T15:50:39.113497Z","iopub.execute_input":"2022-06-30T15:50:39.11394Z","iopub.status.idle":"2022-06-30T15:50:44.796496Z","shell.execute_reply.started":"2022-06-30T15:50:39.113876Z","shell.execute_reply":"2022-06-30T15:50:44.795183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from geopy.geocoders import Nominatim\nfrom folium.plugins import HeatMap","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:31:29.139425Z","iopub.execute_input":"2022-06-30T16:31:29.139903Z","iopub.status.idle":"2022-06-30T16:31:29.146217Z","shell.execute_reply.started":"2022-06-30T16:31:29.139832Z","shell.execute_reply":"2022-06-30T16:31:29.144847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locations=pd.DataFrame({\"state\":districts['state'].unique()})\n\ngeolocator=Nominatim(user_agent=\"app\")\n\n#we need to get the latitude and longitude data\nlat=[]\nlon=[]\nfor location in locations['state']:\n    location = geolocator.geocode(location)    \n    if location is None:\n        lat.append(np.nan)\n        lon.append(np.nan)\n    else:\n        lat.append(location.latitude)\n        lon.append(location.longitude)\n        \nlocations['lat']=lat\nlocations['lon']=lon","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:31:33.253876Z","iopub.execute_input":"2022-06-30T16:31:33.254351Z","iopub.status.idle":"2022-06-30T16:31:45.417051Z","shell.execute_reply.started":"2022-06-30T16:31:33.254288Z","shell.execute_reply":"2022-06-30T16:31:45.415674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state_engagement = merged.groupby(['state'], as_index=False)['engagement_index'].mean()\n\n#merge the state engagement data with latidude and longitude\nfinal_loc = state_engagement.merge(locations,on='state',how=\"left\").dropna()\nfinal_loc","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:32:01.91579Z","iopub.execute_input":"2022-06-30T16:32:01.91625Z","iopub.status.idle":"2022-06-30T16:32:04.036129Z","shell.execute_reply.started":"2022-06-30T16:32:01.916213Z","shell.execute_reply":"2022-06-30T16:32:04.034865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import folium\nfrom folium import plugins\n\nus_map = folium.Map(location=[38,-97],zoom_start =5, tiles='Stamen Terrain')\n\nHeatMap(final_loc[['lat','lon','engagement_index']],zoom=20,radius=20).add_to(us_map)\naverage_engagement = plugins.MarkerCluster().add_to(us_map)\n\nfor lat, long, label, in zip(final_loc.lat, final_loc.lon, final_loc.engagement_index):\n    folium.Marker(\n        location=[lat,long],\n        icon=None,\n        popup=label,\n    ).add_to(average_engagement)\n\nus_map","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:32:08.986575Z","iopub.execute_input":"2022-06-30T16:32:08.98704Z","iopub.status.idle":"2022-06-30T16:32:09.047773Z","shell.execute_reply.started":"2022-06-30T16:32:08.987005Z","shell.execute_reply":"2022-06-30T16:32:09.046843Z"},"trusted":true},"execution_count":null,"outputs":[]}]}