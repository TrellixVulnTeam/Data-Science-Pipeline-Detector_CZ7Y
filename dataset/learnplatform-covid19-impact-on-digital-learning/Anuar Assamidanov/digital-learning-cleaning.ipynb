{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Data Clearning and Generation\n\nThis notebook walkthroughs how we cleaned and generated the data for the LearnPlatform COVID-19 Impact on Digital Learning. We used the data provided by the competition organizers. They have provided a set of daily edtech engagement data from over 200 school districts in 2020, and we leveraged other publicly available data on school closures and shelter-in-place orders in our analysis. We include three basic sets of files to help you get started:\n\n- The engagement_ data folder is based on LearnPlatformâ€™s Student Chrome Extension. The extension collects page load events of over 10K education technology products in our product library, including websites, apps, web apps, software programs, extensions, ebooks, hardwares, and services used in educational institutions. The engagement data have been aggregated at school district level, and each file represents data from one school district.\n- The products_info.csv file includes information about the characteristics of the top 372 products with most users in 2020.\n- The districts_info.csv file includes information about the characteristics of school districts, including data from NCES and FCC.\n- The polcy.csv includes information the dates of school closures and shelter-in-place orders\n\n","metadata":{}},{"cell_type":"code","source":"# importing packages and importing data\nimport datetime\nimport numpy as np\nimport pandas as pd\nproducts_info = pd.read_csv('/kaggle/input/learnplatform-covid19-impact-on-digital-learning/products_info.csv')\ndistricts_info = pd.read_csv('/kaggle/input/learnplatform-covid19-impact-on-digital-learning/districts_info.csv')\n# Data of state policies on school closures and shelter-in-place orders.\npolicy = pd.read_csv('/kaggle/input/policy/policy.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:58:37.464921Z","iopub.execute_input":"2021-09-30T17:58:37.466262Z","iopub.status.idle":"2021-09-30T17:58:37.492788Z","shell.execute_reply.started":"2021-09-30T17:58:37.466188Z","shell.execute_reply":"2021-09-30T17:58:37.492069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# subseting data by Prek-12 and the rest. We specified it digital learning platforms for kids and teen-adults\nhigher = products_info[(products_info['Sector(s)']=='PreK-12; Higher Ed; Corporate') | (products_info['Sector(s)']=='PreK-12; Higher Ed') | (products_info['Sector(s)']=='Higher Ed; Corporate')]\npre_k = products_info[products_info['Sector(s)']=='PreK-12']\npre_k.columns=['lp_id', 'URL', 'Product Name', 'Provider/Company Name', 'Sector(s)',\n       'Primary Essential Function']\nhigher.columns=['lp_id', 'URL', 'Product Name', 'Provider/Company Name', 'Sector(s)',\n       'Primary Essential Function']","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:58:38.411523Z","iopub.execute_input":"2021-09-30T17:58:38.412606Z","iopub.status.idle":"2021-09-30T17:58:38.422725Z","shell.execute_reply.started":"2021-09-30T17:58:38.412548Z","shell.execute_reply":"2021-09-30T17:58:38.421929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aggreagating data engagement data at school district level\ndf= pd.DataFrame()\nfor i in districts_info['district_id']:\n    df1 = pd.read_csv(f'/kaggle/input/learnplatform-covid19-impact-on-digital-learning/engagement_data/{i}.csv')\n    df1 = df1.groupby(by='time').agg({'lp_id':'count', 'pct_access':'mean', 'engagement_index':'sum'}).reset_index()\n    df1['district_id'] = i\n    df = pd.concat([df,df1])\ndf['time'] = df['time'].astype('datetime64[ns]')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:58:39.194378Z","iopub.execute_input":"2021-09-30T17:58:39.194801Z","iopub.status.idle":"2021-09-30T17:58:57.017089Z","shell.execute_reply.started":"2021-09-30T17:58:39.19477Z","shell.execute_reply":"2021-09-30T17:58:57.016195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# building dataset by extracting kids digital learning platforms from the engagement data that have been aggregated at school district level, \n# and each file represents data from one school district.\npre_k_sample= pd.DataFrame()\nfor i in districts_info['district_id']:\n    df1 = pd.read_csv(f'/kaggle/input/learnplatform-covid19-impact-on-digital-learning/engagement_data/{i}.csv')\n    df1 = pd.merge(df1, pre_k['lp_id'], on = 'lp_id')\n    df1 = df1.groupby(by='time').agg({'lp_id':'count', 'pct_access':'mean', 'engagement_index':'sum'}).reset_index()\n    df1['district_id'] = i\n    pre_k_sample = pd.concat([pre_k_sample,df1])\npre_k_sample['time'] = pre_k_sample['time'].astype('datetime64[ns]')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:58:57.018865Z","iopub.execute_input":"2021-09-30T17:58:57.019175Z","iopub.status.idle":"2021-09-30T17:59:14.716405Z","shell.execute_reply.started":"2021-09-30T17:58:57.019136Z","shell.execute_reply":"2021-09-30T17:59:14.714871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# building dataset by extracting teen-aduls digital learning platforms from the engagement data that have been aggregated at school district level, \n# and each file represents data from one school district.\nhigher_sample= pd.DataFrame()\nfor i in districts_info['district_id']:\n    df1 = pd.read_csv(f'/kaggle/input/learnplatform-covid19-impact-on-digital-learning/engagement_data/{i}.csv')\n    df1 = pd.merge(df1, higher['lp_id'], on = 'lp_id')\n    df1 = df1.groupby(by='time').agg({'lp_id':'count', 'pct_access':'mean', 'engagement_index':'sum'}).reset_index()\n    df1['district_id'] = i\n    higher_sample = pd.concat([higher_sample,df1])\nhigher_sample['time'] = higher_sample['time'].astype('datetime64[ns]')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:59:14.717633Z","iopub.execute_input":"2021-09-30T17:59:14.717891Z","iopub.status.idle":"2021-09-30T17:59:32.782078Z","shell.execute_reply.started":"2021-09-30T17:59:14.71786Z","shell.execute_reply":"2021-09-30T17:59:32.781302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cleaning policy dataset and edit errors\npolicy.columns = ['state', 'SC', 'SIP']\npolicy.loc[8, 'state'] = 'District Of Columbia'\npolicy.loc[6, 'SIP'] = '3/23/20'\npolicy.loc[43, 'SIP'] = '4/2/20'\npolicy.loc[policy.SIP =='0', 'SIP'] = np.nan\npolicy.loc[policy.SC =='0', 'SC'] = np.nan\npolicy['SC'] = policy['SC'].astype('datetime64[ns]')\npolicy['SIP'] = policy['SIP'].astype('datetime64[ns]')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:59:32.784614Z","iopub.execute_input":"2021-09-30T17:59:32.784939Z","iopub.status.idle":"2021-09-30T17:59:32.807629Z","shell.execute_reply.started":"2021-09-30T17:59:32.784889Z","shell.execute_reply":"2021-09-30T17:59:32.806655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merging working dataset with district info\ndf = pd.merge(df, districts_info, on ='district_id')\nhigher_sample = pd.merge(higher_sample, districts_info, on ='district_id')\npre_k_sample = pd.merge(pre_k_sample, districts_info, on ='district_id')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:59:32.811441Z","iopub.execute_input":"2021-09-30T17:59:32.811676Z","iopub.status.idle":"2021-09-30T17:59:32.851242Z","shell.execute_reply.started":"2021-09-30T17:59:32.811649Z","shell.execute_reply":"2021-09-30T17:59:32.850224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merging working dataset with policy dataset\ndf = pd.merge(df, policy, on = 'state', how = 'left')\ndf = df[(df['district_id'].notnull()) & (df['state'].notnull())]\nhigher_sample = pd.merge(higher_sample, policy, on = 'state', how = 'left')\nhigher_sample = higher_sample[(higher_sample['district_id'].notnull()) & (higher_sample['state'].notnull())]\npre_k_sample = pd.merge(pre_k_sample, policy, on = 'state', how = 'left')\npre_k_sample = pre_k_sample[(pre_k_sample['district_id'].notnull()) & (pre_k_sample['state'].notnull())]","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:59:32.852499Z","iopub.execute_input":"2021-09-30T17:59:32.852734Z","iopub.status.idle":"2021-09-30T17:59:32.97067Z","shell.execute_reply.started":"2021-09-30T17:59:32.852693Z","shell.execute_reply":"2021-09-30T17:59:32.969697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating dummies for when the state have policy intervention\ndf['treat_SC'] = 0\ndf['treat_SIP'] = 0\ndf.loc[df['SC'] <= df['time'], 'treat_SC'] = 1\ndf.loc[df['SIP'] <= df['time'], 'treat_SIP'] = 1\nhigher_sample['treat_SC'] = 0\nhigher_sample['treat_SIP'] = 0\nhigher_sample.loc[higher_sample['SC'] <= higher_sample['time'], 'treat_SC'] = 1\nhigher_sample.loc[higher_sample['SIP'] <= higher_sample['time'], 'treat_SIP'] = 1\npre_k_sample['treat_SC'] = 0\npre_k_sample['treat_SIP'] = 0\npre_k_sample.loc[pre_k_sample['SC'] <= pre_k_sample['time'], 'treat_SC'] = 1\npre_k_sample.loc[pre_k_sample['SIP'] <= pre_k_sample['time'], 'treat_SIP'] = 1","metadata":{"execution":{"iopub.status.busy":"2021-09-30T17:59:32.972089Z","iopub.execute_input":"2021-09-30T17:59:32.972322Z","iopub.status.idle":"2021-09-30T17:59:32.983944Z","shell.execute_reply.started":"2021-09-30T17:59:32.972295Z","shell.execute_reply":"2021-09-30T17:59:32.983253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# droping outliers that has few observations and unrealistic pct_access\ndf = df.drop(df[(df['lp_id']<10) & (df['pct_access']>5)].index.tolist()).reset_index(drop=True)\nhigher_sample = higher_sample.drop(higher_sample[(higher_sample['lp_id']<10) & (higher_sample['pct_access']>5)].index.tolist()).reset_index(drop=True)\npre_k_sample = pre_k_sample.drop(pre_k_sample[(pre_k_sample['lp_id']<10) & (pre_k_sample['pct_access']>5)].index.tolist()).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:16:58.602871Z","iopub.execute_input":"2021-09-30T19:16:58.603276Z","iopub.status.idle":"2021-09-30T19:16:58.631714Z","shell.execute_reply.started":"2021-09-30T19:16:58.603235Z","shell.execute_reply":"2021-09-30T19:16:58.630326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# exporting dataset\ndf.to_csv('learning.csv', index = False)\nhigher_sample.to_csv('learning_subset_higher.csv', index = False)\npre_k_sample.to_csv('learning_subset_pre_k.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}