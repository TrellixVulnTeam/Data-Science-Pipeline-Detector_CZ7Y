{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport plotly.express as px \nfrom glob import glob \nimport os \nimport time \nfrom IPython.display import display \nimport gc \nfrom wordcloud import WordCloud \nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\nfrom tqdm import tqdm \nimport scipy as sp \n\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans \nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport torch \nimport torch.nn as nn \nfrom torch.utils.data import DataLoader, Dataset ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-12T10:13:11.777862Z","iopub.execute_input":"2021-10-12T10:13:11.778181Z","iopub.status.idle":"2021-10-12T10:13:11.791011Z","shell.execute_reply.started":"2021-10-12T10:13:11.778151Z","shell.execute_reply":"2021-10-12T10:13:11.789661Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Select Use columns ","metadata":{}},{"cell_type":"code","source":"%time \n\ndistrics = pd.read_csv(\"../input/learnplatform-covid19-impact-on-digital-learning/districts_info.csv\", usecols=[\"district_id\", \"state\", \"locale\"])\nproduct = pd.read_csv(\"../input/learnplatform-covid19-impact-on-digital-learning/products_info.csv\", usecols=[\"LP ID\", \"Primary Essential Function\"])\ndistrics = districs.rename(columns={\"district_id\": \"id\"})\nproduct = product.rename(columns={\"LP ID\": \"lp id\"})\nengagement = pd.DataFrame()\n\ncount = 0 \nfor i, f in enumerate(glob(\"../input/learnplatform-covid19-impact-on-digital-learning/engagement_data/*.csv\")):\n    df = pd.read_csv(f)\n    df[\"id\"] = int(f.split(\"/\")[-1].split(\".\")[0])\n    engagement = pd.concat([engagement, df])\n    count += 1 \n    if count == 100:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:45:09.691273Z","iopub.execute_input":"2021-10-12T07:45:09.692659Z","iopub.status.idle":"2021-10-12T07:45:39.280259Z","shell.execute_reply.started":"2021-10-12T07:45:09.692605Z","shell.execute_reply":"2021-10-12T07:45:39.278747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(districs.isnull().sum().to_frame())\ndisplay(product.isnull().sum().to_frame())\ndisplay(engagement.isnull().sum().to_frame())","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:45:48.766455Z","iopub.execute_input":"2021-10-12T07:45:48.767287Z","iopub.status.idle":"2021-10-12T07:45:49.932516Z","shell.execute_reply.started":"2021-10-12T07:45:48.767232Z","shell.execute_reply":"2021-10-12T07:45:49.931537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## merge dataframe ","metadata":{}},{"cell_type":"code","source":"%%time\n\ndf = pd.merge(districs, engagement, how=\"right\", left_on=\"id\", right_on=\"id\")\ndf = pd.merge(df, product, how=\"left\", left_on=\"lp_id\", right_on=\"lp id\")\ndf.drop([\"lp id\", \"id\", \"lp_id\"], axis=1, inplace=True)\n\ndel districs, product, engagement\ngc.collect()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:45:51.853664Z","iopub.execute_input":"2021-10-12T07:45:51.854856Z","iopub.status.idle":"2021-10-12T07:46:03.363834Z","shell.execute_reply.started":"2021-10-12T07:45:51.854656Z","shell.execute_reply":"2021-10-12T07:46:03.362517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:46:03.36569Z","iopub.execute_input":"2021-10-12T07:46:03.366249Z","iopub.status.idle":"2021-10-12T07:46:03.372762Z","shell.execute_reply.started":"2021-10-12T07:46:03.366207Z","shell.execute_reply":"2021-10-12T07:46:03.37146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n'''\n時系列の型変換\n休日とコロナ感染開始日のフラグ\n\nmain/sub 作成\n\n'''\n\ndef split_essential_main(x):\n    if type(x) != list:\n        return \"missing\"\n    else:\n        return x[0]\n    \ndef split_essential_sub(x):\n    if type(x) != list or len(x) == 1:\n        return \"missing\"\n    else:\n        return x[1]\n        \n# datetime \ndf[\"time\"] = pd.to_datetime(df.time)\ndf[\"week\"] = df.time.dt.dayofweek \ndf[\"holiday\"] = df.week.apply(lambda x: 1 if x in [5, 6] else 0)\nd = pd.date_range(start=\"2020-01-01\", end=\"2020-01-19\")\ndf[\"is_pandemic\"] = df.time.apply(lambda x: 0 if x in d else 1)\ndf.drop(\"week\", axis=1, inplace=True)\n\n# primary essential functions \ndf[\"Primary Essential Function\"] = df[\"Primary Essential Function\"].fillna(\"missing\")\ndf[\"split\"] = df[\"Primary Essential Function\"].apply(lambda x: x.split(\"-\"))\ndf[\"main\"] = df.split.apply(split_essential_main)\ndf[\"sub\"] = df.split.apply(split_essential_sub)\ndf.drop(\"split\", axis=1, inplace=True)\n\ngc.collect()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:46:14.926808Z","iopub.execute_input":"2021-10-12T07:46:14.927193Z","iopub.status.idle":"2021-10-12T07:50:50.058362Z","shell.execute_reply.started":"2021-10-12T07:46:14.927157Z","shell.execute_reply":"2021-10-12T07:50:50.057422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Value counts EDA.","metadata":{}},{"cell_type":"markdown","source":"### main and sub value counts.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15, 6))\nax = axes.ravel()\n\nmain = df.main.value_counts()\nax[0].pie(x=main.values, labels=main.index)\nax[0].set_title(\"main counts\")\n\nsub = df[\"sub\"].value_counts().to_frame()\nsub.plot(kind=\"bar\", ax=ax[1])\nax[1].set_title(\"sub counts\")\n\ndel sub, main \ngc.collect()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:51:17.637392Z","iopub.execute_input":"2021-10-12T07:51:17.638971Z","iopub.status.idle":"2021-10-12T07:51:21.696403Z","shell.execute_reply.started":"2021-10-12T07:51:17.638913Z","shell.execute_reply":"2021-10-12T07:51:21.695233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sub count in a specific main ","metadata":{}},{"cell_type":"code","source":"def main_plot(df, n=10):\n    main = df.loc[df.main != \"missing\", \"main\"].unique()\n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    ax = axes.ravel()\n    \n    for i, m in enumerate(main):\n        x = df.loc[df.main == m, \"sub\"].value_counts().to_frame().sort_values(\"sub\", ascending=False)[:n]\n        x.plot(kind=\"bar\", ax=ax[i])\n        ax[i].set_title(f\"main={m}\")\n    del main \n    plt.suptitle(\"main vs sub counts.\", fontsize=16)\n    plt.tight_layout()\n\nmain_plot(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:51:26.968606Z","iopub.execute_input":"2021-10-12T07:51:26.969396Z","iopub.status.idle":"2021-10-12T07:51:37.761525Z","shell.execute_reply.started":"2021-10-12T07:51:26.969317Z","shell.execute_reply":"2021-10-12T07:51:37.760861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### locale and statement value counts.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(22, 6))\nax = axes.ravel()\n\nlocal = df.locale.value_counts()\nax[0].pie(x=local.values, labels=local.index, )\nax[0].set_title(\"locale value counts.\")\n\nstate = df.state.value_counts().to_frame()\nstate.sort_values(\"state\", ascending=False)[:10].plot(kind=\"bar\", ax=ax[1])\nax[1].set_title(\"Top 10k statement counts.\")\n\nstate.sort_values(\"state\", ascending=False)[-10:].plot(kind=\"bar\", ax=ax[2])\nax[2].set_title(\"Under 10k statement counts.\")\n\ndel state, local \ngc.collect()\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T06:05:38.538164Z","iopub.execute_input":"2021-10-12T06:05:38.538485Z","iopub.status.idle":"2021-10-12T06:05:44.576202Z","shell.execute_reply.started":"2021-10-12T06:05:38.538453Z","shell.execute_reply":"2021-10-12T06:05:44.574994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How well developed cities can be categorized by a particular locale ","metadata":{}},{"cell_type":"code","source":"%%time \n\ndef show_cloud(df):\n    local = df.loc[df.locale != \"missing\", \"locale\"].unique()\n    \n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    ax = axes.ravel()\n    for i, l in enumerate(local):\n        x = df.loc[df.locale == l, [\"state\"]]\n        if len(x) == 0: continue\n        word = WordCloud(width=1500, height=1100, background_color=\"white\", max_words=10).generate(\" \".join(x[\"state\"]))\n        ax[i].imshow(word)\n        ax[i].set_title(l)\n        ax[i].set_xticks([])\n        ax[i].set_yticks([])\n    plt.tight_layout()\n    \n    \ndf[\"locale\"] = df.locale.fillna(\"missing\")\ndf[\"state\"] = df.state.fillna(\"missing\")\nshow_cloud(df)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:53:44.731114Z","iopub.execute_input":"2021-10-12T07:53:44.732467Z","iopub.status.idle":"2021-10-12T07:54:29.683459Z","shell.execute_reply.started":"2021-10-12T07:53:44.732387Z","shell.execute_reply":"2021-10-12T07:54:29.682247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transition EDA ","metadata":{}},{"cell_type":"code","source":"def transition_all(df):\n    time = df.groupby(\"time\").mean().loc[:, [\"pct_access\", \"engagement_index\"]]\n    \n    fig, axes = plt.subplots(1, 2, figsize=(22, 6))\n    ax = axes.ravel()\n    time.drop(\"engagement_index\", axis=1).plot(ax=ax[0])\n    ax[0].set_title(\"pct_access\")\n    time.drop(\"pct_access\", axis=1).plot(ax=ax[1])\n    ax[1].set_title(\"engagement_index\")\n    plt.show()\n    gc.collect()\n    \n    \ndef transition_locale(df, is_access=True):\n    local = df.locale.unique()\n    fig, axes = plt.subplots(1, 2, figsize=(22, 6))\n    ax = axes.ravel()\n    for l in local:\n        x = df.loc[df.locale == l, [\"time\", \"pct_access\"]]\n        y = df.loc[df.locale == l, [\"time\", \"engagement_index\"]]\n        x.groupby(\"time\").mean().plot(ax=ax[0])\n        y.groupby(\"time\").mean().plot(ax=ax[1])\n    ax[0].legend(local)\n    ax[1].legend(local)\n    ax[0].set_title(\"access\")\n    ax[1].set_title(\"engagement\")\n    plt.show()\n    gc.collect()\n        \n    \ndef transition_locale_access_trand(df):\n    local = df.locale.unique()\n    fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n    ax = axes.ravel()\n    for i, l in enumerate(local):\n        x = df.loc[df.locale == l, [\"time\", \"pct_access\"]]\n        x[\"rolling_7\"] = x.groupby(\"time\")[\"pct_access\"].rolling(window=90).mean().reset_index(drop=True)\n        x.groupby(\"time\").mean().plot(ax=ax[i])\n        ax[i].set_title(f\"locale {l}\")\n        del x \n    plt.suptitle(\"locale classies pct_access trainsitin trends.\",fontsize=18)\n    plt.tight_layout()\n    gc.collect()\n    \n    \ndef transition_locale_engage_trand(df):\n    local = df.locale.unique()\n    fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n    ax = axes.ravel()\n    for i, l in enumerate(local):\n        x = df.loc[df.locale == l, [\"time\", \"engagement_index\"]]\n        x[\"rolling_7\"] = x.groupby(\"time\")[\"engagement_index\"].rolling(window=90).mean().reset_index(drop=True)\n        x.groupby(\"time\").mean().plot(ax=ax[i])\n        ax[i].set_title(f\"locale {l}\")\n        del x\n    plt.suptitle(\"locale classies engagement_index trainsitin trends.\", fontsize=18)\n    plt.tight_layout()\n    gc.collect()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:18:27.684215Z","iopub.execute_input":"2021-10-12T07:18:27.68457Z","iopub.status.idle":"2021-10-12T07:18:27.706734Z","shell.execute_reply.started":"2021-10-12T07:18:27.684535Z","shell.execute_reply":"2021-10-12T07:18:27.705315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### all locale and engagement and access","metadata":{}},{"cell_type":"code","source":"transition_all(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T06:28:38.49007Z","iopub.execute_input":"2021-10-12T06:28:38.490355Z","iopub.status.idle":"2021-10-12T06:28:39.741879Z","shell.execute_reply.started":"2021-10-12T06:28:38.490327Z","shell.execute_reply":"2021-10-12T06:28:39.741041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Locale dupicated ","metadata":{}},{"cell_type":"code","source":"transition_locale(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:17:34.58021Z","iopub.execute_input":"2021-10-12T07:17:34.58137Z","iopub.status.idle":"2021-10-12T07:17:38.784328Z","shell.execute_reply.started":"2021-10-12T07:17:34.581313Z","shell.execute_reply":"2021-10-12T07:17:38.783172Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### month vs engagement by holiday.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(22, 12))\nax = axes.ravel()\n\ndf[\"month\"] = df.time.dt.month\nsns.violinplot(data=df, x=\"month\", y=\"engagement_index\", hue=\"holiday\", ax=ax[0])\nax[0].set_title(\"engagement\")\nsns.violinplot(data=df, x=\"month\", y=\"pct_access\", hue=\"holiday\", ax=ax[1])\nax[1].set_title(\"pct_access\")\n\ndf.drop(\"month\", axis=1, inplace=True)\ngc.collect()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:55:51.222775Z","iopub.execute_input":"2021-10-12T07:55:51.223662Z","iopub.status.idle":"2021-10-12T07:56:35.264146Z","shell.execute_reply.started":"2021-10-12T07:55:51.223618Z","shell.execute_reply":"2021-10-12T07:56:35.262883Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Locale vs engagement and poc_access transition.","metadata":{}},{"cell_type":"code","source":"transition_locale_access_trand(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:18:30.529051Z","iopub.execute_input":"2021-10-12T07:18:30.529384Z","iopub.status.idle":"2021-10-12T07:18:35.200098Z","shell.execute_reply.started":"2021-10-12T07:18:30.529352Z","shell.execute_reply":"2021-10-12T07:18:35.19884Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transition_locale_engage_trand(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:05:09.892349Z","iopub.execute_input":"2021-10-12T07:05:09.892611Z","iopub.status.idle":"2021-10-12T07:05:14.736503Z","shell.execute_reply.started":"2021-10-12T07:05:09.892582Z","shell.execute_reply":"2021-10-12T07:05:14.732357Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"markdown","source":"### holiday and covid19 before after pandemic ","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(22, 10))\nax = axes.ravel()\n\nsns.barplot(data=df, x=\"holiday\", y=\"pct_access\", ax=ax[0])\nax[0].set_title(\"is holiday use access rate\")\ngc.collect()\n\nsns.barplot(data=df, x=\"holiday\", y=\"engagement_index\", ax=ax[1])\nax[1].set_title(\"is holiday use engagement_index rate\")\ngc.collect()\n\nsns.barplot(data=df, x=\"is_pandemic\", y=\"pct_access\", ax=ax[2])\nax[2].set_title(\"before aftere covid19 access rate\")\ngc.collect()\n\nsns.barplot(data=df, x=\"is_pandemic\", y=\"engagement_index\", ax=ax[3])\nax[2].set_title(\"before aftere covid19 engagement rate\")\ngc.collect()\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:46.330611Z","iopub.execute_input":"2021-10-12T07:28:46.33151Z","iopub.status.idle":"2021-10-12T07:31:25.748893Z","shell.execute_reply.started":"2021-10-12T07:28:46.331456Z","shell.execute_reply":"2021-10-12T07:31:25.747551Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On holidays and weekdays, weekdays are clearly larger. Surprisingly, there is less access before the pandemic due to the distribution before and after the corona.  This can be seen from the time series graph above, due to the fact that it was originally large in the city category. ","metadata":{}},{"cell_type":"markdown","source":"# Search for same state by sub \nThe similarity is calculated by putting together the count tables from the states and the subs used based on them. That is, you can split states that belong to similar classification categories. It also searches for aggregates from states that belong to similar categories. ","metadata":{}},{"cell_type":"code","source":"%%time\n\n'''\ncolumns: state \nindex: state \n\nused cosine calculate.\n'''\n\nstate_sub_count_df = pd.crosstab(df.state, df[\"sub\"])\ns = MinMaxScaler(feature_range=(0.0, 1.0))\ns_df = s.fit_transform(state_sub_count_df)\n\ndf_sparse = sp.sparse.csr_matrix(s_df)\ndf_sparse = cosine_similarity(df_sparse)\ndf_sparse = pd.DataFrame(df_sparse, columns=state_sub_count_df.index, index=state_sub_count_df.index)\ndel state_sub_count_df, s_df\ngc.collect()\ndf_sparse.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T08:04:08.473749Z","iopub.execute_input":"2021-10-12T08:04:08.474861Z","iopub.status.idle":"2021-10-12T08:04:13.136968Z","shell.execute_reply.started":"2021-10-12T08:04:08.474777Z","shell.execute_reply":"2021-10-12T08:04:13.135965Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"us_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\n\n\ndef find_similar_state(state_name: str, n: int=10):\n    x = df_sparse[[state_name]].sort_values(state_name, ascending=False)[1:n+1]\n    x.columns = [\"similar\"]\n    return x \n\n\ndef show_area(similar_state: pd.DataFrame, state_name: str):\n    similar_state[\"state\"] = similar_state.index\n    similar_state = similar_state.reset_index(drop=True)\n    similar_state[\"state_abbver\"] = similar_state.state.replace(us_state_abbrev)\n    \n    fig = go.Figure()\n    layout = dict(\n        title_text = f\"Search for similar ({state_name}) state top 10k\",\n        geo_scope='usa',\n    )\n\n    fig.add_trace(\n        go.Choropleth(\n            locations=similar_state.state_abbver,\n            zmax=1,\n            z = similar_state.similar,\n            locationmode = 'USA-states', \n            marker_line_color='white',\n            geo='geo',\n            colorscale=px.colors.sequential.Teal, \n        )\n    )\n\n    fig.update_layout(layout)   \n    fig.show()\n    \n    \ndef show_count_bar(similar_state: pd.DataFrame):\n    state = similar_state.index.to_list()\n    \n    fig, axes = plt.subplots(1, 2, figsize=(22, 6))\n    ax = axes.ravel()\n    main = df.loc[df.state.isin(state), [\"main\"]].value_counts()\n    ax[0].pie(x=main.values)\n    ax[0].legend(main.index)\n    sub = df.loc[df.state.isin(state), [\"sub\"]].value_counts().to_frame().sort_values(\"sub\", ascending=False)[:5].sort_values(\"sub\", ascending=True)\n    sub.plot(kind=\"barh\", ax=ax[1])\n        \n    ax[0].set_title(\"similar for main rate.\")\n    ax[1].set_title(\"similar for sub counts.\")\n    plt.tight_layout()\n    del main, sub \n    gc.collect()\n    \n    \ndef show_transition(similar_state: pd.DataFrame, state_name):\n#     similar_state = find_similar_state(state_name)\n    state = similar_state.index.to_list()[:5]\n    \n    fig, axes = plt.subplots(2, 3, figsize=(22, 12))\n    ax = axes.ravel()\n    \n    x = df.loc[df.state == state_name, [\"time\", \"engagement_index\"]]\n    x.groupby(\"time\").mean().plot(ax=ax[0])\n    ax[0].set_title(\"current state transition.\")\n    \n    for i, s in enumerate(state):\n        x = df.loc[df.state == s, [\"time\", \"engagement_index\"]]\n        x = x.groupby(\"time\").mean()\n        x.plot(ax=ax[i+1])\n        ax[i+1].set_title(f\"similaer state is {s}.\")\n        \n    plt.tight_layout()\n    del x \n    gc.collect()\n    \n    \ndef search_for_similar_plot(state_name: str, n: int=10):\n    similar_df = find_similar_state(state_name, n)\n    show_area(similar_df, state_name)\n    show_count_bar(similar_df)\n    show_transition(similar_df, state_name)\n    display(similar_df)\n    gc.collect()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T08:42:04.925082Z","iopub.execute_input":"2021-10-12T08:42:04.926549Z","iopub.status.idle":"2021-10-12T08:42:04.956392Z","shell.execute_reply.started":"2021-10-12T08:42:04.926491Z","shell.execute_reply":"2021-10-12T08:42:04.955097Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nsearch_for_similar_plot(\"Wisconsin\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T08:42:05.271846Z","iopub.execute_input":"2021-10-12T08:42:05.272199Z","iopub.status.idle":"2021-10-12T08:42:27.097244Z","shell.execute_reply.started":"2021-10-12T08:42:05.272162Z","shell.execute_reply":"2021-10-12T08:42:27.096235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search_for_similar_plot('North Carolina')","metadata":{"execution":{"iopub.status.busy":"2021-10-12T08:43:48.52328Z","iopub.execute_input":"2021-10-12T08:43:48.524578Z","iopub.status.idle":"2021-10-12T08:44:08.683554Z","shell.execute_reply.started":"2021-10-12T08:43:48.524519Z","shell.execute_reply":"2021-10-12T08:44:08.682521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The transition of group distribution by states with similar subs cannot be said to be very similar.\nRather, it seems to depend on the locale. ","metadata":{}},{"cell_type":"markdown","source":"# Predict tomorrow engagement_index\tby LSTM model.","metadata":{}},{"cell_type":"code","source":"%%time \n\nx = df.groupby(\"time\")[\"engagement_index\", \"pct_access\"].sum()\nx = x.rename(columns={\"engagement_index\": \"engagement_index_lag_1\", \"pct_access\": \"pct_access_lag_1\"})\nx[\"engagement_index\"] = x.engagement_index_lag_1.shift(-1)\n\nfor col in [\"engagement_index_lag_1\", \"pct_access_lag_1\"]:\n    x[col.split(\"_\")[0]+\"_lag_2\"] = x[col].shift(1).fillna(0)\n    x[col.split(\"_\")[0]+\"_lag_3\"] = x[col].shift(2).fillna(0)\n    x[col.split(\"_\")[0]+\"_lag_30\"] = x[col].shift(30).fillna(0)\n    x[col.split(\"_\")[0]+\"_rolling7\"] = x[col].rolling(window=7).mean().fillna(0).reset_index(drop=True)\n    x[col.split(\"_\")[0]+\"_rolling30\"] = x[col].rolling(window=30).mean().fillna(0).reset_index(drop=True)\nx = x.fillna(0)\nx.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T09:18:44.415278Z","iopub.execute_input":"2021-10-12T09:18:44.415646Z","iopub.status.idle":"2021-10-12T09:18:44.742598Z","shell.execute_reply.started":"2021-10-12T09:18:44.415614Z","shell.execute_reply":"2021-10-12T09:18:44.741426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DigitalDataset(Dataset):\n    def __init__(self, df):\n        n_span = 30 \n        train = df.iloc[:(-1)*(n_span+1), :]\n        val = df.iloc[(-1)*(n_span+1): -1, :]\n        test = df.iloc[(-1)*n_span:, :]\n        self.train = []\n        self.val = []\n        self.test = []\n        \n        x_train, x_val, x_test = train.drop(\"engagement_index\", axis=1), val.drop(\"engagement_index\", axis=1), test.drop(\"engagement_index\", axis=1)\n        y_train, y_val = train[[\"engagement_index\"]], val[[\"engagement_index\"]]\n        \n        x_train, x_val, x_test = self._scaler(x_train, x_val, x_test)\n        \n        for i in range(x_train.shape[0]-n_span):\n            input_data = {}\n            inputs = x_train[i:i+n_span]\n            inputs = torch.FloatTensor(inputs)\n            target = y_train.iloc[i+n_span]\n            target = torch.tensor(target, dtype=torch.float)\n            \n            input_data[\"inputs\"] = inputs \n            input_data[\"target\"] = target \n            self.train.append(input_data)\n            \n        for i in range(n_span):\n            input_data = {}\n            inputs_tr = x_train[(-1)*n_span+i:, :]\n            inputs_va = x_val[:i, :]\n            inputs = np.concatenate([inputs_tr, inputs_va])\n            inputs = torch.FloatTensor(inputs)\n            target = y_val.iloc[i]\n            target = torch.tensor(target, dtype=torch.float)\n            \n            input_data[\"inputs\"] = inputs \n            input_data[\"target\"] = target \n            self.val.append(input_data)\n            \n        input_data = {\"inputs\": torch.FloatTensor(x_test)}\n        self.test.append(input_data)\n        \n    def _scaler(self, tr, va, te):\n        rs = RobustScaler()\n        return rs.fit_transform(tr), rs.transform(va), rs.transform(te)\n    \n\nparams = {\n    \"hidden_dim\": 128, \n    \"input_size\": 12, \n}\n\n\nconfig = {\n    \"device\": \"cuda:0\" if torch.cuda.is_available() else \"cpu\", \n    \"batch_size\": 12, \n    \"epoch\": 1000, \n    \"lr\": 0.001\n    \n}\n    \nclass DigitalModel(nn.Module):\n    def __init__(self, input_size=params[\"input_size\"], hidden_dim=params[\"hidden_dim\"]):\n        super(DigitalModel, self).__init__()\n        self.hidden_dim = hidden_dim \n        self.lstm = nn.LSTM(input_size, hidden_dim, batch_first=True)\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim//2),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim//2, 1)\n        )\n        \n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = x[:, -1, :].view(-1, self.hidden_dim)\n        x = self.fc(x)\n        return x \n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T10:31:25.903641Z","iopub.execute_input":"2021-10-12T10:31:25.904737Z","iopub.status.idle":"2021-10-12T10:31:25.929241Z","shell.execute_reply.started":"2021-10-12T10:31:25.90468Z","shell.execute_reply":"2021-10-12T10:31:25.928244Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = DigitalDataset(x)\nprint(f\"input shape: {a.train[0]['inputs'].size()}\")\nprint(f\"target shape: {a.val[0]['target'].size()}\")\n\nnet = DigitalModel()\na = torch.rand(2, 30, 12)\ny = net(a)\nprint(f\"output shape: {y.size()}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T10:26:50.657166Z","iopub.execute_input":"2021-10-12T10:26:50.657514Z","iopub.status.idle":"2021-10-12T10:26:50.745825Z","shell.execute_reply.started":"2021-10-12T10:26:50.65748Z","shell.execute_reply":"2021-10-12T10:26:50.74406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(dl, model, criterion, optimizer, is_train=True):\n    total_loss = []\n    if is_train:\n        model.train()\n    else:\n        model.eval()\n        \n    for d in tqdm(dl):\n        x = d[\"inputs\"].to(config[\"device\"])\n        t = d[\"target\"].to(config[\"device\"])\n        \n        if is_train:\n            y = model(x)\n            loss = criterion(y.view(-1), t.view(-1))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        else:\n            with torch.no_grad():\n                y = model(x)\n                loss = criterion(y.view(-1), t.view(-1))\n                \n        total_loss.append(loss.item())\n        del x, t\n    total_loss = np.array(total_loss)\n    return np.mean(total_loss)\n\ndef val_fn(dl, model):\n    with torch.no_grad():\n        pred = []\n        for d in tqdm(dl):\n            x = d[\"inputs\"].to(config[\"device\"])\n\n            y = model(x)\n            y = y.squeeze().detach().cpu().numpy()\n            for yy in y:\n                pred.append(yy)\n            del x\n    return pred\n\ndef test_fn(dl, model):\n    with torch.no_grad():\n        pred = []\n        for d in tqdm(dl):\n            x = d[\"inputs\"].to(config[\"device\"])\n\n            y = model(x)\n            y = y.squeeze().detach().cpu().numpy()\n            pred.append(y.squeeze())\n    return pred\n\n\ndef mae(pred, corr):\n    return np.mean(np.abs(pred - corr))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-12T10:29:06.602817Z","iopub.execute_input":"2021-10-12T10:29:06.603185Z","iopub.status.idle":"2021-10-12T10:29:06.62396Z","shell.execute_reply.started":"2021-10-12T10:29:06.603151Z","shell.execute_reply":"2021-10-12T10:29:06.621454Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(train_dl, val_dl, debug=True):\n    model = DigitalModel()\n    criterion = nn.L1Loss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n    \n    best_model, best_loss = None, np.inf \n    \n    for e in range(1 if debug else config[\"epoch\"]):\n        ts = time.time()\n        loss_tr = train_fn(train_dl, model, criterion, optimizer)\n        val_tr = train_fn(val_dl, model, criterion, None, False)        \n        \n        if best_loss > val_tr:\n            best_model = model \n            best_loss = val_tr\n        now = time.time()\n        print(f\"epoch: {e+1} | tr loss: {loss_tr:.3f} | va loss: {val_tr:.3f} | dilation {now-ts}s | \")\n    print(f\"best val loss: {best_loss:.3f}\")\n    gc.collect()\n    return best_model \n\ndef predict(dl, model, is_test=False):\n    if is_test:\n        p = test_fn(dl, model)\n    else:\n        p = val_fn(dl, model)\n    return p \n","metadata":{"execution":{"iopub.status.busy":"2021-10-12T10:29:06.790323Z","iopub.execute_input":"2021-10-12T10:29:06.790652Z","iopub.status.idle":"2021-10-12T10:29:06.801927Z","shell.execute_reply.started":"2021-10-12T10:29:06.790622Z","shell.execute_reply":"2021-10-12T10:29:06.800697Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(df, debug):\n    data = DigitalDataset(df)\n    train, val, test = data.train, data.val, data.test \n    \n    train_dl = DataLoader(train, \n                         batch_size=config[\"batch_size\"],\n                         shuffle=False, drop_last=False)\n    val_dl = DataLoader(val, \n                         batch_size=config[\"batch_size\"], \n                         shuffle=False, drop_last=False)\n    test_dl = DataLoader(test, \n                         batch_size=1,\n                         shuffle=False, drop_last=False)\n    model = fit(train_dl, val_dl, debug)\n    predv = predict(val_dl, model, False)\n    predt = predict(test_dl, model, True)\n    \n    print(\"===================================================================================\")\n    print(f\"validation mae: {mae(predv, df.iloc[-31: -1, :]['engagement_index'].values.ravel())}\")\n    print(\"===================================================================================\")\n\n    print(f\"Expected to be {predt[0]} tomorrow \")\n    print(\"===================================================================================\")\n\n    \nif __name__ == \"__main__\":\n    main(x, False)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T10:31:29.740346Z","iopub.execute_input":"2021-10-12T10:31:29.740693Z","iopub.status.idle":"2021-10-12T10:42:27.729738Z","shell.execute_reply.started":"2021-10-12T10:31:29.740645Z","shell.execute_reply":"2021-10-12T10:42:27.728742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}