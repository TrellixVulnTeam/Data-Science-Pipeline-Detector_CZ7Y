{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pdpipe","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np  \n%matplotlib inline  \nfrom plotly import __version__ \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ninit_notebook_mode(connected=True)\ncf.go_offline()\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport glob\nimport missingno as msno\nimport datetime as dt\nimport pdpipe as pdp\nfrom typing import Tuple, List, Dict\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.offline","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# INTRODUCTION AND METHODOLOGY :\nCovid-19 has surely impacted many aspects of our daily habits. The crisis has reshaped many economical, social and, in our case of study, educational aspects. In this analysis, we are about to uncover how this crisis has affected e-learning baised on EdTech engagement data. \nWe will conduct it as below : \n        \n    Data preparing or missing values analysis and treatment,\n    Data exploration and visualisation,\n    \nFrom these steps, we will get mainly to know : \n       \n    Engagement's time evolution in the different states,\n    characteristics of the products the most loaded,\n    Any correlation that are to be found between the states' characteristics and how engaged they are, \n    \nIn between, we will get to know, despite of how engaged, or loaded, they are, the districts and products data to get to know this population more as below : \n    \n    \n    Top 10 providers, \n    Top primary essential function of the products,\n    Top locale and states,\n    How present are black and hispanic people in these states,\n    How large is the number of people having access to free or reduced lunch at school,\n    How much ressources are spent by student.\n\nOnce all the libraries have been downloaded, we download the data, one by one and do the primary exploration and the missing values handling :\n    \n    Product data first, \n    And then, district's data, \n    and finally the engagement data.","metadata":{}},{"cell_type":"markdown","source":"# Data exploration : \n## Products' Data :","metadata":{}},{"cell_type":"markdown","source":"The Product's data is made up of the following columns : \n\n| Name | Description |\n| :--- | :----------- |\n| LP ID| The unique identifier of the product |\n| URL | Web Link to the specific product |\n| Product Name | Name of the specific product |\n| Provider/Company Name | Name of the product provider |\n| Sector(s) | Sector of education where the product is used |\n| Primary Essential Function | The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled |\n","metadata":{}},{"cell_type":"code","source":"Product_data = pd.read_csv('../input/learnplatform-covid19-impact-on-digital-learning/products_info.csv', sep=',')\nProduct_data.head(5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Product_data.info()  ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Total number of entries (rows X columns) in the dataset\ntotal= Product_data.size\n    #Number of missing values per column\nmissingCount =  Product_data.isnull().sum()\n    #Total number of missing values\nmissing_tot = missingCount.sum()\n    # Calculate percentage of missing values\nprint('Total number of missing values for each column of dataframe: \\n \\b \\b \\b',missingCount)\nprint(\"The dataset contains\", round(((missing_tot/total) * 100), 2), \"%\", \"missing values\")\nprint('Total number of rows with at least one missing value column are ', Product_data[ Product_data.isnull().any(axis=1)].shape[0])\nprint('Percentage of rows with missing data ',round((( Product_data[ Product_data.isnull().any(axis=1)].shape[0]/ Product_data.shape[0])*100),2),'%\\n\\n')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not many missing datas on this one. Let's check if there are any correlations between the variables having missing values before going further.","metadata":{}},{"cell_type":"code","source":"ax = msno.heatmap(Product_data,figsize=(5,5))\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the sector's missing data and the primary essential function are 100% correlated, then we know we are about to drop only 21 lines out of 372 rows. Wich is trivial.","metadata":{}},{"cell_type":"code","source":"Product_data.dropna(inplace=True)\nProduct_data.isna().sum()\nProduct_data.rename(columns={'LP ID' : 'lp_id'}, inplace=True) # we will need it later on for the merge","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Product_data.info()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our data is handled for now, and ready for some exploration. ","metadata":{}},{"cell_type":"code","source":"print (\"in this data set,we have a number of unique sectors equal to \", Product_data['Sector(s)'].nunique(), \"wich are\", Product_data['Sector(s)'].unique())\nprint (\"we have a number of unique product's names equal to\" ,Product_data['Product Name'].nunique())\nprint (\"we have a number of unique provider's equal to \", Product_data['Provider/Company Name'].nunique(), \"we will get to know their names later on\",  )\nprint (\"we have a number of unique Primary Essential Function equal to \", Product_data['Primary Essential Function'].nunique(),\"we will get to know their names later on\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's discover some memorable names : the top ten !\n\n#### Provider/Company Name","metadata":{}},{"cell_type":"code","source":"df9=pd.DataFrame(Product_data['Provider/Company Name'].value_counts()).reset_index()\ndf9.rename(columns={'Provider/Company Name':'Number of products', 'index': 'Provider/Company Name'}, inplace= True)\ndf9 ['Percentage']=(df9['Number of products']/df9['Number of products'].sum())*100\ndf9.head (10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df9.head(20).iplot(kind='bar', x = 'Provider/Company Name', y = 'Number of products', xTitle ='Provider/Company Name', yTitle = 'Number of products', orientation = 'v', sortbars=False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Google LLC** is by far the most represented provider. For Google has built a developed offer in term of products throughout the years !\n#### Sectors :","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:04:07.440557Z","iopub.execute_input":"2021-09-25T11:04:07.441125Z","iopub.status.idle":"2021-09-25T11:04:07.453386Z","shell.execute_reply.started":"2021-09-25T11:04:07.441086Z","shell.execute_reply":"2021-09-25T11:04:07.451981Z"}}},{"cell_type":"code","source":"df8=pd.DataFrame(Product_data['Sector(s)'].value_counts()).reset_index()\ndf8.rename(columns = {'Sector(s)': 'Number of products', 'index':'Sector(s)'}, inplace = True)\ndf8 ['percentage']=(df8['Number of products']/df8['Number of products'].sum())*100\ndf8.head(10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df8.head(20).iplot(kind='bar', x = 'Sector(s)', y = 'Number of products', xTitle ='Sector(s)', yTitle = 'Number of products', orientation = 'v', sortbars=False)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prek-12, PreK-12; Higher Ed; Corporate**, PreK-12; Higher Ed are mainly the represented sectors. Schools were closed or partially closed actually.\n\n#### Primary Essential Function:","metadata":{}},{"cell_type":"code","source":"df7=pd.DataFrame(Product_data['Primary Essential Function'].value_counts()).reset_index()\ndf7.rename(columns = {'Primary Essential Function': 'Number of products', 'index':'Primary Essential Function'}, inplace = True)\ndf7 ['Percentage']=(df7['Number of products']/df7['Number of products'].sum())*100\ndf7.head(10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df7.head(20).iplot(kind='bar', x = 'Primary Essential Function', y = 'Number of products', xTitle ='Primary Essential Function', yTitle = 'Number of products', orientation = 'v', sortbars=False)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LC - Digital Learning Platforms**, LC - Sites, Resources & Reference, LC - Content Creation & Curation are the most represented essential functions by a percentage 44%.","metadata":{}},{"cell_type":"markdown","source":"#### Partial summary 1:\n\n    The missing values represent only 5% of the data set, so we dropped them. \n    We have 5 unique sectors and Prek-12, PreK-12; Higher Ed; Corporate, PreK-12; Higher Ed are mainly  represented.\n    We have 284 providers and 7% od the products are provided by Google LLC.\n    These products fulfill 35 unique primary essential functions and LC - Digital Learning Platforms, LC - Sites, Resources & Reference, LC - Content Creation & Curation are the functions of 44% of the products.","metadata":{}},{"cell_type":"markdown","source":"## Districts' Data : \n    \n    Let's handle the data district data the same way : \n    discover them, handle missing values and then explore it a little bit\n    \n    First dicovery : \n    \n    The district's data is made up of the following columns :\n    \n| Name | Description |\n| :--- | :----------- |\n| district_id | The unique identifier of the school district |\n| state | The state where the district resides in |\n| locale | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See [Locale Boundaries User's Manual](https://eric.ed.gov/?id=ED577162) for more information. |\n| pct_black/hispanic | Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data |\n| pct_free/reduced | Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data |\n| county_connections_ratio | `ratio` (residential fixed high-speed connections over 200 kbps in at least one direction/households) based on the county level data from FCC From 477 (December 2018 version). See [FCC data](https://www.fcc.gov/form-477-county-data-internet-access-services) for more information. |\n| pp_total_raw | Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district. |","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:04:07.54076Z","iopub.execute_input":"2021-09-25T11:04:07.541544Z","iopub.status.idle":"2021-09-25T11:04:07.557973Z","shell.execute_reply.started":"2021-09-25T11:04:07.541486Z","shell.execute_reply":"2021-09-25T11:04:07.556143Z"}}},{"cell_type":"code","source":"district_data = pd.read_csv('../input/learnplatform-covid19-impact-on-digital-learning/districts_info.csv',sep=',')\n\ndistrict_data.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"district_data.info()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Total number of entries (rows X columns) in the dataset\ntotal= district_data.size\n    #Number of missing values per column\nmissingCount =  district_data.isnull().sum()\n    #Total number of missing values\nmissing_tot = missingCount.sum()\n    # Calculate percentage of missing values\nprint('Total number of missing values for each column of dataframe: \\n \\b \\b \\b',missingCount)\nprint(\"The dataset contains\", round(((missing_tot/total) * 100), 2), \"%\", \"missing values\")\nprint('Total number of rows with at least one missing value column are ',district_data[ district_data.isnull().any(axis=1)].shape[0])\nprint('Percentage of rows with missing data ',round((( district_data[ district_data.isnull().any(axis=1)].shape[0]/ district_data.shape[0])*100),2),'%\\n\\n')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We cannot just drop off the equivalent of 62% of the data ! Let's check if tere are any correlations before we get to decide what to do !","metadata":{}},{"cell_type":"code","source":"ax = msno.heatmap(district_data,figsize=(5,5))\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If a state is missing then the locale and the percentage of black and hispanic would missing too. Since there no way to induce them from the known variable (taht's the reason why they were hidden), we will drop them.\nin fine, we drop the other rows with missing datas not to have our analysis biased by the filling them. ","metadata":{}},{"cell_type":"code","source":"district_data.dropna(axis=0, inplace=True)\ndistrict_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"in this data set,we have a number of unique districts equal to \", district_data['district_id'].nunique())\nprint (\"These districts belong to a number of unique states equal to\" ,district_data['state'].nunique())\nprint (\"we have a number of unique locale equal to \", district_data['locale'].nunique(), \"wich are\", district_data['locale'].unique())","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Per-pupil total expenditure :","metadata":{}},{"cell_type":"code","source":"df6=pd.DataFrame(district_data ['pp_total_raw'].value_counts()).reset_index()\ndf6.rename(columns={'pp_total_raw':'Number of districts','index':'interval_pp_total_raw'}, inplace= True)\ndf6 ['Percentage']=(df6['Number of districts']/df6['Number of districts'].sum())*100\ndf6.head(11)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df6.iplot(kind='bar', x='interval_pp_total_raw' , y='Number of districts',  xTitle = 'Interval expenditure per pupil', yTitle = 'Numbre of occurence')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource \nDatabase on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district. \n\n* 30% of the districts spend between 18.000 and 20.000 NERD$ and 32% spend between 8000 and 12000.\n\n#### county_connections_ratio:","metadata":{}},{"cell_type":"code","source":"df5=pd.DataFrame(district_data ['county_connections_ratio'].value_counts())\ndf5 ['percentage']=(df5['county_connections_ratio']/df5['county_connections_ratio'].sum())*100\n\ndf5.head(10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| county_connections_ratio | `ratio` (residential fixed high-speed connections over 200 kbps in at least one direction/households)\n based on the county level data from FCC From 477 (December 2018 version).\n \n * We can see that this variable isn't what make a difference between the different districts !","metadata":{}},{"cell_type":"markdown","source":"#### Precentage of students having access to free/reduced lunch :","metadata":{}},{"cell_type":"code","source":"df4=pd.DataFrame(district_data ['pct_free/reduced'].value_counts()).reset_index()\ndf4.rename(columns={'pct_free/reduced':'Number of districts','index':'interval_access_pct_free/reduced'}, inplace= True)\ndf4 ['Percentage']=(df4['Number of districts']/df4['Number of districts'].sum())*100\ndf4.head(10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.iplot(kind='bar', x= 'interval_access_pct_free/reduced' , y='Number of districts', theme='white', mode={'Number of districts' : 'bar','Percentage': 'markers'} , xTitle = 'Access_free/reduced lunch', yTitle = 'Numbre of occurence')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| pct_free/reduced | Percentage of students in the districts eligible for free or reduced-price \nlunch based on 2018-19 NCES data |\n\n* 80% of the districts have the percentage of students eligible for free or reduced-price between 0% and 80 %.\n\n#### Percentage of black/hispanic people :","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:04:07.79522Z","iopub.execute_input":"2021-09-25T11:04:07.795584Z","iopub.status.idle":"2021-09-25T11:04:07.808549Z","shell.execute_reply.started":"2021-09-25T11:04:07.795551Z","shell.execute_reply":"2021-09-25T11:04:07.80746Z"}}},{"cell_type":"code","source":"df3=pd.DataFrame(district_data ['pct_black/hispanic'].value_counts()).reset_index()\ndf3.rename(columns={'pct_black/hispanic' : 'Number of districts','index':'interval_pct_black/hispanic'}, inplace= True)\ndf3 ['percentage']=(df3['Number of districts']/df3['Number of districts'].sum())*100\ndf3.head(10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.iplot(kind='bar', x= 'interval_pct_black/hispanic' , y='Number of districts',  xTitle = 'interval_pct_black/hispanic', yTitle = 'Numbre of occurence')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| pct_black/hispanic | Percentage of students in the districts\n identified as Black or Hispanic based on 2018-19 NCES data |\n\n* 66% of the districts have between 0% and 20% of their population identifying themselves as black or hispanic.","metadata":{}},{"cell_type":"markdown","source":"#### States :","metadata":{}},{"cell_type":"code","source":"df2 = pd.DataFrame (district_data ['state'].value_counts()).reset_index()\ndf2.rename(columns={'state':'Number of districts','index':'States'}, inplace= True)\ndf2 ['Percentage']=(df2['Number of districts']/df2['Number of districts'].sum())*100\n\nk=0\nj=0\nwhile k <80 : \n    k=k+df2.at[j,\"Percentage\"]\n    j=j+1\n    \ndf2.head(j)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.iplot(kind='bar', x= 'States', y='Number of districts', xTitle = 'States', yTitle = 'Number of districts', orientation =\"v\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(j,'Districts constitute 80% of the districts represented in this sample and they are', df2[\"States\"][:j])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Areas :","metadata":{}},{"cell_type":"code","source":"df1=pd.DataFrame (district_data['locale'].value_counts()).reset_index()\ndf1.rename(columns={'locale' : 'Number of districts', 'index':'Locale'}, inplace= True)\ndf1 ['percentage']=(df1['Number of districts']/df1['Number of districts'].sum())*100\ndf1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.iplot(kind=\"bar\", x= 'Locale', y= 'Number of districts', xTitle = 'Locale', yTitle = 'Number of districts by locale')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| locale | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural.\n* 60% of the districts are in suburban areas \n* only 6% are in town","metadata":{}},{"cell_type":"markdown","source":"#### Partial summary 2 : \n    \nThe missing values represent more than 60% of the data set. We dropped all the rows that has a NaN value not to fill them and have a biased data. \nWe have a number of unique districts equal to  176.These districts belong to 23 states, dispesed onto 4 areas: Suburban, Rural, City and Town.\n\nSome numbers to keep in mind about this data set : \n    \n* 30% of the districts spend between 18.000 and 20.000 NERD$ and 32% spend between 8000 and 12000.\n* We can see that county_connections_ratio isn't what make a difference between the different districts !\n* 80% of the districts have the percentage of students eligible for free or reduced-price between 0% and 80 %.\n* 66% of the districts have between 0% and 20% of their population identifying themselves as black or hispanic.\n* 9 Districts constitute 80% of the districts represented in this sample and they are : Connecticut, Utah, Massachusetts,     Illinois, California, Ohio, New York, Indiana, Washington.\n* 60% of the districts are in suburban areas. \n* only 6% are in town.\n   ","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:12:29.682847Z","iopub.execute_input":"2021-09-25T11:12:29.683201Z","iopub.status.idle":"2021-09-25T11:12:33.523908Z","shell.execute_reply.started":"2021-09-25T11:12:29.683169Z","shell.execute_reply":"2021-09-25T11:12:33.523063Z"}}},{"cell_type":"markdown","source":"## Engagement's Data","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:50:27.564614Z","iopub.execute_input":"2021-09-29T10:50:27.565443Z","iopub.status.idle":"2021-09-29T10:50:27.569062Z","shell.execute_reply.started":"2021-09-29T10:50:27.5654Z","shell.execute_reply":"2021-09-29T10:50:27.568223Z"}}},{"cell_type":"markdown","source":"To make the kernel smoother, we handle missing values as soon as we download the engagement data. For the same reason mentionned above, we drop the NaN values. \n\nThe enagement Data has the following columns : \n\n| Name | Description |\n| :--- | :----------- |\n| time | date in \"YYYY-MM-DD\" |\n| lp_id | The unique identifier of the product |\n| pct_access | Percentage of students in the district have at least one page-load event of a given product and on a given day |\n| engagement_index | Total page-load events per one thousand students of a given product and on a given day |\n\n  ","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:38:12.502135Z","iopub.execute_input":"2021-09-25T15:38:12.502516Z","iopub.status.idle":"2021-09-25T15:38:12.508502Z","shell.execute_reply.started":"2021-09-25T15:38:12.502483Z","shell.execute_reply":"2021-09-25T15:38:12.507644Z"}}},{"cell_type":"code","source":"path = '../input/learnplatform-covid19-impact-on-digital-learning/engagement_data' \nall_engagement_data_paths = glob.glob(path + \"/*.csv\")\n\ntemporary = []\nall_engagement_data=pd.DataFrame()\n\nfor i in all_engagement_data_paths :\n    df=pd.read_csv(i)\n    district_id = i.split(\"/\")[4].split(\".\")[0]\n    df[\"district_id\"]=district_id\n    df.dropna(axis=0, inplace=True)\n    df[['Year', 'Month', 'Day']] = df.time.str.split('-', expand=True)\n    \n    temporary.append(df)\n    \n    \nall_engagement_data = pd.concat(temporary)\n\n\nall_engagement_data.isnull().sum()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_engagement_data.head()\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_engagement_data[\"lp_id\"]=all_engagement_data[\"lp_id\"].astype('str')\nprint (\"in this data set,we have a number of unique products equal to \", all_engagement_data['lp_id'].nunique())\nprint (\"These data covers from 01-01-2020 till 31-12-2020\")\nprint (\"and it concerns\", all_engagement_data['district_id'].nunique(), \"districts\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of unique products surpass the ones we have left after cleansing the product and district data. Studiying the engagement data alone won't be very helpfull. To get more insights let's merge the 3 data sets we've dowloded so far. ","metadata":{}},{"cell_type":"markdown","source":"# Merging time : ","metadata":{}},{"cell_type":"code","source":"Product_data[\"lp_id\"] = Product_data[\"lp_id\"].astype(float)\ndistrict_data[\"district_id\"] = district_data[\"district_id\"].astype(float)\nall_engagement_data['district_id']=all_engagement_data['district_id'].astype(float)\nall_engagement_data[\"lp_id\"]=all_engagement_data[\"lp_id\"].astype(float)\n\n\nmerge_df = pd.merge(all_engagement_data, district_data, on=\"district_id\")\nmerge_df = pd.merge(merge_df, Product_data, on=\"lp_id\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_df.head ()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data is ready !","metadata":{}},{"cell_type":"markdown","source":"# Timely based analysis : \n\nWe will focus on the engagement_index only since the pct_access is correlated to it.\nLet's see how engagement index has evolved by state throughout the whole studied period (2020). \nTo get rid off the dips generated by the weekends in terms of engagement_index, we will check how it evoluated from a month to another, instead of a day by day presentation. \n#### Map representation :","metadata":{}},{"cell_type":"code","source":"#agg_digi_learn_df = result_df[result_df[\"Primary Essential Function\"] == 'LC - Digital Learning Platforms']\nagg_engagement_data = merge_df.groupby([\"state\", \"time\"],as_index=False)[\"engagement_index\"].sum().reset_index()\n\n\ndef set_size(value):\n    '''\n    Takes the numeric value of a parameter to visualize on a map (Plotly Geo-Scatter plot)\n    Returns a number to indicate the size of a bubble for a country which numeric attribute value \n    was supplied as an input\n    '''\n    result = np.log(1+value/100)\n    if result < 0:\n        result = 0.001\n    return result\n\n\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\npipeline = pdp.PdPipeline([\n    pdp.ApplyByCols('engagement_index', set_size, 'size', drop=False),\n    pdp.MapColVals('state', us_state_abbrev)])\n\n\n\n\nagg_engagement_data_map = pipeline.apply(agg_engagement_data)\n\nagg_engagement_data_map.fillna(0, inplace=True)\n\n\n\nagg_engagement_data_map = agg_engagement_data_map.sort_values(by='time', ascending=True)\nagg_engagement_data_map.drop(['index'], axis = 1, inplace = True)\nagg_engagement_data_map.tail()\n\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter_geo(\n    agg_engagement_data_map, locations=\"state\", locationmode='USA-states',\n    scope=\"usa\",\n    color=\"engagement_index\", \n    size='size', hover_name=\"state\", animation_frame= pd.to_datetime(agg_engagement_data_map[\"time\"]).dt.month, \n    range_color= [0, 100000], \n    projection=\"albers usa\", \n    title='Engagement Index')\nfig.show ()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Graphic representation :","metadata":{}},{"cell_type":"code","source":"pipeline = pdp.PdPipeline([\n    pdp.ApplyByCols('engagement_index', set_size, 'size', drop=False)])\n\nagg_engagement_data = pipeline.apply(agg_engagement_data)\nagg_engagement_data_monthly = agg_engagement_data.drop(['size','index'], axis=1)\nagg_engagement_data_monthly['month'] = pd.to_datetime(agg_engagement_data[\"time\"]).dt.month\nagg_engagement_data_monthly.drop(['time'], inplace = True, axis =1)\nagg_engagement_data_monthly.head()\nagg_engagement_data_monthly_plot = agg_engagement_data_monthly.pivot_table(index= agg_engagement_data_monthly[\"state\"], columns= agg_engagement_data_monthly[\"month\"], values='engagement_index', aggfunc=sum)\nagg_engagement_data_monthly_plot.rename ({1 : 'January', 2:'February', 3:'March', 4:'April' , 5: 'May', 6:'June', 7:'July', 8:'August', 9:'September', 10:'October', 11:'November', 12:'December'}, axis=1, inplace = True)\nagg_engagement_data_monthly_plot.transpose().iplot()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Partial summary 3 : \nFrom both the map representation and the graphic one, we can deduce : \n\n* Engagement has progressed in the early 2020 untill the month of April when it reached its local maximum for that periode.\n* Engagement has decreased during June, July and for most of the states in August too. \n* Engagement data trend has started increasing in September to surpass April's maximum.\n* The engagement data has a steady evolution until the end of the year.\n* It slightly decreased in December\n\nAs we have seen below, the most used products belong to \"LC : Learning & Curriculum\" , followed by \"CM: Classroom Management\". they are therefore related to distance learning wich is closely impacted by these envents: \n\n* Emergency state on the federal level declared on the 13/03/2020,\n* Seasonal holidays and summer holidays (June, July and August),\n* Back to school season : Many districts didn't reopen in september but in October the trend has changed in October. Parents were also given a choice between in-person and distance instruction, knowing that an achievement gap was identified between these two modes. That is what explains the decrease between September and October-November and because of the gap between the student's results, we can assume that many parents have choosen the in-person instruction.\n* in December, the winter break could be the cause behind the slight decrease.\n\nThese events go by the trend et explain it mainly. \n\nSomething important to notice is that the engagement level dropping because of the winter break didn't reach the level of before the distance learning policies were implemented. \nSo let's uncover how and how much !","metadata":{}},{"cell_type":"markdown","source":"## Engagement's residual value :    \n\nFirst, let's check for the whole year : \n* What are the characteristics of the products the most used, \n* What are the states the most engaged. \n\nAnd then, let's check for the month of December :\n\n* what are the products that kept being used \n* The states that kept being engaged \n\n#### Engagement by provider/company name :","metadata":{}},{"cell_type":"code","source":"merge_data_provider_ranking = merge_df.groupby([\"Provider/Company Name\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nmerge_data_provider_ranking.drop(['index'], inplace = True, axis =1)\nmerge_data_provider_ranking['Percentage']= (merge_data_provider_ranking['engagement_index']/merge_data_provider_ranking['engagement_index'].sum())*100\nmerge_data_provider_ranking.sort_values ('engagement_index', ascending = False).head(5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Products_provided_by_insctructure_inc = Product_data[Product_data['Provider/Company Name']=='Instructure, Inc. ']\nlist(Products_provided_by_insctructure_inc['Product Name'])","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data_provider_ranking.sort_values ('engagement_index', ascending = False).head(5).iplot(kind='bar', x = 'Provider/Company Name', y = 'engagement_index', xTitle ='Provider/Company Name', yTitle = 'engagement_index', orientation = 'v', sortbars=False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In terms of engagement, **Google LLC** keeps being, by far, the first, followed, this time, by ***Instructure, Inc*** thought it doesn't provide many products (less than 0.8%). It provides, Canvas and Instructure. (Very known actually ! ) ","metadata":{}},{"cell_type":"markdown","source":"#### Engagement by sectors :","metadata":{}},{"cell_type":"code","source":"merge_data_Sector_ranking = merge_df.groupby([\"Sector(s)\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nmerge_data_Sector_ranking.drop(['index'], inplace = True, axis =1)\nmerge_data_Sector_ranking['Percentage']= (merge_data_Sector_ranking ['engagement_index']/merge_data_Sector_ranking ['engagement_index'].sum())*100\nmerge_data_Sector_ranking.sort_values ('engagement_index', ascending = False).head(5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data_Sector_ranking.sort_values ('engagement_index', ascending = False).head(5).iplot(kind='bar', x = 'Sector(s)', y = 'engagement_index', xTitle ='Sector(s)', yTitle = 'engagement_index', orientation = 'v', sortbars=False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PreK-12; Higher Ed; Corporate** takes the lead and switch places with PreK-12 ! ","metadata":{}},{"cell_type":"code","source":"merge_data_Primary_Essential_Function_ranking = merge_df.groupby([\"Primary Essential Function\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nmerge_data_Primary_Essential_Function_ranking.drop(['index'], inplace = True, axis =1)\nmerge_data_Primary_Essential_Function_ranking['Percentage']= (merge_data_Primary_Essential_Function_ranking ['engagement_index']/merge_data_Primary_Essential_Function_ranking['engagement_index'].sum())*100\nmerge_data_Primary_Essential_Function_ranking.sort_values ('engagement_index', ascending = False).head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data_Primary_Essential_Function_ranking.sort_values ('engagement_index', ascending = False).head(5).iplot(kind='bar', x = 'Primary Essential Function', y = 'engagement_index', xTitle ='Primary Essential Function', yTitle = 'engagement_index', orientation = 'v', sortbars=False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LC - Content Creation & Curation** takes the lead this time preceding by far ***LC - Digital Learning Platforms***, though only 10% (36 products) of the products represented in this data set has it as primary function. ","metadata":{}},{"cell_type":"markdown","source":"#### Engagement by state :","metadata":{}},{"cell_type":"code","source":"merge_data_State_ranking = merge_df.groupby([\"state\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nmerge_data_State_ranking.drop(['index'], inplace = True, axis =1)\nmerge_data_State_ranking['Percentage']= (merge_data_State_ranking['engagement_index']/merge_data_State_ranking['engagement_index'].sum())*100\nmerge_data_State_ranking.sort_values ('engagement_index', ascending = False).head(5)\n\nk=0\nj=0\nwhile k <80 : \n    k=k+merge_data_State_ranking.sort_values ('engagement_index', ascending = False).at[j,\"Percentage\"]\n    j=j+1\n    \nmerge_data_State_ranking.sort_values ('engagement_index', ascending = False).head(j)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data_State_ranking.sort_values ('engagement_index', ascending = False).head(5).iplot(kind='bar', x = 'state', y = 'engagement_index', xTitle ='state', yTitle = 'engagement_index', orientation = 'v', sortbars=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Illinois** now takes the lead and has switched places with ***Utah***. Indiana kept its third rank. ","metadata":{}},{"cell_type":"markdown","source":"### Let's check if something changed in December : ","metadata":{}},{"cell_type":"code","source":"agg_eng_data_partially = merge_df [['state', 'engagement_index', 'lp_id', 'Product Name', 'Provider/Company Name', 'Primary Essential Function', 'Month', 'Sector(s)']]\nagg_eng_data_december= agg_eng_data_partially[agg_eng_data_partially['Month'] == '12']\nagg_eng_data_december.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Engagement by provider :","metadata":{}},{"cell_type":"code","source":"agg_eng_data_december_products = agg_eng_data_december.groupby([\"Provider/Company Name\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nagg_eng_data_december_products.drop(['index'], inplace = True, axis =1)\ndf20 = agg_eng_data_december_products.sort_values ('engagement_index', ascending = False)\ndf20 ['Percentage']= (df20['engagement_index']/df20['engagement_index'].sum())*100\ndf20.head (10)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same trend ! ","metadata":{}},{"cell_type":"markdown","source":"#### Engagement by sectors :","metadata":{}},{"cell_type":"code","source":"agg_eng_data_december_products = agg_eng_data_december.groupby([\"Sector(s)\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nagg_eng_data_december_products.drop(['index'], inplace = True, axis =1)\ndf21 = agg_eng_data_december_products.sort_values ('engagement_index', ascending = False)\ndf21 ['Percentage']= (df21['engagement_index']/df21['engagement_index'].sum())*100\ndf21.head (10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same trend again !","metadata":{}},{"cell_type":"markdown","source":"#### Engagement by Primary Essential Function :","metadata":{}},{"cell_type":"code","source":"agg_eng_data_december_products = agg_eng_data_december.groupby([\"Primary Essential Function\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nagg_eng_data_december_products.drop(['index'], inplace = True, axis =1)\ndf22 = agg_eng_data_december_products.sort_values ('engagement_index', ascending = False)\ndf22 ['Percentage']= (df22['engagement_index']/df22['engagement_index'].sum())*100\ndf22.head (10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **LC - Content Creation & Curation** keeps being the first, \n* LC - Sites, Resources & Reference - Streaming is now second after being the fifth. Its share in terms of percentage has doubled.\n* SDO - Learning Management Systems (LMS) is now third instead of second \n* all the engagement-indexes have been divided by 5 to 10.","metadata":{}},{"cell_type":"markdown","source":"#### Engagement by states :","metadata":{}},{"cell_type":"code","source":"agg_eng_data_december_products = agg_eng_data_december.groupby([\"state\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nagg_eng_data_december_products.drop(['index'], inplace = True, axis =1)\ndf23 = agg_eng_data_december_products.sort_values ('engagement_index', ascending = False)\ndf23 ['Percentage']= (df23['engagement_index']/df23['engagement_index'].sum())*100\ndf23.head (10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same trend ! \nAll the engagement-indexes of the whole year were didided by 5 to 10 in December !","metadata":{}},{"cell_type":"markdown","source":"Let's check how the engagement index changed from January to December : ","metadata":{}},{"cell_type":"code","source":"agg_engagement_data_monthly_plot['ratio'] = (agg_engagement_data_monthly_plot['December']/agg_engagement_data_monthly_plot['January'])\nprint('The engagement_index has been multiplied by' , agg_engagement_data_monthly_plot['ratio'].min(), 'to', agg_engagement_data_monthly_plot['ratio'].max(), 'between January and December')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Partial summary 4: \n\nIn terms of engagement:\n* **Google LLC** keeps being, by far, the first, followed, this time, by ***Instructure, Inc*** thought it doesn't provide many products (less than 0.8%). It provides, Canvas and Instructure. (Very known actually ! ) \n* **PreK-12; Higher Ed; Corporate** takes the lead and switch places with PreK-12 ! \n* **LC - Content Creation & Curation** takes the lead this time preceding by far ***LC - Digital Learning Platforms***, thought only 10% (36 products) of the products represented in this data set has it as primary function. \n* **Illinois** now takes the lead and has switched places with ***Utah***. Indiana kept its third rank. \n\nThere is no particular change between the trend of the whole year and December. The residual engagement value is 5 to 10 times less than fall 2020 but is  multiplied by 1.14 to 4.75 between January and December.\n","metadata":{}},{"cell_type":"markdown","source":"## Are there any valuable correlations ?\nIn this part we check :\n\n* The possible correlations between the states' characteristics and the engagement index,\n\n#### Correlation table :","metadata":{}},{"cell_type":"code","source":"#we have spiltted columns like 'pct_black/hispanic', 'pct_free/reduced', 'county_connections_ratio' and 'pp_total_raw' into 2 different columns based on their maximum and minimum value\nmerge_df_corr = merge_df\n#'pct_black/hispanic'\nmerge_df_corr[['min_pct_black/hispanic','max_pct_black/hispanic']] = merge_df_corr['pct_black/hispanic'].str.split(\",\",expand=True)\nmerge_df_corr['min_pct_black/hispanic'] = merge_df_corr['min_pct_black/hispanic'].str.strip('[')\nmerge_df_corr['max_pct_black/hispanic'] = merge_df_corr['max_pct_black/hispanic'].str.strip('[')\n\n#'pct_free/reduced'\nmerge_df_corr[['min_pct_free/reduced','max_pct_free/reduced']] = merge_df_corr['pct_free/reduced'].str.split(\",\",expand=True)\nmerge_df_corr['min_pct_free/reduced'] = merge_df_corr['min_pct_free/reduced'].str.strip('[')\nmerge_df_corr['max_pct_free/reduced'] = merge_df_corr['max_pct_free/reduced'].str.strip('[')\n\n#'pp_total_raw'\nmerge_df_corr[['min_pp_total_raw','max_pp_total_raw']] = merge_df_corr['pp_total_raw'].str.split(\",\",expand=True)\nmerge_df_corr['min_pp_total_raw'] = merge_df_corr['min_pp_total_raw'].str.strip('[')\nmerge_df_corr['max_pp_total_raw'] = merge_df_corr['max_pp_total_raw'].str.strip('[')\n\n#Drop the original columns\nmerge_df_corr.drop(['pct_black/hispanic', 'pct_free/reduced', 'county_connections_ratio', 'pp_total_raw'], axis = 1, inplace = True)\n\n#Calculating averages \n\nmerge_df_corr['min_pp_total_raw'] = merge_df_corr['min_pp_total_raw'].astype(float)\nmerge_df_corr['max_pp_total_raw'] = merge_df_corr['max_pp_total_raw'].astype(float)\n\n\nmerge_df_corr['min_pct_free/reduced'] = merge_df_corr['min_pct_free/reduced'].astype(float)\nmerge_df_corr['max_pct_free/reduced'] = merge_df_corr['max_pct_free/reduced'].astype(float)\n\nmerge_df_corr['min_pct_black/hispanic'] = merge_df_corr['min_pct_black/hispanic'].astype(float)\nmerge_df_corr['max_pct_black/hispanic'] = merge_df_corr['max_pct_black/hispanic'].astype(float)\n\nmerge_df_corr[\"avg_pct_black/hispanic\"] = merge_df_corr[[\"min_pct_black/hispanic\", \"max_pct_black/hispanic\"]].mean(axis=1)\nmerge_df_corr[\"avg_pct_free/reduced\"] = merge_df_corr[[\"min_pct_free/reduced\", \"max_pct_free/reduced\"]].mean(axis=1)\nmerge_df_corr[\"avg_pp_total_raw\"] = merge_df_corr[[\"min_pp_total_raw\", \"max_pp_total_raw\"]].mean(axis=1)\n\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_df_corr.drop(['max_pct_black/hispanic','min_pct_black/hispanic', 'max_pct_free/reduced', 'min_pct_free/reduced', 'max_pp_total_raw', 'min_pp_total_raw'], axis=1).corr()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Partial summary 5 : \nLet's focus on the engagement_index : \n* it's unsurprisingly poisitively correlated to the pct_acces. \n* it's positively correlated to the expenditure per pupil. The more it's spent on a student's education, the more access to digital tools they have and hence their engagement-index goes up.\n* it's negatively correlated to the percentage of black or hispanic people. The higher is a district/state's avg_pct_black/hispanic, the lower is its engagement_index. This percentage is positively correlated with the expenditure per pupil and with the percentage of student having access to free/reduced lunch. Wich leads us to think that maybe the engagement isn't a question of expenditure only but of culture as well. .\n* it's negatively correlated the percentage of student having access to free/reduced lunch.","metadata":{}},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"markdown","source":"For this data set, we dropped all the NaN values not to have a biased annalysis. \n\nSome descriptive statistics : \n\n\n* We have 5 unique sectors and Prek-12, PreK-12; Higher Ed; Corporate, PreK-12; Higher Ed are mainly  represented.\n* We have 284 providers and 7% of the products are provided by Google LLC.\n* These products fulfill 35 unique primary essential functions and LC - Digital Learning Platforms, LC - Sites, Resources & Reference, LC   - Content Creation & Curation are the functions of 44% of the products.\n* We have a number of unique districts equal to 176.These districts belong to 23 states, dispersed onto 4 areas: Suburban, Rural, City and Town.\n* 30% of the districts spend between 18.000 and 20.000 NERD$ and 32% spend between 8000 and 12000.\n* The county_connections_ratio isn't what make a difference between the different districts,\n* 80% of the districts have the percentage of students eligible for free or reduced-price between 0% and 80 %.\n* 66% of the districts have between 0% and 20% of their population identifying themselves as black or hispanic.\n* 9 Districts constitute 80% of the districts represented in this sample and they are : Connecticut, Utah, Massachusetts, Illinois, California, Ohio, New York, Indiana, Washington.\n* 60% of the districts are in suburban areas.\n* only 6% of the districts are in town.\n\n\nEngagement progression through 2020 : \n\n* Engagement has progressed in the early 2020 until the month of April when it reached its local maximum for that periode.\n* Engagement has decreased during June, July and for most of the states in August too.\n* Engagemnt data trend has started increasing in September to surpass April's maximum.\n* The engagement data has a steady evolution until the end of the year.\n* It slightly decreased in December.\n\nThe most used products belong to \"LC : Learning & Curriculum\". they are therefore related to distance learning wich is closely impacted by these events:\n\n* Emergency state on the federal level declared on the 13/03/2020,\n* Seasonal holidays and summer holidays (June, July and August),\n* Back to school season : Many districts didn't reopen in september but in October the trend has changed in October. Parents were also given a choice between in-person and distance instruction, knowing that an achievement gap was identified between these two modes. That is what explains the decrease between September and October-November and because of the gap between the student's results, we can assume that many parents have choosen the in-person instruction.\n* in December, the winter break could be the cause behind the slight decrease.\n\nThese events explain the trend mainly. \n\nIn terms of engagement throughout the year : \n\n * Google LLC (27 products) keeps being, by far, the first, followed, this time, by Instructure, Inc thought it doesn't provide many products (less than 0.8%). It provides, Canvas and Instructure. (Very known actually ! )\n* PreK-12; Higher Ed; Corporate takes the lead and swich places with PreK-12 !\n* LC - Content Creation & Curation takes the lead this time preceding by far LC - Digital Learning Platforms, thought only 10% (36 products) of the products represented in this data set has it as primary function.\n* Illinois now takes the lead and has switched places with Utah. Indiana kept its third rank.\n\nSomething important to notice is that the engagement level dropping because of the winter break didn't reach the level of before the distance learning policies were implemented. The analysis showed that nothing changed in the consumer behaviour in terms of products downloaded during December, if not very slightly. The residual engagement value, in December, is 5 to 10 times less than fall 2020. However, it is multiplied by 1.14 to 4.75 compared to January's engagement's data.\n\n* The engagement_index is unsurprisingly poisitively correlated to the pct_acces,\n* it's positively correlated to the expenditure per pupil. The more it's spent on a student education, the more access to digital tools they have and hence their engagement-index goes up.\n* it's negatively correlated to the percentage of black or hispanic people. The higher is a district/state's avg_pct_black/hispanic, the lower is its engagement_index. This percentage is positively correlated with the expenditure per pupil and with the percentage of student having access to free/reduced lunch. Wich leads us to think that maybe the engagement isn't a question of expenditure only but of culture as well. \n* it's negatively correlated to the percentage of student having access to free/reduced lunch.","metadata":{}}]}