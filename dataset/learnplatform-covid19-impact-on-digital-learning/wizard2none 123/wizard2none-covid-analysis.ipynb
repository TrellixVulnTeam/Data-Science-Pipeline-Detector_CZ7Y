{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n* [Introduction](#introduction)\n* [Data Description](#data-description)\n* [Data Cleaning](#data-cleaning)\n* [Data Exploration](#data-exploration)\n* [Data Analysis](#data-analysis)\n* [Conclusions](#conclusions)\n* [Mentions](#mentions)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<a id=\"introduction\"></a>\n<h1 style=\"color:black;\">Introduction</h1>\n\nTBD -- add to later","metadata":{}},{"cell_type":"markdown","source":"<a id=\"data-description\"></a>\n<h1 style=\"color:black;\">Data Description</h1>\n\n<h2 style=\"color:blue;\">Competition Provided Dataset</h2>\nThe competition provided Engagement, District, and Product CSV data with the following fields.\n\n<h3 style=\"color:green;\">Engagement</h3>\n\n<table>\n<thead>\n<tr><th style=\"text-align: right;\">  </th><th>Name            </th><th>Description                                                                                                   </th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\"> 0</td><td>time            </td><td>date in &quot;YYYY-MM-DD&quot;                                                                                          </td></tr>\n<tr><td style=\"text-align: right;\"> 1</td><td>lp_id           </td><td>The unique identifier of the product                                                                          </td></tr>\n<tr><td style=\"text-align: right;\"> 2</td><td>pct_access      </td><td>Percentage of students in the district have at least one page-load event of a given product and on a given day</td></tr>\n<tr><td style=\"text-align: right;\"> 3</td><td>engagement_index</td><td>Total page-load events per one thousand students of a given product and on a given day                        </td></tr>\n</tbody>\n</table>\n\n<h3 style=\"color:green;\">District</h3>\n<table>\n<thead>\n<tr><th style=\"text-align: right;\">  </th><th>Name                  </th><th>Description                                                                                                                                                                                                                                                                             </th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\"> 0</td><td>district_id           </td><td>The unique identifier of the school district                                                                                                                                                                                                                                            </td></tr>\n<tr><td style=\"text-align: right;\"> 1</td><td>state                 </td><td>The state where the district resides in                                                                                                                                                                                                                                                 </td></tr>\n<tr><td style=\"text-align: right;\"> 2</td><td>locale                </td><td>NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User&#x27;s Manual for more information.                                                                                                         </td></tr>\n<tr><td style=\"text-align: right;\"> 3</td><td>pct_black/hispanic    </td><td>Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data                                                                                                                                                                                      </td></tr>\n<tr><td style=\"text-align: right;\"> 4</td><td>pct_free/reduced      </td><td>Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data                                                                                                                                                                             </td></tr>\n<tr><td style=\"text-align: right;\"> 5</td><td>countyconnectionsratio</td><td>ratio (residential fixed high-speed connections over 200 kbps in at least one direction/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.                                                                        </td></tr>\n<tr><td style=\"text-align: right;\"> 6</td><td>pptotalraw            </td><td>Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab&#x27;s National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.</td></tr>\n</tbody>\n</table>\n\n<h3 style=\"color:green;\">Product</h3>\n\n<table>\n<thead>\n<tr><th style=\"text-align: right;\">  </th><th>Name                      </th><th>Description                                                                                                                                                                                                                                                                                                                   </th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\"> 0</td><td>LP ID                     </td><td>The unique identifier of the product                                                                                                                                                                                                                                                                                          </td></tr>\n<tr><td style=\"text-align: right;\"> 1</td><td>URL                       </td><td>Web Link to the specific product                                                                                                                                                                                                                                                                                              </td></tr>\n<tr><td style=\"text-align: right;\"> 2</td><td>Product Name              </td><td>Name of the specific product                                                                                                                                                                                                                                                                                                  </td></tr>\n<tr><td style=\"text-align: right;\"> 3</td><td>Provider/Company Name     </td><td>Name of the product provider                                                                                                                                                                                                                                                                                                  </td></tr>\n<tr><td style=\"text-align: right;\"> 4</td><td>Sector(s)                 </td><td>Sector of education where the product is used                                                                                                                                                                                                                                                                                 </td></tr>\n<tr><td style=\"text-align: right;\"> 5</td><td>Primary Essential Function</td><td>The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning &amp; Curriculum, CM = Classroom Management, and SDO = School &amp; District Operations. Each of these categories have multiple sub-categories with which the products were labeled</td></tr>\n</tbody>\n</table>\n\n<h3 style=\"color:green;\">External Data Source: OxCGRT</h3>\n\nThe [Oxford Covid-19 Government Response Tracker (OxCGRT)](https://github.com/OxCGRT/covid-policy-tracker) collects systematic information on which governments have taken which measures, and when.\n\n\n**Data Coutesy:** Thomas Hale, Noam Angrist, Rafael Goldszmidt, Beatriz Kira, Anna Petherick, Toby Phillips, Samuel Webster, Emily Cameron-Blake, Laura Hallas, Saptarshi Majumdar, and Helen Tatlow. (2021). “A global panel database of pandemic policies (Oxford COVID-19 Government Response Tracker).” Nature Human Behaviour. https://doi.org/10.1038/s41562-021-01079-8","metadata":{}},{"cell_type":"markdown","source":"<a id=\"data-cleaning\"></a>\n<h1 style=\"color:black;\">Data Cleaning</h1> \n\nAfter loading the datasets performed the observations and clean up in the table below.  Of note:\n- Changed missing engagement_index values in to 0 (based upon definition of how value collected)\n- Changed missing pct_access values in to 0 (based upon definition of how value collected)\n\n<table>\n<thead>\n<tr><th style=\"text-align: right;\">  </th><th>Dataset   </th><th>Comment                                                                                   </th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\"> 0</td><td>District  </td><td>Number rows: 233                                                                          </td></tr>\n<tr><td style=\"text-align: right;\"> 1</td><td>District  </td><td>Percent rows with missing state: 24%                                                      </td></tr>\n<tr><td style=\"text-align: right;\"> 2</td><td>Product   </td><td>Number rows: 372                                                                          </td></tr>\n<tr><td style=\"text-align: right;\"> 3</td><td>Product   </td><td>Change column &#x27;LP ID&#x27; to &#x27;lp_id&#x27; to match engagement data                                 </td></tr>\n<tr><td style=\"text-align: right;\"> 4</td><td>Product   </td><td>Dropped 5% rows with missing sector information                                           </td></tr>\n<tr><td style=\"text-align: right;\"> 5</td><td>Product   </td><td>One Hot Encoded Sector(s) column                                                          </td></tr>\n<tr><td style=\"text-align: right;\"> 6</td><td>Product   </td><td>Split &#x27;Primary Essential Function&#x27; into &#x27;primary_function_main&#x27; and &#x27;primary_function_sub&#x27;</td></tr>\n<tr><td style=\"text-align: right;\"> 7</td><td>Engagement</td><td>Number rows: 22,324,190                                                                   </td></tr>\n<tr><td style=\"text-align: right;\"> 8</td><td>Engagement</td><td>engagement_index 5,378,409 missing data rows changed to 0                                 </td></tr>\n<tr><td style=\"text-align: right;\"> 9</td><td>Engagement</td><td>pct_access 13,447 missing data rows changed to 0                                          </td></tr>\n<tr><td style=\"text-align: right;\">10</td><td>Engagement</td><td>Dropped 24% rows missing engagement_index                                                 </td></tr>\n<tr><td style=\"text-align: right;\">11</td><td>Engagement</td><td>Dropped 0% rows missing district_id                                                       </td></tr>\n<tr><td style=\"text-align: right;\">12</td><td>Engagement</td><td>Dropped 20% rows that did not have max days                                               </td></tr>\n<tr><td style=\"text-align: right;\">13</td><td>Engagement</td><td>Dropped dropped(engagement) of rows not in districts table                                </td></tr>\n<tr><td style=\"text-align: right;\">14</td><td>Engagement</td><td>Overall dropped 39% of initial rows)                                                      </td></tr>\n</tbody>\n</table>\n","metadata":{}},{"cell_type":"code","source":"################################################\n# Libraries and cell globals\n################################################\nimport os\nfrom pathlib import Path\nimport glob\n\nimport re\nfrom io import StringIO\nfrom tabulate import tabulate\n\nfrom datetime import datetime\nfrom datetime import date\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as  plt\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm, Normalize\nplt.rcParams.update({'font.size': 14})\n\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n%matplotlib inline\n\nimport matplotlib.style as style\nstyle.use('seaborn-paper')\nstyle.use('seaborn-darkgrid')\n\n# Utility classes and functions used by data analysis\nclass FeedBack:\n    '''\n    Used to collect information and actions and add them to a \n    formatted table for display\n    '''\n    def __init__(self):\n        self.feedback = {'Dataset':[],\n                         'Comment':[]}\n        \n    def __call__(self, dataset, comment):\n        '''\n        Add a comment about dataset\n        ''' \n        self.feedback['Dataset'].append(dataset)\n        self.feedback[\"Comment\"].append(comment)\n        \n    def display(self, fmt = \"html\"):\n        ' Create formatted table'\n        return tabulate(pd.DataFrame(self.feedback),\n                       headers = \"keys\",\n                       tablefmt = fmt)\n    \n    def __str__(self):\n        return self.display()\n    \ndef to_datetime64(itime):\n    t = str(itime)   # time from int to string\n    return np.datetime64('-'.join([t[:4], t[4:6], t[6:]]))\n    \ndef convert_time(date):\n    #ts = pd.to_datetime(str(date)) \n    return ts.strftime('%y.%m.%d')\n\ndef dt_inplace(df):\n    \"\"\"Automatically detect and convert (in place!) each\n    dataframe column of datatype 'object' to a datetime just\n    when ALL of its non-NaN values can be successfully parsed\n    by pd.to_datetime().  Also returns a ref. to df for\n    convenient use in an expression.\n    \n    Source: https://towardsdatascience.com/auto-detect-and-set-the-date-datetime-datatypes-when-reading-csv-into-pandas-261746095361\n    \"\"\"\n    from pandas.errors import ParserError\n    for c in df.columns[df.dtypes=='object']: #don't cnvt num\n        try:\n            df[c]=pd.to_datetime(df[c])\n        except (ParserError,ValueError): #Can't cnvrt some...\n            pass # ...so leave whole column as-is unconvertd.\n    return df\n\ndef read_csv(filepath_or_buf,**kwargs):\n    \"\"\"Drop-in replacement for Pandas pd.read_csv. It invokes\n    pd.read_csv() (passing any keyword args) and then auto-\n    matically detects and converts each column whose datatype\n    is 'object' to a datetime just when ALL of the column's\n    non-NaN values can be successfully parsed by\n    pd.to_datetime(), and returns the resulting dataframe.\n    \n    Source: https://towardsdatascience.com/auto-detect-and-set-the-date-datetime-datatypes-when-reading-csv-into-pandas-261746095361\n    \"\"\"\n    return dt_inplace(pd.read_csv(filepath_or_buf,**kwargs))\n\ndef reduce_mem_usage(df, verbose = False):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    if verbose:\n        end_mem = df.memory_usage().sum() / 1024**2\n        print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \ndef key_sort_func(s):\n    '''\n    Sort key for strings for the form '[number1,number2['\n    returns (number1, number2)\n    '''\n    s = s.replace(']', '').replace('[', '')\n    arr = s.split(',')\n    try:\n        return tuple([int(i) for i in arr])\n\n    except ValueError:\n        try:\n            return tuple([float(i) for i in arr])\n\n        except ValueError:\n            return s\n\n        \ndef convert(s):\n    try:\n        return int(s)\n\n    except ValueError:\n        try:\n            return float(s)\n    \n        except ValueError:\n            try:\n                s = s.replace('[', '').replace(']', '')\n                arr = s.split(',')\n                return (float(arr[0]) + float(arr[-1]))/2.0\n\n            except ValueError:\n                return s\n\n##########################################\n# Annotate bar plots\n#-----------------------------------------\ndef show_values_on_bars(axs):\n    def _show_on_single_plot(ax):        \n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() / 2\n            _y = p.get_y() + p.get_height()\n            value = '{:.2f}'.format(p.get_height())\n            ax.text(_x, _y, value, ha=\"center\") \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\n        \n# Source: https://gist.github.com/rogerallen/1583593\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'Washington DC': 'DC',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\n# x-axis labels (for time plots)\npos = [ '2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01', \n           '2020-05-01', '2020-06-01', '2020-07-01', '2020-08-01',\n           '2020-09-01', '2020-10-01', '2020-11-01', '2020-12-01']\npos = [datetime.strptime(s, \"%Y-%m-%d\") for s in pos]\nlab = [ 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', \n           'July', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n\n#<------- End Libraries and Globals ---------------\n\n# Engagment Table\ns = '''Name\tDescription\ntime\tdate in \"YYYY-MM-DD\"\nlp_id\tThe unique identifier of the product\npct_access\tPercentage of students in the district have at least one page-load event of a given product and on a given day\nengagement_index\tTotal page-load events per one thousand students of a given product and on a given day\n'''\nprint('Engagement')\ndf = pd.read_csv(StringIO(s), sep = \"\\t\")\ndisplay(tabulate(df, headers = \"keys\", tablefmt=\"html\"))\nprint()\n\n# District Table\ns = '''Name\tDescription\ndistrict_id\tThe unique identifier of the school district\nstate\tThe state where the district resides in\nlocale\tNCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.\npct_black/hispanic\tPercentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data\npct_free/reduced\tPercentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\ncountyconnectionsratio\tratio (residential fixed high-speed connections over 200 kbps in at least one direction/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.\npptotalraw\tPer-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.'''\ndf = pd.read_csv(StringIO(s), sep = \"\\t\")\nprint('District')\ndisplay(tabulate(df, headers = \"keys\", tablefmt=\"html\"))\nprint()\n\n# Product\ns = '''Name\tDescription\nLP ID\tThe unique identifier of the product\nURL\tWeb Link to the specific product\nProduct Name\tName of the specific product\nProvider/Company Name\tName of the product provider\nSector(s)\tSector of education where the product is used\nPrimary Essential Function\tThe basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled'''\ndf = pd.read_csv(StringIO(s), sep = \"\\t\")\nprint('Product')\ndisplay(tabulate(df, headers = \"keys\", tablefmt=\"html\"))\nprint()\n\n# District Data Preprocessing \ndef dropped(df):\n    ' Percent dropped '\n    # n_rows from local context\n    global n_rows  # special case of using globals (discouraged)\n                  # but use since we want to update n_rows\n                  # while printing a string\n    result = f'{1 - df.shape[0]/n_rows:.0%}'\n    n_rows = df.shape[0]\n    return result\n    \ndistrict = read_csv(\"/kaggle/input/learnplatform-covid19-impact-on-digital-learning/districts_info.csv\")\n\n# Container for comments during data analysis\nfeedback = FeedBack()\nfeedback(\"District\", f'Number rows: {district.shape[0]:,}')\nfeedback(\"District\", \n                f'Percent rows with missing state: {district.state.isnull().sum()/len(district):.0%}')\n# Abbreviate state names\ndistrict['state'] = district['state'].map(lambda s: us_state_abbrev.get(s, np.nan))\n\n# Product Data Preprocessing\nproduct = read_csv(\"/kaggle/input/learnplatform-covid19-impact-on-digital-learning/products_info.csv\")\nfeedback(\"Product\",\n                f'Number rows: {product.shape[0]:,}')\nproduct = product.rename({'LP ID': 'lp_id'}, axis='columns')\nfeedback(\"Product\", \"Change column 'LP ID' to 'lp_id' to match engagement data\")\nn_rows = product.shape[0]\nproduct = product[product['Sector(s)'].notnull()]\nfeedback(\"Product\", f\"Dropped {dropped(product)} rows with missing sector information\")\n\n# One Hot Encoding of sectors\ntemp_sectors = product['Sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproduct = product.join(temp_sectors)\nproduct.drop(\"Sector(s)\", axis=1, inplace=True)\nfeedback(\"Product\", \"One Hot Encoded Sector(s) column\")\ndel temp_sectors\n\n# Add primary function\nproduct['primary_function_main'] = product['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproduct['primary_function_sub'] = product['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\nfeedback(\"Product\", \"Split 'Primary Essential Function' into 'primary_function_main' and 'primary_function_sub'\")\n\n# Synchronize similar values\nproduct['primary_function_sub'] = product['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproduct.drop(\"Primary Essential Function\", axis=1, inplace=True)\n\n# Engagement Data Preprocessing\npath = \"/kaggle/input/learnplatform-covid19-impact-on-digital-learning/engagement_data\"\nli = []\nfor filename in glob.glob(path + \"/*.csv\"):\n    df = read_csv(filename, index_col=None, header=0)\n    \n    # Add District from basename\n    df['district_id'] = int(os.path.basename(filename).split(\".\")[0])\n    \n    li.append(df)\n\nengagement = pd.concat(li, axis=0, ignore_index=True)\n\nfeedback(\"Engagement\", f'Number rows: {engagement.shape[0]:,}')\n\n# Change missing engagement and pct_access values to 0.0\nfeedback(\"Engagement\", f\"engagement_index {engagement['engagement_index'].isna().sum():,} missing data rows changed to 0\")\ndf['engagement_index'] = df['engagement_index'].fillna(0)\n  \nfeedback(\"Engagement\", f\"pct_access {engagement['pct_access'].isna().sum():,} missing data rows changed to 0\")\ndf['pct_access'] = df['pct_access'].fillna(0)\n\nn_rows = engagement.shape[0]\ninit_n_rows = n_rows\nengagement = engagement[engagement['engagement_index'].notna()]\nfeedback(\"Engagement\", f\"Dropped {dropped(engagement)} rows missing engagement_index\")\nengagement = engagement[engagement['district_id'].notna()]\nfeedback(\"Engagement\", f\"Dropped {dropped(engagement)} rows missing district_id\")\n# Drop districts without max number of days\n# Min/Max days of District\nday_counts = engagement.groupby('district_id').time.nunique()\n\n# Only keep district which have max number of school days\nmax_days = max(day_counts)\nday_counts = day_counts[day_counts==max_days]\n\nengagement = engagement[engagement['district_id'].isin(day_counts.index)]\nfeedback(\"Engagement\", f\"Dropped {dropped(engagement)} rows that did not have max days\")\n\ndel day_counts\n\n# Drop districts which are not in District\n# Some district ids in engagement are not in District\nengagement = engagement[engagement['district_id'].isin(district['district_id'].unique())]  \nfeedback(\"Engagement\", \"Dropped dropped(engagement) of rows not in districts table\")\nfeedback(\"Engagement\", f\"Overall dropped {1 - engagement.shape[0]/init_n_rows:.0%} of initial rows)\")\n                \nreduce_mem_usage(engagement)\n\n# Produce data for markup\ndisplay(feedback)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:28.378064Z","iopub.execute_input":"2021-09-30T18:13:28.378876Z","iopub.status.idle":"2021-09-30T18:13:50.963148Z","shell.execute_reply.started":"2021-09-30T18:13:28.37881Z","shell.execute_reply":"2021-09-30T18:13:50.962196Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data-exploration\"></a>\n<h3 style=\"color:blue;\">Data Exploration</h3>\n\nChecking overlap between Engagement, District, and Product data we have the findings in the table below.  Of note:\n* Engagement table only covered 19 states out of the 23 provided by District table\n* Engagement table uses 8,183 products but only 352 covered by Product table.\n* District table only has one district with a different county_connections_ratio, so can't use it as a separator.\n* Chart below shows large variations in district count per state\n\n<table>\n<thead>\n<tr><th style=\"text-align: right;\">  </th><th>Dataset   </th><th>Comment                                           </th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\"> 0</td><td>Engagement</td><td>Missing state for 2,763,001 rows out of 13,511,615</td></tr>\n<tr><td style=\"text-align: right;\"> 1</td><td>Engagement</td><td>Number states covered 19                          </td></tr>\n<tr><td style=\"text-align: right;\"> 2</td><td>Engagement</td><td>Number of different products used 8,183           </td></tr>\n<tr><td style=\"text-align: right;\"> 3</td><td>Product   </td><td>Number of products 352                            </td></tr>\n<tr><td style=\"text-align: right;\"> 4</td><td>District  </td><td>Number of states 23                               </td></tr>\n<tr><td style=\"text-align: right;\"> 5</td><td>District  </td><td>Attribute county_connections_ratio value counts [0.18, 1[    161\n[1, 2[         1                                                   </td></tr>\n</tbody>\n</table>","metadata":{"execution":{"iopub.status.busy":"2021-09-25T07:09:12.981059Z","iopub.execute_input":"2021-09-25T07:09:12.981377Z","iopub.status.idle":"2021-09-25T07:09:12.990025Z","shell.execute_reply.started":"2021-09-25T07:09:12.981343Z","shell.execute_reply":"2021-09-25T07:09:12.989003Z"}}},{"cell_type":"code","source":"fb = FeedBack()\n# Find number states covered by engagements\ndistricts_with_states = district[district.state.notna()]\nmapping = dict(zip(districts_with_states.district_id, \n                        districts_with_states.state))\n\nstates_covered = engagement[\"district_id\"].map(lambda s: mapping.get(s, np.nan))\nfb(\"Engagement\",\n   f\"Missing state for {states_covered.isna().sum():,} rows out of {engagement.shape[0]:,}\")\nfb(\"Engagement\",\n   f\"Number states covered {states_covered[states_covered.notna()].nunique():,}\")\n\n#fb(\"Engagement\", f\"Number states covered {n_states_engagement:,}\")\nfb(\"Engagement\", f'Number of different products used {engagement.lp_id.nunique():,}')\nfb(\"Product\", f'Number of products {product.shape[0]:,}')\nfb(\"District\", f'Number of states {district.state.nunique()}')\nfb(\"District\", \n   f'Attribute county_connections_ratio value counts {district.county_connections_ratio.value_counts().to_string()}')\n\n# States and Number of Districts\ndistricts_info_by_state = district.state.value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state', 'num_districts']\n\nplt.figure(figsize=(12, 6))\nchart = sns.barplot(x ='state', \n            y = 'num_districts', \n            data = districts_info_by_state,\n            palette = 'hls',\n            order = sorted(districts_info_by_state['state'].unique()),)\n\nchart.set_title('District Count by State')\nchart.set_xticklabels(chart.get_xticklabels(), rotation=30)\nchart.set_ylabel(\"Number of Districts\")\nchart.set_xlabel(\"State\")\n\n# annotation here\nfor p in chart.patches:\n             chart.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n                 ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n                 textcoords='offset points')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:13:50.965425Z","iopub.execute_input":"2021-09-30T18:13:50.965762Z","iopub.status.idle":"2021-09-30T18:14:00.779503Z","shell.execute_reply.started":"2021-09-30T18:13:50.965719Z","shell.execute_reply":"2021-09-30T18:14:00.778728Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate HTML table for Data Exploration\n# Copy/Pasted into Data Exploration Markup\nprint(fb)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:00.780789Z","iopub.execute_input":"2021-09-30T18:14:00.781037Z","iopub.status.idle":"2021-09-30T18:14:00.788305Z","shell.execute_reply.started":"2021-09-30T18:14:00.781007Z","shell.execute_reply":"2021-09-30T18:14:00.786792Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{"execution":{"iopub.status.busy":"2021-09-27T21:45:31.770054Z","iopub.execute_input":"2021-09-27T21:45:31.77031Z","iopub.status.idle":"2021-09-27T21:45:32.510263Z","shell.execute_reply.started":"2021-09-27T21:45:31.77028Z","shell.execute_reply":"2021-09-27T21:45:32.509227Z"}}},{"cell_type":"markdown","source":"<a id=\"data-analysis\"></a>\n<h1 style=\"color:black;\">Data Analysis</h1>\n\n<h2 style=\"color:blue;\">What is the picture of digital connectivity and engagement in 2020?</h2>\n\n<h3 style=\"color:green;\">Connectivity</h3>\n\nDistrict table has limited connectivity information.  It showed the same connectivity for 161 of the 162 districts, with a wide rande of connectivity (0.18 to 1).\n\n| county_connections_ratio | Count |\n| --- | --- |\n| [0.18, 1[ | 161 |\n| [1, 2[ | 1 |\n\n\nAn extenal [Source](https://quello.msu.edu/wp-content/uploads/2020/03/Broadband_Gap_Quello_Report_MSU.pdf) shows connectivity should be as follows.\n\n**High Speed Connectivity at Home**\n\n| Locale | Connectivity |\n| --- | --- |\n| small-town | 53% |\n|rural areas | 53% |\n| Suburbs |  77% |\n| Cities | 70% |\n\n**No Connectivity**\n\n| Locale | Connectivity |\n| --- | --- |\n| rural | 9% |\n| small towns | 6% |\n| suburbs | 4% |\n| Cities | 5% |\n\n<h3 style=\"color:green;\">Engagement</h3>\n\n<h2 style=\"color:blue;\">How does student engagement with online learning platforms relate to different geography?</h2>\n \n**Methodology**\n* Compute the mean online engagement for each state\n* Normalize the mean by the mean across all states\n\n**Results**\n\nChart below shows:\n* Large variation in relative online engagement across states\n* States which significantly exceeded average: AZ, CT, IL, IN, NY, OH\n* In particular, IL has 65% higher engagement than the average (i.e. 1.65 ratio).","metadata":{}},{"cell_type":"code","source":"# Only use districts with state information\nengage_district = engagement.merge(district[district.state.notna()])\n\n# Mean of District Engagements\nstate_avg = (engage_district\n            .groupby([\"time\", \"district_id\", \"state\"])[\"engagement_index\"]\n                    .sum().reset_index()\n                    .groupby([\"state\"])[\"engagement_index\"]\n                    .mean()).reset_index()\n\n# Normalize relative to mean\nstate_avg['engagement_index'] /= state_avg['engagement_index'].mean()\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\norder = sorted(state_avg.state.unique())\nsns.barplot(x = 'state', \n            y = 'engagement_index',\n           data = state_avg,\n           order = order,\n           ax = ax)\n\nax.axhline(1.)\nax.set_ylabel(f'Engagement Relative to Average')\nshow_values_on_bars(ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:00.789493Z","iopub.execute_input":"2021-09-30T18:14:00.789695Z","iopub.status.idle":"2021-09-30T18:14:04.973557Z","shell.execute_reply.started":"2021-09-30T18:14:00.789671Z","shell.execute_reply":"2021-09-30T18:14:04.972896Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"color:blue;\">Different Demographic context (e.g., race/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?</h2>\n\n**Methodology**\n* Calculate the mean of the engagement by district features (such as locale, pct_black/hispanic, etc.)\n* Compare the engagement for each category of the feature to the overall average\n\n**Result**\n\nThe different demographic factors available in the data are:\n* locale \n    - rural and suburban districts exceeds average\n    - rural exceeding cities is unexpected since it has lower connectivity overall than cities\n* pct_black/hispanic\n    - low percentage districts i.e. [0,.2[ and [.2,.4[) exceeded average\n* pct_free/reduced\n    - low percentage districts exceeds average i.e. [0,.2]\n* county_connections_ratio\n    - Not useful since all districts but one have same value that covers a wide range [.18,1[\n* pp_total_raw\n    - Engagement increased with spending\n    - One exception was [18000,20000[ which went down","metadata":{}},{"cell_type":"code","source":"########################################\n# Demographics\n#---------------------------------------    \ndef engage_by(engage_district, column_name, avg):\n    df =  (engage_district\n                    .groupby([\"time\", column_name, \"district_id\"])[\"engagement_index\"]\n                    .sum().reset_index()\n                    .groupby([\"time\", column_name])[\"engagement_index\"]\n                    .mean()\n                   .reset_index())\n    df['engagement_index'] /= avg\n    return df\n\nengage_district = engagement.merge(district)\n\n# Mean of District Engagements\navg = (engage_district\n            .groupby([\"time\", \"district_id\"])[\"engagement_index\"]\n                    .sum().reset_index()\n                    .groupby([\"district_id\"])[\"engagement_index\"]\n                    .mean()).mean()\n\n# Demographic features in district table\nfeatures = [feature for feature in district.columns \n            if feature not in (\"district_id\", \"state\")]\n    \nfig, axes = plt.subplots(len(features), \n                             1, \n                             sharex = False, \n                             sharey = False,\n                             figsize=(12, 20))\n\nfor ax, feature in zip(axes, features):\n    data = engage_by(engage_district, feature, avg)\n    order = sorted(data[feature].unique(), key = key_sort_func)\n    \n    sns.barplot(x = feature,\n        y = 'engagement_index',\n        data = data,\n        order = order,\n        ax = ax,\n        ci = None)\n    ax.axhline(1.)\n    ax.set_ylabel(f'Engagement Relative to Average')\n    \nshow_values_on_bars(axes)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:04.975319Z","iopub.execute_input":"2021-09-30T18:14:04.975986Z","iopub.status.idle":"2021-09-30T18:14:21.029022Z","shell.execute_reply.started":"2021-09-30T18:14:04.975953Z","shell.execute_reply":"2021-09-30T18:14:21.027769Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"color:blue;\">What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n</h2>\n\nExamine nationwide trend of engagements by the sectors:\n- Corporate\n- Higher Ed\n- K-12\n\nA 14 day moving average is applied to the sector data.\n\nA nationwide average is generated for many metrics of the OxGRT data.\n\n**Results**\nWe see that most OxGRT metrics increased drastically in March 2020.  This correlates with a rapid increase in online learning engagement across all three sectors.\n\n<h2 style=\"color:blue;\">Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?\n</h2>\n\n**Results**\n\nThe OxGRT data shows a large spike corresponding to a stimulus in July 2020.  There is not a correspondingly noticeable change in the trajectory for online learning in reaction to the stimulus.  This could be due to two things:\n*  Stimulus occurred in the summer when schools are less active\n*  Interestingly online learning also reduces in the summer for the corporate sector, which would have been assumed to be year round.\n\nComparing the national engagement we observe:\n* Engagements increased rapidly from March 2020 coinciding with OxGRT metrics such as \n    - school closing\n    - workspace closing\n    - etc.\n* Fiscal stimulus during July 2020 had no immediate effect on engagement\n* Online engagements were still high in Fall 2020\n    - Could reflect continued high level of public policy and public awareness as shown by the OxGRT data","metadata":{}},{"cell_type":"code","source":"################################################\n# Sector Engagements\n#-----------------------------------------------\nlp_id_corporate = product[product.sector_Corporate==1].lp_id\nlp_id_higher_ed = product[product.sector_HigherEd==1].lp_id\nlp_id_k12 = product[product[\"sector_PreK-12\"]==1].lp_id\n\nengagement_k12 = engagement[engagement.lp_id.isin(lp_id_corporate)]\nengagement_higher_ed = engagement[engagement.lp_id.isin(lp_id_higher_ed)]\nengagement_corporate = engagement[engagement.lp_id.isin(lp_id_k12)]\n\ndfs = [engagement_k12, engagement_higher_ed, engagement_corporate]\nsectors = ['k-12', 'higher_ed', 'corporate']\n\nplt.subplots(figsize=(8, 6))\nsns.set_theme(style=\"darkgrid\")\n\nfor sector, df in zip(sectors, dfs):\n    engagement_ = df[['time', 'district_id', 'engagement_index']].copy()\n    engagement_ = engagement_.groupby([\"district_id\",\"time\"])[\"engagement_index\"].sum().rename('total').reset_index() #to_frame('total')\n\n    engagement_ = engagement_.groupby(['time'])['total'].mean().rename('mean_').reset_index()\n    engagement_['rolling_mean'] = engagement_.mean_.rolling(7).mean()\n\n    # plot using rolling average\n    sns.lineplot( x = 'time',\n                 y = 'rolling_mean',\n                 data = engagement_,\n                 label = sector)\n\nplt.xlabel('Months of the year 2020')\n\nplt.xticks( pos, lab)\n  \nplt.ylabel('Engagement')\nplt.title('Engagement by Sector in 2020')\nplt.show()\n\n################################################\n# OxGRT Data\n#-----------------------------------------------\ndef int_to_date(idate):\n    s = str(idate)\n    return datetime(year=int(s[0:4]), \n                    month=int(s[4:6]), \n                    day=int(s[6:8]))\n\n# Load OxGRT data from local repository\n# Has been pre-filtered to just the USA\nopenings = pd.read_csv(\"/kaggle/input/opening-status/usa_school_opening.csv\")\n\n# Rename columns to names used by other data tables\nopenings.rename(columns = {'RegionName': 'state', \n                           'Date':'time'},  \n                inplace = True)\n\nopenings['state'] = openings.state.map(us_state_abbrev)\n\n# Districts with a state (only need district_id and state columns)\ndistrict_ = district[district.state.notna()][['district_id', 'state']]\n\n# Add state to engamgent\nengagement_ = engagement.merge(district_, on = [\"district_id\"])\n\n# Only use states which are in engagement dataset\nopenings = openings[openings.state.isin(engagement_.state.unique())]\n\n# Reduce memory usage\nreduce_mem_usage(openings)\ndel engagement_\n\ncriterias = [\"C1_School closing\",\n            \"C2_Workplace closing\",\n            \"C3_Cancel public events\",\n            \"C4_Restrictions on gatherings\",\n             \"E3_Fiscal measures\",\n            \"C5_Close public transport\",\n            \"C6_Stay at home requirements\",\n            \"C7_Restrictions on internal movement\",\n            \"E1_Income support\",\n            \"E2_Debt/contract relief\",\n            \"H1_Public information campaigns\",\n            \"H2_Testing policy\",\n            \"H3_Contact tracing\",\n            \"H4_Emergency investment in healthcare\",\n            \"H6_Facial Coverings\",\n            \"ConfirmedCases\",\n            \"ConfirmedDeaths\",\n            \"StringencyIndex\",\n            \"GovernmentResponseIndex\",\n            \"ContainmentHealthIndex\",\n            \"EconomicSupportIndex\",\n            \n    ]\n\ndef truncate_middle(s, n = 20):\n    if len(s) <= n:\n        # string is already short-enough\n        return s\n    s = s.replace('-', '').replace(' ', '').replace('_', '')\n    if len(s) <= n:\n        # string is already short-enough\n        return s\n    # first and last n/2 characters\n    n //= 2\n    return f'{s[:n]}{s[-n:]}'\n\nstart_date = 20200101 # Year/Mon/Date as integer\nend_date = 20201231\nmask = (openings['time'] >= start_date) & (openings['time'] <= end_date)\nopenings_ = openings[mask].copy()\n\nfig, axes = plt.subplots(len(criterias), \n                             1, \n                             sharex = False, \n                             sharey = False,\n                             figsize=(12, 4*len(criterias)))\n\nfor ax, criteria in zip(axes, criterias):\n    op_time = openings_.groupby(['time'])[criteria].mean().reset_index()\n    op_time['time'] = op_time.time.map(int_to_date)\n    sns.lineplot(x ='time', \n                 y = criteria, \n                 data = op_time,\n                 ax = ax)\n    ax.set_xticks(pos)\n    ax.set_xticklabels(lab)\n    ax.set_ylabel(truncate_middle(criteria))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:21.031169Z","iopub.execute_input":"2021-09-30T18:14:21.031536Z","iopub.status.idle":"2021-09-30T18:14:32.412113Z","shell.execute_reply.started":"2021-09-30T18:14:21.03149Z","shell.execute_reply":"2021-09-30T18:14:32.411102Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"color:blue;\">How does student engagement with different types of education technology change over the course of the pandemic?\n</h2>\n\n**Methodology**\n\nDerived the top 10 products per quarter based upon engagement for sectors as shown below.\n\n**Results**\n\n* K-12\n    - Biggest change was Zoom and Youtube joining the top products in the 2nd quarter of 2020 (Youtube joined the top 3)\n    - Interpretation was a lot of instruction started to be done online through zoom meeting and sharing instruction through youtube channels\n    \n* Higher-Ed\n    - Zoom and Youtube joined the top products in the 2nd quarter of 2020\n* Corporate\n    - Youtube and Meet were consistently joined the top 10 in 2nd quarter of 2020","metadata":{}},{"cell_type":"code","source":"lp_id_corporate = product[product.sector_Corporate==1].lp_id\nlp_id_higher_ed = product[product.sector_HigherEd==1].lp_id\nlp_id_k12 = product[product[\"sector_PreK-12\"]==1].lp_id\n\n# Lookup table for products by lp_ip\nlookup = dict(zip(product.lp_id, product[\"Product Name\"]))\n\nengagement_k12 = engagement[engagement.lp_id.isin(lp_id_corporate)]\nengagement_higher_ed = engagement[engagement.lp_id.isin(lp_id_higher_ed)]\nengagement_corporate = engagement[engagement.lp_id.isin(lp_id_k12)]\n\ndfs = [engagement_k12, engagement_higher_ed, engagement_corporate]\nsectors = ['k-12', 'higher_ed', 'corporate']\n\nn_keep = 10  # number of products to keep\nfor sector, df in zip(sectors, dfs):\n    engagement_ = df[['time', 'lp_id', 'engagement_index']].copy()\n    # https://stackoverflow.com/questions/43744990/aggregate-data-by-quarter\n    # accumulate engagement by quarter\n    by_qtr = (engagement_.groupby(['lp_id', pd.PeriodIndex(engagement_.time, freq='Q-DEC')])\n             .apply(lambda x: x['engagement_index'].sum()/x['time'].nunique())\n             .to_frame('avg').unstack('time')\n          ).stack().reset_index()\n    # top lp_id's by quarter\n    top = (by_qtr.groupby([\"time\", \"lp_id\"])[\"avg\"].sum().rename('total').reset_index()\n            .sort_values([\"time\", \"total\"], ascending = [True, False])\n            .groupby(\"time\").head(n_keep))\n    top['product'] = top.lp_id.map(lookup)   # map lp_id -> product\n    print(f\"Top 10 {sector} products by Quarter\")\n    \n    # Place products into list\n    top_products = top.groupby('time')['product'].apply(list).to_frame()\n    # Display as HTML\n    display(tabulate(top_products, headers=\"keys\", tablefmt=\"html\"))\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T18:14:32.413395Z","iopub.execute_input":"2021-09-30T18:14:32.413633Z","iopub.status.idle":"2021-09-30T18:14:39.605913Z","shell.execute_reply.started":"2021-09-30T18:14:32.413606Z","shell.execute_reply":"2021-09-30T18:14:39.605114Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"conclusions\"></a>\n<h1 style=\"color:black;\">Conclusions</h1>\n\n* COVID-19 has resulted in schools closures in 2020 with a mass migration to online learning for K-12, Higher Ed. and Corporations.\n\n* This effected some 48 million K-12 students and 12 million college students and an untold number of corporate students [Back-to-school statistics](https://nces.ed.gov/fastfacts/display.asp?id=372)\n\n* Analysis of the level of student online engagement showed differentiation in engagement based upon student demographics (i.e. locale, minority status, school district expenditure).  In particular:\n    - Some states had much higher engagements than the average (65% higher for example for Illinois)\n    - Minority and lower income neighborhoods had lower engagements\n    - Engagement was higher for school districts with larger per pupil spending\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"mentions\"></a>\n<h1 style=\"color:black;\">Mentions</h1>\n\n* Collaborators\n    - Florence Wilson of Team TBD\n* Mentions\n    - Approach Analytic Challenges by @Leonie","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:23:08.900617Z","iopub.execute_input":"2021-09-30T13:23:08.901477Z","iopub.status.idle":"2021-09-30T13:23:08.907225Z","shell.execute_reply.started":"2021-09-30T13:23:08.901432Z","shell.execute_reply":"2021-09-30T13:23:08.906455Z"}}}]}