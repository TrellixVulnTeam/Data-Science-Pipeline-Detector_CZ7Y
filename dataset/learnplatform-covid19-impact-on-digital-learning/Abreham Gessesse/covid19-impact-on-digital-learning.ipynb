{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-01T19:36:34.597508Z","iopub.execute_input":"2021-09-01T19:36:34.597903Z","iopub.status.idle":"2021-09-01T19:36:34.66358Z","shell.execute_reply.started":"2021-09-01T19:36:34.59787Z","shell.execute_reply":"2021-09-01T19:36:34.662452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Reading**","metadata":{}},{"cell_type":"code","source":"mata_data1_path = \"../input/learnplatform-covid19-impact-on-digital-learning/districts_info.csv\"\nmata_data2_path = \"../input/learnplatform-covid19-impact-on-digital-learning/products_info.csv\"\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:36:34.665589Z","iopub.execute_input":"2021-09-01T19:36:34.665955Z","iopub.status.idle":"2021-09-01T19:36:34.670427Z","shell.execute_reply.started":"2021-09-01T19:36:34.66592Z","shell.execute_reply":"2021-09-01T19:36:34.669128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_data1 = pd.read_csv(mata_data1_path)\nmeta_data2 = pd.read_csv(mata_data2_path)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:36:34.672226Z","iopub.execute_input":"2021-09-01T19:36:34.672628Z","iopub.status.idle":"2021-09-01T19:36:34.794196Z","shell.execute_reply.started":"2021-09-01T19:36:34.672588Z","shell.execute_reply":"2021-09-01T19:36:34.792982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Processing Engegement Data**","metadata":{}},{"cell_type":"markdown","source":"**Concatinating Engagement Data**","metadata":{}},{"cell_type":"markdown","source":"columns in Engagement Dataframe\n* time\n* lp_id\n* pct_access\n* engagement_index\n* district_id","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"engagement_Path = '../input/learnplatform-covid19-impact-on-digital-learning/engagement_data' \n\ntemp = []\n\nfor district in meta_data1.district_id.unique():\n    df = pd.read_csv(f'{engagement_Path}/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    temp.append(df)\n    \n    \nengagement_df = pd.concat(temp)\nengagement_df = engagement_df.reset_index(drop=True)\nengagement_df","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:36:34.795883Z","iopub.execute_input":"2021-09-01T19:36:34.796316Z","iopub.status.idle":"2021-09-01T19:36:55.874842Z","shell.execute_reply.started":"2021-09-01T19:36:34.796273Z","shell.execute_reply":"2021-09-01T19:36:55.873138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Missing Values**","metadata":{}},{"cell_type":"code","source":"engagement_df.isna()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:36:55.876247Z","iopub.execute_input":"2021-09-01T19:36:55.876524Z","iopub.status.idle":"2021-09-01T19:36:58.107551Z","shell.execute_reply.started":"2021-09-01T19:36:55.876487Z","shell.execute_reply":"2021-09-01T19:36:58.106547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Missing Values With in the column**","metadata":{}},{"cell_type":"code","source":"missing_value=engagement_df.isna().sum()\nmissing_value","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:36:58.109827Z","iopub.execute_input":"2021-09-01T19:36:58.110169Z","iopub.status.idle":"2021-09-01T19:37:00.455922Z","shell.execute_reply.started":"2021-09-01T19:36:58.110136Z","shell.execute_reply":"2021-09-01T19:37:00.455001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to calculate missing values by column\ndef missing_values_table(df):\n    # Total missing values\n    mis_val = engagement_df.isnull().sum()\n\n    # Percentage of missing values\n    mis_val_percent = 100 * engagement_df.isnull().sum() / len(df)\n\n    # dtype of missing values\n    mis_val_dtype = engagement_df.dtypes\n\n    # Make a table with the results\n    mis_val_table = pd.concat([mis_val, mis_val_percent, mis_val_dtype], axis=1)\n\n    # Rename the columns\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values', 2: 'Dtype'})\n\n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n\n    # Print some summary information\n    print (\"Your selected dataframe has \" + str(engagement_df.shape[1]) + \" columns.\\n\"      \n        \"There are \" + str(mis_val_table_ren_columns.shape[0]) + \" columns that have missing values.\")\n\n    # Return the dataframe with missing information\n    return mis_val_table_ren_columns\n\nprint(missing_values_table(engagement_df))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:00.457326Z","iopub.execute_input":"2021-09-01T19:37:00.457597Z","iopub.status.idle":"2021-09-01T19:37:05.178399Z","shell.execute_reply.started":"2021-09-01T19:37:00.457572Z","shell.execute_reply":"2021-09-01T19:37:05.177284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fill Missing Values**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nclass Clean_data:\n    \n    def __init__(self, df:pd.DataFrame):\n        self.df = df\n        \n    def Fiil_value(self, df: pd.DataFrame) -> pd.DataFrame:\n\n        try:\n            #df.dropna()\n            df.fillna(0,inplace = True)\n            #df.replace(to_replace = np.nan, value = 0 )\n        except:\n            pass\n        \n        return df\n\n    def drop_value(self, df:pd.DataFrame)->pd.DataFrame:\n\n\n        try:\n            df = df[df.state.notna()].reset_index(drop=True)\n            for column in df.columns:\n                df[column].fillna(df[column].mode()[0], inplace=True)\n            #df.dropna()\n        except:\n            pass\n\n        return df\n    def duplicates(self, df:pd.DataFrame)->pd.DataFrame:\n        try:\n            df.drop_duplicates(inplace=True)\n            \n        except:\n            pass\n        \n        return df","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:05.179885Z","iopub.execute_input":"2021-09-01T19:37:05.180191Z","iopub.status.idle":"2021-09-01T19:37:05.189134Z","shell.execute_reply.started":"2021-09-01T19:37:05.18016Z","shell.execute_reply":"2021-09-01T19:37:05.188191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**filling missing values with 0**","metadata":{}},{"cell_type":"code","source":"clean_meta_data1= Clean_data(engagement_df)\ndf = clean_meta_data1.Fiil_value(engagement_df)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:05.190599Z","iopub.execute_input":"2021-09-01T19:37:05.191125Z","iopub.status.idle":"2021-09-01T19:37:07.980351Z","shell.execute_reply.started":"2021-09-01T19:37:05.191078Z","shell.execute_reply":"2021-09-01T19:37:07.979493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Processing Districts Data**","metadata":{}},{"cell_type":"code","source":"mata_data1_path = \"../input/learnplatform-covid19-impact-on-digital-learning/districts_info.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:07.981527Z","iopub.execute_input":"2021-09-01T19:37:07.981999Z","iopub.status.idle":"2021-09-01T19:37:07.985399Z","shell.execute_reply.started":"2021-09-01T19:37:07.98195Z","shell.execute_reply":"2021-09-01T19:37:07.98464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"district_data = pd.read_csv(mata_data1_path)\ndistrict_data","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:07.986779Z","iopub.execute_input":"2021-09-01T19:37:07.987069Z","iopub.status.idle":"2021-09-01T19:37:08.024223Z","shell.execute_reply.started":"2021-09-01T19:37:07.987042Z","shell.execute_reply":"2021-09-01T19:37:08.023217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the District data contains the folowing columns \n* district_id\n* state\tlocale\n* pct_black/hispanic\n* pct_free/reduced\n* county_connections_ratio\n* pp_total_raw","metadata":{}},{"cell_type":"markdown","source":"**Missing value treatment**","metadata":{}},{"cell_type":"markdown","source":"filing missing values with mode of the cloumn","metadata":{}},{"cell_type":"code","source":"clean_meta_data1= Clean_data(district_data)\ndf = clean_meta_data1.drop_value(district_data)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:08.025736Z","iopub.execute_input":"2021-09-01T19:37:08.026164Z","iopub.status.idle":"2021-09-01T19:37:08.054715Z","shell.execute_reply.started":"2021-09-01T19:37:08.026009Z","shell.execute_reply":"2021-09-01T19:37:08.053929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Processing Product Data**","metadata":{}},{"cell_type":"code","source":"mata_data2_path = \"../input/learnplatform-covid19-impact-on-digital-learning/products_info.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:08.056054Z","iopub.execute_input":"2021-09-01T19:37:08.056612Z","iopub.status.idle":"2021-09-01T19:37:08.069033Z","shell.execute_reply.started":"2021-09-01T19:37:08.056569Z","shell.execute_reply":"2021-09-01T19:37:08.067892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"product_df = pd.read_csv(mata_data2_path)\n#rename column to merge\nproduct_data1 = product_df.rename({'LP ID':'lp_id'}, axis=1)\n# product_df\nproduct_data1","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:08.071504Z","iopub.execute_input":"2021-09-01T19:37:08.071837Z","iopub.status.idle":"2021-09-01T19:37:08.104405Z","shell.execute_reply.started":"2021-09-01T19:37:08.071807Z","shell.execute_reply":"2021-09-01T19:37:08.103209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(missing_values_table(product_data1))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:37.362183Z","iopub.execute_input":"2021-09-01T19:37:37.362544Z","iopub.status.idle":"2021-09-01T19:37:42.042915Z","shell.execute_reply.started":"2021-09-01T19:37:37.36251Z","shell.execute_reply":"2021-09-01T19:37:42.041867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we have 0 missing value in product_info dataframe","metadata":{}},{"cell_type":"markdown","source":"**Joining District_info and engagement datasets**","metadata":{}},{"cell_type":"code","source":"eng_dist_df = pd.merge(engagement_df,district_data, on = \"district_id\" )\neng_dist_pro_df = pd.merge(eng_dist_df,product_data1, on = \"lp_id\" )\neng_dist_pro_df ","metadata":{"execution":{"iopub.status.busy":"2021-09-01T19:37:48.967233Z","iopub.execute_input":"2021-09-01T19:37:48.96781Z","iopub.status.idle":"2021-09-01T19:38:11.560604Z","shell.execute_reply.started":"2021-09-01T19:37:48.967758Z","shell.execute_reply":"2021-09-01T19:38:11.559917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}