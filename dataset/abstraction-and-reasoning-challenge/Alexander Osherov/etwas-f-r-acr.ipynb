{"cells":[{"metadata":{},"cell_type":"markdown","source":"### This Notebook can solve 17 images from training data and 1 from evaluating data\n### I hope it will be helpful for somebody\n### Please upvote, if you like it"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom numba import jit, prange\nfrom skimage.transform import resize\n\nimport json\nimport os\nimport tqdm.notebook as tqdm\n\n#from tqdm import tqdm_notebook\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\n\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.tree import DecisionTreeClassifier as DT\n\nnp.seterr(divide='ignore', invalid='ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_path =  '/kaggle/input/abstraction-and-reasoning-challenge/training/'\nevaluation_path =  '/kaggle/input/abstraction-and-reasoning-challenge/evaluation/'\ntest_path =  '/kaggle/input/abstraction-and-reasoning-challenge/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = evaluation_path\n\n\nsame_shape = []\nfor ex in tqdm.tqdm(os.listdir(data_path)):# get exampels with same out- and input shape\n    with open(data_path + ex, 'r') as  train_file:\n        all_im = json.load(train_file)\n        im_in = np.array(all_im['train'][0]['input'])\n        im_out = np.array(all_im['train'][0]['output'])\n        if im_in.shape == im_out.shape:\n            same_shape.append(ex)\n            \nprint(\"Same:\",len(same_shape),\"All:\", len(os.listdir(data_path)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My model is only for same shape examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_im_with_same_ioshape(file_path, name, show=False, mode='train'):\n    train = []\n    test = []\n    \n    with open(file_path+name, 'r') as  train_file:\n        all_im = json.load(train_file)\n        im_in = np.array(all_im['train'][0]['input'])\n        im_out = np.array(all_im['train'][0]['output'])\n        \n        if im_in.shape != im_out.shape:\n            return None\n            \n        for im in all_im['train']:\n            \n            im_in = np.array(im['input'])\n            im_out = np.array(im['output'])\n            mask = np.asarray(np.nan_to_num((im_in-im_out)/(im_in-im_out), 0), 'int8')\n            train.append((im_in, im_out, mask))\n            \n            if show:\n                print(\"NAME:\\n\",name)\n                print(\"IN:\\n\")\n                plt.imshow(im_in)\n                plt.show()\n                print(\"OUT:\\n\")\n                plt.imshow(im_out)\n                plt.show()\n                print(\"MASK:\\n\")\n                plt.imshow(mask)\n                plt.show()\n                \n        if mode=='train':\n            for im in all_im['test']:\n\n                im_in = np.array(im['input'])\n                im_out = np.array(im['output'])\n                test.append((im_in, im_out))\n        if mode=='test':\n            for im in all_im['test']:\n\n                im_in = np.array(im['input'])\n                test.append((im_in))\n            \n      \n    return train, test\n               \ntrain, test = get_im_with_same_ioshape(data_path,same_shape[0], show=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Mask is binarised difference between input and output \n* Features are pixels around mask's pixels\n* Targets are colors of output image under mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"#@jit(nopython=False)\ndef get_features(input_, flipping=False, rotate=False, center=True, da=1):#get features form ech pixels\n                                        # a1   a2   a3\n                                        # a4   pix  a5\n                                        # a6   a7   a8\n    im_in,im_out, mask = input_\n    size=sum(sum(mask))\n    \n    if flipping:\n        size*=4\n    if rotate:\n        size*=(7/4)\n        size = int(size)\n        \n    features = np.zeros((size,9))\n    colors = np.zeros(size)\n    f=0\n    for y in range(mask.shape[0]):\n        for x in range(mask.shape[1]):\n\n            if mask[y,x]==1:\n                pix_exp = np.zeros((2*da+1)**2)\n                n_p=0\n                for dy in range(-da,da+1):\n                    for dx in range(-da,da+1):\n                        \n                        if dy!=0 or dx!=0:\n                            if dx+x>=0 and dy+y>=0 and dx+x<mask.shape[1] and dy+y<mask.shape[0]:\n                                pix_exp[n_p]=im_in[y+dy, x+dx]\n                            else:\n                                pix_exp[n_p]=-1\n                        else:\n                            if center:\n                                pix_exp[n_p]=im_in[y, x]#-2\n                            else:\n                                pix_exp[n_p]=-2\n                        \n                        n_p+=1\n\n                features[f] = pix_exp\n                colors[f] = im_out[y, x]\n                f+=1\n                \n                if flipping:\n                    features[f] = np.flipud(pix_exp.reshape(3,3)).flatten()\n                    colors[f] = im_out[y, x]\n                    f+=1\n                    features[f] = np.fliplr(pix_exp.reshape(3,3)).flatten()\n                    colors[f] = im_out[y, x]\n                    f+=1\n                    features[f] = np.flip(pix_exp.reshape(3,3), (0, 1)).flatten()\n                    colors[f] = im_out[y, x]\n                    f+=1\n                if rotate:\n                    features[f] = np.rot90(pix_exp.reshape(3,3), 1).flatten()\n                    colors[f] = im_out[y, x]\n                    f+=1\n                    features[f] = np.rot90(pix_exp.reshape(3,3), 2).flatten()\n                    colors[f] = im_out[y, x]\n                    f+=1\n                    features[f] = np.rot90(pix_exp.reshape(3,3), 3).flatten()\n                    colors[f] = im_out[y, x]\n                    f+=1\n                \n    return features, colors\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Many features are repeated"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"@jit(nopython=False)\ndef get_cf(train, flipping=False, rotate=False, center=True):#mining features from each train example and stacking of them\n    features_set = []\n    colors_set = []\n\n    for in_out_mask in train:\n        features, colors = get_features(in_out_mask, flipping, rotate, center)\n        features_set+=list(features)\n        colors_set+=list(colors)\n    \n    features_set_min = np.unique(np.array(features_set), axis = 0)\n    colors_min = np.zeros(len(features_set_min))\n    \n    for n, feature in enumerate(features_set):#ToDo make adequater\n            for i ,feature_uniq in enumerate(features_set_min):\n                if str(feature_uniq)==str(feature):\n                    colors_min[i]=colors_set[n]\n                    break\n\n            \n    return colors_min, features_set_min\n\ncolors_min, features_set_min = get_cf(train,  flipping=False, rotate=False, center=True)\nprint(colors_min)\nprint(features_set_min)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* For prediction you can use many ML algoritms(KNN, DecisionTree, RandomForest or None(exact match between pixel's feature and features from training exampels))"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#@jit(nopython=False)\ndef make_pred(im_in, features, colors, it=1, solver=None, center=True):  \n    if solver==\"KNN\":\n            model = KNN(2)\n            model.fit(X=features, y=colors)\n    elif solver==\"RF\":\n            model = RF()\n            model.fit(X=features, y=colors)\n    elif solver==\"DT\":\n            model = DT()\n            model.fit(X=features, y=colors)\n    \n        \n\n    for epoch in range(it):\n        im_out = im_in.copy()\n        f=0\n        for y in range(im_in.shape[0]):\n            for x in range(im_in.shape[1]):\n\n                pix_exp = np.zeros(9)\n                n_p=0\n                for dy in range(-1,2):\n                    for dx in range(-1,2):\n\n                        if dy!=0 or dx!=0:\n\n                            if dx+x>=0 and dy+y>=0 and dx+x<im_in.shape[1] and dy+y<im_in.shape[0]:\n                                pix_exp[n_p]=im_in[y+dy, x+dx]\n                            else:\n                                pix_exp[n_p]=-1\n                        else:\n                            if center:\n                                pix_exp[n_p]=im_in[y, x]#-2\n                            else:\n                                pix_exp[n_p]=-2\n\n                        n_p+=1\n                        \n                if solver==None:\n                    for n, f in enumerate(features):\n                        if str(f)==str(pix_exp):\n                            im_out[y,x]=colors[n]\n                else:\n                    im_out[y,x]=model.predict([pix_exp])\n                        \n                        \n                        \n        \n        im_in=im_out.copy()\n    \n                    \n    return im_out\npred=make_pred(test[0][0], features_set_min, colors_min, 1, \"DT\", True)\nprint(\"INPUT\")\nplt.imshow(test[0][0])\nplt.show()\nprint(\"PREDICT\")\nplt.imshow(pred)\nplt.show()\nprint(\"OUTPUT\")\nplt.imshow(test[0][1])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = evaluation_path # evaluation_path or train_path\n\n\nsame_shape = []\nfor ex in tqdm.tqdm(os.listdir(data_path)):\n    with open(data_path + ex, 'r') as  train_file:\n        all_im = json.load(train_file)\n        im_in = np.array(all_im['train'][0]['input'])\n        im_out = np.array(all_im['train'][0]['output'])\n        if im_in.shape == im_out.shape:\n            same_shape.append(ex)\n\n            \nprint(\"Same:\",len(same_shape),\"All:\", len(os.listdir(data_path)))\n\n\nsolved=0\nfor name in tqdm.tqdm(same_shape):\n    data = get_im_with_same_ioshape(data_path, name)\n    if data!=None:\n        train, test = data\n\n        colors, features = get_cf(train, True, True, True) \n        pred = str(make_pred(test[0][0],  features,  colors, 1, None, True))\n        \n        colors1, features1 = get_cf(train, False, False, True)\n        pred1=str(make_pred(test[0][0], features1, colors1, 1, \"DT\", True))\n        \n        colors2, features2 = get_cf(train, False, False, False)\n        pred2=str(make_pred(test[0][0], features2, colors2, 1, None, False)) \n     \n        vorbild =str( test[0][1])\n        if  pred==vorbild or pred1==vorbild or pred2==vorbild:\n            \n            solved+=1\n            print('*************\\nUhu!!!\\n'+str(solved)+\"\\n\"+name)\n            \nprint(\"Same_solved:\", solved)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"/kaggle/input/abstraction-and-reasoning-challenge/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Source: https://www.kaggle.com/c/abstraction-and-reasoning-challenge/overview/evaluation\ndef flattener(grid):\n    grid = grid.astype('uint8').tolist()    \n    str_pred = str([row for row in grid])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num=0\nfor test_name in tqdm.tqdm(sample.output_id):\n        name = test_name.split('_')[0]+'.json'\n        index=int(test_name.split('_')[1]) \n        \n        data = get_im_with_same_ioshape(test_path, name, False, 'test')\n        if data!=None:\n                train, test = data\n                colors, features = get_cf(train, True, True, True) \n                pred = make_pred(test[index],  features,  colors, 1, None, True)\n\n                colors1, features1 = get_cf(train, False, False, True)\n                pred1 = make_pred(test[index], features1, colors1, 1, \"DT\", True)\n\n                colors2, features2 = get_cf(train, False, False, False)\n                pred2 = make_pred(test[index], features2, colors2, 1, None, False)  \n\n                sample.output[num] = ' '.join([flattener(pred), flattener(pred1), flattener(pred2)])\n\n        num+=1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}