{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A DSL alongside a Genetic Algorithm applied to the ARC Dataset\n\nIn this notebook, we present a minimalistic *Domain Specific Language* for some ARC tasks. We also implement an evaluation function able to run a such program against an input image.\n\nIn a second time, we implement a simple genetic algorithm that is able to generate programs written in this DSL and demonstrate its usage on an ARC task."},{"metadata":{},"cell_type":"markdown","source":"### Additions\n\n* Added function to increase size of images - provides ability to representation on a 90x90 grid providing space around the image\n* Additional scratchpad in the image - hidden colors on top of existing to indicate awareness of patterns to next operators - can be used for identifying filling, size/rank of objects, boundaries, special pixels, other features - this may not be necessary, since operators create multiple images, and other operators combine them.\n* create operators "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nimport random\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\nfrom joblib import Parallel, delayed\nimport multiprocessing\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\ntest_path = data_path / 'test'\n\ntraining_tasks = sorted(os.listdir(training_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\n# This code is used to display a task\n# It accepts 11 colors, one more than the images, in case we want to use it\n#\n\ncmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25','#4a4d4a'])\nnorm = colors.Normalize(vmin=0, vmax=10)\ndef plot_one(ax, i,train_or_test,input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25','#4a4d4a'])\n    norm = colors.Normalize(vmin=0, vmax=10)\n    \n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)\n    \n\ndef plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(axs[0,i],i,'train','input')\n        plot_one(axs[1,i],i,'train','output')        \n    plt.tight_layout()\n    plt.show()        \n        \n    num_test = len(task['test'])\n    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n    if num_test==1: \n        plot_one(axs[0],0,'test','input')\n        plot_one(axs[1],0,'test','output')     \n    else:\n        for i in range(num_test):      \n            plot_one(axs[0,i],i,'test','input')\n            plot_one(axs[1,i],i,'test','output')  \n    plt.tight_layout()\n    plt.show() \n\n    \n# Display each output of the function\ndef show_image_list(images):\n    \"\"\" Show each image contained in a list. \"\"\"\n    p = plt.figure(figsize=[17,5]).subplots(1, len(images))\n    \n    if len(images) > 1:\n        for i, image in enumerate(images):\n            p[i].imshow(image, cmap=cmap, norm=norm)\n    elif len(images) == 1:\n        p.imshow(images[0], cmap=cmap, norm=norm)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Domain Specific Language (DSL)**\n\nOur DSL will be a collection of functions of type `np.array -> [np.array]` and `[np.array] -> [np.array]`.\n\nThe first kind of function take an image, and produce a list of images (for example, the image split by different colors). The second type of function take a list of images and produce a new list (for exemple, intersect).\n[](http://)"},{"metadata":{},"cell_type":"markdown","source":"## DSL Implementation\n\nWe start with the functions that take *one image* and produce an *a list of images*.](http://)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# np.array -> [np.array]\ndef groupByColorx_unlifted(pixmap):\n    \"\"\" Split an image into a collection of images with unique color \"\"\"\n    # Count the number of colors\n    nb_colors = int(pixmap.max()) + 1\n    # Create a pixmap for each color\n    splited = [(pixmap == i) * i for i in range(1, nb_colors)]\n    # Filter out empty images\n    return [x for x in splited if np.any(x)]\n\ndef groupByColor_unlifted(pixmap):\n    \"\"\" Split an image into a collection of images with unique color \"\"\"\n    # Identify the colors\n    rng = np.unique(pixmap)\n    nb_colors = int(pixmap.max()) + 1\n    # Create a pixmap for each color\n    splited = [ (pixmap == i) * i for i in rng]\n    #splited.append(pixmap)\n    return splited\n# \n\n# np.array -> [np.array]\ndef cropToContent_unlifted(pixmap):\n    \"\"\" Crop an image to fit exactly the non 0 pixels \"\"\"\n    # Op argwhere will give us the coordinates of every non-zero point\n    true_points = np.argwhere(pixmap)\n    if len(true_points) == 0:\n        return []\n    # Take the smallest points and use them as the top left of our crop\n    top_left = true_points.min(axis=0)\n    # Take the largest points and use them as the bottom right of our crop\n    bottom_right = true_points.max(axis=0)\n    # Crop inside the defined rectangle\n    res = pixmap[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n    return [res]\n\n# np.array -> [np.array]\ndef splitH_unlifted2(pixmap):\n    \"\"\" Split horizontally an image \"\"\"\n    h = pixmap.shape[0]\n    if h % 2 == 1:\n        h = h // 2\n        return [pixmap[:h,:], pixmap[h+1:,:]]\n    else:\n        h = h // 2\n        return [pixmap[:h,:], pixmap[h:,:]]\n    \n    \ndef splitHn_unlifted(pixmap):\n    \"\"\" Split horizontally an image \"\"\"\n    ## find the split point based on the vertical line in the image\n    #look for vertical lines (unchnging color)\n    d=np.diff(pixmap, axis=0)\n    da=np.sum(np.abs(d), axis=0)  #columns with 0 are split options\n    loc=np.where(da == 0)[0]\n    im=[]\n    for p in loc:\n        #print(p)\n        im.append(pixmap[:,:p]) # left half no line\n        im.append(pixmap[:,p+1:])  # right half with no line\n\n    return(im)\n\ndef splitH_unlifted(pixmap):\n    \"\"\" Split horizontally an image \"\"\"\n    ## find the split point based on the vertical line in the image\n    #look for vertical lines (unchnging color)\n    d=np.diff(pixmap, axis=0)\n    da=np.sum(np.abs(d), axis=0)  #columns with 0 are split options\n    loc=np.where(da == 0)[0]\n    im=[]\n    for p in loc:\n        #print(p)\n        im.append(pixmap[:,p:]) # right half with line\n        im.append(pixmap[:,:p+1]) # left half with line\n    return(im)\n\n\ndef splitV_unlifted(pixmap):\n    \"\"\" Split horizontally an image \"\"\"\n    ## find the split point based on the horizontal line in the image\n    #look for horizontal lines (unchnging color)\n    d=np.diff(pixmap, axis=1)\n    da=np.sum(np.abs(d), axis=1)  #rows with 0 are split options\n    loc=np.where(da == 0)[0]\n    im=[]\n    for p in loc:\n        #print(p)\n        im.append(pixmap[p:,:]) # bot half with line\n        im.append(pixmap[:p+1,:]) # top half with line\n    return(im)\n\ndef splitVn_unlifted(pixmap):\n    \"\"\" Split horizontally an image \"\"\"\n    ## find the split point based on the horizontal line in the image\n    #look for horizontal lines (unchnging color)\n    d=np.diff(pixmap, axis=1)\n    da=np.sum(np.abs(d), axis=1)  #rows with 0 are split options\n    loc=np.where(da == 0)[0]\n    im=[]\n    for p in loc:\n        #print(p)\n        im.append(pixmap[:p,:]) # top half no line\n        im.append(pixmap[p+1:,:])  # bot half with no line\n    return(im)\n\n\n# np.array -> [np.array]\ndef negative_unlifted(pixmap):\n    \"\"\" Compute the negative of an image (and conserve the color) \"\"\"\n    negative = np.logical_not(pixmap).astype(int)\n    color = max(pixmap.max(), 1)\n    return [pixmap,negative * color]\n\ndef extend_unlifted(pixmap):\n    \"\"\" Create image where original is padded by 30 pixels all around \"\"\"\n    ##Check if already padded enough?  min dim >=90\n    if min(pixmap.shape) < 90 :\n        padded=np.pad(pixmap, ((30,30), (30, 30)), 'constant', constant_values=(0))\n        #return [padded, pixmap]\n        return [padded]\n    else:\n        #return [pixmap, pixmap]\n        return [pixmap]\n    \n\n\ndef rotate_unlifted(pixmap):    \n    return [pixmap, np.rot90(pixmap)]# rotated image by 90 deg\n\ndef mirror_unlifted(pixmap):\n    return [pixmap, np.fliplr(pixmap)]# mirror image flip H\n\ndef tile2_unlifted(pixmap):\n    image =  np.tile(pixmap, (2,2))\n    s = image.shape\n    h = min(s[0],90)\n    v = min(s[1],90)\n    #print(\"h=\",h,\" v=\",v)\n    return [pixmap, image[:h,:v]]\n\ndef tile3_unlifted(pixmap):\n    image =  np.tile(pixmap, (3,3))\n    s = image.shape\n    h = min(s[0],90)\n    v = min(s[1],90)\n    #print(\"h=\",h,\" v=\",v)\n    return [pixmap, image[:h,:v]]\n\ndef tile3h_unlifted(pixmap):\n    image =  np.tile(pixmap, 3)\n    s = image.shape\n    h = min(s[0],90)\n    v = min(s[1],90)\n    #print(\"h=\",h,\" v=\",v)\n    return [pixmap, image[:h,:v]]\n\ndef tile2h_unlifted(pixmap):\n    image =  np.tile(pixmap, 2)\n    s = image.shape\n    h = min(s[0],90)\n    v = min(s[1],90)\n    #print(\"h=\",h,\" v=\",v)\n    return [pixmap, image[:h,:v]]\n\n\ndef shift_unlifted(pixmap):\n    return # shift image over by 1 to the right\n\ndef zoom3_unlifted(pixmap):\n    \n    newshape = np.array(pixmap.shape) * 3\n    slices = [ slice(0,old, float(old)/new) for old,new in zip(pixmap.shape,newshape) ]\n    coordinates = np.mgrid[slices]\n    indices = coordinates.astype('i')   #choose the biggest smaller integer index\n    \n    return [pixmap, pixmap[tuple(indices)]] # enlarge image taking each 1 pixel and making it 3x3\n\n\ndef zoom2_unlifted(pixmap):\n    \n    newshape = np.array(pixmap.shape) * 2\n    slices = [ slice(0,old, float(old)/new) for old,new in zip(pixmap.shape,newshape) ]\n    coordinates = np.mgrid[slices]\n    indices = coordinates.astype('i')   #choose the biggest smaller integer index\n    \n    return [pixmap, pixmap[tuple(indices)]] # enlarge image taking each 1 pixel and making it 2x2\n\n\n\n\ndef lzoom_unlifted(pixmap):\n\n    return #take small image and turn 1 pixel  2 horizontal, 1 into 3 horizontal  (with mirror and flip this can expand to other cases)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# [np.array] -> [np.array]\ndef identity(x: [np.array]):\n    return x\n\n# [np.array] -> [np.array]\ndef tail(x):\n    if len(x) > 1:\n        return x[1:]\n    else:\n        return x\n\ndef head(x):\n    if len(x) > 1:\n        return x[:-1]\n    else:\n        return x    \n    \ndef swap(x):\n    if len(x) > 1:\n        t=x[-1]\n        x[-1]=x[-2]\n        x[-2]=t\n    \n    return x  \n\n\n# [np.array] -> [np.array]\ndef init(x):\n    if len(x) > 1:\n        return x[:1]\n    else:\n        return x\n\n# [np.array] -> [np.array]\ndef union2(x):\n    \"\"\" Compute the pixel union of all images in the list. \"\"\"\n    if len(x) < 2:\n        return x\n    \n    # Make sure everybody have the same shape\n    first_shape = tuple(x[0].shape)\n    for pixmap in x[1:]:\n        if first_shape != tuple(pixmap.shape):\n            return []\n    \n    return [np.bitwise_or.reduce(np.array(x).astype(int))]\n    \ndef intersect2(x):\n    \"\"\" Compute the pixel intersection of all images in the list. \"\"\"\n    if len(x) < 2:\n        return x\n    \n    # Make sure everybody have the same shape\n    first_shape = tuple(x[0].shape)\n    for pixmap in x[1:]:\n        if first_shape != tuple(pixmap.shape):\n            return []\n    \n    return [(np.prod(np.array(x), axis=0) > 0).astype(int)]\n\ndef union(x):\n    \n    if len(x) < 2:\n        return x\n    l={}\n    # search list to identify shapes and counts\n    for pixmap in x:\n        s=str(pixmap.shape)\n        try:\n            l[s].append(pixmap)\n        except KeyError:\n            l[s]=[pixmap]\n    \n    im=[]\n    for i, k in enumerate(l):\n    #print(i, k,len(l[k]))\n        if len(l[k])>1:\n            mask = (np.logical_or.reduce(np.array(l[k]))).astype(int)\n            #print(mask)\n            for j,m in enumerate(l[k]):\n                #print()\n                im.append(np.prod([mask, m], axis=0) )\n\n    return im\n    \n    \n    \n    \ndef intersect(x):\n    \n    if len(x) < 2:\n        return x\n    l={}\n    # search list to identify shapes and counts\n    for pixmap in x:\n        s=str(pixmap.shape)\n        try:\n            l[s].append(pixmap)\n        except KeyError:\n            l[s]=[pixmap]\n    \n    im=[]\n    for i, k in enumerate(l):\n    #print(i, k,len(l[k]))\n        if len(l[k])>1:\n            mask = (np.prod(np.array(l[k]), axis=0) > 0).astype(int)\n            for j,m in enumerate(l[k]):\n                #print()\n                im.append(np.prod([mask, m], axis=0) )\n\n    return im\n\n\ndef sortByColor(xs):\n    \"\"\" Sort pictures by increasing color id. \"\"\"\n    xs = [x for x in xs if len(x.reshape(-1)) > 0]\n    return list(sorted(xs, key=lambda x: x.max()))\n\ndef sortByWeight(xs):\n    \"\"\" Sort images by how many non zero pixels are contained. \"\"\"\n    xs = [x for x in xs if len(x.reshape(-1)) > 0]\n    return list(sorted(xs, key=lambda x: (x>0).sum()))\n\ndef reverse(x):\n    \"\"\" Reverse the order of a list of images. \"\"\"\n    return x[::-1]\n\ndef colorshift(x):\n    \n    im=[]\n    for pixmap in x:\n        pixmap=pixmap+1\n        pixmap[pixmap==1] = 0 # turn black to black again\n        pixmap[pixmap>10] = 1 # rotate to 1\n        im.append(pixmap)\n    return im\n\ndef stackv(x):  ## join images top to bottom\n    if len(x) < 2:\n        return x\n    l={}\n    # search list to identify shapes and counts\n    for pixmap in x:\n        s=pixmap.shape[1]\n        try:\n            l[s].append(pixmap)\n        except KeyError:\n            l[s]=[pixmap]\n    \n    im=[]\n    for i, k in enumerate(l):\n    #print(i, k,len(l[k]))\n        if len(l[k])>1: ## more than one image with this dimension\n            im.append(np.vstack(l[k]) )\n\n    return im\n\ndef stackh(x):  ## join images top to bottom\n    if len(x) < 2:\n        return x\n    l={}\n    # search list to identify shapes and counts\n    for pixmap in x:\n        s=pixmap.shape[0]\n        try:\n            l[s].append(pixmap)\n        except KeyError:\n            l[s]=[pixmap]\n    \n    im=[]\n    for i, k in enumerate(l):\n    #print(i, k,len(l[k]))\n        if len(l[k])>1: ## more than one image with this dimension\n            im.append(np.hstack(l[k]) )\n\n    return im\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Composition of functions\n\nIt is important to make sure we can chain both functions. It is clear how we can compose two functions `f` and `g` of type `[np.array] -> [np.array]` ; We symply call `g(f([input_image]))`.\n\n\nFor each function of the first type, we need to generated a *lifted version*. A function `np.array -> [np.array]` is can be turned into a function of type `[np.array] -> [np.array]` simply by applying the first function on each image and concatenating the results.\n\n---\nIf you want to know more about the `lift` function, have a look to the concept of [*monades*](https://en.wikipedia.org/wiki/Monad_%28functional_programming%29). We are indeed using the *list monade*."},{"metadata":{"trusted":true},"cell_type":"code","source":"def lift(fct):\n    # Lift the function\n    def lifted_function(xs):\n        list_of_results = [fct(x) for x in xs]\n        return list(itertools.chain(*list_of_results))\n    # Give a nice name to the lifted function\n    import re\n    lifted_function.__name__ = re.sub('_unlifted$', '_lifted', fct.__name__)\n    return lifted_function\n\ncropToContent = lift(cropToContent_unlifted)\ngroupByColor = lift(groupByColor_unlifted)\nsplitH = lift(splitH_unlifted)\nsplitHn = lift(splitHn_unlifted)\nsplitV = lift(splitV_unlifted)\nsplitVn = lift(splitVn_unlifted)\nnegative = lift(negative_unlifted)\nextend = lift(extend_unlifted)\nrotate = lift(rotate_unlifted)\nmirror = lift(mirror_unlifted)\ntile2 = lift(tile2_unlifted)\ntile3 = lift(tile3_unlifted)\ntile2h = lift(tile2h_unlifted)\ntile3h = lift(tile3h_unlifted)\nzoom3 = lift(zoom3_unlifted)\nzoom2 = lift(zoom2_unlifted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task\n\nWe now load a simple task and execute one of our functions on it."},{"metadata":{},"cell_type":"markdown","source":"# Program evaluation\n\n\nWe define our building blocks for programs (the functions in our DSL). We will define a program as a list of functions from our DSL ; `program: [[np.array] -> [np.array]]`. The instructions in our programs will be executed *from left to right*. This mean that if we want to first `splitByColor` and then compute the `negative` of the image, we need to write `[splitByColor, negative]` in this order."},{"metadata":{},"cell_type":"markdown","source":"Let's first write an utilitary function to describe a program as a human readable string."},{"metadata":{"trusted":true},"cell_type":"code","source":"def program_desc(program):\n    \"\"\" Create a human readable description of a program. \"\"\"\n    desc = [x.__name__ for x in program]\n    return(' >> '.join(desc))\n\n# Display the program description alongside its output\n#program = [splitH, groupByColor, negative, intersect]\n#print(program_desc(program))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The evaluation method\nWe need a way to run a such program on a pictures and recover the result. This is done by the `evaluate` function."},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(program: [], input_image: np.array):\n    # Make sure the input is a np.array\n    input_image = np.array(input_image)\n    assert type(input_image) == np.ndarray\n    \n    # Apply each function on the image\n    image_list = [input_image]\n    for fct in program:\n        # Apply the function\n        #image_list.append(input_image)  ##try this to get input in every step\n        image_list = fct(image_list)\n        # Filter out empty images\n        image_list = [img for img in image_list if img.shape[0] > 0 and img.shape[1] > 0]\n        # Break if there is no data\n        if image_list == []:\n            return []\n    return image_list        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Program generation\n\nWe now have a simple and powerful language to express various transformation on images. But someone or something still have to write the actual program that can solve a task. In this part, we will implement a naive but somewhat efficient genetic algorithm that will be able to find by itself the solution to a task."},{"metadata":{},"cell_type":"markdown","source":"## Is a program solution\n\nFirst, we need a way to know if a program is a solution of the given examples of a task."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load my favorite task\nt=0\ntask_file = str(training_path / training_tasks[t])\nwith open(task_file, 'r') as f:\n    task = json.load(f)\n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def are_two_images_equals(a, b):\n    if tuple(a.shape) == tuple(b.shape):\n        if (np.abs(b-a) < 1).all():\n            return True\n    return False\n\ndef is_solution(program, task, verbose=True):\n    for sample in task: # For each pair input/output\n        \n        i = np.array(sample['input'])\n        o = np.array(sample['output'])\n\n        # Evaluate the program on the input\n        images = evaluate(program, i)\n        if len(images) < 1:\n            return False\n        \n        # The solution should be in the 3 last outputs\n        images = images[-3:]\n        #print(\"Images=\",images) #debug\n        # Check if the output is in the 3 images produced\n        is_program_of_for_sample = any([are_two_images_equals(x, o) for x in images])\n        if not is_program_of_for_sample:\n            return False\n    \n    return True\n\nprogram = [zoom3,tile3,intersect]\nprint(program_desc(program),\"is a solution of the task:\", is_solution(program, task['train']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = evaluate(program=[zoom3,tile3,intersect], input_image=task['train'][0]['input'])\nshow_image_list(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_list(results[-3:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitness\n\nTo help our algorithm progress in the right direction, we need a way to give a score to an existing program. The smaller is the score of the program, the closer we are to the solution. One can think of this score as a distance of our program to the optimal solution.\n\nNotice that one can think of this program as a minimization problem (minimize `score`) or maximization problem (minimize `-score`). On machine learning it is common to minimise a distance wereas in genetic algorithm literature you can read that we maximize the fitness of an agent. Both convention work perfectly, but it is more convenient if we choose one and stick to it. Therefore, we will MINIMIZE the score of our programs.\n\nFirst, we are going to evaluate how our program perform on different aspects."},{"metadata":{"trusted":true},"cell_type":"code","source":"import re \ndef subimg_location(haystack, needle):\n    \n    try:\n        \n        haystack_str = b\"\".join(48+haystack.flatten().astype(np.dtype('b'))).decode(\"latin-1\") \n        needle_str = b\"\".join((48+needle.flatten()).astype(np.dtype('b'))).decode(\"latin-1\") \n    except:\n        print(\"needle=\",needle)\n        print(\"type=\",type(needle))\n        print(\"shape=\",needle.shape)\n        print(\"temp=\",temp)\n        print(\" \")\n    \n\n    gap_size = (haystack.shape[1] - needle.shape[1]) \n    \n    #print(gap_size)\n    gap_regex = '.{' + str(gap_size) + '}'\n\n    #print(gap_regex)\n    # Split b into needle.size[0] chunks\n    chunk_size = needle.shape[1] \n    split = [needle_str[i:i+chunk_size] for i in range(0, len(needle_str), chunk_size)]\n\n    # Build regex\n    regex = re.escape(split[0])\n    for i in range(1, len(split)):\n        regex += gap_regex + re.escape(split[i])\n\n    p = re.compile(regex)\n    m = p.search(haystack_str)\n\n    if not m:\n        return False\n\n    x, _ = m.span()\n\n    left = x % (haystack.shape[1] ) \n    top  = int(x / haystack.shape[1] )\n\n    return (top, left)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def width_fitness(predicted, expected_output):\n    \"\"\" How close the predicted image is to have the right width. Less is better.\"\"\"\n    return np.abs(predicted.shape[0] - expected_output.shape[0])\n\ndef height_fitness(predicted, expected_output):\n    \"\"\" How close the predicted image is to have the right height. Less is better.\"\"\"\n    return np.abs(predicted.shape[1] - expected_output.shape[1])\n\ndef activated_pixels_fitness(p, e):\n    \"\"\" How close the predicted image to have the right pixels. Less is better.\"\"\"\n    shape = (max(p.shape[0], e.shape[0]), max(p.shape[1], e.shape[1]))\n    diff = np.zeros(shape, dtype=int)\n    diff[0:p.shape[0], 0:p.shape[1]] = (p > 0).astype(int)\n    diff[0:e.shape[0], 0:e.shape[1]] -= (e > 0).astype(int)\n    \n    fit = (diff != 0).sum()\n    \n    return fit\n\n\ndef submatch_fitness(p,e):\n    \n    (py,px) = p.shape\n    (ey,ex) = e.shape\n    \n    if px<=ex and py<=ey:\n        \n        r = subimg_location(haystack=e,needle=p)\n    \n    elif px>=ex and py>=ey:\n        r = subimg_location(haystack=p,needle=e)\n    elif px<ex and py>=ey:\n        \n        r = subimg_location(haystack=e[:,:px],needle=p)\n    elif px>=ex and py<ey:\n \n        r = subimg_location(haystack=e[:py,:],needle=p)\n    else:\n        print(\"whats up\",px,ex,py,ey)\n            \n    if r == False:\n        return 1\n    else:\n        #print(r)\n        return 0\n        \n\ndef pixels_match_fitness(p,e):\n    shape = (max(p.shape[0], e.shape[0]), max(p.shape[1], e.shape[1]))\n    #check how many pixels match the expected output.\n    p1 = np.zeros(shape, dtype=int)\n    e1 = np.zeros(shape, dtype=int)\n    \n    p1[0:p.shape[0], 0:p.shape[1]] = p\n    e1[0:e.shape[0], 0:e.shape[1]] = e\n    \n    #q=np.abs(p1-e1).sum() + abs(e.shape[0]-p.shape[0])*abs(e.shape[1]-p.shape[1])\n    q=np.abs(p1-e1).sum()\n    \n    s=submatch_fitness(p,e)\n    \n    return q*(1+5*s)\n    \n\ndef colors_fitness(p, e):\n    p_colors = np.unique(p)\n    e_colors = np.unique(e)\n    \n    nb_inter = len(np.intersect1d(p_colors, e_colors))\n\n    return (len(p_colors) - nb_inter) + (len(e_colors) - nb_inter)\n\nfitness_functions = [colors_fitness, activated_pixels_fitness, height_fitness, width_fitness, pixels_match_fitness]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The fitness score (less is better) of our function will be a 4-dimensional tuple containing the result of each of the fitness functions.\n\nWe want to be able to compare two score. Unfortunately, the *lixocographical order* is not adapted, as there is no reason than having a small `width score` is better than having a small `height score`. We are going to define a partial order that give the same weight to any fitness function.\n\nWhen we compare two tuple with this partial order, `(3, 2, 4, 0) < (3, 2, 5, 0)` and `(3, 2, 4, 0) < (4, 2, 4, 0)`. But there is no way to compare `(3, 2, 5, 0)` and `(4, 2, 4, 0)`. We say this two values are *incomparable*. If two score are incomparable, it means that we cannot say that one program is better than the over."},{"metadata":{"trusted":true},"cell_type":"code","source":"def product_less(a, b):\n    \"\"\" Return True iff the two tuples a and b respect a<b for the partial order. \"\"\"\n    a = np.array(a)\n    b = np.array(b)\n    return (np.array(a) < np.array(b)).all()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now write a function that evaluate the fitness of a program on a task."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ([[np.array] -> [np.array]], Taks) -> (int, int, ..., int)\ndef evaluate_fitness(program, task):\n    \"\"\" Take a program and a task, and return its fitness score as a tuple. \"\"\"\n    score = np.zeros((len(fitness_functions)))\n    \n    # For each sample\n    for sample in task:\n        i = np.array(sample['input'])\n        o = np.array(sample['output'])\n        images = evaluate(program, i)\n        # For each fitness function\n        for index, fitness_function in enumerate(fitness_functions):\n            \n            if images == []: # Penalize no prediction!\n                score[index] += 500\n            else: # Take only the score of the last 3 outputs\n                score[index]=0\n                im3=images[-3:]\n                for imct in range(len(im3)):\n                    score[index] = score[index] + fitness_function(im3[imct], o)/len(images)\n                \n    return tuple(score)\n\nprint(\"Fitness evaluation:\", evaluate_fitness([splitHn,reverse,intersect,colorshift], task['train']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Asexual reproduction\n\nNow that we can compare two programs we need a way to generate some of them. We will generate them randomly from a pool of best candidate.\n\nFor the initial run, and also to be able to evaluate fresh candidates, we will also allow spontaneous generation of new born one instruction programs."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_candidates(allowed_nodes=[identity], best_candidates=[], nb_candidates=50):\n    \"\"\"\n    Create a poll of fresh candidates using the `allowed_nodes`.\n    \n    The pool contain a mix of new single instructions programs\n    and mutations of the best candidates.\n    \"\"\"\n    new_candidates = []\n    length_limit = 5 # Maximal length of a program\n    \n    def random_node():\n        return random.choice(allowed_nodes)\n    \n    # Until we have enougth new candidates\n    while(len(new_candidates) < nb_candidates):\n        # Add 10 new programs\n        for i in range(5):\n            new_candidates += [[random_node()]]\n        \n        # Create new programs based on each best candidate\n        for best_program in best_candidates:\n            # Add one op on its right but limit the length of the program\n            if len(best_program) < length_limit - 1:\n                new_candidates += [[random_node()] + best_program]\n            # Add one op on its left but limit the length of the program\n            if len(best_program) < length_limit - 1:\n                new_candidates += [best_program + [random_node()]]\n            # Mutate one instruction of the existing program\n            new_candidates += [list(best_program)]\n            new_candidates[-1][random.randrange(0, len(best_program))] = random_node()\n   \n    # Truncate if we have too many candidates\n    np.random.shuffle(new_candidates)\n    return new_candidates[:nb_candidates]\n\n# Test the function by building some candidates\n#len(build_candidates(allowed_nodes=[identity], best_candidates=[[identity]], nb_candidates=42))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find a program given a task\n\nThis is the last step to our genetic algorithm. We have all the building blocks:\n * Generating both new programs and mutation of existing solutions\n * Evaluating the fitness score of a program\n * Comparing two programs to know if one perform better than the other\n * Detecting when a solution was found\n \nWe can now write a function that will keep generating programs with increasing complexity until a solution is found.\n\nUsing our partial order, we are going to keep the best candidates. Because the order is partial,\nthere is no bound on how many uncomparables candidates we may have at a given iteration."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(task, max_iterations=20, verbose=True):\n    candidates_nodes = [\n        intersect,\n        \n        cropToContent, groupByColor, splitH, splitV,splitVn, splitHn,\n        tile2,tile3,zoom3,zoom2,union,sortByColor, mirror,rotate,colorshift,\n        tile2h,tile3h,stackh,stackv,head,\n        init,tail, sortByWeight, reverse, negative,swap\n        \n        #extend,push,pull\n\n    ]\n    \n    print(\".\")\n    if verbose:\n        print(\"Candidates nodes are:\", [program_desc([n]) for n in candidates_nodes])\n        print()\n\n    best_candidates = {} # A dictionary of {score:candidate}\n    for i in range(max_iterations):\n        if verbose:\n            print(\"Iteration \", i+1)\n            print(\"-\" * 10)\n        \n        # Create a list of candidates\n        candidates = build_candidates(candidates_nodes, best_candidates.values())\n        \n        # Keep candidates with best fitness.\n        # They will be stored in the `best_candidates` dictionary\n        # where the key of each program is its fitness score.\n        for candidate in candidates:\n            score = evaluate_fitness(candidate, task)\n            is_uncomparable = True # True if we cannot compare the two candidate's scores\n            \n            # Compare the new candidate to the existing best candidates\n            best_candidates_items = list(best_candidates.items())\n            for best_score, best_candidate in best_candidates_items:\n                if product_less(score, best_score):\n                    # Remove previous best candidate and add the new one\n                    del best_candidates[best_score]\n                    best_candidates[score] = candidate\n                    is_uncomparable = False # The candidates are comparable\n                if product_less(best_score, score) or best_score == score:\n                    is_uncomparable = False # The candidates are comparable\n            if is_uncomparable: # The two candidates are uncomparable\n                best_candidates[score] = candidate\n\n        # For each best candidate, we look if we have an answer\n        for program in best_candidates.values():\n            if is_solution(program, task):\n                return program\n            \n        # Give some informations by selecting a random candidate\n        if verbose:\n            print(\"Best candidates length:\", len(best_candidates))\n            random_candidate_score = random.choice(list(best_candidates.keys()))\n            print(\"Random candidate score:\", random_candidate_score)\n            print(\"Random candidate implementation:\", program_desc(best_candidates[random_candidate_score]))\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load my favorite task\ntask_file = str(training_path / training_tasks[5])\nprint(task_file)\nwith open(task_file, 'r') as f:\n    task = json.load(f)\n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"program = build_model(task['train'],max_iterations=100, verbose=True)\n\nprint()\nif program is None:\n    print(\"No program was found\")\nelse:\n    print(\"Found program:\", program_desc(program))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndisplay(example_grid)\nprint(flattener(example_grid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* To Do - try each with 20 iterations and then work on harder ones in a second pass\n* Add time monitoring for 9 hrs\n* return best 3 programs when nothing found"},{"metadata":{"trusted":true},"cell_type":"code","source":"#read all inputs into memory first\ntaskdict={}\n\n\nfor output_id in submission.index:\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    f = str(test_path / str(task_id + '.json'))\n    with open(f, 'r') as read_file:\n        task = json.load(read_file)\n        \n    taskdict[output_id] = task\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnum_cores = multiprocessing.cpu_count()\nprint(num_cores)\n\nresults = Parallel(n_jobs=num_cores)(delayed(build_model)(taskdict[i]['train'],50,False) for i in submission.index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct=0\nresdict={}\nfor output_id in submission.index:\n    resdict[output_id] = results[ct]\n    ct=ct+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for output_id in submission.index:\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    f = str(test_path / str(task_id + '.json'))\n    \n    task = taskdict[output_id]\n        \n    program = resdict[output_id]\n    if program is None:\n        print(\"No program was found for:\",f)\n        \n        # skipping over the training examples, since this will be naive predictions\n        # we will use the test input grid as the base, and make some modifications\n        data = task['test'][pair_id]['input'] # test pair input\n        # for the first guess, predict that output is unchanged\n        pred_1 = flattener(data)\n        # for the second guess, change all 0s to 5s\n        data = [[5 if i==0 else i for i in j] for j in data]\n        pred_2 = flattener(data)\n        # for the last gues, change everything to 0\n        data = [[0 for i in j] for j in data]\n        pred_3 = flattener(data)\n        pred = pred_1 + ' ' + pred_2 + ' ' + pred_3 + ' ' \n        \n    else:\n        count=count+1\n        print(\"Task:\",f,\" total:\", count,\" Found program:\", program_desc(program))\n        results = evaluate(program=program, input_image=task['test'][pair_id]['input'])\n        pred=\"\"\n        ct=min(3,len(results))\n        for i in range(ct):\n            x=results[i]\n            x[x>9] = 0 # change extra color to background if it exists\n            pred = pred + flattener(x.to_list()) + ' '\n         \n    submission.loc[output_id, 'output'] = pred\n\nsubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}