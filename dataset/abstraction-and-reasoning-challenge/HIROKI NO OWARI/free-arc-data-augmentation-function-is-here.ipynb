{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Free Data Augmentation Function!**"},{"metadata":{},"cell_type":"markdown","source":"I coded a data augmentation function for ARC!\n\nFeel free to copy and use it!\n\nI decided to just change color combinations and not to turn the images upside down or the other way around, because directions are important for some of the tasks."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    \n    if len(filenames) > 2:\n        print('# of files in {}:'.format(dirname), len(filenames))\n        for i in range(5):\n            print(os.path.join(dirname, filenames[i]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pathlib import Path\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\n\ntraining_tasks = sorted(os.listdir(training_path))\nevaluation_tasks = sorted(os.listdir(evaluation_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\n# the data augmentation function below takes in one task at a time\ntask_file_0 = str(training_path / training_tasks[0])\n\nwith open(task_file_0, 'r') as f:\n    task_0 = json.load(f)\n\n\"\"\"\nThe structure of each loaded task file is,\n    {\n    'test': [{'input': list, 'output': list}],\n    'train': [{'input': list, 'output': list}, {'input': list, 'output': list}, ...]\n    }\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\n\ndef Data_Aug(task):\n    \"\"\"\n    takes in a whole task dictionary\n    returns an augmented train set of a task\n    [{'input': numpy array, 'output': numpy array}, {'input': numpy array, 'output': numpy array}, ...]\n    \"\"\"\n    \n    train_task = task['train']\n    \n    #[1] find out \"key colors\" used commonly across all the train input/output pairs, which must play an important role on the task rule.\n    #Key colors include the background color \"black\". I suppose it and key colors never suddenly change on the test.\n    used_colors_in_each_io_pair = []\n    for i, train_io_pair in enumerate(train_task):\n        ipt, opt = np.array(train_io_pair['input']), np.array(train_io_pair['output'])\n        used_colors_in_each_io_pair.append(np.unique(np.concatenate([ipt.ravel(), opt.ravel()])))\n    \n    key_colors = np.array([])\n    for i in range(len(used_colors_in_each_io_pair)):\n        if i == 0:\n            key_colors = used_colors_in_each_io_pair[i]\n        else:\n            key_colors = np.intersect1d(key_colors, used_colors_in_each_io_pair[i])\n    #[1] ends\n    \n    #[2] change \"non-key colors\" of each train input/output pairs to many color pairs and save the newly-colored input/output pairs.\n    new_train_task = []\n    for train_io_pair in train_task:\n        ipt, opt = np.array(train_io_pair['input']), np.array(train_io_pair['output'])\n        \n        non_key_colors = [i for i in np.unique(np.concatenate([ipt.ravel(), opt.ravel()])) if i not in key_colors]\n        color_comb = list(itertools.product([i for i in range(10) if i not in key_colors], repeat=len(non_key_colors)))\n        trns_lst = [tpl for tpl in color_comb if len(np.unique(tpl)) == len(tpl)]\n        \n        # I assume 100 records are enough for no reason...\n        if len(trns_lst) < 100:\n            idx_arr = np.random.choice(len(trns_lst), len(trns_lst), replace=False)\n        else:\n            idx_arr = np.random.choice(len(trns_lst), 100, replace=False)\n        \n        trns_lst = np.array(trns_lst)[idx_arr]\n        \n        for i in range(len(trns_lst)):\n            new_input = ipt.copy()\n            new_output = opt.copy()\n            for before, after in zip(non_key_colors, trns_lst[i]):\n                new_input[ipt == before] = after\n                new_output[opt == before] = after\n                \n            new_io_pair = {'input': new_input, 'output': new_output}\n            new_train_task.append(new_io_pair)\n    #[2] ends\n        \n    return new_train_task","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I forked a big part of the visualizing function below from [this kernel](https://www.kaggle.com/boliu0/visualizing-all-task-pairs-with-gridlines)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import colors\n\n\ndef plot_one(io_pairs, ax, i, input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    \n    input_matrix = io_pairs[i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)\n    ax.set_yticks([x+0.5 for x in range(len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(input_or_output)\n\n\ndef plot_io_pairs(io_pairs):\n    \"\"\"\n    visualizes all the input/output-pair-dictionaries in a list\n    takes in [{'input': numpy array, 'output': numpy array}, {'input': numpy array, 'output': numpy array}, ...]\n    \"\"\"\n    \n    num_pairs = len(io_pairs)\n    fig, axs = plt.subplots(2, num_pairs, figsize=(3*num_pairs,3*2))\n    \n    if num_pairs == 1: \n        plot_one(io_pairs,axs[0],0,'input')\n        plot_one(io_pairs,axs[1],0,'output')\n    \n    else:\n        for i in range(num_pairs):\n            plot_one(io_pairs,axs[0,i],i,'input')\n            plot_one(io_pairs,axs[1,i],i,'output')\n        plt.tight_layout()\n        plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am still a beginner in this field, and struggling a lot...\n\nIt would really motivate me a lot if you could upvote this kernel!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nfor i in range(15):\n    print(\"task\", i)\n    task_file = str(training_path / training_tasks[i])\n\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    \n    train_io_pairs = Data_Aug(task)\n    \n    for j in range(0, len(train_io_pairs), 10):\n        plot_io_pairs(train_io_pairs[j : j+10])\n\n    plot_io_pairs(task['test'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmmm..., it seems that I succeeded in effectively augmenting about half of the task data.\n\nI am pretty sure that some of the tasks can be augmented by turning the images aournd, but it is hard to code that recognition process...\n\nAny suggestion would be appreciated!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}