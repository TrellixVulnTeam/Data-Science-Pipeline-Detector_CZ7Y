{"cells":[{"metadata":{},"cell_type":"markdown","source":"Done!--All training tasks tagged.\n\nIn the following (hidden) cells I create a dataframe to encode task tags and properties in a way that could possibly generalize to further tasks. The classification is far from perfect and depends largely on my ability to describe task resolution in a DSL-ish and transferrable way, so any help and corrections are greatly appreciated. All my gratitude to boliu0 for [making this bearable](https://www.kaggle.com/boliu0/visualizing-all-task-pairs-with-gridlines).\n\nThe dataframe can be imported from the outputs of this kernel. "},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport random\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Input, concatenate, Activation, BatchNormalization, Softmax, Conv2DTranspose\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.utils import plot_model\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n    \nfrom pathlib import Path\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot func"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def plot_one(task, ax, i,train_or_test,input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    \n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)\n\ndef plot(img):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, ax = plt.subplots()\n    ax.imshow(img, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(img))])\n    ax.set_xticks([x-0.5 for x in range(1+len(img[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n\n\ndef plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(task, axs[0,i],i,'train','input')\n        plot_one(task, axs[1,i],i,'train','output')        \n    plt.tight_layout()\n    plt.show()        \n        \n    num_test = len(task['test'])\n    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n    if num_test==1: \n        plot_one(task, axs[0],0,'test','input')\n        plot_one(task, axs[1],0,'test','output')     \n    else:\n        for i in range(num_test):      \n            plot_one(task, axs[0,i],i,'test','input')\n            plot_one(task, axs[1,i],i,'test','output')  \n    plt.tight_layout()\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Skills list"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"skill_series = pd.Series(\n    [[] for name in sorted(os.listdir(training_path))],\n    index = sorted(os.listdir(training_path))\n)\n\n# 0-5\nskill_series['007bbfb7.json'] = ['image_repetition', 'fractal_repetition']\nskill_series['00d62c1b.json'] = ['loop_filling']\nskill_series['017c7c7b.json'] = ['recoloring', 'pattern_expansion', 'pattern_repetition', 'image_expansion']\nskill_series['025d127b.json'] = ['pattern_modification']\nskill_series['045e512c.json'] = ['pattern_expansion', 'direction_guessing']\nskill_series['0520fde7.json'] = ['detect_wall', 'separate_images', 'pattern_intersection']\n\n# 6-10\nskill_series['05269061.json'] = ['image_filling', 'pattern_expansion', 'diagonals']\nskill_series['05f2a901.json'] = ['pattern_moving', 'direction_guessing', 'bring_patterns_close']\nskill_series['06df4c85.json'] = ['detect_grid', 'connect_the_dots', 'grid_coloring']\nskill_series['08ed6ac7.json'] = ['measure_length', 'order_numbers', 'associate_colors_to_ranks', 'recoloring']\nskill_series['09629e4f.json'] = ['detect_grid', 'separate_images', 'count_tiles', 'take_minimum', 'enlarge_image', 'create_grid', 'adapt_image_to_grid']\n\n# 11-15\nskill_series['0962bcdd.json'] = ['pattern_expansion']\nskill_series['0a938d79.json'] = ['direction_guessing', 'draw_line_from_point', 'pattern_expansion']\nskill_series['0b148d64.json'] = ['detect_grid', 'separate_images', 'find_the_intruder', 'crop']\nskill_series['0ca9ddb6.json'] = ['pattern_expansion', 'associate_patterns_to_colors']\nskill_series['0d3d703e.json'] = ['associate_colors_to_colors']\n\n# 16-20\nskill_series['0dfd9992.json'] = ['image_filling', 'pattern_expansion']\nskill_series['0e206a2e.json'] = ['associate_patterns_to_patterns', 'pattern_repetition', 'pattern_rotation', 'pattern_reflection', 'pattern_juxtaposition']\nskill_series['10fcaaa3.json'] = ['pattern_expansion', 'image_repetition']\nskill_series['11852cab.json'] = ['pattern_expansion']\nskill_series['1190e5a7.json'] = ['detect_grid', 'count_hor_lines', 'count_ver_lines', 'detect_background_color', 'color_guessing', 'create_image_from_info']\n\n# 21-25\nskill_series['137eaa0f.json'] = ['pattern_juxtaposition']\nskill_series['150deff5.json'] = ['pattern_coloring', 'pattern_deconstruction', 'associate_colors_to_patterns']\nskill_series['178fcbfb.json'] = ['direction_guessing', 'draw_line_from_point']\nskill_series['1a07d186.json'] = ['bring_patterns_close', 'find_the_intruder']\nskill_series['1b2d62fb.json'] = ['detect_wall', 'separate_images', 'pattern_intersection']\n\n# 26-30\nskill_series['1b60fb0c.json'] = ['pattern_deconstruction', 'pattern_rotation', 'pattern_expansion']\nskill_series['1bfc4729.json'] = ['pattern_expansion']\nskill_series['1c786137.json'] = ['detect_enclosure', 'crop']\nskill_series['1caeab9d.json'] = ['pattern_moving', 'pattern_alignment']\nskill_series['1cf80156.json'] = ['crop']\n\n# 31-35\nskill_series['1e0a9b12.json'] = ['pattern_moving', 'gravity']\nskill_series['1e32b0e9.json'] = ['detect_grid', 'separate_images', 'image_repetition', 'pattern_completion']\nskill_series['1f0c79e5.json'] = ['pattern_expansion', 'diagonals', 'direction_guessing']\nskill_series['1f642eb9.json'] = ['image_within_image', 'projection_unto_rectangle']\nskill_series['1f85a75f.json'] = ['crop', 'find_the_intruder']\n\n# 36-40\nskill_series['1f876c06.json'] = ['connect_the_dots', 'diagonals']\nskill_series['1fad071e.json'] = ['count_patterns', 'associate_images_to_numbers']\nskill_series['2013d3e2.json'] = ['pattern_deconstruction', 'crop']\nskill_series['2204b7a8.json'] = ['proximity_guessing', 'recoloring']\nskill_series['22168020.json'] = ['pattern_expansion']\n\n# 41-45\nskill_series['22233c11.json'] = ['pattern_expansion', 'size_guessing']\nskill_series['2281f1f4.json'] = ['direction_guessing', 'draw_line_from_point', 'pattern_intersection']\nskill_series['228f6490.json'] = ['pattern_moving', 'loop_filling', 'shape_guessing', 'x_marks_the_spot']\nskill_series['22eb0ac0.json'] = ['connect_the_dots', 'color_matching']\nskill_series['234bbc79.json'] = ['recoloring', 'bring_patterns_close', 'crop']\n\n# 46-50\nskill_series['23581191.json'] = ['draw_line_from_point', 'pattern_intersection']\nskill_series['239be575.json'] = ['detect_connectedness', 'associate_images_to_bools']\nskill_series['23b5c85d.json'] = ['measure_area', 'take_minimum', 'crop']\nskill_series['253bf280.json'] = ['connect_the_dots', 'direction_guessing']\nskill_series['25d487eb.json'] = ['draw_line_from_point', 'direction_guessing', 'color_guessing']\n\n# 51-55\nskill_series['25d8a9c8.json'] = ['detect_hor_lines', 'recoloring', 'remove_noise']\nskill_series['25ff71a9.json'] = ['pattern_moving']\nskill_series['264363fd.json'] = ['pattern_repetition', 'pattern_juxtaposition', 'draw_line_from_point']\nskill_series['272f95fa.json'] = ['detect_grid', 'mimic_pattern', 'grid_coloring']\nskill_series['27a28665.json'] = ['associate_colors_to_patterns', 'take_negative', 'associate_images_to_patterns']\n\n# 56-60\nskill_series['28bf18c6.json'] = ['crop', 'pattern_repetition']\nskill_series['28e73c20.json'] = ['ex_nihilo', 'mimic_pattern']\nskill_series['29623171.json'] = ['detect_grid', 'separate_images', 'count_tiles', 'take_maximum', 'grid_coloring']\nskill_series['29c11459.json'] = ['draw_line_from_point', 'count_tiles']\nskill_series['29ec7d0e.json'] = ['image_filling', 'pattern_expansion', 'detect_grid', 'pattern_repetition']\n\n# 61-65\nskill_series['2bcee788.json'] = ['pattern_reflection', 'direction_guessing', 'image_filling', 'background_filling']\nskill_series['2bee17df.json'] = ['draw_line_from_border', 'count_tiles', 'take_maximum']\nskill_series['2c608aff.json'] = ['draw_line_from_point', 'projection_unto_rectangle']\nskill_series['2dc579da.json'] = ['detect_grid', 'find_the_intruder', 'crop']\nskill_series['2dd70a9a.json'] = ['draw_line_from_point', 'direction_guessing', 'maze']\n\n# 66-70\nskill_series['2dee498d.json'] = ['detect_repetition', 'crop', 'divide_by_n']\nskill_series['31aa019c.json'] = ['find_the_intruder', 'remove_noise', 'contouring']\nskill_series['321b1fc6.json'] = ['pattern_repetition', 'pattern_juxtaposition']\nskill_series['32597951.json'] = ['find_the_intruder', 'recoloring']\nskill_series['3345333e.json'] = ['pattern_completion', 'pattern_reflection', 'remove_noise']\n\n# 71-75\nskill_series['3428a4f5.json'] = ['detect_wall', 'separate_images', 'pattern_differences']\nskill_series['3618c87e.json'] = ['gravity']\nskill_series['3631a71a.json'] = ['image_filling', 'pattern_expansion', 'pattern_rotation']\nskill_series['363442ee.json'] = ['detect_wall', 'pattern_repetition', 'pattern_juxtaposition']\nskill_series['36d67576.json'] = ['pattern_repetition', 'pattern_juxtaposition', 'pattern_reflection', 'pattern_rotation']\n\n# 76-80\nskill_series['36fdfd69.json'] = ['recoloring', 'rectangle_guessing']\nskill_series['3906de3d.json'] = ['gravity']\nskill_series['39a8645d.json'] = ['count_patterns', 'take_maximum', 'crop']\nskill_series['39e1d7f9.json'] = ['detect_grid', 'pattern_repetition', 'grid_coloring']\nskill_series['3aa6fb7a.json'] = ['pattern_completion', 'pattern_rotation']\n\n# 81-85\nskill_series['3ac3eb23.json'] = ['draw_pattern_from_point', 'pattern_repetition']\nskill_series['3af2c5a8.json'] = ['image_repetition', 'image_reflection', 'image_rotation']\nskill_series['3bd67248.json'] = ['draw_line_from_border', 'diagonals','pattern_repetition']\nskill_series['3bdb4ada.json'] = ['recoloring','pattern_repetition', 'holes']\nskill_series['3befdf3e.json'] = ['take_negative', 'pattern_expansion']\n\n# 86-90\nskill_series['3c9b0459.json'] = ['image_rotation']\nskill_series['3de23699.json'] = ['take_negative', 'crop', 'rectangle_guessing']\nskill_series['3e980e27.json'] = ['pattern_repetition', 'pattern_juxtaposition', 'direction_guessing', 'pattern_reflection']\nskill_series['3eda0437.json'] = ['rectangle_guessing', 'recoloring', 'measure_area', 'take_maximum']\nskill_series['3f7978a0.json'] = ['crop', 'rectangle_guessing', 'find_the_intruder']\n\n# 91-95\nskill_series['40853293.json'] = ['connect_the_dots']\nskill_series['4093f84a.json'] = ['gravity', 'recoloring', 'projection_unto_rectangle']\nskill_series['41e4d17e.json'] = ['draw_line_from_point', 'pattern_repetition']\nskill_series['4258a5f9.json'] = ['pattern_repetition', 'contouring']\nskill_series['4290ef0e.json'] = ['pattern_moving', 'concentric', 'crop']\n\n# 96-100\nskill_series['42a50994.json'] = ['remove_noise', 'count_tiles']\nskill_series['4347f46a.json'] = ['loop_filling', 'color_guessing']\nskill_series['444801d8.json'] = ['pattern_repetition', 'pattern_expansion', 'rectangle_guessing']\nskill_series['445eab21.json'] = ['measure_area', 'take_maximum']\nskill_series['447fd412.json'] = ['pattern_repetition', 'draw_pattern_from_point', 'pattern_resizing']\n\n# 101-105\nskill_series['44d8ac46.json'] = ['loop_filling', 'rectangle_guessing']\nskill_series['44f52bb0.json'] = ['detect_symmetry', 'associate_images_to_bools']\nskill_series['4522001f.json'] = ['image_rotation', 'pairwise_analogy']\nskill_series['4612dd53.json'] = ['pattern_completion', 'rectangle_guessing']\nskill_series['46442a0e.json'] = ['image_repetition', 'image_reflection']\n\n# 106-110\nskill_series['469497ad.json'] = ['image_resizing', 'draw_line_from_point', 'diagonals']\nskill_series['46f33fce.json'] = ['pattern_resizing', 'image_resizing']\nskill_series['47c1f68c.json'] = ['detect_grid', 'find_the_intruder', 'crop', 'recolor', 'color_guessing', 'image_repetition', 'image_reflection']\nskill_series['484b58aa.json'] = ['image_filling', 'pattern_expansion', 'pattern_repetition']\nskill_series['48d8fb45.json'] = ['find_the_intruder', 'crop']\n\n# 111-115\nskill_series['4938f0c2.json'] = ['pattern_expansion', 'pattern_rotation', 'pattern_reflection']\nskill_series['496994bd.json'] = ['pattern_reflection']\nskill_series['49d1d64f.json'] = ['pattern_expansion', 'image_expansion']\nskill_series['4be741c5.json'] = ['summarize']\nskill_series['4c4377d9.json'] = ['image_repetition', 'image_reflection']\n\n# 116-120\nskill_series['4c5c2cf0.json'] = ['pattern_expansion', 'pattern_rotation', 'pattern_reflection']\nskill_series['50846271.json'] = ['pattern_completion', 'recoloring']\nskill_series['508bd3b6.json'] = ['draw_line_from_point', 'direction_guessing', 'pattern_reflection']\nskill_series['50cb2852.json'] = ['holes', 'rectangle_guessing']\nskill_series['5117e062.json'] = ['find_the_intruder', 'crop', 'recoloring']\n\n# 121-125\nskill_series['5168d44c.json'] = ['direction_guessing', 'recoloring', 'contouring', 'pattern_moving']\nskill_series['539a4f51.json'] = ['pattern_expansion', 'image_expansion']\nskill_series['53b68214.json'] = ['pattern_expansion', 'image_expansion']\nskill_series['543a7ed5.json'] = ['contouring', 'loop_filling']\nskill_series['54d82841.json'] = ['pattern_expansion', 'gravity']\n\n# 126-130\nskill_series['54d9e175.json'] = ['detect_grid', 'separate_images', 'associate_images_to_images']\nskill_series['5521c0d9.json'] = ['pattern_moving', 'measure_length']\nskill_series['5582e5ca.json'] = ['count_tiles', 'dominant_color']\nskill_series['5614dbcf.json'] = ['remove_noise', 'image_resizing']\nskill_series['56dc2b01.json'] = ['gravity', 'direction_guessing', 'pattern_expansion']\n\n# 131-135\nskill_series['56ff96f3.json'] = ['pattern_completion', 'rectangle_guessing']\nskill_series['57aa92db.json'] = ['draw_pattern_from_point', 'pattern_repetition', 'pattern_resizing']\nskill_series['5ad4f10b.json'] = ['color_guessing', 'remove_noise', 'recoloring', 'crop', 'image_resizing']\nskill_series['5bd6f4ac.json'] = ['rectangle_guessing', 'crop']\nskill_series['5c0a986e.json'] = ['draw_line_from_point', 'diagonals', 'direction_guessing']\n\n# 136-140\nskill_series['5c2c9af4.json'] = ['rectangle_guessing', 'pattern_expansion']\nskill_series['5daaa586.json'] = ['detect_grid', 'crop', 'draw_line_from_point', 'direction_guessing']\nskill_series['60b61512.json'] = ['pattern_completion']\nskill_series['6150a2bd.json'] = ['image_rotation']\nskill_series['623ea044.json'] = ['draw_line_from_point', 'diagonals']\n\n# 141-145\nskill_series['62c24649.json'] = ['image_repetition', 'image_reflection', 'image_rotation']\nskill_series['63613498.json'] = ['recoloring', 'compare_image', 'detect_wall']\nskill_series['6430c8c4.json'] = ['detect_wall', 'separate_images', 'take_complement', 'pattern_intersection']\nskill_series['6455b5f5.json'] = ['measure_area', 'take_maximum', 'take_minimum', 'loop_filling', 'associate_colors_to_ranks']\nskill_series['662c240a.json'] = ['separate_images', 'detect_symmetry',  'find_the_intruder', 'crop']\n\n# 146-150\nskill_series['67385a82.json'] = ['recoloring', 'measure_area', 'associate_colors_to_bools']\nskill_series['673ef223.json'] = ['recoloring', 'draw_line_from_point', 'portals']\nskill_series['6773b310.json'] = ['detect_grid', 'separate_images', 'count_tiles', 'associate_colors_to_numbers']\nskill_series['67a3c6ac.json'] = ['image_reflection']\nskill_series['67a423a3.json'] = ['pattern_intersection', 'contouring']\n\n# 151-155\nskill_series['67e8384a.json'] = ['image_repetition', 'image_reflection', 'image_rotation']\nskill_series['681b3aeb.json'] = ['pattern_moving', 'jigsaw', 'crop', 'bring_patterns_close']\nskill_series['6855a6e4.json'] = ['pattern_moving', 'direction_guessing', 'x_marks_the_spot']\nskill_series['68b16354.json'] = ['image_reflection']\nskill_series['694f12f3.json'] = ['rectangle_guessing', 'loop_filling', 'measure_area', 'associate_colors_to_ranks']\n\n# 156-160\nskill_series['6a1e5592.json'] = ['pattern_moving', 'jigsaw', 'recoloring']\nskill_series['6aa20dc0.json'] = ['pattern_repetition', 'pattern_juxtaposition', 'pattern_resizing']\nskill_series['6b9890af.json'] = ['pattern_moving', 'pattern_resizing', 'crop', 'x_marks_the_spot']\nskill_series['6c434453.json'] = ['replace_pattern']\nskill_series['6cdd2623.json'] = ['connect_the_dots', 'find_the_intruder', 'remove_noise']\n\n# 161-165\nskill_series['6cf79266.json'] = ['rectangle_guessing', 'recoloring']\nskill_series['6d0160f0.json'] = ['detect_grid', 'separate_image', 'find_the_intruder', 'pattern_moving']\nskill_series['6d0aefbc.json'] = ['image_repetition', 'image_reflection']\nskill_series['6d58a25d.json'] = ['draw_line_from_point']\nskill_series['6d75e8bb.json'] = ['rectangle_guessing', 'pattern_completion']\n\n# 166-170\nskill_series['6e02f1e3.json'] = ['count_different_colors', 'associate_images_to_numbers']\nskill_series['6e19193c.json'] = ['draw_line_from_point', 'direction_guessing', 'diagonals']\nskill_series['6e82a1ae.json'] = ['recoloring', 'count_tiles', 'associate_colors_to_numbers']\nskill_series['6ecd11f4.json'] = ['color_palette', 'recoloring', 'pattern_resizing', 'crop']\nskill_series['6f8cd79b.json'] = ['ex_nihilo', 'contouring']\n\n# 171-175\nskill_series['6fa7a44f.json'] = ['image_repetition', 'image_reflection']\nskill_series['72322fa7.json'] = ['pattern_repetition', 'pattern_juxtaposition']\nskill_series['72ca375d.json'] = ['find_the_intruder', 'detect_symmetry', 'crop']\nskill_series['73251a56.json'] = ['image_filling', 'diagonal_symmetry']\nskill_series['7447852a.json'] = ['pattern_expansion', 'pairwise_analogy']\n\n# 176-180\nskill_series['7468f01a.json'] = ['crop', 'image_reflection']\nskill_series['746b3537.json'] = ['crop', 'direction_guessing']\nskill_series['74dd1130.json'] = ['image_reflection', 'diagonal_symmetry']\nskill_series['75b8110e.json'] = ['separate_images', 'image_juxtaposition']\nskill_series['760b3cac.json'] = ['pattern_reflection', 'direction_guessing']\n\n# 181-185\nskill_series['776ffc46.json'] = ['recoloring', 'associate_colors_to_patterns', 'detect_enclosure', 'find_the_intruder']\nskill_series['77fdfe62.json'] = ['recoloring', 'color_guessing', 'detect_grid', 'crop']\nskill_series['780d0b14.json'] = ['detect_grid', 'summarize']\nskill_series['7837ac64.json'] = ['detect_grid', 'color_guessing', 'grid_coloring', 'crop', 'extrapolate_image_from_grid']\nskill_series['794b24be.json'] = ['count_tiles', 'associate_images_to_numbers']\n\n# 186-190\nskill_series['7b6016b9.json'] = ['loop_filling', 'background_filling', 'color_guessing']\nskill_series['7b7f7511.json'] = ['separate_images', 'detect_repetition', 'crop']\nskill_series['7c008303.json'] = ['color_palette', 'detect_grid', 'recoloring', 'color_guessing', 'separate_images', 'crop']\nskill_series['7ddcd7ec.json'] = ['draw_line_from_point', 'direction_guessing', 'diagonals']\nskill_series['7df24a62.json'] = ['pattern_repetition', 'pattern_rotation', 'pattern_juxtaposition', 'out_of_boundary']\n\n# 191-195\nskill_series['7e0986d6.json'] = ['color_guessing', 'remove_noise']\nskill_series['7f4411dc.json'] = ['rectangle_guessing', 'remove_noise']\nskill_series['7fe24cdd.json'] = ['image_repetition', 'image_rotation']\nskill_series['80af3007.json'] = ['crop', 'pattern_resizing', 'image_resizing', 'fractal_repetition']\nskill_series['810b9b61.json'] = ['recoloring', 'detect_closed_curves']\n\n# 196-200\nskill_series['82819916.json'] = ['pattern_repetition', 'color_guessing', 'draw_line_from_point', 'associate_colors_to_colors']\nskill_series['83302e8f.json'] = ['detect_grid', 'detect_closed_curves', 'rectangle_guessing', 'associate_colors_to_bools', 'loop_filling']\nskill_series['834ec97d.json'] = ['draw_line_from_border', 'pattern_repetition', 'spacing', 'measure_distance_from_side']\nskill_series['8403a5d5.json'] = ['draw_line_from_point', 'pattern_repetition', 'direction_guessing']\nskill_series['846bdb03.json'] = ['pattern_moving', 'pattern_reflection', 'crop', 'color_matching', 'x_marks_the_spot']\n\n# 201-205\nskill_series['855e0971.json'] = ['draw_line_from_point', 'direction_guessing', 'separate_images', 'holes']\nskill_series['85c4e7cd.json'] = ['color_guessing', 'recoloring', 'color_permutation']\nskill_series['868de0fa.json'] = ['loop_filling', 'color_guessing', 'measure_area', 'even_or_odd', 'associate_colors_to_bools']\nskill_series['8731374e.json'] = ['rectangle_guessing', 'crop', 'draw_line_from_point']\nskill_series['88a10436.json'] = ['pattern_repetition', 'pattern_juxtaposition']\n\n# 206-210\nskill_series['88a62173.json'] = ['detect_grid', 'separate_images', 'find_the_intruder', 'crop']\nskill_series['890034e9.json'] = ['pattern_repetition', 'rectangle_guessing', 'contouring']\nskill_series['8a004b2b.json'] = ['pattern_repetition', 'pattern_resizing', 'pattern_juxtaposition', 'rectangle_guessing', 'crop']\nskill_series['8be77c9e.json'] = ['image_repetition', 'image_reflection']\nskill_series['8d5021e8.json'] = ['image_repetition', 'image_reflection']\n\n# 211-215\nskill_series['8d510a79.json'] = ['draw_line_from_point', 'detect_wall', 'direction_guessing', 'associate_colors_to_bools']\nskill_series['8e1813be.json'] = ['recoloring', 'color_guessing', 'direction_guesing' 'crop', 'image_within_image']\nskill_series['8e5a5113.json'] = ['detect_wall', 'separate_images', 'image_repetition', 'image_rotation']\nskill_series['8eb1be9a.json'] = ['pattern_repetition', 'image_filling']\nskill_series['8efcae92.json'] = ['separate_images', 'rectangle_guessing', 'count_tiles', 'take_maximum', 'crop']\n\n# 216-220\nskill_series['8f2ea7aa.json'] = ['crop', 'fractal_repetition']\nskill_series['90c28cc7.json'] = ['crop', 'rectangle_guessing', 'summarize']\nskill_series['90f3ed37.json'] = ['pattern_repetition', 'recoloring']\nskill_series['913fb3ed.json'] = ['contouring', 'associate_colors_to_colors']\nskill_series['91413438.json'] = ['count_tiles', 'algebra', 'image_repetition']\n\n# 221-225\nskill_series['91714a58.json'] = ['find_the_intruder', 'remove_noise']\nskill_series['9172f3a0.json'] = ['image_resizing']\nskill_series['928ad970.json'] = ['rectangle_guessing', 'color_guessing', 'draw_rectangle']\nskill_series['93b581b8.json'] = ['pattern_expansion', 'color_guessing', 'out_of_boundary']\nskill_series['941d9a10.json'] = ['detect_grid', 'loop_filling', 'pairwise_analogy']\n\n# 226-230\nskill_series['94f9d214.json'] = ['separate_images', 'take_complement', 'pattern_intersection']\nskill_series['952a094c.json'] = ['rectangle_guessing', 'inside_out']\nskill_series['9565186b.json'] = ['separate_shapes', 'count_tiles', 'recoloring', 'take_maximum', 'associate_color_to_bools']\nskill_series['95990924.json'] = ['pattern_expansion']\nskill_series['963e52fc.json'] = ['image_expansion', 'pattern_expansion']\n\n# 231-235\nskill_series['97999447.json'] = ['draw_line_from_point', 'pattern_expansion']\nskill_series['97a05b5b.json'] = ['pattern_moving', 'pattern_juxtaposition', 'crop', 'shape_guessing']\nskill_series['98cf29f8.json'] = ['pattern_moving', 'bring_patterns_close']\nskill_series['995c5fa3.json'] = ['take_complement', 'detect_wall', 'separate_images', 'associate_colors_to_images', 'summarize']\nskill_series['99b1bc43.json'] = ['take_complement', 'detect_wall', 'separate_images', 'pattern_intersection']\n\n# 236-240\nskill_series['99fa7670.json'] = ['draw_line_from_point', 'pattern_expansion']\nskill_series['9aec4887.json'] = ['pattern_moving', 'x_marks_the_spot', 'crop', 'recoloring', 'color_guessing']\nskill_series['9af7a82c.json'] = ['separate_images', 'count_tiles', 'summarize', 'order_numbers']\nskill_series['9d9215db.json'] = ['pattern_expansion', 'pattern_reflection', 'pattern_rotation']\nskill_series['9dfd6313.json'] = ['image_reflection', 'diagonal_symmetry']\n\n# 241-245\nskill_series['9ecd008a.json'] = ['image_filling', 'pattern_expansion', 'pattern_reflection', 'pattern_rotation', 'crop']\nskill_series['9edfc990.json'] = ['background_filling', 'holes']\nskill_series['9f236235.json'] = ['detect_grid', 'summarize', 'image_reflection']\nskill_series['a1570a43.json'] = ['pattern_moving', 'rectangle_guessing', 'x_marks_the_spot']\nskill_series['a2fd1cf0.json'] = ['connect_the_dots']\n\n# 246-250\nskill_series['a3325580.json'] = ['separate_shapes', 'count_tiles', 'take_maximum', 'summarize', 'remove_intruders']\nskill_series['a3df8b1e.json'] = ['pattern_expansion', 'draw_line_from_point', 'diagonals', 'bounce']\nskill_series['a416b8f3.json'] = ['image_repetition']\nskill_series['a48eeaf7.json'] = ['pattern_moving', 'bring_patterns_close', 'gravity', 'direction_guessing']\nskill_series['a5313dff.json'] = ['loop_filling']\n\n# 251-255\nskill_series['a5f85a15.json'] = ['recoloring', 'pattern_modification', 'pairwise_analogy']\nskill_series['a61ba2ce.json'] = ['pattern_moving', 'bring_patterns_close', 'crop', 'jigsaw']\nskill_series['a61f2674.json'] = ['separate_shapes', 'count_tiles', 'take_maximum', 'take_minimum', 'recoloring', 'associate_colors_to_ranks', 'remove_intruders']\nskill_series['a64e4611.json'] = ['background_filling', 'rectangle_guessing']\nskill_series['a65b410d.json'] = ['pattern_expansion', 'count_tiles', 'associate_colors_to_ranks']\n\n# 256-260\nskill_series['a68b268e.json'] = ['detect_grid', 'separate_images', 'pattern_juxtaposition']\nskill_series['a699fb00.json'] = ['pattern_expansion', 'connect_the_dots']\nskill_series['a740d043.json'] = ['crop', 'detect_background_color', 'recoloring']\nskill_series['a78176bb.json'] = ['draw_parallel_line', 'direction_guessing', 'remove_intruders']\nskill_series['a79310a0.json'] = ['pattern_moving', 'recoloring', 'pairwise_analogy']\n\n# 261-265\nskill_series['a85d4709.json'] = ['separate_images', 'associate_colors_to_images', 'summarize']\nskill_series['a87f7484.json'] = ['separate_images', 'find_the_intruder', 'crop']\nskill_series['a8c38be5.json'] = ['pattern_moving', 'jigsaw', 'crop']\nskill_series['a8d7556c.json'] = ['recoloring', 'rectangle_guessing']\nskill_series['a9f96cdd.json'] = ['replace_pattern', 'out_of_boundary']\n\n# 266-270\nskill_series['aabf363d.json'] = ['recoloring', 'color_guessing', 'remove_intruders']\nskill_series['aba27056.json'] = ['pattern_expansion', 'draw_line_from_point', 'diagonals']\nskill_series['ac0a08a4.json'] = ['image_resizing', 'count_tiles', 'size_guessing']\nskill_series['ae3edfdc.json'] = ['bring_patterns_close', 'gravity']\nskill_series['ae4f1146.json'] = ['separate_images', 'count_tiles', 'crop']\n\n# 271-275\nskill_series['aedd82e4.json'] = ['recoloring', 'separate_shapes', 'count_tiles', 'take_minimum', 'associate_colors_to_bools']\nskill_series['af902bf9.json'] = ['ex_nihilo', 'x_marks_the_spot']\nskill_series['b0c4d837.json'] = ['measure_length', 'associate_images_to_numbers']\nskill_series['b190f7f5.json'] = ['separate_images', 'image_expasion', 'color_palette', 'image_resizing', 'replace_pattern']\nskill_series['b1948b0a.json'] = ['recoloring', 'associate_colors_to_colors']\n\n# 276-280\nskill_series['b230c067.json'] = ['recoloring', 'separate_shapes', 'find_the_intruder', 'associate_colors_to_bools']\nskill_series['b27ca6d3.json'] = ['find_the_intruder', 'count_tiles', 'contouring']\nskill_series['b2862040.json'] = ['recoloring', 'detect_closed_curves', 'associate_colors_to_bools']\nskill_series['b527c5c6.json'] = ['pattern_expansion', 'draw_line_from_point', 'contouring', 'direction_guessing', 'size_guessing']\nskill_series['b548a754.json'] = ['pattern_expansion', 'pattern_modification', 'x_marks_the_spot']\n\n# 281-285\nskill_series['b60334d2.json'] = ['replace_pattern']\nskill_series['b6afb2da.json'] = ['recoloring', 'replace_pattern', 'rectangle_guessing']\nskill_series['b7249182.json'] = ['pattern_expansion']\nskill_series['b775ac94.json'] = ['pattern_expansion', 'pattern_repetition', 'recoloring', 'pattern_rotation', 'pattern_reflection', 'direction_guessing', 'pattern_juxtaposition']\nskill_series['b782dc8a.json'] = ['pattern_expansion', 'maze']\n\n# 286-290\nskill_series['b8825c91.json'] = ['pattern_completion', 'pattern_rotation', 'pattern_reflection']\nskill_series['b8cdaf2b.json'] = ['pattern_expansion', 'draw_line_from_point', 'diagonals', 'pairwise_analogy']\nskill_series['b91ae062.json'] = ['image_resizing', 'size_guessing', 'count_different_colors']\nskill_series['b94a9452.json'] = ['crop', 'take_negative']\nskill_series['b9b7f026.json'] = ['find_the_intruder', 'summarize']\n\n# 291-295\nskill_series['ba26e723.json'] = ['pattern_modification', 'pairwise_analogy', 'recoloring']\nskill_series['ba97ae07.json'] = ['pattern_modification', 'pairwise_analogy', 'rettangle_guessing', 'recoloring']\nskill_series['bb43febb.json'] = ['loop_filling', 'rettangle_guessing']\nskill_series['bbc9ae5d.json'] = ['pattern_expansion', 'image_expansion']\nskill_series['bc1d5164.json'] = ['pattern_moving', 'pattern_juxtaposition', 'crop', 'pairwise_analogy']\n\n# 296-300\nskill_series['bd4472b8.json'] = ['detect_wall', 'pattern_expansion', 'ex_nihilo', 'color_guessing', 'color_palette']\nskill_series['bda2d7a6.json'] = ['recoloring', 'pairwise_analogy', 'pattern_modification', 'color_permutation']\nskill_series['bdad9b1f.json'] = ['draw_line_from_point', 'direction_guessing', 'recoloring', 'take_intersection']\nskill_series['be94b721.json'] = ['separate_shapes', 'count_tiles', 'take_maximum', 'crop']\nskill_series['beb8660c.json'] = ['pattern_moving', 'count_tiles', 'order_numbers']\n\n# 301-305\nskill_series['c0f76784.json'] = ['loop_filling', 'measure_area', 'associate_colors_to_numbers']\nskill_series['c1d99e64.json'] = ['draw_line_from_border', 'detect_grid']\nskill_series['c3e719e8.json'] = ['image_repetition', 'image_expansion', 'count_different_colors', 'take_maximum']\nskill_series['c3f564a4.json'] = ['pattern_expansion', 'image_filling']\nskill_series['c444b776.json'] = ['detect_grid', 'separate_images', 'find_the_intruder', 'image_repetition']\n\n# 306-310\nskill_series['c59eb873.json'] = ['image_resizing']\nskill_series['c8cbb738.json'] = ['pattern_moving', 'jigsaw', 'crop']\nskill_series['c8f0f002.json'] = ['recoloring', 'associate_colors_to_colors']\nskill_series['c909285e.json'] = ['find_the_intruder', 'crop', 'rectangle_guessing']\nskill_series['c9e6f938.json'] = ['image_repetition', 'image_reflection']\n\n# 311-315\nskill_series['c9f8e694.json'] = ['recoloring', 'pattern_repetition', 'color_palette']\nskill_series['caa06a1f.json'] = ['pattern_expansion', 'image_filling']\nskill_series['cbded52d.json'] = ['detect_grid', 'separate_images', 'pattern_modification', 'pattern_repetition', 'pattern_juxtaposition', 'connect_the_dots']\nskill_series['cce03e0d.json'] = ['image_repetition', 'image_expansion', 'pairwise_analogy']\nskill_series['cdecee7f.json'] = ['summarize', 'pairwise_analogy']\n\n# 316-320\nskill_series['ce22a75a.json'] = ['replace_pattern']\nskill_series['ce4f8723.json'] = ['detect_wall', 'separate_images', 'take_complement', 'take_intersection']\nskill_series['ce602527.json'] = ['crop', 'size_guessing', 'shape_guessing', 'find_the_intruder', 'remove_intruder']\nskill_series['ce9e57f2.json'] = ['recoloring', 'count_tiles', 'take_half']\nskill_series['cf98881b.json'] = ['detect_wall', 'separate_images', 'pattern_juxtaposition']\n\n# 321-325\nskill_series['d037b0a7.json'] = ['pattern_expansion', 'draw_line_from_point']\nskill_series['d06dbe63.json'] = ['pattern_expansion', 'pairwise_analogy']\nskill_series['d07ae81c.json'] = ['draw_line_from_point', 'diagonals', 'color_guessing']\nskill_series['d0f5fe59.json'] = ['separate_shapes', 'count_shapes', 'associate_images_to_numbers', 'pairwise_analogy']\nskill_series['d10ecb37.json'] = ['crop']\n\n# 326-330\nskill_series['d13f3404.json'] = ['image_expansion', 'draw_line_from_point', 'diagonals']\nskill_series['d22278a0.json'] = ['pattern_expansion', 'pairwise_analogy']\nskill_series['d23f8c26.json'] = ['crop', 'image_expansion']\nskill_series['d2abd087.json'] = ['separate_shapes', 'count_tiles', 'associate_colors_to_numbers', 'recoloring']\nskill_series['d364b489.json'] = ['pattern_expansion']\n\n# 331-335\nskill_series['d406998b.json'] = ['recoloring', 'one_yes_one_no', 'cylindrical']\nskill_series['d43fd935.json'] = ['draw_line_from_point', 'direction_guessing', 'projection_unto_rectangle']\nskill_series['d4469b4b.json'] = ['dominant_color', 'associate_images_to_colors']\nskill_series['d4a91cb9.json'] = ['connect_the_dots', 'direction_guessing']\nskill_series['d4f3cd78.json'] = ['rectangle_guessing', 'recoloring', 'draw_line_from_point']\n\n# 336-340\nskill_series['d511f180.json'] = ['associate_colors_to_colors']\nskill_series['d5d6de2d.json'] = ['loop_filling', 'replace_pattern', 'remove_intruders']\nskill_series['d631b094.json'] = ['count_tiles', 'dominant_color', 'summarize']\nskill_series['d687bc17.json'] = ['bring_patterns_close', 'gravity', 'direction_guessing', 'find_the_intruder', 'remove_intruders']\nskill_series['d6ad076f.json'] = ['bridges', 'connect_the_dots', 'draw_line_from_point']\n\n# 341-345\nskill_series['d89b689b.json'] = ['pattern_juxtaposition', 'summarize', 'direction_guessing']\nskill_series['d8c310e9.json'] = ['pattern_expansion', 'pattern_repetition', 'pattern_completion']\nskill_series['d90796e8.json'] = ['replace_pattern']\nskill_series['d9f24cd1.json'] = ['draw_line_from_point', 'gravity', 'obstacles']\nskill_series['d9fac9be.json'] = ['find_the_intruder', 'summarize', 'x_marks_the_spot']\n\n# 346-350\nskill_series['dae9d2b5.json'] = ['pattern_juxtaposition', 'separate_images', 'recoloring']\nskill_series['db3e9e38.json'] = ['pattern_expansion', 'out_of_boundary']\nskill_series['db93a21d.json'] = ['contouring', 'draw_line_from_point', 'measure_area', 'measure_length', 'algebra']\nskill_series['dbc1a6ce.json'] = ['connect_the_dots']\nskill_series['dc0a314f.json'] = ['pattern_completion', 'crop']\n\n# 351-355\nskill_series['dc1df850.json'] = ['contouring', 'pattern_expansion', 'out_of_boundary']\nskill_series['dc433765.json'] = ['pattern_moving', 'direction_guessing', 'only_one']\nskill_series['ddf7fa4f.json'] = ['color_palette', 'recoloring']\nskill_series['de1cd16c.json'] = ['separate_images', 'count_tiles', 'take_maximum', 'summarize']\nskill_series['ded97339.json'] = ['connect_the_dots']\n\n# 356-360\nskill_series['e179c5f4.json'] = ['pattern_expansion', 'bouncing']\nskill_series['e21d9049.json'] = ['pattern_expansion', 'draw_line_from_point', 'color_palette']\nskill_series['e26a3af2.json'] = ['remove_noise', 'separate_images']\nskill_series['e3497940.json'] = ['detect_wall', 'separate_images', 'image_reflection', 'image_juxtaposition']\nskill_series['e40b9e2f.json'] = ['pattern_expansion', 'pattern_reflection', 'pattern_rotation']\n\n# 361-365\nskill_series['e48d4e1a.json'] = ['count_tiles', 'pattern_moving', 'detect_grid', 'out_of_boundary']\nskill_series['e5062a87.json'] = ['pattern_repetition', 'pattern_juxtaposition']\nskill_series['e509e548.json'] = ['recoloring', 'associate_colors_to_shapes', 'homeomorphism']\nskill_series['e50d258f.json'] = ['separate_images', 'detect_background_color', 'crop', 'count_tiles', 'take_maximum']\nskill_series['e6721834.json'] = ['pattern_moving', 'pattern_juxtaposition', 'crop']\n\n# 366-370\nskill_series['e73095fd.json'] = ['loop_filling', 'rectangle_guessing']\nskill_series['e76a88a6.json'] = ['pattern_repetition', 'pattern_juxtaposition']\nskill_series['e8593010.json'] = ['holes', 'count_tiles', 'loop_filling', 'associate_colors_to_numbers']\nskill_series['e8dc4411.json'] = ['pattern_expansion', 'direction_guessing']\nskill_series['e9614598.json'] = ['pattern_expansion', 'direction_guessing', 'measure_length']\n\n# 371-375\nskill_series['e98196ab.json'] = ['detect_wall', 'separate_images', 'image_juxtaposition']\nskill_series['e9afcf9a.json'] = ['pattern_modification']\nskill_series['ea32f347.json'] = ['separate_shapes', 'count_tiles', 'recoloring', 'associate_colors_to_ranks']\nskill_series['ea786f4a.json'] = ['pattern_modification', 'draw_line_from_point', 'diagonals']\nskill_series['eb281b96.json'] = ['image_repetition', 'image_reflection']\n\n# 376-380\nskill_series['eb5a1d5d.json'] = ['summarize']\nskill_series['ec883f72.json'] = ['pattern_expansion', 'draw_line_from_point', 'diagonals']\nskill_series['ecdecbb3.json'] = ['pattern_modification', 'draw_line_from_point']\nskill_series['ed36ccf7.json'] = ['image_rotation']\nskill_series['ef135b50.json'] = ['draw_line_from_point', 'bridges', 'connect_the_dots']\n\n# 381-385\nskill_series['f15e1fac.json'] = ['draw_line_from_point', 'gravity', 'obstacles', 'direction_guessing']\nskill_series['f1cefba8.json'] = ['draw_line_from_point', 'pattern_modification']\nskill_series['f25fbde4.json'] = ['crop', 'image_resizing']\nskill_series['f25ffba3.json'] = ['pattern_repetition', 'pattern_reflection']\nskill_series['f2829549.json'] = ['detect_wall', 'separate_images', 'take_complement', 'pattern_intersection']\n\n# 386-390\nskill_series['f35d900a.json'] = ['pattern_expansion']\nskill_series['f5b8619d.json'] = ['pattern_expansion', 'draw_line_from_point', 'image_repetition']\nskill_series['f76d97a5.json'] = ['take_negative', 'recoloring', 'associate_colors_to_colors']\nskill_series['f8a8fe49.json'] = ['pattern_moving', 'pattern_reflection']\nskill_series['f8b3ba0a.json'] = ['detect_grid', 'find_the_intruder', 'dominant_color', 'count_tiles', 'summarize', 'order_numbers']\n\n# 391-395\nskill_series['f8c80d96.json'] = ['pattern_expansion', 'background_filling']\nskill_series['f8ff0b80.json'] = ['separate_shapes', 'count_tiles', 'summarize', 'order_numbers']\nskill_series['f9012d9b.json'] = ['pattern_expansion', 'pattern_completion', 'crop']\nskill_series['fafffa47.json'] = ['separate_images', 'take_complement', 'pattern_intersection']\nskill_series['fcb5c309.json'] = ['rectangle_guessing', 'separate_images', 'count_tiles', 'take_maximum', 'crop', 'recoloring']\n\n# 396-399\nskill_series['fcc82909.json'] = ['pattern_expansion', 'separate_images', 'count_different_colors']\nskill_series['feca6190.json'] = ['pattern_expansion', 'image_expansion', 'draw_line_from_point', 'diagonals']\nskill_series['ff28f65a.json'] = ['count_shapes', 'associate_images_to_numbers']\nskill_series['ff805c23.json'] = ['pattern_expansion', 'pattern_completion', 'crop']\n\nskill_series.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shape predictor"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Shape predictor\n\ndef shape_finder(train, test):\n    # return output shape of test\n    \n    inputs = []\n    outputs = []\n    for task in train:\n        inputs.append(np.array(task[\"input\"]))\n        outputs.append(np.array(task[\"output\"]))\n    \n    shape_ratio = [[np.array(train[i][\"input\"]).shape[j]/np.array(train[i][\"output\"]).shape[j] for j in range(len(np.array(train[i][\"input\"]).shape))] for i in range(len(train))]\n    \n    # input shape is a multiple of output\n    if all(shape_ratio[0] == shape_ratio[i] for i in range(len(shape_ratio))):\n        return [tuple([np.array(test[i][\"input\"]).shape[j]/shape_ratio[0][j] for j in range(len(inputs[i].shape))]) for i in range(len(test))]\n    \n    # All output shape are the same\n    elif all(item.shape == outputs[0].shape for item in outputs):\n        return [outputs[0].shape for i in range(len(test))]\n    \n    return([(0,0),(0,0),(0,0)])\n\n\n# function to test shape_finder\nscore = 0\ntraining_path = data_path / 'training'\ntraining_tasks = sorted(os.listdir(training_path))\nfailed = []\nfor i in range(len(training_tasks)):\n\n    task_file = str(training_path / training_tasks[i])\n\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n        \n    out_shape = shape_finder(task[\"train\"], task[\"test\"])\n    for j in range(len(task[\"test\"])):\n        if out_shape[j] == np.array(task[\"test\"][j][\"output\"]).shape:\n            score+=1\n        else:\n            failed.append(i)\nprint(f\"Score : {score}/{len(training_tasks)} \\n{score*100/len(training_tasks)}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logic specific resolution\n\n## begining with task that only need one logic\n\nFind all the task that have only one logic associated and which should be easier to resolve"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_task_with_logic(logic):\n    #retrieve tasks in list\n    tasks = []\n    for task in one_logic_task.keys():\n        if one_logic_task[task][0] == logic:\n            tasks.append(task)\n    #load\n    loaded_tasks = []\n    for task in tasks:\n        with open(str(training_path / task), \"r\") as f:\n            loaded_tasks.append(json.load(f))\n    return loaded_tasks\n\n# get all task that have only one logic associated\n\none_logic_task = pd.Series()\nfor key in skill_series.keys():\n    if len(skill_series[key]) == 1:\n        one_logic_task[key] = skill_series[key]\nvalues, count = np.unique(one_logic_task.values, return_counts=True)\nfor i,value in enumerate(values):\n    print(value, \":\", count[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task classification\nTry to classify which logic is needed on a specific task"},{"metadata":{},"cell_type":"markdown","source":"### Data prep"},{"metadata":{},"cell_type":"markdown","source":"### Get task that need 1 skill"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_skill = []\nfor skills in skill_series:\n    for skill in skills:\n        if skill not in unique_skill:\n            unique_skill.append(skill)\nprint(len(unique_skill))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocess image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_img(img, preprocess_type, shift= (0,0)):\n    #preprocess one image\n    output_shape = (32,32)\n    img = np.asarray(img)\n\n    if preprocess_type == \"CENTER\":\n        # TODO\n        raise NotImplementedError\n    elif preprocess_type == \"CORNER\":\n        #TODO improve by having another color for outmap\n        background = np.zeros(output_shape)\n        background[shift[0]:shift[0]+img.shape[0],shift[1]:shift[1]+img.shape[1]] = img\n        return background\n    return img.tolist()\n\ndef preprocess_in_out(in_out, preprocess_type, data_augmentation=False):\n    #preprocess input and output the same way\n    in_out_dict = in_out.copy()\n    shift = (0,0)\n    if data_augmentation:\n        max_shape = (32 - max([(len(in_out_dict[key])) for key in in_out_dict.keys()]),32 - max([(len(in_out_dict[key][0])) for key in in_out_dict.keys()]))\n        shift = (random.Random().choice(range(max_shape[0])), random.Random().choice(range(max_shape[1])))\n    for keys in in_out_dict.keys():\n        in_out_dict[keys] = preprocess_img(in_out_dict[keys], preprocess_type, shift)\n    return in_out_dict\n\n\ndef preprocess(task, preprocess_type, data_augmentation=False):\n    #preprocess a whole task\n    for task_keys in task.keys():\n        for index,_ in enumerate(task[task_keys]):\n            task[task_keys][index] = preprocess_in_out(task[task_keys][index], preprocess_type, data_augmentation)\n    return task","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for task in skill_series.keys():\n    with open(str(training_path / task), \"r\") as f:\n        task = json.load(f)\n        for task_keys in task:\n            for index,_ in enumerate(task[task_keys]):\n                for sub_key in task[task_keys][index].keys():\n                    max_shape = (max([(len(task[task_keys][index][key])) for key in task[task_keys][index].keys()]),max([(len(task[task_keys][index][key][0])) for key in task[task_keys][index].keys()]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare data"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# make hot vector\ntotal_skills = []\nfor skills in skill_series.values:\n    for skill in skills:\n        if skill not in total_skills:\n            total_skills.append(skill)\ntotal_skills = sorted(total_skills)\n# print(total_skills)\n\ntrain_input_example = []\ntrain_output_example = []\ntrain_label = []\n\ntest_input_example = []\ntest_output_example = []\ntest_label = []\n\nfor task in skill_series.keys():\n    for i in range(20):\n        # make 20 image with data augmentation\n        with open(str(training_path / task), \"r\") as f:\n            loaded_task = preprocess(json.load(f), \"CORNER\", True) \n\n        indexes = []\n        for skill in skill_series[task]:\n            indexes.append(total_skills.index(skill))\n        label = sum(tf.one_hot(indexes, len(total_skills)))\n\n        for train_task in loaded_task[\"train\"]:\n            train_input_example.append(tf.convert_to_tensor(train_task[\"input\"]))\n            train_output_example.append(tf.convert_to_tensor(train_task[\"output\"]))\n            train_label.append(label)\n        for test_task in loaded_task[\"test\"]:\n            test_input_example.append(tf.convert_to_tensor(test_task[\"input\"]))\n            test_output_example.append(tf.convert_to_tensor(test_task[\"output\"]))\n            test_label.append(label)\n\nprint(train_input_example[0],train_output_example[0], train_label[0])\n\ntrain_example_dataset = tf.data.Dataset.from_tensor_slices((train_input_example, train_output_example))\ntrain_example_dataset = train_example_dataset.map(lambda x, y: (tf.math.divide(x,9),tf.math.divide(y,9)))\ntrain_example_dataset = train_example_dataset.map(lambda x, y : (tf.expand_dims(x,-1), tf.expand_dims(y,-1)))\n\ntrain_label_dataset = tf.data.Dataset.from_tensor_slices((train_label))\ntrain_dataset = tf.data.Dataset.zip((train_example_dataset, train_label_dataset)).batch(32).repeat().shuffle(1301)\n\n\ntest_example_dataset = tf.data.Dataset.from_tensor_slices((test_input_example, test_output_example))\ntest_example_dataset = test_example_dataset.map(lambda x, y: (tf.math.divide(x,9),tf.math.divide(y,9)))\ntest_example_dataset = test_example_dataset.map(lambda x, y : (tf.expand_dims(x,-1), tf.expand_dims(y,-1)))\n\ntest_label_dataset = tf.data.Dataset.from_tensor_slices((test_label))\ntest_dataset = tf.data.Dataset.zip((test_example_dataset, test_label_dataset)).batch(32).repeat().shuffle(416)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model define"},{"metadata":{},"cell_type":"markdown","source":"### test with resnet for v2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import backend, regularizers, models\nL2_WEIGHT_DECAY = 0.01\nBATCH_NORM_DECAY = 0.99\nBATCH_NORM_EPSILON = 0.001\n\ndef identity_block(input_tensor, kernel_size, filters):\n    \"\"\"The identity block is the block that has no conv layer at shortcut.\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of\n            middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    if backend.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n \n    x = layers.Conv2D(filters1, (1, 1), use_bias=False,\n                      kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_tensor)\n \n    x = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x)\n    x = layers.Activation('relu')(x)\n \n    x = layers.Conv2D(filters2, kernel_size,\n                      padding='same', use_bias=False,\n                      kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n \n    x = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x)\n \n    x = layers.Activation('relu')(x)\n \n    x = layers.Conv2D(filters3, (1, 1), use_bias=False,\n                      kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n \n    x = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x)\n \n    x = layers.add([x, input_tensor])\n    x = layers.Activation('relu')(x)\n    return x\n\ndef conv_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n    \"\"\"A block that has a conv layer at shortcut.\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of\n            middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n    # Returns\n        Output tensor for the block.\n    Note that from stage 3,\n    the second conv layer at main path is with strides=(2, 2)\n    And the shortcut should have strides=(2, 2) as well\n    \"\"\"\n \n    filters1, filters2, filters3 = filters\n \n    if backend.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n \n    x = layers.Conv2D(filters1, (1, 1), use_bias=False,\n                      kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_tensor)\n    x = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x)\n    x = layers.Activation('relu')(x)\n \n \n    x = layers.Conv2D(filters2, kernel_size, strides=strides, padding='same',\n                      use_bias=False, kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n    x = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x)\n    x = layers.Activation('relu')(x)\n \n    x = layers.Conv2D(filters3, (1, 1), use_bias=False,\n                      kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n    x = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x)\n \n    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, use_bias=False,\n                             kernel_initializer='he_normal',\n                             kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_tensor)\n    shortcut = layers.BatchNormalization(axis=bn_axis,\n                                         momentum=BATCH_NORM_DECAY,\n                                         epsilon=BATCH_NORM_EPSILON)(shortcut)\n \n    x = layers.add([x, shortcut])\n    x = layers.Activation('relu')(x)\n    return x\n\ndef resnet50(num_classes, input_shape):\n    img_input = layers.Input(shape=input_shape)\n    inputA = Input(shape=input_shape)\n    inputB = Input(shape=input_shape)\n \n    if backend.image_data_format() == 'channels_first':\n        x1 = layers.Lambda(lambda x: backend.permute_dimensions(x, (0, 3, 1, 2)),name='transpose')(inputA)\n        bn_axis = 1\n    else:  # channels_last\n        x1 = inputA\n        bn_axis = 3\n    # Conv1 (7x7,64,stride=2)\n    x1 = layers.ZeroPadding2D(padding=(3, 3))(x1)\n    x1 = layers.Conv2D(32, (7, 7),\n                      strides=(2, 2),\n                      padding='valid', use_bias=False,\n                      kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x1)\n    x1 = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x1)\n    x1 = layers.Activation('relu')(x1)\n    x1 = layers.ZeroPadding2D(padding=(1, 1))(x1)\n \n    # 3x3 max pool,stride=2\n    x1 = layers.MaxPooling2D((3, 3), strides=(2, 2))(x1)\n     \n    if backend.image_data_format() == 'channels_first':\n        x2 = layers.Lambda(lambda x: backend.permute_dimensions(x, (0, 3, 1, 2)),name='transpose')(inputB)\n        bn_axis = 1\n    else:  # channels_last\n        x2 = inputB\n        bn_axis = 3\n    # Conv1 (7x7,64,stride=2)\n    x2 = layers.ZeroPadding2D(padding=(3, 3))(x2)\n    x2 = layers.Conv2D(32, (7, 7),\n                      strides=(2, 2),\n                      padding='valid', use_bias=False,\n                      kernel_initializer='he_normal',\n                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x2)\n    x2 = layers.BatchNormalization(axis=bn_axis,\n                                  momentum=BATCH_NORM_DECAY,\n                                  epsilon=BATCH_NORM_EPSILON)(x2)\n    x2 = layers.Activation('relu')(x2)\n    x2 = layers.ZeroPadding2D(padding=(1, 1))(x2)\n \n    # 3x3 max pool,stride=2\n    x2 = layers.MaxPooling2D((3, 3), strides=(2, 2))(x2)\n    \n    \n    combined = concatenate([x1, x2])\n\n    # Conv2_x\n    # 1×1, 64\n    # 3×3, 64\n    # 1×1, 256\n \n    x = conv_block(combined, 3, [64, 64, 256], strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256])\n    x = identity_block(x, 3, [64, 64, 256])\n \n    # Conv3_x\n    #\n    # 1×1, 128\n    # 3×3, 128\n    # 1×1, 512\n \n    x = conv_block(x, 3, [128, 128, 512])\n    x = identity_block(x, 3, [128, 128, 512])\n    x = identity_block(x, 3, [128, 128, 512])\n    x = identity_block(x, 3, [128, 128, 512])\n \n    # Conv4_x\n    # 1×1, 256\n    # 3×3, 256\n    # 1×1, 1024\n    x = conv_block(x, 3, [256, 256, 1024])\n    x = identity_block(x, 3, [256, 256, 1024])\n    x = identity_block(x, 3, [256, 256, 1024])\n    x = identity_block(x, 3, [256, 256, 1024])\n    x = identity_block(x, 3, [256, 256, 1024])\n    x = identity_block(x, 3, [256, 256, 1024])\n \n    # 1×1, 512\n    # 3×3, 512\n    # 1×1, 2048\n    x = conv_block(x, 3, [512, 512, 2048])\n    x = identity_block(x, 3, [512, 512, 2048])\n    x = identity_block(x, 3, [512, 512, 2048])\n \n    # average pool, 1000-d fc, softmax\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(\n        num_classes, activation='softmax',\n        kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY),\n        bias_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n    # Create model.\n    return models.Model([inputA,inputB], x, name='resnet50')\n\nresnet50 = resnet50(132,(32,32,1))\ntf.keras.utils.plot_model(resnet50, show_shapes=True, dpi=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50.compile(optimizer=keras.optimizers.Adam() ,  # Optimizer\n              # Loss function to minimize\n              loss=keras.losses.CosineSimilarity(),\n              # List of metrics to monitor\n              metrics=['accuracy'])\nresnet50.fit(train_dataset, epochs=30, steps_per_epoch = 1000, validation_steps = 200, validation_data=test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"inputA = Input(shape=(32,32,1))\ninputB = Input(shape=(32,32,1))\n\nfilters = (32, 64)\nx=inputA\ny=inputB\nchanDim = -1\n# define the model input\n# loop over the number of filters\nx = Conv2D(16, (3, 3), padding=\"same\")(x)\nx = Activation(\"relu\")(x)\nx = BatchNormalization(axis=chanDim)(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Model(inputs=inputA, outputs=x)\ny = Conv2D(16, (3, 3), padding=\"same\")(y)\ny = Activation(\"relu\")(y)\ny = BatchNormalization(axis=chanDim)(y)\ny = MaxPooling2D(pool_size=(2, 2))(y)\ny = Model(inputs=inputB, outputs=y)\n\ncombined = concatenate([x.output, y.output])\nfor (i, f) in enumerate(filters):\n    # if this is the first CONV layer then set the input\n    # appropriately\n    # CONV => RELU => BN => POOL\n    if i == 0:\n        first = Conv2D(f, (3, 3), padding=\"same\")(combined)\n    else :\n        first = Conv2D(f, (3, 3), padding=\"same\")(z)\n\n    z = Activation(\"relu\")(first)\n    z = BatchNormalization(axis=chanDim)(z)\n    z = MaxPooling2D(pool_size=(2, 2))(z)\n\n# flatten the volume, then FC => RELU => BN => DROPOUT\nz = Flatten()(z)\nz = Dense(512)(z)\nz = Activation(\"relu\")(z)\nz = BatchNormalization(axis=chanDim)(z)\nz = Dropout(0.5)(z)\n# apply another FC layer, this one to match the number of nodes\n# coming out of the MLP\nz = Dense(132)(z)\nz = Activation(\"relu\")(z)\nmodel = Model([x.input, y.input], z)\ntf.keras.utils.plot_model(model, show_shapes=True, dpi=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam() ,  # Optimizer\n              # Loss function to minimize\n              loss=keras.losses.CosineSimilarity(),\n              # List of metrics to monitor\n              metrics=['accuracy'])\nmodel.fit(train_dataset, epochs=30, steps_per_epoch = 1000, validation_steps = 200, validation_data=test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training_path)\nfor file in os.listdir(training_path):\n    print('\\n',file)\n    with open(os.path.join(training_path, file)) as f:\n        load = json.load(f)\n    preprocess(load, \"CORNER\")\n    result = model((tf.expand_dims(tf.expand_dims(load[\"train\"][0][\"input\"], -1),0), tf.expand_dims(tf.expand_dims(load[\"train\"][0][\"output\"], -1),0)))\n    print([total_skills[i] for i in np.nonzero(result)[1]],'\\n', sorted(skill_series[file]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2n model define"},{"metadata":{"trusted":true},"cell_type":"code","source":"def downsample(filters, size, apply_batchnorm=True):\n  initializer = tf.random_normal_initializer(0., 0.02)\n\n  result = tf.keras.Sequential()\n  result.add(\n      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n                             kernel_initializer=initializer, use_bias=False))\n\n  if apply_batchnorm:\n    result.add(tf.keras.layers.BatchNormalization())\n\n  result.add(tf.keras.layers.LeakyReLU())\n\n  return result\n\ndef upsample(filters, size, apply_dropout=False):\n  initializer = tf.random_normal_initializer(0., 0.02)\n\n  result = tf.keras.Sequential()\n  result.add(\n    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n                                    padding='same',\n                                    kernel_initializer=initializer,\n                                    use_bias=False))\n\n  result.add(tf.keras.layers.BatchNormalization())\n\n  if apply_dropout:\n      result.add(tf.keras.layers.Dropout(0.5))\n\n  result.add(tf.keras.layers.ReLU())\n\n  return result\ndef Generator():\n  OUTPUT_CHANNELS = 9\n  inputs = tf.keras.layers.Input(shape=[32,32,9])\n\n  down_stack = [\n    downsample(4, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n    downsample(8, 4), # (bs, 64, 64, 128)\n    downsample(16, 4), # (bs, 32, 32, 256)\n    downsample(32, 4), # (bs, 16, 16, 512)\n  ]\n\n  up_stack = [\n    upsample(32, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n    upsample(16, 4), # (bs, 16, 16, 1024)\n    upsample(8, 4), # (bs, 32, 32, 512)\n    upsample(4, 4), # (bs, 64, 64, 256)\n  ]\n\n  initializer = tf.random_normal_initializer(0., 0.02)\n  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n                                         strides=2,\n                                         padding='same',\n                                         kernel_initializer=initializer,\n                                         activation='tanh') # (bs, 256, 256, 3)\n\n  x = inputs\n\n  # Downsampling through the model\n  skips = []\n  for down in down_stack:\n    x = down(x)\n    skips.append(x)\n\n  skips = reversed(skips[:-1])\n\n  # Upsampling and establishing the skip connections\n  for up, skip in zip(up_stack, skips):\n    x = up(x)\n    x = tf.keras.layers.Concatenate()([x, skip])\n    x = tf.keras.layers.Conv2D(32,(1,1),padding='same')(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n\n  x = last(x)\n\n  return tf.keras.Model(inputs=inputs, outputs=x)\n\ngenerator = Generator()\ntf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data prep"},{"metadata":{"trusted":true},"cell_type":"code","source":"LOGIC_TO_LOAD = [4]\nfor LOGIC in LOGIC_TO_LOAD:\n    print(len(load_task_with_logic(\"pattern_expansion\")[LOGIC][\"train\"]))\n    for task in load_task_with_logic(\"pattern_expansion\")[LOGIC][\"train\"]:\n        to_plot = preprocess_in_out(task, 'CORNER',True)\n        gen_output = generator(tf.expand_dims(tf.one_hot(np.array(to_plot[\"input\"], dtype=np.int64),9),0), training=False)\n        plot(to_plot[\"input\"])\n        plot(to_plot[\"output\"])\n        plot(tf.math.argmax(gen_output[0,...],axis=-1))\n        #print([gen_output[0][i] for i in range(len(tf.math.argmax(gen_output,axis=-1)[0]))])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_train = []\noutput_train = []\nfor LOGIC in LOGIC_TO_LOAD:\n    for task in load_task_with_logic(\"pattern_expansion\")[LOGIC][\"train\"]:\n        for i in range(100):\n            # data augment 20 times\n            preprocessed_task_train = preprocess_in_out(task,\"CORNER\", True)\n            input_train.append(tf.one_hot(np.array(preprocessed_task_train[\"input\"], dtype=np.int64),9))\n            output_train.append(tf.one_hot(np.array(preprocessed_task_train[\"output\"], dtype=np.int64),9))\nprint(len(input_train), len(output_train))\ninput_test = []\noutput_test = []\nfor LOGIC in LOGIC_TO_LOAD:\n    for task in load_task_with_logic(\"pattern_expansion\")[LOGIC][\"test\"]:\n        for i in range(100):\n            # data augment 20 times\n            preprocessed_task_test = preprocess_in_out(task,\"CORNER\", True)\n            input_test.append(tf.one_hot(np.array(preprocessed_task_test[\"input\"], dtype=np.int64),9))\n            output_test.append(tf.one_hot(np.array(preprocessed_task_test[\"output\"], dtype=np.int64),9))\n\ntrain_input_dataset = tf.data.Dataset.from_tensor_slices(input_train)\n#train_input_dataset = train_input_dataset.map(lambda x: (tf.math.divide(x,9)))\n#train_input_dataset = train_input_dataset.map(lambda x : (tf.expand_dims(x,-1)))\n\ntrain_output_dataset = tf.data.Dataset.from_tensor_slices(output_train)\n#train_output_dataset = train_output_dataset.map(lambda x: (tf.math.divide(x,9)))\n#train_output_dataset = train_output_dataset.map(lambda x : (tf.expand_dims(x,-1)))\n\ntrain_dataset = tf.data.Dataset.zip((train_input_dataset, train_output_dataset)).batch(5).repeat()\n\ntest_input_dataset = tf.data.Dataset.from_tensor_slices(input_test)\n#test_input_dataset = test_input_dataset.map(lambda x: (tf.math.divide(x,9)))\n#test_input_dataset = test_input_dataset.map(lambda x : (tf.expand_dims(x,-1)))\n\ntest_output_dataset = tf.data.Dataset.from_tensor_slices(output_test)\n#test_output_dataset = test_output_dataset.map(lambda x: (tf.math.divide(x,9)))\n#test_output_dataset = test_output_dataset.map(lambda x : (tf.expand_dims(x,-1)))\n\ntest_dataset = tf.data.Dataset.zip((test_input_dataset, test_output_dataset)).batch(5).repeat()\n\ngenerator.compile(optimizer=keras.optimizers.Adam() ,  # Optimizer\n              # Loss function to minimize\n              loss=keras.losses.CosineSimilarity(),\n              # List of metrics to monitor\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator.fit(train_dataset, epochs=5, steps_per_epoch = 2000, validation_steps = 500, validation_data=test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for elemn in train_dataset:\n    [plot(inner) for inner in [tf.squeeze(elem, 0) for elem in tf.argmax(elemn,axis=-1)]]\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}