{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook trains a cellular automata model using Tensorflow. \n[arseny-n](https://www.kaggle.com/arsenynerinovsky) described what is celular automata and how it is related to this challenge in his [notebook](https://www.kaggle.com/arsenynerinovsky/cellular-automata-as-a-language-for-reasoning).\n\nIn the notebook [Training Cellular Automata Part II: Learning Tasks](https://www.kaggle.com/teddykoker/training-cellular-automata-part-ii-learning-tasks#Solved-Tasks) [Teddy Koker](https://www.kaggle.com/teddykoker) implemented a related model,  which solves some of the tasks. \n\nThe model in this notebook is quite similar to the one that Teddy implemented, please read his notebook first if you find something unclear in this one.\nThe model seems to be the same with Teddy's one, except the training mechanism is different, and it is in TensorFlow instead of PyTorch."},{"metadata":{},"cell_type":"markdown","source":"Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D\nimport os\nimport json\nimport numpy as np\nfrom pathlib import Path\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib import animation, rc\nfrom IPython.display import HTML\n\nrc('animation', html='jshtml')\n\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge')\ntrain_path = data_path / 'training'\nvalid_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\n\ntrain_tasks = {task.stem: json.load(task.open())\n               for task in train_path.iterdir()}\nvalid_tasks = {task.stem: json.load(task.open())\n               for task in valid_path.iterdir()}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"Helpful functions"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n    ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n\n\ndef plot_pictures(pictures, labels = None):\n    if labels is None:\n        labels = range(len(pictures))\n    fig, axs = plt.subplots(1, len(pictures), figsize=(2 * len(pictures), 32))\n    for i, (pict, label) in enumerate(zip(pictures, labels)):\n        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n        axs[i].set_title(label)\n    plt.show()\n\n\ndef plot_sample(sample, predict=None):\n    if predict is None:\n        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n    else:\n        plot_pictures([sample['input'], sample['output'], predict], [\n                      'Input', 'Output', 'Predict'])\n\n\n\ndef input_output_shape_is_same(task):\n    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n\n\ndef calk_score(task_test, predict):\n    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]\n\ndef to_hot(x):\n    return tf.one_hot(x,depth=10)\ndef from_hot(x):\n    return tf.argmax(x,axis=-1)\n\ndef loss_f(y_pred,y_truth):\n    return tf.reduce_mean(tf.keras.backend.categorical_crossentropy(y_pred, y_truth))\n\n\n\ntask = train_tasks[\"db3e9e38\"][\"train\"]\ntest = train_tasks[\"db3e9e38\"][\"test\"]\nfor sample in task:\n    plot_sample(sample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Basic Model"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def Model():\n    return tf.keras.Sequential([\n        Conv2D(128, 3,\n        kernel_initializer=tf.random_normal_initializer,\n        activation=tf.nn.relu,padding=\"same\"),\n        Conv2D(10, 1, activation=\"softmax\",\n               kernel_initializer=tf.random_normal_initializer\n               ),\n    ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model trainer"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def solve(task):\n    ca = Model()\n    num_epochs = 100\n    trainer = tf.keras.optimizers.Adam(lr=0.1)\n    for e in range(num_epochs):\n        loss = 0\n        with tf.GradientTape() as g:\n            # for sample in task:\n            iter_n = tf.random.uniform([], minval=2, maxval=15, dtype=tf.int32)\n            for sample in task:\n                x = to_hot(sample[\"input\"])[None]\n                y = to_hot(sample[\"output\"])[None]\n                for i in tf.range(iter_n):\n                    x = ca(x)\n                factor = tf.cast(iter_n,tf.float32)\n                loss += loss_f(x,y)*factor*factor + 1e3*loss_f(ca(y),y)\n                # loss += loss_f(x,y)\n        grads = g.gradient(loss, ca.weights)\n        grads = [g / (tf.norm(g) + 1e-8) for g in grads]\n        trainer.apply_gradients(zip(grads, ca.weights))\n    return ca\n\n\n\nca = %time solve(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Solve tasks"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def predict(ca,x,num=2):\n    for i in range(num):\n        r = ca(x)\n        # r = to_hot(from_hot(r))\n        x = r\n    return x\n\ndef evaluate(task):\n    if input_output_shape_is_same(task):\n        ca = solve(task[\"train\"])\n        for test in task[\"test\"]:\n            to_pred = to_hot(test[\"input\"])[None]\n            test[\"prediction\"] = from_hot(predict(ca,to_pred, 13))[0].numpy()\n        # return pred\n    return None\n\nfor idx, task in tqdm(train_tasks.items()):\n    evaluate(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show results"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for idx, task in tqdm(train_tasks.items()):\n        for test in task[\"test\"]:\n            if \"prediction\" in test and test[\"prediction\"] is not None:\n                plot_pictures([test[\"input\"],test[\"output\"],test[\"prediction\"]],[\"inp\",\"out\",\"pred\"])\n            else:\n                print(None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}