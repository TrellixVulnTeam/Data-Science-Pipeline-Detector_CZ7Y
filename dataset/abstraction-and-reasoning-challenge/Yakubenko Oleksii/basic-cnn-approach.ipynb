{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Solving tasks using one Conv2d(in_channels=10, out_channels=10, kernel_size=5, padding=2)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json\nimport os\nfrom os.path import join as path_join\n\n\ndef load_data(path):\n    tasks = pd.Series()\n    for file_path in os.listdir(path):\n        task_file = path_join(path, file_path)\n\n        with open(task_file, 'r') as f:\n            task = json.load(f)\n\n        tasks[file_path[:-5]] = task\n    return tasks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tasks = load_data('../input/abstraction-and-reasoning-challenge/training/')\nevaluation_tasks = load_data('../input/abstraction-and-reasoning-challenge/evaluation/')\ntest_tasks = load_data('../input/abstraction-and-reasoning-challenge/test/')\n\ntrain_tasks.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam\nfrom torch.nn import Conv2d\nfrom torch import FloatTensor, LongTensor\n\n\n\ndef inp2img(inp):\n    inp = np.array(inp)\n    img = np.full((10, inp.shape[0], inp.shape[1]), 0, dtype=np.uint8)\n    for i in range(10):\n        img[i] = (inp==i)\n    return img\n\n\nclass TaskSolver:        \n    def train(self, task_train, n_epoch=30):\n        \"\"\"basic pytorch train loop\"\"\"\n        self.net = Conv2d(in_channels=10, out_channels=10, kernel_size=5, padding=2)\n        \n        criterion = CrossEntropyLoss()\n        optimizer = Adam(self.net.parameters(), lr = 0.1)\n        \n        for epoch in range(n_epoch):\n            for sample in task_train:\n                inputs = FloatTensor(inp2img(sample['input'])).unsqueeze(dim=0)\n                labels = LongTensor(sample['output']).unsqueeze(dim=0)\n                \n                optimizer.zero_grad()\n                outputs = self.net(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        \n        return self\n            \n    def predict(self, task_test):\n        predictions = []\n        with torch.no_grad():\n            for sample in task_test:\n                inputs = FloatTensor(inp2img(sample['input'])).unsqueeze(dim=0)\n                outputs = self.net(inputs)\n                pred =  outputs.squeeze(dim=0).cpu().numpy().argmax(0)\n                predictions.append(pred)\n                                     \n        return predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"def input_output_shape_is_same(task):\n    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n\ndef calk_score(task_test, predict):\n    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(tasks):\n    ts = TaskSolver()\n    result = []\n    predictions = []\n    for task in tqdm(tasks):\n        if input_output_shape_is_same(task):\n            ts.train(task['train'])\n            pred = ts.predict(task['test'])\n            score = calk_score(task['test'], pred)\n        else:\n            pred = [el['input'] for el in task['test']]\n            score = [0]*len(task['test'])\n        \n        predictions.append(pred)\n        result.append(score)\n       \n    return result, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_result, train_predictions = evaluate(train_tasks)\ntrain_solved = [any(score) for score in train_result]\n\ntotal = sum([len(score) for score in train_result])\nprint(f\"solved : {sum(train_solved)} from {total} ({sum(train_solved)/total})\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation_result, evaluation_predictions = evaluate(evaluation_tasks)\nevaluation_solved = [any(score) for score in evaluation_result]\n\ntotal = sum([len(score) for score in evaluation_result])\nprint(f\"solved : {sum(evaluation_solved)} from {total} ({sum(evaluation_solved)/total})\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize\n\nvisualize solved tasks"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import colors\n\n\ncmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n    \ndef plot_pictures(pictures, labels):\n    fig, axs = plt.subplots(1, len(pictures), figsize=(2*len(pictures),32))\n    for i, (pict, label) in enumerate(zip(pictures, labels)):\n        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n        axs[i].set_title(label)\n    plt.show()\n    \n\ndef plot_sample(sample, predict=None):\n    if predict is None:\n        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n    else:\n        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train solved tasks"},{"metadata":{"trusted":true},"cell_type":"code","source":"for task, prediction, solved in tqdm(zip(train_tasks, train_predictions, train_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### evaluation solved tasks"},{"metadata":{"trusted":true},"cell_type":"code","source":"for task, prediction, solved in tqdm(zip(evaluation_tasks, evaluation_predictions, evaluation_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\ndef make_pediction(tasks):\n    ts = TaskSolver()\n    result = pd.Series()\n    for idx, task in tqdm(test_tasks.iteritems()):\n        if input_output_shape_is_same(task):\n            ts.train(task['train'])\n            pred = ts.predict(task['test'])\n        else:\n            pred = [el['input'] for el in task['test']]\n        \n        for i, p in enumerate(pred):\n            result[f'{idx}_{i}'] = flattener(np.array(p).tolist())\n       \n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = make_pediction(test_tasks)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = submission.reset_index()\nsubmission.columns = ['output_id', 'output']\nsubmission.to_csv('submission.csv', index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All train tasks predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"for task, prediction in tqdm(zip(train_tasks, train_predictions)):\n    if input_output_shape_is_same(task):\n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}