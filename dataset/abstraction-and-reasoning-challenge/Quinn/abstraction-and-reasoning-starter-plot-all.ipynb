{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Abstraction and Reasoning Starter Notebook\n\nThis notebook will get you started on on the basics of this competition"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I like to use the `Path` class for my paths."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pathlib import Path\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `training` folder has 400 JSON tasks. The names of the first three are shown below."},{"metadata":{"trusted":true},"cell_type":"code","source":"training_tasks = sorted(os.listdir(training_path))\nprint(training_tasks[:3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In each task, there are two dictionary keys, `train` and `test`. You learn the pattern from the train input-output pairs, and then apply the pattern to the `test` input, to predict an output."},{"metadata":{"trusted":true},"cell_type":"code","source":"task_file = str(training_path / '00d62c1b.json')\n\nwith open(task_file, 'r') as f:\n    task = json.load(f)\n\nprint(task.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tasks have multiple `train` input-output pairs. Most tasks have a single `test` input-output pair, although some have more than one."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train_pairs = len(task['train'])\nn_test_pairs = len(task['test'])\n\nprint(f'task contains {n_train_pairs} training pairs')\nprint(f'task contains {n_test_pairs} test pairs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drilling into the first `train` input-output pair, we can see the grids are expressed as 2d lists with integers 0-9."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(task['train'][0]['input'])\ndisplay(task['train'][0]['output'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function to plot the first train/test input/output pairs of a task\n\nYou can use this function to plot the first `train` and `test` grids. The color aligns with what is found on the ARC app. Note though, the ARC app presents the grids to scale, where these display the grids in the same size, regardless of their dimension."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_task(task):\n    \"\"\"\n    Plots the all train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, len(task['train']) * 2, figsize=(25,25))\n    \n    for i in range(len(task['train'])):\n        axs[i*2].imshow(task['train'][i]['input'], cmap=cmap, norm=norm)\n        axs[i*2].axis('off')\n        axs[i*2].set_title('Train Input ' + str(i))\n        axs[i*2 + 1].imshow(task['train'][i]['output'], cmap=cmap, norm=norm)\n        axs[i*2 + 1].axis('off')\n        axs[i*2 + 1].set_title('Train Output ' + str(i))\n    \n    plt.tight_layout()\n    plt.show()\n    \n    fig, axs = plt.subplots(1, len(task['test']) * 2, figsize=(5,5))\n    for i in range(len(task['test'])):\n        axs[i*2].imshow(task['test'][i]['input'], cmap=cmap, norm=norm)\n        axs[i*2].axis('off')\n        axs[i*2].set_title('Test Input ' + str(i - len(task['train'])))\n        axs[i*2 + 1].imshow(task['test'][i]['output'], cmap=cmap, norm=norm)\n        axs[i*2 + 1].axis('off')\n        axs[i*2 + 1].set_title('Test Output ' + str(i - len(task['train'])))\n        \n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for train_json in sorted(os.listdir(training_path)):\n    task_file = str(training_path / train_json)\n\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n\n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using the correct prediction format"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `output_id` is the `id` of the task, followed by the index of the `test` input that you should use to make your prediction. The `output` is the predicted output of the corresponding `test` input, reformatted into a string representation. (You can make three predictions per `output_id`, delineated by a space.) Use the following function to convert from a 2d python list to the string representation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndisplay(example_grid)\nprint(flattener(example_grid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Re-creating the sample submission output\n\nThis demonstrates how to loop over the sample submission and make predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"for output_id in submission.index:\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    f = str(test_path / str(task_id + '.json'))\n    with open(f, 'r') as read_file:\n        task = json.load(read_file)\n    # skipping over the training examples, since this will be naive predictions\n    # we will use the test input grid as the base, and make some modifications\n    data = task['test'][pair_id]['input'] # test pair input\n    # for the first guess, predict that output is unchanged\n    pred_1 = flattener(data)\n    # for the second guess, change all 0s to 5s\n    data = [[5 if i==0 else i for i in j] for j in data]\n    pred_2 = flattener(data)\n    # for the last gues, change everything to 0\n    data = [[0 for i in j] for j in data]\n    pred_3 = flattener(data)\n    # concatenate and add to the submission output\n    pred = pred_1 + ' ' + pred_2 + ' ' + pred_3 + ' ' \n    submission.loc[output_id, 'output'] = pred\n\nsubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}