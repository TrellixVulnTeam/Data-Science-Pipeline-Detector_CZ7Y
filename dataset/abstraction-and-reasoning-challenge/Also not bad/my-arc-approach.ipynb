{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preparing the ground <a id=\"preparing-the-ground\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import libraries and define hyperparameters <a id=\"import-libraries-and-define-hyperparameters\"></a> ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport json\nimport time\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom keras.utils import to_categorical\n\nimport seaborn as sns\nimport plotly.express as px\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nimport plotly.figure_factory as ff\n\nimport torch\nT = torch.Tensor\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SIZE = 800\nEPOCHS = 30\nCONV_OUT_1 = 50\nCONV_OUT_2 = 100\nBATCH_SIZE = 32\n\nTEST_PATH = Path('../input/abstraction-and-reasoning-challenge/')\nSUBMISSION_PATH = Path('../input/abstraction-and-reasoning-challenge/')\n\nTEST_PATH = TEST_PATH / 'test'\nSUBMISSION_PATH = SUBMISSION_PATH / 'sample_submission.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the ARC data <a id=\"load-the-arc-data\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Get testing tasks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_task_files = sorted(os.listdir(TEST_PATH))\n\ntest_tasks = []\ntask_ids = []\nfor task_file in test_task_files:\n    with open(str(TEST_PATH / task_file), 'r') as f:\n        task = json.load(f)\n        test_tasks.append(task)\n        task_ids.append(task_file[:task_file.find(\".\")])\n        if \"00576224\" == task_file[:-5]:\n            print(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_ids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract training and testing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Xs_test, Xs_train, ys_train = [], [], []\n\nfor task in test_tasks:\n    X_test, X_train, y_train = [], [], []\n\n    for pair in task[\"test\"]:\n        X_test.append(pair[\"input\"])\n\n    for pair in task[\"train\"]:\n        X_train.append(pair[\"input\"])\n        y_train.append(pair[\"output\"])\n    \n    Xs_test.append(X_test)\n    Xs_train.append(X_train)\n    ys_train.append(y_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"matrices = []\nfor X_test in Xs_test:\n    for X in X_test:\n        matrices.append(X)\n        \nvalues = []\nfor matrix in matrices:\n    for row in matrix:\n        for value in row:\n            values.append(value)\n            \ndf = pd.DataFrame(values)\ndf.columns = [\"values\"]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\ntraining_tasks = sorted(os.listdir(training_path))\n\ndef plot_matrix(matrix, ax):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    ax.imshow(matrix, cmap=cmap, norm=norm)\n    width = np.shape(matrix)[1]\n    height = np.shape(matrix)[0]\n    ax.set_xticks(np.arange(0,width))\n    ax.set_yticks(np.arange(0,height))\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.tick_params(length=0)\n    ax.grid(True)\n\ndef plot_task(task, num=0, dupl=True):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    fig, ax = plt.subplots(1, 4, figsize=(15,15))\n    \n    plot_matrix(task['train'][num]['input'], ax[0])\n    ax[0].set_title('Train Input')\n    \n    plot_matrix(task['train'][num]['output'], ax[1])\n    ax[1].set_title('Train Output')\n    \n    plot_matrix(task['test'][0]['input'], ax[2])\n    ax[2].set_title('Test Input')\n    \n    plot_matrix(task['test'][0]['output'], ax[3])\n    ax[3].set_title('Test Output')\n    plt.tight_layout()\n    plt.show()\n\nfor i in range(4):\n\n    task_file = str(training_path / training_tasks[i])\n\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number frequency <a id=\"number-frequency\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"different_y = 0\ndifferent_xy = 0\nk = []\nfor i in range(len(training_tasks)):\n    task_file = str(training_path / training_tasks[i])\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    outs = [np.array(task['train'][i]['output']) for i in range(len(task['train']))]\n    inps = [np.array(task['train'][i]['input']) for i in range(len(task['train']))]\n    \n    if len(set([x.shape for x in outs])) > 1:\n        different_y += 1\n        if any([x.shape != y.shape for x, y in zip(outs, inps)]):\n            different_xy +=1\n            k.append(i)\nprint(different_y, different_xy)\nprint(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_file = str(training_path / training_tasks[376])\nwith open(task_file, 'r') as f:\n    task = json.load(f)\nplot_task(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helper functions","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def replace_values(a, d):\n    return np.array([d.get(i, i) for i in range(a.min(), a.max() + 1)])[a - a.min()]\n\ndef repeat_matrix(a):\n    return np.concatenate([a]*((SIZE // len(a)) + 1))[:SIZE]\n\ndef get_new_matrix(X):\n    if len(set([np.array(x).shape for x in X])) > 1:\n        X = np.array([X[0]])\n    return X\n\ndef get_outp(outp, dictionary=None, replace=True):\n    if replace:\n        outp = replace_values(outp, dictionary)\n\n    outp_matrix_dims = outp.shape\n    outp_probs_len = outp.shape[0]*outp.shape[1]*10\n    outp = to_categorical(outp.flatten(),\n                          num_classes=10).flatten()\n\n    return outp, outp_probs_len, outp_matrix_dims","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Mutator:\n    def __init__(self):\n        pass\n    \n    def mutate(self, X, y=None):\n        return X, y\n\nclass OneOfMutator(Mutator):\n    def __init__(self, mutators):\n        self.mutators = mutators\n\n    def mutate(self, X, y=None):\n        return np.random.choice(self.mutators).mutate(X, y)\n    \nclass MutationPipeline(Mutator):\n    def __init__(self, mutators):\n        self.mutators = mutators\n    \n    def mutate(self, X, y=None):\n        for mutator in self.mutators:\n            X, y = mutator.mutate(X, y)\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Shifter(Mutator):\n    \"\"\" Class will shift whole picture to a random direction\n    \"\"\"\n    def __init__(self, sigma):\n        self.sigma = sigma\n    \n    def mutate(self, X, y=None):\n        direction = np.random.randint(8)\n        shift = np.random.randint(self.sigma)\n        \n        def do_shift(picture):\n            shifted = np.zeros(picture.shape, dtype=int)\n            if shift == 0:\n                return picture\n            if direction == 0:\n                shifted[:,:-shift] = picture[:,shift:]\n            if direction == 1:\n                shifted[:,shift:] = picture[:,:-shift]\n            if direction == 2:\n                shifted[:-shift,:] = picture[shift:,:]\n            if direction == 3:\n                shifted[shift:,:] = picture[:-shift,:]\n            if direction == 4:\n                shifted[:-shift,:-shift] = picture[shift:,shift:]\n            if direction == 5:\n                shifted[:-shift,shift:] = picture[shift:,:-shift]\n            if direction == 6:\n                shifted[shift:,shift:] = picture[:-shift,:-shift]\n            if direction == 7:\n                shifted[shift:,:-shift] = picture[:-shift,shift:]\n            return shifted\n        \n        return do_shift(X), (None if y is None else do_shift(y))\n    \nmutator = Shifter(2)\n\nfig, ax = plt.subplots(1, 4, figsize=(15,15))\nplot_matrix(np.array(Xs_train[0][0]), ax[0])\nplot_matrix(np.array(ys_train[0][0]), ax[1])\nmutated = mutator.mutate(np.array(Xs_train[0][0]), np.array(ys_train[0][0]))\nplot_matrix(mutated[0], ax[2])\nplot_matrix(mutated[1], ax[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ColorSwitcher(Mutator):\n    \"\"\" Class will shift whole picture to a random direction\n    \"\"\"\n    def __init__(self, except_=[]):\n        self.colors = []\n        for i in range(10):\n            if i not in except_:\n                self.colors.append(i)\n        \n    \n    def mutate(self, X, y=None):\n        rep = np.array(self.colors)\n        orig = np.array(self.colors.copy())\n        np.random.shuffle(rep)\n        dictionary = dict(zip(orig, rep))\n        return replace_values(X, dictionary), (None if y is None else replace_values(y, dictionary))\n    \nmutator = ColorSwitcher([7])\n\n\nfig, ax = plt.subplots(1, 4, figsize=(15,15))\nplot_matrix(np.array(Xs_train[0][1]), ax[0])\nplot_matrix(np.array(ys_train[0][1]), ax[1])\nmutated = mutator.mutate(np.array(Xs_train[0][1]), np.array(ys_train[0][1]))\nplot_matrix(mutated[0], ax[2])\nplot_matrix(mutated[1], ax[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.ndimage.interpolation import rotate\nclass Rotator(Mutator):\n    \"\"\" Class will shift whole picture to a random direction\n    \"\"\"\n    def __init__(self, angles):\n        self.angles = angles\n    \n    def mutate(self, X, y=None):\n        g = np.random.randint(len(self.angles))\n        angle = self.angles[g]\n        return np.rot90(X, angle), (None if y is None else np.rot90(y, angle))\n    \nmutator = Rotator([0,1,2])\n\nfig, ax = plt.subplots(1, 4, figsize=(15,15))\nplot_matrix(np.array(X_train[0]), ax[0])\nplot_matrix(np.array(y_train[0]), ax[1])\nmutated = mutator.mutate(np.array(X_train[0]), np.array(y_train[0]))\nplot_matrix(mutated[0], ax[2])\nplot_matrix(mutated[1], ax[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flipper(Mutator):\n    \"\"\" Class will shift whole picture to a random direction\n    \"\"\"\n    def __init__(self, do_t=False):\n        self.do_t = do_t\n    \n    def mutate(self, X, y=None):\n        direction = np.random.randint(3-self.do_t)\n        def do_mirror(picture):\n            if direction == 0:\n                return np.flipud(picture)\n            if direction == 1:\n                return np.fliplr(picture)\n            if direction == 2:\n                return picture.T\n            return picture\n        return do_mirror(X), (None if y is None else do_mirror(y))\n    \nmutator = Flipper(False)\n\nfig, ax = plt.subplots(1, 4, figsize=(15,15))\nplot_matrix(np.array(X_train[0]), ax[0])\nplot_matrix(np.array(y_train[0]), ax[1])\nmutated = mutator.mutate(np.array(X_train[0]), np.array(y_train[0]))\nplot_matrix(mutated[0], ax[2])\nplot_matrix(mutated[1], ax[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PyTorch DataLoader","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_borders(X):\n    result = []\n    max_ = np.max([np.array(x).shape for x in X])\n    for x in X:\n        x = np.array(x)\n        extended = np.zeros((max_, max_))\n        diffw = max_ - x.shape[0]\n        diffh = max_ - x.shape[1]\n\n        def get_borders_add(diff):\n            addl = diff // 2\n            if addl != diff / 2.0:\n                addr = addl + 1\n            else:\n                addr = addl\n            return addl, addr\n\n        addl, addr = get_borders_add(diffw)\n        addt, addb = get_borders_add(diffh)\n        result.append((addl, max_ - addr, addt, max_ - addb))\n    return result\n    \ndef extend_matrices_to_max(X):\n    if len(set([np.array(x).shape for x in X])) == 1:\n        return X\n    result = []\n    borders = get_borders(X)\n    max_ = np.max([np.array(x).shape for x in X])\n    for i, x in enumerate(X):\n        x = np.array(x)\n        extended = np.zeros((max_, max_))\n        extended[borders[i][0]:borders[i][1], borders[i][2]:borders[i][3]] = x[:, :]\n        result.append(extended.astype(int))\n\n    return np.array(result)\n\ndef narrow_prediction(prediction, orig_X, orig_y):\n    different_y_sizes = False\n    different_with_x_y = False\n    if len(set([x.shape for x in orig_y])) > 1:\n        different_y_sizes = True\n        if any([x.shape != y.shape for x, y in zip(orig_y, orig_X)]):\n            different_with_x_y = True\n    if not different_with_x_y:\n        borders = get_borders(orig_y)\n        return np.array([y[borders[i][0]:borders[i][1], borders[i][2]:borders[i][3]] for i,y in enumerate(prediction)])\n\n    result = []\n    for y in prediction:\n        for i in range(y.shape[0]):\n            if np.sum(y[i]) > 1e-5:\n                left = i\n        for i in reversed(range(y.shape[0])):\n            if np.sum(y[i]) > 1e-5:\n                right = i + 1\n        for i in range(y.shape[1]):\n            if np.sum(y[:,i]) > 1e-5:\n                bot = i\n        for i in reversed(range(y.shape[1])):\n            if np.sum(y[:,i]) > 1e-5:\n                top = i + 1\n        result.append(y[left:right, bot:top])\n    return np.array(result)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Extender:\n    def __init__(self, X_train, X_test, y_train):\n        self.X_train = np.array(X_train)\n        self.X_test = np.array(X_test)\n        self.y_train = np.array(y_train)\n        \n        def get_max_shape(X):\n            shapes1 = [[len(x)] for x in X]\n            shapes2 = [[len(x[0])] for x in X]\n            return np.max((np.max(shapes1),np.max(shapes2)))\n        \n        max_train = get_max_shape(X_train)\n        max_test = get_max_shape(X_test)\n\n        max_ = np.max([max_train, max_test])\n        self.X_train_borders = self.get_borders(self.X_train, max_)\n        self.X_test_borders = self.get_borders(self.X_test, max_)\n\n        self.different_y_sizes = False\n        self.different_with_x_y = False\n        if len(set([np.shape(x) for x in self.y_train])) > 1:\n            self.different_y_sizes = True\n            if any([np.shape(x) != np.shape(y) for x, y in zip(self.y_train, self.X_train)]):\n                self.different_with_x_y = True\n        \n        \n        #self.extended_X_train = np.kron(self.extend_matrices_to_max(self.X_train, max_, self.X_train_borders), np.ones((3,3)))\n        #self.extended_X_test = np.kron(self.extend_matrices_to_max(self.X_test, max_, self.X_test_borders), np.ones((3,3)))\n        self.extended_X_train = self.extend_matrices_to_max(self.X_train, max_, self.X_train_borders)\n        self.extended_X_test = self.extend_matrices_to_max(self.X_test, max_, self.X_test_borders)\n        if not self.different_with_x_y and self.different_y_sizes:\n            self.y_train_borders = self.get_borders(self.y_train, max_)\n            self.extended_y_train = self.extend_matrices_to_max(self.y_train, max_, self.y_train_borders)  \n        else:\n            max_y_train = get_max_shape(self.y_train)\n            self.y_train_borders = self.get_borders(self.y_train, max_y_train)\n            self.extended_y_train = self.extend_matrices_to_max(self.y_train, max_y_train, self.y_train_borders)        \n        \n    def get_borders(self, X, max_):\n        result = []\n\n        for x in X:\n            x = np.array([np.array(k) for k in x])\n            extended = np.zeros((max_, max_))\n            diffw = max_ - x.shape[0]\n            diffh = max_ - x.shape[1]\n\n            def get_borders_add(diff):\n                addl = diff // 2\n                if addl != diff / 2.0:\n                    addr = addl + 1\n                else:\n                    addr = addl\n                return addl, addr\n\n            addl, addr = get_borders_add(diffw)\n            addt, addb = get_borders_add(diffh)\n            result.append((addl, max_ - addr, addt, max_ - addb))\n        return result\n    \n    def extend_matrices_to_max(self, X, max_, borders):\n        shapes = [np.array(x).shape for x in X]\n        result = []\n        for i, x in enumerate(X):\n            x = np.array([np.array(k,dtype=int) for k in x])\n            extended = np.zeros((max_, max_), dtype=int)\n            extended[borders[i][0]:borders[i][1], borders[i][2]:borders[i][3]] = x[:, :]\n\n            result.append(extended)\n        \n        return np.array(result)\n\n    def narrow_prediction(self, prediction, idxs):\n        if not self.different_y_sizes:\n            return prediction\n        if not self.different_with_x_y:\n            borders = self.X_test_borders\n            return np.array([y[borders[i][0]:borders[i][1], borders[i][2]:borders[i][3]] for y,i in zip(prediction, idxs)])\n\n        result = []\n        for y in prediction:\n            left, bot=0,0\n            right, top = y.shape\n            for i in range(y.shape[0]):\n                if np.sum(y[i]) > 1e-5:\n                    left = i\n                    break\n            for i in reversed(range(y.shape[0])):\n                if np.sum(y[i]) > 1e-5:\n                    right = i + 1\n                    break\n            \n            for i in range(y.shape[1]):\n                if np.sum(y[:,i]) > 1e-5:\n                    bot = i\n                    break\n            for i in reversed(range(y.shape[1])):\n                if np.sum(y[:,i]) > 1e-5:\n                    top = i + 1\n                    break\n            result.append(y[left:right, bot:top])\n        return np.array(result)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num = 5\next = Extender(Xs_train[num], Xs_test[num], ys_train[num])\nfig, ax = plt.subplots(1, 4, figsize=(15,15))\nplot_matrix(np.array(Xs_train[num][0]), ax[0])\nplot_matrix(np.array(ys_train[num][0]), ax[1])\nplot_matrix(Xs_test[num][0], ax[2])\nplot_matrix(ext.narrow_prediction([ext.extended_y_train[0]], [0])[0], ax[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ext.extended_y_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ext.extended_X_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ARCDataset(Dataset):\n    def __init__(self, X_train, X_test, y_train, mutation=ColorSwitcher()):\n        self.mutation = mutation\n        self.extender = Extender(X_train, X_test, y_train)\n        self.X_train = repeat_matrix(self.extender.extended_X_train)\n        self.y_train = repeat_matrix(self.extender.extended_y_train)\n        self.colors = []\n        for x in X_train:\n            self.colors += np.unique(x).tolist()\n        for x in X_test:\n            self.colors += np.unique(x).tolist()\n        for x in y_train:\n            self.colors += np.unique(x).tolist()\n        \n    def __len__(self):\n        return SIZE\n    \n    def get_input_dimension(self):\n        return self.X_train[0].shape\n        \n    def get_output_dimension(self):\n        return self.y_train[0].shape\n    \n    def get_output_prob_dimension(self):\n        return self.y_train[0].shape\n\n    def narrow_prediction(self, prediction, idxs):\n        return self.extender.narrow_prediction(prediction, idxs)\n        \n    def get_extended_test(self):\n        return self.extender.extended_X_test\n    \n    def round_colors(self, prediction):\n        @np.vectorize\n        def find_nearest(value):\n            array = np.array(self.colors)\n            idx = (np.abs(array - value)).argmin()\n            return array[idx]\n        return find_nearest(prediction)\n    \n    def __getitem__(self, idx):\n        in_, out_ = self.mutation.mutate(self.X_train[idx], self.y_train[idx])\n\n        return torch.FloatTensor(in_.copy()), torch.LongTensor(out_.copy()), self.get_output_prob_dimension()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset = ARCDataset(Xs_train[0], Xs_test[0], ys_train[0],MutationPipeline([\n#                                            ColorSwitcher(),\n#                                            #Shifter(1),\n#                                            #Flipper(),\n#                                            #Shifter(1),\n#                                            #Rotator([0, 2]),\n#                                            #Shifter(1)\n#                                        ]),)\n# for i in range(50):\n#     fig, ax = plt.subplots(1, 4, figsize=(15,15))\n#     plot_matrix(np.array(Xs_train[0][0]), ax[0])\n#     plot_matrix(np.array(ys_train[0][0]), ax[1])\n#     mutated = mutator.mutate(np.array(Xs_train[0][0]), np.array(ys_train[0][0]))\n#     ten = dataset[i]\n#     plot_matrix(ten[0].detach(), ax[2])\n#     plot_matrix(ten[1].detach(), ax[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling <a id=\"modeling\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/cpUtXRR.png\" width=\"600px\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n\nI use a basic CNN model that takes 2D input and returns 2D output. The sequential architecture is follows:\n\n1. (Conv2D + ReLU) **x** 2\n2. MaxPool **x** 2\n3. Dense\n4. Softmax\n\nThe softmax probabilities are converted to the final 2D matrix through argmax and resize functions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### PyTorch CNN model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        # if you have padding issues, see\n        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)\n    \n    def shape(self):\n        self.conv.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" Full assembly of the parts to form the complete network \"\"\"\n\nimport torch.nn.functional as F\n\n\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, in_d, out_d, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        # self.start = Up(1, 1, bilinear)\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        #self.down2 = Down(128, 256)\n        #self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        #self.down4 = Down(512, 1024 // factor)\n        #self.up1 = Up(1024, 512 // factor, bilinear)\n        #self.up2 = Up(768, 256 // factor, bilinear)\n        #self.up3 = Up(384, 128 // factor, bilinear)\n        self.up4 = Up(192, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n        self.conv = nn.Conv2d(n_classes, n_classes, kernel_size=np.abs(in_d[0]-out_d[0])+1, padding=-np.min((in_d[0]-out_d[0], 0)))\n\n    def forward(self, x):\n        # x1 = self.start(x)\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        #x3 = self.down2(x2)\n        #x4 = self.down3(x3)\n        #x = self.up2(x4, x3)\n        #x = self.up3(x3, x2)\n        x = self.up4(x2, x1)\n        logits = self.outc(x)\n        logits = self.conv(logits)\n        \n        return logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nclass BasicCNNModel(nn.Module):\n    def __init__(self, inp_dim=(10, 10), outp_dim=(10, 10)):\n        super(BasicCNNModel, self).__init__()\n        \n        #self.begin = nn.Conv2d(1, 3, 1)\n        \n        self.network = UNet(1, 10, inp_dim, outp_dim)\n        #self.network['classifier'][4] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n\n    def forward(self, x):\n        #x_ = self.begin.forward(x)\n        x_ = self.network.forward(x)\n        return x_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=BasicCNNModel()\na.parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [5]:\n    task_file = str(training_path / training_tasks[i])\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and postprocessing <a id=\"training-and-postprocessing\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I train the model using PyTorch's autograd functionality. Specifically, I use the **Adam** optimizer and the **MSE** loss function.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Helper functions","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def transform_dim(inp_dim, outp_dim, test_dim):\n    return (test_dim[0]*outp_dim[0]/inp_dim[0],\n            test_dim[1]*outp_dim[1]/inp_dim[1])\n\ndef resize(x, test_dim, inp_dim):\n    if inp_dim == test_dim:\n        return x\n    else:\n        return cv2.resize(flt(x), inp_dim,\n                          interpolation=cv2.INTER_AREA)\n\ndef flt(x): return np.float32(x)\ndef npy(x): return x.cpu().detach().numpy()\ndef itg(x): return np.int32(np.round(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\n\ndef train_model(model, train_loader, dataset, loss, optimizer, num_epochs, scheduler=None):    \n    loss_history = []\n    train_history = []\n    val_history = []\n    for epoch in range(num_epochs):\n        model.train() # Enter train mode\n        \n        loss_accum = 0\n        correct_samples = 0\n        total_samples = 0\n        for i_step, train_batch in enumerate(train_loader):\n            x, y, prob_d = train_batch\n            prediction = model(x.unsqueeze(1))\n            # print(prediction)\n            #_, indices = torch.max(prediction, 1)\n            #print(indices)\n            #print(y)\n#             print(y)\n            loss_value = loss(prediction, y)\n            optimizer.zero_grad()\n            loss_value.backward()\n            \n            #_, indices = torch.max(prediction, 1)\n            #correct_samples += torch.sum(indices == y)\n            #total_samples += y.shape[0]\n            optimizer.step()\n            \n            loss_accum += loss_value\n\n        ave_loss = loss_accum / (i_step if i_step else 1)\n        #train_accuracy = float(correct_samples) / total_samples\n        \n        loss_history.append(float(ave_loss))\n        #train_history.append(train_accuracy)\n\n        if scheduler is not None:\n            scheduler.step()\n\n        #print(\"Average loss: %f\" % (ave_loss))\n        \n        if len(loss_history) > 5 and np.mean(np.abs(np.array(loss_history[-3:]) - np.array(loss_history[-4:-1]))) < 10**(epoch//10)*1e-6:\n            break\n\n        \n    return loss_history\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mutators = [0 for _ in range(100)]\nmutators[0] = MutationPipeline([\nColorSwitcher(),\n#Shifter(1),\nFlipper(False),\n#Shifter(1),\nRotator([0, 2]),\n#Shifter(1)\n])\nmutators[1] = MutationPipeline([\n#ColorSwitcher(),\nShifter(1),\n#Flipper(False),\nShifter(1),\n#Rotator([0, 1, 2]),\nShifter(1)\n])\nmutators[2] = MutationPipeline([\n#ColorSwitcher(),\nShifter(1),\nFlipper(False),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[3] = MutationPipeline([\n])\nmutators[4] = MutationPipeline([\n#ColorSwitcher(),\n#Shifter(1),\nFlipper(False),\n#Shifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[5] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[6] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[7] = MutationPipeline([\n])\nmutators[8] = MutationPipeline([\n])\nmutators[9] = MutationPipeline([\nColorSwitcher(),\n#Shifter(1),\nFlipper(),\n#Shifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[10] = MutationPipeline([\n#ColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[11] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[12] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[13] = MutationPipeline([\n#ColorSwitcher(),\nShifter(1),\n#Flipper(),\n#Shifter(1),\n#Rotator([0, 1, 2]),\n#Shifter(1)\n])\nmutators[14] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[15] = MutationPipeline([\n])\nmutators[16] = MutationPipeline([\nColorSwitcher(),\n#Shifter(1),\nFlipper(),\n#Shifter(1),\nRotator([0, 1, 2]),\n#Shifter(1)\n])\nmutators[17] = MutationPipeline([\n])\nmutators[18] = MutationPipeline([\n])\nmutators[19] = MutationPipeline([\n])\nmutators[20] = MutationPipeline([\n])\nmutators[21] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\n#Flipper(),\nShifter(1),\n#Rotator([0, 1, 2]),\nShifter(1)\n])\nmutators[22] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[23] = MutationPipeline([\n])\nmutators[24] = MutationPipeline([\n])\nmutators[25] = MutationPipeline([\nColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[26] = MutationPipeline([\n])\nmutators[27] = MutationPipeline([\nColorSwitcher([5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[28] = MutationPipeline([\n#ColorSwitcher(),\n#Shifter(1),\nFlipper(),\n#Shifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[29] = MutationPipeline([\nColorSwitcher([1,2,3]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[30] = MutationPipeline([\n#ColorSwitcher(),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[31] = MutationPipeline([\nColorSwitcher([0,1,4]),\nFlipper(),\nRotator([0, 1, 2]),\n])\nmutators[32] = MutationPipeline([\nColorSwitcher([2, 4]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[33] = MutationPipeline([\n])\nmutators[34] = MutationPipeline([\n])\nmutators[35] = MutationPipeline([\n])\nmutators[36] = MutationPipeline([\n])\nmutators[37] = MutationPipeline([\nColorSwitcher([0, 2, 4]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[38] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[39] = MutationPipeline([\n])\nmutators[40] = MutationPipeline([\n#ColorSwitcher([0]),\n#Shifter(1),\nFlipper(),\n#Shifter(1),\nRotator([0, 1, 2]),\n#Shifter(1)\n])\nmutators[41] = MutationPipeline([\nColorSwitcher([0, 8]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[42] = MutationPipeline([\n])\nmutators[43] = MutationPipeline([\n])\nmutators[44] = MutationPipeline([\nColorSwitcher([1, 0, 2, 5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[45] = MutationPipeline([\nColorSwitcher([0, 5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[46] = MutationPipeline([\n])\nmutators[47] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\n#Flipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[48] = MutationPipeline([\nColorSwitcher([0]),\n#Shifter(1),\nFlipper(),\n#Shifter(1),\nRotator([0, 1, 2]),\n#Shifter(1)\n])\nmutators[49] = MutationPipeline([\n])\nmutators[50] = MutationPipeline([\n])\nmutators[51] = MutationPipeline([\nColorSwitcher([0, 5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[52] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[53] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[54] = MutationPipeline([\n#ColorSwitcher([0, 5, 1,]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[55] = MutationPipeline([\n])\nmutators[56] = MutationPipeline([\n#ColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[57] = MutationPipeline([\n])\nmutators[58] = MutationPipeline([\n#ColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(2),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[59] = MutationPipeline([\n#ColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[60] = MutationPipeline([\nColorSwitcher([4]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[61] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[62] = MutationPipeline([\n])\nmutators[63] = MutationPipeline([\n])\nmutators[64] = MutationPipeline([\n])\nmutators[65] = MutationPipeline([\n])\nmutators[66] = MutationPipeline([\nColorSwitcher([0,5]),\nShifter(1),\n#Flipper(),\nShifter(1),\n#Rotator([0, 1, 2]),\nShifter(1)\n])\nmutators[67] = MutationPipeline([\n])\nmutators[68] = MutationPipeline([\nColorSwitcher([0,3]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[69] = MutationPipeline([\nColorSwitcher([1,2]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[70] = MutationPipeline([\n])\nmutators[71] = MutationPipeline([\nColorSwitcher([0, 1]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[72] = MutationPipeline([\n])\nmutators[73] = MutationPipeline([\n])\nmutators[74] = MutationPipeline([\nColorSwitcher([0, 5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[75] = MutationPipeline([])\nmutators[76] = MutationPipeline([])\nmutators[77] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[78] = MutationPipeline([\nColorSwitcher([0, 2]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[79] = MutationPipeline([\nColorSwitcher([0, 5, 1]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[80] = MutationPipeline([\nColorSwitcher([0, 9, 4]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[81] = MutationPipeline([\nColorSwitcher([0, 5]),\nShifter(1),\n#Flipper(),\nShifter(1),\n#Rotator([0, 1, 2]),\nShifter(1)\n])\nmutators[82] = MutationPipeline([\n#ColorSwitcher([0, 5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[83] = MutationPipeline([\n])\nmutators[84] = MutationPipeline([\nColorSwitcher([0, 5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 1, 2]),\nShifter(1)\n])\nmutators[85] = MutationPipeline([\n])\nmutators[86] = MutationPipeline([\n])\nmutators[87] = MutationPipeline([\nColorSwitcher([0, 5]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[88] = MutationPipeline([\nColorSwitcher([0]),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(4)\n])\nmutators[89] = MutationPipeline([\n])\nmutators[90] = MutationPipeline([\nColorSwitcher()\n])\nmutators[91] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[92] = MutationPipeline([\n#ColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[93] = MutationPipeline([\n])\nmutators[94] = MutationPipeline([\nColorSwitcher([0,3]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[95] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[96] = MutationPipeline([\n])\nmutators[97] = MutationPipeline([\nColorSwitcher([0]),\nShifter(1),\nFlipper(),\nShifter(1),\nRotator([0, 2]),\nShifter(1)\n])\nmutators[98] = MutationPipeline([\n])\nmutators[99] = MutationPipeline([\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 0\nstart = time.time()\ntest_predictions = []\nclass Flattener(nn.Module):\n    def forward(self, x):\n        batch_size, *_ = x.shape\n        return x.view(batch_size, -1)\n\nRESULT = {}\n    \ndef do_train(dataset, do_test=False):\n    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n    in_d = dataset.get_input_dimension()\n    prob_d = dataset.get_output_prob_dimension()\n    d = dataset.get_output_dimension()\n    network = BasicCNNModel(in_d, d)\n    # network = nn.Sequential(\n    #   nn.Conv2d(1, 256, np.min((FL, in_d[0])), padding=1),\n    #   nn.ReLU(inplace=True),\n    #   nn.MaxPool2d(4),\n    #   nn.BatchNorm2d(256),\n    #   nn.Conv2d(64, 10, 3, padding=1)\n    # )\n    loss = nn.CrossEntropyLoss()\n\n    optimizer = Adam(network.parameters(), lr=1e-2, weight_decay=1e-3)\n    step_lr = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.05)\n    lh = train_model(network, train_loader, dataset, loss, optimizer, EPOCHS)\n    preds = []\n    if do_test:\n        test_loader = DataLoader(np.array(dataset.extender.extended_X_test, dtype=np.single), batch_size=1, shuffle=False)\n        network.eval()\n        for i, test_batch in enumerate(test_loader):\n            test_batch = test_batch\n            test_preds = network(torch.FloatTensor(test_batch).unsqueeze(1))\n            _, indices = torch.max(test_preds, 1)\n            test_preds = dataset.narrow_prediction(indices.detach().numpy(), [i])\n            preds.append(dataset.round_colors(test_preds)[0])\n    return lh[-1], preds\n\nfor idx, (X_train, y_train) in enumerate(zip(Xs_train, ys_train)):\n    X_test = Xs_test[idx]\n    print(\"TASK \" + str(idx + 1))\n    mutator_losses = {}\n    losses = []\n    EPOCHS = 65\n    if len(mutators[idx].mutators) != 0:\n        dataset = ARCDataset(X_train, X_test, y_train, mutators[idx])\n        train_loss, predictions = do_train(dataset, do_test=True)\n    else:\n        predictions = X_test\n    for test_num, pred in enumerate(predictions):\n        RESULT[\"{}_{}\".format(task_ids[idx], test_num)] = np.array(pred).astype(int).tolist()\n    end = time.time()\n    print(\"Train loss: \" + str(np.round(train_loss, 3)) + \"   \" +\\\n          \"Total time: \" + str(np.round(end - start, 1)) + \" s\" + \"\\n\")\n    fig, ax = plt.subplots(1, 4, figsize=(15,15))\n    plot_matrix(np.array(X_train[0]), ax[0])\n    plot_matrix(np.array(y_train[0]), ax[1])\n    plot_matrix(X_test[0], ax[2])\n    plot_matrix(RESULT[\"{}_{}\".format(task_ids[idx], test_num)], ax[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission <a id=\"submission\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"RESULT[\"{}_{}\".format(task_ids[idx], test_num)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define function to flatten submission matrices","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RESULT[\"00576224_0\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flattener(RESULT[\"00576224_0\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_predictions = [[list(pred) for pred in test_pred] for test_pred in test_predictions]\nrr = {}\nfor id_ in RESULT:\n    rr[id_] = flattener(RESULT[id_])\n    \n#submission = pd.read_csv(SUBMISSION_PATH)\n#submission[\"output\"] = test_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions = pd.Series(rr, name='output')\nsubmissions.index.name = 'output_id'\nsubmissions.reset_index()\nsubmissions = pd.DataFrame(submissions)\nsubmissions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert submission to .csv format","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}