{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# *- encoding: utf-8 -*-\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV\n\nimport pdb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Set Paths"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_result(test_input, test_prediction,\n                input_shape):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 2, figsize=(15,15))\n    test_input = test_input.reshape(input_shape[0],input_shape[1])\n    axs[0].imshow(test_input, cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Actual Target')\n    test_prediction = test_prediction.reshape(input_shape[0],input_shape[1])\n    axs[1].imshow(test_prediction, cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Model Prediction')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_test(test_prediction, task_name):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 1, figsize=(15,15))\n    axs.imshow(test_prediction, cmap=cmap, norm=norm)\n    axs.axis('off')\n    axs.set_title(f'Test Prediction {task_name}')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# For flattening 2D numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv(data_path/'sample_submission.csv')\nsample_sub = sample_sub.set_index('output_id')\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract neighbourhood Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_moore_neighbours(color, cur_row, cur_col, nrows, ncols):\n\n    if cur_row<=0: top = -1\n    else: top = color[cur_row-1][cur_col]\n        \n    if cur_row>=nrows-1: bottom = -1\n    else: bottom = color[cur_row+1][cur_col]\n        \n    if cur_col<=0: left = -1\n    else: left = color[cur_row][cur_col-1]\n        \n    if cur_col>=ncols-1: right = -1\n    else: right = color[cur_row][cur_col+1]\n        \n    return top, bottom, left, right\n\ndef get_tl_tr(color, cur_row, cur_col, nrows, ncols):\n        \n    if cur_row==0:\n        top_left = -1\n        top_right = -1\n    else:\n        if cur_col==0: top_left=-1\n        else: top_left = color[cur_row-1][cur_col-1]\n        if cur_col==ncols-1: top_right=-1\n        else: top_right = color[cur_row-1][cur_col+1]   \n        \n    return top_left, top_right","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make features for each train sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"def features(task, mode='train'):\n    cur_idx = 0\n    num_train_pairs = len(task[mode])\n    total_inputs = sum([len(task[mode][i]['input'])*len(task[mode][i]['input'][0]) for i in range(num_train_pairs)])\n    feat = np.zeros((total_inputs,nfeat))\n    target = np.zeros((total_inputs,), dtype=np.int)\n    \n    global local_neighb\n    for task_num in range(num_train_pairs):\n        input_color = np.array(task[mode][task_num]['input'])\n        target_color = task[mode][task_num]['output']\n        nrows, ncols = len(task[mode][task_num]['input']), len(task[mode][task_num]['input'][0])\n\n        target_rows, target_cols = len(task[mode][task_num]['output']), len(task[mode][task_num]['output'][0])\n        \n        if (target_rows!=nrows) or (target_cols!=ncols):\n            print('Number of input rows:',nrows,'cols:',ncols)\n            print('Number of target rows:',target_rows,'cols:',target_cols)\n            not_valid=1\n            return None, None, 1\n\n        for i in range(nrows):\n            for j in range(ncols):\n                feat[cur_idx,0] = i\n                feat[cur_idx,1] = j\n                feat[cur_idx,2] = input_color[i][j]\n                feat[cur_idx,3:7] = get_moore_neighbours(input_color, i, j, nrows, ncols)\n                feat[cur_idx,7:9] = get_tl_tr(input_color, i, j, nrows, ncols)\n                feat[cur_idx,9] = len(np.unique(input_color[i,:]))\n                feat[cur_idx,10] = len(np.unique(input_color[:,j]))\n                feat[cur_idx,11] = (i+j)\n                feat[cur_idx,12] = len(np.unique(input_color[i-local_neighb:i+local_neighb,\n                                                             j-local_neighb:j+local_neighb]))\n        \n                target[cur_idx] = target_color[i][j]\n                cur_idx += 1\n            \n    return feat, target, 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    \"xgb__n_estimators\": [10],\n    \"xgb__learning_rate\": [0.1],\n    \"xgb__early_stopping_rounds\": np.array((50, 100))\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_task_ids = sorted(os.listdir(test_path))\n\nnfeat = 13\nlocal_neighb = 5\nvalid_scores = {}\nfor task_id in all_task_ids:\n\n    task_file = str(test_path / task_id)\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n\n    feat, target, not_valid = features(task)\n    if not_valid:\n        print('ignoring task', task_file)\n        print()\n        not_valid = 0\n        continue\n\n    nrows, ncols = len(task['train'][-1]['input']\n                       ), len(task['train'][-1]['input'][0])\n    # use the last train sample for validation\n    val_idx = len(feat) - nrows*ncols\n\n    train_feat = feat[:val_idx]\n    val_feat = feat[val_idx:, :]\n\n    train_target = target[:val_idx]\n    val_target = target[val_idx:]\n\n    #     check if validation set has a new color\n    #     if so make the mapping color independant\n    if len(set(val_target) - set(train_target)):\n        print('set(val_target)', set(val_target))\n        print('set(train_target)', set(train_target))\n        print('Number of colors are not same')\n        print('cant handle new colors. skipping')\n        continue\n\n    xgb = XGBClassifier(n_estimators=100, n_jobs=-1)\n   # hgb_pipe = make_pipeline([('xgb', xgb)])\n\n\n    skf = StratifiedKFold(n_splits=10, shuffle = True, random_state = 1001)\n    hgb_grid = GridSearchCV(xgb, param_grid, n_jobs=8, \n         cv=skf, verbose=2, refit=True)\n    hgb_grid.fit(feat, target)\n#     training on input pairs is done.\n#     test predictions begins here\n\n    num_test_pairs = len(task['test'])\n    for task_num in range(num_test_pairs):\n        cur_idx = 0\n        input_color = np.array(task['test'][task_num]['input'])\n        nrows, ncols = len(task['test'][task_num]['input']), len(\n            task['test'][task_num]['input'][0])\n        feat = np.zeros((nrows*ncols, nfeat))\n        unique_col = {col: i for i, col in enumerate(\n            sorted(np.unique(input_color)))}\n\n        for i in range(nrows):\n            for j in range(ncols):\n                feat[cur_idx, 0] = i\n                feat[cur_idx, 1] = j\n                feat[cur_idx, 2] = input_color[i][j]\n                feat[cur_idx, 3:7] = get_moore_neighbours(\n                    input_color, i, j, nrows, ncols)\n                feat[cur_idx, 7:9] = get_tl_tr(\n                    input_color, i, j, nrows, ncols)\n                feat[cur_idx, 9] = len(np.unique(input_color[i, :]))\n                feat[cur_idx, 10] = len(np.unique(input_color[:, j]))\n                feat[cur_idx, 11] = (i+j)\n                feat[cur_idx, 12] = len(np.unique(input_color[i-local_neighb:i+local_neighb,\n                                                              j-local_neighb:j+local_neighb]))\n\n                cur_idx += 1\n\n        print('Made predictions for ', task_id[:-5])\n        preds = hgb_grid.predict(feat).reshape(nrows, ncols)\n        preds = preds.astype(int).tolist()\n        plot_test(preds, task_id)\n        sample_sub.loc[f'{task_id[:-5]}_{task_num}',\n                       'output'] = flattener(preds)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n Best hyperparameters:')\nprint(hgb_grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.to_csv('submission1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\ntraining_tasks = sorted(os.listdir(training_path))\neval_tasks = sorted(os.listdir(evaluation_path))\n\nT = training_tasks\nTrains = []\nfor i in range(400):\n    task_file = str(training_path / T[i])\n    task = json.load(open(task_file, 'r'))\n    Trains.append(task)\n    \nE = eval_tasks\nEvals= []\nfor i in range(400):\n    task_file = str(evaluation_path / E[i])\n    task = json.load(open(task_file, 'r'))\n    Evals.append(task)\n    \ncmap = colors.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n# 0:black, 1:blue, 2:red, 3:greed, 4:yellow,\n# 5:gray, 6:magenta, 7:orange, 8:sky, 9:brown\nplt.figure(figsize=(5, 2), dpi=200)\nplt.imshow([list(range(10))], cmap=cmap, norm=norm)\nplt.xticks(list(range(10)))\nplt.yticks([])\nplt.show()\n\ndef plot_task(task):\n    n = len(task[\"train\"]) + len(task[\"test\"])\n    fig, axs = plt.subplots(2, n, figsize=(4*n,8), dpi=50)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    fig_num = 0\n    for i, t in enumerate(task[\"train\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Train-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Train-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    for i, t in enumerate(task[\"test\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Test-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Test-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    \n    plt.tight_layout()\n    plt.show()\ndef plot_picture(x):\n    plt.imshow(np.array(x), cmap = cmap, norm = norm)\n    plt.show()\ndef Defensive_Copy(A): \n    n = len(A)\n    k = len(A[0])\n    L = np.zeros((n,k), dtype = int)\n    for i in range(n):\n        for j in range(k):\n            L[i,j] = 0 + A[i][j]\n    return L.tolist()\ndef Create(task, task_id = 0):\n    n = len(task['train'])\n    Input = [Defensive_Copy(task['train'][i]['input']) for i in range(n)]\n    Output = [Defensive_Copy(task['train'][i]['output']) for i in range(n)]\n    Input.append(Defensive_Copy(task['test'][task_id]['input']))\n    return Input, Output\ndef Recolor(task):\n    Input = task[0]\n    Output = task[1]\n    Test_Picture = Input[-1]\n    Input = Input[:-1]\n    N = len(Input)\n    \n    for x, y in zip(Input, Output):\n        if len(x) != len(y) or len(x[0]) != len(y[0]):\n            return -1\n        \n    Best_Dict = -1\n    Best_Q1 = -1\n    Best_Q2 = -1\n    Best_v = -1\n    # v ranges from 0 to 3. This gives an extra flexibility of measuring distance from any of the 4 corners\n    Pairs = []\n    for t in range(15):\n        for Q1 in range(1,8):\n            for Q2 in range(1,8):\n                if Q1+Q2 == t:\n                    Pairs.append((Q1,Q2))\n                    \n    for Q1, Q2 in Pairs:\n        for v in range(4):\n    \n  \n            if Best_Dict != -1:\n                continue\n            possible = True\n            Dict = {}\n                      \n            for x, y in zip(Input, Output):\n                n = len(x)\n                k = len(x[0])\n                for i in range(n):\n                    for j in range(k):\n                        if v == 0 or v ==2:\n                            p1 = i%Q1\n                        else:\n                            p1 = (n-1-i)%Q1\n                        if v == 0 or v ==3:\n                            p2 = j%Q2\n                        else :\n                            p2 = (k-1-j)%Q2\n                        color1 = x[i][j]\n                        color2 = y[i][j]\n                        if color1 != color2:\n                            rule = (p1, p2, color1)\n                            if rule not in Dict:\n                                Dict[rule] = color2\n                            elif Dict[rule] != color2:\n                                possible = False\n            if possible:\n                \n                # Let's see if we actually solve the problem\n                for x, y in zip(Input, Output):\n                    n = len(x)\n                    k = len(x[0])\n                    for i in range(n):\n                        for j in range(k):\n                            if v == 0 or v ==2:\n                                p1 = i%Q1\n                            else:\n                                p1 = (n-1-i)%Q1\n                            if v == 0 or v ==3:\n                                p2 = j%Q2\n                            else :\n                                p2 = (k-1-j)%Q2\n                           \n                            color1 = x[i][j]\n                            rule = (p1,p2,color1)\n                            \n                            if rule in Dict:\n                                color2 = 0 + Dict[rule]\n                            else:\n                                color2 = 0 + y[i][j]\n                            if color2 != y[i][j]:\n                                possible = False \n                if possible:\n                    Best_Dict = Dict\n                    Best_Q1 = Q1\n                    Best_Q2 = Q2\n                    Best_v = v\n                \n                \n    if Best_Dict == -1:\n        return -1 #meaning that we didn't find a rule that works for the traning cases\n    \n    #Otherwise there is a rule: so let's use it:\n    n = len(Test_Picture)\n    k = len(Test_Picture[0])\n    \n    answer = np.zeros((n,k), dtype = int)\n   \n    for i in range(n):\n        for j in range(k):\n            if Best_v == 0 or Best_v ==2:\n                p1 = i%Best_Q1\n            else:\n                p1 = (n-1-i)%Best_Q1\n            if Best_v == 0 or Best_v ==3:\n                p2 = j%Best_Q2\n            else :\n                p2 = (k-1-j)%Best_Q2\n           \n            color1 = Test_Picture[i][j]\n            rule = (p1, p2, color1)\n            if (p1, p2, color1) in Best_Dict:\n                answer[i][j] = 0 + Best_Dict[rule]\n            else:\n                answer[i][j] = 0 + color1\n                                    \n           \n            \n    return answer.tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Function = Recolor\ntraining_examples = []\nfor i in range(400):\n    task = Trains[i]\n    basic_task = Create(task,0)\n    a = Function(basic_task)\n  \n    if  a != -1 and task['test'][0]['output'] == a:\n        plot_picture(a)\n        plot_task(task)\n        print(i)\n        training_examples.append(i) \nevaluation_examples = []\n\n\nfor i in range(400):\n    task = Evals[i]\n    basic_task = Create(task,0)\n    a = Function(basic_task)\n    \n    if a != -1 and task['test'][0]['output'] == a:\n       \n        plot_picture(a)\n        plot_task(task)\n        print(i)\n        evaluation_examples.append(i)   \nsubmission = pd.read_csv(data_path/ 'sample_submission.csv')\nsubmission.head()\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\nexample_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndisplay(example_grid)\nprint(flattener(example_grid))\nSolved = []\nProblems = submission['output_id'].values\nProposed_Answers = []\nfor i in  range(len(Problems)):\n    output_id = Problems[i]\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    f = str(test_path / str(task_id + '.json'))\n   \n    with open(f, 'r') as read_file:\n        task = json.load(read_file)\n    \n    n = len(task['train'])\n    Input = [Defensive_Copy(task['train'][j]['input']) for j in range(n)]\n    Output = [Defensive_Copy(task['train'][j]['output']) for j in range(n)]\n    Input.append(Defensive_Copy(task['test'][pair_id]['input']))\n    \n    solution = Recolor([Input, Output])\n   \n    \n    pred = ''\n        \n    if solution != -1:\n        Solved.append(i)\n        pred1 = flattener(solution)\n        pred = pred+pred1+' '\n        \n    if pred == '':\n        pred = flattener(example_grid)\n        \n    Proposed_Answers.append(pred)\n    \nsubmission['output'] = Proposed_Answers\nsubmission.to_csv('submission2.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub1 = sample_sub.reset_index()\nsample_sub1 = sample_sub.sort_values(by=\"output_id\")\n\nsample_sub2 = submission.sort_values(by=\"output_id\")\nout1 = sample_sub1[\"output\"].astype(str).values\nout2 = sample_sub2[\"output\"].astype(str).values\n\nmerge_output = []\nfor o1, o2 in zip(out1, out2):\n    o = o1.strip().split(\" \")[:1] + o2.strip().split(\" \")[:2]\n    o = \" \".join(o[:3])\n    merge_output.append(o)\nsample_sub1[\"output\"] = merge_output\nsample_sub1[\"output\"] = sample_sub1[\"output\"].astype(str)\nsample_sub1.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}