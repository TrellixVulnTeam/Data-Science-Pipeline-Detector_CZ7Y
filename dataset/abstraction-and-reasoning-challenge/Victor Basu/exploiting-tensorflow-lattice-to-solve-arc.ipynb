{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Exploiting Tensorflow Lattice to solve ARC</h1>"},{"metadata":{},"cell_type":"markdown","source":"## Introduction\nThe whole story started with twitter, from where I came to know about this competition. Most probably this competition was launched by Kaggle after a very long gap. This competition was discussed among various individuals in the data science community on twitter. I guessed I would approach the solution through some machine learning algorithms or deep learning. But suddenly after two days of an announcement of this competition, I came across a tweet on my timeline by an anonymous user saying **\"Its a coincidence that TensorFlow released its new library TensorFlow Lattice on the same day this competition was announced by Kaggle**\".<br>\nThe first time when I heard about TensorFlow lattice my reaction was...\n![meme](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse2.mm.bing.net%2Fth%3Fid%3DOIP.OdvSEFavLCxXLlnBuP0NYQHaEK%26pid%3DApi&f=1)\n"},{"metadata":{},"cell_type":"markdown","source":"## An important tweet by François Chollet\nBelow are some of the screenshots of twitter post by François Chollet(@fchollet) which would briefly explain the main objective of this competition.<br>\n> **One interesting thing about the ARC competition is that it serves to highlight how people who use deep learning often have little idea of what deep learning actually does, and when they should be using it or not**\n\n> **DL is applicable when you're doing *pattern recognition*: when you have data that lies on a smooth manifold, along which samples can be interpolated. And you're going to need a dense sampling of your manifold as training data in order to fit a parametric approximation of it**\n\n> **Generalization in deep learning is interpolation along a latent manifold (or rather a learned approximation of it). It has little to do with your model itself and everything to do with the natural organization of your data**\n\n> **Differentiability & minibatch SGD are the strengths of DL: besides making the learning practically tractable, the smoothness & continuity of the function & the incrementality of its fitting work great to learn to approximate latent manifold. But its strengths are also its limits**\n\n> **The whole setup breaks down when you are no longer doing pattern recognition -- when you no longer have a latent manifold (any kind of discrete problem) or no longer have a dense sampling of it. Or when your manifold changes over time.**\n\n> **This isn't complicated**\n\n<br>\nLink to the twitter post - https://twitter.com/fchollet/status/1234789789309652992"},{"metadata":{},"cell_type":"markdown","source":"## What is Tensorflow Lattice?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from IPython.display import YouTubeVideo\nYouTubeVideo('ABBnNjbjv2Q', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TensorFlow Lattice: Flexible, controlled and interpretable ML \n**by Mahdi Milani Fard, Software Engineer, Google Research**\n\nLink to the original blog - https://blog.tensorflow.org/2020/02/tensorflow-lattice-flexible-controlled-and-interpretable-ML.html <br><br>\n### Intro\nMost ML practitioners have encountered the typical scenario where the training data looks very different from the run-time queries on which the model is evaluated. As a result, flexible ML solutions such as DNNs or forests that rely solely on the training dataset often act unexpectedly and even wildly in parts of the input space not covered by the training and validation datasets. This behaviour is especially problematic in cases where important policy or fairness constraints can be violated.<br><br>\nEven though common forms of regularization can result in more sensible extrapolation, standard regularizers cannot guarantee reasonable model behaviour across the entire input space, especially with high-dimensional inputs. Switching to simpler models with more controlled and predictable behaviour can come at a severe cost to the model accuracy.<br><br>\nTF Lattice makes it possible to keep using flexible models, but provides several options to inject domain knowledge into the learning process through semantically meaningful common-sense or policy-driven shape constraints.\n For example, you can specify that the model output should be monotonically increasing with respect to a given input. These extra pieces of domain knowledge can help the model learn beyond just the training dataset and makes it behave in a manner controlled and expected by the user.<br><br>\n A **lattice** is an interpolated look-up table that can approximate arbitrary input-output relationships in your data.\n![lattice](https://www.tensorflow.org/lattice/images/model_comparison.png?) "},{"metadata":{},"cell_type":"markdown","source":"## Into the Problem"},{"metadata":{},"cell_type":"markdown","source":"## The most difficult part of this Problem...\nThe most difficult part while approaching the solution was the implementation of TensorFlow Lattice itself. The implementation guide provided by TensorFlow was very helpful to understand how to use it over tabular data, but what for 2d-matrix data like this?. I went through a deep analysis of how TensorFlow lattice works and then found out a way to implement it. It took almost three weeks for me to implement the Lattice model. I was stressed by the thought of whether it would work successfully or not at the end. Although I also can't deny the fact that implementing Lattice over 2d-matrix was much easier than it looked.<br>\nTrust me I tried my hardest to make it successful each time I failed just to prove that I did not waste my time for three weeks.<br>\n![meme](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia.giphy.com%2Fmedia%2FQOaTohH90fuEM%2Fgiphy.gif&f=1&nofb=1)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nprint(os.listdir(\"../input/\"))\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install -q tensorflow-lattice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\ntry:\n    # %tensorflow_version only exists in Colab.\n    %tensorflow_version 2.x\nexcept Exception:\n    pass\nimport tensorflow as tf\nimport logging\nimport tensorflow_lattice as tfl\nimport sys\nfrom tensorflow import keras\ntf.compat.v1.set_random_seed(123)\nsession_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nsess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\ntf.compat.v1.keras.backend.set_session(sess)\nlogging.disable(sys.maxsize)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_tasks = sorted(os.listdir(training_path))\nprint(training_tasks[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_file = str(training_path / '00d62c1b.json')\n\nwith open(task_file, 'r') as f:\n    task = json.load(f)\n\nprint(task.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train_pairs = len(task['train'])\nn_test_pairs = len(task['test'])\n\nprint(f'task contains {n_train_pairs} training pairs')\nprint(f'task contains {n_test_pairs} test pairs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(task['train'][0]['input'])\ndisplay(task['train'][0]['output'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 4, figsize=(15,15))\n    axs[0].imshow(task['train'][2]['input'], cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Train Input')\n    axs[1].imshow(task['train'][2]['output'], cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Train Output')\n    axs[2].imshow(task['test'][0]['input'], cmap=cmap, norm=norm)\n    axs[2].axis('off')\n    axs[2].set_title('Test Input')\n    axs[3].imshow(task['test'][0]['output'], cmap=cmap, norm=norm)\n    axs[3].axis('off')\n    axs[3].set_title('Test Output')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_data(files):\n    train_x= []\n    train_y = []\n    test_x= []\n    test_y = []\n    for file in files:\n        train_temp_x= []\n        train_temp_y = []\n        test_temp_x= []\n        test_temp_y = []\n        task_file = str(training_path / file)\n        with open(task_file, 'r') as f:\n            task = json.load(f)\n        for c in range(len(task['train'])):\n            train_temp_x.append(np.asarray(task['train'][c]['input']))\n            train_temp_y.append(np.asarray(task['train'][c]['output']))\n        for c in range(len(task['test'])):\n            test_temp_x.append(np.asarray(task['test'][c]['input']))\n            test_temp_y.append(np.asarray(task['test'][c]['output']))\n        train_x.append(train_temp_x)\n        train_y.append(train_temp_y)\n        test_x.append(test_temp_x)\n        test_y.append(test_temp_y)\n    return train_x, train_y, test_x, test_y    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, train_y, test_x, test_y  = extract_data(training_tasks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 4, figsize=(15,15))\naxs[0].imshow(train_x[0][1], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('Train Input')\naxs[1].imshow(train_y[0][1], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('Train Output')\naxs[2].imshow(test_x[0][0], cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('Test Input')\naxs[3].imshow(test_y[0][0], cmap=cmap, norm=norm)\naxs[3].axis('off')\naxs[3].set_title('Test Output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Construction of the Lattice Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_EPOCHS = 2000\nBATCH_SIZE = 64\nLEARNING_RATE=0.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reshapeData(X_, y_):\n    X_ = X_.reshape(X_.shape[0],X_.shape[1],X_.shape[2],1)\n    y_ = y_.reshape(y_.shape[0],y_.shape[1],y_.shape[2],1)\n    return X_,y_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def InitializeSession():\n    tf.compat.v1.keras.backend.clear_session()\n    tf.compat.v1.reset_default_graph()\n    tf.compat.v1.set_random_seed(123)\n    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n    tf.compat.v1.keras.backend.set_session(sess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Lattice_Model(input_data, target_data, use_lim):\n    \n    # We are going to have 2-d embedding as one of lattice inputs.\n    lattice_sizes = [5, 4, 3, 2, 3, 4, 5]\n    \n    input_ = tf.keras.layers.Input(shape=(input_data.shape[1], input_data.shape[2],1), name='Input')\n    conv_1 = tf.keras.layers.Conv2D(128, \n                                    (3,3),\n                                    activation='relu',\n                                    padding='same', \n                                    name='conv_1')\n    activation = tf.keras.layers.LeakyReLU()\n    conv_2 = tf.keras.layers.Conv2D(128, \n                                    (1,1),\n                                    activation='relu', \n                                    name='conv_2')\n    conv_3 = tf.keras.layers.Conv2D(128,\n                                    5,\n                                    activation='relu',\n                                    padding='same',\n                                    name='conv_3')\n    dropout = tf.keras.layers.Dropout(0.4,\n                                      name='Dropout')\n    \n    flatten = tf.keras.layers.Flatten(name='Flatten')\n    \n    dense_1 = tf.keras.layers.Dense(target_data.shape[1]*target_data.shape[2]*7,\n                                    name='Dense')\n    \n    reshape = tf.keras.layers.Reshape((target_data.shape[1],target_data.shape[2],7))\n    if use_lim == 1:\n        lattice = tfl.layers.Lattice(\n                                    lattice_sizes=lattice_sizes,\n                                    monotonicities=['none']*7,\n                                    units=target_data.shape[2],\n                                    output_min=target_data.min(),\n                                    output_max=target_data.max(),\n                                    name = 'Lattice'\n                                    )\n    else:\n        lattice = tfl.layers.Lattice(\n                                    lattice_sizes=lattice_sizes,\n                                    monotonicities=['none']*7,\n                                    units=target_data.shape[2],\n                                    name = 'Lattice'\n                                    )\n    #model_1 = tf.keras.models.Sequential()\n    model = (conv_1)(input_)\n    model = (activation)(model)\n    model = (conv_2)(model)\n    model = (activation)(model)\n    model = (dropout)(model)\n    model = (conv_3)(model)\n    model = (activation)(model)   \n    model = (dropout)(model)\n    model = (flatten)(model)\n    model = (dropout)(model)\n    model = (dense_1)(model)\n    model = (activation)(model)\n    model = (reshape)(model)\n    model = (lattice)(model)\n    #model.build()\n    \n    return tf.keras.models.Model(input_,model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ModelFit(model, X_, y_, use_lim):\n    if use_lim==1:\n        loss_ = tf.keras.losses.mean_squared_error\n    else:\n        loss_ = tf.keras.losses.binary_crossentropy\n    model.compile(\n        loss=loss_,\n        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n    )\n\n    model.fit(\n        X_,\n        y_,\n        batch_size=BATCH_SIZE,\n        epochs=NUM_EPOCHS,\n        validation_split=0.2,\n        verbose=0\n    )\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Note\nwhat is this **use_lim** parameter? <br> Before Explaining this kernel, I found that some the some the problems requires **output_max**, **output_min** with optimization of **means_squared_error**, otherwise both **output_max**, **output_min**  as None with optimization of **binary_crossentropy** to obtain better results."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_1, train_y_1 = reshapeData(np.array(train_x[0]),np.array(train_y[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_1 = Lattice_Model(train_x_1, train_y_1,0)\nModel_1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model_1 = ModelFit(Model_1,train_x_1, train_y_1,0)\nModel_1.evaluate(train_x_1, train_y_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_1 = Model_1.predict(np.array(test_x[0]).reshape(1,np.array(test_x[0]).shape[1],np.array(test_x[0]).shape[2],1))\npred_1 = pred_1.reshape(np.array(test_y[0]).shape[1],np.array(test_y[0]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[0][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[0][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(pred_1), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well the result is not so bad at all. But as you could see that I have rotated the predicted matrix by 90 degrees to match the desired result. We would be discussing that later in this notebook. Let's see how our lattice model performs to solve other problems."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_2, train_y_2 = reshapeData(np.array(train_x[2]),np.array(train_y[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_2 = Lattice_Model(train_x_2, train_y_2,0)\nModel_2 = ModelFit(Model_2,train_x_2, train_y_2,0)\nModel_2.evaluate(train_x_2, train_y_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_2 = Model_2.predict(np.array(test_x[2]).reshape(1,np.array(test_x[2]).shape[1],np.array(test_x[2]).shape[2],1))\npred_2 = pred_2.reshape(np.array(test_y[2]).shape[1],np.array(test_y[2]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[2][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[2][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow((pred_2), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The predicted results have smaller squares, but symmetry is maintained in the predicted output. Let us see what happens if we use mean_squared error for optimization."},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_2_1 = Lattice_Model(train_x_2, train_y_2,1)\nModel_2_1 = ModelFit(Model_2_1,train_x_2, train_y_2,1)\nModel_2_1.evaluate(train_x_2, train_y_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_2_1 = Model_2_1.predict(np.array(test_x[2]).reshape(1,np.array(test_x[2]).shape[1],np.array(test_x[2]).shape[2],1))\npred_2_1 = pred_2_1.reshape(np.array(test_y[2]).shape[1],np.array(test_y[2]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[2][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[2][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow((pred_2_1), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the symmetry is disturbed this time."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_3, train_y_3 = reshapeData(np.array(train_x[4]),np.array(train_y[4]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_3 = Lattice_Model(train_x_3, train_y_3,1)\nModel_3 = ModelFit(Model_3,train_x_3, train_y_3,1)\nModel_3.evaluate(train_x_3, train_y_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_3 = Model_3.predict(np.array(test_x[4]).reshape(1,np.array(test_x[4]).shape[1],np.array(test_x[4]).shape[2],1))\npred_3 = pred_3.reshape(np.array(test_y[4]).shape[1],np.array(test_y[4]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[4][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[4][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow((pred_3), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the model did not perform much well this time...."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_4, train_y_4 = reshapeData(np.array(train_x[5]),np.array(train_y[5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_4 = Lattice_Model(train_x_4, train_y_4,0)\nModel_4 = ModelFit(Model_4,train_x_4, train_y_4,0)\nModel_4.evaluate(train_x_4, train_y_4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_4 = Model_4.predict(np.array(test_x[5]).reshape(1,np.array(test_x[5]).shape[1],np.array(test_x[5]).shape[2],1))\npred_4 = pred_4.reshape(np.array(test_y[5]).shape[1],np.array(test_y[5]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[5][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[5][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(pred_4), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It kind of looks like found a pattern, but as you can see the inverted T section should have black color and the corner square should have blue while the reverse has happened."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_5, train_y_5 = reshapeData(np.array(train_x[6]),np.array(train_y[6]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_5 = Lattice_Model(train_x_5, train_y_5,1)\nModel_5 = ModelFit(Model_5,train_x_5, train_y_5,1)\nModel_5.evaluate(train_x_5, train_y_5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_5 = Model_5.predict(np.array(test_x[6]).reshape(1,np.array(test_x[6]).shape[1],np.array(test_x[6]).shape[2],1))\npred_5 = pred_5.reshape(np.array(test_y[6]).shape[1],np.array(test_y[6]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[6][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[6][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(np.rot90(pred_5)), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No, complains this time..."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 6"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_6, train_y_6 = reshapeData(np.array(train_x[9]),np.array(train_y[9]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_6 = Lattice_Model(train_x_6, train_y_6,1)\nModel_6 = ModelFit(Model_6,train_x_6, train_y_6,1)\nModel_6.evaluate(train_x_6, train_y_6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_6 = Model_6.predict(np.array(test_x[9]).reshape(1,np.array(test_x[9]).shape[1],np.array(test_x[9]).shape[2],1))\npred_6 = pred_6.reshape(np.array(test_y[9]).shape[1],np.array(test_y[9]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[9][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[9][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow((pred_6), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this case, the model is understanding the pattern like a bar with the least height would be yellow, bar with the highest height would be blue, the second-highest would be red and third would be green. But, it does not produce the results keeping the respect of the order of the given input."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 7"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_7, train_y_7 = reshapeData(np.array(train_x[10]),np.array(train_y[10]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_7 = Lattice_Model(train_x_7, train_y_7,1)\nModel_7 = ModelFit(Model_7,train_x_7, train_y_7,1)\nModel_7.evaluate(train_x_7, train_y_7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_7 = Model_7.predict(np.array(test_x[10]).reshape(1,np.array(test_x[10]).shape[1],np.array(test_x[10]).shape[2],1))\npred_7 = pred_7.reshape(np.array(test_y[10]).shape[1],np.array(test_y[10]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[10][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[10][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(pred_7), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Guess, this did not work well..."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 8"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_8, train_y_8 = reshapeData(np.array(train_x[11]),np.array(train_y[11]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_8 = Lattice_Model(train_x_8, train_y_8,1)\nModel_8 = ModelFit(Model_8,train_x_8, train_y_8,1)\nModel_8.evaluate(train_x_8, train_y_8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_8 = Model_8.predict(np.array(test_x[11]).reshape(1,np.array(test_x[11]).shape[1],np.array(test_x[11]).shape[2],1))\npred_8 = pred_8.reshape(np.array(test_y[11]).shape[1],np.array(test_y[11]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[11][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[11][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(pred_8), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad..."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 9"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_9, train_y_9 = reshapeData(np.array(train_x[14]),np.array(train_y[14]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_9 = Lattice_Model(train_x_9, train_y_9,1)\nModel_9 = ModelFit(Model_9,train_x_9, train_y_9,1)\nModel_9.evaluate(train_x_9, train_y_9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_9 = Model_9.predict(np.array(test_x[14]).reshape(1,np.array(test_x[14]).shape[1],np.array(test_x[14]).shape[2],1))\npred_9 = pred_9.reshape(np.array(test_y[14]).shape[1],np.array(test_y[14]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[14][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[14][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow((pred_9), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Problem - 10"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_10, train_y_10 = reshapeData(np.array(train_x[15]),np.array(train_y[15]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_10 = Lattice_Model(train_x_10, train_y_10,1)\nModel_10 = ModelFit(Model_10,train_x_10, train_y_10,1)\nModel_10.evaluate(train_x_10, train_y_10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_10 = Model_10.predict(np.array(test_x[15]).reshape(1,np.array(test_x[15]).shape[1],np.array(test_x[15]).shape[2],1))\npred_10 = pred_10.reshape(np.array(test_y[15]).shape[1],np.array(test_y[15]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[15][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[15][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(np.rot90(pred_10)), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Problem - 11"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_11, train_y_11 = reshapeData(np.array(train_x[16]),np.array(train_y[16]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_11 = Lattice_Model(train_x_11, train_y_11,1)\nModel_11 = ModelFit(Model_11,train_x_11, train_y_11,1)\nModel_11.evaluate(train_x_11, train_y_11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_11 = Model_11.predict(np.array(test_x[16]).reshape(1,np.array(test_x[16]).shape[1],np.array(test_x[16]).shape[2],1))\npred_11 = pred_11.reshape(np.array(test_y[16]).shape[1],np.array(test_y[16]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[16][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[16][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(pred_11), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Problem - 12"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_12, train_y_12 = reshapeData(np.array(train_x[19]),np.array(train_y[19]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_12 = Lattice_Model(train_x_12, train_y_12,1)\nModel_12 = ModelFit(Model_12,train_x_12, train_y_12,1)\nModel_12.evaluate(train_x_12, train_y_12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_12 = Model_12.predict(np.array(test_x[19]).reshape(1,np.array(test_x[19]).shape[1],np.array(test_x[19]).shape[2],1))\npred_12 = pred_12.reshape(np.array(test_y[19]).shape[1],np.array(test_y[19]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[19][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[19][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(pred_12), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to solve this problem by optimizing binary_crossentropy rather than mean_squared_error"},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_12_1 = Lattice_Model(train_x_12, train_y_12,0)\nModel_12_1 = ModelFit(Model_12_1,train_x_12, train_y_12,0)\nModel_12_1.evaluate(train_x_12, train_y_12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_12_1 = Model_12_1.predict(np.array(test_x[19]).reshape(1,np.array(test_x[19]).shape[1],np.array(test_x[19]).shape[2],1))\npred_12_1 = pred_12_1.reshape(np.array(test_y[19]).shape[1],np.array(test_y[19]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[19][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[19][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(pred_12_1), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While optimizing mean_squared_error the model is only able to detect which part of the incomplete pattern is needed to be filled up but is not able to answer which color it would be, while in case of binary_crossentrophy it is answer with entire pattern but is not able to colorize the pattern."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 13"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_13, train_y_13 = reshapeData(np.array(train_x[21]),np.array(train_y[21]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_13 = Lattice_Model(train_x_13, train_y_13,1)\nModel_13 = ModelFit(Model_13,train_x_13, train_y_13,1)\nModel_13.evaluate(train_x_13, train_y_13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_13 = Model_13.predict(np.array(test_x[21]).reshape(1,np.array(test_x[21]).shape[1],np.array(test_x[21]).shape[2],1))\npred_13 = pred_13.reshape(np.array(test_y[21]).shape[1],np.array(test_y[21]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[21][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[21][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow(np.rot90(np.rot90(pred_13.T)), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The problem looks like a puzzle-solving task, and it seems that our lattice model is pretty weak in solving these types of tasks."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 14"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_14, train_y_14 = reshapeData(np.array(train_x[25]),np.array(train_y[25]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_14 = Lattice_Model(train_x_14, train_y_14,0)\nModel_14 = ModelFit(Model_14,train_x_14, train_y_14,0)\nModel_14.evaluate(train_x_14, train_y_14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_14 = Model_14.predict(np.array(test_x[25]).reshape(1,np.array(test_x[25]).shape[1],np.array(test_x[25]).shape[2],1))\npred_14 = pred_14.reshape(np.array(test_y[25]).shape[1],np.array(test_y[25]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[25][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[25][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow((pred_14), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The task in this problem was to highlight out the superimposed section of the half divided input image. Yes, our model failed here also..."},{"metadata":{},"cell_type":"markdown","source":"## Problem - 15"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_15, train_y_15 = reshapeData(np.array(train_x[26]),np.array(train_y[26]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InitializeSession()\nModel_15 = Lattice_Model(train_x_15, train_y_15,1)\nModel_15 = ModelFit(Model_15,train_x_15, train_y_15,1)\nModel_15.evaluate(train_x_15, train_y_15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_15 = Model_15.predict(np.array(test_x[26]).reshape(1,np.array(test_x[26]).shape[1],np.array(test_x[26]).shape[2],1))\npred_15 = pred_15.reshape(np.array(test_y[26]).shape[1],np.array(test_y[26]).shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\naxs[0].imshow(test_x[26][0], cmap=cmap, norm=norm)\naxs[0].axis('off')\naxs[0].set_title('test Input')\naxs[1].imshow(test_y[26][0], cmap=cmap, norm=norm)\naxs[1].axis('off')\naxs[1].set_title('test Output')\naxs[2].imshow((pred_15), cmap=cmap, norm=norm)\naxs[2].axis('off')\naxs[2].set_title('predicted output')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\n* TF Lattice is not the absolute solution \n* It failed to solve puzzle-solving tasks and task involved combination of two inputs as one input.\n* I need to rotate the predicted matrix or Transpose it to get the desired result, so that is some-what a bad behavior shown by our model.\n* To solve all the 15 tasks we have used the same Neural Network model and same Lattice structure, same learning rate, and the same number of iterations, so I believe some unsolvable problems could have been solved with a different NN structure or different Lattice structure.\n\n* For solving bigger size matrix problems like in case of problem-11, a higher dimension lattice could have been a better choice, while training it through a higher number of iterations.\n* I have only approached the tasks that have uniform matrix shape for training, for non-uniform distribution I hope concepts like cellular automata, genetic algorithms and many other concepts discussed in the Notebook section of the competition would definitely help."},{"metadata":{},"cell_type":"markdown","source":"<h2>Please UpVote and share if you like this notebook or if this notebook was informative to you by some means. Also, let me know your opinions and suggestions in the comment section below.</h2>\n![memes](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.1lFiVY2gxBQobWgyRc9AbAHaHa%26pid%3DApi&f=1)"},{"metadata":{},"cell_type":"markdown","source":"## Thank You...."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}