{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports\nimport json\nimport os\nimport numpy as np\nimport time\nXs = []\nfrom random import random, randint, choice, shuffle","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_dataset():\n    dataset = {\n        \"train\": {},\n        \"test\": {},\n        \"evaluation\": {}\n    }\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            beg = dirname.split('/')[-1][:3]\n            if beg == \"abs\":\n                continue\n            print(os.path.join(dirname, filename))\n            with open(os.path.join(dirname, filename)) as json_file:\n                data = json.load(json_file)\n                key = filename[:-5]\n                if beg == \"eva\":\n                    dataset[\"evaluation\"][key] = data\n                if beg == 'tes':\n                    dataset[\"test\"][key] = data\n                if beg == 'tra':\n                    dataset[\"train\"][key] = data\n    return dataset\n\n\n\nclass Task:\n    '''\n        Handle a Task of the ARC Dataset\n    '''\n    def __init__(self, task_name, task_data):\n        self.name = task_name\n        self.data = task_data\n\n    def examples(self):\n        return map(lambda x: (x['input'], x['output']), self.data['train'])\n\n    def test(self):\n        return map(lambda x: x['input'], self.data['test'])\n\n    def get_solutions(self):\n        return map(lambda x: x['output'], self.data['test'])\n\nclass ARC:\n    '''\n        Handle the ARC Dataset\n    '''\n    def __init__(self):\n        self.dataset = get_dataset()\n        self.keys = {}\n        for t_type, tasks in self.dataset.items():\n            self.keys[t_type] = list(tasks.keys())\n\n    def tasks(self, task_type = 'all'):\n        '''\n            Iterate over tasks of task_type type\n\n            Params:\n                task_type: 'train', 'test', 'eval', 'all'\n\n            Return:\n            Iterator\n        '''\n        for t_type, tasks in self.dataset.items():\n            if task_type != 'all' and task_type != t_type:\n                continue\n            for t_name, task in tasks.items():\n                yield Task(t_name, task)\n                \n    def get_random_task(self, task_type):\n        t_name = choice(self.keys[task_type])\n        return Task(t_name, self.dataset[task_type][t_name])\n    \n    def iterate_random_task(self, task_type):\n        while 1:\n            yield self.get_random_task(task_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arc = ARC()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SIZE = 30\nNB_CHANNELS = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_one_hot_resized(X):\n    h, w = X.shape\n    resized = np.ones((MAX_SIZE, MAX_SIZE), dtype=np.uint8) * 10\n    pos_y, pos_x = MAX_SIZE // 2 - h // 2, MAX_SIZE // 2 - w // 2\n    resized[pos_y : pos_y + h, pos_x : pos_x + w] = X\n    return np.eye(NB_CHANNELS)[resized[:]].reshape((MAX_SIZE, MAX_SIZE, NB_CHANNELS))\n\ndef get_inputs(ttype):\n    Xs = []\n    for task in arc.tasks(ttype):\n        for X, y in task.examples():\n            Xs.append(get_one_hot_resized(np.array(X)))\n            Xs.append(get_one_hot_resized(np.array(y)))\n        for X in task.test():\n            Xs.append(get_one_hot_resized(np.array(X)))\n        if ttype not in ['train', 'evaluation']:\n            continue\n        for y in task.get_solutions():\n            Xs.append(get_one_hot_resized(np.array(y)))\n    return Xs\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xs = []\nXs += get_inputs('train')\nXs += get_inputs('evaluation')\nprint(len(Xs), Xs[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input(shape=(MAX_SIZE, MAX_SIZE, NB_CHANNELS))  # adapt this if using `channels_first` image data format\n\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}