{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, json, cv2, time\nimport matplotlib.pyplot as plt\nimport itertools\nfrom tqdm import tqdm\n\nfrom matplotlib import colors\nfrom copy import deepcopy\n\nfrom multiprocessing import Pool as MultiProcessingPool\nimport multiprocessing as mp\nmp.cpu_count()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/abstraction-and-reasoning-challenge/'\nos.listdir(data_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hexcols = ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00', \n           '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25',\n           '#467272'] ## Last color will be used for padding\n\ndef hex2numcolor(color):\n    h2n = lambda x: int(x, 16)\n    r, g, b = h2n(color[1:3]), h2n(color[3:5]), h2n(color[5:7])\n    return np.array([r, g, b])\n\nnpcols = np.array([hex2numcolor(col) for col in hexcols])\n\ndef colorize(img, cols):\n    newimg = np.empty((*img.shape, 3), np.uint8)\n    for k, v in zip(np.arange(len(cols)), cols): newimg[img==k, :] = v\n    return newimg\n\ndef imshow_colored(img):\n    colimg = colorize(img, npcols)\n    plt.imshow(colimg)\n\n\ndef get_tasks(data_path='../data/data/'):\n    training_path = data_path + 'training/'\n    evaluation_path = data_path + 'evaluation/'\n    test_path = data_path + 'test/'\n\n    training_tasks = sorted(os.listdir(training_path))\n    evaluation_tasks = sorted(os.listdir(evaluation_path))\n    test_tasks = sorted(os.listdir(test_path))\n    \n    train_tasks = [Task(tnum, training_path + tfile) for tnum, tfile in enumerate(training_tasks)]\n    eval_tasks = [Task(tnum,evaluation_path + tfile) for tnum, tfile in enumerate(evaluation_tasks)]\n    test_tasks = [Task(tnum,test_path + tfile) for tnum, tfile in enumerate(test_tasks)]\n\n    return train_tasks, eval_tasks, test_tasks\n\ndef get_train_test(task):\n    train_in, train_out = [], []\n    for t in task['train']:\n        train_in.append(np.uint8(np.array(t['input'])))\n        train_out.append(np.uint8(np.array(t['output'])))\n        \n    test_in, test_out = [], []\n    for t in task['test']:\n        test_in.append(np.uint8(np.array(t['input'])))\n        if 'output' in t:\n            test_out.append(np.uint8(np.array(t['output'])))\n    \n    return train_in, train_out, test_in, test_out\n\ndef plot_one(input_matrix=None, ax=None, title=''):\n    ax = ax or plt.axes()\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    \n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(title)\n    \n\ndef plot_task(taskdata, title):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(taskdata[0])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    fig.suptitle(title, fontsize=16, y=1.08)\n    if num_train == 1:\n        axs = axs[...,None]\n    for i in range(num_train):     \n        plot_one(taskdata[0][i], axs[0,i], 'Train Input')\n        plot_one(taskdata[1][i], axs[1,i], 'Train Output')        \n    plt.tight_layout()\n    plt.show()        \n        \n    num_test = len(taskdata[2])\n    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n    if num_test == 1:\n        axs = axs[...,None]\n    for i in range(num_test):      \n        plot_one(taskdata[2][i], axs[0,i], 'Test Input')\n        plot_one(taskdata[3][i], axs[1,i], 'Test Output')  \n    plt.tight_layout()\n    plt.show()\n\n# class Task():\n#     def __init__(self, tasknum, taskfile):\n#         self.taskfile = taskfile\n#         self.tasknum = tasknum\n#         with open(taskfile, 'r') as f:\n#             self.task = json.load(f)\n#         self.origdata = get_train_test(self.task)\n#         self.io, self.test_io = [], []\n#         train_in, train_out, self.test_in, self.test_out = self.origdata\n#         for i,o in zip(train_in, train_out):\n#             self.io.append((i,o))\n    \n#     def show_task(self):\n#         \"\"\"Show the tasks data\"\"\"\n#         plot_task(self.origdata, str(self.tasknum) + ' '+ self.taskfile)\n        \n        \nclass Task():\n    def __init__(self, tasknum, taskfile):\n        self.taskfile = taskfile\n        self.tasknum = tasknum\n        with open(taskfile, 'r') as f:\n            self.task = json.load(f)\n        self.origdata = get_train_test(self.task)\n        self.update_data(self.origdata)\n    \n    def _colorpermute(self, img, swaps, kb):\n            newimg = img.copy()\n            for k, v in zip(np.arange(kb, 10), swaps): \n                newimg[img==k] = v\n            return newimg\n         \n    def update_data_with_colormap(self, colormap, data=None, kb=0):\n        if data is None:\n            data = self.origdata\n        tartgetdata = []\n        for image_list in data:\n            dlist = []\n            for img in image_list:\n                dlist.append(self._colorpermute(img, colormap, kb))\n            tartgetdata.append(dlist)\n        self.update_data(tartgetdata)\n        \n    def swap_colorpairs(self, colorpairs):\n        \"\"\" Input a list of colors to swap \"\"\"\n        if len(np.unique([c[0] for c in colorpairs])) != len(np.unique([c[0] for c in colorpairs])):\n            print(\"Color mapping not one to one skipping\")\n            return\n        colormap = np.arange(10)\n        for c in colorpairs:\n            colormap[c[0]] = c[1]\n            colormap[c[1]] = c[0]\n        self.update_data_with_colormap(colormap, self.data, 0)\n        \n    def randomize_colors(self, keep_black=False):\n        kb = int(keep_black)\n        colormap = np.random.permutation(np.arange(kb, 10))\n        self.update_data_with_colormap(colormap, self.origdata, kb)\n        \n        \n    def update_data(self, data):\n        self.data = data\n        self.io = []\n        train_in, train_out, self.test_in, self.test_out = self.data\n        for i,o in zip(train_in, train_out):\n            self.io.append([i,o])\n            \n    def reset_to_original(self):\n        self.update_data(self.origdata)\n\n    \n    def show_task(self):\n        \"\"\"Show the tasks data\"\"\"\n        plot_task(self.data, str(self.tasknum) + ' '+ self.taskfile)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dslfuncs = {}\nimageproperties = {}\n\nclass DSLFunction():\n    def __init__(self, func, in_types, out_types, num_repeats):\n        self.name = func.__name__\n        self.func = func\n        self.in_types = in_types if not isinstance(in_types, str) else (in_types,)\n        self.out_types = out_types if not isinstance(out_types, str) else (out_types,)\n        self.variable_length_outputs = np.any(['-multiple' in t for t in self.out_types])\n        self.num_repeats = num_repeats\n    def __call__(self, *args):\n        return self.func(*args)\n    def info(self):\n        print('%s : %s -> %s | Repeat %d' % (self.name, self.in_types, self.out_types, self.num_repeats) )\n\n    \ndef register(in_types, out_types, num_repeats=1):\n    def _thunk(func):\n        name = func.__name__\n        dslfuncs[name] = DSLFunction(func, in_types, out_types, num_repeats=num_repeats)\n        return func\n    return _thunk\n\ndef imageproperty(func):\n    name = func.__name__\n    imageproperties[name] = func\n    return func\n\n@register(\"Image\", \"ImageList\")\ndef split_by_color(img, crop=True):\n    \"\"\" Input an image, splits image list of images by different colors\"\"\"\n    if img.max() == 0:\n        return None\n    cols = np.unique(img[img > 0])\n    outs = []\n    for c in cols:\n        colimg = np.zeros_like(img)\n        colimg[img == c] = img[img == c]\n        outs.append(colimg)\n    if crop:\n        return _composite_imagelist_to_imagelist(outs, _crop_nonzero)\n    else:\n        return outs\n\n@register(\"Image\", \"ImageList\")\ndef split_by_blobs(img, conn=8, crop=True):\n    \"\"\" splits image based on connected components (8 connected) \"\"\"\n    if img.max() == 0:\n        return None\n    ncon, cons, stats, cent = cv2.connectedComponentsWithStats(np.uint8(img > 0), connectivity=conn)\n    sortedcons = [c for _,c in sorted(zip(stats[1:, cv2.CC_STAT_AREA], np.arange(1, ncon)), reverse=True)]\n    outs = []\n    for c in sortedcons:\n        consimg = np.zeros_like(img)\n        consimg[cons == c] = img[cons == c]\n        outs.append(consimg)\n    if crop:\n        return _composite_imagelist_to_imagelist(outs, _crop_nonzero)\n    else:\n        return outs\n\n@register(\"Image\", \"ImageList\")\ndef split_by_blobs_4connected(img):\n    return split_by_blobs(img, 4)\n\n@register(\"Image\", \"ImageList\")\ndef split_by_color_and_blobs(img):\n    \"\"\" splits image by color then splits by connected components (8 connected) \"\"\"\n    lst = split_by_color(img)\n    if lst is None:\n        return None\n    return _composite_imagelist_to_imagelist(lst, split_by_blobs)\n\n@register((\"Image\", \"Shape\"), \"ImageList\")\ndef split_by_shape(img, targetshape):\n    \"\"\" splits image by size if image size is integer multiple of target size \"\"\"\n    (rd, cd), mods = np.divmod(img.shape, targetshape)\n    if rd+cd <= 2 or np.sum(mods) > 0:\n        return None\n    outs = []\n    ts = targetshape\n    for r in range(rd):\n        for c in range(cd):\n            crop = img[r*ts[0]:(r+1)*ts[0], c*ts[1]:(c+1)*ts[1]]\n            outs.append(crop)\n    return outs\n    \n\n@register((\"Image\", \"Color\"), \"ImageList\")\ndef split_by_lines_with_color(img, color):\n    \"\"\"Splits based on horizontal and vertical lines accross the image\"\"\"\n    vlines = list(np.where(np.all(img == img[0,:], axis=0) & (img[0,:] == color))[0])\n    hlines = list(np.where(np.all(img == img[:,:1], axis=1) & (img[:,0] == color))[0])\n    if len(hlines) == 0 and len(vlines) == 0:\n        return None\n    hlines = [-1] + hlines + [img.shape[0]]\n    vlines = [-1] + vlines + [img.shape[1]]\n    outs = []\n    for r1, r2 in zip(hlines[:-1], hlines[1:]):\n        for c1, c2 in zip(vlines[:-1], vlines[1:]):\n            crop = img[r1+1:r2, c1+1:c2]\n            if crop.size > 0:\n                outs.append(crop)\n    return outs if len(outs) > 0 else None\n\n\n\n@register(\"Image\", \"ImageList\")\ndef split_by_lines(img):\n    \"\"\"Splits based on horizontal and vertical lines accross the image\"\"\"\n    vlines = list(np.where(np.all(img == img[0,:], axis=0) & (img[0,:] > 0))[0])\n    hlines = list(np.where(np.all(img == img[:,:1], axis=1) & (img[:,0] > 0))[0])\n    if len(hlines) == 0 and len(vlines) == 0:\n        return None\n    hlines = [-1] + hlines + [img.shape[0]]\n    vlines = [-1] + vlines + [img.shape[1]]\n    outs = []\n    for r1, r2 in zip(hlines[:-1], hlines[1:]):\n        for c1, c2 in zip(vlines[:-1], vlines[1:]):\n            crop = img[r1+1:r2, c1+1:c2]\n            if crop.size > 0:\n                outs.append(crop)\n    return outs if len(outs) > 0 else None\n    \n########################################################\n############## Image to Image ##########################\n########################################################\n\n@register(\"Image\", \"Image\")\ndef crop_nonzero(img):\n    \"\"\" Input an image, crops the non zero bounding box\"\"\"\n    return _crop_nonzero(img)\n\n@register(\"Image\", \"Image\")\ndef pixelwise_not(img):\n    cols = np.unique(img)\n    if not len(cols) == 2:\n#         return None\n        img = img.copy()\n        img[img > cols[1]] = cols[1]    # TODO: Minor hack, check out how it turns out else revert\n    newimg = np.zeros_like(img)\n    newimg[img == cols[0]] = cols[1]\n    newimg[img == cols[1]] = cols[0]\n    return newimg\n\n########################################################\n############# List to Image ############################\n########################################################\n    \n@register(\"ImageList\", \"Image\")\ndef pixelwise_and(lst):\n    \"\"\" If colors are different, uses color of img1 \"\"\"\n    if not len(lst) == 2:\n        return None\n    img1, img2 = lst\n    if img1.max() == 0 or img2.max() == 0:\n        return None\n    if not np.all(img1.shape == img2.shape):\n        return None\n    andmap = np.logical_and(img1 > 0, img2 > 0)\n    newimg = np.zeros_like(img1)\n    newimg[andmap] = img1[andmap]\n    return newimg\n\n@register(\"ImageList\", \"Image\")\ndef pixelwise_overlap(lst):\n    \"\"\" Overlaps all images from last to first order \"\"\"\n    if len(lst) == 1:\n        return None\n    if not np.all([lst[-1].shape == l.shape for l in lst[:-1]]):\n        return None\n    newimg = lst[-1].copy()\n    for img in reversed(lst[:-1]):\n        nz = img > 0\n        newimg[nz] = img[nz] \n    return newimg\n\n@register(\"ImageList\", \"Image\")\ndef pixelwise_xor(lst):\n    \"\"\" Pixelwise XOR based on non zero locations \"\"\"\n    if not len(lst) == 2:\n        return None\n    img1, img2 = lst\n    if img1.max() == 0 or img2.max() == 0:\n        return None\n    if not np.all(img1.shape == img2.shape):\n        return None\n    newimg = np.zeros_like(img1)\n    xormap = np.logical_xor(img1 > 0, img2 > 0)\n    newimg[xormap] = img2[xormap]\n    img1map = np.logical_and(xormap, img1 > 0)\n    newimg[img1map] = img1[img1map]\n    return newimg\n\n# @register(\"ImageList\", \"ImageList\")\n# def crop_nonzero_multi(lst):\n#     return _composite_imagelist_to_imagelist(lst, _crop_nonzero)\n\n# @register((\"ImageList\", \"ImageOperator\",), \"ImageList\", 2) ### Makes things too slow\ndef _composite_imagelist_to_imagelist(lst, func):\n    outs = []\n    for img in lst:\n        res = func(img)\n        if res is None:\n            return None\n        if isinstance(res, list):\n            outs.extend(res)\n        else:\n            outs.append(res)\n    return outs\n        \n# @register(\"ImageList\", \"Image\")   \n# def non_repeated_image_in_list(lst):   ################## Very Niche, need to check for bugs\n#     \"\"\"Returns the unique image if others are repeated multiple times\"\"\" \n#     unique_images, reps = _unique_image_with_counts(lst)\n#     is_unique = [r==1 for r in reps]\n#     if not np.sum(is_unique) == 1:\n#         return None\n#     else:\n#         return unique_images[np.where(is_unique)[0][0]]\n\n@register(\"ImageList\", \"Image\")   \ndef least_repeated_image_in_list(lst):   ################## Very Niche\n    \"\"\"Returns the least repeated image if it is uniquely lowest count\"\"\" \n    unique_images, reps = _unique_image_with_counts(lst)\n    argmin = np.argwhere(reps == np.min(reps))\n    if not len(argmin) == 1:\n        return None\n    else:\n        return unique_images[argmin[0][0]]\n    \n@register(\"ImageList\", \"Image\")\ndef most_repeated_image_in_list(lst):   ################## Very Niche\n    \"\"\"Returns the most repeated image if it is uniquely highest count\"\"\"\n    unique_images, reps = _unique_image_with_counts(lst)\n    argmax = np.argwhere(reps == np.max(reps))\n    if not len(argmax) == 1:\n        return None\n    else:\n        return unique_images[argmax[0][0]]\n\n# @register(\"ImageList\", \"Image\")\n# def access_first(lst):\n#     return lst[0]\n\n# @register(\"ImageList\", \"Image\")\n# def access_last(lst):\n#     return lst[-1]\n\n@register((\"ImageList\", \"ImageProperty\"), \"Image\", 2)\ndef min_by_prop(lst, key):\n    return min(lst, key=key)\n\n@register((\"ImageList\", \"ImageProperty\"), \"Image\", 2)\ndef max_by_prop(lst, key):\n    return max(lst, key=key)\n\n# @register(\"ImageList\", \"Image\")\n# def symmetrical_image_in_list(lst):\n#     is_sym = [_is_symmetrical(img) for img in lst]\n#     if not np.any(is_sym):\n#         return None\n#     for img, sym in zip(lst, is_sym):\n#         if sym:\n#             return img\n\n########################################################\n############# List to List #############################\n########################################################\n\n# @register((\"ImageList\", \"ImageProperty\"), \"ImageList\")\n# def sort_by_prop(lst, key):\n#     return sorted(lst, key=key)\n\n# @register(\"ImageList\", \"ImageList\")\n# def reverse_list(lst):\n#     return list(reversed(lst))\n\n########################################################\n############# Image to Color ###########################\n########################################################\n\n# @register(\"Image\", \"Color-multiple\")\n# def image_colors_raster(img):\n#     \"\"\" Return unique colors in raster scan order \"\"\"\n#     _, unique_idx = np.unique(img, return_index=True)\n#     return list(img.ravel()[np.sort(unique_idx)])\n\n# @register(\"Image\", \"Color-multiple\")\n# def image_colors_sorted(img):\n#     \"\"\" Return unique colors by sort order \"\"\"\n#     return np.unique(img)\n\n# @register(\"Image\", \"Color-multiple\")\n# def line_colors(img):\n#     \"\"\" Returns colors of lines in raster scan order \"\"\"\n#     vlines = np.where(np.all(img == img[0,:], axis=0))\n#     hlines = np.where(np.all(img == img[:,:1], axis=1))\n#     if len(hlines) == 0 and len(vlines) == 0:\n#         return None\n#     cols = np.concatenate([img[0, vlines].squeeze(0), img[hlines, 0].squeeze(0)])\n#     _, unique_idx = np.unique(cols, return_index=True)\n#     return list(cols[np.sort(unique_idx)])\n\n\n\n\n\n########################################################\n############# Image Properties #########################\n########################################################\n\n@imageproperty\ndef count_colors(img):\n    return len(np.unique(img))\n\n@imageproperty\ndef count_nonzero(img):\n    return np.sum(img > 0)\n\n@imageproperty\ndef is_symmetrical(img):\n    return np.any([np.array_equal(img, sym) \\\n                   for sym in [np.flipud(img), np.fliplr(img), img.T, np.fliplr(img.T)] ])\n\n\n#### Create new properties #####\n@register(\"Color\", \"ImageProperty\")\ndef create_color_counter(color):\n    return lambda img: _count_single_color(img, color)\n\n################## Other helpers #######################\n\ndef _unique_images(lst):\n    unique_list = []\n    for img in lst:\n        if not np.any([np.array_equal(img, u) for u in unique_list]):\n            unique_list.append(img)\n    return unique_list\n\ndef _unique_image_with_counts(lst):\n    unique_list, rep_count = [], []\n    for img in lst:\n        match = []\n        for i, x in enumerate(unique_list):\n            eq = np.array_equal(img, x)\n            rep_count[i] += int(eq)\n            match.append(eq)\n        if not np.any(match):\n            unique_list.append(img)\n            rep_count.append(1)\n    return unique_list, rep_count\n\ndef _crop_nonzero(img):\n    \"\"\" Input an image, crops the non zero bounding box\"\"\"\n    if img.max() == 0:\n        return None\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    return img[rmin:rmax+1, cmin:cmax+1]\n\ndef _is_symmetrical(img):\n    return np.any([np.array_equal(img, sym) \\\n                   for sym in [np.flipud(img), np.fliplr(img), img.T, np.fliplr(img.T)] ])\n\n\ndef _image_colors_sorted(img):\n    \"\"\" Return unique colors by sort order \"\"\"\n    return np.unique(img)\n\ndef _count_single_color(img, color):\n    return np.sum(img == color)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### Helper functions\n\ndef ravel(tupleOfTuples):\n    return itertools.chain(*tupleOfTuples)\n\ndef pretty_print_program(program, poolnames, postprocess=None):\n    for stage in program:\n        funcname, args_idx = stage\n        stagetext = ''\n        for name, args in zip(poolnames, args_idx):\n            for idx in args:\n                if name == 'ImageProperty' and name in imageproperties:\n                    ## Little cosmetic but depends on imageproperty injection style to the pools\n                    stagetext += list(imageproperties.keys())[idx] + ', ' \n#                 elif name == 'ImageOperator':\n#                     stagetext += list(imageoperators.keys())[idx] + ', ' \n                else:\n                    stagetext += f'{name}[{idx}], '    \n        print(f'{funcname}({stagetext})')\n    if postprocess is not None:\n        print(postprocess)\n    print()\n                                        \ndef reverse_range(top, bottom=0):\n    \" Creates a reversed range because using python 'reversed' is not a persistant iterator\"\n    return range(top-1, bottom-1, -1)\n\ndef serialize_multiple(data, data_types):\n    if not isinstance(data, tuple):\n        data = (data,)\n    new_data, new_data_types = [], []\n    for di, dt in enumerate(data_types):\n#         try:\n        if '-multiple' in dt:\n            dt = dt[:-9]\n            new_data.extend(data[di])\n            new_data_types.extend([dt for _ in data[di]])\n        else:\n            new_data_types.append(dt)\n            new_data.append(data[di])\n#         except:\n#             global debug \n#             debug = data, data_types\n#             print(len(data), data_types)\n#             assert False\n    return tuple(new_data), new_data_types\n\nclass DataPool():\n    def __init__(self, data_type, num_readback_entries=None):\n        self.data_type = data_type\n        self.data = []\n        self.entry_lengths = [0]\n        self.datalen = 0\n        self.num_readback_entries = num_readback_entries\n        self.index = reverse_range(len(self.data))\n        self.update_range()\n    \n    def iterator(self, num_data):\n        return itertools.combinations(self.index, num_data) ## TODO: Might need change to permutations\n    \n    def append_data(self, data):\n        self.data.append(data)\n        \n    def remove_last_data(self):\n        self.data.pop(-1)\n        \n    def update_range(self):\n        diff = len(self.data) - self.datalen\n        if diff == 0:\n            return\n        elif diff > 0:\n            self.datalen = len(self.data)\n            self.entry_lengths.append(diff)\n        else:\n            self.datalen = len(self.data)\n            self.entry_lengths.pop(-1)\n            \n        if self.num_readback_entries is not None:\n            bottom = 0 if len(self.entry_lengths) <= self.num_readback_entries \\\n                       else self.entry_lengths[ -(self.num_readback_entries+1)]\n            self.index = reverse_range(len(self.data), bottom)\n        else:\n            self.index = reverse_range(len(self.data)) ## Range is reversed to prioritize last\n           \n        \nclass OutputPool():\n    def __init__(self, poolnames, num_readback_entries):\n        self.poolnames = poolnames\n        num_readback_entries = num_readback_entries or [None for _ in self.poolnames]\n        self.pools = {name: DataPool(name, nre) for name, nre in zip(self.poolnames, num_readback_entries)}\n        \n    def valid_data_iterator(self, input_types):\n        iters = []\n        for name, pool in self.pools.items():\n            ### IMPORTANT TODO - all DSL functions must have be written in poolnames order to support this\n            num_data = sum([it == name for it in input_types]) \n            iters.append(pool.iterator(num_data))\n        return itertools.product(*iters)\n    \n    def index2data(self, index):\n        data = []\n        for poolidx, dataidx in zip(self.poolnames, index):\n            for idx in dataidx:\n                data.append(self.pools[poolidx].data[idx])\n        return data\n    \n    def update(self, data_tuple, data_types):\n        if not isinstance(data_tuple, tuple):\n            data_tuple = (data_tuple,) \n#         print(\"Updating\", len(data), data_types)\n        for data, dtype in zip(data_tuple, data_types):\n            self.pools[dtype].append_data(data)\n            \n        for name in self.pools:\n            self.pools[name].update_range()\n            \n    def remove_last_entry(self, data_types):\n        for dtype in data_types:\n            self.pools[dtype].remove_last_data()\n            \n        for name in self.pools:\n            self.pools[name].update_range()\n    \n    def _len(self):\n        return {name: len(pool.data) for name, pool in self.pools.items()}\n    \n    def get_pool(self, name):\n        return self.pools[name].data\n    \n    \n    \nclass PostprocessChecker():\n    def __init__(self, task):\n        self.task = task\n        self.name = 'undefined'\n        \n    def _is_valid(self):\n        return True\n    \n    def matches_basic_conditions(self, func_outs):\n        return True\n    \n    def all_match(self, func_outs):\n        for io, out in zip(self.task.io, func_outs):\n            img, target = io\n            if not np.array_equal(self.postprocess_program(out), target):\n                return False\n        return True\n    \n    def postprocess_program(self, img):\n        return img\n    \n    def check(self, func_outs):\n        if not self.matches_basic_conditions(func_outs):\n            return False\n        return self.all_match(func_outs)\n    \nclass SetOutputColor(PostprocessChecker):\n    def __init__(self, task):\n        super().__init__(task)\n        self.name = 'set_output_color'\n        self.setcolor, self.valid = self._is_valid()\n    \n    def _is_valid(self):\n        \"\"\" Valid to use only all outputs have single color \"\"\"\n        allimgs_flat = []\n        for io in self.task.io:\n            allimgs_flat.extend(io[1].ravel())\n        cols = list(np.unique(allimgs_flat))\n        if 0 in cols:\n            cols.pop(0)\n        if len(cols) == 1:\n            return cols[0], True\n        else:\n            return None, False\n    \n    def matches_basic_conditions(self, func_outs):\n        return np.all([np.array_equal(fo.shape, io[1].shape) \\\n                       for fo, io in zip(func_outs, self.task.io)])\n    \n    def postprocess_program(self, img):\n        resimg = img.copy()\n        resimg[resimg > 0] = self.setcolor\n        return resimg\n    \n    \nclass ProgramRunner():\n    def __init__(self, program, initial_pool, dsl, postprocess=None):\n        self.program = program\n        self.initial_pool = initial_pool\n        self.dsl = dsl\n        self.postprocess = postprocess\n    \n    def __call__(self, img):\n        return self.run_program(img)\n    \n    def show(self):\n        pretty_print_program(self.program, self.initial_pool.poolnames, self.postprocess)\n        \n    def run_program(self, img, diagnose=False):\n        \"Diagnose is to be used to debug programs\"\n        pool = deepcopy(self.initial_pool)\n        pool.update(img, ['Image'])\n        func_output = None\n        for stage in self.program:\n            funcname, data_idx = stage\n            func = self.dsl[funcname]\n            output_types = func.out_types\n            try: ## These can occur when a program works on an image but not another of the same task\n                data =  pool.index2data(data_idx)\n                func_output = func(*data)\n                if func.variable_length_outputs:\n                    func_output, serial_output_types = serialize_multiple(func_output, output_types)\n                else:\n                    serial_output_types = output_types\n                pool.update(func_output, serial_output_types)\n            except:\n#                 global debugpool\n#                 debugpool = pool\n#                 global debugprog\n#                 debugprog = self.program\n#                 func_output = func(*data)\n#                 pool.update(func_output, output_types)\n#                 print('Error')\n                return None\n            if diagnose: ### To be implemented\n                pass\n        return func_output\n    \nclass ProgramSearcher():\n    def __init__(self, task, initial_pool, dsl, timeout=None, postprocessors=[]):\n        self.task = task\n        self.dsl = dsl\n        self.initial_pool = initial_pool\n        self.timeout = timeout or np.inf\n        self.test_outs = []\n        \n        self.postprocess = None\n        self.postprocessors = []\n        for pp in postprocessors:\n            postp = pp(task)\n            if postp.valid:\n                self.postprocessors.append(postp)\n        \n    def progrunner(self, program):\n         return ProgramRunner(program, self.initial_pool, self.dsl, self.postprocess)\n    \n    def postprocess_program_check(self, func_outs):\n        for pp in self.postprocessors:\n            if pp.check(func_outs):\n                return True, pp.name, pp.postprocess_program\n        return False, None, None\n        \n    def all_match(self, program, current_out):\n        ## TODO: Clean up this mess\n        if len(self.postprocessors) > 0: # Exectute only if postprocessors available\n            if not isinstance(current_out, np.ndarray):\n                return False\n            ## TODO: This is only valid for color based postprocessing, need to standardize this\n            if not np.array_equal(current_out.shape, self.target.shape):\n                return False\n        else:\n            if not np.array_equal(current_out, self.target): ## Prevent building program when no match\n                return False\n            \n        progrunner = self.progrunner(program)\n        task = self.task\n        train_outs = []\n        matched = True\n        for io in task.io:\n            img, target = io\n            out = progrunner(img)\n            train_outs.append(out)\n            if out is None:\n                return False\n            elif not np.array_equal(out, target):\n                matched = False\n                \n        self.test_outs = []\n        for test_img in task.test_in:\n            out = progrunner(test_img)\n            self.test_outs.append(out)\n            if out is None:\n                return False\n        \n        if not matched:\n            matched, self.postprocess, pp_func = self.postprocess_program_check(train_outs)\n            if self.postprocess is not None:\n                self.test_outs = [pp_func(tout) for tout in self.test_outs]\n                \n        return matched\n    \n    def should_terminate(self, prog):\n        if (len(prog) == self.maxlen) or (time.time()-self.starttime > self.timeout):\n            return True\n        \n    def search(self, maxlen, prevent_duplicates=False):\n        if maxlen < 3:\n            prevent_duplicates = False ## For smaller programs, the overhead makes it slower overall\n        self.starttime = time.time()\n        self.run_count = 0\n        self.maxlen = maxlen\n        self.match_condition = self.all_match\n#         self.terminate = lambda prog: len(prog) == self.maxlen\n        funcnames = []\n        for key in self.dsl:\n            funcnames.extend([key for _ in range(self.dsl[key].num_repeats)])\n        pool = deepcopy(self.initial_pool)\n        img, self.target = self.task.io[0]\n        pool.update(img, ['Image'])\n        nodes_visited = {} if prevent_duplicates else None \n        program = self._programsearch(pool=pool, \n                                      out=None, \n                                      program=[], \n                                      function_names=funcnames,\n                                      nodes_visited=nodes_visited)\n        time_elapsed = time.time() - self.starttime\n        if program is None:\n            return False, self.run_count, time_elapsed, None, self.test_outs\n        else:\n            return True, self.run_count, time_elapsed, self.progrunner(program), self.test_outs\n\n    def _programsearch(self, pool, out, program, function_names, nodes_visited):\n\n        ## Match Check\n        if self.match_condition(program, out):\n            return program\n\n        ## Termination\n        if self.should_terminate(program):\n            return None\n\n        ## DFS\n        for funcidx, funcname in enumerate(function_names):\n            new_function_names = function_names[:funcidx] + function_names[funcidx+1:]\n            func = self.dsl[funcname]\n            input_types = func.in_types\n            output_types = func.out_types\n            for valid_data_index in pool.valid_data_iterator(input_types):\n                if nodes_visited is not None:\n                    node_key = funcname + str(valid_data_index)\n                    if node_key in nodes_visited:\n                        continue\n                    else:\n                        nodes_visited[node_key] = True ## Cannot avoid this double access\n                self.run_count += 1\n                data =  pool.index2data(valid_data_index)\n                try:\n                    func_output = func(*data)\n                    if func_output is None:\n                        continue\n                except:\n#                     print(input_types)\n#                     pretty_print_program(program + [(func.name, valid_data_index)], pool.poolnames)\n#                     print([len(p) for p in pool.pools])\n#                     global debugpool \n#                     debugpool = pool\n#                     func_output = func(*data)\n                    continue\n                \n                if func.variable_length_outputs:\n                    func_output, serial_output_types = serialize_multiple(func_output, output_types)\n                else:\n                    serial_output_types = output_types\n                \n                program.append((func.name, valid_data_index))\n                pool.update(func_output, serial_output_types)\n                \n                nv_copy = None if nodes_visited is None else nodes_visited.copy()\n                finalprogram = self._programsearch(pool, \n                                                   func_output, \n                                                   program, \n                                                   new_function_names, \n                                                   nv_copy)\n    \n                if finalprogram is not None:\n                    return finalprogram\n            \n                if nodes_visited is not None:\n                    nodes_visited.pop(node_key, None)\n                program.pop(-1)\n                pool.remove_last_entry(serial_output_types)\n        return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tasks, eval_tasks, test_tasks = get_tasks(data_path)\nallpoolnames = ['Image', 'ImageList', 'ImageProperty', 'Color', 'Shape']\nreadback = [2, 2, None, 1, 1]\n\nprint(\"%d DSL Functions\" % len(dslfuncs))\nfor f in dslfuncs:\n    dslfuncs[f].info()\nprint()\nprint(\"%d Image Properties\" % len(imageproperties))\nfor f in imageproperties:\n    print(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def progsearch_check():\n    # Sanity Check\n    run_count = 0\n    maxlen = 3\n#     task = train_tasks[71] # solvable with len 3\n#     task = train_tasks[215] # solvable with len 4\n#     task = train_tasks[110] # solvable with len 5\n    task = train_tasks[78] # solvable with len 3\n#     task = train_tasks[130] # unsolvable\n    initpool = OutputPool(poolnames=allpoolnames, num_readback_entries=readback)\n    props, propdt = serialize_multiple( ([f for _, f in imageproperties.items()],), ['ImageProperty-multiple'])\n    initpool.update(props, propdt)\n    colors = _image_colors_sorted(task.io[0][0])\n    colors, dt = serialize_multiple( colors, ['Color-multiple'])\n    initpool.update(colors, dt)\n    outshape = list(task.io[0][1].shape)\n    initpool.update(outshape, ['Shape'])\n    searcher = ProgramSearcher(task=task, initial_pool=initpool, dsl=dslfuncs, postprocessors=[SetOutputColor])\n    solved, run_count, time_elapsed, progrunner, test_outs = searcher.search(maxlen=maxlen, prevent_duplicates=True)\n    print(task.tasknum, solved, run_count, '%0.3fs' % time_elapsed)\n    if solved:\n        print()\n        progrunner.show()\nprogsearch_check()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def search_on_task(arg):\n#     task, maxlen, timeout, dsldict = arg\n#     pool = OutputPool(poolnames=allpoolnames, num_readback_entries=readback)\n#     props, propdt = serialize_multiple( ([f for _, f in imageproperties.items()],), ['ImageProperty-multiple'] )\n#     pool.update(props, propdt)\n#     colors = _image_colors_sorted(task.io[0][0])\n#     colors, dt = serialize_multiple( colors, ['Color-multiple'])\n#     pool.update(colors, dt)\n#     outshape = list(task.io[0][1].shape)\n#     pool.update(outshape, ['Shape'])\n#     searcher = ProgramSearcher(task=task, initial_pool=pool, dsl=dsldict, \n#                                postprocessors=[SetOutputColor], timeout=timeout)\n#     solved, run_count, time_elapsed, progrunner, test_outs = searcher.search(maxlen=maxlen, prevent_duplicates=True)\n#     return (task.tasknum, solved, run_count, time_elapsed, progrunner, test_outs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def search_on_task(arg):\n    task, maxlen, timeout, dsldict, try_backgroundswap = arg\n    if try_backgroundswap:\n        allpix = []\n        for io in task.io:\n            allpix.extend(np.ravel(io[0]))\n            allpix.extend(np.ravel(io[1]))\n        cols = np.unique(allpix)\n    else:\n        cols = [0]\n    for c in cols:\n        task.swap_colorpairs([(c,0)])\n        pool = OutputPool(poolnames=allpoolnames, num_readback_entries=readback)\n        props, propdt = serialize_multiple( ([f for _, f in imageproperties.items()],), ['ImageProperty-multiple'] )\n        pool.update(props, propdt)\n        colors = _image_colors_sorted(task.io[0][0])\n        colors, dt = serialize_multiple( colors, ['Color-multiple'])\n        pool.update(colors, dt)\n        outshape = list(task.io[0][1].shape)\n        pool.update(outshape, ['Shape'])\n        searcher = ProgramSearcher(task=task, initial_pool=pool, dsl=dsldict, \n                                   postprocessors=[SetOutputColor], timeout=timeout)\n        solved, run_count, time_elapsed, progrunner, test_outs = searcher.search(maxlen=maxlen, prevent_duplicates=True)\n        task.swap_colorpairs([(c,0)])\n        if solved:\n            for idx, img in enumerate(test_outs):\n                newimg = img.copy()\n                for k, v in zip([0,c], [c,0]): \n                    newimg[img==k] = v\n                test_outs[idx] = newimg\n            break\n        \n    return (task.tasknum, solved, run_count, time_elapsed, progrunner, test_outs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def multiprocess_run(tasks, df, task_type, lenvals, excludelist, timeout, dsldict, validate_test=False):\n#     alltasks = deepcopy(tasks)\n# #     alltasks = [task for task in alltasks if df.loc[task.tasknum, 'Type'] == task_type \n# #                                              and task.tasknum not in excludelist]\n#     print(f'Searching {len(alltasks)} tasks with timeout {timeout}')\n#     foundprogs = {}\n#     for maxlen in lenvals:\n#         tic = time.time()\n#         search_args = [(task, maxlen, timeout, dsldict) for task in alltasks]\n#         with MultiProcessingPool(4) as p:\n#             for sr in p.imap_unordered(search_on_task, search_args):\n#                 if sr[1]:\n#                     foundprogs[sr[0]] = sr[2:]\n#         alltasks = [task for task in alltasks if task.tasknum not in foundprogs]\n#         print('Maxlen %d Total time %fs' % (maxlen, time.time()-tic))\n#         print(foundprogs.keys())\n#         print(\"Tasks solved:\", len(foundprogs.keys()))\n    \n#     if validate_test:\n#         for tnum in foundprogs:\n#             target_outs = tasks[tnum].test_out\n#             prog_outs = foundprogs[tnum][-1]\n#             if not np.all([np.array_equal(po, to) for po, to in zip(prog_outs, target_outs)]):\n#                 print(f'Task {tnum} got false solution')\n#     return foundprogs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multiprocess_run(tasks, df, task_type, lenvals, excludelist, timeout, dsldict, validate_test=False, try_bgswap=False):\n    alltasks = deepcopy(tasks)\n#     alltasks = [task for task in alltasks if df.loc[task.tasknum, 'Type'] == task_type \n#                                              and task.tasknum not in excludelist]\n    \n    print(f'Searching {len(alltasks)} tasks with timeout {timeout}')\n    foundprogs = {}\n    for maxlen in lenvals:\n        tic = time.time()\n        search_args = [(task, maxlen, timeout, dsldict, try_bgswap) for task in alltasks]\n        with MultiProcessingPool(4) as p:\n            for sr in p.imap_unordered(search_on_task, search_args):\n                if sr[1]:\n                    foundprogs[sr[0]] = sr[2:]\n        alltasks = [task for task in alltasks if task.tasknum not in foundprogs]\n        print('Maxlen %d Total time %fs' % (maxlen, time.time()-tic))\n        print(foundprogs.keys())\n        print(\"Tasks solved:\", len(foundprogs.keys()))\n        \n    if validate_test:\n        for tnum in foundprogs:\n            target_outs = tasks[tnum].test_out\n            prog_outs = foundprogs[tnum][-1]\n            if not np.all([np.array_equal(po, to) for po, to in zip(prog_outs, target_outs)]):\n                print(f'Task {tnum} got false solution')\n    return foundprogs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_foundprogs = multiprocess_run(train_tasks, 'task_df', 'Cut and Transform', lenvals=[1,2], \n#                               timeout=None, excludelist=[], dsldict=dslfuncs, validate_test=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# eval_foundprogs = multiprocess_run(eval_tasks, 'eval_task_df', 'Cut and Transform', lenvals=[1,2], \n#                               timeout=None, excludelist=[], dsldict=dslfuncs, validate_test=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runtime_error = False\ntry:\n    if not np.all(test_tasks[0].io[0][0] == eval_tasks[0].io[0][0]):\n        test_foundprogs = multiprocess_run(test_tasks, 'test_task_df', 'Cut and Transform', lenvals=[1,2,3,4], \n                                  timeout=None, excludelist=[], dsldict=dslfuncs, try_bgswap=True)\n    else:\n        print('Skipping commit time run')\n        for task in test_tasks:\n            task.randomize_colors(keep_black=False)\n        test_foundprogs = multiprocess_run(test_tasks, 'test_task_df', 'Cut and Transform', lenvals=[1,2], \n                                  timeout=None, excludelist=[], dsldict=dslfuncs, try_bgswap=True)\n        for task in test_tasks:\n            task.reset_to_original()\nexcept:\n    print(\"Runtime error\")\n    runtime_error = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([list(row) for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='output_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not runtime_error:\n    \n    for prognum in test_foundprogs:\n        task_id = test_tasks[prognum].taskfile.split('/')[-1].split('.')[0] \n        pred_outs = test_foundprogs[prognum][-1]\n        for idx, img in enumerate(pred_outs):\n            output_id = f'{task_id}_{idx}'\n            pred_1 = flattener(img)\n            pred = pred_1 + ' ' + pred_1 + ' ' + pred_1 + ' '\n            submission.loc[output_id, 'output'] = pred\n            display(submission.loc[output_id])\n    if len(test_foundprogs) > 0:\n        submission.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}