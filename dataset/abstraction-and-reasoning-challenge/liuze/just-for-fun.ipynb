{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_1(input, task_id=''):\n    input = np.asarray(input)\n    if input.shape != (2,2):\n        return input.tolist()\n    output = np.zeros((6,6))\n    output[0,:] = np.array(input[0,:].tolist()*3)\n    output[1,:] = np.array(input[1,:].tolist()*3)\n    output[2,:] = np.array(input[0,:].tolist()[::-1]*3)\n    output[3,:] = np.array(input[1,:].tolist()[::-1]*3)\n    output[4,:] = np.array(input[0,:].tolist()*3)\n    output[5,:] = np.array(input[1,:].tolist()*3)\n    print('model1', task_id)\n    return output.astype(int).tolist()\n\ndef model_2(task, task_id=''):\n    train_data = task['train']\n    test_data = task['test']\n    for data in train_data:\n        input = data['input']\n        output = data['output']\n        if np.asarray(input).shape !=np.asarray(output).shape :\n            return input\n    color_map = dict()\n    for item in train_data:\n        input = item['input']   \n        output = item['output']\n        for x,y in zip(input[0],output[0]):\n            color_map[x] = y\n    for data in test_data:\n        input = data['input']\n        output = np.array(input, dtype='int')\n#         print('start', output)\n        for i in range(output.shape[0]):\n            for j in range(output.shape[1]):\n                output[i,j] = color_map.get(output[i,j], 0)\n    print(task_id, 'model2 predict')\n    return output.tolist()\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef load_task(filename, task_type=0):\n    path = training_path\n    if task_type==1:\n        path = evaluation_path\n    if task_type==2:\n        path = test_path\n    task_file = str(path / filename)\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n        return task\n    \n\n# ref: https://www.kaggle.com/boliu0/visualizing-all-task-pairs-with-gridlines\ndef plot_one(ax, i,train_or_test,input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    \n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)\n    \n\ndef plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(axs[0,i],i,'train','input')\n        plot_one(axs[1,i],i,'train','output')        \n    plt.tight_layout()\n    plt.show()        \n        \n    num_test = len(task['test'])\n    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n    if num_test==1: \n        plot_one(axs[0],0,'test','input')\n        plot_one(axs[1],0,'test','output')     \n    else:\n        for i in range(num_test):      \n            plot_one(axs[0,i],i,'test','input')\n            plot_one(axs[1,i],i,'test','output')  \n    plt.tight_layout()\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pathlib import Path\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_tasks = sorted(os.listdir(training_path))\nprint(training_tasks[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ret = []\nfor file in training_tasks:\n    task = load_task(file, 0)\n    x = task['train'][0]['input']\n    x = np.asarray(x)\n    ret.append((file, str(x.shape)))\n    \ndf_shape = pd.DataFrame(ret, columns=['filename','shape'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_shape.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_shape.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_shape['shape'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file1 = df_shape[df_shape['shape']=='(2, 2)']\ndisplay(file1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file = file1.iloc[0,0]\ntask = load_task(file)\n\nplot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file = file1.iloc[1,0]\ntask = load_task(file)\n\nplot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file1 = df_shape[df_shape['shape']=='(3, 3)']\ndisplay(file1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file = file1.iloc[0,0]\ntask = load_task(file)\n\nplot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model_2(task)\nprint(pred)\nprint(task['test'][0]['output'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file = file1.iloc[1,0]\ntask = load_task(file)\nprint(task)\nplot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tasks have multiple `train` input-output pairs. Most tasks have a single `test` input-output pair, although some have more than one."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(task['train'][0]['input'])\ndisplay(task['train'][0]['output'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using the correct prediction format"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `output_id` is the `id` of the task, followed by the index of the `test` input that you should use to make your prediction. The `output` is the predicted output of the corresponding `test` input, reformatted into a string representation. (You can make three predictions per `output_id`, delineated by a space.) Use the following function to convert from a 2d python list to the string representation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndisplay(example_grid)\nprint(flattener(example_grid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Re-creating the sample submission output\n\nThis demonstrates how to loop over the sample submission and make predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"for output_id in submission.index:\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    f = str(test_path / str(task_id + '.json'))\n    with open(f, 'r') as read_file:\n        task = json.load(read_file)\n    # skipping over the training examples, since this will be naive predictions\n    # we will use the test input grid as the base, and make some modifications\n    data = task['test'][pair_id]['input'] # test pair input\n    # for the first guess, predict that output is unchanged\n    pred_1 = model_1(data, task_id)\n    pred_1 = flattener(pred_1)\n    # for the second guess, change all 0s to 5s\n    data = model_2(task, task_id)\n    pred_2 = flattener(data)\n    # for the last gues, change everything to 0\n    data = [[0 for i in j] for j in data]\n    pred_3 = flattener(data)\n    # concatenate and add to the submission output\n    pred = pred_1 + ' ' + pred_2 + ' ' + pred_3 + ' ' \n    submission.loc[output_id, 'output'] = pred\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}