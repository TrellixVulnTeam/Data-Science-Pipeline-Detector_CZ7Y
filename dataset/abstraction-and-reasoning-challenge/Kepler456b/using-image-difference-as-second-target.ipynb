{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is basically a single step Cellular Automata solution applied to the test set following the example in https://www.kaggle.com/teddykoker/training-cellular-automata-part-ii-learning-tasks\n\nThe main difference here is the addition of a second target, which is almost the difference between the input and output. This seems to boost the accuracy on the training set from 18 to 24, but did not change anything for the evaluation."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json\nimport os\nfrom os.path import join as path_join\n\n\ndef load_data(path):\n    tasks = pd.Series()\n    for file_path in os.listdir(path):\n        task_file = path_join(path, file_path)\n\n        with open(task_file, 'r') as f:\n            task = json.load(f)\n\n        tasks[file_path[:-5]] = task\n    return tasks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tasks = load_data('../input/abstraction-and-reasoning-challenge/training/')\nevaluation_tasks = load_data('../input/abstraction-and-reasoning-challenge/evaluation/')\ntest_tasks = load_data('../input/abstraction-and-reasoning-challenge/test/')\n\ntrain_tasks.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nimport torch.nn as nn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam\nfrom torch.nn import Conv2d\nfrom torch import FloatTensor, LongTensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\n\nclass CAModel(nn.Module):\n    def __init__(self, num_states):\n        super(CAModel, self).__init__()      \n        self.simple_conv = nn.Sequential(\n            nn.Conv2d(num_states, 32, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.conv1 = nn.Conv2d(32, num_states, kernel_size=1)\n        self.conv2 = nn.Conv2d(32, num_states+1, kernel_size=1)\n        self.soft = nn.Softmax(dim=1)\n        \n    def forward(self, x, steps = 1):\n        for step in range(steps):\n            x = self.simple_conv(x)\n            y1 = self.conv1(x)\n            y2 = self.conv2(x)\n            x = self.soft(y1)\n        return y1, y2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import colors\n\n\ncmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25', '#530C25'])\nnorm = colors.Normalize(vmin=0, vmax=10)\n    \ndef plot_pictures(pictures, labels):\n    fig, axs = plt.subplots(1, len(pictures), figsize=(2*len(pictures),32))\n    for i, (pict, label) in enumerate(zip(pictures, labels)):\n        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n        axs[i].set_title(label)\n    plt.show()\n    \n\ndef plot_sample(sample, predict=None):\n    if predict is None:\n        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n    else:\n        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inp2img(inp):\n    inp = np.array(inp)\n    img = np.full((10, inp.shape[0], inp.shape[1]), 0, dtype=np.uint8)\n    for i in range(10):\n        img[i] = (inp==i)\n    return img\n\ndef target_maker(samin, samout):\n    target = np.full((len(samin), len(samin[0])), 0, dtype=np.uint8)\n    for i in range(len(samin)):\n        for j in range(len(samin[0])):\n            if samin[i][j]==samout[i][j]:\n                target[i,j] = 10  #index 10 is for retained info. see pred_maker.\n            else:\n                target[i,j] = samout[i][j]\n    return target\n\ndef pred_maker(inp, pred, pred_grade):\n    inp = np.asarray(inp)\n    final_pred = np.full((inp.shape[0], inp.shape[1]), 0, dtype=np.uint8)\n    grade_avg = np.mean(pred_grade)\n    threshold = 0.66\n    for i in range(pred.shape[0]):\n        for j in range(pred.shape[1]):\n            if pred[i,j] == 10 or pred_grade[i, j]/grade_avg < threshold: #index=10\n                final_pred[i,j] = inp[i,j]\n            else:\n                final_pred[i,j] = pred[i,j]\n    return final_pred\n    \nclass TaskSolver:        \n    def train(self, task_train, n_epoch=100, max_steps=2):\n        \"\"\"basic pytorch train loop\"\"\"\n        self.net = CAModel(10)\n        criterion = CrossEntropyLoss()\n        optimizer = Adam(self.net.parameters(), lr = 0.01) #(0.1 / (num_steps * 2)))\n            \n        for epoch in range(n_epoch):\n            optimizer.zero_grad()\n            for sample in task_train:\n                #Our target is label - input. This makes it easier.\n                target = target_maker(sample['input'],sample['output'])\n                inputs = FloatTensor(inp2img(sample['input'])).unsqueeze(dim=0)\n                labels1 = LongTensor(sample['output']).unsqueeze(dim=0)\n                labels2 = LongTensor(target).unsqueeze(dim=0)\n                outputs1 = self.net(inputs)[0]\n                outputs2 = self.net(inputs)[1]\n                loss = criterion(outputs1, labels1)\n                loss.backward()\n                loss = criterion(outputs2, labels2)\n                loss.backward()\n                optimizer.step()\n\n        #output_img = outputs.squeeze(dim=0).detach().cpu().numpy().argmax(0)\n        #plot_pictures([sample['input'], sample['output'],target, output_img ], ['Input', 'label', 'target', 'Predict'])\n            \n        #output_img = outputs.detach().numpy()\n        #output_img = np.squeeze(output_img)\n        #output_img = np.argmax(output_img, axis=0)\n        #plot_pictures([sample['input'],target,output_img],['input','target','predict'])\n            \n        return self\n            \n    def predict(self, task_test):\n        predictions = []\n        pred_grades = []\n        with torch.no_grad():\n            for sample in task_test:\n                inputs = FloatTensor(inp2img(sample['input'])).unsqueeze(dim=0)\n                outputs = self.net(inputs)[0]\n                #outputs = self.net(inputs)[1]\n                pred =  outputs.squeeze(dim=0).cpu().numpy().argmax(0)\n                \n                #pred_grade = np.full((pred.shape[0], pred.shape[1]), 0, dtype=np.float64)\n                #for i in range(pred.shape[0]):\n                #    for j in range(pred.shape[1]):\n                #        k = pred[i][j]\n                #        pred_grade[i][j] = (torch.nn.Softmax(dim=1)(outputs)).squeeze(dim=0).cpu().numpy()[k][i][j]\n                \n                #final_pred = pred_maker(sample['input'],pred, pred_grade)\n                final_pred = pred\n                predictions.append(final_pred)\n                \n                #predictions.append(pred)\n                \n        return predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"def input_output_shape_is_same(task):\n    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n\ndef calk_score(task_test, predict):\n    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(tasks):\n    ts = TaskSolver()\n    result = []\n    predictions = []\n    for task in tqdm(tasks):\n        if input_output_shape_is_same(task):\n            ts.train(task['train'])\n            pred = ts.predict(task['test'])\n            score = calk_score(task['test'], pred)\n        else:\n            pred = [el['input'] for el in task['test']]\n            score = [0]*len(task['test'])\n        \n        predictions.append(pred)\n        result.append(score)\n       \n    return result, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_result, train_predictions = evaluate(train_tasks)\ntrain_solved = [any(score) for score in train_result]\n\ntotal = sum([len(score) for score in train_result])\nprint(f\"solved : {sum(train_solved)} from {total} ({sum(train_solved)/total})\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation_result, evaluation_predictions = evaluate(evaluation_tasks)\nevaluation_solved = [any(score) for score in evaluation_result]\n\ntotal = sum([len(score) for score in evaluation_result])\nprint(f\"solved : {sum(evaluation_solved)} from {total} ({sum(evaluation_solved)/total})\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize\n\nvisualize solved tasks"},{"metadata":{},"cell_type":"markdown","source":"### train solved tasks"},{"metadata":{"trusted":true},"cell_type":"code","source":"for task, prediction, solved in tqdm(zip(train_tasks, train_predictions, train_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### evaluation solved tasks"},{"metadata":{"trusted":true},"cell_type":"code","source":"for task, prediction, solved in tqdm(zip(evaluation_tasks, evaluation_predictions, evaluation_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\ndef make_pediction(tasks):\n    ts = TaskSolver()\n    result = pd.Series()\n    for idx, task in tqdm(test_tasks.iteritems()):\n        if input_output_shape_is_same(task):\n            ts.train(task['train'])\n            pred = ts.predict(task['test'])\n        else:\n            pred = [el['input'] for el in task['test']]\n        \n        for i, p in enumerate(pred):\n            result[f'{idx}_{i}'] = flattener(np.array(p).tolist())\n       \n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = make_pediction(test_tasks)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = submission.reset_index()\nsubmission.columns = ['output_id', 'output']\nsubmission.to_csv('submission.csv', index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All train tasks predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"for task, prediction in tqdm(zip(train_tasks, train_predictions)):\n    if input_output_shape_is_same(task):\n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}