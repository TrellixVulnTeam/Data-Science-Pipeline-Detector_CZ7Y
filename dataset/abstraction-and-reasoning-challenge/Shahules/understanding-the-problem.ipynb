{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <font size='5' color='red'>Content</font>"},{"metadata":{},"cell_type":"markdown","source":"Hey fellow Kagglers,this is a one strange competition among the all the competitions that has been lauched in kaggle till date.So,I dedicate this notebook to share what I undertood about the competition and **Abstract Reasoning**.\n![](https://miro.medium.com/max/2081/1*KVomuoRF3Io41g4Zhjy2iw.jpeg)"},{"metadata":{},"cell_type":"markdown","source":"To understand why abstract reasoning is critical for general intelligence, consider Archimedes’ famous “Eureka!” moment: by noticing that the volume of an object is equivalent to the volume of water that the object displaces, he understood volume at a conceptual level, and was therefore able to reason about the volume of other irregularly shaped objects.The ability to relate two abstract concepts also allowed Albert Einstein to formulate the basics of the theory of relativity as he reasoned that an equivalence relation exists between an observer falling in uniform acceleration and an observer in a uniform gravitational field. Abstract reasoning has long been used as an example that separates human cognition from artificial intelligence(AI)\n\nWe would like AI to have similar capabilities. While current systems can defeat world champions in complicated strategic games, they often struggle on other apparently simple tasks, especially when an abstract concept needs to be discovered and reapplied in a new setting. For example, if specifically trained to only count triangles, then even our best AI systems can still fail to count squares, or any other previously unencountered object.So,I hope you now understand the basic difference between our problem and the traditional artificial intelligence problems that we are familiar with.Now,we will move onto exploring this competition.."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\n    \nfrom pathlib import Path\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font size='4' color='red'>Abstract reasoning dataset</font>\n\nAbstract Reasoning Corpus (ARC) comprises a training set and an evaluation set. The training set features 400 tasks,while the evaluation set features 400 tasks.  The evaluation set is further split into a publicevaluation set (400 tasks) and a private evaluation set (100 tasks). All tasks are unique, and the set of test tasks and the set of training tasks are disjoint.Let's check this first.."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\n\ntraining_tasks = sorted(os.listdir(training_path))\nevaluation_tasks = sorted(os.listdir(evaluation_path))\ntest_tasks = sorted(os.listdir(test_path))\nprint(\"Number of examples in training corpus is \",len(training_tasks))\nprint(\"Number of examples in evaluation corpus is \",len(evaluation_tasks))\nprint(\"Number of examples in testing corpus is \",len(test_tasks))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay,now each task consists of a small number of demonstration examples (3 on average), and a small number of test examples (generally 1, although it may be 2 or 3 in rare cases). Each example consists of an “input grid” and an “output grid”.  Each “grid” is a literal grid of symbols (each symbol is typically visualized via a unique color). Thereare 10 unique symbols (or colors).  A grid can be any height or width between 1x1 and 30x30, inclusive (the median height is 9 and the median width is 10). Let's understand this by checking our training corpus."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\ncmap = colors.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n\ndef plot_task(task):\n    n = len(task[\"train\"]) + len(task[\"test\"])\n    fig, axs = plt.subplots(2, n, figsize=(4*n,8), dpi=50)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    fig_num = 0\n    for i, t in enumerate(task[\"train\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Train-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Train-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    for i, t in enumerate(task[\"test\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Test-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Test-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    \n    plt.tight_layout()\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, json_path in enumerate(training_tasks[:3]):\n    \n    task_file = str(training_path / json_path)\n\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n\n    print(f\"{i:03d}\", task_file)\n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you can see that for each task there are n number of training pairs and 1 test pair.We need to build an algorithm to that is trained on these n training pairs and can predict the output pattern for the test input.Also you can observe that the grid size is not same for all tasks,our algoithm should first be able to figure out the output grid size given some training pairs.\nSo now you know your objective we will move onto submission section."},{"metadata":{},"cell_type":"markdown","source":"## <font size='3' color='red'>prediction format</font>"},{"metadata":{},"cell_type":"markdown","source":"For each test task,you can use 3 trials.If anyone of these trials exactly match the correct output matrix,the answer is regarded as correct.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\ndisplay(submission.head())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The output_id is the id of the task, followed by the index of the test input that you should use to make your prediction. The output is the predicted output of the corresponding test input, reformatted into a string representation.Let's check how this is represented.."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of submissions for each test task is\" ,len(submission['output'][0].strip().split(' ')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try and print an image correponding to one output"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_output(outputid):\n    \n    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n    l=0\n    for sub in submission.loc[outputid]['output'].strip().split(' '):\n        out=[]\n        for i in sub.split('|')[1:-1]:\n                x=list(map(int,list(i)))\n                out.append(x)\n\n        axs[l].imshow(out,cmap=cmap)\n        axs[l].axis('off')\n        l=l+1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_output('009d5c81_0')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you can see the three predicted ouput patterns for test task 1 . For each test task there are 3 trails like this and if any of these exactly match the expected output your submission is regarded as correct."},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='red'>Please leave an upvote if you feel this was helpful<font size='3' color='blue'>   \n##    Thank you</font></font>"},{"metadata":{},"cell_type":"markdown","source":"### References\n- https://deepmind.com/blog/article/measuring-abstract-reasoning\n- https://arxiv.org/pdf/1911.01547.pdf\n- https://towardsdatascience.com/are-neural-networks-capable-of-abstract-reasoning-lets-use-an-iq-test-to-prove-it-1d1ff1929fef"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}