{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n!ls -l ../input\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dir_voc = \"/kaggle/input/pascal-voc-2012/VOC2012/\"\ndir_ssd = \"/kaggle/input/ssdogawa/\"\ndir_input = \"/kaggle/input\"\n!ls -l $dir_voc\n!ls -l $dir_ssd\n\nimport sys\n\nsys.path.insert(0,dir_ssd)\nprint(sys.path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# パッケージのimport\nimport cv2\nimport numpy as np\nimport os.path as osp\nimport time\nimport random\nimport pandas as pd\n\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.optim as optim\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 乱数のシードを設定\ntorch.manual_seed(1234)\nnp.random.seed(1234)\nrandom.seed(1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"使用デバイス：\", device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n\n\n# ファイルパスのリストを取得\nrootpath = dir_voc #\"./data/VOCdevkit/VOC2012/\"\ntrain_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n    rootpath)\n\n# Datasetを作成\nvoc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n               'bottle', 'bus', 'car', 'cat', 'chair',\n               'cow', 'diningtable', 'dog', 'horse',\n               'motorbike', 'person', 'pottedplant',\n               'sheep', 'sofa', 'train', 'tvmonitor']\ncolor_mean = (104, 117, 123)  # (BGR)の色の平均値\ninput_size = 300  # 画像のinputサイズを300×300にする\n\ntrain_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n\nval_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n\n\n# DataLoaderを作成する\nbatch_size = 32\n\ntrain_dataloader = data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n\nval_dataloader = data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n\n# 辞書オブジェクトにまとめる\ndataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from utils.ssd_model import SSD\n\n# SSD300の設定\nssd_cfg = {\n    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n    'input_size': 300,  # 画像の入力サイズ\n    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n}\n\n# SSDネットワークモデル\nnet = SSD(phase=\"train\", cfg=ssd_cfg)\n\n# SSDの初期の重みを設定\n# ssdのvgg部分に重みをロードする\nvgg_weights = torch.load(dir_ssd+'./weights/vgg16_reducedfc.pth')\nnet.vgg.load_state_dict(vgg_weights)\n\n# ssdのその他のネットワークの重みはHeの初期値で初期化\n\n\ndef weights_init(m):\n    if isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight.data)\n        if m.bias is not None:  # バイアス項がある場合\n            nn.init.constant_(m.bias, 0.0)\n\n\n# Heの初期値を適用\nnet.extras.apply(weights_init)\nnet.loc.apply(weights_init)\nnet.conf.apply(weights_init)\n\n# GPUが使えるかを確認\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"使用デバイス：\", device)\n\nprint('ネットワーク設定完了：学習済みの重みをロードしました')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from utils.ssd_model import MultiBoxLoss\n\n# 損失関数の設定\ncriterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n\n# 最適化手法の設定\noptimizer = optim.SGD(net.parameters(), lr=1e-3,\n                      momentum=0.9, weight_decay=5e-4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# モデルを学習させる関数を作成\n\n\ndef train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n\n    # GPUが使えるかを確認\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"使用デバイス：\", device)\n\n    # ネットワークをGPUへ\n    net.to(device)\n\n    # ネットワークがある程度固定であれば、高速化させる\n    torch.backends.cudnn.benchmark = True\n\n    # イテレーションカウンタをセット\n    iteration = 1\n    epoch_train_loss = 0.0  # epochの損失和\n    epoch_val_loss = 0.0  # epochの損失和\n    logs = []\n\n    # epochのループ\n    for epoch in range(num_epochs+1):\n\n        # 開始時刻を保存\n        t_epoch_start = time.time()\n        t_iter_start = time.time()\n\n        print('-------------')\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-------------')\n\n        # epochごとの訓練と検証のループ\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                net.train()  # モデルを訓練モードに\n                print('（train）')\n            else:\n                if((epoch+1) % 10 == 0):\n                    net.eval()   # モデルを検証モードに\n                    print('-------------')\n                    print('（val）')\n                else:\n                    # 検証は10回に1回だけ行う\n                    continue\n\n            # データローダーからminibatchずつ取り出すループ\n            for images, targets in dataloaders_dict[phase]:\n\n                # GPUが使えるならGPUにデータを送る\n                images = images.to(device)\n                targets = [ann.to(device)\n                           for ann in targets]  # リストの各要素のテンソルをGPUへ\n\n                # optimizerを初期化\n                optimizer.zero_grad()\n\n                # 順伝搬（forward）計算\n                with torch.set_grad_enabled(phase == 'train'):\n                    # 順伝搬（forward）計算\n                    outputs = net(images)\n\n                    # 損失の計算\n                    loss_l, loss_c = criterion(outputs, targets)\n                    loss = loss_l + loss_c\n\n                    # 訓練時はバックプロパゲーション\n                    if phase == 'train':\n                        loss.backward()  # 勾配の計算\n\n                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n                        nn.utils.clip_grad_value_(\n                            net.parameters(), clip_value=2.0)\n\n                        optimizer.step()  # パラメータ更新\n\n                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n                            t_iter_finish = time.time()\n                            duration = t_iter_finish - t_iter_start\n                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n                                iteration, loss.item(), duration))\n                            t_iter_start = time.time()\n\n                        epoch_train_loss += loss.item()\n                        iteration += 1\n\n                    # 検証時\n                    else:\n                        epoch_val_loss += loss.item()\n\n        # epochのphaseごとのlossと正解率\n        t_epoch_finish = time.time()\n        print('-------------')\n        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n            epoch+1, epoch_train_loss, epoch_val_loss))\n        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n        t_epoch_start = time.time()\n\n        # ログを保存\n        log_epoch = {'epoch': epoch+1,\n                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n        logs.append(log_epoch)\n        df = pd.DataFrame(logs)\n        df.to_csv(\"log_output.csv\")\n\n        epoch_train_loss = 0.0  # epochの損失和\n        epoch_val_loss = 0.0  # epochの損失和\n\n        # ネットワークを保存する\n        if ((epoch+1) % 10 == 0):\n            torch.save(net.state_dict(), 'ssd300_' +\n                       str(epoch+1) + '.pth')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 学習・検証を実行する\nnum_epochs= 100#50  \ntrain_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}