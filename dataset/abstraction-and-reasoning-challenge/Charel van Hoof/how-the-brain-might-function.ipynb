{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How the brain might function \n### Free Energy Principle tutorial without a PhD\n<img src=\"https://cdn.pixabay.com/photo/2018/05/08/08/44/artificial-intelligence-3382507_960_720.jpg\" width=500>\n<center>Image by <a href=\"https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Gerd Altmann</a> from <a href=\"https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Pixabay</a> </center>   \n<br>\n\nWelcome to my quest to discover the secret of human-level artificial intelligence!  \n\n## Where to start?\nI did start, like many others, to understand machine learning: Deep Neural networks, Convolutional Neural Networks, Recurring Neural Networks, Reinforcement learning, etc, etc. I found it very interesting and I am enthusiastic about the potential, it will and is changing the world. Nevertheless, I also noticed that this form of Artificial Intelligence is not yet really intelligent. In essence, it is a regression technique. The answer is not anymore in just more data or more computing power. \n\nLike many new discoveries, we turn to nature as a best practice. The brain is the only true source of intelligence we are aware of today. Somehow the brain has the ability to abstract meaning out of a stream of sensory data and uses it to model/understand the world to make decisions. The higher brain functions translate lower-level sensory information (e.g. pixel blob on the retina) to meaning (e.g. it is an apple) and link all the various information around that meaning together. (e.g. I know how it tastes, or if we were talking about stock prices I know it is the company that makes iPhones). Something we have not yet been able to do properly with all our Neural Network related technology today. What does the brain do? To have an insight into that question we need to turn to neuroscience.\n\n## The Free Energy Principle\nNeuroscience has produced a candidate which suggests that several global brain theories might be unified within a free-energy framework: [Free Energy Principle](https://en.wikipedia.org/wiki/Free_energy_principle) (FEP) by [Karl Friston](https://www.fil.ion.ucl.ac.uk/~karl/). The free-energy principle is an attempt to explain the structure and function of the brain, starting from the very fact that we exist. The Free Energy Principle is mathematically rigorous and both neurologically and evolutionary plausible. It is argued it [might hold the key to true AI](https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/). Thought that it is relevant for this competition and might inspire people to have a good look at it.   \n\nBefore we dive into the content I would like to thank François Chollet for this competition. I like it and see many more are interested, like me, to help figure out the secret of intelligence. This competition is a nice way to move the agenda forward.  ","metadata":{}},{"cell_type":"markdown","source":"# Free Energy Principle tutorial without a PhD\nA lot of research papers have been published by Karl Friston and understanding them has a steep learning curve. Even to the point that people complain about it ([¨God Help Us, Let’s Try To Understand Friston On Free Energy¨](https://www.lesswrong.com/posts/wpZJvgQ4HvJE2bysy/god-help-us-let-s-try-to-understand-friston-on-free-energy)). I did record a number of kernels which I positioned as \"Free Energy Principle tutorial without a PhD\" to help understand the Free Energy principle. Apologies I couldn't fit it into one notebook, there is much to explain. If you are curious, start with the first notebook and decide if you want to push forward.  \n\nNote that I did not create the kernels especially for this competition, I decided 1.5 years ago to research intelligence which resulted in a part-time Phd next to my work. When I saw François Cholletthis' announcements and subsequent Kaggle competition, I decided to see if I can help with my (humble) knowledge. Hopefully, it inspires some people in this fantastic Kaggle community and helps to translate the ideas into machine learning code (which I will certainly do, but not sure if I will make the timeline of the competition). ","metadata":{}},{"cell_type":"markdown","source":"## Does it work?\nYou might wonder if it is worth it to try to understand the Free Energy principle, Yes it is! Below some teasers of robots moving with active Inference. \n\n<img src=\"https://i.imgur.com/yZxHtES.gif\" width=400> \n<center>Active Inference Controller, Full video: <a href=\"https://www.youtube.com/watch?v=Vsb0MzOp_TY\">link</a>  </center>   \n<br>\n\n<img src=\"https://i.imgur.com/seB0ar1.gif\" width=400> \n<center>Full video: <a href=\"https://www.youtube.com/watch?v=rdbbmwo4TY4\">link</a>  </center>   \n<br>\n\nWhy I like/use these robot arm examples? It goes back to how infants learn their abilities after birth. The brain is skull-bound and needs to infer the causes of its sensory input, even states of your own body need to be inferred, everything outside the brain needs to be inferred. According to this research [paper](https://royalsocietypublishing.org/doi/10.1098/rstb.2018.0030) learning of the generative model starts by learning your own body: it enables infants to first recognize their body as sensory signals producing no or very small prediction error (self-cognition).  ","metadata":{}},{"cell_type":"markdown","source":"## How the brain might function - part 1 base camp\nSee this Notebook: [Learn by example: Active Inference in the brain -1](https://www.kaggle.com/charel/learn-by-example-active-inference-in-the-brain-1)  \nIn essence, the brain is a prediction mechanism, one that attempts to minimize the error of its hypothesis about the world and the sensory input it receives:\n* The skull-bound brain needs to infer the world.\n* The brain builds an internal model of the world using Bayesian inference (the generative model).\n* Discrepancies between the internal model (the prediction) and the sensory observations result in prediction error.\n* The brain aims to minimize the Free Energy which is equivalent to minimizing prediction errors\n* by improving perception, acting on the environment, learning the generative model, optimizing the expected precision of uncertainty.\n\n","metadata":{}},{"cell_type":"markdown","source":"## How the brain might function - part 2 advanced base camp\nSee this Notebook: [Learn by example: Active Inference in the brain -2](https://www.kaggle.com/charel/learn-by-example-active-inference-in-the-brain-2)  \nUnder some fairly basic assumptions, the integrals and probability densities of the Free Energy translate into a straightforward prediction error minimization scheme as we will see in this notebook. It will take some ¨mathematically rigorous¨ steps and for those who speak English more frequent than ¨Math¨ (like me) you need some stamina, just follow step by step. \n\n* See this supporting [notebook](https://www.kaggle.com/charel/learn-by-example-active-inference-noise) to generate noise with temporal smoothness. Noise refers to any random fluctuations of data. In nature, noise and other inaccuracies are all around us and biological life needs to function despite this uncertainty. The brain is remarkably robust against uncertainty. For example, we have a good chance to catch a ball if it is later in the day and there are more shadows, if your cat suddenly rushes by, if the ball is spinning, if your arms are a little sore, etc. In conventional control theory, it is assumed that fluctuations are independent, a sequence of serially uncorrelated random variables (e.g. white noise). Random fluctuations are sufficiently fast that we do not observe their serial or temporal correlations. This is less plausible for biological reality, random fluctuations originate from dynamical systems themselves (e.g. sound, waves). Therefore, these signals are continuous and not infinitely rough as is white noise for example. It is noise with some form of temporal smoothness.","metadata":{}},{"cell_type":"markdown","source":"## How the brain might function - part 3 camp observation point\nSee this Notebook: [Learn by example: Active Inference in the brain -3](https://www.kaggle.com/charel/learn-by-example-active-inference-in-the-brain-3)  \nIn this notebook, I will dive into the neurological plausible aspects. My background is in Information Technology. One of the things I learned in my career is not to start large software development programs without an architecture to frame the solution. If we want to write biological-inspired true artificial intelligence software  it makes sense to understand the functional architecture of the brain first. So, I am very curious and interested to learn about neuroscience and the brain.\n\nThe Free Energy Principle models the world in a hierarchical model, because:\n+ we perceive the real world as hierarchically structured, a nested structure where ¨this normally belongs to that¨\n+ a functional hierarchical architecture is observed in the brain, prior knowledge is stored in an internal model to represent the world. Higher abstract / slower time scale / “beliefs” influences all the way down to low level sensory / short term /“interpretations” predictions and visa-versa. Or in other words, our perception is not only based on sensory observations but is also based on what we expect to perceive.\n+ Deep models with many hierarchical layers have proven to be successful in incrementally abstracting, learning, and representing knowledge, a feature well known for people working with deep neural networks\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## How the brain might function - part 4 Improving perception\n\nSee this Notebook: [Learn by example: Active Inference in the brain-4](https://www.kaggle.com/charel/learn-by-example-active-inference-in-the-brain-4)  \nAfter 3 full notebooks of theory, I can imagine that you want to see some working code. We will set up a simulation environment so the theory is applied in an intuitive context and show how lowering Free Energy will be done by gradient descent (the standard way neural networks learn) resulting in a form of enhanced predictive coding (prediction error minimization based on *precision weighted* prediction errors).  \nFor the active inference architecture, I will use a \"building blocks\" concept. The analogy would be the neuron as a building block to stack into deep neural network architectures. So, the first focus will be on the equivalent building blocks for active inference, in that case, a simplest building block with 1 sensory observation (y), 1 prior (v), and 1 hidden state (x). Let's start simple and understand the basics before the complexities of full deep/hierarchical models can be attempted to be understood.  \nIn the final part of this notebook, it is showcased how Free Energy minimization could be implemented in neural circuits. The idea is to constraint the executed computations in a biologically plausible manner resulting in a biologically plausible predictive coding scheme.\n1. https://www.kaggle.com/charel/active-inference-code-by-example-1\n1. https://www.kaggle.com/charel/active-inference-code-by-example-2\n1. https://www.kaggle.com/charel/active-inference-code-by-example-3 \n\nPrediction coding schemes already have shown their potential and one of the best know examples that got a fair amount of attention is Prednet. Prednet is a deep *Pred*ictive *Net*work that learns to predict the next frame of a video. It is inspired by the principles of predictive coding from neuroscience literature, Here you will find the [paper](https://arxiv.org/pdf/1605.08104.pdf) and the [code](https://coxlab.github.io/prednet/). Below some next frame predictions are shown on the Caltech Pedestrian dataset. Quite amazing to see the network can learn to predict a trajectory of a turning car, to fill in the background it leaves behind, to predict the appearance of shadows, etc. And in case you argue that the prediction can be quite simple, just predict the previous video frame. Prednet outperforms significantly a copy last frame approach. It can learn hidden or latent variables and is able to generalize over different video footage, e.g. the model was trained on KITTI dataset and sequences below are from the Pedestrian dataset.\n\n![](https://coxlab.github.io/prednet/plots/caltech_montage_3.gif). \n<center> Video footage from: https://coxlab.github.io/prednet/ </center>   \n<br>\n","metadata":{}},{"cell_type":"markdown","source":"## How the brain might function - part 5 Acting on the environment\nSee this Notebook: Learn by example: [Active Inference in the brain-5](https://www.kaggle.com/charel/learn-by-example-active-inference-in-the-brain-5)  \nHow action is incorporated in the Free Energy Principle, the 'active' in 'active inference'. Starting with why incorporating action in the framework is so important. In this notebook, you will find the reasoning why action could be the birthplace of intelligence, a critical missing piece in artificial neural networks. Next, we will look at how action is incorporated, leading to code so you can test it for yourself. I also added a section to compare active inference to other machine learning frameworks.  \nAfter this notbook you are equipped with the knowledge to make robots move with active inference!\n<img src=\"https://i.imgur.com/bSLaDd8.gif\" width=400> \n<center> Jackal robot moving with active inference by a group of students at the Technical University Delft  </center>   \n\n","metadata":{}}]}