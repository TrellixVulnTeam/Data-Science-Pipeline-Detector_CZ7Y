{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n    \nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\npath = Path('/kaggle/input/abstraction-and-reasoning-challenge')\ntrain_df = path/'training'\nevaluation_df = path/'evaluation'\ntest_df = path/'test'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_task = sorted(os.listdir(train_df))\ntest_task = sorted(os.listdir(test_df))\nevaluation_task = sorted(os.listdir(evaluation_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_task[:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_task), len(test_task), len(evaluation_task))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_one(ax, i,train_or_test,input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    \n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(axs[0,i],i,'train','input')\n        plot_one(axs[1,i],i,'train','output')        \n    plt.tight_layout()\n    plt.show()        \n        \n    num_test = len(task['test'])\n    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n    if num_test==1: \n        plot_one(axs[0],0,'test','input')\n        plot_one(axs[1],0,'test','output')     \n    else:\n        for i in range(num_test):      \n            plot_one(axs[0,i],i,'test','input')\n            plot_one(axs[1,i],i,'test','output')  \n    plt.tight_layout()\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n# 0:black, 1:blue, 2:red, 3:greed, 4:yellow,\n# 5:gray, 6:magenta, 7:orange, 8:sky, 9:brown\nplt.figure(figsize=(4, 2), dpi=300)\nplt.imshow([list(range(12))], cmap=cmap, norm=norm)\nplt.xticks(list(range(12)))\nplt.yticks([])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(train_task)):\n    task_file = str(train_df / train_task[i])\n    \n    with open(task_file, 'r') as f:\n        task = json.load(f)\n        \n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(test_task)):\n    task_file = str(test_df / test_task[i])\n    \n    with open(task_file, 'r') as f:\n        task = json.load(f)\n        \n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(evaluation_task)):\n    task_file = str(evaluation_df / evaluation_task[i])\n    \n    with open(task_file, 'r') as f:\n        task = json.load(f)\n        \n    plot_task(task)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}