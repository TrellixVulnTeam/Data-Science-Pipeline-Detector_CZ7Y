{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **6.2.20 UPDATE - this notebook explored Halite in its initial form, and has not been updated to reflect the latest changes in Kaggle environments or Halite gameplay rules**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# Halite environment was defined in v0.2.1\n!pip install 'kaggle-environments>=0.2.1'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Halite Environment","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make\n\nenv = make(\"halite\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a Submission (agent)\n\nTo submit to the competition, a python file must be created where the last function is the \"act\" (the function which given an observation generates an action).  Logic above the \"act\" function is allowed including helpers.  Any python that executes immediately will be run during the initialize phase and not included in the \"act timeout\".\n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image. Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile submission.py\n\nfrom random import choice\ndef agent(obs):\n    action = {}\n    ship_id = list(obs.players[obs.player][2].keys())[0]\n    ship_action = choice([\"NORTH\", \"SOUTH\", \"EAST\", \"WEST\", None])\n    if ship_action is not None:\n        action[ship_id] = ship_action\n    return action","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test your Agent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play against yourself without an ERROR or INVALID.\n# Note: The first episode in the competition will run this to weed out erroneous agents.\nenv.run([\"/kaggle/working/submission.py\", \"/kaggle/working/submission.py\"])\nprint(\"EXCELLENT SUBMISSION!\" if env.toJSON()[\"statuses\"] == [\"DONE\", \"DONE\"] else \"MAYBE BAD SUBMISSION?\")\n\n# Play as the first agent against default \"shortest\" agent.\nenv.run([\"/kaggle/working/submission.py\", \"random\"])\nenv.render(mode=\"ipython\", width=800, height=600)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Debug/Train your Agent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nfrom random import choice\ndef my_agent(obs):\n    action = {}\n    ship_id = list(obs.players[obs.player][2].keys())[0]\n    ship_action = choice([\"NORTH\", \"SOUTH\", \"EAST\", \"WEST\", None])\n    if ship_action is not None:\n        action[ship_id] = ship_action\n    return action\n\nwhile not env.done:\n    my_action = my_agent(observation)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate your Agent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_reward(rewards):\n    wins = 0\n    ties = 0\n    loses = 0\n    for r in rewards:\n        r0 = 0 if r[0] is None else r[0]\n        r1 = 0 if r[1] is None else r[1]\n        if r0 > r1:\n            wins += 1\n        elif r1 > r0:\n            loses += 1\n        else:\n            ties += 1\n    return f'wins={wins/len(rewards)}, ties={ties/len(rewards)}, loses={loses/len(rewards)}'\n\n# Run multiple episodes to estimate its performance.\n# Setup agentExec as LOCAL to run in memory (runs faster) without process isolation.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\n    \"halite\",\n    [\"/kaggle/working/submission.py\", \"random\"],\n    num_episodes=10, configuration={\"agentExec\": \"LOCAL\"}\n)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/halite/submissions) to view your score and episodes being played.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}