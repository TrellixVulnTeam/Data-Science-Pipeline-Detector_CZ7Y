{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"labels = pd.read_csv('../input/imet-2020-fgvc7/labels.csv')\ntrainset = pd.read_csv('../input/imet-2020-fgvc7/train.csv',dtype='str')\ntestset = pd.read_csv('../input/imet-2020-fgvc7/sample_submission.csv',dtype='str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.sample(10).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset.sample(10).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset.sample(10).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, BatchNormalization\nfrom PIL import Image\n%matplotlib inline\nsns.set(style=\"whitegrid\")\nwarnings.filterwarnings(\"ignore\")\nfrom numpy.random import seed\nfrom tensorflow import random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.set_seed(0)\nseed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of training samples:',len(trainset))\nprint('Number of test samples:',len(testset))\nprint('Number of labels;',len(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attribute_ids = trainset['attribute_ids'].values\n# Get attributes for each images\nattributes = []\nfor item_attributes in [x.split(' ') for x in attribute_ids]:\n    for attribute in item_attributes:\n        attributes.append(int(attribute))\nattr_pd = pd.DataFrame(attributes, columns=['attribute_id'])\nattr_pd = attr_pd.merge(labels)\nattr_pd\ntop30 = attr_pd['attribute_name'].value_counts().to_frame()\ntop30=top30[:30]\nunique_attr = attr_pd['attribute_id'].nunique()\nprint('Number of unique attributes:',unique_attr)\nplt.subplots(figsize=(11,8))\nax = sns.barplot(y=top30.index,x='attribute_name',data=top30,order=reversed(top30.index),palette='rocket')\nplt.ylabel('Surface type')\nplt.xlabel('Count')\nsns.despine()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attr_pd['tag'] = attr_pd['attribute_name'].apply(lambda x:x.split('::')[0])\ngroup_attr = attr_pd.groupby('tag').count()\nprint('Number of attribute groups:',attr_pd['tag'].nunique())\nplt.subplots(figsize=(12,8))\nax=sns.barplot(y=group_attr.index,x='attribute_name',data=group_attr,palette='rocket')\nplt.ylabel('Attribute Group')\nplt.xlabel('Count')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset['Number of tags']=trainset['attribute_ids'].apply(lambda x:len(x.split(' ')))\ntrainset\nsns.countplot(x='Number of tags',data=trainset,palette='rocket')\nplt.ylabel('Surface type')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = 1\nplt.figure(figsize=[16,16])\nfor img_name in os.listdir(\"../input/test/\")[:16]:\n    img = cv2.imread(\"../input/test/{}\".format(img_name))[...,[2,1,0]]\n    plt.subplot(4,4,c)\n    plt.imshow(img)\n    plt.title(\"test image {}\".format(c))\n    c += 1\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('white')\nplt.figure(figsize=[22,20])\ncount=1\nfor img_name in os.listdir('../input/imet-2020-fgvc7/train/')[:36]:\n    img = cv2.imread('../input/imet-2020-fgvc7/train/%s'%img_name)\n    plt.subplot(6,6,count)\n    plt.imshow(img)\n    plt.title('Item %s'%count)\n    count+=1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling Phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_ext(fn):\n    return fn+\".png\"\ntrainset[\"id\"]=trainset[\"id\"].apply(append_ext)\ntestset[\"id\"]=testset[\"id\"].apply(append_ext)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 128\nEPOCHS = 30\nLEARNING_RATE = 0.0001\nHEIGHT = 64\nWIDTH = 64\nCANAL = 3\nN_CLASSES = unique_attr\nclasses = list(map(str,range(N_CLASSES)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5),padding='Same', input_shape=(HEIGHT, WIDTH, CANAL)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5),padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=64, kernel_size=(4,4),padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(4,4),padding='Same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1024))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(N_CLASSES, activation=\"sigmoid\"))\nmodel.summary()\n\noptimizer = optimizers.adam(lr=LEARNING_RATE)\nmodel.compile(optimizer=optimizer , loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen=ImageDataGenerator(rescale=1./255., validation_split=0.25)\ntest_datagen = ImageDataGenerator(rescale=1./255.)\n\ntrain_generator=datagen.flow_from_dataframe(\n    dataframe=trainset,\n    directory='/kaggle/input/imet-2020-fgvc7/train/',\n    x_col='id',\n    y_col='attribute_ids',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    class_mode=\"categorical\",    \n    classes=classes,\n    target_size=(HEIGHT, WIDTH),\n    subset='training')\n\nvalid_generator=datagen.flow_from_dataframe(\n    dataframe=trainset,\n    directory='/kaggle/input/imet-2020-fgvc7/train/',\n    x_col='id',\n    y_col='attribute_ids',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    class_mode=\"categorical\",    \n    classes=classes,\n    target_size=(HEIGHT, WIDTH),\n    subset='validation')\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=testset,\n    x_col=\"id\",\n    directory='/kaggle/input/imet-2020-fgvc7/test/',\n    target_size = (HEIGHT, WIDTH),\n    batch_size = 1,\n    shuffle = False,\n    class_mode = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\nSTEP_SIZE_VAL = valid_generator.n // valid_generator.batch_size\n\nhistory = model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VAL,\n                    epochs=EPOCHS,\n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\nn_steps = len(test_generator.filenames)\npreds = model.predict_generator(test_generator, steps = n_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nfor pred_ar in preds:\n    valid = ''\n    for idx, pred in enumerate(pred_ar):\n        if pred > 0.3:  # Using 0.3 as threshold\n            if len(valid) == 0:\n                valid += str(idx)\n            else:\n                valid += (' %s' % idx)\n    if len(valid) == 0:\n        valid = str(np.argmax(pred_ar))\n    predictions.append(valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nfig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', figsize=(20,7))\n\nax1.plot(history.history['accuracy'], label='Train Accuracy')\nax1.plot(history.history['val_accuracy'], label='Validation accuracy')\nax1.legend(loc='best')\nax1.set_title('Accuracy')\n\nax2.plot(history.history['loss'], label='Train loss')\nax2.plot(history.history['val_loss'], label='Validation loss')\nax2.legend(loc='best')\nax2.set_title('Loss')\n\nplt.xlabel('Epochs')\nsns.despine()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames=test_generator.filenames\nresults=pd.DataFrame({'id':filenames, 'attribute_ids':predictions})\nresults['id'] = results['id'].map(lambda x: str(x)[:-4])\nresults.to_csv('submission.csv',index=False)\nresults.sample(10).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}