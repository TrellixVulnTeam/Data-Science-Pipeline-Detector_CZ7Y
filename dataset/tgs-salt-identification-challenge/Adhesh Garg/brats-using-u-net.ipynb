{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/brats17aug/train/Train\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\nfrom keras.layers.merge import concatenate, add\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set some parameters\nim_width = 400\nim_height = 400\nborder = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = next(os.walk(\"../input/brats17aug/train/Train/images\"))[2] # list of names all images in the given path\nprint(\"No. of images = \", len(ids))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\ny = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n    # Load images\n    img = load_img(\"../input/brats17aug/train/Train/images/\"+id_, grayscale=True)\n    x_img = img_to_array(img)\n    x_img = resize(x_img, (400, 400, 1), mode = 'constant', preserve_range = True)\n    # Load masks\n    mask = img_to_array(load_img(\"../input/brats17aug/train/Train/masks/\"+id_, grayscale=True))\n    mask = resize(mask, (400, 400, 1), mode = 'constant', preserve_range = True)\n    # Save images\n    X[n] = x_img/255.0\n    y[n] = mask/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ix = random.randint(0, len(X_train))\nhas_mask = y_train[ix].max() > 0 # salt indicator\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 15))\n\nax1.imshow(X_train[ix, ..., 0], cmap = 'seismic', interpolation = 'bilinear')\nif has_mask: # if salt\n    # draw a boundary(contour) in the original image separating salt and non-salt areas\n    ax1.contour(y_train[ix].squeeze(), colors = 'k', linewidths = 5, levels = [0.5])\nax1.set_title('Seismic')\n\nax2.imshow(y_train[ix].squeeze(), cmap = 'gray', interpolation = 'bilinear')\nax2.set_title('Salt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv2d_block(input_tensor, n_filters, kernel_size , batchnorm = True):\n    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n    # first layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # second layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\ndef dice(y_true, y_pred, smooth=1):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    And=K.sum(y_truef* y_predf)\n    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\ndef jaccard(y_true, y_pred, smooth=100):\n  \n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac) * smooth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n    \"\"\"Function to define the UNET Model\"\"\"\n    # Contracting Path\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 5, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 5, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 5, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 5, batchnorm = batchnorm)\n\n    # Expansive Path\n    u6 = Conv2DTranspose(n_filters * 8, (5, 5), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 5, batchnorm = batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 4, (5, 5), strides = (2, 2), padding = 'same')(c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 5, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (5, 5), strides = (2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 5, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (5, 5), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 5, batchnorm = batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input((im_height, im_width, 1), name='img')\nmodel = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\nmodel.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\",dice,jaccard])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=callbacks,\\\n                    validation_data=(X_valid, y_valid))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\")\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(results.history[\"dice\"], label=\"dice\")\nplt.plot(results.history[\"val_dice\"], label=\"val_dice\")\nplt.plot(results.history[\"jaccard\"], label=\"jaccard\")\nplt.plot(results.history[\"val_jaccard\"], label=\"val_jaccard\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model-tgs-salt.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_valid, y_valid, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.metrics_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_train = model.predict(X_train, verbose=1)\npreds_val = model.predict(X_valid, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_sample(X, y, preds, binary_preds, ix=None):\n    \"\"\"Function to plot the results\"\"\"\n    for ix in range(0,20):\n        fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n        ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n        ax[0].set_title('MRI')\n\n        ax[1].imshow(y[ix].squeeze())\n        ax[1].set_title('Mask/OT')\n\n        ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n        ax[2].set_title('OT Predicted')\n\n        ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n        ax[3].set_title('OT Predicted binary');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sample(X_valid, y_valid, preds_val, preds_val_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}