{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom numpy.random import seed\nseed(1)\nfrom zipfile import ZipFile\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import Tensor, unsqueeze, optim, device\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import cat\n\nif torch.cuda.is_available():\n    print(\"using GPU\")\n    torch.set_default_tensor_type('torch.cuda.FloatTensor')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zip_path = \"../input/tgs-salt-identification-challenge/train.zip\"\nwith ZipFile(zip_path,'r') as z:\n    z.extractall(\"./train\")\n\nzip_path = \"../input/tgs-salt-identification-challenge/test.zip\"\nwith ZipFile(zip_path,'r') as z:\n    z.extractall('./test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/tgs-salt-identification-challenge/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/tgs-salt-identification-challenge/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\nlen(train_df)\ntrain_df[\"masks\"] = [np.array(imread(\"./train/masks/{}.png\".format(idx), as_gray=True)) / 255/257\\\n                     for idx in (train_df.index)]\nimg_size_ori = train_df[\"masks\"][0].size\ntrain_df[\"coverage\"] = train_df.masks.map(np.sum) / img_size_ori\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids_train, ids_valid =\\\n    train_test_split(\n    train_df.index.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_imgs = [np.array(imread(\"./train/images/{}.png\".format(idx), as_gray=True)) / 255\\\n                     for idx in ids_train]\ny_imgs = [np.array(imread(\"./train/masks/{}.png\".format(idx), as_gray=True)) / 255/257\\\n                     for idx in ids_train]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx_train = np.concatenate((\\\nx_imgs, [np.fliplr(x) for x in x_imgs], [np.flipud(x) for x in x_imgs], [np.rot90(x) for x in x_imgs])\n, axis = 0)\n\ny_train = np.concatenate((\\\ny_imgs, [np.fliplr(x) for x in y_imgs], [np.flipud(x) for x in y_imgs], [np.rot90(x) for x in y_imgs])\\\n, axis = 0)\n\nx_train = Tensor(x_train)\ny_train = Tensor(y_train)\n\nx_train = unsqueeze(x_train, 1)\ny_train = unsqueeze(y_train, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = [np.array(imread(\"./train/images/{}.png\".format(idx), as_gray=True)) / 255\\\n                     for idx in ids_valid]\ny_val = [np.array(imread(\"./train/masks/{}.png\".format(idx), as_gray=True)) / 255/257\\\n                     for idx in ids_valid]\nx_val = Tensor(x_val)\ny_val = Tensor(y_val)\n\nx_val = unsqueeze(x_val, 1)\ny_val = unsqueeze(y_val, 1)\n\nprint(x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        # if you have padding issues, see\n        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n        x = cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)\n    \nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024 // factor)\n        self.up1 = Up(1024, 512 // factor, bilinear)\n        self.up2 = Up(512, 256 // factor, bilinear)\n        self.up3 = Up(256, 128 // factor, bilinear)\n        self.up4 = Up(128, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef batch_loader(x_train, y_train, batch_size):\n    \n    if not x_train.shape[0]%batch_size : \n        its = x_train.shape[0]//batch_size\n        for batch in range(its):\n            imgs = x_train[batch*batch_size: (batch+1)*batch_size]\n            masks = y_train[batch*batch_size: (batch+1)*batch_size]\n            yield imgs, masks, batch_size\n    else: \n        its = x_train.shape[0]//batch_size\n        for batch in range(its):\n            imgs = x_train[batch*batch_size: (batch+1)*batch_size]\n            masks = y_train[batch*batch_size: (batch+1)*batch_size]\n            yield imgs, masks, batch_size\n        \n        imgs = x_train[its*batch_size: ]\n        masks = y_train[its*batch_size:]\n        yield imgs, masks, x_train.shape[0] - its*batch_size\n    \nSMOOTH = 1e-8\ndef iou_pytorch(outputs, labels):\n    outputs = outputs>=0.5\n    labels = labels==1\n    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n    \n    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n    \n    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10) / 10  # This is equal to comparing with thresolds\n    \n    return thresholded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef train(net, x_train, y_train, x_val, y_val,epochs,  batch_size, criterion,optimizer, scheduler = None, metrics = None):\n    net.train()\n    flag = True\n    for epoch in (range(epochs)):\n\n        total_loss = 0\n        trained_imgs = 0\n        for imgs, masks, cur_size in batch_loader(x_train, y_train, batch_size):\n            masks_pred = net(imgs)\n            loss = criterion(masks_pred, masks)*cur_size\n            total_loss += float(loss)\n            trained_imgs += cur_size\n#             print(\"loss:\",str.format('{0:.3f}', float(total_loss/ trained_imgs)), end = '\\r')\n            optimizer.zero_grad()\n            if flag:\n                loss.backward(retain_graph=True)\n                flag = not flag\n            else:\n                loss.backward(retain_graph=False)\n            optimizer.step()\n#         print(\"End of Epoch\", epoch+1, \"with avg loss:\", str.format('{0:.3f}', float(total_loss/x_train.shape[0])))\n        \n        total_val_loss = 0\n        total_iou = 0\n        for imgs, masks, cur_size in batch_loader(x_val, y_val, batch_size):\n            masks_pred = net(imgs)\n            val_loss = criterion(masks_pred, masks)*cur_size\n            \n            total_val_loss += float(val_loss)\n            iou = float(torch.sum(metrics(masks_pred.squeeze(1), masks.squeeze(1))))\n\n            total_iou += iou\n#             print(\"loss:\",str.format('{0:.3f}', float(val_loss/cur_size)), end = '\\r')\n        print(\"Epoch {}\".format(epoch + 1))\n        print(\"val_loss: \", str.format('{0:.3f}', float(total_val_loss/ x_val.shape[0])))\n        print(\"val_iou: \", str.format('{0:.3f}', float(total_iou/ x_val.shape[0])))\n        \n        if scheduler != None and metrics != None:\n            scheduler.step(total_iou)\n            \nnet = UNet(1,1,  bilinear=False)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.RMSprop(net.parameters(), lr=0.001, weight_decay=1e-8, momentum=0.9)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',factor = 0.1, patience=3, min_lr=1e-7)\nepochs = 1\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6da2d2d-2c56-419a-b2fe-d6d8007daa8d","_cell_guid":"9e827ae1-e0d4-43c9-a142-ca21f15cb1b0","trusted":true},"cell_type":"code","source":"train(net, x_train, y_train, x_val, y_val, 200, 64, criterion, optimizer, scheduler, iou_pytorch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(net.state_dict(), \"./unet.pth\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}