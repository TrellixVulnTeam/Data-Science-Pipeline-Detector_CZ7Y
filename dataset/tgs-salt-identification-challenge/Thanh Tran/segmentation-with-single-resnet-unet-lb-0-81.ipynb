{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom IPython.display import clear_output\nfrom IPython.display import Image\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, Dropout, Concatenate, Add\nfrom keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras import backend as K\nfrom tensorflow.python.ops.numpy_ops import np_config\n\nnp_config.enable_numpy_behavior()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set up data dirs","metadata":{}},{"cell_type":"code","source":"TEST_DIR = './data/test'\nTRAIN_DIR = './data/train'\n\ndef setup_data(type):\n    \"\"\"\n    Set up working dirs\n    \n    \"\"\"\n    if type == 'train':\n        os.makedirs(TRAIN_DIR, exist_ok=True)\n        os.system(f'cp ../input/tgs-salt-identification-challenge/train.csv {TRAIN_DIR}')\n        os.system(f'unzip -qq ../input/tgs-salt-identification-challenge/train.zip -d {TRAIN_DIR}')\n        print(f'Set up {TRAIN_DIR}')\n    elif type == 'test':\n        os.makedirs(TEST_DIR, exist_ok=True)\n        os.system(f'unzip -qq ../input/tgs-salt-identification-challenge/test.zip -d {TEST_DIR}')\n        print(f'Set up {TEST_DIR}')\n    else:\n        print(f'Type {type} not supported (train|test)')\n        \nsetup_data('train')\nsetup_data('test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get list of training images\ntrain_imgs_path = './data/train/images'\ntrain_masks_path = './data/train/masks'\ntrain_imgs = os.listdir(train_imgs_path)\nprint('Number of train images:', len(train_imgs))\n\ntrain_masks = os.listdir(train_masks_path)\n\n# Get list of test images\ntest_imgs_path = './data/test/images'\nprint('Number of test images:', len(os.listdir(test_imgs_path)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split training and validation set\nWe split data by coverage ratio of salt ","metadata":{}},{"cell_type":"code","source":"def get_coverage_level(mask):\n    return np.sum(mask) / (img_height * img_width)\n\ndef map_to_class(cover):\n    if cover == 0.0:\n        return 0\n    elif 0.0 < cover <= 0.05: # equivalent to ~500 masked pixels\n        return 1\n    elif  0.05 < cover <= 0.3:\n        return 2\n    elif 0.3 < cover <= 0.5:\n        return 3\n    elif 0.5 < cover <= 0.8:\n        return 4\n    elif 0.8 < cover <= 1.0:\n        return 5\n    else:\n        raise ValueError(f'Mask has inappropriate pixel value: {cover}')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:13:45.892876Z","iopub.execute_input":"2022-01-08T13:13:45.893517Z","iopub.status.idle":"2022-01-08T13:13:45.900003Z","shell.execute_reply.started":"2022-01-08T13:13:45.89349Z","shell.execute_reply":"2022-01-08T13:13:45.899066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image dimension\nimg_height = 128\nimg_width = 128\n\n# Set up X and y\nX = np.zeros((len(train_imgs), img_height, img_width, 1), dtype=np.float32)\ny = np.zeros((len(train_masks), img_height, img_width, 1), dtype=np.float32)\n\n# Load imgs\nfor idx, img_path in enumerate(train_imgs):\n    img = load_img(train_imgs_path + '/' + img_path, color_mode='grayscale', target_size=(img_height, img_width, 1))\n    X[idx] = img_to_array(img) / 255.0\n    \ncoverage = np.array([])            # coverage ratio\ncoverage_class = np.array([])      # equivalent coverage class\n# Load masks\nfor idx, mask_path in enumerate(train_masks):\n    mask = load_img(train_masks_path + '/' + mask_path, color_mode='grayscale', target_size=(img_height, img_width, 1))\n    y[idx] = img_to_array(mask) / 65535.0\n    # Save coverage\n    cover = get_coverage_level(y[idx])\n    coverage = np.append(coverage, cover)\n    coverage_class = np.append(coverage_class, map_to_class(cover))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:14:00.710675Z","iopub.execute_input":"2022-01-08T13:14:00.711213Z","iopub.status.idle":"2022-01-08T13:14:05.054177Z","shell.execute_reply.started":"2022-01-08T13:14:00.711174Z","shell.execute_reply":"2022-01-08T13:14:05.053448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot salt coverage ratio and coverage class\nfig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(coverage, kde=False, ax=axs[0])\nsns.distplot(coverage_class, kde=False, ax=axs[1])\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage ratio\")\naxs[1].set_xlabel(\"Coverage class\")","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:14:05.055604Z","iopub.execute_input":"2022-01-08T13:14:05.05586Z","iopub.status.idle":"2022-01-08T13:14:05.455138Z","shell.execute_reply.started":"2022-01-08T13:14:05.055826Z","shell.execute_reply":"2022-01-08T13:14:05.454457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split train and validation set\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=coverage_class, random_state=0)\nprint('Number of training imgs:', len(X_train))\nprint('Number of validation imgs:', len(X_val))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:14:13.601999Z","iopub.execute_input":"2022-01-08T13:14:13.602718Z","iopub.status.idle":"2022-01-08T13:14:13.773505Z","shell.execute_reply.started":"2022-01-08T13:14:13.602678Z","shell.execute_reply":"2022-01-08T13:14:13.772703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See some examples\nfig = plt.figure(figsize=(20, 20))\nfor i in range(1, 17, 2):\n    idx = random.randint(0, len(X_train))\n    has_mask = y_train[idx].max() > 0\n    ax1 = plt.subplot(4, 4, i)\n    ax1.imshow(X_train[idx])\n    if has_mask:\n        ax1.contour(y_train[idx].squeeze(), linewidths=3, levels=[0.5])\n    ax1.set_title(f'X_train[{idx}]')\n    ax2 = plt.subplot(4, 4, i + 1)\n    ax2.imshow(y_train[idx])\n    ax2.set_title(f'y_train[{idx}]')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:14:14.258064Z","iopub.execute_input":"2022-01-08T13:14:14.258597Z","iopub.status.idle":"2022-01-08T13:14:16.623761Z","shell.execute_reply.started":"2022-01-08T13:14:14.258561Z","shell.execute_reply":"2022-01-08T13:14:16.623145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"# def augment(X, y):\n#     idx = 0\n#     limit = len(X)\n#     while idx < limit: \n#         prob = tf.random.uniform([], dtype=tf.float32).numpy()\n#         len_aug = tf.random.uniform([], minval=1, maxval=400, dtype=tf.int32).numpy()\n#         if len_aug > limit - idx:\n#             len_aug = limit - idx\n#         if 0 <= prob < 0.25:\n#             X = np.append(X, [np.fliplr(x) for x in X[idx:len_aug+idx]], axis=0)\n#             y = np.append(y, [np.fliplr(x) for x in y[idx:len_aug+idx]], axis=0)\n#         elif 0.25 <= prob < 0.5:\n#             X = np.append(X, [np.flipud(x) for x in X[idx:len_aug+idx]], axis=0)\n#             y = np.append(y, [np.flipud(x) for x in y[idx:len_aug+idx]], axis=0) \n#         elif 0.5 <= prob < 0.75:\n#             X = np.append(X, [np.expand_dims(np.transpose(np.squeeze(x)), axis=-1) for x in X[idx:len_aug+idx]], axis=0)\n#             y = np.append(y, [np.expand_dims(np.transpose(np.squeeze(x)), axis=-1) for x in y[idx:len_aug+idx]], axis=0) \n#         elif 0.75 <= prob <= 1:\n#             X = np.append(X, [np.rot90(x) for x in X[idx:len_aug+idx]], axis=0)\n#             y = np.append(y, [np.rot90(x) for x in y[idx:len_aug+idx]], axis=0)\n#         else:\n#             raise ValueError('prob is not valid')\n#         idx += len_aug\n        \n#     return X, y\n    \n# X_train, y_train = augment(X_train, y_train)\n\nX_train = np.append(X_train, [np.fliplr(x) for x in X_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:15:28.0956Z","iopub.execute_input":"2022-01-08T13:15:28.095868Z","iopub.status.idle":"2022-01-08T13:15:28.575928Z","shell.execute_reply.started":"2022-01-08T13:15:28.095838Z","shell.execute_reply":"2022-01-08T13:15:28.575145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training images after augmentation:', X_train.shape)\nprint('Training masks after augmentation:', X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:15:28.577579Z","iopub.execute_input":"2022-01-08T13:15:28.577806Z","iopub.status.idle":"2022-01-08T13:15:28.58325Z","shell.execute_reply.started":"2022-01-08T13:15:28.577775Z","shell.execute_reply":"2022-01-08T13:15:28.582531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss\nWe define Lovasz loss function","metadata":{}},{"cell_type":"code","source":"# Credit: https://github.com/bermanmaxim/LovaszSoftmax/blob/master/tensorflow/lovasz_losses_tf.py  \n# Edited for competible with Tensorflow 2\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    gts = tf.reduce_sum(gt_sorted)\n    intersection = gts - tf.cumsum(gt_sorted)\n    union = gts + tf.cumsum(1. - gt_sorted)\n    jaccard = 1. - intersection / union\n    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        def treat_image(log_lab):\n            log, lab = log_lab\n            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n            log, lab = flatten_binary_scores(log, lab, ignore)\n            return lovasz_hinge_flat(log, lab)\n        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n\n    def compute_loss():\n        labelsf = tf.cast(labels, logits.dtype)\n        signs = 2. * labelsf - 1.\n        errors = 1. - logits * tf.stop_gradient(signs)\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n        gt_sorted = tf.gather(labelsf, perm)\n        grad = lovasz_grad(gt_sorted)\n        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n        return loss\n\n    # deal with the void prediction case (only void pixels)\n    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n                   lambda: tf.reduce_sum(logits) * 0.,\n                   compute_loss,\n                   name=\"loss\")\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = tf.reshape(scores, (-1,))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return scores, labels\n    valid = tf.not_equal(labels, ignore)\n    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vscores, vlabels\n\ndef lovasz_loss(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    #logits = K.log(y_pred / (1. - y_pred))\n    logits = y_pred #Jiaxin\n    loss = lovasz_hinge(logits, y_true, per_image=True, ignore=None)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:15:49.424743Z","iopub.execute_input":"2022-01-08T13:15:49.425Z","iopub.status.idle":"2022-01-08T13:15:49.441269Z","shell.execute_reply.started":"2022-01-08T13:15:49.424972Z","shell.execute_reply":"2022-01-08T13:15:49.440568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics\nWe define [mean IoU](https://www.kaggle.com/c/tgs-salt-identification-challenge/overview/evaluation) (competition's evaluation method) metrics here. ","metadata":{}},{"cell_type":"code","source":"# Credit: https://www.kaggle.com/donchuk/fast-implementation-of-scoring-metric/script\n# Edited for competible with Tensorflow 2\ndef get_iou_vector(A, B):\n    batch_size = A.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch]>0, B[batch]>0\n        \n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n        thresholds = np.arange(0.5, 1, 0.05)\n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        metric.append(np.mean(s))\n\n    return np.mean(metric)\n\n\ndef mean_iou(label, pred):\n    return tf.numpy_function(get_iou_vector, [label, pred>0.5], tf.float64)\n\n\ndef mean_iou_2(label, pred):\n    return tf.numpy_function(get_iou_vector, [label, pred>0], tf.float64)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:16:02.256465Z","iopub.execute_input":"2022-01-08T13:16:02.257111Z","iopub.status.idle":"2022-01-08T13:16:02.26605Z","shell.execute_reply.started":"2022-01-08T13:16:02.257054Z","shell.execute_reply":"2022-01-08T13:16:02.26525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-net Resnet based model","metadata":{}},{"cell_type":"code","source":"def batch_activation(input_tensor):\n    x = BatchNormalization()(input_tensor)\n    x = Activation('relu')(x)\n    return x\n\n\ndef residual_blocks(input_tensor, filters, has_batch_activation=False):\n    x = batch_activation(input_tensor)\n    x = Conv2D(filters, 3, kernel_initializer='he_normal', padding='same', activation='relu')(x)\n    x = Conv2D(filters, 3, kernel_initializer='he_normal', padding='same')(x)\n    x = Add()([x, input_tensor])\n    if has_batch_activation:\n        x = batch_activation(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:16:05.601711Z","iopub.execute_input":"2022-01-08T13:16:05.601979Z","iopub.status.idle":"2022-01-08T13:16:05.60803Z","shell.execute_reply.started":"2022-01-08T13:16:05.601949Z","shell.execute_reply":"2022-01-08T13:16:05.607293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_Resnet_Unet(inputs, kernel_size=(3, 3), num_filters=16, dropout_rate=0.5):\n    def encoder_blocks(input_tensor, filters, kernel_shape=kernel_size):\n        \"\"\"\n        Encoder blocks for Res-Unet\n        \"\"\"\n        x = Conv2D(filters, kernel_shape, padding='same')(input_tensor)\n        x = residual_blocks(x, filters)\n        x = residual_blocks(x, filters, True)\n\n        return x\n    \n    def decoder_blocks(input_tensor, filters, do_rate, kernel_shape=kernel_size):\n        \"\"\"\n        Decoder blocks for Res-Unet\n        \"\"\"\n        x = Dropout(do_rate)(input_tensor)\n        x = Conv2D(filters, kernel_shape, padding='same')(x)\n        x = residual_blocks(x, filters)\n        x = residual_blocks(x, filters, True)\n        \n        return x\n\n    \n    # Encoder\n    e1 = encoder_blocks(inputs, filters=num_filters)\n    x = MaxPooling2D(pool_size=(2, 2))(e1)\n    x = Dropout(dropout_rate / 2)(x)\n    \n    e2 = encoder_blocks(x, filters=num_filters * 2)\n    x = MaxPooling2D(pool_size=(2, 2))(e2)\n    x = Dropout(dropout_rate)(x)\n    \n    e3 = encoder_blocks(x, filters=num_filters * 4)\n    x = MaxPooling2D(pool_size=(2, 2))(e3)\n    x = Dropout(dropout_rate)(x)\n    \n    e4 = encoder_blocks(x, filters=num_filters * 8)\n    x = MaxPooling2D(pool_size=(2, 2))(e4)\n    x = Dropout(dropout_rate)(x)\n    \n    # Middle\n    m = Conv2D(num_filters * 16, kernel_size, padding='same')(x)\n    m = residual_blocks(m, num_filters * 16)\n    m = residual_blocks(m, num_filters * 16, True)\n    \n    # Decoder\n    d4 = Conv2DTranspose(num_filters * 8, kernel_size, strides=(2, 2), padding='same')(m)\n    x = Concatenate()([d4, e4])\n    x = decoder_blocks(x, num_filters * 8, dropout_rate)\n    \n    d3 = Conv2DTranspose(num_filters * 4, kernel_size, strides=(2, 2), padding='same')(x)\n    x = Concatenate()([d3, e3])\n    x = decoder_blocks(x, num_filters * 4, dropout_rate)\n    \n    d2 = Conv2DTranspose(num_filters * 4, kernel_size, strides=(2, 2), padding='same')(x)\n    x = Concatenate()([d2, e2])\n    x = decoder_blocks(x, num_filters * 2, dropout_rate)\n    \n    d1 = Conv2DTranspose(num_filters, kernel_size, strides=(2, 2), padding='same')(x)\n    x = Concatenate()([d1, e1])\n    x = decoder_blocks(x, num_filters, dropout_rate)\n    \n    x = Conv2D(1, 1, padding='same', activation=None)(x)\n    output = Activation('sigmoid')(x)\n    \n    return output, x","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:16:05.870748Z","iopub.execute_input":"2022-01-08T13:16:05.871286Z","iopub.status.idle":"2022-01-08T13:16:05.888212Z","shell.execute_reply.started":"2022-01-08T13:16:05.871251Z","shell.execute_reply":"2022-01-08T13:16:05.887386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(inputs,\n                 outputs,\n                 optimizers_used, \n                 loss_used='bce',\n                 lr=0.01,\n                 save_model_name='best_model.h5', \n                 min_lr=0.0001, \n                 factor=0.5):\n        \n    model = Model(inputs=[inputs], outputs=[outputs])\n    \n    # Set up optimizers\n    if optimizers_used == 'Adam':\n        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n    elif optimizers_used == 'SGD':\n        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n    else:\n        raise ValueError('Optimizer not implemented!')\n    \n    # Set up callbacks\n    if loss_used == 'lovasz':\n        checkpoint = ModelCheckpoint(save_model_name, monitor='val_mean_iou_2', verbose=1,\n                             save_best_only=True, mode='max')\n        rdlr = ReduceLROnPlateau(monitor='val_mean_iou_2', factor=factor, patience=6,\n                                 min_lr=min_lr, verbose=1, mode='max')\n    elif loss_used == 'bce':\n        checkpoint = ModelCheckpoint(save_model_name, monitor='val_mean_iou', verbose=1,\n                             save_best_only=True, mode='max')\n        rdlr = ReduceLROnPlateau(monitor='val_mean_iou', factor=factor, patience=6,\n                                 min_lr=min_lr, verbose=1, mode='max')\n    else:\n        raise ValueError('Loss not implemented!')\n    \n    callbacks = [checkpoint, rdlr]\n    return model, callbacks, optimizer","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:16:25.557357Z","iopub.execute_input":"2022-01-08T13:16:25.557652Z","iopub.status.idle":"2022-01-08T13:16:25.569253Z","shell.execute_reply.started":"2022-01-08T13:16:25.557622Z","shell.execute_reply":"2022-01-08T13:16:25.568355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = Input(shape=(img_height, img_width, 1))\noutputs, pre_output = build_Resnet_Unet(inputs=inputs)\n\nmodel, callbacks, optimizer = create_model(inputs, \n                                           outputs, \n                                           optimizers_used='Adam', \n                                           loss_used='bce', \n                                           save_model_name='best_model_1.h5')\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[mean_iou])\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T13:16:50.224379Z","iopub.execute_input":"2022-01-08T13:16:50.224647Z","iopub.status.idle":"2022-01-08T13:16:53.272717Z","shell.execute_reply.started":"2022-01-08T13:16:50.224618Z","shell.execute_reply":"2022-01-08T13:16:53.272005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(X_train, y_train, batch_size=32, epochs=60, verbose=1,\n                 callbacks=callbacks, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T07:43:53.371873Z","iopub.execute_input":"2022-01-08T07:43:53.372327Z","iopub.status.idle":"2022-01-08T08:07:20.320491Z","shell.execute_reply.started":"2022-01-08T07:43:53.372293Z","shell.execute_reply":"2022-01-08T08:07:20.319717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 4))\n\nplt.subplot(121)\nplt.title('Loss')\nplt.plot(hist.history['loss'], label='training loss')\nplt.plot(hist.history['val_loss'], label='validation loss')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.subplot(122)\nplt.title('Mean IoU')\nplt.plot(hist.history['mean_iou'], label='training IoU')\nplt.plot(hist.history['val_mean_iou'], label='validation IoU')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:07:20.322652Z","iopub.execute_input":"2022-01-08T08:07:20.322881Z","iopub.status.idle":"2022-01-08T08:07:20.683896Z","shell.execute_reply.started":"2022-01-08T08:07:20.322853Z","shell.execute_reply":"2022-01-08T08:07:20.683169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = load_model('./best_model_1.h5', custom_objects={'mean_iou': mean_iou})\n\ninputs2 = model1.layers[0].input\noutputs2 = model1.layers[-1].input\nmodel, callbacks, optimizer = create_model(inputs=inputs2, \n                                           outputs=outputs2, \n                                           optimizers_used='Adam', \n                                           loss_used='lovasz',\n                                           save_model_name='best_model_2.h5')\nmodel.compile(optimizer=optimizer, loss=lovasz_loss, metrics=[mean_iou_2])","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:03:50.853223Z","iopub.execute_input":"2022-01-08T11:03:50.853801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, batch_size=32, epochs=40, verbose=1,\n                     callbacks=callbacks, validation_data=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 4))\n\nplt.subplot(121)\nplt.title('Loss')\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='validation loss')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.subplot(122)\nplt.title('Mean IoU')\nplt.plot(history.history['mean_iou_2'], label='training IoU')\nplt.plot(history.history['val_mean_iou_2'], label='validation IoU')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T07:42:52.566588Z","iopub.status.idle":"2022-01-08T07:42:52.567209Z","shell.execute_reply.started":"2022-01-08T07:42:52.566977Z","shell.execute_reply":"2022-01-08T07:42:52.567001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"# Load model for final test\nbest_model = load_model('./best_model_2.h5', custom_objects={'mean_iou_2': mean_iou_2, 'lovasz_loss': lovasz_loss})","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:52:35.851242Z","iopub.execute_input":"2022-01-08T12:52:35.851702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test images\ntest_imgs_path = './data/test/images'\ntest_imgs = os.listdir(test_imgs_path)\n\nX_test = np.zeros((len(test_imgs), img_height, img_width, 1), dtype=np.float32)\ntest_ids = []\n\n# Load imgs\nfor idx, img_path in tqdm(enumerate(test_imgs)):\n    img = load_img(test_imgs_path + '/' + img_path, color_mode='grayscale', target_size=(img_height, img_width, 1))\n    X_test[idx] = img_to_array(img) / 255.0\n    test_ids.append(img_path.split('.')[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-08T10:59:35.395253Z","iopub.execute_input":"2022-01-08T10:59:35.395631Z","iopub.status.idle":"2022-01-08T10:59:51.486Z","shell.execute_reply.started":"2022-01-08T10:59:35.395589Z","shell.execute_reply":"2022-01-08T10:59:51.484844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict \npreds_test = best_model.predict(X_test, verbose=1)\npreds_val = best_model.predict(X_val, verbose=1)\n\npreds_test_bin = (preds_test > 0.5).astype(np.uint8)\npreds_val_bin = (preds_val > 0.5).astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T10:59:51.488002Z","iopub.execute_input":"2022-01-08T10:59:51.488364Z","iopub.status.idle":"2022-01-08T11:00:20.180309Z","shell.execute_reply.started":"2022-01-08T10:59:51.488319Z","shell.execute_reply":"2022-01-08T11:00:20.179246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# IoU metric implementation for validation set check\n# Credit: https://www.kaggle.com/aglotero/another-iou-metric\n# Edited for personal uses\ndef iou_metric(labels, y_pred):\n    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n    intersection = temp1[0]\n    \n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n  \n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    return iou","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get IoU list and equivalent salt coverage list\niou_list = [np.asscalar(np.squeeze(iou_metric(y_true, y_pred))) for y_true, y_pred in tqdm(zip(y_val, preds_val_bin))]\ncoverage_list = [get_coverage_level(label) for label in y_val]\n\nplt.figure(figsize=(8, 8))\nsns.scatterplot(x=coverage_list, y=iou_list)\nplt.title('Biểu đồ tỷ lệ bao phủ (trục X) và điểm IoU (trục Y) tương ứng')\nplt.xlabel('Tỷ lệ bao phủ')\nplt.ylabel('IoU')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T10:50:15.088687Z","iopub.execute_input":"2022-01-08T10:50:15.088993Z","iopub.status.idle":"2022-01-08T10:50:15.466345Z","shell.execute_reply.started":"2022-01-08T10:50:15.088928Z","shell.execute_reply":"2022-01-08T10:50:15.465291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot some predictions of validation set\ndef plot_sample(X, y, preds, binary_preds, n_rows, n_cols=4, known_idx=[]):\n    fig, ax = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows), squeeze=False)\n    for row in range(0, n_rows):\n        for col in range(0, n_cols):\n            ix = col % n_cols\n            if ix == 0:\n                # Get random image index\n                if len(known_idx) > 0:\n                    idx = random.randint(0, len(known_idx))\n                else:\n                    idx = random.randint(0, len(X))\n                has_mask = y[idx].max() > 0\n\n                ax[row][col].imshow(X[idx, ..., 0], cmap='seismic')\n                if has_mask:\n                    ax[row][col].contour(y[idx].squeeze(), levels=[0.5])\n                ax[row][col].set_title('Seismic')\n\n            elif ix == 1:\n                ax[row][col].imshow(y[idx].squeeze())\n                ax[row][col].set_title('Salt')\n\n            elif ix == 2:   \n                ax[row][col].imshow(preds[idx].squeeze(), vmin=0, vmax=1)\n                if has_mask:\n                    ax[row][col].contour(y[idx].squeeze(), colors='k', levels=[0.5])\n                ax[row][col].set_title('Salt Predicted')\n\n            else:   \n                ax[row][col].imshow(binary_preds[idx].squeeze(), vmin=0, vmax=1)\n                if has_mask:\n                    ax[row][col].contour(y[idx].squeeze(), colors='k', levels=[0.5])\n                ax[row][col].set_title('Salt Predicted binary')\n\nplot_sample(X_val, y_val, preds_val, preds_val_bin, 4)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:00:20.186066Z","iopub.execute_input":"2022-01-08T11:00:20.186354Z","iopub.status.idle":"2022-01-08T11:00:23.948099Z","shell.execute_reply.started":"2022-01-08T11:00:20.186311Z","shell.execute_reply":"2022-01-08T11:00:23.947142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Return to org size\npreds_test_final = []\npreds_test_bin_final = []\nfor i in tqdm(range(len(preds_test_bin))):\n    preds_test_final.append(tf.image.resize(preds_test[i], [101, 101], preserve_aspect_ratio=True))\n    preds_test_bin_final.append(tf.image.resize(preds_test_bin[i], [101, 101], preserve_aspect_ratio=True))\n\nprint(preds_test_final[5].shape)\nprint(preds_test_bin_final[5].shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:12:25.653342Z","iopub.execute_input":"2022-01-08T08:12:25.653908Z","iopub.status.idle":"2022-01-08T08:12:29.092381Z","shell.execute_reply.started":"2022-01-08T08:12:25.65387Z","shell.execute_reply":"2022-01-08T08:12:29.091022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot some predictions of test set\nfig = plt.figure(figsize=(20, 20))\nfor i in range(1, 25, 3):\n    idx = random.randint(0, len(X_test))\n    filename = test_ids[idx]\n    ax1 = plt.subplot(4, 6, i)\n    ax1.imshow(X_test[idx])\n    ax1.set_title(f'X_test[{filename}]')\n    ax2 = plt.subplot(4, 6, i + 1)\n    ax2.imshow(preds_test_final[idx])\n    ax2.set_title(f'preds_test_final[{filename}]')\n    ax3 = plt.subplot(4, 6, i + 2)\n    ax3.imshow(preds_test_bin_final[idx])\n    ax3.set_title(f'preds_test_bin_final[{filename}]')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T07:42:52.584932Z","iopub.status.idle":"2022-01-08T07:42:52.585547Z","shell.execute_reply.started":"2022-01-08T07:42:52.585296Z","shell.execute_reply":"2022-01-08T07:42:52.58532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare submission","metadata":{}},{"cell_type":"code","source":"import more_itertools as mit\n\ndef get_submission_format(img, order='F'):\n    runs = []\n    pixels = img.reshape(img.shape[0] * img.shape[1], order=order)\n    if pixels.max() > 0:\n        mask_idx = tf.squeeze(tf.where(pixels == 1)) + 1\n        try:\n            for group in mit.consecutive_groups(mask_idx.numpy()):\n                run = list(group)\n                runs.append(str(run[0]))\n                runs.append(str(len(run)))\n            return ' '.join(runs)\n        except Exception as e:\n            print(e, '-', mask_idx.numpy())\n            return ''\n    else:\n        return ''\n\n# Get submission record\npred_dict = {filename:get_submission_format(img) for filename, img in tqdm(zip(test_ids, preds_test_bin_final))}","metadata":{"execution":{"iopub.status.busy":"2022-01-08T07:42:52.586722Z","iopub.status.idle":"2022-01-08T07:42:52.587333Z","shell.execute_reply.started":"2022-01-08T07:42:52.5871Z","shell.execute_reply":"2022-01-08T07:42:52.587125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame.from_dict(pred_dict,orient='index')\ndf.index.names = ['id']\ndf.columns = ['rle_mask']\ndf = df.reset_index()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-01-08T07:42:52.588567Z","iopub.status.idle":"2022-01-08T07:42:52.589204Z","shell.execute_reply.started":"2022-01-08T07:42:52.588961Z","shell.execute_reply":"2022-01-08T07:42:52.588986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('resnet_unet_fliplr_batch32_train2_submitOptimize.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T07:42:52.590364Z","iopub.status.idle":"2022-01-08T07:42:52.590988Z","shell.execute_reply.started":"2022-01-08T07:42:52.590748Z","shell.execute_reply":"2022-01-08T07:42:52.590781Z"},"trusted":true},"execution_count":null,"outputs":[]}]}