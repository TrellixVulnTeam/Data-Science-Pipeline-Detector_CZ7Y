{"cells":[{"metadata":{"_uuid":"c8fc6c3e84f282d0e6f664caf9848297b6c62a16"},"cell_type":"markdown","source":"### U-net with simple Resnet Blocks v2, can get 0.80+\n* Original version : \n  https://www.kaggle.com/shaojiaxin/u-net-with-simple-resnet-blocks\n        \n        \n#### update log\n1.   Cancel last dropout (seems better)\n2.  modify convolution_block, to be more consistant with the standard resent model. \n      * https://arxiv.org/abs/1603.05027\n3. Use faster  IOU metric score code,\n      * https://www.kaggle.com/donchuk/fast-implementation-of-scoring-metric\n4. Use  binary_crossentropy loss and then Lovász-hinge loss (very slow!)\n     * Lovász-hinge loss: https://github.com/bermanmaxim/LovaszSoftmax\n5. Start with saved model\n6. Display salt map mosiacs to show prediction quality over wider space. Mosiacs are from Salt Jigsaw Puzzle by Vicens Gaitan\n7. Alter predicitons based on proximity to other predictions"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\n%matplotlib inline\n\n# import cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook #, tnrange\n#from itertools import chain\nfrom skimage.io import imread, imshow #, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model, save_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras import optimizers\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n\nimport time\nt_start = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d87876952b8f06832f229ce95f2476639d3da04"},"cell_type":"code","source":"#print(os.listdir(\"../input/trained-unet-model/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c36d16775556c3e358edefab5710dc1541ccfc4"},"cell_type":"code","source":"version = 5\nbasic_name = f'Unet_resnet_v{version}'\nsave_model_name = basic_name + '.model'\nprevious_model_name = \"../input/u-net-with-simple-resnet-blocks-v2-new-loss/\" + save_model_name\nsubmission_file = basic_name + '.csv'\ndata_source = \"../input/tgs-salt-identification-challenge/\"\nstored_trained_model = \"../input/trained-unet-model/Unet_resnet_v5.model\"\nfMosaic = \"../input/trained-unet-model/mosaic.csv\"\nfTrain = \"../input/trained-unet-model/train-files.csv\"\nfTest = \"../input/trained-unet-model/test-files.csv\"\n\n\n#print(save_model_name)\n#print(previous_model_name)\n#print(submission_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c469280793719bf311d51e6ba2cdaea157d175"},"cell_type":"code","source":"img_size_ori = 101\nimg_size_target = 101\n\ndef upsample(img):# not used\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    \ndef downsample(img):# not used\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0044ece987200fd6fc0e1a3b812b9224226d0434"},"cell_type":"code","source":"mosaic_df=pd.read_csv(fMosaic)\ntrain_files_df = pd.read_csv(fTrain)\ntest_files_df = pd.read_csv(fTest)\n\ntrain_files_df.insert(0, 'img_id', range(0,len(train_files_df)))\ntest_files_df.insert(0, 'img_id', range(len(train_files_df),len(train_files_df)+len(test_files_df)))\nall_files_df = pd.concat([train_files_df,test_files_df],sort=False)\n\nall_files_df[['img_name','a','b']]=all_files_df['x'].str.partition(\".\")\n\n\n\n#all_files_df.head(4010)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a64babef03b9a0dbc94387a1dad54971c3e028d"},"cell_type":"code","source":"# Loading of training/testing ids and depths\ntrain_df = pd.read_csv(data_source + \"train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(data_source + \"depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\n\n#test_df = pd.read_csv(data_source + \"test\", index_col=\"id\", usecols=[0])\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\n#train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35b27e593fdfad653e1ce93ae38649c1287402d9"},"cell_type":"code","source":"test_df[\"images\"] = [np.array(load_img(data_source + \"test/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(test_df.index)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80c3768717007fb5f087d3e01619f1a9f9a3beac"},"cell_type":"code","source":"train_df[\"images\"] = [np.array(load_img(data_source + \"train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f55103f7daad6f03ec874c643077fe686c31bee"},"cell_type":"code","source":"train_df[\"masks\"] = [np.array(load_img(data_source + \"train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19955a230b858d2ddf7f839b579246d83c818c13"},"cell_type":"code","source":"#train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd709c51b82e9827cd91fa09dd47ec5e4bef7795"},"cell_type":"code","source":"#train_df[['xof','yof','mos_num']]\n#train_df = pd.merge(train_df,mosaic_df,how = 'left',left_on='img_id', right_on = 'img_id')\n#test_df = pd.merge(test_df,mosaic_df,how = 'left',left_on='img_id', right_on = 'img_id')\n\n\n#mosaic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"815340a2178885e185aab47843d337377ca232d7"},"cell_type":"code","source":"all_arr = pd.concat([train_df,test_df],sort=False)\nall_arr.insert(0, 'orig_id', range(1,len(all_arr)+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd19149e9c54cd003b7df305c8395c43a6ef747d"},"cell_type":"code","source":"#all_arr.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72898c7083dbe3ff496cd5ccb30c33faf02eae8a"},"cell_type":"code","source":"all_arr = pd.merge(all_arr,all_files_df,how = 'left',left_index=True, right_on = 'img_name')\n#all_arr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b784cc35f04c2a0aac8b68eea351287f4ecaa8e"},"cell_type":"code","source":"#all_arr = pd.merge(all_arr,mosaic_df,how = 'left',left_on='img_id', right_on = 'img_id')\n#all_arr.head(4010)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"010066dd50ef4fdfa7dabe2c946fd7491f9556fd"},"cell_type":"code","source":"train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ad5ac1576277fc54d768933c36efd1f9ff01acd"},"cell_type":"markdown","source":"fig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(train_df.coverage, kde=False, ax=axs[0])\nsns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage\")\naxs[1].set_xlabel(\"Coverage class\")"},{"metadata":{"trusted":true,"_uuid":"9f34c4263989a3d95af1e5922c1b7d2126655610"},"cell_type":"markdown","source":"#Plotting the depth distributions¶\n\nsns.distplot(train_df.z, label=\"Train\")\nsns.distplot(test_df.z, label=\"Test\")\nplt.legend()\nplt.title(\"Depth distribution\")"},{"metadata":{"trusted":true,"_uuid":"0cba8bb153f3093495bb0c26f119d8d6fcb6fb72"},"cell_type":"code","source":"#test = np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51981795f0dd6b8ca7abe4db367f48313b63811e"},"cell_type":"code","source":"# Create train/validation split stratified by salt coverage\nids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state= None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fb577cdf27f365d4a912728c2a7654d0e60fac8"},"cell_type":"code","source":"def BatchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation == True:\n        x = BatchActivate(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, batch_activate = False):\n    x = BatchActivate(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    if batch_activate:\n        x = BatchActivate(x)\n    return x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02967d71ee7f936254ab54acf2aa7c2e038a2b21"},"cell_type":"code","source":"# Build model\ndef build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n    # 101 -> 50\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1, True)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(DropoutRatio/2)(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2, True)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio)(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4, True)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8, True)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = residual_block(convm,start_neurons * 16, True)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n    \n    # 12 -> 25\n    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(DropoutRatio)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n\n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(DropoutRatio)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n    \n    # 50 -> 101\n    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(DropoutRatio)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n    \n    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n    output_layer =  Activation('sigmoid')(output_layer_noActi)\n    \n    return output_layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bd5e479d3aa211bcb5fe32ce9c4d71cd012eefa"},"cell_type":"code","source":"def get_iou_vector(A, B):\n    batch_size = A.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch]>0, B[batch]>0\n#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n#             metric.append(0)\n#             continue\n#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n#             metric.append(0)\n#             continue\n#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n#             metric.append(1)\n#             continue\n        \n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n        thresholds = np.arange(0.5, 1, 0.05)\n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        metric.append(np.mean(s))\n\n    return np.mean(metric)\n\ndef my_iou_metric(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n\ndef my_iou_metric_2(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e25caa2102813289cbd74796b612fbbfaaff8154"},"cell_type":"code","source":"# code download from: https://github.com/bermanmaxim/LovaszSoftmax\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    gts = tf.reduce_sum(gt_sorted)\n    intersection = gts - tf.cumsum(gt_sorted)\n    union = gts + tf.cumsum(1. - gt_sorted)\n    jaccard = 1. - intersection / union\n    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        def treat_image(log_lab):\n            log, lab = log_lab\n            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n            log, lab = flatten_binary_scores(log, lab, ignore)\n            return lovasz_hinge_flat(log, lab)\n        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n\n    def compute_loss():\n        labelsf = tf.cast(labels, logits.dtype)\n        signs = 2. * labelsf - 1.\n        errors = 1. - logits * tf.stop_gradient(signs)\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n        gt_sorted = tf.gather(labelsf, perm)\n        grad = lovasz_grad(gt_sorted)\n        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n        return loss\n\n    # deal with the void prediction case (only void pixels)\n    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n                   lambda: tf.reduce_sum(logits) * 0.,\n                   compute_loss,\n                   strict=True,\n                   name=\"loss\"\n                   )\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = tf.reshape(scores, (-1,))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return scores, labels\n    valid = tf.not_equal(labels, ignore)\n    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vscores, vlabels\n\ndef lovasz_loss(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    #logits = K.log(y_pred / (1. - y_pred))\n    logits = y_pred #Jiaxin\n    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"072ab621d38cc93d26998f391357cb6efc791600"},"cell_type":"code","source":"#Data augmentation\nx_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\nprint(x_train.shape)\nprint(y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba0c93a2e7ae04788011b1247bd8b0c6606ae9c1"},"cell_type":"markdown","source":"# Non physical data augmentation\n\n#Up down flip\nx_train = np.append(x_train, [np.flipud(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.flipud(x) for x in y_train], axis=0)\n\n# 90 deg rotation\nx_train = np.append(x_train, [np.flip(x,axis = (0,1)) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.flip(x,axis = (0,1)) for x in y_train], axis=0)\n\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(y_valid.shape)"},{"metadata":{"trusted":true,"_uuid":"98ba64dfcfe267544b87032844555e761770f9b7"},"cell_type":"code","source":"# This will load a stored trained model or the last trained model\nfrom pathlib import Path\n\nif Path(previous_model_name).is_file():\n    print(\"Using previous sucessful run's model\")\n    model2 = load_model(previous_model_name,custom_objects={'my_iou_metric_2': my_iou_metric,\n                                                        'lovasz_loss': lovasz_loss,\n                                                        'my_iou_metric': my_iou_metric})\nelse:\n    print(\"Using stored trained model\")\n    model2 = load_model(stored_trained_model,custom_objects={'my_iou_metric_2': my_iou_metric,\n                                                        'lovasz_loss': lovasz_loss,\n                                                        'my_iou_metric': my_iou_metric})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7cef38be8a5d81bb3ee70d35cf27699122eac81"},"cell_type":"code","source":"# Use this one if you want to start from a pre-trained model\n\n# remove layter activation layer and use losvasz loss\ninput_x = model2.layers[0].input\n\noutput_layer = Activation('sigmoid',name='output_activaton')(model2.layers[-1].output)\nmodel1 = Model(input_x, output_layer)\nc = optimizers.adam(lr = 0.01)\n\nmodel1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n\n#model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30622932f68888e895a9b8cac91810a1bb3c5e75","collapsed":true},"cell_type":"markdown","source":"# model\ninput_layer = Input((img_size_target, img_size_target, 1))\noutput_layer = build_model(input_layer, 16,0.5)\n\nmodel1 = Model(input_layer, output_layer)\n\nc = optimizers.adam(lr = 0.01)\nmodel1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n\nmodel1.summary()"},{"metadata":{"trusted":true,"_uuid":"41699081be465c14e193ffad4fd00bd56840f156","scrolled":true},"cell_type":"code","source":"#early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\nmodel_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n                                   mode = 'max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n\nepochs = 10\nbatch_size = 32\nhistory = model1.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[ model_checkpoint,reduce_lr], \n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c298a9337709ace6abe42d713699f1b0ef8e854e"},"cell_type":"code","source":"fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\nax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\nax_loss.legend()\nax_loss.grid(True,axis = 'y')\nax_score.plot(history.epoch, history.history[\"my_iou_metric\"], label=\"Train score\")\nax_score.plot(history.epoch, history.history[\"val_my_iou_metric\"], label=\"Validation score\")\nax_score.legend()\nax_score.grid(True,axis = 'y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"513a3f8490ae5cbc61651458750ba369f99f6f62"},"cell_type":"code","source":"model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n# remove layter activation layer and use losvasz loss\ninput_x = model1.layers[0].input\n\noutput_layer = model1.layers[-1].input\nmodel = Model(input_x, output_layer)\nc = optimizers.adam(lr = 0.01)\n\n# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\nmodel.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41b2b225831aff854646f59eb1683a6f827158ab"},"cell_type":"markdown","source":"model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n                                                   'lovasz_loss': lovasz_loss})\n\nmodel.summary()"},{"metadata":{"trusted":true,"_uuid":"bc68a1d9f9ec3837a2988bd7fe05d1fffdbc381d"},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=30, verbose=1)\nmodel_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n                                   mode = 'max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\nepochs = 50\nbatch_size = 32\n\nhistory = model.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[ model_checkpoint,reduce_lr,early_stopping], \n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"347c6567c95430f28ec51b94f42603e37a4056db"},"cell_type":"code","source":"fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\nax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\nax_loss.legend()\nax_loss.grid(True,axis = 'y')\nax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\nax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\nax_score.legend()\nax_score.grid(True,axis = 'y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"817a5ced27499d1691fbe5f8cd984ea0221ee83a"},"cell_type":"code","source":"model = model2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a081f8f61a713457c8c8f3979a78f75541875456"},"cell_type":"code","source":"model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n                                                   'lovasz_loss': lovasz_loss})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f68651e1ce6ad9a461c8f1a25a1250fd489adfed"},"cell_type":"code","source":"def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n    return preds_test/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7a061700364ea17735f953d6bd3c835bc3dc630"},"cell_type":"code","source":"preds_train = predict_result(model,x_train,img_size_target)\npreds_valid = predict_result(model,x_valid,img_size_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a9b1a900a8a4d031978c3b5ef2e739b5661de73"},"cell_type":"code","source":"#Score the model and do a threshold optimization by the best IoU.\n\n# src: https://www.kaggle.com/aglotero/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n\n\n    true_objects = 2\n    pred_objects = 2\n\n    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n    #print(temp1)\n    intersection = temp1[0]\n    #print(\"temp2 = \",temp1[1])\n    #print(intersection.shape)\n   # print(intersection)\n    # Compute areas (needed for finding the union between all objects)\n    #print(np.histogram(labels, bins = true_objects))\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    #print(\"area_true = \",area_true)\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n    \n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91b1be75d7e8ff74db956c8c846c47ed7576ecb2"},"cell_type":"code","source":"## Scoring for last model, choose threshold by validation data \nthresholds_ori = np.linspace(0.3, 0.7, 31)\n# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\nthresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n\n# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n# print(ious)\nious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\nprint(ious)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1beb285910aa6532d7a69a70afa6a9671e6d347d"},"cell_type":"code","source":"# instead of using default 0 as threshold, use validation data to find the best threshold.\nthreshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd0f96d274975763031a768308148927082002e7"},"cell_type":"code","source":"def iou(img_true, img_pred):\n    i = np.sum((img_true*img_pred) >0)\n    u = np.sum((img_true + img_pred) >0)\n    if u == 0:\n        return 1.0\n    return i/u\n\ndef plot_sample(X, y, preds):\n    ix = random.randint(0, len(X))\n    \n    iou_score = iou(y[ix,:,:,0],preds[ix]>threshold_best)\n    \n    has_mask = y[ix].max() > 0\n\n    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Seismic')\n\n    ax[1].imshow(y[ix].squeeze())\n    ax[1].set_title('Salt')\n\n    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[2].set_title('Salt Pred. IOU: ' + str(round(iou_score,5)));\n    \n    i = ((preds[ix]>threshold_best)*y[ix,:,:,0]) >0\n    u = ((preds[ix]>threshold_best) + y[ix,:,:,0]) >0\n    \n    #print(i)\n    #print(preds[ix] + y[ix,:,:,0])\n    #print(preds[ix,0,0:5]-preds[ix,0,1:6])\n    \n    umi = u!=i\n    \n    #print(y[ix,:,:,0].shape)\n    \n     \n    ax[3].matshow(u, vmin=0, vmax=1, alpha = 1, cmap = 'Reds')\n    ax[3].matshow(i, vmin=0, vmax=1, cmap = 'Greens', alpha = 0.5)\n    ax[3].set_title('Intercection and Union')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a52b8fc4675fe4df437f312ebda757e537fdc0d"},"cell_type":"markdown","source":"# Check if train data looks all right\nfor i in range(40):\n    plot_sample(x_train, y_train, preds_train)"},{"metadata":{"trusted":true,"_uuid":"3dff87573038c348b6291e993ed7c06b42cfa065"},"cell_type":"markdown","source":"# Check if valid data looks all right\nfor i in range(40):\n    plot_sample(x_valid, y_valid, preds_valid)"},{"metadata":{"trusted":true,"_uuid":"2c4852ecf2c504a4ce30e975f5e36b534c2111e6"},"cell_type":"code","source":"\"\"\"\nused for converting the decoded image to rle mask\nFast compared to previous one\n\"\"\"\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21bb50645b1c67d907e42c262d92f975668fccac"},"cell_type":"code","source":"x_test = np.array([(np.array(load_img(data_source + \"/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce8185fa64aafbe42ebde98aba984b4f22b0050e"},"cell_type":"code","source":"x_all_train = np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n\npreds_train = predict_result(model,x_all_train,img_size_target)\n\npreds_test = predict_result(model,x_test,img_size_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cb8e7e3f65db7137b99458e4c09e2ebf27f348b"},"cell_type":"code","source":"#all_arr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"477ca494ae65145aecda403af1722ccaaf34bf83"},"cell_type":"code","source":"all_preds = list(np.concatenate((preds_train,preds_test)))\n#print(all_arr.shape)\npreds_df = pd.DataFrame(pd.Series(all_preds), columns = ['pred_masks'])\npreds_df.insert(0, 'orig_id', range(1,len(preds_df)+1))\n\nall_arr = pd.merge(all_arr,preds_df,how = 'left',left_on = 'orig_id', right_on = 'orig_id')\n#all_arr['pred_masks']=pd.Series(all_preds)\n#all_arr.head()#4010)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd01e295ef14345d1b5dbdff061a6950c1378ebb"},"cell_type":"code","source":"#mosaic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86683470cf168505a5e4730150968365e24e8090","trusted":true},"cell_type":"code","source":"all_arr_saved = all_arr.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00a7fc9446046e27ffed18f2954de14fc59d04ff"},"cell_type":"code","source":"#all_arr = all_arr_saved.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2839aa5a0042e0bbf73e2b67d9b6da6209e7b01b"},"cell_type":"code","source":"def plot_mosaic(index,visualize = 1, train = 1):\n    #fig, ax = plt.plot()\n    mos = mosaic_df.loc[mosaic_df['mid']==index]\n\n    max_x = int(mos['x_offset'].max())+1\n    max_y = int(mos['y_offset'].max())+1\n    \n    max_x = max(max_x,max_y)\n    max_y = max_x\n    \n    if visualize: fig, ax = plt.subplots(max_y, max_x, figsize=(20, 20))\n    #print(max_x,max_y)\n\n    #print(mos.head(10))\n\n    #for index, row in df.iterrows():\n    #   print row['c1'], row['c2']\n    #print(test_df[all_arr['img_id']==0]['images'])\n    image = all_arr.loc[all_arr['img_id']==(1)]['images'].iloc[0]*0\n    for i in range(max_x):\n        for j in range(max_y):\n            #ax[j,i].imshow(image, cmap='seismic')\n            if visualize: ax[j,i].axis('off')\n            #Here's where I adjust images based on surroundings\n            \n            img_center = mos.loc[mos['y_offset']==j]\n            img_center = img_center.loc[img_center['x_offset']==i] \n            \n            if img_center.shape[0] > 0:\n                           \n                target_img_id = (img_center['img_id'].iloc[0]-1)\n                top_pred_mask_center = all_arr.loc[all_arr['img_id']==target_img_id]['pred_masks'].iloc[0]\n                np_center_mask = np.array(top_pred_mask_center)\n            \n            if i>0:\n                img_left = mos.loc[mos['y_offset']==j]\n                img_left = img_left.loc[img_left['x_offset']==(i-1)]\n                if img_left.shape[0] > 0 and img_center.shape[0] > 0:\n                    left_img_id = (img_left['img_id'].iloc[0]-1)\n                    pred_mask_left = all_arr.loc[all_arr['img_id']==left_img_id]['pred_masks'].iloc[0]\n                    \n                    np_pred_mask_left = np.array(pred_mask_left)\n                    \n                    right_column_of_left_mask = np_pred_mask_left[:,-1]\n                    \n                    left_column_of_center_mask = np_center_mask[:,0]\n                    \n                    lr_diff = np.mean(left_column_of_center_mask)-np.mean(right_column_of_left_mask)\n                    \n                    new_left_mask = pred_mask_left - lr_diff*0.5\n                    new_right_mask = top_pred_mask_center + lr_diff*0.5\n                    \n                    if train:\n                        all_arr.loc[all_arr['img_id']==target_img_id,'pred_masks'] = [new_right_mask]\n                        all_arr.loc[all_arr['img_id']==left_img_id,'pred_masks'] = [new_left_mask]\n                    \n                    \n            if j>0:\n                img_above = mos.loc[mos['y_offset']==j-1]\n                img_above = img_above.loc[img_above['x_offset']==i]\n                \n                \n                if img_above.shape[0] > 0 and img_center.shape[0] > 0: #This one increase salt threshold if the one below\n                    last_pred_mask_above = all_arr.loc[all_arr['img_id']==(img_above['img_id'].iloc[0]-1)]['pred_masks'].iloc[0]\n                    last_pred_mask_row_above = last_pred_mask_above[-1]\n                    \n                    \n                    top_pred_mask_row_center = top_pred_mask_center[0]\n                    top_bot_mean_diff = np.mean(last_pred_mask_row_above)-np.mean(top_pred_mask_row_center)\n                    new_center_mask = top_pred_mask_center + top_bot_mean_diff*1.\n                    \n                    if train: \n                        all_arr.loc[all_arr['img_id']==target_img_id,'pred_masks'] = [new_center_mask]#pd.Series(list(new_mask))\n                    \n                    #print('df value: ',all_arr.loc[all_arr['img_id']==target_img_id,'pred_masks'])\n                    \n    if visualize:\n        for index, im in mos.iterrows():\n            #print(im)\n            x_off = int(im['x_offset'])\n            y_off = int(im['y_offset'])\n            #print(x_off,y_off)\n            #print(im['img_id'])\n            #print(all_arr.loc[all_arr['img_id']==1]['images'])#all_arr['img_id']==im['index']])\n            image = all_arr.loc[all_arr['img_id']==(im['img_id']-1)]['images'].iloc[0]\n            pred_mask = all_arr.loc[all_arr['img_id']==(im['img_id']-1)]['pred_masks'].iloc[0] >threshold_best\n            mask = all_arr.loc[all_arr['img_id']==(im['img_id']-1)]['masks'].iloc[0]\n\n            ax[y_off,x_off].imshow(image, cmap='Greys')\n            ax[y_off,x_off].imshow(pred_mask, alpha = 0.2, cmap = 'Greens', vmin=0, vmax=1)\n            if (im['img_id']<4000):\n                ax[y_off,x_off].imshow(mask, alpha = 0.2, cmap = 'seismic')\n\n        #print(mos.shape)\n        #mos.head(100)\n        #plt.tight_layout()\n        plt.subplots_adjust(hspace=0,wspace = 0)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edd95a8ae190dbaf3d4c4f5be4cdb37b78c254ed"},"cell_type":"code","source":"#plot_mosaic(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fb7ad4d3a8d04571633c148bca5fc62d6d34eb6"},"cell_type":"code","source":"plot_mosaic(100)\nfor i in tqdm_notebook(range(1,200)):\n    plot_mosaic(i,0,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9d0763c8f61daf7c82ffaf04d60a4aab29cf96b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae9689748fce3549ba4c713bee41fb7bbeb9cb0a"},"cell_type":"code","source":"# updates pred_test based on mosiac findings\n#print(np.array(all_arr.loc[all_arr['img_id']>3999,'pred_masks'].tolist()).shape)\n\npreds_test = np.array(all_arr.loc[all_arr['img_id']>3999,'pred_masks'].tolist())\npreds_train = np.array(all_arr.loc[all_arr['img_id']<=3999,'pred_masks'].tolist())\ny_train = np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1de679a6e52f5925e8b66b5fc99814703dc8e08f"},"cell_type":"code","source":"ious = np.array([iou_metric_batch(y_train, preds_train > threshold) for threshold in tqdm_notebook(thresholds)])\nprint(ious)\n# instead of using default 0 as threshold, use validation data to find the best threshold.\nthreshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4d5e9cd614fb1dd963516aee08c8c78e28de259"},"cell_type":"code","source":"for i in range(1,40):\n    plot_mosaic(i,1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ccac81a492b9caaff4a25401165e145cf2c6f8e"},"cell_type":"code","source":"t1 = time.time()\npred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\nt2 = time.time()\n\nprint(f\"Usedtime = {t2-t1} s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"770d7d596656f4f1ad17a6063ad662ac80e11b24"},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv(submission_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c89c406884ee54bee2c57aff51b116c157553ae9"},"cell_type":"code","source":"t_finish = time.time()\nprint(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a3009187c164635fbe163bd8ce406c2e309b1e5f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}