{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch #version 0.3\nfrom torchvision import transforms, models\nfrom torch.autograd import Variable\nfrom torch.utils import data\nimport torch.nn.functional as F\nfrom torch import nn\nimport sklearn\nimport cv2\nimport imageio\nimport skimage\n\nimport glob\nfrom tqdm import tqdm, tqdm_notebook\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9dae674a4616e4fc85a41c9be9c59cef89167e01"},"cell_type":"code","source":"# https://github.com/leigh-plt/cs231n_hw2018/blob/master/assignment2/pytorch_tutorial.ipynb\ndef save_checkpoint(checkpoint_path, model, optimizer):\n    state = {'state_dict': model.state_dict(),\n             'optimizer' : optimizer.state_dict()}\n    torch.save(state, checkpoint_path)\n    print('model saved to %s' % checkpoint_path)\n    \ndef load_checkpoint(checkpoint_path, model, optimizer):\n    state = torch.load(checkpoint_path)\n    model.load_state_dict(state['state_dict'])\n    optimizer.load_state_dict(state['optimizer'])\n    print('model loaded from %s' % checkpoint_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3c35372c332144879cb4635d0d0ab4daffa908a","collapsed":true},"cell_type":"code","source":"def conv3x3(in_, out):\n    return nn.Conv2d(in_, out, 3, padding=1)\n\nclass ConvRelu(nn.Module):\n    def __init__(self, in_, out):\n        super().__init__()\n        self.conv = conv3x3(in_, out)\n        self.activation = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.activation(x)\n        return x\n\n\nclass DecoderBlock(nn.Module):\n    def __init__(self, in_channels, middle_channels, out_channels):\n        super().__init__()\n\n        self.block = nn.Sequential(\n            #先下采样\n            ConvRelu(in_channels, middle_channels),\n            #卷积转置是一种上采样\n            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.block(x)\n\nclass UNet11(nn.Module):\n    def __init__(self, num_filters=32):\n        \"\"\"\n        :param num_classes:\n        :param num_filters:\n        \"\"\"\n        super().__init__()\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # Convolutions are from VGG11\n        self.encoder = models.vgg11().features\n        \n        # \"relu\" layer is taken from VGG probably for generality, but it's not clear \n        self.relu = self.encoder[1]\n        \n        self.conv1 = self.encoder[0]\n        self.conv2 = self.encoder[3]\n        self.conv3s = self.encoder[6]\n        self.conv3 = self.encoder[8]\n        self.conv4s = self.encoder[11]\n        self.conv4 = self.encoder[13]\n        self.conv5s = self.encoder[16]\n        self.conv5 = self.encoder[18]\n    \n        self.center = DecoderBlock(num_filters * 8 * 2, num_filters * 8 * 2, num_filters * 8)\n        self.dec5 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 8)\n        self.dec4 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 4)\n        self.dec3 = DecoderBlock(num_filters * (8 + 4), num_filters * 4 * 2, num_filters * 2)\n        self.dec2 = DecoderBlock(num_filters * (4 + 2), num_filters * 2 * 2, num_filters)\n        self.dec1 = ConvRelu(num_filters * (2 + 1), num_filters)\n        \n        self.final = nn.Conv2d(num_filters, 1, kernel_size=1, )\n    \n    def forward(self, x):\n        conv1 = self.relu(self.conv1(x))\n        conv2 = self.relu(self.conv2(self.pool(conv1)))\n        conv3s = self.relu(self.conv3s(self.pool(conv2)))\n        conv3 = self.relu(self.conv3(conv3s))\n        conv4s = self.relu(self.conv4s(self.pool(conv3)))\n        conv4 = self.relu(self.conv4(conv4s))\n        conv5s = self.relu(self.conv5s(self.pool(conv4)))\n        conv5 = self.relu(self.conv5(conv5s))\n\n        center = self.center(self.pool(conv5))\n\n        # Deconvolutions with copies of VGG11 layers of corresponding size \n        dec5 = self.dec5(torch.cat([center, conv5], 1))\n        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n        return F.sigmoid(self.final(dec1))\n\ndef get_model():\n    model = UNet11()\n    model.train() #\n    return model.cuda()#注意这里别忘了调gpu!!!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"640a98440d98f41947f41e04d1c68834e9531bfc"},"cell_type":"code","source":"def image_process(impath, is_mask=False):\n    image = cv2.imread(impath) #(101, 101, 3)\n    \n    if is_mask:\n        image = image[:,:,0:1] // 255\n    else:\n        image = image / 255.0\n    \n    top_pad = 13\n    bottom_pad = 14\n    left_pad = 13\n    right_pad = 14\n    #https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=copymakeborder#copymakeborder\n    image = cv2.copyMakeBorder(image, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_REFLECT_101)\n    \n    #tsfm = transforms.Compose([transforms.ToTensor()]) \n    #image = tsfm(image)  \n    \n    #return torch.tensor(np.transpose(image, (2, 0, 1)).astype('float32'), dtype=torch.FloatTensor)\n    #pytorch 0.3 不能用torch.tensor(...)\n    \n    #return torch.FloatTensor(np.transpose(image, (2, 0, 1)).astype('float32'))\n    #不知道为啥不行\n    return torch.FloatTensor(image.astype('float32'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce0d75f2771d26ad1cc2ed134a16fe61efb7b0fe","collapsed":true},"cell_type":"code","source":"class TGSSaltDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, root_path, file_list, is_test=False):\n        self.root_path = root_path\n        self.file_list = file_list\n        self.is_test = is_test\n    \n    def __len__(self):\n        return len(self.file_list)\n    \n    def __getitem__(self, index):\n        if index not in range(0, len(self.file_list)):\n            return self.__getitem__(np.random.randint(0, self.__len__()))\n        \n        file_id = self.file_list[index]\n        \n        image_folder = os.path.join(self.root_path, \"images\")\n        image_path = os.path.join(image_folder, file_id + \".png\")\n        \n        #image = np.array(imageio.imread(image_path), dtype=np.uint8)\n        image = image_process(image_path)\n        \n        if not self.is_test:\n            mask_folder = os.path.join(self.root_path, \"masks\")\n            mask_path = os.path.join(mask_folder, file_id + \".png\")\n \n            #mask = np.array(imageio.imread(mask_path), dtype=np.uint8)\n            mask = image_process(mask_path, is_mask=True)\n            return (image, mask) \n        else:\n            return (image,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3ea57945436958194d4d3c7c8f5af76dd74e60f","collapsed":true},"cell_type":"code","source":"series = pd.read_csv(\"../input/train.csv\")['id']\nfile_list = [series[i] for i in range(len(series))]\n\nval_file_list = file_list[::10]#val_file_list = [file_list[i] for i in range(len(file_list)) if i%10==0]\ntrain_file_list = [f for f in file_list if f not in val_file_list]\n\ntrain_dataset = TGSSaltDataset(\"../input/train\", train_file_list)\nval_dataset = TGSSaltDataset(\"../input/train/\", val_file_list)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0a04f006b707124cacf62e744ef2b5e18ef9034","collapsed":true},"cell_type":"code","source":"model = get_model()\nepoch_num = 13 #13的时候val loss 最低\nlearning_rate = 1e-4\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"#这里debug好艰难啊……各种shape对不上\nfor epoch in range(epoch_num):\n    train_loss = []\n    for image, mask in tqdm_notebook(data.DataLoader(train_dataset, batch_size=30, shuffle=True, )):\n        #此时image [30, 128, 128, 3], mask不知道为啥少了一维是 [30, 128, 128]\n        image = torch.transpose(image, 1, 3).cuda() #image变成[30, 3, 128, 128]       \n        #image = image / 255\n        y_pred = model(Variable(image)) #y_pred是[30, 1, 128, 128]\n        #mask = mask // 255 #Convert mask to 0 and 1 format ??????\n        mask = mask[:, np.newaxis, :, :]#mask变成[30, 1, 128, 128]\n        mask = mask.type(torch.FloatTensor)#从bytetensor变成float tensor\n        \n        #一开始没有把数据归一化到[0,1]，导致loss都是负的（交叉熵里有ln（1-x），x必须在0，1之间）\n        loss = criterion(y_pred, Variable(mask.cuda())) #torch.Size([1])\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss.append(loss.data[0])#pytorch 0.3 里得这样提取出[1]tensor的值\n    val_loss = []\n    for image, mask in tqdm_notebook(data.DataLoader(val_dataset, batch_size=30, shuffle=True, )):\n        image = torch.transpose(image, 1, 3).cuda()\n        y_pred = model(Variable(image)) \n        mask = mask[:, np.newaxis, :, :]\n        mask = mask.type(torch.FloatTensor)\n        \n        loss = criterion(y_pred, Variable(mask.cuda()))         \n        val_loss.append(loss.data[0])\n        \n    print(\"Epoch: %d, Train Loss: %.3f, Val Loss: %.3f\" % (epoch, np.mean(train_loss), np.mean(val_loss)))\nprint(\"Training Completed!\")\nsave_checkpoint('tgs-%i.pth' % epoch_num, model, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"77d75de79a27215835d0436e571dfa2f67ef1563"},"cell_type":"code","source":"load_checkpoint('./tgs-13.pth', model, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"370e25c64deefa41210a6b7748290be849d9fcf4","collapsed":true},"cell_type":"code","source":"test_path = \"../input/test/\"\ntest_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\ntest_file_list = [f.split('/')[-1].split('.')[0] for f in test_file_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2107fbd7b80f2e976ad038cdbfe5d5ab9d8fc915","collapsed":true},"cell_type":"code","source":"test_dataset = TGSSaltDataset(test_path, test_file_list, is_test=True)\ntest_dataloader = data.DataLoader(test_dataset, batch_size=30) #为啥test也有batchsize？？","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a018b9e17ed4ce1088a16bfb0f9a8e24f1584239","collapsed":true},"cell_type":"code","source":"test_predictions = []\nmodel.eval()\nfor image in test_dataloader:\n    #????不知道为啥image是一个长为1的list，list[0]是[30, 128, 128, 3]的byteTensor\n    image = image[0]\n    image = np.transpose(image, (0,3,2,1)).type(torch.FloatTensor).cuda() #image变成[30, 3, 128, 128]       \n    image = image / 255\n    y_pred = model(Variable(image)) #[30, 1, 128, 128]\n    test_predictions.append(y_pred)\ntest_predictions_stacked = np.vstack(test_predictions)[:, 0, :, :]\ntest_predictions_stacked = test_predictions_stacked[:, bottom_pad + 1:128 - top_pad - 1, left_pad + 1:128 - right_pad - 1]\ntest_predictions_stacked.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"976b76c516796c81791ce7f2599a5ce8cce89cb7"},"cell_type":"code","source":"val_predictions = []\nval_masks = []\nfor image, mask in tqdm_notebook(data.DataLoader(val_dataset, batch_size = 30)):\n    image = torch.transpose(image, 1, 3).cuda()\n    y_pred = model(Variable(image)) #[30, 1, 128, 128]\n    val_predictions.append(y_pred.cpu().data.numpy())\n    val_masks.append(mask)#[30,128,128]\n    \nval_predictions_stacked = np.vstack(val_predictions)[:, 0, :, :]\nval_masks_stacked = np.vstack(val_masks)\n\nval_predictions_stacked = val_predictions_stacked[:, bottom_pad + 1:128 - top_pad - 1, left_pad + 1:128 - right_pad - 1]\nval_masks_stacked = val_masks_stacked[:, bottom_pad + 1:128 - top_pad - 1, left_pad + 1:128 - right_pad - 1]\n\nval_masks_stacked.shape, val_predictions_stacked.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"211a91dd0d615b7e7d88d01e65a005b4133eb1ef"},"cell_type":"code","source":"from sklearn.metrics import jaccard_similarity_score\n\nmetric_by_threshold = []\nfor threshold in np.linspace(0, 1, 11):\n    val_binary_prediction = (val_predictions_stacked > threshold).astype(int)\n    \n    iou_values = []\n    for y_mask, p_mask in zip(val_masks_stacked, val_binary_prediction):\n        iou = jaccard_similarity_score(y_mask.flatten(), p_mask.flatten())\n        iou_values.append(iou)\n    iou_values = np.array(iou_values)\n    \n    accuracies = [\n        np.mean(iou_values > iou_threshold) #之后要不要把mean改成max试试？\n        for iou_threshold in np.linspace(0.5, 0.95, 10)\n    ]\n    print('Threshold: %.1f, Metric: %.3f' % (threshold, np.mean(accuracies)))\n    metric_by_threshold.append((np.mean(accuracies), threshold))\n    \nbest_metric, best_threshold = max(metric_by_threshold)#这怎么求max？？","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7318db27145db93e24e4641ee97b3299457af82b"},"cell_type":"code","source":"threshold = best_threshold\nbinary_prediction = (all_predictions_stacked > threshold).astype(int)\n\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b > prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\nall_masks = []\nfor p_mask in list(binary_prediction):\n    p_mask = rle_encoding(p_mask)\n    all_masks.append(' '.join(map(str, p_mask)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8cc00ef257cf20771a818fe1e5aa5a607da41f07"},"cell_type":"code","source":"submit = pd.DataFrame([test_file_list, all_masks]).T\nsubmit.columns = ['id', 'rle_mask']\nsubmit.to_csv('submit_baseline_torch.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}