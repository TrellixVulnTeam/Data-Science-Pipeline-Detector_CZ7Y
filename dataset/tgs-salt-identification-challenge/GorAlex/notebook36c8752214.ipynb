{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nimport os\nimport random\nimport tqdm\n\nfrom IPython.display import clear_output\n\nimport gc\n\nRANDOM_SEED = 42\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:56:47.261829Z","iopub.execute_input":"2021-06-09T07:56:47.26218Z","iopub.status.idle":"2021-06-09T07:56:48.482908Z","shell.execute_reply.started":"2021-06-09T07:56:47.262105Z","shell.execute_reply":"2021-06-09T07:56:48.48209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install -U git+https://github.com/albu/albumentations --no-cache-dir\n!pip3 install pytorch-lightning==0.8.5\n!pip3 install segmentation-models-pytorch\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:56:51.971678Z","iopub.execute_input":"2021-06-09T07:56:51.971995Z","iopub.status.idle":"2021-06-09T07:57:23.66525Z","shell.execute_reply.started":"2021-06-09T07:56:51.971969Z","shell.execute_reply":"2021-06-09T07:57:23.664418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as albu\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.logging import TensorBoardLogger\n\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:57:47.229272Z","iopub.execute_input":"2021-06-09T07:57:47.229627Z","iopub.status.idle":"2021-06-09T07:57:51.152891Z","shell.execute_reply.started":"2021-06-09T07:57:47.229595Z","shell.execute_reply":"2021-06-09T07:57:51.151906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install pytorch_toolbelt==0.3.2\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:57:51.154422Z","iopub.execute_input":"2021-06-09T07:57:51.154748Z","iopub.status.idle":"2021-06-09T07:58:07.438154Z","shell.execute_reply.started":"2021-06-09T07:57:51.154713Z","shell.execute_reply":"2021-06-09T07:58:07.437277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_toolbelt import losses as L\nfrom pytorch_toolbelt.losses import DiceLoss, FocalLoss\nimport pytorch_toolbelt","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:58:07.440264Z","iopub.execute_input":"2021-06-09T07:58:07.440645Z","iopub.status.idle":"2021-06-09T07:58:07.457098Z","shell.execute_reply.started":"2021-06-09T07:58:07.440605Z","shell.execute_reply":"2021-06-09T07:58:07.456251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/tgs-salt-identification-challenge/train.zip\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:58:07.460222Z","iopub.execute_input":"2021-06-09T07:58:07.460543Z","iopub.status.idle":"2021-06-09T07:58:09.212147Z","shell.execute_reply.started":"2021-06-09T07:58:07.460517Z","shell.execute_reply":"2021-06-09T07:58:09.211178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir        = '/kaggle/input/tgs-salt-identification-challenge/'\nIMAGE_PATH      = './images/'\nMASK_PATH       = './masks/'\nIMAGE_PATH_TEST = './competition_data/test/images/'","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:58:09.214735Z","iopub.execute_input":"2021-06-09T07:58:09.215252Z","iopub.status.idle":"2021-06-09T07:58:09.222205Z","shell.execute_reply.started":"2021-06-09T07:58:09.215131Z","shell.execute_reply":"2021-06-09T07:58:09.221229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Transforms**","metadata":{}},{"cell_type":"code","source":"def get_val_augs(height=128, width=128):\n\n    train_transform = [\n        albu.Resize(height=height, width=width, interpolation=cv2.INTER_CUBIC, always_apply=True),\n        albu.Normalize(),\n        ToTensorV2(),\n    ]\n\n    return albu.Compose(train_transform)\n\n\ndef get_train_augs(height=128, width=128):\n\n    train_transform = [\n        albu.Resize(height=height, width=width, interpolation=cv2.INTER_CUBIC, always_apply=True),\n        albu.HorizontalFlip(p=0.5),\n        albu.VerticalFlip(p=0.5),\n        albu.OpticalDistortion(interpolation=cv2.INTER_CUBIC, border_mode=cv2.BORDER_REFLECT_101, p=0.3),\n        albu.ShiftScaleRotate(shift_limit=0.01, scale_limit=(-0.15, 0.25), rotate_limit=5,\n                              interpolation=cv2.INTER_CUBIC, border_mode=cv2.BORDER_REFLECT_101,\n                              p=0.5),\n#         albu.ToGray(),\n        albu.Normalize(),\n        ToTensorV2(),\n    ]\n\n    return albu.Compose(train_transform) ","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:58:58.224479Z","iopub.execute_input":"2021-06-09T07:58:58.224821Z","iopub.status.idle":"2021-06-09T07:58:58.234072Z","shell.execute_reply.started":"2021-06-09T07:58:58.224786Z","shell.execute_reply":"2021-06-09T07:58:58.231399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Dataset**","metadata":{}},{"cell_type":"code","source":"def stratify_dataset(df, columns, n_fold, ds_path=None):\n    folds = df.copy()\n    folds[\"fold\"] = (list(range(n_fold)) * folds.shape[0])[:folds.shape[0]]\n    if ds_path is not None:\n        folds.to_csv(str(ds_path), index=False)\n    return folds","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:58:59.940718Z","iopub.execute_input":"2021-06-09T07:58:59.941333Z","iopub.status.idle":"2021-06-09T07:58:59.947517Z","shell.execute_reply.started":"2021-06-09T07:58:59.94129Z","shell.execute_reply":"2021-06-09T07:58:59.946733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_by_fold(folds, val_fold_n):\n    folds = folds.copy()\n    train_df = folds[~folds.fold.isin([val_fold_n])]\n    val_df = folds[folds.fold.isin([val_fold_n])]\n    return train_df, val_df","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:02.784315Z","iopub.execute_input":"2021-06-09T07:59:02.784683Z","iopub.status.idle":"2021-06-09T07:59:02.790428Z","shell.execute_reply.started":"2021-06-09T07:59:02.784654Z","shell.execute_reply":"2021-06-09T07:59:02.789521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SaltDataset(Dataset):\n    def __init__(self, df, transforms=None, phase='train'):\n        \n        self.root_dir   = root_dir\n        self.ids        = df.index\n#         self.depths     = df['z'].to_numpy()\n#         self.rle        = df['rle_mask'].to_numpy()\n        self.transforms = transforms\n        self.phase = phase\n\n    def __getitem__(self, index: int):\n        id    = self.ids[index]\n        if self.phase=='train':\n            image = cv2.imread(str(IMAGE_PATH+id+'.png'), cv2.IMREAD_COLOR)\n            mask = cv2.imread(str(MASK_PATH+id+'.png'), cv2.IMREAD_COLOR)\n            mask = np.all(mask == (255,255,255), axis = 2).astype(np.uint8) * 1\n            if self.transforms is not None:\n                data = self.transforms(image=image, mask=mask)\n                image = data['image']\n                mask = data['mask']\n            return image, mask\n        else:\n            image = cv2.imread(str(IMAGE_PATH_TEST+id+'.png'), cv2.IMREAD_COLOR)\n            if self.transforms is not None:\n                data = self.transforms(image=image)\n                image = data['image']\n            return image\n    def __len__(self):  # return count of sample we have\n        return len(self.ids)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:03.632868Z","iopub.execute_input":"2021-06-09T07:59:03.633206Z","iopub.status.idle":"2021-06-09T07:59:03.641665Z","shell.execute_reply.started":"2021-06-09T07:59:03.633175Z","shell.execute_reply":"2021-06-09T07:59:03.640851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df  = pd.read_csv(root_dir+'train.csv', index_col='id')\ndepths_df = pd.read_csv(root_dir+'depths.csv', index_col='id')\ndf = df.join(depths_df)\n\ndf = stratify_dataset(df, ['id', 'rle_mask', 'z'], 5)\n\ntrain_df, val_df = split_by_fold(df, 0)\n\ntrain_transforms = get_train_augs()\nval_transforms   = get_val_augs()\n\ntrain_dataset = SaltDataset(df=train_df, transforms=train_transforms)\nvalid_dataset = SaltDataset(df=val_df, transforms=val_transforms)\n\nbatch_size  = 16\nnum_workers = 2\n    \ntrain_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\nvalid_loader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:04.884148Z","iopub.execute_input":"2021-06-09T07:59:04.884496Z","iopub.status.idle":"2021-06-09T07:59:04.984525Z","shell.execute_reply.started":"2021-06-09T07:59:04.884464Z","shell.execute_reply":"2021-06-09T07:59:04.983674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = next(iter(train_loader))\nprint(x.shape, y.shape)\nplt.imshow(x[0].permute(1, 2, 0).numpy())\nplt.show()\nplt.imshow(y[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:05.604151Z","iopub.execute_input":"2021-06-09T07:59:05.60463Z","iopub.status.idle":"2021-06-09T07:59:06.28469Z","shell.execute_reply.started":"2021-06-09T07:59:05.604589Z","shell.execute_reply":"2021-06-09T07:59:06.283694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Metrics**","metadata":{}},{"cell_type":"code","source":"def iou_torch(\n    preds, target, thresh=0.5):\n    with torch.no_grad():\n        smooth = 1e-6\n        \n        target = target.byte()\n        preds = preds.squeeze(1)\n        preds = (torch.sigmoid(preds) > thresh).byte()\n\n        intersection = (preds & target).float().sum(dim=(1, 2))\n        union = (preds | target).float().sum(dim=(1, 2))\n\n        iou = (intersection + smooth) / (union + smooth)\n\n        return iou.mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:10.735555Z","iopub.execute_input":"2021-06-09T07:59:10.735885Z","iopub.status.idle":"2021-06-09T07:59:10.741918Z","shell.execute_reply.started":"2021-06-09T07:59:10.735854Z","shell.execute_reply":"2021-06-09T07:59:10.741053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"class SegModel(pl.LightningModule):\n    def __init__(self):\n        super(SegModel, self).__init__()\n        self.batch_size = 16\n        self.learning_rate = 1e-3\n        self.num_workers = 2\n        self.net = smp.Unet(\"resnet34\", \n                 encoder_weights = \"imagenet\", \n                 in_channels = 3,\n                 classes = 1,\n                 activation = None)\n        \n        df  = pd.read_csv(root_dir+'train.csv', index_col='id')\n        depths_df = pd.read_csv(root_dir+'depths.csv', index_col='id')\n        df = df.join(depths_df)\n\n        df = stratify_dataset(df, ['id', 'rle_mask', 'z'], 5)\n\n        train_df, val_df = split_by_fold(df, 0)\n\n        train_transforms = get_train_augs()\n        val_transforms   = get_val_augs()\n\n        self.train_dataset = SaltDataset(df=train_df, transforms=train_transforms)\n        self.valid_dataset = SaltDataset(df=val_df, transforms=val_transforms)\n        \n        self.loss = DiceLoss(mode = 'binary', log_loss = False)\n        self.losses_log = {\n            'train': [],\n            'val': []\n        }\n        self.metrics_log = {\n            'train': [],\n            'val': []\n        }\n\n    def forward(self, x):\n        return self.net(x)\n    \n    def training_step(self, batch, batch_nb) :\n        x, y = batch\n        y_hat = self.forward(x)\n        losses = self.loss(y_hat, y)\n        metrics = iou_torch(y_hat, y)\n        torch.cuda.empty_cache()\n        gc.collect\n        \n        return {'loss' : losses.mean(),\n                'metric': metrics.mean()}\n    \n    def validation_step(self, batch, batch_nb):\n        # OPTIONAL\n        x, y = batch\n        y_hat = self(x.float())\n        losses = self.loss(y_hat, y)\n        metrics = iou_torch(y_hat, y)\n        torch.cuda.empty_cache()\n        gc.collect\n\n        return {'val_loss' : losses.mean(),\n                'val_metric': metrics.mean()}\n    \n    def training_epoch_end(self, outputs):\n        # OPTIONAL\n\n        avg_losses = torch.tensor([x['loss'] for x in outputs]).mean()\n        self.losses_log['train'].append(avg_losses)\n        \n        avg_metrics = torch.tensor([x['metric'] for x in outputs]).mean()\n        self.metrics_log['train'].append(avg_metrics)\n        \n        print('epoch: %.0f | phase: train | loss: %.3f | metric: %.3f |'% (self.current_epoch, avg_losses, avg_metrics))\n        \n        tensorboard_logs = {'loss': avg_losses,\n                            'metric' : avg_metrics}\n        \n        return {'avg_loss': avg_losses,\n                'avg_metric': avg_metrics,\n                'log': tensorboard_logs}\n    \n    def validation_epoch_end(self, outputs):\n        # OPTIONAL\n        avg_losses = torch.tensor([x['val_loss'] for x in outputs]).mean()\n        self.losses_log['val'].append(avg_losses)\n        \n        avg_metrics = torch.tensor([x['val_metric'] for x in outputs]).mean()\n        self.metrics_log['val'].append(avg_metrics)\n        \n    \n        print('epoch: %.0f | phase: val | loss: %.3f | metric: %.3f |'% (self.current_epoch, avg_losses, avg_metrics))\n        \n        tensorboard_logs = {'val_loss': avg_losses,\n                            'val_metric' : avg_metrics}\n        \n        return {'avg_val_loss': avg_losses,\n                'avg_val_metric': avg_metrics,\n                'log': tensorboard_logs}\n    \n    \n    def configure_optimizers(self):\n        opt = torch.optim.Adam(self.net.parameters(),\n                               lr = self.learning_rate)\n        sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, \n                                                         mode = \"min\",\n                                                         factor = 0.3,\n                                                         patience = 5,\n                                                         verbose = True)\n        return [opt], [sch]\n    \n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(self.train_dataset,\n                                           batch_size = self.batch_size,\n                                           shuffle = True,\n                                           num_workers = self.num_workers)\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(self.valid_dataset,\n                                           batch_size = self.batch_size,\n                                           shuffle = False,\n                                           num_workers = self.num_workers)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:12.925189Z","iopub.execute_input":"2021-06-09T07:59:12.925536Z","iopub.status.idle":"2021-06-09T07:59:12.945027Z","shell.execute_reply.started":"2021-06-09T07:59:12.925502Z","shell.execute_reply":"2021-06-09T07:59:12.94393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SegModel()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:13.925665Z","iopub.execute_input":"2021-06-09T07:59:13.926161Z","iopub.status.idle":"2021-06-09T07:59:19.831299Z","shell.execute_reply.started":"2021-06-09T07:59:13.926118Z","shell.execute_reply":"2021-06-09T07:59:19.830398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    filepath = 'top_model_weights.ckpt',\n    save_top_k = 1,\n    verbose = True, \n    monitor = 'avg_val_metric',\n    mode = 'max')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:19.832893Z","iopub.execute_input":"2021-06-09T07:59:19.833303Z","iopub.status.idle":"2021-06-09T07:59:19.842872Z","shell.execute_reply.started":"2021-06-09T07:59:19.833243Z","shell.execute_reply":"2021-06-09T07:59:19.842064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = TensorBoardLogger(\n    \"lightning_logs\")","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:19.84463Z","iopub.execute_input":"2021-06-09T07:59:19.845027Z","iopub.status.idle":"2021-06-09T07:59:19.849225Z","shell.execute_reply.started":"2021-06-09T07:59:19.844987Z","shell.execute_reply":"2021-06-09T07:59:19.848292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(gpus = 1, \n                     max_epochs = 250, \n                     checkpoint_callback = checkpoint_callback,\n                     early_stop_callback = None,\n                     logger = logger,\n                     show_progress_bar = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:19.850886Z","iopub.execute_input":"2021-06-09T07:59:19.851267Z","iopub.status.idle":"2021-06-09T07:59:19.917419Z","shell.execute_reply.started":"2021-06-09T07:59:19.851232Z","shell.execute_reply":"2021-06-09T07:59:19.916654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fit**","metadata":{}},{"cell_type":"code","source":"trainer.fit(model)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:02:07.159Z","iopub.execute_input":"2021-06-09T08:02:07.159331Z","iopub.status.idle":"2021-06-09T08:07:57.758764Z","shell.execute_reply.started":"2021-06-09T08:02:07.159299Z","shell.execute_reply":"2021-06-09T08:07:57.757617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_path = checkpoint_callback.best_model_path\nprint(best_path)\npred_model = SegModel.load_from_checkpoint(best_path)\npred_model.eval()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:08:01.542823Z","iopub.execute_input":"2021-06-09T08:08:01.543153Z","iopub.status.idle":"2021-06-09T08:08:02.416219Z","shell.execute_reply.started":"2021-06-09T08:08:01.54312Z","shell.execute_reply":"2021-06-09T08:08:02.415283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/tgs-salt-identification-challenge/competition_data.zip\nclear_output()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-09T08:08:15.013942Z","iopub.execute_input":"2021-06-09T08:08:15.014281Z","iopub.status.idle":"2021-06-09T08:08:22.595929Z","shell.execute_reply.started":"2021-06-09T08:08:15.014247Z","shell.execute_reply":"2021-06-09T08:08:22.59501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(im):\n    \n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:08:34.63215Z","iopub.execute_input":"2021-06-09T08:08:34.632522Z","iopub.status.idle":"2021-06-09T08:08:34.640291Z","shell.execute_reply.started":"2021-06-09T08:08:34.632485Z","shell.execute_reply":"2021-06-09T08:08:34.639409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = \"./competition_data/test/images/\"\nsub_df = pd.read_csv('./competition_data/sample_submission.csv')\nn = sub_df.shape[0]\n\nrle_mask = []\nfor idx in range(n):\n    \n    sample_name = sub_df['id'][idx]\n    image = cv2.imread(str(image_path+sample_name+'.png'), cv2.IMREAD_COLOR)\n    image = val_transforms(image=image)['image']\n    \n    pred = pred_model(image.unsqueeze(0))\n    pred = (torch.sigmoid(pred) > 0.5).byte()\n    \n    rle_mask.append(rle_encode(pred.squeeze().numpy()))\n    print(\"\\rprogress {}/{}\".format(idx+1, n), end = \"\")\n    \nsub_df['rle_mask'] = rle_mask","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:08:52.602207Z","iopub.execute_input":"2021-06-09T08:08:52.602665Z","iopub.status.idle":"2021-06-09T08:09:08.594071Z","shell.execute_reply.started":"2021-06-09T08:08:52.602626Z","shell.execute_reply":"2021-06-09T08:09:08.591397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}