{"cells":[{"metadata":{"_uuid":"54ba903177a7625ce4047cb3b41abc605ba7058b"},"cell_type":"markdown","source":"### Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage.data import imread\nfrom pathlib import Path\nfrom tqdm import tqdm, tqdm_notebook\nimport cv2\nimport tensorflow as tf\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb375428b8f63581b4dc649a793bd09a57fb9be3"},"cell_type":"markdown","source":"#### Load train.csv"},{"metadata":{"trusted":true,"_uuid":"d101b1c5bda5afabcd9bc2ff9caaad215c69a595"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\", \n                    index_col = 0)\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d1155f5cc376ce05f4ae07d9b0517e529c104b2","scrolled":true},"cell_type":"code","source":"haveMask = ~(train.rle_mask.isna())\nhaveMask.sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac618d0f270332902e9ffaec8717b2eade2d91a8"},"cell_type":"markdown","source":"### Visualize 8 images with pixels having salt"},{"metadata":{"trusted":true,"_uuid":"4f6d05de384e22de9580f04d45d45fda4d6db2dd"},"cell_type":"code","source":"samples = train[haveMask].sample(8)\ntgs = \"../input\"\ntgs1 = \"../input/tgs-salt-identification-challenge\"\nfig, ax = plt.subplots(4, 4, sharex= \"col\", sharey = \"row\")\nfig.set_size_inches(12, 12)\nfor i, imgId in enumerate(samples.index):\n    row = (i*2)//4\n    col = (i*2)%4\n    \n    #show image\n    path = Path(tgs+\"/train/images\") / '{}.png'.format(imgId)\n    img = imread(path)\n    ax[row, col].imshow(img)\n    \n    #Show mask\n    path = Path(tgs+\"/train/masks\") / '{}.png'.format(imgId)\n    img = imread(path)\n    ax[row, col + 1].imshow(img, cmap = \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cac8fe15d4caed6a591a0cdccb4a763c71e90da6"},"cell_type":"markdown","source":"### Function which takes id of an image, reads it and returns ndarray"},{"metadata":{"trusted":true,"_uuid":"2220f2d298c1ddaafa21aeebfaf647a59a1d4200"},"cell_type":"code","source":"tgs = \"../input\"\ntgs1 = \"../input/tgs-salt-identification-challenge\"\ndef getImage(imgId):\n    path = Path(tgs+\"/train/images/\") / '{}'.format(imgId)\n    img = imread(path)\n    return img.astype(np.uint8)\n\ndef getGrayImage(imgId):\n    path = Path(tgs+\"/train/images/\")/'{}'.format(imgId)\n    img = imread(path).astype(np.uint8)\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    return img\n\ndef getGrayTestImage(imgId):\n    path = Path(tgs+\"/test/images/\")/'{}'.format(imgId)\n    img = imread(path).astype(np.uint8)\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    return img\n\ndef getMask(imgId):\n    path = Path(tgs+\"/train/masks/\") / '{}'.format(imgId)\n    img = imread(path)\n    return img.astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### Define Accuracy Metric\n[IoU Metric Explanation](https://www.kaggle.com/pestipeti/explanation-of-scoring-metric)"},{"metadata":{"trusted":true,"_uuid":"5845f5a118d9c6d0fc4169ec3d28fda594be2740"},"cell_type":"code","source":"thresholds = [0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]\nn_thresholds = len(thresholds)\n\n#function to return A∩B and A∪B\ndef IoUhelper(TrueMask, predictedMask):\n    intersection = cv2.bitwise_and(TrueMask, predictedMask)\n    union = cv2.bitwise_or(TrueMask, predictedMask)\n    intersectionCnt = cv2.countNonZero(intersection)\n    unionCnt = cv2.countNonZero(union)\n    return intersectionCnt, unionCnt\n\ndef meanHit(TrueMask, predictedMask):\n    hitCnt = 0\n    intersectionCnt, unionCnt = IoUhelper(TrueMask, predictedMask)\n#     print(\"intersction = \", intersectionCnt, \"unionCnt = \", unionCnt)\n    #if both TrueMask is empty and PredictedMask is empty\n    if(intersectionCnt == 0 and unionCnt == 0):\n        return 1\n    \n    #if TrueMask in empty and  Predicted mask in non empty\n    #--------------------OR-------------------------\n    #if TrueMask is non empty and Predicted Mask is empty\n    if(intersectionCnt == 0 and unionCnt != 0):\n        return 0\n    \n    #if TrueMask is non empty and predicted Mask is non emtpy\n    IoU = intersectionCnt/unionCnt\n    for t in thresholds:\n        hitCnt+=int(IoU > t)\n    return hitCnt/n_thresholds\n\ndef accuracy(mask, mask_pred):\n    num = mask.shape[0]\n    scores = []\n    for i in range(num):\n        score = meanHit(mask[i], mask_pred[i])\n        scores.append(score)\n        \n    return np.mean(scores)\n\n# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    y_pred_ = tf.to_int32(y_pred > 0.55)\n    y_true = tf.to_int32(y_true > 0.55)\n    for t in np.arange(0.5, 1.0, 0.05):\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\n\ndef get_iou_vector(A, B):\n    batch_size = A.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch]>0, B[batch]>0\n#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n#             metric.append(0)\n#             continue\n#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n#             metric.append(0)\n#             continue\n#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n#             metric.append(1)\n#             continue\n        \n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n        thresholds = np.arange(0.5, 1, 0.05)\n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        metric.append(np.mean(s))\n\n    return np.mean(metric)\n\ndef my_iou_metric(label, pred):\n    return -tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n\n## intersection over union\ndef IoU(y_true, y_pred, eps=1e-6):\n    if np.max(y_true) == 0.0:\n        return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n    return -K.mean( (intersection + eps) / (union + eps), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34560f0dac4eb4d1a9f28564cb7f26e88bda9d38"},"cell_type":"markdown","source":"#### Checking correctness of accuracy metric"},{"metadata":{"trusted":true,"_uuid":"a0d9f541ff63bada8eb25a4c810fc5ae4f7976c3"},"cell_type":"code","source":"# Testing accuracy metric\nfig, ax = plt.subplots(1, 3)\nfig.set_size_inches(12, 4)\n#Read an image with mask\nimgId = train[haveMask].index[4]\nimg1 = getImage(imgId+\".png\")\nimg2 = getMask(imgId+\".png\")\nimg3 = (np.ones(img2.shape)*255).astype(np.uint8)\n\nax[0].imshow(img1)\nax[0].set_title(\"Image\")\n\nax[1].imshow(img2, cmap = 'gray')\nax[1].set_title(\"True Mask\")\n\nax[2].imshow(img3, cmap = \"gray\", vmin = 0, vmax = 255)\nax[2].set_title(\"Predicted Mask\")\nprint(\"Average Precision = \",meanHit(img2, img3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d74a9c8a26c80742d42846703e342bc496b0e4e"},"cell_type":"markdown","source":"### rle_encoder\n> Function takes a mask and return string which contains rle_encoding<br>\n Funtion expects that mask only contains 0 and 255 as pixel value"},{"metadata":{"trusted":true,"_uuid":"e3d1d918274981f1a55b83d11fd3a7e90ec6da56"},"cell_type":"code","source":"def rle_encoding(mask):\n    mask = mask.ravel()\n    encoding = \"\"\n    i = 0\n\n    while(i<len(mask)):\n        currCnt = 0\n        start = i\n        if(mask[i] == 255):\n            while(i < len(mask) and mask[i] == 255):\n                currCnt+=1\n                i+=1\n                \n            encoding+=(\" \"+ str(start+1) + \" \" + str(currCnt))\n        else: i+=1\n    return encoding.strip()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23fe3ef87023b5e08da008e92311e8b2192ce31f"},"cell_type":"markdown","source":"#### Checking Correctness of Encoding Function\n- Note that encoding is done by taking transpose of image"},{"metadata":{"trusted":true,"_uuid":"60869f38a8c474af975a254acaf6bb52ddc673a6"},"cell_type":"code","source":"imgId = train[haveMask].index[18]\nrle_orig = train[haveMask].rle_mask[18]\nimg1 = getImage(imgId+\".png\")\nimg2 = getMask(imgId+\".png\")\nrle1 = rle_encoding(np.transpose(img2))\nprint(\"Original Encoding\\n\", rle_orig)\nprint(\"Len1 = \", len(rle_orig.split()))\nprint(\"-------\")\nprint(\"Encoding\\n\", rle1)\nprint(\"Len2 = \", len(rle1.split()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50a5907ecf14b0dc7e6c3069ba7aaea72b901934"},"cell_type":"markdown","source":"### Read Train and Test Image "},{"metadata":{"trusted":true,"_uuid":"f9e21d8d6f7cc59d26de2734e0c4e934ad85072c"},"cell_type":"code","source":"#Get the Directory\nTRAIN_IMAGE_DIR = tgs+'/train/images'\nTRAIN_MASK_DIR = tgs+'/train/masks'\nTEST_MASK_DIR = tgs+'/test/images'\n\nim_height = 128\nim_width = 128\n\ntrain_image_list = os.listdir(TRAIN_IMAGE_DIR)\ntrain_mask_list = os.listdir(TRAIN_MASK_DIR)\ntest_image_list = os.listdir(TEST_MASK_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5017941b421d2e33a877d7cb1803ceb13d59643d"},"cell_type":"code","source":"X_train_image = np.zeros((len(train_image_list), \n                         im_height, im_width, 1), dtype = np.uint8)\nY_train_mask = np.zeros((len(train_mask_list),\n                         im_height, im_width, 1), dtype = np.uint8)\n\nfor i in tqdm(range(len(train_image_list))):\n    imgId = train_image_list[i]\n    img = getGrayImage(imgId)\n    img = cv2.resize(img, (im_height, im_width))\n    X_train_image[i] = img.reshape(im_height, im_width, 1)\n\n    img = getMask(imgId)\n    img = cv2.resize(img, (im_height, im_width))\n    Y_train_mask[i] = img.reshape(im_height, im_width, 1)\n    \nprint(\"X_train Shape = \", X_train_image.shape, \"Y_train Shape = \", Y_train_mask.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"436451ebee274aeb9d962622f02adc074584f16c"},"cell_type":"markdown","source":"#####  Check if Data is loaded properly"},{"metadata":{"trusted":true,"_uuid":"2c6250df39003f03f36f0bdd5bac321801bdfce2"},"cell_type":"code","source":"# os.listdir(\"./\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cba1101e5bdc905f99c756e03723069f93f8734f"},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, sharex = \"col\", sharey= \"row\")\nfig.set_size_inches(8, 4)\n\nimg = X_train_image[70, :, :, 0]\nax[0].imshow(img, cmap = 'gray')\nax[1].imshow(Y_train_mask[70, :,:,0], cmap = \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12efae1ac282f7796773d5d1e60f06a28477f5b3"},"cell_type":"markdown","source":"### Data Augmentation ( Basic Augmentation)"},{"metadata":{"trusted":true,"_uuid":"303c33fbc44a0ac2e512940d79437b1bbadec408"},"cell_type":"code","source":"temp = np.array([[[[1, 3], [1, 2],[0, 2]]\n                ,[[0, 4], [0, 5],[2, 1]]],\n                [[[1, 2], [1, 6],[0, 12]]\n                ,[[1, 30], [1, 21],[1, 123]]],\n                [[[1, 90], [1, 91],[0, 32]]\n                ,[[1, 56], [1, 72],[1, 97]]]])\n# print(temp, \"\\n---\")\n# print(np.sum(temp, axis = 1), np.sum(temp, axis = 3).shape)\n# print(temp.shape)\n# # temp = np.append(temp, [[[[1, 10], [1, 11],[0, 70]]\n# #                 ,[[1, 67], [1, 43],[4, 324]]]], axis = 0)\n# print(temp.shape)\n# print(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44ec4706ed70a50e4c79e7183219292f2336515b"},"cell_type":"code","source":"# X_train_image1 = np.append(X_train_image, [np.fliplr(x) for x in X_train_image], axis = 0)\n# Y_train_mask1 = np.append(Y_train_mask, [np.fliplr(y) for y in Y_train_mask], axis = 0)\n# X_train_image = np.append(X_train_image1, [np.flipud(x) for x in X_train_image], axis = 0)\n# Y_train_mask = np.append(Y_train_mask1, [np.flipud(x) for x in Y_train_mask], axis = 0)\n# print(X_train_image.shape)\n# print(Y_train_mask.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e12f2a341953128603cebe97e51ea33401fb2b82"},"cell_type":"markdown","source":"#### Train Validation Split"},{"metadata":{"_uuid":"7965a221fa920073d417f71cc19aec00a6a21db9"},"cell_type":"markdown","source":"\n\n##### Step1.Count One(255) is a mask which will be used for assigning label to an image\n> Labels will be based on how many ones(or255) are there in a mask. "},{"metadata":{"trusted":true,"_uuid":"1b3c67908837c485ab43f97226fb74eef4cbb941"},"cell_type":"code","source":"temp = np.array([[[[1], [1],[0]]\n                ,[[0], [0],[2]]],\n                [[[1], [1],[0]]\n                ,[[1], [1],[1]]],\n                [[[1], [1],[0]]\n                ,[[1], [1],[1]]]])\n# print(temp[0])\nprint(temp,\"\\n\", temp.shape)\n\nnp.sum(np.count_nonzero(temp, axis = 2\n                ), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d035eabed8a3d861ac8bda9a7cb99026a20f6122"},"cell_type":"code","source":"print(X_train_image.dtype, Y_train_mask.dtype, X_train_image.shape, Y_train_mask.shape)\ncntOne = np.sum(np.count_nonzero(Y_train_mask, axis = 2), axis = 1).ravel()\nprint(cntOne.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c202fadb25052dad706637aee8ae54aa2bbba92"},"cell_type":"code","source":"#Checking correctness\nprint(np.count_nonzero(Y_train_mask[2]))\nprint(cntOne[2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7aabbf348a96b0490719161681c52315c638792"},"cell_type":"markdown","source":"##### Step2. Create Labels"},{"metadata":{"trusted":true,"_uuid":"9ceac4ee46baa23c0b68c939e2abba60f1ae7d91"},"cell_type":"code","source":"#Testing how to assign labels\nx = np.array([0, 1.0, 3.0, 1.6])\nbins = np.array([0, 1.0, 2.5, 4.0, 10.0])\ninds = np.digitize(x, bins)\nnp.unique(inds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"669370fcb0cd0f278eeaf84eb1daed4976d45ef5"},"cell_type":"code","source":"#Create Labels\nbins = np.array([0, 1600, 3200, 4800, 6400, 8000, 9600, 11200, 12800, 14400])\nlabels = np.digitize(cntOne, bins)\nprint(np.unique(labels), labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8220ba2636df541d6e3752d5eb493f6181a8532e"},"cell_type":"markdown","source":"##### Step3. Create Split"},{"metadata":{"trusted":true,"_uuid":"6622c371538aec29553a9d97eab1c62584c820fd"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, val_X, train_Y, val_Y = train_test_split(X_train_image, Y_train_mask,\n                                                  test_size = 0.1,\n                                                 random_state = 43, \n                                                 stratify = labels)\nprint(\"TrainX shape = \", train_X.shape, \"TrainY Shape = \", train_Y.shape)\nprint(\"ValidationX Shape = \", val_X.shape, \"ValidationY Shape = \", val_Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74877a3750456722219193a1542da29cd89f669f"},"cell_type":"markdown","source":"### Augmentation"},{"metadata":{"trusted":true,"_uuid":"64edb3f2046e3fb9ed6f5072f8b9578f7b9d6ea1","scrolled":true},"cell_type":"code","source":"def augment(X, Y):\n    print(\"FlipLR\")\n    X1 = np.append(X, [np.fliplr(x) for x in X], axis = 0)\n    Y1 = np.append(Y, [np.fliplr(y) for y in Y], axis = 0)\n    \n    print(\"Roll\")\n    X = np.append(X1, [np.roll(x, 40, axis = 1) for x in X1], axis = 0)\n    Y = np.append(Y1, [np.roll(y, 40, axis = 1) for y in Y1], axis = 0)\n\n    m = X.shape[0]\n    np.random.seed(2000)\n    index = np.arange(0, m)\n    np.random.shuffle(index)\n    print(\"Shuffle\")\n    X = X[index]\n    Y = Y[index]\n    return X, Y\n\nprint(\"Training Augmentation\")\ntrain_X, train_Y = augment(train_X, train_Y)\nval_X, val_Y = augment(val_X, val_Y)\nprint(train_X.shape, train_Y.shape)\nprint(val_X.shape, val_Y.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69f54f6a08d1eeafb7953fc0297f64f38ec02a73"},"cell_type":"markdown","source":"### Normalize"},{"metadata":{"trusted":true,"_uuid":"256dcfb9f4a91ad408a579dea2130d2220b5e3b3"},"cell_type":"code","source":"print(train_Y[70, :, :, 0])\ntrain_X = (train_X.astype(np.float32)/255.0)\ntrain_Y = (train_Y/255.0).astype(np.bool).astype(np.uint8)\nval_X = (val_X.astype(np.float32)/255.0)\nval_Y = (val_Y/255.0).astype(np.bool).astype(np.uint8)\nprint(train_X.dtype, train_Y.dtype)\nprint(train_Y[70, :, :, 0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e440b6279e4e1b576cc0450a66ea0eede2894408"},"cell_type":"markdown","source":"#### Training using Convolutional Neural Network"},{"metadata":{"trusted":true,"_uuid":"c731b218aa86c83a769819c2d1f5e03c0d3702fe"},"cell_type":"code","source":"import keras\n\n# config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU':8} ) \n# sess = tf.Session(config=config) \n# keras.backend.set_session(sess)\n\n# from keras import backend as K\n# K.tensorflow_backend._get_available_gpus()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d732f76bd83f389b9f83f9b36437d1f3451665d"},"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bee9a77caee2833a3f61d2b6ec52f8859a3c4960"},"cell_type":"code","source":"def batchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef residualBlock(blockInput, numChannel, matchChannel = False):\n    #inputs --> BN --> Relu\n    x = batchActivate(blockInput)\n    #blockInput --> BN --> Relu --> weights\n    x = Conv2D(numChannel, (3, 3), activation= None, padding = \"same\",\n               use_bias = False)(x)\n    #blockInput --> BN --> Relu --> weights --> BN --> Relu\n    x = batchActivate(x)\n    #blockInput --> BN --> Relu --> weights --> BN --> Relu --> weights\n    x = Conv2D(numChannel, (3, 3), activation=None, padding = \"same\", \n              use_bias = False)(x)\n    \n    #Match Channels\n    if matchChannel:\n        blockInput = Conv2D(numChannel, (1, 1), activation= None, padding = \"same\", \n                           use_bias = False)(x)\n    \n    #blockInput----------------------------------------------------|\n    #                                                              +\n    #                                                              |\n    #blockInput --> BN --> Relu --> weights --> BN --> Relu --> weights\n    x = Add()([x, blockInput])\n    #Not sure about this layer\n#     x = Activation('relu')(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bc8112c72e67d3cac730328c57de671b430c95c","scrolled":true},"cell_type":"code","source":"inputs = Input(shape = (im_height, im_width, 1))\n\n#Initaial layer\ninit = Conv2D(16, (7, 7), activation=\"relu\", padding = \"same\")(inputs)\n#Pending:One pool layer\n\n#128, 128\nconv1 = residualBlock(init, 16)\nconv1 = residualBlock(conv1, 16)\nc1 = residualBlock(conv1, 16)\nc1 = BatchNormalization()(c1)\n# c1 = Dropout(0.2)(c1)\np1 = MaxPooling2D(pool_size=(2, 2))(c1)\n\n#64, 64\nconv2 = residualBlock(p1, 32, True)\nc2 = residualBlock(conv2, 32)\nc2 = BatchNormalization()(c2)\n# c2 = Dropout(0.2)(c2)\np2 = MaxPooling2D(pool_size = (2, 2))(c2)\n# p2 = Dropout(0.1)(p2)\n\n#32, 32\nconv3 = residualBlock(p2, 64, True)\nc3 = residualBlock(conv3, 64)\nc3 = BatchNormalization()(c3)\n# c3 = Dropout(0.2)(c3)\np3 = MaxPooling2D(pool_size = (2, 2))(c3)\n# p3 = Dropout(0.1)(p3)\n\n#16, 16\nconv4 = residualBlock(p3, 128, True)\nc4 = residualBlock(conv4, 128)\nc4 = BatchNormalization()(c4)\n# c4 = Dropout(0.2)(c4)\np4 = MaxPooling2D(pool_size=(2, 2))(c4)\n# p4 = Dropout(0.1)(p4)\n\n#8, 8\nconv5 = residualBlock(p4, 256, True)\nconv5 = residualBlock(conv5, 256)\nconv5 = residualBlock(conv5, 256)\nc5 = residualBlock(conv5, 256)\nc5 = BatchNormalization()(c5)\n# p5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n\n\n# Start decoding-----------------\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), activation = \"relu\",\n                    padding = \"same\")(c5)\n#-----\n#16, 16\nu6 = concatenate([u6, c4])\nconv6 = residualBlock(u6, 128, True)\nconv6 = residualBlock(conv6, 128)\n#------\nu7 = Conv2DTranspose(64, (2, 2), strides = (2, 2,), activation = \"relu\",\n                     padding = \"same\")(conv6)\n#32, 32\nu7 = concatenate([u7, c3])\nconv7 = residualBlock(u7, 64, True)\nconv7 = residualBlock(conv7, 64)\n#------\nu8 = Conv2DTranspose(32, (2, 2), strides = (2, 2), activation = \"relu\",\n                     padding = \"same\")(conv7)\n#64, 64\nu8 = concatenate([u8, c2])\nconv8 = residualBlock(u8, 32, True)\nconv8 = residualBlock(conv8, 32)\n\n#---\nu9 = Conv2DTranspose(16, (2, 2), strides = (2, 2), activation = \"relu\",\n                     padding = \"same\")(conv8)\n#128, 128\nu9 = concatenate([u9, c1], axis=3)\nconv9 = residualBlock(u9, 16, True)\nconv9 = residualBlock(conv9, 16)\nconv9 = residualBlock(conv9, 16)\n\noutputs1 = Conv2D(16, (1, 1), activation = \"relu\", padding = \"same\")(conv9)\noutputs = Conv2D(1, (1, 1), activation = \"sigmoid\")(outputs1)\n\nmodel = Model(inputs = [inputs], outputs = [outputs])\noptimizer = keras.optimizers.Adam()\n\nmodel.compile(optimizer = optimizer, loss = \"binary_crossentropy\", \n              metrics = [my_iou_metric])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b89c5b958e0b29c7e78f0c7f0925032cb974f3a8","scrolled":true},"cell_type":"code","source":"import keras\nearlyStopping = EarlyStopping(patience = 20, verbose = 1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5',monitor = 'val_my_iou_metric', \n                               verbose=1, save_best_only=True)\nreducelr=ReduceLROnPlateau(monitor='val_my_iou_metric',patience=5, \n                            min_lr=0.00001, verbose=1,factor=0.5)\nepochs = 50\n\nbatch_size = 64\n\nhistory = model.fit(train_X , train_Y, epochs = epochs,\n                    batch_size = batch_size,\n                    validation_data = (val_X, val_Y),\n                    callbacks=[earlyStopping, checkpointer, reducelr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bb450d57c7c5931965bd53fec994635f2663482"},"cell_type":"code","source":"model1 = load_model(\"./model-tgs-salt-1.h5\",\n                   custom_objects = {'my_iou_metric':my_iou_metric})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"444240cd7c3b7331e185eb04ba7b04c70fcb73d6"},"cell_type":"code","source":"history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77f12c3e2209c93872c3dbb0ed974672e6eb81b3"},"cell_type":"code","source":"lr = history.history['lr']\nx = -1\nlr1 = []\nlrepoch = []\nfor (n,r) in enumerate(lr):\n    if r!=x:\n        lr1.append(r)\n        lrepoch.append(n + 1)\n        x = r","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b1bed453ebe5968a11834396e0796f5567e8204"},"cell_type":"code","source":"lrepoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9f4d02fa5e319fba4b7234ad3329975993a2ec2"},"cell_type":"code","source":"fig, (ax_loss, ax_acc) = plt.subplots(2, 1, sharex = 'col', sharey = 'row')\nfig.set_size_inches(15, 16)  #width, height\n\nax_loss.plot(history.history['loss'], label = 'train_loss')\nax_loss.plot(history.history['val_loss'], label = 'val_loss')\n# ax_loss.plot(history.history['lr'], label = 'learning_rate')\nax_loss.legend()\nplt.xticks(lrepoch)\nax_loss.grid(True, which = 'both')\nax_loss.set_xlabel(\"num_epoch\")\nax_loss.set_ylabel(\"loss/lr\")\nax_loss.set_title(\"Loss\")\nax_acc.plot(history.history['my_iou_metric'], label = 'train_metric')\nax_acc.plot(history.history['val_my_iou_metric'], label = \"val_metric\")\n# ax_acc.plot(history.history['lr'], label = 'learning_rate')\nax_acc.legend()\nax_acc.grid(True, which = 'both')\nplt.xticks(lrepoch)\nax_acc.set_xlabel(\"num_epoch\")\nax_acc.set_ylabel(\"acc/lr\")\nax_acc.set_title(\"iou metric\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"134a4764802e46f00c228f438b39e77b55f0e2b7"},"cell_type":"markdown","source":"### Predict model on some random validation set images"},{"metadata":{"trusted":true,"_uuid":"619c4eec88a8a6f3944f18cff7558f8a949c05f8"},"cell_type":"code","source":"print(X_train_image[12:13, :,:, 0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d9e0132e90f53453eab6403ab4393dcd9355bee"},"cell_type":"code","source":"samples = train[haveMask].sample(8)\nfig, ax = plt.subplots(3, 3, sharex = \"col\", sharey = \"row\")\nfig.set_size_inches(9, 9)\n\nindex = np.random.randint(1, 400, size = (3))\n\nfor i,ind in enumerate(index):\n    img = val_X[ind:ind+1, :, :]\n    origMask = val_Y[ind:ind+1, :, :]\n    predMask = model1.predict(img)\n    ax[i, 0].imshow(img[0, :, :, 0], cmap = 'gray')\n    ax[i, 0].set_title(str(ind))\n    ax[i, 1].imshow(origMask[0, :, :, 0], cmap = 'gray')\n    ax[i, 2].imshow(predMask[0, :, :, 0]>0.55\n                    , cmap = 'gray')\n    origMask = cv2.inRange(origMask[0, :, :, 0], 0.55, 255)\n    predMask = cv2.inRange(predMask[0, :, :, 0], 0.55, 255)\n    ax[i, 1].imshow(origMask, cmap = 'gray')\n    ax[i, 2].imshow(predMask, cmap = 'gray')\n    print(\"mean IoU = \", meanHit(origMask, predMask))\n\n# pred_mask = model.predict(X_train_image[22:23, :, :])\n# print(img.shape)\n# print(img[0,:,:])\n# plt.imshow(img[0,:,:,0]>0.5, cmap = \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62a1a42d95e8e13909e9fce68fb62e5a5e2e5432"},"cell_type":"markdown","source":"#### mean IoU on Validation Set"},{"metadata":{"trusted":true,"_uuid":"1f5753262277eb6a7b76a2673977ed8aca227d1f","scrolled":true},"cell_type":"code","source":"totIoU = 0.0\nm = val_X.shape[0]\n# print(\"m = \", m)\nfor i in tqdm(range(m)):\n    img = val_X[i:i+1, :, :]\n    origMask = val_Y[i:i+1, :, :]\n    predMask = model1.predict(img)\n    origMask = cv2.inRange(origMask[0, :, :, 0], 0.55, 255)\n    predMask = cv2.inRange(predMask[0, :, :, 0], 0.55, 255)\n    totIoU += meanHit(origMask, predMask)\n# print(\"totIoU=\", totIoU)\nprint(\"mean IoU = \", totIoU/m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b6079342a4e2e4fb7fd4380df813797b4c7b5d2"},"cell_type":"markdown","source":"---"},{"metadata":{"_uuid":"430e299c3faf4dbe40148509fecd6ad2225e16dd"},"cell_type":"markdown","source":"#### Load Test Image Data"},{"metadata":{"trusted":true,"_uuid":"21ea3e8cb61a94c45aba81f79387229cbd02e8a7"},"cell_type":"code","source":"X_test_image = np.zeros((len(test_image_list), im_height, \n                       im_width, 1), dtype = np.uint8)\nfor i in tqdm(range(len(test_image_list))):\n    imgId = test_image_list[i]\n    img = getGrayTestImage(imgId)\n    img = cv2.resize(img, (im_height, im_width))\n    X_test_image[i] = img.reshape(im_height, im_width, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ccdc672a90f42dfd178ce825d8687663752f92c"},"cell_type":"code","source":"X_test_image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96b270cbcbc283bdbbb45c074c4c154950c78012"},"cell_type":"code","source":"#Normalize \nX_test_image = X_test_image/255.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0eafb74931e2100bcce8040ea64d6956f8eded0b"},"cell_type":"markdown","source":"#### Predictiion on some random test images"},{"metadata":{"trusted":true,"_uuid":"2974c440e1d19c5e03c706d3de816427d57fecf1"},"cell_type":"code","source":"# Y_test = model.predict(X_test_image[14:15,:,:])\nfig, ax = plt.subplots(3, 2, sharex = \"col\", sharey = \"row\")\nfig.set_size_inches(12, 12)\n\nindex = np.random.randint(1, 18000, size = (3))\n\nfor i,ind in enumerate(index):\n    img = X_test_image[ind:ind+1, :, :]\n    predMask = model1.predict(img)\n    ax[i, 0].imshow(img[0, :, :, 0], cmap = 'gray')\n    predMask = cv2.inRange(predMask[0, :, :, 0], 0.5, 255)   #type uint8 shape:128,128\n    print(predMask.dtype)\n    ax[i, 1].imshow(predMask, cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7acb09704ede03a2cbd6f0f8872e9e2f06b77cf2"},"cell_type":"markdown","source":"#### Prepare submission file"},{"metadata":{"trusted":true,"_uuid":"35cae0d7e9403af68caaa2dde98e682acb9f1b86"},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"757aaa295aded2245cd73b2e71a7dd52480fde4a"},"cell_type":"code","source":"print(X_test_image[0].dtype\n     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d84aaafea63cd3cb0b863421593bbe6458ed51b5"},"cell_type":"code","source":"test_image_list[0][:-4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bf48e51a2e20ddd14ad5d304c987bb150d1124c"},"cell_type":"code","source":"origSize = (101, 101)\nsubmit_names = []\nsubmit_rleMasks = []\n\nfor i in tqdm(range(len(test_image_list))):\n    img = X_test_image[i:i+1,:,:]   #1, 128, 128, 1\n    predMask =  model1.predict(img)\n    predMask = cv2.inRange(predMask[0, :, :, 0], 0.55, 255)  #128, 128, uint8\n    predMask = cv2.resize(predMask, origSize)\n    submit_names.append(test_image_list[i][:-4])\n    submit_rleMasks.append(rle_encoding(np.transpose(predMask)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79d1e294599638fb7b282f390cd1e10471137448"},"cell_type":"code","source":"sub = pd.DataFrame({'id':submit_names, 'rle_mask': submit_rleMasks})\nprint(sub.shape)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c12016e6053c02d3f6efefd2d05f55f3f9e45bcc"},"cell_type":"code","source":"#Replace emtpy rle_mask with np.nan\nfor i in tqdm(range(len(test_image_list))):\n    if(len(sub.iloc[i, 1]) == 0):\n        sub.iloc[i, 1] = np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f8c02bb3fb243572214a94f65251d980d1a05c1"},"cell_type":"code","source":"print(sub.shape)\nsub.head(n = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2abf64e5701c027ebe97e4d02b3225e0d5f3718b"},"cell_type":"code","source":"# img = getGrayTestImage(\"604e99b0c6.png\")\nprint(img.shape)\nind = 213\nfig ,ax = plt.subplots(1, 2, sharex = \"col\", sharey = \"row\")\nimg = X_test_image[ind:ind+1, :, :]\nax[0].imshow(img[0, :, :, 0], cmap = \"gray\")\npredMask = model1.predict(img)\nax[1].imshow(predMask[0,:,:,0]>0.55, cmap = \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9abb29cc7a2a890ea93c6f992c43d704a3908d0d"},"cell_type":"code","source":"sub.to_csv(\"tgsModel1.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7b91e5a935924a21d9c826c90335ed79a54ef21"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}