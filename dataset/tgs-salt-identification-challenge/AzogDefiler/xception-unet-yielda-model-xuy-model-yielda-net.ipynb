{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# basic Xception Unet Yielda model; XUY model(XYU model) or simply Yielda net model"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4b62ca91d324d6732b0a6114387a9d473b071e2"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom random import randint\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.transform import resize\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b184f3a6398c225392553ae74d4816f7f8b83fd2"},"cell_type":"code","source":"img_size_ori = 101\nimg_size_target = 101\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85f0af599be4f376df037526a6e3075aecbb67f2"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n\ntrain_df = train_df.join(depths_df)\n\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da4d8768d0b103072b5cc3d459f760cc25c02b2d"},"cell_type":"code","source":"len(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd66fedf607aa92820ac4ef89b84a2de748ab25e"},"cell_type":"code","source":"train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=False)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbb7bf4d321c4bb775b761619e440ec6ffbe9d9d"},"cell_type":"code","source":"train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38abe61149a0bfc1378d1bf83f0c70e7f1a26380"},"cell_type":"code","source":"# Simple split of images into training and testing sets\nids_train, ids_valid, x_train, x_valid, y_train, y_valid = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.tolist()).reshape(-1, img_size_target, img_size_target, 3), \n    np.array(train_df.masks.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    test_size=0.1, random_state=1234 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ca80c0f8b19a0d94c50f02d1460a5a8246d1fd5a"},"cell_type":"code","source":"from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications import Xception, InceptionResNetV2\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e297aaf36f82fd2b053412675abd950ca163150e"},"cell_type":"code","source":"base_model = Xception( include_top=False, input_shape=((101,101,3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"96d25168f99360f397324f3b212a9d6219323c38"},"cell_type":"code","source":"def conv_block_simple(prevlayer, filters, strides=(1, 1)):\n    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides)(prevlayer)\n    conv = BatchNormalization()(conv)\n    conv = Activation('relu')(conv)\n    return conv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2d89b4dbaa7dae4dbf73419bcd8f0b7fa3f3ecac"},"cell_type":"code","source":"def build_model(start_neurons=16):\n    \n    for l in base_model.layers:\n        l.trainable = True\n    #--------------------------------------------------------------------------------------\n    conv0 = base_model.get_layer('block1_conv1_act').output # 50\n    conv1 = base_model.get_layer('block2_sepconv2_bn').output # 48\n    conv2 = base_model.get_layer('block3_sepconv2_bn').output # 24\n    conv3 = base_model.get_layer('block4_sepconv2_bn').output # 12\n    conv4_1 = base_model.get_layer('block5_sepconv1').output # 6\n    conv4 = base_model.get_layer('block13_sepconv2_bn').output # 6\n    conv5 = base_model.get_layer('conv2d_4').output # 3 ----- ебанашка керас, не норм. имя, всегда разное\n    conv6 = base_model.get_layer('block14_sepconv2_act').output # 3\n    \n    midlle = concatenate([conv5, conv6], axis=-1)\n    convm = conv_block_simple(midlle, start_neurons * 16)\n    convm = conv_block_simple(convm, start_neurons * 16)\n    \n    deconv1 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    deconv1 = concatenate([deconv1, conv4])\n    deconv1 = conv_block_simple(deconv1, start_neurons * 8)\n    deconv1 = conv_block_simple(deconv1, start_neurons * 8)\n    deconv1 = concatenate([deconv1, conv4_1])\n    deconv1 = conv_block_simple(deconv1, start_neurons * 8)\n    \n    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv1)\n    deconv2 = concatenate([deconv2, conv3])\n    deconv2 = conv_block_simple(deconv2, start_neurons * 4)\n    deconv2 = conv_block_simple(deconv2, start_neurons * 4)\n    \n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv2)\n    deconv3 = concatenate([deconv3, conv2])\n    deconv3 = conv_block_simple(deconv3, start_neurons * 4)\n    deconv3 = conv_block_simple(deconv3, start_neurons * 4)\n    \n    deconv4 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(deconv3)\n    deconv4 = concatenate([deconv4, conv1])\n    deconv4 = conv_block_simple(deconv4, start_neurons * 2)\n    deconv4 = conv_block_simple(deconv4, start_neurons * 2)\n    \n    deconv5 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(1, 1), padding=\"valid\")(deconv4)\n    deconv5 = concatenate([deconv5, conv0])\n    deconv5 = conv_block_simple(deconv5, start_neurons * 1)\n    deconv5 = conv_block_simple(deconv5, start_neurons * 1)    \n    \n    inp = base_model.input\n    deconv6 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(deconv5)\n    deconv6 = concatenate([deconv6, inp])\n    deconv6 = conv_block_simple(deconv6, start_neurons * 1)\n    deconv6 = conv_block_simple(deconv6, start_neurons * 1)     \n    \n    output = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(deconv6)\n    \n    return Model(base_model.input, output)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d84746169ee08b0a72661c7a3d8d651d00d31a2"},"cell_type":"code","source":"model = build_model(start_neurons=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ffa64d14e75882195d621feb05a4345614af3986"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4229c02dd88869431e94ddf1c54cbb9ae9e2b51b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"28f2f130803f114671efbc07b2391f465613b577"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5c33a9f75e3b01cd41cef5d1cd3709b7dfd4be70"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"880d092a1c1cd9c1cd08cb606194c1832cbb3928"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e34874196e38c73c015399d2c0f8dd541eb53c6e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1fb54b53b29183c1787b9bb29de4f186fa27877f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2e85bfb5763447c93cce2ecea17b0cc4fc670aaf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"056d4d76da296e73b3d40d332c9508d174b967c6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b45d3090a4bf010fefef46b36a65f0f1565914e7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1485bdf6da9f5179ecd262fc1b3927bf7e7133d5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"884626d2eb967399080e3696707b90bdde6a0211"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"82f444942c685f8598597bde9e255a2efce4bd7c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"81b939349d6f310f64f19f995edc549bbce74e4e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c618184165569d6443b3b5f14163ca4f1aad7bf7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0909e8afabb413f341520df1dcd9eaaa2fe563e4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0a9cead081444364c0870e0c0cef2b7da3650a5d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c40ed8b8f309761db5d0e7cbf6931c318fbbc4ed"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2b7582c7f215d16627d7561aecac14e50051d556"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ee1050fefbcfe59c95cfaf1d316ce86b452401f5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}