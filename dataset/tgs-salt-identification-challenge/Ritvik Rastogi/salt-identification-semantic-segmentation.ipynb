{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, sys, random, warnings, math\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nfrom tqdm.auto import tqdm, trange\nfrom itertools import chain\n\nimport cv2\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import models, Input, layers, callbacks, utils, optimizers, applications","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class config:\n    im_width = 128\n    im_height = 128\n    im_chan = 1\n    path_train = 'train/'\n    path_test = 'test/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"! unzip -q ../input/tgs-salt-identification-challenge/train.zip -d train/\n! unzip -q ../input/tgs-salt-identification-challenge/test.zip -d test/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(19)\nids = random.choices(os.listdir('train/images'), k=6)\nfig = plt.figure(figsize=(20,6))\nfor j, img_name in enumerate(ids):\n    q = j+1\n    \n    img = load_img('train/images/' + img_name)\n    img_mask = load_img('train/masks/' + img_name)\n    \n    plt.subplot(2, 6, q*2-1)\n    plt.imshow(img)\n    plt.subplot(2, 6, q*2)\n    plt.imshow(img_mask)\nfig.suptitle('Sample Images', fontsize=24);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ids = next(os.walk(config.path_train+\"images\"))[2]\ntest_ids = next(os.walk(config.path_test+\"images\"))[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.zeros((len(train_ids), config.im_height, config.im_width, config.im_chan), dtype=np.uint8)\nY = np.zeros((len(train_ids), config.im_height, config.im_width, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    x = img_to_array(load_img(config.path_train + '/images/' + id_, color_mode=\"grayscale\"))\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X[n] = x\n    mask = img_to_array(load_img(config.path_train + '/masks/' + id_, color_mode=\"grayscale\"))\n    Y[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\nprint('Done!')\nprint('X shape:', X.shape)\nprint('Y shape:', Y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Augmentation and Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X[:int(0.9*len(X))]\nY_train = Y[:int(0.9*len(X))]\nX_eval  = X[int(0.9*len(X)):]\nY_eval  = Y[int(0.9*len(X)):]\n\nX_train = np.append(X_train, [np.fliplr(x) for x in X], axis=0)\nY_train = np.append(Y_train, [np.fliplr(x) for x in Y], axis=0)\nX_train = np.append(X_train, [np.flipud(x) for x in X], axis=0)\nY_train = np.append(Y_train, [np.flipud(x) for x in Y], axis=0)\n# X_train = np.append(X_train, [np.rot90(x, k=1) for x in X], axis=0)\n# Y_train = np.append(Y_train, [np.rot90(x, k=1) for x in Y], axis=0)\n# X_train = np.append(X_train, [np.rot90(x, k=3) for x in X], axis=0)\n# Y_train = np.append(Y_train, [np.rot90(x, k=3) for x in Y], axis=0)\n\ndel X, Y\n\nprint('X train shape:', X_train.shape, 'X eval shape:', X_eval.shape)\nprint('Y train shape:', Y_train.shape, 'Y eval shape:', Y_eval.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = layers.BatchNormalization()(x)\n    if activation == True:\n        x = layers.LeakyReLU(alpha=0.1)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = layers.LeakyReLU(alpha=0.1)(blockInput)\n    x = layers.BatchNormalization()(x)\n    blockInput = layers.BatchNormalization()(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = layers.Add()([x, blockInput])\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def UXception(input_shape=(None, None, 3)):\n\n    backbone = applications.Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n    input_layer = backbone.input\n    start_neurons = 16\n\n    conv4 = backbone.layers[121].output\n    conv4 = layers.LeakyReLU(alpha=0.1)(conv4)\n    pool4 = layers.MaxPooling2D((2, 2))(conv4)\n    pool4 = layers.Dropout(0.1)(pool4)\n    \n     # Middle\n    convm = layers.Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = layers.LeakyReLU(alpha=0.1)(convm)\n    \n    # 10 -> 20\n    deconv4 = layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = layers.concatenate([deconv4, conv4])\n    uconv4 = layers.Dropout(0.1)(uconv4)\n    \n    uconv4 = layers.Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = layers.LeakyReLU(alpha=0.1)(uconv4)\n    \n    # 10 -> 20\n    deconv3 = layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    conv3 = backbone.layers[31].output\n    uconv3 = layers.concatenate([deconv3, conv3])    \n    uconv3 = layers.Dropout(0.1)(uconv3)\n    \n    uconv3 = layers.Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = layers.LeakyReLU(alpha=0.1)(uconv3)\n\n    # 20 -> 40\n    deconv2 = layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    conv2 = backbone.layers[21].output\n    conv2 = layers.ZeroPadding2D(((1,0),(1,0)))(conv2)\n    uconv2 = layers.concatenate([deconv2, conv2])\n        \n    uconv2 = layers.Dropout(0.1)(uconv2)\n    uconv2 = layers.Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = layers.LeakyReLU(alpha=0.1)(uconv2)\n    \n    # 40 -> 80\n    deconv1 = layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    conv1 = backbone.layers[11].output\n    conv1 = layers.ZeroPadding2D(((3,0),(3,0)))(conv1)\n    uconv1 = layers.concatenate([deconv1, conv1])\n    \n    uconv1 = layers.Dropout(0.1)(uconv1)\n    uconv1 = layers.Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = layers.LeakyReLU(alpha=0.1)(uconv1)\n    \n    \n    # 80 -> 160\n    uconv0 = layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n    uconv0 = layers.Dropout(0.1)(uconv0)\n    uconv0 = layers.Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = layers.LeakyReLU(alpha=0.1)(uconv0)\n    \n    uconv0 = layers.Dropout(0.1/2)(uconv0)\n    output_layer = layers.Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n    \n    model = models.Model(input_layer, output_layer)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer = Input(shape=(config.im_height, config.im_width, 1))\nscaled = layers.Lambda(lambda x: x / 255) (input_layer)\nx = layers.Conv2D(3, 1, activation='relu', padding='same')(scaled)\noutput_layer = UXception(input_shape=(config.im_height, config.im_width, 3))(x)\n\nmodel = models.Model(input_layer, output_layer)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_model(model, expand_nested=True, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = callbacks.EarlyStopping(patience=30, verbose=1, restore_best_weights=True)\nrlp = callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-12, verbose=1)\n\nresults = model.fit(\n    X_train, Y_train, validation_data=(X_eval, Y_eval), batch_size=8, epochs=300, callbacks=[es, rlp]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nfig, ax = plt.subplots(2, 1, figsize=(20, 8))\nhistory = pd.DataFrame(results.history)\nhistory[['loss', 'val_loss']].plot(ax=ax[0])\nhistory[['acc', 'val_acc']].plot(ax=ax[1])\nfig.suptitle('Learning Curve', fontsize=24);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scoring"},{"metadata":{"trusted":true},"cell_type":"code","source":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_eval = model.predict(X_eval, verbose=1)\n\nthresholds = np.linspace(0, 1, 50)\nious = np.array([iou_metric_batch(Y_eval, np.int32(preds_eval > threshold)) for threshold in tqdm(thresholds)])\n\nthreshold_best_index = np.argmax(ious[9:-10]) + 9\niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get and resize test images\nX_test = np.zeros((len(test_ids), config.im_height, config.im_width, config.im_chan), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    x = img_to_array(load_img(config.path_test + '/images/' + id_, color_mode=\"grayscale\"))\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test = model.predict(X_test, verbose=1)\npreds_test_upsampled = []\nfor i in trange(len(preds_test)):\n    preds_test_upsampled.append(resize(\n        np.squeeze(preds_test[i]), (sizes_test[i][0], sizes_test[i][1]),  mode='constant', preserve_range=True\n    ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf train\n!rm -rf test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {\n    fn[:-4]:RLenc(np.round(preds_test_upsampled[i] > threshold_best)) \n    for i,fn in tqdm(enumerate(test_ids), total=len(test_ids))\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}