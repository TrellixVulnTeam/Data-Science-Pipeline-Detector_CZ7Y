{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torchvision import models\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torchvision import transforms as T\nfrom torchvision.utils import make_grid\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nimport numbers\nfrom PIL import Image, ImageOps\nimport math\nimport zipfile\nimport matplotlib.image as mpimg\nfrom collections import defaultdict\nimport time\nfrom tqdm.notebook import tqdm\nimport albumentations as A #great data augmentation lib\nimport cv2\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install torchsummary\nfrom torchsummary import summary\n! pip install segmentation-models-pytorch\nimport segmentation_models_pytorch as smp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Input Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"/kaggle/input/tgs-salt-identification-challenge/train.zip\") as z:\n    z.extractall(\"./train/\")\nwith zipfile.ZipFile(\"/kaggle/input/tgs-salt-identification-challenge/test.zip\") as z:\n    z.extractall(\"./test/\")\n# ! unzip \"/kaggle/input/tgs-salt-identification-challenge/train.zip\" -d './train/'\n# ! unzip \"/kaggle/input/tgs-salt-identification-challenge/test.zip\" -d './test/'\nprint('unzip finished')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAIN_CSV = '/kaggle/input/tgs-salt-identification-challenge/train.csv'\nDEPTH_CSV = '/kaggle/input/tgs-salt-identification-challenge/depths.csv'\n\nTRAIN_IMAGE_DIR = '/kaggle/working/train/images/'\nTRAIN_MASK_DIR = '/kaggle/working/train/masks/'\n\nTEST_IMAGE_DIR = '/kaggle/working/test/images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_CSV)\ndf_depth = pd.read_csv(DEPTH_CSV)\n\ndf = pd.merge(df_depth, df_train)\ndf['salt'] = df['rle_mask'].notnull().replace([False, True], [0,1]) #0 = no_salt #1 = salt\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_salt = df[df['rle_mask'].isnull()]\nsalt = df[df['rle_mask'].notnull()]\n\n# dist = (len(no_salt), len(salt))\n# plt.bar([0,1], dist, color=['g', 'b'])\nsns.countplot(df['salt'])\nplt.xticks(ticks= [0,1], labels=['no salt', 'salt'])\nplt.title('Label Distribution'); plt.ylabel('count')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(no_salt), len(salt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(salt['z'], label='Salt', bins=30, color='y')\nsns.distplot(no_salt['z'], label='No Salt', bins=30, color='b')\nplt.title('Depth Distribution')\nplt.xlabel('Depth'); plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check sample image\nfig = plt.figure(figsize=(20, 5))\n\nrand_idx = np.random.randint(0, 4000, 20) #generate random indexes\n\nfor i, file in enumerate(rand_idx):\n    ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks = [])\n    figs = df['id'][file]\n    img = mpimg.imread(f'/kaggle/working/train/images/{figs}.png')\n    mask = mpimg.imread(f'/kaggle/working/train/masks/{figs}.png')\n    ax.imshow(img[:,:,0], cmap='seismic')\n    ax.imshow(mask, alpha=0.35, cmap='gray')\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Constum Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Seismic(Dataset):\n    def __init__(self, img_root, mask_root, X, transform=None):\n        self.img_dir = img_root\n        self.mask_dir = mask_root\n        self.X = X\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        \n        img_id = self.X[idx]\n        \n        img_path = self.img_dir + str(img_id) + \".png\"\n        mask_path = self.mask_dir + str(img_id) + \".png\"\n        \n#         img = Image.open(img_path).resize((128, 128))\n#         mask = Image.open(mask_path).resize((128, 128))\n        img = cv2.imread(img_path)\n        img = cv2.resize(img, (128,128))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        mask = cv2.imread(mask_path)\n        mask = cv2.resize(mask, (128,128))\n        \n        if self.transform is not None:\n            aug = self.transform(image=img, mask=mask) #transform image and mask\n            \n            img = Image.fromarray(aug['image'])\n            mask = Image.fromarray(aug['mask']).convert('L') #convert to 1channel\n            \n            t = T.ToTensor()\n            img = t(img)\n            mask = t(mask)\n        \n        if self.transform is None:\n            img = Image.fromarray(img)\n            mask = Image.fromarray(mask).convert('L')\n            \n            t = T.ToTensor()\n            img = t(img)\n            mask = t(mask)\n        return img, mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Augmentation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Split Data Train/Val/Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainval, X_test, y_trainval, y_test = train_test_split(df['id'].values, df['salt'].values,\n                                                          stratify=df['salt'].values, \n                                                          test_size=0.05, random_state=97)\n\nX_train, X_val = train_test_split(X_trainval, stratify=y_trainval, \n                                  test_size=0.1, random_state=97)\n\nlen(X_train), len(X_val), len(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img = cv2.imread(TRAIN_IMAGE_DIR+\"f59821d067.png\")\n# mask = cv2.imread(TRAIN_MASK_DIR+\"f59821d067.png\")\n# #aug = A.ElasticTransform()\n# #img = cv2.resize(img, (128,128))\n# trans = transform(image=img, mask=mask)\n# plt.imshow(trans['image'], cmap='seismic')\n# plt.imshow(trans['mask'], alpha=0.2, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Compose([A.HorizontalFlip(), \n                       A.VerticalFlip(),\n                       A.RandomRotate90(), \n                       A.OpticalDistortion(),\n                       A.Transpose()])\n\ntrain_set = Seismic(TRAIN_IMAGE_DIR, TRAIN_MASK_DIR, X_train, transform=transform)\nval_set = Seismic(TRAIN_IMAGE_DIR, TRAIN_MASK_DIR, X_val, transform)\ntest_set = Seismic(TRAIN_IMAGE_DIR, TRAIN_MASK_DIR, X_test, transform=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imge = Image.open(TRAIN_IMAGE_DIR+'351ea99ec3'+'.png')\n# masks = Image.open(TRAIN_MASK_DIR+'351ea99ec3'+'.png')\n# t = Compose([RandomRotate(30)])\n# imgs, masks = t(imge, masks)\n# # t = T.ToTensor()\n# # img = t(imge)\n# #mask /= 65535.\n# imgs.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, mask = test_set[21]\nprint(\"Image_size: \", img.size())\nprint(\"Mask_size: \", mask.size())\nprint('Max Pixel Image Val:', img.max())\nprint('Max Pixel mask Val:', mask.max())\nplt.imshow(img[0], cmap='seismic')\nplt.imshow(mask[0], alpha=0.5, cmap='gray');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check dataset with augmentation\nfig = plt.figure(figsize=(10, 5))\n\nrand_idx = np.random.randint(0, 3420, 10) #generate random indexes\n\nfor i, file in enumerate(rand_idx):\n    image, mask = train_set[file]\n    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks = [])\n    ax.imshow(image[0], cmap='seismic')\n    ax.imshow(mask[0], cmap='gray', alpha=0.3)\n\nplt.tight_layout(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataloader","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataloader\nbatch_size = 32\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_batch(dl):\n    for images, mask in dl:\n        fig, ax = plt.subplots(figsize=(20, 20))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0), cmap='seismic')\n        ax.imshow(make_grid(mask, nrow=16).permute(1, 2, 0), alpha=0.5)\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_batch(train_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## U-NET With Resnet18 Encoder from Scratch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, in_channel, mid_channel, out_channel):\n        super(Decoder, self).__init__()\n        \n        self.conv = nn.Conv2d(in_channel, mid_channel, kernel_size=3, stride=1, padding=1) #keep ratio\n        self.conv_trans = nn.ConvTranspose2d(mid_channel, out_channel, kernel_size=4, stride=2, padding=1)\n        \n    def forward(self, x):\n        x = F.relu(self.conv(x), inplace=True)\n        x = F.relu(self.conv_trans(x), inplace=True)\n        return x\n    \nclass Unet_resnet18(nn.Module):\n    def __init__(self, n_classes):\n        super(Unet_resnet18, self).__init__()\n        \n        #encoder\n        self.encoder = models.resnet18(pretrained=True)\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv1 = nn.Sequential(self.encoder.conv1, self.encoder.bn1,\n                                  self.encoder.relu, self.pool) #64\n        self.conv2 = self.encoder.layer1 #64\n        self.conv3 = self.encoder.layer2 #128\n        self.conv4 = self.encoder.layer3 #256\n        self.conv5 = self.encoder.layer4 #depth 512\n        \n        #center\n        self.center = Decoder(512, 312, 256)\n        \n        #decoder\n        self.decoder5 = Decoder(256+512, 256, 256)\n        self.decoder4 = Decoder(256+256, 128, 128)\n        self.decoder3 = Decoder(128+128, 64, 64)\n        self.decoder2 = Decoder(64+64, 32, 32)\n        self.decoder1 = Decoder(32, 16, 16)\n        self.decoder0 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n    \n        self.final = nn.Conv2d(8, n_classes, kernel_size=1)\n        \n    def forward(self, x):\n        \n        #encoder\n        conv1 = self.conv1(x) #64x64\n        conv2 = self.conv2(conv1) #32x32\n        conv3 = self.conv3(conv2) #16x16\n        conv4 = self.conv4(conv3) #8x8\n        conv5 = self.conv5(conv4) #4x4\n        \n        center = self.center(self.pool(conv5)) #4x4\n        #decoder\n        dec5 = self.decoder5(torch.cat([center, conv5], 1)) #8x8\n        dec4 = self.decoder4(torch.cat([dec5, conv4], 1)) #16x16\n        dec3 = self.decoder3(torch.cat([dec4, conv3], 1)) #32x32\n        dec2 = self.decoder2(torch.cat([dec3, conv2], 1)) #64x64\n        dec1 = self.decoder1(dec2) #128x128\n        dec0 = F.relu(self.decoder0(dec1))\n        \n        final = torch.sigmoid(self.final(dec0))\n        \n        return final\n    \nmodel_res18 = Unet_resnet18(1)\nmodel_res18.to(device)\nmodel_res18.train()\nmodel_res18\n#summary(test, (3, 128, 128) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resnet34 (The Easy Way)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_res34 = smp.Unet('resnet34', classes=1, activation='sigmoid')\nmodel_res34.to(device)\nmodel_res34.train()\nmodel_res34","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training\n## Help Functions\n### Costum Loss Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##loval loss :https://github.com/bermanmaxim/LovaszSoftmax/blob/master/pytorch/lovasz_losses.py\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = scores.view(-1)\n    labels = labels.view(-1)\n    if ignore is None:\n        return scores, labels\n    valid = (labels != ignore)\n    vscores = scores[valid]\n    vlabels = labels[valid]\n    return vscores, vlabels\n\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    p = len(gt_sorted)\n    gts = gt_sorted.sum()\n    intersection = gts - gt_sorted.float().cumsum(0)\n    union = gts + (1 - gt_sorted).float().cumsum(0)\n    jaccard = 1. - intersection / union\n    if p > 1: # cover 1-pixel case\n        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n    return jaccard\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n                          for log, lab in zip(logits, labels))\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n    if len(labels) == 0:\n        # only void pixels, the gradients should be 0\n        return logits.sum() * 0.\n    signs = 2. * labels.float() - 1.\n    errors = (1. - logits * Variable(signs))\n    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n    perm = perm.data\n    gt_sorted = labels[perm]\n    grad = lovasz_grad(gt_sorted)\n    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n    return loss\n\n#PyTorch\nclass LovaszHingeLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(LovaszHingeLoss, self).__init__()\n\n    def forward(self, inputs, targets):\n        #inputs = F.sigmoid(inputs)    \n        Lovasz = lovasz_hinge(inputs, targets, per_image=False)                       \n        return Lovasz\n    \n##Dice Loss\nclass DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1e-5):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        #inputs = torch.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n        \n        return 1 - dice","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Costum Metrices","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(output, mask):\n    ps = torch.exp(output)\n    _, top_class = ps.topk(1, dim=1)\n    correct = top_class == mask.view(*top_class.shape)\n    score = torch.mean(correct.type(torch.FloatTensor)).item()\n    return score\n\n\ndef IoU_score(inputs, targets, smooth=1e-5):\n    #flatten label and prediction tensors\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n\n    #intersection is equivalent to True Positive count\n    #union is the mutually inclusive area of all labels & predictions \n    intersection = (inputs * targets).sum()\n    total = (inputs + targets).sum()\n    union = total - intersection \n\n    IoU = (intersection + smooth)/(union + smooth)\n    \n    return IoU\n\ndef Dice_score(inputs, targets, smooth=1e-5):\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n\n    intersection = (inputs * targets).sum()                            \n    dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n    \n    return dice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler):\n    torch.cuda.empty_cache()\n    train_losses = []\n    test_losses = []\n    val_iou = []; val_dice = [];\n    train_iou = []; train_dice = [];\n    lrs = []\n    \n    model.to(device)\n    fit_time = time.time()\n    for e in range(epochs):\n        since = time.time()\n        running_loss = 0\n        iou_score = 0\n        dice_score = 0\n        #training loop\n        for image, mask in train_loader:\n            #training phase\n            model.train()\n            image = image.to(device); mask = mask.to(device);\n            #forward\n            output = model(image)\n            loss = criterion(output, mask)\n            \n            #score\n            iou_score += IoU_score(output, mask).item()\n            dice_score += Dice_score(output, mask).item()\n            \n            #backward\n            loss.backward() \n            optimizer.step() #update weight          \n            optimizer.zero_grad() #reset gradient\n            \n            #step the learning rate\n            lrs.append(get_lr(optimizer))\n            scheduler.step() \n        \n            running_loss += loss.item()\n            \n        else:\n            model.eval()\n            test_loss = 0\n            total_train = 0\n            correct_train = 0\n            val_iou_score = 0\n            val_dice_score = 0\n            #validation loop\n            with torch.no_grad():\n                for image, mask in val_loader:\n                    image = image.to(device); mask = mask.to(device);\n                    output = model(image)\n                    #score\n                    val_iou_score +=  IoU_score(output, mask).item()\n                    val_dice_score += Dice_score(output, mask).item()\n                    #loss\n                    loss = criterion(output, mask)                                  \n                    test_loss += loss.item()\n            \n            #calculatio mean for each batch\n            train_losses.append(running_loss/len(train_loader))\n            test_losses.append(test_loss/len(val_loader))\n            #iou\n            val_iou.append(val_iou_score/len(val_loader))\n            train_iou.append(iou_score/len(train_loader))\n            #dice\n            val_dice.append(val_dice_score/len(val_loader))\n            train_dice.append(dice_score/len(train_loader))\n        \n            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n                  \"Train IoU/Dice:{:.3f}/{:.3f}..\".format((iou_score/len(train_loader)),(dice_score/len(train_loader))),\n                  \"Val IoU/Dice: {:.3f}/{:.3f}..\".format((val_iou_score/len(val_loader)),(val_dice_score/len(val_loader))), \n                  \"Time: {:.2f}s\".format((time.time()-since)))\n        \n    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n               'train_dice':train_dice, 'val_dice': val_dice,\n               'train_iou' :train_iou, 'val_iou':val_iou, \n               'lrs': lrs}\n    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n    return history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training (Learning Time) ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Resnet18","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#model resnet18\nmodel_res18 = Unet_resnet18(n_classes=1)\nmodel_res18.to(device)\nmodel_res18.train()\n\nmax_lr = 1e-3 #1e-4\nepoch = 20\nweight_decay = 1e-4\n\ncriterion = nn.BCELoss()\noptimizer18 = torch.optim.AdamW(model_res18.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer18, max_lr, epochs=epoch,\n                                            steps_per_epoch=len(train_loader))\n\nhistory18 = fit(epoch, model_res18, train_loader, val_loader, criterion, optimizer18, sched)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using DiceLoss()\nepoch = 20\nmax_lr = 1e-5 #1e-4\n\ncriterion_dice = DiceLoss()\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer18, max_lr, epochs=epoch,\n                                            steps_per_epoch=len(train_loader))\nhistory18_dice = fit(epoch, model_res18, train_loader, val_loader, \n                     criterion_dice, optimizer18, sched)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_history(history18, history18_dice):\n    t_loss = history18['train_loss'] + history18_dice['train_loss']\n    v_loss = history18['val_loss'] + history18_dice['val_loss']\n    t_dice = history18['train_dice'] + history18_dice['train_dice']\n    v_dice = history18['val_dice'] + history18_dice['val_dice']\n    t_iou = history18['train_iou'] + history18_dice['train_iou']\n    v_iou = history18['val_iou'] + history18_dice['val_iou']\n    lr = history18['lrs'] + history18_dice['lrs']\n    comb = {'train_loss':t_loss, 'val_loss':v_loss, 'train_dice':t_dice,\n            'val_dice':v_dice, 'train_iou':t_iou, 'val_iou':v_iou, 'lrs':lr}\n    return comb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_resnet18 = combine_history(history18, history18_dice)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# epoch = 10\n# max_lr = 1e-5 #1e-4\n\n# criterion_lovasz = LovaszHingeLoss()\n# sched = torch.optim.lr_scheduler.OneCycleLR(optimizer18, max_lr, epochs=epoch,\n#                                             steps_per_epoch=len(train_loader))\n# history18_lovasz = fit(epoch, model_res18, train_loader, val_loader, \n#                        criterion_lovasz, optimizer18, sched)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model_res18.state_dict(), 'model_resnet18.pth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resnet34","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#model resnet34\nmodel_res34 = smp.Unet('resnet34', classes=1, activation='sigmoid')\nmodel_res34.to(device)\nmodel_res34.train()\n\nmax_lr = 1e-3 #1e-4\nepoch = 20\nweight_decay = 1e-4\n\ncriterion = nn.BCELoss()\noptimizer34 = torch.optim.AdamW(model_res34.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer34, max_lr, epochs=epoch,\n                                            steps_per_epoch=len(train_loader))\n\nhistory34 = fit(epoch, model_res34, train_loader, val_loader, criterion, optimizer34, sched)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_lr = 1e-5 #1e-4\nepoch = 20\n\ncriterion_dice34 = DiceLoss()\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer34, max_lr, epochs=epoch,\n                                            steps_per_epoch=len(train_loader))\n\nhistory34_dice = fit(epoch, model_res34, train_loader, val_loader, \n                criterion_dice34, optimizer34, sched)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_resnet34 = combine_history(history34, history34_dice)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model_res34.state_dict(), 'unet_resnet34.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loss(x, history):\n    plt.plot(x, history['val_loss'], label='val', marker='o')\n    plt.plot(x, history['train_loss'], label='train', marker='o')\n    plt.title('Loss per epoch'); plt.ylabel('loss');\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n    \ndef plot_score(x, history):\n    plt.plot(x, history['train_dice'], label='train_dice', marker='x')\n    plt.plot(x, history['val_dice'], label='val_dice', marker='x')\n    plt.plot(x, history['train_iou'], label='train_iou', marker='*')\n    plt.plot(x, history['val_iou'], label='val_iou',  marker='*')\n    plt.title('Score per epoch'); plt.ylabel('score')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RESNET18')\nplot_loss(np.arange(1,41), history_resnet18)\nplot_score(np.arange(1,41), history_resnet18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RESNET34')\nplot_loss(np.arange(1,41), history_resnet34)\nplot_score(np.arange(1,41), history_resnet34)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(model, image, mask, threshold):\n    model.eval()\n    with torch.no_grad():\n        model.to(device)\n        image = image.to(device)\n        mask = mask.to(device)\n        image = image.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        \n        predict = model(image) > threshold\n        score = IoU_score(predict, mask)\n        predict = predict.squeeze(0).squeeze(0)\n    return predict.cpu(), score.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load model state_dict()\nunet_resnet18 = Unet_resnet18(n_classes=1)\nunet_resnet18.load_state_dict(torch.load('model_resnet18.pth'))\n\nunet_resnet34 = smp.Unet('resnet34', classes=1, activation='sigmoid')\nunet_resnet34.load_state_dict(torch.load('unet_resnet34.pth'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding Best Threshold","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"thre = np.linspace(0.4, 0.9, 15)\nIoU_mean = []\nfor thres in thre:\n    IoU = 0\n    for image, mask in val_set:\n        _, score = predict_image(unet_resnet18, image, mask, thres)\n        IoU += score\n    IoU_mean.append(IoU/len(val_set))\n\niou_score = pd.DataFrame({\"Threshold\": thre, \"IoU_score\": IoU_mean})\niou_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(thre, IoU_mean)\nplt.plot(thre[np.argmax(IoU_mean)], np.max(IoU_mean), marker='x',\n        label='Best Threshold {:.3f}'.format(thre[np.argmax(IoU_mean)]))\nplt.grid(); plt.ylabel('IoU Score'); plt.xlabel('Threshold');\nplt.title('Best Threshold Finder')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation Using Test Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score_all = []\nfor image, mask in test_set:\n    _, score = predict_image(unet_resnet18, image, mask, threshold=0.5) #threshold can be different in datasets\n    score_all.append(score)\nprint('IoU score over all test set Resnet18: ',np.mean(score_all))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_all = []\nfor image, mask in test_set:\n    _, score = predict_image(unet_resnet34, image, mask, threshold=0.5) #threshold can be different in datasets\n    score_all.append(score)\nprint('IoU score over all test set Resnet34: ',np.mean(score_all))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test single image\ndef plot_predict_image(idx):\n    image, mask = test_set[idx]\n    mask_pre, score = predict_image(unet_resnet34, image, mask, threshold=0.5)\n\n    #plot\n    fig = plt.figure(figsize=(15, 5))\n    plt.subplot(1, 4, 1)\n    plt.imshow(image[0], cmap='seismic')\n    plt.contour(mask[0], cmap='Greens')\n    plt.title('Seismic'); plt.axis('off')\n    \n    plt.subplot(1, 4, 2)\n    plt.imshow(mask_pre)\n    plt.title('Predict Mask | score: {:.3f}'.format(score))\n    plt.axis('off')\n    \n    plt.subplot(1, 4, 3)\n    plt.imshow(mask[0])\n    plt.title('Ground truth')\n    plt.axis('off');\n    \n    plt.subplot(1, 4, 4)\n    plt.imshow(mask_pre, cmap='Greens')\n    plt.imshow(mask[0], alpha=0.5)\n    plt.title('Overlay Predict and Ground truth')\n    plt.axis('off');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = [159, 173, 53, 94]\nfor i in a:\n    plot_predict_image(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install jovian\nimport jovian\njovian.commit(project= 'salt-segmentation', privacy='private')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}