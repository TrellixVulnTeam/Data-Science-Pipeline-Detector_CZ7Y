{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dependencies","metadata":{"id":"RHrEnmXXuAqp"}},{"cell_type":"code","source":"# ! pip install torch==1.8.1 torchvision==0.9.1 wandb pandas\n!pip install wandb --upgrade\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"id":"GsMh9gXCuDvs","executionInfo":{"status":"ok","timestamp":1621694234530,"user_tz":-420,"elapsed":11755,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"outputId":"d59b8a32-f37d-478d-c693-9fbd06b7e245","execution":{"iopub.status.busy":"2021-06-09T02:53:38.502988Z","iopub.execute_input":"2021-06-09T02:53:38.503312Z","iopub.status.idle":"2021-06-09T02:53:51.374046Z","shell.execute_reply.started":"2021-06-09T02:53:38.503283Z","shell.execute_reply":"2021-06-09T02:53:51.373037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set run variable","metadata":{"id":"S9sHeWonusKS"}},{"cell_type":"code","source":"# Model config ======\nRUN_NAME        = 'unetv1'\nN_CLASSES       = 1\nINPUT_SIZE      = 128\nEPOCHS          = 10\nLEARNING_RATE   = 0.0001\nSTART_FRAME     = 16\nDROP_RATE       = 0.5\n\n# Data config =======\nSAVE_PATH       = './'\nDATA_PATH       = './'\nIMAGE_PATH      = 'train/images/'\nMASK_PATH       = 'train/masks/'\n\nRANDOM_SEED     = 42\nVALID_RATIO     = 0.2\nBATCH_SIZE      = 16\nNUM_WORKERS     = 0\nCLASSES         = {1:'salt'}","metadata":{"id":"WiHs2pTTurcO","executionInfo":{"status":"ok","timestamp":1621697800851,"user_tz":-420,"elapsed":279,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:51.375833Z","iopub.execute_input":"2021-06-09T02:53:51.37637Z","iopub.status.idle":"2021-06-09T02:53:51.382683Z","shell.execute_reply.started":"2021-06-09T02:53:51.376327Z","shell.execute_reply":"2021-06-09T02:53:51.381718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download dataset & setup env variable","metadata":{"id":"4l6zd98_t83H"}},{"cell_type":"code","source":"!unzip ../input/tgs-salt-identification-challenge/train.zip -d ./train\nclear_output()","metadata":{"id":"APFvHa-izy7N","executionInfo":{"status":"ok","timestamp":1621694254346,"user_tz":-420,"elapsed":6128,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:51.384647Z","iopub.execute_input":"2021-06-09T02:53:51.385289Z","iopub.status.idle":"2021-06-09T02:53:53.11252Z","shell.execute_reply.started":"2021-06-09T02:53:51.385251Z","shell.execute_reply":"2021-06-09T02:53:53.111643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, dataloader, random_split\n\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"id":"ubrHowZdwVIC","executionInfo":{"status":"ok","timestamp":1621694254348,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:53.114326Z","iopub.execute_input":"2021-06-09T02:53:53.114706Z","iopub.status.idle":"2021-06-09T02:53:53.254681Z","shell.execute_reply.started":"2021-06-09T02:53:53.114666Z","shell.execute_reply":"2021-06-09T02:53:53.253847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nimport os\nimport time\n\n# login wandb\nos.environ['WANDB_API_KEY'] = '2a291fe931b1a2be33e1c09cb5b86dcd6843ea48'","metadata":{"id":"BOj2S47At8Xb","executionInfo":{"status":"ok","timestamp":1621694255031,"user_tz":-420,"elapsed":692,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:53.255931Z","iopub.execute_input":"2021-06-09T02:53:53.256307Z","iopub.status.idle":"2021-06-09T02:53:53.70728Z","shell.execute_reply.started":"2021-06-09T02:53:53.256266Z","shell.execute_reply":"2021-06-09T02:53:53.706371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from distutils.dir_util import copy_tree\n\nfromDir = '../input/tgs-salt-identification-challenge'\ntoDir = './'\n\ncopy_tree(fromDir, toDir)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:53:53.708703Z","iopub.execute_input":"2021-06-09T02:53:53.709051Z","iopub.status.idle":"2021-06-09T02:53:58.148652Z","shell.execute_reply.started":"2021-06-09T02:53:53.709008Z","shell.execute_reply":"2021-06-09T02:53:58.147911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataset & Dataloader","metadata":{"id":"29k9PXE-v2Oh"}},{"cell_type":"code","source":"class TGSDataset(Dataset):\n    \"\"\"TGS Salt Identification dataset.\"\"\"\n    \n    def __init__(self, root_dir=DATA_PATH, transform=None):\n        \"\"\"\n        Args:\n            root_path (string): Directory with all the images.\n            transformer (function): whether to apply the data augmentation scheme\n                mentioned in the paper. Only applied on the train split.\n        \"\"\"\n\n        # load dataset from root dir\n        train_df  = pd.read_csv(root_dir+'train.csv', index_col='id')\n        depths_df = pd.read_csv(root_dir+'depths.csv', index_col='id')\n        train_df = train_df.join(depths_df)\n\n        self.root_dir   = root_dir\n        self.ids        = train_df.index\n        self.depths     = train_df['z'].to_numpy()\n        self.rle        = train_df['rle_mask'].to_numpy()\n        \n        if transform is None:\n            self.transfrom = transforms.Compose([transforms.Resize((INPUT_SIZE, INPUT_SIZE)), \n                                                  transforms.Grayscale(), \n                                                  transforms.ToTensor(),])\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, index):\n        id    = self.ids[index]\n        depth = self.depths[index]\n\n        # file should be unzipped\n        image = Image.open(self.root_dir+IMAGE_PATH+id+'.png')\n        mask  = Image.open(self.root_dir+MASK_PATH+id+'.png')\n    \n        image = self.transfrom(image)\n        mask  = self.transfrom(mask)\n\n        return image, mask","metadata":{"id":"q16CF46Qvzto","executionInfo":{"status":"ok","timestamp":1621697626305,"user_tz":-420,"elapsed":286,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.149896Z","iopub.execute_input":"2021-06-09T02:53:58.150207Z","iopub.status.idle":"2021-06-09T02:53:58.160255Z","shell.execute_reply.started":"2021-06-09T02:53:58.15018Z","shell.execute_reply":"2021-06-09T02:53:58.159159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloader(dataset, \n                    batch_size=BATCH_SIZE, random_seed=RANDOM_SEED, \n                    valid_ratio=VALID_RATIO, shuffle=True, num_workers=NUM_WORKERS):\n    \"\"\"\n    Params:\n    -------\n    - dataset: the dataset.\n    - batch_size: how many samples per batch to load.\n    - random_seed: fix seed for reproducibility.\n    - valid_ratio: percentage split of the training set used for\n      the validation set. Should be a float in the range [0, 1].\n    - shuffle: whether to shuffle the train/validation indices.\n    - num_workers: number of subprocesses to use when loading the dataset.\n    \"\"\"\n\n    error_msg = \"[!] valid_ratio should be in the range [0, 1].\"\n    assert ((valid_ratio >= 0) and (valid_ratio <= 1)), error_msg\n\n    # split the dataset\n    n = len(dataset)\n    n_valid = int(valid_ratio*n)\n    n_train = n - n_valid\n\n    # init random seed\n    torch.manual_seed(random_seed)\n\n    train_dataset, valid_dataset = random_split(dataset, (n_train, n_valid))\n\n    train_loader = DataLoader(train_dataset, batch_size, shuffle=shuffle, num_workers=num_workers)\n    valid_loader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, valid_loader\n","metadata":{"id":"be0VG8-Wt6vj","executionInfo":{"status":"ok","timestamp":1621694271645,"user_tz":-420,"elapsed":390,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.163401Z","iopub.execute_input":"2021-06-09T02:53:58.164081Z","iopub.status.idle":"2021-06-09T02:53:58.171876Z","shell.execute_reply.started":"2021-06-09T02:53:58.164041Z","shell.execute_reply":"2021-06-09T02:53:58.170898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load dataset\ndataset = TGSDataset(DATA_PATH)\ntrainloader, validloader = get_dataloader(dataset=dataset)","metadata":{"id":"nG7TDzrjwbJK","executionInfo":{"status":"ok","timestamp":1621697629609,"user_tz":-420,"elapsed":306,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.174271Z","iopub.execute_input":"2021-06-09T02:53:58.174686Z","iopub.status.idle":"2021-06-09T02:53:58.239611Z","shell.execute_reply.started":"2021-06-09T02:53:58.174651Z","shell.execute_reply":"2021-06-09T02:53:58.238864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_dataset(dataset, n_sample=4):\n    \"\"\"Visualize dataset with n_sample\"\"\"\n    fig = plt.figure()\n\n    # show image\n    for i in range(n_sample):\n        image, mask = dataset[i]\n        image = transforms.ToPILImage()(image)\n        mask = transforms.ToPILImage()(mask)\n        print(i, image.size, mask.size)\n\n\n        plt.tight_layout()\n        ax = plt.subplot(1, n_sample, i + 1)\n        ax.set_title('Sample #{}'.format(i))\n        ax.axis('off')\n\n        plt.imshow(image, cmap=\"Greys\")\n        plt.imshow(mask, alpha=0.3, cmap=\"OrRd\")\n\n        if i == n_sample-1:\n            plt.show()\n            break","metadata":{"id":"97-udxulwa_3","executionInfo":{"status":"ok","timestamp":1621695981788,"user_tz":-420,"elapsed":704,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.240778Z","iopub.execute_input":"2021-06-09T02:53:58.241109Z","iopub.status.idle":"2021-06-09T02:53:58.247868Z","shell.execute_reply.started":"2021-06-09T02:53:58.241072Z","shell.execute_reply":"2021-06-09T02:53:58.246693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_dataset(dataset)","metadata":{"id":"nIn4gCavwx1x","executionInfo":{"status":"ok","timestamp":1621697633053,"user_tz":-420,"elapsed":680,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"outputId":"1d76c503-a9c4-4ba8-e058-3abe09c5b73d","execution":{"iopub.status.busy":"2021-06-09T02:53:58.249238Z","iopub.execute_input":"2021-06-09T02:53:58.249901Z","iopub.status.idle":"2021-06-09T02:53:58.597377Z","shell.execute_reply.started":"2021-06-09T02:53:58.249864Z","shell.execute_reply":"2021-06-09T02:53:58.596584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unet & block","metadata":{"id":"HHR6v-3Vw6PD"}},{"cell_type":"code","source":"class BatchActivate(nn.Module):\n    def __init__(self, num_features):\n        super(BatchActivate, self).__init__()\n        self.norm = nn.BatchNorm2d(num_features)\n\n    def forward(self, x):\n        return F.relu(self.norm(x))\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel=3, padding=1, stride=1, activation=True):\n        super(ConvBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n                            kernel_size=kernel, stride=stride, padding=padding)\n        self.batchnorm  = BatchActivate(out_channels)\n        self.activation = activation\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.activation:\n            x = self.batchnorm(x)\n        return x\n\nclass DoubleConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel=3, padding=1, stride=1):\n        super(DoubleConvBlock, self).__init__()\n        self.conv1 = ConvBlock(in_channels, out_channels, kernel, padding, stride)\n        self.conv2 = ConvBlock(out_channels, out_channels, kernel, padding, stride)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, batch_activation=False):\n        super(ResidualBlock, self).__init__()\n        self.batch_activation = batch_activation\n        self.norm  = nn.BatchNorm2d(num_features=in_channels)\n        self.conv1 = ConvBlock(in_channels, in_channels, kernel=3, stride=1, padding=1)\n        self.conv2 = ConvBlock(in_channels, in_channels, kernel=3, stride=1, padding=1, activation=False)\n\n    def forward(self, x):\n        residual = x\n        x = self.norm(x)\n        x = self.conv1(x)\n        x = self.conv2(x)\n\n        x += residual\n        # x = x.view(x.size(0),-1)\n        \n        if self.batch_activation:\n            x = self.norm(x)\n        \n        return x\n","metadata":{"id":"skw2Boqiw50M","executionInfo":{"status":"ok","timestamp":1621694288387,"user_tz":-420,"elapsed":383,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.598516Z","iopub.execute_input":"2021-06-09T02:53:58.598864Z","iopub.status.idle":"2021-06-09T02:53:58.612317Z","shell.execute_reply.started":"2021-06-09T02:53:58.598824Z","shell.execute_reply":"2021-06-09T02:53:58.611385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unet original","metadata":{}},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, in_channels=1, n_classes=N_CLASSES, start_fm=START_FRAME):\n        super(UNet, self).__init__()\n        # Input 1x128x128\n\n        # Maxpool \n        self.pool = nn.MaxPool2d((2,2))\n\n        # Transpose conv\n        self.deconv_4  = nn.ConvTranspose2d(start_fm*16, start_fm*8, 2, 2)\n        self.deconv_3  = nn.ConvTranspose2d(start_fm*8, start_fm*4, 2, 2)\n        self.deconv_2  = nn.ConvTranspose2d(start_fm*4, start_fm*2, 2, 2)\n        self.deconv_1  = nn.ConvTranspose2d(start_fm*2, start_fm, 2, 2)\n        \n        # Encoder \n        self.encoder_1 = DoubleConvBlock(in_channels, start_fm, kernel=3)\n        self.encoder_2 = DoubleConvBlock(start_fm, start_fm*2, kernel=3)\n        self.encoder_3 = DoubleConvBlock(start_fm*2, start_fm*4, kernel=3)\n        self.encoder_4 = DoubleConvBlock(start_fm*4, start_fm*8, kernel=3)\n\n        # Middle\n        self.middle = DoubleConvBlock(start_fm*8, start_fm*16)\n        \n        # Decoder\n        self.decoder_4 = DoubleConvBlock(start_fm*16, start_fm*8)\n        self.decoder_3 = DoubleConvBlock(start_fm*8, start_fm*4)\n        self.decoder_2 = DoubleConvBlock(start_fm*4, start_fm*2)\n        self.decoder_1 = DoubleConvBlock(start_fm*2, start_fm)\n\n        self.conv_last = nn.Conv2d(start_fm, n_classes, 1)\n\n    def forward(self, x):\n        # Encoder\n        conv1 = self.encoder_1(x)\n        x     = self.pool(conv1)\n\n        conv2 = self.encoder_2(x)\n        x     = self.pool(conv2)\n\n        conv3 = self.encoder_3(x)\n        x     = self.pool(conv3)\n\n        conv4 = self.encoder_4(x)\n        x     = self.pool(conv4)\n\n        # Middle\n        x     = self.middle(x)\n\n        # Decoder\n        x     = self.deconv_4(x)\n        x     = torch.cat([conv4, x], dim=1)\n        x     = self.decoder_4(x)\n\n        x     = self.deconv_3(x)\n        x     = torch.cat([conv3, x], dim=1)\n        x     = self.decoder_3(x)\n\n        x     = self.deconv_2(x)\n        x     = torch.cat([conv2, x], dim=1)\n        x     = self.decoder_2(x)\n\n        x     = self.deconv_1(x)\n        x     = torch.cat([conv1, x], dim=1)\n        x     = self.decoder_1(x)\n        \n        out   = self.conv_last(x)\n        return out","metadata":{"id":"LfW3pr0Yw0jy","executionInfo":{"status":"ok","timestamp":1621694299447,"user_tz":-420,"elapsed":273,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.614153Z","iopub.execute_input":"2021-06-09T02:53:58.614975Z","iopub.status.idle":"2021-06-09T02:53:58.630746Z","shell.execute_reply.started":"2021-06-09T02:53:58.61493Z","shell.execute_reply":"2021-06-09T02:53:58.630024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unet Res","metadata":{}},{"cell_type":"code","source":"class UNet_ResNet(nn.Module):\n    def __init__(self, in_channels=1, n_classes=N_CLASSES, dropout=0.5, start_fm=START_FRAME):\n        super(UNet_ResNet, self).__init__()\n\n        # Encoder \n        self.encoder_1 = nn.Sequential(\n            nn.Conv2d(in_channels, start_fm, 3, padding=(1,1)),\n            ResidualBlock(start_fm),\n            ResidualBlock(start_fm, batch_activation=True),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout2d(dropout//2),\n        )\n\n        self.encoder_2 = nn.Sequential(\n            nn.Conv2d(start_fm, start_fm*2, 3, padding=(1,1)),\n            ResidualBlock(start_fm*2),\n            ResidualBlock(start_fm*2, batch_activation=True),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout2d(dropout),\n        )\n\n        self.encoder_3 = nn.Sequential(\n            nn.Conv2d(start_fm*2, start_fm*4, 3, padding=(1,1)),\n            ResidualBlock(start_fm*4),\n            ResidualBlock(start_fm*4, batch_activation=True),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout2d(dropout),\n        )\n        \n        self.encoder_4 = nn.Sequential(\n            nn.Conv2d(start_fm*4, start_fm*8, 3, padding=(1,1)),\n            ResidualBlock(start_fm*8),\n            ResidualBlock(start_fm*8, batch_activation=True),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout2d(dropout),\n        )\n\n        self.middle = nn.Sequential(\n            nn.Conv2d(start_fm*8, start_fm*16, 3, padding=3//2),\n            ResidualBlock(start_fm*16),\n            ResidualBlock(start_fm*16, batch_activation=True),\n            nn.MaxPool2d((2,2))\n        )\n        \n        # Transpose conv\n        self.deconv_4  = nn.ConvTranspose2d(start_fm*16, start_fm*8, 2, 2)\n        self.deconv_3  = nn.ConvTranspose2d(start_fm*8, start_fm*4, 2, 2)\n        self.deconv_2  = nn.ConvTranspose2d(start_fm*4, start_fm*2, 2, 2)\n        self.deconv_1  = nn.ConvTranspose2d(start_fm*2, start_fm, 2, 2)\n\n        # Decoder \n        self.decoder_4 = nn.Sequential(\n            nn.Dropout2d(dropout),\n            nn.Conv2d(start_fm*16, start_fm*8, 3, padding=(1,1)),\n            ResidualBlock(start_fm*8),\n            ResidualBlock(start_fm*8, batch_activation=True),\n        )\n\n        self.decoder_3 = nn.Sequential(\n            nn.Dropout2d(dropout),\n            nn.Conv2d(start_fm*8, start_fm*4, 3, padding=(1,1)),\n            ResidualBlock(start_fm*4),\n            ResidualBlock(start_fm*4, batch_activation=True),\n        )\n\n        self.decoder_2 = nn.Sequential(\n            nn.Dropout2d(dropout),\n            nn.Conv2d(start_fm*4, start_fm*2, 3, padding=(1,1)),\n            ResidualBlock(start_fm*2),\n            ResidualBlock(start_fm*2, batch_activation=True),\n        )\n\n        self.decoder_1 = nn.Sequential(\n            nn.Dropout2d(dropout),\n            nn.Conv2d(start_fm*2, start_fm, 3, padding=(1,1)),\n            ResidualBlock(start_fm),\n            ResidualBlock(start_fm, batch_activation=True),\n            nn.ConvTranspose2d(start_fm, start_fm, 2, 2)\n        )\n            \n        self.conv_last = nn.Conv2d(start_fm, n_classes, 1)\n\n    def forward(self, x):\n        # Encoder\n        conv1 = self.encoder_1(x)\n\n        conv2 = self.encoder_2(conv1)\n\n        conv3 = self.encoder_3(conv2)\n\n        conv4 = self.encoder_4(conv3)\n\n        # Middle\n        x     = self.middle(conv4)\n\n        # Decoder\n        x     = self.deconv_4(x)\n        x     = torch.cat([conv4, x], dim=1)\n        x     = self.decoder_4(x)\n\n        x     = self.deconv_3(x)\n        x     = torch.cat([conv3, x], dim=1)\n        x     = self.decoder_3(x)\n\n        x     = self.deconv_2(x)\n        x     = torch.cat([conv2, x], dim=1)\n        x     = self.decoder_2(x)\n\n        x     = self.deconv_1(x)\n        x     = torch.cat([conv1, x], dim=1)\n        x     = self.decoder_1(x)\n        \n        out   = (self.conv_last(x))\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:53:58.632208Z","iopub.execute_input":"2021-06-09T02:53:58.63261Z","iopub.status.idle":"2021-06-09T02:53:58.656681Z","shell.execute_reply.started":"2021-06-09T02:53:58.63257Z","shell.execute_reply":"2021-06-09T02:53:58.655821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start train\n## Helper function","metadata":{"id":"0Wq4Y-IvxKH0"}},{"cell_type":"code","source":"def labels():\n  l = {}\n  for i, label in enumerate(CLASSES):\n    l[i] = label\n  return l\n\ndef tensor2np(tensor):\n    tensor = tensor.squeeze().cpu()\n    return tensor.detach().numpy()\n\ndef normtensor(tensor):\n    tensor = torch.where(tensor<0., torch.zeros(1).cuda(), torch.ones(1).cuda())\n    return tensor\n\ndef wandb_mask(bg_imgs, pred_masks, true_masks):\n    # bg_imgs    = [np.array(transforms.ToPILImage()(image)) for image in bg_imgs]\n    # pred_masks = [np.array(transforms.ToPILImage()(image)) for image in pred_masks]\n    # true_masks = [np.array(transforms.ToPILImage()(image)) for image in true_masks]\n\n    return wandb.Image(bg_imgs, masks={\n        \"predictions\" : {\n            \"mask_data\" : pred_masks,\n            \"class_labels\" : CLASSES\n            },\n        \"ground_truth\" : {\n            \"mask_data\" : true_masks, \n            \"class_labels\" : CLASSES\n            }\n        })\n    \ndef count_params(model):\n    pytorch_total_params = sum(p.numel() for p in model.parameters())\n    return pytorch_total_params","metadata":{"id":"Gx6M0IBCxJ6c","executionInfo":{"status":"ok","timestamp":1621697816592,"user_tz":-420,"elapsed":539,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.658084Z","iopub.execute_input":"2021-06-09T02:53:58.658592Z","iopub.status.idle":"2021-06-09T02:53:58.668265Z","shell.execute_reply.started":"2021-06-09T02:53:58.65855Z","shell.execute_reply":"2021-06-09T02:53:58.667063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train & Eval function","metadata":{"id":"ivgiP_D0xe5W"}},{"cell_type":"code","source":"def cal_iou(outputs, labels, SMOOTH=1e-6):\n    with torch.no_grad():\n        outputs = outputs.squeeze(1).bool()  # BATCH x 1 x H x W => BATCH x H x W\n        labels = labels.squeeze(1).bool()\n        \n        intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n        union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n        \n        iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n        \n        # thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n    \n    return iou\n\n    # return iou.cpu().detach().numpy()\n\ndef get_iou_score(outputs, labels):\n    A = labels.squeeze(1).bool()\n    pred = torch.where(outputs<0., torch.zeros(1).cuda(), torch.ones(1).cuda())\n    B = pred.squeeze(1).bool()\n    intersection = (A & B).float().sum((1,2))\n    union = (A| B).float().sum((1, 2)) \n    iou = (intersection + 1e-6) / (union + 1e-6)  \n    \n    return iou.cpu().detach().numpy()","metadata":{"id":"zjF5Ugyt0Zm4","executionInfo":{"status":"ok","timestamp":1621696221367,"user_tz":-420,"elapsed":424,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.669612Z","iopub.execute_input":"2021-06-09T02:53:58.67028Z","iopub.status.idle":"2021-06-09T02:53:58.680861Z","shell.execute_reply.started":"2021-06-09T02:53:58.670239Z","shell.execute_reply":"2021-06-09T02:53:58.679902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, device, trainloader, optimizer, loss_function):\n    model.train()\n    running_loss = 0\n    mask_list, iou = [], []\n    for i, (input, mask) in enumerate(trainloader):\n        # load data into cuda\n        input, mask = input.to(device), mask.to(device)\n\n        # forward\n        predict = model(input)\n        loss = loss_function(predict, mask)\n\n        # metric\n        iou.append(get_iou_score(predict, mask).mean())\n        running_loss += (loss.item())\n        \n        # zero the gradient + backprpagation + step\n        optimizer.zero_grad()\n\n        loss.backward()\n        optimizer.step()\n\n        # log the first image of the batch\n        if ((i + 1) % 10) == 0:\n            pred = normtensor(predict[0])\n            img, pred, mak = tensor2np(input[0]), tensor2np(pred), tensor2np(mask[0])\n            mask_list.append(wandb_mask(img, pred, mak))\n            \n    mean_iou = np.mean(iou)\n    total_loss = running_loss/len(trainloader)\n    wandb.log({'Train loss': total_loss, 'Train IoU': mean_iou, 'Train prediction': mask_list})\n\n    return total_loss, mean_iou","metadata":{"id":"er8jrzm4xdUm","executionInfo":{"status":"ok","timestamp":1621697030917,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.682388Z","iopub.execute_input":"2021-06-09T02:53:58.682765Z","iopub.status.idle":"2021-06-09T02:53:58.693835Z","shell.execute_reply.started":"2021-06-09T02:53:58.68273Z","shell.execute_reply":"2021-06-09T02:53:58.693014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, device, testloader, loss_function, best_iou):\n    model.eval()\n    running_loss = 0\n    mask_list, iou  = [], []\n    with torch.no_grad():\n        for i, (input, mask) in enumerate(testloader):\n            input, mask = input.to(device), mask.to(device)\n\n            predict = model(input)\n            loss = loss_function(predict, mask)\n\n            running_loss += loss.item()\n            iou.append(get_iou_score(predict, mask).mean())\n\n            # log the first image of the batch\n            if ((i + 1) % 1) == 0:\n                pred = normtensor(predict[0])\n                img, pred, mak = tensor2np(input[0]), tensor2np(pred), tensor2np(mask[0])\n                mask_list.append(wandb_mask(img, pred, mak))\n\n    test_loss = running_loss/len(testloader)\n    mean_iou = np.mean(iou)\n    wandb.log({'Valid loss': test_loss, 'Valid IoU': mean_iou, 'Prediction': mask_list})\n    \n    if mean_iou>best_iou:\n    # export to onnx + pt\n        try:\n            torch.onnx.export(model, input, SAVE_PATH+RUN_NAME+'.onnx')\n            torch.save(model.state_dict(), SAVE_PATH+RUN_NAME+'.pth')\n        except:\n            print('Can export weights')\n\n    return test_loss, mean_iou","metadata":{"id":"dCt3fSTrxGTE","executionInfo":{"status":"ok","timestamp":1621697308658,"user_tz":-420,"elapsed":271,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.695265Z","iopub.execute_input":"2021-06-09T02:53:58.695723Z","iopub.status.idle":"2021-06-09T02:53:58.707561Z","shell.execute_reply.started":"2021-06-09T02:53:58.695685Z","shell.execute_reply":"2021-06-09T02:53:58.706801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_pipeline(config):\n    # tell wandb to get started\n    with wandb.init(project=\"TGS-Salt-identification\", tags=['Unet'], config=config):\n        # access all HPs through wandb.config, so logging matches execution!\n        config = wandb.config\n        \n        # make the model, data, and optimization problem\n        model, criterion, optimizer = make(config)\n        \n        best_iou = -1\n        wandb.watch(model, criterion, log=\"all\", log_freq=10)\n        for epoch in range(config.epoch):\n\n            t0 = time.time()\n            train_loss, train_iou = train(model, device, trainloader, optimizer, criterion)\n            t1 = time.time()\n\n            print(f'Epoch: {epoch} | Train loss: {train_loss:.3f} | Train IoU: {train_iou:.3f} | Time: {(t1-t0):.1f}s')\n\n            test_loss, test_iou = test(model, device, validloader, criterion, best_iou)\n            print(f'Epoch: {epoch} | Valid loss: {test_loss:.3f} | Valid IoU: {test_iou:.3f} | Time: {(t1-t0):.1f}s')\n            \n            # Wandb summary\n            if best_iou < test_iou:\n                best_iou = test_iou\n                wandb.run.summary[\"best_accuracy\"] = best_iou\n        \n        trained_weight = wandb.Artifact(RUN_NAME, type='weights')\n        trained_weight.add_file(SAVE_PATH+RUN_NAME+'.onnx')\n        trained_weight.add_file(SAVE_PATH+RUN_NAME+'.pth')\n        wandb.log_artifact(trained_weight)\n\n        print(\"Model saved to Wandb\")\n\n    return model","metadata":{"id":"B6ig3lXL1KYu","executionInfo":{"status":"ok","timestamp":1621695227972,"user_tz":-420,"elapsed":320,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.710393Z","iopub.execute_input":"2021-06-09T02:53:58.710678Z","iopub.status.idle":"2021-06-09T02:53:58.720966Z","shell.execute_reply.started":"2021-06-09T02:53:58.710654Z","shell.execute_reply":"2021-06-09T02:53:58.720106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make(config):\n    # Make the model\n    model = UNet().to(device)\n\n    print('Number of parameter:', count_params(model))\n\n    # Make the loss and optimizer\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer   = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    \n    return model, criterion, optimizer","metadata":{"id":"dCZsm78j1Rsk","executionInfo":{"status":"ok","timestamp":1621694323340,"user_tz":-420,"elapsed":294,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.722368Z","iopub.execute_input":"2021-06-09T02:53:58.722877Z","iopub.status.idle":"2021-06-09T02:53:58.731208Z","shell.execute_reply.started":"2021-06-09T02:53:58.722783Z","shell.execute_reply":"2021-06-09T02:53:58.730491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"bfETAO4bxnTn"}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nconfig = dict(\n    lr          = LEARNING_RATE,\n    batchsize   = BATCH_SIZE,\n    epoch       = EPOCHS,\n    model_sf    = START_FRAME,\n    device      = device,\n)","metadata":{"id":"3wsCT1fS1IBm","executionInfo":{"status":"ok","timestamp":1621697035060,"user_tz":-420,"elapsed":297,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:53:58.732646Z","iopub.execute_input":"2021-06-09T02:53:58.733053Z","iopub.status.idle":"2021-06-09T02:53:58.741579Z","shell.execute_reply.started":"2021-06-09T02:53:58.732977Z","shell.execute_reply":"2021-06-09T02:53:58.740527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model_pipeline(config)","metadata":{"id":"Md9Bm9VL1vj4","executionInfo":{"status":"error","timestamp":1621697840407,"user_tz":-420,"elapsed":15200,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"outputId":"c3dd6947-4c59-40ea-b810-b9fd95b8dd58","execution":{"iopub.status.busy":"2021-06-09T02:53:58.742962Z","iopub.execute_input":"2021-06-09T02:53:58.743392Z","iopub.status.idle":"2021-06-09T02:58:16.607634Z","shell.execute_reply.started":"2021-06-09T02:53:58.743357Z","shell.execute_reply":"2021-06-09T02:58:16.606662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"markdown","source":"## Helper function","metadata":{}},{"cell_type":"code","source":"!unzip ../input/tgs-salt-identification-challenge/test.zip -d ./test\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:16.611613Z","iopub.execute_input":"2021-06-09T02:58:16.611873Z","iopub.status.idle":"2021-06-09T02:58:20.197343Z","shell.execute_reply.started":"2021-06-09T02:58:16.611843Z","shell.execute_reply":"2021-06-09T02:58:20.196482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_IMAGE_PATH = 'test/images/'","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.199483Z","iopub.execute_input":"2021-06-09T02:58:20.19984Z","iopub.status.idle":"2021-06-09T02:58:20.205966Z","shell.execute_reply.started":"2021-06-09T02:58:20.199798Z","shell.execute_reply":"2021-06-09T02:58:20.205165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_df  = pd.read_csv('./'+'train.csv', index_col='id')\ndepths_df = pd.read_csv('./'+'depths.csv', index_col='id')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.208759Z","iopub.execute_input":"2021-06-09T02:58:20.209012Z","iopub.status.idle":"2021-06-09T02:58:20.242391Z","shell.execute_reply.started":"2021-06-09T02:58:20.208989Z","shell.execute_reply":"2021-06-09T02:58:20.241646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = depths_df.loc[depths_df.index.isin(train_df.index) == False]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.243556Z","iopub.execute_input":"2021-06-09T02:58:20.243909Z","iopub.status.idle":"2021-06-09T02:58:20.252646Z","shell.execute_reply.started":"2021-06-09T02:58:20.243865Z","shell.execute_reply":"2021-06-09T02:58:20.251536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:16:57.058489Z","iopub.execute_input":"2021-06-09T03:16:57.058809Z","iopub.status.idle":"2021-06-09T03:16:57.072645Z","shell.execute_reply.started":"2021-06-09T03:16:57.058779Z","shell.execute_reply":"2021-06-09T03:16:57.071617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Test_TGSDataset(Dataset):\n    \"\"\"TGS Salt Identification dataset.\"\"\"\n    \n    def __init__(self, root_dir=DATA_PATH, transform=None):\n        \"\"\"\n        Args:\n            root_path (string): Directory with all the images.\n            transformer (function): whether to apply the data augmentation scheme\n                mentioned in the paper. Only applied on the train split.\n        \"\"\"\n\n        # load dataset from root dir\n        train_df  = pd.read_csv(root_dir+'train.csv', index_col='id')\n        depths_df = pd.read_csv(root_dir+'depths.csv', index_col='id')\n        test_df = depths_df.loc[depths_df.index.isin(train_df.index) == False]\n\n        self.root_dir   = root_dir\n        self.ids        = test_df.index\n        self.depths     = test_df['z'].to_numpy()\n        \n        if transform is None:\n            self.transfrom = transforms.Compose([transforms.Resize((INPUT_SIZE, INPUT_SIZE)), \n                                                  transforms.Grayscale(), \n                                                  transforms.ToTensor(),])\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, index):\n        id    = self.ids[index]\n        depth = self.depths[index]\n\n        # file should be unzipped\n        image = Image.open(self.root_dir+TEST_IMAGE_PATH+id+'.png')\n        image = self.transfrom(image)\n\n        return image","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.261195Z","iopub.execute_input":"2021-06-09T02:58:20.261594Z","iopub.status.idle":"2021-06-09T02:58:20.270718Z","shell.execute_reply.started":"2021-06-09T02:58:20.261537Z","shell.execute_reply":"2021-06-09T02:58:20.269697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_test_dataset(dataset, n_sample=4):\n    \"\"\"Visualize dataset with n_sample\"\"\"\n    fig = plt.figure()\n\n    # show image\n    for i in range(n_sample):\n        image = dataset[i]\n        image = transforms.ToPILImage()(image)\n        print(i, image.size)\n\n        plt.tight_layout()\n        ax = plt.subplot(1, n_sample, i + 1)\n        ax.set_title('Sample #{}'.format(i))\n        ax.axis('off')\n\n        plt.imshow(image, cmap=\"Greys\")\n\n        if i == n_sample-1:\n            plt.show()\n            break","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.272352Z","iopub.execute_input":"2021-06-09T02:58:20.272862Z","iopub.status.idle":"2021-06-09T02:58:20.281709Z","shell.execute_reply.started":"2021-06-09T02:58:20.27282Z","shell.execute_reply":"2021-06-09T02:58:20.280938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = Test_TGSDataset(DATA_PATH)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.283106Z","iopub.execute_input":"2021-06-09T02:58:20.283539Z","iopub.status.idle":"2021-06-09T02:58:20.31791Z","shell.execute_reply.started":"2021-06-09T02:58:20.283501Z","shell.execute_reply":"2021-06-09T02:58:20.317187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_test_dataset(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.318982Z","iopub.execute_input":"2021-06-09T02:58:20.319294Z","iopub.status.idle":"2021-06-09T02:58:20.581815Z","shell.execute_reply.started":"2021-06-09T02:58:20.31926Z","shell.execute_reply":"2021-06-09T02:58:20.580343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_mask = []","metadata":{"execution":{"iopub.status.busy":"2021-06-09T02:58:20.583003Z","iopub.execute_input":"2021-06-09T02:58:20.583338Z","iopub.status.idle":"2021-06-09T02:58:20.587026Z","shell.execute_reply.started":"2021-06-09T02:58:20.583301Z","shell.execute_reply":"2021-06-09T02:58:20.586171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_dataset, device):\n    model.eval()\n    predicted_masks = []\n    back_transform = transforms.Compose([transforms.Resize((101,101))])\n    with torch.no_grad():\n        for i, input in enumerate(test_loader):\n            input = input.to(device)\n            predict = model(input)\n            predict = back_transform(predict)\n            predict = (predict > 0).type(torch.float)\n            predicted_masks.append(predict)\n    predicted_masks = torch.cat(predicted_masks)\n    return predicted_masks\n            \n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:59:16.70407Z","iopub.execute_input":"2021-06-09T03:59:16.70441Z","iopub.status.idle":"2021-06-09T03:59:16.709972Z","shell.execute_reply.started":"2021-06-09T03:59:16.704378Z","shell.execute_reply":"2021-06-09T03:59:16.709168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_mask = predict(model, test_dataset, device=device)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:59:26.125857Z","iopub.execute_input":"2021-06-09T03:59:26.12619Z","iopub.status.idle":"2021-06-09T03:59:59.921521Z","shell.execute_reply.started":"2021-06-09T03:59:26.12616Z","shell.execute_reply":"2021-06-09T03:59:59.920663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_sample_test_result(test_dataset, predicted_mask, n_samples=20):\n    \"\"\"Visualize test sample and corresponding result.\"\"\"\n    plt.rcParams[\"figure.figsize\"] = (20,10)\n    back_transform = transforms.Compose([transforms.Resize((101,101))])\n    for i in range(n_samples):\n        sample = predicted_mask[i]  \n        sample = torch.squeeze(sample, dim=0)\n        sample = transforms.ToPILImage()(sample)\n        X = test_dataset[i]\n        X = back_transform(X)\n        X = transforms.ToPILImage()(X)\n        \n        ax = plt.subplot(2, int(n_samples/2), i + 1)\n        ax.set_title('Sample #{}'.format(i))\n        ax.axis('off')\n        plt.imshow(X, cmap=\"Greys\")\n        plt.imshow(sample, alpha=0.3, cmap=\"OrRd\")\n        if i == n_samples-1:\n            plt.show()\n            break\n        \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-09T04:00:48.051036Z","iopub.execute_input":"2021-06-09T04:00:48.051379Z","iopub.status.idle":"2021-06-09T04:00:48.059829Z","shell.execute_reply.started":"2021-06-09T04:00:48.051339Z","shell.execute_reply":"2021-06-09T04:00:48.058817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_sample_test_result(test_dataset, predicted_mask)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T04:00:50.764346Z","iopub.execute_input":"2021-06-09T04:00:50.76468Z","iopub.status.idle":"2021-06-09T04:00:51.791425Z","shell.execute_reply.started":"2021-06-09T04:00:50.76465Z","shell.execute_reply":"2021-06-09T04:00:51.785925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_mask_np = predicted_mask.cpu().data.numpy()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T04:01:15.461222Z","iopub.execute_input":"2021-06-09T04:01:15.461571Z","iopub.status.idle":"2021-06-09T04:01:16.003604Z","shell.execute_reply.started":"2021-06-09T04:01:15.461535Z","shell.execute_reply":"2021-06-09T04:01:16.002785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_mask_np[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T04:01:17.732251Z","iopub.execute_input":"2021-06-09T04:01:17.732595Z","iopub.status.idle":"2021-06-09T04:01:17.738425Z","shell.execute_reply.started":"2021-06-09T04:01:17.732562Z","shell.execute_reply":"2021-06-09T04:01:17.737559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"id":"CTkVDdUKyMIK","executionInfo":{"status":"aborted","timestamp":1621682461531,"user_tz":-420,"elapsed":40,"user":{"displayName":"Nguyễn Mạnh Dũng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_PTxA8pe1bPxBqC41UASX7Av79o29rRDxDThdlA=s64","userId":"03772830615363167239"}},"execution":{"iopub.status.busy":"2021-06-09T02:58:54.586641Z","iopub.execute_input":"2021-06-09T02:58:54.587047Z","iopub.status.idle":"2021-06-09T02:58:54.594219Z","shell.execute_reply.started":"2021-06-09T02:58:54.587009Z","shell.execute_reply":"2021-06-09T02:58:54.593334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rle_encode(np.squeeze(predicted_mask_np[0]))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T04:01:27.674588Z","iopub.execute_input":"2021-06-09T04:01:27.674909Z","iopub.status.idle":"2021-06-09T04:01:27.682243Z","shell.execute_reply.started":"2021-06-09T04:01:27.674876Z","shell.execute_reply":"2021-06-09T04:01:27.681158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rle_results = []\nfor im in predicted_mask_np:\n    im = np.squeeze(im)\n    im_rle_result = rle_encode(im)\n    rle_results.append(im_rle_result)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T04:02:16.298734Z","iopub.execute_input":"2021-06-09T04:02:16.299063Z","iopub.status.idle":"2021-06-09T04:02:18.483866Z","shell.execute_reply.started":"2021-06-09T04:02:16.299034Z","shell.execute_reply":"2021-06-09T04:02:18.483009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.DataFrame([list(test_dataset.ids), rle_results]).T\nsubmit.columns = ['id', 'rle_mask']\nsubmit.to_csv('torch_submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T04:08:02.384316Z","iopub.execute_input":"2021-06-09T04:08:02.38468Z","iopub.status.idle":"2021-06-09T04:08:04.307964Z","shell.execute_reply.started":"2021-06-09T04:08:02.384649Z","shell.execute_reply":"2021-06-09T04:08:04.307143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}