{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# pre\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/tgs-salt-identification-challenge/train.zip -d ./train\nclear_output()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/tgs-salt-identification-challenge/test.zip -d ./test\nclear_output()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Move Directory**","metadata":{}},{"cell_type":"code","source":"from distutils.dir_util import copy_tree\n\nfromDir = '../input/tgs-salt-identification-challenge'\ntoDir = './'\n\ncopy_tree(fromDir, toDir)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T01:52:58.810151Z","iopub.execute_input":"2021-08-21T01:52:58.810506Z","iopub.status.idle":"2021-08-21T01:53:03.860547Z","shell.execute_reply.started":"2021-08-21T01:52:58.81047Z","shell.execute_reply":"2021-08-21T01:53:03.85971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Library","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, dataloader, random_split\n\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport wandb\nimport time\nimport copy\n\n# login wandb\nos.environ['WANDB_API_KEY'] = '2a291fe931b1a2be33e1c09cb5b86dcd6843ea48'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONFIG","metadata":{}},{"cell_type":"code","source":"# Model\nRUN_NAME        = 'unetv1'\nN_CLASSES       = 1\nINPUT_SIZE      = 101\nEPOCHS          = 100\nLEARNING_RATE   = 0.002\nSTART_FRAME     = 16\nDROP_RATE       = 0.5\n\n# Data\nSAVE_PATH       = './'\nDATA_PATH       = './'\nIMAGE_PATH      = 'train/images/'\nMASK_PATH       = 'train/masks/'\n\nREAL_SIZE       = 101\nRANDOM_SEED     = 42\nVALID_RATIO     = 0.2\nBATCH_SIZE      = 16\nNUM_WORKERS     = 0\nCLASSES         = {1:'salt'}","metadata":{"execution":{"iopub.status.busy":"2021-08-21T01:53:23.716873Z","iopub.execute_input":"2021-08-21T01:53:23.717227Z","iopub.status.idle":"2021-08-21T01:53:23.724218Z","shell.execute_reply.started":"2021-08-21T01:53:23.717186Z","shell.execute_reply":"2021-08-21T01:53:23.723341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataset and dataloader train","metadata":{}},{"cell_type":"code","source":"class TGSDataset(Dataset):\n    \"\"\"TGS Salt Identification dataset.\"\"\"\n    \n    def __init__(self, root_dir=DATA_PATH, transform=None):\n        \"\"\"\n        Args:\n            root_path (string): Directory with all the images.\n            transformer (function): whether to apply the data augmentation scheme\n                mentioned in the paper. Only applied on the train split.\n        \"\"\"\n\n        # load dataset from root dir\n        train_df  = pd.read_csv(root_dir+'train.csv', index_col='id')\n        depths_df = pd.read_csv(root_dir+'depths.csv', index_col='id')\n        train_df = train_df.join(depths_df)\n\n        self.root_dir   = root_dir\n        self.ids        = train_df.index\n        self.depths     = train_df['z'].to_numpy()\n        self.rle        = train_df['rle_mask'].to_numpy()\n        \n        if transform is None:\n            self.transfrom = transforms.Compose([transforms.Grayscale(), \n                                                 transforms.ToTensor(),])\n                                                 \n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, index):\n        id    = self.ids[index]\n        depth = self.depths[index]\n\n        # file should be unzipped\n        image = Image.open(self.root_dir+IMAGE_PATH+id+'.png')\n        mask  = Image.open(self.root_dir+MASK_PATH+id+'.png')\n    \n        image = self.transfrom(image)\n        mask  = self.transfrom(mask)\n\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2021-08-21T01:53:30.12783Z","iopub.execute_input":"2021-08-21T01:53:30.128163Z","iopub.status.idle":"2021-08-21T01:53:30.139552Z","shell.execute_reply.started":"2021-08-21T01:53:30.128132Z","shell.execute_reply":"2021-08-21T01:53:30.138562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloader(dataset, \n                    batch_size=BATCH_SIZE, random_seed=RANDOM_SEED, \n                    valid_ratio=VALID_RATIO, shuffle=True, num_workers=NUM_WORKERS):\n    \"\"\"\n    Params:\n    -------\n    - dataset: the dataset.\n    - batch_size: how many samples per batch to load.\n    - random_seed: fix seed for reproducibility.\n    - valid_ratio: percentage split of the training set used for\n      the validation set. Should be a float in the range [0, 1].\n    - shuffle: whether to shuffle the train/validation indices.\n    - num_workers: number of subprocesses to use when loading the dataset.\n    \"\"\"\n\n    error_msg = \"[!] valid_ratio should be in the range [0, 1].\"\n    assert ((valid_ratio >= 0) and (valid_ratio <= 1)), error_msg\n\n    # split the dataset\n    n = len(dataset)\n    n_valid = int(valid_ratio*n)\n    n_train = n - n_valid\n\n    # init random seed\n    torch.manual_seed(random_seed)\n\n    train_dataset, valid_dataset = random_split(dataset, (n_train, n_valid))\n\n    train_loader = DataLoader(train_dataset, batch_size, shuffle=shuffle, num_workers=num_workers)\n    valid_loader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-08-21T01:53:36.273725Z","iopub.execute_input":"2021-08-21T01:53:36.27405Z","iopub.status.idle":"2021-08-21T01:53:36.280612Z","shell.execute_reply.started":"2021-08-21T01:53:36.274019Z","shell.execute_reply":"2021-08-21T01:53:36.279679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load dataset\ndataset = TGSDataset(DATA_PATH)\ntrainloader, validloader = get_dataloader(dataset=dataset, valid_ratio=0.05)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T01:53:42.538667Z","iopub.execute_input":"2021-08-21T01:53:42.538984Z","iopub.status.idle":"2021-08-21T01:53:42.614805Z","shell.execute_reply.started":"2021-08-21T01:53:42.538952Z","shell.execute_reply":"2021-08-21T01:53:42.613976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_dataset(dataset, n_sample=4):\n    \"\"\"Visualize dataset with n_sample\"\"\"\n    fig = plt.figure()\n\n    # show image\n    for i in range(n_sample):\n        image, mask = dataset[i]\n        image = transforms.ToPILImage()(image)\n        mask = transforms.ToPILImage()(mask)\n        print(i, image.size, mask.size)\n\n\n        plt.tight_layout()\n        ax = plt.subplot(1, n_sample, i + 1)\n        ax.set_title('Sample #{}'.format(i))\n        ax.axis('off')\n\n        plt.imshow(image, cmap=\"Greys\")\n        plt.imshow(mask, alpha=0.3, cmap=\"OrRd\")\n\n        if i == n_sample-1:\n            plt.show()\n            break","metadata":{"execution":{"iopub.status.busy":"2021-08-21T01:53:43.991153Z","iopub.execute_input":"2021-08-21T01:53:43.991521Z","iopub.status.idle":"2021-08-21T01:53:43.997771Z","shell.execute_reply.started":"2021-08-21T01:53:43.991489Z","shell.execute_reply":"2021-08-21T01:53:43.99692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_dataset(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T01:53:48.61377Z","iopub.execute_input":"2021-08-21T01:53:48.614094Z","iopub.status.idle":"2021-08-21T01:53:48.954412Z","shell.execute_reply.started":"2021-08-21T01:53:48.614063Z","shell.execute_reply":"2021-08-21T01:53:48.953587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and Eval Function","metadata":{}}]}