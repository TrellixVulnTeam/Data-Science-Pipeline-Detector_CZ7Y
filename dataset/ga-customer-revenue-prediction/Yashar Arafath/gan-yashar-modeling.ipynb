{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading dataset\ndf_train = pd.read_csv(\"/kaggle/input/ga-customer-revenue-prediction/train.csv\")\n\n\n#reading dataset\ndf_test = pd.read_csv(\"/kaggle/input/ga-customer-revenue-prediction/test.csv\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert json columns\n\nimport os\nimport json\nfrom pandas.io.json import json_normalize\n\ndef load_df(csv_path='/kaggle/input/ga-customer-revenue-prediction/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the train and test dataset\n\ntrain_df = load_df('/kaggle/input/ga-customer-revenue-prediction/train.csv')\n\n\ntest_df = load_df('/kaggle/input/ga-customer-revenue-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#better description for dataset\n\nfrom scipy import stats\n\n\ndef DataDesc(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n    \n    return summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#describe test data\nDataDesc(test_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#describe train data\nDataDesc(train_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputation of null values and converting the columns values to int in train dataset\n\ndef fill_na(df):   \n    df['totals.pageviews'].fillna(1, inplace=True)\n    df['totals.newVisits'].fillna(0, inplace=True)\n    df['totals.bounces'].fillna(0, inplace=True) \n    df[\"totals.transactionRevenue\"].fillna(0.0, inplace=True)\n    \n    # Changing datatypes from object to desired ones\n    df['totals.pageviews'] = df['totals.pageviews'].astype(int)\n    df['totals.newVisits'] = df['totals.newVisits'].astype(int)\n    df['totals.bounces'] = df['totals.bounces'].astype(int)\n    df[\"totals.transactionRevenue\"] = df[\"totals.transactionRevenue\"].astype(float)\n    \n    \n    df['trafficSource.isTrueDirect'].fillna(False, inplace=True) \n    df['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace=True) # filling boolean with True\n    df[train_df['geoNetwork.city'] == \"(not set)\"]['geoNetwork.city'] = np.nan\n    df['geoNetwork.city'].fillna(\"NaN\", inplace=True)\n    \n    return df\n\ndf = fill_na(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputation of null values and converting the columns values to int in test data\n\ndef fill_na(df1):   \n    df1['totals.pageviews'].fillna(1, inplace=True)\n    df1['totals.newVisits'].fillna(0, inplace=True)\n    df1['totals.bounces'].fillna(0, inplace=True)\n    \n    # Changing datatypes from object to desired ones\n    df1['totals.pageviews'] = df1['totals.pageviews'].astype(int)\n    df1['totals.newVisits'] = df1['totals.newVisits'].astype(int)\n    df1['totals.bounces'] = df1['totals.bounces'].astype(int)\n    \n    \n    df1['trafficSource.isTrueDirect'].fillna(False, inplace=True) \n    df1['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace=True) # filling boolean with True\n    df1[train_df['geoNetwork.city'] == \"(not set)\"]['geoNetwork.city'] = np.nan\n    df1['geoNetwork.city'].fillna(\"NaN\", inplace=True)\n    \n    return df1\n\ndf1 = fill_na(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting to float fullVisitorId & sessionId to float\n\ndf['fullVisitorId'] = df['fullVisitorId'].astype(float)\n\ndf['sessionId'] = df['sessionId'].astype(float)\n\n\n\ndf1['fullVisitorId'] = df1['fullVisitorId'].astype(float)\n\ndf1['sessionId'] = df1['sessionId'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing columns with unique values in train\n\nfor col in df.columns:\n    if len(df[col].unique()) == 1:\n        df.drop(col,inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing columns with unique values in train\n\nfor col in df1.columns:\n    if len(df1[col].unique()) == 1:\n        df1.drop(col,inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function is to extract date features in train\n\nfrom datetime import datetime\n\n\ndef date_process(df):\n    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d\") # seting the column as pandas datetime\n    df[\"weekday\"] = df['date'].dt.weekday #extracting week day\n    df[\"day\"] = df['date'].dt.day # extracting day\n    df[\"month\"] = df['date'].dt.month # extracting day\n    df[\"year\"] = df['date'].dt.year # extracting day\n    df['visitHour'] = (df['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour))).astype(int)\n    \n    return df\ndf = date_process(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function is to extract date features in test\n\nfrom datetime import datetime\n\n\ndef df1_date(df1):\n    df1[\"date\"] = pd.to_datetime(df1[\"date\"], format=\"%Y%m%d\") # seting the column as pandas datetime\n    df1[\"weekday\"] = df1['date'].dt.weekday #extracting week day\n    df1[\"day\"] = df1['date'].dt.day # extracting day\n    df1[\"month\"] = df1['date'].dt.month # extracting day\n    df1[\"year\"] = df1['date'].dt.year # extracting day\n    df1['visitHour'] = (df1['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour))).astype(int)\n    \n    return df1\ndf1 = df1_date(df1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check Variables not in test but in train \n\nprint(\"Variables not in test but in train : \", set(df.columns).difference(set(df1.columns)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop session id and trafficSource.campaignCode as they give no value to revenuw\n\ndf = df.drop(['sessionId', 'trafficSource.campaignCode'], axis = 1)\ndf1 = df1.drop(['sessionId'], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill totals.transactionRevenue columns with 0 for nan data and convert it to values.\n#convert full visitor id to values\n\ndf[\"totals.transactionRevenue\"].fillna(0, inplace=True)\ntrain_y = df[\"totals.transactionRevenue\"].values\ntrain_id = df[\"fullVisitorId\"].values\ntest_id = df1[\"fullVisitorId\"].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection, preprocessing, metrics\n\n# function to label encode the categorical variables \n\ndf_cat = [\"channelGrouping\", \"device.browser\", 'device.isMobile',\n            \"device.deviceCategory\", \"device.operatingSystem\", \n            \"geoNetwork.city\", \"geoNetwork.continent\", \n            \"geoNetwork.country\", \"geoNetwork.metro\",\n            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n            \"trafficSource.adwordsClickInfo.adNetworkType\", \n            \"trafficSource.adwordsClickInfo.gclId\", \n            \"trafficSource.adwordsClickInfo.page\", \n            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n            \"trafficSource.keyword\", \"trafficSource.medium\", \n            \"trafficSource.referralPath\", \"trafficSource.source\",\n            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect']\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#label encoding the categorical variable in train and test\n\nfor col in df_cat:\n    print(col)\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(df[col].values.astype('str')) + list(df1[col].values.astype('str')))\n    df[col] = lbl.transform(list(df[col].values.astype('str')))\n    df1[col] = lbl.transform(list(df1[col].values.astype('str')))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the these columns to float\n\nnum_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\", 'totals.bounces',  'totals.newVisits']    \nfor col in num_cols:\n    df[col] = df[col].astype(float)\n    df1[col] = df1[col].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check variable not in test but in train\n\nprint(\"Variables not in test but in train : \", set(df.columns).difference(set(df1.columns)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\n#converting date to date time\n\ndf[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[df['date']<=datetime.date(2017,5,31)]\nval_X = df[df['date']>datetime.date(2017,5,31)]\nX = X.drop(['date'], axis = 1)\nval_X = df.drop(['date'], axis = 1)\ntest_x = df.drop(['date'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = X.drop(['totals.transactionRevenue'], axis = 1)\nval_x = val_X.drop(['totals.transactionRevenue'], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.log1p((X[\"totals.transactionRevenue\"]).values)\nval_y = np.log1p((val_X[\"totals.transactionRevenue\"]).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = pd.DataFrame(y)\nval_y = pd.DataFrame(val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature selection for sessions and devices\n# affects revenue -  Channelgrouping,  visitnumber, device browser, deviceOS, deviceis mobile, device category\n# doesnt affects revenue - full visitid, visit id,visitstarttime\n\nimport matplotlib.pyplot as plt\n\ndevice_session = x.iloc[:,0:9]\n\nplt.figure(figsize=(10,30), facecolor='white')\nplotnumber = 1\n\nlocation\nfor column in device_session:\n    if plotnumber<=12 :\n        ax = plt.subplot(10,3,plotnumber)\n        plt.scatter(device_session[column],y)\n        plt.xlabel(column,fontsize=10)\n        plt.ylabel('revenue',fontsize=10)\n    plotnumber+=1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature selection for totals columns\n# affects revenue -  total page views, total hits, totals new visits\n# doesnt affects revenue - bounces\nimport matplotlib.pyplot as plt\n\ntotals = x.iloc[:,16:20]\n\nplt.figure(figsize=(10,10), facecolor='white')\nplotnumber = 1\n\nlocation\nfor column in totals:\n    if plotnumber<=5 :\n        ax = plt.subplot(3,3,plotnumber)\n        plt.scatter(totals[column],y)\n        plt.xlabel(column,fontsize=10)\n        plt.ylabel('revenue',fontsize=10)\n    plotnumber+=1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature selection for traffic source columns\n# affects revenue -  all these columns somewhat affects the revenue \n\n\nimport matplotlib.pyplot as plt\n\ntraffic_source = x.iloc[:,20:32]\n\nplt.figure(figsize=(10,30), facecolor='white')\nplotnumber = 1\n\nlocation\nfor column in traffic_source:\n    if plotnumber<=12 :\n        ax = plt.subplot(10,3,plotnumber)\n        plt.scatter(traffic_source[column],y)\n        plt.xlabel(column,fontsize=10)\n        plt.ylabel('revenue',fontsize=10)\n    plotnumber+=1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature selection for geo location columns\n# affects revenue -  all these columns some what affects revenue\n\nimport matplotlib.pyplot as plt\n\ngeo_location = x.iloc[:,9:16]\n\nplt.figure(figsize=(10,30), facecolor='white')\nplotnumber = 1\n\nlocation\nfor column in geo_location:\n    if plotnumber<=12 :\n        ax = plt.subplot(10,3,plotnumber)\n        plt.scatter(geo_location[column],y)\n        plt.xlabel(column,fontsize=10)\n        plt.ylabel('revenue',fontsize=10)\n    plotnumber+=1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature selection for totals columns\n# affects revenue -  all columns except day\n# doesnt affects revenue - day\n\nimport matplotlib.pyplot as plt\n\ntime = x.iloc[:,32:37]\n\nplt.figure(figsize=(10,30), facecolor='white')\nplotnumber = 1\n\nlocation\nfor column in time:\n    if plotnumber<=12 :\n        ax = plt.subplot(10,3,plotnumber)\n        plt.scatter(time[column],y)\n        plt.xlabel(column,fontsize=10)\n        plt.ylabel('revenue',fontsize=10)\n    plotnumber+=1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop columns that doesnt affects revenue\n\nx = x.drop(['day', 'totals.bounces', 'fullVisitorId', 'visitId', 'visitStartTime'], axis = 1)\nval_x = val_x.drop(['day', 'totals.bounces', 'fullVisitorId', 'visitId', 'visitStartTime'], axis = 1)\ntest_x = test_x.drop(['day', 'totals.bounces', 'fullVisitorId', 'visitId', 'visitStartTime'], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= train_x\nY= train_y\nval_x = df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['date'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\ndf['date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\n\ndef run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\", \n        \"num_leaves\" : 30,\n        \"min_child_samples\" : 100,\n        \"learning_rate\" : 0.1,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.5,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    model_lgbm = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n    \n    pred_test_y = model_lgbm.predict(test_X, num_iteration=model_lgbm.best_iteration)\n    pred_val_y = model_lgbm.predict(val_X, num_iteration=model_lgbm.best_iteration)\n    return pred_test_y, model_lgbm, pred_val_y\n\n# Training the model #\npred_test, model_lgbm, pred_val = run_lgb(x, y, val_x, val_y, test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,18))\nlgb.plot_importance(model_lgbm, max_num_features=50, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x.drop(['visitId', 'visitStartTime', 'trafficSource.adwordsClickInfo.page', 'trafficSource.adwordsClickInfo.slot'\n           ,'trafficSource.campaign', 'trafficSource.adContent', 'device.deviceCategory', 'trafficSource.medium'], axis = 1)\n\nval_x = val_x.drop(['visitId', 'visitStartTime', 'trafficSource.adwordsClickInfo.page', 'trafficSource.adwordsClickInfo.slot'\n           ,'trafficSource.campaign', 'trafficSource.adContent', 'device.deviceCategory', 'trafficSource.medium'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport xgboost as xg \nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\nn_estimators = [500,1000,2000]\nmax_depth= [7, 8, 9, 10]\nlearning_rate= [0.2, 0.3, 0.4]\ncolsample_bytree= [0.5, 0.6,0.8]\nsubsample= [0.5,0.7, 0.8]\nscale_pos_weight=[1,1.5,2]\nrandom_search = {'n_estimators': n_estimators, 'max_depth': max_depth, 'learning_rate': learning_rate,\n                 'subsample': subsample, 'colsample_bytree':colsample_bytree, 'scale_pos_weight': scale_pos_weight}\n               \nRandom = RandomizedSearchCV(estimator = xg.XGBRegressor(objective='reg:squarederror'),param_distributions = random_search,\n                            verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Random.fit(x,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xg \nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import r2_score\n\n\nmodel = xg.XGBRegressor(objective ='reg:squarederror', n_estimators = 900, verbosity=1, learning_rate=0.25, max_depth=8,\n                       subsample=0.5, colsample_bytree=0.5, scale_pos_weight=3)\nmodel.fit(x, y) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_predict = model.predict(x)\nrmse = (np.sqrt(MSE(y, y_train_predict)))\nr2 = r2_score(y, y_train_predict)\n\nprint(\"The model performance for training set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\n\n# model evaluation for testing set\n\ny_test_predict = model.predict(val_x)\n# root mean square error of the model\nrmse = (np.sqrt(MSE(val_y, y_test_predict)))\n\n# r-squared score of the model\nr2 = r2_score(val_y, y_test_predict)\n\nprint(\"The model performance for testing set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error \nfrom math import sqrt\n\ndef adj_r2(x,y,r2):\n    \"\"\"\n                Method Name: adj_r2\n                Description: This method calculates adjusted r2 value\n                Output: adjusted r2 score value\n                On Failure: Raise Exception\n\n                Written By: Chethan\n                Version: 1.0\n                \n    \"\"\"\n    try:\n        n = x.shape[0]\n        p = x.shape[1]\n        adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n        return adjusted_r2\n    \n    except Exception as e:\n        raise Exception()\n\nr2_score = model.score(x, y)\nadj_r2_score = adj_r2 (x, y,r2_score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adj_r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_selec = df.drop(['date', 'totals.transactionRevenue'], axis = 1)\nfeature_selec.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_booster().get_score(importance_type=\"gain\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_important = model.get_booster().get_score(importance_type='weight')\nkeys = list(feature_important.keys())\nvalues = list(feature_important.values())\n\ndata = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\ndata.plot(kind='barh', figsize=(12,18))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"Feature Importance\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nsorted_idx = model.feature_importances_.argsort()\nplt.barh(df.feature_names[sorted_idx], model.feature_importances_[sorted_idx])\nplt.xlabel(\"Xgboost Feature Importance\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}