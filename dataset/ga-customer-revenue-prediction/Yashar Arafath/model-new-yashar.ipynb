{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading dataset\ndf_train = pd.read_csv(\"/kaggle/input/ga-customer-revenue-prediction/train.csv\")\n\n\n#reading dataset\ndf_test = pd.read_csv(\"/kaggle/input/ga-customer-revenue-prediction/test.csv\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert json columns\n\nimport os\nimport json\nfrom pandas.io.json import json_normalize\n\ndef load_df(csv_path='/kaggle/input/ga-customer-revenue-prediction/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the train and test dataset\n\ntrain_df = load_df('/kaggle/input/ga-customer-revenue-prediction/train.csv')\n\n\ntest_df = load_df('/kaggle/input/ga-customer-revenue-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputation of null values and converting the columns values to int in train dataset\n\ndef fill_na(df):   \n    df['totals.pageviews'].fillna(1, inplace=True)\n    df['totals.newVisits'].fillna(0, inplace=True)\n    df['totals.bounces'].fillna(0, inplace=True) \n    df[\"totals.transactionRevenue\"].fillna(0.0, inplace=True)\n    \n    # Changing datatypes from object to desired ones\n    df['totals.pageviews'] = df['totals.pageviews'].astype(int)\n    df['totals.newVisits'] = df['totals.newVisits'].astype(int)\n    df['totals.bounces'] = df['totals.bounces'].astype(int)\n    df[\"totals.transactionRevenue\"] = df[\"totals.transactionRevenue\"].astype(float)\n    \n    \n    df['trafficSource.isTrueDirect'].fillna(False, inplace=True) \n    df['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace=True) # filling boolean with True\n    df[train_df['geoNetwork.city'] == \"(not set)\"]['geoNetwork.city'] = np.nan\n    df['geoNetwork.city'].fillna(\"NaN\", inplace=True)\n    \n    return df\n\ndf = fill_na(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputation of null values and converting the columns values to int in test data\n\ndef fill_na(df1):   \n    df1['totals.pageviews'].fillna(1, inplace=True)\n    df1['totals.newVisits'].fillna(0, inplace=True)\n    df1['totals.bounces'].fillna(0, inplace=True)\n    \n    # Changing datatypes from object to desired ones\n    df1['totals.pageviews'] = df1['totals.pageviews'].astype(int)\n    df1['totals.newVisits'] = df1['totals.newVisits'].astype(int)\n    df1['totals.bounces'] = df1['totals.bounces'].astype(int)\n    \n    \n    df1['trafficSource.isTrueDirect'].fillna(False, inplace=True) \n    df1['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace=True) # filling boolean with True\n    df1[train_df['geoNetwork.city'] == \"(not set)\"]['geoNetwork.city'] = np.nan\n    df1['geoNetwork.city'].fillna(\"NaN\", inplace=True)\n    \n    return df1\n\ndf1 = fill_na(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting to float fullVisitorId & sessionId to float\n\ndf['fullVisitorId'] = df['fullVisitorId'].astype(float)\n\ndf['sessionId'] = df['sessionId'].astype(float)\n\n\n\ndf1['fullVisitorId'] = df1['fullVisitorId'].astype(float)\n\ndf1['sessionId'] = df1['sessionId'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing columns with unique values in train\n\nfor col in df.columns:\n    if len(df[col].unique()) == 1:\n        df.drop(col,inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Removing columns with unique values in train\n\nfor col in df1.columns:\n    if len(df1[col].unique()) == 1:\n        df1.drop(col,inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function is to extract date features in train\n\nfrom datetime import datetime\n\n\ndef date_process(df):\n    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d\") # seting the column as pandas datetime\n    df[\"weekday\"] = df['date'].dt.weekday #extracting week day\n    df[\"day\"] = df['date'].dt.day # extracting day\n    df[\"month\"] = df['date'].dt.month # extracting day\n    df[\"year\"] = df['date'].dt.year # extracting day\n    df['visitHour'] = (df['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour))).astype(int)\n    \n    return df\ndf = date_process(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function is to extract date features in test\n\nfrom datetime import datetime\n\n\ndef df1_date(df1):\n    df1[\"date\"] = pd.to_datetime(df1[\"date\"], format=\"%Y%m%d\") # seting the column as pandas datetime\n    df1[\"weekday\"] = df1['date'].dt.weekday #extracting week day\n    df1[\"day\"] = df1['date'].dt.day # extracting day\n    df1[\"month\"] = df1['date'].dt.month # extracting day\n    df1[\"year\"] = df1['date'].dt.year # extracting day\n    df1['visitHour'] = (df1['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour))).astype(int)\n    \n    return df1\ndf1 = df1_date(df1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop session id and trafficSource.campaignCode as they give no value to revenuw\n\ndf = df.drop(['sessionId', 'trafficSource.campaignCode'], axis = 1)\ndf1 = df1.drop(['sessionId'], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill totals.transactionRevenue columns with 0 for nan data and convert it to values.\n#convert full visitor id to values\n\ndf[\"totals.transactionRevenue\"].fillna(0, inplace=True)\ntrain_y = df[\"totals.transactionRevenue\"].values\ntrain_id = df[\"fullVisitorId\"].values\ntest_id = df1[\"fullVisitorId\"].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection, preprocessing, metrics\n\n# function to label encode the categorical variables \n\ndf_cat = [\"channelGrouping\", \"device.browser\", 'device.isMobile',\n            \"device.deviceCategory\", \"device.operatingSystem\", \n            \"geoNetwork.city\", \"geoNetwork.continent\", \n            \"geoNetwork.country\", \"geoNetwork.metro\",\n            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n            \"trafficSource.adwordsClickInfo.adNetworkType\", \n            \"trafficSource.adwordsClickInfo.gclId\", \n            \"trafficSource.adwordsClickInfo.page\", \n            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n            \"trafficSource.keyword\", \"trafficSource.medium\", \n            \"trafficSource.referralPath\", \"trafficSource.source\",\n            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#label encoding the categorical variable in train and test\n\nfor col in df_cat:\n    print(col)\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(df[col].values.astype('str')) + list(df1[col].values.astype('str')))\n    df[col] = lbl.transform(list(df[col].values.astype('str')))\n    df1[col] = lbl.transform(list(df1[col].values.astype('str')))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the these columns to float\n\nnum_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\", 'totals.bounces',  'totals.newVisits']    \nfor col in num_cols:\n    df[col] = df[col].astype(float)\n    df1[col] = df1[col].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\n#converting date to date time\n\ndf[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[df['date']<=datetime.date(2017,5,31)]\n\nval_X = df[df['date']>datetime.date(2017,5,31)]\nX = X.drop(['date'], axis = 1)\nval_X = val_X.drop(['date'], axis = 1)\ntest_X = df1.drop(['date'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.log1p((X[\"totals.transactionRevenue\"]).values)\nval_y = np.log1p((val_X[\"totals.transactionRevenue\"]).values)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = X.drop(['totals.transactionRevenue'], axis = 1)\nval_x = val_X.drop(['totals.transactionRevenue'], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = pd.DataFrame(y)\nval_y = pd.DataFrame(val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop columns that doesnt affects revenue\n\nx1 = x.drop(['day', 'totals.bounces', 'fullVisitorId', 'visitId', 'visitStartTime', 'trafficSource.adwordsClickInfo.adNetworkType',\n          'trafficSource.adwordsClickInfo.isVideoAd' ], axis = 1)\nval_x1 = val_x.drop(['day', 'totals.bounces', 'fullVisitorId', 'visitId', 'visitStartTime', 'trafficSource.adwordsClickInfo.adNetworkType',\n          'trafficSource.adwordsClickInfo.isVideoAd' ], axis = 1)\ntest_x = test_X.drop(['weekday', 'totals.bounces', 'fullVisitorId', 'visitId', 'visitStartTime', 'trafficSource.adwordsClickInfo.adNetworkType',\n          'trafficSource.adwordsClickInfo.isVideoAd' ], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xg \nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import r2_score\n\n\nmodel = xg.XGBRegressor(objective ='reg:squarederror',n_estimators = 1000, verbosity=1, learning_rate=0.3, max_depth=8,\n                       subsample=0.5, colsample_bytree=0.5, scale_pos_weight=3)\nmodel.fit(x1, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(x1,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_predict = model.predict(x1)\nrmse = (np.sqrt(MSE(y, y_train_predict)))\nr2 = r2_score(y, y_train_predict)\n\nprint(\"The model performance for training set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\n\n# model evaluation for testing set\n\ny_test_predict = model.predict(val_x1)\n# root mean square error of the model\nrmse = (np.sqrt(MSE(val_y, y_test_predict)))\n\n# r-squared score of the model\nr2 = r2_score(val_y, y_test_predict)\n\nprint(\"The model performance for testing set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pickle file with xgboost model\nimport pickle\n\nmodel_file = \"model.sav\"\nwith open(model_file,mode='wb') as model_f:\n    pickle.dump(model,model_f)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwith open(model_file,mode='rb') as model_f:\n    model = pickle.load(model_f)\n    result = model.score(val_x1,val_y)\n    print(\"result:\",result)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pkl_Filename = \"Pickle_XG_Model.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)\n\n# Load the Model back from file\nwith open(Pkl_Filename, 'rb') as file:  \n    Pickled_XG_Model = pickle.load(file)\n\nPickled_XG_Model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LGB Model starts here..."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model with lgbm\n\nfrom sklearn import model_selection, preprocessing, metrics\nimport lightgbm as lgb\n\n\ndef run_lgb(x1, y, val_x1, val_y, test_x):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\", \n        \"num_leaves\" : 30,\n        \"min_child_samples\" : 100,\n        \"learning_rate\" : 0.05,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.5,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : 1,\n        \"max_depth\" : 10\n        \n    }\n    \n    lgtrain = lgb.Dataset(x1, label=y)\n    lgval = lgb.Dataset(val_x1, label=val_y)\n    model_lgbm = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n    \n    pred_test_y = model_lgbm.predict(test_x, num_iteration=model_lgbm.best_iteration)\n    pred_val_y = model_lgbm.predict(val_x1, num_iteration=model_lgbm.best_iteration)\n    return pred_test_y, model_lgbm, pred_val_y\n\n# Training the model #\npred_test, model_lgbm, pred_val = run_lgb(x1, y, val_x1, val_y, test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_predict = model_lgbm.predict(x1)\nrmse = (np.sqrt(MSE(y, y_train_predict)))\nr2 = r2_score(y, y_train_predict)\n\nprint(\"The model performance for training set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_predict = model_lgbm.predict(x1)\nrmse = (np.sqrt(MSE(y, y_train_predict)))\nr2 = r2_score(y, y_train_predict)\n\nprint(\"The model performance for training set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\n\n# model evaluation for testing set\n\ny_test_predict = model_lgbm.predict(val_x1)\n# root mean square error of the model\nrmse = (np.sqrt(MSE(val_y, y_test_predict)))\n\n# r-squared score of the model\nr2 = r2_score(val_y, y_test_predict)\n\nprint(\"The model performance for testing set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pkl_Filename = \"lgb_model.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model_lgbm, file)\n\n# Load the Model back from file\nwith open(Pkl_Filename, 'rb') as file:  \n    lgb_model = pickle.load(file)\n\nlgb_model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}