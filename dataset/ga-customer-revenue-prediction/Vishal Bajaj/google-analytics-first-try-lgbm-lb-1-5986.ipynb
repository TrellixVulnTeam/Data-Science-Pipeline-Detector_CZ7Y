{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.metrics import explained_variance_score, roc_auc_score, precision_recall_curve, roc_curve, average_precision_score,accuracy_score\nfrom sklearn import model_selection, preprocessing, metrics\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_val_score, cross_validate\n\n##from keras starter\n#from keras.layers import Dense,Dropout\n#from keras.models import Sequential\n#from keras.optimizers import SGD,RMSprop\n#from sklearn.model_selection import train_test_split\n#from sklearn.preprocessing import MinMaxScaler\n#from keras.layers.normalization import BatchNormalization\n#from keras import backend as K\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport gc\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5cc5bacafe7de99b736c04084856f4e3e1a3781"},"cell_type":"markdown","source":"**Data Prep**\n\nKudos to [Juli√°n Peller](https://www.kaggle.com/julian3833) for his quick start [kernel](https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields/notebook) to flatten json data!!"},{"metadata":{"_uuid":"971642d3ef14549a0a5c2d835be6d8a21843ee1f","trusted":false},"cell_type":"code","source":"def load_df(csv_path='../input/train.csv', low_memory=False, nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"%%time\n##One time activity if you export flattened files to CSV to load later\n\ntrain = load_df()\ntest = load_df('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ccfab5295fdfc6f366ef4ab1ad50fc0a4da08ae","trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7aeef9a910b432cbe019d3bc279ff797d0f99842","trusted":false},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b7e30f254833c6ecc5ab3c7beff5765f2d5dc1e","trusted":false},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ff4892e7544ff824309ed057bb8c6757b36afe9","trusted":false},"cell_type":"code","source":"%%time\n##One time activity if you export flattened files to CSV to load later on your local environment\n\ntrain.to_csv(\"train-flattened.csv\", index=False)\ntest.to_csv(\"test-flattened.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fce3c3207599f4b4ef66d2c0cce080945f2e0077","trusted":false},"cell_type":"code","source":"%%time\ntrain_flat = pd.read_csv(\"train-flattened.csv\", low_memory=False, nrows=903653)\ntest_flat = pd.read_csv(\"test-flattened.csv\", low_memory=False, nrows=804684)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e95879e9689c75a6b0cd059f2d882c2602b3306d","trusted":false},"cell_type":"code","source":"del train\ndel test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32876c933a6b0e64079fd946680be21e3046c838","trusted":false},"cell_type":"code","source":"train_flat.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"903d4e83dae9f3e877f8a08e041165565b489dd1","trusted":false},"cell_type":"code","source":"train_flat.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36b62999e4b25f8d2a2939e5fa0d28d825a67d60","scrolled":false,"trusted":false},"cell_type":"code","source":"print(train_flat.info(), test_flat.info())\n\n#TEST - dtypes: bool(1), float64(4), int64(6), object(42)\n#TRAIN - dtypes: bool(1), float64(5), int64(6), object(43) -- extra column is [trafficSource.campaignCode]\n##On the read csv of the flattened file there are more numerics!","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0e484d362956ea5906c05594c538f2e47967325"},"cell_type":"markdown","source":"**CHECKING the DATA**\n\nIn the below section I created a simple priont procedure to see the differences between TRAIN and TEST, as this is a very categorical dense dataset.\n\nFYI: you can change 'objcol' to check only the object colums or exclude='object' the rest to get a less scattered picture."},{"metadata":{"_uuid":"c2f6ad8da798f45f0ff31f741b9e556c8901a3ce","trusted":false},"cell_type":"code","source":"%%time\nobjcol = test_flat.columns\n\n##For some reason [trafficSource.campaignCode] is not present in the TEST dataset.\n##already checked the vlaues using --------- train_flat['trafficSource.campaignCode'].value_counts(), and there is only 1 value with a count of 1 rest is nan!\n\nfor col in objcol:\n    train_u = train_flat[col].unique()\n    train_ucnt = train_flat[col].nunique()\n    test_u = test_flat[col].unique()\n    test_ucnt = test_flat[col].nunique() \n    train_na = train_flat[col].isna().sum()\n    test_na = test_flat[col].isna().sum()\n\n    if train_flat[col].nunique() <= 20:\n        print(col, ' - ', train_flat[col].dtypes , ' - TRAIN - ', round(train_na * 100 / 903653,2), '% is NAN', '--- TOTAL NAN', train_na,  '    ====== UNIQUE VALUES TRAIN-   ', train_ucnt, '     ======', train_u)\n        print('                              TEST - ', round(test_na * 100 / 804684,2), '% is NAN', '--- TOTAL NAN', test_na,  '    ====== UNIQUE VALUES TEST-   ', test_ucnt, '     ======', test_u, '\\n')\n    else:\n        print(col, ' - ', train_flat[col].dtypes , ' - TRAIN - ', round(train_na * 100 / 903653,2), '% is NAN', '--- TOTAL NAN', '    ====== UNIQUE VALUES TRAIN-   ', train_ucnt, '     ====== TOO MANY VALUES TO PRINT!!')\n        print('                              TEST - ', round(test_na * 100 / 804684,2), '% is NAN', '--- TOTAL NAN',  '    ====== UNIQUE VALUES TEST-   ', test_ucnt, '     ====== TOO MANY VALUES TO PRINT!!\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fb0083d1a28dca9a86350ff5d9c8313515c3ed8"},"cell_type":"markdown","source":"**Dropping and Cleaning columns**\n\nLooks like there are a quite a few columns to drop and transform. Basically anything with only \"1\" value 'not available in demo dataset'. Important, some columns contain this text and have many other values in other rows so be careful not to drop just any column with this value!\n\n1. **Step 1** - Manage NANs for columns trafficSource.isTrueDirect, totals.newVisits, totals.bounces, trafficSource.adwordsClickInfo.isVideoAd (not sure abiout this, NAN may = TRUE) , trafficSource.isTrueDirect, etc.\n2. **Step 2** - Visualization, lets look at the distributions and spreads of the various categories in relation to the **LOG(totals.transactionRevenue)**.\n3. **Step 3** - Delete the columns from both TEST and Train if that is the only value available is 'not available in demo dataset', Remove extra column from tain set 'trafficSource.campaignCode'. Drop columns not useful with too many categories or too many NANs. Word of caution ---- trafficSource.isTrueDirect have 69% NAN however the other value is TRUE, so I would replace NAN with FALSE. A couple of columns like that!"},{"metadata":{"_uuid":"60536f728fa6f186bff0e05ac15a6f5733e4c590"},"cell_type":"markdown","source":"**Step 1 -  Handle NANs and missing values** \n\nManage NANs for columns totals.transactionRevenue, trafficSource.isTrueDirect, totals.newVisits, totals.bounces, trafficSource.adwordsClickInfo.isVideoAd (not sure abiout this, NAN may be = TRUE) , trafficSource.isTrueDirect, etc."},{"metadata":{"_uuid":"606e17968104f767eabe9e03b254a783799b2e18","trusted":false},"cell_type":"code","source":"##Fillna with 0\ntrain_flat['totals.transactionRevenue'].fillna(0,inplace=True)\n\ndef fillNan(cols):\n    for col in cols:\n        train_flat[col].fillna(0,inplace=True)\n        test_flat[col].fillna(0,inplace=True)\n    \ncols = ['trafficSource.adwordsClickInfo.page', 'trafficSource.isTrueDirect', 'totals.newVisits', 'totals.bounces', 'trafficSource.adwordsClickInfo.isVideoAd']\nfillNan(cols);  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c37c167c9dabeb7e5fd2b08fedd2657c5a91843d"},"cell_type":"markdown","source":"**Step 2 - Visualization** \n\nLOG of the transaction revenue sums by continent, subcontinent, & operatingSystem, with a hue of deviceCategory.\n\nUpon analysis, \n--'trafficSource.adwordsClickInfo.isVideoAd' has no impact on transaction values neither does device.deviceCategory even though its varied.\n--'device.operatingSystem' seems imbalance not to mention additional Operating systems like 'Tizen' 'Playstation Vita' 'OS/2', different values between the test and train.\n--Country, Subcontinent and continent seeme to give a better picture of revenue distribution."},{"metadata":{"_uuid":"11dee09fbe029502728e1e4d4f8850bdfb296e9f","trusted":false},"cell_type":"code","source":"##Create new column TransactionRevenueLog and transform Date\n#had previously set it to np.og but changed to np.log1p to handle ,0, values in revenue based on the dicussion here https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47124\ntrain_flat['totals.transactionRevenueLog'] =  np.log1p(train_flat['totals.transactionRevenue'])\n\n##Create a new NAN column to help with teh reporting aspect as '0' shows up on all the plots and makes it relly hard to see the distribution of the actual transactions with values in there.\ntrain_flat['totals.transactionRevenueLogNAN'] =  np.log1p(train_flat['totals.transactionRevenue'])\ntrain_flat['totals.transactionRevenueLogNAN'].replace(0,np.nan,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f1dd65f400972e6c5542b7394e2fe2a44f9de3bf"},"cell_type":"code","source":"train_flat['totals.transactionRevenueLogNAN'].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a645dda78e90be203df7ff199fbd186209d6bc15","trusted":false},"cell_type":"code","source":"##transform the date columns\ntrain_flat['datestr'] = pd.to_datetime(train_flat['date'].astype('str'), format='%Y%m%d')\ntest_flat['datestr'] = pd.to_datetime(test_flat['date'].astype('str'), format='%Y%m%d')\n\n##technically the .dt.day, dt.month should work in Kaggle but it does not seem to!\n\ntrain_flat['year'], train_flat['month'],train_flat['day'], train_flat['week']  = train_flat['datestr'].apply(lambda x: x.year).astype('int64'), train_flat['datestr'].apply(lambda x: x.month).astype('int64'), train_flat['datestr'].apply(lambda x: x.day).astype('int64'), train_flat['datestr'].apply(lambda x: x.week).astype('int64')\ntest_flat['year'], test_flat['month'],test_flat['day'], test_flat['week']  = test_flat['datestr'].apply(lambda x: x.year).astype('int64'), test_flat['datestr'].apply(lambda x: x.month).astype('int64'), test_flat['datestr'].apply(lambda x: x.day).astype('int64'), test_flat['datestr'].apply(lambda x: x.week).astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"415e250f307e087ebbcdc8417f28f9e4d9018b39"},"cell_type":"code","source":"train_flat['day'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbe574332f9b238a575b1a16b5f3de46b6c4266d","trusted":false},"cell_type":"code","source":"#The lineplot of the date columns\n\ndef plot_lineplot(train_flat, cols, col_y):\n    for col in cols:\n        fig = plt.figure(figsize=(15,8))\n        sns.set_style(\"whitegrid\")\n        g = sns.lineplot(col, col_y, hue='device.isMobile', data=train_flat)\n        plt.xlabel(col) # Set text for the x axis\n        plt.ylabel('log of transaction revenue')# Set text for y axis\n        fig.show()\n\ncol_y = train_flat['totals.transactionRevenueLogNAN']\ncat_cols = ['datestr','day', 'month', 'year', 'week']   \nplot_lineplot(train_flat, cat_cols, col_y)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"_uuid":"d7ee96da15e219daea92080248f132206d5ce8f8","trusted":false},"cell_type":"code","source":"def plot_box_mobile(train_flat, cols, col_y):\n    for col in cols:\n        fig = plt.figure(figsize=(20,8))\n        sns.set_style(\"whitegrid\")\n        g = sns.boxplot(col, col_y, hue='device.isMobile', data=train_flat)\n        plt.xlabel(col) # Set text for the x axis\n        plt.ylabel('log of transaction revenue')# Set text for y axis\n        for item in g.get_xticklabels():\n            item.set_rotation(90)\n        fig.show()\n\ncol_y = train_flat['totals.transactionRevenueLogNAN']\ncat_cols = ['geoNetwork.continent','geoNetwork.subContinent','geoNetwork.metro', 'geoNetwork.city','trafficSource.source', 'trafficSource.medium']  \nplot_box_mobile(train_flat, cat_cols, col_y)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_uuid":"f6ce82b5813baf92addd265a72edd1aa0ce20599","trusted":false},"cell_type":"code","source":"# Device as a violin plot\ndef plot_violin(train_flat, cols, col_y):\n    for col in cols:\n        fig = plt.figure(figsize=(22,10))\n        sns.set_style(\"whitegrid\")\n        g = sns.violinplot(col, col_y, data=train_flat)\n        plt.xlabel(col) # Set text for the x axis\n        plt.ylabel('log of transaction revenue')# Set text for y axis\n        for item in g.get_xticklabels():\n            item.set_rotation(90)\n        fig.show()\n\ncol_y = train_flat['totals.transactionRevenueLogNAN']\ncat_cols = ['device.isMobile','device.browser','device.deviceCategory','device.operatingSystem','trafficSource.adwordsClickInfo.isVideoAd']\n#cat_cols = train_flat.select_dtypes(include='object')    \nplot_violin(train_flat, cat_cols, col_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f89629a083c19868e59154d0c50ee1330a1e119","trusted":false},"cell_type":"code","source":"#The KDE of the numeric columns\ndef plot_jointplot(train_flat, cols, col_y):\n    for col in cols:\n        fig = plt.figure(figsize=(15,15))\n        sns.set_style(\"whitegrid\")\n        sns.jointplot(col, col_y , data=train_flat)\n        plt.xlabel(col) # Set text for the x axis\n        plt.ylabel('log of transaction revenue')# Set text for y axis\n        fig.show()\n\ncol_y = train_flat['totals.transactionRevenueLogNAN']\ncat_cols = ['totals.hits','visitNumber', 'totals.pageviews', 'totals.bounces', 'totals.newVisits', 'visitStartTime']\n#cat_cols = train_flat.select_dtypes(include='object')    \nplot_jointplot(train_flat, cat_cols, col_y)\n\n##HITS and PAGEVIEWS have very similar distributions! We could probably drop one of them...., VISTNUMBER seems pretty different","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89e361ce9470ec1ddfdfbf662f3011307506abe0","trusted":false},"cell_type":"code","source":"#One more by all counties\ndef plot_box(train_flat, cols, col_y):\n    for col in cols:\n        fig = plt.figure(figsize=(150,25))\n        sns.set_style(\"whitegrid\")\n        g = sns.boxplot(col, col_y, data=train_flat)\n        plt.xlabel(col) # Set text for the x axis\n        plt.ylabel('log of transaction revenue')# Set text for y axis\n        for item in g.get_xticklabels():\n            item.set_rotation(90)\n        fig.show()\n\ncol_y = train_flat['totals.transactionRevenueLog']\ncat_cols = [ 'geoNetwork.region']\n#cat_cols = train_flat.select_dtypes(include='object')    \nplot_box(train_flat, cat_cols, col_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b48565ba31a7e05b8779dc30d297fb29c137688","trusted":false},"cell_type":"code","source":"#Step 3 - Cleanup/Drop those columns\n\n##Column not in test set\ntrain_flat.drop(columns='trafficSource.campaignCode', axis=1, inplace=True) ## Only for train\n\n##Columns with only one value 'not available in demo dataset'\ncol_check = train_flat.loc[:,(train_flat == 'not available in demo dataset').any(axis=0)].columns\n\nfor col in col_check:\n    if train_flat[col].nunique() <= 1:\n        train_flat.drop(columns=col, axis=1, inplace=True)\n        test_flat.drop(columns=col, axis=1, inplace=True)\n        print(col, 'is dropped')\n        \ncol_drop = [\n    #Constant Values\n    'socialEngagementType',\n    \n    ## (including in test on this run. Without these I get a 1.7681 LB score)\n    ##'device.browser', 'device.deviceCategory', 'trafficSource.source', 'geoNetwork.metro',  'geoNetwork.city',\n    'geoNetwork.networkDomain', \n    \n    #Pageviews is too similar to page hits might be removed when training is capped. 'totals.pageviews'\n    ##Too many NANs\n    'trafficSource.adContent',\n    'trafficSource.adwordsClickInfo.adNetworkType',\n    'trafficSource.adwordsClickInfo.gclId',\n    'trafficSource.keyword',\n    'trafficSource.referralPath',\n    'trafficSource.adwordsClickInfo.slot'    \n    ]\n        \nfor col in col_drop:\n    train_flat.drop(columns=col, axis=1, inplace=True)\n    test_flat.drop(columns=col, axis=1, inplace=True)\n    print(col, 'is dropped')\n\nprint('All cleaned up')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ff256d36c0f956fca87dc8f7ba0ac3d47891397"},"cell_type":"markdown","source":"**This section covers the ENCODING and PREDICTING for LIGHTGBM**\n\nMany thanks to [SKR's](https://www.kaggle.com/sudalairajkumar) [kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-baseline-ga-customer-revenue) for the LabelEncoding code!!"},{"metadata":{"trusted":false,"_uuid":"4ccb451548322e07e5fabda587367fc406c428a2"},"cell_type":"code","source":"# Impute 0 for missing target values\ntrain_flat[\"totals.transactionRevenue\"].fillna(0, inplace=True)\ntrain_flat[\"totals.transactionRevenueLog\"].fillna(0, inplace=True)\ntrain_id = train_flat[\"fullVisitorId\"].values\ntest_id = test_flat[\"fullVisitorId\"].values\n\n# label encode the categorical variables and convert the numerical variables to float\ncat_cols = ['channelGrouping', \n            'device.operatingSystem', \n            #'geoNetwork.continent', \n            'geoNetwork.region', \n            'geoNetwork.metro',\n            'geoNetwork.city',\n            #'device.isMobile', \n            #'device.browser', \n            #'device.deviceCategory', \n            'trafficSource.source', \n            #'trafficSource.medium', \n            'day', \n            'month', \n            #'year', \n            'week', \n            #'totals.bounces', \n            'totals.newVisits'\n           ]\nfor col in cat_cols:\n    print(col)\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train_flat[col].values.astype('str')) + list(test_flat[col].values.astype('str')))\n    train_flat[col] = lbl.transform(list(train_flat[col].values.astype('str')))\n    test_flat[col] = lbl.transform(list(test_flat[col].values.astype('str')))\n    \n   # train_flat[col] = train_flat[col].astype('category')\n    #test_flat[col] = test_flat[col].astype('category')\n\nnum_cols = ['totals.hits', 'visitNumber', 'visitStartTime', 'totals.pageviews']    \nfor col in num_cols:\n    train_flat[col] = train_flat[col].astype(float)\n    test_flat[col] = test_flat[col].astype(float)\nprint('Done with transformations!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2041e48f266876b7397c7763af35111a3627710c"},"cell_type":"code","source":"train_flat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1f43d32654e458731c90fdeeb394eb448b97bfc3"},"cell_type":"code","source":"# Split the train dataset into development and valid based on time \ntrain_s1x = train_flat[train_flat['datestr']<='2017-06-30']\ntrain_s2x = train_flat[train_flat['datestr']>'2017-06-30']\ntrain_s1ylog = train_s1x[\"totals.transactionRevenueLog\"].values\ntrain_s2ylog = train_s2x[\"totals.transactionRevenueLog\"].values\n\ntrain_s1x = train_s1x[cat_cols + num_cols] \ntrain_s2x = train_s2x[cat_cols + num_cols] \ntest_X = test_flat[cat_cols + num_cols] \n\ntrain_flat_x = train_flat[cat_cols + num_cols] \ntrain_flat_ylog = train_flat[\"totals.transactionRevenueLog\"].values\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"46bd1cea0d3bbcf4f0390434714b52f965008a55"},"cell_type":"code","source":"train_s1x.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25ff2daa1770af0bc2a169a61c06c093ae8eda46","trusted":false},"cell_type":"code","source":"params = {\"early_stopping_rounds\":200, \n           \"eval_metric\" : 'rmse', \n            \"eval_set\" : [(train_s2x, train_s2ylog)],\n           'eval_names': ['valid'],\n           'verbose': 100,\n          'feature_name': num_cols, # that's actually the default\n         'categorical_feature': cat_cols # that's actually the default\n         }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34da3669c468d223bfb727ae4b7a73a576ef3a2a","trusted":false},"cell_type":"code","source":"print('Start training...')\n# train\ngbm = lgb.LGBMRegressor(n_estimators=4000,                                         \n                        learning_rate=0.017,            \n                        num_leaves=68,            \n                        metric= 'rmse',             \n                        #max_bin=400,            \n                        bagging_fraction=.8, #subsample            \n                        feature_fraction=.8, #colsample_bytree            \n                        bagging_frequency=10,            \n                        bagging_seed=2018,            \n                        max_depth=14,            \n                        #reg_alpha=.2,            \n                        #reg_lambda=.5,            \n                        min_split_gain=.1,            \n                        min_child_weight=.5,            \n                        min_child_samples=300,            \n                        silent=-1)\nbst = gbm.fit(train_s1x, train_s1ylog, **params)\nprint('done')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33c47c6f2916c6e57db3cf4ad789a22459a8f1ff","trusted":false},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82012470770ef4795bb8a0711aa19b9d07d818d9","trusted":false},"cell_type":"code","source":"lgb.plot_importance(gbm,max_num_features=30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f76e9168ea7e037d993f721c7ec097fffa4e5995","trusted":false},"cell_type":"code","source":"#predictions = bst.predict(test_X, num_iteration=bst.best_iteration)\npredictions = bst.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c0691612f6e8b8c55c302dedda8c1eeefbabe57","trusted":false},"cell_type":"code","source":"submission = pd.DataFrame({ 'fullVisitorId': test_id,'PredictedLogRevenue': predictions })\nsubmission = submission.groupby('fullVisitorId')['PredictedLogRevenue'].sum().reset_index()\nsubmission.to_csv(\"GA_submission_LGBM_20180923_log1plimitedfeaturescatv2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c41e8e45c949b62371ea967afc93787d2fdbbf44"},"cell_type":"markdown","source":"**KERAS IMPLEMENTATION**\n\nCredit to tutorial [here](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/).\nand [here](https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/)"},{"metadata":{"_uuid":"e15ca7aee16a9c68807bee13992d56f7c1603ac1","trusted":false},"cell_type":"code","source":"#def rmse(y_true, y_pred):\n    #return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n\n#scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n#scalarX.fit(train_s1x)\n\n#X = scalarX.transform(train_s1x)\n\n\n#model = Sequential()\n#model.add(Dense(24,input_dim=10,activation='relu'))\n#model.add(Dense(12,input_dim=10,activation='relu'))\n#model.add(Dense(6))\n#model.add(Dense(1))\n#model.compile(optimizer='adam',loss='mse',metrics=[rmse])\n\n#model.fit(X, train_s1ylog, epochs=5, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da50c42ca882b074601b81e53611eec216505dfd","trusted":false},"cell_type":"code","source":"#history = model.fit(train_s1x, train_s1ylog,validation_data=(train_s2x, train_s2ylog), epochs=5,batch_size=100, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fc69562c87baac981bfdcf4534539d16e12ce1b","trusted":false},"cell_type":"code","source":"#plt.plot(history.history['rmse'])\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8da7d1b68f7eb3a79f254ac91df0b6362b1c3dbe","trusted":false},"cell_type":"code","source":"#preds = model.predict(test_X)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}