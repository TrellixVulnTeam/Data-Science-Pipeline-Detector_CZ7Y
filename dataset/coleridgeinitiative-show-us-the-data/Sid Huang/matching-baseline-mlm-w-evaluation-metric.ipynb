{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook added [Evaluation Metric](https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/discussion/230091) to [Matching + Masked Dataset Modeling](https://www.kaggle.com/tungmphung/coleridge-predict-with-masked-dataset-modeling) blended w/ [Baseline Model](https://www.kaggle.com/chienhsianghung/coleridge-initiative-naive-cv-local-validation).<br>\nThanks to [@sakami](https://www.kaggle.com/sakami), [@tungmphung](https://www.kaggle.com/tungmphung), [@prashansdixit](https://www.kaggle.com/prashansdixit), [@suryadeepti](https://www.kaggle.com/suryadeepti) for sharing these amazing works.","metadata":{}},{"cell_type":"markdown","source":"# Install packages","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\n\nfrom IPython.display import clear_output\nclear_output()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T15:33:56.935958Z","iopub.execute_input":"2021-06-09T15:33:56.936378Z","iopub.status.idle":"2021-06-09T15:35:29.028716Z","shell.execute_reply.started":"2021-06-09T15:33:56.936347Z","shell.execute_reply":"2021-06-09T15:35:29.027389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport time\nimport datetime\nimport random\nimport glob\nimport importlib\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.autonotebook import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorForLanguageModeling, \\\nAutoModelForMaskedLM, Trainer, TrainingArguments, pipeline\n\nfrom typing import List\nimport string\nfrom functools import partial\nfrom collections import defaultdict, Counter\nfrom textblob import TextBlob\n\nSEED = 1\nsns.set()\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.032068Z","iopub.execute_input":"2021-06-09T15:35:29.032521Z","iopub.status.idle":"2021-06-09T15:35:29.047191Z","shell.execute_reply.started":"2021-06-09T15:35:29.03245Z","shell.execute_reply":"2021-06-09T15:35:29.045622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPUTE_CV = False\nALL_BLENDED = False\nBASELINE_HELPING = True\nMATCH_ONLY = False\n\nsample_submission = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\n\nif len(sample_submission) > 4: COMPUTE_CV = False\n    \nif COMPUTE_CV: \n    print('this submission notebook will compute CV score but commit notebook will not')\nelse:\n    print('this submission notebook will only be used to submit result')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.049425Z","iopub.execute_input":"2021-06-09T15:35:29.049969Z","iopub.status.idle":"2021-06-09T15:35:29.082195Z","shell.execute_reply.started":"2021-06-09T15:35:29.049924Z","shell.execute_reply":"2021-06-09T15:35:29.080953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\ntrain_files_path = '../input/coleridgeinitiative-show-us-the-data/train'\ntrain = pd.read_csv(train_path)\n\nif COMPUTE_CV: \n    sample_submission = train\n    paper_test_folder = '../input/coleridgeinitiative-show-us-the-data/train'\nelse:\n    sample_submission = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\n    paper_test_folder = '../input/coleridgeinitiative-show-us-the-data/test'\n    test_files_path = '../input/coleridgeinitiative-show-us-the-data/test'\n\nadnl_govt_labels_path = '../input/coleridge-additional-gov-datasets-22000popular/data_set_800_with2000popular.csv'","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.084301Z","iopub.execute_input":"2021-06-09T15:35:29.085257Z","iopub.status.idle":"2021-06-09T15:35:29.202466Z","shell.execute_reply.started":"2021-06-09T15:35:29.085209Z","shell.execute_reply":"2021-06-09T15:35:29.201458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"papers = {}\nfor paper_id in sample_submission['Id']:\n    with open(f'{paper_test_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.209951Z","iopub.execute_input":"2021-06-09T15:35:29.210912Z","iopub.status.idle":"2021-06-09T15:35:29.23133Z","shell.execute_reply.started":"2021-06-09T15:35:29.210864Z","shell.execute_reply":"2021-06-09T15:35:29.230413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Literal Matching","metadata":{}},{"cell_type":"markdown","source":"### Create a knowledge bank","metadata":{}},{"cell_type":"code","source":"all_labels = set()\n\nfor label_1, label_2, label_3 in train[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n    all_labels.add(str(label_1).lower())\n    all_labels.add(str(label_2).lower())\n    all_labels.add(str(label_3).lower())\n    \nprint(f'No. different labels: {len(all_labels)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.235427Z","iopub.execute_input":"2021-06-09T15:35:29.235899Z","iopub.status.idle":"2021-06-09T15:35:29.312208Z","shell.execute_reply.started":"2021-06-09T15:35:29.235843Z","shell.execute_reply":"2021-06-09T15:35:29.310904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Additional Govt Datasets","metadata":{}},{"cell_type":"code","source":"adnl_govt_labels = pd.read_csv(adnl_govt_labels_path)\n\nfor l in adnl_govt_labels.title:\n    all_labels.add(l)\n    \nall_labels = set(all_labels)\nprint(f'No. different labels: {len(all_labels)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.314034Z","iopub.execute_input":"2021-06-09T15:35:29.31478Z","iopub.status.idle":"2021-06-09T15:35:29.342785Z","shell.execute_reply.started":"2021-06-09T15:35:29.314705Z","shell.execute_reply":"2021-06-09T15:35:29.341436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Matching on test data","metadata":{}},{"cell_type":"code","source":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n\ndef totally_clean_text(txt):\n    txt = clean_text(txt)\n    txt = re.sub(' +', ' ', txt)\n    return txt","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.344564Z","iopub.execute_input":"2021-06-09T15:35:29.345302Z","iopub.status.idle":"2021-06-09T15:35:29.353107Z","shell.execute_reply.started":"2021-06-09T15:35:29.345255Z","shell.execute_reply":"2021-06-09T15:35:29.351363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"literal_preds = []\n\nfor paper_id in tqdm(sample_submission['Id']):\n    paper = papers[paper_id]\n    text_1 = '. '.join(section['text'] for section in paper).lower()\n    text_2 = totally_clean_text(text_1)\n    \n    labels = set()\n    for label in all_labels:\n        if label in text_1 or label in text_2:\n            labels.add(clean_text(label))\n    \n    literal_preds.append('|'.join(labels))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:29.355127Z","iopub.execute_input":"2021-06-09T15:35:29.355955Z","iopub.status.idle":"2021-06-09T15:35:30.739246Z","shell.execute_reply.started":"2021-06-09T15:35:29.355873Z","shell.execute_reply":"2021-06-09T15:35:30.738025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"literal_preds[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:30.74149Z","iopub.execute_input":"2021-06-09T15:35:30.742043Z","iopub.status.idle":"2021-06-09T15:35:30.751184Z","shell.execute_reply.started":"2021-06-09T15:35:30.741983Z","shell.execute_reply":"2021-06-09T15:35:30.749854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Masked Dataset Modeling","metadata":{}},{"cell_type":"markdown","source":"### Paths and Hyperparameters","metadata":{}},{"cell_type":"code","source":"PRETRAINED_PATH = '../input/coleridge-mlm-model/mlm-model'\nTOKENIZER_PATH = '../input/coleridge-mlm-model/model_tokenizer'\n\n\nMAX_LENGTH = 64\nOVERLAP = 20\n\nPREDICT_BATCH = 32 # a higher value requires higher GPU memory usage\n\nDATASET_SYMBOL = '$' # this symbol represents a dataset name\nNONDATA_SYMBOL = '#' # this symbol represents a non-dataset name","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:30.753858Z","iopub.execute_input":"2021-06-09T15:35:30.75454Z","iopub.status.idle":"2021-06-09T15:35:30.763447Z","shell.execute_reply.started":"2021-06-09T15:35:30.754481Z","shell.execute_reply":"2021-06-09T15:35:30.761852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform data to MLM format","metadata":{}},{"cell_type":"markdown","source":"### Load model and tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, use_fast=True)\nmodel = AutoModelForMaskedLM.from_pretrained(PRETRAINED_PATH)\n\nmlm = pipeline(\n    'fill-mask', \n    model=model,\n    tokenizer=tokenizer,\n    device=0 if torch.cuda.is_available() else -1\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:30.766239Z","iopub.execute_input":"2021-06-09T15:35:30.766889Z","iopub.status.idle":"2021-06-09T15:35:36.06337Z","shell.execute_reply.started":"2021-06-09T15:35:30.766841Z","shell.execute_reply":"2021-06-09T15:35:36.062078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Auxiliary functions","metadata":{}},{"cell_type":"code","source":"def jaccard_similarity(s1, s2):\n    l1 = s1.split(\" \")\n    l2 = s2.split(\" \")    \n    intersection = len(list(set(l1).intersection(l2)))\n    union = (len(l1) + len(l2)) - intersection\n    return float(intersection) / union\n\ndef clean_paper_sentence(s):\n    \"\"\"\n    This function is essentially clean_text without lowercasing.\n    \"\"\"\n    s = re.sub('[^A-Za-z0-9]+', ' ', str(s)).strip()\n    s = re.sub(' +', ' ', s)\n    return s\n\ndef shorten_sentences(sentences):\n    \"\"\"\n    Sentences that have more than MAX_LENGTH words will be split\n    into multiple sentences with overlappings.\n    \"\"\"\n    short_sentences = []\n    for sentence in sentences:\n        words = sentence.split()\n        if len(words) > MAX_LENGTH:\n            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n        else:\n            short_sentences.append(sentence)\n    return short_sentences\n\nconnection_tokens = {'s', 'of', 'and', 'in', 'on', 'for', 'data', 'dataset'}\ndef find_mask_candidates(sentence):\n    \"\"\"\n    Extract masking candidates for Masked Dataset Modeling from a given $sentence.\n    A candidate should be a continuous sequence of at least 2 words, \n    each of these words either has the first letter in uppercase or is one of\n    the connection words ($connection_tokens). Furthermore, the connection \n    tokens are not allowed to appear at the beginning and the end of the\n    sequence.\n    \"\"\"\n    def candidate_qualified(words):\n        while len(words) and words[0].lower() in connection_tokens:\n            words = words[1:]\n        while len(words) and words[-1].lower() in connection_tokens:\n            words = words[:-1]\n        \n        return len(words) >= 2\n    \n    candidates = []\n    \n    phrase_start, phrase_end = -1, -1\n    for id in range(1, len(sentence)):\n        word = sentence[id]\n        if word[0].isupper() or word in connection_tokens:\n            if phrase_start == -1:\n                phrase_start = phrase_end = id\n            else:\n                phrase_end = id\n        else:\n            if phrase_start != -1:\n                if candidate_qualified(sentence[phrase_start:phrase_end+1]):\n                    candidates.append((phrase_start, phrase_end))\n                phrase_start = phrase_end = -1\n    \n    if phrase_start != -1:\n        if candidate_qualified(sentence[phrase_start:phrase_end+1]):\n            candidates.append((phrase_start, phrase_end))\n    \n    return candidates","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:36.065046Z","iopub.execute_input":"2021-06-09T15:35:36.065431Z","iopub.status.idle":"2021-06-09T15:35:36.083094Z","shell.execute_reply.started":"2021-06-09T15:35:36.065391Z","shell.execute_reply":"2021-06-09T15:35:36.081752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transform","metadata":{}},{"cell_type":"code","source":"mask = mlm.tokenizer.mask_token","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:36.086064Z","iopub.execute_input":"2021-06-09T15:35:36.087183Z","iopub.status.idle":"2021-06-09T15:35:36.104217Z","shell.execute_reply.started":"2021-06-09T15:35:36.087138Z","shell.execute_reply":"2021-06-09T15:35:36.102579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_test_data = []\n\nfor paper_id in tqdm(sample_submission['Id']):\n    # load paper\n    paper = papers[paper_id]\n    \n    # extract sentences\n    sentences = set([clean_paper_sentence(sentence) for section in paper \n                     for sentence in section['text'].split('.')\n                    ])\n    sentences = shorten_sentences(sentences) # make sentences short\n    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n    sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study'])]\n    sentences = [sentence.split() for sentence in sentences] # sentence = list of words\n    \n    # mask\n    test_data = []\n    for sentence in sentences:\n        for phrase_start, phrase_end in find_mask_candidates(sentence):\n            dt_point = sentence[:phrase_start] + [mask] + sentence[phrase_end+1:]\n            test_data.append((' '.join(dt_point), ' '.join(sentence[phrase_start:phrase_end+1]))) # (masked text, phrase)\n    \n    all_test_data.append(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:36.10664Z","iopub.execute_input":"2021-06-09T15:35:36.108209Z","iopub.status.idle":"2021-06-09T15:35:36.282298Z","shell.execute_reply.started":"2021-06-09T15:35:36.108163Z","shell.execute_reply":"2021-06-09T15:35:36.281025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict","metadata":{}},{"cell_type":"code","source":"pred_mlm_labels = []\n\npbar = tqdm(total = len(all_test_data))\nfor test_data in all_test_data:\n    pred_bag = set()\n    \n    if len(test_data):\n        texts, phrases = list(zip(*test_data))\n        mlm_pred = []\n        for p_id in range(0, len(texts), PREDICT_BATCH):\n            batch_texts = texts[p_id:p_id+PREDICT_BATCH]\n            batch_pred = mlm(list(batch_texts), targets=[f' {DATASET_SYMBOL}', f' {NONDATA_SYMBOL}'])\n            \n            if len(batch_texts) == 1:\n                batch_pred = [batch_pred]\n            \n            mlm_pred.extend(batch_pred)\n        \n        for (result1, result2), phrase in zip(mlm_pred, phrases):\n            if (result1['score'] > result2['score']*2 and result1['token_str'] == DATASET_SYMBOL) or\\\n               (result2['score'] > result1['score']*2 and result2['token_str'] == NONDATA_SYMBOL):\n                pred_bag.add(clean_text(phrase))\n    \n    # filter labels by jaccard score \n    filtered_labels = []\n    \n    for label in sorted(pred_bag, key=len, reverse=True):\n        if len(filtered_labels) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered_labels):\n            filtered_labels.append(label)\n            \n    pred_mlm_labels.append('|'.join(filtered_labels))\n    pbar.update(1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-09T15:35:36.284148Z","iopub.execute_input":"2021-06-09T15:35:36.284849Z","iopub.status.idle":"2021-06-09T15:35:38.724922Z","shell.execute_reply.started":"2021-06-09T15:35:36.2848Z","shell.execute_reply":"2021-06-09T15:35:38.723577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_mlm_labels[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:38.726585Z","iopub.execute_input":"2021-06-09T15:35:38.727258Z","iopub.status.idle":"2021-06-09T15:35:38.734436Z","shell.execute_reply.started":"2021-06-09T15:35:38.727205Z","shell.execute_reply":"2021-06-09T15:35:38.733261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"def read_append_return(filename, train_files_path=train_files_path, output='text'):\n    \"\"\"\n    Function to read json file and then return the text data from them and append to the dataframe\n    \"\"\"\n    json_path = os.path.join(train_files_path, (filename+'.json'))\n    headings = []\n    contents = []\n    combined = []\n    with open(json_path, 'r') as f:\n        json_decode = json.load(f)\n        for data in json_decode:\n            headings.append(data.get('section_title'))\n            contents.append(data.get('text'))\n            combined.append(data.get('section_title'))\n            combined.append(data.get('text'))\n    \n    all_headings = ' '.join(headings)\n    all_contents = ' '.join(contents)\n    all_data = '. '.join(combined)\n    \n    if output == 'text':\n        return all_contents\n    elif output == 'head':\n        return all_headings\n    else:\n        return all_data\n    \n    \ndef text_cleaning(text):\n    '''\n    Converts all text to lower case, Removes special charecters, emojis and multiple spaces\n    text - Sentence that needs to be cleaned\n    '''\n    text = ''.join([k for k in text if k not in string.punctuation])\n    text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n    # text = re.sub(\"/'+/g\", ' ', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:38.735989Z","iopub.execute_input":"2021-06-09T15:35:38.736665Z","iopub.status.idle":"2021-06-09T15:35:38.750656Z","shell.execute_reply.started":"2021-06-09T15:35:38.736619Z","shell.execute_reply":"2021-06-09T15:35:38.749432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if BASELINE_HELPING or ALL_BLENDED:\n    tqdm.pandas()\n\n    train['text'] = train['Id'].progress_apply(read_append_return)\n\n    if not COMPUTE_CV:\n        sample_submission['text'] = sample_submission['Id'].progress_apply(partial(read_append_return, train_files_path=test_files_path))\n\n    train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:38.752294Z","iopub.execute_input":"2021-06-09T15:35:38.752986Z","iopub.status.idle":"2021-06-09T15:35:58.387341Z","shell.execute_reply.started":"2021-06-09T15:35:38.752939Z","shell.execute_reply":"2021-06-09T15:35:58.385979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if BASELINE_HELPING or ALL_BLENDED:\n    tqdm.pandas()\n    \n    train['text'] = train['text'].progress_apply(text_cleaning)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:35:58.389386Z","iopub.execute_input":"2021-06-09T15:35:58.390239Z","iopub.status.idle":"2021-06-09T15:40:02.513307Z","shell.execute_reply.started":"2021-06-09T15:35:58.390193Z","shell.execute_reply":"2021-06-09T15:40:02.511812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"if BASELINE_HELPING or ALL_BLENDED:\n    temp_1 = [x.lower() for x in train['dataset_label'].unique()]\n    temp_2 = [x.lower() for x in train['dataset_title'].unique()]\n    temp_3 = [x.lower() for x in train['cleaned_label'].unique()]\n\n    existing_labels = all_labels\n\n    print(f'len(temp_1) = {len(temp_1)}')\n    print(f'len(temp_2) = {len(temp_2)}')\n    print(f'len(temp_3) = {len(temp_3)}')\n    print(f'len(existing_labels) = {len(existing_labels)}')\n\n    id_list = []\n    lables_list = []\n    for index, row in tqdm(sample_submission.iterrows()):\n        sample_text = row['text']\n        row_id = row['Id']\n        temp_df = train[train['text'] == text_cleaning(sample_text)]\n        cleaned_labels = temp_df['cleaned_label'].to_list()\n\n        for known_label in existing_labels:\n            if known_label in sample_text.lower():\n                cleaned_labels.append(clean_text(known_label))\n\n        cleaned_labels = [clean_text(x) for x in cleaned_labels]\n        cleaned_labels = set(cleaned_labels)\n        lables_list.append('|'.join(cleaned_labels))\n        id_list.append(row_id)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:47:03.32363Z","iopub.execute_input":"2021-06-09T15:47:03.324073Z","iopub.status.idle":"2021-06-09T15:47:09.299528Z","shell.execute_reply.started":"2021-06-09T15:47:03.324033Z","shell.execute_reply":"2021-06-09T15:47:09.297843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Aggregate final predictions and write submission file","metadata":{}},{"cell_type":"code","source":"final_predictions = []\n\nif ALL_BLENDED:\n    for literal_match, mlm_pred, lables_match in zip(literal_preds, pred_mlm_labels, lables_list):\n        temp = [literal_match, mlm_pred, lables_match]\n        temp = [pred for pred in temp if pred]\n        temp = ('|').join(temp)\n        final_predictions.append(temp)\n        \nelif BASELINE_HELPING:\n    for literal_match, mlm_pred, lables_match in zip(literal_preds, pred_mlm_labels, lables_list):\n        if lables_match:\n            final_predictions.append(lables_match)\n        else:\n            final_predictions.append(mlm_pred)\n\nelif MATCH_ONLY:\n    final_predictions = literal_preds\n\nelse:    \n    for literal_match, mlm_pred in zip(literal_preds, pred_mlm_labels):\n        if literal_match:\n            final_predictions.append(literal_match)\n        else:\n            final_predictions.append(mlm_pred)\n\nsample_submission['PredictionString'] = final_predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:47:18.670941Z","iopub.execute_input":"2021-06-09T15:47:18.671399Z","iopub.status.idle":"2021-06-09T15:47:18.681872Z","shell.execute_reply.started":"2021-06-09T15:47:18.671367Z","shell.execute_reply":"2021-06-09T15:47:18.680595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['PredictionString'] = final_predictions\nsample_submission[['Id', 'PredictionString']].to_csv('submission.csv', index=False)\n\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:47:24.803732Z","iopub.execute_input":"2021-06-09T15:47:24.804119Z","iopub.status.idle":"2021-06-09T15:47:24.82925Z","shell.execute_reply.started":"2021-06-09T15:47:24.804088Z","shell.execute_reply":"2021-06-09T15:47:24.827878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Metric","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/discussion/230091\ndef compute_fbeta(y_true: List[List[str]],\n                  y_pred: List[List[str]],\n                  beta: float = 0.5) -> float:\n    \"\"\"Compute the Jaccard-based micro FBeta score.\n\n    References\n    ----------\n    - https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/overview/evaluation\n    \"\"\"\n\n    def _jaccard_similarity(str1: str, str2: str) -> float:\n        a = set(str1.split()) \n        b = set(str2.split())\n        c = a.intersection(b)\n        return float(len(c)) / (len(a) + len(b) - len(c))\n\n    tp = 0  # true positive\n    fp = 0  # false positive\n    fn = 0  # false negative\n    for ground_truth_list, predicted_string_list in zip(y_true, y_pred):\n        predicted_string_list_sorted = sorted(predicted_string_list)\n        for ground_truth in sorted(ground_truth_list):            \n            if len(predicted_string_list_sorted) == 0:\n                fn += 1\n            else:\n                similarity_scores = [\n                    _jaccard_similarity(ground_truth, predicted_string)\n                    for predicted_string in predicted_string_list_sorted\n                ]\n                matched_idx = np.argmax(similarity_scores)\n                if similarity_scores[matched_idx] >= 0.5:\n                    predicted_string_list_sorted.pop(matched_idx)\n                    tp += 1\n                else:\n                    fn += 1\n        fp += len(predicted_string_list_sorted)\n\n    tp *= (1 + beta ** 2)\n    fn *= beta ** 2\n    fbeta_score = tp / (tp + fp + fn)\n    return fbeta_score","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:47:25.528068Z","iopub.execute_input":"2021-06-09T15:47:25.528436Z","iopub.status.idle":"2021-06-09T15:47:25.54282Z","shell.execute_reply.started":"2021-06-09T15:47:25.528405Z","shell.execute_reply":"2021-06-09T15:47:25.538908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    COMPUTE_CV_SCORE = compute_fbeta(sample_submission['cleaned_label'].apply(lambda x: [x]),\\\n                  sample_submission['PredictionString'].apply(lambda x: x.split('|')))\n    print('COMPUTE_CV_SCORE =', COMPUTE_CV_SCORE)\nelse:\n    print(f'COMPUTE_CV = {COMPUTE_CV}')\n    \nprint(f'ALL_BLENDED = {ALL_BLENDED}')\nprint(f'BASELINE_HELPING = {BASELINE_HELPING}')\nprint(f'MATCH_ONLY = {MATCH_ONLY}')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:47:26.615732Z","iopub.execute_input":"2021-06-09T15:47:26.616121Z","iopub.status.idle":"2021-06-09T15:47:26.624952Z","shell.execute_reply.started":"2021-06-09T15:47:26.616075Z","shell.execute_reply":"2021-06-09T15:47:26.623775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"|   | CV | LB |\n| --- | --- | --- |\n| og | 0.604 | 0.536 |\n| og s1.5 |   | 0.535 |\n| og s2.5 |   | 0.535 |\n| pred_mlm_labels | 0.108 |   |\n| lables_list | 0.548 |   |\n| all | 0.261 |   |\n| og2all | 0.454 |   |\n| 150 400 |   | 0.536 |\n| 200 300 |   | 0.536 |\n| 2021 |   | 0.536 |\n| 42 |   | 0.536 |\n| 42 s1.5 |   | 0.535 |\n| 42 .70 |   | 0.536 |\n| 42 .80 |   | 0.536 |\n| MATCH_ONLY |   | 0.533 |\n| BASELINE_HELPING |   |   |","metadata":{}}]}