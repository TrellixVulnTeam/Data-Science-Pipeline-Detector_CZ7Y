{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook shows how to fine-tune a BERT model (from huggingface) for our dataset recognition task.\n\nNote that internet is needed during the training phase (for downloading the bert-base-cased model). Internet can be turned off during prediction.","metadata":{}},{"cell_type":"markdown","source":"Changes by Group 12:\n- Added 'train.head()' twice\n- Added the comment about loading the articles\n- Added and updated docstrings\n- Changed 'id' to 'paper_id' to prevent shadowing\n- Only append every other negative sample, to reduce the amount of negative samples\n","metadata":{}},{"cell_type":"markdown","source":"## Install packages","metadata":{}},{"cell_type":"code","source":"!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-27T19:28:16.288956Z","iopub.execute_input":"2021-05-27T19:28:16.289395Z","iopub.status.idle":"2021-05-27T19:28:43.517253Z","shell.execute_reply.started":"2021-05-27T19:28:16.289272Z","shell.execute_reply":"2021-05-27T19:28:43.516372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport time\nimport datetime\nimport random\nimport glob\nimport importlib\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm  # Progressbar\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nrandom.seed(123)\nnp.random.seed(456)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:28:43.52099Z","iopub.execute_input":"2021-05-27T19:28:43.521285Z","iopub.status.idle":"2021-05-27T19:28:44.254629Z","shell.execute_reply.started":"2021-05-27T19:28:43.521257Z","shell.execute_reply":"2021-05-27T19:28:44.253859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy my_seqeval.py to the working directory because the input directory is non-writable\n!cp /kaggle/input/coleridge-packages/my_seqeval.py ./","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:28:44.255787Z","iopub.execute_input":"2021-05-27T19:28:44.256108Z","iopub.status.idle":"2021-05-27T19:28:44.898191Z","shell.execute_reply.started":"2021-05-27T19:28:44.256076Z","shell.execute_reply":"2021-05-27T19:28:44.896878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 64 # max no. words for each sentence.\nOVERLAP = 20 # if a sentence exceeds MAX_LENGTH, we split it to multiple sentences with overlapping\n\nMAX_SAMPLE = None # set a small number for experimentation, set None for production.","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:28:44.89986Z","iopub.execute_input":"2021-05-27T19:28:44.900254Z","iopub.status.idle":"2021-05-27T19:28:44.906406Z","shell.execute_reply.started":"2021-05-27T19:28:44.90021Z","shell.execute_reply":"2021-05-27T19:28:44.904571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\npaper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\n\ntrain = pd.read_csv(train_path)\ntrain = train[:MAX_SAMPLE]\nprint(f'No. raw training rows: {len(train)}')\ntrain.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:28:44.909625Z","iopub.execute_input":"2021-05-27T19:28:44.910102Z","iopub.status.idle":"2021-05-27T19:28:45.038194Z","shell.execute_reply.started":"2021-05-27T19:28:44.910076Z","shell.execute_reply":"2021-05-27T19:28:45.037491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Group by publication, training labels should have the same form as expected output.","metadata":{}},{"cell_type":"code","source":"train = train.groupby('Id').agg({\n    'pub_title': 'first',\n    'dataset_title': '|'.join,\n    'dataset_label': '|'.join,\n    'cleaned_label': '|'.join\n}).reset_index()\n\nprint(f'No. grouped training rows: {len(train)}')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:28:45.04132Z","iopub.execute_input":"2021-05-27T19:28:45.04157Z","iopub.status.idle":"2021-05-27T19:28:45.40687Z","shell.execute_reply.started":"2021-05-27T19:28:45.041545Z","shell.execute_reply":"2021-05-27T19:28:45.40604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the text of the articles into a dictionary:\npapers = {}\nfor paper_id in train['Id'].unique():\n    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper\n","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:28:45.408547Z","iopub.execute_input":"2021-05-27T19:28:45.408895Z","iopub.status.idle":"2021-05-27T19:29:36.640526Z","shell.execute_reply.started":"2021-05-27T19:28:45.408859Z","shell.execute_reply":"2021-05-27T19:29:36.639738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform data to NER format","metadata":{}},{"cell_type":"code","source":"def clean_training_text(txt):\n    \"\"\" Similar to the default clean_text function but without lowercasing.\n    Replaces all sequences of non-alphabetical and non-numerical chars\n    ('[^A-Za-z0-9]+') with one space (' ').\n    \"\"\"\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n\ndef shorten_sentences(sentences):\n    \"\"\"Split sentences into shorter ones with OVERLAP chars shared and a\n    length of MAX_LENGTH. Returns a list.\n    \"\"\"\n    short_sentences = []\n    for sentence in sentences:\n        words = sentence.split()\n        if len(words) > MAX_LENGTH:\n            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n        else:\n            short_sentences.append(sentence)\n    return short_sentences\n\ndef find_sublist(big_list, small_list):\n    \"\"\"Find the indices of big_list where small_list occurs. Returns a\n    list of these indices.\n    \"\"\"\n    all_positions = []\n    for i in range(len(big_list) - len(small_list) + 1):\n        if small_list == big_list[i:i+len(small_list)]:\n            all_positions.append(i)\n    \n    return all_positions\n","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:29:36.641745Z","iopub.execute_input":"2021-05-27T19:29:36.642065Z","iopub.status.idle":"2021-05-27T19:29:36.653049Z","shell.execute_reply.started":"2021-05-27T19:29:36.642033Z","shell.execute_reply":"2021-05-27T19:29:36.652204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NEW (Emma): only a small subset of the additional labels!\nadditional_labels_path = '../input/filtered-bigger-govt-dataset/ExtraLabelsCleaned.txt'\nadd_labels = pd.read_csv(additional_labels_path)\nprint(f'Number of rows of additional labels: {len(add_labels)}')\nadd_labels_set = set(add_labels['Label'])\n\nadd_labels_set_escaped = set()\nfor label in add_labels_set:\n    label_escaped = label.replace(\"-\", r\"\\-\").replace(\"(\", r\"\\(\").replace(\")\", r\"\\)\")\n    label_cleaned = clean_training_text(label_escaped)\n    add_labels_set_escaped.add(label_cleaned)\n\nadd_labels.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:29:36.654277Z","iopub.execute_input":"2021-05-27T19:29:36.654613Z","iopub.status.idle":"2021-05-27T19:29:36.678409Z","shell.execute_reply.started":"2021-05-27T19:29:36.654576Z","shell.execute_reply":"2021-05-27T19:29:36.677774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tag_sentence(sentence, labels):\n    \"\"\"Create IOB tag sequence of a sentence with B and I on the\n    'labels' and O on other words.\n    Requirement: sentence should be cleaned, because Str.split() is used.\n    \"\"\"\n    \n    sentence_lower = sentence.lower()\n    sentence_words_lower = sentence.lower().split()\n    sentence_words = sentence.split()\n    \n    if labels is not None and any(re.findall(f'\\\\b{label}\\\\b', sentence_lower)\n                                  for label in labels): # positive sample\n        nes = ['O'] * len(sentence_words)\n\n        for label in labels:\n            label_words = label.split()\n            all_pos = find_sublist(sentence_words_lower, label_words)\n            \n            # NEW (Emma):\n#             n_of_matches = len(all_pos)\n#             if n_of_matches > 0:\n#                 LABEL_FREQS[label] = LABEL_FREQS.get(label, 0) + n_of_matches\n            \n            # OLD:\n            for pos in all_pos:\n                nes[pos] = 'B'\n                for i in range(pos+1, pos+len(label_words)):\n                    nes[i] = 'I'\n\n        return True, list(zip(sentence_words, nes))\n        \n    else: # negative sample\n        nes = ['O'] * len(sentence_words)\n        return False, list(zip(sentence_words, nes))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:29:36.680309Z","iopub.execute_input":"2021-05-27T19:29:36.68063Z","iopub.status.idle":"2021-05-27T19:29:36.68916Z","shell.execute_reply.started":"2021-05-27T19:29:36.680597Z","shell.execute_reply":"2021-05-27T19:29:36.687214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create IOB tag sequences for all the ","metadata":{}},{"cell_type":"code","source":"cnt_pos, cnt_neg = 0, 0  # number of sentences that contain/not contain labels\ncnt_neg_total = 0  # NEW: amount of encountered negative sentences (always bigger or equal to cnt_neg)\nner_data = []\n\npbar = tqdm(total=len(train),position=0, leave=True)\nfor i, paper_id, dataset_label in train[['Id', 'dataset_label']].itertuples():\n    # paper\n    paper = papers[paper_id]\n    \n    # labels\n    labels = dataset_label.split('|')\n    labels = set([clean_training_text(label) for label in labels])\n    for label in labels: \n        add_labels_set_escaped.add(label.lower())  # only have lower cases in this list\n\n    # sentences\n    sentences = set([clean_training_text(sentence) for section in paper \n                 for sentence in section['text'].split('.') \n                ])\n    sentences = shorten_sentences(sentences) # make sentences short\n    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n    \n    # NEW: Select the labels that are in this text:\n    text = \"\\s\".join(sentences)\n    lower_labels = set()\n    for label in add_labels_set_escaped:\n        if label in text.lower():\n            lower_labels.add(label)\n\n    # OLD:\n    # positive sample\n    last = None\n    for sentence in sentences:\n        is_positive, tags = tag_sentence(sentence, lower_labels)\n        if is_positive:\n            cnt_pos += 1\n            ner_data.append(tags)\n        elif any(word in sentence.lower() for word in ['data', 'study']):\n            if cnt_neg_total % 2 == 0:  # NEW: only append every other negative sample\n                ner_data.append(tags)\n                cnt_neg += 1\n            cnt_neg_total += 1\n    \n    # process bar\n    pbar.update(1)\n    pbar.set_description(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")\n    \n    # NEW:\n#     if i >= 10:\n#         break\n    # OLD:\n    \n# shuffling\nrandom.shuffle(ner_data)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-27T19:29:36.691Z","iopub.execute_input":"2021-05-27T19:29:36.691962Z","iopub.status.idle":"2021-05-27T19:35:07.19268Z","shell.execute_reply.started":"2021-05-27T19:29:36.691861Z","shell.execute_reply":"2021-05-27T19:35:07.19185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write the tokens (sentences) and the IOB tags to a file, with the format:\n\n{\n\n\"tokens\": \\[\"Source\", \"USDA\", \"Economic\", \"Research\", \"Service\", \"using\", \"Agricultural\", \"Resource\", \"Management\", \"Survey\", \"2006\"\\],\n\n\"tags\": \\[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"O\"\\]\n\n}\n\nAnother example:\n\n{\n\n\"tokens\": \\[\"Currently\", \"we\", \"have\", \"used\", \"the\", \"COVID\", \"19\", \"Open\", \"Research\", \"Dataset\", \"CORD\", \"19\", \"publicly\", \"made\", \"available\", \"by\", \"Allen\", \"Institute\", \"of\", \"AI\", \"on\", \"20th\", \"March\", \"2020\"\\],\n\n\"tags\": \\[\"O\", \"O\", \"O\", \"O\", \"O\", \"B\", \"I\", \"I\", \"I\", \"I\", \"I\", \"I\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"\\]\n\n}\n\nNegative sentences only have \"O\" tags.\n","metadata":{}},{"cell_type":"code","source":"with open('train_ner.json', 'w') as f:\n    for row in ner_data:\n        words, nes = list(zip(*row))\n        row_json = {'tokens' : words, 'tags' : nes}\n        json.dump(row_json, f)\n        f.write('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:21:54.875752Z","iopub.execute_input":"2021-05-25T17:21:54.876264Z","iopub.status.idle":"2021-05-25T17:22:30.503599Z","shell.execute_reply.started":"2021-05-25T17:21:54.876227Z","shell.execute_reply":"2021-05-25T17:22:30.501807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tune a BERT model for NER","metadata":{}},{"cell_type":"code","source":"!python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n--model_name_or_path 'bert-base-cased' \\\n--train_file './train_ner.json' \\\n--validation_file './train_ner.json' \\\n--num_train_epochs 1 \\\n--per_device_train_batch_size 8 \\\n--per_device_eval_batch_size 8 \\\n--save_steps 15000 \\\n--output_dir './output' \\\n--report_to 'none' \\\n--seed 123 \\\n--do_train ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T15:16:40.671764Z","iopub.status.idle":"2021-05-25T15:16:40.672209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the tuning finishes, we should find our model in './output'.","metadata":{}}]}