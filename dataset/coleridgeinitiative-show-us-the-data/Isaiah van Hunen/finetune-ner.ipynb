{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using BERT for NER for Coleridge Challenge\nThis notebook shows how to fine-tune a BERT model (from huggingface) for our dataset recognition task.\n\nNote that internet is needed during the training phase (for downloading the bert-base-cased model). Therefore, this notebook is executed seperately. Internet can be turned off during prediction.","metadata":{}},{"cell_type":"markdown","source":"## Install packages","metadata":{}},{"cell_type":"code","source":"!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-05T09:16:59.707526Z","iopub.execute_input":"2021-06-05T09:16:59.707825Z","iopub.status.idle":"2021-06-05T09:17:27.117134Z","shell.execute_reply.started":"2021-06-05T09:16:59.707753Z","shell.execute_reply":"2021-06-05T09:17:27.116086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport time\nimport datetime\nimport random\nimport glob\nimport importlib\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nrandom.seed(123)\nnp.random.seed(456)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:17:27.120584Z","iopub.execute_input":"2021-06-05T09:17:27.120856Z","iopub.status.idle":"2021-06-05T09:17:27.877395Z","shell.execute_reply.started":"2021-06-05T09:17:27.12083Z","shell.execute_reply":"2021-06-05T09:17:27.876673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# QUESTION: What does my_seqeval.py do and do we need it?\n\n# Copy my_seqeval.py to the working directory because the input directory is non-writable\n!cp /kaggle/input/coleridge-packages/my_seqeval.py ./","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:17:29.303922Z","iopub.execute_input":"2021-06-05T09:17:29.304246Z","iopub.status.idle":"2021-06-05T09:17:29.949005Z","shell.execute_reply.started":"2021-06-05T09:17:29.304213Z","shell.execute_reply":"2021-06-05T09:17:29.948094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 48 # Max number of words for each sentence\nOVERLAP = 16 # If a sentence exceeds MAX_LENGTH, split into multiple sentences with OVERLAP\nMAX_SAMPLE = None # Restrict samples for experimentation and speed, set None for production\nCUSTOM_SPLIT = False","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:17:33.967494Z","iopub.execute_input":"2021-06-05T09:17:33.967832Z","iopub.status.idle":"2021-06-05T09:17:33.972583Z","shell.execute_reply.started":"2021-06-05T09:17:33.967802Z","shell.execute_reply":"2021-06-05T09:17:33.971236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"# Load labels\nif CUSTOM_SPLIT:\n    train_path = '../input/colridge-custom-dataset-split/data_subsets/Train_set.csv'\nelse:\n    train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\npaper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\n\ntrain = pd.read_csv(train_path)\ntrain = train[:MAX_SAMPLE]\nprint(f'Loaded {len(train)} training labels')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:17:35.217688Z","iopub.execute_input":"2021-06-05T09:17:35.218006Z","iopub.status.idle":"2021-06-05T09:17:35.367185Z","shell.execute_reply.started":"2021-06-05T09:17:35.217975Z","shell.execute_reply":"2021-06-05T09:17:35.365718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aggregate labels per publication\ntrain = train.groupby('Id').agg({\n    'pub_title': 'first',\n    'dataset_title': '|'.join,\n    'dataset_label': '|'.join,\n    'cleaned_label': '|'.join\n}).reset_index()\n\nprint(f'Number of publications in training labels: {len(train)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:17:49.096387Z","iopub.execute_input":"2021-06-05T09:17:49.096752Z","iopub.status.idle":"2021-06-05T09:17:49.428537Z","shell.execute_reply.started":"2021-06-05T09:17:49.096721Z","shell.execute_reply":"2021-06-05T09:17:49.42766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load paper contents\npapers = {}\nfor paper_id in tqdm(train['Id'].unique()):\n    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:18:51.044301Z","iopub.execute_input":"2021-06-05T09:18:51.044827Z","iopub.status.idle":"2021-06-05T09:18:58.642273Z","shell.execute_reply.started":"2021-06-05T09:18:51.044789Z","shell.execute_reply":"2021-06-05T09:18:58.641371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform data to NER format","metadata":{}},{"cell_type":"code","source":"def clean_training_text(txt):\n    \"\"\"\n    Clean text without lowercasing.\n    \"\"\"\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n \ndef shorten_sentences(sentences):\n    '''\n    Split sentences with overlap if too long\n    '''\n    short_sentences = []\n    for sentence in sentences:\n        words = sentence.split()\n        if len(words) > MAX_LENGTH:\n            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n        else:\n            short_sentences.append(sentence)\n    return short_sentences\n\ndef find_sublist(big_list, small_list):\n    '''\n    Find offset(s) of sublist in list\n    '''\n    all_positions = []\n    for i in range(len(big_list) - len(small_list) + 1):\n        if small_list == big_list[i:i+len(small_list)]:\n            all_positions.append(i)\n    return all_positions\n\ndef tag_sentence(sentence, labels):\n    '''\n    Create Named EntitieS (NES) for sentences\n    REQUIREMENT: both sentence and labels are already cleaned\n    NOTE: Uses `O` for non-entities, `B` for beginning of entities and `I` for continuing entities\n    '''\n    sentence_words = sentence.split()\n    nes = ['O'] * len(sentence_words)\n    \n    # QUESTION: Why is regex used? Is it a faster initial determination (of positive labels)?\n    if labels is not None and any(re.findall(f'\\\\b{label}\\\\b', sentence)\n                                  for label in labels): # Contains at least 1 dataset entity\n        for label in labels:\n            label_words = label.split()\n\n            # Find, for each label, the offset(s) in the sentence\n            all_pos = find_sublist(sentence_words, label_words)\n            for pos in all_pos:\n                nes[pos] = 'B'\n                for i in range(pos+1, pos+len(label_words)):\n                    nes[i] = 'I'\n\n        return True, list(zip(sentence_words, nes))\n        \n    else: # If only negative entities, return immediately\n        return False, list(zip(sentence_words, nes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_pos, cnt_neg = 0, 0 # Number of sentences that contain/do not contain labels\nner_data = [] # List of (sentence_words, NES) elements\n\npbar = tqdm(total=len(train))\nfor i, _id, dataset_label in train[['Id', 'dataset_label']].itertuples():\n    paper = papers[_id]\n    labels = dataset_label.split('|')\n    labels = [clean_training_text(label) for label in labels]\n    \n    # Clean sentences\n    sentences = set([clean_training_text(sentence) for section in paper \n        for sentence in section['text'].split('.') \n    ])\n    sentences = shorten_sentences(sentences)\n    sentences = [sentence for sentence in sentences if len(sentence) > 10] # Enforce minimum-length sentences\n    # NOTE: This selection could technically lead to false negatives\n    \n    \n    # Selection of sentences for NER training data\n    # Use dataset entities and sentences with related concepts \n    # NOTE: Using all sentences would introduce a class imbalance\n    for sentence in sentences:\n        is_positive, tags = tag_sentence(sentence, labels)\n        if is_positive:\n            cnt_pos += 1\n            ner_data.append(tags)\n        elif any(word in sentence.lower() for word in ['data', 'study']): \n            ner_data.append(tags)\n            cnt_neg += 1\n    \n    pbar.update(1)\n    pbar.set_description(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")\n\n# Shuffle sentence tags\nrandom.shuffle(ner_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write training data to disk\nwith open('train_ner.json', 'w') as f:\n    for row in ner_data:\n        words, nes = list(zip(*row))\n        row_json = {'tokens' : words, 'tags' : nes}\n        json.dump(row_json, f)\n        f.write('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tune a BERT model for NER","metadata":{}},{"cell_type":"code","source":"# TODO: Inspect command flags and options\n\n!python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n--model_name_or_path 'bert-base-cased' \\\n--train_file './train_ner.json' \\\n--validation_file './train_ner.json' \\\n--num_train_epochs 1 \\\n--per_device_train_batch_size 8 \\\n--per_device_eval_batch_size 8 \\\n--save_steps 15000 \\\n--output_dir './output' \\\n--report_to 'none' \\\n--seed 123 \\\n--do_train ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}