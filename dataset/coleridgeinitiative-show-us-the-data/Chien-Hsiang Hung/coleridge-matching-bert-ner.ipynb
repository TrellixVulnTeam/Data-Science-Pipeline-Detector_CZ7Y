{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook gives a simple combination of literal matching and Named Entity Recognition using BERT (base model from huggingface).\n\nThe training phase of the BERT model was done in another kernel: Pytorch BERT for Named Entity Recognition.","metadata":{}},{"cell_type":"code","source":"MAX_SAMPLE = None # set a small number for experimentation, set None for production.","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:53:26.082139Z","iopub.execute_input":"2021-05-25T03:53:26.082579Z","iopub.status.idle":"2021-05-25T03:53:26.08722Z","shell.execute_reply.started":"2021-05-25T03:53:26.082479Z","shell.execute_reply":"2021-05-25T03:53:26.086497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install packages","metadata":{}},{"cell_type":"code","source":"!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:53:26.124664Z","iopub.execute_input":"2021-05-25T03:53:26.125141Z","iopub.status.idle":"2021-05-25T03:54:57.742344Z","shell.execute_reply.started":"2021-05-25T03:53:26.125111Z","shell.execute_reply":"2021-05-25T03:54:57.741286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport time\nimport datetime\nimport random\nimport glob\nimport importlib\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nrandom.seed(123)\nnp.random.seed(456)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T03:54:57.744468Z","iopub.execute_input":"2021-05-25T03:54:57.745064Z","iopub.status.idle":"2021-05-25T03:54:58.572545Z","shell.execute_reply.started":"2021-05-25T03:54:57.745032Z","shell.execute_reply":"2021-05-25T03:54:58.571535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\ntrain = pd.read_csv(train_path)\ntrain = train[:MAX_SAMPLE]\n\npaper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\npapers = {}\nfor paper_id in train['Id'].unique():\n    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:54:58.586645Z","iopub.execute_input":"2021-05-25T03:54:58.587028Z","iopub.status.idle":"2021-05-25T03:55:50.983495Z","shell.execute_reply.started":"2021-05-25T03:54:58.587Z","shell.execute_reply":"2021-05-25T03:55:50.982613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_path = '../input/coleridgeinitiative-show-us-the-data/sample_submission.csv'\nsample_submission = pd.read_csv(sample_submission_path)\n\npaper_test_folder = '../input/coleridgeinitiative-show-us-the-data/test'\nfor paper_id in sample_submission['Id']:\n    with open(f'{paper_test_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:50.985072Z","iopub.execute_input":"2021-05-25T03:55:50.985402Z","iopub.status.idle":"2021-05-25T03:55:51.021118Z","shell.execute_reply.started":"2021-05-25T03:55:50.985361Z","shell.execute_reply":"2021-05-25T03:55:51.020122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Literal matching","metadata":{}},{"cell_type":"code","source":"train_files_path = '../input/coleridgeinitiative-show-us-the-data/train'\ntest_files_path = '../input/coleridgeinitiative-show-us-the-data/test'","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:51.022436Z","iopub.execute_input":"2021-05-25T03:55:51.022761Z","iopub.status.idle":"2021-05-25T03:55:51.027172Z","shell.execute_reply.started":"2021-05-25T03:55:51.022731Z","shell.execute_reply":"2021-05-25T03:55:51.025836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n\n\ndef totally_clean_text(txt):\n    txt = clean_text(txt)\n    txt = re.sub(' +', ' ', txt)\n    return txt\n\n\ndef text_cleaning(text):\n    '''\n    Converts all text to lower case, Removes special charecters, emojis and multiple spaces\n    text - Sentence that needs to be cleaned\n    '''\n    text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n    text = re.sub(' +', ' ', text)\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    return text\n\n\ndef read_json_pub(filename, train_data_path=train_files_path, output='text'):\n    json_path = os.path.join(train_data_path, (filename+'.json'))\n    headings = []\n    contents = []\n    combined = []\n    \n    with open(json_path, 'r') as f:\n        json_decode = json.load(f)\n        for data in json_decode:\n            headings.append(data.get('section_title'))\n            contents.append(data.get('text'))\n            combined.append(data.get('section_title'))\n            combined.append(data.get('text'))\n    \n    all_headings = ' '.join(headings)\n    all_contents = ' '.join(contents)\n    all_data = '. '.join(combined)\n    \n    if output == 'text':\n        return all_contents\n    elif output == 'head':\n        return all_headings\n    else:\n        return all_data","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:51.029139Z","iopub.execute_input":"2021-05-25T03:55:51.029591Z","iopub.status.idle":"2021-05-25T03:55:51.046927Z","shell.execute_reply.started":"2021-05-25T03:55:51.02953Z","shell.execute_reply":"2021-05-25T03:55:51.045942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\nadnl_govt_labels = pd.read_csv('../input/bigger-govt-dataset-list/data_set_800.csv')\n\nliteral_preds = []\nto_append = []\nfor index, row in tqdm(sample_submission.iterrows()):\n    to_append = [row['Id'],'']\n    large_string = str(read_json_pub(row['Id'], test_files_path))\n    clean_string = text_cleaning(large_string)\n    for index, row2 in adnl_govt_labels.iterrows():\n        query_string = str(row2['title'])\n        if query_string in clean_string:\n            if to_append[1] != '' and clean_text(query_string) not in to_append[1]:\n                to_append[1] = to_append[1] + '|' + clean_text(query_string)\n            if to_append[1] == '':\n                to_append[1] = clean_text(query_string)\n    literal_preds.append(*to_append[1:])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:51.048296Z","iopub.execute_input":"2021-05-25T03:55:51.048602Z","iopub.status.idle":"2021-05-25T03:55:52.352177Z","shell.execute_reply.started":"2021-05-25T03:55:51.048552Z","shell.execute_reply":"2021-05-25T03:55:52.351291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a knowledge bank","metadata":{}},{"cell_type":"markdown","source":"### Matching on test data","metadata":{}},{"cell_type":"code","source":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n\ndef totally_clean_text(txt):\n    txt = clean_text(txt)\n    txt = re.sub(' +', ' ', txt)\n    return txt","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:52.353835Z","iopub.execute_input":"2021-05-25T03:55:52.35422Z","iopub.status.idle":"2021-05-25T03:55:52.360524Z","shell.execute_reply.started":"2021-05-25T03:55:52.35418Z","shell.execute_reply":"2021-05-25T03:55:52.359433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bert prediction","metadata":{"trusted":true}},{"cell_type":"markdown","source":"### Paths and Hyperparameters","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 64 # max no. words for each sentence.\nOVERLAP = 20 # if a sentence exceeds MAX_LENGTH, we split it to multiple sentences with overlapping\n\nPREDICT_BATCH = 64000 \n\nPRETRAINED_PATH = '../input/pytorch-bert-for-named-entity-recognition/output'\nTEST_INPUT_SAVE_PATH = './input_data'\nTEST_NER_DATA_FILE = 'test_ner_input.json'\nTRAIN_PATH = '../input/pytorch-bert-for-named-entity-recognition/train_ner.json'\nVAL_PATH = '../input/pytorch-bert-for-named-entity-recognition/train_ner.json'\n\nPREDICTION_SAVE_PATH = './pred'\nPREDICTION_FILE = 'test_predictions.txt'","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:52.361859Z","iopub.execute_input":"2021-05-25T03:55:52.362151Z","iopub.status.idle":"2021-05-25T03:55:52.373104Z","shell.execute_reply.started":"2021-05-25T03:55:52.362122Z","shell.execute_reply":"2021-05-25T03:55:52.37188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transform data to NER format","metadata":{}},{"cell_type":"markdown","source":"Group by publication, training labels should have the same form as expected output.","metadata":{}},{"cell_type":"code","source":"train = train.groupby('Id').agg({\n    'pub_title': 'first',\n    'dataset_title': '|'.join,\n    'dataset_label': '|'.join,\n    'cleaned_label': '|'.join\n}).reset_index()\n\nprint(f'No. grouped training rows: {len(train)}')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:52.374341Z","iopub.execute_input":"2021-05-25T03:55:52.374679Z","iopub.status.idle":"2021-05-25T03:55:53.047061Z","shell.execute_reply.started":"2021-05-25T03:55:52.374645Z","shell.execute_reply":"2021-05-25T03:55:53.045682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_training_text(txt):\n    \"\"\"\n    similar to the default clean_text function but without lowercasing.\n    \"\"\"\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n\ndef shorten_sentences(sentences):\n    short_sentences = []\n    for sentence in sentences:\n        words = sentence.split()\n        if len(words) > MAX_LENGTH:\n            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n        else:\n            short_sentences.append(sentence)\n    return short_sentences","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:53.048184Z","iopub.execute_input":"2021-05-25T03:55:53.048465Z","iopub.status.idle":"2021-05-25T03:55:53.055499Z","shell.execute_reply.started":"2021-05-25T03:55:53.048437Z","shell.execute_reply":"2021-05-25T03:55:53.054476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rows = [] # test data in NER format\npaper_length = [] # store the number of sentences each paper has\n\nfor paper_id in sample_submission['Id']:\n    # load paper\n    paper = papers[paper_id]\n    \n    # extract sentences\n    sentences = [clean_training_text(sentence) for section in paper \n                 for sentence in section['text'].split('.')\n                ]\n    sentences = shorten_sentences(sentences) # make sentences short\n    sentences = [sentence for sentence in sentences if len(sentence) > 1] # only accept sentences with length > 10 chars\n    sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study'])]\n        \n    # collect all sentences in json\n    for sentence in sentences:\n        sentence_words = sentence.split()\n        dummy_tags = ['O']*len(sentence_words)\n        test_rows.append({'tokens' : sentence_words, 'tags' : dummy_tags})\n    \n    # track which sentence belongs to which data point\n    paper_length.append(len(sentences))\n    \nprint(f'total number of sentences: {len(test_rows)}')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:53.057014Z","iopub.execute_input":"2021-05-25T03:55:53.057404Z","iopub.status.idle":"2021-05-25T03:55:53.117605Z","shell.execute_reply.started":"2021-05-25T03:55:53.057365Z","shell.execute_reply":"2021-05-25T03:55:53.116746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Do predict and collect results","metadata":{}},{"cell_type":"code","source":"os.environ[\"MODEL_PATH\"] = f\"{PRETRAINED_PATH}\"\nos.environ[\"TRAIN_FILE\"] = f\"{TRAIN_PATH}\"\nos.environ[\"VALIDATION_FILE\"] = f\"{VAL_PATH}\"\nos.environ[\"TEST_FILE\"] = f\"{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}\"\nos.environ[\"OUTPUT_DIR\"] = f\"{PREDICTION_SAVE_PATH}\"","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:53.119005Z","iopub.execute_input":"2021-05-25T03:55:53.119295Z","iopub.status.idle":"2021-05-25T03:55:53.124729Z","shell.execute_reply.started":"2021-05-25T03:55:53.119267Z","shell.execute_reply":"2021-05-25T03:55:53.123623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy my_seqeval.py to the working directory because the input directory is non-writable\n!cp /kaggle/input/coleridge-packages/my_seqeval.py ./\n\n# make necessart directories and files\nos.makedirs(TEST_INPUT_SAVE_PATH, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:53.126221Z","iopub.execute_input":"2021-05-25T03:55:53.12653Z","iopub.status.idle":"2021-05-25T03:55:53.888049Z","shell.execute_reply.started":"2021-05-25T03:55:53.126502Z","shell.execute_reply":"2021-05-25T03:55:53.886891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_predict():\n    !python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n    --model_name_or_path \"$MODEL_PATH\" \\\n    --train_file \"$TRAIN_FILE\" \\\n    --validation_file \"$VALIDATION_FILE\" \\\n    --test_file \"$TEST_FILE\" \\\n    --output_dir \"$OUTPUT_DIR\" \\\n    --report_to 'none' \\\n    --seed 123 \\\n    --do_predict","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:53.890056Z","iopub.execute_input":"2021-05-25T03:55:53.890458Z","iopub.status.idle":"2021-05-25T03:55:53.897628Z","shell.execute_reply.started":"2021-05-25T03:55:53.890414Z","shell.execute_reply":"2021-05-25T03:55:53.896348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_outputs = []\n\nfor batch_begin in range(0, len(test_rows), PREDICT_BATCH):\n    # write data rows to input file\n    with open(f'{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}', 'w') as f:\n        for row in test_rows[batch_begin:batch_begin+PREDICT_BATCH]:\n            json.dump(row, f)\n            f.write('\\n')\n    \n    # remove output dir\n    !rm -r \"$OUTPUT_DIR\"\n    \n    # do predict\n    bert_predict()\n    \n    # read predictions\n    with open(f'{PREDICTION_SAVE_PATH}/{PREDICTION_FILE}') as f:\n        this_preds = f.read().split('\\n')[:-1]\n        bert_outputs += [pred.split() for pred in this_preds]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:55:53.899279Z","iopub.execute_input":"2021-05-25T03:55:53.899581Z","iopub.status.idle":"2021-05-25T03:57:59.429436Z","shell.execute_reply.started":"2021-05-25T03:55:53.899532Z","shell.execute_reply":"2021-05-25T03:57:59.4283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Restore Dataset labels from predictions","metadata":{}},{"cell_type":"code","source":"# get test sentences\ntest_sentences = [row['tokens'] for row in test_rows]\n\ndel test_rows","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.431872Z","iopub.execute_input":"2021-05-25T03:57:59.432218Z","iopub.status.idle":"2021-05-25T03:57:59.437663Z","shell.execute_reply.started":"2021-05-25T03:57:59.432186Z","shell.execute_reply":"2021-05-25T03:57:59.436901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_dataset_labels = [] # store all dataset labels for each publication\n\nfor length in paper_length:\n    labels = set()\n    for sentence, pred in zip(test_sentences[:length], bert_outputs[:length]):\n        curr_phrase = ''\n        for word, tag in zip(sentence, pred):\n            if tag == 'B': # start a new phrase\n                if curr_phrase:\n                    labels.add(curr_phrase)\n                    curr_phrase = ''\n                curr_phrase = word\n            elif tag == 'I' and curr_phrase: # continue the phrase\n                curr_phrase += ' ' + word\n            else: # end last phrase (if any)\n                if curr_phrase:\n                    labels.add(curr_phrase)\n                    curr_phrase = ''\n        # check if the label is the suffix of the sentence\n        if curr_phrase:\n            labels.add(curr_phrase)\n            curr_phrase = ''\n    \n    # record dataset labels for this publication\n    bert_dataset_labels.append(labels)\n    \n    del test_sentences[:length], bert_outputs[:length]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.438715Z","iopub.execute_input":"2021-05-25T03:57:59.438983Z","iopub.status.idle":"2021-05-25T03:57:59.458887Z","shell.execute_reply.started":"2021-05-25T03:57:59.438958Z","shell.execute_reply":"2021-05-25T03:57:59.457569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_dataset_labels[:5]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.460175Z","iopub.execute_input":"2021-05-25T03:57:59.460553Z","iopub.status.idle":"2021-05-25T03:57:59.4802Z","shell.execute_reply.started":"2021-05-25T03:57:59.46052Z","shell.execute_reply":"2021-05-25T03:57:59.479179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filter based on Jaccard score and clean","metadata":{}},{"cell_type":"code","source":"def jaccard_similarity(s1, s2):\n    l1 = s1.split(\" \")\n    l2 = s2.split(\" \")    \n    intersection = len(list(set(l1).intersection(l2)))\n    union = (len(l1) + len(l2)) - intersection\n    return float(intersection) / union\n\nfiltered_bert_labels = []\n\nfor labels in bert_dataset_labels:\n    filtered = []\n    \n    for label in sorted(labels, key=len):\n        label = clean_text(label)\n        if len(filtered) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered):\n            filtered.append(label)\n    \n    filtered_bert_labels.append('|'.join(filtered))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.481732Z","iopub.execute_input":"2021-05-25T03:57:59.482045Z","iopub.status.idle":"2021-05-25T03:57:59.491514Z","shell.execute_reply.started":"2021-05-25T03:57:59.482016Z","shell.execute_reply":"2021-05-25T03:57:59.490537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_bert_labels[:5]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.492819Z","iopub.execute_input":"2021-05-25T03:57:59.493284Z","iopub.status.idle":"2021-05-25T03:57:59.50502Z","shell.execute_reply.started":"2021-05-25T03:57:59.493247Z","shell.execute_reply":"2021-05-25T03:57:59.504268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aggregate final predictions and write submission file","metadata":{}},{"cell_type":"code","source":"final_predictions = bert_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_predictions = []\n# for literal_match, bert_pred in zip(literal_preds, filtered_bert_labels):\n#     if literal_match:\n#         final_predictions.append(literal_match)\n#     else:\n#         final_predictions.append(bert_pred)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.506842Z","iopub.execute_input":"2021-05-25T03:57:59.507133Z","iopub.status.idle":"2021-05-25T03:57:59.514969Z","shell.execute_reply.started":"2021-05-25T03:57:59.507097Z","shell.execute_reply":"2021-05-25T03:57:59.514215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['PredictionString'] = final_predictions\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.516298Z","iopub.execute_input":"2021-05-25T03:57:59.51676Z","iopub.status.idle":"2021-05-25T03:57:59.546366Z","shell.execute_reply.started":"2021-05-25T03:57:59.516719Z","shell.execute_reply":"2021-05-25T03:57:59.545622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(f'submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:57:59.547687Z","iopub.execute_input":"2021-05-25T03:57:59.547972Z","iopub.status.idle":"2021-05-25T03:57:59.556543Z","shell.execute_reply.started":"2021-05-25T03:57:59.547943Z","shell.execute_reply":"2021-05-25T03:57:59.55571Z"},"trusted":true},"execution_count":null,"outputs":[]}]}