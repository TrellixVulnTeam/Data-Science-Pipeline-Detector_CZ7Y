{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import copy\nimport csv\nimport time\nfrom typing import Optional, Tuple, List, Dict, Type\nimport lightgbm as lgb\nfrom sklearn.metrics import log_loss\nfrom scipy import stats\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\nfrom torch.nn.modules.module import Module\nfrom torch.nn.modules.dropout import Dropout\nfrom torch.nn.modules.linear import Linear\nfrom torch.nn.modules.normalization import LayerNorm\nfrom torch.nn.parameter import Parameter\nfrom torch.nn.init import xavier_uniform_\nfrom torch.nn.init import constant_\nfrom torch.nn.init import xavier_normal_\nfrom torch.nn.modules.container import ModuleList\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\n\ntorch.manual_seed(0)\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class OttoDataset(Dataset):\n    def __init__(self, data, target, idx, mode):\n\n        self.data = data\n        self.target = target\n        self.idx = np.asarray(idx)\n        self.mode = mode\n\n    def __len__(self):\n        return self.idx.shape[0]\n\n    def __getitem__(self, index):\n        index = self.idx[index]\n        row = self.data[index]\n        \n        if self.mode == 'test':\n            return torch.tensor(row)\n        else:\n            label = self.target[index]\n            return torch.tensor(row), torch.tensor(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/otto-group-product-classification-challenge/train.csv')\ntest = pd.read_csv('../input/otto-group-product-classification-challenge/test.csv')\nsample_submit = pd.read_csv('../input/otto-group-product-classification-challenge/sampleSubmission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'] = train['target'].str.replace('Class_', '')\ntrain['target'] = train['target'].astype(int) - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"excluded_column = ['target', 'id']\ncols = [c for c in train.columns if c not in (excluded_column + [])]\n\ndata = pd.concat([train, test]).reset_index()\nfor c in cols:\n    data[c] = np.log(1+data[c])\ndata_scale = StandardScaler().fit_transform(data[cols])\ndata = pd.concat([data[['id', 'target']], pd.DataFrame(data_scale)], axis=1)\n\ntrain = data[~data['target'].isnull()].reset_index(drop=True)\ntest = data[data['target'].isnull()].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"excluded_column = ['target', 'id']\ncols = [c for c in train.columns if c not in excluded_column]\n\ntest_dataset = OttoDataset(test[cols].values, np.zeros(test.shape[0]), list(range(test.shape[0])), 'test')\ntest_loader = torch.utils.data.DataLoader(\n      dataset=test_dataset,  \n      batch_size=64, \n      shuffle=False, \n      num_workers=2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MLPNet (nn.Module):\n    def __init__(self):\n        super(MLPNet, self).__init__()\n        self.fc1 = nn.Linear(93, 512)   \n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 512)\n        self.fc4 = nn.Linear(512, 9)\n        self.dropout1 = nn.Dropout2d(0.2)\n        self.dropout2 = nn.Dropout2d(0.2)\n        self.dropout3 = nn.Dropout2d(0.2)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = F.relu(self.fc3(x))\n        x = self.dropout3(x)\n        x = self.fc4(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nnum_epochs = 50\n \nNFOLDS = 5\nRANDOM_STATE = 871972\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, \n                        random_state=RANDOM_STATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = []\noof = np.zeros((len(train), 9))\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y = train['target'])):\n    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n    y_train, y_valid = X_train['target'].astype(int), X_valid['target'].astype(int)\n    train_dataset = OttoDataset(X_train[cols].values, y_train.values, list(range(X_train.shape[0])), 'train')\n    valid_dataset = OttoDataset(X_valid[cols].values, y_valid.values, list(range(X_valid.shape[0])), 'train')\n    \n    # set data loader\n    train_loader = torch.utils.data.DataLoader(\n          dataset=train_dataset,  \n          batch_size=64, \n          shuffle=True, \n          num_workers=2) \n    valid_loader = torch.utils.data.DataLoader(\n          dataset=valid_dataset,\n          batch_size=64, \n          shuffle=False,\n          num_workers=2)\n    net = MLPNet().to(device)\n    \n    # optimizing\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n    for epoch in range(num_epochs):\n        # initialize each epoch\n        train_loss, train_acc, val_loss, val_acc = 0, 0, 0, 0\n        \n        # ======== train_mode ======\n        net.train()\n        for i, (datas, labels) in enumerate(train_loader):  \n            datas, labels = datas.to(device), labels.to(device)\n            optimizer.zero_grad()  \n            feature = net(datas.float())\n            outputs = feature\n            loss = criterion(outputs, labels) \n            train_loss += loss.item()\n            acc = (outputs.max(1)[1] == labels).sum()\n            train_acc += acc.item() \n            loss.backward()      \n            optimizer.step() \n            avg_train_loss = train_loss / len(train_loader.dataset) \n            avg_train_acc = train_acc / len(train_loader.dataset) \n        # ======== valid_mode ======\n        net.eval()\n        with torch.no_grad():\n            for datas, labels in valid_loader:        \n                datas, labels = datas.to(device), labels.to(device)\n                feature = net(datas.float()) \n                outputs = feature\n                loss = criterion(outputs, labels) \n                val_loss += loss.item()\n                acc = (outputs.max(1)[1] == labels).sum()\n                val_acc += acc.item()\n        avg_val_loss = val_loss / len(valid_loader.dataset)\n        avg_val_acc = val_acc / len(valid_loader.dataset)\n        print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}' \n                       .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))\n        \n    # ======== valid_mode ======\n    net.eval()\n    valid_predict = []\n    with torch.no_grad():\n        for datas, labels in valid_loader:        \n            datas, labels = datas.to(device), labels.to(device)\n            feature = net(datas.float()) \n            outputs = F.softmax(feature, dim=1)\n            valid_predict.append(outputs)\n    oof[valid_index] = torch.cat(valid_predict, dim=0)\n    # ======== test ======\n    test_predict = []\n    with torch.no_grad():\n        for datas in test_loader:        \n            datas = datas.to(device)\n            feature = net(datas.float())\n            outputs = F.softmax(feature, dim=1)\n            test_predict.append(outputs)\n    y_preds.append(torch.cat(test_predict, dim=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_name = ['nn_' + str(i) for i in range(9)]\n\npd.DataFrame(oof, columns = column_name).to_csv('oof_nn.csv', index=False)\n\ny_pred_nn = np.zeros((len(y_preds[0]), 9))\nfor i in range(len(y_preds)):\n    y_pred_nn += y_preds[i].cpu().numpy() / len(y_preds)\npd.DataFrame(y_pred_nn, columns = column_name).to_csv('submit_nn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.concat([sample_submit[['id']], pd.DataFrame(y_pred_nn)], axis = 1)\nsubmit.columns = sample_submit.columns\nsubmit.to_csv('submit.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}