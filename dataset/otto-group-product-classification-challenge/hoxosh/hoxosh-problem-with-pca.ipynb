{"cells":[{"metadata":{},"cell_type":"markdown","source":"Sorry I use Japanese.  \n\nPCAを使った時にだけLBスコアが下がってしまいます。（なぜかCVスコアはそこまで変わりない）  \nリークしている可能性がありますが、どうしたらこのバグが治るかわかりません。  \nアイデアがあったらぜひコメントで教えてください！\n\n私が書いたコードは\n・Training dataをfitし、transformで全体のデータを処理する\n・CVの中のTraining dataをfitし、transformで全体のデータを処理する\n\nという2つのものです。\n後ろの処理は最後に載せます。"},{"metadata":{},"cell_type":"markdown","source":"Import"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from typing import Any, Dict\nimport umap\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components\nfrom sklearn.decomposition import PCA\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nimport tensorflow as tf\nfrom sklearn.decomposition import PCA\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import Reshape, LayerNormalization, PReLU\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import AveragePooling1D\nfrom tensorflow.keras.layers import Dropout\n\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras import regularizers\nimport os\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/otto-group-product-classification-challenge/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/otto-group-product-classification-challenge/test.csv\")\nss = pd.read_csv(\"/kaggle/input/otto-group-product-classification-challenge/sampleSubmission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def docking(train: pd.DataFrame, test: pd.DataFrame) -> [pd.DataFrame, pd.Series]:\n    print(\"docking\")\n    dict_a: Dict\n    dict_a = {\"Class_1\": 0,\n              \"Class_2\": 1,\n              \"Class_3\": 2,\n              \"Class_4\": 3,\n              \"Class_5\": 4,\n              \"Class_6\": 5,\n              \"Class_7\": 6,\n              \"Class_8\": 7,\n              \"Class_9\": 8,\n              }\n    target = train[\"target\"].map(dict_a)\n    con_df = pd.concat([train, test], sort=False)\n    \"\"\"\n    targetは Class_n　→ n-1　にした（1-9だったので）\n    trainのcolumnsは feat_n → n にする\n    \"\"\"\n    con_df = con_df.drop([\"id\", \"target\"], axis=1)\n    con_df.columns = con_df.columns.map(lambda x: int(x[5:]))\n    con_df = np.log1p(con_df)\n\n    return con_df, target\n\n\ndef split_data(df, df_pca, df_features, target, join_pca: bool):\n    # df = np.log1p(df)\n    # df = pd.concat([df, df_pca], axis=1, join=\"inner\")\n    if join_pca:\n        # df = pd.concat([df, df_pca], axis=1, join_axes=[df.index])\n        df = pd.concat([df.reset_index(drop=True), df_pca.reset_index(drop=True)], axis=1)\n    # df = df_pca.copy()\n\n    # df = pd.concat([df, df_features], axis=1, join_axes=[df.index])\n    df = pd.concat([df.reset_index(drop=True), df_features.reset_index(drop=True)], axis=1)\n    train_df = df[:len(target)]\n    test_df = df[len(target):]\n    return train_df, test_df\n\n\ndef make_features(df: pd.DataFrame):\n    memo = pd.DataFrame()\n    memo[\"count_zero\"] = df[df == 0].count(axis=1)\n    # memo[\"count_one\"] = df[df == 1].count(axis=1)\n    return memo\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_pca(df: pd.DataFrame, target: pd.Series):\n    n = 10\n    pca = PCA(n_components=n)\n    pca.fit(df[:len(target)])\n    # df_pca = pca.fit_transform(df)\n    df_pca = pca.transform(df)\n    n_name = [f\"pca{i}\" for i in range(n)]\n    df_pca = pd.DataFrame(df_pca, columns=n_name)\n    return df_pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df, target = docking(train, test)\ndf_pca = do_pca(df, target)\ndf_features = make_features(df)\ndf_train, df_test = split_data(df, df_pca, df_features, target, join_pca=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"補足： headでよく見ると、pcaの値がdf_trainとdf_testで一致してた！  \nindexによるマージミスと思われる"},{"metadata":{},"cell_type":"markdown","source":"# Define Simple NN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def nn_train_model(\n        df: pd.DataFrame, target: pd.DataFrame, test: pd.DataFrame\n):\n    n_splits = 5\n    num_class = 9\n    epochs = 10\n    lr_init = 0.01\n    bs = 256\n    num_features = df.shape[1]\n    folds = KFold(n_splits=n_splits, random_state=71, shuffle=True)\n\n    model = tf.keras.models.Sequential([\n        Input(shape=(num_features,)),\n        Dense(128, kernel_initializer='glorot_uniform', activation=\"relu\"),\n        BatchNormalization(),\n        Dropout(0.25),\n\n        Dense(128, kernel_initializer='glorot_uniform', activation=\"relu\"),\n        BatchNormalization(),\n        Dropout(0.25),\n\n        Dense(64, kernel_initializer='glorot_uniform', activation=\"relu\"),\n        BatchNormalization(),\n        Dropout(0.25),\n\n        Dense(num_class, activation=\"softmax\")\n    ])\n    \n    # print(model.summary())\n    optimizer = tf.keras.optimizers.Adam(lr=lr_init, decay=0.0001)\n\n    \"\"\"callbacks\"\"\"\n    callbacks = []\n    # callbacks.append(tf.keras.callbacks.LearningRateScheduler(lr_scheduler))\n    # log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    # callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1))\n\n    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n    preds = np.zeros((test.shape[0], num_class))\n    for trn_idx, val_idx in folds.split(df, target):\n        train_x = df.iloc[trn_idx, :].values\n        val_x = df.iloc[val_idx, :].values\n        train_y = target[trn_idx].values\n        val_y = target[val_idx].values\n\n        # train_x = np.reshape(train_x, (-1, num_features, 1))\n        # val_x = np.reshape(val_x, (-1, num_features, 1))\n        model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=epochs, verbose=2, batch_size=bs,\n                  callbacks=callbacks)\n        preds += model.predict(test.values) / n_splits\n\n    return preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training dataをfitし、transformで全体のデータを処理する\n"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"pred1 = nn_train_model(df_train, target, df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"補足： Foldごとにtrain-valのlossが極端に違うので気づいた。  \nKFoldはデフォルトだとshuffleしない & ラベルとidが明確に相関してるのでシャッフルしよう"},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submit_file(pred: np.ndarray, ss: pd.DataFrame) -> None:\n    save_path = \"submission.csv\"\n    ss.iloc[:, 1:] = pred\n    ss.to_csv(save_path, index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_submit_file(pred1, ss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}