{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\nfrom sklearn import decomposition\nfrom sklearn.metrics import log_loss\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import GridSearchCV  \nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nfrom matplotlib import pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read training data\ndata = pd.read_csv('../input/train.csv')\nfrom sklearn.model_selection import train_test_split\ntrain_X = data.drop([\"target\",\"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05f9a6780ded1f8963e6f3a74ab9dd1291065c3b"},"cell_type":"markdown","source":"# Representation of the target with numerical values "},{"metadata":{"trusted":true,"_uuid":"65cbce005771c252f84f34d86c961ff2b3343817"},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(data[\"target\"])\ntrain_y = le.transform(data[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d184c6a35fc4d3164084ad6c39dd57996abc75a8"},"cell_type":"markdown","source":"# Splitting the data (train.csv)"},{"metadata":{"trusted":true,"_uuid":"57b91d36153bb4d5fd5d99eb9d572d538a88567d"},"cell_type":"code","source":"# split train set into 2 parts with same distribution: 80% train, 20% validation\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\nfor train_index, test_index in sss.split(train_X.values, train_y):\n    X_train = train_X.values[train_index]\n    X_val = train_X.values[test_index]\n\n    y_train = train_y[train_index]\n    y_val = train_y[test_index]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c260afa93b9c1e8014d83c5636b86ce05347c9b"},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_uuid":"0615e2443bb340a0fff34c0f36fe93b606569606"},"cell_type":"markdown","source":"## Null values ?"},{"metadata":{"_uuid":"e1fd5c3b3726fb21a52698d63ce40d7e103e45c9","trusted":true},"cell_type":"code","source":"missing_val_count_by_column = (data.isnull().sum())\nprint(missing_val_count_by_column.sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"504b9ed30335e4cc5f82d5f57f040e6d4dcb3177","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3493e4b05d3e146704479c53f8c449772de706ca"},"cell_type":"markdown","source":"## Balance in the class ?"},{"metadata":{"_uuid":"02cd6cb5e2f02bdc04a7035660cbce02676f7f69","trusted":true},"cell_type":"code","source":"data[\"target\"].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00c7c3a3057e1047b53cd80112093b03bc260278"},"cell_type":"code","source":"data[\"target\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47b0d2dec4da9e6e5b14a334c4f1f412b5a52cc0"},"cell_type":"code","source":"ros = RandomOverSampler()\nX_ros, y_ros = ros.fit_sample(X_train, y_train)\n\nunique, counts = np.unique(y_ros, return_counts=True)\n\nprint(np.asarray((unique, counts)).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d752064cf5d6413b866b5b2ecf418bc44198d397"},"cell_type":"code","source":"pd.Series(y_ros).value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6a2db8a2079f24e2c1b035457a6aaee2257acb9"},"cell_type":"markdown","source":"## Scaling"},{"metadata":{"trusted":true,"_uuid":"981dabd27067abb5939149af2daf115149a6d3e5"},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_val_scaled = scaler.transform(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2aedfe2c127eb8f290d42a4269eb90159f2ed45"},"cell_type":"code","source":"test_data = pd.read_csv('../input/test.csv')\ntest_X = test_data.drop([\"id\"], axis=1)\nscaler_all = StandardScaler()\ntrain_X_scaled = scaler_all.fit_transform(train_X)\ntest_X_scaled = scaler.transform(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b94a5516a8d811a6faa16fe79895a93b2d78ca0"},"cell_type":"markdown","source":"## PCA ?"},{"metadata":{"trusted":true,"_uuid":"9a0aeddf336d92da1b5472cb9d223b57a2eeb6f9"},"cell_type":"code","source":"pca = decomposition.PCA(n_components=20)\npca.fit(X_train_scaled)\n\nX_train_pca = pca.transform(X_train_scaled)\nprint(pca.explained_variance_ratio_)\nprint(pca.explained_variance_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e881d55f072c099df693f1548d00872ecccea704"},"cell_type":"markdown","source":"## Determine number of components"},{"metadata":{"trusted":true,"_uuid":"553d74b42428e21b0c80e732b783fb8a565ccbba"},"cell_type":"code","source":"pca = decomposition.PCA()\npca.fit(X_train_scaled)\n\nX_train_pca = pca.transform(X_train_scaled)\n#print(np.cumsum(pca.explained_variance_ratio_))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c5d4696389f1a1ee3f0aa1c36844291c3b11d9b"},"cell_type":"markdown","source":"At least 95% of the variance in the data can be explained by 77 components."},{"metadata":{"_uuid":"aa48f7354ea0e9dc7bf0692d67a88cb60cd21e8c"},"cell_type":"markdown","source":"# XGBOOST"},{"metadata":{"trusted":true,"_uuid":"2c511cd29cd60d84725b1a0009d5e8eab30437f2"},"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X_train_scaled, y_train)\npreds = xgb.predict_proba(X_val_scaled)\nscore = log_loss(y_val, preds)\nprint(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17a25bf7fb51d39e2ee0bf2e4069d7009f5fbf4c"},"cell_type":"code","source":"xgb.get_params","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e13792b02e9ce180224117d04871234a1fb1ecbc"},"cell_type":"markdown","source":"# Fitting and Tuning an Algorithm"},{"metadata":{"trusted":true,"_uuid":"3b1cff124643b697d0af73fc491c383cc11617c6"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n\"\"\"\nparam_test = {\n    'n_estimators': [300],\n    'n_jobs': [4], #Number of jobs to run in parallel. -1 means using all processors\n}\ngsearch = GridSearchCV(estimator = XGBClassifier(), param_grid = param_test, scoring='neg_log_loss', n_jobs=-1,iid=False, cv=3,verbose=1, return_train_score=True)\ngsearch.fit(X_train_scaled,y_train)\npd.DataFrame(gsearch.cv_results_)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62234056b9bda891e0a8004f44eb4a31eca56ed9","scrolled":true},"cell_type":"code","source":"scores = []\nn_estimators = [100,200,400,450,500,525,550,600,700]\n\nfor nes in n_estimators:\n    xgb = XGBClassifier(learning_rate =0.1, n_estimators=nes, max_depth=7, min_child_weight=3, subsample=0.8, \n                             colsample_bytree=0.8, nthread=4, seed=42, objective='multi:softprob')\n    xgb.fit(X_train_scaled, y_train)\n    preds = xgb.predict_proba(X_val_scaled)\n    score = log_loss(y_val, preds)\n    scores.append(score)\n    print(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60f87bc3f6dedd810fa71a07b9085d9de02fcd1d"},"cell_type":"code","source":"plt.plot(n_estimators,scores,'o-')\nplt.ylabel(log_loss)\nplt.xlabel(\"n_estimator\")\nprint(\"best n_estimator {}\".format(n_estimators[np.argmin(scores)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1926e3ea787ae8182e1347acba64442129cc4935"},"cell_type":"code","source":"scores_md = []\nmax_depths = [1,3,5,6,7,8,10]\n\nfor md in max_depths:\n    xgb = XGBClassifier(learning_rate =0.1, n_estimators=n_estimators[np.argmin(scores)], \n                        max_depth=md, min_child_weight=3, subsample=0.8, \n                        colsample_bytree=0.8, nthread=4, seed=42, objective='multi:softprob')\n    xgb.fit(X_train_scaled, y_train)\n    preds = xgb.predict_proba(X_val_scaled)\n    score = log_loss(y_val, preds)\n    scores_md.append(score)\n    print(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99adafe37865a121f88facce9d3956196f5ea83e"},"cell_type":"code","source":"plt.plot(max_depths,scores_md,'o-')\nplt.ylabel(log_loss)\nplt.xlabel(\"max_depth\")\nprint(\"best max_depth {}\".format(max_depths[np.argmin(scores_md)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"277fe6eac575d100db410b35545c7e5bbf1de1ad"},"cell_type":"code","source":"scores_mcw = []\nmin_child_weights = [1,2,3,4,5]\n\nfor mcw in min_child_weights:\n    xgb = XGBClassifier(learning_rate =0.1, n_estimators=n_estimators[np.argmin(scores)],\n                        max_depth=max_depths[np.argmin(scores_md)], \n                        min_child_weight=mcw, subsample=0.8, \n                        colsample_bytree=0.8, nthread=4, seed=42, objective='multi:softprob')\n    xgb.fit(X_train_scaled, y_train)\n    preds = xgb.predict_proba(X_val_scaled)\n    score = log_loss(y_val, preds)\n    scores_mcw.append(score)\n    print(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"107bee0a04e85afc8451291374bc148aac61154a"},"cell_type":"code","source":"plt.plot(min_child_weights,scores_mcw,\"o-\")\nplt.ylabel(log_loss)\nplt.xlabel(\"min_child_weight\")\nprint(\"best min_child_weight {}\".format(min_child_weights[np.argmin(scores_mcw)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"320381481b464bd17705ed3ef51169220e2d33ba"},"cell_type":"code","source":"scores_ss = []\nsubsamples = [0.5,0.6,0.7,0.8,0.9,1]\n\nfor ss in subsamples:\n    xgb = XGBClassifier(learning_rate =0.1, n_estimators=n_estimators[np.argmin(scores)], \n                        max_depth=max_depths[np.argmin(scores_md)],\n                        min_child_weight=min_child_weights[np.argmin(scores_mcw)], subsample=ss, \n                        colsample_bytree=0.8, nthread=4, seed=42, objective='multi:softprob')\n    xgb.fit(X_train_scaled, y_train)\n    preds = xgb.predict_proba(X_val_scaled)\n    score = log_loss(y_val, preds)\n    scores_ss.append(score)\n    print(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0a97046b737688b8d81db17273361514c70b817"},"cell_type":"code","source":"plt.plot(subsamples,scores_ss,\"o-\")\nplt.ylabel(log_loss)\nplt.xlabel(\"subsample\")\nprint(\"best subsample {}\".format(subsamples[np.argmin(scores_ss)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f42c62071238a6219fe5f0dccea53e757949403"},"cell_type":"code","source":"scores_cb = []\ncolsample_bytrees = [0.5,0.6,0.7,0.8,0.9,1]\n\nfor cb in colsample_bytrees:\n    xgb = XGBClassifier(learning_rate =0.1, n_estimators=n_estimators[np.argmin(scores)], \n                        max_depth=max_depths[np.argmin(scores_md)], \n                        min_child_weight=min_child_weights[np.argmin(scores_mcw)], \n                        subsample=subsamples[np.argmin(scores_ss)], \n                        colsample_bytree=cb, nthread=4, seed=42, objective='multi:softprob')\n    xgb.fit(X_train_scaled, y_train)\n    preds = xgb.predict_proba(X_val_scaled)\n    score = log_loss(y_val, preds)\n    scores_cb.append(score)\n    print(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92c53c65525cc88825bf3f2b4ab46f5a5cdb69f3"},"cell_type":"code","source":"plt.plot(colsample_bytrees,scores_cb,\"o-\")\nplt.ylabel(log_loss)\nplt.xlabel(\"colsample_bytree\")\nprint(\"best colsample_bytree {}\".format(colsample_bytrees[np.argmin(scores_cb)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"895918488103964311de1676e9b071de6562c9f6"},"cell_type":"code","source":"scores_eta = []\netas = [0.001,0.01,0.1,0.2,0.3,0.5,1]\n\nfor eta in etas:\n    xgb = XGBClassifier(learning_rate =eta, n_estimators=n_estimators[np.argmin(scores)], \n                        max_depth=max_depths[np.argmin(scores_md)], \n                        min_child_weight=min_child_weights[np.argmin(scores_mcw)], \n                        subsample=subsamples[np.argmin(scores_ss)], \n                        colsample_bytree=colsample_bytrees[np.argmin(scores_cb)], \n                        nthread=4, seed=42, objective='multi:softprob')\n    xgb.fit(X_train_scaled, y_train)\n    preds = xgb.predict_proba(X_val_scaled)\n    score = log_loss(y_val, preds)\n    scores_eta.append(score)\n    print(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23e5ad5a6171a03435967f40ae00034da6d68d7f"},"cell_type":"code","source":"plt.plot(etas,scores_eta,\"o-\")\nplt.ylabel(log_loss)\nplt.xlabel(\"eta\")\nprint(\"best eta {}\".format(etas[np.argmin(scores_eta)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c8b6120e720173a6501080bcb18e5a90cfb8c01"},"cell_type":"code","source":"xgb = XGBClassifier(learning_rate =eta, n_estimators=n_estimators[np.argmin(scores)], \n                        max_depth=max_depths[np.argmin(scores_md)], \n                        min_child_weight=min_child_weights[np.argmin(scores_mcw)], \n                        subsample=subsamples[np.argmin(scores_ss)], \n                        colsample_bytree=colsample_bytrees[np.argmin(scores_cb)], \n                        nthread=4, seed=42, objective='multi:softprob')\ncalibrated_xgb = CalibratedClassifierCV(xgb, cv=5, method='isotonic')\ncalibrated_xgb.fit(X_train_scaled, y_train)\npreds = calibrated_xgb.predict_proba(X_val_scaled)\nscore = log_loss(y_val, preds)\nscores_eta.append(score)\nprint(\"test data log loss eval : {}\".format(log_loss(y_val,preds)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d85b69b305035cbec333471bd8294af291603410"},"cell_type":"markdown","source":"# submission"},{"metadata":{"_kg_hide-output":false,"_uuid":"9590bb67f1a7bb7444776bd8632404a7652d4802","trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(learning_rate =0.1, n_estimators=525, max_depth=8, min_child_weight=3, subsample=0.7, \n                       colsample_bytree=0.7, nthread=4, seed=42, objective='multi:softprob')\nmy_model = CalibratedClassifierCV(xgb, cv=5, method='isotonic')\nmy_model.fit(train_X_scaled,train_y)\ntest_preds = my_model.predict_proba(test_X_scaled)\noutput = pd.DataFrame(test_preds,columns=[\"Class_\"+str(i) for i in range(1,10)])\noutput.insert(loc=0, column='id', value=test_data.id)\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"303b8a1222e0f761f79477f2a5852f06f8e6a023","trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3937c82909223a79a5b2499720fa1be99515616c","trusted":true},"cell_type":"code","source":"output.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"widgets":{"state":{},"version":"1.1.2"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}