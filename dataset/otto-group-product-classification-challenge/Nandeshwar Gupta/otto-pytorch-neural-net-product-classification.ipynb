{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Otto Group Product Classification\n\n- __Author__ - [Nandeshwar Gupta](https://nandeshwar.in/)\n- __Date__ - 04Feb2022\n- __Link__ - [Kaggle](https://www.kaggle.com/nandeshwar) || [Github](https://github.com/nandesh553)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:11.638762Z","iopub.execute_input":"2022-02-07T06:47:11.639466Z","iopub.status.idle":"2022-02-07T06:47:11.6673Z","shell.execute_reply.started":"2022-02-07T06:47:11.639374Z","shell.execute_reply":"2022-02-07T06:47:11.666593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:12.741514Z","iopub.execute_input":"2022-02-07T06:47:12.742033Z","iopub.status.idle":"2022-02-07T06:47:14.063185Z","shell.execute_reply.started":"2022-02-07T06:47:12.741996Z","shell.execute_reply":"2022-02-07T06:47:14.062397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checklist\n\n- [x] Read Dataset\n- [ ] Scale Dataset\n    - [x] Z-Score Normalization\n    - [ ] MinMax Scaling\n    - [ ] Without Scaling\n- [X] Data Splitting\n- [X] Define Evaluation metric\n- [X] Define Optimizer\n- [X] Model Training\n- [ ] Gridsearch\n- [ ] KFold","metadata":{}},{"cell_type":"markdown","source":"### Read Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/otto-group-product-classification-challenge/train.csv\", index_col='id')\ntest_df = pd.read_csv(\"/kaggle/input/otto-group-product-classification-challenge/test.csv\", index_col='id')","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:16.651745Z","iopub.execute_input":"2022-02-07T06:47:16.652296Z","iopub.status.idle":"2022-02-07T06:47:18.27827Z","shell.execute_reply.started":"2022-02-07T06:47:16.652254Z","shell.execute_reply":"2022-02-07T06:47:18.277516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encode classes","metadata":{}},{"cell_type":"code","source":"classes = train_df.iloc[:,-1].unique()\nidx_to_class = {i:x for i, x in enumerate(classes)}\nclass_to_idx = {x:i for i, x in idx_to_class.items()}\n\nprint(len(idx_to_class.items()))\nprint(idx_to_class)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:18.279929Z","iopub.execute_input":"2022-02-07T06:47:18.280165Z","iopub.status.idle":"2022-02-07T06:47:18.290984Z","shell.execute_reply.started":"2022-02-07T06:47:18.280135Z","shell.execute_reply":"2022-02-07T06:47:18.290175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling target variables\nTo make training the network easier, we'll standardize each of the continuous variables. That is, we'll shift and scale the variables such that they have zero mean and a standard deviation of 1. It is also called __Z-Score Normalization__.","metadata":{}},{"cell_type":"code","source":"# Preprocessing [Z Score Normalization]\n\nprint(\"Scaling train_df .....\")\nfor col in train_df.columns[:-1]:\n    mean, std = train_df[col].mean(), train_df[col].std()\n    train_df[col] = train_df[col].apply(lambda x: (x-mean)/std)\n    \nprint(\"Scaling test_df  ..... \")\nfor col in test_df.columns[:-1]:\n    mean, std = test_df[col].mean(), test_df[col].std()\n    test_df[col] = test_df[col].apply(lambda x: (x-mean)/std)\n    \nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:20.223466Z","iopub.execute_input":"2022-02-07T06:47:20.223946Z","iopub.status.idle":"2022-02-07T06:47:29.457953Z","shell.execute_reply.started":"2022-02-07T06:47:20.22391Z","shell.execute_reply":"2022-02-07T06:47:29.457189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_workers = 2\nbatch_size = 64\nvalidation_size = 0.2","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:29.459305Z","iopub.execute_input":"2022-02-07T06:47:29.459804Z","iopub.status.idle":"2022-02-07T06:47:29.463756Z","shell.execute_reply.started":"2022-02-07T06:47:29.459763Z","shell.execute_reply":"2022-02-07T06:47:29.463108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:33.185219Z","iopub.execute_input":"2022-02-07T06:47:33.186087Z","iopub.status.idle":"2022-02-07T06:47:33.231846Z","shell.execute_reply.started":"2022-02-07T06:47:33.186048Z","shell.execute_reply":"2022-02-07T06:47:33.231126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OttoDataset(Dataset):\n    def __init__(self, df, train=True, normalized=False):\n        self.df = df\n        self.train = train\n        \n        # Reshuffle Dataset\n        self.df = self.df.sample(frac=1)\n        \n        if normalized:\n            raise NotImplementedError(\"Normaization is not yet implemented. Implement and see change in results\")\n        \n        if self.train:\n            self.X = torch.from_numpy(np.array(self.df.iloc[:,:-1]))\n            self.y = [class_to_idx[x] for x in self.df.iloc[:,-1]]\n            self.y = torch.from_numpy(np.array(self.y))\n        else:\n            self.X = torch.from_numpy(np.array(self.df))\n            self.y = torch.tensor([])\n        \n        print(f\"Shape of X {self.X.shape} and Y is {self.y.shape}\")\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if self.train:\n            return self.X[idx], self.y[idx]\n        else:\n            return self.X[idx]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:49.220642Z","iopub.execute_input":"2022-02-07T06:47:49.221025Z","iopub.status.idle":"2022-02-07T06:47:49.229933Z","shell.execute_reply.started":"2022-02-07T06:47:49.220973Z","shell.execute_reply":"2022-02-07T06:47:49.229219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pytorch dataset\ntrain_dataset = OttoDataset(train_df, train=True)\ntest_dataset = OttoDataset(test_df, train=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:50.745498Z","iopub.execute_input":"2022-02-07T06:47:50.746211Z","iopub.status.idle":"2022-02-07T06:47:51.079449Z","shell.execute_reply.started":"2022-02-07T06:47:50.746173Z","shell.execute_reply":"2022-02-07T06:47:51.078549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# script to create train and validation set with shuffle\nnum_train = len(train_df)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(validation_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = DataLoader(train_dataset, batch_size=batch_size, \n    sampler=valid_sampler, num_workers=num_workers)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, \n    num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:47:54.213756Z","iopub.execute_input":"2022-02-07T06:47:54.214464Z","iopub.status.idle":"2022-02-07T06:47:54.226649Z","shell.execute_reply.started":"2022-02-07T06:47:54.214427Z","shell.execute_reply":"2022-02-07T06:47:54.225818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module):\n    \n    def __init__(self):\n        \n        super(MLP, self).__init__()\n        \n        self.fc1 = nn.Linear(93, 256)\n        self.fc2 = nn.Linear(256, 512)\n        self.fc3 = nn.Linear(512, 9)\n        \n        self.dropout1 = nn.Dropout(p=0.25)\n        \n    def forward(self, x):\n        \n        x = self.dropout1(F.relu(self.fc1(x)))\n        x = self.dropout1(F.relu(self.fc2(x)))\n        x = self.fc3(x)\n        \n        return x       \n    \nmodel = MLP()\nprint(model)\n\n# move tensors to GPU if CUDA is available\nif train_on_gpu:\n    model.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:48:02.628467Z","iopub.execute_input":"2022-02-07T06:48:02.628718Z","iopub.status.idle":"2022-02-07T06:48:05.358749Z","shell.execute_reply.started":"2022-02-07T06:48:02.62869Z","shell.execute_reply":"2022-02-07T06:48:05.357998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Specify Loss Function and Optimizer\nDecide on a loss and optimization function that is best suited for this classification task. The linked code examples from above, may be a good starting point; this PyTorch classification example or this, more complex Keras example. Pay close attention to the value for learning rate as this value determines how your model converges to a small error.","metadata":{}},{"cell_type":"code","source":"# specify loss function\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.6)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:48:12.493778Z","iopub.execute_input":"2022-02-07T06:48:12.494447Z","iopub.status.idle":"2022-02-07T06:48:12.498978Z","shell.execute_reply.started":"2022-02-07T06:48:12.494411Z","shell.execute_reply":"2022-02-07T06:48:12.497979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the network","metadata":{}},{"cell_type":"code","source":"%%time\n\nn_epochs = 100\nvalid_loss_min = np.Inf\n\nfor epoch in range(n_epochs):\n    \n    model.train()\n    \n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data.float())\n        \n        # calculate the batch loss        \n        loss = criterion(output, target)\n        \n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        \n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        \n        train_loss += loss.item()*data.size(0)\n        \n    model.eval()\n    \n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        \n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data.float())\n        \n        # calculate the batch loss\n        loss = criterion(output, target)\n        \n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss/len(train_loader.dataset)\n    valid_loss = valid_loss/len(valid_loader.dataset)\n    \n     # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_otto-1.pt')\n        valid_loss_min = valid_loss","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:48:41.842247Z","iopub.execute_input":"2022-02-07T06:48:41.84252Z","iopub.status.idle":"2022-02-07T06:54:13.230448Z","shell.execute_reply.started":"2022-02-07T06:48:41.842492Z","shell.execute_reply":"2022-02-07T06:54:13.229566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the saved model\nCheck whether we are running on a gpu or CPU","metadata":{}},{"cell_type":"code","source":"if train_on_gpu:\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\n    \nmodel.load_state_dict(torch.load('model_otto-1.pt', map_location=device))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:56:02.764896Z","iopub.execute_input":"2022-02-07T06:56:02.765657Z","iopub.status.idle":"2022-02-07T06:56:02.776952Z","shell.execute_reply.started":"2022-02-07T06:56:02.765593Z","shell.execute_reply":"2022-02-07T06:56:02.776025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame(0, index=np.arange(test_df.shape[0]), columns=np.concatenate([np.array([\"id\"]), classes]))\nsub_df['id'] = test_df.index\nsub_df","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:59:27.179368Z","iopub.execute_input":"2022-02-07T06:59:27.17983Z","iopub.status.idle":"2022-02-07T06:59:27.200233Z","shell.execute_reply.started":"2022-02-07T06:59:27.179791Z","shell.execute_reply":"2022-02-07T06:59:27.199543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nwith torch.no_grad():\n    counter = 0\n    for data in test_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data = data.cuda()\n\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data.float())\n        row = F.softmax(output).data\n        fin_row = np.around(row.squeeze().to('cpu').numpy(), decimals=1)\n        sub_df.iloc[counter*batch_size:(counter+1)*batch_size, 1:] = fin_row.copy()\n#         print(counter*batch_size, (counter+1)*batch_size, fin_row.shape, data.shape)\n        counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:10:36.793988Z","iopub.execute_input":"2022-02-07T07:10:36.794542Z","iopub.status.idle":"2022-02-07T07:10:53.742543Z","shell.execute_reply.started":"2022-02-07T07:10:36.794503Z","shell.execute_reply":"2022-02-07T07:10:53.741757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:11:01.597054Z","iopub.execute_input":"2022-02-07T07:11:01.59732Z","iopub.status.idle":"2022-02-07T07:11:01.625524Z","shell.execute_reply.started":"2022-02-07T07:11:01.597291Z","shell.execute_reply":"2022-02-07T07:11:01.624757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:12:08.68774Z","iopub.execute_input":"2022-02-07T07:12:08.688313Z","iopub.status.idle":"2022-02-07T07:12:09.738326Z","shell.execute_reply.started":"2022-02-07T07:12:08.688274Z","shell.execute_reply":"2022-02-07T07:12:09.73752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}