{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"ad8dd4c252dd5aaba7b8393c5b7369f326a0960a","_cell_guid":"43300c5f-cfb8-460d-bd04-876ac66a9bc6","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom scipy.stats import boxcox \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\ntrain_df=pd.read_csv(\"../input/train.csv\")\ntest_df=pd.read_csv(\"../input/test.csv\")\nsubmission_df=pd.read_csv(\"../input/sampleSubmission.csv\")\nsubmission_df.head()","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"59dd25eaa9d52db7e6881a14520367c671aae432","_cell_guid":"e6272790-2a0d-42ad-9bc0-cd792204c83c","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # read and wrangle dataframes\nimport matplotlib.pyplot as plt # visualization\nimport seaborn as sns # statistical visualizations and aesthetics\nfrom sklearn.base import TransformerMixin # To create new classes for transformations\nfrom sklearn.preprocessing import (FunctionTransformer, StandardScaler) # preprocessing \nfrom sklearn.decomposition import PCA # dimensionality reduction\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom scipy.stats import boxcox # data transform\nfrom sklearn.model_selection import (train_test_split, KFold , StratifiedKFold, \n                                     cross_val_score, GridSearchCV, \n                                     learning_curve, validation_curve) # model selection modules\nfrom sklearn.pipeline import Pipeline # streaming pipelines\nfrom sklearn.base import BaseEstimator, TransformerMixin # To create a box-cox transformation class\nfrom collections import Counter\nimport warnings\n# load models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import (XGBClassifier, plot_importance)\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom time import time\nfrom sklearn.datasets import make_friedman1\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.svm import SVR\n\n","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"trusted":false},"cell_type":"code","source":"# train_df=pd.read_csv(\"../input/train.csv\")\n# train_df.head()\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# # plt.hist(train_df['target'])\n# # f, ax = plt.subplots(figsize=(20, 8))\n# # train_df['target'].value_counts().plot('bar')\n# # sns.heatmap(train_df)\n# train_df.isnull().sum()\n# train_df.fillna(value=np.nan, inplace=True)\n\n# # Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n\n# from sklearn.feature_selection import SelectKBest\n# from sklearn.feature_selection import chi2\n# # load data\n# # url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n# # names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n# # dataframe = pandas.read_csv(url, names=names)\n# array = train_df.values\n# # print (array)\n# X = array[:,0:94]\n# Y = array[:,94]\n# # feature extraction\n# test = SelectKBest(score_func=chi2, k=60)\n# fit = test.fit(X, Y)\n# # # summarize scores\n# np.set_printoptions(precision=7)\n# print(fit.scores_)\n# features = fit.transform(X)\n# # summarize selected features\n# print(features[0:5,:])\n# # print (type(features))\n# print('Feature list:', features.columns_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ceda45d5ef7c2be5a1e0c1023e0cff5b47e6522","_cell_guid":"cecf966f-cf86-4503-b12f-9f0b765ee04c","collapsed":true,"trusted":false},"cell_type":"code","source":"# array=train_df.values\n# X = array[:,0:94]\n# Y = array[:,94]\n# sns.countplot(Y,label='count')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6c9dca60537ff1c154065dcf92d92c305085dbc","_cell_guid":"8ef8a84b-61c1-44ff-a481-14b9aa3f2206","collapsed":true,"trusted":false},"cell_type":"code","source":"# train_df.describe()\n# # train_df.feat_3.unique()\n# # plt.scatter(train_df['feat_3'],train_df['target'])\n# y=train_df.target\n# list = ['id','target']\n# x = train_df.drop(list,axis = 1 )\n# print(type(x))\n# print(y.shape)\n# data=pd.concat([y,train_df.iloc[:,1:11]],axis=1)\n# data=pd.melt(data,id_vars=\"target\",var_name=\"features\" ,value_name=\"value\")\n# # data\n# plt.figure(figsize=(10,10))\n# sns.violinplot(x=\"features\", y=\"value\", hue=\"target\", data=data,split=False, inner=\"quart\")\n# plt.xticks(rotation=90)\n# tic = time.time()\n# sns.swarmplot(x=\"features\", y=\"value\", hue=\"target\", data=data)\n# plt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d23d18a2f6f04d5ef98b5fd668f4276077c4003","_cell_guid":"b27954c2-8807-4051-bd7d-63ee36ea0dbc","collapsed":true,"trusted":false},"cell_type":"code","source":"# correlation map\n# f,ax = plt.subplots(figsize=(50, 50))\n# sns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n# corrmap=train_df.corr().abs()\n# corrmap\n# upper = corrmap.where(np.triu(np.ones(corrmap.shape), k=1).astype(np.bool))\n# # upper\n# to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]\n# print(to_drop)\n# train_df_new=train_df.drop(to_drop,axis=1)\n# train_df_new=train_df_new.drop(['target'],axis=1)\n# train_df_new.columns\n# df=x\n# def get_redundant_pairs(df):\n#     '''Get diagonal and lower triangular pairs of correlation matrix'''\n#     pairs_to_drop = set()\n#     cols = df.columns\n#     for i in range(0, df.shape[1]):\n#         for j in range(0, i+1):\n#             pairs_to_drop.add((cols[i], cols[j]))\n#     return pairs_to_drop\n\n# def get_top_abs_correlations(df, n=5):\n#     au_corr = df.corr().abs().unstack()\n#     labels_to_drop = get_redundant_pairs(df)\n#     au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n#     return au_corr[0:n]\n\n# print(\"Top Absolute Correlations\")\n# print(get_top_abs_correlations(df,10))\n\n# Top Absolute Correlations\n# feat_39  feat_45    0.824146\n# feat_3   feat_46    0.777517\n# feat_15  feat_72    0.764664\n# feat_30  feat_84    0.716862\n# feat_9   feat_64    0.702951","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3524d4696a09c95a5ebf3b23bda7ade6e24e685b","_cell_guid":"7666da06-d3cd-449d-98f1-b011246b8b15","collapsed":true,"trusted":false},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fe1285417a349ed341827cb36858ac080d65c52","_cell_guid":"bf40f2dc-7e07-4fae-b8ca-b8c3a09b9bf7","collapsed":true,"trusted":false},"cell_type":"code","source":"\n# y=train_df.target\n# # split data train 70 % and test 30 %\n# x_train, x_test, y_train, y_test = train_test_split(train_df_new, y, test_size=0.3, random_state=42)\n\n# #random forest classifier with n_estimators=10 (default)\n# clf_rf = RandomForestClassifier(random_state=43)      \n# clr_rf = clf_rf.fit(x_train,y_train)\n# pred_y=clf_rf.predict(x_test)\n# ac = accuracy_score(y_test,pred_y)\n# pred_y\n# print('Accuracy is: ',ac)\n# cm = confusion_matrix(y_test,clf_rf.predict(x_test))\n# sns.heatmap(cm,annot=True,fmt=\"d\")\n# pred_y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48671997e02784e4adb9f9f6ebc1015f2f8233c4","_cell_guid":"e652db77-0656-4e92-bbbd-15b3eca45291","collapsed":true,"trusted":false},"cell_type":"code","source":"# #select best\n# drop_list=['id','target']\n# X=train_df.drop(drop_list,axis=1)\n# y=train_df.target\n\n# test=SelectKBest(chi2,k=10)\n# fit=test.fit(X,y)\n# print('Score list:', fit.pvalues_)\n# X_1=fit.transform(X)\n# # y_1=fit.transform(y)\n# y_1=y\n# x_train, x_test, y_train, y_test = train_test_split(X_1, y_1, test_size=0.3, random_state=42)\n# clf_rf_2 = RandomForestClassifier()   \n# clr_rf_2 = clf_rf_2.fit(x_train,y_train)\n# ac_2 = accuracy_score(y_test,clf_rf_2.predict(x_test))\n# print('Accuracy is: ',ac_2)\n# cm_2 = confusion_matrix(y_test,clf_rf_2.predict(x_test))\n# sns.heatmap(cm_2,annot=True,fmt=\"d\") \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0737e562d7b79483e70a10a2cf4d076665eda87d","_cell_guid":"983c7338-5e1a-4dc0-98c0-b17e433021d3","collapsed":true,"trusted":false},"cell_type":"code","source":"# #Recursive feature elimination\n# from sklearn.feature_selection import RFE\n\n# drop_list=['id','target','feat_45', 'feat_46', 'feat_64', 'feat_72', 'feat_84']\n# X=train_df.drop(drop_list,axis=1)\n# y=train_df.target\n# #boxcox normalization\n# bc_features=[]\n# for col in X.columns:\n#     bc_transformed,_=boxcox(X[col]+1)\n#     bc_features.append(bc_transformed)\n    \n# bc_features = np.column_stack(bc_features)\n# df_bc=pd.DataFrame(data=bc_features,columns=X.columns)\n# X=df_bc\n# clf_rf_3 = RandomForestClassifier()      \n# rfe = RFE(estimator=clf_rf_3, n_features_to_select=38, step=1)\n# fit=rfe.fit(X,y)\n# X_1=fit.transform(X)\n# y_1=y\n# x_train, x_test, y_train, y_test = train_test_split(X_1, y_1, test_size=0.3, random_state=42)\n\n# clf_rf_rfe = RandomForestClassifier()   \n# clr_rf_rfe = clf_rf_rfe.fit(x_train,y_train)\n# ac_2 = accuracy_score(y_test,clf_rf_rfe.predict(x_test))\n# print('Accuracy is: ',ac_2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abcb781d7efe9e5b8a9ef79f3e3912292a818c1a","_cell_guid":"07232eba-b6b5-483f-8d8a-bacc7b453f93","collapsed":true,"trusted":false},"cell_type":"code","source":"\n\n# drop_list=['id','target','feat_45', 'feat_46', 'feat_64', 'feat_72', 'feat_84']\n# X=train_df.drop(drop_list,axis=1)\n# y=train_df.target\n# #boxcox normalization\n# bc_features=[]\n# for col in X.columns:\n#     bc_transformed,_=boxcox(X[col]+1)\n#     bc_features.append(bc_transformed)\n    \n# bc_features = np.column_stack(bc_features)\n# df_bc=pd.DataFrame(data=bc_features,columns=X.columns)\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# n_components = 30\n# pipelines = []\n# n_estimators = 50\n# seed=40\n# #print(df.shape)\n# pipelines.append( ('SVC',\n#                    Pipeline([\n#                               ('sc', StandardScaler()),\n#                               ('pca', PCA(n_components = n_components, random_state=seed ) ),\n#                              ('SVC', SVC(random_state=seed))]) ) )\n\n\n# pipelines.append(('KNN',\n#                   Pipeline([ \n#                               ('sc', StandardScaler()),\n#                             ('pca', PCA(n_components = n_components, random_state=seed ) ),\n#                             ('KNN', KNeighborsClassifier()) ])))\n# pipelines.append( ('RF',\n#                    Pipeline([\n#                               ('sc', StandardScaler()),\n#                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('RF', RandomForestClassifier(random_state=seed, n_estimators=n_estimators)) ]) ))\n\n\n# pipelines.append( ('ADA',\n#                    Pipeline([ \n#                               ('sc', StandardScaler()),\n#                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                     ('ADA', AdaBoostClassifier(random_state=seed,  n_estimators=n_estimators)) ]) ))\n\n# pipelines.append( ('ET',\n#                    Pipeline([\n#                               ('sc', StandardScaler()),\n#                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('ET', ExtraTreesClassifier(random_state=seed, n_estimators=n_estimators)) ]) ))\n# # pipelines.append( ('GB',\n# #                    Pipeline([ \n# #                              ('sc', StandardScaler()),\n# #                             ('pca', PCA(n_components = n_components, random_state=seed ) ), \n# #                              ('GB', GradientBoostingClassifier(random_state=seed)) ]) ))\n\n# pipelines.append( ('LR',\n#                    Pipeline([\n#                               ('sc', StandardScaler()),\n#                               ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('LR', LogisticRegression(random_state=seed)) ]) ))\n\n# results, names, times  = [], [] , []\n# num_folds = 10\n# scoring = 'accuracy'\n\n# for name, model in pipelines:\n#     start = time()\n#     kfold = StratifiedKFold(n_splits=num_folds, random_state=seed)\n#     cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring = scoring,\n#                                 n_jobs=-1) \n#     t_elapsed = time() - start\n#     results.append(cv_results)\n#     names.append(name)\n#     times.append(t_elapsed)\n#     msg = \"%s: %f (+/- %f) performed in %f seconds\" % (name, 100*cv_results.mean(), \n#                                                        100*cv_results.std(), t_elapsed)\n#     print(msg)\n\n\n# fig = plt.figure(figsize=(12,8))    \n# fig.suptitle(\"Algorithms comparison\")\n# ax = fig.add_subplot(1,1,1)\n# plt.boxplot(results)\n# ax.set_xticklabels(names)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7a77721365e8bdda57fbd2a5dcd97fa8981a6f4","_cell_guid":"f50eeb66-46cc-4900-9899-b2c9f60d0029","collapsed":true,"trusted":false},"cell_type":"code","source":"# n_components = 30\n# pipelines = []\n# n_estimators = 50\n# seed=40\n# #print(df.shape)\n# pipelines.append( ('SVC',\n#                    Pipeline([\n#                               ('sc', StandardScaler()),\n#                               ('pca', PCA(n_components = n_components, random_state=seed ) ),\n#                              ('SVC', SVC(random_state=seed))]) ) )\n\n# print ((pipelines) )\n# for name, model in pipelines:\n#     print (type(pipelines) )\n#     print ('**********' )\n#     print ((model ))\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15b04c84b9563c2fe24edb7ebe214bb36f8158d2","_cell_guid":"f959a3bc-7c56-44b5-96ba-f97b412026e1","collapsed":true,"trusted":false},"cell_type":"code","source":"print(pipelines.named_steps )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afab6c4f10b3e41e2c5bac7e535aa027e47347fa","_cell_guid":"5db51987-2733-4114-8420-21cab0cd5fa4","collapsed":true,"trusted":false},"cell_type":"code","source":"# Create a pipeline with a Random forest classifier\n\n# drop_list=['id','target','feat_45', 'feat_46', 'feat_64', 'feat_72', 'feat_84']\n# X=train_df.drop(drop_list,axis=1)\n# y=train_df.target\n# #boxcox normalization\n# bc_features=[]\n# for col in X.columns:\n#     bc_transformed,_=boxcox(X[col]+1)\n#     bc_features.append(bc_transformed)\n    \n# bc_features = np.column_stack(bc_features)\n# df_bc=pd.DataFrame(data=bc_features,columns=X.columns)\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\n# # pipe_rfc = Pipeline([ \n# #                       ('scl', StandardScaler()), \n# #                     ('rfc', RandomForestClassifier(random_state=42, n_jobs=-1) )])\n\n# pipelines.append( ('rfc',\n#                    Pipeline([\n#                               ('sc', StandardScaler()),\n#                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('rfc', RandomForestClassifier(random_state=seed, n_estimators=n_estimators)) ]) ))\n# pipelines.append( ('SVC',\n#                    Pipeline([\n#                               ('sc', StandardScaler()),\n#                               ('pca', PCA(n_components = n_components, random_state=seed ) ),\n#                              ('SVC', SVC(random_state=seed))]) ) )\n\n# # Set the grid parameters\n# # param_grid_rfc =  [ {rfc:{\n# #     'rfc__n_estimators': [20, 30,30,50], # number of estimators\n# #     #'rfc__criterion': ['gini', 'entropy'],   # Splitting criterion\n# #     'rfc__max_features':[0.05 , 0.1], # maximum features used at each split\n# #     'rfc__max_depth': [None, 5], # Max depth of the trees\n# #     'rfc__min_samples_split': [0.005, 0.01], # mininal samples in leafs\n# #     })]\n# param_grid_rfc =   {'rfc':{\n#     'rfc__n_estimators': [20, 30,30,50], # number of estimators\n#     #'rfc__criterion': ['gini', 'entropy'],   # Splitting criterion\n#     'rfc__max_features':[0.05 , 0.1], # maximum features used at each split\n#     'rfc__max_depth': [None, 5], # Max depth of the trees\n#     'rfc__min_samples_split': [0.005, 0.01], # mininal samples in leafs\n#     },\n#      'SVC':{}              }\n# # abc=[param_grid_rfc['rfc']]\n# # Use 10 fold CV\n# scoring = 'accuracy'\n# for name,model in pipelines:\n#     print (model)\n#     print (name)\n   \n#     param_grid_val=[param_grid_rfc[name]]\n#     print(param_grid_val)\n#     kfold = StratifiedKFold(n_splits=5, random_state= 42)\n#     grid_rfc = GridSearchCV(model, param_grid= param_grid_val, cv=kfold, scoring=scoring, verbose= 1, n_jobs=-1)\n\n#     #Fit the pipeline\n#     start = time()\n#     grid_rfc = grid_rfc.fit(x_train, y_train)\n#     end = time()\n\n#     print(\"RFC grid search took %.3f seconds\" %(end-start))\n\n#     # Best score and best parameters\n#     print('-------Best score----------')\n#     print(grid_rfc.best_score_ * 100.0)\n#     print('-------Best params----------')\n#     print(grid_rfc.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33e53ef97cda760eda557bbcc5b9a60c94917eb9","_cell_guid":"6564b778-53df-4138-a3d1-966b3eca7d8e","collapsed":true,"trusted":false},"cell_type":"code","source":"# param_grid_rfc =   {'rfc':{\n#     'rfc__n_estimators': [20, 30,30,50], # number of estimators\n#     #'rfc__criterion': ['gini', 'entropy'],   # Splitting criterion\n#     'rfc__max_features':[0.05 , 0.1], # maximum features used at each split\n#     'rfc__max_depth': [None, 5], # Max depth of the trees\n#     'rfc__min_samples_split': [0.005, 0.01], # mininal samples in leafs\n#     }}\n# abc=[param_grid_rfc['rfc']]\n# print(abc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1552698ae8b3904371680745e4a68f2eb3230dd3","_cell_guid":"f4191ee9-3e86-49d2-a4ca-1f83582c51e7","collapsed":true,"trusted":false},"cell_type":"code","source":"# mask = rfe.get_support(indices=True)\n# print(mask)\n# columns=X.columns[rfe.get_support()]\n# # X_trans = pd.DataFrame(X_1,columns=columns)\n# X_trans=train_df[columns]\n# X_trans.head()\n# df=X_trans\n# for feat in columns:\n#     skew = df[feat].skew()\n#     sns.distplot(df[feat], kde= False, label='Skew = %.3f' %(skew), bins=40)\n#     plt.legend(loc='best')\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22edceae6cad4442a72aac55deb212c2bea2832e","_cell_guid":"55f22068-18bd-49e8-a664-8b94887d6494","collapsed":true,"trusted":false},"cell_type":"code","source":"# df=train_df.corr()\n# df=df.reindex()\n# df.columns\n# df=train_df_out\n\n# bc_features=[]\n# for col in train_df.columns:\n#     bc_transformed,_=boxcox(df[col]+1)\n#     bc_features.append(bc_transformed)\n    \n# bc_features = np.column_stack(bc_features)\n# df_bc=pd.DataFrame(data=bc_features,columns=columns)\n# print(type(y_1))\n# # y_trans = pd.DataFrame(y,columns=['target'])\n# # df_bc['target']=train_df['target']\n# x_train, x_test, y_train, y_test = train_test_split(df_bc, train_df_out['target'], test_size=0.3, random_state=42)\n# clf_rf_rfe = RandomForestClassifier()   \n# clr_rf_rfe = clf_rf_rfe.fit(x_train,y_train)\n# ac_2 = accuracy_score(y_test,clf_rf_rfe.predict(x_test))\n\n# print('Accuracy is: ',ac_2)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b471f6c2fda10bfd1b74d59ff7fe35c9ec0d2c49","_cell_guid":"1bf088ed-3143-4ad7-9c04-86cb5a200515","collapsed":true,"trusted":false},"cell_type":"code","source":"#     fig, ax = plt.subplots(1,2,figsize=10,10))  \n# sns.pairplot(df_bc)\n\n# # Detect observations with more than one outlier\n# from collections import Counter\n# def outlier_hunt(df):\n#     \"\"\"\n#     Takes a dataframe df of features and returns a list of the indices\n#     corresponding to the observations containing more than 2 outliers. \n#     \"\"\"\n#     outlier_indices = []\n    \n#     # iterate over features(columns)\n#     for col in df.columns.tolist():\n#         # 1st quartile (25%)\n#         Q1 = np.percentile(df[col], 25)\n        \n#         # 3rd quartile (75%)\n#         Q3 = np.percentile(df[col],75)\n        \n#         # Interquartile rrange (IQR)\n#         IQR = Q3 - Q1\n        \n#         # outlier step\n#         outlier_step = 1.5 * IQR\n        \n#         # Determine a list of indices of outliers for feature col\n#         outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n#         # append the found outlier indices for col to the list of outlier indices \n#         outlier_indices.extend(outlier_list_col)\n        \n#     # select observations containing more than 2 outliers\n#     outlier_indices = Counter(outlier_indices)        \n#     multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2 )\n    \n#     return multiple_outliers   \n\n# print('The dataset contains %d observations with more than 2 outliers' %(len(outlier_hunt(train_df[columns]))))   \n\n# outlier_df=outlier_hunt(train_df[columns])\n# print((outlier_df))\n# outlier_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dda8698149ff85ae818fe30343c1ee4119fd71fd","_cell_guid":"e47e869e-63d9-472a-94fe-4dca897207bc","collapsed":true,"trusted":false},"cell_type":"code","source":"# abc=pd.DataFrame()\n# abc['feat_10']=np.log(train_df['feat_10']+1)\n# f,ax = plt.subplots(figsize=(10, 10))\n# plt.xticks(rotation=90)\n# sns.boxplot(x=abc['feat_10'],data=train_df)\n# plt.show()\n# plt.xticks(rotation=90)\n\n# train_df[columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b011c2aae507bc58fc686583f2b9b6608370a204","_cell_guid":"b89dcdaf-1a8b-41ec-a986-b5057412b5f9","collapsed":true,"trusted":false},"cell_type":"code","source":"# abc=train_df.groupby(\"feat_11\")[\"feat_11\"].count()\n# train_df_out=train_df.drop(train_df.index[outlier_df])/\n# train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a580bafda752f39ab9ac63e06a0670f729e93ed","_cell_guid":"8164a868-19be-4dec-8b1b-531e8a4bbc15","collapsed":true,"trusted":false},"cell_type":"code","source":"# for feature in columns:\n#     fig, ax = plt.subplots(1,2,figsize=(7,3.5))    \n#     ax[0].hist(df[feature], color='blue', bins=30, alpha=0.3, label='Skew = %s' %(str(round(df[feature].skew(),3))) )\n#     ax[0].set_title(str(feature))   \n#     ax[0].legend(loc=0)\n#     ax[1].hist(df_bc[feature], color='red', bins=30, alpha=0.3, label='Skew = %s' %(str(round(df_bc[feature].skew(),3))) )\n#     ax[1].set_title(str(feature)+' after a Box-Cox transformation')\n#     ax[1].legend(loc=0)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"670fcf39466cf301bbd906a53797927631781bf4","_cell_guid":"3f47504c-3c1e-4764-8a50-7f3675e4fa60","collapsed":true,"trusted":false},"cell_type":"code","source":"# PCA feature Extraction\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.decomposition import PCA\n# scl=StandardScaler()\n# pca=PCA(n_components=8)\n# drop_list=['id','target','feat_45', 'feat_46', 'feat_64', 'feat_72', 'feat_84']\n# X=train_df.drop(drop_list,axis=1)\n# y=train_df.target\n# X_1=scl.fit_transform(X)\n# pca.fit(X_1)\n# print(pca.explained_variance_ )\n# X_2 = pca.transform(X_1)\n# x_train, x_test, y_train, y_test = train_test_split(X_2, y, test_size=0.3, random_state=42)\n\n# clf_rf_rfe = RandomForestClassifier()   \n# clr_rf_rfe = clf_rf_rfe.fit(x_train,y_train)\n# ac_2 = accuracy_score(y_test,clf_rf_rfe.predict(x_test))\n# print('Accuracy is: ',ac_2)\n\n# # plt.figure(1, figsize=(14, 13))\n# # plt.clf()\n# # plt.axes([.2, .2, .7, .7])\n# # plt.plot(pca.explained_variance_ratio_, linewidth=2)\n# # plt.axis('tight')\n# # plt.xlabel('n_components')\n# # plt.ylabel('explained_variance_ratio_')\n# y_test.value_counts().plot('bar')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec336a110944129e2f93709d90f1ee8ba00f2c68","_cell_guid":"da584a34-8596-458c-8a24-aa85313937f8","collapsed":true,"trusted":false},"cell_type":"code","source":"# # train_df['target'].value_counts().plot('bar')\n# # a=['1','2','3','4','5','6','7','8','9','10']\n# a=[1,2,3,4,5,6,7,8,9,10]\n# df=pd.DataFrame(a,columns=['val'])\n# Q1 = np.percentile(df['val'], 25\n#                   )\n# Q1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6519828748c96a29f179f589fb198f8e57cb871d","_cell_guid":"3f822fb7-084f-4c22-a094-96a769180a30","collapsed":true,"trusted":false},"cell_type":"code","source":"param_grid_rfc= {'RF':{\n    'RF__n_estimators': [20], # number of estimators\n    'RF__criterion': ['gini'],   # Splitting criterion  ['gini', 'entropy']\n    'RF__max_features':['log2'], # maximum features used at each split ['log2','sqrt',None]\n    'RF__max_depth': [5,8,15,25,30,None], # Max depth of the trees[,8,15,25,30,None]\n    'RF__min_samples_split': [2,5,10,15,100], # mininal samples in leafs [1.1,2,5,10,15,100]\n#      'RF__min_samples_leaf': [1,2,5,10]\n    },\n     'SVC':{\n         'SVC__C': [0.001,0.01,10,100],\n         'SVC__gamma':['auto'],\n         'SVC__class_weight':['balanced',None]\n    } ,     \n    'LR':{\n        'LR__penalty': ['L1'],\n        'LR__C': [0.001,0.01,10,100]\n    },\n     'KNN':{\n        'KNN__n_neighbors': [2,4,8,16,32],\n        'KNN__p': [2,3]\n    } , \n    'XGB':{\n    'XGB__eta': [0.01,0.015,0.025,0.05,0.1], # number of estimators\n    'XGB__gamma': [0.05,0.1,0.3,0.5,0.7,0.9,1.0],   # Splitting criterion\n    'XGB__max_depth':[3,5,7,9,12,15,17,25], # maximum features used at each split\n    'XGB__min_child_weight': [1,3,5,7], # Max depth of the trees\n    'XGB__sub_sample': [0.6,0.7,0.8,0.9,1.0], # mininal samples in leafs\n    'XGB__calsample_bytree': [0.6,0.7,0.8,0.9,1.0],\n    'XGB__lambda' :[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]   ,\n    'XGB__alpha' :[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n     } ,\n     'LASOO' : {\n         'LASOO__alpha': [0.1,1.0,10],\n         'LASOO__normalize':['True','False']\n     },\n     'RIDGE' : {\n         'LASOO__alpha': [0.01,0.1,1.0,10,100],\n         'LASOO__normalize':['True','False'],\n         'LASOO__fit_intercept':['True','False'],\n     'ADA' : {}  ,\n     'ET' :{}  \n    }}\n     \n     \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5434cf86eeb2ea97bde68ea5f642914d739755c3","_cell_guid":"71974ef5-6e6f-4ed0-9ba1-2009218d08a5","collapsed":true,"trusted":true},"cell_type":"code","source":"drop_list=['id','target','feat_45', 'feat_46', 'feat_64', 'feat_72', 'feat_84']\nX=train_df.drop(drop_list,axis=1)\ny=train_df.target\n#boxcox normalization\nbc_features=[]\nfor col in X.columns:\n    bc_transformed,_=boxcox(X[col]+1)\n    bc_features.append(bc_transformed)\n    \nbc_features = np.column_stack(bc_features)\ndf_bc=pd.DataFrame(data=bc_features,columns=X.columns)\n# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\n# n_components = 30\n# pipelines = []\n# n_estimators = 50\n# seed=40","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"86ecccf4c8b4993555d12cc1f4176b6a8d624eee","_cell_guid":"3988ee94-f4f6-440f-a9c8-c05d84d57751","trusted":true},"cell_type":"code","source":"rfc=RandomForestClassifier(random_state=42, n_estimators=25,max_depth=6,min_samples_leaf=5)\nrfecv = RFECV(rfc, step=5, cv=StratifiedKFold(3),scoring='accuracy')\nrfecv = rfecv.fit(df_bc, y)\n\nrfecv = rfecv.fit(X, y)\nprint(rfecv.support_ )\nprint(rfecv.ranking_)\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)\n\n# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"615897df50e01962bf29115c9b31ed40bc274dd4","_cell_guid":"2b4fc71e-58e0-477c-adca-4eb453770f59","trusted":true},"cell_type":"code","source":"columns=X.columns[rfecv.get_support()]\nprint(columns)\nX_1 = rfecv.transform(X)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"e6d2a1563ef9b227f7563224e6d915343eff3957","_cell_guid":"d4b5813a-265e-4edb-9cec-190db6964d5b","collapsed":true,"trusted":false},"cell_type":"code","source":"\n# n_components = 30\n# pipelines = []\n# n_estimators = 10\n# seed=40\n#print(df.shape)\n# pipelines.append( ('SVC',\n#                    Pipeline([\n# #                               ('sc', StandardScaler()),\n# #                               ('pca', PCA(n_components = n_components, random_state=seed ) ),\n#                              ('SVC', SVC(random_state=seed))]) ) )\n\n\n# pipelines.append(('KNN',\n#                   Pipeline([ \n# #                               ('sc', StandardScaler()),\n# #                             ('pca', PCA(n_components = n_components, random_state=seed ) ),\n#                             ('KNN', KNeighborsClassifier()) ])))\n# pipelines.append( ('RF',\n#                    Pipeline([\n# #                               ('sc', StandardScaler()),\n# #                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('RF', RandomForestClassifier(random_state=seed, n_estimators=n_estimators)) ]) ))\n\n\n# pipelines.append( ('ADA',\n#                    Pipeline([ \n# #                               ('sc', StandardScaler()),\n# #                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                     ('ADA', AdaBoostClassifier(random_state=seed,  n_estimators=n_estimators)) ]) ))\n\n# pipelines.append( ('ET',\n#                    Pipeline([\n# #                               ('sc', StandardScaler()),\n# #                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('ET', ExtraTreesClassifier(random_state=seed, n_estimators=n_estimators)) ]) ))\n# pipelines.append( ('GB',\n#                    Pipeline([ \n#                              ('sc', StandardScaler()),\n#                             ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('GB', GradientBoostingClassifier(random_state=seed)) ]) ))\n\n# pipelines.append( ('LR',\n#                    Pipeline([\n# #                               ('sc', StandardScaler()),\n# #                               ('pca', PCA(n_components = n_components, random_state=seed ) ), \n#                              ('LR', LogisticRegression(random_state=seed)) ]) ))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b9823aface76fbde0afcec0b03b2a8aebf0fa0f","scrolled":true,"_cell_guid":"42a219ac-62cd-4134-94c6-7d485459ffd7","trusted":false,"collapsed":true},"cell_type":"code","source":"# results, names, times  = [], [] , []\n# num_folds = 2\n# scoring = 'accuracy'\n\n# for name,model in pipelines:\n#     print (model)\n#     print (name)\n   \n#     param_grid_val=[param_grid_rfc[name]]\n#     print('grid val=%s' %param_grid_val)\n#     print('model param=%s' %model.get_params().keys())\n#     kfold = StratifiedKFold(n_splits=2, random_state= 42)\n#     grid_rfc = GridSearchCV(model, param_grid= param_grid_val, cv=kfold, scoring=scoring, verbose= 1, n_jobs=1)\n\n#     #Fit the pipeline\n#     start = time()\n#     grid_rfc = grid_rfc.fit(X_1, y)\n#     end = time()\n\n#     print(\"RFC grid search took %.3f seconds\" %(end-start))\n\n#     # Best score and best parameters\n#     print('-------Best score----------')\n#     print(grid_rfc.best_score_ * 100.0)\n#     print('-------Best params----------')\n#     print(grid_rfc.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbd246a7a4a47156524b2bc281215d04bd8ca0ca","_cell_guid":"c5ebbe57-6708-40fc-bbf9-3a00261039f1","trusted":true,"scrolled":true},"cell_type":"code","source":"# {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__min_samples_split': 5, 'RF__n_estimators': 20}\n\n#random forest classifier with n_estimators=10 (default)\nclf_rf = RandomForestClassifier(random_state=43,criterion='gini', max_depth= None, max_features= 'log2', min_samples_split= 5, n_estimators= 20)      \nclr_rf = clf_rf.fit(X_1,y)\npred_y=clf_rf.predict(test_df[columns])\n# ac = accuracy_score(y_test,pred_y)\npred_y\n# print('Accuracy is: ',ac)\n# cm = confusion_matrix(y_test,clf_rf.predict(x_test))\n# sns.heatmap(cm,annot=True,fmt=\"d\")\n# pred_y","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b938541e7bb1abdf236852be672a781858fe6c79"},"cell_type":"code","source":"# test_df\ndf = pd.DataFrame(pred_y)\n# df\nsubmit=pd.concat([test_df[['id']], df], axis=1)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e925c24b4e8cb2725f05e4181e8b24a443892fe"},"cell_type":"code","source":"# abc=submit.get_dummies(0)\nabc=pd.get_dummies(submit, prefix=['0'])","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98fe0076e470fced48619ca18ba8dcb774a757d0"},"cell_type":"code","source":"abc.columns = abc.columns.str.replace('0_','')","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bbef4981fbfa9d2880f9055a27f5481bef1a8fa"},"cell_type":"code","source":"abc","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"55309b8211d99250c147b5deacecc2f249b00ce4"},"cell_type":"code","source":"abc.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}