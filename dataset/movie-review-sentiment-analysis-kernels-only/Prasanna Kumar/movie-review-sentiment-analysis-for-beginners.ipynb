{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the train,test,submission datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test=pd.read_csv(r\"/kaggle/input/movie-review-sentiment-analysis-kernels-only/test.tsv.zip\",sep=\"\\t\")\ntrain=pd.read_csv(r\"/kaggle/input/movie-review-sentiment-analysis-kernels-only/train.tsv.zip\",sep=\"\\t\")\nsub = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/sampleSubmission.csv', sep=\",\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look at the test data\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look at the test data\ntrain.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Output Inspection**\n* 0 - negative   \n* 1 - somewhat negative    \n* 2 - neutral   \n* 3 - somewhat positive   \n* 4 - positive   "},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets look at the shape of the train data\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is a huge dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets look at the shape of the test data\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['SentenceId']==3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that the sentenceId with value 3 has mostly same  repeated words in Phrase column "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['SentenceId']==2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similarly,we can see that the sentenceId with value 2 has mostly same repeated words in Phrase column"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Point to Note**\n\n*       We can say here that each sentenceId is grouped  based on the similar words in phrase column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# since we have different values in  sentenceId,check the total no of unique sentenceId \nprint(\"For train data \",train['SentenceId'].nunique()) \nprint(\"For test data \",test['SentenceId'].nunique()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npd.DataFrame(train.groupby('SentenceId')['Phrase'].count()).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Returning average count of phrases per sentence, per Dataset\nint(train.groupby('SentenceId')['Phrase'].count().mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int(test.groupby('SentenceId')['Phrase'].count().mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Returning average word length of phrases\nprint(\"train \",int(np.mean(train['Phrase'].apply(lambda x: len(x.split())))))\nprint(\"test\",int(np.mean(test['Phrase'].apply(lambda x: len(x.split())))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exploring Target Value**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_count=train['Sentiment'].value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gets the unique value count of an object\ntrain_labels=train['Sentiment'].value_counts().index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfig,ax = plt.subplots(1, 1, dpi = 100, figsize = (7, 5))\ng=sns.barplot(train_labels,train_count)\nax.set_xlabel(\"target\")\nax.set_ylabel(\"count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we can say that almost half of the target values are 2(neutral).\n* we can also say that data is not balanced based on target feature"},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering** "},{"metadata":{},"cell_type":"markdown","source":"So, we have only phrases as data. And a phrase can contain a single word. And one punctuation mark can cause phrase to receive a different sentiment. Also assigned sentiments can be strange. This means several things:\n* using stopwords can be a bad idea, especially when phrases contain one single stopword\n* untuation could be important, so it should be used;\n* ngrams are necessary to get the most info from data (know about ngrams ->https://www.kaggle.com/c/avito-demand-prediction/discussion/58819)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = nltk.tokenize.TweetTokenizer()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TF-IDF**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tfidf vectoriser\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\nfull_text = list(train['Phrase'].values) + list(test['Phrase'].values)\nvectorizer.fit(full_text)  #learns both train and test data vocabulary\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Why have i fitted the vectorizer with both train and test data?**\n> In real world we don't know what will be in new(test) data, so we have to fit only train data. On the other hand, in kaggle we have both train and test, this means we can    take   into account word distribution in both datasets.\nAlso go through this link https://www.kaggle.com/questions-and-answers/58368 to know more"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_vectorized = vectorizer.transform(train['Phrase'])\ntest_vectorized = vectorizer.transform(test['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_vectorized.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_vectorized.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Applying Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\novr = OneVsRestClassifier(logreg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Know about OneVsRestClassifier here https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"ovr.fit(train_vectorized, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(ovr, train_vectorized, y, scoring='accuracy', n_jobs=-1, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean of 10 cv :\",np.mean(scores) * 100)\nprint( \"standard deviation\",np.std(scores) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=ovr.predict(test_vectorized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.Sentiment=y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}