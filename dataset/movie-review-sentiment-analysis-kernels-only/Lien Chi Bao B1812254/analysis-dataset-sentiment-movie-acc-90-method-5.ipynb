{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **GIỚI THIỆU**\n\n* Xin chào! Hôm nay tôi sẽ phải hoàn thành một nhiệm vụ khá thú vị đó là **\"Phân tích đánh giá cảm xúc người xem qua bộ dữ liệu 50K IMDB** bằng tất cả các **phương pháp học máy(gồm có: LSVC,Bayes Thơ Ngây,SGDC,LR,LSTM) và học sâu(CNN)** mà tôi biết. Vui lòng cho ý kiến khách quan để tất cả chúng ta có thể trao đổi với nhau tích cực hơn và hiệu quả hơn. Cảm ơn các bạn đã xem!\n\n* Trước khi bắt đầu thì tôi sẽ cho bạn **biết trước kết quả thu được** sẽ ra sao để chúng ta có thể dễ dàng rà soát chúng một cách dễ dàng và hiệu quả.**(ở đây tôi chỉ trình bày kết quả đạt được về độ chính xác của từng mô hình, các bạn cảm thấy hay và hứng thú có thể xem từng chi tiết code & chú thích mà tôi để bên dưới).**\n\n* Bạn có thể xem số liệu **\"so sánh bảng mô hình\" tại dòng \"Nhận xét về kết quả thu được từ 4 mô hình\" bên dưới**, tôi đã nén lại dưới dạng dataFrame cho bạn dễ nhìn & so sánh khách quan.\n\n* ***Được rồi! chúng ta không vòng vo nữa, vào việc nào!Chúc bạn 1 ngày tốt lành...LOVE***","metadata":{}},{"cell_type":"markdown","source":"**KẾT QUẢ BÁO TRƯỚC(KẾT QUẢ IN ĐẬM LÀ KẾT QUẢ KIỂM TRA CÓ ĐỘ CHÍNH XÁC CAO NHẤT)**\n1.  **LSVC:**\n    * **Độ chính xác của việc sử dụng TF-IDF fit với mô hình Linear SVC: 90.29%**\n    * Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Linear SVC: 89.77%\n    * Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Linear SVC: 89.46%\n\n2.  **MNB:**\n    * Độ chính xác của việc sử dụng TF-IDF fit với mô hình Multinomial Naive Bayes: 86.63%\n    * Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Multinomial Naive Bayes: 88.75%\n    * Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit Multinomial Naive Bayes: 89.10%\n\n3.  **SGDC:** \n    * TF-IDF: Độ chính xác của SGD Classifier: 88.67%\n    * Độ chính xác của SGD Classifier binary = False: 85.84%\n    * Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit SGD Classifier: 85.84%\n\n4.  **LR:**\n    * Độ chính xác của việc sử dụng TF-IDF fit với mô hình hồi quy logistic: 88.50%\n    * Độ chính xác của việc sử dụng CountVectorizer fit với mô hình hồi quy logistic: 85.62%\n    * Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit với mô hình hồi quy logistic: 89.65%\n5.  **DEEP LEARNING**\n    * **Mô hình CNN cho độ chính xác tốt nhất trong số tất cả với 84.71% trên tập dữ liệu train và test**\n___","metadata":{}},{"cell_type":"markdown","source":"# **CÀI ĐẶT**","metadata":{}},{"cell_type":"code","source":"!pip install nltk\n!pip install spacy\n!python -m spacy download en\n!pip install scipy\n!pip install -U scikit-learn\n!pip install seaborn\n!pip install tensorflow\n!pip install tf-nightly","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:05:19.491105Z","iopub.execute_input":"2021-10-07T17:05:19.491547Z","iopub.status.idle":"2021-10-07T17:07:23.425472Z","shell.execute_reply.started":"2021-10-07T17:05:19.491441Z","shell.execute_reply":"2021-10-07T17:07:23.424178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **THƯ VIỆN CẦN THIẾT**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array,asarray,zeros\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix, accuracy_score\nfrom sklearn import metrics\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom keras.utils.np_utils import to_categorical \nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import Sequential\nfrom keras.layers import Embedding,LSTM\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.layers.embeddings import Embedding\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\ntf.random.set_seed(4)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:23.428064Z","iopub.execute_input":"2021-10-07T17:07:23.428473Z","iopub.status.idle":"2021-10-07T17:07:28.986126Z","shell.execute_reply.started":"2021-10-07T17:07:23.428404Z","shell.execute_reply":"2021-10-07T17:07:28.985092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **ĐỌC TẬP DỮ LIỆU VÀ HIỂN THỊ TẬP DỮ LIỆU**","metadata":{}},{"cell_type":"code","source":"#df = pd.read_csv(\"../input/imdb-dataset/IMDB Dataset.csv\",encoding=\"ISO-8859-1\")\ndf = pd.read_csv(\"../input/imdb-dataset/IMDB Dataset.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:28.987325Z","iopub.execute_input":"2021-10-07T17:07:28.988593Z","iopub.status.idle":"2021-10-07T17:07:31.508711Z","shell.execute_reply.started":"2021-10-07T17:07:28.988553Z","shell.execute_reply":"2021-10-07T17:07:31.5076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sentiment.value_counts()\n#df.describe","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.510669Z","iopub.execute_input":"2021-10-07T17:07:31.510918Z","iopub.status.idle":"2021-10-07T17:07:31.533741Z","shell.execute_reply.started":"2021-10-07T17:07:31.51089Z","shell.execute_reply":"2021-10-07T17:07:31.532723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Ok! Như các bạn thấy sau khi đọc dữ liệu chúng ta có 50k cảm xúc, trong đó có 25k cảm xúc tích cực (Positive) và 25k cảm xúc tiêu cực(Negative). Nhưng đây chỉ là dữ liệu thô chúng ta có, việc chúng ta cần làm sẽ dự đoán lại các cảm xúc (sentiment) để có cái nhìn khách quan hơn và xem mô hình nào sẽ làm độ chính xác của dữ liệu được dự đoán là cao nhất.***","metadata":{}},{"cell_type":"markdown","source":"***Ok! Trước khi dự đoán mô hình chúng ta phải làm sạch dữ liệu (tiền xử lí dữ liệu). Để quá trình làm sạch dữ liệu diễn ra hiệu quả và quy mô với khối lượng dữ liệu lớn, chúng ta cần xây dựng hàm làm sạch dữ liệu ngẫu nhiên 1 câu trong tập dữ liệu. Được rồi! tới đây chắc bạn đã hiểu rồi. Tôi sẽ dùng dòng thứ 3 trong tập dữ liệu...loc[2]***","metadata":{}},{"cell_type":"code","source":"example_sentences = df['review'].loc[2]\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.535627Z","iopub.execute_input":"2021-10-07T17:07:31.536093Z","iopub.status.idle":"2021-10-07T17:07:31.544663Z","shell.execute_reply.started":"2021-10-07T17:07:31.536046Z","shell.execute_reply":"2021-10-07T17:07:31.543601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TIỀN XỬ LÍ DỮ LIỆU CHO 1 CÂU**","metadata":{}},{"cell_type":"code","source":"# 1. Xóa content HTML\nsoup = BeautifulSoup(example_sentences, \"html.parser\")\nexample_sentences = soup.get_text()\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.546327Z","iopub.execute_input":"2021-10-07T17:07:31.546625Z","iopub.status.idle":"2021-10-07T17:07:31.558757Z","shell.execute_reply.started":"2021-10-07T17:07:31.546592Z","shell.execute_reply":"2021-10-07T17:07:31.557643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Sử dụng Biểu thức chính quy để xóa mọi thứ\nexample_sentences = re.sub('\\[[^]]*\\]', ' ',example_sentences)\nexample_sentences = re.sub('[^a-zA-Z]', ' ',example_sentences)\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.561094Z","iopub.execute_input":"2021-10-07T17:07:31.561609Z","iopub.status.idle":"2021-10-07T17:07:31.573095Z","shell.execute_reply.started":"2021-10-07T17:07:31.561565Z","shell.execute_reply":"2021-10-07T17:07:31.572119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Chuyển qua từ thường(LowerCase)\nexample_sentences = example_sentences.lower()\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.57471Z","iopub.execute_input":"2021-10-07T17:07:31.575595Z","iopub.status.idle":"2021-10-07T17:07:31.590698Z","shell.execute_reply.started":"2021-10-07T17:07:31.575543Z","shell.execute_reply":"2021-10-07T17:07:31.589342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Tách từ (split)\nexample_sentences = example_sentences.split()\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.592452Z","iopub.execute_input":"2021-10-07T17:07:31.592736Z","iopub.status.idle":"2021-10-07T17:07:31.605374Z","shell.execute_reply.started":"2021-10-07T17:07:31.592707Z","shell.execute_reply":"2021-10-07T17:07:31.604246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Xử lí từ dừng(stopword)\nexample_sentences = [word for word in example_sentences if not word in set(stopwords.words('english'))]\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.608327Z","iopub.execute_input":"2021-10-07T17:07:31.60858Z","iopub.status.idle":"2021-10-07T17:07:31.647575Z","shell.execute_reply.started":"2021-10-07T17:07:31.608535Z","shell.execute_reply":"2021-10-07T17:07:31.646683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Stemming/Lemmatization\nps = PorterStemmer()\nps_example_sentences = [ps.stem(word) for word in example_sentences]\nps_example_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.648847Z","iopub.execute_input":"2021-10-07T17:07:31.6491Z","iopub.status.idle":"2021-10-07T17:07:31.661754Z","shell.execute_reply.started":"2021-10-07T17:07:31.649073Z","shell.execute_reply":"2021-10-07T17:07:31.660465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. Lemmatization/WordNetLemmatizer\nlem = WordNetLemmatizer()\nexample_sentences = [lem.lemmatize(word) for word in example_sentences]\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:31.663947Z","iopub.execute_input":"2021-10-07T17:07:31.664323Z","iopub.status.idle":"2021-10-07T17:07:34.020573Z","shell.execute_reply.started":"2021-10-07T17:07:31.66428Z","shell.execute_reply":"2021-10-07T17:07:34.019784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. Nối lại các từ(join)\nexample_sentences = ' '.join(example_sentences)\nexample_sentences","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:34.021916Z","iopub.execute_input":"2021-10-07T17:07:34.022213Z","iopub.status.idle":"2021-10-07T17:07:34.029078Z","shell.execute_reply.started":"2021-10-07T17:07:34.022181Z","shell.execute_reply":"2021-10-07T17:07:34.02799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Hoàn hảo! Bạn thấy gì không? dòng thứ 3 trông Dataset đã được xử lí sạch sẽ...Ok! Mọi thứ có vẻ ổn! Chúng ta sẽ đến phần Vecto hóa văn bản***\n___","metadata":{}},{"cell_type":"markdown","source":"# Vector hóa văn bản\n   Tôi sẽ áp dụng 3 phương pháp cho công việc này như sau:\n\n*   **CountVectorizer (Bag of Words Model-Mô Hình Túi Từ)**\n*   **TfidfVectorizer (Bag of Words Model)**\n*   **Keras Tokenizer (Embedding)--> Phần này tôi sẽ nói thêm Ở MỤC NHÚNG TỪ**\n\n**CountVector & TF_IDF sẽ là 2 kĩ thuật mà tôi sẽ cài đặt,xử lí và kiểm tra cho các mô hình...**","metadata":{}},{"cell_type":"code","source":"# Khởi tạo một kho(corpus) để chứa dữ liệu câu\ncorpus = []\ncorpus.append(example_sentences)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:34.030177Z","iopub.execute_input":"2021-10-07T17:07:34.030461Z","iopub.status.idle":"2021-10-07T17:07:34.041Z","shell.execute_reply.started":"2021-10-07T17:07:34.030429Z","shell.execute_reply":"2021-10-07T17:07:34.039931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vector hóa câu bằng mô hình túi từ (Bag of Words)--> chúng ta sẽ thấy có số 1,2 & 3...\ndem_vecto = CountVectorizer()\nsentences_dem_vecto = dem_vecto.fit_transform(corpus)\nsentences_dem_vecto.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:34.042455Z","iopub.execute_input":"2021-10-07T17:07:34.042732Z","iopub.status.idle":"2021-10-07T17:07:34.057484Z","shell.execute_reply.started":"2021-10-07T17:07:34.042702Z","shell.execute_reply":"2021-10-07T17:07:34.056661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# biến đổi túi từ thành 1- Vectorizer với Binary = True sẽ làm được việc đó\ndem_vecto_bin = CountVectorizer(binary=True)\nsentences_dem_vecto_bin = dem_vecto_bin.fit_transform(corpus)\nsentences_dem_vecto_bin.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:34.05946Z","iopub.execute_input":"2021-10-07T17:07:34.059769Z","iopub.status.idle":"2021-10-07T17:07:34.069077Z","shell.execute_reply.started":"2021-10-07T17:07:34.059736Z","shell.execute_reply":"2021-10-07T17:07:34.068434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Ok! Được rồi! Tiếp đến chúng ta sẽ tiếp cận sử dụng TfidfVectorizer (TF-IDF) & Tính (TF * IDF) của mô hình túi từ**","metadata":{}},{"cell_type":"code","source":"tfidf_vecto = TfidfVectorizer()\nsentences_tfidf_vecto = tfidf_vecto.fit_transform(corpus)\nsentences_tfidf_vecto.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:34.070715Z","iopub.execute_input":"2021-10-07T17:07:34.07101Z","iopub.status.idle":"2021-10-07T17:07:34.088589Z","shell.execute_reply.started":"2021-10-07T17:07:34.070901Z","shell.execute_reply":"2021-10-07T17:07:34.087695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chia tập dữ liệu\n**Tôi sẽ chia tập dữ liệu để huấn luận mô hình với 75% dữ liệu là traning, 25% là test, random_state = 42 (chúng ta có thể lấy random tùy ý) & sau đó, tôi cần thay thế \"review\" và \"sentiment\" về dạng 2 kiểu số là \"Positive: 1\" và \"Nagative: 0 để fit với mô hình\"**","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test= train_test_split(df['review'], df['sentiment'], test_size=0.25, random_state=42)\ny_train = (y_train.replace({'positive': 1, 'negative': 0})).values\ny_test  = (y_test.replace({'positive': 1, 'negative': 0})).values\nprint(y_train)\nprint(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:34.090019Z","iopub.execute_input":"2021-10-07T17:07:34.090254Z","iopub.status.idle":"2021-10-07T17:07:34.144873Z","shell.execute_reply.started":"2021-10-07T17:07:34.090228Z","shell.execute_reply":"2021-10-07T17:07:34.143999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Tiền xử lí dữ liệu cho tập dữ liệu 50K**\n**Ok! Mọi thứ gần ổn! Giờ đến lúc tôi sẽ cho làm sạch toàn tập dữ liệu... Tôi sẽ chia làm 2 phần.. Phần train và phần test để làm sạch... (^_^)vui lòng chờ vì dữ liệu lớn sẽ mất nhiều thời gian của bạn**","metadata":{}},{"cell_type":"code","source":"corpus_train = []\nfor i in range(x_train.shape[0]):\n    soup = BeautifulSoup(x_train.iloc[i], \"html.parser\")\n    review = soup.get_text()\n    review = re.sub('\\[[^]]*\\]', ' ', review)\n    review = re.sub('[^a-zA-Z]', ' ', review)\n    review = review.lower()\n    review = review.split()\n    review = [word for word in review if not word in set(stopwords.words('english'))]\n    lem = WordNetLemmatizer()\n    review = [lem.lemmatize(word) for word in review]\n    review = ' '.join(review)\n    corpus_train.append(review)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:07:34.146401Z","iopub.execute_input":"2021-10-07T17:07:34.146628Z","iopub.status.idle":"2021-10-07T17:27:44.891266Z","shell.execute_reply.started":"2021-10-07T17:07:34.146603Z","shell.execute_reply":"2021-10-07T17:27:44.889414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_test  = []\nfor j in range(x_test.shape[0]):\n    soup = BeautifulSoup(x_test.iloc[j], \"html.parser\")\n    review = soup.get_text()\n    review = re.sub('\\[[^]]*\\]', ' ', review)\n    review = re.sub('[^a-zA-Z]', ' ', review)\n    review = review.lower()\n    review = review.split()\n    review = [word for word in review if not word in set(stopwords.words('english'))]\n    lem = WordNetLemmatizer()\n    review = [lem.lemmatize(word) for word in review]\n    review = ' '.join(review)\n    corpus_test.append(review)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:27:44.894561Z","iopub.execute_input":"2021-10-07T17:27:44.894941Z","iopub.status.idle":"2021-10-07T17:34:30.145622Z","shell.execute_reply.started":"2021-10-07T17:27:44.894888Z","shell.execute_reply":"2021-10-07T17:34:30.144651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_train[-1]","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:34:30.147101Z","iopub.execute_input":"2021-10-07T17:34:30.147388Z","iopub.status.idle":"2021-10-07T17:34:30.156505Z","shell.execute_reply.started":"2021-10-07T17:34:30.147357Z","shell.execute_reply":"2021-10-07T17:34:30.155378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_test[-1]","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:34:30.159826Z","iopub.execute_input":"2021-10-07T17:34:30.160381Z","iopub.status.idle":"2021-10-07T17:34:30.173067Z","shell.execute_reply.started":"2021-10-07T17:34:30.160332Z","shell.execute_reply":"2021-10-07T17:34:30.172234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vectơ hóa bằng kỹ thuật TF-IDF - Phần này sử dụng chung cho mô hình\ntfidf_vecto = TfidfVectorizer(ngram_range=(1, 3))\ntfidf_vecto_train = tfidf_vecto.fit_transform(corpus_train)\ntfidf_vecto_test = tfidf_vecto.transform(corpus_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:34:30.174531Z","iopub.execute_input":"2021-10-07T17:34:30.175047Z","iopub.status.idle":"2021-10-07T17:36:01.910346Z","shell.execute_reply.started":"2021-10-07T17:34:30.175013Z","shell.execute_reply":"2021-10-07T17:36:01.909303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TRIỂN KHAI MÔ HÌNH**\n**Xong! Mọi thứ đã ổn...Giờ là lúc tôi xây dựng mô hình từng mô hình cho tập dữ liệu và đưa ra mô hình có độ chính xác cao nhất.**\n___\n\n   # Tôi sẽ bắt đầu với mô hình Linear Support Vector Classification(LSVC)","metadata":{}},{"cell_type":"code","source":"LSVC = LinearSVC(C=0.5, random_state=42)\nLSVC.fit(tfidf_vecto_train, y_train)\ndu_doan = LSVC.predict(tfidf_vecto_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:36:01.911789Z","iopub.execute_input":"2021-10-07T17:36:01.912035Z","iopub.status.idle":"2021-10-07T17:36:06.233336Z","shell.execute_reply.started":"2021-10-07T17:36:01.912009Z","shell.execute_reply":"2021-10-07T17:36:06.232298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\nfrom sklearn import metrics\nprint(\"Classification report of Linear SVC: \\n\",classification_report(y_test,du_doan, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Linear SVC: \\n\",confusion_matrix(y_test,du_doan))\ndochinhxac = metrics.accuracy_score(y_test,du_doan)\nprint(\"Độ chính xác của việc sử dụng TF-IDF fit với mô hình Linear SVC: \\n\" +str('{:04.2f}'.format(dochinhxac *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:36:06.235009Z","iopub.execute_input":"2021-10-07T17:36:06.235533Z","iopub.status.idle":"2021-10-07T17:36:06.277192Z","shell.execute_reply.started":"2021-10-07T17:36:06.235484Z","shell.execute_reply":"2021-10-07T17:36:06.276264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng TF-IDF fit với mô hình Linear SVC: \n90.29%**\n\n**Khoan! Tôi sẽ vectơ hóa bằng cách sử dụng CountVectorizer (binary = False) và fit với mô hình LinearSVC để kiểm tra xem thế nào?**","metadata":{}},{"cell_type":"code","source":"dem_vecto = CountVectorizer(ngram_range=(1,3), binary=False)\nfalse_dem_vecto_train = dem_vecto.fit_transform(corpus_train)\nfalse_dem_vecto_test = dem_vecto.transform(corpus_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:36:06.278615Z","iopub.execute_input":"2021-10-07T17:36:06.27905Z","iopub.status.idle":"2021-10-07T17:37:32.950534Z","shell.execute_reply.started":"2021-10-07T17:36:06.27901Z","shell.execute_reply":"2021-10-07T17:37:32.949583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"false_dem_LSVC = LinearSVC(C=0.5, random_state=42, max_iter=5000)\nfalse_dem_LSVC.fit(false_dem_vecto_train,y_train)\nfalse_dem_du_doan_LSVC = false_dem_LSVC.predict(false_dem_vecto_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:37:32.951947Z","iopub.execute_input":"2021-10-07T17:37:32.95222Z","iopub.status.idle":"2021-10-07T17:40:28.041328Z","shell.execute_reply.started":"2021-10-07T17:37:32.952189Z","shell.execute_reply":"2021-10-07T17:40:28.040226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng CountVectorizer (binary = False) và fit với mô hình LinearSVC\\n\")\nprint(\"Classification report of Linear SVC (binary = False): \\n\",classification_report(y_test,false_dem_du_doan_LSVC, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Linear SVC (binary = False): \\n\",confusion_matrix(y_test,false_dem_du_doan_LSVC))\naccuracy_score_false_lsvc = metrics.accuracy_score(y_test,false_dem_du_doan_LSVC)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit với mô hình Linear SVC: \\n\" +str('{:04.2f}'.format(accuracy_score_false_lsvc *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:40:28.050805Z","iopub.execute_input":"2021-10-07T17:40:28.051747Z","iopub.status.idle":"2021-10-07T17:40:28.089921Z","shell.execute_reply.started":"2021-10-07T17:40:28.051684Z","shell.execute_reply":"2021-10-07T17:40:28.088977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit với mô hình Linear SVC: 89.77%**\n\n***Bây giờ tôi sẽ vectơ hóa bằng cách sử dụng CountVectorizer (binary = True) và fit với mô hình LinearSVC để xem kết quả so với (binary = false) sẽ thế nào?***","metadata":{}},{"cell_type":"code","source":"true_dem_vecto = CountVectorizer(ngram_range=(1,3), binary=True)\ntrue_dem_vecto_train = true_dem_vecto.fit_transform(corpus_train)\ntrue_dem_vecto_test = true_dem_vecto.transform(corpus_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:40:28.091593Z","iopub.execute_input":"2021-10-07T17:40:28.091932Z","iopub.status.idle":"2021-10-07T17:41:53.789117Z","shell.execute_reply.started":"2021-10-07T17:40:28.091889Z","shell.execute_reply":"2021-10-07T17:41:53.788015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_dem_LSVC = LinearSVC(C=0.5, random_state=42,max_iter=5000)\ntrue_dem_LSVC.fit(true_dem_vecto_train,y_train)\ntrue_dem_du_doan_LSVC = true_dem_LSVC.predict(true_dem_vecto_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:41:53.790943Z","iopub.execute_input":"2021-10-07T17:41:53.791304Z","iopub.status.idle":"2021-10-07T17:43:48.19029Z","shell.execute_reply.started":"2021-10-07T17:41:53.791261Z","shell.execute_reply":"2021-10-07T17:43:48.189105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng CountVectorizer (binary = True) và fit với mô hình LinearSVC\\n\")\nprint(\"Classification report of Linear SVC binary = True: \\n\",classification_report(y_test,true_dem_du_doan_LSVC, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Linear SVC binary = True: \\n\",confusion_matrix(y_test,true_dem_du_doan_LSVC))\naccuracy_score_true_LSVC = metrics.accuracy_score(y_test,true_dem_du_doan_LSVC)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit với mô hình Linear SVC: \\n\" +str('{:04.2f}'.format(accuracy_score_true_LSVC *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:43:48.192148Z","iopub.execute_input":"2021-10-07T17:43:48.192494Z","iopub.status.idle":"2021-10-07T17:43:48.232518Z","shell.execute_reply.started":"2021-10-07T17:43:48.192449Z","shell.execute_reply":"2021-10-07T17:43:48.231628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit với mô hình Linear SVC: 89.46%**\n\n***TUYỆT VỜI! chúng ta đạt được độ chính xác gần như tối đa bằng cách sử dụng công cụ vectơ TF-IDF. Và cũng bằng công cụ này tôi sẽ sử dụng thêm mô hình thứ 2-Naive Bayes. Mô hình Bayes sử dụng các xác suất trước để dự đoán xác suất sau rất hữu ích cho việc phân loại với các tính năng rời rạc như phân loại văn bản.***\n___\n    \n   # Mô hình thứ hai: Bayes Thơ Ngây(Multinomial Naive Bayes-MNB)","metadata":{}},{"cell_type":"code","source":"tfidf_vecto_bayes = TfidfVectorizer(ngram_range=(1, 1))\ntfidf_vecto_bayes_train = tfidf_vecto_bayes.fit_transform(corpus_train)\ntfidf_vecto_bayes_test = tfidf_vecto_bayes.transform(corpus_test)\nprint(tfidf_vecto_bayes_train.toarray().shape,tfidf_vecto_bayes_test.toarray().shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:43:48.23387Z","iopub.execute_input":"2021-10-07T17:43:48.23414Z","iopub.status.idle":"2021-10-07T17:44:15.084938Z","shell.execute_reply.started":"2021-10-07T17:43:48.234108Z","shell.execute_reply":"2021-10-07T17:44:15.083921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Có thể thấy rằng trong kho chúng ta có 81301 dữ liệu... Vì vậy, tôi đề xuất dùng Chi-Square(Chi Phân phối bình phương) khi dữ liệu của chúng ta ở dạng đếm tần suất và điều chúng ta quan tâm là số lượng đối tượng thuộc các loại khác nhau, Chi-Square sẽ giúp chúng ta thực hiện việc kiểm tra gần đúng về mặt ý nghĩa đối với sự liên kết(association) giữa hai biến lập nhóm (categorical variables). Bạn có thể lấy bao nhiêu features cũng được(ở đây tôi sẽ lấy ngẫu nhiên 50000 features)**\n\nCác bạn có thể tham khảo Chi-Square tại: https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/using-chi-square-statistic-in-research/","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, chi2\nchichi = SelectKBest(chi2, k=50000)\ntfidf_vecto_bayes_train = chichi.fit_transform(tfidf_vecto_bayes_train,y_train)\ntfidf_vecto_bayes_test = chichi.transform(tfidf_vecto_bayes_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:44:15.086398Z","iopub.execute_input":"2021-10-07T17:44:15.086888Z","iopub.status.idle":"2021-10-07T17:44:15.328415Z","shell.execute_reply.started":"2021-10-07T17:44:15.086847Z","shell.execute_reply":"2021-10-07T17:44:15.327228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_names = tfidf_vecto_bayes.get_feature_names()\nfeat_names = [feat_names[i] for i in chichi.get_support(indices=True)]\nfeat_names = np.asarray(feat_names)\nfeat_names[32245]","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:44:15.330163Z","iopub.execute_input":"2021-10-07T17:44:15.330409Z","iopub.status.idle":"2021-10-07T17:44:15.525024Z","shell.execute_reply.started":"2021-10-07T17:44:15.330381Z","shell.execute_reply":"2021-10-07T17:44:15.524056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Ok! Giờ tôi sẽ fit nó với mô hình Multinomial Naive Bayes.**","metadata":{}},{"cell_type":"code","source":"clf_MNB = MultinomialNB()\nclf_MNB.fit(tfidf_vecto_bayes_train,y_train)\ndu_doan_MNB = clf_MNB.predict(tfidf_vecto_bayes_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:44:15.526384Z","iopub.execute_input":"2021-10-07T17:44:15.526623Z","iopub.status.idle":"2021-10-07T17:44:15.569309Z","shell.execute_reply.started":"2021-10-07T17:44:15.526597Z","shell.execute_reply":"2021-10-07T17:44:15.568244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng TF-IDF fit với mô hình Multinomial Naive Bayes\\n\")\nprint(\"Classification report of Multinomial Naive Bayes: \\n\",classification_report(y_test,du_doan_MNB, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Multinomial Naive Bayes: \\n\",confusion_matrix(y_test,du_doan_MNB))\naccuracy_score_MNB = metrics.accuracy_score(y_test,du_doan_MNB)\nprint(\"Độ chính xác của việc sử dụng TF-IDF fit với mô hình Multinomial Naive Bayes: \\n\" +str('{:04.2f}'.format(accuracy_score_MNB *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:44:15.571069Z","iopub.execute_input":"2021-10-07T17:44:15.571348Z","iopub.status.idle":"2021-10-07T17:44:15.608235Z","shell.execute_reply.started":"2021-10-07T17:44:15.571314Z","shell.execute_reply":"2021-10-07T17:44:15.607314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng TF-IDF fit với mô hình Multinomial Naive Bayes: 86.63%**\n\n**Phân phối đa thức thường yêu cầu số feature số nguyên. Tuy nhiên, trong thực tế, các phép đếm phân số như tf-idf cũng có thể hoạt động. Bây giờ tôi sẽ sử dụng CountVectorizer làm mô hình Bag-of-Words trước khi áp dụng mô hình MultinomialNB để xem thế nào nha.**\n\n***Tôi sẽ vectơ hóa bằng cách sử dụng CountVectorizer (binary = False) và fit với mô hình LinearSVC để kiểm tra xem thế nào?***","metadata":{}},{"cell_type":"code","source":"vecto_MNB = CountVectorizer(ngram_range=(1, 3), binary=False)\ndem_vecto_train_MNB = vecto_MNB.fit_transform(corpus_train)\ndem_vecto_test_MNB = vecto_MNB.transform(corpus_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:44:15.609589Z","iopub.execute_input":"2021-10-07T17:44:15.609845Z","iopub.status.idle":"2021-10-07T17:45:31.107558Z","shell.execute_reply.started":"2021-10-07T17:44:15.609814Z","shell.execute_reply":"2021-10-07T17:45:31.106494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dem_MNB = MultinomialNB()\ndem_MNB.fit(dem_vecto_train_MNB,y_train)\ndem_du_doan_MNB = dem_MNB.predict(dem_vecto_test_MNB)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:45:31.109175Z","iopub.execute_input":"2021-10-07T17:45:31.109769Z","iopub.status.idle":"2021-10-07T17:45:32.108493Z","shell.execute_reply.started":"2021-10-07T17:45:31.109733Z","shell.execute_reply":"2021-10-07T17:45:32.107828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng CountVectorizer (binary = False) và fit với mô hình Multinomial Naive Bayes\\n\")\nprint(\"Classification report of Multinomial Naive Bayes binary = False: \\n\",classification_report(y_test,dem_du_doan_MNB, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Multinomial Naive Bayes binary = False: \\n\",confusion_matrix(y_test,dem_du_doan_MNB))\naccuracy_score_dem_MNB = metrics.accuracy_score(y_test,dem_du_doan_MNB)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Multinomial Naive Bayes: \\n\" +str('{:04.2f}'.format(accuracy_score_dem_MNB *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:45:32.110305Z","iopub.execute_input":"2021-10-07T17:45:32.11077Z","iopub.status.idle":"2021-10-07T17:45:32.146916Z","shell.execute_reply.started":"2021-10-07T17:45:32.110738Z","shell.execute_reply":"2021-10-07T17:45:32.146173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Multinomial Naive Bayes: 88.75%**","metadata":{}},{"cell_type":"code","source":"true_dem_vecto_MNB = CountVectorizer(ngram_range=(1,3), binary=True)\ntrue_dem_vecto_train_MNB = true_dem_vecto_MNB.fit_transform(corpus_train)\ntrue_dem_vecto_test_MNB = true_dem_vecto_MNB.transform(corpus_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:45:32.148004Z","iopub.execute_input":"2021-10-07T17:45:32.149045Z","iopub.status.idle":"2021-10-07T17:46:50.722433Z","shell.execute_reply.started":"2021-10-07T17:45:32.149004Z","shell.execute_reply":"2021-10-07T17:46:50.721137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_dem_MNB = MultinomialNB()\ntrue_dem_MNB.fit(true_dem_vecto_train_MNB,y_train)\ntrue_dem_du_doan_MNB = true_dem_MNB.predict(true_dem_vecto_test_MNB)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:46:50.723842Z","iopub.execute_input":"2021-10-07T17:46:50.72412Z","iopub.status.idle":"2021-10-07T17:46:51.731831Z","shell.execute_reply.started":"2021-10-07T17:46:50.724091Z","shell.execute_reply":"2021-10-07T17:46:51.73072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng CountVectorizer (binary = True) và fit với mô hình Multinomial Naive Bayes\\n\")\nprint(\"Classification report of Multinomial Naive Bayes binary = True: \\n\",classification_report(y_test,true_dem_du_doan_MNB, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Multinomial Naive Bayes binary = True: \\n\",confusion_matrix(y_test,true_dem_du_doan_MNB))\naccuracy_score_true_dem_MNB = metrics.accuracy_score(y_test,true_dem_du_doan_MNB)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit Multinomial Naive Bayes: \\n\" +str('{:04.2f}'.format(accuracy_score_true_dem_MNB *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:46:51.733703Z","iopub.execute_input":"2021-10-07T17:46:51.733973Z","iopub.status.idle":"2021-10-07T17:46:51.77474Z","shell.execute_reply.started":"2021-10-07T17:46:51.733929Z","shell.execute_reply":"2021-10-07T17:46:51.773386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit Multinomial Naive Bayes: 89.10%**\n___","metadata":{}},{"cell_type":"markdown","source":"   # Mô hình thứ ba: Stochastic Gradient Descent Classifier(SGDC)\n**Ok, CÓ thể bạn đang bị rối xíu... Ở mô hình thứ 3 này,để tiết kiệm thời gian cho bạn thì tôi sẽ gơm gọn code lại và đi nhanh phần TfidfVectorizervà CountVectorizer bằng cách sử dụng \"binary = True\" và \"binary = False\" luôn... Ok chứ! Bắt đầu nào!**\n\n**CHÚ Ý: Từ mô hình số 3 này trở về sau, TF-IDF tôi sẽ sử dụng mặc định cài sẵn ở trên và code nhanh, tôi chỉ lặp lại phần countvectorier cho moi người dễ phân biệt...Ok!**\n\nBạn có thể đọc thên tại đây:https://scikit-learn.org/stable/modules/sgd.html","metadata":{}},{"cell_type":"code","source":"#Count vectorizer for bag of words\ndem_vecto_SGD = CountVectorizer(binary=False,ngram_range=(1,3))\ndem_vecto_train_SGD=dem_vecto_SGD.fit_transform(corpus_train)\ndem_vecto_test_SGD=dem_vecto_SGD.transform(corpus_test)\nprint('Count vectorizer for train:',dem_vecto_train_SGD.shape)\nprint('Count vectorizer for test:',dem_vecto_test_SGD.shape)\n\nSGDC = SGDClassifier(loss='hinge',random_state=42)\nfalse_dem_SGDC = SGDC.fit(dem_vecto_train_SGD,y_train)\n\ntfidf_SGDC= SGDC.fit(tfidf_vecto_train,y_train)\n#Predicting the model for bag of words\nfalse_dem_du_doan_SGDC=false_dem_SGDC.predict(dem_vecto_test_SGD)\nprint(false_dem_du_doan_SGDC)\n#Predicting the model for tfidf features\ntfidf_du_doan_SGDC=tfidf_SGDC.predict(tfidf_vecto_test)\nprint(tfidf_du_doan_SGDC)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:46:51.776436Z","iopub.execute_input":"2021-10-07T17:46:51.77686Z","iopub.status.idle":"2021-10-07T17:48:15.600142Z","shell.execute_reply.started":"2021-10-07T17:46:51.776816Z","shell.execute_reply":"2021-10-07T17:48:15.599196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng TF_IDF fit với mô hình SGD Classifier\\n\")\nprint(\"Classification report of SGD Classifier: \\n\",classification_report(y_test,tfidf_du_doan_SGDC, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of SGD Classifier: \\n\",confusion_matrix(y_test,tfidf_du_doan_SGDC))\naccuracy_score_tfidf_SGDC = metrics.accuracy_score(y_test,tfidf_du_doan_SGDC)\nprint(\"Độ chính xác của việc sử dụng TF_IDF fit với mô hình SGD Classifier: \\n\" +str('{:04.2f}'.format(accuracy_score_tfidf_SGDC *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:48:15.601948Z","iopub.execute_input":"2021-10-07T17:48:15.602757Z","iopub.status.idle":"2021-10-07T17:48:15.648386Z","shell.execute_reply.started":"2021-10-07T17:48:15.602704Z","shell.execute_reply":"2021-10-07T17:48:15.647143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng TF_IDF fit với mô hình SGD Classifier: 88.67%**","metadata":{}},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng CountVectorizer (binary = False) fit với mô hình SGD Classifier\\n\")\nprint(\"Classification report of SGD Classifier: \\n\",classification_report(y_test,false_dem_du_doan_SGDC, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of SGD Classifier: \\n\",confusion_matrix(y_test,false_dem_du_doan_SGDC))\naccuracy_score_false_count_SGDC = metrics.accuracy_score(y_test,false_dem_du_doan_SGDC)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit với mô hình SGD Classifier: \\n\" +str('{:04.2f}'.format(accuracy_score_false_count_SGDC *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:48:15.650292Z","iopub.execute_input":"2021-10-07T17:48:15.650678Z","iopub.status.idle":"2021-10-07T17:48:15.688669Z","shell.execute_reply.started":"2021-10-07T17:48:15.650629Z","shell.execute_reply":"2021-10-07T17:48:15.687994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit với mô hình SGD Classifier: 85.84%**","metadata":{}},{"cell_type":"markdown","source":"**Bây giờ tôi sẽ vectơ hóa bằng cách sử dụng CountVectorizer (binary = True) và fit với mô hình SGDC để xem kết quả so với (binary = True) sẽ thế nào?**","metadata":{}},{"cell_type":"code","source":"true_dem_vecto=CountVectorizer(binary=True,ngram_range=(1,3))\ntrue_dem_vecto_train=true_dem_vecto.fit_transform(corpus_train)\ntrue_dem_vecto_test=true_dem_vecto.transform(corpus_test)\n\ntrue_SGDC = SGDClassifier(loss='hinge',random_state=42)\ntrue_dem_SGDC=true_SGDC.fit(true_dem_vecto_train,y_train)\n\ntrue_dem_du_doan_SGDC=true_dem_SGDC.predict(true_dem_vecto_test)\nprint(\"Kết quả của việc sử dụng CountVectorizer (binary = True) fit với mô hình SGD Classifier\\n\")\nprint(\"Classification report of SGD Classifier: \\n\",classification_report(y_test,true_dem_du_doan_SGDC, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of SGD Classifier: \\n\",confusion_matrix(y_test,true_dem_du_doan_SGDC))\naccuracy_score_true_count_SGDC = metrics.accuracy_score(y_test,true_dem_du_doan_SGDC)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit SGD Classifier: \\n\" +str('{:04.2f}'.format(accuracy_score_true_count_SGDC *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:48:15.689979Z","iopub.execute_input":"2021-10-07T17:48:15.690375Z","iopub.status.idle":"2021-10-07T17:49:39.208763Z","shell.execute_reply.started":"2021-10-07T17:48:15.690345Z","shell.execute_reply":"2021-10-07T17:49:39.207882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit SGD Classifier: 89.46%**\n___","metadata":{}},{"cell_type":"markdown","source":"   # Mô hình thứ tư: Hồi Quy Logistic (Logistic regression)\n\n   ***Cũng như mô hình thứ ba, tôi sẽ code nhanh phần này***","metadata":{}},{"cell_type":"code","source":"LR_dem_vecto=CountVectorizer(binary=False,ngram_range=(1,3))\nLR_false_dem_vecto_train=LR_dem_vecto.fit_transform(corpus_train)\nLR_false_dem_vecto_test=LR_dem_vecto.transform(corpus_test)\n\nLR=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\ndem_LR=LR.fit(LR_false_dem_vecto_train,y_train)\ntfidf_LR=LR.fit(tfidf_vecto_train,y_train)\n\nfalse_du_doan_LR=dem_LR.predict(LR_false_dem_vecto_test)\ndu_doan_tfidf_LR=tfidf_LR.predict(tfidf_vecto_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:49:39.210236Z","iopub.execute_input":"2021-10-07T17:49:39.211138Z","iopub.status.idle":"2021-10-07T17:57:46.03005Z","shell.execute_reply.started":"2021-10-07T17:49:39.211078Z","shell.execute_reply":"2021-10-07T17:57:46.028503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng TF-IDF fit với mô hình hồi quy logistic\\n\")\nprint(\"Classification report of Logistic Regression: \\n\",classification_report(y_test,du_doan_tfidf_LR, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Logistic Regression: \\n\",confusion_matrix(y_test,du_doan_tfidf_LR))\naccuracy_score_tfidf_LR = metrics.accuracy_score(y_test,du_doan_tfidf_LR)\nprint(\"Độ chính xác của việc sử dụng TF-IDF fit với mô hình hồi quy logistic: \\n\" +str('{:04.2f}'.format(accuracy_score_tfidf_LR *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:57:46.031897Z","iopub.execute_input":"2021-10-07T17:57:46.032188Z","iopub.status.idle":"2021-10-07T17:57:46.069185Z","shell.execute_reply.started":"2021-10-07T17:57:46.032158Z","shell.execute_reply":"2021-10-07T17:57:46.067875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng TF-IDF fit với mô hình hồi quy logistic: 88.50%**","metadata":{}},{"cell_type":"code","source":"print(\"Kết quả của việc sử dụng CountVectorizer (binary=False) fit với mô hình hồi quy logistic\\n\")\nprint(\"Classification report of Logistic Regression: \\n\",classification_report(y_test,false_du_doan_LR, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Logistic Regression: \\n\",confusion_matrix(y_test,false_du_doan_LR))\naccuracy_score_false_count_LR = metrics.accuracy_score(y_test,false_du_doan_LR)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary=False) fit với mô hình hồi quy logistic: \\n\" +str('{:04.2f}'.format(accuracy_score_false_count_LR *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:57:46.070805Z","iopub.execute_input":"2021-10-07T17:57:46.071252Z","iopub.status.idle":"2021-10-07T17:57:46.109765Z","shell.execute_reply.started":"2021-10-07T17:57:46.071208Z","shell.execute_reply":"2021-10-07T17:57:46.108738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary=False) fit với mô hình hồi quy logistic: 85.62%**","metadata":{}},{"cell_type":"code","source":"true_dem_LR_vecto=CountVectorizer(binary=True,ngram_range=(1,3))\ntrue_dem_LR_vecto_train=true_dem_LR_vecto.fit_transform(corpus_train)\ntrue_dem_LR_vecto_test=true_dem_LR_vecto.transform(corpus_test)\n\ntrue_LR=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\ntrue_dem_LR=true_LR.fit(true_dem_LR_vecto_train,y_train)\n\ntrue_du_doan_LR=true_dem_LR.predict(true_dem_LR_vecto_test)\n\nprint(\"Kết quả của việc sử dụng CountVectorizer (binary = True) fit với mô hình hồi quy logistic\\n\")\nprint(\"Classification report of Logistic Regression: \\n\",classification_report(y_test,true_du_doan_LR, target_names = ['Positive','Negative']))\nprint(\"Confusion Matrix of Logistic Regression: \\n\",confusion_matrix(y_test,true_du_doan_LR))\naccuracy_score_true_count_LR = metrics.accuracy_score(y_test,true_du_doan_LR)\nprint(\"Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit với mô hình hồi quy logistic: \\n\" +str('{:04.2f}'.format(accuracy_score_true_count_LR *100)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T17:57:46.111145Z","iopub.execute_input":"2021-10-07T17:57:46.111398Z","iopub.status.idle":"2021-10-07T18:02:20.079045Z","shell.execute_reply.started":"2021-10-07T17:57:46.11137Z","shell.execute_reply":"2021-10-07T18:02:20.078009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit với mô hình hồi quy logistic: 89.65%**\n___","metadata":{}},{"cell_type":"markdown","source":"# **Nhận xét về kết quả thu được từ 4 mô hình:**\n\n**Chúng ta có thể thấy rằng mô hình LinearSVC(LSVC) có TF-IDF đạt độ chính xác cao nhất:90.29%.** Vì vậy, tôi sẽ biểu diễn cho bạn thấy về kết quả dự đoán dự trên tập dữ liệu chúng ta có được. Ok! đi nào","metadata":{}},{"cell_type":"code","source":"accuracy = {'LSVC': ['90.29','89.77','89.46'],\n            'MNB': ['86.63','88.75','89.10'],\n            'SGDC':['88.67','85.84','89.46'],\n            'LR' :['88.50','85.62', '89.65']}\naccuracy = pd.DataFrame(accuracy,index=['TF-IDF','Binary=False','Binary=True'])\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:20.080582Z","iopub.execute_input":"2021-10-07T18:02:20.080857Z","iopub.status.idle":"2021-10-07T18:02:20.098224Z","shell.execute_reply.started":"2021-10-07T18:02:20.080825Z","shell.execute_reply":"2021-10-07T18:02:20.097197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"   # Biểu diễn kết quả dự đoán tập dữ liệu IMDB 50K","metadata":{}},{"cell_type":"code","source":"df_predicted = x_test.copy()\ndf_predicted = pd.DataFrame(df_predicted)\ndf_predicted.columns = ['review']\ndf_predicted = df_predicted.reset_index()\ndf_predicted = df_predicted.drop(['index'], axis=1)\ndf_predicted.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:20.099873Z","iopub.execute_input":"2021-10-07T18:02:20.100185Z","iopub.status.idle":"2021-10-07T18:02:20.131897Z","shell.execute_reply.started":"2021-10-07T18:02:20.100145Z","shell.execute_reply":"2021-10-07T18:02:20.13086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_hientai = y_test.copy()\ny_test_hientai = pd.DataFrame(y_test_hientai)\ny_test_hientai.columns = ['sentiment']\ny_test_hientai['sentiment'] = y_test_hientai['sentiment'].replace({1: 'positive', 0: 'negative'})","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:20.133234Z","iopub.execute_input":"2021-10-07T18:02:20.133499Z","iopub.status.idle":"2021-10-07T18:02:20.143438Z","shell.execute_reply.started":"2021-10-07T18:02:20.133469Z","shell.execute_reply":"2021-10-07T18:02:20.142127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predicted = du_doan.copy()\ny_test_predicted = pd.DataFrame(y_test_predicted)\ny_test_predicted.columns = ['predicted_sentiment']\ny_test_predicted['predicted_sentiment'] = y_test_predicted['predicted_sentiment'].replace({1: 'positive', 0: 'negative'})","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:20.144731Z","iopub.execute_input":"2021-10-07T18:02:20.144993Z","iopub.status.idle":"2021-10-07T18:02:20.15789Z","shell.execute_reply.started":"2021-10-07T18:02:20.144946Z","shell.execute_reply":"2021-10-07T18:02:20.157061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ketqua_test = pd.concat([df_predicted, y_test_hientai, y_test_predicted], axis=1)\nketqua_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:20.159716Z","iopub.execute_input":"2021-10-07T18:02:20.160344Z","iopub.status.idle":"2021-10-07T18:02:20.182596Z","shell.execute_reply.started":"2021-10-07T18:02:20.160285Z","shell.execute_reply":"2021-10-07T18:02:20.181395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tạo lớp nhúng (Creation the embedding layer)\n***Như đã trình bày, tôi cần mộp lớp nhúng chuyển đổi dữ liệu văn bản của tôi thành dữ liệu số. Nó được sử dụng làm lớp đầu tiên cho các mô hình học sâu trong keras. Đây là bước đầu tiên để tôi có thể tiến tới mô hình học sâu... Nó cũng khá nhanh và không mất nhiều thời gian của bạn đâu...cùng đi nhé!ok!Go!!!***","metadata":{}},{"cell_type":"code","source":"# Tạo một từ để lập chỉ mục từ điển từ mô đun tokenizer \n# Mỗi từ được sử dụng làm khóa trong khi chỉ mục duy nhất tương ứng và được sử dụng làm giá trị cho khóa.\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(x_train)\n \nx_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:20.184913Z","iopub.execute_input":"2021-10-07T18:02:20.185347Z","iopub.status.idle":"2021-10-07T18:02:38.752683Z","shell.execute_reply.started":"2021-10-07T18:02:20.185297Z","shell.execute_reply":"2021-10-07T18:02:38.751667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x_train\n#print(y_train)\n#print(y_test)\n#x_test","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:38.754044Z","iopub.execute_input":"2021-10-07T18:02:38.754286Z","iopub.status.idle":"2021-10-07T18:02:38.758981Z","shell.execute_reply.started":"2021-10-07T18:02:38.754259Z","shell.execute_reply":"2021-10-07T18:02:38.757894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"do_dai_danhsach_x = [len(i) for i in x_train + x_test]\nprint(f'Độ dài tối đa của câu:{max(do_dai_danhsach_x)}')\nprint(f'Độ dài trung bình của câu:{np.mean(do_dai_danhsach_x)}')","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:38.760384Z","iopub.execute_input":"2021-10-07T18:02:38.760629Z","iopub.status.idle":"2021-10-07T18:02:38.793523Z","shell.execute_reply.started":"2021-10-07T18:02:38.760603Z","shell.execute_reply":"2021-10-07T18:02:38.792561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sử dụng seaborn để vẽ độ dài câu\nplt.figure(figsize=(8,5), dpi= 80)\nsns.distplot(do_dai_danhsach_x, color='blue')\nplt.title('Biểu đồ thể hiện số lượng từ',fontsize=20,color='black')\nplt.xlabel('Số từ')\nplt.ylabel('Số lượt review')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:38.795671Z","iopub.execute_input":"2021-10-07T18:02:38.796504Z","iopub.status.idle":"2021-10-07T18:02:39.51259Z","shell.execute_reply.started":"2021-10-07T18:02:38.796454Z","shell.execute_reply":"2021-10-07T18:02:39.511564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tôi sẽ đặt kích thước tối đa của mỗi danh sách là 100. Nếu danh sách nào có maxlength > 100 sẽ bị cắt bớt và danh sách nào có maxlength < 100 sẽ được thêm 0 cho đến khi có độ dài tối đa = maxlength.Dễ hiểu đúng không?**\n**Quá trình này được gọi là padding. Đoạn code dưới đây sẽ tìm kích thước vocabulary và sau đó là perfom padding trên cả X_train và X_test , tokenizer.word_index**","metadata":{}},{"cell_type":"code","source":"vocabulary_size = len(tokenizer.word_index) + 1\nmaxlength = 100\n\nx_train_padding = pad_sequences(x_train, padding=\"post\",maxlen=maxlength)\nx_test_padding = pad_sequences(x_test, padding=\"post\",maxlen=maxlength)\n# Kiểm tra danh sách ngẫu nhiên trong X_train (các câu trước đó)\n# có cùng độ dài là 100\nlen(x_train[3])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:39.514537Z","iopub.execute_input":"2021-10-07T18:02:39.514914Z","iopub.status.idle":"2021-10-07T18:02:40.851112Z","shell.execute_reply.started":"2021-10-07T18:02:39.514865Z","shell.execute_reply":"2021-10-07T18:02:40.850167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kiểm tra xíu\nx_train_padding","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:40.852577Z","iopub.execute_input":"2021-10-07T18:02:40.852901Z","iopub.status.idle":"2021-10-07T18:02:40.861315Z","shell.execute_reply.started":"2021-10-07T18:02:40.852858Z","shell.execute_reply":"2021-10-07T18:02:40.860074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocabulary_size","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:40.862827Z","iopub.execute_input":"2021-10-07T18:02:40.863103Z","iopub.status.idle":"2021-10-07T18:02:40.875781Z","shell.execute_reply.started":"2021-10-07T18:02:40.863072Z","shell.execute_reply":"2021-10-07T18:02:40.874885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Kết quả đã chỉ ra rằng tôi có 109137 từ duy nhất trong kho và tôi sẽ tạo mạng noron được thiết kế để từ dữ liệu số.**\n\n* **Nhúng từ(Word Embedding) sẽ đảm nhiệm việc cải thiện khả năng mạng noron học từ dữ liệu văn bản và các vectơ được gọi chung là Embeddings.**\n\n* **Tiếp theo tôi sẽ tạo ra ma trận feature mà cụ thể công cụ tôi sẽ sử dụng GloVe Embeddings. Theo định nghĩa, GloVe là viết tắt của Global Vectors dùng để biểu diễn từ. Đây là một thuật toán học không giám sát được phát triển bởi Stanford cho việc tạo nhúng từ bằng cách tổng hợp ma trận đồng xuất hiện các word-word toàn cục từ một kho ngữ liệu mà chúng ta thu được.**\n\n* **Kết quả nhúng được hiển thị trong các cấu trúc tuyến tính thú vị của từ trong không gian vectơ. Nói cách khác,nếu hai từ cùng xuất hiện nhiều lần, điều đó có nghĩa là chúng có một số điểm tương đồng về ngôn ngữ hoặc ngữ nghĩa. Ok chứ!**\n* **GloVe word Embedding sẽ tạo một từ điển và sẽ chứa các từ làm khóa(keys) và danh sách nhúng tương ứng của chúng dưới dạng giá trị(values)**\n\n    * Bạn có thể tham khảo thêm tại đây: https://trituenhantao.io/kien-thuc/huong-dan-su-dung-glove/\n    * Các bạn có thể tham khảo tại đây: https://ichi.pro/vi/nhung-tu-la-gi-71370589666818","metadata":{}},{"cell_type":"code","source":"tudien_duoc_nhung = dict()\nglove_file = open('../input/glove6b100d/glove.6B.100d.txt',encoding='utf-8')\nfor line in glove_file:\n    record = line.split()\n    word = record[0]\n    kich_thuoc = asarray(record[1:], dtype = \"float32\")\n    tudien_duoc_nhung[word] = kich_thuoc\nglove_file.close()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:02:40.87734Z","iopub.execute_input":"2021-10-07T18:02:40.877574Z","iopub.status.idle":"2021-10-07T18:03:00.10564Z","shell.execute_reply.started":"2021-10-07T18:02:40.87755Z","shell.execute_reply":"2021-10-07T18:03:00.104799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Kế tiếp, tôi sẽ tạo ra một ma trận nhúng(matrix embedding). Ở đây, mỗi số hàng sẽ tương ứng với chỉ mục của từ trong kho ngữ liệu. Ma trận sẽ chứa các embedding từ GloVe cho các từ(word) trong kho dữ liệu của tôi có được.Ok!**","metadata":{}},{"cell_type":"code","source":"ma_tran_nhung = zeros((vocabulary_size,100))\nfor word, index in tokenizer.word_index.items():\n    vecto_nhung = tudien_duoc_nhung.get(word)\n    if vecto_nhung is not None:\n        ma_tran_nhung[index] = vecto_nhung","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:00.106909Z","iopub.execute_input":"2021-10-07T18:03:00.107385Z","iopub.status.idle":"2021-10-07T18:03:00.414308Z","shell.execute_reply.started":"2021-10-07T18:03:00.107341Z","shell.execute_reply":"2021-10-07T18:03:00.413475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vecto_nhung","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:00.415878Z","iopub.execute_input":"2021-10-07T18:03:00.416764Z","iopub.status.idle":"2021-10-07T18:03:00.427119Z","shell.execute_reply.started":"2021-10-07T18:03:00.416713Z","shell.execute_reply":"2021-10-07T18:03:00.425902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ma_tran_nhung","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:00.428928Z","iopub.execute_input":"2021-10-07T18:03:00.429334Z","iopub.status.idle":"2021-10-07T18:03:00.441147Z","shell.execute_reply.started":"2021-10-07T18:03:00.429289Z","shell.execute_reply":"2021-10-07T18:03:00.43993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bạn có thể xóa dấu # để in ra 'tudien_duoc_nhung'\n#tudien_duoc_nhung","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:00.442774Z","iopub.execute_input":"2021-10-07T18:03:00.443135Z","iopub.status.idle":"2021-10-07T18:03:00.450392Z","shell.execute_reply.started":"2021-10-07T18:03:00.443091Z","shell.execute_reply":"2021-10-07T18:03:00.449352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Mô hình học Sâu (Deep Learning Models)**\n\n***Ở mô hình học sâu thì nó hơi khác so với các mô hình máy học... Nhưng khi tìm hiểu thì mình thấy có rất nhiều thứ hay mà chúng ta có thể khám phá khi dự đoán cho tập dữ liệu chúng ta đang xét...Come on! cùng đi với tôi nào! GO!***","metadata":{}},{"cell_type":"markdown","source":"   # Mô hình học sâu đơn giản\n* ***Để không bị rối thì tôi sẽ làm phần đơn giản cho bạn dễ hình dung mô hình học sâu được thiết kế thế nào? ok!***\n* ***Tạo một mạng nơ-ron học sâu đơn giản. Sau đó tạo một lớp nhúng(class embed) bằng cách chỉ định các tham số mà chúng tôi đã tạo trước đó và thêm(add) nó vào mô hình(model)***\n* ***Flatten lớp nhúng lại vì tôi đang kết nối thẳng lớp nhúng với lớp Dense(Dense layer)***\n* ***Cuối cùng, tôi thêm một lớp dense với chức năng kích hoạt sigmoid.***\n* ***Tôi biết bạn đang tự hỏi Sigmoid và Dense là gì? Chúng có quan hệ gì?***\n\n*     Bạn có thể tham khảo tại đây: https://vn.got-it.ai/blog/tim-hieu-sigmoid-function-va-lich-su-hinh-thanh-cua-no\n*     Bạn có thể tham khảo tại đây: https://trituenhantao.io/tu-dien-thuat-ngu/dense-layer/","metadata":{}},{"cell_type":"code","source":"mo_hinh = Sequential()\nlop_nhung = Embedding(vocabulary_size, 100, weights = [ma_tran_nhung],input_length=maxlength,trainable=False)\nmo_hinh.add(lop_nhung)\nmo_hinh.add(Flatten())\nmo_hinh.add(Dense(1, activation = 'sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:00.452058Z","iopub.execute_input":"2021-10-07T18:03:00.452777Z","iopub.status.idle":"2021-10-07T18:03:01.050155Z","shell.execute_reply.started":"2021-10-07T18:03:00.452716Z","shell.execute_reply":"2021-10-07T18:03:01.049407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Biên dịch\nmo_hinh.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])\nprint(mo_hinh.summary())","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:01.051632Z","iopub.execute_input":"2021-10-07T18:03:01.052106Z","iopub.status.idle":"2021-10-07T18:03:01.077524Z","shell.execute_reply.started":"2021-10-07T18:03:01.052071Z","shell.execute_reply":"2021-10-07T18:03:01.076592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, batch_size=128,epochs = 20, verbose=1, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:01.08011Z","iopub.execute_input":"2021-10-07T18:03:01.080788Z","iopub.status.idle":"2021-10-07T18:03:27.057672Z","shell.execute_reply.started":"2021-10-07T18:03:01.080737Z","shell.execute_reply":"2021-10-07T18:03:27.056479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diem_danh_gia = mo_hinh.evaluate(x_test_padding, y_test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:27.059723Z","iopub.execute_input":"2021-10-07T18:03:27.060067Z","iopub.status.idle":"2021-10-07T18:03:28.009706Z","shell.execute_reply.started":"2021-10-07T18:03:27.060029Z","shell.execute_reply":"2021-10-07T18:03:28.009073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Kiểm tra độ chính xác\nprint(\"Độ chính xác: {:.2%}\".format(diem_danh_gia[1]))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:28.011309Z","iopub.execute_input":"2021-10-07T18:03:28.01176Z","iopub.status.idle":"2021-10-07T18:03:28.017976Z","shell.execute_reply.started":"2021-10-07T18:03:28.011712Z","shell.execute_reply":"2021-10-07T18:03:28.016981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"du_doan_y = mo_hinh.predict(x_test_padding)\ndu_doan_y = np.round(du_doan_y).astype(int)\nprint(classification_report(y_test,du_doan_y))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:28.019475Z","iopub.execute_input":"2021-10-07T18:03:28.020022Z","iopub.status.idle":"2021-10-07T18:03:28.809668Z","shell.execute_reply.started":"2021-10-07T18:03:28.019935Z","shell.execute_reply":"2021-10-07T18:03:28.80887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Biểu đồ hiệu suất chính xác của mô hình',fontsize=15)\nplt.xlabel('Epochs',fontsize=15)\nplt.ylabel('Accuracy',fontsize=15)\nplt.legend(['Train data','Test data'],loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Biểu đồ hiệu suất thất bại của mô hình',fontsize=15)\nplt.xlabel('Epochs',fontsize=10)\nplt.ylabel('Loss',fontsize=10)\nplt.legend(['train','test'],loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:28.811248Z","iopub.execute_input":"2021-10-07T18:03:28.811861Z","iopub.status.idle":"2021-10-07T18:03:29.345844Z","shell.execute_reply.started":"2021-10-07T18:03:28.81182Z","shell.execute_reply":"2021-10-07T18:03:29.344659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Độ chính xác trên tập dữ liệu huấn luyện cao hơn so với tập dữ liệu thử nghiệm nên mạng nơ-ron sâu không tốt cho các dự đoán.**","metadata":{}},{"cell_type":"markdown","source":"   # Mạng nơ-ron hồi quy (RNN - Recurrent Neural Network) + LSTM\n   \n   **Mạng nơ-ron hồi quy hoạt động tốt trên dữ liệu sequence. Dữ liệu văn bản là một chuỗi sequence data nên RNN là lựa chọn tốt để giải quyết các vấn đề liên quan đến văn bản.**\n* **Thứ nhất, tôi xây dựng cấu trúc mô hình và tạo một lớp nhúng bằng cách chỉ định các tham số mà chúng ta đã tạo trước đó.**\n* **Tiếp theo,tạo mạng nơ-ron lặp lại. Ở đây, tôi sẽ sử dụng LTSM-Long Short Term Memory networks(Mạng bộ nhớ dài-ngắn).**\n* **Hai chiều có nghĩa là trình tự xử lý RNN từ đầu đến cuối và ngược lại Điều này sẽ làm cho mô hình hoạt động tốt hơn.ôi đã thêm một lớp ẩn khác và bao gồm một chức năng kích hoạt là relu.s**\n* **Cuối cùng, tôi thêm một lớp dense với chức năng kích hoạt sigmoid.**\n\n* Bạn có thể tham khảo tại đây:https://nttuan8.com/bai-14-long-short-term-memory-lstm/\n* Bạn có thể tham khảo tại đây: https://dominhhai.github.io/vi/2017/10/what-is-rnn/","metadata":{}},{"cell_type":"code","source":"mo_hinh = tf.keras.Sequential([tf.keras.layers.Embedding(vocabulary_size, 100,weights=[ma_tran_nhung],input_length=maxlength, trainable=False),\n                                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),tf.keras.layers.Dense(128, activation='relu'),\n                                tf.keras.layers.Dense(1, activation='sigmoid')])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:29.347252Z","iopub.execute_input":"2021-10-07T18:03:29.347525Z","iopub.status.idle":"2021-10-07T18:03:30.368862Z","shell.execute_reply.started":"2021-10-07T18:03:29.347493Z","shell.execute_reply":"2021-10-07T18:03:30.368049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mo_hinh.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-4),metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:30.37018Z","iopub.execute_input":"2021-10-07T18:03:30.371121Z","iopub.status.idle":"2021-10-07T18:03:30.385979Z","shell.execute_reply.started":"2021-10-07T18:03:30.371061Z","shell.execute_reply":"2021-10-07T18:03:30.384921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mo_hinh.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:30.387755Z","iopub.execute_input":"2021-10-07T18:03:30.388082Z","iopub.status.idle":"2021-10-07T18:03:30.404707Z","shell.execute_reply.started":"2021-10-07T18:03:30.388048Z","shell.execute_reply":"2021-10-07T18:03:30.403642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs=10,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:03:30.406379Z","iopub.execute_input":"2021-10-07T18:03:30.406711Z","iopub.status.idle":"2021-10-07T18:17:18.470628Z","shell.execute_reply.started":"2021-10-07T18:03:30.406676Z","shell.execute_reply":"2021-10-07T18:17:18.469764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_score = mo_hinh.evaluate(x_test_padding, y_test, verbose = 1)\nacc_score","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:17:18.472559Z","iopub.execute_input":"2021-10-07T18:17:18.473259Z","iopub.status.idle":"2021-10-07T18:17:42.00802Z","shell.execute_reply.started":"2021-10-07T18:17:18.47322Z","shell.execute_reply":"2021-10-07T18:17:42.007076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy Test: {:.2%}\".format(acc_score[1]))\nprint(\"Accuracy Score: {:.2%}\".format(acc_score[0]))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:17:42.009257Z","iopub.execute_input":"2021-10-07T18:17:42.009991Z","iopub.status.idle":"2021-10-07T18:17:42.016167Z","shell.execute_reply.started":"2021-10-07T18:17:42.009926Z","shell.execute_reply":"2021-10-07T18:17:42.015317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Độ chính xác của tập dữ liệu huấn luyện và kiểm tra gần nhau, vì vậy mô hình RNN (LSTM) hoạt động tốt trên dữ liệu mới.**","metadata":{}},{"cell_type":"code","source":"# hàm dự đóán\ndu_doan_y = mo_hinh.predict(x_test_padding)\ndu_doan_y = np.round(du_doan_y).astype(int)\nprint(classification_report(y_test,du_doan_y))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:17:42.017434Z","iopub.execute_input":"2021-10-07T18:17:42.018057Z","iopub.status.idle":"2021-10-07T18:18:05.063988Z","shell.execute_reply.started":"2021-10-07T18:17:42.018012Z","shell.execute_reply":"2021-10-07T18:18:05.062684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'],color=\"red\")\nplt.plot(history.history['val_accuracy'])\nplt.title(\"Hiệu Suất Chính Xác Mô Hình Sử Dụng RNN\",fontsize=15)\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"Accuracy\",fontsize=10)\nplt.legend([\"Train Data\",\"Text data\"],loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:18:05.075814Z","iopub.execute_input":"2021-10-07T18:18:05.076207Z","iopub.status.idle":"2021-10-07T18:18:05.329572Z","shell.execute_reply.started":"2021-10-07T18:18:05.076166Z","shell.execute_reply":"2021-10-07T18:18:05.328891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'],color=\"red\")\nplt.plot(history.history['val_loss'])\nplt.title(\"Hiệu Suất Thất Bại Mô Hình Sử Dụng RNN\",fontsize=15)\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"loss\",fontsize=10)\nplt.legend([\"train Data\",\"text data\"],loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:18:05.330875Z","iopub.execute_input":"2021-10-07T18:18:05.331546Z","iopub.status.idle":"2021-10-07T18:18:05.555976Z","shell.execute_reply.started":"2021-10-07T18:18:05.331506Z","shell.execute_reply":"2021-10-07T18:18:05.555271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"   # Mạng Nơ-ron Hồi Quy Với (2 RNN layer or 2 LSTM layer) + dropout\n   **TƯƠNG TỰ như trên: Nhưng ở đây tôi thêm vào DROPOUT, ta được:**\n* **Thứ nhất, tôi xây dựng cấu trúc mô hình và tạo một lớp nhúng bằng cách chỉ định các tham số mà chúng ta đã tạo trước đó.**\n* **Tiếp theo,tạo mạng nơ-ron lặp lại. Ở đây, tôi sẽ sử dụng LTSM-Long Short Term Memory networks(Mạng bộ nhớ dài-ngắn).**\n* **Hai chiều có nghĩa là trình tự xử lý RNN từ đầu đến cuối và ngược lại Điều này sẽ làm cho mô hình hoạt động tốt hơn.ôi đã thêm một lớp ẩn khác và bao gồm một chức năng kích hoạt là relu**\n* **thêm Dropout để ngăn mô hình không vừa vặn**\n* **loại bỏ ngẫu nhiên một số tế bào thần kinh trong các lớp ẩn**\n* **Cuối cùng, tôi thêm một lớp dense với chức năng kích hoạt sigmoid.**","metadata":{}},{"cell_type":"code","source":"mo_hinh = tf.keras.Sequential([tf.keras.layers.Embedding(vocabulary_size, 100,weights=[ma_tran_nhung],input_length=maxlength, trainable=False),\n            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences = True)),\n            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(25)),\n            tf.keras.layers.Dense(50, activation='relu'),\n            tf.keras.layers.Dropout(0.5),\n            tf.keras.layers.Dense(1, activation='sigmoid')])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:18:05.557233Z","iopub.execute_input":"2021-10-07T18:18:05.557972Z","iopub.status.idle":"2021-10-07T18:18:07.004674Z","shell.execute_reply.started":"2021-10-07T18:18:05.557919Z","shell.execute_reply":"2021-10-07T18:18:07.00343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mo_hinh.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:18:07.006541Z","iopub.execute_input":"2021-10-07T18:18:07.007032Z","iopub.status.idle":"2021-10-07T18:18:07.02143Z","shell.execute_reply.started":"2021-10-07T18:18:07.006984Z","shell.execute_reply":"2021-10-07T18:18:07.020154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mo_hinh.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-4),metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:18:07.023098Z","iopub.execute_input":"2021-10-07T18:18:07.024031Z","iopub.status.idle":"2021-10-07T18:18:07.039073Z","shell.execute_reply.started":"2021-10-07T18:18:07.023953Z","shell.execute_reply":"2021-10-07T18:18:07.038098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lắp mô hình với bộ train để training và tôi sử dụng 30 Epochs để tìm độ chính xác tối ưu nhất có thể.Ok! Đợi tí xem kết quả nào!**","metadata":{}},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs= 10,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:18:07.040639Z","iopub.execute_input":"2021-10-07T18:18:07.041472Z","iopub.status.idle":"2021-10-07T18:28:55.737465Z","shell.execute_reply.started":"2021-10-07T18:18:07.041422Z","shell.execute_reply":"2021-10-07T18:28:55.736609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs= 5,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:28:55.739396Z","iopub.execute_input":"2021-10-07T18:28:55.739834Z","iopub.status.idle":"2021-10-07T18:34:21.952636Z","shell.execute_reply.started":"2021-10-07T18:28:55.739797Z","shell.execute_reply":"2021-10-07T18:34:21.951533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs= 5,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:34:21.95759Z","iopub.execute_input":"2021-10-07T18:34:21.958106Z","iopub.status.idle":"2021-10-07T18:40:04.28288Z","shell.execute_reply.started":"2021-10-07T18:34:21.958053Z","shell.execute_reply":"2021-10-07T18:40:04.282108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs= 2,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:40:04.284528Z","iopub.execute_input":"2021-10-07T18:40:04.285284Z","iopub.status.idle":"2021-10-07T18:42:17.074289Z","shell.execute_reply.started":"2021-10-07T18:40:04.285246Z","shell.execute_reply":"2021-10-07T18:42:17.073194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs= 2,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:42:17.076175Z","iopub.execute_input":"2021-10-07T18:42:17.076478Z","iopub.status.idle":"2021-10-07T18:44:39.056237Z","shell.execute_reply.started":"2021-10-07T18:42:17.076446Z","shell.execute_reply":"2021-10-07T18:44:39.055116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs= 1,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:44:39.058023Z","iopub.execute_input":"2021-10-07T18:44:39.058334Z","iopub.status.idle":"2021-10-07T18:45:45.355327Z","shell.execute_reply.started":"2021-10-07T18:44:39.0583Z","shell.execute_reply":"2021-10-07T18:45:45.354213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, epochs= 1,batch_size = 128, verbose = 1,validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:45:45.359601Z","iopub.execute_input":"2021-10-07T18:45:45.361799Z","iopub.status.idle":"2021-10-07T18:47:07.337487Z","shell.execute_reply.started":"2021-10-07T18:45:45.361758Z","shell.execute_reply":"2021-10-07T18:47:07.336351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_score = mo_hinh.evaluate(x_test_padding, y_test, verbose = 1)\nacc_score","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:47:07.339397Z","iopub.execute_input":"2021-10-07T18:47:07.339661Z","iopub.status.idle":"2021-10-07T18:47:22.123857Z","shell.execute_reply.started":"2021-10-07T18:47:07.33963Z","shell.execute_reply":"2021-10-07T18:47:22.122825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy Score: {:.2%}\".format(acc_score[0]))\nprint(\"Accuracy Train:{:.2%}\".format(acc_score[1]))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:47:22.125862Z","iopub.execute_input":"2021-10-07T18:47:22.126471Z","iopub.status.idle":"2021-10-07T18:47:22.133463Z","shell.execute_reply.started":"2021-10-07T18:47:22.126419Z","shell.execute_reply":"2021-10-07T18:47:22.132363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"du_doan_y = mo_hinh.predict(x_test_padding)\ndu_doan_y = np.round(du_doan_y).astype(int)\nprint(classification_report(y_test,du_doan_y))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:47:22.135375Z","iopub.execute_input":"2021-10-07T18:47:22.135727Z","iopub.status.idle":"2021-10-07T18:47:37.194729Z","shell.execute_reply.started":"2021-10-07T18:47:22.135675Z","shell.execute_reply":"2021-10-07T18:47:37.19379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác khi sử dụng lớp RNN bổ sung thêm LSTM(2 lớp RNN + LSTM) + propout  là 83%.**","metadata":{}},{"cell_type":"markdown","source":"   # Convolutional Neural Network with dropout","metadata":{}},{"cell_type":"code","source":"from keras.layers.core import Activation, Dropout, Dense\nfrom keras.layers import Flatten\nfrom keras.layers import GlobalMaxPooling1D,Conv1D,LSTM\n\nmo_hinh = Sequential()\n\nlop_nhung = Embedding(vocabulary_size, 100, weights=[ma_tran_nhung], input_length=maxlength , trainable=False)\nmo_hinh.add(lop_nhung)\n\nmo_hinh.add(Conv1D(128, 5, activation='relu'))\nmo_hinh.add(GlobalMaxPooling1D())\nmo_hinh.add(Dropout(0.2)),\nmo_hinh.add(Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:47:37.196141Z","iopub.execute_input":"2021-10-07T18:47:37.196401Z","iopub.status.idle":"2021-10-07T18:47:37.511647Z","shell.execute_reply.started":"2021-10-07T18:47:37.196371Z","shell.execute_reply":"2021-10-07T18:47:37.510835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mo_hinh.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:47:37.512972Z","iopub.execute_input":"2021-10-07T18:47:37.513451Z","iopub.status.idle":"2021-10-07T18:47:37.527023Z","shell.execute_reply.started":"2021-10-07T18:47:37.513418Z","shell.execute_reply":"2021-10-07T18:47:37.525971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mo_hinh.summary())","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:47:37.528883Z","iopub.execute_input":"2021-10-07T18:47:37.530255Z","iopub.status.idle":"2021-10-07T18:47:37.544122Z","shell.execute_reply.started":"2021-10-07T18:47:37.530201Z","shell.execute_reply":"2021-10-07T18:47:37.54334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\naccuracy_score = mo_hinh.evaluate(x_test_padding, y_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:47:37.545604Z","iopub.execute_input":"2021-10-07T18:47:37.545831Z","iopub.status.idle":"2021-10-07T18:49:01.256194Z","shell.execute_reply.started":"2021-10-07T18:47:37.545803Z","shell.execute_reply":"2021-10-07T18:49:01.255446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, batch_size=128, epochs=4, verbose=1, validation_split=0.2)\n\naccuracy_score = mo_hinh.evaluate(x_test_padding, y_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:49:01.258595Z","iopub.execute_input":"2021-10-07T18:49:01.259317Z","iopub.status.idle":"2021-10-07T18:49:56.860462Z","shell.execute_reply.started":"2021-10-07T18:49:01.259268Z","shell.execute_reply":"2021-10-07T18:49:56.859389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = mo_hinh.fit(x_train_padding, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n\naccuracy_score = mo_hinh.evaluate(x_test_padding, y_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:49:56.862327Z","iopub.execute_input":"2021-10-07T18:49:56.862588Z","iopub.status.idle":"2021-10-07T18:52:21.640682Z","shell.execute_reply.started":"2021-10-07T18:49:56.862558Z","shell.execute_reply":"2021-10-07T18:52:21.639627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"du_doany = mo_hinh.predict(x_test_padding)\ndu_doany = np.round(du_doany).astype(int)\nprint(classification_report(y_test,du_doany))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:52:21.642378Z","iopub.execute_input":"2021-10-07T18:52:21.642666Z","iopub.status.idle":"2021-10-07T18:52:24.222652Z","shell.execute_reply.started":"2021-10-07T18:52:21.642625Z","shell.execute_reply":"2021-10-07T18:52:24.221759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:52:24.223842Z","iopub.execute_input":"2021-10-07T18:52:24.224104Z","iopub.status.idle":"2021-10-07T18:52:24.231009Z","shell.execute_reply.started":"2021-10-07T18:52:24.224074Z","shell.execute_reply":"2021-10-07T18:52:24.230138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test Score: {:.2%}\".format(accuracy_score[0]))\nprint(\"Test Accuracy: {:.2%}\".format(accuracy_score[1]))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:52:24.232086Z","iopub.execute_input":"2021-10-07T18:52:24.232922Z","iopub.status.idle":"2021-10-07T18:52:24.248431Z","shell.execute_reply.started":"2021-10-07T18:52:24.232882Z","shell.execute_reply":"2021-10-07T18:52:24.247553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Độ chính xác khi sử dụng CNN trên tập dữ liệu là 84.71%**","metadata":{}},{"cell_type":"markdown","source":"# Word cloud for positive review words","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud \nplt.figure(figsize=(15,5))\npositive_text = corpus_train[2]\nWC=WordCloud(width=1500,height=1000,max_words=500,min_font_size=5)\npositive_words=WC.generate(positive_text)\nplt.imshow(positive_words,interpolation='bilinear')\nplt.show","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:52:24.249894Z","iopub.execute_input":"2021-10-07T18:52:24.250884Z","iopub.status.idle":"2021-10-07T18:52:27.051449Z","shell.execute_reply.started":"2021-10-07T18:52:24.250828Z","shell.execute_reply":"2021-10-07T18:52:27.050796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud \nplt.figure(figsize=(15,5))\npositive_text = corpus_train[20]\nWC=WordCloud(width=1500,height=1000,max_words=500,min_font_size=5)\npositive_words=WC.generate(positive_text)\nplt.imshow(positive_words,interpolation='bilinear')\nplt.show","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:52:27.0526Z","iopub.execute_input":"2021-10-07T18:52:27.053465Z","iopub.status.idle":"2021-10-07T18:52:30.414012Z","shell.execute_reply.started":"2021-10-07T18:52:27.053429Z","shell.execute_reply":"2021-10-07T18:52:30.412984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"   # Tạo trình tạo đánh giá ngẫu nhiên\n\n* **Tạo một biến cho bài đánh giá phim được tạo ngẫu nhiên**\n* **in bài đánh giá ngẫu nhiên**","metadata":{}},{"cell_type":"code","source":"index = np.random.randint(x_train_padding.shape[0])\nex = corpus_train[index]\nprint(ex)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:52:30.416007Z","iopub.execute_input":"2021-10-07T18:52:30.416353Z","iopub.status.idle":"2021-10-07T18:52:30.423102Z","shell.execute_reply.started":"2021-10-07T18:52:30.41631Z","shell.execute_reply":"2021-10-07T18:52:30.421895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Ở đây,Tôi muốn dự đoán đánh giá ngẫu nhiên là poitive or negative(tích cực hoặc tiêu cực) bằng cách sử dụng mô hình đã tạo. Vì vậy, bài đánh giá sẽ được xử lý trước tương tự như những gì mà tôi đã làm trong tập dữ liệu trước khi huấn luyện, tức là các từ sẽ được chuyển đổi thành số nguyên và độ dài tối đa là 100. Danh sách trống được tạo ra và sẽ lưu trữ các giá trị. Cuối cùng, tôi tạo một vòng lặp for để lặp qua danh sách. Chúng ta sẽ dự đoán được đánh giá người xem thế nào?***\n\n**QUY ƯỚC:**\n\n* **Dự đoán ngẫu nhiên gần bằng 1 => Đánh giá tích cực(Positive)**\n* **Dự đoán ngẫu nhiên = 0 => Đánh giá tiêu cực(Negative)**","metadata":{}},{"cell_type":"code","source":"ex = tokenizer.texts_to_sequences(ex)\nds = []\nfor e in ex:\n    for i in e:\n        ds.append(i)\nds = [ds]\nex = pad_sequences(ds, padding = 'post', maxlen = maxlength)\nmo_hinh.predict(ex)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T18:52:30.425019Z","iopub.execute_input":"2021-10-07T18:52:30.425582Z","iopub.status.idle":"2021-10-07T18:52:30.507832Z","shell.execute_reply.started":"2021-10-07T18:52:30.425545Z","shell.execute_reply":"2021-10-07T18:52:30.506936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**=> Đánh giá ngẫu nhiên tôi tạo ra cho kết quả 0,99 gần bằng 1, có nghĩa là đó là đánh giá TÍCH CỰC(POSITIVE).**","metadata":{}},{"cell_type":"markdown","source":"# Kết Luận\n* **Cả 5 giải thuật thì giải thuật hiểu quả nhất là Linear SVC với độ chính xác 90.29 %**\n* **Tất cả các giải thuật còn lại điều hoạt động tốt và hiệu quả cũng khá cao**\n* **Việc tối ưu hóa mô hình có thể mang lại kết quả tốt hơn khi sử dụng nhiều dữ liệu hơn.**\n* **Độ chính xác từng mô hình**\n    * **1.  LSVC:**\n        * **Độ chính xác của việc sử dụng TF-IDF fit với mô hình Linear SVC: 90.29%**\n        * Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Linear SVC: 89.77%\n        * Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Linear SVC: 89.46%\n\n    * **2.  MNB:**\n        * Độ chính xác của việc sử dụng TF-IDF fit với mô hình Multinomial Naive Bayes: 86.63%\n        * Độ chính xác của việc sử dụng CountVectorizer (binary = False) fit Multinomial Naive Bayes: 88.75%\n        * Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit Multinomial Naive Bayes: 89.10%\n\n    * **3.  SGDC:**\n        * TF-IDF: Độ chính xác của SGD Classifier: 88.67%\n        * Độ chính xác của SGD Classifier binary = False: 85.84%\n        * Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit SGD Classifier: 85.84%\n\n    * **4.  LR:**\n        * Độ chính xác của việc sử dụng TF-IDF fit với mô hình hồi quy logistic: 88.50%\n        * Độ chính xác của việc sử dụng CountVectorizer fit với mô hình hồi quy logistic: 85.62%\n        * Độ chính xác của việc sử dụng CountVectorizer (binary = True) fit với mô hình hồi quy logistic: 89.65%\n        \n* **Ngoài ra,việc sử dụng phương pháp học sâu thì:**\n        * Độ chính xác khi sử dụng CNN trên tập dữ liệu là 84.71%\n        * Điểm chính xác khi sử dụng mạng nơ-ron học sâu đơn giản là 71.80%%\n        * Độ chính xác khi sử dụng lớp RNN bổ sung thêm LSTM(2 lớp RNN + LSTM) là 83%.\n        * Độ chính xác khi sử dụng 2 lớp RNN với LSTM là 80.89%\n        * Mô hình CNN cho độ chính xác tốt nhất trong số tất cả với 84.71% trên tập dữ liệu train và test.\n        * Sử dụng RNN (LSTM) với hai lớp ẩn cũng là cách tốt nhất mang lại độ chính xác 80.89% trên cả tập dữ liệu đào tạo và kiểm tra.\n     * **Mô hình Mạng Nơ-ron hiệu quả để phân tích cảm xúc trên các đánh giá IMDB**","metadata":{}},{"cell_type":"markdown","source":"# GOOD BYE (^_^) Thanks you very much, Thanks come from BAO BI!\n\n**Class A1, Computer Science, Can Tho University, Vietnam**\n\n**FB:** https://www.facebook.com/baobi1998\n\n**Kaggle:** https://www.kaggle.com/lienchibaob1812254\n\n**github:** https://github.com/lienchibao1998","metadata":{}}]}