{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Project Introduction"},{"metadata":{},"cell_type":"markdown","source":"This Rotten Tomatoes movie review dataset is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee. This competition presents a chance to benchmark your sentiment-analysis ideas on the Rotten Tomatoes dataset. You are asked to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive.<br/>\nThe objective of this project is to bulid a appropriate model that classify sentiment of each phrase. "},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/train.tsv', sep=\"\\t\")\ntest = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/test.tsv', sep=\"\\t\")\nsub = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/sampleSubmission.csv', sep=\",\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Understanding**<br/>\nsentiment id representate different sentiment categories, and the following meaning explain the sentiment id:<br/>\n             The sentiment labels are:<br/>\n                             0 - negative<br/>\n                             1 - somewhat negative<br/>\n                             2 - neutral<br/>\n                             3 - somewhat positive<br/>\n                             4 - positive"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of phrases in train: {}. Number of sentences in train: {}.'.format(train.shape[0], len(train.SentenceId.unique())))\nprint('Number of phrases in test: {}. Number of sentences in test: {}.'.format(test.shape[0], len(test.SentenceId.unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average count of phrases per sentence in train is {0:.0f}.'.format(train.groupby('SentenceId')['Phrase'].count().mean()))\nprint('Average count of phrases per sentence in test is {0:.0f}.'.format(test.groupby('SentenceId')['Phrase'].count().mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Find Overlapped Phrases Between Train and Test Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"overlapped = pd.merge(train[[\"Phrase\", \"Sentiment\"]], test, on=\"Phrase\", how=\"inner\")\nprint(overlapped.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overlapped.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overlap_boolean_mask_test = test['Phrase'].isin(overlapped['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are overlapped phrase texts between training and testing data, which should assign training data labels directly instead of getting from prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check sentiment distribution\nimport seaborn as sns\nsns.countplot(x='Sentiment', data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As can be seen from the bar chart above, there is an imbalance issue in the training dataset, and neutral sentiment data significant more than any other class. Therefore, undersampling should be used to solve this kind of problem.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ramdomly select 40,000 records from neutral sentiment to fit the model\nneutral = len(train[train['Sentiment'] == 2])\nneutral_indices = train[train.Sentiment == 2].index\nrandom_indices = np.random.choice(neutral_indices,40000, replace=True)\nno_neutral_indices = train[train.Sentiment != 2].index\nunder_sample_indices = np.concatenate([no_neutral_indices,random_indices])\ntrain = train.loc[under_sample_indices]\ntrain.reset_index(inplace = True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train['index']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Sentiment', data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"**Thoughts on feature processing and engineering:**<br/>\nSo, we have only phrases as data. And a phrase can contain a single word. And one punctuation mark can cause phrase to receive a different sentiment. Also assigned sentiments can be strange. This means several things:<br/>\n<br/>\napply stopwords removal methods on all data records can be a bad idea, because some phrases contain one single stopword;<br/>\nand also puntuation could be important, so it should be used;<br/>\nusing features like word count or sentence length won't be useful\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import RegexpTokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**Clean Training Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing value check\ntrain = train.replace('',np.NaN)\ntrain = train.replace(' ',np.NaN)\ntrain.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete missing value\ntrain.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add phrase lenghth colunm \n# and the phrase length is for separating long phrase and short Phrase\ntrain['phrase_length'] = train['Phrase'].apply(lambda x: len(x.split()))\n# check value counts\nphrase_length = train.phrase_length.value_counts()\nphrase_length.plot.bar(figsize=(25,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# step 1: Normalization\ntrain['Phrase'] = train['Phrase'].apply(lambda x: x.lower())\n# separate the dataset \ntrain1 = train[train['phrase_length'] >5]\ntrain2 = train[train['phrase_length'] <=5]\n# step 2:  stopwords removal \nstop = stopwords.words('english')\ntrain1['Phrase'] = train1['Phrase'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n# step 3: Tokenization and punctuation removal\ntokenizer = RegexpTokenizer(r'\\w+')\ntrain1['Phrase'] = train1['Phrase'].apply(lambda x: tokenizer.tokenize(x))\ntrain2['Phrase'] = train2['Phrase'].apply(lambda x: word_tokenize(x))\n# train1['Phrase'] = train1['Phrase'].apply(lambda x: remove_punctuations(x))\n# merge data\nframes = [train1, train2]\ntrain = pd.concat(frames)\ntrain.sort_index(inplace=True)\n# step 4: Lemmatization\nwl=WordNetLemmatizer()\ntrain['Phrase'] = train['Phrase'].apply(lambda x: [wl.lemmatize(w,pos = 'v') for w in x])\ntrain['Phrase'] = train['Phrase'].apply(lambda x: [wl.lemmatize(w) for w in x])\n# re-calculate the phrase length\ntrain['phrase_length'] = train['Phrase'].apply(lambda x: len(x))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.phrase_length.max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Clean Testing dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# same data cleaning process on test data set\n# add phrase length column\ntest['phrase_length'] = test['Phrase'].apply(lambda x: len(x.split()))\n# cleaning process:\n# step 1: lowercase\ntest['Phrase'] = test['Phrase'].apply(lambda x: x.lower())\n# separate dataset\ntest1 = test[test['phrase_length'] >5]\ntest2 = test[test['phrase_length'] <=5]\n# step 2: stopwords removal \ntest1['Phrase'] = test1['Phrase'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n# step 3: Tokenization and punctuation removal\ntest1['Phrase'] = test1['Phrase'].apply(lambda x: tokenizer.tokenize(x))\ntest2['Phrase'] = test2['Phrase'].apply(lambda x: word_tokenize(x))\n# merge the test dataset\nframe = [test1, test2]\ntest = pd.concat(frame)\ntest.sort_index(inplace=True)\n# step 4: Lemmatization\ntest['Phrase'] = test['Phrase'].apply(lambda x: [wl.lemmatize(w,pos = 'v') for w in x])\ntest['Phrase'] = test['Phrase'].apply(lambda x: [wl.lemmatize(w) for w in x])\ntest['phrase_length'] = test['Phrase'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.phrase_length.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Model Buliding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['Sentiment']\ny = keras.utils.to_categorical(y,num_classes=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phrase_train, phrase_valid, y_train, y_valid = train_test_split(train['Phrase'], y, test_size=0.2, random_state=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**1D_CNN model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(phrase_train)\ntokenizer.fit_on_texts(phrase_valid)\nx_train = tokenizer.texts_to_sequences(phrase_train)\nx_valid = tokenizer.texts_to_sequences(phrase_valid)\nmax_len = 32\nx_train = pad_sequences(x_train, maxlen = max_len)\nx_valid = pad_sequences(x_valid, maxlen = max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model1 = Sequential()\nfilters = 100\ncnn_model1.add(Embedding(input_dim = 15000, output_dim=1000, input_length = 32))\n# cnn_model1.add(layers.Flatten())\ncnn_model1.add(Dropout(0.1))\ncnn_model1.add(Conv1D(filters, 3, strides=1, padding='valid', activation='relu'))\n\ncnn_model1.add(GlobalMaxPool1D())\ncnn_model1.add(layers.Dense(10, activation='relu'))\ncnn_model1.add(layers.Dense(5, activation='softmax'))\ncnn_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ncnn_model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience = 10, verbose=2)\nhistory1 = cnn_model1.fit(x_train, y_train,\n                         validation_data=(x_valid, y_valid),\n                          epochs=20,\n                         batch_size=1000,\n                         callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=7000)\ntokenizer.fit_on_texts(test.Phrase)\nx_test = tokenizer.texts_to_sequences(test.Phrase)\nmax_len = 32\nx_test = pad_sequences(x_test, maxlen = max_len)\npred1 = cnn_model1.predict_classes(x_test,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.Sentiment = pred1\nsub.to_csv('sub1.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LSTM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model = Sequential()\nlstm_model.add(Embedding(input_dim = 10000, output_dim=1000, input_length = 32))\nlstm_model.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\nlstm_model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\nlstm_model.add(Dense(5, activation='softmax'))\nlstm_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\nlstm_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience = 10, verbose=2)\nhistory2 = lstm_model.fit(x_train, y_train,\n                          validation_data=(x_valid, y_valid),\n                         epochs=20,\n                         batch_size=1000\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tokenizer = Tokenizer(num_words=7000)\n#tokenizer.fit_on_texts(test.Phrase)\n#x_test = tokenizer.texts_to_sequences(test.Phrase)\n#max_len = 32\n#x_test = pad_sequences(x_test, maxlen = max_len)\npred2 = lstm_model.predict_classes(x_test,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.Sentiment = pred2\nsub.to_csv('sub2.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CNN+GRU**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model3= Sequential()\nmodel3.add(Embedding(10000,1000,input_length = 32))\nmodel3.add(Conv1D(64,kernel_size=3,padding='same',activation='relu'))\nmodel3.add(MaxPooling1D(pool_size=2))\nmodel3.add(Dropout(0.25))\nmodel3.add(GRU(128,return_sequences=True))\nmodel3.add(Dropout(0.3))\nmodel3.add(Flatten())\nmodel3.add(Dense(128,activation='relu'))\nmodel3.add(Dropout(0.5))\nmodel3.add(Dense(5,activation='softmax'))\nmodel3.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\nmodel3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nearly_stopping = EarlyStopping(monitor='val_loss', patience = 10, verbose=2)\nhistory3 = model3.fit(x_train, y_train, validation_data=(x_valid, y_valid),epochs = 15, batch_size = 1000, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred3 = model3.predict_classes(x_test,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.Sentiment = pred3\nsub.to_csv('sub3.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NB**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import model_selection, naive_bayes, svm\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Phrase'] = train['Phrase'].apply(lambda x: ' '.join(x))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Phrase'] = test['Phrase'].apply(lambda x: ' '.join(x))\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tfidf_vect = TfidfVectorizer(max_features=10000)\nx_train_tf = Tfidf_vect.fit_transform(train.Phrase)\nx_test_tf = Tfidf_vect.transform(test.Phrase)\ny_train_tf = train['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(Tfidf_vect.vocabulary_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(x_train_tf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the training dataset on the NB classifier\nNaive = naive_bayes.MultinomialNB()\nNaive.fit(x_train_tf,y_train_tf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the labels on train dataset\npredictions_NB = Naive.predict(x_train_tf)\n# Use accuracy_score function to get the accuracy\nprint(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, y_train_tf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred4 = Naive.predict(x_test_tf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.Sentiment = pred4\nsub.to_csv('sub4.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_all=pd.DataFrame({'model1':pred1,'model2':pred2,'model3':pred3,'model4':pred4})\npred_mode=sub_all.agg('mode',axis=1)[0].values\nsub_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalpred=(pred1+pred2+pred3+pred4)//4\nsub.Sentiment = finalpred\nsub.to_csv('sub_all.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overlapped.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overlapped.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lapped_id = overlapped.PhraseId","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_al = sub[~sub['PhraseId'].isin(lapped_id)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_al.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overlap_records = overlapped[['PhraseId','Sentiment']]\noverlap_records.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overlap_records.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_final= pd.concat([sub_al,overlap_records])\nsub_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_final['PhraseId'].duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_final.reset_index(inplace=True)\ntype(sub_final.PhraseId[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub_final.reindex(sub_final['PhraseId'].abs().sort_values(ascending=True).index)\nsub.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub[['PhraseId','Sentiment']]\nsub.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.reset_index(inplace=True)\nsub.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub[['PhraseId','Sentiment']]\nsub.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission1.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}