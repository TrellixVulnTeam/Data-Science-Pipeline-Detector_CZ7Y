{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>End-to-End NLP Process with Sentiment Analysis</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this notebook we are going to go through on how to perform text classification using logistic regression and several text encoding techniques such as bag of words and tf-idf. Our task will be to classify text to determine it's sentiment class. Our dataset contains the movie review data with labeled sentiment class of 0,1,2,3 and 4 where 0 is negative, 1 somehow negative, 2 neutral, 3 somehow positive and 4 positive.<br><br>\nWe will start with Exploratory Data Analysis then perform machine learning modeling.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div align='center'><h1>Import required libraries</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\nfrom nltk import ngrams\nimport string,re\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nimport warnings, os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,7))\nplt.style.use('ggplot')\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Locate the data directories\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/movie-review-sentiment-analysis-kernels-only/train.tsv.zip',sep='\\t')\ntest=pd.read_csv('/kaggle/input/movie-review-sentiment-analysis-kernels-only/test.tsv.zip',sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align='center'><H1>Part 1 Exploratory Data Analysis</H1></div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sentiment Description","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sentiment_class'] = train['Sentiment'].map({0:'negative',1:'somewhat negative',2:'neutral',3:'somewhat positive',4:'positive'})\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove punctuations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punctuation(text):\n    return \"\".join([t for t in text if t not in string.punctuation])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Phrase']=train['Phrase'].apply(lambda x:remove_punctuation(x))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove words with less than 2 characters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def words_with_more_than_three_chars(text):\n    return \" \".join([t for t in text.split() if len(t)>3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Phrase']=train['Phrase'].apply(lambda x:words_with_more_than_three_chars(x))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove stopwords","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words=stopwords.words('english')\ntrain['Phrase']=train['Phrase'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check sentiment categories","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Sentiment')['Sentiment'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the target variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('sentiment_class')['sentiment_class'].count().plot(kind='bar',title='Target class',figsize=(16,7),grid=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get percentages of each class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"((train.groupby('sentiment_class')['sentiment_class'].count()/train.shape[0])*100).plot(kind='pie',figsize=(7,7),title='% Target class', autopct='%1.0f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding Phrase length","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['PhraseLength']=train['Phrase'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sort_values(by='PhraseLength', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of phrase length on each class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,7))\nbins=np.linspace(0,200,50)\nplt.hist(train[train['sentiment_class']=='negative']['PhraseLength'],bins=bins,density=True,label='negative')\nplt.hist(train[train['sentiment_class']=='somewhat negative']['PhraseLength'],bins=bins,density=True,label='somewhat negative')\nplt.hist(train[train['sentiment_class']=='neutral']['PhraseLength'],bins=bins,density=True,label='neutral')\nplt.hist(train[train['sentiment_class']=='somewhat positive']['PhraseLength'],bins=bins,density=True,label='somewhat positive')\nplt.hist(train[train['sentiment_class']=='positive']['PhraseLength'],bins=bins,density=True,label='positive')\nplt.xlabel('Phrase length')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Common words with word cloud","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Install wordcoud library\n# !pip install wordcloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS \nstopwords = set(STOPWORDS) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_cloud_common_words=[]  \nfor index, row in train.iterrows(): \n    word_cloud_common_words.append((row['Phrase'])) \nword_cloud_common_words\n\nwordcloud = WordCloud(width = 1600, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 5).generate(''.join(word_cloud_common_words)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (16, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word Frequency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text_list=[]  \nfor index, row in train.iterrows(): \n    text_list.append((row['Phrase'])) \ntext_list\n\ntotal_words=''.join(text_list)\ntotal_words=word_tokenize(total_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_words=FreqDist(total_words)\nword_frequency=FreqDist(freq_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10 common words\nprint(word_frequency.most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize \npd.DataFrame(word_frequency,index=[0]).T.sort_values(by=[0],ascending=False).head(20).plot(kind='bar',figsize=(16,6),grid=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Common words used for negative sentiment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_text_list=[]  \nfor index, row in train[train['Sentiment']==0].iterrows(): \n    neg_text_list.append((row['Phrase'])) \nneg_text_list\n\nneg_total_words=' '.join(neg_text_list)\nneg_total_words=word_tokenize(neg_total_words)\n\nneg_freq_words=FreqDist(neg_total_words)\nneg_word_frequency=FreqDist(neg_freq_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize \npd.DataFrame(neg_word_frequency,index=[0]).T.sort_values(by=[0],ascending=False).head(20).plot(kind='bar',figsize=(16,6),grid=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Common words used for positive sentiment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_text_list=[]  \nfor index, row in train[train['Sentiment']==4].iterrows(): \n    pos_text_list.append((row['Phrase'])) \npos_text_list\n\npos_total_words=' '.join(pos_text_list)\npos_total_words=word_tokenize(pos_total_words)\n\npos_freq_words=FreqDist(pos_total_words)\npos_word_frequency=FreqDist(pos_freq_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize \npd.DataFrame(pos_word_frequency,index=[0]).T.sort_values(by=[0],ascending=False).head(20).plot(kind='bar',figsize=(16,6),grid=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Common bigram words used for positive sentiment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text=\"Tom and Jerry love mickey. But mickey dont love Tom and Jerry. What a love mickey is getting from these two friends\"\nbigram_frequency = FreqDist(ngrams(word_tokenize(text),3))\nbigram_frequency.most_common()[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_list=[]  \nfor index, row in train.iterrows(): \n    text_list.append((row['Phrase'])) \ntext_list\n\ntotal_words=' '.join(text_list)\ntotal_words=word_tokenize(total_words)\n\nfreq_words=FreqDist(total_words)\nword_frequency=FreqDist(ngrams(freq_words,2))\nword_frequency.most_common()[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize \npd.DataFrame(word_frequency,index=[0]).T.sort_values(by=[0],ascending=False).head(20).plot(kind='bar',figsize=(16,6),grid=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align='center'><H1>Part 2 Machine Learning Modeling</H1></div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Prepare Training data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Create Bag of words with CountVectorizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['tokenized_words']=train['Phrase'].apply(lambda x:word_tokenize(x))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer=CountVectorizer()\nphrase_dtm=count_vectorizer.fit_transform(train['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phrase_dtm.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split data into training and validation sets (70:30) ratio","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val=train_test_split(phrase_dtm,train['Sentiment'],test_size=0.3, random_state=38)\nX_train.shape,y_train.shape,X_val.shape,y_val.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train Logistic Regression model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Measure model performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(model.predict(X_val),y_val)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Free up memory for tf-idf","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train\ndel X_val\ndel y_train\ndel y_val","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing data with tf-idf","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf=TfidfVectorizer()\ntfidf_dtm=tfidf.fit_transform(train['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val=train_test_split(tfidf_dtm,train['Sentiment'],test_size=0.3, random_state=38)\nX_train.shape,y_train.shape,X_val.shape,y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_model=LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(tfidf_model.predict(X_val),y_val)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict on test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tfidf_model.predict(X_val)[0:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"new data prediction function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_new_text(text):\n    tfidf_text=tfidf.transform([text])\n    return tfidf_model.predict(tfidf_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_new_text(\"The movie is bad and sucks!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare Test Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Phrase']=test['Phrase'].apply(lambda x:remove_punctuation(x))\ntest['Phrase']=test['Phrase'].apply(lambda x:words_with_more_than_three_chars(x))\ntest['Phrase']=test['Phrase'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\ntest_dtm=tfidf.transform(test['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Predict with test data\ntest['Sentiment']=tfidf_model.predict(test_dtm)\ntest.set_index=test['PhraseId']\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save results to csv file\n# test.to_csv('Submission.csv',columns=['PhraseId','Sentiment'],index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}