{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport torch\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-22T06:02:03.048129Z","iopub.execute_input":"2021-07-22T06:02:03.048725Z","iopub.status.idle":"2021-07-22T06:02:03.058987Z","shell.execute_reply.started":"2021-07-22T06:02:03.048663Z","shell.execute_reply":"2021-07-22T06:02:03.057891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n#device=xm.xla_device()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:03.061109Z","iopub.execute_input":"2021-07-22T06:02:03.061967Z","iopub.status.idle":"2021-07-22T06:02:03.072221Z","shell.execute_reply.started":"2021-07-22T06:02:03.061925Z","shell.execute_reply":"2021-07-22T06:02:03.071029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:03.074399Z","iopub.execute_input":"2021-07-22T06:02:03.074935Z","iopub.status.idle":"2021-07-22T06:02:03.085601Z","shell.execute_reply.started":"2021-07-22T06:02:03.074895Z","shell.execute_reply":"2021-07-22T06:02:03.084613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nz=zipfile.ZipFile('/kaggle/input/movie-review-sentiment-analysis-kernels-only/train.tsv.zip')\ntrain = pd.read_csv(z.open('train.tsv'),delimiter='\\t',usecols = ['Phrase','Sentiment'])\nz=zipfile.ZipFile('/kaggle/input/movie-review-sentiment-analysis-kernels-only/test.tsv.zip')\ntest = pd.read_csv(z.open('test.tsv'),delimiter='\\t',usecols = ['PhraseId','Phrase'])\nsns.countplot(train[\"Sentiment\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:03.087443Z","iopub.execute_input":"2021-07-22T06:02:03.088059Z","iopub.status.idle":"2021-07-22T06:02:03.497016Z","shell.execute_reply.started":"2021-07-22T06:02:03.088014Z","shell.execute_reply":"2021-07-22T06:02:03.496105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import BertForSequenceClassification, BertTokenizer, BertConfig,BertModel\nprint('transformers version :', transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:03.498496Z","iopub.execute_input":"2021-07-22T06:02:03.498941Z","iopub.status.idle":"2021-07-22T06:02:03.505362Z","shell.execute_reply.started":"2021-07-22T06:02:03.498899Z","shell.execute_reply":"2021-07-22T06:02:03.504158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nfrom transformers import BertForSequenceClassification, AdamW, BertConfig\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = 5,output_attentions = False, output_hidden_states = False)\nprint(model)\nconfig = BertConfig.from_pretrained('bert-base-uncased')\nprint(config)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:03.50692Z","iopub.execute_input":"2021-07-22T06:02:03.507326Z","iopub.status.idle":"2021-07-22T06:02:10.193302Z","shell.execute_reply.started":"2021-07-22T06:02:03.507285Z","shell.execute_reply":"2021-07-22T06:02:10.19243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = train.Phrase.values\nlabels = train.Sentiment.values","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:10.196466Z","iopub.execute_input":"2021-07-22T06:02:10.196724Z","iopub.status.idle":"2021-07-22T06:02:10.206118Z","shell.execute_reply.started":"2021-07-22T06:02:10.196698Z","shell.execute_reply":"2021-07-22T06:02:10.205027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsentences = test.Phrase.values","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:10.209973Z","iopub.execute_input":"2021-07-22T06:02:10.210884Z","iopub.status.idle":"2021-07-22T06:02:10.21986Z","shell.execute_reply.started":"2021-07-22T06:02:10.210809Z","shell.execute_reply":"2021-07-22T06:02:10.218901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tPhraseId = test.PhraseId.values","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:10.222432Z","iopub.execute_input":"2021-07-22T06:02:10.222932Z","iopub.status.idle":"2021-07-22T06:02:10.230073Z","shell.execute_reply.started":"2021-07-22T06:02:10.222887Z","shell.execute_reply":"2021-07-22T06:02:10.229097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tPhraseId[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:10.231583Z","iopub.execute_input":"2021-07-22T06:02:10.232064Z","iopub.status.idle":"2021-07-22T06:02:10.242225Z","shell.execute_reply.started":"2021-07-22T06:02:10.232025Z","shell.execute_reply":"2021-07-22T06:02:10.241188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsentences[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:10.243632Z","iopub.execute_input":"2021-07-22T06:02:10.244225Z","iopub.status.idle":"2021-07-22T06:02:10.25229Z","shell.execute_reply.started":"2021-07-22T06:02:10.244187Z","shell.execute_reply":"2021-07-22T06:02:10.251346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = []\nfor sent in sentences:\n    token_words = tokenizer.tokenize(sent)\n    max_len.append(len(token_words))\nprint(max(max_len))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T06:02:10.253598Z","iopub.execute_input":"2021-07-22T06:02:10.254039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = []\nattention_masks = []\n\nfor sent in sentences:\n    encoded_dict = tokenizer.encode_plus(\n                        sent,\n                        truncation=True,\n                        add_special_tokens = True,\n                        max_length = 80,\n                        padding='max_length',\n                        pad_to_max_length = True,\n                        return_attention_mask = True,   \n                        return_tensors = 'pt',     \n                   )\n\n    # 単語ID変換    \n    input_ids.append(encoded_dict['input_ids'])\n    # Attentionmask\n    attention_masks.append(encoded_dict['attention_mask'])\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\n# tenosor変換\nlabels = torch.tensor(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testinput_ids = []\ntestattention_masks = []\n\nfor sent in tsentences:\n    encoded_dict = tokenizer.encode_plus(\n                        sent,\n                        truncation=True,\n                        add_special_tokens = True,\n                        max_length = 80,\n                        padding='max_length',\n                        pad_to_max_length = True,\n                        return_attention_mask = True,   \n                        return_tensors = 'pt',     \n                   )\n  \n    testinput_ids.append(encoded_dict['input_ids'])\n    testattention_masks.append(encoded_dict['attention_mask'])\ntestinput_ids = torch.cat(testinput_ids, dim=0)\ntestattention_masks = torch.cat(testattention_masks, dim=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, random_split\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\n# データセット\ndataset = TensorDataset(input_ids, attention_masks, labels)\ntestdataset = TensorDataset(testinput_ids, testattention_masks)\n\ntrain_size = int(len(dataset))\nval_size = int(len(testdataset))\n\nprint('トレーニングデータ：{}'.format(train_size))\nprint('テストデータ:　{} '.format(val_size))\n\n# データローダー\nbatch_size = 32\ntrain_dataloader = DataLoader(dataset,sampler = RandomSampler(dataset),batch_size = batch_size)\nvalidation_dataloader = DataLoader(testdataset,sampler = SequentialSampler(testdataset),batch_size = batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model):\n    model.train() \n    train_loss = 0\n    k=0\n    #print(k)\n    for batch in train_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        optimizer.zero_grad()\n        #loss, logits \n        a = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)\n        loss=a[0]\n        logit=a[1]\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        train_loss += loss.item()\n        k=k+1\n        ##if k % 100==0:\n            ##print(k)\n    return train_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_epoch = 2\ntrain_loss_ = []\ntest_loss_ = []\n\nfor epoch in range(max_epoch):\n    train_ = train(model)\n    test_ = train(model)\n    train_loss_.append(train_)\n    test_loss_.append(test_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=[]\nfor batch in validation_dataloader:\n    b_input_ids = batch[0].to(device)\n    b_input_mask = batch[1].to(device)\n    with torch.no_grad():      \n        pred=model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask)\n        preds.append(pred[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yos=[]\nyola=[]\nfor h in preds:\n    for hh in h:\n        #print(hh)\n        y=hh.to('cpu').detach().numpy().copy()\n        yos.append(y)\n        yola.append(np.argmax(y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yola[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_df = pd.DataFrame(tPhraseId, columns=['PhraseId'])\npred_df = pd.DataFrame(yola, columns=['Sentiment'])\nSubmission_df = pd.concat([id_df, pred_df], axis=1)\nSubmission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}