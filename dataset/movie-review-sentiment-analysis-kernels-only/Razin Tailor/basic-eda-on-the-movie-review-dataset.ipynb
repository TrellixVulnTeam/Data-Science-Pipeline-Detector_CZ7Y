{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA Movie Review Dataset Rotten Tomatoes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))\n\nimport os\nimport sys\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_colwidth', 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/movie-dataset-rotten-tomatoes/train.tsv', sep='\\t')\ntest_df = pd.read_csv('../input/movie-dataset-rotten-tomatoes/test.tsv', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### No Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df.SentenceId.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df.Phrase.unique()), len(train_df.PhraseId.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Sentiment.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"```\nThe sentiment labels are:\n\n0 - negative\n1 - somewhat negative\n2 - neutral\n3 - somewhat positive\n4 - positive\n```"},{"metadata":{},"cell_type":"markdown","source":"## Let's check the sentiment distribution in the train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"def id_to_label(id):\n    id_to_label_dict = {\n        0: 'negative',\n        1: 'somewhat negative',\n        2: 'neutral',\n        3: 'somewhat positive',\n        4: 'positive'\n    }\n    return id_to_label_dict[id]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['sentiment_label'] = list(map(id_to_label, train_df['Sentiment']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_distribution_counts = train_df.groupby('sentiment_label')['sentiment_label'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,9))\nsns.countplot(train_df['sentiment_label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = train_df.drop_duplicates(subset=['SentenceId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,9))\nplt.title('Review Sentiments on Unique Sentences')\nsns.countplot(temp_df['sentiment_label'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's remove punctuation marks as well\n### There are multiple ways to do it \n### I am using RegexpTokenizer from nltk\n### (Refer) https://www.kite.com/python/answers/how-to-remove-all-punctuation-marks-with-nltk-in-python"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\ndef remove_punctuation(phrase):\n    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n    new_words = tokenizer.tokenize(phrase)\n    return ' '.join(new_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['clean_phrase'] = list(map(remove_punctuation, train_df['Phrase']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There are words like `a, am, and, any... ` etc, such words don't carry any significant importance as such \n### Such words are called `Stop Words` and generally they are omitted from the analysis\n\n### Let's find and remove such stop words from our dataset\n\n```\nIf you have not downloaded already, use this\n\nimport nltk\nnltk.download('stopwords')\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nenglish_stops = set(stopwords.words('english'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(english_stops))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### nltk provides us with 179 unique stopwords, we will use this set to filter our `CleanPhrase`"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stop_words(phrase):\n    tokenized = phrase.split(' ')\n    filtered = list()\n    for word in tokenized:\n        if word.lower() not in english_stops:\n            filtered.append(word)\n    return ' '.join(filtered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['phrase_without_stopwords'] = list(map(remove_stop_words, train_df['clean_phrase']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding Phrase Length as another feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['phrase_length'] = train_df['phrase_without_stopwords'].apply(lambda x: len(x.split(' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's analyze 1 word phrases"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_word_review = train_df[train_df.phrase_length == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_word_review.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some data cleaning (Removing rows with only whitespace in `phrase_without_stopwords`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_value = float(\"NaN\")\ntrain_df.replace(\"\", nan_value, inplace=True)\ntrain_df.replace(\" \", nan_value, inplace=True)\ntrain_df.dropna(subset = [\"phrase_without_stopwords\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_word_review = train_df[train_df.phrase_length == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_word_review.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### At this point we can visualize some most common words using the wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_wordcloud(data, stopwords, title = None):\n    \"\"\"\n    Overridden the function from `https://www.kaggle.com/parth05rohilla/sentiment-analysis-using-7-different-techniques`\n    \"\"\"\n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=200,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n    ).generate(str(data))\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df['phrase_without_stopwords'], english_stops, 'Most Common Words from the whole corpus')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df[train_df['Sentiment'] == 0]['phrase_without_stopwords'], english_stops, 'Negative Reviews')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df[train_df['Sentiment'] == 1]['phrase_without_stopwords'], english_stops, 'Somewhat Negative Reviews')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df[train_df['Sentiment'] == 2]['phrase_without_stopwords'], english_stops, 'Neutral Reviews')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df[train_df['Sentiment'] == 3]['phrase_without_stopwords'], english_stops, 'Somewhat Positive Reviews')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df[train_df['Sentiment'] == 4]['phrase_without_stopwords'], english_stops, 'Positive Reviews')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some more look into one_word_review (Phrases)"},{"metadata":{},"cell_type":"markdown","source":"### let's see which words are mostly used for all emotions"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_by_sentiment = one_word_review.groupby('sentiment_label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nsentiment_word_count_dict = dict()\n\nfor sentiment, data in grouped_by_sentiment:\n    sentiment_word_count_dict[sentiment] = dict()\n    for d in data.values:\n        if d[-2] not in sentiment_word_count_dict[sentiment].keys():\n            sentiment_word_count_dict[sentiment][d[-2]] = 1\n        else:\n            sentiment_word_count_dict[sentiment][d[-2]] +=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['sentiment_label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_sentiment_dict = sentiment_word_count_dict['negative']\nsomewhat_negative_sentiment_dict = sentiment_word_count_dict['somewhat negative']\nneutral_sentiment_dict = sentiment_word_count_dict['neutral']\nsomewhat_positive_sentiment_dict = sentiment_word_count_dict['somewhat positive']\npositive_sentiment_dict = sentiment_word_count_dict['positive']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import operator\nsorted_negative_sentiment_words = sorted(negative_sentiment_dict.items(), key=operator.itemgetter(1), reverse=True)[:10]\nsorted_somewhat_negative_sentiment_words = sorted(somewhat_negative_sentiment_dict.items(), key=operator.itemgetter(1), reverse=True)[:10]\nsorted_neutral_sentiment_words = sorted(neutral_sentiment_dict.items(), key=operator.itemgetter(1), reverse=True)[:10]\nsorted_somewhat_positive_sentiment_words = sorted(somewhat_positive_sentiment_dict.items(), key=operator.itemgetter(1), reverse=True)[:10]\nsorted_positive_sentiment_words = sorted(positive_sentiment_dict.items(), key=operator.itemgetter(1), reverse=True)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting Top 10 negative sentiment words"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,9))\nplt.xticks(rotation=90)\nplt.title(\"Top 10 one word Negative Reviews\")\nsns.barplot(x=[i[0] for i in sorted_negative_sentiment_words], y=[i[1] for i in sorted_negative_sentiment_words], )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,9))\nplt.xticks(rotation=90)\nplt.title(\"Top 10 one word Somewhat Negative Reviews\")\nsns.barplot(x=[i[0] for i in sorted_somewhat_negative_sentiment_words], y=[i[1] for i in sorted_somewhat_negative_sentiment_words], )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,9))\nplt.xticks(rotation=90)\nplt.title(\"Top 10 one word Neutral Reviews\")\nsns.barplot(x=[i[0] for i in sorted_neutral_sentiment_words], y=[i[1] for i in sorted_neutral_sentiment_words], )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,9))\nplt.xticks(rotation=90)\nplt.title(\"Top 10 one word Somewhat Positive Reviews\")\nsns.barplot(x=[i[0] for i in sorted_somewhat_positive_sentiment_words], y=[i[1] for i in sorted_somewhat_positive_sentiment_words], )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,9))\nplt.xticks(rotation=90)\nplt.title(\"Top 10 one word Positive Reviews\")\nsns.barplot(x=[i[0] for i in sorted_positive_sentiment_words], y=[i[1] for i in sorted_positive_sentiment_words], )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Similarly we can analyze the data even more to understand it even further"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}