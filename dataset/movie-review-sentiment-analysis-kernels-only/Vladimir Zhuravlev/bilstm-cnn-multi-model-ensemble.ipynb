{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# To get reproducible results\nnp.random.seed(0)\ntf.set_random_seed(0)\n\nprint(os.listdir(\"../input\"))","execution_count":1,"outputs":[{"output_type":"stream","text":"['movie-review-sentiment-analysis-kernels-only', 'fasttext-crawl-300d-2m']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"test_file = '../input/movie-review-sentiment-analysis-kernels-only/test.tsv'\ntest = pd.read_csv(test_file, delimiter='\\t').fillna('')\nx_test = test.values[:, 2]\n\ntrain_file = '../input/movie-review-sentiment-analysis-kernels-only/train.tsv'\ntrain = pd.read_csv(train_file, delimiter='\\t').fillna('')\nx_train = train.values[:, 2]\ny_train = train.values[:, 3]\n\nprint('x_test count: {}'.format(len(x_test)))\nprint('x_train count: {}'.format(len(x_train)))\nprint('y_train count: {}'.format(len(y_train)))","execution_count":2,"outputs":[{"output_type":"stream","text":"x_test count: 66292\nx_train count: 156060\ny_train count: 156060\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import text, sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\n\nmax_length = 60\nmax_features = 20000\n\nx_all = []\nx_all.extend(x_test)\nx_all.extend(x_train)\n\ntk = Tokenizer(num_words=max_features, lower=True, filters='\\n\\t')\ntk.fit_on_texts(x_all)\nx_train_seq = tk.texts_to_sequences(x_train)\nx_test_seq = tk.texts_to_sequences(x_test)\n\nnp_x_train = pad_sequences(x_train_seq, maxlen=max_length,  padding='post')\nnp_x_test = pad_sequences(x_test_seq, maxlen=max_length,  padding='post')\nnp_y_train = to_categorical(y_train)\n\nprint ('np_x_train shape: {}'.format(np_x_train.shape))\nprint ('np_x_test shape: {}'.format(np_x_test.shape))\nprint ('np_y_train shape: {}'.format(np_y_train.shape))","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"np_x_train shape: (156060, 60)\nnp_x_test shape: (66292, 60)\nnp_y_train shape: (156060, 5)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tqdm\n\nword_dict = tk.word_index\nembedding_dim = 300\nembeddings_index = {}\n\nwith open('../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec', 'r') as f:\n    lines = f.readlines()\n\nfor i in tqdm.tqdm(range(len(lines))):\n    values = lines[i].rstrip().rsplit(' ')\n    word = values[0]\n    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n\nmax_features = min(max_features, len(word_dict) + 1)\nembedding_matrix = np.zeros((max_features, embedding_dim))\n\nfor word, i in word_dict.items():\n    if i >= max_features:\n        break\n\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\nprint('Embedding matrix: {}'.format(embedding_matrix.shape))","execution_count":4,"outputs":[{"output_type":"stream","text":"100%|██████████| 2000001/2000001 [02:05<00:00, 15903.73it/s]\n","name":"stderr"},{"output_type":"stream","text":"Embedding matrix: (19479, 300)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import *\nfrom keras.callbacks import EarlyStopping\n\ndef one_input_classifier(index, classifier_type, input_length, max_features, class_num, embedding_dim, embedding_matrix):\n    inputs = Input(shape=(input_length,), name='input_1')\n    embeddings = Embedding(max_features, embedding_dim,\n                           weights=[embedding_matrix], input_length=input_length,\n                           trainable=False, name='embedding_1')(inputs)\n    x = SpatialDropout1D(0.3, name='spatial_dropout1d_1')(embeddings)\n\n    if classifier_type == 'bilstm_cnn':\n        x = Bidirectional(CuDNNLSTM(128, name='lstm_1', return_sequences=True), name='bidirectional_1')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Conv1D(128, 5, activation='relu', name='conv1d_1')(x)\n        x = Conv1D(128, 3, activation='relu', name='conv1d_2')(x)\n        x = Conv1D(128, 1, activation='relu', name='conv1d_3')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n        x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_3')(x)\n\n    elif classifier_type == 'bilstm_cnn_x2':\n        x = Bidirectional(CuDNNLSTM(64, name='lstm_1', return_sequences=True), name='bidirectional_1')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Conv1D(64, 5, activation='relu', name='conv1d_1')(x)\n        x = Conv1D(64, 4, activation='relu', name='conv1d_2')(x)\n        x = Conv1D(64, 3, activation='relu', name='conv1d_3')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n        x = Bidirectional(CuDNNLSTM(128, name='lstm_2', return_sequences=True), name='bidirectional_2')(x)\n        x = Dropout(0.25, name='dropout_3')(x)\n        x = Conv1D(128, 3, activation='relu', name='conv1d_4')(x)\n        x = Conv1D(128, 2, activation='relu', name='conv1d_5')(x)\n        x = Conv1D(128, 1, activation='relu', name='conv1d_6')(x)\n        x = Dropout(0.25, name='dropout_4')(x)\n\n        x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_5')(x)\n\n    elif classifier_type == 'lstm_cnn':\n        x = CuDNNLSTM(128, name='lstm_1', return_sequences=True)(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Conv1D(128, 5, activation='relu', name='conv1d_1')(x)\n        x = Conv1D(128, 3, activation='relu', name='conv1d_2')(x)\n        x = Conv1D(128, 1, activation='relu', name='conv1d_3')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n        x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_3')(x)\n\n    elif classifier_type == 'cnn_bilstm':\n        x = Conv1D(128, 5, activation='relu', name='conv1d_1')(x)\n        x = Conv1D(128, 3, activation='relu', name='conv1d_2')(x)\n        x = Conv1D(128, 1, activation='relu', name='conv1d_3')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Bidirectional(CuDNNLSTM(128, name='lstm_1', return_sequences=True), name='bidirectional_1')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n        x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_3')(x)\n\n    elif classifier_type == 'cnn_bilstm_x2':\n        x = Conv1D(64, 5, activation='relu', name='conv1d_1')(x)\n        x = Conv1D(64, 4, activation='relu', name='conv1d_2')(x)\n        x = Conv1D(64, 3, activation='relu', name='conv1d_3')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Bidirectional(CuDNNLSTM(64, name='lstm_1', return_sequences=True), name='bidirectional_1')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n        x = Conv1D(128, 3, activation='relu', name='conv1d_4')(x)\n        x = Conv1D(128, 2, activation='relu', name='conv1d_5')(x)\n        x = Conv1D(128, 1, activation='relu', name='conv1d_6')(x)\n        x = Dropout(0.25, name='dropout_3')(x)\n        x = Bidirectional(CuDNNLSTM(128, name='lstm_2', return_sequences=True), name='bidirectional_2')(x)\n        x = Dropout(0.25, name='dropout_4')(x)\n\n        x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_5')(x)\n\n    elif classifier_type == 'cnn_lstm':\n        x = Conv1D(128, 5, activation='relu', name='conv1d_1')(x)\n        x = Conv1D(128, 3, activation='relu', name='conv1d_2')(x)\n        x = Conv1D(128, 1, activation='relu', name='conv1d_3')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = CuDNNLSTM(128, name='lstm_1', return_sequences=True)(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n        x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_3')(x)\n\n    elif classifier_type == 'bilstm_only':\n        x = Bidirectional(CuDNNLSTM(128, name='lstm_1'), name='bidirectional_1')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n    elif classifier_type == 'lstm_only':\n        x = CuDNNLSTM(128, name='lstm_1')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n    elif classifier_type == 'cnn_only':\n        x = Conv1D(128, 5, activation='relu', name='conv1d_1')(x)\n        x = Conv1D(128, 3, activation='relu', name='conv1d_2')(x)\n        x = Conv1D(128, 1, activation='relu', name='conv1d_3')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n\n        x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n        x = Dense(32, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n\n    elif classifier_type == 'dense_only':\n        x = Flatten(name='flatten_1')(x)\n        x = Dense(1024, activation='relu', name='dense_1')(x)\n        x = Dropout(0.25, name='dropout_1')(x)\n        x = Dense(128, activation='relu', name='dense_2')(x)\n        x = Dropout(0.25, name='dropout_2')(x)\n        x = Dense(32, activation='relu', name='dense_3')(x)\n        x = Dropout(0.25, name='dropout_3')(x)\n\n    preds = Dense(class_num, activation='softmax', name='preds')(x)\n    model = Model(inputs=inputs, outputs=preds, name='model_{}'.format(index))\n    model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1,\n                               mode='min', baseline=None, restore_best_weights=True)\n\nclass_num = np_y_train.shape[1]\nepochs = 32\nbatch_size = 1024\nvalidation_split = 0.2\nclassifier_num = 10\n\nprint('Classes: {}'.format(class_num))\nprint('Epochs: {}'.format(epochs))\nprint('Batch size: {}'.format(batch_size))\nprint('Validation split: {:.1}'.format(validation_split))\nprint('Classifiers: {}'.format(classifier_num))","execution_count":6,"outputs":[{"output_type":"stream","text":"Classes: 5\nEpochs: 32\nBatch size: 1024\nValidation split: 0.2\nClassifiers: 10\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = []\nclassifier_types = ['bilstm_cnn', 'bilstm_cnn_x2', 'lstm_cnn', 'cnn_bilstm', 'cnn_bilstm_x2', 'cnn_lstm', 'bilstm_only', 'lstm_only', 'cnn_only', 'dense_only']\n\nfor i in tqdm.tqdm(range(len(classifier_types))):\n    classifiers.append(one_input_classifier(i, classifier_types[i], max_length, max_features,\n                                            class_num, embedding_dim, embedding_matrix))\n\nfor i in range(classifier_num):\n    classifiers[i].summary()\n    hist = classifiers[i].fit(np_x_train, np_y_train, validation_split=validation_split,\n                              callbacks=[early_stopping], epochs=epochs, batch_size=batch_size, verbose=1)\n    classifiers[i].trainable = False\n\n    print('{}'.format(classifier_types[i]))\n    print('min loss ({}): {:.4}'.format(i, min(hist.history['loss'])))\n    print('min val_loss ({}): {:.4}'.format(i, min(hist.history['val_loss'])))\n    print('max acc ({}): {:.4}'.format(i, max(hist.history['acc'])))\n    print('max val_acc ({}): {:.4}'.format(i, max(hist.history['val_acc'])))\n\ny_pred_list = []\n\nfor i in range(classifier_num):\n    y_pred = classifiers[i].predict(np_x_test, batch_size=1024, verbose=1)\n    y_pred_list.append(y_pred)","execution_count":7,"outputs":[{"output_type":"stream","text":"\r  0%|          | 0/10 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:38: UserWarning: [Errno 12] Cannot allocate memory.  joblib will operate in serial mode\n  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n100%|██████████| 10/10 [00:12<00:00,  1.06s/it]","name":"stderr"},{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 60, 256)           440320    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 60, 256)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 56, 128)           163968    \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 54, 128)           49280     \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 54, 128)           16512     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 54, 128)           0         \n_________________________________________________________________\nglobal_maxpool1d_1 (GlobalMa (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                4128      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,518,073\nTrainable params: 674,373\nNon-trainable params: 5,843,700\n_________________________________________________________________\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 13s 104us/step - loss: 1.0677 - acc: 0.5717 - val_loss: 0.9488 - val_acc: 0.6106\nEpoch 2/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.9267 - acc: 0.6203 - val_loss: 0.9241 - val_acc: 0.6235\nEpoch 3/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.8823 - acc: 0.6357 - val_loss: 0.8966 - val_acc: 0.6300\nEpoch 4/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.8525 - acc: 0.6472 - val_loss: 0.8990 - val_acc: 0.6331\nEpoch 5/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.8247 - acc: 0.6605 - val_loss: 0.8920 - val_acc: 0.6333\nEpoch 6/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.8023 - acc: 0.6704 - val_loss: 0.8736 - val_acc: 0.6371\nEpoch 7/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.7805 - acc: 0.6789 - val_loss: 0.8661 - val_acc: 0.6409\nEpoch 8/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.7610 - acc: 0.6854 - val_loss: 0.8686 - val_acc: 0.6388\nEpoch 9/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.7450 - acc: 0.6911 - val_loss: 0.8632 - val_acc: 0.6440\nEpoch 10/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.7339 - acc: 0.6964 - val_loss: 0.8659 - val_acc: 0.6404\nEpoch 11/32\n124848/124848 [==============================] - 9s 73us/step - loss: 0.7196 - acc: 0.7020 - val_loss: 0.8718 - val_acc: 0.6405\nRestoring model weights from the end of the best epoch\nEpoch 00011: early stopping\nbilstm_cnn\nmin loss (0): 0.7196\nmin val_loss (0): 0.8632\nmax acc (0): 0.702\nmax val_acc (0): 0.644\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 60, 128)           187392    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 60, 128)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 56, 64)            41024     \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 53, 64)            16448     \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 51, 64)            12352     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 51, 64)            0         \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 51, 256)           198656    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 51, 256)           0         \n_________________________________________________________________\nconv1d_4 (Conv1D)            (None, 49, 128)           98432     \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 48, 128)           32896     \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 48, 128)           16512     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 48, 128)           0         \n_________________________________________________________________\nglobal_maxpool1d_1 (GlobalMa (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                4128      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,451,705\nTrainable params: 608,005\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 14s 114us/step - loss: 1.2027 - acc: 0.5224 - val_loss: 1.1007 - val_acc: 0.5524\nEpoch 2/32\n124848/124848 [==============================] - 11s 84us/step - loss: 1.0680 - acc: 0.5647 - val_loss: 1.0298 - val_acc: 0.5908\nEpoch 3/32\n124848/124848 [==============================] - 11s 84us/step - loss: 0.9904 - acc: 0.5942 - val_loss: 0.9864 - val_acc: 0.5734\nEpoch 4/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.9729 - acc: 0.5977 - val_loss: 1.2441 - val_acc: 0.5235\nEpoch 5/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.9947 - acc: 0.5918 - val_loss: 0.9573 - val_acc: 0.6060\nEpoch 6/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.9194 - acc: 0.6172 - val_loss: 0.9405 - val_acc: 0.6102\nEpoch 7/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.8906 - acc: 0.6295 - val_loss: 0.9385 - val_acc: 0.6027\nEpoch 8/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.8837 - acc: 0.6333 - val_loss: 0.9141 - val_acc: 0.6173\nEpoch 9/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.8595 - acc: 0.6433 - val_loss: 0.8953 - val_acc: 0.6247\nEpoch 10/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.8387 - acc: 0.6519 - val_loss: 0.9020 - val_acc: 0.6293\nEpoch 11/32\n124848/124848 [==============================] - 11s 85us/step - loss: 0.8252 - acc: 0.6575 - val_loss: 0.9061 - val_acc: 0.6285\nRestoring model weights from the end of the best epoch\nEpoch 00011: early stopping\nbilstm_cnn_x2\nmin loss (1): 0.8252\nmin val_loss (1): 0.8953\nmax acc (1): 0.6575\nmax val_acc (1): 0.6293\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nlstm_1 (CuDNNLSTM)           (None, 60, 128)           220160    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 60, 128)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 56, 128)           82048     \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 54, 128)           49280     \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 54, 128)           16512     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 54, 128)           0         \n_________________________________________________________________\nglobal_maxpool1d_1 (GlobalMa (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                4128      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,215,993\nTrainable params: 372,293\nNon-trainable params: 5,843,700\n_________________________________________________________________\n","name":"stdout"},{"output_type":"stream","text":"Train on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 8s 62us/step - loss: 1.0712 - acc: 0.5744 - val_loss: 0.9593 - val_acc: 0.6088\nEpoch 2/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.9293 - acc: 0.6174 - val_loss: 0.9260 - val_acc: 0.6217\nEpoch 3/32\n124848/124848 [==============================] - 5s 43us/step - loss: 0.8947 - acc: 0.6312 - val_loss: 0.9020 - val_acc: 0.6309\nEpoch 4/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.8678 - acc: 0.6432 - val_loss: 0.9431 - val_acc: 0.6252\nEpoch 5/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.8433 - acc: 0.6524 - val_loss: 0.8823 - val_acc: 0.6369\nEpoch 6/32\n124848/124848 [==============================] - 5s 43us/step - loss: 0.8224 - acc: 0.6602 - val_loss: 0.9106 - val_acc: 0.6343\nEpoch 7/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.8053 - acc: 0.6671 - val_loss: 0.8781 - val_acc: 0.6394\nEpoch 8/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.7846 - acc: 0.6760 - val_loss: 0.8916 - val_acc: 0.6331\nEpoch 9/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.7734 - acc: 0.6805 - val_loss: 0.8574 - val_acc: 0.6444\nEpoch 10/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.7620 - acc: 0.6847 - val_loss: 0.8683 - val_acc: 0.6465\nEpoch 11/32\n124848/124848 [==============================] - 5s 44us/step - loss: 0.7491 - acc: 0.6899 - val_loss: 0.8713 - val_acc: 0.6399\nRestoring model weights from the end of the best epoch\nEpoch 00011: early stopping\nlstm_cnn\nmin loss (2): 0.7491\nmin val_loss (2): 0.8574\nmax acc (2): 0.6899\nmax val_acc (2): 0.6465\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 56, 128)           192128    \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 54, 128)           49280     \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 54, 128)           16512     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 54, 128)           0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 54, 256)           264192    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 54, 256)           0         \n_________________________________________________________________\nglobal_maxpool1d_1 (GlobalMa (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                8224      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,374,201\nTrainable params: 530,501\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 10s 77us/step - loss: 1.0664 - acc: 0.5711 - val_loss: 0.9673 - val_acc: 0.6007\nEpoch 2/32\n124848/124848 [==============================] - 7s 56us/step - loss: 0.9166 - acc: 0.6204 - val_loss: 0.9336 - val_acc: 0.6137\nEpoch 3/32\n124848/124848 [==============================] - 7s 56us/step - loss: 0.8665 - acc: 0.6408 - val_loss: 0.9056 - val_acc: 0.6180\nEpoch 4/32\n124848/124848 [==============================] - 7s 56us/step - loss: 0.8246 - acc: 0.6585 - val_loss: 0.9411 - val_acc: 0.6143\nEpoch 5/32\n124848/124848 [==============================] - 7s 56us/step - loss: 0.7935 - acc: 0.6730 - val_loss: 0.8937 - val_acc: 0.6256\nEpoch 6/32\n124848/124848 [==============================] - 7s 56us/step - loss: 0.7697 - acc: 0.6827 - val_loss: 0.8941 - val_acc: 0.6271\nEpoch 7/32\n124848/124848 [==============================] - 7s 57us/step - loss: 0.7513 - acc: 0.6889 - val_loss: 0.8979 - val_acc: 0.6257\nRestoring model weights from the end of the best epoch\nEpoch 00007: early stopping\ncnn_bilstm\nmin loss (3): 0.7513\nmin val_loss (3): 0.8937\nmax acc (3): 0.6889\nmax val_acc (3): 0.6271\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 56, 64)            96064     \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 53, 64)            16448     \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 51, 64)            12352     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 51, 64)            0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 51, 128)           66560     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 51, 128)           0         \n_________________________________________________________________\nconv1d_4 (Conv1D)            (None, 49, 128)           49280     \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 48, 128)           32896     \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 48, 128)           16512     \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 48, 128)           0         \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 48, 256)           264192    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 48, 256)           0         \n_________________________________________________________________\nglobal_maxpool1d_1 (GlobalMa (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                8224      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,406,393\nTrainable params: 562,693\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 14s 109us/step - loss: 1.1912 - acc: 0.5211 - val_loss: 1.1411 - val_acc: 0.5453\nEpoch 2/32\n124848/124848 [==============================] - 9s 76us/step - loss: 1.0258 - acc: 0.5867 - val_loss: 0.9754 - val_acc: 0.5939\n","name":"stdout"},{"output_type":"stream","text":"Epoch 3/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.9341 - acc: 0.6145 - val_loss: 0.9593 - val_acc: 0.6035\nEpoch 4/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.8932 - acc: 0.6310 - val_loss: 0.9823 - val_acc: 0.5953\nEpoch 5/32\n124848/124848 [==============================] - 10s 76us/step - loss: 0.8639 - acc: 0.6435 - val_loss: 0.9296 - val_acc: 0.6069\nEpoch 6/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.8402 - acc: 0.6540 - val_loss: 0.9273 - val_acc: 0.6148\nEpoch 7/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.8204 - acc: 0.6630 - val_loss: 0.9359 - val_acc: 0.6101\nEpoch 8/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.8099 - acc: 0.6663 - val_loss: 0.9195 - val_acc: 0.6134\nEpoch 9/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.7905 - acc: 0.6748 - val_loss: 0.9168 - val_acc: 0.6191\nEpoch 10/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.7837 - acc: 0.6772 - val_loss: 0.9187 - val_acc: 0.6149\nEpoch 11/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.7706 - acc: 0.6831 - val_loss: 0.9133 - val_acc: 0.6200\nEpoch 12/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.7664 - acc: 0.6857 - val_loss: 0.9364 - val_acc: 0.6084\nEpoch 13/32\n124848/124848 [==============================] - 9s 76us/step - loss: 0.7576 - acc: 0.6886 - val_loss: 0.9149 - val_acc: 0.6150\nRestoring model weights from the end of the best epoch\nEpoch 00013: early stopping\ncnn_bilstm_x2\nmin loss (4): 0.7576\nmin val_loss (4): 0.9133\nmax acc (4): 0.6886\nmax val_acc (4): 0.62\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 56, 128)           192128    \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 54, 128)           49280     \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 54, 128)           16512     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 54, 128)           0         \n_________________________________________________________________\nlstm_1 (CuDNNLSTM)           (None, 54, 128)           132096    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 54, 128)           0         \n_________________________________________________________________\nglobal_maxpool1d_1 (GlobalMa (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                4128      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,238,009\nTrainable params: 394,309\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 8s 64us/step - loss: 1.0797 - acc: 0.5662 - val_loss: 0.9521 - val_acc: 0.6051\nEpoch 2/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.9240 - acc: 0.6188 - val_loss: 0.9275 - val_acc: 0.6170\nEpoch 3/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.8724 - acc: 0.6394 - val_loss: 0.9065 - val_acc: 0.6251\nEpoch 4/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.8304 - acc: 0.6577 - val_loss: 0.9034 - val_acc: 0.6251\nEpoch 5/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.7951 - acc: 0.6726 - val_loss: 0.9299 - val_acc: 0.6015\nEpoch 6/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.7719 - acc: 0.6845 - val_loss: 0.9013 - val_acc: 0.6249\nEpoch 7/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.7524 - acc: 0.6907 - val_loss: 0.9144 - val_acc: 0.6125\nEpoch 8/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.7367 - acc: 0.6984 - val_loss: 0.8965 - val_acc: 0.6277\nEpoch 9/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.7233 - acc: 0.7026 - val_loss: 0.9021 - val_acc: 0.6231\nEpoch 10/32\n124848/124848 [==============================] - 5s 38us/step - loss: 0.7122 - acc: 0.7076 - val_loss: 0.9073 - val_acc: 0.6263\nRestoring model weights from the end of the best epoch\nEpoch 00010: early stopping\ncnn_lstm\nmin loss (5): 0.7122\nmin val_loss (5): 0.8965\nmax acc (5): 0.7076\nmax val_acc (5): 0.6277\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 256)               440320    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                8224      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,292,409\nTrainable params: 448,709\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 9s 72us/step - loss: 1.0433 - acc: 0.5789 - val_loss: 0.9252 - val_acc: 0.6160\nEpoch 2/32\n124848/124848 [==============================] - 6s 47us/step - loss: 0.9198 - acc: 0.6209 - val_loss: 0.9004 - val_acc: 0.6250\nEpoch 3/32\n124848/124848 [==============================] - 6s 47us/step - loss: 0.8860 - acc: 0.6344 - val_loss: 0.8856 - val_acc: 0.6303\nEpoch 4/32\n124848/124848 [==============================] - 6s 47us/step - loss: 0.8627 - acc: 0.6463 - val_loss: 0.8907 - val_acc: 0.6307\nEpoch 5/32\n124848/124848 [==============================] - 6s 47us/step - loss: 0.8416 - acc: 0.6546 - val_loss: 0.8722 - val_acc: 0.6362\nEpoch 6/32\n124848/124848 [==============================] - 6s 47us/step - loss: 0.8217 - acc: 0.6620 - val_loss: 0.8686 - val_acc: 0.6394\nEpoch 7/32\n124848/124848 [==============================] - 6s 47us/step - loss: 0.8054 - acc: 0.6681 - val_loss: 0.8726 - val_acc: 0.6368\nEpoch 8/32\n124848/124848 [==============================] - 6s 47us/step - loss: 0.7892 - acc: 0.6753 - val_loss: 0.8615 - val_acc: 0.6432\nEpoch 9/32\n124848/124848 [==============================] - 6s 46us/step - loss: 0.7727 - acc: 0.6820 - val_loss: 0.8713 - val_acc: 0.6412\nEpoch 10/32\n","name":"stdout"},{"output_type":"stream","text":"124848/124848 [==============================] - 6s 46us/step - loss: 0.7640 - acc: 0.6825 - val_loss: 0.8748 - val_acc: 0.6406\nRestoring model weights from the end of the best epoch\nEpoch 00010: early stopping\nbilstm_only\nmin loss (6): 0.764\nmin val_loss (6): 0.8615\nmax acc (6): 0.6825\nmax val_acc (6): 0.6432\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nlstm_1 (CuDNNLSTM)           (None, 128)               220160    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                4128      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,068,153\nTrainable params: 224,453\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 6s 50us/step - loss: 1.2268 - acc: 0.5112 - val_loss: 1.1417 - val_acc: 0.5051\nEpoch 2/32\n124848/124848 [==============================] - 3s 25us/step - loss: 1.1320 - acc: 0.5437 - val_loss: 1.0689 - val_acc: 0.5518\nEpoch 3/32\n124848/124848 [==============================] - 3s 25us/step - loss: 1.0942 - acc: 0.5590 - val_loss: 1.1476 - val_acc: 0.5339\nEpoch 4/32\n124848/124848 [==============================] - 3s 25us/step - loss: 1.1573 - acc: 0.5493 - val_loss: 1.2698 - val_acc: 0.4922\nRestoring model weights from the end of the best epoch\nEpoch 00004: early stopping\nlstm_only\nmin loss (7): 1.094\nmin val_loss (7): 1.069\nmax acc (7): 0.559\nmax val_acc (7): 0.5518\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 56, 128)           192128    \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 54, 128)           49280     \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 54, 128)           16512     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 54, 128)           0         \n_________________________________________________________________\nglobal_maxpool1d_1 (GlobalMa (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                4128      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 6,105,913\nTrainable params: 262,213\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 6s 48us/step - loss: 1.0588 - acc: 0.5742 - val_loss: 1.0010 - val_acc: 0.5998\nEpoch 2/32\n124848/124848 [==============================] - 3s 23us/step - loss: 0.9194 - acc: 0.6208 - val_loss: 0.9494 - val_acc: 0.6060\nEpoch 3/32\n124848/124848 [==============================] - 3s 23us/step - loss: 0.8777 - acc: 0.6386 - val_loss: 0.9244 - val_acc: 0.6145\nEpoch 4/32\n124848/124848 [==============================] - 3s 23us/step - loss: 0.8407 - acc: 0.6522 - val_loss: 0.9268 - val_acc: 0.6142\nEpoch 5/32\n124848/124848 [==============================] - 3s 23us/step - loss: 0.8069 - acc: 0.6660 - val_loss: 0.9270 - val_acc: 0.6150\nRestoring model weights from the end of the best epoch\nEpoch 00005: early stopping\ncnn_only\nmin loss (8): 0.8069\nmin val_loss (8): 0.9244\nmax acc (8): 0.666\nmax val_acc (8): 0.615\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 60)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 60, 300)           5843700   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 18000)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              18433024  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               131200    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 32)                4128      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32)                0         \n_________________________________________________________________\npreds (Dense)                (None, 5)                 165       \n=================================================================\nTotal params: 24,412,217\nTrainable params: 18,568,517\nNon-trainable params: 5,843,700\n_________________________________________________________________\nTrain on 124848 samples, validate on 31212 samples\nEpoch 1/32\n124848/124848 [==============================] - 7s 55us/step - loss: 1.0510 - acc: 0.5740 - val_loss: 0.9612 - val_acc: 0.6008\nEpoch 2/32\n124848/124848 [==============================] - 3s 23us/step - loss: 0.9222 - acc: 0.6229 - val_loss: 0.9418 - val_acc: 0.6039\nEpoch 3/32\n124848/124848 [==============================] - 3s 23us/step - loss: 0.8527 - acc: 0.6534 - val_loss: 0.9395 - val_acc: 0.6057\nEpoch 4/32\n124848/124848 [==============================] - 3s 23us/step - loss: 0.7842 - acc: 0.6838 - val_loss: 0.9489 - val_acc: 0.6048\nEpoch 5/32\n124848/124848 [==============================] - 3s 24us/step - loss: 0.7163 - acc: 0.7135 - val_loss: 0.9697 - val_acc: 0.6014\nRestoring model weights from the end of the best epoch\nEpoch 00005: early stopping\ndense_only\nmin loss (9): 0.7163\nmin val_loss (9): 0.9395\nmax acc (9): 0.7135\nmax val_acc (9): 0.6057\n66292/66292 [==============================] - 3s 44us/step\n66292/66292 [==============================] - 3s 52us/step\n66292/66292 [==============================] - 2s 31us/step\n","name":"stdout"},{"output_type":"stream","text":"66292/66292 [==============================] - 2s 36us/step\n66292/66292 [==============================] - 3s 46us/step\n66292/66292 [==============================] - 2s 33us/step\n66292/66292 [==============================] - 2s 36us/step\n66292/66292 [==============================] - 2s 26us/step\n66292/66292 [==============================] - 2s 23us/step\n66292/66292 [==============================] - 2s 24us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_num = np_x_test.shape[0]\ny_pred_class = np.ndarray(shape=(test_num,), dtype=np.int32)\n\nfor i in range(test_num):\n    votes = []\n\n    for j in range(classifier_num):\n        vote = y_pred_list[j][i].argmax(axis=0).astype(int)\n        votes.append(vote)\n\n    vote_final = max(set(votes), key=votes.count)\n    y_pred_class[i] = vote_final\n\nmapping = {phrase: sentiment for _, _, phrase, sentiment in train.values}\n\n# Overlapping\nfor i, phrase in enumerate(test.Phrase.values):\n    if phrase in mapping:\n        y_pred_class[i] = mapping[phrase]\n\ntest['Sentiment'] = y_pred_class\ntest[['PhraseId', 'Sentiment']].to_csv('submission.csv', index=False)\ntest.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   PhraseId    ...      Sentiment\n0    156061    ...              3\n1    156062    ...              3\n2    156063    ...              2\n3    156064    ...              3\n4    156065    ...              2\n\n[5 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>156061</td>\n      <td>8545</td>\n      <td>An intermittently pleasing but mostly routine ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>156062</td>\n      <td>8545</td>\n      <td>An intermittently pleasing but mostly routine ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156063</td>\n      <td>8545</td>\n      <td>An</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>156064</td>\n      <td>8545</td>\n      <td>intermittently pleasing but mostly routine effort</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>156065</td>\n      <td>8545</td>\n      <td>intermittently pleasing but mostly routine</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}