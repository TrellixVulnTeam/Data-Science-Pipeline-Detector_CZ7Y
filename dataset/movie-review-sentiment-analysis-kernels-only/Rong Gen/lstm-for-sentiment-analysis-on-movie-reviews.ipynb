{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"seed = 1\nimport random\nimport numpy as np\nfrom tensorflow import set_random_seed\n\n\nrandom.seed(seed)\nnp.random.seed(seed)\nset_random_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a298e9f7c62e7e559b8f683c555ced09289e9c05","collapsed":true},"cell_type":"code","source":"#load data\ntrain = pd.read_csv('../input/train.tsv',  sep=\"\\t\")\ntest = pd.read_csv('../input/test.tsv',  sep=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"947c58dedb8931aa53d0f13b2f5a64ca53cbbba4","collapsed":true},"cell_type":"code","source":"#观察数据\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49ae768b21f15ffcb9afbac53580050c7b932d4b","collapsed":true},"cell_type":"code","source":"#数据没有空值,观察数据内容\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af4111500df1f9c5d057bccc9507543e09ee24f1","collapsed":true},"cell_type":"code","source":"#观察样本的大致统计分布\ntrain['Sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a7427b0c091cdb3dfc023982454e64c5dbd52c98"},"cell_type":"code","source":"#试试NB的效果\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvec = CountVectorizer(\n    lowercase=True,     # 英文文本全小写\n    analyzer='word', # 逐个字母解析\n    ngram_range=(1,1),  # 1=出现的字母以及每个字母出现的次数，2=出现的连续2个字母，和连续2个字母出现的频次\n    # trump images are now... => 1gram = t,r,u,m,p... 2gram = tr,ru,um,mp...\n    max_features=1000,  # keep the most common 1000 ngrams\n    preprocessor=None\n)\n\nX=train['Phrase']\nY=train['Sentiment']\nX_test=test['Phrase']\n\nvec.fit(X)\nX=vec.transform(X)\nX_test=vec.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cdb193ab4109fb60dbc42dfa60f327e039388fc","collapsed":true},"cell_type":"code","source":"#对数据进行切分\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d74931ee1ba561fc61a89724c2e70f9be66001c2"},"cell_type":"code","source":"from sklearn.e","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9535bd7fab925cab9334119c684baf731305d67","collapsed":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f52ee047b9008f67f2419bf1165f4266bde0510b","collapsed":true},"cell_type":"code","source":"classifier.score(X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b01995605b4c7d0c5cbe06db39b98020a4989c5c","collapsed":true},"cell_type":"code","source":"#对文本进行预处理\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\n\nX=train['Phrase']\nY=train['Sentiment']\nX_test=test['Phrase']\nmax_features=20000  #最大单词数\nmax_length=100      #句子最大长度\n\n#设置分词器\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X)\nX=tokenizer.texts_to_sequences(X)\nX=pad_sequences(X_train,maxlen=max_length)\n\n#对测试集数据做同样处理\nX_test=tokenizer.texts_to_sequences(X_test)\nX_test=pad_sequences(X_test,maxlen=max_length)\n\n#将y进行One-Hot编码\nY = to_categorical(train['Sentiment'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"55daacdcd50bc2adbe2916f032b2a54f3b94a123"},"cell_type":"code","source":"#对数据进行切分\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"03894a677b0ef61fbb9ad900a4e436797718d2a4"},"cell_type":"code","source":"#搭建模型,利用LSTM搭建\nfrom keras.layers.core import Activation, Dense\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\n\nmodel = Sequential()\n# Input / Embdedding\nmodel.add(Embedding(max_features, 128, input_length=max_length))\n#LSTM\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(5))\nmodel.add(Activation(\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ea3fddb00462f83ac487ed06e148bc540753e3eb"},"cell_type":"code","source":"sub = pd.read_csv('../input/sampleSubmission.csv')\n\nsub['Sentiment'] = model.predict_classes(test_X, batch_size=batch_size, verbose=1)\nsub.to_csv('sub_cnn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"278adc7324ec6741fbab9aaeb7bc426849ef549f","collapsed":true},"cell_type":"code","source":"def format_data(train, test, max_features, maxlen):\n    \"\"\"\n    Convert data to proper format.\n    1) Shuffle\n    2) Lowercase\n    3) Sentiments to Categorical\n    4) Tokenize and Fit\n    5) Convert to sequence (format accepted by the network)\n    6) Pad\n    7) Voila!\n    \"\"\"\n    from keras.preprocessing.text import Tokenizer\n    from keras.preprocessing.sequence import pad_sequences\n    from keras.utils import to_categorical\n    \n    train = train.sample(frac=1).reset_index(drop=True)\n    train['Phrase'] = train['Phrase'].apply(lambda x: x.lower())\n    test['Phrase'] = test['Phrase'].apply(lambda x: x.lower())\n\n    X = train['Phrase']\n    test_X = test['Phrase']\n    Y = to_categorical(train['Sentiment'].values)\n\n    tokenizer = Tokenizer(num_words=max_features)\n    tokenizer.fit_on_texts(list(X))\n\n    X = tokenizer.texts_to_sequences(X)\n    X = pad_sequences(X, maxlen=maxlen)\n    test_X = tokenizer.texts_to_sequences(test_X)\n    test_X = pad_sequences(test_X, maxlen=maxlen)\n\n    return X, Y, test_X","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}