{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = 'Mình nặng 70.5kg, nặng 175.8 cm.'\ndigit = '\\d+'\n\nimport re\nprint(re.findall(digit, text))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/bms-molecular-translation/\"\ntest = pd.read_csv(path + 'sample_submission.csv', index_col=0)\n\nlabels_path = path + \"train_labels.csv\"\ndf_train_alls = pd.read_csv(labels_path)\ndf_train_labels=df_train_alls[:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fully_qualified_path = path + \"train/{}/{}/{}/{}.png\"\nconvert_image_id_to_path = lambda image_id_details :fully_qualified_path.format(image_id_details[0], image_id_details[1], image_id_details[2], image_id_details) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s_type=[inchi.split(\"/\")[1] for inchi in tqdm(df_train_alls[\"InChI\"])]\nprint(set(s_type))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels['image_path']=df_train_labels['image_id'].apply(convert_image_id_to_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elements=['Cl', 'C','Br','B','Si','S' 'H', 'P', 'O', 'N', 'I', 'F']\nelements_revise=['G', 'C','R','B','L','S' 'H', 'P', 'O', 'N', 'I', 'F']\n\ndf_train_labels['formula'] = df_train_labels['InChI'].apply(lambda x: x.split('/')[1]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def revise_element(element):\n    revise=element\n    if \"Cl\" in element:\n        revise=revise.replace(\"Cl\", \"G\")\n    if \"Br\" in element:\n        revise=revise.replace(\"Br\", \"R\")\n    if \"Si\" in element:\n        revise=revise.replace(\"Si\", \"L\")\n    return revise;","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels['formula']=df_train_labels['formula'].apply(revise_element)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def number_of_carbon(element):\n    nums={\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"}\n    result=\"\"\n    for i in range(1,len(element)):\n        if element[i] in nums:\n            result=result+element[i]\n        else:\n            break    \n    return int(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels['C']=df_train_labels['formula'].apply(number_of_carbon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pickle import dump\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications import DenseNet121\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.densenet import preprocess_input\nfrom keras.models import Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_X(path):\n    filename = path\n    image = load_img(filename, target_size=(128, 128))\n         # convert the image pixels to a numpy array\n    image = img_to_array(image)\n    image=255-image[:,:,0]\n    return image.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels['X']=df_train_labels['image_path'].apply(create_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.array(df_train_labels.X.values.tolist())\nX.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y=df_train_labels[\"C\"].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.datasets import mnist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=X.reshape(X.shape[0],X.shape[1],X.shape[2],1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m=X.shape[0]\ntest_val=int(m/5)\nX_val, Y_val = X[:m-2*test_val:m-test_val], Y[:m-2*test_val:m-test_val]\nX_train, Y_train = X[:m-2*test_val], Y[:m-2*test_val]\nX_test,Y_test=X[m-test_val:], Y[m-test_val:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nmodel = Sequential()\n \n# Thêm Convolutional layer với 32 kernel, kích thước kernel 3*3\n# dùng hàm sigmoid làm activation và chỉ rõ input_shape cho layer đầu tiên\nmodel.add(Conv2D(1, (3, 3), activation='sigmoid', input_shape=(128,128,1)))\nmodel.add(Conv2D(1, (3, 3), activation='sigmoid'))\n# Thêm Max pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# Flatten layer chuyển từ tensor sang vector\nmodel.add(Flatten())\n\n# Thêm Fully Connected layer với 128 nodes và dùng hàm sigmoid\nmodel.add(Dense(256, activation='relu',kernel_regularizer=keras.regularizers.l1_l2(0.001)))\nmodel.add(Dense(256, activation='relu',kernel_regularizer=keras.regularizers.l1_l2(0.001)))\nmodel.add(Dense(16, activation='relu',kernel_regularizer=keras.regularizers.l1_l2(0.001)))\n\n# Output layer với 10 node và dùng softmax function để chuyển sang xác xuất.\nmodel.add(Dense(1, activation='relu',kernel_regularizer=keras.regularizers.l1_l2(0.01)))\n# 6. Compile model, chỉ rõ hàm loss_function nào được sử dụng, phương thức \n# đùng để tối ưu hàm loss function.\nmodel.compile(loss='mean_squared_error',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"H = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n          batch_size=32, epochs=10, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"H.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. Vẽ đồ thị loss, accuracy của traning set và validation set\nfig = plt.figure()\nnumOfEpoch = 3\nplt.plot(np.arange(0, numOfEpoch), H.history['loss'], label='training loss')\nplt.plot(np.arange(0, numOfEpoch), H.history['val_loss'], label='validation loss')\nplt.plot(np.arange(0, numOfEpoch), 1-np.array(H.history['accuracy']), label='accuracy')\nplt.plot(np.arange(0, numOfEpoch), 1-np.array(H.history['val_accuracy']), label='validation accuracy')\nplt.title('Accuracy and Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss|Accuracy')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_test, Y_test, verbose=0)\nprint(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(100):\n    y_predict = model.predict(X_test[i].reshape(1,128,128,1))\n    print(\"Dự đoan {}vs thức tế {}\".format(y_predict[0][0],Y_test[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_image_id_2_path(image_id: str) -> str:\n    return path + \"test/{}/{}/{}/{}.png\".format(\n        image_id[0], image_id[1], image_id[2], image_id \n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_image(image_id, label):\n    plt.figure(figsize=(10, 8))\n    \n    image = cv2.imread(convert_image_id_2_path(image_id))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    plt.imshow(image)\n    plt.title(f\"{label}\", fontsize=14)\n    plt.axis(\"off\")\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_image_denoise(image_id):\n    plt.figure(figsize=(10, 8))  \n    image = cv2.imread(convert_image_id_2_path(image_id), cv2.IMREAD_GRAYSCALE)\n    _, blackAndWhite = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(blackAndWhite, None, None, None, 8, cv2.CV_32S)\n    sizes = stats[1:, -1] #get CC_STAT_AREA component\n    img2 = np.zeros((labels.shape), np.uint8)\n    for i in range(0, nlabels - 1):\n        if sizes[i] >= 2:   #filter small dotted regions\n            img2[labels == i + 1] = 255\n    image = cv2.bitwise_not(img2)\n    plt.imshow(image)    \n    plt.axis(\"off\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_train_batch(image_ids, labels):\n    plt.figure(figsize=(32, 24))\n    \n    for ind, (image_id, label) in enumerate(zip(image_ids, labels)):\n        plt.subplot(3, 3, ind + 1)\n        image = cv2.imread(convert_image_id_to_path(image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(f\"{label[:50]}...\", fontsize=10)\n        plt.axis(\"off\")\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=0\nvisualize_image(test.index[i], test.index[i])\nvisualize_image_denoise(test.index[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = df_train_labels[:1]\nimage_ids = tmp_df['image_id']\nlabels = tmp_df[\"InChI\"].values\nvisualize_train_batch(image_ids, labels)\nprint(labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = df_train_labels[7:9]\nimage_ids = tmp_df['image_id']\nlabels = tmp_df[\"InChI\"].values\nvisualize_train_batch(image_ids, labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Length of training-data:',len(df_train_labels))\nprint('Number of unique chemical identifier:',len(df_train_labels['InChI'].value_counts().index))\nprint('Max count of any chemical identifier in trainign data:',max(df_train_labels['InChI'].value_counts().values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_shape=[]\nw_shape=[]\naspect_ratio=[]\nfor idx,image_id in enumerate(df_train_labels.image_id.values[:3000]):\n    image = cv2.imread(df_train_labels['image_path'][idx])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    h_shape.append(image.shape[0])\n    w_shape.append(image.shape[1])\n    aspect_ratio.append(1.0 * (image.shape[1] / image.shape[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nplt.subplots_adjust(top = 0.5, bottom=0.01, hspace=1, wspace=0.4)\nplt.subplot(2, 2, 1)\nplt.hist(np.array(h_shape) * np.array(w_shape), bins=50)\nplt.xticks(rotation=45)\nplt.title(\"Area Image Distribution\", fontsize=14)\nplt.subplot(2, 2, 2)\nplt.hist(h_shape, bins=50)\nplt.title(\"Height Image Distribution\", fontsize=14)\nprint()\nplt.subplot(2, 2, 3)\nplt.hist(w_shape, bins=50)\nplt.title(\"Width Image Distribution\", fontsize=14)\nplt.subplot(2, 2, 4)\nplt.hist(aspect_ratio, bins=50)\nplt.title(\"Aspect Ratio Distribution\", fontsize=14);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(h_shape,w_shape)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_odd(h,w):\n    for i in range(len(h_shape)):\n        if h_shape[i]>h or w_shape[i]>w:\n            visualize_train_batch(df_train_labels.loc[i:i].image_id, df_train_labels.loc[i:i].InChI)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_odd(800,1500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pickle import dump\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications import DenseNet121\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.densenet import preprocess_input\nfrom keras.models import Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract features from each image\ndef extract_features():\n    \n # load the model\n    model = DenseNet121()\n    # re-structure the model\n    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n    # summarize\n    #print(model.summary())\n # extract features from each image\n    features = dict()\n    for idx,name in enumerate(df_train_labels['image_path'].values[:100]):\n        filename = name\n        image = load_img(filename, target_size=(224, 224))\n         # convert the image pixels to a numpy array\n        image = img_to_array(image)\n         # reshape data for the model\n        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n         # prepare the image for the DenseNet121 model\n        image = preprocess_input(image)\n         # get features\n        feature = model.predict(image, verbose=0)\n         # store feature\n        features[df_train_labels['image_id'][idx]] = feature\n        #print('>%s' % name)\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = extract_features()\nprint('Extracted Features: %d' % len(features))\n# save to file\ndump(features, open('features.pkl', 'wb'))\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract texts for images\ndef load_text():\n    mapping = dict()\n    for idx,text in enumerate(df_train_labels['InChI'].values[:101]):\n        mapping[df_train_labels['image_id'][idx]]=text\n    return mapping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_vocabulary(descriptions):\n    all_desc = set()\n    for key,value in descriptions.items():\n        all_desc.update([value])\n    return all_desc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = load_text()\nvocabulary  = to_vocabulary(texts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loaded: %d ' % len(texts))\nprint('Vocabulary Size: %d' % len(vocabulary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport Levenshtein","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(path + 'sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=df_train_labels\ntrain['InChI_list'] = train['InChI'].progress_apply(lambda x: x.split('/'))\ntrain['InChI_length'] = train['InChI_list'].progress_apply(len)\nInChI_df = train['InChI_list'].progress_apply(pd.Series)\ntrain = pd.concat([train, InChI_df.add_prefix('InChI_')], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    scores = []\n    for true, pred in zip(y_true, y_pred):\n        score = Levenshtein.distance(true, pred)\n        scores.append(score)\n    avg_score = np.mean(scores)\n    return avg_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode_concat_string = ''\nfor i in range(11):\n    mode_string = train[f'InChI_{i}'].fillna('nan').mode()[0]\n    if mode_string != 'nan':\n        if i == 0:\n            mode_concat_string += mode_string\n        else:\n            mode_concat_string += '/' + mode_string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mode_concat_string)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = train['InChI'].values\ny_pred = [mode_concat_string] * len(train)\nscore = get_score(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['InChI'] = mode_concat_string\noutput_cols = ['image_id', 'InChI']\ndisplay(test[output_cols])\ntest[output_cols].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}