{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BigQuery-Geotab Intersection Congestion"},{"metadata":{},"cell_type":"markdown","source":"Weâ€™ve all been there: Stuck at a traffic light, only to be given mere seconds to pass through an intersection, behind a parade of other commuters. Imagine if you could help city planners and governments anticipate traffic hot spots ahead of time and reduce the stop-and-go stress of millions of commuters like you."},{"metadata":{},"cell_type":"markdown","source":"# Table of contents\n- [Imports and initial exploration](#imports)\n\n- [Exploratory Data Analysis](#eda)\n    - [Time features](#hmw)\n    - [Exploring street features](#streetfeatures)\n    - [Latitude and Longitude](#latlon)\n    \n- [Preprocessing](#prepro)\n\n- [Baseline model](#baseline)"},{"metadata":{},"cell_type":"markdown","source":"## Imports and initial exploration\n<a id='imports'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n!pip install pandarallel\n\nimport pandas as pd\nimport pandarallel\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport mplleaflet\nfrom collections import Counter\n\nimport json\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RepeatedKFold\nfrom tensorflow import keras\n\nfrom mlxtend.regressor import StackingRegressor\n\npandarallel.pandarallel.initialize(progress_bar=True)\n\nsns.set_style('darkgrid')\nsns.set_palette('deep')\n\nnp.random.seed(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/bigquery-geotab-intersection-congestion/train.csv')\ntest = pd.read_csv('../input/bigquery-geotab-intersection-congestion/test.csv')\nsample = pd.read_csv('../input/bigquery-geotab-intersection-congestion/sample_submission.csv')\nwith open('../input/bigquery-geotab-intersection-congestion/submission_metric_map.json') as f:\n    submission_metric_map = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n<a id='eda'></a>"},{"metadata":{},"cell_type":"markdown","source":"### Time features\n<a id='hmw'></a>"},{"metadata":{},"cell_type":"markdown","source":"We all know there is probably a high correlation between the time features and the  values we want to predict, let's visualize this interaction"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_features = ['Hour', 'Month', 'Weekend']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2,1, figsize=[15,10])\n\nsns.countplot(data=train[train['Weekend']==0], hue='City', x='Hour', ax=axes[0],);\nsns.countplot(data=train[train['Weekend']==1], hue='City', x='Hour', ax=axes[1]);\naxes[0].legend([])\naxes[1].legend(loc=[-0.2,0.7])\naxes[0].set_title(\"Weekdays\")\naxes[1].set_title(\"Weekends\")\nfig.set_dpi(500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Month', hue='City', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring street features\n<a id='streetfeatures'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"street_features = ['EntryStreetName', 'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Path']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see clearly path is just a concatenation of the other features, so we can just drop it"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('Path', axis=1, inplace=True)\ntest.drop('Path', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cardinal directions can be expressed using the following equation:\n$$\n\\frac{\\theta}{\\pi}\n$$\nWhere $\\theta$ is the angle between the we want to encode direction and the north direction measured clockwise"},{"metadata":{"trusted":true},"cell_type":"code","source":"directions = {\n    'N': 0,\n    'NE': 1/4,\n    'E': 1/2,\n    'SE': 3/4,\n    'S': 1,\n    'SW': 5/4,\n    'W': 3/2,\n    'NW': 7/4\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['EntryHeading'] = train['EntryHeading'].map(directions)\ntrain['ExitHeading'] = train['ExitHeading'].map(directions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['EntryHeading'] = test['EntryHeading'].map(directions)\ntest['ExitHeading'] = test['ExitHeading'].map(directions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['diffHeading'] = (train['ExitHeading']-train['EntryHeading'])\ntest['diffHeading'] = (test['ExitHeading']-test['EntryHeading'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looking at street names"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_count = Counter()\nfor name in train['EntryStreetName']:\n    if pd.isna(name):\n        continue\n    for word in name.split():\n        word_count[word]+=1\n        \nfor name in train['ExitStreetName']:\n    if pd.isna(name):\n        continue\n    for word in name.split():\n        word_count[word]+=1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sorted(word_count.items(),key=lambda item: item[1], reverse=True)[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use the following road types: Street, Avenue, Road, Boulevard, Broad and Drive\n\nAfter searching on the <a href='https://360.here.com/2016/12/30/whats-the-difference-between-a-road-a-street-and-an-avenue/'>internet</a> their differences, I found that Avenue and Street are basically the same thing."},{"metadata":{},"cell_type":"markdown","source":"a) Street (for any thoroughfare) \n\nb) Road (for any thoroughfare) \n\nc) Way (for major roads - also appropriate for pedestrian routes) \n\nd) Avenue (for residential roads) \n\ne) Drive (for residential roads) \n\nf) Grove (for residential roads) \n\ng) Lane (for residential roads) \n\nh) Gardens (for residential roads) subject to there being no confusion with any local open space \n\ni) Place (for residential roads) \n\nj) Crescent (for a crescent shaped road) \n\nk) Court/Close (for a cul-de-sac only) \n\nl) Square (for a square only) \n\nm) Hill (for a hillside road only) \n\nn) Circus (for a large roundabout) \n\no) Vale (for residential roads) \n\np) Rise (for residential roads) \n\nq) Row (for residential roads) \n\nr) Wharf (for residential roads) \n\ns) Mews (for residential roads) \n\nt) Mead (for residential roads) \n\nu) Meadow (for residential roads)"},{"metadata":{"trusted":true},"cell_type":"code","source":"road_encoding = {\n    'Street': 0,\n    'St': 0,\n    'Avenue': 1,\n    'Ave': 1,\n    'Boulevard': 2,\n    'Road': 3,\n    'Drive': 4,\n    'Lane': 5,\n    'Tunnel': 6,\n    'Highway': 7,\n    'Way': 8,\n    'Parkway': 9,\n    'Parking': 9,\n    'Oval': 10,\n    'Square': 11,\n    'Place': 12,\n    'Bridge': 13,\n    'Unknown': 14\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode(x):\n    if pd.isna(x):\n        return road_encoding['Unknown']\n    for road in road_encoding.keys():\n        if road in x:\n            return road_encoding[road]\n        \n    return road_encoding['Unknown']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['EntryType'] = train['EntryStreetName'].parallel_apply(encode)\ntrain['ExitType'] = train['ExitStreetName'].parallel_apply(encode)\ntest['EntryType'] = test['EntryStreetName'].parallel_apply(encode)\ntest['ExitType'] = test['ExitStreetName'].parallel_apply(encode)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['EqualStreets'] = (train['EntryStreetName']==train['ExitStreetName'])\ntest['EqualStreets'] = (test['EntryStreetName']==test['ExitStreetName'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Latitude and Longitude\n<a id='latlon'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,10])\ntmp = train[train['City']=='Boston'].groupby(['Latitude', 'Longitude'])['RowId'].count().reset_index()\nsns.kdeplot(tmp['Longitude'], tmp['Latitude'])\n\nmplleaflet.display()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = train['City'].unique()\nscalers_lat = {}\nscalers_lon = {}\nfor city in cities:\n    latitudes = np.array(train[train['City']==city]['Latitude']).reshape(-1,1)\n    longitudes = np.array(train[train['City']==city]['Longitude']).reshape(-1,1)\n    scalers_lat[city] = StandardScaler().fit(latitudes)\n    scalers_lon[city] = StandardScaler().fit(longitudes)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train['Latitude'] = train.parallel_apply(lambda row: scalers_lat[row['City']].transform(np.array(row['Latitude']).reshape(1,1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Longitude'] = train.parallel_apply(lambda row: scalers_lon[row['City']].transform(np.array(row['Longitude']).reshape(1,1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Latitude'] = test.parallel_apply(lambda row: scalers_lat[row['City']].transform(np.array(row['Latitude']).reshape(1,1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Longitude'] = test.parallel_apply(lambda row: scalers_lon[row['City']].transform(np.array(row['Longitude']).reshape(1,1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(train['Longitude'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n<a id='prepro'></a>"},{"metadata":{},"cell_type":"markdown","source":"Let's create a new dataframe with the new following features: TotaTimeStopped, DistanceToFirstStop and Percentile.\n\nCreating a dataframe in the following way can enable us to use the percentile as a feature and can help us boost the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_columns = ['IntersectionId', 'Latitude', 'Longitude', 'EntryStreetName',\n       'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend', 'DistanceToFirstStop',\n       'Month', 'TotalTimeStopped', 'Percentile', 'City', 'diffHeading', 'EntryType', 'ExitType', 'EqualStreets']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test_columns = ['IntersectionId', 'Latitude', 'Longitude', 'EntryStreetName',\n       'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend',\n       'Month', 'Percentile', 'City', 'diffHeading', 'EntryType', 'ExitType', 'EqualStreets']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.DataFrame(columns=new_train_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test = pd.DataFrame(columns=new_test_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for per in [20, 40, 50, 60, 80]:\n    new_df = train.copy()\n    new_df['TotalTimeStopped'] = new_df['TotalTimeStopped_p'+str(per)]\n    new_df['DistanceToFirstStop'] = new_df['DistanceToFirstStop_p'+str(per)]\n    new_df['Percentile'] = pd.Series([per for _ in range(len(new_df))])\n    new_df.drop(['TotalTimeStopped_p20', 'TotalTimeStopped_p40',\n       'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80',\n       'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40',\n       'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60',\n       'TimeFromFirstStop_p80', 'DistanceToFirstStop_p20',\n       'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50',\n       'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80', 'RowId'], axis=1,inplace=True)\n    new_train = pd.concat([new_train, new_df], sort=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for per in [20, 50, 80]:\n    new_df = test.copy()\n    new_df['Percentile'] = pd.Series([per for _ in range(len(new_df))])\n    new_test = pd.concat([new_test, new_df], sort=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.concat([new_train.drop('City', axis=1), pd.get_dummies(new_train['City'])], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test = pd.concat([new_test.drop('City', axis=1), pd.get_dummies(new_test['City'])], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = new_train.reindex(sorted(new_train.columns), axis=1)\nnew_test = new_test.reindex(sorted(new_test.columns), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test = new_test.sort_values(by=['RowId', 'Percentile'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(new_train.drop(['EntryStreetName', 'ExitStreetName', 'IntersectionId', \n                                   'TotalTimeStopped', 'DistanceToFirstStop'], axis=1), dtype=np.float32)\nX_test = np.array(new_test.drop(['EntryStreetName', 'ExitStreetName', 'IntersectionId', \n                                 'RowId'], axis=1), dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.array(new_train[['TotalTimeStopped', 'DistanceToFirstStop']], dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline model\n<a id='baseline'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import backend as K\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean((y_true-y_pred)**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=45)(x)\n    act1 = keras.layers.PReLU()(fc1)\n    bn1 = keras.layers.BatchNormalization()(act1)\n    dp1 = keras.layers.Dropout(0.15)(bn1)\n    concat1 = keras.layers.Concatenate()([x, dp1])\n    fc2 = keras.layers.Dense(units=60)(concat1)\n    act2 = keras.layers.PReLU()(fc2)\n    bn2 = keras.layers.BatchNormalization()(act2)\n    dp2 = keras.layers.Dropout(0.2)(bn2)\n    concat2 = keras.layers.Concatenate()([concat1, dp2])\n    fc3 = keras.layers.Dense(units=40)(concat2)\n    act3 = keras.layers.PReLU()(fc3)\n    bn3 = keras.layers.BatchNormalization()(act3)\n    dp3 = keras.layers.Dropout(0.2)(bn3)\n    concat3 = keras.layers.Concatenate([concat2, dp3])\n    output = keras.layers.Dense(units=2, activation='softmax')(concat2)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model\n\ndef train_model(X_train, y_train, X_val, y_val):\n    model = get_model()\n    model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7), loss='mse', metrics=[rmse])\n    er = EarlyStopping(patience=20, min_delta=1e-4, restore_best_weights=True, monitor='val_loss')\n    model.fit(X_train, y_train, epochs=200, callbacks=[er], validation_data=[X_val, y_val], batch_size=batch_size)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rkf = RepeatedKFold(n_splits=5, n_repeats=5)\n\nmodels = []\n\nfor tr_idx, vl_idx in rkf.split(X_train, y_train):\n    \n    x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n    x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n    \n    model = train_model(x_tr, y_tr, x_vl, y_vl)\n    models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"y_pred = np.mean([model.predict(X_test) for model in models], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"l = []\nfor i in range(1920335):\n    for j in [0,3,1,4,2,5]:\n        l.append(str(i)+'_'+str(j))\nsample['TargetId'] = l","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sample['Target'] = y_pred.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sample['temp_1'] = sample['TargetId'].parallel_apply(lambda x : int(x.split('_')[0]))\nsample['temp_2'] = sample['TargetId'].parallel_apply(lambda x : int(x.split('_')[1]))\nsample = sample.sort_values(by=['temp_1', 'temp_2'])\ndel sample['temp_1']\ndel sample['temp_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sample.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission_metric_map","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}