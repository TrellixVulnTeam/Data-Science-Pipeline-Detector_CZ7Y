{"cells":[{"metadata":{},"cell_type":"markdown","source":"## A better baseline using the median and taking into account city/weekend/hour/month\n\t\nI will try to minimize RMSE a bit further from the median using a bit more information:\n\n- City\n- Weekday\n- Month\n- Hour\n\nThis should lower the RMSE a bit further, even taking into account I am leaving some data behind wich I should be able to exploit later.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace 'kaggle-competitions-project' with YOUR OWN project id here --  \nPROJECT_ID = 'kaggle-competitions-project'\n\nfrom google.cloud import bigquery\nclient = bigquery.Client(project=PROJECT_ID, location=\"US\")\ndataset = client.create_dataset('bqml_example', exists_ok=True)\n\nfrom google.cloud.bigquery import magics\nfrom kaggle.gcp import KaggleKernelCredentials\nmagics.context.credentials = KaggleKernelCredentials()\nmagics.context.project = PROJECT_ID\n\n# create a reference to our table\ntable = client.get_table(\"kaggle-competition-datasets.geotab_intersection_congestion.train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext google.cloud.bigquery","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a table with stats summary \n\nFirst, let's jut calculate the median over the city/weekend/month/hour fields.\n\nI will use this SQL construct everywhere to avoid executing the same notebook twice (testing, and submitting - commit - to kaggle).\n\n```sql\nCREATE TABLE IF NOT EXISTS 'tablename'\nAS SELECT << something >>\n;\n\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bigquery \n\ncreate table `kaggle-competitions-project`.kaggle.medianas_01\nas select city,\n       weekend,\n       month,\n       hour,\n       tts20[offset(20)] as time_p20,\n       tts50[offset(50)] as time_p50,\n       tts80[offset(80)] as time_p80,\n       dffs20[offset(20)] as dist_p20,\n       dffs50[offset(50)] as dist_p50,\n       dffs80[offset(80)] as dist_p80\nfrom (select \n       city,\n       weekend,\n       month,\n       hour,\n       approx_quantiles(TotalTimeStopped_p20,100) as tts20,\n       approx_quantiles(TotalTimeStopped_p50,100) as tts50,\n       approx_quantiles(TotalTimeStopped_p80,100) as tts80,\n       approx_quantiles(DistanceToFirstStop_p20,100) as dffs20,\n       approx_quantiles(DistanceToFirstStop_p50,100) as dffs50,\n       approx_quantiles(DistanceToFirstStop_p80,100) as dffs80\n    from `kaggle-competition-datasets`.geotab_intersection_congestion.train\n    group by city, weekend, month, hour\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now just join the test table with the results we got before.\nBest (economical) way to do it for me is a create table if not exists because when the notebook runs it still works.\n\nThe test table has some entries without a matching city/month/weekend/hour pairings in the training set.\nIn this case, instead of producing a NULL value in the join (which is not allowed by kaggle), we set the median of the whole dataset hoping this will lower the RSME: (0, 0, 40, 0, 0, 95.4)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bigquery\n\nCREATE TABLE IF NOT EXISTS `kaggle-competitions-project`.kaggle.baseline_02\nAS SELECT\n    rowID as TargetId,\n    IFNULL(time_p20, 0) as time_p20,\n    IFNULL(time_p50, 0) as time_p50,\n    IFNULL(time_p80, 40) as time_p80,\n    IFNULL(dist_p20, 0) as dist_p20,\n    IFNULL(dist_p50, 0) as dist_p50,\n    IFNULL(dist_p80, 95.4) as dist_p80\nFROM `kaggle-competition-datasets`.geotab_intersection_congestion.test test\nLEFT JOIN `kagglebqml-254810`.kaggle.medianas_01 m01\n  ON test.city = m01.city and\n      test.month = m01.month and\n      test.weekend = m01.weekend and\n      test.hour = m01.hour;","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create submission table\n\nNow we have to create a submission result from the results in the baseline_02 table.\nThis could be done instead of creating the baseline_02 table; but it is easier this way (not cheper, though).\n\nMaybe this could be the a better place to put the IFNULL instead of the baseline_02 table.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bigquery\n\nCREATE TABLE IF NOT EXISTS `kaggle-competitions-project`.kaggle.submission_02\nAS\n   SELECT CONCAT(CAST(TargetID as string), '_0') as TargetId, time_p20 as Target from `kagglebqml-254810`.kaggle.baseline_02\n   UNION ALL\n   SELECT CONCAT(CAST(TargetID as string), '_1') as TargetId, time_p50 as Target from `kagglebqml-254810`.kaggle.baseline_02\n   UNION ALL\n   SELECT CONCAT(CAST(TargetID as string), '_2') as TargetId, time_p80 as Target from `kagglebqml-254810`.kaggle.baseline_02\n   UNION ALL\n   SELECT CONCAT(CAST(TargetID as string), '_3') as TargetId, dist_p20 as Target from `kagglebqml-254810`.kaggle.baseline_02\n   UNION ALL\n   SELECT CONCAT(CAST(TargetID as string), '_4') as TargetId, dist_p50 as Target from `kagglebqml-254810`.kaggle.baseline_02\n   UNION ALL\n   SELECT CONCAT(CAST(TargetID as string), '_5') as TargetId, dist_p80 as Target from `kagglebqml-254810`.kaggle.baseline_02\n   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit the data to Kaggle\n\nWe don't need to create a CSV file in this notebook.\nThe best and easy way to do it, is to tell BigQuery to export the data as a CSV file (compressed with gzip) into Google Cloud Storage.\nJust remember to use 'csv.gz' as the file extension."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}