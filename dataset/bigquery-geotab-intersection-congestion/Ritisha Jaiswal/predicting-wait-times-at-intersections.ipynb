{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Objective : \n\nWeâ€™ve all been there: Stuck at a traffic light, only to be given mere seconds to pass through an intersection, behind a parade of other commuters. Imagine if you could help city planners and governments anticipate traffic hot spots ahead of time and reduce the stop-and-go stress of millions of commuters like you.\n\nThe task here is to predict congestion, based on an aggregate measure of stopping distance and waiting times, at intersections in 4 major US cities: Atlanta, Boston, Chicago & Philadelphia.\n\n# About the data\n\nThe data consists of aggregated trip logging metrics from commercial vehicles, such as semi-trucks. The data have been grouped by :\n\n1. intersection\n2. month\n3. hour of day\n4. direction driven through the intersection\n5. whether the day was on a weekend or not\n\nFor each grouping in the test set, you need to make predictions for three different quantiles, that is, **20th, 50th, and 80th percentiles** for:\n\n1. The total time stopped at an intersection \n2. The distance between the intersection and the first place a vehicle stopped while waiting."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/bigquery-geotab-intersection-congestion/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/bigquery-geotab-intersection-congestion/test.csv\")\nsample_df=pd.read_csv(\"/kaggle/input/bigquery-geotab-intersection-congestion/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above info, the categorical features in the data are : \n* EntryStreetName            \n* ExitStreetName             \n* EntryHeading               \n* ExitHeading \n* City\n* Path"},{"metadata":{"trusted":true},"cell_type":"code","source":"#total number of intersections in our dataset\nprint(\"The total number of unique intersections in our dataset are : {}\".format(train_df['IntersectionId'].nunique()))\nprint(\"The total number of Cities in our dataset are : {}\".format(train_df['City'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of intersections in each city\ntrain_df.groupby('City')['IntersectionId'].nunique().plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The maximum number of entry streets for intersections in our dataset is : {}\".format(train_df.groupby('IntersectionId')['EntryStreetName'].nunique().max()))\nprint(\"The average number of entry streets for intersections in our dataset is : {}\".format(train_df.groupby('IntersectionId')['EntryStreetName'].nunique().mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The maximum number of exit streets for intersections in our dataset is : {}\".format(train_df.groupby('IntersectionId')['ExitStreetName'].nunique().max()))\nprint(\"The average number of exit streets for intersections in our dataset is : {}\".format(train_df.groupby('IntersectionId')['ExitStreetName'].nunique().mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforming CAtegorical features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set(rc={'figure.figsize':(11.7,8.27)})\ncorr = train_df.corr()\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rowID\ntrain_df.drop('RowId', axis=1, inplace=True)\ntest_df.drop('RowId', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check cardinality of all the categorical variables\nfor y in train_df.columns:\n    if(train_df[y].dtype == object):\n          print(\"The caridinality for {} is : {}\".format(y, train_df[y].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df[['IntersectionId', 'Latitude', 'Longitude', 'EntryStreetName', \n              'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend', 'Month', 'Path','City']]\ny1 = train_df[\"TotalTimeStopped_p20\"]\ny2 = train_df[\"TotalTimeStopped_p50\"]\ny3 = train_df[\"TotalTimeStopped_p80\"]\ny4 = train_df[\"DistanceToFirstStop_p20\"]\ny5 = train_df[\"DistanceToFirstStop_p50\"]\ny6 = train_df[\"DistanceToFirstStop_p80\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Dummies for train Data\ndfen = pd.get_dummies(X[\"EntryHeading\"],prefix = 'entry')\ndfex = pd.get_dummies(X[\"ExitHeading\"],prefix = 'exit')\ncity = pd.get_dummies(X[\"City\"],prefix = 'city')\n\nX = pd.concat([X,dfen],axis=1)\nX = pd.concat([X,dfex],axis=1)\nX = pd.concat([X,city],axis=1)\n\nX.drop(\"EntryHeading\", axis=1, inplace=True)\nX.drop(\"ExitHeading\", axis=1, inplace=True)\nX.drop(\"City\", axis=1, inplace=True)\n\n#Creating Dummies for test Data\ndfent = pd.get_dummies(test_df[\"EntryHeading\"],prefix = 'entry')\ndfext = pd.get_dummies(test_df[\"ExitHeading\"],prefix = 'exit')\ncity_test = pd.get_dummies(test_df[\"City\"],prefix = 'city')\n\ntest_df = pd.concat([test_df,dfent],axis=1)\ntest_df = pd.concat([test_df,dfext],axis=1)\ntest_df = pd.concat([test_df,city_test],axis=1)\n\ntest_df.drop(\"EntryHeading\", axis=1, inplace=True)\ntest_df.drop(\"ExitHeading\", axis=1, inplace=True)\ntest_df.drop(\"City\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing rows having NaN values for EntryStreetName and ExitStreetName\n#Path being concatenation of EntryStreetName_EntryHeading_ExitStreetName_ExitHeading\ntrain_df[train_df.isnull().any(axis=1)].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling rows with NaN's\nX.fillna(\"nan\", inplace=True)\ntest_df.fillna(\"nan\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since Path column is just concatenation of texts from EntryStreetName_EntryHeading_ExitStreetName_ExitHeading it doesn't provide any significant info to the model so let's drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop('Path', axis=1, inplace=True)\ntest_df.drop('Path', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX['EntryStreetName'] = le.fit_transform(X['EntryStreetName'])\ntest_df['EntryStreetName'] = le.fit_transform(test_df['EntryStreetName'])\n\nX['ExitStreetName'] = le.fit_transform(X['ExitStreetName'])\ntest_df['ExitStreetName'] = le.fit_transform(test_df['ExitStreetName'])\n\n# X['Path'] = le.fit_transform(X['Path'])\n# test_df['Path'] = le.fit_transform(test_df['Path'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import lightgbm as lgb\n# from sklearn.model_selection import KFold, StratifiedKFold\n# def kfold_lightgbm(target, num_folds= 10):\n#     print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(X.shape, test_df.shape))\n#     folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n#     # Create arrays and dataframes to store results\n#     oof_preds = np.zeros(X.shape[0])\n#     sub_preds = np.zeros(test_df.shape[0])\n\n#     for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X,target)):\n#         train_x, train_y = X.iloc[train_idx], target.iloc[train_idx]\n#         valid_x, valid_y = X.iloc[valid_idx], target.iloc[valid_idx]\n\n#         # LightGBM parameters found by Bayesian optimization\n#         clf = lgb.LGBMRegressor(\n#             nthread=4,\n#             n_estimators=10000,\n#             learning_rate=0.001,\n#             num_leaves=34,\n#             colsample_bytree=0.9497036,\n#             subsample=0.8715623,\n#             max_depth=8,\n#             reg_alpha=0.041545473,\n#             reg_lambda=0.0735294,\n#             min_split_gain=0.0222415,\n#             min_child_weight=39.3259775,\n#             silent=-1,\n#             verbose=-1)\n\n#         clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n#             eval_metric= 'rmse', verbose= 500, early_stopping_rounds= 200)\n\n#         oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration_)\n#         sub_preds += clf.predict(test_df, num_iteration=clf.best_iteration_) / folds.n_splits\n#         return sub_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# pred1 = kfold_lightgbm(y1)\n# pred2 = kfold_lightgbm(y2)\n# pred3 = kfold_lightgbm(y3)\n# pred4 = kfold_lightgbm(y4)\n# pred5 = kfold_lightgbm(y5)\n# pred6 = kfold_lightgbm(y6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Appending all predictions\n# prediction = []\n# for i in range(len(pred1)):\n#     for j in [pred1,pred2,pred3,pred4,pred5,pred6]:\n#         prediction.append(j[i])\n        \n# sample_df[\"Target\"] = prediction\n# sample_df.to_csv(\"Submission_CB.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trying H2o AutoML and evaluating it's performance on our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = h2o.import_file(\"/kaggle/input/bigquery-geotab-intersection-congestion/train.csv\")\nh2o_test = h2o.import_file(\"/kaggle/input/bigquery-geotab-intersection-congestion/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1 = \"TotalTimeStopped_p20\"\ny2 = \"TotalTimeStopped_p50\"\ny3 = \"TotalTimeStopped_p80\"\ny4 = \"DistanceToFirstStop_p20\"\ny5 = \"DistanceToFirstStop_p50\"\ny6 = \"DistanceToFirstStop_p80\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splits = df.split_frame(ratios = [0.8], seed = 1)\ntrain = splits[0]\ntest = splits[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml_1 = H2OAutoML(max_runtime_secs = 300, seed = 1)\naml_1.train(y = y1, training_frame = df)\nprint(aml_1.leader.model_performance(test))\naml_1.leaderboard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml_2 = H2OAutoML(max_runtime_secs = 300, seed = 1)\naml_2.train(y = y2, training_frame = df)\nprint(aml_2.leader.model_performance(test))\naml_2.leaderboard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml_3 = H2OAutoML(max_runtime_secs = 300, seed = 1)\naml_3.train(y = y3, training_frame = df)\nprint(aml_3.leader.model_performance(test))\naml_3.leaderboard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml_4 = H2OAutoML(max_runtime_secs = 300, seed = 1)\naml_4.train(y = y4, training_frame = df)\nprint(aml_4.leader.model_performance(test))\naml_4.leaderboard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml_5 = H2OAutoML(max_runtime_secs = 300, seed = 1)\naml_5.train(y = y5, training_frame = df)\nprint(aml_5.leader.model_performance(test))\naml_5.leaderboard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml_6 = H2OAutoML(max_runtime_secs = 300, seed = 1)\naml_6.train(y = y6, training_frame = df)\nprint(aml_6.leader.model_performance(test))\naml_6.leaderboard.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trying Linear models with regularization"},{"metadata":{"trusted":true},"cell_type":"code","source":"y1 = train_df[\"TotalTimeStopped_p20\"]\ny2 = train_df[\"TotalTimeStopped_p50\"]\ny3 = train_df[\"TotalTimeStopped_p80\"]\ny4 = train_df[\"DistanceToFirstStop_p20\"]\ny5 = train_df[\"DistanceToFirstStop_p50\"]\ny6 = train_df[\"DistanceToFirstStop_p80\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (12.0, 6.0)\ny6_val = pd.DataFrame({\"y6\":train_df[\"DistanceToFirstStop_p80\"], \"log(y6 + 1)\":np.log1p(train_df[\"DistanceToFirstStop_p80\"])})\ny6_val.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model,y_value):\n    rmse= np.sqrt(-cross_val_score(model, X, y_value, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ridge = Ridge()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alphas = [0.01, 0.05, 0.1, 0.3]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha),y1).mean() \n            for alpha in alphas]\n\ncv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_ridge_2 = [rmse_cv(Ridge(alpha = alpha),y2).mean() \n            for alpha in alphas]\n\ncv_ridge_2 = pd.Series(cv_ridge_2, index = alphas)\ncv_ridge_2.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_ridge_3 = [rmse_cv(Ridge(alpha = alpha),y3).mean() \n            for alpha in alphas]\n\ncv_ridge_3 = pd.Series(cv_ridge_3, index = alphas)\ncv_ridge_3.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_ridge_4 = [rmse_cv(Ridge(alpha = alpha),y4).mean() \n            for alpha in alphas]\n\ncv_ridge_4 = pd.Series(cv_ridge_4, index = alphas)\ncv_ridge_4.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_ridge_5 = [rmse_cv(Ridge(alpha = alpha),y5).mean() \n            for alpha in alphas]\n\ncv_ridge_5 = pd.Series(cv_ridge_5, index = alphas)\ncv_ridge_5.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y6 = np.log1p(train_df[\"DistanceToFirstStop_p80\"])\ncv_ridge_6 = [rmse_cv(Ridge(alpha = alpha),y6).mean() \n            for alpha in alphas]\n\ncv_ridge_6 = pd.Series(cv_ridge_6, index = alphas)\ncv_ridge_6.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be continued\n\n**Kindly UPVOTE if you find it insightful. Will mean a lot to me!**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}