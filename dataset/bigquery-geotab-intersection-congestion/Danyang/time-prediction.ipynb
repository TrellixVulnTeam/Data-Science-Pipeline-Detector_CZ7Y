{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport os\nimport datetime as dt\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom scipy.signal import savgol_filter\nfrom sklearn.preprocessing import scale \nfrom sklearn import model_selection\nfrom sys import stdout\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import cross_val_predict\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_users = pd.read_csv('../input/bigquery-geotab-intersection-congestion/train.csv')\ntest_users = pd.read_csv('../input/bigquery-geotab-intersection-congestion/test.csv')\nprint(\"There were\", train_users.shape[0], \"observations in the training set and\", test_users.shape[0], \"in the test set.\")\nprint(\"In total there were\", train_users.shape[0] + test_users.shape[0], \"observations.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\ncor = train_users.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_users.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users['City'].unique(), train_users['Hour'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"intersaction_city=train_users[['City','IntersectionId']].drop_duplicates()\n\nintersaction_city.groupby(['City'])['IntersectionId'].aggregate('count').reset_index().sort_values('IntersectionId', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_counts(train_users):\n   for i in train_users.columns:\n       count = train_users[i].nunique()\n       print(i, \": \", count)\nunique_counts(train_users)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.distplot(train_users.Hour.dropna(), rug=True)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x='Month', data=train_users)\nplt.xlabel('Month')\nplt.ylabel('Number of observations')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x='Hour', data=train_users)\nplt.xlabel('Hour')\nplt.ylabel('Number of observations')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,12))\n\nplt.subplot(211)\ng = sns.countplot(x=\"Hour\", data=train_users, hue='City', dodge=True)\ng.set_title(\"Hour Count Distribution by City\", fontsize=20)\ng.set_ylabel(\"Count\",fontsize= 17)\ng.set_xlabel(\"Hours of Day\", fontsize=17)\nsizes=[]\nfor p in g.patches:\n    height = p.get_height()\n    sizes.append(height)\n\ng.set_ylim(0, max(sizes) * 1.15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,12))\n\nplt.subplot(211)\ng = sns.countplot(x=\"Month\", data=train_users, hue='City', dodge=True)\ng.set_title(\"Month Count Distribution by City\", fontsize=20)\ng.set_ylabel(\"Count\",fontsize= 17)\ng.set_xlabel(\"Month\", fontsize=17)\nsizes=[]\nfor p in g.patches:\n    height = p.get_height()\n    sizes.append(height)\n\ng.set_ylim(0, max(sizes) * 1.15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1 = train_users['TotalTimeStopped_p20']\ny2 = train_users['TotalTimeStopped_p50']\ny3 = train_users['TotalTimeStopped_p80']\ny4 = train_users['DistanceToFirstStop_p20']\ny5 = train_users['DistanceToFirstStop_p50']   \ny6 = train_users['DistanceToFirstStop_p80']   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Entry = pd.get_dummies(train_users[\"EntryHeading\"],prefix = 'EN')\nExit = pd.get_dummies(train_users[\"ExitHeading\"],prefix = 'EX')\nC = pd.get_dummies(train_users[\"City\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users = train_users.merge(\n    train_users.groupby('City')[['Latitude', 'Longitude']].mean(),\n    left_on='City', right_index=True, suffixes=['', 'Dist']\n)\ntrain_users.LatitudeDist = (np.abs(train_users.Latitude - train_users.LatitudeDist)).round(2)\ntrain_users.LongitudeDist = (np.abs(train_users.Longitude - train_users.LongitudeDist)).round(2)\ntrain_users['CenterDistL1'] = (train_users.LatitudeDist + train_users.LongitudeDist).round(2)\ntrain_users['CenterDistL2'] = (np.sqrt((train_users.LatitudeDist ** 2 + train_users.LongitudeDist ** 2))).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users = pd.concat([train_users,Entry],axis=1)\ntrain_users = pd.concat([train_users,Exit],axis=1)\ntrain_users = pd.concat([train_users,C],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train_users[['Hour','Weekend','Month','EN_S','EN_SW','EN_SE','EN_N','EN_NW','EN_NE','EN_W','EN_E','EX_S','EX_SW','EX_SE','EX_N','EX_NW','EX_NE','EX_W','EX_E','Atlanta','Boston','Chicago','Philadelphia']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimise_pls_cv(X, y, n_comp, plot_components=True):\n    '''Run PLS including a variable number of components, up to n_comp,\n       and calculate MSE '''\n    mse = []\n    component = np.arange(1, n_comp)\n    for i in component:\n        pls = PLSRegression(n_components=i)\n        # Cross-validation\n        y_cv = cross_val_predict(pls, X, y, cv=10)\n        mse.append(mean_squared_error(y, y_cv))\n        comp = 100*(i+1)/40\n        # Trick to update status on the same line\n        stdout.write(\"\\r%d%% completed\" % comp)\n        stdout.flush()\n    stdout.write(\"\\n\")\n    # Calculate and print the position of minimum in MSE\n    msemin = np.argmin(mse)\n    print(\"Suggested number of components: \", msemin+1)\n    stdout.write(\"\\n\")\n    if plot_components is True:\n        with plt.style.context(('ggplot')):\n            plt.plot(component, np.array(mse), '-v', color = 'blue', mfc='blue')\n            plt.plot(component[msemin], np.array(mse)[msemin], 'P', ms=10, mfc='red')\n            plt.xlabel('Number of PLS components')\n            plt.ylabel('MSE')\n            plt.title('PLS')\n            plt.xlim(left=-1)\n        plt.show()\n    # Define PLS object with optimal number of components\n    pls_opt = PLSRegression(n_components=msemin+1)\n    # Fir to the entire dataset\n    pls_opt.fit(X, y)\n    y_c = pls_opt.predict(X)\n    # Cross-validation\n    y_cv = cross_val_predict(pls_opt, X, y, cv=10)\n    # Calculate scores for calibration and cross-validation\n    score_c = r2_score(y, y_c)\n    score_cv = r2_score(y, y_cv)\n    # Calculate mean squared error for calibration and cross validation\n    mse_c = mean_squared_error(y, y_c)\n    mse_cv = mean_squared_error(y, y_cv)\n    print('R2 calib: %5.3f'  % score_c)\n    print('R2 CV: %5.3f'  % score_cv)\n    print('MSE calib: %5.3f' % mse_c)\n    print('MSE CV: %5.3f' % mse_cv)\n    # Plot regression and figures of merit\n    rangey = max(y) - min(y)\n    rangex = max(y_c) - min(y_c)\n    # Fit a line to the CV vs response\n    z = np.polyfit(y, y_c, 1)\n    with plt.style.context(('ggplot')):\n        fig, ax = plt.subplots(figsize=(9, 5))\n        ax.scatter(y_c, y, c='red', edgecolors='k')\n        #Plot the best fit line\n        ax.plot(np.polyval(z,y), y, c='blue', linewidth=1)\n        #Plot the ideal 1:1 line\n        ax.plot(y, y, color='green', linewidth=1)\n        plt.title('$R^{2}$ (CV): '+str(score_cv))\n        plt.xlabel('Predicted $^{\\circ}$Brix')\n        plt.ylabel('Measured $^{\\circ}$Brix')\n        plt.show()\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimise_pls_cv(X,y1, 20, plot_components=True)\n#The lowest RMSE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimise_pls_cv(X,y2, 20, plot_components=True)\n#R2 calib: 0.014\n#R2 CV: 0.010\n#MSE calib: 238.604\n#MSE CV: 239.453","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimise_pls_cv(X,y3, 20, plot_components=True)\n#R2 calib: 0.020\n#R2 CV: 0.013\n#MSE calib: 775.134\n#MSE CV: 780.114","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimise_pls_cv(X,y4, 20, plot_components=True)\n#R2 calib: 0.003\n#R2 CV: 0.001\n#MSE calib: 781.981\n#MSE CV: 783.262","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimise_pls_cv(X,y5, 20, plot_components=True)\n#R2 calib: 0.006\n#R2 CV: 0.003\n#MSE calib: 5111.828\n#MSE CV: 5130.587","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimise_pls_cv(X,y6, 20, plot_components=True)\n#R2 calib: 0.006\n#R2 CV: -0.000\n#MSE calib: 23172.832\n#MSE CV: 23313.593","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results=sm.OLS(y1,X).fit()\nresults.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_users.columns # This will show all the column names\ntest_users.head(10) # Show first 10 records of dataframe\ntest_users.describe() #You can look at summary of numerical fields by using describe() function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Entry2 = pd.get_dummies(test_users[\"EntryHeading\"],prefix = 'EN')\nExit2 = pd.get_dummies(test_users[\"ExitHeading\"],prefix = 'EX')\nC2 = pd.get_dummies(test_users[\"City\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_users = test_users.merge(\n    test_users.groupby('City')[['Latitude', 'Longitude']].mean(),\n    left_on='City', right_index=True, suffixes=['', 'Dist']\n)\ntest_users.LatitudeDist = (np.abs(test_users.Latitude - test_users.LatitudeDist)).round(2)\ntest_users.LongitudeDist = (np.abs(test_users.Longitude - test_users.LongitudeDist)).round(2)\ntest_users['CenterDistL1'] = (test_users.LatitudeDist + test_users.LongitudeDist).round(2)\ntest_users['CenterDistL2'] = (np.sqrt((test_users.LatitudeDist ** 2 + test_users.LongitudeDist ** 2))).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_users = pd.concat([test_users,Entry2],axis=1)\ntest_users = pd.concat([test_users,Exit2],axis=1)\ntest_users = pd.concat([test_users,C2],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=test_users[['Hour','Weekend','Month','EN_S','EN_SW','EN_SE','EN_N','EN_NW','EN_NE','EN_W','EN_E','EX_S','EX_SW','EX_SE','EX_N','EX_NW','EX_NE','EX_W','EX_E','Atlanta','Boston','Chicago','Philadelphia']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\ncb_model= CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cb_model.fit(X, y1)\n#pred_CB1=cb_model.predict(x)\n#cb_model.fit(X, y2)\n#pred_CB2=cb_model.predict(x)\n#cb_model.fit(X, y3)\n#pred_CB3=cb_model.predict(x)\n#cb_model.fit(X, y4)\n#pred_CB4=cb_model.predict(x)\n#cb_model.fit(X, y5)\n#pred_CB5=cb_model.predict(x)\n#cb_model.fit(X, y6)\n#pred_CB6=cb_model.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction_CB = []\n#for i in range(len(pred_CB1)):\n    #for j in [pred_CB1,pred_CB2,pred_CB3,pred_CB4,pred_CB5,pred_CB6]:\n        #prediction_CB.append(j[i])\n        \n#submission_CB = pd.read_csv(\"../input/bigquery-geotab-intersection-congestion/sample_submission.csv\")\n#submission_CB[\"Target\"] = prediction_CB\n#submission_CB.to_csv(\"Submission_CB.csv\",index = False)\n#RMSE=79","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users['IsTrain'] = 1\ntest_users['IsTrain'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole = pd.concat([train_users, test_users], sort=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole['random'] = np.random.rand(len(whole))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_stats = pd.concat([\n    pd.DataFrame(whole.count()).rename(columns={0: 'cnt'}),\n    pd.DataFrame(whole.nunique()).rename(columns={0: 'unique'}),\n], sort=True, axis=1)\ncolumn_stats.sort_values(by='unique')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_columns = list(column_stats[column_stats.cnt < 10 ** 6].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = [\n    'TotalTimeStopped_p20',\n    'TotalTimeStopped_p50',\n    'TotalTimeStopped_p80',\n    'DistanceToFirstStop_p20',\n    'DistanceToFirstStop_p50',\n    'DistanceToFirstStop_p80',\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_not_use = train_columns + ['IsTrain', 'Path', 'RowId', 'IntersectionId',\n                              'random','City','EntryHeading','ExitHeading','EntryStreetName','ExitStreetName']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = [c for c in whole.columns if c not in do_not_use]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fix = {\n    'lambda': 1., 'nthread': 4, 'booster': 'gbtree',\n    'silent': 1, 'eval_metric': 'rmse',\n    'objective': 'reg:squarederror'}\nconfig = dict(min_child_weight=20,\n              eta=0.05, colsample_bytree=0.6,\n              max_depth=20, subsample=0.8)\nconfig.update(fix)\nnround = 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_SAMPLE_SIZE = 0.7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole = whole.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_mse = 0.0\nsubmission_parts = []\nfor i, target in enumerate(target_columns):\n    train_idx = whole.random < TRAIN_SAMPLE_SIZE\n    valid_idx = whole.random >= TRAIN_SAMPLE_SIZE\n    Xtr = whole[train_idx][feature_columns]\n    Xv = whole[valid_idx][feature_columns]\n    ytr = whole[train_idx][target].values\n    yv = whole[valid_idx][target].values\n    print(Xtr.shape, ytr.shape, Xv.shape, yv.shape)\n    dtrain = xgb.DMatrix(Xtr, label=ytr)\n    dvalid = xgb.DMatrix(Xv, label=yv)\n    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n    model = xgb.train(config, dtrain, nround, evals=watchlist,\n                      verbose_eval=50, early_stopping_rounds=50)\n    pv = model.predict(dvalid)\n    mse = np.mean((yv - pv) ** 2)\n    total_mse += mse / 6\n    print(target, 'rmse', np.sqrt(mse))\n    df = pd.DataFrame({\n        'Target': model.predict(xgb.DMatrix(test_users[feature_columns])),\n        'TargetId': test_users.RowId.astype(str) + '_' + str(i)})\n    submission_parts.append(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(total_mse)\nprint('Total rmse', rmse)\nsubmission = pd.concat(submission_parts, sort=True)\nsubmission.to_csv('submission.csv', index=False)\n#RMSE 41","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def run_lgb_f(train_users, test_users):\n    #all_preds = {0 : [], 1 : [], 2 : [], 3 : [], 4 : [], 5 : []}\n    #all_target = [y1, y2, y3, y4, y5, y6]\n    #nfold = 5\n    #kf = KFold(n_splits=nfold, random_state=228, shuffle=True)\n    #for i in range(len(all_preds)):\n        #print('Training and predicting for target {}'.format(i+1))\n        #oof = np.zeros(len(train_users))\n        #all_preds[i] = np.zeros(len(test_users))\n        #n = 1\n        #for train_index, valid_index in kf.split(all_target[i]):\n            #print(\"fold {}\".format(n))\n            #xg_train = lgb.Dataset(train_users.iloc[train_index],\n                                   #label=all_target[i][train_index]\n                                   #)\n            #xg_valid = lgb.Dataset(train_users.iloc[valid_index],\n                                   #label=all_target[i][valid_index]\n                                   #)\n            #clf = lgb.train(param, xg_train, 100000, valid_sets=[xg_train, xg_valid], \n                            #verbose_eval=500, early_stopping_rounds=100)\n            #oof[valid_index] = clf.predict(train_users.iloc[valid_index], num_iteration=clf.best_iteration) \n\n            #all_preds[i] += clf.predict(test_users, num_iteration=clf.best_iteration) / nfold\n            #n = n + 1\n            #print(\"\\n\\nCV RMSE: {:<0.4f}\".format(np.sqrt(mean_squared_error(all_target[i], oof))))\n    #return all_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#param = {'application': 'regression', \n         #'learning_rate': 0.05, \n         #'metric': 'rmse', \n         #'seed': 42, \n         #'bagging_fraction': 0.7, \n         #'feature_fraction': 0.9, \n         #'lambda_l1': 0.0, \n         #'lambda_l2': 5.0, \n         #'max_depth': 30, \n         #'min_child_weight': 50.0, \n         #'min_split_gain': 0.1, \n         #'num_leaves': 230}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_preds = run_lgb_f(train_users[feature_columns], test_users[feature_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission = pd.read_csv('/kaggle/input/bigquery-geotab-intersection-congestion/sample_submission.csv')\n#data = pd.DataFrame(all_preds).stack()\n#data = pd.DataFrame(data)\n#submission['Target'] = data[0].values\n#submission.to_csv('submission.csv', index=False)\n#RMSE 80-84","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}