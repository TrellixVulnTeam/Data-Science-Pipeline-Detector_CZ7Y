{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nimport pandas as pd\nimport numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Experiemnt**\n\nI simply assumed that the intersection counted on the datasets reflected denseness of that area, and I want to see how this denseness affects the targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/bigquery-geotab-intersection-congestion/train.csv')\ntest = pd.read_csv('/kaggle/input/bigquery-geotab-intersection-congestion/test.csv')\ntrain_df = train.copy()\ntest_df = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#From : https://www.machinelearningplus.com/statistics/mahalanobis-distance/\nimport scipy as sp\nfrom scipy import linalg\ndef mahalanobis(x=None, data=None, cov=None):\n    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n    x    : vector or matrix of data with, say, p columns.\n    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n    \"\"\"\n    x_minus_mu = x - np.mean(data)\n    if not cov:\n        cov = np.cov(data.values.T)\n    inv_covmat = sp.linalg.inv(cov)\n    left_term = np.dot(x_minus_mu, inv_covmat)\n    mahal = np.dot(left_term, x_minus_mu.T)\n    return mahal.diagonal()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def AddMahala(datasets):\n    list = datasets['City'].unique()\n    count = datasets['City'].nunique()\n    datasets['Mahalanobis'] = np.nan\n  \n    for i in range(count):\n    \n        dataset = datasets.loc[datasets['City']==list[i]]\n        distance = dataset[['Longitude', 'Latitude']]\n        distance = distance.round(5)\n        distance = distance.drop_duplicates()\n        mahala = mahalanobis(x=distance, data=distance[['Latitude','Longitude']])\n    \n        count2 = len(mahala)\n        for j in range(count2):\n            idx1 = datasets[['Longitude','Latitude']].round(5)==distance.iloc[j]\n            idx1 = idx1['Longitude']&idx1['Latitude']\n            datasets['Mahalanobis'].loc[idx1] = mahala[j]\n\n    return datasets\n  \n\ntrain_df2 = AddMahala(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I used mahalanobis distance(MD distance) for a method to see the distributions(Intersections), and the center of distance and its distribution are computed by the number of intersections in the city. This center is not the same as the center of city but similar as assumed. we will check later.(There are other metrics available such as taxicab metric.\n\nMahalanobis distance drawn from this formula $(\\textbf{x} - \\bar{\\textbf{x}})^\\top\\textbf{S}^{-1} (\\textbf{x} -  \\bar{\\textbf{x}})$ , where $\\textbf{S}$ is covariance matrix of $\\textbf{x}$ and $\\textbf{x}$ is sample_size by 2 matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotMdist(dataset):\n    fig = plt.figure(figsize=(20,3))\n    count = dataset['City'].nunique()\n    list = dataset['City'].unique()\n    for i in range(count):\n        plt.subplot(1, count, i+1)\n        distance = dataset.loc[dataset['City']==list[i]]\n        ax = sns.distplot(distance['Mahalanobis'],kde=False)\n        ax.set_title(list[i])\n        ax.set_xlabel('Mahalanobis_distance')\n        #dataset[i]['mahala'] = distance['mahala']\n\nplotMdist(train_df2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dist Plot by Mahalanobis Distance**\n\nYou see that the distribution is skewed towards zero. this means the points(Latitude, Longitude) are concentrated in the mean of intersection points. \nNotice: the mean of intersection points will not be the same as center of the city but approximately close to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"def splitwrtMahal(datasets,num):\n  \n    list = datasets['City'].unique()\n    count = len(list)\n    datasets['Mahalcat'] = np.nan\n  \n    for i in range(count):\n    \n        idx = datasets['City']==list[i]\n        dataset = datasets.loc[idx]\n        values = dataset['Mahalanobis']\n        split = np.linspace(0,1,num+1)\n        values = values.quantile(split[1:-1]).values\n        len_val = len(values)\n        for j in (range(len_val+1)):\n            if j ==0:\n                idx1 = dataset['Mahalanobis']<values[j]\n            elif 0<j<len_val :\n                idx1 = (dataset['Mahalanobis']>=values[j-1])&(dataset['Mahalanobis']<values[j])\n            else:\n                idx1 = dataset['Mahalanobis']>=values[j-1]\n\n        \n            dataset['Mahalcat'].loc[idx1] = j\n        datasets['Mahalcat'].loc[idx] = dataset['Mahalcat']\n    return datasets\ntrain_df3 = splitwrtMahal(train_df2,4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df4 = train_df3.loc[train_df3['TotalTimeStopped_p80']>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df3.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df3.groupby('Mahalcat').TotalTimeStopped_p80.count().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Equally splitted as desired."},{"metadata":{},"cell_type":"markdown","source":"**Plot by Categorized Mahalanobis Distance**\n\nWe can see something different among catorgries. Although this distance does not exactly catch center of distance this categorization is still useful. We can use this to point out specific categories(areas) to delve into.\nCategory 2 contains the center of city in Chicago as you will see below That's why green line is having the highest TotalTimeStopped_80p. In Philadephia, Distance catch the center."},{"metadata":{"trusted":true},"cell_type":"code","source":"check1 = ['DistanceToFirstStop_p80','TotalTimeStopped_p80']\ncheck2 = ['Hour','Month','Weekend']\ndef MahalPlot(datasets,check1,check2):\n    \n    count = datasets['City'].nunique()\n    list = datasets['City'].unique()\n    fig,ax =plt.subplots(1,4)\n    fig.set_size_inches(15, 3)\n    for i in range(count):\n        dataset = datasets.loc[datasets['City']==list[i]]\n        \n        if check2 =='Weekend':\n            dataset.groupby([check2,'Mahalcat'])[check1].mean().unstack().plot(ax=ax[i],kind='bar')\n        else:\n            dataset.groupby([check2,'Mahalcat'])[check1].mean().unstack().plot(ax=ax[i])\n        if i==0:\n            ax[i].set_ylabel(check1)\n        if check2 == 'Month':\n            ax[i].set(xlim=(6, 12))\n        ax[i].set_title(list[i])\n        \n    plt.show()\nMahalPlot(train_df3,check1[0],check2[0])\nMahalPlot(train_df3,check1[0],check2[1])\nMahalPlot(train_df3,check1[0],check2[2])\nMahalPlot(train_df3,check1[1],check2[0])\nMahalPlot(train_df3,check1[1],check2[1])\nMahalPlot(train_df3,check1[1],check2[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Delete 0's from TotalTimeStoppped_p80**"},{"metadata":{"trusted":true},"cell_type":"code","source":"MahalPlot(train_df4,check1[0],check2[0])\nMahalPlot(train_df4,check1[0],check2[1])\nMahalPlot(train_df4,check1[0],check2[2])\nMahalPlot(train_df4,check1[1],check2[0])\nMahalPlot(train_df4,check1[1],check2[1])\nMahalPlot(train_df4,check1[1],check2[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing MD distance in Geomap**\n\nI separated Traffic map with respect to its categorized mahalanobis distance (0,1) and (2,3). The center of distribution may not the same as the center of city you see in the example below (Chicago), and Blue and Red dots indicate above 90 percentile, below 10 percentile of the mean of TotalTimeStopped_80p."},{"metadata":{"trusted":true},"cell_type":"code","source":"def trafficMap(dataset):\n  \n    fig,ax = plt.subplots(figsize = (10,10))\n    crs = {'init' :'epsg:4326'}\n    city = dataset['City'].unique()[0]\n    geometry = [Point(xy) for xy in zip(dataset['Longitude'],dataset['Latitude'])]\n    geo_df = gpd.GeoDataFrame(dataset, crs = crs\n                          , geometry = geometry)\n    minx, miny, maxx, maxy = geo_df.total_bounds\n    ax.set_xlim(minx-0.01, maxx+0.01)\n    ax.set_ylim(miny-0.01, maxy+0.01)\n    abc = dataset.groupby(['IntersectionId']).TotalTimeStopped_p80.mean().quantile(.90)\n    abc1 = dataset.groupby(['IntersectionId']).TotalTimeStopped_p80.mean().quantile(.10)\n    geo_df[geo_df['TotalTimeStopped_p80']>=abc].plot(ax = ax, markersize = 0.8, color='b', marker='*', label='5')\n    geo_df[(geo_df['TotalTimeStopped_p80']<=abc1)].plot(ax = ax, markersize = 0.2, color='r', marker='*', label='5')\n  \n    ax.set_title(city)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a2 = train_df3.loc[(train_df3['Mahalcat']<=1)&(train_df3['City']=='Chicago')]\ntrafficMap(a2)\na2 = train_df3.loc[(train_df3['Mahalcat']>1)&(train_df3['City']=='Chicago')]\ntrafficMap(a2)\na2 = train_df3.loc[(train_df3['Mahalcat']<=1)&(train_df3['City']=='Philadelphia')]\ntrafficMap(a2)\na2 = train_df3.loc[(train_df3['Mahalcat']>1)&(train_df3['City']=='Philadelphia')]\ntrafficMap(a2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df3.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Imputing Missings**\n\nWe have missing values in EntryStreetName and ExitStreetName, and we many not need these since it is already contained in Path XD. There is a way to extract these two from Path by simple code."},{"metadata":{"trusted":true},"cell_type":"code","source":"# This...\ntrain_df3['Entry']=train_df['Path'].str.split(\"_\").str.get(0)\ntrain_df3['Exit']=train_df['Path'].str.split(\"_\").str.get(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df3.groupby(['Entry','Exit']).DistanceToFirstStop_p80.mean()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}