{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/effnetpytorch/EfficientNet-PyTorch-master/\n!pip install ../input/pytorchmetriclearning\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport multiprocessing\n\nfrom kaggle_secrets import UserSecretsClient\n\n# from skimage.io import imread\nimport cv2\n\nfrom skimage.transform import resize\nimport numpy as np\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n\ntrain_df = pd.read_csv(\"../input/hotel-id-2021-fgvc8/train.csv\")\nn_classes = len(train_df['hotel_id'].value_counts())\n\nle.fit(train_df['hotel_id'])\ntrain_df['label'] = le.transform(train_df['hotel_id'])\nclass_map = dict(sorted(train_df[['label', 'hotel_id']].values.tolist()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass HotelDataset(torch.utils.data.Dataset):\n    \"\"\"Some Information about CaliforniaDataset\"\"\"\n    def __init__(self, x_set, y_set, img_size = (224, 224), transform = None, training = True):\n        super(HotelDataset, self).__init__()\n\n        self.x_set = x_set\n        self.training = training\n        if training == True:\n            self.y_set = torch.nn.functional.one_hot(y_set)\n        self.img_size = img_size\n        self.transform = transform\n\n    def __getitem__(self, index):\n        #print(self.x_set[index])\n        #print(self.x_set[index])\n        x = cv2.resize(cv2.imread(self.x_set[index]), dsize = self.img_size)\n        #print(x.shape)\n        #x = torchvision.transforms.functional.to_tensor(x)\n        if self.training == True:\n            y = self.y_set[index]\n            return (x, y, index)\n        if self.transform is not None:\n            x = self.transform(x)\n        return (x, index)\n\n    def __len__(self):\n        return len(self.x_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom efficientnet_pytorch import EfficientNet\nfrom torch import nn\nclass MLP(nn.Module):\n    def __init__(self, layers_size,  final_softmax=False, type = \"embedding\"):\n        super(MLP, self).__init__()\n        layers_list = []\n        for i in range(1, len(layers_size) - 1):\n            layers_list.append(nn.Linear(layers_size[i - 1], layers_size[i]))\n            layers_list.append(nn.BatchNorm1d(num_features = layers_size[i]))\n            layers_list.append(nn.Tanh())\n        layers_list.append(nn.Linear(layers_size[-2], layers_size[-1]))\n        if final_softmax:\n            layers_list.append(nn.Softmax(dim = 1))\n        else:\n            layers_list.append(nn.Tanh())\n        self.net = nn.Sequential(*layers_list)\n    \n    def forward(self, x):\n        return self.net(x)\n        \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DIR = \"../input/hotel-id-2021-fgvc8/test_images/\"\npretrained_dir = \"../input/savedmodelbatchnorm/example_saved_models/\"\nX_file_name = [name for name in os.listdir(TEST_DIR)]\nX_test = [TEST_DIR + name for name in X_file_name]\nX_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Set trunk model and replace the softmax layer with an identity function\ntrunk = EfficientNet.from_name('efficientnet-b0')\ntrunk_output_size = trunk._fc.out_features\n\ntrunk = (trunk.to(device))\n\n# Set embedder model. This takes in the output of the trunk and outputs 64 dimensional embeddings\nembedder = (MLP([trunk_output_size, 512, 256]).to(device))\n\n# Set the classifier. The classifier will take the embeddings and output a 50 dimensional vector.\n# (Our training set will consist of the first 50 classes of the CIFAR100 dataset.)\n# We'll specify the classification loss further down in the code.\nclassifier = (MLP([256, 256, n_classes], final_softmax = True)).to(device)\n\n# Set optimizers\ntrunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001, weight_decay=0.0001)\nembedder_optimizer = torch.optim.Adam(embedder.parameters(), lr=0.001, weight_decay=0.0001)\nclassifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001, weight_decay=0.0001)\n\n# Set the image transforms\ntrain_transform = transforms.Compose([transforms.ToTensor(),\n                                    #transforms.Resize(224, 224),\n                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\nval_transform = transforms.Compose([transforms.ToTensor(),\n                                    #transforms.Resize(224, 224),\n                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n\n\n\n\ntrunk.load_state_dict(torch.load(pretrained_dir + 'trunk_best3.pth'))\nembedder.load_state_dict(torch.load(pretrained_dir + 'embedder_best3.pth'))\nclassifier.load_state_dict(torch.load(pretrained_dir + 'classifier_best3.pth'))\n\n\n\n# Set the image transforms\ntrain_transform = transforms.Compose([transforms.ToTensor(),\n                                    #transforms.Resize(224, 224),\n                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\nval_transform = transforms.Compose([transforms.ToTensor(),\n                                    #transforms.Resize(224, 224),\n                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testDs = HotelDataset(X_test, None, training = False, transform = val_transform)\ntestDl = torch.utils.data.DataLoader(\n        testDs, \n        batch_size = 1,\n        num_workers = 1,\n        shuffle=False,\n        #sampler=SequentialSampler(validation_dataset),\n        pin_memory=False,\n        #collate_fn=collate_fn,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(trunk, embedder, classifier, device, val_loader, k = 5):\n    s_ls = []\n    with torch.no_grad():\n        trunk.eval()\n        embedder.eval()\n        classifier.eval()\n        for (x, index) in (val_loader):\n            #print(x.shape)\n            x = x.to(device)\n            label = classifier(embedder(trunk(x)))\n            label = torch.squeeze(label)\n            values, indices = label.topk(5, dim = 0)\n            indices = np.array(indices.to('cpu')).tolist()\n            s_ls.append([X_file_name[index], indices])\n            #s_ls.append(label)\n            #print(label)\n    return s_ls\n            \n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl = predict(trunk, embedder, classifier, device, testDl)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for v in cl:\n    n = []\n    for i in v[1]:\n        n.append(class_map[i])\n    v[1] = \" \".join(map(str, n))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ../working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.DataFrame.from_records(cl, columns=['image', 'hotel_id'])\npred_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"60291 50996 45167 26181 52458","metadata":{},"execution_count":null,"outputs":[]}]}