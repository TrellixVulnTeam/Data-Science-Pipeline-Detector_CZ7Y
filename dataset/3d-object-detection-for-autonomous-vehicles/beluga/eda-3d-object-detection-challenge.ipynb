{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is certainly an interesting and challenging competition.\n![gif](https://raw.githubusercontent.com/lyft/nuscenes-devkit/master/notebooks/media/001.gif)\nLets take a look at the 85GB unique dataset!\n\n\n\n**Disclaimer: I do not know anything about 3D object detection nor about Autonomous Vehicles. \nThe notebook is provided \"as is\", without warranty of any kind... :)**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport pandas as pd\nimport datetime as dt\nimport numpy as np\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport datetime as dt\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport warnings\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = 99\nsns.set_palette(sns.color_palette('tab20', 20))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"start = dt.datetime.now()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = '/kaggle/input/3d-object-detection-for-autonomous-vehicles/'\ndirs = os.listdir(base)\nprint(dirs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unique ground truth and submission format\nWe are required to optimize a custom performance metric, the mean average precision[](http://) at different intersection over union (IoU) thresholds."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(base + 'train.csv')\nsample_submission = pd.read_csv(base + 'sample_submission.csv')\nprint(f'train: {train.shape}, sample submission: {sample_submission.shape}')\ntrain.head(2)\nsample_submission.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The annotations in train.csv have the following components:\n* **center_x**, **center_y** and **center_z** are the world coordinates of the center of the 3D bounding volume.\n* **width**, **length** and **height** are the dimensions of the volume.\n* **yaw** is the angle of the volume around the z axis (where y is forward/back, x is left/right, and z is up/down - making 'yaw' the direction the front of the vehicle / bounding box is pointing at while on the ground).\n* **class_name** is the type of object contained by the bounding volume.\n\n\n**We have 638K annotated objects in 22K train samples.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the parsing of prediction strings. Each object should have 8 params\nmax([len(ps.split(' ')) % 8 for ps in train.PredictionString.values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_columns = ['sample_id', 'object_id', 'center_x', 'center_y', 'center_z',\n                  'width', 'length', 'height', 'yaw', 'class_name']\nobjects = []\nfor sample_id, ps in tqdm(train.values[:]):\n    object_params = ps.split()\n    n_objects = len(object_params)\n    for i in range(n_objects // 8):\n        x, y, z, w, l, h, yaw, c = tuple(object_params[i * 8: (i + 1) * 8])\n        objects.append([sample_id, i, x, y, z, w, l, h, yaw, c])\ntrain_objects = pd.DataFrame(\n    objects,\n    columns = object_columns\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in object_columns[2:-1]:\n    train_objects[col] = train_objects[col].astype('float')\ntrain_objects['confidence'] = 1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_objects.groupby('sample_id').count()[['object_id']].hist()\nplt.title('Number of objects per sample')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_objects.shape\ntrain_objects.head()\ntrain_objects.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### Object annotations"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(ncols=3)\nsns.distplot(train_objects.center_x, ax = ax[0])\nsns.distplot(train_objects.center_y, ax = ax[1])\nsns.distplot(train_objects.center_z, ax = ax[2])\nplt.suptitle('X, y, z coord distribution')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(ncols=3)\nsns.distplot(train_objects.width, ax = ax[0])\nsns.distplot(train_objects.length, ax = ax[1])\nsns.distplot(train_objects.height, ax = ax[2])\nplt.suptitle('Width, length, height distribution')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classes\n\nVast majority of the annotated objects is just car. We have other vehicles and pedestrians to detect."},{"metadata":{"trusted":true},"cell_type":"code","source":"class_cnt = train_objects.groupby('class_name').count()[['object_id']].sort_values(by='object_id', ascending=False).reset_index()\nclass_cnt['p'] = class_cnt.object_id / class_cnt.object_id.sum() \nclass_cnt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_objects.groupby('class_name').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sample submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y, z, w, l, h, yaw = train_objects[[\n    'center_x', 'center_y', 'center_z', 'width', 'length', 'height', 'yaw']].mean()\nmean_prediction_string = ' '.join(map(str, [0.9, x, y, z, 10*w, 10*l, h, yaw, 'car']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['PredictionString'] = mean_prediction_string \nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.shape\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in os.listdir(base + 'train_data'):\n    print(f)\n    try:\n        df = pd.read_json(base + 'train_data/' + f)\n        df.shape\n        df.head()\n        df.nunique()\n    except Exception as e:\n        print(e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References\n[1] https://github.com/lyft/nuscenes-devkit"},{"metadata":{"trusted":true},"cell_type":"code","source":"end = dt.datetime.now()\nprint('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}