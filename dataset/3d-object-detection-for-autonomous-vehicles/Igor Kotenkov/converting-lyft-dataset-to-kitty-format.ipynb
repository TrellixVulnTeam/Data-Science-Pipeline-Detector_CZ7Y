{"cells":[{"metadata":{},"cell_type":"markdown","source":"## In this kernel we convert LEVEL5 Lyft data (NuScenes format) to KITTI format, which is usually used in public repositories. After this you can search for repos, that solve KITTI 3d-detection task."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install -qqq -U git+https://github.com/stalkermustang/nuscenes-devkit.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dir with all input data from Kaggle\nINP_DIR = Path('/kaggle/input/3d-object-detection-for-autonomous-vehicles/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dir with index json tables (scenes, categories, logs, etc...)\nTABLES_DIR = INP_DIR.joinpath('train_data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adjust the dataroot parameter below to point to your local dataset path.\n# The correct dataset path contains at least the following four folders (or similar): images, lidar, maps\n!ln -s {INP_DIR}/train_images images\n!ln -s {INP_DIR}/train_maps maps\n!ln -s {INP_DIR}/train_lidar lidar","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA_DIR = Path().absolute() \n# Empty init equals '.'.\n# We use this because we link train dirs to current dir (cell above)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dir to write KITTY-style dataset\nSTORE_DIR = DATA_DIR.joinpath('kitti_format')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m lyft_dataset_sdk.utils.export_kitti nuscenes_gt_to_kitti -h","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convertation to KITTY-format\n!python -m lyft_dataset_sdk.utils.export_kitti nuscenes_gt_to_kitti \\\n        --lyft_dataroot {DATA_DIR} \\\n        --table_folder {TABLES_DIR} \\\n        --samples_count 20 \\\n        --parallel_n_jobs 2 \\\n        --get_all_detections True \\\n        --store_dir {STORE_DIR}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check created (converted) files. velodyne = LiDAR poinclouds data (in binary)\n!ls {STORE_DIR}/velodyne | head -2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# render converted data for check. Currently don't support multithreading :(\n!python -m lyft_dataset_sdk.utils.export_kitti render_kitti \\\n        --store_dir {STORE_DIR}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Script above write images to 'render' folder\n# in store_dir (where we have converted dataset)\nRENDER_DIR = STORE_DIR.joinpath('render')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all rendered files\nall_renders = list(RENDER_DIR.glob('*'))\nall_renders.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# render radar data (bird view) and camera data with bboxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image.open(all_renders[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image.open(all_renders[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I'm use rendering only for check success converting. \n\n## Can be used to visualize NN predictions for test lyft set (visual metric estimation :D)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf {STORE_DIR}","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}