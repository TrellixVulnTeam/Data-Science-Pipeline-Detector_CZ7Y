{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Low memory use : be careful**\n\nI share this notebook in order to warn about the use of memory reduction because I am facing weirds results.\nI am not an expert in Python and dtypes changes, and maybe these are obvious for some of you. \n\nSorry if these observations have already been reported, please let me know it in comments.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-25T04:40:22.989436Z","iopub.execute_input":"2022-03-25T04:40:22.99009Z","iopub.status.idle":"2022-03-25T04:40:23.018619Z","shell.execute_reply.started":"2022-03-25T04:40:22.98994Z","shell.execute_reply":"2022-03-25T04:40:23.017832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I am loading the dataset version with parquet (https://www.kaggle.com/datasets/robikscube/ubiquant-parquet)\n\nSee this notebook for information https://www.kaggle.com/code/camilomx/parquet-format-quickstart","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_df = pd.read_parquet(\"/kaggle/input/ubiquant-parquet/train_low_mem.parquet\")","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:40:32.651033Z","iopub.execute_input":"2022-03-25T04:40:32.651541Z","iopub.status.idle":"2022-03-25T04:41:07.449185Z","shell.execute_reply.started":"2022-03-25T04:40:32.651505Z","shell.execute_reply":"2022-03-25T04:41:07.448196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the describe information.","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:41:14.142299Z","iopub.execute_input":"2022-03-25T04:41:14.142657Z","iopub.status.idle":"2022-03-25T04:41:47.784603Z","shell.execute_reply.started":"2022-03-25T04:41:14.142622Z","shell.execute_reply":"2022-03-25T04:41:47.783196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:42:00.297156Z","iopub.execute_input":"2022-03-25T04:42:00.298344Z","iopub.status.idle":"2022-03-25T04:42:00.328888Z","shell.execute_reply.started":"2022-03-25T04:42:00.298282Z","shell.execute_reply":"2022-03-25T04:42:00.327868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Everything seems OK.","metadata":{}},{"cell_type":"code","source":"# Let's create a copy of train_df\ntrain_df_1 = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:42:04.392051Z","iopub.execute_input":"2022-03-25T04:42:04.393238Z","iopub.status.idle":"2022-03-25T04:42:06.443271Z","shell.execute_reply.started":"2022-03-25T04:42:04.393187Z","shell.execute_reply":"2022-03-25T04:42:06.442119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_1.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:42:25.800485Z","iopub.execute_input":"2022-03-25T04:42:25.800899Z","iopub.status.idle":"2022-03-25T04:42:25.829592Z","shell.execute_reply.started":"2022-03-25T04:42:25.800851Z","shell.execute_reply":"2022-03-25T04:42:25.828358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_1.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:42:38.920316Z","iopub.execute_input":"2022-03-25T04:42:38.920617Z","iopub.status.idle":"2022-03-25T04:43:13.354959Z","shell.execute_reply.started":"2022-03-25T04:42:38.920586Z","shell.execute_reply":"2022-03-25T04:43:13.353659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same information in this copy.","metadata":{}},{"cell_type":"markdown","source":"Some people (and me) use this function to reduce the memory use of the dataset. \n\nReference : https://www.kaggle.com/code/gemartin/load-data-reduce-memory-usage/notebook","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\n\n\ntrain_df_1 = reduce_mem_usage(train_df_1)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:46:42.764298Z","iopub.execute_input":"2022-03-25T04:46:42.765071Z","iopub.status.idle":"2022-03-25T04:50:37.211508Z","shell.execute_reply.started":"2022-03-25T04:46:42.765023Z","shell.execute_reply":"2022-03-25T04:50:37.209861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_1.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:52:06.423426Z","iopub.execute_input":"2022-03-25T04:52:06.423868Z","iopub.status.idle":"2022-03-25T04:52:08.083547Z","shell.execute_reply.started":"2022-03-25T04:52:06.423821Z","shell.execute_reply":"2022-03-25T04:52:08.082457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look at the describe information.","metadata":{}},{"cell_type":"code","source":"train_df_1.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:52:13.520994Z","iopub.execute_input":"2022-03-25T04:52:13.521323Z","iopub.status.idle":"2022-03-25T04:55:09.951987Z","shell.execute_reply.started":"2022-03-25T04:52:13.521281Z","shell.execute_reply":"2022-03-25T04:55:09.950596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see NaN values are appearing and some values such as mean for features f_i have changed a little.\n\nLet's see some other stranges things :","metadata":{}},{"cell_type":"code","source":"# Before memory reduction\ninvestments = train_df[\"investment_id\"].nunique()\nprint(\"Before memory reduction \\nNumber of unique investiment_id : \", investments)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:55:19.354968Z","iopub.execute_input":"2022-03-25T04:55:19.355275Z","iopub.status.idle":"2022-03-25T04:55:19.382689Z","shell.execute_reply.started":"2022-03-25T04:55:19.355243Z","shell.execute_reply":"2022-03-25T04:55:19.381874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After memory reduction\ninvestments = train_df_1[\"investment_id\"].nunique()\nprint(\"After memory reduction \\nNumber of unique investiment_id : \", investments)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T04:55:23.331454Z","iopub.execute_input":"2022-03-25T04:55:23.332484Z","iopub.status.idle":"2022-03-25T04:55:23.388478Z","shell.execute_reply.started":"2022-03-25T04:55:23.332433Z","shell.execute_reply":"2022-03-25T04:55:23.387135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, be careful when using data memory reduction.","metadata":{}}]}