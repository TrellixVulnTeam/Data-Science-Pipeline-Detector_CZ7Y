{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In my (limited) experience in the financial ML, it is better to start simple. \n\nAs this is my very first notebook in this competition, I decided to use a linear model as my baseline. By using a linear model, we can effectively see how each anonymized feature is associated with the target.\n\nI use the following parquet file to fit everything within this notebook.\n\n[‚è´ Fast Data Loading and Low Mem with Parquet Files](https://www.kaggle.com/robikscube/fast-data-loading-and-low-mem-with-parquet-files)\n\nSo let's get it started!","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport gc\nimport pathlib\nfrom tqdm.auto import tqdm\nimport joblib\nimport pathlib\nimport json\nimport glob\nimport time\nimport datetime\nfrom scipy import stats\nfrom multiprocessing import Pool, cpu_count\n\n# models\nfrom sklearn import linear_model\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nfrom matplotlib_venn import venn2, venn3\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('seaborn-colorblind')\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-26T09:34:54.688973Z","iopub.execute_input":"2022-01-26T09:34:54.689568Z","iopub.status.idle":"2022-01-26T09:34:57.476077Z","shell.execute_reply.started":"2022-01-26T09:34:54.689415Z","shell.execute_reply":"2022-01-26T09:34:57.475096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"# train = pd.read_parquet('../input/ubiquant-parquet/train.parquet')\ntrain = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\n\nprint(train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:34:57.477587Z","iopub.execute_input":"2022-01-26T09:34:57.477919Z","iopub.status.idle":"2022-01-26T09:35:42.314857Z","shell.execute_reply.started":"2022-01-26T09:34:57.477874Z","shell.execute_reply":"2022-01-26T09:35:42.314098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss = pd.read_csv('/kaggle/input/ubiquant-market-prediction/example_sample_submission.csv')\nprint(ss.shape)\nss.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:35:42.316211Z","iopub.execute_input":"2022-01-26T09:35:42.317151Z","iopub.status.idle":"2022-01-26T09:35:42.340822Z","shell.execute_reply.started":"2022-01-26T09:35:42.31708Z","shell.execute_reply":"2022-01-26T09:35:42.339793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"features = train.columns[train.columns.str.startswith('f_')].values.tolist()\nprint(len(features), features)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:35:42.343953Z","iopub.execute_input":"2022-01-26T09:35:42.344658Z","iopub.status.idle":"2022-01-26T09:35:42.355039Z","shell.execute_reply.started":"2022-01-26T09:35:42.344586Z","shell.execute_reply":"2022-01-26T09:35:42.353942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit a linear model\nmodel = linear_model.Ridge()\nmodel.fit(train[features], train['target'])","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:35:42.35732Z","iopub.execute_input":"2022-01-26T09:35:42.357752Z","iopub.status.idle":"2022-01-26T09:35:54.58187Z","shell.execute_reply.started":"2022-01-26T09:35:42.357696Z","shell.execute_reply":"2022-01-26T09:35:54.580879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coef\nfeature_importance = pd.DataFrame()\nfeature_importance['features'] = features\nfeature_importance['weight'] = model.coef_.ravel()\n\nfeature_importance.sort_values(by=['weight'], ascending=False).style.background_gradient(cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:35:54.583888Z","iopub.execute_input":"2022-01-26T09:35:54.588706Z","iopub.status.idle":"2022-01-26T09:35:54.755484Z","shell.execute_reply.started":"2022-01-26T09:35:54.588615Z","shell.execute_reply":"2022-01-26T09:35:54.754103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"%%time\nimport ubiquant\n\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:    \n    sample_prediction_df['target'] = model.predict(test_df[features])  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:35:54.757125Z","iopub.execute_input":"2022-01-26T09:35:54.757391Z","iopub.status.idle":"2022-01-26T09:35:54.87122Z","shell.execute_reply.started":"2022-01-26T09:35:54.75736Z","shell.execute_reply":"2022-01-26T09:35:54.869919Z"},"trusted":true},"execution_count":null,"outputs":[]}]}