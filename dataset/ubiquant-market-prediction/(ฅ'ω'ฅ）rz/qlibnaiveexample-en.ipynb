{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A series of Qlib based kernels. Welcome to explore more details in [Qlib](http://github.com/microsoft/qlib)\n- [A Different EDA based on Qlib\\[EN/中文\\]](https://www.kaggle.com/youngyang/a-different-eda-based-on-qlib-en/)\n- [A Naive Qlib Example\\[EN/中文\\]](https://www.kaggle.com/youngyang/qlibnaiveexample-en/)\n\nThis is a very Naive example of Qlib.  The score is not high. It aims to demonstrate a short and easy example to use Qlib.\nWelcome to explore more Quant ML  models implemnted in Qlib.\n\n这是一个非常初级的Qlib样例。 分数不高， 它的主要目的是为了展示一个简单的基于Qlib做预测的样例。\n欢迎基于这个样例来探索在Qlib中的更多基于 ML 的Quant模型","metadata":{}},{"cell_type":"markdown","source":"# Set Qlib Env","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.insert(0, '../input/qlib-dev-w/packages')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T02:51:04.15834Z","iopub.execute_input":"2022-02-18T02:51:04.158681Z","iopub.status.idle":"2022-02-18T02:51:04.180738Z","shell.execute_reply.started":"2022-02-18T02:51:04.1586Z","shell.execute_reply":"2022-02-18T02:51:04.180086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nfrom typing import Union\nimport qlib\nfrom qlib.workflow import R\nimport numpy as np\nimport pandas as pd\nfrom qlib.data.dataset.handler import DataHandlerLP\nfrom qlib.data.dataset.loader import StaticDataLoader\nfrom qlib.data.dataset import DatasetH\nfrom qlib.contrib.model.pytorch_nn import DNNModelPytorch\nfrom sklearn.model_selection import GroupKFold\nqlib.init()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T02:51:04.182294Z","iopub.execute_input":"2022-02-18T02:51:04.182556Z","iopub.status.idle":"2022-02-18T02:51:18.413237Z","shell.execute_reply.started":"2022-02-18T02:51:04.182509Z","shell.execute_reply":"2022-02-18T02:51:18.412572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"def read_data(path: Union[str, pd.DataFrame]=\"../input/train.pkl\", proc_type='train'):\n    \"\"\" Read data and turn it into Qlib's format\"\"\"\n    df = pd.read_pickle(path) if isinstance(path, str) else path\n\n    if proc_type == \"test\": # The format of test data and training data is different\n        df[\"time_id\"] = df[\"row_id\"].apply(lambda x: int(x.split(\"_\")[0]))\n        del test_df[\"row_id\"]\n    else:\n        assert proc_type == \"train\"\n\n    df = df.set_index([\"time_id\", \"investment_id\"])\n    df.columns = pd.MultiIndex.from_tuples([(\"label\" if col == \"target\" else \"feature\", col) for col in df.columns])\n    df.index.names = [\"datetime\", \"instrument\"]  # Qlib's processors requires datetime\n    df = df.astype(np.float32)  # for supporting unstack operation\n    return df\ndata_df = read_data(\"../input/ubiquant-market-prediction-half-precision-pickle/train.pkl\")\n\n# Datahandler\ndh = DataHandlerLP(data_loader=StaticDataLoader(data_df), drop_raw=True)   # data processing is normally implemented in data handler\ndel data_df\ndel dh.data_loader","metadata":{"execution":{"iopub.status.busy":"2022-02-18T02:51:18.415164Z","iopub.execute_input":"2022-02-18T02:51:18.415684Z","iopub.status.idle":"2022-02-18T02:51:39.222216Z","shell.execute_reply.started":"2022-02-18T02:51:18.415647Z","shell.execute_reply":"2022-02-18T02:51:39.221581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"def split_kfold(idx, fold=5):\n    kfold = GroupKFold(n_splits=fold)\n    cv_index = []\n    for fold_id, (train_idx, valid_idx) in enumerate(kfold.split(idx, groups=idx.get_level_values(\"datetime\"))):\n        all_seg = {\"train\": idx[train_idx], \"valid\": idx[valid_idx]}\n        cv_index.append(all_seg)\n    return cv_index\n\nidx = dh.fetch().index\ncv_index = split_kfold(idx)  # create cross validation based on cv_index\ndel idx\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T02:51:39.226533Z","iopub.execute_input":"2022-02-18T02:51:39.228383Z","iopub.status.idle":"2022-02-18T02:51:41.908991Z","shell.execute_reply.started":"2022-02-18T02:51:39.228344Z","shell.execute_reply":"2022-02-18T02:51:41.908319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"R.start_exp()\n\nkwargs = {\n    \"lr\": 0.002,\n    \"optimizer\": \"adam\",\n    \"max_steps\": 8000,\n    \"batch_size\": 8192,\n    \"pt_model_kwargs\": {\n        'input_dim': 300,\n        'layers': (256, )\n    },\n    \"scheduler\": None,\n}\nR.log_params(**kwargs)  # save params in experiment manager\n\ncv_models = []\nfor seg in cv_index:\n    ds = DatasetH(handler=dh, segments=seg)\n    m = DNNModelPytorch(**kwargs)\n    m.fit(ds)\n    cv_models.append(m)\n\nR.save_objects(**{\"cv_models.pkl\": cv_models, \"handler.pkl\": dh})   # save the models and data processors\nR.end_exp()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T02:51:41.910446Z","iopub.execute_input":"2022-02-18T02:51:41.910918Z","iopub.status.idle":"2022-02-18T02:52:48.423065Z","shell.execute_reply.started":"2022-02-18T02:51:41.91088Z","shell.execute_reply":"2022-02-18T02:52:48.422145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# Test\nimport ubiquant\n\nenv = ubiquant.make_env()\niter_test = env.iter_test()\n\ndef get_avg(preds):\n    return sum(preds) / len(preds)\n\nfor (test_df, sample_prediction_df) in iter_test:\n    # use the same data handler in both inference and training\n    dh.data_loader = StaticDataLoader(read_data(test_df, proc_type=\"test\"))  # load raw data\n    dh.setup_data(init_type=dh.IT_LS)  # process data\n    ds = DatasetH(handler=dh, segments={\"test\": slice(None)}) # inference on data\n\n    preds = []\n\n    # NN\n    preds_nn = []\n    for m in cv_models:\n        preds_nn.append(m.predict(ds).values)\n    preds.append(get_avg(preds_nn))\n    # TODO: You may try more models\n\n    # ensemble models\n    sample_prediction_df.loc[:, \"target\"] = get_avg(preds)\n\n    env.predict(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T02:52:48.424424Z","iopub.execute_input":"2022-02-18T02:52:48.424781Z","iopub.status.idle":"2022-02-18T02:52:48.556354Z","shell.execute_reply.started":"2022-02-18T02:52:48.424743Z","shell.execute_reply":"2022-02-18T02:52:48.555573Z"},"trusted":true},"execution_count":null,"outputs":[]}]}