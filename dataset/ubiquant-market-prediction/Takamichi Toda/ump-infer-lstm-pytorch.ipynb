{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# UMP Infer LSTM (pytorch)\n\nThis code is infer LSTM model.\n\nTraining code is here:  \nhttps://www.kaggle.com/takamichitoda/ump-train-lstm-pytorch\n\nLSTM model needs to input previous featureâ€™s history.  \nThat dataset is here:  \nhttps://www.kaggle.com/takamichitoda/ump-features-history\n\nIn this code, I infer by concatenating this historical data with the data from the API.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport gc\n\nimport pickle\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\nfrom transformers import AdamW\nfrom sklearn.model_selection import KFold\n\nfrom tqdm.auto import tqdm\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nimport ubiquant\n\ndevice = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:02.616295Z","iopub.execute_input":"2022-02-02T08:46:02.617087Z","iopub.status.idle":"2022-02-02T08:46:05.152028Z","shell.execute_reply.started":"2022-02-02T08:46:02.61699Z","shell.execute_reply":"2022-02-02T08:46:05.1512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GCF:\n    INPUT_ROOT = \"/kaggle/input/ump-npy-dataset/\"\n    MODEL_ROOT = \"/kaggle/input/ump-train-lstm-pytorch\"\n    SCALER_PATH = \"/kaggle/input/ump-npy-dataset/std_scaler.pkl\"\n    LATEST_FEATURES = '/kaggle/input/ump-features-history/latest_features_128.npy'\n    \n    SEED = 0\n    MAX_LEN = 128\n    N_FOLDS = 5\n    \n    BS = 256\n    HIDDEN_SIZE = 128\n    FEAT_COLS = [f\"f_{i}\" for i in range(300)]","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:05.153743Z","iopub.execute_input":"2022-02-02T08:46:05.154547Z","iopub.status.idle":"2022-02-02T08:46:05.161028Z","shell.execute_reply.started":"2022-02-02T08:46:05.154501Z","shell.execute_reply":"2022-02-02T08:46:05.160165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UMPLSTM(nn.Module):\n    def __init__(self):\n        super(UMPLSTM, self).__init__()\n        conv_out = 64\n        pool_k = 16\n\n        self.lstm = nn.LSTM(300, GCF.HIDDEN_SIZE, batch_first=True, num_layers=1, dropout=0.0)        \n        self.head = nn.Sequential(\n            nn.Linear(GCF.HIDDEN_SIZE, GCF.HIDDEN_SIZE),\n            nn.LayerNorm(GCF.HIDDEN_SIZE),\n            nn.ReLU(),\n            nn.Linear(GCF.HIDDEN_SIZE, 1),\n        )\n        \n        self.criterion = nn.MSELoss(reduction='none')\n        \n    def forward(self, _x, _y=None):\n        out, _ = self.lstm(_x)\n        regr = self.head(out)\n        regr = regr.squeeze(2)\n        \n        if _y is None:\n            return None, regr\n        \n        mask = (_y != 999).float()\n        loss = self.criterion(regr, _y)\n        loss = (loss * mask).mean()\n        \n        return loss, regr","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:05.162572Z","iopub.execute_input":"2022-02-02T08:46:05.162845Z","iopub.status.idle":"2022-02-02T08:46:05.17414Z","shell.execute_reply.started":"2022-02-02T08:46:05.162808Z","shell.execute_reply":"2022-02-02T08:46:05.173448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_path = f\"{GCF.MODEL_ROOT}/ump_lstm_f0_best_rmse.pth\"\nmodel = UMPLSTM()\nmodel.load_state_dict(torch.load(load_path, map_location=torch.device('cpu')))\nmodel.to(device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:05.176389Z","iopub.execute_input":"2022-02-02T08:46:05.176676Z","iopub.status.idle":"2022-02-02T08:46:07.694474Z","shell.execute_reply.started":"2022-02-02T08:46:05.17664Z","shell.execute_reply":"2022-02-02T08:46:07.693805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = pickle.load(open(GCF.SCALER_PATH, \"rb\"))\nscaler","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:07.695687Z","iopub.execute_input":"2022-02-02T08:46:07.696458Z","iopub.status.idle":"2022-02-02T08:46:07.707227Z","shell.execute_reply.started":"2022-02-02T08:46:07.69642Z","shell.execute_reply":"2022-02-02T08:46:07.706428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latest_features = np.load(GCF.LATEST_FEATURES)\nlatest_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:07.708597Z","iopub.execute_input":"2022-02-02T08:46:07.708853Z","iopub.status.idle":"2022-02-02T08:46:08.120529Z","shell.execute_reply.started":"2022-02-02T08:46:07.708818Z","shell.execute_reply":"2022-02-02T08:46:08.119747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    _id = test_df['investment_id'].values\n    \n    # update new investment_id\n    if len(latest_features) <= _id.max():\n        add = _id.max() - len(latest_features) + 1\n        new_f = np.zeros((add, GCF.MAX_LEN, 300))\n        latest_features = np.vstack([latest_features, new_f])\n        \n    curr_x = scaler.transform(test_df[GCF.FEAT_COLS].values)\n    prev_x = torch.tensor(latest_features[_id, 1:])\n    x = torch.cat([prev_x, torch.tensor(curr_x).unsqueeze(1)], dim = 1)\n    \n    with torch.no_grad():\n        _, pred = model(x.float().to(device))\n\n    sample_prediction_df['target'] = pred[:, -1].cpu().tolist()  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions\n    \n    # status update\n    latest_features[_id] = x.cpu().numpy()\n    \n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:08.122048Z","iopub.execute_input":"2022-02-02T08:46:08.122506Z","iopub.status.idle":"2022-02-02T08:46:09.068045Z","shell.execute_reply.started":"2022-02-02T08:46:08.122454Z","shell.execute_reply":"2022-02-02T08:46:09.067295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_prediction_df","metadata":{"execution":{"iopub.status.busy":"2022-02-02T08:46:09.069311Z","iopub.execute_input":"2022-02-02T08:46:09.069572Z","iopub.status.idle":"2022-02-02T08:46:09.084003Z","shell.execute_reply.started":"2022-02-02T08:46:09.069538Z","shell.execute_reply":"2022-02-02T08:46:09.083352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}