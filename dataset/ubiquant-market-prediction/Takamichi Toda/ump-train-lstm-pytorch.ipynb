{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# UMP Train LSTM\n\nThis code train LSTM model.\n\nTo save time and memory, I converted train.csv to a numpy array beforehand. ([dataset link](https://www.kaggle.com/takamichitoda/ump-npy-dataset))\n\nThis code is still being improved. If you find any corrections, please let me know.\n\nUPDATE:\n- Version 7: use long history, LB->0.122\n- Version 8: only time_id over 400, LB-> 0.123\n- Version 10: add time unique features, LB->\n- Version 12: only time_id over 420, len=512, LB->","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport gc\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\nfrom transformers import AdamW\nfrom sklearn.model_selection import KFold, GroupKFold\n\nfrom tqdm.auto import tqdm\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import mean_squared_error\n\ndevice = torch.device(\"cuda\")\nscaler = torch.cuda.amp.GradScaler()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T00:49:54.493251Z","iopub.execute_input":"2022-02-16T00:49:54.493545Z","iopub.status.idle":"2022-02-16T00:50:00.818201Z","shell.execute_reply.started":"2022-02-16T00:49:54.493468Z","shell.execute_reply":"2022-02-16T00:50:00.81742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MAX_LEN is a parameter to see how much historical data to look at.\n\nIn this time, I set 32. (I'm searching best parameter)","metadata":{}},{"cell_type":"code","source":"class GCF:\n    INPUT_ROOT = \"/kaggle/input/ump-npy-dataset/\"\n    SEED = 0\n    MAX_LEN = 1024\n    EVAL_MAX_LEN = 1024\n    N_FOLDS = 5\n    \n    BS = 256\n    HIDDEN_SIZE = 128\n    N_EPOCHS = 80 * 1\n    \n    LR = 1e-3\n    WEIGHT_DECAY = 1e-5","metadata":{"execution":{"iopub.status.busy":"2022-02-16T00:50:00.819977Z","iopub.execute_input":"2022-02-16T00:50:00.820244Z","iopub.status.idle":"2022-02-16T00:50:00.826891Z","shell.execute_reply.started":"2022-02-16T00:50:00.820211Z","shell.execute_reply":"2022-02-16T00:50:00.82618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=GCF.SEED):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2022-02-16T00:50:00.828159Z","iopub.execute_input":"2022-02-16T00:50:00.828838Z","iopub.status.idle":"2022-02-16T00:50:00.835507Z","shell.execute_reply.started":"2022-02-16T00:50:00.828765Z","shell.execute_reply":"2022-02-16T00:50:00.834737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.load(f\"{GCF.INPUT_ROOT}/features_std_scaled.npy\")\ny = np.load(f\"{GCF.INPUT_ROOT}/targets.npy\")\ninvestment_id = np.load(f\"{GCF.INPUT_ROOT}/investment_id.npy\")\ntime_id = np.load(f\"{GCF.INPUT_ROOT}/time_id.npy\")\n\nX = X.astype(np.float16)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T00:50:00.83769Z","iopub.execute_input":"2022-02-16T00:50:00.837977Z","iopub.status.idle":"2022-02-16T00:50:37.954863Z","shell.execute_reply.started":"2022-02-16T00:50:00.837945Z","shell.execute_reply":"2022-02-16T00:50:37.954183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X[time_id >= 420, :]\ny = y[time_id >= 420]\ninvestment_id = investment_id[time_id >= 420]\ntime_id = time_id[time_id >= 420]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T00:50:37.956241Z","iopub.execute_input":"2022-02-16T00:50:37.956717Z","iopub.status.idle":"2022-02-16T00:50:39.295481Z","shell.execute_reply.started":"2022-02-16T00:50:37.956681Z","shell.execute_reply":"2022-02-16T00:50:39.294737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is Custom Dataset\n\nIf data size is less than MAX_LEN, I do padding.\n\nFor testing and validation, I use the latest MAL_LEN data.\n","metadata":{}},{"cell_type":"code","source":"class UMPDataset(Dataset):\n    \n    def __init__(self, ids, is_train):\n        self.ids = ids\n        self.is_train = is_train\n        self.l = GCF.MAX_LEN if is_train else GCF.EVAL_MAX_LEN\n        \n    def __len__(self):\n        return len(self.ids)\n    \n    def __getitem__(self, item):\n        _id = self.ids[item]\n        _x = X[investment_id == _id, :]\n        _y = y[investment_id == _id]\n        \n        if len(_x) > self.l:\n            if self.is_train:\n                tail_i = random.randint(self.l, len(_x) - 1)\n            else:\n                tail_i = len(_x) - 1\n            _x = _x[tail_i-self.l:tail_i, :]\n            _y = _y[tail_i-self.l:tail_i]\n        elif len(_x) < self.l:\n            pad_len = self.l - len(_x)\n            x_pad = np.zeros((pad_len, 300))\n            y_pad = np.ones(pad_len) * 999\n            _x = np.vstack([x_pad, _x])\n            _y = np.hstack([y_pad, _y])\n        \n        return _x, _y","metadata":{"execution":{"iopub.status.busy":"2022-02-16T01:02:42.437765Z","iopub.execute_input":"2022-02-16T01:02:42.43831Z","iopub.status.idle":"2022-02-16T01:02:42.447824Z","shell.execute_reply.started":"2022-02-16T01:02:42.43827Z","shell.execute_reply":"2022-02-16T01:02:42.447149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is Custom Model.\n\nThe padding area loss are masked.","metadata":{}},{"cell_type":"code","source":"class AddGaussianNoise(object):\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()).to(device) * self.std + self.mean\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n    \n    \nclass UMPLSTM(nn.Module):\n    def __init__(self):\n        super(UMPLSTM, self).__init__()\n\n        self.noise = AddGaussianNoise(std=0.2)\n        \n        self.ae_encoder = nn.Linear(300, 128)\n        self.ae_act = nn.ReLU()\n        self.ae_decoder = nn.Linear(128, 300)\n            \n        self.rnn = nn.LSTM(300+128, GCF.HIDDEN_SIZE, batch_first=True, num_layers=1, dropout=0.0)\n        self.dropout = nn.Dropout(p=0.2)\n        self.head = nn.Sequential(\n            nn.Linear(GCF.HIDDEN_SIZE+300, GCF.HIDDEN_SIZE),\n            nn.LayerNorm(GCF.HIDDEN_SIZE),\n            nn.ReLU(),\n            nn.Linear(GCF.HIDDEN_SIZE, 1),\n        )\n        \n    def forward(self, _x, _y=None):\n        if self.training:\n            h = self.noise(_x)\n        else:\n            h = _x\n            \n        ae_h1 = self.ae_act(self.ae_encoder(h))\n        ae_h2 = self.ae_decoder(ae_h1)\n        ae_loss = nn.MSELoss()(ae_h2, h)\n        \n        h = torch.cat([_x, ae_h1], dim=2)\n        \n        h, _ = self.rnn(h)\n        h = self.dropout(h)\n        h = torch.cat([_x, h], dim=2)\n        regr = self.head(h)\n        regr = regr.squeeze(2)\n        \n        if _y is None:\n            return None, regr\n\n        mask = (_y != 999).float()\n        loss = nn.MSELoss(reduction='none')(regr, _y)\n        loss = (loss * mask).mean()\n        \n        loss = loss + ae_loss\n        \n        return loss, regr","metadata":{"execution":{"iopub.status.busy":"2022-02-16T01:02:54.768476Z","iopub.execute_input":"2022-02-16T01:02:54.769241Z","iopub.status.idle":"2022-02-16T01:02:54.784813Z","shell.execute_reply.started":"2022-02-16T01:02:54.769201Z","shell.execute_reply":"2022-02-16T01:02:54.78397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(dloader, model):\n    losses = []\n    model.train()\n    optimizer.zero_grad()\n    for _x, _y in dloader:\n        with torch.cuda.amp.autocast(): \n            loss, regr = model(_x.float().to(device), _y.float().to(device))\n        losses.append(loss.item())\n        scaler.scale(loss).backward()\n        scaler.step(optimizer) \n        scaler.update() \n        optimizer.zero_grad()\n    return losses\n\ndef valid_loop(dloader, model):\n    predicts = []\n    model.eval()\n    for _x, _y in dloader:\n        with torch.no_grad():\n            loss, regr = model(_x.float().to(device), _y.float().to(device))\n        predicts.append(regr.cpu())\n    predicts = torch.vstack(predicts)\n    return predicts","metadata":{"execution":{"iopub.status.busy":"2022-02-16T01:02:56.700109Z","iopub.execute_input":"2022-02-16T01:02:56.700699Z","iopub.status.idle":"2022-02-16T01:02:56.70821Z","shell.execute_reply.started":"2022-02-16T01:02:56.700661Z","shell.execute_reply":"2022-02-16T01:02:56.707392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_score(ids, predicts):\n    dfs = []\n    for idx, _id in enumerate(ids):\n        _time_id = time_id[investment_id == _id]\n        _y = y[investment_id == _id]\n        _time_id = _time_id[-GCF.EVAL_MAX_LEN:]\n        _y = _y[-GCF.EVAL_MAX_LEN:]\n        pred = predicts[idx, :].numpy()\n        if len(_y) != GCF.EVAL_MAX_LEN:\n            n_data = len(_y)\n            pred = pred[-n_data:]\n\n        df = pd.DataFrame(np.vstack([_time_id, _y, pred]).T, columns=['time_id', 'target', 'predict'])\n        dfs.append(df)\n    result_df = pd.concat(dfs, axis=0)\n    \n    time_count = result_df['time_id'].value_counts()\n    result_df = result_df.query(f\"time_id in {time_count[time_count > 1].index.tolist()}\")\n    score = np.mean(result_df.groupby('time_id').apply(lambda x: x.corr()['target']['predict']))\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-02-16T01:03:00.720495Z","iopub.execute_input":"2022-02-16T01:03:00.720755Z","iopub.status.idle":"2022-02-16T01:03:00.728758Z","shell.execute_reply.started":"2022-02-16T01:03:00.720728Z","shell.execute_reply":"2022-02-16T01:03:00.728012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"main process","metadata":{}},{"cell_type":"code","source":"all_ids = np.unique(investment_id)\n\nkf = KFold(n_splits=GCF.N_FOLDS, random_state=GCF.SEED, shuffle=True)\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(all_ids)):\n    print(f\"Fold-{fold}\")\n    train_dset = UMPDataset(all_ids[train_idx], True)\n    valid_dset = UMPDataset(all_ids[valid_idx], False)\n    y_true = np.vstack([y for _, y in valid_dset])\n    \n    train_dloader = DataLoader(train_dset, batch_size=GCF.BS,\n                               pin_memory=True, shuffle=True, drop_last=True,\n                               worker_init_fn=lambda x: set_seed())\n    valid_dloader = DataLoader(valid_dset, batch_size=GCF.BS,\n                               pin_memory=True, shuffle=False, drop_last=False)\n    \n    model = UMPLSTM()\n    model.to(device)\n    optimizer = AdamW(model.parameters(), lr=GCF.LR, weight_decay=GCF.WEIGHT_DECAY)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=5, threshold=0.0001, min_lr=1e-8, verbose=True)\n    \n    set_seed()\n    train_losses, valid_rmse, valid_scores = [], [], []\n    best_score, best_rmse = float('-inf'), float('inf')\n    for epoch in tqdm(range(GCF.N_EPOCHS)):\n        losses = train_loop(train_dloader, model)\n        predicts = valid_loop(valid_dloader, model)\n        \n        train_losses += losses\n        rmse = mean_squared_error(y_true[y_true != 999], predicts[y_true != 999].numpy(), squared=False)\n        score = calc_score(all_ids[valid_idx], predicts)\n        \n        scheduler.step(score)\n        \n        valid_rmse.append(rmse)\n        valid_scores.append(score)\n        \n        print(f\"  epoch: {epoch}, RMSE={rmse}, SCORE={score}\")\n        if best_rmse > rmse:\n            best_rmse = rmse\n            torch.save(model.state_dict(), f\"ump_lstm_f{fold}_best_rmse.pth\")\n            print('    -> best rmse update!!')\n        if best_score < score:\n            best_score = score\n            torch.save(model.state_dict(), f\"ump_lstm_f{fold}_best_score.pth\")\n            print('    -> best score update!!')\n        \n    plt.plot(train_losses)\n    plt.title('train loss')\n    plt.show()\n    \n    plt.plot(valid_rmse)\n    plt.title('valid rmse')\n    plt.show()\n    \n    plt.plot(valid_scores)\n    plt.title('valid scores')\n    plt.show()\n    \n    #break  # only one fold","metadata":{"execution":{"iopub.status.busy":"2022-02-16T01:03:02.3107Z","iopub.execute_input":"2022-02-16T01:03:02.311402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(valid_rmse)\nprint(valid_scores)\nprint(np.mean(valid_rmse))\nprint(np.mean(valid_scores))","metadata":{},"execution_count":null,"outputs":[]}]}