{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# General information about this notebook\n\nHi,\n\nI am Thomas, creator of the automl library e2eml. In this notebook I give you a little walkthrough and example run using a feature called Timewalk.\n\nI created this library for personal development, but also to give something back to the data science community. You can install the library using !pip install e2eml (here I installed it using no internet, but which is painful).\nWhat does e2eml offer?\n\ne2eeml has two major goals: You can either speed up your prototyping and exploration (with Timewalk) or create a full pipeline with just a few lines of code. e2eml will take care of:\n\n- data preprocessing\n- model training\n- model fine-tuning\n - model evaluation\n - logging file\n\nIt can handle datetime, categorical and numerical data and allows you to build classification & regression models. For NLP tasks you can even let it create a full BERT model for you. It is NOT built for time series at all currently, but I wanted to give it a shot at least.\n\n# Why e2eml and not any other automl framework?\n\nThis decision is fully up to you. They all have their ins & outs. Chose what suits your needs best. e2eml is just an option for you.\n\n# What is the spirit of e2eml?\n\nThis library tries to maximize the model performance. It shall help to see how far you can get given your data. As a characteristic it creates huge notebooks, but we really wanted to print out a lot for. We want you to be able to actually see what is happening under the hood. That comes at a cost here. If you prefer very elegant and silent implementations, check out the fantastic Pycaret library. Additionally being able to fine-tune BERT models for you can be a life saver. We also provide some GPU acceleration with RAPIDS. Currently this is implemented in a few spots only however.\n","metadata":{}},{"cell_type":"code","source":"!pip install interface_meta --no-index --find-links=file:../input/e2eml-inc-dependencies/interface_meta-1.2.4-py2.py3-none-any.whl\n!pip install astor --no-index --find-links=file:../input/e2eml-inc-dependencies/astor-0.8.1-py2.py3-none-any.whl\n!pip install formulaic --no-index --find-links=file:../input/formulaic/formulaic-0.2.4-py3-none-any.whl\n!pip install autograd --no-index --find-links=file:../input/e2eml-inc-dependencies/autograd-1.3-py3-none-any.whl\n!pip install autograd-gamma --no-index --find-links=file:../input/e2eml-inc-dependencies/autograd-gamma-0.5.0/dist/autograd-gamma-0.5.0.tar\n!pip install lifelines --no-index --find-links=file:../input/lifelines/lifelines-0.26.4-py3-none-any.whl\n!pip install ngboost --no-index --find-links=file:../input/e2eml-inc-dependencies/ngboost-0.3.12-py3-none-any.whl\n!pip install boostaroota --no-index --find-links=file:../input/e2eml-inc-dependencies/boostaroota-1.3-py2.py3-none-any.whl\n!pip install matplotlib --no-index --find-links=file:../input/e2eml-inc-dependencies/matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl\n!pip install catboost --no-index --find-links=file:../input/e2eml-inc-dependencies/catboost-0.21-cp38-none-manylinux1_x86_64.whl\n!pip install pytorch_tabnet --no-index --find-links=file:../input/e2eml-inc-dependencies/pytorch_tabnet-3.1.1-py3-none-any.whl\n!pip install shap --no-index --find-links=file:../input/e2eml-inc-dependencies/shap-0.39.0-cp35-cp35m-linux_armv6l.whl\n!pip install e2eml --no-index --no-dependencies --find-links=file:../input/e2eml-inc-dependencies/e2eml-2.10.4-py3-none-any.whl","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-31T08:24:22.040629Z","iopub.execute_input":"2022-01-31T08:24:22.041211Z","iopub.status.idle":"2022-01-31T08:26:02.234097Z","shell.execute_reply.started":"2022-01-31T08:24:22.041113Z","shell.execute_reply":"2022-01-31T08:26:02.233237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trying to install RAPIDS, but I could not make it work.\nOtherwise we could use RAPIDS to accelerate the clustering parts a lot.","metadata":{}},{"cell_type":"code","source":"import sys\n!cp ../input/rapids/rapids.21.06 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:26:02.236968Z","iopub.execute_input":"2022-01-31T08:26:02.237457Z","iopub.status.idle":"2022-01-31T08:28:34.230664Z","shell.execute_reply.started":"2022-01-31T08:26:02.237412Z","shell.execute_reply":"2022-01-31T08:28:34.229642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conda uninstall pyarrow","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-31T08:28:34.232769Z","iopub.execute_input":"2022-01-31T08:28:34.233072Z","iopub.status.idle":"2022-01-31T08:40:38.313366Z","shell.execute_reply.started":"2022-01-31T08:28:34.233032Z","shell.execute_reply":"2022-01-31T08:40:38.312474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pyarrow","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:40:38.316734Z","iopub.execute_input":"2022-01-31T08:40:38.31703Z","iopub.status.idle":"2022-01-31T08:40:48.569623Z","shell.execute_reply.started":"2022-01-31T08:40:38.31699Z","shell.execute_reply":"2022-01-31T08:40:48.568788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n# load libraries\nimport sys\nfrom e2eml.regression import regression_blueprints\nfrom e2eml.full_processing import postprocessing\nfrom e2eml.timetravel import timetravel\nfrom sklearn.model_selection import train_test_split\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:40:48.571501Z","iopub.execute_input":"2022-01-31T08:40:48.572257Z","iopub.status.idle":"2022-01-31T08:41:04.192289Z","shell.execute_reply.started":"2022-01-31T08:40:48.572208Z","shell.execute_reply":"2022-01-31T08:41:04.191529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = \"target\"","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:41:04.193654Z","iopub.execute_input":"2022-01-31T08:41:04.193895Z","iopub.status.idle":"2022-01-31T08:41:04.200976Z","shell.execute_reply.started":"2022-01-31T08:41:04.193862Z","shell.execute_reply":"2022-01-31T08:41:04.199913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", nrows=40000)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:41:04.202814Z","iopub.execute_input":"2022-01-31T08:41:04.203169Z","iopub.status.idle":"2022-01-31T08:41:10.156904Z","shell.execute_reply.started":"2022-01-31T08:41:04.203137Z","shell.execute_reply":"2022-01-31T08:41:10.156241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test train split\n\nWe hold back the newest data points as unseen holdout data for validation.\nThis has two reasons:\n- Without any unseen data we cannot see overfitting\n- The data might not consist of static behaviour. In real world applications patterns might change over time. And in timne series we also really want to make sure not to overfit.","metadata":{}},{"cell_type":"code","source":"train_df = df_train.head(30000).copy()\nval_df = df_train.tail(10000).copy()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:41:10.158308Z","iopub.execute_input":"2022-01-31T08:41:10.15875Z","iopub.status.idle":"2022-01-31T08:41:10.223047Z","shell.execute_reply.started":"2022-01-31T08:41:10.158711Z","shell.execute_reply":"2022-01-31T08:41:10.222215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df_target = val_df[target]\nval_df = val_df.drop(target, axis=1)\nval_df","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-31T08:41:10.22456Z","iopub.execute_input":"2022-01-31T08:41:10.224827Z","iopub.status.idle":"2022-01-31T08:41:10.278746Z","shell.execute_reply.started":"2022-01-31T08:41:10.224791Z","shell.execute_reply":"2022-01-31T08:41:10.277913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Automl using e2eml\n\nWe use e2eml. There are plenty of fantastic frameworks. Chose whatever you like.\nHere we instantiate the base class we need to use for the Timewalk function and all individual pipelines as well.","metadata":{}},{"cell_type":"code","source":"market_ml = regression_blueprints.RegressionBluePrint(datasource=train_df, \n                        target_variable=target,\n                        train_split_type='cross',\n                        rapids_acceleration=True,\n                        preferred_training_mode='auto',\n                        ml_task='regression')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:41:10.281192Z","iopub.execute_input":"2022-01-31T08:41:10.283473Z","iopub.status.idle":"2022-01-31T08:41:10.351323Z","shell.execute_reply.started":"2022-01-31T08:41:10.28344Z","shell.execute_reply":"2022-01-31T08:41:10.350525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From here we have two general options. We can:\n- run a certain blueprint straight away (this is great to create a ready-to-use pipeline for prediction)\n- run Timewalk to fully explore many algorithms and preprocessing combinations\n\nHere we assume that we don't know much about what works for this dataset. So we chose Timewalk. Timewalk takes a long time to run (this can be controlled by manually chosing algorithms and preprocessing steps to use). As we have plenty of data Timewalk will automatically switch off some algorithms. I.e. Xgboost will not run here (this has been designed due to problems of releasing the memory again and also due to high consumption of system resources).\n\nIn fact I decided to chose fast algorithms here. So Xgboost has been left out because of memory, SVM regression because of sped and scalability and TabNet because of speed.\nAs this is for show casing only here, we also use a micro sample considering the amount of data. So not expecting any good performance here.","metadata":{}},{"cell_type":"code","source":"results = timetravel.timewalk_auto_exploration(class_instance=market_ml,\n                                   holdout_df=val_df,\n                                   holdout_target=val_df_target,\n                                   algs_to_test=[\"linear_regression\",\"vowpal_wabbit\", \"ridge\", \"lgbm\"],\n                                   speed_up_model_tuning=True,\n                                   experiment_comment='First short glimpse',\n                                   experiment_name=\"market_prediction.pkl\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-31T08:41:10.352596Z","iopub.execute_input":"2022-01-31T08:41:10.35308Z","iopub.status.idle":"2022-01-31T13:48:15.022001Z","shell.execute_reply.started":"2022-01-31T08:41:10.35304Z","shell.execute_reply":"2022-01-31T13:48:15.020963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Timewalk returns a result dataframe. Performance has been poor in all instances, but LGBM already grabbed some signal at least. So in another notebook I will use a much bigger sample and try to run the LGBM blueprint using our winning preprocessing steps.","metadata":{}},{"cell_type":"code","source":"results.sort_values(by=[\"Mean absolute error\"], ascending=[True])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T13:55:39.230751Z","iopub.execute_input":"2022-01-31T13:55:39.231034Z","iopub.status.idle":"2022-01-31T13:55:39.289893Z","shell.execute_reply.started":"2022-01-31T13:55:39.230997Z","shell.execute_reply":"2022-01-31T13:55:39.289051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing the preprocessing steps of our best iteration and model\nbest_params = results.sort_values(by=[\"Mean absolute error\"], ascending=[False]).head(1)[\"Preprocessing applied\"].values.tolist()[0]\nbest_params","metadata":{"execution":{"iopub.status.busy":"2022-01-31T14:08:45.081343Z","iopub.execute_input":"2022-01-31T14:08:45.081974Z","iopub.status.idle":"2022-01-31T14:08:45.102357Z","shell.execute_reply.started":"2022-01-31T14:08:45.081933Z","shell.execute_reply":"2022-01-31T14:08:45.101424Z"},"trusted":true},"execution_count":null,"outputs":[]}]}