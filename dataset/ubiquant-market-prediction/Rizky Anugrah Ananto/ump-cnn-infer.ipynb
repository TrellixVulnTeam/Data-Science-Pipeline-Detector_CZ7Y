{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nplt.rcParams['figure.figsize'] = (10, 9)\nplt.style.use('seaborn-darkgrid')\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import IntegerLookup\n\nfrom tqdm.keras import TqdmCallback\nfrom tqdm.auto import tqdm\nimport ubiquant\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-20T06:51:51.669716Z","iopub.execute_input":"2022-04-20T06:51:51.670093Z","iopub.status.idle":"2022-04-20T06:51:59.162381Z","shell.execute_reply.started":"2022-04-20T06:51:51.670003Z","shell.execute_reply":"2022-04-20T06:51:59.161652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\n\ninvestment_ids = train['investment_id'].unique()\ninvestment_size = train['investment_id'].nunique() + 1\n\nInvestmentLayer = IntegerLookup(max_tokens = investment_size)\nInvestmentLayer.adapt(\n    pd.DataFrame({\n        'investment_ids' : investment_ids.tolist()\n    })\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:51:59.163901Z","iopub.execute_input":"2022-04-20T06:51:59.164477Z","iopub.status.idle":"2022-04-20T06:52:15.932416Z","shell.execute_reply.started":"2022-04-20T06:51:59.164444Z","shell.execute_reply":"2022-04-20T06:52:15.931341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = ubiquant.make_env()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:15.934235Z","iopub.execute_input":"2022-04-20T06:52:15.934983Z","iopub.status.idle":"2022-04-20T06:52:15.939946Z","shell.execute_reply.started":"2022-04-20T06:52:15.934936Z","shell.execute_reply":"2022-04-20T06:52:15.93896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:15.942242Z","iopub.execute_input":"2022-04-20T06:52:15.942656Z","iopub.status.idle":"2022-04-20T06:52:15.951266Z","shell.execute_reply.started":"2022-04-20T06:52:15.942613Z","shell.execute_reply":"2022-04-20T06:52:15.950634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset0(x, y = None, batch_size = 512, shuffle = False) :\n    def preprocess(x, y) :\n        return x, y\n    feat = [col for col in x.columns if col.startswith('f_')]\n    feature = x[feat].values\n    dataset = tf.data.Dataset.from_tensor_slices((\n        feature, y\n    )).map(preprocess).batch(batch_size = batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    if shuffle :\n        dataset = dataset.shuffle(500, seed = 50)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:15.952558Z","iopub.execute_input":"2022-04-20T06:52:15.95339Z","iopub.status.idle":"2022-04-20T06:52:15.963464Z","shell.execute_reply.started":"2022-04-20T06:52:15.953349Z","shell.execute_reply":"2022-04-20T06:52:15.962706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset1(x, y = None, batch_size = 512, shuffle = False) :\n    def preprocess(x, y) :\n        return x, y\n    feat = [col for col in x.columns if col.startswith('f_')]\n    investment = x['investment_id'].values\n    feature = x[feat].values\n    dataset = tf.data.Dataset.from_tensor_slices((\n        (investment, feature), y\n    )).map(preprocess).batch(batch_size = batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    if shuffle :\n        dataset = dataset.shuffle(500, seed = 50)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:15.964822Z","iopub.execute_input":"2022-04-20T06:52:15.965213Z","iopub.status.idle":"2022-04-20T06:52:15.975393Z","shell.execute_reply.started":"2022-04-20T06:52:15.965171Z","shell.execute_reply":"2022-04-20T06:52:15.974203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try :\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver().connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept :\n    strategy = tf.distribute.get_strategy()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:15.976855Z","iopub.execute_input":"2022-04-20T06:52:15.977156Z","iopub.status.idle":"2022-04-20T06:52:15.988015Z","shell.execute_reply.started":"2022-04-20T06:52:15.977126Z","shell.execute_reply":"2022-04-20T06:52:15.986958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlationMetric(x, y, axis=-2):\n    from tensorflow.python.ops import math_ops\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n    x = tf.convert_to_tensor(x)\n    y = math_ops.cast(y, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return corr\n\n\ndef correlationLoss(x,y, axis=-2):\n    from tensorflow.python.ops import math_ops\n    x = tf.convert_to_tensor(x)\n    y = math_ops.cast(y, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xsqsum = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    ysqsum = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xsqsum * ysqsum)\n    return tf.convert_to_tensor( K.mean(tf.constant(1.0, dtype=x.dtype) - corr ) , dtype=tf.float32 )\n\ndef build_model0() :\n    with strategy.scope() :\n        inputs = keras.layers.Input(shape = (300, ), dtype = tf.float16)\n        x = keras.layers.Dense(256, activation = 'swish')(inputs)\n        x = keras.layers.Dropout(.1)(x)\n\n        x = keras.layers.Reshape((-1, 1))(x)\n        x = keras.layers.Conv1D(16, 4, strides = 1, padding = 'same')(x)\n        x = keras.layers.MaxPool1D()(x)\n        x = keras.layers.BatchNormalization()(x)\n\n        x = keras.layers.Conv1D(32, 4, padding = 'same')(x)\n        x = keras.layers.MaxPool1D()(x)\n        x = keras.layers.BatchNormalization()(x)\n\n        x = keras.layers.Conv1D(64, 4, padding = 'same')(x)\n        x = keras.layers.MaxPool1D()(x)\n        x = keras.layers.BatchNormalization()(x)\n\n        x = keras.layers.Conv1D(128, 4, padding = 'same')(x)\n        x = keras.layers.MaxPool1D()(x)\n        x = keras.layers.BatchNormalization()(x)\n\n        x = keras.layers.Conv1D(128, 4, padding = 'same')(x)\n        x = keras.layers.MaxPool1D()(x)\n        x = keras.layers.BatchNormalization()(x)\n\n        x = keras.layers.Flatten()(x)\n\n        x1 = keras.layers.Dense(256, activation = 'swish', kernel_regularizer = 'l2')(x)\n        x2 = keras.layers.Dense(128, activation = 'swish', kernel_regularizer=  'l2')(x1)\n\n        x = keras.layers.Concatenate(axis = -1)([x1, x2])\n        x = keras.layers.Dense(64, activation = 'swish', kernel_regularizer = 'l2')(x)\n        out = keras.layers.Dense(1, activation = 'linear')(x)\n\n        model = keras.models.Model(\n            inputs = inputs,\n            outputs = out\n        )\n        model.compile(\n            optimizer = keras.optimizers.Adam(learning_rate = 7e-4),\n            loss = correlationLoss,\n            metrics = [correlationMetric, keras.metrics.RootMeanSquaredError(name = 'rmse')]\n        )\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:15.989647Z","iopub.execute_input":"2022-04-20T06:52:15.989926Z","iopub.status.idle":"2022-04-20T06:52:16.013281Z","shell.execute_reply.started":"2022-04-20T06:52:15.989896Z","shell.execute_reply":"2022-04-20T06:52:16.012136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model1() :\n    investment = keras.layers.Input(shape = (1, ), dtype = tf.uint16)\n    xinvest = InvestmentLayer(investment)\n    xinvest = keras.layers.Embedding(investment_size, 64, input_length = 1)(xinvest)\n    xinvest = keras.layers.Reshape((-1,))(xinvest)\n    \n    xinvest = keras.layers.Dense(128, activation = 'swish')(xinvest)\n    xinvest = keras.layers.Dense(128, activation = 'swish')(xinvest)\n    xinvest = keras.layers.Dense(256, activation = 'swish')(xinvest)\n    \n    feat = keras.layers.Input(shape = (300, ), dtype = tf.float16)\n    xfeat = keras.layers.BatchNormalization()(feat)\n    xfeat = keras.layers.Dense(512, activation = 'swish')(xfeat)\n    xfeat = keras.layers.Reshape((-1, 1))(xfeat)\n    \n    xfeat = keras.layers.Conv1D(16, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(32, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(32, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(64, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(64, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(128, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(256, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Flatten()(xfeat)\n    \n    x = keras.layers.Concatenate(axis = -1)([xinvest, xfeat])\n    \n    x1 = keras.layers.Dense(512, activation = 'swish', kernel_regularizer = 'l2')(x)\n    x2 = keras.layers.Dense(512, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Concatenate(axis = -1)([x1, x2, x])\n    \n    x3 = keras.layers.Dense(256, activation = 'swish', kernel_regularizer = 'l2')(x)\n    x4 = keras.layers.Dense(256, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Concatenate(axis = -1)([x3, x4, x])\n    \n    x5 = keras.layers.Dense(128, activation = 'swish', kernel_regularizer = 'l2')(x)\n    x6 = keras.layers.Dense(128, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Concatenate(axis = -1)([x1, x2, x3, x4, x5, x6])\n    x = keras.layers.Dense(64, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Dense(1, activation = 'linear')(x)\n    \n    model = keras.models.Model(\n        inputs = [investment, feat],\n        outputs = x\n    )\n    model.compile(\n        optimizer = keras.optimizers.Adam(learning_rate = 7e-4),\n        loss = correlationLoss,\n        metrics = [correlationMetric]\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:16.014736Z","iopub.execute_input":"2022-04-20T06:52:16.015032Z","iopub.status.idle":"2022-04-20T06:52:16.035678Z","shell.execute_reply.started":"2022-04-20T06:52:16.015003Z","shell.execute_reply":"2022-04-20T06:52:16.034653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_and_save_model(model, weights) :\n    model.load_weights(weights)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:16.03805Z","iopub.execute_input":"2022-04-20T06:52:16.038336Z","iopub.status.idle":"2022-04-20T06:52:16.05193Z","shell.execute_reply.started":"2022-04-20T06:52:16.038302Z","shell.execute_reply":"2022-04-20T06:52:16.050916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model0 = build_model0()\nmodels0 = [\n    load_and_save_model(model0, f'../input/cnn-just-feature/cnn_model_fold_{i}')\n    for i in range(4)\n]\nmodel1 = build_model1()\nmodels1 = [\n    load_and_save_model(model1, f'../input/cnn-train/model_fold{i}')\n    for i in range(4)\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:16.05337Z","iopub.execute_input":"2022-04-20T06:52:16.054034Z","iopub.status.idle":"2022-04-20T06:52:19.550142Z","shell.execute_reply.started":"2022-04-20T06:52:16.053998Z","shell.execute_reply":"2022-04-20T06:52:19.549235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor i, (test, sub) in enumerate(iter_test) :\n    try :\n        preds = []\n        test_ds0 = make_dataset0(test, batch_size = 512, shuffle = False)\n        for model in models0 :\n            preds.append(model.predict(test_ds0).ravel())\n        test_ds1 = make_dataset1(test, batch_size = 512, shuffle = False)\n        for model in models1 :\n            preds.append(model.predict(test_ds1).ravel())\n        preds = np.max(preds, axis = 0)\n        sub['target'] = preds\n        del test_ds0, test_ds1\n    except :\n        sub['target'] = 0\n        print(f'Exception in iter no. {i}')\n    if i == 0 :\n        display(sub)\n    env.predict(sub)\n    K.clear_session()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T06:52:19.551208Z","iopub.execute_input":"2022-04-20T06:52:19.551423Z","iopub.status.idle":"2022-04-20T06:52:23.543595Z","shell.execute_reply.started":"2022-04-20T06:52:19.551398Z","shell.execute_reply":"2022-04-20T06:52:23.542695Z"},"trusted":true},"execution_count":null,"outputs":[]}]}