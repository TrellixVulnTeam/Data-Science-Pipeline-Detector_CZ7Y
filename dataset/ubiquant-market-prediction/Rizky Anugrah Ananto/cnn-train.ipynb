{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nplt.rcParams['figure.figsize'] = (10, 9)\nplt.style.use('seaborn-darkgrid')\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom scipy.stats import pearsonr\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import IntegerLookup\n\nfrom warnings import filterwarnings, simplefilter\nfilterwarnings('ignore')\nsimplefilter('ignore')\n\nfrom tqdm.auto import tqdm\nfrom tqdm.keras import TqdmCallback\n\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-19T18:32:38.487529Z","iopub.execute_input":"2022-04-19T18:32:38.487831Z","iopub.status.idle":"2022-04-19T18:32:44.89432Z","shell.execute_reply.started":"2022-04-19T18:32:38.487752Z","shell.execute_reply":"2022-04-19T18:32:44.893591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:32:44.895864Z","iopub.execute_input":"2022-04-19T18:32:44.896094Z","iopub.status.idle":"2022-04-19T18:33:01.848705Z","shell.execute_reply.started":"2022-04-19T18:32:44.896052Z","shell.execute_reply":"2022-04-19T18:33:01.848005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset(x, y = None, batch_size = 512, shuffle = False) :\n    def preprocess(x, y) :\n        return x, y\n    feat = [col for col in x.columns if col.startswith('f_')]\n    investment = x['investment_id'].values\n    feature = x[feat].values\n    dataset = tf.data.Dataset.from_tensor_slices((\n        (investment, feature), y\n    )).map(preprocess).batch(batch_size = batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    if shuffle :\n        dataset = dataset.shuffle(500, seed = 50)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:33:01.849996Z","iopub.execute_input":"2022-04-19T18:33:01.850266Z","iopub.status.idle":"2022-04-19T18:33:01.857329Z","shell.execute_reply.started":"2022-04-19T18:33:01.850233Z","shell.execute_reply":"2022-04-19T18:33:01.856497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"investment_ids = train['investment_id'].unique()\ninvestment_size = train['investment_id'].nunique() + 1\ninvestment_size","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:33:01.859654Z","iopub.execute_input":"2022-04-19T18:33:01.860018Z","iopub.status.idle":"2022-04-19T18:33:01.916723Z","shell.execute_reply.started":"2022-04-19T18:33:01.859936Z","shell.execute_reply":"2022-04-19T18:33:01.915977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InvestmentLayer = IntegerLookup(max_tokens = investment_size)\nInvestmentLayer.adapt(\n    pd.DataFrame({\n        'investment_ids' : investment_ids.tolist()\n    })\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:33:01.917951Z","iopub.execute_input":"2022-04-19T18:33:01.9186Z","iopub.status.idle":"2022-04-19T18:33:04.827661Z","shell.execute_reply.started":"2022-04-19T18:33:01.918557Z","shell.execute_reply":"2022-04-19T18:33:04.826923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlationMetric(x, y, axis=-2):\n    from tensorflow.python.ops import math_ops\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n    x = tf.convert_to_tensor(x)\n    y = math_ops.cast(y, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return corr\n\n\ndef correlationLoss(x,y, axis=-2):\n    from tensorflow.python.ops import math_ops\n    x = tf.convert_to_tensor(x)\n    y = math_ops.cast(y, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xsqsum = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    ysqsum = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xsqsum * ysqsum)\n    return tf.convert_to_tensor( K.mean(tf.constant(1.0, dtype=x.dtype) - corr ) , dtype=tf.float32 )","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:33:04.829063Z","iopub.execute_input":"2022-04-19T18:33:04.829311Z","iopub.status.idle":"2022-04-19T18:33:04.842518Z","shell.execute_reply.started":"2022-04-19T18:33:04.829267Z","shell.execute_reply":"2022-04-19T18:33:04.841171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model() :\n    investment = keras.layers.Input(shape = (1, ), dtype = tf.uint16)\n    xinvest = InvestmentLayer(investment)\n    xinvest = keras.layers.Embedding(investment_size, 64, input_length = 1)(xinvest)\n    xinvest = keras.layers.Reshape((-1,))(xinvest)\n    \n    xinvest = keras.layers.Dense(128, activation = 'swish')(xinvest)\n    xinvest = keras.layers.Dense(128, activation = 'swish')(xinvest)\n    xinvest = keras.layers.Dense(256, activation = 'swish')(xinvest)\n    \n    feat = keras.layers.Input(shape = (300, ), dtype = tf.float16)\n    xfeat = keras.layers.BatchNormalization()(feat)\n    xfeat = keras.layers.Dense(512, activation = 'swish')(xfeat)\n    xfeat = keras.layers.Reshape((-1, 1))(xfeat)\n    \n    xfeat = keras.layers.Conv1D(16, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(32, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(32, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(64, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(64, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(128, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Conv1D(256, 4)(xfeat)\n    xfeat = keras.layers.MaxPool1D()(xfeat)\n    xfeat = keras.layers.BatchNormalization()(xfeat)\n    \n    xfeat = keras.layers.Flatten()(xfeat)\n    \n    x = keras.layers.Concatenate(axis = -1)([xinvest, xfeat])\n    \n    x1 = keras.layers.Dense(512, activation = 'swish', kernel_regularizer = 'l2')(x)\n    x2 = keras.layers.Dense(512, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Concatenate(axis = -1)([x1, x2, x])\n    \n    x3 = keras.layers.Dense(256, activation = 'swish', kernel_regularizer = 'l2')(x)\n    x4 = keras.layers.Dense(256, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Concatenate(axis = -1)([x3, x4, x])\n    \n    x5 = keras.layers.Dense(128, activation = 'swish', kernel_regularizer = 'l2')(x)\n    x6 = keras.layers.Dense(128, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Concatenate(axis = -1)([x1, x2, x3, x4, x5, x6])\n    x = keras.layers.Dense(64, activation = 'swish', kernel_regularizer = 'l2')(x)\n    \n    x = keras.layers.Dense(1, activation = 'linear')(x)\n    \n    model = keras.models.Model(\n        inputs = [investment, feat],\n        outputs = x\n    )\n    model.compile(\n        optimizer = keras.optimizers.Adam(learning_rate = 7e-4),\n        loss = correlationLoss,\n        metrics = [correlationMetric]\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:34:10.764839Z","iopub.execute_input":"2022-04-19T18:34:10.76517Z","iopub.status.idle":"2022-04-19T18:34:10.786047Z","shell.execute_reply.started":"2022-04-19T18:34:10.765127Z","shell.execute_reply":"2022-04-19T18:34:10.785145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:34:10.967948Z","iopub.execute_input":"2022-04-19T18:34:10.968476Z","iopub.status.idle":"2022-04-19T18:34:11.765722Z","shell.execute_reply.started":"2022-04-19T18:34:10.968431Z","shell.execute_reply":"2022-04-19T18:34:11.764891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_index = [\n    (\n        train.loc[(train.time_id > 800) & (train.time_id <= 1000)].index,\n        train.loc[(train.time_id > 1000)].index\n    ),\n    (\n        train.loc[(train.time_id > 900) & (train.time_id <= 1100)].index,\n        train.loc[(train.time_id > 1100)].index\n    ),\n    (\n        train.loc[(train.time_id > 1000) & (train.time_id <= 1200)].index,\n        train.loc[(train.time_id > 1200)].index\n    ),\n    (\n        train.loc[(train.time_id > 800) & (train.time_id <= 1200)].index,\n        train.loc[(train.time_id > 1200)].index\n    ),\n    (\n        train.loc[(train.time_id > 900)].index,\n        train.loc[(train.time_id > 800) & (train.time_id <= 900)].index\n    )\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:34:21.593783Z","iopub.execute_input":"2022-04-19T18:34:21.594069Z","iopub.status.idle":"2022-04-19T18:34:33.189108Z","shell.execute_reply.started":"2022-04-19T18:34:21.594032Z","shell.execute_reply":"2022-04-19T18:34:33.188328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\nK.clear_session()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:34:33.192365Z","iopub.execute_input":"2022-04-19T18:34:33.192924Z","iopub.status.idle":"2022-04-19T18:34:33.431995Z","shell.execute_reply.started":"2022-04-19T18:34:33.192869Z","shell.execute_reply":"2022-04-19T18:34:33.431301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train.pop('target')\ny","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:34:40.318876Z","iopub.execute_input":"2022-04-19T18:34:40.319125Z","iopub.status.idle":"2022-04-19T18:34:40.329304Z","shell.execute_reply.started":"2022-04-19T18:34:40.319097Z","shell.execute_reply":"2022-04-19T18:34:40.328622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\nfor i, (t, v) in enumerate(cv_index) :\n    K.clear_session()\n    xtrain = train.iloc[t, :]\n    xval = train.iloc[v, :]\n    ytrain = y.iloc[t]\n    yval = y.iloc[v]\n    \n    train_ds = make_dataset(xtrain, ytrain, shuffle = True, batch_size = 512)\n    val_ds = make_dataset(xval, yval, shuffle = False, batch_size = 512)\n    del xtrain, xval\n    gc.collect()\n    \n    model = build_model()\n    cb = [\n        keras.callbacks.EarlyStopping(patience = 10, min_delta = .001, restore_best_weights = True),\n        keras.callbacks.ReduceLROnPlateau(patience = 3, factor = .3, min_lr = 2e-5),\n        TqdmCallback(verbose = 1)\n    ]\n    history = model.fit(\n        train_ds, validation_data = val_ds,\n        epochs = 250, callbacks = cb, verbose = 0\n    )\n    yhat = model.predict(val_ds).ravel()\n    history = pd.DataFrame(history.history).loc[3:, ['val_loss', 'loss']].plot.line(figsize = (8, 8))\n    model.save_weights(f'model_fold{i}')\n    plt.show()\n    score, p = pearsonr(yval, yhat)\n    scores.append(score)\n    print(f'Pearson Fold {i} : {score}')\n    print(f'p-value Fold {i} : {p}')\n    K.clear_session()\n    del ytrain, yval, model, history, score\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:34:41.073806Z","iopub.execute_input":"2022-04-19T18:34:41.07445Z","iopub.status.idle":"2022-04-19T19:15:34.226763Z","shell.execute_reply.started":"2022-04-19T18:34:41.074411Z","shell.execute_reply":"2022-04-19T19:15:34.224827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}