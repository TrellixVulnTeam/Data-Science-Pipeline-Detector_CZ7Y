{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom cuml.svm import SVR\n\nimport random\n\nimport pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-17T13:22:17.461624Z","iopub.execute_input":"2022-02-17T13:22:17.461931Z","iopub.status.idle":"2022-02-17T13:22:21.370987Z","shell.execute_reply.started":"2022-02-17T13:22:17.461846Z","shell.execute_reply":"2022-02-17T13:22:21.370257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Prepare data","metadata":{}},{"cell_type":"code","source":"# Define col name\ndata_types_dict = {\n    'time_id': 'int16',\n    'investment_id': 'int16',\n    \"target\": 'float32',\n}\n\nfeatures = [f'f_{i}' for i in range(300)]\n\nfor f in features:\n    data_types_dict[f] = 'float32'\n    \ntrain = pd.read_csv('../input/ubiquant-market-prediction/train.csv',\n                       usecols = data_types_dict.keys(),\n                       dtype=data_types_dict,\n                       )\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:22:21.37247Z","iopub.execute_input":"2022-02-17T13:22:21.372707Z","iopub.status.idle":"2022-02-17T13:28:34.35379Z","shell.execute_reply.started":"2022-02-17T13:22:21.372673Z","shell.execute_reply":"2022-02-17T13:28:34.352943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create model and Train","metadata":{}},{"cell_type":"code","source":"N_DEVIDE_DATA = 20 #devide train data into 20 datasets, train 19 of them individually and use another to test to prevent memory leaks\nn_row = len(train)\nidx_list = list(range(n_row))\nrandom.shuffle(idx_list)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:28:34.355304Z","iopub.execute_input":"2022-02-17T13:28:34.355551Z","iopub.status.idle":"2022-02-17T13:28:37.916793Z","shell.execute_reply.started":"2022-02-17T13:28:34.355519Z","shell.execute_reply":"2022-02-17T13:28:37.91608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# train 19 datasets individually\nmodels = []\nfor i in range(N_DEVIDE_DATA-1):\n    start_idx = int(n_row/N_DEVIDE_DATA)*i\n    end_idx = int(n_row/N_DEVIDE_DATA)*(i+1)\n    devide_idx_list = idx_list[start_idx:end_idx]\n    \n    tr = train.iloc[devide_idx_list]\n    X = tr[features].to_numpy()\n    y = tr['target'].to_numpy()\n    \n    #Create model\n    model = SVR(C=1.0, kernel='rbf', epsilon=0.1)\n    \n    #Train\n    model.fit(X, y)\n    r2 = model.score(X, y)  \n    print(i,'R^2:',r2)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:43:57.42682Z","iopub.execute_input":"2022-02-17T13:43:57.427121Z","iopub.status.idle":"2022-02-17T13:45:05.606694Z","shell.execute_reply.started":"2022-02-17T13:43:57.42707Z","shell.execute_reply":"2022-02-17T13:45:05.605942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"#Read test data\nstart_idx = int(n_row/N_DEVIDE_DATA)*19\ndevide_idx_list = idx_list[start_idx:]\n\ntest = train.iloc[devide_idx_list]\nX_test = test[features].to_numpy()\ny_test = test['target'].to_numpy()\n\n#predict\npre_y=0\nfor model in models:\n    pre_y += model.predict(X_test)\npre_y /= len(models)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:02:41.051283Z","iopub.execute_input":"2022-02-17T05:02:41.05156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Result of prediction with test data\nplt.scatter(y_test,pre_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Coefficience\nnp.corrcoef(y_test.tolist(), pre_y.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"#Save model \nfor i, model in enumerate(models):\n    filename = 'model_svr_{}.sav'.format(i)\n    pickle.dump(model, open(filename, 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Model","metadata":{}},{"cell_type":"code","source":"#Read model\nmodels = []\nfor i in range(19):\n    filename = 'model_svr_{}.sav'.format(i)\n    loaded_model = pickle.load(open(filename, 'rb'))\n    models.append(loaded_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"#Predict Target\nimport ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test()\n\nfor (test_df, sample_prediction_df) in iter_test:\n    test_x = test_df[features].to_numpy()\n    \n    for loaded_model in models:\n        sample_prediction_df['target'] += loaded_model.predict(test_x)\n    sample_prediction_df['target'] /= len(models)+1\n    \n    env.predict(sample_prediction_df) \n    display(sample_prediction_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}