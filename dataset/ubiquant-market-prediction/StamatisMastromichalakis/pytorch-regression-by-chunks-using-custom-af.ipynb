{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Begin","metadata":{}},{"cell_type":"markdown","source":"This notebook is just a fork of https://www.kaggle.com/seraphwedd18/pytorch-regression-model-train-by-chunks by using custom activation function ALReLU ( https://arxiv.org/abs/2012.07564 ) instead of ReLU","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-22T08:17:26.768991Z","iopub.execute_input":"2022-01-22T08:17:26.769233Z","iopub.status.idle":"2022-01-22T08:17:26.860387Z","shell.execute_reply.started":"2022-01-22T08:17:26.769162Z","shell.execute_reply":"2022-01-22T08:17:26.859373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting Environmental Variables","metadata":{}},{"cell_type":"code","source":"import time\nimport torch\nimport random\n\ns = time.time()\n\nseed = int(np.random.randint(0, 1e9))\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Random seed:\", seed)\nprint(\"Device:\", device)\nbasic_cols = ['row_id', 'time_id', 'investment_id', 'target']\nnum_feat = 300 #total of 300 feats from f_0 to f_299\nfeatures = [f'f_{i}' for i in range(num_feat)]\ncols = basic_cols + features","metadata":{"execution":{"iopub.status.busy":"2022-01-22T08:17:26.861882Z","iopub.execute_input":"2022-01-22T08:17:26.862097Z","iopub.status.idle":"2022-01-22T08:17:28.199564Z","shell.execute_reply.started":"2022-01-22T08:17:26.862068Z","shell.execute_reply":"2022-01-22T08:17:28.198739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.__version__ ","metadata":{"execution":{"iopub.status.busy":"2022-01-22T08:33:58.156754Z","iopub.execute_input":"2022-01-22T08:33:58.157355Z","iopub.status.idle":"2022-01-22T08:33:58.164581Z","shell.execute_reply.started":"2022-01-22T08:33:58.157318Z","shell.execute_reply":"2022-01-22T08:33:58.16376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model creation and Training","metadata":{}},{"cell_type":"code","source":"# import pytorch\nfrom IPython.display import clear_output\nimport torch.optim as optim\nimport torch\n\nfrom torch import nn\n\n# import activation functions\n#import Mish.Torch.functional as Func\n\n\n\n\n@torch.jit.script\ndef ALReLU(input):\n    \"\"\"\n    Applies the ALReLU function :\n    alrelu(x) = torch.maximum(torch.abs(alpha*input), input)\n    \"\"\"\n    alpha = 0.01\n    return torch.maximum(torch.abs(alpha*input), input)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:06:26.639907Z","iopub.execute_input":"2022-01-22T09:06:26.640592Z","iopub.status.idle":"2022-01-22T09:06:26.649092Z","shell.execute_reply.started":"2022-01-22T09:06:26.64055Z","shell.execute_reply":"2022-01-22T09:06:26.648424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionModel(torch.nn.Module):\n    def __init__(self, in_shape, out_shape, hidden, device='cpu'):\n        super().__init__()\n        self.in_shape = in_shape\n        self.out_shape = out_shape\n        self.hidden = hidden\n        self.device = device\n        self.initialize_weights()\n        \n    def initialize_weights(self):\n        self.w1 = torch.nn.Parameter(torch.randn((self.hidden, self.in_shape), device=self.device, requires_grad=True))\n        self.w2 = torch.nn.Parameter(torch.randn((self.out_shape, self.hidden), device=self.device, requires_grad=True))\n        self.b1 = torch.nn.Parameter(torch.randn(1, device=self.device, requires_grad=True))\n        self.b2 = torch.nn.Parameter(torch.randn(1, device=self.device, requires_grad=True))\n    \n    def forward(self, x):\n        #basic linear computation\n        y_hat = torch.add(torch.mm(self.w1, x.t()), self.b1)\n        #Apply ALReLU\n        y_hat = ALReLU(y_hat)\n        #return regression out\n        return torch.add(torch.mm(self.w2, y_hat), self.b2)\n\nclass PredModel(torch.nn.Module):\n    def __init__(self, in_shape, out_shape, hidden, device='cpu'):\n        super().__init__()\n        self.in_shape = in_shape\n        self.out_shape = out_shape\n        self.hidden = hidden\n        self.device = device\n        # We will be considering a multi-tower construct with varying\n        # sized of hidden nodes\n        # Tower 1\n        self.t1 = RegressionModel(self.in_shape, self.hidden//4, self.hidden, self.device)\n        self.t2 = RegressionModel(self.in_shape, self.hidden//4, self.hidden//2, self.device)\n        self.t3 = RegressionModel(self.in_shape, self.hidden//4, self.hidden//4, self.device)\n        self.out = RegressionModel(self.hidden//4, self.out_shape, self.hidden//4, self.device)\n    \n    def forward(self, x):\n        #get sum of each tower\n        y_hat = torch.add(self.t1(x), torch.add(self.t2(x), self.t3(x)))\n        #get average\n        y_hat = torch.mul(y_hat, 1/3)\n        y_hat = self.out(y_hat.t())\n        return y_hat","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:08:02.485203Z","iopub.execute_input":"2022-01-22T09:08:02.485797Z","iopub.status.idle":"2022-01-22T09:08:02.499701Z","shell.execute_reply.started":"2022-01-22T09:08:02.48576Z","shell.execute_reply":"2022-01-22T09:08:02.498023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef loss(y_predicted, y_target):\n    #RMSE Loss\n    return torch.sqrt(torch.mean((y_predicted - y_target)**2))\n\nmodel = PredModel(num_feat, 1, 64, device)\n\nverbose = 25\nepochs = 1000\nchunks = 900000\ntol = 500\n\nfor q, data in enumerate(pd.read_csv(\n    \"../input/ubiquant-market-prediction/train.csv\", usecols=cols, chunksize=chunks)):\n    #Initialize weights and biases\n    optimizer = optim.Adam(model.parameters(), lr=0.01/(2**q))\n    \n    clear_output(wait=True)\n    print(f\"Currently training on {q*chunks} to {(q+1)*chunks}:\")\n    min_loss = np.inf\n    cnt = 0\n    \n    x_dataset = torch.tensor(data[features].values, dtype=torch.float).to(device)\n    y_dataset = torch.tensor(data['target'].values, dtype=torch.float).to(device)\n    \n    # Main optimization loop\n    for t in range(1, epochs+1):\n        # Set the gradients to 0.\n        optimizer.zero_grad()\n        # Compute the current predicted y's from x_dataset\n        y_predicted = model(x_dataset)\n        # See how far off the prediction is\n        current_loss = loss(y_predicted, y_dataset)\n        # Compute the gradient of the loss\n        current_loss.backward()\n        # Update model W and b accordingly.\n        optimizer.step()\n        \n        #Check for early stopping\n        if current_loss >= min_loss:\n            cnt += 1\n            if cnt >= tol:\n                print(\"Early stopping!\")\n                break\n        else:\n            min_loss = current_loss\n            cnt = 0\n\n        if t%verbose==0:\n            print(f\"epoch = {t:4}/{epochs}, loss = {current_loss:.8f}, min_loss = {min_loss:.8f}, count = {cnt}\")\n    \n    print(f\"Total time spent: {time.time()-s:.4f} seconds\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-22T09:08:09.620844Z","iopub.execute_input":"2022-01-22T09:08:09.621106Z","iopub.status.idle":"2022-01-22T09:19:19.647257Z","shell.execute_reply.started":"2022-01-22T09:08:09.621076Z","shell.execute_reply":"2022-01-22T09:19:19.646495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:19:35.35169Z","iopub.execute_input":"2022-01-22T09:19:35.352876Z","iopub.status.idle":"2022-01-22T09:19:35.5649Z","shell.execute_reply.started":"2022-01-22T09:19:35.352836Z","shell.execute_reply":"2022-01-22T09:19:35.56414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_x = torch.tensor(test_df[features].values, dtype=torch.float).to(device)\n    pred = model(test_x)\n    sample_prediction_df['target'] = pred.detach().cpu().numpy().T\n    env.predict(sample_prediction_df) \n    display(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:19:37.32056Z","iopub.execute_input":"2022-01-22T09:19:37.321048Z","iopub.status.idle":"2022-01-22T09:19:37.438591Z","shell.execute_reply.started":"2022-01-22T09:19:37.321015Z","shell.execute_reply":"2022-01-22T09:19:37.437969Z"},"trusted":true},"execution_count":null,"outputs":[]}]}