{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom scipy import stats\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import *\nimport warnings\n\nimport pickle\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:29.687675Z","iopub.execute_input":"2022-02-21T05:02:29.688421Z","iopub.status.idle":"2022-02-21T05:02:37.010969Z","shell.execute_reply.started":"2022-02-21T05:02:29.688328Z","shell.execute_reply":"2022-02-21T05:02:37.010159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nn_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:37.012867Z","iopub.execute_input":"2022-02-21T05:02:37.013134Z","iopub.status.idle":"2022-02-21T05:02:53.393897Z","shell.execute_reply.started":"2022-02-21T05:02:37.013097Z","shell.execute_reply":"2022-02-21T05:02:53.393081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:53.395247Z","iopub.execute_input":"2022-02-21T05:02:53.395717Z","iopub.status.idle":"2022-02-21T05:02:53.402174Z","shell.execute_reply.started":"2022-02-21T05:02:53.395678Z","shell.execute_reply":"2022-02-21T05:02:53.401274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:53.403442Z","iopub.execute_input":"2022-02-21T05:02:53.403825Z","iopub.status.idle":"2022-02-21T05:02:53.435232Z","shell.execute_reply.started":"2022-02-21T05:02:53.403787Z","shell.execute_reply":"2022-02-21T05:02:53.434373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"investment_id = train.pop(\"investment_id\")\ninvestment_id.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:53.437856Z","iopub.execute_input":"2022-02-21T05:02:53.438134Z","iopub.status.idle":"2022-02-21T05:02:53.455498Z","shell.execute_reply.started":"2022-02-21T05:02:53.438089Z","shell.execute_reply":"2022-02-21T05:02:53.45447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = train.pop(\"time_id\")","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:53.457036Z","iopub.execute_input":"2022-02-21T05:02:53.457808Z","iopub.status.idle":"2022-02-21T05:02:53.46999Z","shell.execute_reply.started":"2022-02-21T05:02:53.457769Z","shell.execute_reply":"2022-02-21T05:02:53.469244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train.pop(\"target\")\ny.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:53.471414Z","iopub.execute_input":"2022-02-21T05:02:53.471701Z","iopub.status.idle":"2022-02-21T05:02:53.485506Z","shell.execute_reply.started":"2022-02-21T05:02:53.471664Z","shell.execute_reply":"2022-02-21T05:02:53.48472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ninvestment_ids = list(investment_id.unique())\ninvestment_id_size = len(investment_ids) + 1\ninvestment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\ninvestment_id_lookup_layer.adapt(pd.DataFrame({\"investment_ids\":investment_ids}))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:53.487222Z","iopub.execute_input":"2022-02-21T05:02:53.487743Z","iopub.status.idle":"2022-02-21T05:02:56.169373Z","shell.execute_reply.started":"2022-02-21T05:02:53.487704Z","shell.execute_reply":"2022-02-21T05:02:56.168588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndef preprocess(X, y):\n    return X, y\ndef make_dataset(feature, investment_id, y, batch_size=1024, mode=\"train\"):\n    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature), y))\n    ds = ds.map(preprocess)\n    if mode == \"train\":\n        ds = ds.shuffle(4096)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:56.170984Z","iopub.execute_input":"2022-02-21T05:02:56.171424Z","iopub.status.idle":"2022-02-21T05:02:56.178406Z","shell.execute_reply.started":"2022-02-21T05:02:56.171383Z","shell.execute_reply":"2022-02-21T05:02:56.177356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(128, activation='relu')(investment_id_x)\n    investment_id_x = layers.Dense(128, activation='relu')(investment_id_x)\n\n    feature_x = layers.Dense(128, activation='relu')(features_inputs)\n    feature_x = layers.Dense(128, activation='relu')(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(256, activation='swish', kernel_regularizer=\"l2\")(x)\n\n\n\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:56.179816Z","iopub.execute_input":"2022-02-21T05:02:56.180144Z","iopub.status.idle":"2022-02-21T05:02:56.192249Z","shell.execute_reply.started":"2022-02-21T05:02:56.180094Z","shell.execute_reply":"2022-02-21T05:02:56.19126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:56.194012Z","iopub.execute_input":"2022-02-21T05:02:56.194789Z","iopub.status.idle":"2022-02-21T05:02:56.695108Z","shell.execute_reply.started":"2022-02-21T05:02:56.194747Z","shell.execute_reply":"2022-02-21T05:02:56.694247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(5, shuffle=True, random_state=42)\nmodels = []\nfor index, (train_indices, valid_indices) in enumerate(kfold.split(train, investment_id)):\n    X_train, X_val = train.iloc[train_indices], train.iloc[valid_indices]\n    investment_id_train = investment_id[train_indices]\n    y_train, y_val = y.iloc[train_indices], y.iloc[valid_indices]\n    investment_id_val = investment_id[valid_indices]\n    train_ds = make_dataset(X_train, investment_id_train, y_train)\n    valid_ds = make_dataset(X_val, investment_id_val, y_val, mode=\"valid\")\n    model = get_model()\n    checkpoint = keras.callbacks.ModelCheckpoint(f\"model_{index}\", save_best_only=True)\n    early_stop = keras.callbacks.EarlyStopping(patience=10)\n    history = model.fit(train_ds, epochs=20, validation_data=valid_ds, callbacks=[checkpoint, early_stop])\n    model = keras.models.load_model(f\"model_{index}\")\n    models.append(model)\n    \n    pearson_score = stats.pearsonr(model.predict(valid_ds).ravel(), y_val.values)[0]\n    print('Pearson:', pearson_score)\n    pd.DataFrame(history.history, columns=[\"mse\", \"val_mse\"]).plot()\n    plt.title(\"MSE\")\n    plt.show()\n    pd.DataFrame(history.history, columns=[\"mae\", \"val_mae\"]).plot()\n    plt.title(\"MAE\")\n    plt.show()\n    pd.DataFrame(history.history, columns=[\"rmse\", \"val_rmse\"]).plot()\n    plt.title(\"RMSE\")\n    plt.show()\n    del investment_id_train\n    del investment_id_val\n    del X_train\n    del X_val\n    del y_train\n    del y_val\n    del train_ds\n    del valid_ds\n    gc.collect()\n    break","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:02:56.696672Z","iopub.execute_input":"2022-02-21T05:02:56.697593Z","iopub.status.idle":"2022-02-21T05:07:12.536374Z","shell.execute_reply.started":"2022-02-21T05:02:56.697526Z","shell.execute_reply":"2022-02-21T05:07:12.535478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test(investment_id, feature):\n    return (investment_id, feature), 0\ndef make_test_dataset(feature, investment_id, batch_size=1024):\n    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature)))\n    ds = ds.map(preprocess_test)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\ndef inference(models, ds):\n    y_preds = []\n    for model in models:\n        y_pred = model.predict(ds)\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T05:07:12.539006Z","iopub.execute_input":"2022-02-21T05:07:12.539315Z","iopub.status.idle":"2022-02-21T05:07:12.545948Z","shell.execute_reply.started":"2022-02-21T05:07:12.539274Z","shell.execute_reply":"2022-02-21T05:07:12.545043Z"},"trusted":true},"execution_count":null,"outputs":[]}]}