{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:10:37.455239Z","iopub.execute_input":"2022-01-21T14:10:37.455628Z","iopub.status.idle":"2022-01-21T14:10:38.614887Z","shell.execute_reply.started":"2022-01-21T14:10:37.45552Z","shell.execute_reply":"2022-01-21T14:10:38.61384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook contains an initial EDA of train dataset for the [Ubiquant Market Prediction competition](https://www.kaggle.com/c/ubiquant-market-prediction) as well as a simple baseline model training and inference. Here I analyze the overall structure of the dataset, the distributions of different features, and the correlation of features and target.","metadata":{}},{"cell_type":"markdown","source":"# Basic EDA","metadata":{}},{"cell_type":"markdown","source":"Let's load the data and look a the high-level data structure.","metadata":{}},{"cell_type":"code","source":"data_types_dict = {\n#     'time_id': 'int32',\n    'investment_id': 'int16',\n    \"target\": 'float16',\n}\n\nfeatures = [f'f_{i}' for i in range(300)]\n\nfor f in features:\n    data_types_dict[f] = 'float16'\n    \ntarget = 'target'","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:10:38.616477Z","iopub.execute_input":"2022-01-21T14:10:38.616736Z","iopub.status.idle":"2022-01-21T14:10:38.622762Z","shell.execute_reply.started":"2022-01-21T14:10:38.616699Z","shell.execute_reply":"2022-01-21T14:10:38.621722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/ubiquant-market-prediction/train.csv', \n#                        nrows=5 * 10**3,\n                       usecols = data_types_dict.keys(),\n                       dtype=data_types_dict)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:10:38.623797Z","iopub.execute_input":"2022-01-21T14:10:38.624385Z","iopub.status.idle":"2022-01-21T14:17:55.071963Z","shell.execute_reply.started":"2022-01-21T14:10:38.624351Z","shell.execute_reply":"2022-01-21T14:17:55.070378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:17:55.074561Z","iopub.execute_input":"2022-01-21T14:17:55.074871Z","iopub.status.idle":"2022-01-21T14:17:55.37256Z","shell.execute_reply.started":"2022-01-21T14:17:55.074828Z","shell.execute_reply":"2022-01-21T14:17:55.371703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our dataset contains 300 anonymous features that don't have any description, `investment_id,` and target that is also some anonymous float value.","metadata":{}},{"cell_type":"markdown","source":"## Target","metadata":{}},{"cell_type":"code","source":"train_df['target'].hist(bins = 100, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:17:55.37518Z","iopub.execute_input":"2022-01-21T14:17:55.375401Z","iopub.status.idle":"2022-01-21T14:17:56.273247Z","shell.execute_reply.started":"2022-01-21T14:17:55.375375Z","shell.execute_reply":"2022-01-21T14:17:56.272348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target values look quite normal without any outliers or long tails. We should not have any problems working with it. Let's also plot distributions of targets of a few random features:","metadata":{}},{"cell_type":"code","source":"for f in np.random.choice(train_df['investment_id'].unique(), 10):\n    train_df[train_df['investment_id'] == f]['target'].hist(bins = 100, alpha = 0.2, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:17:56.274617Z","iopub.execute_input":"2022-01-21T14:17:56.274833Z","iopub.status.idle":"2022-01-21T14:17:58.954895Z","shell.execute_reply.started":"2022-01-21T14:17:56.274807Z","shell.execute_reply":"2022-01-21T14:17:58.953943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On a high-level target for each investment_id also looks ok.","metadata":{}},{"cell_type":"markdown","source":"## Investment_id","metadata":{}},{"cell_type":"code","source":"train_df['investment_id'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:17:58.956247Z","iopub.execute_input":"2022-01-21T14:17:58.956464Z","iopub.status.idle":"2022-01-21T14:17:58.986266Z","shell.execute_reply.started":"2022-01-21T14:17:58.956437Z","shell.execute_reply":"2022-01-21T14:17:58.985463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['investment_id'].value_counts().plot(kind = 'bar',figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:17:58.98737Z","iopub.execute_input":"2022-01-21T14:17:58.987579Z","iopub.status.idle":"2022-01-21T14:18:44.548631Z","shell.execute_reply.started":"2022-01-21T14:17:58.987554Z","shell.execute_reply":"2022-01-21T14:18:44.547608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 3579 different investments, and most of them have a substantial amount of data points and probably don't require any filtering so far.","metadata":{}},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"markdown","source":"It is hard to analyze all features one by one, but let's do so aggregated analysis. First of all, let's just look at some features distributions.","metadata":{}},{"cell_type":"code","source":"f = 'f_67'\ntrain_df[f].hist(bins = 100, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:18:44.550005Z","iopub.execute_input":"2022-01-21T14:18:44.550272Z","iopub.status.idle":"2022-01-21T14:18:45.387324Z","shell.execute_reply.started":"2022-01-21T14:18:44.550229Z","shell.execute_reply":"2022-01-21T14:18:45.386645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = 'f_109'\ntrain_df[f].hist(bins = 100, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:18:45.388748Z","iopub.execute_input":"2022-01-21T14:18:45.388971Z","iopub.status.idle":"2022-01-21T14:18:46.200486Z","shell.execute_reply.started":"2022-01-21T14:18:45.388944Z","shell.execute_reply":"2022-01-21T14:18:46.199884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = 'f_62'\ntrain_df[f].hist(bins = 100, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:18:46.201505Z","iopub.execute_input":"2022-01-21T14:18:46.202224Z","iopub.status.idle":"2022-01-21T14:18:46.944435Z","shell.execute_reply.started":"2022-01-21T14:18:46.202187Z","shell.execute_reply":"2022-01-21T14:18:46.943819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = 'f_234'\ntrain_df[f].hist(bins = 100, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:18:46.945674Z","iopub.execute_input":"2022-01-21T14:18:46.946575Z","iopub.status.idle":"2022-01-21T14:18:47.783149Z","shell.execute_reply.started":"2022-01-21T14:18:46.946523Z","shell.execute_reply":"2022-01-21T14:18:47.782101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = 'f_164'\ntrain_df[f].hist(bins = 100, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:18:47.784737Z","iopub.execute_input":"2022-01-21T14:18:47.785088Z","iopub.status.idle":"2022-01-21T14:18:48.630115Z","shell.execute_reply.started":"2022-01-21T14:18:47.785042Z","shell.execute_reply":"2022-01-21T14:18:48.629107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some features look normal, but most have outliers, skewed distribution, and multiple modes. Probably the analysis of features one by one will bring a lot of value later in the competition, but we will not go deep into it in this notebook.","metadata":{}},{"cell_type":"code","source":"train_df[features].nunique().hist()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:18:48.634582Z","iopub.execute_input":"2022-01-21T14:18:48.634885Z","iopub.status.idle":"2022-01-21T14:19:13.289875Z","shell.execute_reply.started":"2022-01-21T14:18:48.63485Z","shell.execute_reply":"2022-01-21T14:19:13.289058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All features have a lot of unique values, so they either float or have some added noise to hide the integer/categorical nature.","metadata":{}},{"cell_type":"markdown","source":"## Features interaction","metadata":{}},{"cell_type":"markdown","source":"We will do analysis on a smaller random 1% samle of the dataset to speed up the process.","metadata":{}},{"cell_type":"code","source":"sample_df = train_df.sample(frac = 0.01)\nsample_df","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:19:13.291366Z","iopub.execute_input":"2022-01-21T14:19:13.291764Z","iopub.status.idle":"2022-01-21T14:19:13.634838Z","shell.execute_reply.started":"2022-01-21T14:19:13.291731Z","shell.execute_reply":"2022-01-21T14:19:13.633972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation = sample_df[[target] + features].corr()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:19:13.636227Z","iopub.execute_input":"2022-01-21T14:19:13.636458Z","iopub.status.idle":"2022-01-21T14:19:21.322645Z","shell.execute_reply.started":"2022-01-21T14:19:13.636431Z","shell.execute_reply":"2022-01-21T14:19:21.3218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation['target'].iloc[1:].hist(bins = 20, figsize = (20,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:19:21.324119Z","iopub.execute_input":"2022-01-21T14:19:21.324439Z","iopub.status.idle":"2022-01-21T14:19:21.60983Z","shell.execute_reply.started":"2022-01-21T14:19:21.324396Z","shell.execute_reply":"2022-01-21T14:19:21.608915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no strong correlation between features and target. Let's look at the correlation of features with each other.","metadata":{}},{"cell_type":"code","source":"sns.clustermap(correlation, figsize=(20, 20))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:19:21.611197Z","iopub.execute_input":"2022-01-21T14:19:21.611431Z","iopub.status.idle":"2022-01-21T14:19:24.752639Z","shell.execute_reply.started":"2022-01-21T14:19:21.611401Z","shell.execute_reply":"2022-01-21T14:19:24.751842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are definitely some clusters of highly correlated features that can be later analyzed together.","metadata":{}},{"cell_type":"markdown","source":"## Feature engeneering","metadata":{}},{"cell_type":"markdown","source":"Let's take some top features from the last run of the notebook, look at them and generate some interactions.","metadata":{}},{"cell_type":"code","source":"top_feautures = ['f_74', 'f_153', 'f_145', 'f_108', 'f_231']","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:19:24.754106Z","iopub.execute_input":"2022-01-21T14:19:24.75463Z","iopub.status.idle":"2022-01-21T14:19:24.759367Z","shell.execute_reply.started":"2022-01-21T14:19:24.754589Z","shell.execute_reply":"2022-01-21T14:19:24.758385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from seaborn import pairplot\nsample_df = train_df.sample(10000).reset_index()\npairplot(sample_df[top_feautures + ['target']])","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:19:24.760558Z","iopub.execute_input":"2022-01-21T14:19:24.760794Z","iopub.status.idle":"2022-01-21T14:20:41.187487Z","shell.execute_reply.started":"2022-01-21T14:19:24.760746Z","shell.execute_reply":"2022-01-21T14:20:41.186277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"gen_features = []\n\nfor i, f1 in enumerate(top_feautures[:-1]):\n    for j, f2 in enumerate(top_feautures[i+1:]):\n        train_df[f\"{f1}*{f2}\"] = train_df[f1] * train_df[f2]\n        train_df[f\"{f1}/{f2}\"] = train_df[f1] / train_df[f2]\n        \n        gen_features.append(f\"{f1}*{f2}\")\n        gen_features.append(f\"{f1}/{f2}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:20:41.189072Z","iopub.execute_input":"2022-01-21T14:20:41.189324Z","iopub.status.idle":"2022-01-21T14:20:41.975355Z","shell.execute_reply.started":"2022-01-21T14:20:41.189296Z","shell.execute_reply":"2022-01-21T14:20:41.974592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:20:41.976949Z","iopub.execute_input":"2022-01-21T14:20:41.977258Z","iopub.status.idle":"2022-01-21T14:20:43.117702Z","shell.execute_reply.started":"2022-01-21T14:20:41.977218Z","shell.execute_reply":"2022-01-21T14:20:43.116937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will use LGBMRegressor to train a simple baseline model.","metadata":{}},{"cell_type":"code","source":"features += gen_features","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:20:43.118975Z","iopub.execute_input":"2022-01-21T14:20:43.119188Z","iopub.status.idle":"2022-01-21T14:20:43.123297Z","shell.execute_reply.started":"2022-01-21T14:20:43.119161Z","shell.execute_reply":"2022-01-21T14:20:43.122205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold \nseed = 0\nfolds = 15\nmodels = []\n\nskf = StratifiedKFold(folds, shuffle = True, random_state = seed)\n\nfor train_index, test_index in skf.split(train_df, train_df['investment_id']):\n    train = train_df.iloc[train_index]\n    valid = train_df.iloc[test_index]\n    \n    lgbm = LGBMRegressor(\n        num_leaves=31,\n        n_estimators = 1500,\n        min_child_samples = 1000, \n        subsample=0.7, \n        subsample_freq=1,\n        n_jobs= -1\n    )\n\n    lgbm.fit(train[features], train[target], eval_set = (valid[features], valid[target]), early_stopping_rounds = 10)\n    models.append(lgbm)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-21T14:20:43.124842Z","iopub.execute_input":"2022-01-21T14:20:43.125138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm\nlightgbm.plot_importance(lgbm, figsize = (20, 60))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    for i, f1 in enumerate(top_feautures[:-1]):\n        for j, f2 in enumerate(top_feautures[i+1:]):\n            test_df[f\"{f1}*{f2}\"] = test_df[f1] * test_df[f2]\n            test_df[f\"{f1}/{f2}\"] = test_df[f1] / test_df[f2]\n    \n    test_df['target']  = 0\n    \n    for lgbm in models:\n        test_df['target'] += lgbm.predict(test_df[features])\n    test_df['target'] /= len(models)\n    env.predict(test_df[['row_id','target']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}