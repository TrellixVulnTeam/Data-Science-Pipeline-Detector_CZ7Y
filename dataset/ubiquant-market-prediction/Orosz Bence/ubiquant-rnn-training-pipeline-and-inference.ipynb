{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nThis is my starter notebook for how to start with a recurrent neural network in this competition. It has much room for improvement, but hopefully this gives you a baseline to work with. \n\nThis notebook currently score .142 on the latest version. I also have a lgbm training pipeline in this notebook that scores a .133 but it is not used in this inference.\n\nThe training pipelines are attached, the models were trained offline, and the weights are attached for inference.\n\n## Model\n- 300 feature input\n- Batch Normalization\n- Dense feature extractor with dropout\n- Reshape and Batch Normalization to setup for RNN\n- LSTM layers\n- Dense head\n\nSee diagram below\n\n## Callbacks\n- ReduceLROnPlateau\n- ModelCheckpoint\n- EarlyStopping\n\n## Future Ideas\n- add new input features\n- add investment_id as an input with an embedding layer\n- use attention\n- try different callbacks, learning rates, loss functions, etc\n- try 1-D CNN","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image, display\ndisplay(Image(filename=\"../input/ubiquant-models/saved_models/images/rnn_v2.png\", width = 210, height = 65))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:10.298213Z","iopub.execute_input":"2022-04-07T14:27:10.298552Z","iopub.status.idle":"2022-04-07T14:27:10.347683Z","shell.execute_reply.started":"2022-04-07T14:27:10.298458Z","shell.execute_reply":"2022-04-07T14:27:10.347068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport pickle\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import GroupKFold\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-07T14:27:10.348847Z","iopub.execute_input":"2022-04-07T14:27:10.34918Z","iopub.status.idle":"2022-04-07T14:27:19.546981Z","shell.execute_reply.started":"2022-04-07T14:27:10.349154Z","shell.execute_reply":"2022-04-07T14:27:19.54631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"def setup_cv(df, X, y, groups, splits=5):\n    kf = GroupKFold(n_splits=splits)\n    for f, (t_, v_) in enumerate(kf.split(X=X, y=y, groups=groups)):\n            df.loc[v_, 'fold'] = f\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:19.548049Z","iopub.execute_input":"2022-04-07T14:27:19.548383Z","iopub.status.idle":"2022-04-07T14:27:19.554864Z","shell.execute_reply.started":"2022-04-07T14:27:19.548355Z","shell.execute_reply":"2022-04-07T14:27:19.552243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models\n\n## RNN","metadata":{}},{"cell_type":"code","source":"def get_rnn_v2():\n    f300_in = L.Input(shape=(300,), name='300 feature input')\n    x = L.BatchNormalization(name='batch_norm1')(f300_in)\n    x = L.Dense(256, activation='swish', name='dense1')(x)\n    x = L.Dropout(0.1, name='dropout1')(x)\n    x = L.Reshape((1, -1), name='reshape1')(x)\n    x = L.BatchNormalization(name='batch_norm2')(x)\n    x = L.LSTM(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True, activation='relu', name='lstm1')(x)\n    x = L.LSTM(16, dropout=0.1, return_sequences=False, activation='relu', name='lstm2')(x)\n    output_layer = L.Dense(1, name='output')(x)\n\n    model = M.Model([f300_in], \n                    [output_layer])\n\n    model.compile(optimizer=tf.optimizers.Adam(lr=0.001),\n                  loss='mse', metrics=['mse'])\n\n    return model\n\nclass UbiquantRNNV2:\n    def __init__(self, df: pd.DataFrame, feature_cols: list=None, target: str='target'):\n\n        self.model = get_rnn_v2()\n\n        self.df = df\n\n        if feature_cols is not None:\n            self.feature_cols = feature_cols\n        else:\n            self.feature_cols = [f\"f_{i}\" for i in range(300)]\n\n        self.target_col = target\n\n    def train_one_fold(self, f: int, max_epochs=10):\n        X_train = self.df[self.df.fold!=f][self.feature_cols]\n        X_valid = self.df[self.df.fold==f][self.feature_cols]\n\n        y_train = self.df[self.df.fold!=f][self.target_col]\n        y_valid = self.df[self.df.fold==f][self.target_col]\n\n        self.model.fit(X_train, y_train,\n                       validation_data=(X_valid, y_valid),\n                       batch_size=128, epochs=max_epochs,\n                       callbacks=[\n                         ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='min'),\n                         ModelCheckpoint(f'RNN_v2_checkpoint_{f}.hdf5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min'),\n                         EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, mode='min', baseline=None, restore_best_weights=True)\n            ])\n\n        oof = self.model.predict(X_valid)\n        oof_score = np.sqrt(mean_squared_error(y_valid, oof))\n        print(f'oof rmse: {oof_score}')\n\n    def predict(self, X: np.ndarray):\n        preds = self.model.predict(X)\n        return preds\n\n    def save(self, path: str):\n        pickle.dump(self.model, open(path, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:19.556857Z","iopub.execute_input":"2022-04-07T14:27:19.55712Z","iopub.status.idle":"2022-04-07T14:27:19.582947Z","shell.execute_reply.started":"2022-04-07T14:27:19.557087Z","shell.execute_reply":"2022-04-07T14:27:19.582162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM","metadata":{}},{"cell_type":"code","source":"class UbiquantLGBM:\n    \"\"\"\n    This class is the Training Pipeline for an LGBM Regressor\n    \"\"\"\n    def __init__(self, df: pd.DataFrame, feature_cols: list=None, target: str='target'):\n        \"\"\" Creates the pipeline \"\"\"\n        params = {\n            'random_state': 42, \n            'verbosity': -1,\n            'metrics': 'rmse',\n        }  \n        self.model = LGBMRegressor(**params)\n\n        self.df = df\n\n        if feature_cols is not None:\n            self.feature_cols = feature_cols\n        else:\n            self.feature_cols = [f\"f_{i}\" for i in range(300)]\n\n        self.target_col = target\n\n    def train_one_fold(self, f: int):\n        \"\"\" Trains one fold of the lgbm \"\"\"\n        X_train = self.df[self.df.fold!=f][self.feature_cols]\n        X_valid = self.df[self.df.fold==f][self.feature_cols]\n\n        y_train = self.df[self.df.fold!=f][self.target_col]\n        y_valid = self.df[self.df.fold==f][self.target_col]\n\n        self.model.fit(X_train, y_train, \n                       eval_set=[(X_valid, y_valid)],\n                       eval_metric='rmse',\n                       verbose=False,\n                       early_stopping_rounds=30)\n\n        oof = self.model.predict(X_valid)\n        oof_score = np.sqrt(mean_squared_error(y_valid, oof))\n        print(f'oof rmse: {oof_score}')\n\n    def predict(self, X: np.ndarray):\n        \"\"\" Makes a prediction with the model \"\"\"\n        preds = self.model.predict(X)\n        return preds\n\n    def save(self, path: str):\n        \"\"\"Saves the model \"\"\"\n        pickle.dump(self.model, open(path, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:19.584223Z","iopub.execute_input":"2022-04-07T14:27:19.584911Z","iopub.status.idle":"2022-04-07T14:27:19.603647Z","shell.execute_reply.started":"2022-04-07T14:27:19.584875Z","shell.execute_reply":"2022-04-07T14:27:19.602905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def load_model(file_path):\n    \"\"\" Loads a model pipeline object \"\"\"\n    file = open(file_path,'rb')\n    model = pickle.load(file)\n    file.close()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:19.604923Z","iopub.execute_input":"2022-04-07T14:27:19.605186Z","iopub.status.idle":"2022-04-07T14:27:19.621786Z","shell.execute_reply.started":"2022-04-07T14:27:19.605154Z","shell.execute_reply":"2022-04-07T14:27:19.621155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Define our model with the trained weights \"\"\"\nrnn0 = get_rnn_v2()\nrnn0.load_weights(\"../input/ubiquant-models/saved_models/rnn_checkpoints/RNN_v2_checkpoint_0.hdf5\")\nrnn1 = get_rnn_v2()\nrnn1.load_weights(\"../input/ubiquant-models/saved_models/rnn_checkpoints/RNN_v2_checkpoint_1.hdf5\")\nrnn2 = get_rnn_v2()\nrnn2.load_weights(\"../input/ubiquant-models/saved_models/rnn_checkpoints/RNN_v2_checkpoint_2.hdf5\")\nrnn3 = get_rnn_v2()\nrnn3.load_weights(\"../input/ubiquant-models/saved_models/rnn_checkpoints/RNN_v2_checkpoint_3.hdf5\")\nrnn4 = get_rnn_v2()\nrnn4.load_weights(\"../input/ubiquant-models/saved_models/rnn_checkpoints/RNN_v2_checkpoint_4.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:19.622846Z","iopub.execute_input":"2022-04-07T14:27:19.623394Z","iopub.status.idle":"2022-04-07T14:27:21.441747Z","shell.execute_reply.started":"2022-04-07T14:27:19.62332Z","shell.execute_reply":"2022-04-07T14:27:21.440594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Make predictions for competition \"\"\"\nimport ubiquant\nenv = ubiquant.make_env()  \niter_test = env.iter_test()\nfeats = [f\"f_{i}\" for i in range(300)]\n\nfor (test_df, sample_prediction_df) in iter_test:\n    test_300 = test_df[feats]\n    test_invest_id = test_df[['investment_id']]\n    \n    pred0 = rnn0.predict(test_300)\n    pred1 = rnn1.predict(test_300)\n    pred2 = rnn2.predict(test_300)\n    pred3 = rnn3.predict(test_300)\n    pred4 = rnn4.predict(test_300)\n    pred = np.mean([pred0, pred1, pred2, pred3, pred4], axis=0)\n    \n    sample_prediction_df['target'] = pred\n    env.predict(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:21.442837Z","iopub.execute_input":"2022-04-07T14:27:21.4433Z","iopub.status.idle":"2022-04-07T14:27:26.227754Z","shell.execute_reply.started":"2022-04-07T14:27:21.443258Z","shell.execute_reply":"2022-04-07T14:27:26.226867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:27:26.228887Z","iopub.execute_input":"2022-04-07T14:27:26.229135Z","iopub.status.idle":"2022-04-07T14:27:26.244764Z","shell.execute_reply.started":"2022-04-07T14:27:26.229103Z","shell.execute_reply":"2022-04-07T14:27:26.243649Z"},"trusted":true},"execution_count":null,"outputs":[]}]}