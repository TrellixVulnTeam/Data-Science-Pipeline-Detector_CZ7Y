{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# My ML Aproach Simple DNN...\nThe steps you are going to cover in this tutorial are as follows:\n\n* Load Data.\n* Define Keras Model.\n* Compile Keras Model.\n* Fit Keras Model.\n* Evaluate Keras Model.\n* Tie It All Together.\n* Make Predictions","metadata":{}},{"cell_type":"markdown","source":"# 1. Loading Libraries.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-13T21:29:06.853291Z","iopub.execute_input":"2022-02-13T21:29:06.854031Z","iopub.status.idle":"2022-02-13T21:29:06.869597Z","shell.execute_reply.started":"2022-02-13T21:29:06.853948Z","shell.execute_reply":"2022-02-13T21:29:06.868884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom sklearn.model_selection import StratifiedKFold\nimport gc\n\n# Datatable Libraries...\nimport datatable as dt","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:06.875294Z","iopub.execute_input":"2022-02-13T21:29:06.877932Z","iopub.status.idle":"2022-02-13T21:29:10.5086Z","shell.execute_reply.started":"2022-02-13T21:29:06.8779Z","shell.execute_reply":"2022-02-13T21:29:10.507703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Notebook Configuration.","metadata":{}},{"cell_type":"code","source":"%%time\n# Notebook Configuration...\n\n# Amount of data we want to load into the Model...\nDATA_ROWS = None\n\n# Dataframe, the amount of rows and cols to visualize...\nNROWS = 50\nNCOLS = 15\n\n# Main data location path...\nBASE_PATH = '/kaggle/input/ubiquant-market-prediction/'","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.509922Z","iopub.execute_input":"2022-02-13T21:29:10.510431Z","iopub.status.idle":"2022-02-13T21:29:10.516555Z","shell.execute_reply.started":"2022-02-13T21:29:10.51039Z","shell.execute_reply":"2022-02-13T21:29:10.515813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# I like to disable my Notebook Warnings.\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.519036Z","iopub.execute_input":"2022-02-13T21:29:10.5201Z","iopub.status.idle":"2022-02-13T21:29:10.527299Z","shell.execute_reply.started":"2022-02-13T21:29:10.520058Z","shell.execute_reply":"2022-02-13T21:29:10.526517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Configure notebook display settings to only use 2 decimal places, tables look nicer.\npd.options.display.float_format = '{:,.2f}'.format\npd.set_option('display.max_columns', NCOLS) \npd.set_option('display.max_rows', NROWS)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.528832Z","iopub.execute_input":"2022-02-13T21:29:10.529207Z","iopub.status.idle":"2022-02-13T21:29:10.538897Z","shell.execute_reply.started":"2022-02-13T21:29:10.529171Z","shell.execute_reply":"2022-02-13T21:29:10.537524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Read the Original Datasets, Build Memory Efficient Dataset...","metadata":{}},{"cell_type":"code","source":"%%script false --no-raise-error\n%%time\n# Read the CSV using datatble\ntrn_data = dt.fread(BASE_PATH + 'train.csv', max_nrows = DATA_ROWS)\ntst_data = dt.fread(BASE_PATH + 'example_test.csv', max_nrows = DATA_ROWS)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.540434Z","iopub.execute_input":"2022-02-13T21:29:10.541087Z","iopub.status.idle":"2022-02-13T21:29:10.56786Z","shell.execute_reply.started":"2022-02-13T21:29:10.54105Z","shell.execute_reply":"2022-02-13T21:29:10.566881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n%%time\n# Convert from a Datatable to Pandas Df.\ntrn_data = trn_data.to_pandas()\ntst_data = tst_data.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.569455Z","iopub.execute_input":"2022-02-13T21:29:10.56972Z","iopub.status.idle":"2022-02-13T21:29:10.593397Z","shell.execute_reply.started":"2022-02-13T21:29:10.569691Z","shell.execute_reply":"2022-02-13T21:29:10.592555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n%%time\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.594803Z","iopub.execute_input":"2022-02-13T21:29:10.595013Z","iopub.status.idle":"2022-02-13T21:29:10.619285Z","shell.execute_reply.started":"2022-02-13T21:29:10.594985Z","shell.execute_reply":"2022-02-13T21:29:10.618044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n%%time\ntrn_data = reduce_mem_usage(trn_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.622568Z","iopub.execute_input":"2022-02-13T21:29:10.622799Z","iopub.status.idle":"2022-02-13T21:29:10.644044Z","shell.execute_reply.started":"2022-02-13T21:29:10.622763Z","shell.execute_reply":"2022-02-13T21:29:10.643176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n%%time\ntst_data = reduce_mem_usage(tst_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.646592Z","iopub.execute_input":"2022-02-13T21:29:10.647215Z","iopub.status.idle":"2022-02-13T21:29:10.667018Z","shell.execute_reply.started":"2022-02-13T21:29:10.647182Z","shell.execute_reply":"2022-02-13T21:29:10.66615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n%%time\ntrn_data.to_pickle('trn_data.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.670367Z","iopub.execute_input":"2022-02-13T21:29:10.670811Z","iopub.status.idle":"2022-02-13T21:29:10.690872Z","shell.execute_reply.started":"2022-02-13T21:29:10.670774Z","shell.execute_reply":"2022-02-13T21:29:10.689944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n%%time\ntst_data.to_pickle('tst_data.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.692458Z","iopub.execute_input":"2022-02-13T21:29:10.692835Z","iopub.status.idle":"2022-02-13T21:29:10.713975Z","shell.execute_reply.started":"2022-02-13T21:29:10.692793Z","shell.execute_reply":"2022-02-13T21:29:10.713068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Loading the Memory Efficient Datasets...","metadata":{}},{"cell_type":"code","source":"%%time\nBASE_PATH = '../input/ubiquantmarketpredictionmemoryefficientdata/'\ntrn_data = pd.read_pickle(BASE_PATH + 'trn_data.pkl')\ntst_data = pd.read_pickle(BASE_PATH + 'tst_data.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:10.717404Z","iopub.execute_input":"2022-02-13T21:29:10.718218Z","iopub.status.idle":"2022-02-13T21:29:23.363197Z","shell.execute_reply.started":"2022-02-13T21:29:10.718169Z","shell.execute_reply":"2022-02-13T21:29:23.362452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Exploring the Datasets","metadata":{}},{"cell_type":"code","source":"%%time\ntrn_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:23.364358Z","iopub.execute_input":"2022-02-13T21:29:23.364791Z","iopub.status.idle":"2022-02-13T21:29:23.39404Z","shell.execute_reply.started":"2022-02-13T21:29:23.364752Z","shell.execute_reply":"2022-02-13T21:29:23.393243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%time\nIGNORE = ['row_id', 'time_id', 'investment_id', 'target']\nTARGET_FEATURE_NAME = 'target'","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:23.395425Z","iopub.execute_input":"2022-02-13T21:29:23.395673Z","iopub.status.idle":"2022-02-13T21:29:23.401694Z","shell.execute_reply.started":"2022-02-13T21:29:23.39564Z","shell.execute_reply":"2022-02-13T21:29:23.40075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nFEATURE_NAMES = [feat for feat in trn_data.columns if feat not in IGNORE]\nNUMERIC_FEATURE_NAMES = FEATURE_NAMES","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:23.403406Z","iopub.execute_input":"2022-02-13T21:29:23.404001Z","iopub.status.idle":"2022-02-13T21:29:23.411298Z","shell.execute_reply.started":"2022-02-13T21:29:23.403937Z","shell.execute_reply":"2022-02-13T21:29:23.410351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#X = trn_data[FEATURE_NAMES]\n#y = trn_data[TARGET_FEATURE_NAME]\n#X_test = tst_data[FEATURE_NAMES]\n#inv_ids = trn_data['investment_id']","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:23.412842Z","iopub.execute_input":"2022-02-13T21:29:23.413186Z","iopub.status.idle":"2022-02-13T21:29:23.419366Z","shell.execute_reply.started":"2022-02-13T21:29:23.413149Z","shell.execute_reply":"2022-02-13T21:29:23.418532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gc\n# del trn_data\n# del tst_data\n# gc.collect","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:23.421112Z","iopub.execute_input":"2022-02-13T21:29:23.421709Z","iopub.status.idle":"2022-02-13T21:29:23.42581Z","shell.execute_reply.started":"2022-02-13T21:29:23.42167Z","shell.execute_reply":"2022-02-13T21:29:23.424966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%time\n# define the keras model\nmodel = Sequential()\nmodel.add(Dense(256, input_dim = (trn_data[FEATURE_NAMES].shape[1]), activation = 'swish'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='swish'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation='swish'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:23.427421Z","iopub.execute_input":"2022-02-13T21:29:23.427962Z","iopub.status.idle":"2022-02-13T21:29:28.687717Z","shell.execute_reply.started":"2022-02-13T21:29:23.427896Z","shell.execute_reply":"2022-02-13T21:29:28.686938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:28.68887Z","iopub.execute_input":"2022-02-13T21:29:28.689734Z","iopub.status.idle":"2022-02-13T21:29:28.701304Z","shell.execute_reply.started":"2022-02-13T21:29:28.689688Z","shell.execute_reply":"2022-02-13T21:29:28.700364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n# compile the keras model\nmodel.compile(loss = 'mse', optimizer = 'adam', metrics = ['mae'])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:28.702885Z","iopub.execute_input":"2022-02-13T21:29:28.703302Z","iopub.status.idle":"2022-02-13T21:29:28.791848Z","shell.execute_reply.started":"2022-02-13T21:29:28.703265Z","shell.execute_reply":"2022-02-13T21:29:28.790853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = keras.callbacks.EarlyStopping(patience = 25)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:28.793739Z","iopub.execute_input":"2022-02-13T21:29:28.79403Z","iopub.status.idle":"2022-02-13T21:29:28.87207Z","shell.execute_reply.started":"2022-02-13T21:29:28.79399Z","shell.execute_reply":"2022-02-13T21:29:28.871255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n# fit the keras model on the dataset\nmodel.fit(X, y, epochs = 100, batch_size = 2048, callbacks=[early_stop], verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:28.877643Z","iopub.execute_input":"2022-02-13T21:29:28.880217Z","iopub.status.idle":"2022-02-13T21:29:28.968062Z","shell.execute_reply.started":"2022-02-13T21:29:28.880166Z","shell.execute_reply":"2022-02-13T21:29:28.967029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n# evaluate the keras model\n_, mae = model.evaluate(X, y)\nprint('MAE: %.3f' % (mae))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:28.970789Z","iopub.execute_input":"2022-02-13T21:29:28.971317Z","iopub.status.idle":"2022-02-13T21:29:29.053338Z","shell.execute_reply.started":"2022-02-13T21:29:28.971264Z","shell.execute_reply":"2022-02-13T21:29:29.052366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\nimport tensorflow as tf\ndef preprocess(X, y):\n    return X, y\n\ndef make_dataset(X, y, batch_size = 512, mode = 'train'):\n    ds = tf.data.Dataset.from_tensor_slices((X, y))\n    ds = ds.map(preprocess)\n    \n    if mode == \"train\":\n        ds = ds.shuffle(2048)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:29.057054Z","iopub.execute_input":"2022-02-13T21:29:29.057298Z","iopub.status.idle":"2022-02-13T21:29:29.140693Z","shell.execute_reply.started":"2022-02-13T21:29:29.057256Z","shell.execute_reply":"2022-02-13T21:29:29.139591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.optimizers.Adam(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:29.142593Z","iopub.execute_input":"2022-02-13T21:29:29.143132Z","iopub.status.idle":"2022-02-13T21:29:29.148743Z","shell.execute_reply.started":"2022-02-13T21:29:29.143089Z","shell.execute_reply":"2022-02-13T21:29:29.14801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nmodels = []\npredictions = []\nkfold = StratifiedKFold(5, shuffle = True, random_state = 42)\n\nfor index, (train_indices, valid_indices) in enumerate(kfold.split(trn_data[FEATURE_NAMES], trn_data['investment_id'])):\n    \n    print(f'Training Fold Number:: {index}')\n    X_train, X_val = trn_data[FEATURE_NAMES].iloc[train_indices], trn_data[FEATURE_NAMES].iloc[valid_indices]\n    y_train, y_val = trn_data[TARGET_FEATURE_NAME].iloc[train_indices], trn_data[TARGET_FEATURE_NAME].iloc[valid_indices]\n    \n    #investment_id_train = trn_data['investment_id'].iloc[train_indices]\n    #investment_id_val = trn_data['investment_id'].iloc[valid_indices]\n    \n    #train_ds = make_dataset(X_train, y_train)\n    #valid_ds = make_dataset(X_val, y_val, mode = 'valid')\n    \n    \n    model.compile(loss = 'mae', optimizer = optimizer, metrics = ['mae'])\n    #history = model.fit(train_ds, validation_data = valid_ds, epochs = 25, callbacks=[early_stop], verbose = False)\n    history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 100, batch_size = 1024, callbacks = [early_stop], verbose = 1)\n    print('........')\n    _, mae = model.evaluate(X_val, y_val, batch_size = 32)\n    print('........')\n    pred = model.predict(tst_data[FEATURE_NAMES])\n    \n    print(f'Fold {index}, MAE:: {mae}')\n    print('')\n    models.append(model)\n    predictions.append(pred)\n    \n    del X_train\n    del X_val\n    del y_train\n    del y_val\n    gc.collect()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:29:29.150224Z","iopub.execute_input":"2022-02-13T21:29:29.150671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(models, test_data, features):\n    y_preds = []\n    for model in models:\n        y_pred = model.predict(test_data[features])\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test() \n\nfor (test_df, sample_prediction_df) in iter_test:\n    sample_prediction_df['target'] = inference(models, test_df, FEATURE_NAMES)\n    env.predict(sample_prediction_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}