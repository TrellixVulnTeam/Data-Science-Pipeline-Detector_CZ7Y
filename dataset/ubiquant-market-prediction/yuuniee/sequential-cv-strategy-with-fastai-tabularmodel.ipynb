{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Fastai tutorial Notebook by @slawekbiel\nNotebook link >\nhttps://www.kaggle.com/slawekbiel/fast-fastai-training\n\nCross Validation in Time Series Idea by @lucasmorin\nDiscussion Link >\nhttps://www.kaggle.com/c/ubiquant-market-prediction/discussion/302710\n","metadata":{}},{"cell_type":"code","source":"from fastai.tabular.all import *\nimport gc\nimport random\nimport os\n\nimport numpy as np\nfrom scipy.stats import pearsonr as p\nimport scipy.stats\n\n# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:13:59.855292Z","iopub.execute_input":"2022-03-04T12:13:59.855848Z","iopub.status.idle":"2022-03-04T12:14:02.415723Z","shell.execute_reply.started":"2022-03-04T12:13:59.855734Z","shell.execute_reply":"2022-03-04T12:14:02.414966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_gpus = torch.cuda.device_count()\nprint('gpu count : ', num_gpus)\n\nfor gpu_id in range(num_gpus):\n    print(f'set gpu id : {gpu_id}')\n    torch.cuda.set_device(gpu_id)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:14:02.417416Z","iopub.execute_input":"2022-03-04T12:14:02.417658Z","iopub.status.idle":"2022-03-04T12:14:02.426153Z","shell.execute_reply.started":"2022-03-04T12:14:02.417623Z","shell.execute_reply":"2022-03-04T12:14:02.425339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Barebone lightweight dataloading","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:50:54.828341Z","iopub.execute_input":"2022-01-27T17:50:54.828714Z","iopub.status.idle":"2022-01-27T17:50:54.833614Z","shell.execute_reply.started":"2022-01-27T17:50:54.828674Z","shell.execute_reply":"2022-01-27T17:50:54.83258Z"}}},{"cell_type":"code","source":"class UbiquantDataset:\n    def __init__(self, feature_tensor, targets):\n        store_attr()\n        self.n_inp = 2\n    def __getitem__(self, idx):\n        return torch.empty(0),self.feature_tensor[idx], self.targets[idx, None]\n    \n    def __len__(self):\n        return len(self.feature_tensor)\n    \nclass UbiDL(DataLoader):\n    def __iter__(self):\n        if self.shuffle:\n            self.__idxs = torch.tensor(range(0,self.n))\n        else:\n            self.__idxs = torch.tensor(range(0,self.n))\n        for batch_start in range(0, self.n, self.bs):\n            if batch_start + self.bs > self.n and self.drop_last:\n                return \n            indices = self.__idxs[batch_start:batch_start+self.bs]\n            yield self.dataset[indices]","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:14:02.428069Z","iopub.execute_input":"2022-03-04T12:14:02.428541Z","iopub.status.idle":"2022-03-04T12:14:02.43709Z","shell.execute_reply.started":"2022-03-04T12:14:02.428507Z","shell.execute_reply":"2022-03-04T12:14:02.436391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A custom metric and loss function for training","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:50:54.828341Z","iopub.execute_input":"2022-01-27T17:50:54.828714Z","iopub.status.idle":"2022-01-27T17:50:54.833614Z","shell.execute_reply.started":"2022-01-27T17:50:54.828674Z","shell.execute_reply":"2022-01-27T17:50:54.83258Z"}}},{"cell_type":"code","source":"def pearson_coef(data):\n    return data.corr()['target']['preds']\n\nclass CompMetric(AccumMetric):\n    def __init__(self, val_df):\n        super().__init__(None)\n        self.val_df = val_df\n        \n    @property\n    def name(self):\n        return 'Valid_Pearson'\n        \n    @property\n    def value(self):\n        preds = torch.cat(self.preds)\n        self.val_df['preds'] = preds.cpu().numpy()\n        return np.mean(self.val_df[['time_id', 'target', 'preds']].groupby('time_id').apply(pearson_coef))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:14:02.439058Z","iopub.execute_input":"2022-03-04T12:14:02.439511Z","iopub.status.idle":"2022-03-04T12:14:02.447125Z","shell.execute_reply.started":"2022-03-04T12:14:02.43946Z","shell.execute_reply":"2022-03-04T12:14:02.446298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ndef pearson_loss(x, y):\n    xd = x - x.mean()\n    yd = y - y.mean()\n    nom = (xd*yd).sum()\n    denom = ((xd**2).sum() * (yd**2).sum()).sqrt()\n    return 1 - nom / denom\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:14:02.44955Z","iopub.execute_input":"2022-03-04T12:14:02.449851Z","iopub.status.idle":"2022-03-04T12:14:02.456857Z","shell.execute_reply.started":"2022-03-04T12:14:02.449823Z","shell.execute_reply":"2022-03-04T12:14:02.456158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Function","metadata":{}},{"cell_type":"code","source":"def inference(models, data):\n    preds = []\n    for model in models:\n        with torch.no_grad():\n            pred = model([], data).view(-1).cpu().numpy()\n            preds.append(pred)\n    res = np.mean(np.stack(preds), axis=0)\n    return res","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:14:02.458702Z","iopub.execute_input":"2022-03-04T12:14:02.459294Z","iopub.status.idle":"2022-03-04T12:14:02.468199Z","shell.execute_reply.started":"2022-03-04T12:14:02.459257Z","shell.execute_reply":"2022-03-04T12:14:02.467532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the data from feather","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:50:54.828341Z","iopub.execute_input":"2022-01-27T17:50:54.828714Z","iopub.status.idle":"2022-01-27T17:50:54.833614Z","shell.execute_reply.started":"2022-01-27T17:50:54.828674Z","shell.execute_reply":"2022-01-27T17:50:54.83258Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\n# Seed everything\nseed_everything(42)\n\nFOLDS = 5\n# Read data\ntrain = pd.read_feather('../input/ubiquant-trainfeather-32-bit/train32.feather')\n\n# Feature list\nfeatures = [col for col in train.columns if col not in ['row_id', 'time_id', 'investment_id', 'target']]\n\n# Create groups based on time_id\ntrain.loc[(train['time_id'] >= 0) & (train['time_id'] < 280), 'group'] = 0\ntrain.loc[(train['time_id'] >= 280) & (train['time_id'] < 585), 'group'] = 1\ntrain.loc[(train['time_id'] >= 585) & (train['time_id'] < 825), 'group'] = 2\ntrain.loc[(train['time_id'] >= 825) & (train['time_id'] < 1030), 'group'] = 3\ntrain.loc[(train['time_id'] >= 1030) & (train['time_id'] < 1400), 'group'] = 4\ntrain['group'] = train['group'].astype(np.int16)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:14:02.469127Z","iopub.execute_input":"2022-03-04T12:14:02.471192Z","iopub.status.idle":"2022-03-04T12:14:38.323393Z","shell.execute_reply.started":"2022-03-04T12:14:02.471162Z","shell.execute_reply":"2022-03-04T12:14:38.322418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use fast.ai Learner for trainig with Sequential Cross Validation","metadata":{}},{"cell_type":"markdown","source":"![CV](https://miro.medium.com/max/753/1*qvdnPF8ETV9mFdMT0Y_BBA.png)","metadata":{}},{"cell_type":"markdown","source":"### train : validation = 8 : 2\n\n> ### And \n\n### test -> next group data","metadata":{}},{"cell_type":"code","source":"%%time\n\nfor fold in range(FOLDS):\n    group_index = train[train['group'] <= fold].index\n    group_index_list = group_index.values.tolist()\n    trn_ind = group_index_list[:int(len(group_index_list)*0.8)]\n    val_ind = group_index_list[int(len(group_index_list)*0.8):]\n\n    print(f'Training fold {fold}')\n    print(f'Training with {len(trn_ind)} rows')\n    print(f'Validating with {len(val_ind)} rows')\n    print(f'Training light gradient boosting model with {len(features)} features...')\n    print('train time ids is ... ', train['time_id'].loc[trn_ind].values[:5], ' ~ ', train['time_id'].loc[trn_ind].values[-5:])\n    print('train idx is ... ', trn_ind[:5], ' ~ ', trn_ind[-5:])\n    print('valid time ids is ... ', train['time_id'].loc[val_ind].values[:5], ' ~ ', train['time_id'].loc[val_ind].values[-5:])\n    print('valid idx is ... ', val_ind[:5], ' ~ ', val_ind[-5:])\n\n    \n    x_train, x_val = train[features].loc[trn_ind], train[features].loc[val_ind]\n    y_train, y_val = train['target'].loc[trn_ind], train['target'].loc[val_ind]\n\n\n    feature_tensor_train = torch.tensor(x_train.to_numpy()).cuda()\n    target_tensor_train = torch.tensor(y_train.to_numpy()).cuda()\n    feature_tensor_valid = torch.tensor(x_val.to_numpy()).cuda()\n    target_tensor_valid = torch.tensor(y_val.to_numpy()).cuda()\n    \n    \n    del x_train, x_val, y_train, y_val\n\n\n    ds_train = UbiquantDataset(feature_tensor_train, target_tensor_train)\n    ds_val = UbiquantDataset(feature_tensor_valid, target_tensor_valid)\n\n\n    del feature_tensor_train, target_tensor_train, feature_tensor_valid, target_tensor_valid\n    \n    \n    dls = DataLoaders.from_dsets(ds_train, ds_val , bs = 4096, dl_type=UbiDL, num_workers=0)\n\n\n    model = TabularModel(emb_szs={}, n_cont=len(features), out_sz=1, layers = [128, 64, 32, 16]).cuda()\n\n    \n    # pearson loss > \n    learn = Learner(dls, model, loss_func=pearson_loss, metrics = CompMetric(train.loc[val_ind]))\n    # mse loss >\n    # learn = Learner(dls, model, loss_func=MSELossFlat(), metrics=CompMetric(train.loc[val_ind]))\n\n        \n    print('=start train=')\n    learn.fit(10, 1e-3,  cbs=EarlyStoppingCallback(monitor=\"Valid_Pearson\", patience=2))\n    # arn.fit_one_cycle(5, 1e-3, cbs=[SaveModelCallback(monitor=\"Valid_Pearson\", comp=np.less)])\n\n\n    torch.save(learn.model, f'model_{fold}.pth')\n    \n    del ds_train, ds_val\n    del dls, model, learn\n    \n    \n    \n    \n    \n    ###############################################################################################\n    # testing at next group < 0 ~ 3 and group 4\n    if fold < 4:\n        # load models\n        loaded_models = []\n        for i in range(fold + 1):\n            loaded_model = torch.load(f'model_{i}.pth').cuda().eval()\n            loaded_models.append(loaded_model)\n        \n        print('=' * 50)\n        print(f' > fold {fold} model Scores at test data(next fold & final fold) < ')\n        print('=' * 50)\n        \n        # at next group\n        test_df = train[train['group'] == (fold + 1)]\n        test_data = torch.tensor(test_df[features].to_numpy(), dtype=torch.float).cuda()\n        \n        ensemble_preds = inference(loaded_models, test_data)\n        preds = inference(loaded_models[-1:], test_data)\n        print('=' * 50)\n        pearson_score = p(preds, test_df.target)[0]\n        print(f'fold {str(fold)} model Pearson at group {str(fold+1)} data : ', pearson_score)\n        rmse_score = rmse(test_df.target, preds)\n        print(f'fold {str(fold)} model RMSE at group {str(fold+1)} data : ', rmse_score)\n        \n        pearson_score = p(ensemble_preds, test_df.target)[0]\n        print(f'fold 0 ~ {str(fold)} model ensemble Pearson at group {str(fold+1)} data : ', pearson_score)\n        rmse_score = rmse(test_df.target, ensemble_preds)\n        print(f'fold 0 ~ {str(fold)} model ensemble RMSE at group {str(fold+1)} data : ', rmse_score)\n        print('=' * 50)\n        del test_df, test_data, preds, ensemble_preds\n        \n        # at group 4\n        test_df = train[train['group'] == 4]\n        test_data = torch.tensor(test_df[features].to_numpy(), dtype=torch.float).cuda()\n        # with torch.no_grad():\n        #     preds = loaded_model([], test_data).view(-1).cpu().numpy()\n        ensemble_preds = inference(loaded_models, test_data)\n        preds = inference(loaded_models[-1:], test_data)\n        \n        print('=' * 50)\n        pearson_score = p(preds, test_df.target)[0]\n        print(f'fold {str(fold)} model Pearson at group 4 data : ', pearson_score)\n        rmse_score = rmse(test_df.target, preds)\n        print(f'fold {str(fold)} model RMSE at group 4 data : ', rmse_score)\n        pearson_score = p(ensemble_preds, test_df.target)[0]\n        print(f'fold 0 ~ {str(fold)} model ensemble Pearson at group 4 data : ', pearson_score)\n        rmse_score = rmse(test_df.target, ensemble_preds)\n        print(f'fold 0 ~ {str(fold)} model ensemble RMSE at group 4 data : ', rmse_score)\n        print('=' * 50)\n        del loaded_model, test_df, test_data, preds, ensemble_preds\n        \n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:29:43.630565Z","iopub.execute_input":"2022-03-04T12:29:43.631029Z","iopub.status.idle":"2022-03-04T12:30:34.340677Z","shell.execute_reply.started":"2022-03-04T12:29:43.630993Z","shell.execute_reply":"2022-03-04T12:30:34.339949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nAt this result, The greater the time difference, the lower the score, and the smaller the time difference, the higher the score.\n(Especially, in the fold 1 data and fold 4 data results of the fold 0 model,)\n\nMaybe it's the fate we'll face in Private Score...\n(The larger the time difference between LB and PB data, the more)\n\nIs ensembe always right? \n\nSometimes it's good and sometimes it's not.\n(At least in this result.)\n\nAnd, it will depend on the environment of the future market. \n\nWe don't know what the environment would be like. \n\nMaybe, this is why you should use a generalized model.","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"models = []\nfor fold in range(FOLDS):\n    models.append(torch.load(f'model_{fold}.pth').cuda().eval())","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:17:36.491434Z","iopub.execute_input":"2022-03-04T12:17:36.49192Z","iopub.status.idle":"2022-03-04T12:17:36.520173Z","shell.execute_reply.started":"2022-03-04T12:17:36.49188Z","shell.execute_reply":"2022-03-04T12:17:36.519516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submission_inference(models, data):\n    preds = []\n    for model in models:\n        with torch.no_grad():\n            pred = model([], data).view(-1).cpu().numpy()\n            preds.append(pred)\n#     res = np.mean(np.stack(preds), axis=0)\n#     print('mean : ', res)\n    res = preds[4] * 0.6 + preds[3] * 0.2 + preds[2] * 0.1 + preds[1] * 0.05 + + preds[0] * 0.05\n    # print('weighted : ', res)\n    return res","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:17:36.522503Z","iopub.execute_input":"2022-03-04T12:17:36.522738Z","iopub.status.idle":"2022-03-04T12:17:36.528488Z","shell.execute_reply.started":"2022-03-04T12:17:36.522707Z","shell.execute_reply":"2022-03-04T12:17:36.527261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\n\nenv = ubiquant.make_env()  \niter_test = env.iter_test()\nfor (test_df, sub_df) in iter_test:\n    \n    data = torch.tensor(test_df[features].to_numpy(), dtype=torch.float).cuda()\n    preds = submission_inference(models, data)\n        \n    sub_df['target'] = preds\n    env.predict(sub_df) ","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:17:36.529983Z","iopub.execute_input":"2022-03-04T12:17:36.530478Z","iopub.status.idle":"2022-03-04T12:17:36.656665Z","shell.execute_reply.started":"2022-03-04T12:17:36.530442Z","shell.execute_reply":"2022-03-04T12:17:36.65603Z"},"trusted":true},"execution_count":null,"outputs":[]}]}