{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport glob\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport missingno as msno\n\nfrom random import choice, choices\nfrom tqdm import tqdm\nfrom itertools import cycle\nfrom scipy.stats import skewnorm\n\n\npd.set_option(\"display.max_columns\", None)\n\nplt.style.use(\"ggplot\")\ncolor_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\ncolor_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-24T04:47:42.009154Z","iopub.execute_input":"2022-01-24T04:47:42.009555Z","iopub.status.idle":"2022-01-24T04:47:43.060403Z","shell.execute_reply.started":"2022-01-24T04:47:42.009443Z","shell.execute_reply":"2022-01-24T04:47:43.059427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_dist_box(value, title=''):\n    c = choice(color_pal)\n    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw = {\"height_ratios\": (0.2, 1)}, figsize=(18, 9))\n    mean, median = np.mean(value), np.median(value)\n    \n    sns.boxplot(value, ax=ax_box, color=c)\n    #ax_box.axvline(mean, color='r', linestyle='--')\n    #ax_box.axvline(median, color='b')\n    \n    sns.distplot(value, ax=ax_hist, color=c)\n    #ax_hist.axvline(mean, color='r', linestyle='--')\n    #ax_hist.axvline(median, color='b')\n    plt.title(title)\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-24T04:47:43.0624Z","iopub.execute_input":"2022-01-24T04:47:43.06272Z","iopub.status.idle":"2022-01-24T04:47:43.06915Z","shell.execute_reply.started":"2022-01-24T04:47:43.062675Z","shell.execute_reply":"2022-01-24T04:47:43.068335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Problem Statement\n\nIn this competition, youâ€™ll build a model that forecasts an `investment's return rate`.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Data\n\nDataset Link here: https://www.kaggle.com/robikscube/ubiquant-parquet\n\nRead about parquet files here: https://databricks.com/glossary/what-is-parquet\n\n5.5GB in size.\n\nThis is faster and keeps the dtypes of the original dataset.","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_df = pd.read_parquet('../input/ubiquant-parquet/train.parquet')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T04:47:43.204085Z","iopub.execute_input":"2022-01-24T04:47:43.204996Z","iopub.status.idle":"2022-01-24T04:48:41.879053Z","shell.execute_reply.started":"2022-01-24T04:47:43.204955Z","shell.execute_reply":"2022-01-24T04:48:41.878223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**train.csv**\n\n- `row_id` - A unique identifier for the row.\n- `time_id` - The ID code for the time the data was gathered. The time IDs are in order, but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.\n- `investment_id` - The ID code for an investment. Not all investment have data in all time IDs.\n- `target` - The target.\n- `[f_0:f_299]` - Anonymized features generated from market data.\n","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:41.880787Z","iopub.execute_input":"2022-01-24T04:48:41.881311Z","iopub.status.idle":"2022-01-24T04:48:42.097126Z","shell.execute_reply.started":"2022-01-24T04:48:41.881274Z","shell.execute_reply":"2022-01-24T04:48:42.096168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### time_id vs investment_id\n\n- In training data we have time_id range between `0` to `1219`.\n- We will try to understand time_id vs investment_id in next few cells.\n- I am extracting some stats from those two features","metadata":{}},{"cell_type":"code","source":"print(\"No of unique investment_id in test : \", train_df.investment_id.nunique())","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:42.09866Z","iopub.execute_input":"2022-01-24T04:48:42.099406Z","iopub.status.idle":"2022-01-24T04:48:42.1486Z","shell.execute_reply.started":"2022-01-24T04:48:42.099361Z","shell.execute_reply":"2022-01-24T04:48:42.147692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_stat_df = train_df.groupby(['investment_id'])['time_id'].agg(['count', 'min', 'max', 'std']).reset_index()\ntime_stat_df['diff'] = time_stat_df['max'] - time_stat_df['min']\ntime_stat_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:42.150892Z","iopub.execute_input":"2022-01-24T04:48:42.151629Z","iopub.status.idle":"2022-01-24T04:48:42.364879Z","shell.execute_reply.started":"2022-01-24T04:48:42.151577Z","shell.execute_reply":"2022-01-24T04:48:42.363939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Above df exlpaines about unique `investment_id` \n- `count`: number of rows in training data for that investment_id\n- `min`: time id when that investment_id started\n- `max`: time id when that investment_id ended (1219 is max in training)\n- `std`: time_id spred for that investment_id ","metadata":{}},{"cell_type":"code","source":"plot_dist_box(time_stat_df['count'], title=\"Number of time_id's per investment_id distribution\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:42.366216Z","iopub.execute_input":"2022-01-24T04:48:42.367151Z","iopub.status.idle":"2022-01-24T04:48:42.866946Z","shell.execute_reply.started":"2022-01-24T04:48:42.367102Z","shell.execute_reply":"2022-01-24T04:48:42.865992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_dist_box(time_stat_df['min'], title=\"Started time_id's per investment_id distribution\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:42.868267Z","iopub.execute_input":"2022-01-24T04:48:42.868512Z","iopub.status.idle":"2022-01-24T04:48:43.343433Z","shell.execute_reply.started":"2022-01-24T04:48:42.868481Z","shell.execute_reply":"2022-01-24T04:48:43.341056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can observe that most of the investments started when time=0, some investments started in between 200 to 400 and 600 to 1000","metadata":{}},{"cell_type":"code","source":"# chcking missing time_ids\nprint(f\"We have {time_stat_df.query('count != diff').shape[0]} no of investment_ids missing at least one time_id out of {time_stat_df.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:43.345056Z","iopub.execute_input":"2022-01-24T04:48:43.345349Z","iopub.status.idle":"2022-01-24T04:48:43.3616Z","shell.execute_reply.started":"2022-01-24T04:48:43.345302Z","shell.execute_reply":"2022-01-24T04:48:43.360705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_stat_df['miss_count'] = time_stat_df['diff'] - time_stat_df['count']\n\nplot_dist_box(time_stat_df['miss_count'], title=\"Missing time_id's per investment_id distribution\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:43.363065Z","iopub.execute_input":"2022-01-24T04:48:43.36373Z","iopub.status.idle":"2022-01-24T04:48:43.832798Z","shell.execute_reply.started":"2022-01-24T04:48:43.363689Z","shell.execute_reply":"2022-01-24T04:48:43.831962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can observe that more then 50% investments are having > 100 missing time_ids","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(30, 5))\ntrain_df.groupby('time_id')['investment_id'].count().plot(color=choice(color_pal))\nplt.title(\"unique investment_id's by time\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:43.834061Z","iopub.execute_input":"2022-01-24T04:48:43.834682Z","iopub.status.idle":"2022-01-24T04:48:44.150151Z","shell.execute_reply.started":"2022-01-24T04:48:43.834643Z","shell.execute_reply":"2022-01-24T04:48:44.149299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can observe that lot's of time_ids missing in between time_id 300 to 550.\n- And also after time_id 600 investment_ids increase a lot towards the end.","metadata":{}},{"cell_type":"markdown","source":"### Missing time_ids","metadata":{}},{"cell_type":"code","source":"tmp_df = train_df[['time_id', 'investment_id']].copy()\ntmp_df['target'] = 0\ntmp_df = tmp_df.pivot(index='investment_id', columns=['time_id'])\n#tmp_df = tmp_df.loc[tmp_df.isna().sum(axis=1).sort_values().index]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:44.153058Z","iopub.execute_input":"2022-01-24T04:48:44.153637Z","iopub.status.idle":"2022-01-24T04:48:45.663092Z","shell.execute_reply.started":"2022-01-24T04:48:44.153591Z","shell.execute_reply":"2022-01-24T04:48:45.662243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(tmp_df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:45.664206Z","iopub.execute_input":"2022-01-24T04:48:45.66443Z","iopub.status.idle":"2022-01-24T04:48:48.470213Z","shell.execute_reply.started":"2022-01-24T04:48:45.664403Z","shell.execute_reply":"2022-01-24T04:48:48.469385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can observe that lots of investment_id's have missing time_ids ","metadata":{}},{"cell_type":"markdown","source":"# Target","metadata":{}},{"cell_type":"code","source":"plot_dist_box(train_df['target'], 'Target Distribution')\nprint(f\"Target Mean :{train_df['target'].mean()} - Std :{train_df['target'].std()} - Median :{train_df['target'].median()}\" )","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:48:48.471424Z","iopub.execute_input":"2022-01-24T04:48:48.471647Z","iopub.status.idle":"2022-01-24T04:49:00.331543Z","shell.execute_reply.started":"2022-01-24T04:48:48.471619Z","shell.execute_reply":"2022-01-24T04:49:00.330576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# target over time\nfig, ax = plt.subplots(figsize=(30, 5))\ntrain_df.groupby('time_id')['target'].count().plot()\nplt.title(\"unique investment_ids over time\")\n\nfig, ax = plt.subplots(figsize=(30, 10))\nax = train_df.groupby('time_id')['target'].mean().plot()\nax = train_df.groupby('time_id')['target'].std().plot()\nax = train_df.groupby('time_id')['target'].median().plot()\nax.legend(['mean', 'std', 'median'])\nplt.title(\"target mean vs std vs median over time\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:49:00.333173Z","iopub.execute_input":"2022-01-24T04:49:00.333691Z","iopub.status.idle":"2022-01-24T04:49:01.216193Z","shell.execute_reply.started":"2022-01-24T04:49:00.333644Z","shell.execute_reply":"2022-01-24T04:49:01.215287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- we can observe that when the less number of investment_ids over time more fluctuations in mean, std, median target over time ","metadata":{}},{"cell_type":"code","source":"# target vs investiment_ids\n\nfig, ax = plt.subplots(figsize=(30, 5))\ntmp_df = train_df.groupby('investment_id')['target'].agg(['count', 'min', 'max', 'std', 'mean', 'median']).reset_index()\ntmp_df = tmp_df.sort_values('count').reset_index(drop=True)\ntmp_df['count'].plot()\nplt.title(\"target count sort by investment_id frequency\")\n\nfig, ax = plt.subplots(figsize=(30, 5))\nax = tmp_df['mean'].plot()\nax = tmp_df['median'].plot()\nax.legend(['mean', 'median'])\nplt.title('meam vs median over investmet_id')\n\nfig, ax = plt.subplots(figsize=(30, 5))\nax = tmp_df['std'].plot()\nplt.title('std over investment_id')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T04:49:01.217481Z","iopub.execute_input":"2022-01-24T04:49:01.217801Z","iopub.status.idle":"2022-01-24T04:49:02.14622Z","shell.execute_reply.started":"2022-01-24T04:49:01.217765Z","shell.execute_reply":"2022-01-24T04:49:02.145291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- we can observe that when the less time_id's per investment_id more fluctuations in target.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Please upvote if like it ðŸ™‚ ","metadata":{}}]}