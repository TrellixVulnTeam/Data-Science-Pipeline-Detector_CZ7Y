{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport joblib\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom argparse import Namespace\nfrom collections import defaultdict\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n\nimport lightgbm as lgb\n\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom random import choices\n\n\nSEED = 1111\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('max_columns', 64)\n\ndef seed_everything(seed: int = 42) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T09:45:04.604239Z","iopub.execute_input":"2022-01-21T09:45:04.604676Z","iopub.status.idle":"2022-01-21T09:45:06.955909Z","shell.execute_reply.started":"2022-01-21T09:45:04.604592Z","shell.execute_reply":"2022-01-21T09:45:06.955127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#args = Namespace(\n#    seed=21,\n#   folds=5,\n#    workers=4,\n#    samples=2500000,\n#    data_path=Path(\"../input/ubiquant-parquet/\"),\n#)\n#seed_everything(1111)\ndata_path=Path(\"../input/ubiquant-parquet/\")\nsamples=2500000","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:45:06.957757Z","iopub.execute_input":"2022-01-21T09:45:06.958729Z","iopub.status.idle":"2022-01-21T09:45:06.964057Z","shell.execute_reply.started":"2022-01-21T09:45:06.958688Z","shell.execute_reply":"2022-01-21T09:45:06.963188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = pd.read_parquet(data_path.joinpath(\"train_low_mem.parquet\"))\nassert train.isnull().any().sum() == 0, \"null exists.\"","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:45:06.972627Z","iopub.execute_input":"2022-01-21T09:45:06.972931Z","iopub.status.idle":"2022-01-21T09:45:51.51472Z","shell.execute_reply.started":"2022-01-21T09:45:06.972889Z","shell.execute_reply":"2022-01-21T09:45:51.513491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if args.samples is not None:\n    #train = train.sample(args.samples, random_state=args.seed).reset_index(drop=True)\n   # train = train[-args.samples:].reset_index(drop=True)\n    #gc.collect()\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:45:51.517055Z","iopub.execute_input":"2022-01-21T09:45:51.518113Z","iopub.status.idle":"2022-01-21T09:45:53.646872Z","shell.execute_reply.started":"2022-01-21T09:45:51.518054Z","shell.execute_reply":"2022-01-21T09:45:53.64604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cat_features = []\n#num_features = list(train.filter(like=\"f_\").columns)\n#features = num_features + cat_features\nfeatures = [c for c in train.columns if \"f_\" in c]\n#scaler = StandardScaler()\n#train[num_features] = scaler.fit_transform(train[num_features])\ntrain = reduce_mem_usage(train)\n#joblib.dump(scaler, 'scaler.joblib')\ngc.collect()\nlen(features)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:45:53.648448Z","iopub.execute_input":"2022-01-21T09:45:53.649072Z","iopub.status.idle":"2022-01-21T09:48:47.785388Z","shell.execute_reply.started":"2022-01-21T09:45:53.649024Z","shell.execute_reply":"2022-01-21T09:48:47.784262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# corr_matrix = train.filter(like=\"f_\").corr().abs()\n# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n# # Find features with correlation greater than 0.97\n# to_drop = [column for column in upper.columns if any(upper[column] >= 0.97)]\n# sorted(to_drop)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:48:47.787019Z","iopub.execute_input":"2022-01-21T09:48:47.787321Z","iopub.status.idle":"2022-01-21T09:48:47.793667Z","shell.execute_reply.started":"2022-01-21T09:48:47.787279Z","shell.execute_reply":"2022-01-21T09:48:47.792429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\ndef feval_rmse(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'rmse', rmse(y_true, y_pred), False\n\ntrain.fillna(train.mean(),inplace=True)\n\nX_train = train.loc[:, train.columns.str.contains('f_')]\n    \ny_train = train['target']\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:48:47.795805Z","iopub.execute_input":"2022-01-21T09:48:47.796364Z","iopub.status.idle":"2022-01-21T09:48:47.820444Z","shell.execute_reply.started":"2022-01-21T09:48:47.796319Z","shell.execute_reply":"2022-01-21T09:48:47.819371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features_importance = run()\n#print(f\"lgbm {args.folds} folds mean rmse: {rmse(train.target, train.preds)}, mean pearsonr: {pearsonr(train.target, train.preds)[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:48:47.823592Z","iopub.execute_input":"2022-01-21T09:48:47.823936Z","iopub.status.idle":"2022-01-21T09:55:35.057201Z","shell.execute_reply.started":"2022-01-21T09:48:47.823888Z","shell.execute_reply":"2022-01-21T09:55:35.055614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n\n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"tanh\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n        #optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        #loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.MeanAbsolutePercentageError(name='mean_absolute_percentage_error'),\n        #loss = [NegCorrelation],\n        metrics=tf.keras.metrics.RootMeanSquaredError(name='root_mean_squared_error'),\n        #metrics= [Correlation]\n\n    )\n\n    return model\n\n\nbatch_size = 5000\nhidden_units = [150, 150, 150]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\nmodel = create_mlp(\n    len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate\n    )\n\nmodel.fit(X_train, y_train, epochs=100, batch_size=5000)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:55:35.058624Z","iopub.status.idle":"2022-01-21T09:55:35.059215Z","shell.execute_reply.started":"2022-01-21T09:55:35.058906Z","shell.execute_reply":"2022-01-21T09:55:35.058935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()  \niter_test = env.iter_test()\n\n#scaler = joblib.load('scaler.joblib')\n#models = [joblib.load(f'lgbm_seed{args.seed}_{fold}.pkl') for fold in range(args.folds)]\n\nfor (test_df, sample_prediction_df) in iter_test:\n    #test_df[num_features] = scaler.fit_transform(test_df[num_features]) \n    #final_pred = [models[fold].predict(test_df[features]) for fold in range(args.folds)]\n    #sample_prediction_df['target'] = np.mean(np.stack(final_pred), axis=0)\n    x_tt = test_df.loc[:, features].values\n    sample_prediction_df['target'] = model(x_tt, training = False).numpy()\n    env.predict(sample_prediction_df) \n    display(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T09:55:35.061236Z","iopub.status.idle":"2022-01-21T09:55:35.061741Z","shell.execute_reply.started":"2022-01-21T09:55:35.061477Z","shell.execute_reply":"2022-01-21T09:55:35.061505Z"},"trusted":true},"execution_count":null,"outputs":[]}]}