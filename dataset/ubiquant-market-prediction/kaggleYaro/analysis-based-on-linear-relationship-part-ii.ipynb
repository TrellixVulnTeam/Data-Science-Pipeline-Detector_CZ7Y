{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n- I am new to Kaggle competition and joined this competition.\n- I have tried my best but could not achieve high score so far.\n- I would like to share what I have done (very basic analysis though...). It would be very helpful if you give me any comments/advices (and upvote if you find this useful)!","metadata":{}},{"cell_type":"markdown","source":"# Contents (List of Questions I came up)\n\n- Which model should we use? (**Part I**)\n- Should we use all the data for training? If not, how to filter them out? (**Part I**)\n- CV and the baseline score (**Part I**)\n- Should we apply Target preprocessing? If so, how? (**Part II**)\n- Should we apply Feature preprocessing? If so, how? (**Part II**)\n- What are missing?","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport gc\nimport psutil\nimport time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Lasso, Ridge, LinearRegression, LassoCV\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nfrom sklearn import metrics\nfrom scipy.stats import pearsonr\nfrom typing import Tuple\n\nmem = psutil.virtual_memory()\nprint(f' Memory Consumption Rate: {mem.percent}')\nprint(f' Memory Consumption: {mem.used/1000/1000/1000}')\nprint(f'Available: {mem.free/1000/1000/1000}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:22:27.09295Z","iopub.execute_input":"2022-03-29T12:22:27.093559Z","iopub.status.idle":"2022-03-29T12:22:28.514007Z","shell.execute_reply.started":"2022-03-29T12:22:27.093421Z","shell.execute_reply":"2022-03-29T12:22:28.513092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Data\nThanks to https://www.kaggle.com/datasets/robikscube/ubiquant-parquet, we can reduce the memory usage.","metadata":{}},{"cell_type":"code","source":"%%time\ndef reduce_memory_usage(df, features):\n    for feature in features:\n        item = df[feature].astype(np.float16)\n        df[feature] = item\n        del item\n        gc.collect()\n        \ntarget = 'target'\nn_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\nfeature_columns = ['investment_id', 'time_id'] + features\nX = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet', columns=feature_columns + [\"target\"])\nreduce_memory_usage(X, features + [\"target\"])\nprint(X.shape)\nX.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:22:28.515822Z","iopub.execute_input":"2022-03-29T12:22:28.516332Z","iopub.status.idle":"2022-03-29T12:26:43.010341Z","shell.execute_reply.started":"2022-03-29T12:22:28.516283Z","shell.execute_reply":"2022-03-29T12:26:43.008567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filter out Training Data","metadata":{}},{"cell_type":"code","source":"time_id_list = list(X['time_id'].unique())\ninvestment_id_list = list(X['investment_id'].unique())\ndata_dummy = [np.nan for _ in range(len(time_id_list)*len(investment_id_list))]\nX_filled = pd.DataFrame(data_dummy, columns=['dummy'])\nX_filled['time_id'] = np.repeat(time_id_list, len(investment_id_list))\nX_filled['investment_id'] = np.tile(investment_id_list, len(time_id_list))\nX_filled = X_filled.set_index(['time_id', 'investment_id'])\nX_orig = X.set_index(['time_id','investment_id'])\nX_orig = X_orig[['target']]\nX_filled = X_filled.join(X_orig).drop('dummy', axis=1) # join\nX_filled = X_filled.unstack() # move investment_id to columns\nX_filled = X_filled.T.reset_index(level=0).drop('level_0', axis=1).T # multi columns to single column\nthred = len(X_filled) - 500 # 最低500サンプル（２年分）あれば、通常の学習プロセスで扱う。\ndf_null_count = X_filled.isnull().sum(axis=0).sort_values(ascending=False)\ndf_chosen = df_null_count[df_null_count < thred]\ninvestment_id_list = list(df_chosen.index)\nX_filled_chosen = X_filled[investment_id_list]\ndf_nnull = X_filled_chosen.isnull().sum(axis=1).to_frame()\ndf_nnull.columns = ['nnull']\ndf_nnull['nnull_diff'] = df_nnull['nnull'].diff(1)\ndf_nnull['too_many_missing'] = (df_nnull['nnull'] > 1000) | (df_nnull['nnull_diff'] > 200)\nX_filled_chosen = X_filled_chosen.iloc[~df_nnull['too_many_missing'].values, :]\nX_filled_chosen = X_filled_chosen.astype(\"object\").fillna(method=\"ffill\").astype(\"float\")\nX_filled_chosen.dropna(inplace=True)\ntime_id_chosen = list(X_filled_chosen.index)\n\ntrain = X[X['time_id'].isin(time_id_chosen)]\ntrain.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:26:43.01191Z","iopub.execute_input":"2022-03-29T12:26:43.012434Z","iopub.status.idle":"2022-03-29T12:27:07.014533Z","shell.execute_reply.started":"2022-03-29T12:26:43.012372Z","shell.execute_reply":"2022-03-29T12:27:07.013227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a bit of cleaning in memory\ndel X_filled, X_filled_chosen, X_orig, data_dummy\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T12:27:07.016586Z","iopub.execute_input":"2022-03-29T12:27:07.016942Z","iopub.status.idle":"2022-03-29T12:27:07.156951Z","shell.execute_reply.started":"2022-03-29T12:27:07.016905Z","shell.execute_reply":"2022-03-29T12:27:07.155867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GroupTimeSeriesSplit:\n    \"\"\"\n    From: https://www.kaggle.com/c/ubiquant-market-prediction/discussion/304036\n    Custom class to create a Group Time Series Split. We ensure\n    that the time id values that are in the testing data are not a part\n    of the training data & the splits are temporal\n    \"\"\"\n    def __init__(self, n_folds: int, holdout_size: int, groups: str, cv = False) -> None:\n        self.n_folds = n_folds\n        self.holdout_size = holdout_size\n        self.groups = groups\n        self.cv = cv\n\n    def split(self, X) -> Tuple[np.array, np.array]:\n        # Take the group column and get the unique values\n        unique_time_ids = np.unique(self.groups.values)\n\n        # Split the time ids into the length of the holdout size\n        # and reverse so we work backwards in time. Also, makes\n        # it easier to get the correct time_id values per\n        # split\n        array_split_time_ids = np.array_split(\n            unique_time_ids, len(unique_time_ids) // self.holdout_size\n        )[::-1]\n\n        # Get the first n_folds values\n        array_split_time_ids = array_split_time_ids[:self.n_folds]\n\n        for time_ids in array_split_time_ids:\n            # Get test index - time id values that are in the time_ids\n            test_condition = X['time_id'].isin(time_ids)\n            test_index = X.loc[test_condition].index\n\n            # Get train index - The train index will be the time\n            # id values right up until the minimum value in the test\n            # data - we can also add a gap to this step by\n            # time id < (min - gap)\n            if self.cv:\n                train_condition = ( X['time_id'] < (np.min(time_ids)) ) | ( X['time_id'] > (np.max(time_ids)) )\n            else:\n                train_condition = X['time_id'] < (np.min(time_ids))\n            train_index = X.loc[train_condition].index\n\n            yield train_index, test_index","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:27:07.158497Z","iopub.execute_input":"2022-03-29T12:27:07.158833Z","iopub.status.idle":"2022-03-29T12:27:07.172593Z","shell.execute_reply.started":"2022-03-29T12:27:07.158798Z","shell.execute_reply":"2022-03-29T12:27:07.171696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Should we apply Target preprocessing? If so, how?\n\n- In linear analysis, it is important to deal with outlier sample (it would lead the model underfitting).\n- To me, it is popular to clip the outlier in the target samples.\n- I am not 100% confident if we should do that, because we cannot clip the target samples in Public/Private LB stage.\n- Here we check the effect of target clipping in the following way:\n  - clip the target in training set.\n  - do NOT clip the target in validation set.","metadata":{"_kg_hide-input":false,"_kg_hide-output":true}},{"cell_type":"markdown","source":"### Case 0: No Target Clipping","metadata":{}},{"cell_type":"code","source":"y_all_orig = train['target'].astype(np.float16)\n\nholdout_size = 60\nFOLDS = int(len(np.unique(train['time_id'])) / holdout_size)-1\npearson_means = []\ngtss = GroupTimeSeriesSplit(n_folds=FOLDS, holdout_size=holdout_size, groups=train['time_id'], cv=True)\nfor fold, (tr, val) in enumerate(gtss.split(train)):\n    X_train = train.loc[tr, features]\n    y_train = y_all_orig[tr]\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    train_val = train.loc[val, :]\n    df_pearson_all = pd.DataFrame(columns=['time_id', 'investment_id', 'y_pred', 'y_true'])\n    df_pearson_all['time_id'] = train_val['time_id'].values\n    df_pearson_all['investment_id'] = train_val['investment_id'].values\n    X_val = train.loc[val, features]\n    y_val = y_all_orig[val]\n    df_pearson_all['y_pred'] = model.predict(X_val)\n    df_pearson_all['y_true'] = y_val.values\n    m = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).mean()\n    std = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).std()\n    pearson_means.append(m)\n    r2_train = model.score(X_train, y_train)\n    r2_val = model.score(X_val, y_val)\n    print(\"fold: {}, val mean corr: {:.3%}, val stdev corr: {:.3%}, train r2: {:.3%}, val r2: {:.3%}\".format(fold, m, std, r2_train, r2_val))\n    del X_train, y_train, X_val, y_val, tr, val\n    gc.collect()\n    \nprint(\"Peason Mean over Folds: {:.3%}, Stdev over Folds {:.3%}\".format(np.array(pearson_means).mean(), np.array(pearson_means).std()))\nprint()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:27:07.174065Z","iopub.execute_input":"2022-03-29T12:27:07.174317Z","iopub.status.idle":"2022-03-29T12:32:28.621027Z","shell.execute_reply.started":"2022-03-29T12:27:07.174285Z","shell.execute_reply":"2022-03-29T12:32:28.620034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Case 1: Clip Target for both the Lower and Upper side\n- Lower 1% quantile and upper 1% quantile","metadata":{}},{"cell_type":"code","source":"%%time\n\ny_lower_qs = {}\ny_upper_qs = {}\nTGTID = ['investment_id', 'target']\ndef f_y(x):\n    invest_id = x['investment_id'].values[0]\n    x_num = x.drop('investment_id', axis=1).values\n    y_lower_qs[invest_id] = np.quantile(x_num, q=0.01, axis=0)\n    y_upper_qs[invest_id] = np.quantile(x_num, q=0.99, axis=0) # 0.99\n    x_num = np.clip(x_num, y_lower_qs[invest_id], y_upper_qs[invest_id])\n    x['target'] = x_num.astype(np.float16)\n    return x\ny_all_orig = train['target'].astype(np.float16)\ny_all_correct = train[TGTID].groupby('investment_id').apply(lambda x: f_y(x))['target'].astype(np.float16)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-03-29T12:32:28.622721Z","iopub.execute_input":"2022-03-29T12:32:28.623476Z","iopub.status.idle":"2022-03-29T12:32:33.47662Z","shell.execute_reply.started":"2022-03-29T12:32:28.623423Z","shell.execute_reply":"2022-03-29T12:32:33.475458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holdout_size = 60\nFOLDS = int(len(np.unique(train['time_id'])) / holdout_size)-1\npearson_means = []\ngtss = GroupTimeSeriesSplit(n_folds=FOLDS, holdout_size=holdout_size, groups=train['time_id'], cv=True)\nfor fold, (tr, val) in enumerate(gtss.split(train)):\n    X_train = train.loc[tr, features]\n    y_train = y_all_correct[tr]\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    train_val = train.loc[val, :]\n    df_pearson_all = pd.DataFrame(columns=['time_id', 'investment_id', 'y_pred', 'y_true'])\n    df_pearson_all['time_id'] = train_val['time_id'].values\n    df_pearson_all['investment_id'] = train_val['investment_id'].values\n    X_val = train.loc[val, features]\n    y_val = y_all_orig[val]\n    df_pearson_all['y_pred'] = model.predict(X_val)\n    df_pearson_all['y_true'] = y_val.values\n    m = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).mean()\n    std = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).std()\n    pearson_means.append(m)\n    r2_train = model.score(X_train, y_train)\n    r2_val = model.score(X_val, y_val)\n    print(\"fold: {}, val mean corr: {:.3%}, val stdev corr: {:.3%}, train r2: {:.3%}, val r2: {:.3%}\".format(fold, m, std, r2_train, r2_val))\n    del X_train, y_train, X_val, y_val, tr, val\n    gc.collect()\n    \nprint(\"Peason Mean over Folds: {:.3%}, Stdev over Folds {:.3%}\".format(np.array(pearson_means).mean(), np.array(pearson_means).std()))\nprint()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:32:33.478129Z","iopub.execute_input":"2022-03-29T12:32:33.47839Z","iopub.status.idle":"2022-03-29T12:37:44.61871Z","shell.execute_reply.started":"2022-03-29T12:32:33.478359Z","shell.execute_reply":"2022-03-29T12:37:44.617782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Lower 3% quantile and upper 3% quantile","metadata":{}},{"cell_type":"code","source":"y_lower_qs = {}\ny_upper_qs = {}\nTGTID = ['investment_id', 'target']\ndef f_y(x):\n    invest_id = x['investment_id'].values[0]\n    x_num = x.drop('investment_id', axis=1).values\n    y_lower_qs[invest_id] = np.quantile(x_num, q=0.03, axis=0)\n    y_upper_qs[invest_id] = np.quantile(x_num, q=0.97, axis=0) # 0.99\n    x_num = np.clip(x_num, y_lower_qs[invest_id], y_upper_qs[invest_id])\n    x['target'] = x_num.astype(np.float16)\n    return x\ny_all_orig = train['target'].astype(np.float16)\ny_all_correct = train[TGTID].groupby('investment_id').apply(lambda x: f_y(x))['target'].astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T12:37:44.61992Z","iopub.execute_input":"2022-03-29T12:37:44.62016Z","iopub.status.idle":"2022-03-29T12:37:49.67021Z","shell.execute_reply.started":"2022-03-29T12:37:44.620128Z","shell.execute_reply":"2022-03-29T12:37:49.669318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holdout_size = 60\nFOLDS = int(len(np.unique(train['time_id'])) / holdout_size)-1\npearson_means = []\ngtss = GroupTimeSeriesSplit(n_folds=FOLDS, holdout_size=holdout_size, groups=train['time_id'], cv=True)\nfor fold, (tr, val) in enumerate(gtss.split(train)):\n    X_train = train.loc[tr, features]\n    y_train = y_all_correct[tr]\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    train_val = train.loc[val, :]\n    df_pearson_all = pd.DataFrame(columns=['time_id', 'investment_id', 'y_pred', 'y_true'])\n    df_pearson_all['time_id'] = train_val['time_id'].values\n    df_pearson_all['investment_id'] = train_val['investment_id'].values\n    X_val = train.loc[val, features]\n    y_val = y_all_orig[val]\n    df_pearson_all['y_pred'] = model.predict(X_val)\n    df_pearson_all['y_true'] = y_val.values\n    m = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).mean()\n    std = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).std()\n    pearson_means.append(m)\n    r2_train = model.score(X_train, y_train)\n    r2_val = model.score(X_val, y_val)\n    print(\"fold: {}, val mean corr: {:.3%}, val stdev corr: {:.3%}, train r2: {:.3%}, val r2: {:.3%}\".format(fold, m, std, r2_train, r2_val))\n    del X_train, y_train, X_val, y_val, tr, val\n    gc.collect()\n    \nprint(\"Peason Mean over Folds: {:.3%}, Stdev over Folds {:.3%}\".format(np.array(pearson_means).mean(), np.array(pearson_means).std()))\nprint()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:37:49.673051Z","iopub.execute_input":"2022-03-29T12:37:49.67333Z","iopub.status.idle":"2022-03-29T12:43:07.527605Z","shell.execute_reply.started":"2022-03-29T12:37:49.673296Z","shell.execute_reply":"2022-03-29T12:43:07.526624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Case 2: Clip Target only for Upper side\n- upper 3% quantile\n- It improves A LOT on **train r2**.\n- From my experience (NIKKEI225 and the option market), market behaves consistently when market crashes. Instead market might not behaves consistently when market goes upward. Clipping only upper side does not seem strange to me...\n- For fold 5, the val corr shows relatively low score. (We have a room to improve.)\n- **In colusions, we use target clipping with this setup.**","metadata":{}},{"cell_type":"code","source":"y_upper_qs = {}\nTGTID = ['investment_id', 'target']\ndef f_y(x):\n    invest_id = x['investment_id'].values[0]\n    x_num = x.drop('investment_id', axis=1).values\n    y_upper_qs[invest_id] = np.quantile(x_num, q=0.97, axis=0) # 0.99\n    x_num = np.clip(x_num, None, y_upper_qs[invest_id])\n    x['target'] = x_num.astype(np.float16)\n    return x\ny_all_orig = train['target'].astype(np.float16)\ny_all_correct = train[TGTID].groupby('investment_id').apply(lambda x: f_y(x))['target'].astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T12:43:07.529409Z","iopub.execute_input":"2022-03-29T12:43:07.530574Z","iopub.status.idle":"2022-03-29T12:43:11.977043Z","shell.execute_reply.started":"2022-03-29T12:43:07.530495Z","shell.execute_reply":"2022-03-29T12:43:11.976044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holdout_size = 60\nFOLDS = int(len(np.unique(train['time_id'])) / holdout_size)-1\npearson_means = []\ngtss = GroupTimeSeriesSplit(n_folds=FOLDS, holdout_size=holdout_size, groups=train['time_id'], cv=True)\nfor fold, (tr, val) in enumerate(gtss.split(train)):\n    X_train = train.loc[tr, features]\n    y_train = y_all_correct[tr]\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    train_val = train.loc[val, :]\n    df_pearson_all = pd.DataFrame(columns=['time_id', 'investment_id', 'y_pred', 'y_true'])\n    df_pearson_all['time_id'] = train_val['time_id'].values\n    df_pearson_all['investment_id'] = train_val['investment_id'].values\n    X_val = train.loc[val, features]\n    y_val = y_all_orig[val]\n    df_pearson_all['y_pred'] = model.predict(X_val)\n    df_pearson_all['y_true'] = y_val.values\n    m = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).mean()\n    std = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).std()\n    pearson_means.append(m)\n    r2_train = model.score(X_train, y_train)\n    r2_val = model.score(X_val, y_val)\n    print(\"fold: {}, val mean corr: {:.3%}, val stdev corr: {:.3%}, train r2: {:.3%}, val r2: {:.3%}\".format(fold, m, std, r2_train, r2_val))\n    del X_train, y_train, X_val, y_val, tr, val\n    gc.collect()\n    \nprint(\"Peason Mean over Folds: {:.3%}, Stdev over Folds {:.3%}\".format(np.array(pearson_means).mean(), np.array(pearson_means).std()))\nprint()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-29T12:43:11.978341Z","iopub.execute_input":"2022-03-29T12:43:11.978589Z","iopub.status.idle":"2022-03-29T12:48:20.474269Z","shell.execute_reply.started":"2022-03-29T12:43:11.97856Z","shell.execute_reply":"2022-03-29T12:48:20.471676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Should we apply Feature preprocessing? If so, how?\n\n- Next, we consider feature clipping and normalization.\n- Given we do not distinguish investment_id in the training, it would be important to normalize feature values for different investment_id into the same range.\n- Here we check the effect of feature clipping and normalization in the following way:\n  - learn to clip and normalize the features in training set.\n  - apply trained clipping and scalers in validation set.\n  - if a investment_id in validation set is not in training set, we do not do anything.","metadata":{}},{"cell_type":"markdown","source":"### Case 1: Clip and Normalize Features in Training\n\n- **train r2** consistently increases in each fold.\n- However, **valid r2** decrease for almost all the folds.","metadata":{}},{"cell_type":"code","source":"FEATID = features + ['investment_id']\nTGTID = ['investment_id', 'target']\npearson_means = []\nholdout_size = 60\nFOLDS = int(len(np.unique(train['time_id'])) / holdout_size)-1\ngtss = GroupTimeSeriesSplit(n_folds=FOLDS, holdout_size=holdout_size, groups=train['time_id'], cv=True)\nfor fold, (tr, val) in enumerate(gtss.split(train)):\n    X_train = train.loc[tr, FEATID]\n    y_train = train.loc[tr, TGTID]\n\n    # Outlier treatment and Normalization of X_train (by investment_id)\n    scalers = {}\n    lower_qs = {}\n    upper_qs = {}\n    for invest_id in X_train['investment_id'].unique():\n        scalers[invest_id] = StandardScaler()\n    def ft_x(x):\n        invest_id = x['investment_id'].values[0]\n        x_num = x.drop('investment_id', axis=1).values\n        lower_qs[invest_id] = np.quantile(x_num, q=0.01, axis=0)\n        upper_qs[invest_id] = np.quantile(x_num, q=0.99, axis=0)\n        x_num = np.clip(x_num, lower_qs[invest_id], upper_qs[invest_id])\n        x_num = scalers[invest_id].fit_transform(x_num)\n        x[features] = x_num.astype(np.float16)\n        return x\n    X_train = X_train.groupby('investment_id').apply(lambda x: ft_x(x))[features].astype(np.float16)\n\n    # Outlier treatment of y_train (by investment_id)\n    y_upper_qs = {}\n    def ft_y(x):\n        invest_id = x['investment_id'].values[0]\n        x_num = x.drop('investment_id', axis=1).values\n        y_upper_qs[invest_id] = np.quantile(x_num, q=0.97, axis=0)\n        x_num = np.clip(x_num, None, y_upper_qs[invest_id])\n        x['target'] = x_num.astype(np.float16)\n        return x\n    y_train = y_train.groupby('investment_id').apply(lambda x: ft_y(x))['target'].astype(np.float16)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    train_val = train.loc[val, :]\n    df_pearson_all = pd.DataFrame(columns=['time_id', 'investment_id', 'y_pred', 'y_true'])\n    df_pearson_all['time_id'] = train_val['time_id'].values\n    df_pearson_all['investment_id'] = train_val['investment_id'].values\n    train_val.drop(['time_id', 'target'], axis=1, inplace=True)\n\n    # apply trained Scaler/quantiles to X_val\n    # if new investmen_id appears, we do not do anything (we could do apply average scaler/quantile for example...). \n    def t_x(x):\n        invest_id = x['investment_id'].values[0]\n        if invest_id in lower_qs.keys():\n            x_num = x.drop('investment_id', axis=1).values\n            x_num = np.clip(x_num, lower_qs[invest_id], upper_qs[invest_id])\n            x_num = scalers[invest_id].transform(x_num)\n            x[features] = x_num.astype(np.float16)\n        else:\n            #print(\"invest id not found in train: {}\".format(invest_id))\n            pass\n        return x\n    X_val = train_val.groupby('investment_id').apply(lambda x: t_x(x))[features].astype(np.float16)\n    y_val = train.loc[val, 'target'].astype(np.float16)\n    # evaluation\n    df_pearson_all['y_pred'] = model.predict(X_val)\n    df_pearson_all['y_true'] = y_val.values\n    m = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).mean()\n    std = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).std()\n    pearson_means.append(m)\n    r2_train = model.score(X_train, y_train)\n    r2_val = model.score(X_val, y_val)\n    print(\"fold: {}, val mean corr: {:.3%}, val stdev corr: {:.3%}, train r2: {:.3%}, val r2: {:.3%}\".format(fold, m, std, r2_train, r2_val))\n    del X_train, y_train, X_val, y_val, tr, val\n    gc.collect()\n\nprint(\"Peason Mean over Folds: {:.3%}, Stdev over Folds {:.3%}\".format(np.array(pearson_means).mean(), np.array(pearson_means).std()))\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T12:48:20.480597Z","iopub.execute_input":"2022-03-29T12:48:20.482122Z","iopub.status.idle":"2022-03-29T13:14:13.281325Z","shell.execute_reply.started":"2022-03-29T12:48:20.48199Z","shell.execute_reply":"2022-03-29T13:14:13.280294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Case 2: Fit and Transform StandardScaler to X_val\n- Given the above results, I just wanted to try the case where we know the true mean and stdev of X_val (I know it is not possible to do in this competition).\n- We find **very high correlation values** in all the folds (again, I know I am cheating...).\n- I have not fully understood what is happening here.\n  - It seems that mean and stdev of X shift from training period to validation period (domain shift).\n  - If so, a model trained with train dataset would not have prediction capability for validation dataset.\n  - However, we found the same model have good prediction ability for validation dataset if we refit scaler to validation dataset.\n  - I am a bit confused...\n- Can we guess mean and stdev of X in Public/Private LB?\n  - we can store X history in the TimeSeriesAPI, at least we can calculate rolling mean/std of X.\n  - I thought we can do similar if we use `(X-rolling_mean)/rolling_std` as a feature instead of doing feature normalization.\n  - I did a small test but did not work (maybe we can do better...).\n- My gut feeling is now using non-liniear model:\n  - linear model is based on the fact that each feature is normally distributed.\n  - However, we found domain shift. If we believe that provided training data includes all market regimes happening in the future (the one in Private LB), we can build regime switching model depending on the input X.\n  - If I have time, I want to try the above (using simple regime swtiching model, GBDT, or NN model expected to learn that internally. We should be careful of overfitting when using large model like GBDT/NN).","metadata":{}},{"cell_type":"code","source":"FEATID = features + ['investment_id']\nTGTID = ['investment_id', 'target']\npearson_means = []\nholdout_size = 60\nFOLDS = int(len(np.unique(train['time_id'])) / holdout_size)-1\ngtss = GroupTimeSeriesSplit(n_folds=FOLDS, holdout_size=holdout_size, groups=train['time_id'], cv=True)\nfor fold, (tr, val) in enumerate(gtss.split(train)):\n    X_train = train.loc[tr, FEATID]\n    y_train = train.loc[tr, TGTID]\n\n    # Outlier treatment and Normalization of X_train (by investment_id)\n    scalers = {}\n    lower_qs = {}\n    upper_qs = {}\n    for invest_id in X_train['investment_id'].unique():\n        scalers[invest_id] = StandardScaler()\n    def ft_x(x):\n        invest_id = x['investment_id'].values[0]\n        x_num = x.drop('investment_id', axis=1).values\n        lower_qs[invest_id] = np.quantile(x_num, q=0.01, axis=0)\n        upper_qs[invest_id] = np.quantile(x_num, q=0.99, axis=0)\n        x_num = np.clip(x_num, lower_qs[invest_id], upper_qs[invest_id])\n        x_num = scalers[invest_id].fit_transform(x_num)\n        x[features] = x_num.astype(np.float16)\n        return x\n    X_train = X_train.groupby('investment_id').apply(lambda x: ft_x(x))[features].astype(np.float16)\n\n    # Outlier treatment of y_train (by investment_id)\n    y_upper_qs = {}\n    def ft_y(x):\n        invest_id = x['investment_id'].values[0]\n        x_num = x.drop('investment_id', axis=1).values\n        y_upper_qs[invest_id] = np.quantile(x_num, q=0.97, axis=0)\n        x_num = np.clip(x_num, None, y_upper_qs[invest_id])\n        x['target'] = x_num.astype(np.float16)\n        return x\n    y_train = y_train.groupby('investment_id').apply(lambda x: ft_y(x))['target'].astype(np.float16)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    train_val = train.loc[val, :]\n    df_pearson_all = pd.DataFrame(columns=['time_id', 'investment_id', 'y_pred', 'y_true'])\n    df_pearson_all['time_id'] = train_val['time_id'].values\n    df_pearson_all['investment_id'] = train_val['investment_id'].values\n    train_val.drop(['time_id', 'target'], axis=1, inplace=True)\n\n    # RETRAIN Scaler to X_val\n    # if new investmen_id appears, we do not do anything (we could do apply average scaler/quantile for example...). \n    def t_x(x):\n        invest_id = x['investment_id'].values[0]\n        if invest_id in lower_qs.keys():\n            x_num = x.drop('investment_id', axis=1).values\n            x_num = np.clip(x_num, lower_qs[invest_id], upper_qs[invest_id])\n            x_num = scalers[invest_id].fit_transform(x_num)\n            x[features] = x_num.astype(np.float16)\n        else:\n            #print(\"invest id not found in train: {}\".format(invest_id))\n            pass\n        return x\n    X_val = train_val.groupby('investment_id').apply(lambda x: t_x(x))[features].astype(np.float16)\n    y_val = train.loc[val, 'target'].astype(np.float16)\n    # evaluation\n    df_pearson_all['y_pred'] = model.predict(X_val)\n    df_pearson_all['y_true'] = y_val.values\n    m = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).mean()\n    std = df_pearson_all.groupby('time_id').apply(lambda x: pearsonr(x['y_true'], x['y_pred'])[0]).std()\n    pearson_means.append(m)\n    r2_train = model.score(X_train, y_train)\n    r2_val = model.score(X_val, y_val)\n    print(\"fold: {}, val mean corr: {:.3%}, val stdev corr: {:.3%}, train r2: {:.3%}, val r2: {:.3%}\".format(fold, m, std, r2_train, r2_val))\n    del X_train, y_train, X_val, y_val, tr, val\n    gc.collect()\n\nprint(\"Peason Mean over Folds: {:.3%}, Stdev over Folds {:.3%}\".format(np.array(pearson_means).mean(), np.array(pearson_means).std()))\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:34:22.936988Z","iopub.execute_input":"2022-03-29T13:34:22.937727Z","iopub.status.idle":"2022-03-29T14:00:09.374798Z","shell.execute_reply.started":"2022-03-29T13:34:22.937683Z","shell.execute_reply":"2022-03-29T14:00:09.373787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. What are missing?\n\nI used linear regression model with target clipping and feature clipping/normalization. I have not achieved high correlation score so far.\n\nI think I am missing the following functionality in the model:\n- functionality to switch market regime to deal with domain shift.\n- functionality to take into account inter-feature effect.\n- functionality to deal with outlier (this could improve the OOS correlation by a bit).","metadata":{}},{"cell_type":"code","source":"print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 1000000:\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name))/1000/1000/1000,'|'))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T06:14:37.875706Z","iopub.execute_input":"2022-03-29T06:14:37.876658Z","iopub.status.idle":"2022-03-29T06:14:37.914751Z","shell.execute_reply.started":"2022-03-29T06:14:37.876617Z","shell.execute_reply":"2022-03-29T06:14:37.91362Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}