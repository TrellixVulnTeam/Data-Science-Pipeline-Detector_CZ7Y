{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"    # This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T08:37:14.323183Z","iopub.execute_input":"2022-02-21T08:37:14.323806Z","iopub.status.idle":"2022-02-21T08:37:14.354684Z","shell.execute_reply.started":"2022-02-21T08:37:14.323696Z","shell.execute_reply":"2022-02-21T08:37:14.353943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\nfrom scipy.stats import probplot, pearsonr\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Linear \n\nimport pickle\nfrom torch.autograd import Variable\nimport torch.utils.data as Data\nimport math\nimport time\nimport datetime\nimport os\nimport random\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T08:37:14.356193Z","iopub.execute_input":"2022-02-21T08:37:14.356388Z","iopub.status.idle":"2022-02-21T08:37:24.522485Z","shell.execute_reply.started":"2022-02-21T08:37:14.356365Z","shell.execute_reply":"2022-02-21T08:37:24.521217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Saving 'train_data' to 'pkl', for less time to load 'train_data'**","metadata":{}},{"cell_type":"code","source":"'''\ntrain_dtypes = {f'f_{i}': np.float32 for i in range(300)}\ntrain_dtypes['investment_id'] = np.uint16\ntrain_dtypes['time_id'] = np.uint16\ntrain_dtypes['target'] = np.float32\n\ndf_train = pd.read_csv('../input/ubiquant-market-prediction/train.csv', usecols=list(train_dtypes.keys()), dtype=train_dtypes)\nprint(f'Training Set Shape: {df_train.shape} - Memory Usage: {df_train.memory_usage().sum() / 1024 ** 2:.2f} MB')\ndf_train.to_pickle('train.pkl')\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-21T08:37:24.526797Z","iopub.execute_input":"2022-02-21T08:37:24.527589Z","iopub.status.idle":"2022-02-21T08:37:24.538031Z","shell.execute_reply.started":"2022-02-21T08:37:24.527549Z","shell.execute_reply":"2022-02-21T08:37:24.53717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **load data from .pkl**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **some data analysis**","metadata":{}},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **data loaders**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **transformers base model**","metadata":{}},{"cell_type":"code","source":"import pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Linear \n\n\n\ndef gen_trg_mask(length, device):\n    mask = torch.tril(torch.ones(length, length, device=device)) == 1\n\n    mask = (\n        mask.float()\n        .masked_fill(mask == 0, float(\"-inf\"))\n        .masked_fill(mask == 1, float(0.0))\n    )\n\n    return mask\n\nclass Transformers(pl.LightningModule):\n    def __init__(\n        self,\n        n_encoder_inputs,\n        n_decoder_inputs,\n        channels=64,\n        dropout=0.1,\n        in_ebddim = 128,\n        tar_ebddim = 128,\n        ):\n        super(Transformers, self).__init__() \n\n        self.dropout = dropout\n\n        self.input_pos_embedding = torch.nn.Embedding(in_ebddim, embedding_dim=channels)\n        self.target_pos_embedding = torch.nn.Embedding(tar_ebddim, embedding_dim=channels)\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=channels,\n            nhead=8,\n            dropout=self.dropout,\n            dim_feedforward=4 * channels,\n        )\n        decoder_layer = nn.TransformerDecoderLayer(\n            d_model=channels,\n            nhead=8,\n            dropout=self.dropout,\n            dim_feedforward=4 * channels,\n        )\n\n        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=8)\n        self.decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=8)\n\n        self.input_projection = Linear(n_encoder_inputs, channels)\n        self.output_projection = Linear(n_decoder_inputs, channels)\n\n        self.linear = Linear(channels, 1)\n\n        self.do = nn.Dropout(p=self.dropout)\n\n    def encode_src(self, src):\n        # src = src.long()\n        src_start = self.input_projection(src).permute(1, 0, 2)\n\n        in_sequence_len, batch_size = src_start.size(0), src_start.size(1)\n        pos_encoder = (\n            torch.arange(0, in_sequence_len, device=src.device)\n            .unsqueeze(0)\n            .repeat(batch_size, 1)\n        )\n\n        pos_encoder = self.input_pos_embedding(pos_encoder).permute(1, 0, 2)\n\n        src = src_start + pos_encoder\n\n        src = self.encoder(src) + src_start\n\n        return src\n\n    def decode_trg(self, trg, memory):\n        # trg = trg.long()\n        trg_start = self.output_projection(trg).permute(1, 0, 2)\n\n        out_sequence_len, batch_size = trg_start.size(0), trg_start.size(1)\n\n        pos_decoder = (\n            torch.arange(0, out_sequence_len, device=trg.device)\n            .unsqueeze(0)\n            .repeat(batch_size, 1)\n        )\n        pos_decoder = self.target_pos_embedding(pos_decoder).permute(1, 0, 2)\n\n        trg = pos_decoder + trg_start\n\n        trg_mask = gen_trg_mask(out_sequence_len, trg.device)\n\n        out = self.decoder(tgt=trg, memory=memory, tgt_mask=trg_mask) + trg_start\n\n        out = out.permute(1, 0, 2)\n\n        out = self.linear(out)\n\n        return out\n\n    def forward(self, x):\n        src, trg = x\n\n        src = self.encode_src(src)\n\n        out = self.decode_trg(trg=trg, memory=src)\n\n        return out\n    \n    \n\nn_classes = 100\n\nsource = torch.rand(size=(32, 16, 9))\ntarget_in = torch.rand(size=(32, 16, 9))\ntarget_out = torch.rand(size=(32, 16, 1))\nts = Transformers(n_encoder_inputs=9, n_decoder_inputs=9)\n\npred = ts((source, target_in))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T08:37:24.54232Z","iopub.execute_input":"2022-02-21T08:37:24.542671Z","iopub.status.idle":"2022-02-21T08:37:24.956705Z","shell.execute_reply.started":"2022-02-21T08:37:24.542632Z","shell.execute_reply":"2022-02-21T08:37:24.955851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **train models**","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 17 17:24:09 2022\n\n@author: jaycezhao\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\nfrom scipy.stats import probplot, pearsonr\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Linear \n\nimport pickle\nfrom torch.autograd import Variable\nimport torch.utils.data as Data\nimport math\nimport time\nimport datetime\nimport os\nimport random\n\ndf_train = pd.read_pickle('../input/ubiquant-train-pkl/train.pkl')\n\ncols = list(df_train.columns)\nfearures_col = cols[3:]\nkeys = df_train[['investment_id','time_id']].groupby(by=['investment_id','time_id']).first().reset_index()\n\ninvestment_ids = list(keys['investment_id'].unique())\n\n\ndef data_loaders(df_train_raw,investment_ids,fearures_col):\n    df_train = df_train_raw.copy()\n    target = []\n    train_x = []\n    train_y = []\n    \n    target_test = []\n    train_x_test = []\n    train_y_test = []\n    train_flag = False\n    test_flag = False\n    for ids in range(len(investment_ids[:])):\n    #investment_id = investment_ids[0]\n        investment_id = investment_ids[ids]\n        # print('\\r make data_loaders****totall:{totall}/now:{ids}/investment_id:{investment_id}'.format(totall=len(investment_ids[:]),ids=ids+1,investment_id=investment_id),end='')\n        data_temp = df_train[df_train['investment_id']==investment_id]   \n        data_temp_train = data_temp[(data_temp['time_id']<1066)&(data_temp['time_id']>700)]\n        if len(data_temp_train)>0:\n            train_flag = True\n            target.extend(data_temp_train['target'].tolist()[:])\n            train_x.extend(data_temp_train[fearures_col].values.tolist()[:])\n            #embadding transform\n            temp_y = data_temp_train[fearures_col[::-1]].values.tolist()[:]\n            train_y.extend(temp_y)\n        data_temp_test = data_temp[data_temp['time_id']>1066]\n        if len(data_temp_test)>0:\n            test_flag = True\n            target_test.extend(data_temp_test['target'].tolist()[:])\n            train_x_test.extend(data_temp_test[fearures_col].values.tolist()[:])\n            #embadding transform\n            temp_test_y = data_temp_test[fearures_col[::-1]].values.tolist()[:]\n            train_y_test.extend(temp_test_y)          \n    train_dataset = [train_x,train_y,target] \n    test_dataset = [train_x_test,train_y_test,target_test]\n    return train_dataset,test_dataset,train_flag,test_flag\ntrain_dataset,test_dataset,train_flag,test_flag = data_loaders(df_train,investment_ids[:5],fearures_col)    \n\ndef gen_trg_mask(length, device):\n    mask = torch.tril(torch.ones(length, length, device=device)) == 1\n\n    mask = (\n        mask.float()\n        .masked_fill(mask == 0, float(\"-inf\"))\n        .masked_fill(mask == 1, float(0.0))\n    )\n\n    return mask\n\nclass Transformers(pl.LightningModule):\n    def __init__(\n        self,\n        n_encoder_inputs,\n        n_decoder_inputs,\n        channels=64,\n        dropout=0.1,\n        in_ebddim = 128,\n        tar_ebddim = 128,\n        ):\n        super(Transformers, self).__init__() \n\n        self.dropout = dropout\n\n        self.input_pos_embedding = torch.nn.Embedding(in_ebddim, embedding_dim=channels)\n        self.target_pos_embedding = torch.nn.Embedding(tar_ebddim, embedding_dim=channels)\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=channels,\n            nhead=8,\n            dropout=self.dropout,\n            dim_feedforward=4 * channels,\n        )\n        decoder_layer = nn.TransformerDecoderLayer(\n            d_model=channels,\n            nhead=8,\n            dropout=self.dropout,\n            dim_feedforward=4 * channels,\n        )\n\n        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=8)\n        self.decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=8)\n\n        self.input_projection = Linear(n_encoder_inputs, channels)\n        self.output_projection = Linear(n_decoder_inputs, channels)\n\n        self.linear = Linear(channels, 1)\n\n        self.do = nn.Dropout(p=self.dropout)\n\n    def encode_src(self, src):\n        # src = src.long()\n        src_start = self.input_projection(src).permute(1, 0, 2)\n\n        in_sequence_len, batch_size = src_start.size(0), src_start.size(1)\n        pos_encoder = (\n            torch.arange(0, in_sequence_len, device=src.device)\n            .unsqueeze(0)\n            .repeat(batch_size, 1)\n        )\n\n        pos_encoder = self.input_pos_embedding(pos_encoder).permute(1, 0, 2)\n\n        src = src_start + pos_encoder\n\n        src = self.encoder(src) + src_start\n\n        return src\n\n    def decode_trg(self, trg, memory):\n        # trg = trg.long()\n        trg_start = self.output_projection(trg).permute(1, 0, 2)\n\n        out_sequence_len, batch_size = trg_start.size(0), trg_start.size(1)\n\n        pos_decoder = (\n            torch.arange(0, out_sequence_len, device=trg.device)\n            .unsqueeze(0)\n            .repeat(batch_size, 1)\n        )\n        pos_decoder = self.target_pos_embedding(pos_decoder).permute(1, 0, 2)\n\n        trg = pos_decoder + trg_start\n\n        trg_mask = gen_trg_mask(out_sequence_len, trg.device)\n\n        out = self.decoder(tgt=trg, memory=memory, tgt_mask=trg_mask) + trg_start\n\n        out = out.permute(1, 0, 2)\n\n        out = self.linear(out)\n\n        return out\n\n    def forward(self, x):\n        src, trg = x\n\n        src = self.encode_src(src)\n\n        out = self.decode_trg(trg=trg, memory=src)\n\n        return out\n    \n\nsource = torch.rand(size=(32, 16, 9))\ntarget_in = torch.rand(size=(32, 16, 9))\ntarget_out = torch.rand(size=(32, 16, 1))\nts = Transformers(n_encoder_inputs=9, n_decoder_inputs=9)\n\npred = ts((source, target_in))\n\n\n\ndef set_seed(seed):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    \nclass DataSet_Ids(Data.Dataset):\n    def __init__(self, dataset_ids):\n        super(DataSet_Ids, self).__init__()\n        self.dataset_ids = dataset_ids\n    def __len__(self):\n        return np.shape(self.dataset_ids)[0]\n    def __getitem__(self, idx):\n        return self.dataset_ids[idx]\n\n\ndef make_dateloader_iters(train_x_raw,train_y_raw,target_raw):\n    steps_all = int((len(target_raw)-windows)/step)\n    train_xs = []\n    train_ys = []\n    targets = []\n    for iters in range(steps_all):\n        train_x = train_x_raw[iters*step:iters*step+windows]\n        train_y = train_y_raw[iters*step:iters*step+windows]\n        target = target_raw[iters*step:iters*step+windows]                \n        \n        x = np.array(train_x)\n\n        y = np.array(train_y)\n\n        z = np.expand_dims(np.array(target),1)\n               \n        \n        # x = np.array([np.array(train_x),np.array(train_y),np.array(train_x)])\n        # x = np.swapaxes(x,0,2)\n        # x = np.swapaxes(x,0,1)\n        # y = np.array([np.array(train_y),np.array(train_x),np.array(train_y)])\n        # y = np.swapaxes(y,0,2)\n        # y = np.swapaxes(y,0,1)\n        # z = np.expand_dims(np.array(target),1)\n        # z = z[:,:,np.newaxis]        \n        \n        train_xs.append(x)\n        train_ys.append(y)\n        targets.append(z)\n    return train_xs,train_ys,targets\n\nclass Train_DataSet(Data.Dataset):\n    def __init__(self, enc_inputs, dec_inputs, dec_outputs):\n        super(Train_DataSet, self).__init__()\n        self.enc_inputs = enc_inputs\n        self.dec_inputs = dec_inputs\n        self.dec_outputs = dec_outputs\n  \n    def __len__(self):\n        return np.shape(self.enc_inputs)[0]\n    \n    def __getitem__(self, idx):\n        return self.enc_inputs[idx], self.dec_inputs[idx], self.dec_outputs[idx]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T08:37:24.959047Z","iopub.execute_input":"2022-02-21T08:37:24.959374Z","iopub.status.idle":"2022-02-21T08:38:17.062361Z","shell.execute_reply.started":"2022-02-21T08:37:24.95934Z","shell.execute_reply":"2022-02-21T08:38:17.061384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(investment_ids)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T08:57:43.77565Z","iopub.execute_input":"2022-02-21T08:57:43.776316Z","iopub.status.idle":"2022-02-21T08:57:43.781236Z","shell.execute_reply.started":"2022-02-21T08:57:43.77628Z","shell.execute_reply":"2022-02-21T08:57:43.78066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T08:38:17.064417Z","iopub.execute_input":"2022-02-21T08:38:17.065167Z","iopub.status.idle":"2022-02-21T08:38:17.333527Z","shell.execute_reply.started":"2022-02-21T08:38:17.065122Z","shell.execute_reply":"2022-02-21T08:38:17.332821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch = 32\nbatch_size = 128\nstep = 32\nwindows = 32\nSEED = 42\nLR=1e-5\nset_seed(SEED)\ntimest = time.time()\n\n\nn_decoder_inputs=len(fearures_col)\nn_encoder_inputs=len(fearures_col)\n# print(n_decoder_inputs,n_encoder_inputs)\ninvestment_ids = list(keys['investment_id'].unique())\n\nmodel = Transformers(n_encoder_inputs=n_encoder_inputs, \n                     n_decoder_inputs=n_decoder_inputs,\n                     channels=64,in_ebddim = 128,tar_ebddim = 128)\nlos_min = 1000\ngpus = [0]\ncuda_gpu = torch.cuda.is_available()\nif (cuda_gpu):                   \n    model = torch.nn.DataParallel(model,device_ids=gpus).cuda()  \nfor h in range(epoch): \n    model.train()\n    # lr = float(LR*(1*math.cos((0.5*math.pi*h/epoch))))\n    lr = float(LR*(1-(h/epoch)**0.5))\n    optimizer = torch.optim.Adam(model.parameters(),lr)\n    loss_list = []\n    loss_evl_list = [2]    \n    for steps, investment_id in enumerate(investment_ids[::8]):\n        time_now = datetime.datetime.now().strftime('%Y_%m_%d ## %H:%M:%S')\n        train_dataset,test_dataset,train_flag,test_flag = data_loaders(df_train,[investment_id],fearures_col)\n        #print('Training ############# investment_ids:{investment_id}'.format(investment_id=investment_id))\n        if train_flag:\n            [train_x_raw,train_y_raw,target_raw] = train_dataset \n            train_xs,train_ys,targets = make_dateloader_iters(train_x_raw,train_y_raw,target_raw)\n            \n            train_xs,train_ys,targets = torch.FloatTensor(train_xs), torch.FloatTensor(train_ys), torch.FloatTensor(targets)\n            train_loader = Data.DataLoader(Train_DataSet(train_xs,train_ys,targets),batch_size=16, shuffle=False,num_workers=0)\n            for iters,(x,y,z) in enumerate(train_loader):\n                # print(np.shape(x),np.shape(y),np.shape(z))\n            \n                # x,y,z = torch.FloatTensor(x),torch.FloatTensor(y),torch.FloatTensor(z)\n\n                if (cuda_gpu):\n                    encin_tr, decin_tr, decout_tr = Variable(x).cuda(),Variable(y).cuda(),Variable(z).cuda()\n                else:           \n                    encin_tr, decin_tr, decout_tr = Variable(x),Variable(y),Variable(z)\n                # print('\\nxz',encin_tr.size(),decin_tr.size(),decout_tr.size())   \n                output = model((encin_tr, decin_tr))\n                # print(output.size())\n                loss_fun = nn.MSELoss()\n                loss = loss_fun(decout_tr,output)\n    \n                loss_list.append(loss.cpu().detach().numpy()) \n                #清空上一次梯度\n                optimizer.zero_grad()\n                #误差反向传递\n                loss.backward()\n                #优化器参数更新\n                optimizer.step()\n            if steps%5==0:    \n                print('\\r Train steps average loss is:{}/ Time is: {} /totall:{epoch}/now:{h} / investment_id is {investment_id}'.format(np.mean(loss_list),time_now,epoch=epoch,h=h+1,investment_id=investment_id),end='')\n\n    for steps, investment_id in enumerate(investment_ids[::8]):\n        time_now = datetime.datetime.now().strftime('%Y_%m_%d ## %H:%M:%S')\n        if test_flag:\n            [test_x_raw,test_y_raw,target_test] = test_dataset \n            test_xs,test_ys,target_tests = make_dateloader_iters(test_x_raw,test_y_raw,target_test)\n            \n            test_xs,test_ys,target_tests = torch.FloatTensor(test_xs), torch.FloatTensor(test_ys), torch.FloatTensor(target_tests)\n            test_loader = Data.DataLoader(Train_DataSet(test_xs,test_ys,target_tests),batch_size=16, shuffle=False,num_workers=0)\n            for iters,(x,y,z) in enumerate(test_loader):\n                # print(np.shape(x),np.shape(y),np.shape(z))\n            \n                # x,y,z = torch.FloatTensor(x),torch.FloatTensor(y),torch.FloatTensor(z)\n        \n                if (cuda_gpu):\n                    encin_te, decin_te, decout_te = Variable(x).cuda(),Variable(y).cuda(),Variable(z).cuda()\n                else:           \n                    encin_te, decin_te, decout_te = Variable(x),Variable(y),Variable(z)\n                # print('\\nxz',encin_tr.size(),decin_tr.size(),decout_tr.size())   \n                output_te = model((encin_te, decin_te))\n                # print(output.size())\n                loss_fun = nn.MSELoss()\n                loss_evl = loss_fun(decout_te,output_te)\n                loss_evl_list.append(loss_evl.cpu().detach().numpy()) \n            if steps%5==0:\n                print('\\r Evl steps average loss is:{}, Time is: {} totall:{epoch}/now:{h} / investment_id is {investment_id}'.format(np.mean(loss_evl_list),time_now,epoch=epoch,h=h+1,investment_id=investment_id),end='')\n        losses_avev = np.mean(loss_evl_list)\n        if losses_avev <= los_min:\n            los_min = losses_avev\n            epo = h+1\n            print('Save models '+\"./model_\"+str(h+1)+\".pth\\n\")\n            torch.save(model.state_dict(),\"model.pth\")  ","metadata":{"execution":{"iopub.status.busy":"2022-02-21T08:59:21.024859Z","iopub.execute_input":"2022-02-21T08:59:21.02573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}