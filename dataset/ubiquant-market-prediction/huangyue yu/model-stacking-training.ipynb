{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom tqdm.notebook import tqdm\nimport pickle\nfrom sklearn.model_selection import GroupKFold\nfrom scipy.stats import pearsonr\nfrom sklearn import metrics\nimport lightgbm as lgb\nfrom lightgbm import plot_importance\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n#from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold \nimport joblib\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-07T06:46:38.651582Z","iopub.execute_input":"2022-03-07T06:46:38.651827Z","iopub.status.idle":"2022-03-07T06:46:40.74651Z","shell.execute_reply.started":"2022-03-07T06:46:38.651801Z","shell.execute_reply":"2022-03-07T06:46:40.745802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gpu only\nimport cudf\nfrom cuml.linear_model import LinearRegression","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:46:43.316098Z","iopub.execute_input":"2022-03-07T06:46:43.316584Z","iopub.status.idle":"2022-03-07T06:46:44.906315Z","shell.execute_reply.started":"2022-03-07T06:46:43.316526Z","shell.execute_reply":"2022-03-07T06:46:44.905585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from https://www.kaggle.com/valleyzw/ubiquant-lgbm-baseline\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in tqdm(df.columns):\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16) #np.float16\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:46:46.009482Z","iopub.execute_input":"2022-03-07T06:46:46.010403Z","iopub.status.idle":"2022-03-07T06:46:46.023155Z","shell.execute_reply.started":"2022-03-07T06:46:46.01037Z","shell.execute_reply":"2022-03-07T06:46:46.022344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nfeatures = [f'f_{i}' for i in range(300)] \nadd_feat =  ['investment_id'] + ['time_id']\nDATA_ = (pd.read_parquet('../input/ubiquant-parquet-low-mem/train_low_mem.parquet', columns = features + add_feat + ['target']))\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:46:49.570355Z","iopub.execute_input":"2022-03-07T06:46:49.570614Z","iopub.status.idle":"2022-03-07T06:47:32.574203Z","shell.execute_reply.started":"2022-03-07T06:46:49.570586Z","shell.execute_reply":"2022-03-07T06:47:32.573432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outlier_list = []\noutlier_col = []\n\nfor col in (f\"f_{i}\" for i in range(300)):\n    _mean, _std = DATA_[col].mean(), DATA_[col].std()\n    #print ('==>', _mean, _std)\n    temp_df = DATA_.loc[(DATA_[col] > (_mean + _std * 70)) | (DATA_[col] < (_mean - _std * 70))]\n    temp2_df = DATA_.loc[(DATA_[col] > (_mean + _std * 35)) | (DATA_[col] < (_mean - _std * 35))]\n    if len(temp_df) >0 : \n        outliers = temp_df.index.to_list()\n        outlier_list.extend(outliers)\n        outlier_col.append(col)\n        print(col, len(temp_df))\n    elif len(temp2_df)>0 and len(temp2_df) <6 :\n        outliers = temp2_df.index.to_list()\n        outlier_list.extend(outliers)\n        outlier_col.append(col)\n        print(col, len(temp2_df))\n\noutlier_list = list(set(outlier_list))\nDATA_.drop(DATA_.index[outlier_list], inplace = True)\nprint(len(outlier_col), len(outlier_list), DATA_.shape)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:48:53.100498Z","iopub.execute_input":"2022-03-07T06:48:53.101111Z","iopub.status.idle":"2022-03-07T06:49:02.883307Z","shell.execute_reply.started":"2022-03-07T06:48:53.101075Z","shell.execute_reply":"2022-03-07T06:49:02.882645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # load data\n# features = [f'f_{i}' for i in range(300)] + ['investment_id'] \n# PATH = '../input/ubiquant-parquet-low-mem'\n# DATA_ = reduce_mem_usage(pd.read_parquet(f'{PATH}/train_low_mem.parquet', columns=features+['target']))\n# #DATA =reduce_mem_usage(pd.read_csv(PATH + '/train.csv', nrows=1141410))\n# for col in ['investment_id']:\n#     DATA_[col] = DATA_[col].astype(int)\n# print ('data loading done ', len(DATA_))\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:31:13.024765Z","iopub.execute_input":"2022-03-04T02:31:13.026559Z","iopub.status.idle":"2022-03-04T02:31:13.031737Z","shell.execute_reply.started":"2022-03-04T02:31:13.026523Z","shell.execute_reply":"2022-03-04T02:31:13.031077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\nDATA_ = reduce_mem_usage(DATA_)\nfor col in ['investment_id','time_id']:\n    DATA_[col] = DATA_[col].astype(int)\nprint ('data loading done ', len(DATA_))\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:49:02.887112Z","iopub.execute_input":"2022-03-07T06:49:02.888902Z","iopub.status.idle":"2022-03-07T06:52:00.029782Z","shell.execute_reply.started":"2022-03-07T06:49:02.888865Z","shell.execute_reply":"2022-03-07T06:52:00.029108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples=1500000\nif samples is not None:\n    #train = train.sample(args.samples, random_state=args.seed).reset_index(drop=True)\n    DATA = DATA_[-samples:].reset_index(drop=True)\n    gc.collect()\nDATA.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:52:42.84896Z","iopub.execute_input":"2022-03-07T06:52:42.849214Z","iopub.status.idle":"2022-03-07T06:52:44.099104Z","shell.execute_reply.started":"2022-03-07T06:52:42.849187Z","shell.execute_reply":"2022-03-07T06:52:44.098365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata_slice = int(0.95*len(DATA))\nx_train = DATA[:data_slice][features+add_feat]\ny_train = DATA[:data_slice]['target']\nx_test = DATA[data_slice:][features+add_feat]\ny_test = DATA[data_slice:]['target']\ndel DATA\ngc.collect()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:52:46.364332Z","iopub.execute_input":"2022-03-07T06:52:46.364607Z","iopub.status.idle":"2022-03-07T06:52:47.496111Z","shell.execute_reply.started":"2022-03-07T06:52:46.364571Z","shell.execute_reply":"2022-03-07T06:52:47.495417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicModel(object):\n    \"\"\"Parent class of basic models\"\"\"\n    def train(self, x_train, y_train, x_val, y_val):\n        \"\"\"return a trained model and eval metric of validation data\"\"\"\n        pass\n    \n    def predict(self, model, x_test,feature_importance=None):\n        \"\"\"return the predicted result of test data\"\"\"\n        pass\n    \n    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n        \"\"\"K-fold stacking\"\"\"\n        num_train, num_test = x_train.shape[0], x_test.shape[0]\n        oof_train = np.zeros((num_train,)) \n        oof_test = np.zeros((num_test,))\n        oof_test_all_fold = np.zeros((num_test, n_folds))\n        aucs = []\n        \n       \n        \n        skf = StratifiedKFold(n_splits = n_folds ,shuffle = True, random_state = 2022)\n        # KF = KFold(n_splits = n_folds, random_state=2017)\n        \n        feature_importance = [0]*301\n        # split methods\n        \n        for i, (train_index, val_index) in enumerate(skf.split(x_train, x_train['time_id'])):\n            print('{0} fold, train {1}, val {2}'.format(i, \n                                                        len(train_index),\n                                                        len(val_index)))\n            x_tra, y_tra = x_train.iloc[train_index], y_train.iloc[train_index]\n            x_val, y_val = x_train.iloc[val_index], y_train.iloc[val_index]\n            model, auc = self.train(x_tra, y_tra, x_val, y_val, i)\n            aucs.append(auc)\n            \n            oof_train[val_index],feature_importance = self.predict(model, x_val, feature_importance)\n            \n            # scatter\n            plt.figure(figsize=(20, 7), facecolor='#f6f5f5')\n            plt.scatter(oof_train[val_index]-y_val, np.arange(len(y_val)))\n            plt.show()\n            \n            print ('Pearsonr:',pearsonr(y_val, oof_train[val_index])[0])\n            \n            \n            oof_test_all_fold[:, i], _ = self.predict(model, x_test)\n            \n\n            \n            \n            #print ('Pearsonr:',pearsonr(x_test, oof_test_all_fold[:, i])[0])\n            del train_index, val_index, x_tra, y_tra, x_val, y_val, model\n            gc.collect()\n            \n        oof_test = np.mean(oof_test_all_fold, axis=1)\n        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n        \n        del x_train, y_train, x_test\n        gc.collect()\n        return oof_train, oof_test, feature_importance","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:52:49.976323Z","iopub.execute_input":"2022-03-07T06:52:49.976798Z","iopub.status.idle":"2022-03-07T06:52:49.992083Z","shell.execute_reply.started":"2022-03-07T06:52:49.976761Z","shell.execute_reply":"2022-03-07T06:52:49.991235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LinearRegressor(BasicModel):\n    def __init__(self):\n        \"\"\"set parameters\"\"\"\n        \n    def train(self, x_train, y_train, x_val, y_val, fold):\n        print('train with linear model')\n        model = LinearRegression(fit_intercept = True, normalize = False, algorithm = \"eig\")\n        reg = model.fit(x_train, y_train)\n        \n        joblib.dump(model, f'LinearRegression_{fold}.pkl')\n        del x_train, y_train, x_val, y_val\n        gc.collect()\n        \n        return model, 0\n\n    def predict(self, model, x_test, feature_importance=None):\n        print('test with linear model')\n    \n\n        # 显示重要特征\n#         plt.figure(figsize=(16, 10))\n#         plot_importance(model)\n#         plt.show()\n        return model.predict(x_test),feature_importance","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:34:11.33341Z","iopub.execute_input":"2022-03-04T02:34:11.333904Z","iopub.status.idle":"2022-03-04T02:34:11.34348Z","shell.execute_reply.started":"2022-03-04T02:34:11.333866Z","shell.execute_reply":"2022-03-04T02:34:11.342714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RAPIDSModel:\n    def __init__(self):\n        self.te = cuml.preprocessing.TargetEncoder()\n        self.base_model = cuml.ensemble.RandomForestRegressor(n_estimators=256, split_criterion=\"mse\", bootstrap=True,\n                                                              max_samples=0.6, min_samples_leaf=64, max_features=0.6, n_bins=512)\n        \n    def fit(self, x_train, y_train):\n        #train_df[\"investment_te\"] = self.te.fit_transform(x_train[\"investment_id\"], y_train).astype(\"float32\")\n        self.base_model.fit(x_train, y_train)\n        return self\n        \n    def predict(self, test_df):\n        #test_df[\"investment_te\"] = self.te.transform(test_df[\"investment_id\"]).astype(\"float32\").get()\n        return self.base_model.predict(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:34:11.344796Z","iopub.execute_input":"2022-03-04T02:34:11.345515Z","iopub.status.idle":"2022-03-04T02:34:11.353122Z","shell.execute_reply.started":"2022-03-04T02:34:11.345478Z","shell.execute_reply":"2022-03-04T02:34:11.352295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RandomForest(BasicModel):\n    def __init__(self):\n        \"\"\"set parameters\"\"\"\n        \n    def train(self, x_train, y_train, x_val, y_val, fold):\n        print('train with randomForest model')\n        model = RAPIDSModel().fit(x_train, y_train)\n        \n        \n        joblib.dump(model, f'randomForest_{fold}.pkl')\n        del x_train, y_train, x_val, y_val\n        gc.collect()\n        \n        return model, 0\n\n    def predict(self, model, x_test, feature_imprtance=None):\n        print('test with randomForest model')\n        return model.predict(x_test),feature_imprtance","metadata":{"execution":{"iopub.status.busy":"2022-03-04T02:34:11.354235Z","iopub.execute_input":"2022-03-04T02:34:11.354534Z","iopub.status.idle":"2022-03-04T02:34:11.364246Z","shell.execute_reply.started":"2022-03-04T02:34:11.3545Z","shell.execute_reply":"2022-03-04T02:34:11.36352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\ndef feval_rmse(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'rmse', rmse(y_true, y_pred), False\n\nclass LGBMRegressor(BasicModel):\n    def __init__(self):\n#         self.num_boost_round = 2000\n        self.early_stopping_rounds = 50\n        self.verbose = 100\n        self.params = {\n            'learning_rate':0.05,\n            \"objective\": \"regression\",\n            \"metric\": \"rmse\",\n            'boosting_type': \"gbdt\",\n            'verbosity': -1,\n            'n_jobs': -1, \n            'seed': 2017,\n            'lambda_l1': 0.03627602394442367, \n            'lambda_l2': 0.43523855951142926, \n            'num_leaves': 114, \n            'feature_fraction': 0.9505625064462319, \n            'bagging_fraction': 0.9785558707339647, \n            'bagging_freq': 7, \n            'max_depth': -1, \n            'max_bin': 501, \n            'min_data_in_leaf': 374,\n            'n_estimators': 1000, \n            }\n        \n        \n\n        \n    def train(self, x_train, y_train, x_val, y_val,fold):\n        print('train with lgb model')\n        train_dataset = lgb.Dataset(x_train, y_train, categorical_feature=[])\n        valid_dataset = lgb.Dataset(x_val, y_val, categorical_feature=[])\n\n        model = lgb.train(\n            self.params,\n            train_set = train_dataset, \n            valid_sets = [train_dataset, valid_dataset], \n            verbose_eval=self.verbose,\n            early_stopping_rounds=self.early_stopping_rounds,\n            feval = feval_rmse\n        )\n        joblib.dump(model, f'LGBMRegressor_{fold}.pkl')\n        \n        #print (model.best_score['valid_1'])\n        del x_train, y_train, x_val, y_val,train_dataset,valid_dataset\n        gc.collect()\n        return model, model.best_score['valid_1']['rmse']\n    \n    def predict(self, model, x_test, feature_importance=None):\n        print('test with lgb model')\n\n    \n        if feature_importance is not None:\n            # 显示重要特征\n#             plt.rcParams[\"figure.figsize\"]=(16, 10)\n#             plot_importance(model,max_num_features=80)\n#             plt.show()\n            importance = model.feature_importance()\n            feature_importance = [i + j for i, j in zip(feature_importance, importance)]\n            \n        \n        \n        return model.predict(x_test, num_iteration=model.best_iteration),feature_importance","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:26:43.230291Z","iopub.execute_input":"2022-03-07T01:26:43.23069Z","iopub.status.idle":"2022-03-07T01:26:43.250215Z","shell.execute_reply.started":"2022-03-07T01:26:43.230627Z","shell.execute_reply":"2022-03-07T01:26:43.249059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import plot_tree\n\ndef feat_dic2list (score_dict):\n    importance = [0]*300\n    for i in range(300):\n        if f'f_{i}'in score_dict:\n            importance[i] = score_dict[f'f_{i}']\n    if 'investment_id' in score_dict:\n        importance.append(score_dict['investment_id'])\n    return importance\n        \n    \n\nclass XGBRegressor(BasicModel):\n    def __init__(self):\n        \"\"\"set parameters\"\"\"\n        #self.num_rounds=1000\n        self.early_stopping_rounds = 10\n        self.verbose = 1\n        self.params = {\n            'n_estimators':500,\n            'learning_rate':0.05,\n            'max_depth': 12,\n            'subsample':0.9,\n            'colsample_bytree':0.7,\n            # colsample_bylevel=0.75,\n            'missing':-999,\n            'random_state':1111,\n            'tree_method':\"gpu_hist\"\n         }\n        \n        \n    def train(self, x_train, y_train, x_val, y_val, fold):\n        print('train with xgb model')\n        \n        dtrain = xgb.DMatrix(x_train, y_train)\n        \n        plst = list(self.params.items())\n        \n        train = xgb.DMatrix(data=x_train,\n                            label=y_train)\n        valid = xgb.DMatrix(data=x_val,\n                            label=y_val)\n     \n        model = xgb.train(plst, dtrain, evals=[(train, 'train'), (valid, 'valid')], early_stopping_rounds = self.early_stopping_rounds)\n        \n        joblib.dump(model, f'XGBRegressor_{fold}.pkl')\n        xgbval = xgb.DMatrix(x_val, y_val)\n        del train,valid,x_train, y_train, x_val, y_val\n        gc.collect()\n        \n        return model, float(model.eval(xgbval).split()[1].split(':')[1])\n\n    def predict(self, model, x_test, feature_importance= None):\n        print('test with xgb model')\n        xgbtest = xgb.DMatrix(x_test)\n        ans = model.predict(xgbtest)\n\n        if feature_importance is not None:\n#             # 显示重要特征\n#             plt.figure(figsize=(16, 10))\n#             plot_tree(model, max_depth=5)\n#             plt.show()\n\n            importance = feat_dic2list(model.get_score(importance_type='weight'))\n            feature_importance = [i + j for i, j in zip(feature_importance, importance)]\n            \n        return ans, feature_importance","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:52:55.738981Z","iopub.execute_input":"2022-03-07T06:52:55.739237Z","iopub.status.idle":"2022-03-07T06:52:55.751702Z","shell.execute_reply.started":"2022-03-07T06:52:55.739209Z","shell.execute_reply":"2022-03-07T06:52:55.750911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_XGBRegressor = XGBRegressor()\nxgb_oof_train, xgb_oof_test, feat_importance = xgb_XGBRegressor.get_oof(x_train, y_train, x_test)\ndel xgb_XGBRegressor\n# feat_importance_df_xgb = cudf.DataFrame({'importance':feat_importance,'var':features})\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T06:52:58.966862Z","iopub.execute_input":"2022-03-07T06:52:58.96751Z","iopub.status.idle":"2022-03-07T06:56:10.045205Z","shell.execute_reply.started":"2022-03-07T06:52:58.967468Z","shell.execute_reply":"2022-03-07T06:56:10.044561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlgb_LGBMRegressor = LGBMRegressor()\nlgb_oof_train, lgb_oof_test, feat_importance = lgb_LGBMRegressor.get_oof(x_train, y_train, x_test)\ndel lgb_LGBMRegressor\n#feat_importance_df_lgb = cudf.DataFrame({'importance':feat_importance,'var':features})\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:26:43.251878Z","iopub.execute_input":"2022-03-07T01:26:43.253151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feat_importance_df_lgb=feat_importance_df_lgb.sort_values(by='importance',ascending=True)\n# feat_importance_df_xgb=feat_importance_df_xgb.sort_values(by='importance',ascending=True)\n# idx1 = feat_importance_df_lgb[:100]['var'].to_arrow().to_pylist()\n# idx2 = feat_importance_df_xgb[:100]['var'].to_arrow().to_pylist()\n# x_train = x_train[list(set(idx1).union(set(idx2)))]\n# x_test = x_test[list(set(idx1).union(set(idx2)))]\n# del feat_importance_df_lgb,feat_importance_df_xgb\n# gc.collect()\n\n# list(set(idx1).union(set(idx2)))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T05:06:43.983212Z","iopub.execute_input":"2022-03-04T05:06:43.984083Z","iopub.status.idle":"2022-03-04T05:06:43.989094Z","shell.execute_reply.started":"2022-03-04T05:06:43.984041Z","shell.execute_reply":"2022-03-04T05:06:43.987819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cuml\n# lr_LinearRegressor = LinearRegressor()\n# lr_oof_train, lr_oof_test,_ = lr_LinearRegressor.get_oof(x_train, y_train, x_test)\n# del lr_LinearRegressor\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T05:06:43.991077Z","iopub.execute_input":"2022-03-04T05:06:43.992112Z","iopub.status.idle":"2022-03-04T05:06:44.002537Z","shell.execute_reply.started":"2022-03-04T05:06:43.992064Z","shell.execute_reply":"2022-03-04T05:06:44.001379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cuml\n# rf_RandomForest = RandomForest()\n# rf_oof_train, rf_oof_test,_ = rf_RandomForest.get_oof(x_train.astype('float32'), y_train, x_test.astype('float32'))\n# del rf_RandomForest\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T05:06:44.004763Z","iopub.execute_input":"2022-03-04T05:06:44.005261Z","iopub.status.idle":"2022-03-04T05:06:44.013122Z","shell.execute_reply.started":"2022-03-04T05:06:44.005213Z","shell.execute_reply":"2022-03-04T05:06:44.012336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_train = [xgb_oof_train, lgb_oof_train] \ninput_test = [xgb_oof_test, lgb_oof_test]\n\nstacked_train = np.concatenate([f.reshape(-1, 1) for f in input_train], axis=1)\nstacked_test = np.concatenate([f.reshape(-1, 1) for f in input_test], axis=1)\ndel xgb_oof_train, lgb_oof_train, xgb_oof_test, lgb_oof_test\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T05:06:44.01575Z","iopub.execute_input":"2022-03-04T05:06:44.016081Z","iopub.status.idle":"2022-03-04T05:06:44.230664Z","shell.execute_reply.started":"2022-03-04T05:06:44.016046Z","shell.execute_reply":"2022-03-04T05:06:44.229736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = LinearRegression()\nfinal_model.fit(stacked_train, y_train)\ntest_prediction = final_model.predict(stacked_test)\n\n# test\n\nplt.figure(figsize=(20, 7), facecolor='#f6f5f5')\nplt.scatter(test_prediction-y_test, np.arange(len(y_test)))\nplt.show()\n\njoblib.dump(final_model, 'xgb—lgb-linearReges.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-03-04T05:06:44.233597Z","iopub.execute_input":"2022-03-04T05:06:44.233924Z","iopub.status.idle":"2022-03-04T05:06:50.677047Z","shell.execute_reply.started":"2022-03-04T05:06:44.233886Z","shell.execute_reply":"2022-03-04T05:06:50.67638Z"},"trusted":true},"execution_count":null,"outputs":[]}]}