{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ubiquant market prediction - EDA\n\n<img src=\"https://cdn.pixabay.com/photo/2017/08/30/07/56/clock-2696234_1280.jpg\" width=\"800px\">","metadata":{}},{"cell_type":"markdown","source":"# Table of contents\n\n- [Motivation](#motivation)\n- [Loading packages and data](#packages)\n- [Initial explorations (to be continued)](#initial_eda)\n- [Feature generation (to be continued)](#new_features)\n    - [Operations to perform](#operations)\n    - [The feature selector](#selector)\n    - [Model structure](#model)\n    - [Go, honey, go!](#search)","metadata":{}},{"cell_type":"markdown","source":"# Motivation <a class=\"anchor\" id=\"motivation\"></a>\n\nOur goal is to predict a metric (not known by us but related to the return rate) that should help traders to make a trading decision. To solve this task we are given:\n\n* 300 anonymized features\n* different investments. They are not the same all the time, there can be different investment ids in the test data than in train [(look here)](https://www.kaggle.com/c/ubiquant-market-prediction/discussion/301693).\n* time_ids per investment\n* (and row ids)\n\nThe features in the training set were derived using real historic data. Furthermore the description says that: \n\n**the final private leaderboard will be determined using data gathered after the training period closes, which means that the public and private leaderboards will have zero overlap**\n\nWhat exactly does this mean? Is the test data gathered in temporal order right after the training period? Is it subsequent? Or could it also mean that the test data was gathered later after some time has passed by? For me this is not really clear...","metadata":{}},{"cell_type":"markdown","source":"# Loading packages and data <a class=\"anchor\" id=\"packages\"></a>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.linear_model import Ridge\nfrom scipy.stats import pearsonr\n\nfrom kaggle_secrets import UserSecretsClient\n\nimport wandb\n# always wanted to try it out - now it's time to do so! :-) \n\nimport seaborn as sns\nsns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-29T05:09:35.177634Z","iopub.execute_input":"2022-01-29T05:09:35.17844Z","iopub.status.idle":"2022-01-29T05:09:37.223158Z","shell.execute_reply.started":"2022-01-29T05:09:35.178377Z","shell.execute_reply":"2022-01-29T05:09:37.221987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_wandb=False\nif use_wandb:\n    user_secrets = UserSecretsClient()\n    secret_value_wb = user_secrets.get_secret(\"wandb\")\n    ! wandb login $secret_value_wb\n    wandb.init(project=\"ubiquant\", name=\"starter\")","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-29T05:09:41.732141Z","iopub.execute_input":"2022-01-29T05:09:41.732469Z","iopub.status.idle":"2022-01-29T05:09:41.738118Z","shell.execute_reply.started":"2022-01-29T05:09:41.732423Z","shell.execute_reply":"2022-01-29T05:09:41.737407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\ntrain.head()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-29T05:09:47.769763Z","iopub.execute_input":"2022-01-29T05:09:47.770355Z","iopub.status.idle":"2022-01-29T05:10:24.475967Z","shell.execute_reply.started":"2022-01-29T05:09:47.770313Z","shell.execute_reply":"2022-01-29T05:10:24.475312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_parquet('../input/ubiquant-parquet/example_test.parquet')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:10:24.477521Z","iopub.execute_input":"2022-01-29T05:10:24.477956Z","iopub.status.idle":"2022-01-29T05:10:24.540318Z","shell.execute_reply.started":"2022-01-29T05:10:24.477925Z","shell.execute_reply":"2022-01-29T05:10:24.539269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Analysis <a class=\"anchor\" id=\"exploration\"></a>","metadata":{}},{"cell_type":"markdown","source":"# Initial explorations <a class=\"anchor\" id=\"initial_eda\"></a>","metadata":{}},{"cell_type":"markdown","source":"How much samples can be found?","metadata":{}},{"cell_type":"code","source":"train.shape[0]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-29T05:10:24.541897Z","iopub.execute_input":"2022-01-29T05:10:24.542208Z","iopub.status.idle":"2022-01-29T05:10:24.551947Z","shell.execute_reply.started":"2022-01-29T05:10:24.542167Z","shell.execute_reply":"2022-01-29T05:10:24.551022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How many investments are present?","metadata":{}},{"cell_type":"code","source":"train.investment_id.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:10:45.216755Z","iopub.execute_input":"2022-01-29T05:10:45.217099Z","iopub.status.idle":"2022-01-29T05:10:45.244691Z","shell.execute_reply.started":"2022-01-29T05:10:45.21706Z","shell.execute_reply":"2022-01-29T05:10:45.243952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What's the maximum time_id per investment id?","metadata":{}},{"cell_type":"code","source":"train.groupby(\"investment_id\").time_id.max().value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:10:52.078059Z","iopub.execute_input":"2022-01-29T05:10:52.079091Z","iopub.status.idle":"2022-01-29T05:10:52.246183Z","shell.execute_reply.started":"2022-01-29T05:10:52.079042Z","shell.execute_reply":"2022-01-29T05:10:52.245201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's interesting! Most of the ids have a max time_id of 1219. But there are a few ids that differ from them. ","metadata":{}},{"cell_type":"code","source":"train.groupby(\"investment_id\").time_id.max().value_counts().index.max()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:10:58.834163Z","iopub.execute_input":"2022-01-29T05:10:58.83448Z","iopub.status.idle":"2022-01-29T05:10:58.99344Z","shell.execute_reply.started":"2022-01-29T05:10:58.834429Z","shell.execute_reply":"2022-01-29T05:10:58.992654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"investment_id\").time_id.max().value_counts().index.min()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:11:01.698715Z","iopub.execute_input":"2022-01-29T05:11:01.699024Z","iopub.status.idle":"2022-01-29T05:11:01.858416Z","shell.execute_reply.started":"2022-01-29T05:11:01.698994Z","shell.execute_reply":"2022-01-29T05:11:01.857518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no ids with an id > 1219 or < 62. We should better look at a few examples. By the way - how many outlier samples do we have?","metadata":{}},{"cell_type":"code","source":"selection = train.groupby(\"investment_id\").time_id.max()\noutlier_inv_ids = selection[selection != 1219].index.values\nlen(outlier_inv_ids)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-29T05:11:08.771259Z","iopub.execute_input":"2022-01-29T05:11:08.772144Z","iopub.status.idle":"2022-01-29T05:11:08.932126Z","shell.execute_reply.started":"2022-01-29T05:11:08.772092Z","shell.execute_reply":"2022-01-29T05:11:08.931523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nfor n in range(10):\n    plt.plot(train[train.investment_id == outlier_inv_ids[n]].time_id,\n               train[train.investment_id == outlier_inv_ids[n]].target.cumsum(), '.')\n    plt.xlim([0,1220])\n    plt.title(\"Return/target cumsum for outlier investments\")\n    plt.xlabel(\"time_id\")\n    plt.ylabel(\"cumsum return\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-29T05:11:15.528628Z","iopub.execute_input":"2022-01-29T05:11:15.529527Z","iopub.status.idle":"2022-01-29T05:11:16.256681Z","shell.execute_reply.started":"2022-01-29T05:11:15.529487Z","shell.execute_reply":"2022-01-29T05:11:16.255535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n\n* We can clearly see that some investments miss parts of their timeseries or end earlier.\n* Looking back into the competition description, we find: \"The ID code for an investment. **Not all investment have data in all time IDs**.\"","metadata":{}},{"cell_type":"markdown","source":"### How many investments do we have per time id?","metadata":{}},{"cell_type":"code","source":"num_investments_per_time_id = train.groupby(\"time_id\").investment_id.nunique()\n\nplt.figure(figsize=(20,5))\nplt.plot(num_investments_per_time_id.index, num_investments_per_time_id.values, 'o', color=\"black\")\nplt.xlabel(\"time_id\")\nplt.ylabel(\"count\")\nplt.title(\"Number of unique investment_ids given time_id\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-29T05:11:23.927986Z","iopub.execute_input":"2022-01-29T05:11:23.928336Z","iopub.status.idle":"2022-01-29T05:11:24.861624Z","shell.execute_reply.started":"2022-01-29T05:11:23.928296Z","shell.execute_reply":"2022-01-29T05:11:24.859026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n\n* The number of unique investment ids seems to be roughly constant in the beginning but has an increasind trend after the crazy id 400. \n* We can see that the number of investments given the time id varies especially around the id 400.\n\nWhat does that mean...? The description says...\n\n>  The time IDs are in order, but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.\n\nHmm... what?!\n\nDoes it mean given a single investment the time id is in order but the time between ids can vary (also for this single investment)? If so, do we have different \"temporal spaces\" per investment? Then time_id 12 for example would be a different time for each investment? Or does it mean that this id 12 is the same real time for all investment ids? ","metadata":{}},{"cell_type":"markdown","source":"### How is the target distributed?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2,2,figsize=(20,10))\nsns.distplot(train.target.values, color=\"red\", ax=ax[0,0])\nax[0,0].set_title(\"Target distribution\")\nn = 0\nselected_id = train[train.target > 8].investment_id.values[n]\nselection = train[train.investment_id == selected_id][[\"time_id\", \"target\"]]\nax[0,1].set_title(\"Target distribution of investment id {}\".format(selected_id))\nsns.distplot(selection.target.values, ax=ax[0,1], color=\"seagreen\")\nax[1,0].plot(selection.time_id.values, selection.target.values)\nax[1,0].set_title(\"Target timeseries of investment id {}\".format(selected_id))\nax[1,1].plot(selection.time_id.values, selection.target.cumsum().values)\nax[1,1].set_title(\"Target timeseries cumsum of investment id {}\".format(selected_id))","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:11:31.621761Z","iopub.execute_input":"2022-01-29T05:11:31.622301Z","iopub.status.idle":"2022-01-29T05:11:44.125186Z","shell.execute_reply.started":"2022-01-29T05:11:31.622245Z","shell.execute_reply":"2022-01-29T05:11:44.124409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n\n* Looks like Student's t-distribution (like normal with heavy tails).\n* Browsing through different outlier series the heavy tails belong to steep changes given our temporal interval. Looking at the cumsum we can see that it does not necessarily mean that this is a strange behaviour as we could also have strong changes over a small number of time_id steps. ","metadata":{}},{"cell_type":"markdown","source":"# How are features (or the target) distributed over time?","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model structure <a class=\"anchor\" id=\"model\"></a>\n\nOk, this problem has some difficulties:\n\n* We have investment_ids that can be present in train & test or only in train or only in test. \n* We can have some kind of measurement gaps where values are missing.\n* Timeseries can have different lengths in total. \n* The time inverals can vary.\n\n","metadata":{}},{"cell_type":"markdown","source":"Before adding more and more content about feature engineering, I like to build a loop that will allow to add previous features.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:11:51.986173Z","iopub.execute_input":"2022-01-29T05:11:51.987142Z","iopub.status.idle":"2022-01-29T05:11:52.015596Z","shell.execute_reply.started":"2022-01-29T05:11:51.987092Z","shell.execute_reply":"2022-01-29T05:11:52.014248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selection = [\"time_id\", \"investment_id\"]\nN=100\nmy_features = [\"f_{}\".format(n) for n in range(N)]\nselection.extend(my_features)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:11:58.63788Z","iopub.execute_input":"2022-01-29T05:11:58.638196Z","iopub.status.idle":"2022-01-29T05:11:58.645082Z","shell.execute_reply.started":"2022-01-29T05:11:58.638164Z","shell.execute_reply":"2022-01-29T05:11:58.643328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[selection].copy()\nfor f in my_features:\n    X[f + \"_shift1\"] = X.groupby(\"investment_id\")[f].shift(1)\n\n    X[f + \"_diff\"] = X[f] - X[f+\"_shift1\"]\n    X[f + \"_diff\"] = X[f+\"_diff\"].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:12:01.401727Z","iopub.execute_input":"2022-01-29T05:12:01.40264Z","iopub.status.idle":"2022-01-29T05:12:22.573165Z","shell.execute_reply.started":"2022-01-29T05:12:01.402577Z","shell.execute_reply":"2022-01-29T05:12:22.572046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [\"f_{}_diff\".format(n) for n in range(N)]\nfeatures.extend([\"f_{}\".format(n) for n in range(N)])\nprint(len(features))","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:12:22.574754Z","iopub.execute_input":"2022-01-29T05:12:22.575022Z","iopub.status.idle":"2022-01-29T05:12:22.581681Z","shell.execute_reply.started":"2022-01-29T05:12:22.574986Z","shell.execute_reply":"2022-01-29T05:12:22.580376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = Ridge()\nx_train = X[features]\ny_train = train.target\nlm.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:12:28.450412Z","iopub.execute_input":"2022-01-29T05:12:28.450731Z","iopub.status.idle":"2022-01-29T05:12:43.170955Z","shell.execute_reply.started":"2022-01-29T05:12:28.450699Z","shell.execute_reply":"2022-01-29T05:12:43.169603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\n\nprevious_test_df = train[train.time_id == train.time_id.max()]\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    for f in my_features:\n        test_df.loc[:, f+\"_shift1\"] = np.nan\n        already_known = previous_test_df[previous_test_df.investment_id.isin(test_df.investment_id)]\n        test_df.loc[test_df.investment_id.isin(already_known.investment_id), f+\"_shift1\"] = already_known[f]\n        test_df.loc[:, f+\"_diff\"] = test_df[f] - test_df[f+\"_shift1\"]\n        test_df.loc[:, f+\"_diff\"] = test_df.loc[:, f+\"_diff\"].fillna(0)\n    \n    pred = lm.predict(test_df[features])\n    sample_prediction_df['target'] = pred  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions\n    previous_test_df = test_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T05:12:43.174355Z","iopub.execute_input":"2022-01-29T05:12:43.175771Z","iopub.status.idle":"2022-01-29T05:12:43.32566Z","shell.execute_reply.started":"2022-01-29T05:12:43.175638Z","shell.execute_reply":"2022-01-29T05:12:43.324396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The loop seems to work. Next topic - feature generation.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}