{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Begin","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tqdm.notebook as tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport time\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:12:05.305076Z","iopub.execute_input":"2022-01-21T14:12:05.30606Z","iopub.status.idle":"2022-01-21T14:12:06.560781Z","shell.execute_reply.started":"2022-01-21T14:12:05.305932Z","shell.execute_reply":"2022-01-21T14:12:06.559894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"markdown","source":"First, declare the column dtypes:","metadata":{}},{"cell_type":"code","source":"col_dtypes = {\n    'row_id' : np.object,\n    'time_id' : np.uint16,\n    'investment_id' : np.uint16,\n    'target' : np.float64,\n}\nfor i in range(300):\n    col_dtypes[f\"f_{i}\"] = np.float32","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:12:06.562609Z","iopub.execute_input":"2022-01-21T14:12:06.56284Z","iopub.status.idle":"2022-01-21T14:12:06.568167Z","shell.execute_reply.started":"2022-01-21T14:12:06.562811Z","shell.execute_reply":"2022-01-21T14:12:06.567251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load full train data using declared dtypes to save space.","metadata":{}},{"cell_type":"code","source":"%%time\ntrain = pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", dtype=col_dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T14:12:06.56934Z","iopub.execute_input":"2022-01-21T14:12:06.56957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batching\nBatches will be generated for each `time_id`. Missing parts of the data (each `investment_id` missing) will be filled with zeros.","metadata":{}},{"cell_type":"code","source":"pardir = '/kaggle/working/by_time_id'\nos.mkdir(pardir)\n\nkeep_cols = ['investment_id', 'target'] + [f\"f_{i}\" for i in range(300)]\n\nn_inv_id = train.investment_id.max()\nfiller = range(1, n_inv_id+1)\n\nfor group in tqdm.tqdm(train.groupby(by='time_id'), desc='Grouping by time_id'):\n    df = group[1]\n    df['sort'] = df['investment_id']\n    df = df.set_index('sort').reindex(filler).fillna(\n        0).reset_index()[keep_cols]\n    df.to_parquet(\n        pardir+f\"/train_data_time_id_{group[0]}.parquet\"\n    )","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test reading time of parquet batch and saving metadata of batch","metadata":{}},{"cell_type":"code","source":"metadata = {'time_id':[], 'paths':[]}\nfor i in tqdm.tqdm(train.time_id.unique()):\n    try:\n        temp = pd.read_parquet(pardir+f\"/train_data_time_id_{i}.parquet\")\n        metadata['time_id'].append(i)\n        metadata['paths'].append(f\"train_data_time_id_{i}.parquet\")\n    except:\n        print(\"Missing!\")\n        \nmetadata = pd.DataFrame(metadata)\nmetadata.to_csv(\"train_time_id_meta.csv\", index=False)\nmetadata","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}