{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The goal of this notebook is to provide a lightweight and fast starting point for training MLP models. It uses a very simple model and is optimized for speed so the whole thing including dataloading and training takes around a minute and half to run on kaggle. Still using the same parameters I got a respectable single model score: `0.143` when trained on the whole dataset.\n\nThings to note:\n- All the data is preloaded into GPU and then directly passed to model without any copying. \n- I'm using a custom version of pearson coefficient for loss.\n- There is no regularization, just a small model and small number of epochs to prevent overfitting.\n- A custom callback allows me to track the competition metric while training.\n- A flat constant learning rate, I found that LR scheduling didn't help with just five epochs.\n- A large batch size makes training fast.","metadata":{}},{"cell_type":"code","source":"from fastai.tabular.all import *","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:01:56.751321Z","iopub.execute_input":"2022-01-30T06:01:56.751637Z","iopub.status.idle":"2022-01-30T06:01:59.159818Z","shell.execute_reply.started":"2022-01-30T06:01:56.751558Z","shell.execute_reply":"2022-01-30T06:01:59.159114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the data from feather and stick on GPU","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:50:54.828341Z","iopub.execute_input":"2022-01-27T17:50:54.828714Z","iopub.status.idle":"2022-01-27T17:50:54.833614Z","shell.execute_reply.started":"2022-01-27T17:50:54.828674Z","shell.execute_reply":"2022-01-27T17:50:54.83258Z"}}},{"cell_type":"code","source":"%%time\nSPLIT_IDX = 2493988 # train/val split at 80% of time_ids\ndata_df = pd.read_feather('../input/ubiquant-trainfeather-32-bit/train32.feather')\nval_df = data_df.iloc[SPLIT_IDX:].copy()\n\nftrs = [f'f_{i}' for i in range(300)]\nfeature_tensor = torch.tensor(data_df[ftrs].to_numpy()).cuda()\ntarget_tensor = torch.tensor(data_df.target.to_numpy()).cuda()\n\ndel data_df","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:01:59.161398Z","iopub.execute_input":"2022-01-30T06:01:59.161631Z","iopub.status.idle":"2022-01-30T06:02:44.619331Z","shell.execute_reply.started":"2022-01-30T06:01:59.161595Z","shell.execute_reply":"2022-01-30T06:02:44.617646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Barebone lightweight dataloading","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:50:54.828341Z","iopub.execute_input":"2022-01-27T17:50:54.828714Z","iopub.status.idle":"2022-01-27T17:50:54.833614Z","shell.execute_reply.started":"2022-01-27T17:50:54.828674Z","shell.execute_reply":"2022-01-27T17:50:54.83258Z"}}},{"cell_type":"code","source":"class UbiquantDataset:\n    def __init__(self, feature_tensor, targets):\n        store_attr()\n        self.n_inp = 2\n    def __getitem__(self, idx):\n        return torch.empty(0),self.feature_tensor[idx], self.targets[idx, None]\n    \n    def __len__(self):\n        return len(self.feature_tensor)\n    \nclass UbiDL(DataLoader):\n    def __iter__(self):\n        if self.shuffle:\n            self.__idxs = torch.tensor(range(0,self.n))\n        else:\n            self.__idxs = torch.tensor(range(0,self.n))\n        for batch_start in range(0, self.n, self.bs):\n            if batch_start + self.bs > self.n and self.drop_last:\n                return \n            indices = self.__idxs[batch_start:batch_start+self.bs]\n            yield self.dataset[indices]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:02:44.620923Z","iopub.execute_input":"2022-01-30T06:02:44.621188Z","iopub.status.idle":"2022-01-30T06:02:44.630265Z","shell.execute_reply.started":"2022-01-30T06:02:44.621153Z","shell.execute_reply":"2022-01-30T06:02:44.629263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### A custom metric and loss function for training","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:50:54.828341Z","iopub.execute_input":"2022-01-27T17:50:54.828714Z","iopub.status.idle":"2022-01-27T17:50:54.833614Z","shell.execute_reply.started":"2022-01-27T17:50:54.828674Z","shell.execute_reply":"2022-01-27T17:50:54.83258Z"}}},{"cell_type":"code","source":"def pearson_coef(data):\n    return data.corr()['target']['preds']\n\nclass CompMetric(AccumMetric):\n    def __init__(self, val_df):\n        super().__init__(None)\n        self.val_df = val_df\n        \n    @property\n    def name(self):\n        return 'Pears'\n        \n    @property\n    def value(self):\n        preds = torch.cat(self.preds)\n        val_df['preds'] = preds.cpu().numpy()\n        return np.mean(self.val_df[['time_id', 'target', 'preds']].groupby('time_id').apply(pearson_coef))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:02:44.632569Z","iopub.execute_input":"2022-01-30T06:02:44.63311Z","iopub.status.idle":"2022-01-30T06:02:44.643135Z","shell.execute_reply.started":"2022-01-30T06:02:44.633075Z","shell.execute_reply":"2022-01-30T06:02:44.642279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pearson_loss(x, y):\n    xd = x - x.mean()\n    yd = y - y.mean()\n    nom = (xd*yd).sum()\n    denom = ((xd**2).sum() * (yd**2).sum()).sqrt()\n    return 1 - nom / denom","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:02:44.644448Z","iopub.execute_input":"2022-01-30T06:02:44.644737Z","iopub.status.idle":"2022-01-30T06:02:44.654034Z","shell.execute_reply.started":"2022-01-30T06:02:44.644702Z","shell.execute_reply":"2022-01-30T06:02:44.653075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use fast.ai Learner for trainig","metadata":{}},{"cell_type":"code","source":"ds_train = UbiquantDataset(feature_tensor[:SPLIT_IDX], target_tensor[:SPLIT_IDX])\nds_val = UbiquantDataset(feature_tensor[SPLIT_IDX:], target_tensor[SPLIT_IDX:])\n\ndls = DataLoaders.from_dsets(ds_train, ds_val , bs = 4096,dl_type=UbiDL, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:02:44.656226Z","iopub.execute_input":"2022-01-30T06:02:44.656775Z","iopub.status.idle":"2022-01-30T06:02:44.672723Z","shell.execute_reply.started":"2022-01-30T06:02:44.656739Z","shell.execute_reply":"2022-01-30T06:02:44.671889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TabularModel(emb_szs={}, n_cont=300, out_sz=1, layers = [128,64, 32,16]).cuda()\n\nlearn = Learner(dls, model, loss_func=pearson_loss, metrics = CompMetric(val_df))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:02:44.674332Z","iopub.execute_input":"2022-01-30T06:02:44.674867Z","iopub.status.idle":"2022-01-30T06:02:44.712963Z","shell.execute_reply.started":"2022-01-30T06:02:44.674831Z","shell.execute_reply":"2022-01-30T06:02:44.71229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlearn.fit(5, 1e-3)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:02:44.714193Z","iopub.execute_input":"2022-01-30T06:02:44.714632Z","iopub.status.idle":"2022-01-30T06:03:09.314503Z","shell.execute_reply.started":"2022-01-30T06:02:44.714598Z","shell.execute_reply":"2022-01-30T06:03:09.313669Z"},"trusted":true},"execution_count":null,"outputs":[]}]}