{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Baseline for Ubiquant Market Prediction using ANN","metadata":{}},{"cell_type":"markdown","source":"**Thanks to notebook contributors for make baseline for my notebook**\n- https://www.kaggle.com/code/sohier/competition-api-detailed-introduction/notebook\n- https://www.kaggle.com/code/pythonash/end-to-end-simple-and-powerful-dnn-with-leakyrelu\n- https://www.kaggle.com/code/robikscube/fast-data-loading-and-low-mem-with-parquet-files","metadata":{}},{"cell_type":"markdown","source":"First import libraries and dataset.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow.keras as keras\nimport tensorflow as tf\nimport cudf\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\ndf = df.astype(\"float16\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess dataset\n\nBecause of it's baseline I use only f_n for features for X_train.","metadata":{}},{"cell_type":"code","source":"index_col = df.drop([\"row_id\", \"time_id\", \"target\", \"investment_id\"], axis=1).columns\nX_train = df[index_col]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = df[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T06:16:49.500547Z","iopub.execute_input":"2022-04-09T06:16:49.500814Z","iopub.status.idle":"2022-04-09T06:16:49.504422Z","shell.execute_reply.started":"2022-04-09T06:16:49.500785Z","shell.execute_reply":"2022-04-09T06:16:49.50376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train, X_test, y_test = X_train[0:2122479], y_train[0:2122479], X_train[2122479:], y_train[2122479:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making model\n\nI make simple model using Dense layer and BatchNormalizaion without hyper parameter tuning.","metadata":{}},{"cell_type":"code","source":"es = keras.callbacks.EarlyStopping(monitor=\"val_mse\", patience=4, mode=\"min\")\nmc = keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor=\"val_mse\", save_best_only=True, mode=\"min\", verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Input = keras.layers.Input(shape=X_train.shape[1])\nx = keras.layers.Dense(128, activation=\"relu\")(Input)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(64, activation=\"relu\")(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(32, activation=\"relu\")(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(16, activation=\"relu\")(x)\nx = x = keras.layers.BatchNormalization()(x)\nOutput = keras.layers.Dense(1, activation=\"linear\")(x)\n\nmodel = keras.models.Model(inputs = Input, outputs = Output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\nmodel.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[es, mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"import ubiquant\nmodel = tf.keras.models.load_model('best_model.h5')\nenv = ubiquant.make_env()   \niter_test = env.iter_test()    \nfor (test_df, sample_prediction_df) in iter_test:\n    sample_prediction_df[\"target\"] = model.predict(test_df[index_col])\n    env.predict(sample_prediction_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}