{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-11T04:08:52.907147Z","iopub.execute_input":"2022-04-11T04:08:52.908113Z","iopub.status.idle":"2022-04-11T04:08:54.368107Z","shell.execute_reply.started":"2022-04-11T04:08:52.907914Z","shell.execute_reply":"2022-04-11T04:08:54.367151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = (pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\n         .sort_values(['time_id', 'investment_id'])\n         .drop(columns=['row_id'])\n         .query('time_id > 599')\n         .reset_index(drop=True));\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:09:03.883152Z","iopub.execute_input":"2022-04-11T04:09:03.883864Z","iopub.status.idle":"2022-04-11T04:09:48.625534Z","shell.execute_reply.started":"2022-04-11T04:09:03.883759Z","shell.execute_reply":"2022-04-11T04:09:48.624568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(['time_id'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:09:54.057124Z","iopub.execute_input":"2022-04-11T04:09:54.057473Z","iopub.status.idle":"2022-04-11T04:09:54.784778Z","shell.execute_reply.started":"2022-04-11T04:09:54.057436Z","shell.execute_reply":"2022-04-11T04:09:54.783979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components='mle')\nprincipalComponents = pca.fit_transform(train_df.loc[:,train_df.columns!='target'])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:10:00.419919Z","iopub.execute_input":"2022-04-11T04:10:00.420571Z","iopub.status.idle":"2022-04-11T04:10:56.738962Z","shell.execute_reply.started":"2022-04-11T04:10:00.420532Z","shell.execute_reply":"2022-04-11T04:10:56.737798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"principalDf = pd.DataFrame(data = principalComponents)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:11:01.797015Z","iopub.execute_input":"2022-04-11T04:11:01.797444Z","iopub.status.idle":"2022-04-11T04:11:01.804006Z","shell.execute_reply.started":"2022-04-11T04:11:01.797403Z","shell.execute_reply":"2022-04-11T04:11:01.803003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# define data\nscaler = StandardScaler()\n# transform data\nprincipalDf = scaler.fit_transform(principalDf)\nprincipalDf = pd.DataFrame(data = principalDf)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:11:08.270388Z","iopub.execute_input":"2022-04-11T04:11:08.270949Z","iopub.status.idle":"2022-04-11T04:11:16.190878Z","shell.execute_reply.started":"2022-04-11T04:11:08.270893Z","shell.execute_reply":"2022-04-11T04:11:16.189882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=train_df['target']\ndel(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:11:16.192829Z","iopub.execute_input":"2022-04-11T04:11:16.19312Z","iopub.status.idle":"2022-04-11T04:11:16.199442Z","shell.execute_reply.started":"2022-04-11T04:11:16.193084Z","shell.execute_reply":"2022-04-11T04:11:16.19776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost\nfrom xgboost import XGBRegressor\nmodel = XGBRegressor()\nmodel.fit(principalDf,y)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:11:38.169765Z","iopub.execute_input":"2022-04-11T04:11:38.170337Z","iopub.status.idle":"2022-04-11T06:29:20.099505Z","shell.execute_reply.started":"2022-04-11T04:11:38.170294Z","shell.execute_reply":"2022-04-11T06:29:20.097345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#principalComponentstest = pca.fit_transform(test_df)\n#principalDfTest = pd.DataFrame(data = principalComponentstest)\n#principalDfTest = scaler.fit_transform(principalDfTest)\n#prediction=model.predict(principalDfTest)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save_model('./model_pca')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_df(df):\n    principalComponentstest = pca.transform(df)\n    principalDfTest = pd.DataFrame(data = principalComponentstest)\n    principalDfTest = scaler.transform(principalDfTest)\n    principalDfTest=pd.DataFrame(data = principalDfTest)\n    return principalDfTest\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:55:25.699572Z","iopub.execute_input":"2022-04-11T06:55:25.701972Z","iopub.status.idle":"2022-04-11T06:55:25.720608Z","shell.execute_reply.started":"2022-04-11T06:55:25.701803Z","shell.execute_reply":"2022-04-11T06:55:25.719169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment  \niter_test = env.iter_test()  ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:55:44.392056Z","iopub.execute_input":"2022-04-11T06:55:44.392419Z","iopub.status.idle":"2022-04-11T06:55:44.439265Z","shell.execute_reply.started":"2022-04-11T06:55:44.392384Z","shell.execute_reply":"2022-04-11T06:55:44.43789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_df_reduced=reduce_df(test_df.loc[:,test_df.columns!='row_id'])\n    sample_prediction_df['target'] = model.predict(test_df_reduced)  \n    env.predict(sample_prediction_df)   ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:55:52.320909Z","iopub.execute_input":"2022-04-11T06:55:52.321736Z","iopub.status.idle":"2022-04-11T06:55:52.758277Z","shell.execute_reply.started":"2022-04-11T06:55:52.321674Z","shell.execute_reply":"2022-04-11T06:55:52.757031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv(\"./submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}