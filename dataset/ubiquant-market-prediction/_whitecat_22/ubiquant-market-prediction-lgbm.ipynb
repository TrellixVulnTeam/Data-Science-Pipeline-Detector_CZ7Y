{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nimport time\n\nimport joblib\n\nfrom sklearn.preprocessing import StandardScaler    # RobustScaler\nfrom sklearn.model_selection import KFold    # GroupKFold\n\nimport lightgbm as lgb\n\n# Warningの無効化\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n# データフレームcolumの全表示\npd.set_option(\"display.max_columns\", None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-06T01:05:55.999064Z","iopub.execute_input":"2022-02-06T01:05:55.99993Z","iopub.status.idle":"2022-02-06T01:05:58.327351Z","shell.execute_reply.started":"2022-02-06T01:05:55.999777Z","shell.execute_reply":"2022-02-06T01:05:58.326604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            #else:\n            elif str(col_type)[:5] == \"float\":\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:05:58.3289Z","iopub.execute_input":"2022-02-06T01:05:58.329084Z","iopub.status.idle":"2022-02-06T01:05:58.34199Z","shell.execute_reply.started":"2022-02-06T01:05:58.329062Z","shell.execute_reply":"2022-02-06T01:05:58.341136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data_strict(file_name=\"/kaggle/input/ubiquant-market-prediction-half-precision-pickle/train.pkl\"):\n    df = pd.read_pickle(file_name).pipe(reduce_mem_usage)\n    assert df.isnull().any().sum() == 0, \"null exists.\"\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:05:58.342973Z","iopub.execute_input":"2022-02-06T01:05:58.343141Z","iopub.status.idle":"2022-02-06T01:05:58.361313Z","shell.execute_reply.started":"2022-02-06T01:05:58.343119Z","shell.execute_reply":"2022-02-06T01:05:58.360319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.read_pickle(\"../input/ubiquant-market-prediction-half-precision-pickle/train.pkl\")\ndf_train = read_data_strict()\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:05:58.363666Z","iopub.execute_input":"2022-02-06T01:05:58.363939Z","iopub.status.idle":"2022-02-06T01:08:27.270636Z","shell.execute_reply.started":"2022-02-06T01:05:58.363911Z","shell.execute_reply":"2022-02-06T01:08:27.269707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"keys = [\"time_id\", \"investment_id\"]\nfeatures = list(df_train.filter(like=\"f_\").columns)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:08:27.271964Z","iopub.execute_input":"2022-02-06T01:08:27.272132Z","iopub.status.idle":"2022-02-06T01:08:29.185948Z","shell.execute_reply.started":"2022-02-06T01:08:27.272102Z","shell.execute_reply":"2022-02-06T01:08:29.185156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# データのスケーリング\nscaler = StandardScaler()    # RobustScaler()\ndf_train[features] = scaler.fit_transform(df_train[features])","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:08:29.187081Z","iopub.execute_input":"2022-02-06T01:08:29.187267Z","iopub.status.idle":"2022-02-06T01:09:26.337689Z","shell.execute_reply.started":"2022-02-06T01:08:29.18724Z","shell.execute_reply":"2022-02-06T01:09:26.336398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joblib.dump(scaler, \"scaler.joblib\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:09:26.339003Z","iopub.execute_input":"2022-02-06T01:09:26.339273Z","iopub.status.idle":"2022-02-06T01:09:26.347825Z","shell.execute_reply.started":"2022-02-06T01:09:26.339239Z","shell.execute_reply":"2022-02-06T01:09:26.346701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = df_train[keys + features] #.values\ntrain_y = df_train[\"target\"] #.values","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:09:26.348874Z","iopub.execute_input":"2022-02-06T01:09:26.349058Z","iopub.status.idle":"2022-02-06T01:09:27.566356Z","shell.execute_reply.started":"2022-02-06T01:09:26.349036Z","shell.execute_reply":"2022-02-06T01:09:27.565039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# time_id列のtime_idを単位として分割することにする\ntime_id = train_x[\"time_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:09:27.567811Z","iopub.execute_input":"2022-02-06T01:09:27.568052Z","iopub.status.idle":"2022-02-06T01:09:27.572544Z","shell.execute_reply.started":"2022-02-06T01:09:27.568023Z","shell.execute_reply":"2022-02-06T01:09:27.571273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n        \"learning_rate\": 0.1,\n        \"boosting_type\": \"gbdt\",\n        \"random_state\": 71,\n        \"verbosity\": -1,\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        \"extra_trees\": True,\n        \"feature_pre_filter\": False,\n        \"lambda_l1\": 6.787140466107184e-07,\n        \"lambda_l2\": 8.198566956005054,\n        \"num_leaves\": 52,\n        \"feature_fraction\": 0.4,\n        \"bagging_fraction\": 1.0,\n        \"bagging_freq\": 0,\n        \"min_child_samples\": 20,\n        \"n_estimators\": 3000,\n        \"extra_trees\": True\n}\n\nnum_round = 3000\n\nn_folds = 5\n\ncat_features = [\"investment_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:09:27.573985Z","iopub.execute_input":"2022-02-06T01:09:27.574488Z","iopub.status.idle":"2022-02-06T01:09:27.589287Z","shell.execute_reply.started":"2022-02-06T01:09:27.574369Z","shell.execute_reply":"2022-02-06T01:09:27.588443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x[\"preds\"] = 0","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:09:27.590353Z","iopub.execute_input":"2022-02-06T01:09:27.591216Z","iopub.status.idle":"2022-02-06T01:09:27.610995Z","shell.execute_reply.started":"2022-02-06T01:09:27.591151Z","shell.execute_reply":"2022-02-06T01:09:27.61029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KFoldクラスを用いて、time_id単位で分割する\nkf = KFold(n_splits = n_folds, shuffle = False, random_state = 71)\nfor fold, (tr_group_idx, va_group_idx) in enumerate(kf.split(time_id)):\n    # time_idをtrain/valid（学習に使うデータ、バリデーションデータ）に分割する\n    tr_x, tr_y = train_x.iloc[tr_group_idx], train_y.iloc[tr_group_idx]\n    va_x, va_y = train_x.iloc[va_group_idx], train_y.iloc[va_group_idx]\n    # 各レコードのtime_idがtrain/validのどちらに属しているかによって分割する\n    lgb_train = lgb.Dataset(tr_x[features], tr_y, categorical_feature = cat_features)\n    lgb_eval  = lgb.Dataset(va_x[features], va_y, categorical_feature = cat_features)\n\n    model = lgb.train(\n            params,\n            train_set = lgb_train, \n            valid_sets = [lgb_train, lgb_eval], \n            verbose_eval = 50,\n            num_boost_round = num_round,\n            early_stopping_rounds = 100,\n    )\n\n    joblib.dump(model, f\"lgbm_{fold}.pkl\")\n    \n    # 予測\n    va_pred = model.predict(va_x[features])\n    train_x.loc[va_group_idx, \"preds\"] = va_pred","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:09:27.612542Z","iopub.execute_input":"2022-02-06T01:09:27.613106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict & submit","metadata":{}},{"cell_type":"code","source":"import ubiquant","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = ubiquant.make_env()                   # initialize the environment\niter_test = env.iter_test()                 # an iterator which loops over the test set and sample submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = joblib.load(\"scaler.joblib\")\nmodels = [joblib.load(f\"lgbm_{fold}.pkl\") for fold in range(n_folds)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    #test_df[features] = scaler.fit_transform(test_df[features]) \n    test_df[features] = scaler.transform(test_df[features]) \n    final_pred = [models[fold].predict(test_df[features]) for fold in range(n_folds)]\n    sample_prediction_df[\"target\"] = np.mean(np.stack(final_pred), axis = 0)\n    env.predict(sample_prediction_df) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}