{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### As the [Competition Q&A](https://www.kaggle.com/c/ubiquant-market-prediction/discussion/301693) said:<br>\n\n```The mapping relationship between investment_id and a certain investment is fixed, but the investment_ids that appear in the train data, the public leaderboard, and the private leaderboard are not the same, some only appear in the train data, some only in public leaderboard and some only in the private leaderboard.```\n\n### the method to deal with investment_ids that only appear in test data should be considered.\n","metadata":{}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T06:23:50.888169Z","iopub.execute_input":"2022-03-16T06:23:50.889268Z","iopub.status.idle":"2022-03-16T06:23:53.303476Z","shell.execute_reply.started":"2022-03-16T06:23:50.889176Z","shell.execute_reply":"2022-03-16T06:23:53.302663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get investment_id data and train-test indexs generated by StratifiedKFold (for saving memory)","metadata":{}},{"cell_type":"code","source":"def gen_ids_and_skf_idxs():\n    train = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\n    investment_id = train[[\"investment_id\"]].astype('int64')\n    train.pop(\"investment_id\")\n    train.pop(\"time_id\")\n    train.pop(\"target\")\n    skf = StratifiedKFold(5, shuffle=True, random_state=42)\n    idxs = list(enumerate(skf.split(train, investment_id)))\n    del train\n    gc.collect()\n    return investment_id, idxs","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:23:53.308888Z","iopub.execute_input":"2022-03-16T06:23:53.309191Z","iopub.status.idle":"2022-03-16T06:23:53.317102Z","shell.execute_reply.started":"2022-03-16T06:23:53.309149Z","shell.execute_reply":"2022-03-16T06:23:53.316258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"investment_id, idxs = gen_ids_and_skf_idxs()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:23:53.318858Z","iopub.execute_input":"2022-03-16T06:23:53.319469Z","iopub.status.idle":"2022-03-16T06:24:08.671685Z","shell.execute_reply.started":"2022-03-16T06:23:53.319418Z","shell.execute_reply":"2022-03-16T06:24:08.670658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tensorflow model modified from model3 of https://www.kaggle.com/librauee/infer-dnn-model-ensemble/","metadata":{}},{"cell_type":"code","source":"class MyModel(keras.Model):\n    \n    def __init__(self, investment_id, device='gpu'):\n        super().__init__()\n    \n        investment_ids = list(np.unique(investment_id.values))\n        investment_id_size = len(investment_ids) + 1\n        \n        with tf.device(device):\n            self.id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\n\n            self.id_lookup_layer.adapt(investment_id)\n\n            self.inv_embedding = layers.Embedding(investment_id_size, 32)\n            self.inv_fc = keras.Sequential([\n                layers.Dense(64, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros'),\n                layers.Dropout(0.5),\n                layers.Dense(32, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros'),\n                layers.Dropout(0.5),\n            ])\n\n            self.fea_fc = keras.Sequential([\n                layers.Dense(256, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros'),\n                keras.layers.BatchNormalization(axis=1),\n                layers.Dropout(0.5),\n                layers.Dense(128, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros'),\n                keras.layers.BatchNormalization(axis=1),\n                layers.Dropout(0.5),\n                layers.Dense(64, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros')\n            ])\n            \n            self.fc = keras.Sequential([\n                layers.Dropout(0.5),\n                layers.Dense(128, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros', kernel_regularizer=\"l2\"),\n                layers.Dropout(0.5),\n                layers.Dense(32, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros',  kernel_regularizer=\"l2\"),\n                layers.Dropout(0.5),\n                layers.Dense(16, activation='swish', kernel_initializer='he_normal', bias_initializer='zeros', kernel_regularizer=\"l2\"),\n                layers.Dense(1)\n            ])\n    \n    def call(self, inputs):\n        inv_id, fea = inputs\n        \n        inv = self.id_lookup_layer(inv_id)\n        inv = self.inv_embedding(inv)\n        inv = self.inv_fc(inv)\n        inv = tf.squeeze(inv, axis=1)\n        \n        fea = self.fea_fc(fea)\n        \n        concat = tf.concat([inv, fea], axis=1)\n        output = self.fc(concat)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:08.676038Z","iopub.execute_input":"2022-03-16T06:24:08.676331Z","iopub.status.idle":"2022-03-16T06:24:08.693067Z","shell.execute_reply.started":"2022-03-16T06:24:08.676296Z","shell.execute_reply":"2022-03-16T06:24:08.692006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlation(x, y, axis=-2):\n    xmean = tf.reduce_mean(x, axis=axis)\n    ymean = tf.reduce_mean(y, axis=axis)\n    cossim = keras.losses.cosine_similarity(x - xmean, y - ymean, axis=axis)\n    return 1 + cossim","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:08.694426Z","iopub.execute_input":"2022-03-16T06:24:08.694659Z","iopub.status.idle":"2022-03-16T06:24:08.708848Z","shell.execute_reply.started":"2022-03-16T06:24:08.694629Z","shell.execute_reply":"2022-03-16T06:24:08.708087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make custom tf_dataset","metadata":{}},{"cell_type":"code","source":"# Let us see how layers.IntegerLookup works.\ninvestment_ids = list(np.unique(investment_id.values))\ninvestment_id_size = len(investment_ids) + 1\nid_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\nid_lookup_layer.adapt(investment_id)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:08.710135Z","iopub.execute_input":"2022-03-16T06:24:08.711062Z","iopub.status.idle":"2022-03-16T06:24:49.592724Z","shell.execute_reply.started":"2022-03-16T06:24:08.711014Z","shell.execute_reply":"2022-03-16T06:24:49.591672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The OOV investment_ids will be mapped to a constant value 0:\nfor i in range(0, 6):\n    print(f\"id {i} is in investment_id:\", i in investment_ids)\nprint(id_lookup_layer([0, 1, 2, 3, 4, 5, -1]))\n\n# id 0 is in investment_id: True\n# id 1 is in investment_id: True\n# id 2 is in investment_id: True\n# id 3 is in investment_id: True\n# id 4 is in investment_id: True\n# id 5 is in investment_id: False\n# tf.Tensor([2994 1090 1823 1344 3292    0    0], shape=(7,), dtype=int64)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.593952Z","iopub.execute_input":"2022-03-16T06:24:49.59417Z","iopub.status.idle":"2022-03-16T06:24:49.605189Z","shell.execute_reply.started":"2022-03-16T06:24:49.594143Z","shell.execute_reply":"2022-03-16T06:24:49.604274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random mask:\n# To force the inv_embedding layer to see the OOV id (0 in this case) in train stage, which may help model to learn some \"common knowledge\" of the investment_id.\n# And then when the model faces OOV investment_ids, the embedding of those ids would not be too random.\n\ndef random_mask(feas, target, ratio=0.1):\n    inv_id, fea = feas\n    mask = tf.random.uniform(tf.shape(inv_id)) < ratio\n    inv_id = tf.where(mask, tf.constant(-1, dtype=tf.int64), inv_id)\n    return (inv_id, fea), target","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.606247Z","iopub.execute_input":"2022-03-16T06:24:49.606894Z","iopub.status.idle":"2022-03-16T06:24:49.617432Z","shell.execute_reply.started":"2022-03-16T06:24:49.606846Z","shell.execute_reply":"2022-03-16T06:24:49.616453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset(feature, investment_id, y, batch_size=512, mode=\"train\"):\n    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature), y))\n    if mode == \"train\":\n        ds = ds.map(random_mask).shuffle(batch_size * 4)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.61877Z","iopub.execute_input":"2022-03-16T06:24:49.619009Z","iopub.status.idle":"2022-03-16T06:24:49.629355Z","shell.execute_reply.started":"2022-03-16T06:24:49.618982Z","shell.execute_reply":"2022-03-16T06:24:49.62849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tf_dataset(train_idx, test_idx):\n    n_features = 300\n    features = [f'f_{i}' for i in range(n_features)]\n    df = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\n    con_feas = df[features]\n    y = df['target']\n    train_dataset = make_dataset(con_feas.iloc[train_idx, :], investment_id.iloc[train_idx], y.iloc[train_idx])\n    val_dataset = make_dataset(con_feas.iloc[test_idx, :], investment_id.iloc[test_idx], y.iloc[test_idx], mode=\"valid\")\n    \n    del df, con_feas, y\n    gc.collect()\n    \n    return train_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.630654Z","iopub.execute_input":"2022-03-16T06:24:49.630891Z","iopub.status.idle":"2022-03-16T06:24:49.640755Z","shell.execute_reply.started":"2022-03-16T06:24:49.630863Z","shell.execute_reply":"2022-03-16T06:24:49.639475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A scheduler which can be used for lr decay, weight decay, temperature decay, etc..","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch, para, bound=20):\n    if epoch < bound:\n        return para\n    else:\n        return para / tf.math.exp(0.02)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.642234Z","iopub.execute_input":"2022-03-16T06:24:49.642741Z","iopub.status.idle":"2022-03-16T06:24:49.651287Z","shell.execute_reply.started":"2022-03-16T06:24:49.64269Z","shell.execute_reply":"2022-03-16T06:24:49.650473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# %%time\n# for idx, (train_idx, test_idx) in idxs:\n#     print(f\"the {idx}th fold:\")\n    \n#     print(\"train_idx and test_idx:\")\n#     print(train_idx, test_idx)\n    \n#     print(\"get tf_dataset...\")\n#     train_dataset, val_dataset = get_tf_dataset(train_idx, test_idx)\n\n#     print(\"get model...\")\n#     model = MyModel(investment_id=investment_id)\n#     rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n#     optimizer = optimizer=tf.optimizers.Adam(0.001)\n#     model.compile(\n#         optimizer=optimizer,\n#         loss='mse',\n#         metrics=[rmse, correlation]\n#     )\n#     model.build([(None, 1), (None, 300)])\n    \n#     lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler)\n#     checkpoint = keras.callbacks.ModelCheckpoint(f'model_{idx}/model', monitor=\"val_correlation\", save_best_only=True, save_weights_only=True)\n#     early_stop = keras.callbacks.EarlyStopping(monitor=\"val_correlation\", patience=10, mode='min')\n    \n#     print(\"start training...\")\n#     history = model.fit(train_dataset, epochs=50, validation_data=val_dataset, callbacks=[lr_scheduler, checkpoint, early_stop])\n    \n#     model.load_weights(f\"model_{idx}/model\")\n#     for metric in [\"rmse\", \"correlation\"]:\n#         pd.DataFrame(history.history, columns=[metric, f\"val_{metric}\"]).plot()\n#         plt.title(metric.upper())\n#         plt.show()\n    \n#     del train_dataset, val_dataset, model, rmse, optimizer, checkpoint, early_stop, history\n#     gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.65264Z","iopub.execute_input":"2022-03-16T06:24:49.652934Z","iopub.status.idle":"2022-03-16T06:24:49.661262Z","shell.execute_reply.started":"2022-03-16T06:24:49.652903Z","shell.execute_reply":"2022-03-16T06:24:49.660446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.663828Z","iopub.execute_input":"2022-03-16T06:24:49.664056Z","iopub.status.idle":"2022-03-16T06:24:49.674119Z","shell.execute_reply.started":"2022-03-16T06:24:49.664028Z","shell.execute_reply":"2022-03-16T06:24:49.673304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"model = MyModel(investment_id=investment_id, device='cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:24:49.675279Z","iopub.execute_input":"2022-03-16T06:24:49.675929Z","iopub.status.idle":"2022-03-16T06:25:30.515255Z","shell.execute_reply.started":"2022-03-16T06:24:49.675888Z","shell.execute_reply":"2022-03-16T06:25:30.514238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test(investment_id, feature):\n    return (investment_id, feature), 0\n\ndef make_test_dataset(feature, investment_id, batch_size=1024):\n    ds = tf.data.Dataset.from_tensor_slices((investment_id, feature)).map(preprocess_test).batch(batch_size)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:25:30.516568Z","iopub.execute_input":"2022-03-16T06:25:30.516816Z","iopub.status.idle":"2022-03-16T06:25:30.523188Z","shell.execute_reply.started":"2022-03-16T06:25:30.516777Z","shell.execute_reply":"2022-03-16T06:25:30.52231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(model, ds):\n    y_preds = []\n    for i in range(5):\n        # \n        model.load_weights(f\"../input/ubi-dnn-test1/model_{i}/model\")  # private models' weights saved in training cell\n        y_pred = model.predict(ds)\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:25:30.524696Z","iopub.execute_input":"2022-03-16T06:25:30.525218Z","iopub.status.idle":"2022-03-16T06:25:30.53577Z","shell.execute_reply.started":"2022-03-16T06:25:30.525182Z","shell.execute_reply":"2022-03-16T06:25:30.534862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:25:30.536768Z","iopub.execute_input":"2022-03-16T06:25:30.537615Z","iopub.status.idle":"2022-03-16T06:25:30.558835Z","shell.execute_reply.started":"2022-03-16T06:25:30.537559Z","shell.execute_reply":"2022-03-16T06:25:30.557817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\n\nfor (test_df, sample_prediction_df) in iter_test:\n    ds = make_test_dataset(test_df[features].astype('float16'), test_df[[\"investment_id\"]].astype('int64'))\n    sample_prediction_df['target'] = inference(model, ds)\n    env.predict(sample_prediction_df) \n    display(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:25:30.560226Z","iopub.execute_input":"2022-03-16T06:25:30.560708Z","iopub.status.idle":"2022-03-16T06:25:32.926327Z","shell.execute_reply.started":"2022-03-16T06:25:30.560674Z","shell.execute_reply":"2022-03-16T06:25:32.925525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modified from\nhttps://www.kaggle.com/librauee/infer-dnn-model-ensemble <br>\nhttps://www.kaggle.com/lonnieqin/ubiquant-market-prediction-with-dnn","metadata":{}}]}