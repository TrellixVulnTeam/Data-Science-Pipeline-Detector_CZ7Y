{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-20T10:15:40.416239Z","iopub.execute_input":"2022-04-20T10:15:40.41735Z","iopub.status.idle":"2022-04-20T10:15:40.468272Z","shell.execute_reply.started":"2022-04-20T10:15:40.417235Z","shell.execute_reply":"2022-04-20T10:15:40.467544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom scipy import stats \nfrom sklearn.decomposition import PCA\nfrom tqdm import notebook\nimport warnings\nwarnings.filterwarnings('ignore')   ","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:15:55.985642Z","iopub.execute_input":"2022-04-20T10:15:55.985912Z","iopub.status.idle":"2022-04-20T10:16:00.741806Z","shell.execute_reply.started":"2022-04-20T10:15:55.985882Z","shell.execute_reply":"2022-04-20T10:16:00.741102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)] \ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\nprint(train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:16:36.01773Z","iopub.execute_input":"2022-04-20T10:16:36.018464Z","iopub.status.idle":"2022-04-20T10:16:53.490665Z","shell.execute_reply.started":"2022-04-20T10:16:36.018425Z","shell.execute_reply":"2022-04-20T10:16:53.489961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"investment_id = train.pop(\"investment_id\")\ntime_id = train.pop(\"time_id\")\n\ntarget = train.pop(\"target\")\ntarget.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:17:04.792618Z","iopub.execute_input":"2022-04-20T10:17:04.792895Z","iopub.status.idle":"2022-04-20T10:17:04.821583Z","shell.execute_reply.started":"2022-04-20T10:17:04.792862Z","shell.execute_reply":"2022-04-20T10:17:04.820879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()  \nax.plot(target);  ","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:17:12.128172Z","iopub.execute_input":"2022-04-20T10:17:12.129198Z","iopub.status.idle":"2022-04-20T10:17:12.970355Z","shell.execute_reply.started":"2022-04-20T10:17:12.129147Z","shell.execute_reply":"2022-04-20T10:17:12.969686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train1 = train.iloc[:,0:100]\ntrain2 = train.iloc[:,100:200]\ntrain3 = train.iloc[:,200:300]","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:17:21.124293Z","iopub.execute_input":"2022-04-20T10:17:21.124587Z","iopub.status.idle":"2022-04-20T10:17:28.638924Z","shell.execute_reply.started":"2022-04-20T10:17:21.124554Z","shell.execute_reply":"2022-04-20T10:17:28.638152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:17:30.857192Z","iopub.execute_input":"2022-04-20T10:17:30.857434Z","iopub.status.idle":"2022-04-20T10:17:30.863264Z","shell.execute_reply.started":"2022-04-20T10:17:30.857407Z","shell.execute_reply":"2022-04-20T10:17:30.862501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train1.shape,\n      train2.shape,\n      train3.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:17:32.57628Z","iopub.execute_input":"2022-04-20T10:17:32.577056Z","iopub.status.idle":"2022-04-20T10:17:32.582572Z","shell.execute_reply.started":"2022-04-20T10:17:32.577012Z","shell.execute_reply":"2022-04-20T10:17:32.581776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 512 \nFOLD = 6\nSEED = 42\nEPOCHS = 3\n\nskfolds = StratifiedKFold(n_splits=FOLD, \n                          random_state=SEED)\n                          \nLOSS_HISTORY = [] \nTEST_LOSS_HISTORY = []\nTRAIN_LOSS = tf.keras.metrics.Mean(name='TRAIN_LOSS', dtype=tf.float32) \nTEST_LOSS = tf.keras.metrics.Mean(name='TEST_LOSS', dtype=tf.float32)    \n\nLOSS_FN = keras.losses.MeanAbsoluteError() \nOPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n\ndef ret(a):\n    return  a\n\ntf.executing_eagerly()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:18:10.346409Z","iopub.execute_input":"2022-04-20T10:18:10.346661Z","iopub.status.idle":"2022-04-20T10:18:13.525413Z","shell.execute_reply.started":"2022-04-20T10:18:10.346633Z","shell.execute_reply":"2022-04-20T10:18:13.524729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(keras.Model):\n    def __init__(self):\n        super(Model, self).__init__()\n        \n        self.inputs = tf.keras.layers.Lambda(ret, input_shape = [300], dtype=tf.float16)\n        \n        self.x1 = tf.keras.layers.Dense(256, activation = 'swish')\n        self.batch_x1 = tf.keras.layers.BatchNormalization()\n        self.x2 = tf.keras.layers.Dense(256, activation = 'swish')\n        self.batch_x2 = tf.keras.layers.BatchNormalization()\n        self.dr1 = tf.keras.layers.Dropout(0.15)\n        self.x3 = tf.keras.layers.Dense(256, activation = 'swish')\n        self.batch_x3 = tf.keras.layers.BatchNormalization()\n        self.x4 = tf.keras.layers.Dense(128, kernel_regularizer=\"l2\", activation = 'swish')\n        self.batch_x4 = tf.keras.layers.BatchNormalization()\n        self.dr2 = tf.keras.layers.Dropout(0.15)\n        self.x5 = tf.keras.layers.Dense(128, kernel_regularizer=\"l2\", activation = 'swish')\n        self.x6 = tf.keras.layers.Dense(32, activation = 'swish')\n        self.x7 = tf.keras.layers.Dense(32, activation = 'swish')\n        self.out_x = tf.keras.layers.Dense(1)\n        \n        self.b1 = tf.keras.layers.Dense(256, activation = 'relu')\n        self.batch_b1 = tf.keras.layers.BatchNormalization()\n        self.bdr1 = tf.keras.layers.Dropout(0.15)\n        self.b2 = tf.keras.layers.Dense(256, activation = 'relu')\n        self.batch_b2 = tf.keras.layers.BatchNormalization()\n        self.b3 = tf.keras.layers.Dense(256, activation = 'relu')\n        self.batch_b3 = tf.keras.layers.BatchNormalization()\n        self.b4 = tf.keras.layers.Dense(128, kernel_regularizer=\"l1\", activation = 'relu')\n        self.batch_b4 = tf.keras.layers.BatchNormalization()\n        self.b5 = tf.keras.layers.Dense(128, kernel_regularizer=\"l1\", activation = 'relu')\n        self.b6 = tf.keras.layers.Dense(32, activation = 'relu')\n        self.b7 = tf.keras.layers.Dense(32, activation = 'relu')\n        self.out_b = tf.keras.layers.Dense(1)\n        \n        self.c1 = tf.keras.layers.Dense(256, activation = 'relu')\n        self.batch_c1 = tf.keras.layers.BatchNormalization()\n        self.c2 = tf.keras.layers.Dense(256, activation = 'relu')\n        self.batch_c2 = tf.keras.layers.BatchNormalization()\n        self.cdr1 = tf.keras.layers.Dropout(0.15)\n        self.c3 = tf.keras.layers.Dense(128, kernel_regularizer=\"l2\", activation = 'elu')\n        self.batch_c3 = tf.keras.layers.BatchNormalization()\n        self.c4 = tf.keras.layers.Dense(32, activation = 'elu')\n        self.c5 = tf.keras.layers.Dense(32, activation = 'elu')\n        self.out_c = tf.keras.layers.Dense(1)\n        \n        self.out = tf.keras.layers.Average()\n\n    def call(self, input):   \n        x, b, c = input           \n        x = self.inputs(x)\n        b = self.inputs(b)\n        c = self.inputs(c)\n    \n        x = self.x1(x)\n        x = self.batch_x1(x)\n        x = self.x2(x)\n        x = self.batch_x2(x)\n        x = self.dr1(x)\n        x = self.x3(x)\n        x = self.batch_x3(x)\n        x = self.x4(x)\n        x = self.batch_x4(x)\n        x = self.dr2(x)\n        x = self.x5(x)\n        x = self.x6(x)\n        x = self.x7(x)\n        x = self.out_x(x)\n        \n        b = self.b1(b)\n        b = self.batch_b1(b)\n        b = self.bdr1(b)\n        b = self.b2(b)\n        b = self.batch_b2(b)\n        b = self.b3(b)\n        b = self.batch_b3(b)\n        b = self.b4(b)\n        b = self.batch_b4(b) \n        b = self.b5(b)\n        b = self.b6(b)\n        b = self.b7(b)\n        b = self.out_b(b)\n    \n        c = self.c1(c)\n        c = self.batch_c1(c)\n        c = self.c2(c)\n        c = self.batch_c2(c)\n        c = self.cdr1(c)\n        c = self.c3(c)\n        c = self.batch_c3(c)\n        c = self.c4(c)\n        c = self.c5(c)\n        c = self.out_c(c)\n        \n        return self.out([x,b,c])","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:25:55.656725Z","iopub.execute_input":"2022-04-20T10:25:55.65725Z","iopub.status.idle":"2022-04-20T10:25:55.682278Z","shell.execute_reply.started":"2022-04-20T10:25:55.657214Z","shell.execute_reply":"2022-04-20T10:25:55.681519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:26:01.808355Z","iopub.execute_input":"2022-04-20T10:26:01.808609Z","iopub.status.idle":"2022-04-20T10:26:01.853657Z","shell.execute_reply.started":"2022-04-20T10:26:01.808579Z","shell.execute_reply":"2022-04-20T10:26:01.853006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(investment, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(investment)\n        loss_value = LOSS_FN(labels, predictions)\n        \n    LOSS_HISTORY.append(TRAIN_LOSS(loss_value))\n    grads = tape.gradient(loss_value, model.trainable_variables)\n    OPTIMIZER.apply_gradients(zip(grads, model.trainable_variables))\n    \n    TRAIN_LOSS(loss_value)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:26:03.565611Z","iopub.execute_input":"2022-04-20T10:26:03.566002Z","iopub.status.idle":"2022-04-20T10:26:03.571425Z","shell.execute_reply.started":"2022-04-20T10:26:03.565968Z","shell.execute_reply":"2022-04-20T10:26:03.570742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef test_step(investment, labels):\n    predictions = model(investment)\n    test_loss_value = LOSS_FN(labels, predictions)\n    TEST_LOSS_HISTORY.append(TEST_LOSS(test_loss_value))\n    \n    TEST_LOSS(test_loss_value)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:26:05.581926Z","iopub.execute_input":"2022-04-20T10:26:05.582576Z","iopub.status.idle":"2022-04-20T10:26:05.586991Z","shell.execute_reply.started":"2022-04-20T10:26:05.582539Z","shell.execute_reply":"2022-04-20T10:26:05.586143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train1.shape,\n      train2.shape,\n      train3.shape,\n      investment_id.shape,\n      target.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:26:07.195502Z","iopub.execute_input":"2022-04-20T10:26:07.196073Z","iopub.status.idle":"2022-04-20T10:26:07.201482Z","shell.execute_reply.started":"2022-04-20T10:26:07.196034Z","shell.execute_reply":"2022-04-20T10:26:07.200532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for num_fold, (train_index, valid_index) in enumerate(skfolds.split(train1, investment_id)):\n    print('num_fold:', num_fold+1)\n    \n    if num_fold > 0:\n        del train_dataset\n        del test_dataset\n    \n    X_train1, X_valid1 = train1.iloc[train_index], train1.iloc[valid_index]\n    X_train2, X_valid2 = train2.iloc[train_index], train2.iloc[valid_index]\n    X_train3, X_valid3 = train3.iloc[train_index], train3.iloc[valid_index]\n\n    Y_train, Y_valid = target.iloc[train_index], target.iloc[valid_index] \n\n    train_dataset = tf.data.Dataset.from_tensor_slices(\n    ((X_train1, X_train2, X_train3), Y_train))\n    train_dataset = train_dataset.batch(BATCH)\n    \n    test_dataset = tf.data.Dataset.from_tensor_slices(\n    ((X_valid1, X_valid2, X_valid3), Y_valid))\n    test_dataset = test_dataset.batch(BATCH)\n    \n    del X_train1\n    del X_valid1\n    del X_train2\n    del X_valid2\n    del X_train3\n    del X_valid3\n    del Y_train\n    del Y_valid\n    del train_index\n    del valid_index\n    \n    for epoch in notebook.tqdm(range(EPOCHS)):\n        # set_learning_rate(num_fold, epoch)\n        TRAIN_LOSS.reset_states()\n        TEST_LOSS.reset_states()\n        \n        for (batch, (investment, labels)) in enumerate(train_dataset):\n            train_step(investment, labels)\n            \n        for (batch, (investment, labels)) in enumerate(test_dataset):\n            test_step(investment, labels)\n            \n        print(\n        f'Epoch {epoch + 1}, '\n        f'Loss: {TRAIN_LOSS.result()}, '\n        f'Test Loss: {TEST_LOSS.result()}')\n        \n    num_fold+=1\n","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:26:29.709354Z","iopub.execute_input":"2022-04-20T10:26:29.709608Z","iopub.status.idle":"2022-04-20T10:38:17.366802Z","shell.execute_reply.started":"2022-04-20T10:26:29.709577Z","shell.execute_reply":"2022-04-20T10:38:17.366121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_dataset\ndel test_dataset\ndel train1\ndel train2\ndel train3","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:39:01.378911Z","iopub.execute_input":"2022-04-20T10:39:01.379384Z","iopub.status.idle":"2022-04-20T10:39:01.446299Z","shell.execute_reply.started":"2022-04-20T10:39:01.379345Z","shell.execute_reply":"2022-04-20T10:39:01.445553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test(feature1, feature2, feature3):\n    return (feature1, feature2, feature3), 0\n\ndef make_test_dataset(feature, batch_size=512):\n    \n    feature1 = feature.iloc[:,0:100]\n    feature2 = feature.iloc[:,100:200]\n    feature3 = feature.iloc[:,200:300]\n      \n    ds = tf.data.Dataset.from_tensor_slices((feature1, feature2, feature3))\n    ds = ds.map(preprocess_test)\n    ds = ds.batch(BATCH)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:39:19.313776Z","iopub.execute_input":"2022-04-20T10:39:19.314572Z","iopub.status.idle":"2022-04-20T10:39:19.320724Z","shell.execute_reply.started":"2022-04-20T10:39:19.314531Z","shell.execute_reply":"2022-04-20T10:39:19.319889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test() \n\nfor (test_df, sample_prediction_df) in iter_test:\n    ds = make_test_dataset(test_df[features])\n    sample_prediction_df['target'] =  model.predict(ds)\n    env.predict(sample_prediction_df) ","metadata":{"execution":{"iopub.status.busy":"2022-04-20T10:39:36.666306Z","iopub.execute_input":"2022-04-20T10:39:36.666576Z","iopub.status.idle":"2022-04-20T10:39:37.294749Z","shell.execute_reply.started":"2022-04-20T10:39:36.666545Z","shell.execute_reply":"2022-04-20T10:39:37.294068Z"},"trusted":true},"execution_count":null,"outputs":[]}]}