{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-15T17:21:18.744024Z","iopub.execute_input":"2022-02-15T17:21:18.744283Z","iopub.status.idle":"2022-02-15T17:21:18.755579Z","shell.execute_reply.started":"2022-02-15T17:21:18.744254Z","shell.execute_reply":"2022-02-15T17:21:18.754752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom scipy import stats # stats.pearsonr\nfrom tqdm import notebook\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:18.758179Z","iopub.execute_input":"2022-02-15T17:21:18.758396Z","iopub.status.idle":"2022-02-15T17:21:23.48661Z","shell.execute_reply.started":"2022-02-15T17:21:18.758366Z","shell.execute_reply":"2022-02-15T17:21:23.485912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)] \ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\nprint(train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:23.487826Z","iopub.execute_input":"2022-02-15T17:21:23.488106Z","iopub.status.idle":"2022-02-15T17:21:41.364985Z","shell.execute_reply.started":"2022-02-15T17:21:23.488069Z","shell.execute_reply":"2022-02-15T17:21:41.364295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"investment_id = train.pop(\"investment_id\")\ntime_id = train.pop(\"time_id\")\n\ntarget = train.pop(\"target\")\ntarget.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:41.367091Z","iopub.execute_input":"2022-02-15T17:21:41.367796Z","iopub.status.idle":"2022-02-15T17:21:41.393821Z","shell.execute_reply.started":"2022-02-15T17:21:41.367757Z","shell.execute_reply":"2022-02-15T17:21:41.393051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()  \nax.plot(target);  ","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:41.395198Z","iopub.execute_input":"2022-02-15T17:21:41.395445Z","iopub.status.idle":"2022-02-15T17:21:42.253156Z","shell.execute_reply.started":"2022-02-15T17:21:41.395412Z","shell.execute_reply":"2022-02-15T17:21:42.252451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:42.254497Z","iopub.execute_input":"2022-02-15T17:21:42.254893Z","iopub.status.idle":"2022-02-15T17:21:42.283296Z","shell.execute_reply.started":"2022-02-15T17:21:42.254855Z","shell.execute_reply":"2022-02-15T17:21:42.282422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 512 \nFOLD = 5\nSEED = 42\nEPOCHS = 3\n\nskfolds = StratifiedKFold(n_splits=FOLD, \n                          random_state=SEED, \n                          shuffle = True)\n\nLOSS_HISTORY = [] \nTEST_LOSS_HISTORY = []\nTRAIN_LOSS = tf.keras.metrics.Mean(name='TRAIN_LOSS', dtype=tf.float32) \nTEST_LOSS = tf.keras.metrics.Mean(name='TEST_LOSS', dtype=tf.float32)    \n\nLOSS_FN = keras.losses.MeanSquaredError()\nOPTIMIZER = tf.keras.optimizers.Adam()\n\ninvestment_ids = list(investment_id.unique())\ninvestment_id_size = len(investment_ids) + 1 \n\ninvestment_id_lookup_layer = tf.keras.layers.IntegerLookup(max_tokens=investment_id_size) \ninvestment_id_lookup_layer.adapt(pd.DataFrame({\"investment_ids\":investment_ids}))\n\ndef ret(a):\n    return  a\n\ntf.executing_eagerly()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:42.284994Z","iopub.execute_input":"2022-02-15T17:21:42.285302Z","iopub.status.idle":"2022-02-15T17:21:45.810331Z","shell.execute_reply.started":"2022-02-15T17:21:42.285263Z","shell.execute_reply":"2022-02-15T17:21:45.809573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(keras.Model):\n    def __init__(self, investment_id_size, investment_id_lookup_layer):\n        super(Model, self).__init__() \n        self.investment_id_size = investment_id_size\n        self.investment_id_lookup_layer = investment_id_lookup_layer\n        \n        #self.investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n        self.investment_id_inputs = tf.keras.layers.Lambda(ret, input_shape = [1], dtype=tf.uint16)\n        self.investment_id_lookup_layer = investment_id_lookup_layer\n        self.investment_id_emb = tf.keras.layers.Embedding(investment_id_size, 32, input_length=1)\n        self.investment_id_res = tf.keras.layers.Reshape((-1, ))\n        self.investment_id_1 = tf.keras.layers.Dense(64, activation='swish')\n        self.investment_id_2 = tf.keras.layers.Dense(64, activation='swish')\n        self.investment_id_3 = tf.keras.layers.Dense(64, activation='swish')\n        \n        self.inputs = tf.keras.layers.Lambda(ret, input_shape = [300], dtype=tf.float16)\n        self.d1 = tf.keras.layers.Dense(256, activation = 'swish')\n        self.d2 = tf.keras.layers.Dense(256, activation = 'swish')\n        self.d3 = tf.keras.layers.Dense(256, activation = 'swish')\n        \n        self.conc = tf.keras.layers.Concatenate(axis=1)\n        \n        self.dd5 = tf.keras.layers.Dense(512, kernel_regularizer=\"l2\", activation = 'swish')\n        self.dd6 = tf.keras.layers.Dense(128, kernel_regularizer=\"l2\", activation = 'swish')\n        self.dd7 = tf.keras.layers.Dense(32, kernel_regularizer=\"l2\", activation = 'swish')\n        self.out = tf.keras.layers.Dense(1)\n\n    def call(self, input): # x - X_train, b - investment_id_train\n        x, b = input\n        x = self.inputs(x)\n        x = self.d1(x)\n        x = self.d2(x)\n        x = self.d3(x)\n        \n        b = self.investment_id_inputs(b)\n        b = self.investment_id_lookup_layer(b)\n        b = self.investment_id_emb(b)\n        b = self.investment_id_res(b)\n        b = self.investment_id_1(b)\n        b = self.investment_id_2(b)\n        b = self.investment_id_3(b)\n        \n        c = self.conc([x,b])\n        \n        y = self.dd5(c)\n        y = self.dd6(c)\n        y = self.dd7(c)\n        return self.out(y)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:45.811906Z","iopub.execute_input":"2022-02-15T17:21:45.812223Z","iopub.status.idle":"2022-02-15T17:21:45.828097Z","shell.execute_reply.started":"2022-02-15T17:21:45.812188Z","shell.execute_reply":"2022-02-15T17:21:45.827341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(investment_id_size, investment_id_lookup_layer)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:45.832813Z","iopub.execute_input":"2022-02-15T17:21:45.833114Z","iopub.status.idle":"2022-02-15T17:21:45.864485Z","shell.execute_reply.started":"2022-02-15T17:21:45.833082Z","shell.execute_reply":"2022-02-15T17:21:45.863863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(investment, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(investment) # investment[0] - X_train : investment[1] - investment_id_train\n        loss_value = LOSS_FN(labels, predictions)\n        #tf.keras.losses.MeanSquaredError(labels, predictions) # tf.keras.losses.MeanAbsoluteError(labels, predictions) \n        #print(loss_value)\n    \n    LOSS_HISTORY.append(TRAIN_LOSS(loss_value))\n\n    grads = tape.gradient(loss_value, model.trainable_variables)\n    OPTIMIZER.apply_gradients(zip(grads, model.trainable_variables))\n    \n    TRAIN_LOSS(loss_value)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:45.867774Z","iopub.execute_input":"2022-02-15T17:21:45.867981Z","iopub.status.idle":"2022-02-15T17:21:45.873957Z","shell.execute_reply.started":"2022-02-15T17:21:45.867956Z","shell.execute_reply":"2022-02-15T17:21:45.873063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef test_step(investment, labels):\n    predictions = model(investment)\n    test_loss_value = LOSS_FN(labels, predictions)\n    TEST_LOSS_HISTORY.append(TEST_LOSS(test_loss_value))\n    \n    TEST_LOSS(test_loss_value)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:45.875501Z","iopub.execute_input":"2022-02-15T17:21:45.876135Z","iopub.status.idle":"2022-02-15T17:21:45.882799Z","shell.execute_reply.started":"2022-02-15T17:21:45.876098Z","shell.execute_reply":"2022-02-15T17:21:45.882003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for num_fold, (train_index, valid_index) in enumerate(skfolds.split(train, investment_id)):\n    print('num_fold:', num_fold+1)\n    \n    if num_fold > 0:\n        del train_dataset\n        del test_dataset\n    '''\n    if 'train_dataset' in globals():\n        del train_dataset \n    if 'test_dataset' in globals():\n        del test_dataset \n    '''     \n    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n    Y_train, Y_valid = target.iloc[train_index], target.iloc[valid_index] \n    print(X_train.shape, Y_train.shape)\n    print(X_valid.shape, Y_valid.shape)\n    investment_id_train = investment_id[train_index]\n    investment_id_val = investment_id[valid_index]\n    print(investment_id_train.shape, investment_id_val.shape)\n   \n    train_dataset = tf.data.Dataset.from_tensor_slices(\n    ((X_train, investment_id_train), Y_train))\n    train_dataset = train_dataset.shuffle(4096).batch(BATCH)\n    \n    test_dataset = tf.data.Dataset.from_tensor_slices(\n    ((X_valid, investment_id_val), Y_valid))\n    test_dataset = test_dataset.shuffle(4096).batch(BATCH)\n    \n    del X_train\n    del Y_train\n    del X_valid\n    del Y_valid\n    del train_index\n    del valid_index\n    \n    for epoch in notebook.tqdm(range(EPOCHS)):\n        \n        TRAIN_LOSS.reset_states()\n        TEST_LOSS.reset_states()\n        \n        for (batch, (investment, labels)) in enumerate(train_dataset):\n            train_step(investment, labels)\n            \n        for (batch, (investment, labels)) in enumerate(test_dataset):\n            test_step(investment, labels)\n            \n        print(\n        f'Epoch {epoch + 1}, '\n        f'Loss: {TRAIN_LOSS.result()}, '\n        f'Test Loss: {TEST_LOSS.result()}')\n\n    num_fold+=1","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:21:45.884885Z","iopub.execute_input":"2022-02-15T17:21:45.88512Z","iopub.status.idle":"2022-02-15T17:29:48.66228Z","shell.execute_reply.started":"2022-02-15T17:21:45.885096Z","shell.execute_reply":"2022-02-15T17:29:48.661332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_dataset\ndel test_dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:29:54.069803Z","iopub.execute_input":"2022-02-15T17:29:54.0701Z","iopub.status.idle":"2022-02-15T17:29:54.14981Z","shell.execute_reply.started":"2022-02-15T17:29:54.070067Z","shell.execute_reply":"2022-02-15T17:29:54.148645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test(feature, investment_id):\n    return (feature, investment_id), 0\n\n\ndef make_test_dataset(feature, in_id,  batch_size=512):\n    ds = tf.data.Dataset.from_tensor_slices((feature, in_id))\n    ds = ds.map(preprocess_test)\n    ds = ds.batch(BATCH)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:33:47.371903Z","iopub.execute_input":"2022-02-15T17:33:47.372472Z","iopub.status.idle":"2022-02-15T17:33:47.37725Z","shell.execute_reply.started":"2022-02-15T17:33:47.372436Z","shell.execute_reply":"2022-02-15T17:33:47.376431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test() ","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:32:26.310674Z","iopub.execute_input":"2022-02-15T17:32:26.310926Z","iopub.status.idle":"2022-02-15T17:32:26.335649Z","shell.execute_reply.started":"2022-02-15T17:32:26.310899Z","shell.execute_reply":"2022-02-15T17:32:26.33493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    print(\"shape\", test_df.shape)\n    ds  = make_test_dataset(test_df[features], test_df[\"investment_id\"])\n\n    #for test_dataset in ds:\n    preds = model.predict(ds) \n    print(type(preds))\n    print(preds)\n    sample_prediction_df['target'] = preds\n    env.predict(sample_prediction_df) ","metadata":{"execution":{"iopub.status.busy":"2022-02-15T17:34:30.530595Z","iopub.execute_input":"2022-02-15T17:34:30.530845Z","iopub.status.idle":"2022-02-15T17:34:30.537108Z","shell.execute_reply.started":"2022-02-15T17:34:30.530818Z","shell.execute_reply":"2022-02-15T17:34:30.53598Z"},"trusted":true},"execution_count":null,"outputs":[]}]}