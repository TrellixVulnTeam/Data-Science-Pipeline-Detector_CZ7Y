{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-13T19:34:19.989848Z","iopub.execute_input":"2022-03-13T19:34:19.990509Z","iopub.status.idle":"2022-03-13T19:34:21.449157Z","shell.execute_reply.started":"2022-03-13T19:34:19.990446Z","shell.execute_reply":"2022-03-13T19:34:21.448422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    is_training = False\n    tf_record_dataset_path = \"../input/ump-combinatorialpurgedgroupkfold-tf-record/\"\n    output_dataset_path = \"../input/ubiquant-market-prediction-with-dnn-output/\"\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T19:26:15.279409Z","iopub.execute_input":"2022-03-13T19:26:15.279968Z","iopub.status.idle":"2022-03-13T19:26:15.285031Z","shell.execute_reply.started":"2022-03-13T19:26:15.279878Z","shell.execute_reply":"2022-03-13T19:26:15.284082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert tfrecords to npy files","metadata":{}},{"cell_type":"code","source":"def decode_function(record_bytes):\n    return tf.io.parse_single_example(\n      # Data\n      record_bytes,\n      # Schema\n      {\n          \"features\": tf.io.FixedLenFeature([300], dtype=tf.float32),\n          \"time_id\": tf.io.FixedLenFeature([], dtype=tf.int64),\n          \"investment_id\": tf.io.FixedLenFeature([], dtype=tf.int64),\n          \"target\": tf.io.FixedLenFeature([], dtype=tf.float32)\n      }\n    )\ndef preprocess(item):\n    return (\n        tf.expand_dims(tf.cast(item[\"features\"], dtype=tf.float16), -1), \n        tf.cast(item[\"target\"], dtype=tf.float32), \n        tf.cast(item[\"time_id\"], dtype=tf.int16), \n        tf.cast(item[\"investment_id\"], dtype=tf.int16))\ndef make_dataset(file_paths, batch_size=100000, mode=\"train\"):\n    ds = tf.data.TFRecordDataset(file_paths)\n    ds = ds.map(decode_function)\n    ds = ds.map(preprocess)\n    ds = ds.batch(batch_size)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-03-13T19:35:08.5197Z","iopub.execute_input":"2022-03-13T19:35:08.520513Z","iopub.status.idle":"2022-03-13T19:35:08.530332Z","shell.execute_reply.started":"2022-03-13T19:35:08.520473Z","shell.execute_reply":"2022-03-13T19:35:08.529335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    path = f\"{config.tf_record_dataset_path}fold_{i}_train.tfrecords\"\n    ds = make_dataset([path], mode=\"train\")\n    X_batches = []\n    y_batches = []\n    tid_batches = []\n    iid_batches = []\n    j = 0\n    for X, y, tid, iid in ds:\n        print(j)\n        X_batches.append(X.numpy())\n        y_batches.append(y.numpy())\n        tid_batches.append(tid.numpy())\n        iid_batches.append(iid.numpy())\n        j += 1\n        \n    all_X_batches = np.concatenate(X_batches, axis=0)\n    all_y_batches = np.concatenate(y_batches, axis=0)\n    all_tid_batches = np.concatenate(tid_batches, axis=0)\n    all_iid_batches = np.concatenate(iid_batches, axis=0)\n    with open(f'fold_{i}_train_X.npy', 'wb') as f:\n        np.save(f, all_X_batches)\n    with open(f'fold_{i}_train_y.npy', 'wb') as f:\n        np.save(f, all_y_batches)\n    with open(f'fold_{i}_train_tid.npy', 'wb') as f:\n        np.save(f, all_tid_batches)\n    with open(f'fold_{i}_train_iid.npy', 'wb') as f:\n        np.save(f, all_iid_batches)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T19:29:33.815007Z","iopub.execute_input":"2022-03-13T19:29:33.815391Z","iopub.status.idle":"2022-03-13T19:32:10.130421Z","shell.execute_reply.started":"2022-03-13T19:29:33.815356Z","shell.execute_reply":"2022-03-13T19:32:10.129019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    path = f\"{config.tf_record_dataset_path}fold_{i}_test.tfrecords\"\n    ds = make_dataset([path], mode=\"valid\")\n    X_batches = []\n    y_batches = []\n    tid_batches = []\n    iid_batches = []\n    j = 0\n    for X, y, tid, iid in ds:\n        print(j)\n        X_batches.append(X.numpy())\n        y_batches.append(y.numpy())\n        tid_batches.append(tid.numpy())\n        iid_batches.append(iid.numpy())\n        j += 1\n        \n    all_X_batches = np.concatenate(X_batches, axis=0)\n    all_y_batches = np.concatenate(y_batches, axis=0)\n    all_tid_batches = np.concatenate(tid_batches, axis=0)\n    all_iid_batches = np.concatenate(iid_batches, axis=0)\n    with open(f'fold_{i}_test_X.npy', 'wb') as f:\n        np.save(f, all_X_batches)\n    with open(f'fold_{i}_test_y.npy', 'wb') as f:\n        np.save(f, all_y_batches)\n    with open(f'fold_{i}_test_tid.npy', 'wb') as f:\n        np.save(f, all_tid_batches)\n    with open(f'fold_{i}_test_iid.npy', 'wb') as f:\n        np.save(f, all_iid_batches)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T18:11:11.23045Z","iopub.execute_input":"2022-03-13T18:11:11.230752Z","iopub.status.idle":"2022-03-13T18:11:11.366795Z","shell.execute_reply.started":"2022-03-13T18:11:11.230722Z","shell.execute_reply":"2022-03-13T18:11:11.365649Z"},"trusted":true},"execution_count":null,"outputs":[]}]}