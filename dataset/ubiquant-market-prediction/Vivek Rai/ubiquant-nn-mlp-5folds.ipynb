{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## References :-\n- Thanks to [@HENG ZHENG](https://www.kaggle.com/hengzheng) for [training](https://www.kaggle.com/hengzheng/nn-mlp-5folds-training/) and [inference](https://www.kaggle.com/hengzheng/nn-mlp-5folds/) notebooks.\n- I have slightly changed the code so that it can be run on Kaggle itself.\n- I have used [Parquet dataset ](https://www.kaggle.com/robikscube/ubiquant-parquet). Thanks to [@Rob Mulla](https://www.kaggle.com/robikscube)\n- https://www.kaggle.com/c/ubiquant-market-prediction/discussion/301752\n- https://www.kaggle.com/valleyzw/ubiquant-lgbm-baseline/","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport joblib\nimport random\nimport numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nfrom pathlib import Path\nfrom argparse import Namespace\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-22T12:20:17.841004Z","iopub.execute_input":"2022-01-22T12:20:17.841334Z","iopub.status.idle":"2022-01-22T12:20:19.097151Z","shell.execute_reply.started":"2022-01-22T12:20:17.841253Z","shell.execute_reply":"2022-01-22T12:20:19.096402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed: int = 42) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:19.100833Z","iopub.execute_input":"2022-01-22T12:20:19.101389Z","iopub.status.idle":"2022-01-22T12:20:19.116365Z","shell.execute_reply.started":"2022-01-22T12:20:19.101357Z","shell.execute_reply":"2022-01-22T12:20:19.114907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = Namespace(\n    seed=21,\n    folds=5,\n    workers=4,\n    samples=200000,\n    data_path=Path(\"../input/ubiquant-parquet/\"),\n)\nseed_everything(args.seed)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:19.119562Z","iopub.execute_input":"2022-01-22T12:20:19.119777Z","iopub.status.idle":"2022-01-22T12:20:19.127458Z","shell.execute_reply.started":"2022-01-22T12:20:19.119751Z","shell.execute_reply":"2022-01-22T12:20:19.126682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_parquet(args.data_path.joinpath(\"train_low_mem.parquet\"))\nassert train.isnull().any().sum() == 0, \"null exists.\"","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:19.130118Z","iopub.execute_input":"2022-01-22T12:20:19.130487Z","iopub.status.idle":"2022-01-22T12:20:40.296934Z","shell.execute_reply.started":"2022-01-22T12:20:19.130403Z","shell.execute_reply":"2022-01-22T12:20:40.296117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if args.samples is not None:\n    train = train[-args.samples:].reset_index(drop=True)\n    gc.collect()\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:40.29828Z","iopub.execute_input":"2022-01-22T12:20:40.298665Z","iopub.status.idle":"2022-01-22T12:20:40.619185Z","shell.execute_reply.started":"2022-01-22T12:20:40.298626Z","shell.execute_reply":"2022-01-22T12:20:40.618484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_feats = [f'f_{i}' for i in range(300)]\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\ntrain[cont_feats] = scaler.fit_transform(train[cont_feats])\ntrain = reduce_mem_usage(train)\ngc.collect()\nlen(cont_feats)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:40.62279Z","iopub.execute_input":"2022-01-22T12:20:40.624747Z","iopub.status.idle":"2022-01-22T12:20:52.76376Z","shell.execute_reply.started":"2022-01-22T12:20:40.624706Z","shell.execute_reply":"2022-01-22T12:20:52.762941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:52.765097Z","iopub.execute_input":"2022-01-22T12:20:52.765424Z","iopub.status.idle":"2022-01-22T12:20:52.989926Z","shell.execute_reply.started":"2022-01-22T12:20:52.765386Z","shell.execute_reply":"2022-01-22T12:20:52.989272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UBIQUANT_DATASET(Dataset):\n    def __init__(self, df_data, mode='train'):\n        self.mode = mode\n        self.ids = np.array(df_data['investment_id'].values.tolist(), dtype=np.int64)\n        self.vals = np.array(df_data.iloc[:, 4:].values.tolist(), dtype=np.float64)\n        if self.mode != 'test':\n            self.targets = np.array(df_data['target'].values, dtype=np.float64)\n        self.len = df_data.shape[0]\n        \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self, index):\n        ids_out = self.ids[index]\n        vals_out = self.vals[index]\n        if self.mode != 'test':\n            targets_out = self.targets[index]\n            return ids_out, vals_out, targets_out\n        else:\n            return ids_out, vals_out","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:52.990826Z","iopub.execute_input":"2022-01-22T12:20:52.991073Z","iopub.status.idle":"2022-01-22T12:20:52.999092Z","shell.execute_reply.started":"2022-01-22T12:20:52.991039Z","shell.execute_reply":"2022-01-22T12:20:52.99835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy from: https://www.kaggle.com/elcaiseri/pytorch-optiver-realized-volatility-baseline\n\ndef swish(x):\n    return x * torch.sigmoid(x)\n\n\nclass SimpleMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.emb = nn.Embedding(3774, 64)\n        self.emb_drop = nn.Dropout(0.1)\n        \n        self.bn1 = nn.BatchNorm1d(300)\n        self.lin1 = nn.Linear(64+300, 32)\n        self.lin2 = nn.Linear(32, 128)\n        self.lin3 = nn.Linear(128, 64)\n        self.lin4 = nn.Linear(64, 32)\n        self.lin_drop = nn.Dropout(0.25)\n        self.lin5 = nn.Linear(32, 1)    \n\n    def forward(self, x_cat, x_cont):\n        x1 = self.emb(x_cat)\n        x1 = self.emb_drop(x1)\n        \n        x2 = self.bn1(x_cont)\n\n        x = torch.cat([x1, x2], 1)\n        x = swish(self.lin1(x))\n        x = swish(self.lin2(x))\n        x = swish(self.lin3(x))\n        x = swish(self.lin4(x))\n        x = self.lin5(x)\n        \n        return x\n    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:53.000257Z","iopub.execute_input":"2022-01-22T12:20:53.001003Z","iopub.status.idle":"2022-01-22T12:20:53.0638Z","shell.execute_reply.started":"2022-01-22T12:20:53.000964Z","shell.execute_reply":"2022-01-22T12:20:53.062865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(dataloaders, fold_id):\n    \n    model = SimpleMLP().to(device)\n    loss_fn = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), \n                           lr=1e-3)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                     factor=0.1, \n                                                     patience=1, \n                                                     mode='min')\n    \n    epochs = 8\n    num_train_examples = len(dataloaders['train'])\n    num_valid_examples = len(dataloaders['valid'])\n\n    losses = []\n    best_loss = np.inf\n\n    for e in range(epochs):\n        # train\n        model.train()\n        train_loss = 0\n        for i, (ids, vals, targets) in enumerate(dataloaders['train']):\n            ids = ids.to(device)\n            vals = vals.to(device=device, dtype=torch.float)\n            targets = targets.unsqueeze(1).to(device, dtype=torch.float)\n\n            yhat = model(ids, vals)\n            loss = loss_fn(yhat, targets)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        train_epoch_loss = train_loss / num_train_examples\n\n        # valid\n        model.eval()\n        valid_preds = list()\n        valid_loss = 0\n        with torch.no_grad():\n            for i, (ids, vals, targets) in enumerate(dataloaders['valid']):\n                ids = ids.to(device)\n                vals = vals.to(device=device, dtype=torch.float)\n                targets = targets.unsqueeze(1).to(device, dtype=torch.float)\n\n                yhat = model(ids, vals)\n                val_loss = loss_fn(yhat, targets)\n                valid_loss += val_loss.item()\n                valid_preds.extend(yhat.detach().cpu().numpy().flatten())\n        valid_epoch_loss = valid_loss / num_valid_examples\n\n        # change lr\n        scheduler.step(valid_epoch_loss)\n\n        # oof\n        oof = df_valid[['target']].copy()\n        oof['pred'] = valid_preds\n        score = oof['pred'].corr(oof['target'])\n\n        # print score\n        print(f\"Epoch {e}, LR: {optimizer.param_groups[0]['lr']}\")\n        print(f\"train loss: {train_epoch_loss:.8f}, valid loss {valid_epoch_loss:.8f}, pearson score: {score:.6f}\")\n        losses.append((train_epoch_loss, valid_epoch_loss))\n\n        # save model\n        if best_loss > valid_epoch_loss:\n            torch.save(model.state_dict(), f'simple_mlp_model_{fold_id}.pth')\n            print(f'-- loss from {best_loss:.8f} to {valid_epoch_loss:.8f}, model saved')\n            best_loss = valid_epoch_loss\n        print()\n    \n    del model\n    gc.collect()\n    \n    return losses, oof","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:53.067152Z","iopub.execute_input":"2022-01-22T12:20:53.067433Z","iopub.status.idle":"2022-01-22T12:20:53.084201Z","shell.execute_reply.started":"2022-01-22T12:20:53.067396Z","shell.execute_reply":"2022-01-22T12:20:53.083421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_list = list()\n\nkfold = GroupKFold(n_splits=5)\nfor fold_id, (trn_idx, val_idx) in enumerate(kfold.split(train, train['target'], train['time_id'])):\n    \n    print(f'Training Fold: {fold_id}\\n')\n    \n    df_train = train.iloc[trn_idx]\n    df_valid = train.iloc[val_idx]\n    \n    train_set = UBIQUANT_DATASET(df_train, mode='train')\n    valid_set = UBIQUANT_DATASET(df_valid, mode='valid')\n    \n    dataloaders = {\n        'train': DataLoader(train_set, batch_size=1024, num_workers=4, pin_memory=True, shuffle=True),\n        'valid': DataLoader(valid_set, batch_size=1024, num_workers=4, pin_memory=True, shuffle=False)\n    }\n    \n    _, oof = train_fn(dataloaders, fold_id)\n    oof_list.append(oof)\n    \n    del df_train, df_valid, train_set, valid_set, oof\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:20:53.085597Z","iopub.execute_input":"2022-01-22T12:20:53.085869Z","iopub.status.idle":"2022-01-22T12:24:09.596668Z","shell.execute_reply.started":"2022-01-22T12:20:53.085832Z","shell.execute_reply":"2022-01-22T12:24:09.595818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = pd.concat(oof_list)\nprint('oof pearson score:', oof['pred'].corr(oof['target']))","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:24:09.598019Z","iopub.execute_input":"2022-01-22T12:24:09.598773Z","iopub.status.idle":"2022-01-22T12:24:09.616126Z","shell.execute_reply.started":"2022-01-22T12:24:09.59873Z","shell.execute_reply":"2022-01-22T12:24:09.615147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joblib.dump(scaler, 'minmaxscaler.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:24:09.617331Z","iopub.execute_input":"2022-01-22T12:24:09.617989Z","iopub.status.idle":"2022-01-22T12:24:09.625808Z","shell.execute_reply.started":"2022-01-22T12:24:09.617942Z","shell.execute_reply":"2022-01-22T12:24:09.624861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"class UBIQUANT_DATASET_TEST(Dataset):\n    def __init__(self, df_data):\n        self.ids = np.array(df_data['investment_id'].values.tolist(), dtype=np.int64)\n        self.vals = np.array(df_data.iloc[:, 1:].values.tolist(), dtype=np.float64)\n        self.len = df_data.shape[0]\n        \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self, index):\n        ids_out = self.ids[index]\n        vals_out = self.vals[index]\n        return ids_out, vals_out","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:26:14.051853Z","iopub.execute_input":"2022-01-22T12:26:14.052498Z","iopub.status.idle":"2022-01-22T12:26:14.059225Z","shell.execute_reply.started":"2022-01-22T12:26:14.052455Z","shell.execute_reply":"2022-01-22T12:26:14.058158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = joblib.load('./minmaxscaler.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:24:09.639342Z","iopub.execute_input":"2022-01-22T12:24:09.640104Z","iopub.status.idle":"2022-01-22T12:24:09.649289Z","shell.execute_reply.started":"2022-01-22T12:24:09.640061Z","shell.execute_reply":"2022-01-22T12:24:09.648438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_list = list()\nfor fold_id in range(5):\n    model = SimpleMLP().to(device)\n    model.load_state_dict(torch.load(f'./simple_mlp_model_{fold_id}.pth'))\n    models_list.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:24:09.650458Z","iopub.execute_input":"2022-01-22T12:24:09.650753Z","iopub.status.idle":"2022-01-22T12:24:09.692721Z","shell.execute_reply.started":"2022-01-22T12:24:09.650711Z","shell.execute_reply":"2022-01-22T12:24:09.692083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\n\nenv = ubiquant.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:24:09.693968Z","iopub.execute_input":"2022-01-22T12:24:09.694219Z","iopub.status.idle":"2022-01-22T12:24:09.720506Z","shell.execute_reply.started":"2022-01-22T12:24:09.694185Z","shell.execute_reply":"2022-01-22T12:24:09.71984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.drop([\"row_id\"], axis=1)\n    test_df[cont_feats] = scaler.transform(test_df[cont_feats])\n    test_set = UBIQUANT_DATASET_TEST(test_df)\n    test_dataloader = DataLoader(test_set, batch_size=1024, \n                                 num_workers=2, pin_memory=True, shuffle=False)\n    y_preds = list()\n    with torch.no_grad():\n        for i, (ids, vals) in enumerate(test_dataloader):\n            ids = ids.to(device)\n            vals = vals.to(device=device, dtype=torch.float)\n            y_pred = np.zeros((len(ids), ))\n            for model in models_list:\n                model.eval()\n                y_pred += model(ids, vals).detach().cpu().numpy().flatten() / 5\n            y_preds.extend(y_pred)\n    sample_prediction_df['target'] = y_preds\n    env.predict(sample_prediction_df)\n    display(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T12:27:07.458675Z","iopub.execute_input":"2022-01-22T12:27:07.459111Z","iopub.status.idle":"2022-01-22T12:27:08.247544Z","shell.execute_reply.started":"2022-01-22T12:27:07.459065Z","shell.execute_reply":"2022-01-22T12:27:08.246651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}