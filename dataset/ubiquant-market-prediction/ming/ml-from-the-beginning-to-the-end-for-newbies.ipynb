{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **First. Big Picture -üèî**","metadata":{}},{"cell_type":"markdown","source":"To attempt to predict returns, there are many computer-based algorithms and models for financial market trading. <br>\n**Yet,** with new techniques and approaches, **data science could improve quantitative researchers' ability to forecast an investment's return.**\n\n> Ubiquant is committed to creating long-term stable returns for investors.\n\nIn this competition, you‚Äôll build **a model that forecasts an investment's return rate**. <br> \nTrain and test your algorithm on historical prices. Top entries will solve this real-world data science problem with as much accuracy as possible.","metadata":{}},{"cell_type":"markdown","source":"# **Second. Problem definition -‚úè**","metadata":{}},{"cell_type":"markdown","source":"\"This dataset contains features derived from real historic data from thousands of investments.\" <br>\n**Your challenge is to predict the value of an obfuscated metric relevant for making trading decisions.**","metadata":{}},{"cell_type":"markdown","source":"- row_id - A unique identifier for the row.\n- time_id - The ID code for the time the data was gathered. The time IDs are in order, but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.\n- investment_id - The ID code for an investment. Not all investment have data in all time IDs.\n- **target - The target.**\n- [f_0:f_299] - Anonymized features generated from market data.","metadata":{}},{"cell_type":"markdown","source":"**Performance metrics** is  the mean of the Pearson correlation coefficient\n","metadata":{}},{"cell_type":"markdown","source":"# **Third. Data & Import**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom scipy import stats\nfrom pathlib import Path\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:04:15.486675Z","iopub.execute_input":"2022-03-26T09:04:15.487112Z","iopub.status.idle":"2022-03-26T09:04:23.162576Z","shell.execute_reply.started":"2022-03-26T09:04:15.486973Z","shell.execute_reply":"2022-03-26T09:04:23.161547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading as Parquet Low Memory (Fast & Low Mem Use)**\nhttps://www.kaggle.com/robikscube/fast-data-loading-and-low-mem-with-parquet-files","metadata":{}},{"cell_type":"code","source":"%%time\nn_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\ntrain = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:04:23.164483Z","iopub.execute_input":"2022-03-26T09:04:23.164832Z","iopub.status.idle":"2022-03-26T09:05:01.520344Z","shell.execute_reply.started":"2022-03-26T09:04:23.164785Z","shell.execute_reply":"2022-03-26T09:05:01.51919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_mem = train.memory_usage().sum() / 1024**2\n\ndef decreasing_train(train):\n    for col in train.columns:\n        col_type = train[col].dtype\n\n        if col_type != object:\n            c_min = train[col].min()\n            c_max = train[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    train[col] = train[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    train[col] = train[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    train[col] = train[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    train[col] = train[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    train[col] = train[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    train[col] = train[col].astype(np.float32)\n                else:\n                    train[col] = train[col].astype(np.float64)\n        else:\n            train[col] = train[col].astype('category')\n    return train\n\ntrain = decreasing_train(train)\nend_mem = train.memory_usage().sum() / 1024**2\nprint('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\nprint('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:05:01.521906Z","iopub.execute_input":"2022-03-26T09:05:01.522224Z","iopub.status.idle":"2022-03-26T09:09:09.438183Z","shell.execute_reply.started":"2022-03-26T09:05:01.52219Z","shell.execute_reply":"2022-03-26T09:09:09.434726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fourth. Take a looke and Split test data -üôÑ**","metadata":{}},{"cell_type":"code","source":"display(train.info())\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:09.445521Z","iopub.execute_input":"2022-03-26T09:09:09.446003Z","iopub.status.idle":"2022-03-26T09:09:13.613907Z","shell.execute_reply.started":"2022-03-26T09:09:09.445945Z","shell.execute_reply":"2022-03-26T09:09:13.609292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in ['investment_id', 'time_id']:\n    print(f'------------------{i} / value counts------------------')\n    display(train[i].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:13.617974Z","iopub.execute_input":"2022-03-26T09:09:13.618329Z","iopub.status.idle":"2022-03-26T09:09:13.852009Z","shell.execute_reply.started":"2022-03-26T09:09:13.618292Z","shell.execute_reply":"2022-03-26T09:09:13.851317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:13.85332Z","iopub.execute_input":"2022-03-26T09:09:13.853747Z","iopub.status.idle":"2022-03-26T09:09:13.897393Z","shell.execute_reply.started":"2022-03-26T09:09:13.853706Z","shell.execute_reply":"2022-03-26T09:09:13.896371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['investment_id', 'time_id']].hist(bins=50, figsize=(10,5))\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:13.898887Z","iopub.execute_input":"2022-03-26T09:09:13.899169Z","iopub.status.idle":"2022-03-26T09:09:19.015202Z","shell.execute_reply.started":"2022-03-26T09:09:13.899133Z","shell.execute_reply":"2022-03-26T09:09:19.01424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**380-410(time_id)** are strange and You can see time_id's increasing aspect","metadata":{}},{"cell_type":"markdown","source":"# Split Test data <br>\nWe will split data based on time_id category [stratified sampling] <br> for preventing **sampling bias**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(train, train['time_id']):\n    train_set = train.loc[train_index]\n    test_set = train.loc[test_index]","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:19.01652Z","iopub.execute_input":"2022-03-26T09:09:19.016803Z","iopub.status.idle":"2022-03-26T09:09:38.250324Z","shell.execute_reply.started":"2022-03-26T09:09:19.016771Z","shell.execute_reply":"2022-03-26T09:09:38.249196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x = test_set.drop(['target', 'row_id'], axis=1).copy()\ntest_target = test_set['target'].copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:38.251816Z","iopub.execute_input":"2022-03-26T09:09:38.252146Z","iopub.status.idle":"2022-03-26T09:09:39.242085Z","shell.execute_reply.started":"2022-03-26T09:09:38.252105Z","shell.execute_reply":"2022-03-26T09:09:39.240467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_set['time_id'].value_counts() / len(train_set))\ndisplay(test_set['time_id'].value_counts() / len(test_set))","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:39.244666Z","iopub.execute_input":"2022-03-26T09:09:39.244996Z","iopub.status.idle":"2022-03-26T09:09:39.311854Z","shell.execute_reply.started":"2022-03-26T09:09:39.244953Z","shell.execute_reply":"2022-03-26T09:09:39.311099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ndel test_set","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:39.31328Z","iopub.execute_input":"2022-03-26T09:09:39.314056Z","iopub.status.idle":"2022-03-26T09:09:39.341438Z","shell.execute_reply.started":"2022-03-26T09:09:39.314002Z","shell.execute_reply":"2022-03-26T09:09:39.340109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fifth. EDA & Visualization -üìä**","metadata":{}},{"cell_type":"code","source":"ubiquant = train_set.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1) Check time_id","metadata":{}},{"cell_type":"code","source":"time_count = ubiquant['time_id'].groupby(ubiquant['investment_id']).count()\ntime_count.plot(kind='hist', bins=25, grid=True, title='time_count')\nplt.show()\n\ntime_mean = ubiquant['time_id'].groupby(ubiquant['investment_id']).mean()\ntime_mean.plot(kind='hist', bins=25, grid=True, title='time_mean')\nplt.show()\n\ntime_std = ubiquant['time_id'].groupby(ubiquant['investment_id']).std()\ntime_std.plot(kind='hist', bins=25, grid=True, title='time_std')\nplt.show()\n\ndel time_count\ndel time_mean\ndel time_std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2) Scatter plot","metadata":{}},{"cell_type":"code","source":"from pandas.plotting import scatter_matrix\n\nattri = ['investment_id', 'time_id', 'f_0', 'f_1']\nscatter_matrix(ubiquant[attri], figsize = (12,8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3) Check Outlier","metadata":{}},{"cell_type":"code","source":"investment_count = ubiquant.groupby(['investment_id'])['target'].count()\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\ninvestment_count.plot.hist(bins=60, color = 'blue', alpha = 0.4)\nplt.title(\"Count of investment by target\")\nplt.show()\n\ninvestment_mean = ubiquant.groupby(['investment_id'])['target'].mean()\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\ninvestment_mean.plot.hist(bins=60, color = 'blue', alpha = 0.4)\nplt.title(\"Mean of investment by target\")\nplt.show()\n\nax = sns.jointplot(x=investment_count, y=investment_mean, kind='reg',\n                  height=8, color = 'blue')\nax.ax_joint.set_xlabel('observations')\nax.ax_joint.set_ylabel('mean target')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Sixth. Feature Engineering -üõ†**","metadata":{}},{"cell_type":"markdown","source":"1) Make label","metadata":{}},{"cell_type":"code","source":"train_x = train_set.drop(['target', 'row_id'], axis=1).copy()\ntrain_target = train_set['target'].copy()\ndisplay(train_x.head())\ntrain_target.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T09:09:42.279569Z","iopub.execute_input":"2022-03-26T09:09:42.279913Z","iopub.status.idle":"2022-03-26T09:09:47.298842Z","shell.execute_reply.started":"2022-03-26T09:09:42.279879Z","shell.execute_reply":"2022-03-26T09:09:47.297777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2) Remove outlier","metadata":{}},{"cell_type":"code","source":"# Step 2.\noutlier_id = investment_mean.reset_index(name='mean')\noutlier_id = outlier_id[abs(outlier_id['mean']) < 0.15]\noutlier_id = outlier_id['investment_id'].tolist()\n\n# removeing outlier_id\nremove_df = train_set[train_set['investment_id'].isin(outlier_id)].copy()\nremove_df","metadata":{"execution":{"iopub.status.busy":"2022-03-17T08:02:58.717014Z","iopub.execute_input":"2022-03-17T08:02:58.717311Z","iopub.status.idle":"2022-03-17T08:03:05.804442Z","shell.execute_reply.started":"2022-03-17T08:02:58.71728Z","shell.execute_reply":"2022-03-17T08:03:05.803656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 3.\ninvestment_count = remove_df.groupby(['investment_id'])['target'].count()\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\ninvestment_count.plot.hist(bins=60, color = 'blue', alpha = 0.4)\nplt.title(\"Count of investment by target\")\nplt.show()\n\ninvestment_mean = remove_df.groupby(['investment_id'])['target'].mean()\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\ninvestment_mean.plot.hist(bins=60, color = 'blue', alpha = 0.4)\nplt.title(\"Mean of investment by target\")\nplt.show()\n\nax = sns.jointplot(x=investment_count, y=investment_mean, kind='reg',\n                  height=8, color = 'blue')\nax.ax_joint.set_xlabel('observations')\nax.ax_joint.set_ylabel('mean target')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T08:03:05.805527Z","iopub.execute_input":"2022-03-17T08:03:05.80648Z","iopub.status.idle":"2022-03-17T08:03:07.753625Z","shell.execute_reply.started":"2022-03-17T08:03:05.806419Z","shell.execute_reply":"2022-03-17T08:03:07.752513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3) Scaling & Simple pipeline <br>\nbut f_0 ~ f_300 seem to be similar scale. so we don't need scaling","metadata":{}},{"cell_type":"code","source":"# from sklearn.pipeline import Pipeline\n# from sklearn.preprocessing import StandardScaler\n\n# f_num_pipeline = Pipeline([\n#     ('std_scaler', StandardScaler())\n# ])\n\n# ubi_f_pipe = f_num_pipeline.fit_transform(train_set[features])","metadata":{"execution":{"iopub.status.busy":"2022-03-17T08:03:07.755176Z","iopub.execute_input":"2022-03-17T08:03:07.755602Z","iopub.status.idle":"2022-03-17T08:03:07.761228Z","shell.execute_reply.started":"2022-03-17T08:03:07.755558Z","shell.execute_reply":"2022-03-17T08:03:07.759652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_set","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Seventh. Modeling & Training -üó°**","metadata":{}},{"cell_type":"code","source":"import lightgbm\nimport xgboost\n\ntrain_ds = lightgbm.Dataset(train_x, label = train_target) \nval_ds = lightgbm.Dataset(test_x, label = test_target) \nparams = {'learning_rate': 0.01, \n          'max_depth': 5, \n          'objective': 'regression', \n          'metric': 'mse', \n          'is_training_metric': True, \n          'num_leaves': 144}\nmodel = lightgbm.train(params, train_ds, 85, val_ds)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T08:08:51.023536Z","iopub.execute_input":"2022-03-17T08:08:51.02388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\n\nprediction = model.predict(test_x)\nmse = mean_squared_error(test_target, prediction)\nprint(f'model mse is {mse}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"StratifiedKFold","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import KFold\nparams = {'learning_rate': 0.01, \n          'max_depth': 5, \n          'objective': 'regression', \n          'metric': 'mse', \n          'is_training_metric': True, \n          'num_leaves': 144}\nkfold = KFold(n_splits=5)\nmodels = []\nprint('start')\n\nfor  train_indices, valid_indices in kfold.split(train_x):\n    print('start')\n    train_x, val_x = train_x.iloc[train_indices], train_x.iloc[valid_indices]\n    train_y, val_y = train_target.iloc[train_indices], train_target.iloc[valid_indices]\n    train_ds = lightgbm.Dataset(train_x, label = train_y) \n    val_ds = lightgbm.Dataset(val_x, label = val_y) \n    print('middle')\n    #checkpoint = keras.callbacks.ModelCheckpoint(f\"model_{index}\", save_best_only=True)\n    early_stop = keras.callbacks.EarlyStopping(patience=10)\n    model = lightgbm.train(params, train_ds, 100, val_ds)\n    models.append(model)\n    print('finishs')\n    pearson_score = stats.pearsonr(model.predict(val_x).ravel(), val_y.values)[0]\n    print('Pearson:', pearson_score)\n    del train_x\n    del val_x\n    del train_y\n    del val_y\n    del train_ds\n    del val_ds\n    gc.collect()\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Eighth. Tunning -üéπ**","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# from lightgbm import LGBMRegressor\n# LGB = LGBMRegressor()\n\n# lgb_param_grid = {\n#     'num_leaves' : [1,5,10],\n#     'learning_rate': [1,0.1,0.01,0.001],\n#     'n_estimators': [50, 100, 200, 500, 1000,5000], \n#     'max_depth': [15,20,25],\n#     'num_leaves': [50, 100, 200],\n#     'min_split_gain': [0.3, 0.4],\n# }\n# gsLGB = GridSearchCV(LGB,param_grid = lgb_param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs= 4, verbose = 1)\n# gsLGB.fit(train_x, train_target)\n# LGB_best = gsLGB.best_estimator_\n\n# print('ÏµúÏ†Å ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞: ', gsLGB.best_params_)\n# print('ÏµúÍ≥† ÏòàÏ∏° Ï†ïÌôïÎèÑ: {:.4f}'.format(gsLGB.best_score_))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission -‚õ∑**","metadata":{}},{"cell_type":"code","source":"def inference(models, ds):\n    y_preds = []\n    for model in models:\n        y_pred = model.predict(ds)\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test() \nfor (test_df, sample_prediction_df) in iter_test:\n    time_df = test_df.row_id.str.split('_').str[0].astype(int)\n    test_df.drop(['row_id'], axis=1, inplace=True)\n    test_df['time_id'] = time_df\n    sample_prediction_df['target'] = inference(models, test_df)\n    env.predict(sample_prediction_df) ","metadata":{},"execution_count":null,"outputs":[]}]}