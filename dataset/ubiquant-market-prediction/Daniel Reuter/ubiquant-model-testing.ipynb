{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nimport torch\nfrom tensorflow import keras\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T00:50:06.112617Z","iopub.execute_input":"2022-04-05T00:50:06.113519Z","iopub.status.idle":"2022-04-05T00:50:12.686322Z","shell.execute_reply.started":"2022-04-05T00:50:06.113419Z","shell.execute_reply":"2022-04-05T00:50:12.685319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def correlationMetric(x, y, axis=-2):\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n    x = tf.convert_to_tensor(x)\n    y = math_ops.cast(y, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return corr","metadata":{"execution":{"iopub.status.busy":"2022-04-05T00:50:12.687913Z","iopub.execute_input":"2022-04-05T00:50:12.688093Z","iopub.status.idle":"2022-04-05T00:50:12.694777Z","shell.execute_reply.started":"2022-04-05T00:50:12.688072Z","shell.execute_reply":"2022-04-05T00:50:12.693673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_version = 3\nnn_model = keras.models.load_model(f'../input/nn-version{nn_version}/nn_model{nn_version}', \n                                   custom_objects={'correlationMetric':correlationMetric})\n\nlgbm_version = 3\nlgbm_model, importance = pickle.load(open(f'../input/lgbm-version{lgbm_version}/lgbm_results{lgbm_version}.pkl', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T00:50:12.696191Z","iopub.execute_input":"2022-04-05T00:50:12.696756Z","iopub.status.idle":"2022-04-05T00:50:17.555909Z","shell.execute_reply.started":"2022-04-05T00:50:12.696717Z","shell.execute_reply":"2022-04-05T00:50:17.555191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_lgbm(df, columns, mod):\n    '''\n    Returns LGBM predictions over columns in df given mod\n    ''' \n    return mod.predict(df[columns])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T00:50:17.557558Z","iopub.execute_input":"2022-04-05T00:50:17.558302Z","iopub.status.idle":"2022-04-05T00:50:17.565734Z","shell.execute_reply.started":"2022-04-05T00:50:17.558263Z","shell.execute_reply":"2022-04-05T00:50:17.56388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_nn(df, columns, mod):\n    '''\n    Returns NN predictions over columns in df given mod\n    ''' \n    return mod.predict(df[columns])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T00:50:17.567127Z","iopub.execute_input":"2022-04-05T00:50:17.567313Z","iopub.status.idle":"2022-04-05T00:50:17.584521Z","shell.execute_reply.started":"2022-04-05T00:50:17.56729Z","shell.execute_reply":"2022-04-05T00:50:17.583787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\n\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\n\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    \n    \n    #transform(test_df) # generate derived features\n    \n    features         = [col for col in test_df if col.startswith('f_')]\n    #derived_features = [col for col in test_df if col.startswith('all')]\n    #cluster_features = [col for col in test_df if col.startswith('clust')]\n    \n    \n    test_df['target_lgbm'] = predict_lgbm(test_df, features, lgbm_model)\n    test_df['target_nn']   = predict_nn(  test_df, features, nn_model)\n    \n    for x in ['target_lgbm', 'target_nn']:\n        test_df[x] = test_df[x]/test_df[x].std()\n     \n    test_df['target_ensemble'] = test_df[['target_lgbm', 'target_nn']].mean(axis=1)\n\n    # Choose version to submit\n    test_df['target'] = test_df['target_ensemble']\n    \n    env.predict(test_df[['row_id','target']])","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-04-05T00:50:17.602387Z","iopub.execute_input":"2022-04-05T00:50:17.60258Z","iopub.status.idle":"2022-04-05T00:50:18.361911Z","shell.execute_reply.started":"2022-04-05T00:50:17.602554Z","shell.execute_reply":"2022-04-05T00:50:18.360587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}