{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi, and thank you for stopping by and looking at my work! Please feel free to upvote or comment if you find this notebook helpful, or if you have suggestions for improvement. \n\nPlease note that this notebook is work in progress and does not reflect a complete solution/approach yet.","metadata":{}},{"cell_type":"markdown","source":"# Loading Dataset\nPrepare reading the CSV file as int16 and float16 format to save memory.","metadata":{}},{"cell_type":"code","source":"import time\nimport numpy as np \nimport pandas as pd \n\ndata_types_dict = {\n    'time_id': 'int16',\n    'investment_id': 'int16',\n    \"target\": 'float16',\n}\n\nfeatures = [f'f_{i}' for i in range(300)]\n\nfor f in features:\n    data_types_dict[f] = 'float16'","metadata":{"execution":{"iopub.status.busy":"2022-02-15T02:36:28.488849Z","iopub.execute_input":"2022-02-15T02:36:28.489472Z","iopub.status.idle":"2022-02-15T02:36:28.599897Z","shell.execute_reply.started":"2022-02-15T02:36:28.489353Z","shell.execute_reply":"2022-02-15T02:36:28.599304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\ntrain_data = pd.read_csv('../input/ubiquant-market-prediction/train.csv',\n                        usecols = data_types_dict.keys(),\n                        dtype = data_types_dict,\n                        skiprows=range(1,100000), #Keeps the header this way\n                        nrows=10000)\n\nend_time = time.time()\n\nread_time = end_time - start_time \n\nprint(\"Reading dataset took: \", read_time, \"sec\")","metadata":{"execution":{"iopub.status.busy":"2022-02-15T02:36:53.062731Z","iopub.execute_input":"2022-02-15T02:36:53.063387Z","iopub.status.idle":"2022-02-15T02:37:04.314966Z","shell.execute_reply.started":"2022-02-15T02:36:53.063342Z","shell.execute_reply":"2022-02-15T02:37:04.314041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for missing values\nmissing_values_count = train_data.isnull().sum()\nprint(missing_values_count)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T02:37:06.367345Z","iopub.execute_input":"2022-02-15T02:37:06.368071Z","iopub.status.idle":"2022-02-15T02:37:06.398299Z","shell.execute_reply.started":"2022-02-15T02:37:06.368023Z","shell.execute_reply":"2022-02-15T02:37:06.397367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Columns' Interpretation\n\n* row_id - A unique identifier for the row.\n* time_id - The ID code for the time the data was gathered. The time IDs are in order, but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.\n* investment_id - The ID code for an investment. Not all investment have data in all time IDs.\n* target - The target.\n* [f_0:f_299] - Anonymized features generated from market data.","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T02:37:08.585639Z","iopub.execute_input":"2022-02-15T02:37:08.585943Z","iopub.status.idle":"2022-02-15T02:37:08.630836Z","shell.execute_reply.started":"2022-02-15T02:37:08.58591Z","shell.execute_reply":"2022-02-15T02:37:08.629993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T02:37:10.159712Z","iopub.execute_input":"2022-02-15T02:37:10.160016Z","iopub.status.idle":"2022-02-15T02:37:10.199991Z","shell.execute_reply.started":"2022-02-15T02:37:10.159983Z","shell.execute_reply":"2022-02-15T02:37:10.198875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sorting by investment_id and time_id to use for constructing lag features later\ntest_frame = train_data.sort_values(by=['investment_id', 'time_id'])\ntest_frame.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:20:35.008498Z","iopub.execute_input":"2022-02-15T03:20:35.008897Z","iopub.status.idle":"2022-02-15T03:20:35.061928Z","shell.execute_reply.started":"2022-02-15T03:20:35.008852Z","shell.execute_reply":"2022-02-15T03:20:35.061051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What's next?\n* Data cleaning (data appears to have no missing values)\n* Baseline Model\n* EDA \n* Feature Engineering (try constructing lag features)\n\n[this notebook might be useful for reference](https://www.kaggle.com/ilialar/ubiquant-eda-and-baseline/notebook)","metadata":{}},{"cell_type":"markdown","source":"Trying out PCA","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\nfrom sklearn.feature_selection import mutual_info_regression\n\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\ndef plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs\n\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:22:58.023835Z","iopub.execute_input":"2022-02-15T03:22:58.024396Z","iopub.status.idle":"2022-02-15T03:22:58.036938Z","shell.execute_reply.started":"2022-02-15T03:22:58.024361Z","shell.execute_reply":"2022-02-15T03:22:58.035871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = test_frame.copy()\ny = X.pop('target')\nX = X.loc[:, features]\n\n#Standardize - NOTE TO SELF: check if normalization is needed for this dataset\nX_scaled = (X - X.mean(axis=0)) / X.std(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:07:42.805527Z","iopub.execute_input":"2022-02-15T04:07:42.806019Z","iopub.status.idle":"2022-02-15T04:07:43.114797Z","shell.execute_reply.started":"2022-02-15T04:07:42.80597Z","shell.execute_reply":"2022-02-15T04:07:43.113673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.any(np.isnan(X_scaled))\n#X_scaled[features].isnull().sum()\nfor i in range(0,299):\n    if X_scaled[\"f_%s\" % i].isnull().sum() != 0:\n        print(\"f_%s\" % i,\" \", X_scaled[\"f_%s\" % i].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:05:45.992Z","iopub.execute_input":"2022-02-15T04:05:45.992587Z","iopub.status.idle":"2022-02-15T04:05:46.063815Z","shell.execute_reply.started":"2022-02-15T04:05:45.992539Z","shell.execute_reply":"2022-02-15T04:05:46.062795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.f_170","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:06:21.255267Z","iopub.execute_input":"2022-02-15T04:06:21.255878Z","iopub.status.idle":"2022-02-15T04:06:21.263623Z","shell.execute_reply.started":"2022-02-15T04:06:21.255842Z","shell.execute_reply":"2022-02-15T04:06:21.262813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Turns out, f_124, f_170, f_182 have std = 0. we'll need to address those manualy to make PCA work.\nHowever, a better solution would be to use float64 data type, so those inf and NaN will not appear in the first place.","metadata":{}},{"cell_type":"code","source":"X_scaled.f_124 = X_scaled.f_124.fillna(0.0)\nX_scaled.f_170 = X_scaled.f_170.fillna(0.0)\nX_scaled.f_182 = X_scaled.f_182.fillna(1.0)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:09:12.838911Z","iopub.execute_input":"2022-02-15T04:09:12.839742Z","iopub.status.idle":"2022-02-15T04:09:12.845618Z","shell.execute_reply.started":"2022-02-15T04:09:12.839704Z","shell.execute_reply":"2022-02-15T04:09:12.84481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n# Create principal components\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# Convert to dataframe\ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_pca.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:10:47.559162Z","iopub.execute_input":"2022-02-15T04:10:47.559917Z","iopub.status.idle":"2022-02-15T04:10:47.911552Z","shell.execute_reply.started":"2022-02-15T04:10:47.559862Z","shell.execute_reply":"2022-02-15T04:10:47.910706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After fitting, the PCA instance contains the loadings in its components_ attribute. (Terminology for PCA is inconsistent, unfortunately. We're following the convention that calls the transformed columns in X_pca the components, which otherwise don't have a name.) We'll wrap the loadings up in a dataframe.","metadata":{}},{"cell_type":"code","source":"loadings = pd.DataFrame(\n    pca.components_.T,  # transpose the matrix of loadings\n    columns=component_names,  # so the columns are the principal components\n    index=X.columns,  # and the rows are the original features\n)\nloadings.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:13:46.684482Z","iopub.execute_input":"2022-02-15T04:13:46.684763Z","iopub.status.idle":"2022-02-15T04:13:46.71388Z","shell.execute_reply.started":"2022-02-15T04:13:46.684735Z","shell.execute_reply":"2022-02-15T04:13:46.713233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at explained variance\nplot_variance(pca)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:14:06.117213Z","iopub.execute_input":"2022-02-15T04:14:06.117517Z","iopub.status.idle":"2022-02-15T04:14:07.589005Z","shell.execute_reply.started":"2022-02-15T04:14:06.117486Z","shell.execute_reply":"2022-02-15T04:14:07.588366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = make_mi_scores(X_pca, y, discrete_features=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:21:51.340027Z","iopub.execute_input":"2022-02-15T04:21:51.340907Z","iopub.status.idle":"2022-02-15T04:22:43.074445Z","shell.execute_reply.started":"2022-02-15T04:21:51.340859Z","shell.execute_reply":"2022-02-15T04:22:43.073625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1,300):\n    print(mi_scores[\"PC%s\" % i])","metadata":{"execution":{"iopub.status.busy":"2022-02-15T04:35:40.760534Z","iopub.execute_input":"2022-02-15T04:35:40.761346Z","iopub.status.idle":"2022-02-15T04:35:40.802309Z","shell.execute_reply.started":"2022-02-15T04:35:40.761306Z","shell.execute_reply":"2022-02-15T04:35:40.78826Z"},"trusted":true},"execution_count":null,"outputs":[]}]}