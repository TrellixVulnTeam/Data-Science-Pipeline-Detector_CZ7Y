{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport joblib\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom argparse import Namespace\nfrom collections import defaultdict\n\nimport optuna\nimport scipy as sc\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import TimeSeriesSplit, StratifiedKFold, GroupKFold, train_test_split, KFold\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('max_columns', 64)\n\ndef seed_everything(seed: int = 42) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T14:16:08.952499Z","iopub.execute_input":"2022-02-08T14:16:08.953332Z","iopub.status.idle":"2022-02-08T14:16:11.968928Z","shell.execute_reply.started":"2022-02-08T14:16:08.953225Z","shell.execute_reply":"2022-02-08T14:16:11.968097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = Namespace(\n    debug=False,\n    seed=21,\n    folds=5,\n    workers=4,\n    min_time_id=530, \n    holdout=False,\n    cv_method=\"stratified\",\n    num_bins=16,\n    timeout=int(3600*8.5), # an hour * x\n    data_path=Path(\"../input/ubiquant-parquet/\"),\n)\nseed_everything(args.seed)\n\nif args.debug:\n    setattr(args, 'min_time_id', 1100)\n\nassert args.cv_method in {\"kfold\", \"group\", \"stratified\", \"time\", \"group_time\"}, \"unknown cv method\"\nassert args.data_path.exists(), \"data_path not exists\"","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:16:11.970909Z","iopub.execute_input":"2022-02-08T14:16:11.971321Z","iopub.status.idle":"2022-02-08T14:16:11.979679Z","shell.execute_reply.started":"2022-02-08T14:16:11.971275Z","shell.execute_reply":"2022-02-08T14:16:11.978641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = pd.read_parquet(args.data_path.joinpath(\"train_low_mem.parquet\"))\nassert train.isnull().any().sum() == 0, \"null exists.\"\nassert train.row_id.str.extract(r\"(?P<time_id>\\d+)_(?P<investment_id>\\d+)\").astype(train.time_id.dtype).equals(train[[\"time_id\", \"investment_id\"]]), \"row_id!=time_id_investment_id\"\nassert train.time_id.is_monotonic_increasing, \"time_id not monotonic increasing\"\n\nif args.min_time_id is not None:\n    train = train.query(\"time_id>=@args.min_time_id\").reset_index(drop=True)\n    gc.collect()\n    \ntoo_few_time_investment = [1415, 2800]\ntrain=train.loc[~train.investment_id.isin(too_few_time_investment)].reset_index(drop=True)\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:16:11.981427Z","iopub.execute_input":"2022-02-08T14:16:11.981841Z","iopub.status.idle":"2022-02-08T14:17:15.56367Z","shell.execute_reply.started":"2022-02-08T14:16:11.981794Z","shell.execute_reply":"2022-02-08T14:17:15.562559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# StratifiedKFold by time_span: [discussion](https://www.kaggle.com/c/ubiquant-market-prediction/discussion/302429)","metadata":{}},{"cell_type":"code","source":"time_id_df = (\n    train.filter(regex=r\"^(?!f_).*\")\n    .groupby(\"investment_id\")\n    .agg({\"time_id\": [\"min\", \"max\"]})\n    .reset_index()\n)\ntime_id_df[\"time_span\"] = time_id_df[\"time_id\"].diff(axis=1)[\"max\"]\ntime_id_df.head(6)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:17:15.566673Z","iopub.execute_input":"2022-02-08T14:17:15.567042Z","iopub.status.idle":"2022-02-08T14:17:15.628163Z","shell.execute_reply.started":"2022-02-08T14:17:15.566998Z","shell.execute_reply":"2022-02-08T14:17:15.627393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(time_id_df.drop(columns=\"time_id\").droplevel(level=1, axis=1), on=\"investment_id\", how='left')\ntrain.time_span.hist(bins=args.num_bins, figsize=(16,8))\ndel time_id_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:17:15.63219Z","iopub.execute_input":"2022-02-08T14:17:15.632411Z","iopub.status.idle":"2022-02-08T14:17:16.57058Z","shell.execute_reply.started":"2022-02-08T14:17:15.632384Z","shell.execute_reply":"2022-02-08T14:17:16.569655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if args.holdout:\n    _target = pd.cut(train.time_span, args.num_bins, labels=False)\n    _train, _valid = train_test_split(_target, stratify=_target)\n    print(f\"train length: {len(_train)}\", f\"holdout length: {len(_valid)}\")\n    valid = train.iloc[_valid.index].sort_values(by=[\"time_id\", \"investment_id\"]).reset_index(drop=True)\n    train = train.iloc[_train.index].sort_values(by=[\"time_id\", \"investment_id\"]).reset_index(drop=True)\n    train.time_span.hist(bins=args.num_bins, figsize=(16,8), alpha=0.8)\n    valid.time_span.hist(bins=args.num_bins, figsize=(16,8), alpha=0.8)\n    valid.drop(columns=\"time_span\").to_parquet(\"valid.parquet\")\n    del valid, _train, _valid, _target\n    gc.collect()\nassert train.time_id.is_monotonic_increasing, \"time_id not monotonic increasing\"","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:17:16.571626Z","iopub.execute_input":"2022-02-08T14:17:16.571835Z","iopub.status.idle":"2022-02-08T14:17:16.582322Z","shell.execute_reply.started":"2022-02-08T14:17:16.571809Z","shell.execute_reply":"2022-02-08T14:17:16.581419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if args.cv_method==\"stratified\":\n    train[\"fold\"] = -1\n    _target = pd.cut(train.time_span, args.num_bins, labels=False)\n    skf = StratifiedKFold(n_splits=args.folds)\n    for fold, (train_index, valid_index) in enumerate(skf.split(_target, _target)):\n        train.loc[valid_index, 'fold'] = fold\n\n    fig, axs = plt.subplots(nrows=args.folds, ncols=1, sharex=True, figsize=(16,8), tight_layout=True)\n    for ax, (fold, df) in zip(axs, train[[\"fold\", \"time_span\"]].groupby(\"fold\")):\n        ax.hist(df.time_span, bins=args.num_bins)\n        ax.text(0, 40000, f\"fold: {fold}, count: {len(df)}\", fontsize=16)\n    plt.show()\n    del _target, train_index, valid_index\n    _=gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:17:16.583749Z","iopub.execute_input":"2022-02-08T14:17:16.583997Z","iopub.status.idle":"2022-02-08T14:17:16.595194Z","shell.execute_reply.started":"2022-02-08T14:17:16.58397Z","shell.execute_reply":"2022-02-08T14:17:16.594478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features = []\nnum_features = list(train.filter(like=\"f_\").columns)\nfeatures = num_features + cat_features\n\ncombination_features = [\"f_231-f_250\", \"f_118-f_280\", \"f_155-f_297\", \"f_25-f_237\", \"f_179-f_265\", \"f_119-f_270\", \"f_71-f_197\"]\nfor f in combination_features:\n    f1, f2 = f.split(\"-\")\n    train[f] = train[f1] + train[f2]\nfeatures += combination_features\n\nto_drop = [\"f_148\", \"f_72\", \"f_49\", \"f_205\", \"f_228\", \"f_97\", \"f_262\"]\nfeatures = list(sorted(set(features).difference(set(to_drop))))\n\ntrain = reduce_mem_usage(train.drop(columns=\"time_span\"))\ntrain[[\"investment_id\", \"time_id\"]] = train[[\"investment_id\", \"time_id\"]].astype(np.uint16)\ntrain=train.drop(columns=[\"row_id\"]+to_drop)\n\nif args.cv_method==\"stratified\":\n    train[\"fold\"] = train[\"fold\"].astype(np.uint8)\ngc.collect()\n#features += [\"time_id\"] # https://www.kaggle.com/c/ubiquant-market-prediction/discussion/302429\nlen(features)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:17:16.596487Z","iopub.execute_input":"2022-02-08T14:17:16.596855Z","iopub.status.idle":"2022-02-08T14:17:44.211435Z","shell.execute_reply.started":"2022-02-08T14:17:16.596824Z","shell.execute_reply":"2022-02-08T14:17:44.210556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\n# TODO: replace with feval_pearsonr\ndef feval_rmse(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'rmse', rmse(y_true, y_pred), False\n\n# https://www.kaggle.com/c/ubiquant-market-prediction/discussion/302480\ndef feval_pearsonr(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'pearsonr', pearsonr(y_true, y_pred)[0], True\n\ndef objective(trial):    \n    params = {\n        'learning_rate':0.05,\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        'boosting_type': \"gbdt\", #trial.suggest_categorical(\"boosting_type\", [\"dart\", \"gbdt\"]),\n        'verbosity': -1,\n        'n_jobs': -1,\n        'seed': args.seed,\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 18, 128, step=4),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        'n_estimators': 1000, #trial.suggest_int('n_estimators',200,1000),\n        'max_depth': trial.suggest_int('max_depth', -1, 32, step=4),\n        'max_bin':trial.suggest_int('max_bin', 32, 512),\n        'min_data_in_leaf':trial.suggest_int('min_data_in_leaf',8, 512),\n    }\n    \n    y = train['target']\n    train['preds'] = -1000\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"pearsonr\", valid_name='valid_1')\n    scores = []\n    \n    def run_single_fold(fold, trn_ind, val_ind):\n        train_dataset = lgb.Dataset(train.loc[trn_ind, features], y.loc[trn_ind], categorical_feature=cat_features)\n        valid_dataset = lgb.Dataset(train.loc[val_ind, features], y.loc[val_ind], categorical_feature=cat_features)\n        model = lgb.train(\n            params,\n            train_set = train_dataset, \n            valid_sets = [train_dataset, valid_dataset], \n            verbose_eval=0,\n            early_stopping_rounds=50,\n            callbacks=[pruning_callback],\n            feval = feval_pearsonr\n        )\n        preds = model.predict(train.loc[val_ind, features])\n        train.loc[val_ind, \"preds\"] = preds\n        scores.append(rmse(y.loc[val_ind], preds))\n        del train_dataset, valid_dataset, model\n        gc.collect()\n        \n    if args.cv_method==\"stratified\":\n        for fold in range(args.folds):\n            trn_ind, val_ind = train.fold!=fold, train.fold==fold\n            run_single_fold(fold, trn_ind, val_ind)\n    elif args.cv_method==\"time\":\n        tscv = TimeSeriesSplit(args.folds)\n        for fold, (trn_ind, val_ind) in enumerate(tscv.split(train[features])):\n            run_single_fold(fold, trn_ind, val_ind)\n    elif args.cv_method==\"group\":\n        # https://www.kaggle.com/lucamassaron/eda-target-analysis/notebook\n        kfold = GroupKFold(args.folds)\n        for fold, (trn_ind, val_ind) in enumerate(kfold.split(train[features], y, train.time_id)):\n            run_single_fold(fold, trn_ind, val_ind)\n    elif args.cv_method==\"kfold\":\n        kfold = KFold(args.folds)\n        for fold, (trn_ind, val_ind) in enumerate(kfold.split(train[features], train.investment_id)):\n            run_single_fold(fold, trn_ind, val_ind)\n         \n    gc.collect()\n    #return np.mean(scores)\n    df = train[[\"target\", \"preds\", \"time_id\"]].query(\"preds!=-1000\")\n    return df.groupby(\"time_id\").apply(lambda x: pearsonr(x.target, x.preds)[0]).mean()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:17:44.2138Z","iopub.execute_input":"2022-02-08T14:17:44.21405Z","iopub.status.idle":"2022-02-08T14:17:44.23722Z","shell.execute_reply.started":"2022-02-08T14:17:44.214018Z","shell.execute_reply":"2022-02-08T14:17:44.236281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_warmup_steps=25))\nstudy.optimize(objective, timeout=args.timeout)\n\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:17:44.238425Z","iopub.execute_input":"2022-02-08T14:17:44.238664Z","iopub.status.idle":"2022-02-08T14:19:15.445491Z","shell.execute_reply.started":"2022-02-08T14:17:44.238636Z","shell.execute_reply":"2022-02-08T14:19:15.444078Z"},"trusted":true},"execution_count":null,"outputs":[]}]}