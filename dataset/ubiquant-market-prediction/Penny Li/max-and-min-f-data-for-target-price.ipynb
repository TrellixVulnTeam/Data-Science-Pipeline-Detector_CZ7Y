{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import SGDRegressor\nfrom pandas import read_csv\nfrom matplotlib import pyplot\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport time\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom scipy import stats\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import *\nimport warnings\nimport time\n\nimport pickle\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.keras import backend as K\n\nimport math\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    file=open(\"/kaggle/input/ubiquant-market-prediction/train.csv\",\"r\")\n    print(file.readline())\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-20T19:46:35.020081Z","iopub.execute_input":"2022-04-20T19:46:35.021056Z","iopub.status.idle":"2022-04-20T19:46:35.08809Z","shell.execute_reply.started":"2022-04-20T19:46:35.021004Z","shell.execute_reply":"2022-04-20T19:46:35.087062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Exploration**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ubiquant-market-prediction/train.csv\",nrows=100000)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:46:35.093916Z","iopub.execute_input":"2022-04-20T19:46:35.094201Z","iopub.status.idle":"2022-04-20T19:46:43.484367Z","shell.execute_reply.started":"2022-04-20T19:46:35.094171Z","shell.execute_reply":"2022-04-20T19:46:43.483414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation Matrices**","metadata":{}},{"cell_type":"code","source":"corr_matrix = df.corr()\nprint(corr_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:46:43.486474Z","iopub.execute_input":"2022-04-20T19:46:43.486998Z","iopub.status.idle":"2022-04-20T19:47:08.587101Z","shell.execute_reply.started":"2022-04-20T19:46:43.486951Z","shell.execute_reply":"2022-04-20T19:47:08.585932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation Plots**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.matshow(df.corr())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:08.58845Z","iopub.execute_input":"2022-04-20T19:47:08.58869Z","iopub.status.idle":"2022-04-20T19:47:33.754303Z","shell.execute_reply.started":"2022-04-20T19:47:08.588661Z","shell.execute_reply":"2022-04-20T19:47:33.752702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As no obvious correlation exists between any of the F_* data and the target data, I decided to give the max and min values of the F_* data a try, as shown below.","metadata":{}},{"cell_type":"code","source":"df1 = df.drop(df.columns[[0, 1, 2, 3, 4]], axis=1) \ndf1","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:33.757321Z","iopub.execute_input":"2022-04-20T19:47:33.758115Z","iopub.status.idle":"2022-04-20T19:47:33.875003Z","shell.execute_reply.started":"2022-04-20T19:47:33.758081Z","shell.execute_reply":"2022-04-20T19:47:33.873849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=df1.max(axis = 1, skipna = True)\ndf2","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:33.877071Z","iopub.execute_input":"2022-04-20T19:47:33.877422Z","iopub.status.idle":"2022-04-20T19:47:33.989697Z","shell.execute_reply.started":"2022-04-20T19:47:33.877374Z","shell.execute_reply":"2022-04-20T19:47:33.98864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.insert(0, \"Max\", df2, True)\ndf1","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:33.990761Z","iopub.execute_input":"2022-04-20T19:47:33.991482Z","iopub.status.idle":"2022-04-20T19:47:34.039498Z","shell.execute_reply.started":"2022-04-20T19:47:33.99145Z","shell.execute_reply":"2022-04-20T19:47:34.038106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=df1.min(axis = 1, skipna = True)\ndf3","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:34.040816Z","iopub.execute_input":"2022-04-20T19:47:34.041092Z","iopub.status.idle":"2022-04-20T19:47:34.387996Z","shell.execute_reply.started":"2022-04-20T19:47:34.041054Z","shell.execute_reply":"2022-04-20T19:47:34.386929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.insert(0, \"Min\", df3, True)\ndf1","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:34.389343Z","iopub.execute_input":"2022-04-20T19:47:34.389649Z","iopub.status.idle":"2022-04-20T19:47:34.441587Z","shell.execute_reply.started":"2022-04-20T19:47:34.389608Z","shell.execute_reply":"2022-04-20T19:47:34.440623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['target'] = df['target']\ndf1","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:34.442904Z","iopub.execute_input":"2022-04-20T19:47:34.443616Z","iopub.status.idle":"2022-04-20T19:47:34.490843Z","shell.execute_reply.started":"2022-04-20T19:47:34.443578Z","shell.execute_reply":"2022-04-20T19:47:34.489973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport numpy as np\n\nx = df1.Max\ny = df1.target\npyplot.scatter(x, y)\n\nx = df1.Min\ny = df1.target\npyplot.scatter(x, y)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:34.493585Z","iopub.execute_input":"2022-04-20T19:47:34.493831Z","iopub.status.idle":"2022-04-20T19:47:35.421898Z","shell.execute_reply.started":"2022-04-20T19:47:34.493802Z","shell.execute_reply":"2022-04-20T19:47:35.420868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The outter edges of teh above plot forms the boundaries of predicting the target data. For the data points inside the boundaries, I went further to explore the standard deviation between the target date and the mean of the F_* data points.","metadata":{}},{"cell_type":"code","source":"df4=df1.mean(axis = 1, skipna = True)\ndf4","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:35.423281Z","iopub.execute_input":"2022-04-20T19:47:35.423505Z","iopub.status.idle":"2022-04-20T19:47:35.699784Z","shell.execute_reply.started":"2022-04-20T19:47:35.423478Z","shell.execute_reply":"2022-04-20T19:47:35.698612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.insert(0, \"Mean\", df4, True)\ndf1","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:35.7012Z","iopub.execute_input":"2022-04-20T19:47:35.701546Z","iopub.status.idle":"2022-04-20T19:47:35.756953Z","shell.execute_reply.started":"2022-04-20T19:47:35.701504Z","shell.execute_reply":"2022-04-20T19:47:35.755827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['time_id'] = df['time_id']\ndf1","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:35.758621Z","iopub.execute_input":"2022-04-20T19:47:35.759002Z","iopub.status.idle":"2022-04-20T19:47:35.815442Z","shell.execute_reply.started":"2022-04-20T19:47:35.758955Z","shell.execute_reply":"2022-04-20T19:47:35.814088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5 = df1[['Mean', 'target']].std(axis = 1, skipna = True)\ndf5","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:35.816519Z","iopub.execute_input":"2022-04-20T19:47:35.816742Z","iopub.status.idle":"2022-04-20T19:47:36.0107Z","shell.execute_reply.started":"2022-04-20T19:47:35.816714Z","shell.execute_reply":"2022-04-20T19:47:36.010038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.insert(0, \"StdDev\", df5, True)\ndf1","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:36.011768Z","iopub.execute_input":"2022-04-20T19:47:36.012018Z","iopub.status.idle":"2022-04-20T19:47:36.062426Z","shell.execute_reply.started":"2022-04-20T19:47:36.011989Z","shell.execute_reply":"2022-04-20T19:47:36.061428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n! pip install seaborn","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:36.063734Z","iopub.execute_input":"2022-04-20T19:47:36.063971Z","iopub.status.idle":"2022-04-20T19:47:47.527482Z","shell.execute_reply.started":"2022-04-20T19:47:36.063944Z","shell.execute_reply":"2022-04-20T19:47:47.524422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from matplotlib import pyplot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.regplot(x=\"StdDev\", y=\"target\", data=df1)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:47:47.531631Z","iopub.execute_input":"2022-04-20T19:47:47.532055Z","iopub.status.idle":"2022-04-20T19:48:03.59083Z","shell.execute_reply.started":"2022-04-20T19:47:47.532005Z","shell.execute_reply":"2022-04-20T19:48:03.590068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot of the standard deviation of the F_* data and the target data give a potential relatinship that's worth exploring onward, as deivation from the mean in F data contributes to both higher than lower target price.\n\nTo further explore this relationship, below are the plots of time_id against standard deviation of F data and target price respectively.","metadata":{}},{"cell_type":"code","source":"sns.regplot(x=\"time_id\", y=\"StdDev\", data=df1)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:48:03.593127Z","iopub.execute_input":"2022-04-20T19:48:03.593805Z","iopub.status.idle":"2022-04-20T19:48:17.899495Z","shell.execute_reply.started":"2022-04-20T19:48:03.593757Z","shell.execute_reply":"2022-04-20T19:48:17.898806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(x=\"time_id\", y=\"target\", data=df1)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:48:17.900932Z","iopub.execute_input":"2022-04-20T19:48:17.90136Z","iopub.status.idle":"2022-04-20T19:48:32.053619Z","shell.execute_reply.started":"2022-04-20T19:48:17.901311Z","shell.execute_reply":"2022-04-20T19:48:32.052756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DNN_1='../input/ubiquant-dnn-r41-5folds/'\nDNN_2='../input/ubiquant-dnn-r42-5folds/'\nDNN_3='../input/ubiquant-dnn-lonnie/'\nDNN_4='../input/ubiquant-dnn-lonnie-2/'","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:48:32.055025Z","iopub.execute_input":"2022-04-20T19:48:32.05524Z","iopub.status.idle":"2022-04-20T19:48:32.059686Z","shell.execute_reply.started":"2022-04-20T19:48:32.055215Z","shell.execute_reply":"2022-04-20T19:48:32.058773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nn_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:48:32.061691Z","iopub.execute_input":"2022-04-20T19:48:32.062037Z","iopub.status.idle":"2022-04-20T19:48:41.192919Z","shell.execute_reply.started":"2022-04-20T19:48:32.061995Z","shell.execute_reply":"2022-04-20T19:48:41.191436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ninvestment_id = train.pop(\"investment_id\").copy()\ninvestment_ids = list(investment_id.unique())\ninvestment_id_size = len(investment_ids) + 1\ninvestment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\ninvestment_id_lookup_layer.adapt(pd.DataFrame({\"investment_ids\":investment_ids}))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:48:41.19425Z","iopub.execute_input":"2022-04-20T19:48:41.19447Z","iopub.status.idle":"2022-04-20T19:48:41.389657Z","shell.execute_reply.started":"2022-04-20T19:48:41.194443Z","shell.execute_reply":"2022-04-20T19:48:41.388951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n\n    \n    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n\n\n\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:50:17.137115Z","iopub.execute_input":"2022-04-20T19:50:17.137564Z","iopub.status.idle":"2022-04-20T19:50:17.15537Z","shell.execute_reply.started":"2022-04-20T19:50:17.137521Z","shell.execute_reply":"2022-04-20T19:50:17.154437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlation(x, y, axis=-2):\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n    x = tf.convert_to_tensor(x)\n    y = math_ops.cast(y, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return tf.constant(1.0, dtype=x.dtype) - corr\n\ndef get_model2():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dropout(0.1)(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dropout(0.1)(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dropout(0.1)(investment_id_x)\n    \n    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n    feature_x = layers.Dropout(0.1)(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dropout(0.1)(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dropout(0.1)(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dropout(0.1)(x)\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse, correlation])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:53:06.464095Z","iopub.execute_input":"2022-04-20T19:53:06.464989Z","iopub.status.idle":"2022-04-20T19:53:06.487558Z","shell.execute_reply.started":"2022-04-20T19:53:06.464932Z","shell.execute_reply":"2022-04-20T19:53:06.486335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model3():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    \n    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse, correlation])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:53:36.187556Z","iopub.execute_input":"2022-04-20T19:53:36.188379Z","iopub.status.idle":"2022-04-20T19:53:36.201918Z","shell.execute_reply.started":"2022-04-20T19:53:36.188328Z","shell.execute_reply":"2022-04-20T19:53:36.200973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:53:52.52653Z","iopub.execute_input":"2022-04-20T19:53:52.526913Z","iopub.status.idle":"2022-04-20T19:53:52.732201Z","shell.execute_reply.started":"2022-04-20T19:53:52.526874Z","shell.execute_reply":"2022-04-20T19:53:52.731276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodels=[]\nfor index in range(5):\n    model=get_model()\n    model = keras.models.load_model(DNN_1+f\"model_{index}\")\n#    models.append(model)\n    \nfor index in range(5):\n    model=get_model()\n    model = keras.models.load_model(DNN_2+f\"model_{index}\")\n#    models.append(model)\n    \nfor index in range(5):\n    model=get_model2()\n    model.load_weights(DNN_3+f\"model_{index}.tf\")\n    models.append(model)\n    \nfor index in range(5):\n    model=get_model3()\n    model.load_weights(DNN_4+f\"model_{index}.tf\")\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:54:26.732424Z","iopub.execute_input":"2022-04-20T19:54:26.732787Z","iopub.status.idle":"2022-04-20T19:54:46.979272Z","shell.execute_reply.started":"2022-04-20T19:54:26.73275Z","shell.execute_reply":"2022-04-20T19:54:46.978508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test(investment_id, feature):\n    return (investment_id, feature), 0\ndef make_test_dataset(feature, investment_id, batch_size=1024):\n    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature)))\n    ds = ds.map(preprocess_test)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\ndef inference(models, ds):\n    y_preds = []\n    for model in models:\n        y_pred = model.predict(ds)\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:55:26.92049Z","iopub.execute_input":"2022-04-20T19:55:26.920784Z","iopub.status.idle":"2022-04-20T19:55:26.929401Z","shell.execute_reply.started":"2022-04-20T19:55:26.920755Z","shell.execute_reply":"2022-04-20T19:55:26.928009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test() \nfor (test_df, sample_prediction_df) in iter_test:\n    ds = make_test_dataset(test_df[features], test_df[\"investment_id\"])\n    sample_prediction_df['target'] = inference(models, ds)\n    env.predict(sample_prediction_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv(\"./submission.csv\")\nsubmission","metadata":{},"execution_count":null,"outputs":[]}]}