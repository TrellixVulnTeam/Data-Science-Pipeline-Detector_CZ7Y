{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom tqdm import tqdm\nimport os \nimport glob\ntqdm.pandas()\nimport matplotlib.pyplot as plt\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:27:31.441409Z","iopub.execute_input":"2022-03-07T09:27:31.441963Z","iopub.status.idle":"2022-03-07T09:27:32.214089Z","shell.execute_reply.started":"2022-03-07T09:27:31.441925Z","shell.execute_reply":"2022-03-07T09:27:32.213361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Welcome to the Notebook on challenge Ubiquant Market Prediction. I hope you enjoy the Tutorial. **(WORK IN PROGRESS)**","metadata":{}},{"cell_type":"markdown","source":"![tf2](https://blogger.googleusercontent.com/img/a/AVvXsEhCZhxqPJb0_Qa4DD8pRS65AmohKJL49y9kMRGj1tADlHxteSKQjUovAZohPop-ej9dfw-Z4_vKyq4aS8Smvro2aSDWmLq3LzwEmfICqTf3ipmSPiWAjix1fSddgyLoajK2y387-pi1r_aRiE3FEH0L_hu-CEboaAloznbVw9aroBzJPmJWfAuhzVGu)","metadata":{}},{"cell_type":"markdown","source":"Content:\n\n1. **Reducing the Size of dataset by bringing every attribute to the correct datatype and saving them in pickle chunks.**\n2. **Loading the reduced version in the memory.**\n3. **Trying to explore some of the variables**\n4. **Finding Variables which are correlated to the target variable.**\n5. **Create tensorflow data API which can be effectively passed to the model for training.**\n6. **Defining the Architecture of the Model**\n7. **Defining the callbacks.**\n8. **Finally training the model.**","metadata":{}},{"cell_type":"markdown","source":"**LETS START BY DEFINING SOME OF THE PATHS******","metadata":{}},{"cell_type":"code","source":"train_path = \"../input/ubiquant-market-prediction/train.csv\"\ntest_path = \"../input/ubiquant-market-prediction/example_test.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:46:11.206325Z","iopub.execute_input":"2022-03-07T08:46:11.206935Z","iopub.status.idle":"2022-03-07T08:46:11.210378Z","shell.execute_reply.started":"2022-03-07T08:46:11.206892Z","shell.execute_reply":"2022-03-07T08:46:11.209657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets try to reduce down the **dataset** first !! The code is pretty self understandable :)","metadata":{}},{"cell_type":"code","source":"# Lets first try to reduce the size of the dataframe by bringing it to right dtype and saving those chunks.\n\ndef reduce_memory_usage(df, chunk):\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    print(\"Initial Memory chunk: {:.3f}\".format(start_mem))\n    \n    for col in df.columns:\n        type_ = df[col].dtype\n        \n        if str(type_) != \"object\":\n            if str(type_)[:3] == \"int\":\n                min_ = df[col].min()\n                max_ = df[col].max()\n\n                if min_ > np.iinfo(np.int8).min and max_ < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif min_ > np.iinfo(np.int16).min and max_ < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif min_ > np.iinfo(np.int32).min and max_ < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                else:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if min_ > np.finfo(np.float16).min and max_ < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif min_ > np.finfo(np.float32).min and max_ < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n    \n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    print(\"Final Memory chunk: {:.3f}\".format(end_mem))\n    print(\"Reduced by: {:.2f}\".format((start_mem - end_mem) / start_mem))\n    \n    df.to_pickle(f\"chunk_{chunk}.pkl\")\n    print(f\"chunk_{chunk}.pkl\",\"saved!\")\n                    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:46:11.741622Z","iopub.execute_input":"2022-03-07T08:46:11.742245Z","iopub.status.idle":"2022-03-07T08:46:11.755985Z","shell.execute_reply.started":"2022-03-07T08:46:11.742211Z","shell.execute_reply":"2022-03-07T08:46:11.754724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since the dataset is very huge, reading it in chunks of shown size and processing every chunk seperately.**","metadata":{}},{"cell_type":"code","source":"gc.collect()\nchunksize = 10 ** 6\n\nfor chunk_id, chunk in enumerate(pd.read_csv(train_path, chunksize=chunksize)):\n    reduce_memory_usage(chunk, chunk_id)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:46:12.571559Z","iopub.execute_input":"2022-03-07T08:46:12.57206Z","iopub.status.idle":"2022-03-07T08:58:23.344123Z","shell.execute_reply.started":"2022-03-07T08:46:12.572025Z","shell.execute_reply":"2022-03-07T08:58:23.342495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since the dataset is drastically reduced lets try to concatenate everything in one frame****","metadata":{}},{"cell_type":"code","source":"appended_list = []\npath = glob.glob(os.path.join(os.curdir, \"chunk_*.pkl\"), recursive=True)\n\nfor item in tqdm(path):\n    df = pd.read_pickle(item)\n    appended_list.append(df)\n    \nfinal_frame = pd.concat(appended_list, axis = 0, ignore_index=True)    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:58:23.345926Z","iopub.execute_input":"2022-03-07T08:58:23.346216Z","iopub.status.idle":"2022-03-07T08:58:28.236169Z","shell.execute_reply.started":"2022-03-07T08:58:23.346167Z","shell.execute_reply":"2022-03-07T08:58:28.235399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_frame.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:03:14.474653Z","iopub.execute_input":"2022-03-07T09:03:14.475165Z","iopub.status.idle":"2022-03-07T09:05:45.171699Z","shell.execute_reply.started":"2022-03-07T09:03:14.475126Z","shell.execute_reply":"2022-03-07T09:05:45.170963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_frame.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:05:45.173362Z","iopub.execute_input":"2022-03-07T09:05:45.173788Z","iopub.status.idle":"2022-03-07T09:05:45.200066Z","shell.execute_reply.started":"2022-03-07T09:05:45.173749Z","shell.execute_reply":"2022-03-07T09:05:45.199401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets try to do some EDA here!!**","metadata":{}},{"cell_type":"code","source":"def plot_counts(dataframe, name = None,bins = 1000):\n    dataframe.value_counts().sort_index().plot(kind = \"hist\", bins = bins, density = True)\n    plt.xlabel(\"Instance\")\n    if name:\n        plt.title(name, fontsize=12)\n    plt.ylabel(\"Unique Count\")\n    plt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:05:45.201082Z","iopub.execute_input":"2022-03-07T09:05:45.201467Z","iopub.status.idle":"2022-03-07T09:05:45.207213Z","shell.execute_reply.started":"2022-03-07T09:05:45.201431Z","shell.execute_reply":"2022-03-07T09:05:45.206473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int_col = [col for col in final_frame.columns if 'int' in str(final_frame[col].dtype)]\nint_col","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:05:45.209452Z","iopub.execute_input":"2022-03-07T09:05:45.209846Z","iopub.status.idle":"2022-03-07T09:05:45.222048Z","shell.execute_reply.started":"2022-03-07T09:05:45.209789Z","shell.execute_reply":"2022-03-07T09:05:45.220775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets Visualize them\nplt.rcParams[\"figure.figsize\"] = (16, 8)\nplt.subplot(1, 2, 1)\nplot_counts(final_frame[int_col[0]], name = int_col[0], bins = 5**2)\nplt.subplot(1, 2, 2)\nplot_counts(final_frame[int_col[1]], name = int_col[1], bins = 5**2)\n\nplt.subplots_adjust(wspace=0.8, hspace=0.8)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:05:45.224923Z","iopub.execute_input":"2022-03-07T09:05:45.225117Z","iopub.status.idle":"2022-03-07T09:05:45.744874Z","shell.execute_reply.started":"2022-03-07T09:05:45.225094Z","shell.execute_reply":"2022-03-07T09:05:45.744236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_frame.drop([\"row_id\"], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:05:45.746035Z","iopub.execute_input":"2022-03-07T09:05:45.746785Z","iopub.status.idle":"2022-03-07T09:05:48.820592Z","shell.execute_reply.started":"2022-03-07T09:05:45.746747Z","shell.execute_reply":"2022-03-07T09:05:48.819782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = final_frame[\"target\"].values\nfinal_frame.drop([\"target\"], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:05:48.8219Z","iopub.execute_input":"2022-03-07T09:05:48.822134Z","iopub.status.idle":"2022-03-07T09:05:52.005227Z","shell.execute_reply.started":"2022-03-07T09:05:48.822102Z","shell.execute_reply":"2022-03-07T09:05:52.004476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (8,8))\nsns.kdeplot(target, ax = ax, shade=True)\nax.set_xlabel(\"Target Distribution\")\nax.set_ylabel(\"Density\")","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:30:44.169269Z","iopub.execute_input":"2022-03-07T09:30:44.169738Z","iopub.status.idle":"2022-03-07T09:30:59.784037Z","shell.execute_reply.started":"2022-03-07T09:30:44.169699Z","shell.execute_reply":"2022-03-07T09:30:59.783265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LETS SEE THE **DISTRIBUTION** OF THE VARIABLES","metadata":{}},{"cell_type":"code","source":"def plot_me(data):\n    # Lets plot these \n    plt.figure(figsize = (30, 30))\n    n_rows = 5\n    n_cols = 6\n\n    \n    for idx, col in enumerate(data.columns):\n        ax = plt.subplot(n_rows, n_cols, idx+1)\n        sns.kdeplot(data[col], ax=ax, fill=True)\n        ax.grid(\"True\")\n        ax.set_xlabel(col)\n        ax.set_ylabel(\"Density\")\n\n    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:37:55.576886Z","iopub.execute_input":"2022-03-07T09:37:55.577367Z","iopub.status.idle":"2022-03-07T09:37:55.584048Z","shell.execute_reply.started":"2022-03-07T09:37:55.577326Z","shell.execute_reply":"2022-03-07T09:37:55.583242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = final_frame.columns[2:]\nplot_me(final_frame.loc[:,columns[:30]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:40:05.308981Z","iopub.execute_input":"2022-03-07T09:40:05.309261Z","iopub.status.idle":"2022-03-07T09:47:58.627178Z","shell.execute_reply.started":"2022-03-07T09:40:05.309227Z","shell.execute_reply":"2022-03-07T09:47:58.626557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[30:60]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:56:46.957894Z","iopub.execute_input":"2022-03-07T09:56:46.958185Z","iopub.status.idle":"2022-03-07T10:04:41.067774Z","shell.execute_reply.started":"2022-03-07T09:56:46.958136Z","shell.execute_reply":"2022-03-07T10:04:41.066971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[60:90]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:04:41.069522Z","iopub.execute_input":"2022-03-07T10:04:41.07002Z","iopub.status.idle":"2022-03-07T10:12:33.942826Z","shell.execute_reply.started":"2022-03-07T10:04:41.069982Z","shell.execute_reply":"2022-03-07T10:12:33.941481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[90:120]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:12:33.94432Z","iopub.execute_input":"2022-03-07T10:12:33.94476Z","iopub.status.idle":"2022-03-07T10:20:27.776821Z","shell.execute_reply.started":"2022-03-07T10:12:33.944724Z","shell.execute_reply":"2022-03-07T10:20:27.775336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[120:150]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:20:27.778926Z","iopub.execute_input":"2022-03-07T10:20:27.779449Z","iopub.status.idle":"2022-03-07T10:28:19.944879Z","shell.execute_reply.started":"2022-03-07T10:20:27.779395Z","shell.execute_reply":"2022-03-07T10:28:19.944244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[150:180]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:28:19.946108Z","iopub.execute_input":"2022-03-07T10:28:19.946868Z","iopub.status.idle":"2022-03-07T10:36:12.381904Z","shell.execute_reply.started":"2022-03-07T10:28:19.94683Z","shell.execute_reply":"2022-03-07T10:36:12.381259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[180:210]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:36:12.383132Z","iopub.execute_input":"2022-03-07T10:36:12.383538Z","iopub.status.idle":"2022-03-07T10:44:04.169985Z","shell.execute_reply.started":"2022-03-07T10:36:12.383501Z","shell.execute_reply":"2022-03-07T10:44:04.169314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[210:240]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:44:04.171528Z","iopub.execute_input":"2022-03-07T10:44:04.172006Z","iopub.status.idle":"2022-03-07T10:51:57.722884Z","shell.execute_reply.started":"2022-03-07T10:44:04.171967Z","shell.execute_reply":"2022-03-07T10:51:57.722258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[240:270]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:51:57.724339Z","iopub.execute_input":"2022-03-07T10:51:57.724771Z","iopub.status.idle":"2022-03-07T10:59:49.916909Z","shell.execute_reply.started":"2022-03-07T10:51:57.724736Z","shell.execute_reply":"2022-03-07T10:59:49.916279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_me(final_frame.loc[:,columns[270:]])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T10:59:49.918478Z","iopub.execute_input":"2022-03-07T10:59:49.918926Z","iopub.status.idle":"2022-03-07T11:07:41.474938Z","shell.execute_reply.started":"2022-03-07T10:59:49.918888Z","shell.execute_reply":"2022-03-07T11:07:41.474295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets see if there are some features which are correlated to our **target variable****","metadata":{}},{"cell_type":"code","source":"# Lets check which features are correlated to the target variable\n\ncorrelation = []\n\nfor col in tqdm(final_frame.columns):\n    pearson_relation = np.corrcoef(target, final_frame[col])[0,1]\n    correlation.append(pearson_relation)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T09:07:41.615894Z","iopub.execute_input":"2022-03-07T09:07:41.616141Z","iopub.status.idle":"2022-03-07T09:07:55.445253Z","shell.execute_reply.started":"2022-03-07T09:07:41.616112Z","shell.execute_reply":"2022-03-07T09:07:55.444554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Turns out that the target variable is not much linearly correlated to any of the given features.\n\nThe below plot shows that maximum correlation goes only till 0.05(max)","metadata":{}},{"cell_type":"markdown","source":"WE will do more EDA Section here..........\n**But lets start to do Learning stuff !!**","metadata":{}},{"cell_type":"markdown","source":"**Deep Learning**","metadata":{}},{"cell_type":"markdown","source":"![tf2](https://www.marketing-branding.com/wp-content/uploads/2020/05/tensorflow-beneficios.jpg)","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:15:14.889317Z","iopub.execute_input":"2022-03-03T10:15:14.88963Z","iopub.status.idle":"2022-03-03T10:15:15.716696Z","shell.execute_reply.started":"2022-03-03T10:15:14.889593Z","shell.execute_reply":"2022-03-03T10:15:15.715898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We need to install right tensorflow version according to CUDA requirements**","metadata":{}},{"cell_type":"code","source":"!pip uninstall tensorflow -y","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:15:15.718209Z","iopub.execute_input":"2022-03-03T10:15:15.718732Z","iopub.status.idle":"2022-03-03T10:15:32.911346Z","shell.execute_reply.started":"2022-03-03T10:15:15.718669Z","shell.execute_reply":"2022-03-03T10:15:32.910388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-gpu==2.4.0","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:15:32.913082Z","iopub.execute_input":"2022-03-03T10:15:32.913693Z","iopub.status.idle":"2022-03-03T10:16:48.081132Z","shell.execute_reply.started":"2022-03-03T10:15:32.913647Z","shell.execute_reply":"2022-03-03T10:16:48.079951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# To ignore some of the warnings","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:16:48.082876Z","iopub.execute_input":"2022-03-03T10:16:48.083165Z","iopub.status.idle":"2022-03-03T10:16:50.837496Z","shell.execute_reply.started":"2022-03-03T10:16:48.083126Z","shell.execute_reply":"2022-03-03T10:16:50.836758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Lets Split the dataset into train and validation set.***","metadata":{}},{"cell_type":"code","source":"def split_set_index(data, size):\n        train_size = int(len(data) * size)\n        index = tf.random.shuffle(tf.range(len(data)))\n        return index[:train_size], index[train_size:]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T10:16:50.838812Z","iopub.execute_input":"2022-03-03T10:16:50.839054Z","iopub.status.idle":"2022-03-03T10:16:50.84696Z","shell.execute_reply.started":"2022-03-03T10:16:50.839012Z","shell.execute_reply":"2022-03-03T10:16:50.846408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_idx, val_idx = split_set_index(final_frame.values, size=0.8)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T10:16:50.847788Z","iopub.execute_input":"2022-03-03T10:16:50.848106Z","iopub.status.idle":"2022-03-03T10:16:58.150825Z","shell.execute_reply.started":"2022-03-03T10:16:50.848077Z","shell.execute_reply":"2022-03-03T10:16:58.150003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataloader : There are two different ways for generating the data. Both are shown.\n\n1. **Keras Generator Sequence**\n2. **Tensorflow Data API**","metadata":{}},{"cell_type":"markdown","source":"Lets first create a **Keras Generator** which generates batch of data\n\nFor learning more on tf2 data api refer [here](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)","metadata":{}},{"cell_type":"code","source":"class Keras_Dataloader(tf.keras.utils.Sequence):\n    def __init__(self, data, batchsize = 16):\n        self.data = data\n        self.index = np.arange(len(self.data))\n        self.batchsize = batchsize\n        \n    def on_epoch_end(self):              # Always called at end of each epoch. HEre we simply shuffle the data\n        self.data = tf.random.shuffle(self.data)\n    \n    def __len__(self):                    # Returns the number of element in a batch\n        return int(np.floor(len(self.data) / self.batchsize))\n    \n    def __getitem__(self, idx):           # Returns the elements of a batch.\n        index = self.index[idx * self.batchsize : self.batchsize * (idx + 1)]\n        id_ = [self.data[k] for k in index]\n        \n        X, Y = self.return_elements(id_)\n        return X, Y\n    \n    def return_elements(self, idx):            # Helper FUnction\n        \n        x_batch = final_frame.iloc[idx,:].values\n        y_batch = target[idx]\n        \n        return np.asarray(x_batch, dtype=np.float32), np.asarray(y_batch, dtype=np.float16)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:16:58.152258Z","iopub.execute_input":"2022-03-03T10:16:58.152507Z","iopub.status.idle":"2022-03-03T10:16:58.162156Z","shell.execute_reply.started":"2022-03-03T10:16:58.152472Z","shell.execute_reply":"2022-03-03T10:16:58.160557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets see how to build the same thing using **Tensorflow Data API**","metadata":{}},{"cell_type":"code","source":"class Dataloader:\n    \n    def __init__(self, train, val,batchsize = 16, buffersize = 8):\n        self.batchsize = batchsize\n        self.buffersize = buffersize\n        self.train = tf.data.Dataset.from_tensor_slices(train)\n        self.val = tf.data.Dataset.from_tensor_slices(val)\n        \n        \n    def weiter_process(self, instance):\n        idx = instance.numpy()\n        instance = final_frame.iloc[idx].values\n        label = target[idx]\n        \n        # Any other preprocessing here if needs to be done\n        \n        return tf.cast(instance, dtype=tf.float32), tf.cast(label, dtype=tf.float16)\n    \n    def process(self, instance):  # Since eager tensor is passed to work on it we call tf.py_function and work on instance\n        instance, label = tf.py_function(self.weiter_process, [instance],[tf.float32, tf.float16])\n        return instance, label\n        \n    def create_loader(self, dataset):\n        \n        # NOte here map function maps every instance of data to first go through the function process and then does remaining on its output\n        dataset = dataset.map(self.process, num_parallel_calls=tf.data.AUTOTUNE)\n        \n        # then we cache the data, shuffle it and batch it \n        dataset = dataset.cache().shuffle(self.buffersize).batch(self.batchsize).repeat(1)\n        \n        # prefetching means during the process start to prepare the next batch \n        dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n        return dataset\n        \n    def return_loaders(self):\n        train_loader = self.create_loader(self.train)\n        val_loader = self.create_loader(self.val)\n        return train_loader, val_loader\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:16:58.163811Z","iopub.execute_input":"2022-03-03T10:16:58.164398Z","iopub.status.idle":"2022-03-03T10:16:58.175234Z","shell.execute_reply.started":"2022-03-03T10:16:58.164358Z","shell.execute_reply":"2022-03-03T10:16:58.174493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# COnfigurations to be used, Uncomment BUFFERSIZE If you want to use tensorflow data api\n\nBATCHSIZE = 32\n#BUFFERSIZE = 8\nEPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:16:58.176505Z","iopub.execute_input":"2022-03-03T10:16:58.177911Z","iopub.status.idle":"2022-03-03T10:16:58.18652Z","shell.execute_reply.started":"2022-03-03T10:16:58.177872Z","shell.execute_reply":"2022-03-03T10:16:58.185845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For Keras Generator**: Lets use Keras generator API for it","metadata":{}},{"cell_type":"code","source":"gc.collect()\ntrain_loader = Keras_Dataloader(data=train_idx, batchsize=BATCHSIZE)\nval_loader = Keras_Dataloader(data=val_idx, batchsize=BATCHSIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:16:58.187472Z","iopub.execute_input":"2022-03-03T10:16:58.187704Z","iopub.status.idle":"2022-03-03T10:16:58.361787Z","shell.execute_reply.started":"2022-03-03T10:16:58.18767Z","shell.execute_reply":"2022-03-03T10:16:58.360864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For Tensorflow DATA API**","metadata":{}},{"cell_type":"code","source":"\"\"\"gc.collect()\ndataloader = Dataloader(train = train_idx, val = val_idx, batchsize=BATCHSIZE, buffersize=BUFFERSIZE)\ntrain_loader_tf, val_loader_tf = dataloader.return_loaders()\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:16:58.363198Z","iopub.execute_input":"2022-03-03T10:16:58.363447Z","iopub.status.idle":"2022-03-03T10:16:58.369439Z","shell.execute_reply.started":"2022-03-03T10:16:58.363415Z","shell.execute_reply":"2022-03-03T10:16:58.368555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for X,Y in train_loader:\n    print(X.shape)\n    print(Y.shape)\n    break\n    \n# FOr tensorflow data api \n\"\"\"    \nfor X,Y in train_loader.take(1):\n    print(X.shape)\n    print(Y.shape)\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:16:58.371099Z","iopub.execute_input":"2022-03-03T10:16:58.371666Z","iopub.status.idle":"2022-03-03T10:16:58.400151Z","shell.execute_reply.started":"2022-03-03T10:16:58.371624Z","shell.execute_reply":"2022-03-03T10:16:58.399323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets define normal Sequential model. Everything is self understood**","metadata":{}},{"cell_type":"code","source":"# Lets define a Sequential Model\n\ninput_shape = final_frame.iloc[0].values.shape\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape = input_shape),\n    tf.keras.layers.Dropout(rate = 0.8),model.compile(loss=tf.keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adam())\n    tf.keras.layers.Dense(400, activation=tf.keras.activations.relu),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate = 0.5),\n    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate = 0.5),\n    tf.keras.layers.Dense(750, activation=tf.keras.activations.relu),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate = 0.5),\n    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate = 0.5),\n    tf.keras.layers.Dense(400, activation=tf.keras.activations.relu),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate = 0.5),\n    tf.keras.layers.Dense(128, activation=tf.keras.activations.relu),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate = 0.5),\n    tf.keras.layers.Dense(8, activation=tf.keras.activations.relu),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate = 0.3),\n    tf.keras.layers.Dense(1)\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T11:14:26.82793Z","iopub.execute_input":"2022-03-03T11:14:26.828415Z","iopub.status.idle":"2022-03-03T11:14:26.990756Z","shell.execute_reply.started":"2022-03-03T11:14:26.828376Z","shell.execute_reply":"2022-03-03T11:14:26.990052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T11:14:29.967226Z","iopub.execute_input":"2022-03-03T11:14:29.967502Z","iopub.status.idle":"2022-03-03T11:14:30.452643Z","shell.execute_reply.started":"2022-03-03T11:14:29.967473Z","shell.execute_reply":"2022-03-03T11:14:30.451902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining Callbacks.**\n\nTo learn more refer [here](https://www.tensorflow.org/guide/keras/custom_callback)","metadata":{}},{"cell_type":"markdown","source":"Callbacks: There are some callbacks that you can use directly like Earlystop and Checkpoints. But tensorflow also have the option to define custom callbacks which I used here for Onecycle,Exponential Schedule and ResultCallback. How to define custom callbacks ? Ok let me break it down.\n\nFor creating custom callback you need to subclass **tf.keras.callbacks.Callback** class.\nNow you have predefined function like\n\n**on_(train|test|predict)begin(self, logs=None)**, **on(train|test|predict)end(self, logs=None)**,**on(train|test|predict)_batch_begin(self, batch, logs=None)**,etc... \n\nNow every function is either called at the (beginning/end) of (batch/epoch/train/test/predict) this depends on which you are using. All we gotta do is manipulate the function accordingly.","metadata":{}},{"cell_type":"code","source":"K = tf.keras.backend\nclass Track_Progress(tf.keras.callbacks.Callback):\n    def __init__(self,**kwargs):\n        super().__init__(**kwargs)\n        self.loss = []\n        self.val_loss = []\n        self.epoch = []\n        self.lr = []\n    def on_epoch_end(self, epoch, logs=None):\n        self.loss.append(logs[\"loss\"])\n        self.val_loss.append(logs[\"val_loss\"])\n        self.lr.append(K.get_value(self.model.optimizer.lr))\n        self.epoch.append(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T11:14:36.828966Z","iopub.execute_input":"2022-03-03T11:14:36.829288Z","iopub.status.idle":"2022-03-03T11:14:36.836948Z","shell.execute_reply.started":"2022-03-03T11:14:36.829252Z","shell.execute_reply":"2022-03-03T11:14:36.836125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets define some callbacks\ndef give_id(path):\n    import time\n    id_ = time.strftime(\"run_%Y_%m_%D_%H_%M_%S\")\n    return os.path.join(path, id_)\n\n\nlogdir = give_id(os.curdir)\ntensorboard = tf.keras.callbacks.TensorBoard(log_dir = logdir)\nearlystop = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\nmodelcheckpoint_best = tf.keras.callbacks.ModelCheckpoint(filepath=os.curdir, save_best_only=True,save_weights_only=True)\nmodelcheckpoint_last = tf.keras.callbacks.ModelCheckpoint(filepath=os.curdir, save_best_only=False,save_weights_only=True)\ntracker = Track_Progress()\n\nCallbacks = [tensorboard, earlystop, modelcheckpoint_best, modelcheckpoint_best, tracker]","metadata":{"execution":{"iopub.status.busy":"2022-03-03T11:14:39.773699Z","iopub.execute_input":"2022-03-03T11:14:39.774152Z","iopub.status.idle":"2022-03-03T11:14:40.034179Z","shell.execute_reply.started":"2022-03-03T11:14:39.774113Z","shell.execute_reply":"2022-03-03T11:14:40.033314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adam())","metadata":{"execution":{"iopub.status.busy":"2022-03-03T11:14:47.396358Z","iopub.execute_input":"2022-03-03T11:14:47.396925Z","iopub.status.idle":"2022-03-03T11:14:47.416599Z","shell.execute_reply.started":"2022-03-03T11:14:47.396878Z","shell.execute_reply":"2022-03-03T11:14:47.415839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(generator=train_loader, validation_data=val_loader, callbacks=Callbacks, epochs=EPOCHS, use_multiprocessing=True, workers=-1, shuffle=False, max_queue_size=10, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T11:14:57.331918Z","iopub.execute_input":"2022-03-03T11:14:57.332577Z","iopub.status.idle":"2022-03-03T13:53:31.286855Z","shell.execute_reply.started":"2022-03-03T11:14:57.332534Z","shell.execute_reply":"2022-03-03T13:53:31.286049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"model.fit(train_loader, epochs=EPOCHS, validation_data=val_loader, callbacks=[tensorboard, earlystop, modelcheckpoint_best, modelcheckpoint_best, tracker],\n         verbose=1)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-03-03T10:51:30.360986Z","iopub.status.idle":"2022-03-03T10:51:30.361645Z","shell.execute_reply.started":"2022-03-03T10:51:30.361387Z","shell.execute_reply":"2022-03-03T10:51:30.361412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8, 8))\nval_loss = tracker.val_loss\ntrain_loss = tracker.loss\nepoch = tracker.epoch\n\nplt.plot(epoch, val_loss)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:01:49.307328Z","iopub.execute_input":"2022-03-03T14:01:49.307579Z","iopub.status.idle":"2022-03-03T14:01:49.497271Z","shell.execute_reply.started":"2022-03-03T14:01:49.307551Z","shell.execute_reply":"2022-03-03T14:01:49.496584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8, 8))\nplt.plot(epoch, train_loss)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Training Loss\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:01:54.466332Z","iopub.execute_input":"2022-03-03T14:01:54.469575Z","iopub.status.idle":"2022-03-03T14:01:54.897265Z","shell.execute_reply.started":"2022-03-03T14:01:54.469519Z","shell.execute_reply":"2022-03-03T14:01:54.896527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets train a bit more using a smaller learning rate\n\nmodel.compile(loss=tf.keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-4))\nmodel.fit_generator(generator=train_loader, validation_data=val_loader, callbacks=Callbacks, epochs=5, use_multiprocessing=True, workers=-1, shuffle=False, max_queue_size=10, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:04:17.582445Z","iopub.execute_input":"2022-03-03T14:04:17.582836Z","iopub.status.idle":"2022-03-03T15:24:09.198351Z","shell.execute_reply.started":"2022-03-03T14:04:17.582793Z","shell.execute_reply":"2022-03-03T15:24:09.197613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"trained_model.h5\")\n\nimport json\nmodel_json = model.to_json()\nwith open(os.path.join(os.curdir,\"model_graph.json\"), \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:51:47.26846Z","iopub.execute_input":"2022-03-03T15:51:47.269243Z","iopub.status.idle":"2022-03-03T15:51:47.383639Z","shell.execute_reply.started":"2022-03-03T15:51:47.269202Z","shell.execute_reply":"2022-03-03T15:51:47.382936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:44:59.903188Z","iopub.execute_input":"2022-03-03T15:44:59.903932Z","iopub.status.idle":"2022-03-03T15:45:03.554249Z","shell.execute_reply.started":"2022-03-03T15:44:59.903885Z","shell.execute_reply":"2022-03-03T15:45:03.553396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![Work in Progress](https://t4.ftcdn.net/jpg/04/33/46/65/360_F_433466592_JpXOCCvbV3kMKTWo3jZKhGBnqEafnmfw.jpg)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}