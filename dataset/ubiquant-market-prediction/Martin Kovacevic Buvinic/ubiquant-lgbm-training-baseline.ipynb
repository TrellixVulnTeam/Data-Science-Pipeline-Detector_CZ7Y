{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import GroupKFold\nimport lightgbm as lgb\nfrom tqdm.notebook import tqdm\nimport random\nimport joblib\nimport warnings\nimport gc\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 100)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T13:59:57.834232Z","iopub.execute_input":"2022-01-28T13:59:57.834725Z","iopub.status.idle":"2022-01-28T13:59:59.951503Z","shell.execute_reply.started":"2022-01-28T13:59:57.834618Z","shell.execute_reply":"2022-01-28T13:59:59.950624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Seed \nMODEL_SEED = 42\n# Learning rate\nLR = 0.05\n# Folds\nFOLDS = 5","metadata":{"execution":{"iopub.status.busy":"2022-01-28T13:59:59.953076Z","iopub.execute_input":"2022-01-28T13:59:59.953327Z","iopub.status.idle":"2022-01-28T13:59:59.958035Z","shell.execute_reply.started":"2022-01-28T13:59:59.953297Z","shell.execute_reply":"2022-01-28T13:59:59.956735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n# Calculate pearson correlation coefficient\ndef pearson_coef(data):\n    return data.corr()['target']['prediction']\n\n# Calculate mean pearson correlation coefficient\ndef comp_metric(valid_df):\n    return np.mean(valid_df.groupby(['time_id']).apply(pearson_coef))\n\n# Function to train and evaluate\ndef train_and_evaluate():\n    # Seed everything\n    seed_everything(MODEL_SEED)\n    # Read data\n    train = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\n    # Feature list\n    features = [col for col in train.columns if col not in ['row_id', 'time_id', 'investment_id', 'target']]\n    # Some feature engineering\n    # Get the correlations with the target to encode time_id\n    corr1 = train[features[0:100] + ['target']].corr()['target'].reset_index()\n    corr2 = train[features[100:200] + ['target']].corr()['target'].reset_index()\n    corr3 = train[features[200:] + ['target']].corr()['target'].reset_index()\n    corr = pd.concat([corr1, corr2, corr3], axis = 0, ignore_index = True)\n    corr['target'] = abs(corr['target'])\n    corr.sort_values('target', ascending = False, inplace = True)\n    best_corr = corr.iloc[3:103, 0].to_list()\n    del corr1, corr2, corr3, corr\n    # Add time id related features (market general features to relate time_ids)\n    time_id_features = []\n    for col in tqdm(best_corr):\n        mapper = train.groupby(['time_id'])[col].mean().to_dict()\n        train[f'time_id_{col}'] = train['time_id'].map(mapper)\n        train[f'time_id_{col}'] = train[f'time_id_{col}'].astype(np.float16)\n        time_id_features.append(f'time_id_{col}')\n    print(f'We added {len(time_id_features)} features related to time_id')\n    # Update feature list\n    features += time_id_features\n    np.save('features.npy', np.array(features))\n    np.save('best_corr.npy', np.array(best_corr))\n    # Store out of folds predictions\n    oof_predictions = np.zeros(len(train))\n    # Initiate GroupKFold\n    kfold = GroupKFold(n_splits = FOLDS)\n    # Create groups based on time_id\n    train.loc[(train['time_id'] >= 0) & (train['time_id'] < 280), 'group'] = 0\n    train.loc[(train['time_id'] >= 280) & (train['time_id'] < 585), 'group'] = 1\n    train.loc[(train['time_id'] >= 585) & (train['time_id'] < 825), 'group'] = 2\n    train.loc[(train['time_id'] >= 825) & (train['time_id'] < 1030), 'group'] = 3\n    train.loc[(train['time_id'] >= 1030) & (train['time_id'] < 1400), 'group'] = 4\n    train['group'] = train['group'].astype(np.int16)\n    #Lightgbm hyperparammeters\n    params = {\n        'boosting_type': 'gbdt',\n        'metric': 'mse',\n        'objective': 'regression',\n        'n_jobs': -1,\n        'seed': MODEL_SEED,\n        'num_leaves': 150,\n        'learning_rate': LR,\n        'feature_fraction': 0.4,\n        'bagging_freq': 7,\n        'bagging_fraction': 0.80,\n        'lambda_l1': 1,\n        'lambda_l2': 3,\n    }\n    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, groups = train['group'])):\n        print(f'Training fold {fold + 1}')\n        x_train, x_val = train[features].loc[trn_ind], train[features].loc[val_ind]\n        y_train, y_val = train['target'].loc[trn_ind], train['target'].loc[val_ind]\n        n_training_rows = x_train.shape[0]\n        n_validation_rows = x_val.shape[0]\n        # Build lgbm dataset\n        train_set, val_set = lgb.Dataset(x_train, y_train), lgb.Dataset(x_val, y_val)\n        print(f'Training with {n_training_rows} rows')\n        print(f'Validating with {n_validation_rows} rows')\n        print(f'Training light gradient boosting model with {len(features)} features...')\n        # Train and evaluate\n        model = lgb.train(\n            params, \n            train_set, \n            num_boost_round = 10000, \n            early_stopping_rounds = 100, \n            valid_sets = [train_set, val_set], \n            verbose_eval = 100\n        )\n        # Predict validation set\n        val_pred = model.predict(x_val)\n        # Add validation prediction to out of folds array\n        oof_predictions[val_ind] = val_pred\n        # Save model to disk for inference\n        joblib.dump(model, f'lgbm_{fold + 1}.pkl')\n        del x_train, x_val, y_train, y_val, train_set, val_set\n        gc.collect()\n    # Compute out of folds Pearson Correlation Coefficient (for each time_id)\n    oof_df = pd.DataFrame({'time_id': train['time_id'], 'target': train['target'], 'prediction': oof_predictions})\n    # Save out of folds csv for blending\n    oof_df.to_csv('simple_lgbm.csv', index = False)\n    score = comp_metric(oof_df)\n    print(f'Our out of folds mean pearson correlation coefficient is {score}')    \n    \ntrain_and_evaluate()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T13:59:59.960444Z","iopub.execute_input":"2022-01-28T13:59:59.961805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}