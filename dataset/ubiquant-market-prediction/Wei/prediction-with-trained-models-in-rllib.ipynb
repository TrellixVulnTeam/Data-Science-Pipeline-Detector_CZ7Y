{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from ray.rllib.agents.registry import get_trainer_class\nimport ray\nimport numpy as np\nimport gym\nfrom gym import spaces\nfrom ray.rllib.env.env_context import EnvContext","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-06T07:09:59.619717Z","iopub.execute_input":"2022-03-06T07:09:59.620355Z","iopub.status.idle":"2022-03-06T07:10:11.232192Z","shell.execute_reply.started":"2022-03-06T07:09:59.620294Z","shell.execute_reply":"2022-03-06T07:10:11.231359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GymEnvUbiquant(gym.Env):\n    \"\"\"\n    Dummy Environment class for to allow tuner to retrieve action_space and observation space dimensions.\n    \"\"\"\n    def __init__(self, config:EnvContext):\n        self.num_investment = config['num_investment'] # evaluate one by one\n        self.num_features = config['num_features'] # fix to 300 features\n        self.pred_dict = {}\n        self.action_space = spaces.Box(\n            low=-15,\n            high=15,\n            shape=(self.num_investment,)\n        )\n        # observation from the investment id with num_features\n        self.observation_space = spaces.Box(\n            low=-100,\n            high=100,\n            shape=(self.num_investment, self.num_features)\n        )\n    def step(self,a):\n        \"\"\"\n        given an action a, return the state of the environment with rewards\n        \"\"\"\n        return None, None, None, None\n    \n    def reset(self):\n        \"\"\"\n        provide the next input\n        \"\"\"\n        return None\n    \n    def render(self):\n        pass\n    \n    def close(self):\n        pass\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:19:31.477773Z","iopub.execute_input":"2022-03-06T07:19:31.478459Z","iopub.status.idle":"2022-03-06T07:19:31.489777Z","shell.execute_reply.started":"2022-03-06T07:19:31.478415Z","shell.execute_reply":"2022-03-06T07:19:31.488814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    # or \"corridor\" if registered above\n    \"env\": GymEnvUbiquant,\n    \"log_level\": \"INFO\",\n    \"env_config\": {'num_features': 300,\n                       'num_investment': 1,},\n    \"framework\": \"torch\",\n    \"model\": {\n        \"use_lstm\": True,\n        \"lstm_cell_size\": 128,\n        \"fcnet_hiddens\": [512, 512, 256],\n        \"fcnet_activation\": \"swish\"\n    },\n    \"num_envs_per_worker\": 1,\n    \"num_workers\": 1,\n    \"lambda\": 0.95,\n    \"shuffle_sequences\": False,\n    \"sgd_minibatch_size\": 512,\n    \"vf_clip_param\": 100.0,\n    \"vf_loss_coeff\": 0.5,\n    \"batch_mode\": \"complete_episodes\",\n    \"lr\": 1e-4,\n}\n\n\n# Initiates state for LSTM, a r are none since we are not using previous rewards and actions as inputs to LSTM.\ninit_prev_a = prev_a = None\ninit_prev_r = prev_r = None\nlstm_cell_size = config[\"model\"][\"lstm_cell_size\"]\ninit_state = state = [np.zeros([lstm_cell_size], np.float32) for _ in range(2)]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:21:20.335244Z","iopub.execute_input":"2022-03-06T07:21:20.335583Z","iopub.status.idle":"2022-03-06T07:21:20.345189Z","shell.execute_reply.started":"2022-03-06T07:21:20.335538Z","shell.execute_reply":"2022-03-06T07:21:20.344227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ray.init()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:19:39.569021Z","iopub.execute_input":"2022-03-06T07:19:39.569511Z","iopub.status.idle":"2022-03-06T07:19:43.748281Z","shell.execute_reply.started":"2022-03-06T07:19:39.569457Z","shell.execute_reply":"2022-03-06T07:19:43.747377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a \"trainer\" with policy to compute action.\ntrainer = get_trainer_class(\"PPO\")(config=config)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:21:21.802728Z","iopub.execute_input":"2022-03-06T07:21:21.803362Z","iopub.status.idle":"2022-03-06T07:22:03.665497Z","shell.execute_reply.started":"2022-03-06T07:21:21.803319Z","shell.execute_reply":"2022-03-06T07:22:03.664881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import checkpoint model:\ntrainer.restore('../input/rllibchkpt-run100/checkpoint_005100/checkpoint-5100')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:22:07.637179Z","iopub.execute_input":"2022-03-06T07:22:07.637533Z","iopub.status.idle":"2022-03-06T07:22:07.735636Z","shell.execute_reply.started":"2022-03-06T07:22:07.637496Z","shell.execute_reply":"2022-03-06T07:22:07.734659Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A naive way to store outputs from the input to keep track of state... \n# may be useful if using LSTM that requires one to keep track of action states\nMAIN_DICT = {} \n\n# Data structur of dictionary:\n#investment_id : {time_id#: {features: f_0 to f_299, # feature was not used.\n#                            predictions: x,\n#                            state: y}\n#                 }","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:45:30.666599Z","iopub.execute_input":"2022-03-06T07:45:30.667151Z","iopub.status.idle":"2022-03-06T07:45:30.671344Z","shell.execute_reply.started":"2022-03-06T07:45:30.667109Z","shell.execute_reply":"2022-03-06T07:45:30.670268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_dict(df, df_out):\n    \"\"\"\n    Takes the test df and update internal dictionary\n    Run the prediction model and output it to a dataframe\n    \"\"\"\n    global MAIN_DICT\n    \n    for group, df in df.groupby('investment_id'):\n        # using time-id to uniquely identify each entry for each investment id\n        time_id = df.row_id.iloc[0] #df.row_id.apply(lambda x: x.split('_'))[1][0]\n        # extract features from the df..\n        obs = df.loc[:,[f for f in df.columns if 'f' in f]].to_numpy() # required to be stored?\n        assert obs.shape == (1,300), f'obs shape: {obs.shape}'\n        \n        if group in MAIN_DICT:\n            # get the previous state for this investment_id:\n            prev_time_id = MAIN_DICT[group]['last_time']\n            state = MAIN_DICT[group][prev_time_id]['state']\n        else:\n            MAIN_DICT[group] = {}\n            state = [np.zeros([lstm_cell_size], np.float32) for _ in range(2)]\n                    \n        a, state_out, _ = trainer.compute_single_action(\n            observation=obs,\n            state=state,\n            prev_action=prev_a,\n            prev_reward=prev_r,\n            explore=False, # set to false or should be stochastic??\n            policy_id=\"default_policy\",  # <- default value\n        )\n        \n        # update the MAIN_DICT:\n        MAIN_DICT[group].update({time_id: {'state': state_out,\n                                           'a': a},\n                                 'last_time': time_id, # pointer to the current instance for quick lookup of state_out.\n                                })\n        \n        # update the prediction dataframe for competition\n        df_out.loc[df_out.row_id==time_id,'target'] = a\n        \n    return df_out\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:57:36.119399Z","iopub.execute_input":"2022-03-06T07:57:36.119732Z","iopub.status.idle":"2022-03-06T07:57:36.132542Z","shell.execute_reply.started":"2022-03-06T07:57:36.119698Z","shell.execute_reply":"2022-03-06T07:57:36.131647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\n\nfor (test_df, sample_prediction_df) in iter_test:\n    sample_prediction_df = update_dict(test_df, sample_prediction_df)\n    env.predict(sample_prediction_df)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T07:53:37.868506Z","iopub.execute_input":"2022-03-06T07:53:37.86881Z","iopub.status.idle":"2022-03-06T07:53:38.035907Z","shell.execute_reply.started":"2022-03-06T07:53:37.868779Z","shell.execute_reply":"2022-03-06T07:53:38.034909Z"},"trusted":true},"execution_count":null,"outputs":[]}]}