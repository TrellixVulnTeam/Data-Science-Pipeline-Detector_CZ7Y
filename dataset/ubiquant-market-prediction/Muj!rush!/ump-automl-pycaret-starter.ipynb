{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyCaret\n\nPyCaret beginneer's room.\n\n[PyCaret](https://pycaret.org/) 1.0.0, released in 2020, is a free Python library that allows you to do data preprocessing, visualization, and model development for machine learning model development in a few lines of code. AutoML, one of the low-code (only a few lines).PyCaret is a Python wrapper around several major machine learning libraries (scikit-learn, XGBoost, LightGBM, etc.) and can handle classification, regression, clustering, anomaly detection, and natural language processing.\n\nFor kaggler, it may be useful by allowing you to quickly try out a rough score of various models. However, advanced kagglers are likely to have their own preprocessing and model evaluation, or already have a pipeline, so they may not use it as much.\n\n* I referred to the wonderful pycaret notebook [here](https://www.kaggle.com/hasanbasriakcay/ubiquan-market-preds-pycaret-model-comparisons/notebook).\n\n\n* Please note that PyCaret takes a long time to run the code because it trains multiple models.Please note that it will take some time and no code will be executed here.\n\n* I am a beginner in machine learning, so I would appreciate comments if there are any mistakes.","metadata":{}},{"cell_type":"markdown","source":"# List of Pycaret functions used in notebook\n\nPreprocessing：　setup()\n\nCompare models： compare_models()\n\nCreate model： create_model()\n\nTuning： tune_model()\n\nVisualization： plot_model()\n\nEvaluate： evaluate_model()\n\nInference： finalize_model(), predict_model()","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pycaret[full]","metadata":{"execution":{"iopub.status.busy":"2022-02-11T15:28:17.08207Z","iopub.execute_input":"2022-02-11T15:28:17.082481Z","iopub.status.idle":"2022-02-11T15:29:13.950599Z","shell.execute_reply.started":"2022-02-11T15:28:17.082443Z","shell.execute_reply":"2022-02-11T15:29:13.949173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T15:29:13.953415Z","iopub.execute_input":"2022-02-11T15:29:13.953811Z","iopub.status.idle":"2022-02-11T15:29:13.960902Z","shell.execute_reply.started":"2022-02-11T15:29:13.953765Z","shell.execute_reply":"2022-02-11T15:29:13.959504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train data read(parquet format)\n\nhttps://www.kaggle.com/robikscube/fast-data-loading-and-low-mem-with-parquet-files/notebook","metadata":{}},{"cell_type":"code","source":"%%time\ntrain = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\ntest = pd.read_parquet('../input/ubiquant-parquet/example_test.parquet')\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-02-11T15:29:13.962635Z","iopub.execute_input":"2022-02-11T15:29:13.96319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reduce data\nReduce the data because the data size is too large and it will run out of memory later.\n\nNote that the original data records have been deleted down to 1/100.","metadata":{}},{"cell_type":"markdown","source":"### reduce colums","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/hasanbasriakcay/ubiquan-market-preds-pycaret-model-comparisons\n### Cols Select\nIGNORE_COLS = ['row_id', 'f_4', 'f_13', 'f_20', 'f_27', 'f_30', 'f_49', 'f_63', 'f_66', 'f_73', 'f_74', 'f_84', 'f_111', \n               'f_115', 'f_120', 'f_122', 'f_124', 'f_129', 'f_148', 'f_170', 'f_182', 'f_200', 'f_228', 'f_248', 'f_254', \n               'f_258', 'f_269', 'f_272', 'f_291', 'f_293', 'f_299', 'f_4', 'f_7', 'f_13', 'f_19', 'f_20', 'f_27', 'f_30', \n               'f_35', 'f_37', 'f_39', 'f_40', 'f_49', 'f_56', 'f_60', 'f_61', 'f_63', 'f_66', 'f_67', 'f_70', 'f_73', 'f_74', \n               'f_75', 'f_84', 'f_99', 'f_101', 'f_102', 'f_107', 'f_111', 'f_115', 'f_120', 'f_122', 'f_123', 'f_124', 'f_129', \n               'f_148', 'f_154', 'f_161', 'f_164', 'f_166', 'f_170', 'f_175', 'f_180', 'f_182', 'f_183', 'f_191', 'f_199', 'f_200', \n               'f_201', 'f_202', 'f_205', 'f_211', 'f_215', 'f_217', 'f_218', 'f_220', 'f_227', 'f_228', 'f_235', 'f_244', 'f_248', \n               'f_253', 'f_254', 'f_258', 'f_269', 'f_272', 'f_275', 'f_278', 'f_283', 'f_288', 'f_291', 'f_292', 'f_293', 'f_296', \n               'f_299']\n\nbasic_cols = ['time_id', 'investment_id', 'target']\nnum_feat = 300\nfeatures = [f'f_{i}' for i in range(num_feat)]\ncols = basic_cols + features\nselected_cols = []\nfor c in cols:\n    if c in IGNORE_COLS:\n        continue\n    selected_cols.append(c)\ntrain=train[selected_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### reduce rows","metadata":{}},{"cell_type":"code","source":"train=train[:25002] #time id:0-10\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reduce Memory Usage","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/hasanbasriakcay/ubiquan-market-preds-pycaret-model-comparisons\n\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ntrain = reduce_mem_usage(train)\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# import pycaret.regression\n\nThis competition is a regression, so it will use 'from pycaret.regression import *'","metadata":{}},{"cell_type":"code","source":"#regression\nfrom pycaret.regression import *\n\n#classification:Not required for this competition.\n#from pycaret.classification import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing：setup()\n\nThe first step is to run setup().\n\nsetup() is used to set up the preprocessing. It performs missing value processing, data division, etc.\n\nLet's  look at the main items.\n* session_id : A pseudo-random number that is distributed as a seed for reproducibility. In this experiment, session_id is set as 2022 for later reproducibility.\n* Original Data : The original shape of the data set. In this experiment, (25002, 229) means 25002 samples and 229 features including the target column.\n* Missing Values : This is indicated as True when the original data has missing values. For this experiment, there are no missing values in the data set.\n* Numeric Features : The number of features to be inferred as numeric. In this dataset, 228 features will be inferred as numeric.\n* Categorical Features : Number of features to be inferred as categorical. There are no Categorical Features in this dataset.\n* Transformed Train Set : Displays the shape of the transformed training set (17501, 229). \n* Transformed Test Set : Displays the shape of the transformed test set (7501, 229).","metadata":{}},{"cell_type":"code","source":"%%time\n\nreg = setup(data = train,\n            target = 'target',\n            #numeric_features = NUM_FEATURES,\n            session_id = 2022,\n            silent = True, #Skip checking for type estimation.\n            data_split_shuffle = False) #Avoid using \"future\" observations to predict \"past\" observations.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Comparison： compare_models()\n\nThe function trains all the models in the model library and scores them using k-fold cross-validation for metric evaluation.\n\nThe output includes accuracy, AUC, recall, goodness of fit, F1, Kappa, and MCC, along with training time.\n\nYou can also use lightgbm, catboost, xgboost, etc., which are often used in kaggle.\n\n","metadata":{}},{"cell_type":"code","source":"%%time\n\n#It will take some time to run.\nbest_model=compare_models(sort = 'RMSE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can also get multiple models of a higher level.","metadata":{}},{"cell_type":"code","source":"#Not executed because it takes time to execute\n\n#N = 3 #Specify the number of upper models\n#top_models = compare_models(sort = 'RMSE', n_select = N)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create model;create_model()\n\nIn this case, I will use the Random Forest Classifier model.\n\nThe metrics printed in the compare_models() score grid will be the average score across all CV folds.","metadata":{}},{"cell_type":"code","source":"%%time\nmodel = create_model('rf')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuning： tune_model()\n\nPyCaret uses a random grid search to automatically adjust the hyperparameters of the model.\n\nThe output is the model's best accuracy, AUC, repeatability, goodness-of-fit, F1, kappa, and MCC","metadata":{}},{"cell_type":"code","source":"#It will take about 10 hours to run.\n#Not executed because it takes time to execute\n\n#tuned_model = tune_model(model, optimize = 'RMSE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get parameters\nYou can check the parameters of the model","metadata":{}},{"cell_type":"code","source":"#Not executed because it takes time to execute\n#tuned_model.get_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the hyperparameters :evaluate_model\n\nYou can check the evaluation metrics of the model","metadata":{}},{"cell_type":"code","source":"%%time\nevaluate_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blending:blend_models()\n\nIf no model is specified, blend_models() will use all the models supported by PyCaret. If no model is specified, blend_models() will use all models supported by PyCaret for blending.","metadata":{}},{"cell_type":"code","source":"##Not executed because it takes time to execute\n\n# create models\n#cat = create_model('catboost') #CatBoost\n#rf = create_model('rf') #Random Forest\n#lr = create_model('lr') #Logistic Regression\n\n# tuning\n#tuned_cat = tune_model(cat)\n#tuned_rf = tune_model(rf)\n#tuned_lr = tune_model(lr)\n\n# Blending\n#soft：Use the prediction label of the model with the highest prediction score.\n#hard：Majority rule for predictive labels\n#blender_specific = blend_models(estimator_list = [tuned_cat,tuned_rf,tuned_lr], method = 'soft')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking :stack_models()\n\nStacking is often used in kaggle, but it can be done by simply setting up multiple trainers and a trainer for the metamodel","metadata":{}},{"cell_type":"code","source":"#Not executed because it takes time to execute\n\n# create individual models for stacking\n#cat = create_model('catboost')\n#rf = create_model('rf')\n#tuned_cat = tune_model(cat)\n#tuned_rf = tune_model(rf)\n\n#meta_model\n#xgboost = create_model('xgboost')\n\n# stacking models\n#stacker = stack_models(estimator_list = [tuned_cat,tuned_rf], meta_model = xgboost)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference: predict_model()\nPerform one final check by reviewing the evaluation metrics to predict the test/hold-out set before finalizing the model.","metadata":{}},{"cell_type":"code","source":"%%time\npredict_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finalize the model: finalize_model()\n\nFinally, run finalize_model() to finalize the model","metadata":{}},{"cell_type":"code","source":"%%time\nfinal_model = finalize_model(model)\npredict_model(final_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization: plot_model()\n\nYou can visualize various graphs with plot_model().","metadata":{}},{"cell_type":"code","source":"#Prediction error plot\nplot_model(final_model, plot='error')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature importance\nplot_model(final_model, plot='feature')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Not executed because it takes time to execute\n\n#learning curve\n#plot_model(final_model, plot='learning')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save & load model","metadata":{}},{"cell_type":"code","source":"#save_model()\n#save_model(final_rf,model_name='Final RF Model')\n\n#load_model()\n#saved_final_rf = load_model(model_name='Final RF Model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pycaret + SHAP\npycaret also supports shap, but this note will not run it because it takes too long.","metadata":{}},{"cell_type":"code","source":"#!pip install shap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import shap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Passing a model to interpret_model displays a summary plot\n#summary plot shows us which explanatory variables have a large effect on the model.\n\n#interpret_model(final_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display dependence plot with 'correlation' argument\n#dependence plot is a scatter plot of a specific explanatory variable and SHAP values.\n\n#interpret_model(final_model,plot='correlation')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#force plot when 'reason' is specified as argument.\n#force plot shows SHAP values for individual data.\n#specify data index with observation argument\n\n#interpret_model(final_model,plot='reason',observation=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}