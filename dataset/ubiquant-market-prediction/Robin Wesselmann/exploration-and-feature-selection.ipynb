{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt \nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T12:40:59.078417Z","iopub.execute_input":"2022-02-16T12:40:59.079557Z","iopub.status.idle":"2022-02-16T12:41:00.391663Z","shell.execute_reply.started":"2022-02-16T12:40:59.079385Z","shell.execute_reply":"2022-02-16T12:41:00.390475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data\ntrain = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:41:00.393787Z","iopub.execute_input":"2022-02-16T12:41:00.394182Z","iopub.status.idle":"2022-02-16T12:41:42.180434Z","shell.execute_reply.started":"2022-02-16T12:41:00.394137Z","shell.execute_reply":"2022-02-16T12:41:42.179104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, col_excluded = []):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    df_cols = list(df.columns)\n    df_cols = [col for col in df_cols if col not in col_excluded]\n        \n    for col in df_cols:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    \n    \n    \n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ntrain = reduce_mem_usage(train, ['row_id', 'time_id', 'investment_id'])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:41:42.185489Z","iopub.execute_input":"2022-02-16T12:41:42.18629Z","iopub.status.idle":"2022-02-16T12:46:11.476821Z","shell.execute_reply.started":"2022-02-16T12:41:42.186238Z","shell.execute_reply":"2022-02-16T12:46:11.475475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extensive EDA","metadata":{}},{"cell_type":"code","source":"#General information\ntrain.info(memory_usage = \"deep\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:46:11.47861Z","iopub.execute_input":"2022-02-16T12:46:11.478931Z","iopub.status.idle":"2022-02-16T12:46:12.119528Z","shell.execute_reply.started":"2022-02-16T12:46:11.478891Z","shell.execute_reply":"2022-02-16T12:46:12.118296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Rough Overview: There are 5 Types of columns__\n\n* __Investment id:__ The statistical unit to analyze. There are 3579 different investments with their proper range of time ids \n* __time ids:__ There are 1211 different time ids and for each investment id there are o average 877 different time ids\n* __row_id:__ Union of the time_id and the investment_id for a specific record\n* __f_x:__ 300 anonymized features out of the market data for each specific\n* __target:__  investment's return rate for a specific time_id","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:46:12.122288Z","iopub.execute_input":"2022-02-16T12:46:12.122636Z","iopub.status.idle":"2022-02-16T12:46:12.167917Z","shell.execute_reply.started":"2022-02-16T12:46:12.12258Z","shell.execute_reply":"2022-02-16T12:46:12.16699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#no null values on target variable and other variables\nprint(\"Number of null values in dataset: {} samples\".format(train.isnull().sum().sort_values().sum()))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:46:12.169333Z","iopub.execute_input":"2022-02-16T12:46:12.169701Z","iopub.status.idle":"2022-02-16T12:46:18.164071Z","shell.execute_reply.started":"2022-02-16T12:46:12.16965Z","shell.execute_reply":"2022-02-16T12:46:18.16282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Investment_id and time_id","metadata":{}},{"cell_type":"code","source":"print(\"There are {} different investment_ids\".format(len(train[\"investment_id\"].value_counts().index)))\nprint(\"There are {} different time_ids\".format(len(train[\"time_id\"].value_counts().index)))\n\nmean_cnt_time_id = np.round(train.groupby(\"investment_id\")[\"time_id\"].count().mean(),2)\n\nprint(\"There are on average {} different time id per investment_id\".format(mean_cnt_time_id))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:46:18.165731Z","iopub.execute_input":"2022-02-16T12:46:18.16611Z","iopub.status.idle":"2022-02-16T12:46:18.349704Z","shell.execute_reply.started":"2022-02-16T12:46:18.166062Z","shell.execute_reply":"2022-02-16T12:46:18.34825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But not every investment has the exact 877.73 time steps. Some have more and some have less (red line below). ","metadata":{}},{"cell_type":"code","source":"iid = train[\"investment_id\"].value_counts()\n\nfig, sub = plt.subplots(1,1,figsize=(20,5))\nsns.barplot(x=iid.index, y = iid.values,ax = sub, order = iid.index, palette = \"cividis\")\nsub.axhline(y = mean_cnt_time_id, ls = \"--\", lw = 3.0, color = \"red\", alpha = 0.7)\nsub.set_xlabel(\"Different investment ids\")\nsub.set_ylabel(\"Different Time ids\");","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:46:18.351412Z","iopub.execute_input":"2022-02-16T12:46:18.351767Z","iopub.status.idle":"2022-02-16T12:47:10.404747Z","shell.execute_reply.started":"2022-02-16T12:46:18.351721Z","shell.execute_reply":"2022-02-16T12:47:10.403685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the count of the investment ids grouped by the time id, we see that the relationship exhibit a trend and an unusual behavior: \n\n* Trend: There are more investments which have been executed in the later time id space than in the earlier time ids\n* Unusual behavior: Within the range around time id 400, there are less investment ids than in other time_id ranges","metadata":{}},{"cell_type":"code","source":"#credits: https://www.kaggle.com/allunia/ubiquant-eda\ntid_iid = train.groupby(\"time_id\")[\"investment_id\"].count()\n\nfig, sub = plt.subplots(1,1,figsize=(30,5))\n\nsns.scatterplot(x = tid_iid.index, y = tid_iid.values, ax = sub)\nsub.grid()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:10.406215Z","iopub.execute_input":"2022-02-16T12:47:10.406507Z","iopub.status.idle":"2022-02-16T12:47:10.785717Z","shell.execute_reply.started":"2022-02-16T12:47:10.40647Z","shell.execute_reply":"2022-02-16T12:47:10.784431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_timeid = train.groupby(\"investment_id\")[\"time_id\"].max().value_counts().index.max()\n\ntime_id_max = train.groupby(\"investment_id\")[\"time_id\"].max()\ntid_max_high_freq = time_id_max[time_id_max == 1219]\ntid_max_outlier = time_id_max[time_id_max != 1219]\n\nprint(\"{} of the {} investment_ids have a max time id of {}\".format(tid_max_high_freq.shape[0], time_id_max.shape[0], freq_timeid))\nprint(\"So there are {} outliers with different max time ids\".format(tid_max_outlier.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:10.787444Z","iopub.execute_input":"2022-02-16T12:47:10.787709Z","iopub.status.idle":"2022-02-16T12:47:11.076175Z","shell.execute_reply.started":"2022-02-16T12:47:10.787677Z","shell.execute_reply":"2022-02-16T12:47:11.075203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples = 15\n\ntid_max_outlier_samples = tid_max_outlier.sample(samples).index\n\nfig, sub = plt.subplots(1,1,figsize = (16,8))\n\nfor n in range(samples):\n    \n    plt.plot(train[train[\"investment_id\"] == tid_max_outlier_samples[n]][\"time_id\"],\n            train[train[\"investment_id\"] == tid_max_outlier_samples[n]][\"target\"].cumsum(), \".\")\n    \n    plt.xlim([0,1220])\n    plt.title(\"Outlier investment ids (# timeids != 1219)\")\n    \nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:11.080159Z","iopub.execute_input":"2022-02-16T12:47:11.080885Z","iopub.status.idle":"2022-02-16T12:47:14.027224Z","shell.execute_reply.started":"2022-02-16T12:47:11.080818Z","shell.execute_reply":"2022-02-16T12:47:14.026033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But there are apparently \"holes\": Listing all unique time ids in a sorted row, you got not a clean row of upcounting ids. There is a small fraction of holes in the set","metadata":{}},{"cell_type":"code","source":"shifted = np.array(sorted(train[\"time_id\"].unique())[1:])\noriginal = np.array(sorted(train[\"time_id\"].unique())[:-1])\n\nunique, counts = np.unique(shifted - original, return_counts = True)\npd.Series(counts, index = unique)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:14.028692Z","iopub.execute_input":"2022-02-16T12:47:14.029097Z","iopub.status.idle":"2022-02-16T12:47:14.075485Z","shell.execute_reply.started":"2022-02-16T12:47:14.029061Z","shell.execute_reply":"2022-02-16T12:47:14.074485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target distribution","metadata":{}},{"cell_type":"markdown","source":"The target distribution itself looks ok. Not strongly skewed nor any bigger outliers observable","metadata":{}},{"cell_type":"code","source":"fig, sub = plt.subplots(1,1,figsize=(12,4))\ntrain[\"target\"].hist(bins = 100, edgecolor = \"black\")\nsub.get_yaxis().set_major_formatter(plt.matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\nsub.set_ylabel(\"Count\")\nsub.set_xlabel(\"Target\");","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:14.077234Z","iopub.execute_input":"2022-02-16T12:47:14.07755Z","iopub.status.idle":"2022-02-16T12:47:14.987694Z","shell.execute_reply.started":"2022-02-16T12:47:14.077505Z","shell.execute_reply":"2022-02-16T12:47:14.98672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.set_index(\"time_id\", drop = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:14.989663Z","iopub.execute_input":"2022-02-16T12:47:14.99045Z","iopub.status.idle":"2022-02-16T12:47:15.005186Z","shell.execute_reply.started":"2022-02-16T12:47:14.990396Z","shell.execute_reply":"2022-02-16T12:47:15.004435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To get an impression for the different return rates of the respective investments in the following some plots <br />\nThe different investments seem to have a individual development and in the plots, several gaps between some time_ids become evident","metadata":{}},{"cell_type":"code","source":"def plot_target_analysis(sample_ls = [], col=\"target\"):\n    \n    if len(sample_ls)!=0:\n        for invest in sample_ls:\n\n            fig, sub = plt.subplots(1,3,figsize = (30,5))\n            df_tmp = train[train[\"investment_id\"]==invest]\n\n            #general \n            df_tmp_t = df_tmp[col]\n            df_tmp_t_mean = df_tmp.rolling(window = 10)[col].mean()\n            df_tmp_t_std = df_tmp.rolling(window = 10)[col].std()\n\n            #development\n            df_tmp_d = df_tmp[col].cumsum()\n\n            sub[0].plot(df_tmp_t.index, df_tmp_t, alpha = 0.3)\n            sub[0].plot(df_tmp_t_mean.index, df_tmp_t_mean, color = \"red\", label = \"10d mean\")\n            sub[0].plot(df_tmp_t_std.index, df_tmp_t_std, color = \"green\", ls = \"--\", label = \"10d std\")\n            sub[0].set_title(f\"{col} over time_id (Investment id {invest})\")\n            sub[0].set_xlim((-50,1250))\n            sub[0].set_ylabel(f\"{col}\")\n            sub[0].legend(loc = \"upper right\")\n            sub[0].grid()\n\n            sub[1].plot(df_tmp_d.index, df_tmp_d)\n            sub[1].set_title(f\"{col} development (Investment id {invest})\")\n            sub[1].set_xlim((-50,1250))\n            sub[1].set_ylabel(f\"{col}\")\n            sub[1].grid()\n\n            sub[2].hist(df_tmp_t, bins = 30, edgecolor = \"black\")\n            sub[2].set_title(f\"{col} distribution (Investment id {invest})\")\n            sub[2].set_xlabel(f\"{col}\")\n            sub[2].grid()\n\n            fig.tight_layout()\n    else:\n        print(\"no invest_ls given.\")\n        \ninvests = train[\"investment_id\"].sample(3)\nplot_target_analysis(invests,\"target\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:15.006426Z","iopub.execute_input":"2022-02-16T12:47:15.007109Z","iopub.status.idle":"2022-02-16T12:47:17.626805Z","shell.execute_reply.started":"2022-02-16T12:47:15.00707Z","shell.execute_reply":"2022-02-16T12:47:17.625902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## fx-distribution","metadata":{}},{"cell_type":"code","source":"plot_target_analysis(invests,\"f_2\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:17.628199Z","iopub.execute_input":"2022-02-16T12:47:17.628445Z","iopub.status.idle":"2022-02-16T12:47:20.292063Z","shell.execute_reply.started":"2022-02-16T12:47:17.628412Z","shell.execute_reply":"2022-02-16T12:47:20.290923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__The fx features are all numerical (continuous) variables__","metadata":{}},{"cell_type":"code","source":"target_sample = train.sample(frac = 0.10)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:20.293872Z","iopub.execute_input":"2022-02-16T12:47:20.294604Z","iopub.status.idle":"2022-02-16T12:47:23.622378Z","shell.execute_reply.started":"2022-02-16T12:47:20.294553Z","shell.execute_reply":"2022-02-16T12:47:23.621199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_chk = target_sample[target_sample.columns[3:]]\n\n[col for col in cat_chk if cat_chk[col].nunique()<50]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:23.623857Z","iopub.execute_input":"2022-02-16T12:47:23.624097Z","iopub.status.idle":"2022-02-16T12:47:26.035645Z","shell.execute_reply.started":"2022-02-16T12:47:23.624067Z","shell.execute_reply":"2022-02-16T12:47:26.034206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Relationships ","metadata":{}},{"cell_type":"markdown","source":"There seems not to be a strong linear correlation between the features and the target","metadata":{}},{"cell_type":"code","source":"correlation = target_sample[target_sample.columns[2:]].corr()\n\nfig = plt.figure(figsize=(10, 4))\n\nplt.hist(correlation[\"target\"][1:], edgecolor = \"black\", bins = 25)\nplt.ylabel(\"Count\")\nplt.xlabel(\"Correlation\")\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:47:26.03809Z","iopub.execute_input":"2022-02-16T12:47:26.038475Z","iopub.status.idle":"2022-02-16T12:48:45.723196Z","shell.execute_reply.started":"2022-02-16T12:47:26.038423Z","shell.execute_reply":"2022-02-16T12:48:45.72194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_dict = {k : v for k, v in sorted(abs(correlation[\"target\"]).items(), key = lambda item: item[1])}","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:45.724977Z","iopub.execute_input":"2022-02-16T12:48:45.725253Z","iopub.status.idle":"2022-02-16T12:48:45.732782Z","shell.execute_reply.started":"2022-02-16T12:48:45.72522Z","shell.execute_reply":"2022-02-16T12:48:45.731305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"-----the five features with the lowest linear correlation with the target-----\\n\")\n\nfor feat in list(corr_dict)[:5]:\n    print(\"Feature {} correlation: {}\".format(feat, corr_dict[feat]))\n    \nprint(\"\\n-----the five features with the highest linear correlation with the target-----\\n\")\n\nfor feat in list(corr_dict)[-6:-1]:\n    print(\"Feature {} correlation: {}\".format(feat, corr_dict[feat]))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:45.734343Z","iopub.execute_input":"2022-02-16T12:48:45.734579Z","iopub.status.idle":"2022-02-16T12:48:45.754266Z","shell.execute_reply.started":"2022-02-16T12:48:45.734543Z","shell.execute_reply":"2022-02-16T12:48:45.753219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Looking at the linear correlation between the fx features, we can see that there are several highly correlated features. Highly correlated features often contain the same information and we could drop some features without information loss__","metadata":{}},{"cell_type":"code","source":"sns.clustermap(abs(correlation), figsize = (15,15), cmap = \"mako\");","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:45.755935Z","iopub.execute_input":"2022-02-16T12:48:45.756237Z","iopub.status.idle":"2022-02-16T12:48:48.041998Z","shell.execute_reply.started":"2022-02-16T12:48:45.756198Z","shell.execute_reply":"2022-02-16T12:48:48.040729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:48.043748Z","iopub.execute_input":"2022-02-16T12:48:48.044215Z","iopub.status.idle":"2022-02-16T12:48:49.141705Z","shell.execute_reply.started":"2022-02-16T12:48:48.044165Z","shell.execute_reply":"2022-02-16T12:48:49.140377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom joblib import Parallel, delayed\nimport dill as pickle\nfrom joblib.externals.loky import set_loky_pickler\nset_loky_pickler(\"dill\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:49.143638Z","iopub.execute_input":"2022-02-16T12:48:49.144526Z","iopub.status.idle":"2022-02-16T12:48:49.337062Z","shell.execute_reply.started":"2022-02-16T12:48:49.144466Z","shell.execute_reply":"2022-02-16T12:48:49.336025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_sample = train.sample(frac = 0.005)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:49.338595Z","iopub.execute_input":"2022-02-16T12:48:49.338876Z","iopub.status.idle":"2022-02-16T12:48:49.857265Z","shell.execute_reply.started":"2022-02-16T12:48:49.338813Z","shell.execute_reply":"2022-02-16T12:48:49.856187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif_data = pd.DataFrame()\nvif_data[\"feature\"] = train.columns[3:]\n\nvif_data[\"VIF\"] = [variance_inflation_factor(target_sample[target_sample.columns[3:]].values.astype(\"float32\"), i) for i in range(len(train.columns[3:]))]\n#Parallel processing doesn't work on kaggle due to 'PicklingError' problems\n#vif_list = Parallel(n_jobs = 3, verbose = 5)(delayed(variance_inflation_factor)(target_sample[target_sample.columns[3:]].values.astype(\"float32\"), i) for i in range(len(train.columns[3:])))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:48:49.858923Z","iopub.execute_input":"2022-02-16T12:48:49.859187Z","iopub.status.idle":"2022-02-16T12:56:36.525867Z","shell.execute_reply.started":"2022-02-16T12:48:49.859153Z","shell.execute_reply":"2022-02-16T12:56:36.524266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The features with a Variance Inflation Factor > 5 can be dropped due to the risk of Multicollinearity  (some books speak about a rule of thumb of VIF of 10 as a bareer, but we are a bit more conservative here)","metadata":{}},{"cell_type":"code","source":"vif_data[vif_data[\"VIF\"]>5][\"feature\"].values","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:56:36.5296Z","iopub.execute_input":"2022-02-16T12:56:36.530448Z","iopub.status.idle":"2022-02-16T12:56:36.545313Z","shell.execute_reply.started":"2022-02-16T12:56:36.530364Z","shell.execute_reply":"2022-02-16T12:56:36.54434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(vif_data[vif_data[\"VIF\"]>5][\"feature\"].values, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:57:38.609593Z","iopub.execute_input":"2022-02-16T12:57:38.610428Z","iopub.status.idle":"2022-02-16T12:57:38.614882Z","shell.execute_reply.started":"2022-02-16T12:57:38.610375Z","shell.execute_reply":"2022-02-16T12:57:38.613879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:57:43.687402Z","iopub.execute_input":"2022-02-16T12:57:43.687751Z","iopub.status.idle":"2022-02-16T12:57:43.863511Z","shell.execute_reply.started":"2022-02-16T12:57:43.687712Z","shell.execute_reply":"2022-02-16T12:57:43.86252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition to the feature selection by looking at th VIF, we can also select features using the embedded functioning of the lightgbm model and its feature importance calculation","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\nimport lightgbm as lgb\n\nfeatureCutoff = 100\n\nlgbc=lgb.LGBMRegressor(n_estimators=50, learning_rate=0.05,\n                    num_leaves=32, colsample_bytree=0.2,                                           \n                    reg_alpha=3, reg_lambda=1, min_split_gain=0.01,    \n                    min_child_weight=40)\n\nembeded_lgb_selector = SelectFromModel(lgbc, max_features=featureCutoff)\nembeded_lgb_selector.fit(X = train[train.columns[3:]], y = train[\"target\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:57:57.985364Z","iopub.execute_input":"2022-02-16T12:57:57.985741Z","iopub.status.idle":"2022-02-16T12:59:32.508743Z","shell.execute_reply.started":"2022-02-16T12:57:57.985692Z","shell.execute_reply":"2022-02-16T12:59:32.507662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filter = embeded_lgb_selector.get_support()\nselected_feat = train.columns[3:][filter]\n\nselected_feat = list(train.columns[:3]) + list(selected_feat)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:59:37.73057Z","iopub.execute_input":"2022-02-16T12:59:37.73113Z","iopub.status.idle":"2022-02-16T12:59:37.737399Z","shell.execute_reply.started":"2022-02-16T12:59:37.731091Z","shell.execute_reply":"2022-02-16T12:59:37.736169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To enrich the dataset it's possible to engineer some further information out of existing information","metadata":{}},{"cell_type":"code","source":"def feature_engineering(df, features):\n    \n    df['mean'] = df[features].mean(axis=1)\n    df['median'] = df[features].median(axis=1)\n    #df['q01'] = df[features].quantile(q=0.01, axis=1)\n    #df['q05'] = df[features].quantile(q=0.05, axis=1)\n    #df['q10'] = df[features].quantile(q=0.10, axis=1)\n    df['q25'] = df[features].quantile(q=0.25, axis=1)\n    df['q75'] = df[features].quantile(q=0.75, axis=1)\n    df['q90'] = df[features].quantile(q=0.90, axis=1)\n    df['q95'] = df[features].quantile(q=0.95, axis=1)\n    #df['q99'] = df[features].quantile(q=0.99, axis=1)\n    df['max'] = df[features].max(axis=1)\n    df['min'] = df[features].min(axis=1)\n    \n    df['std'] = df[features].std(axis=1)\n    df['range'] = df['max'] - df['min']\n    df['iqr'] = df['q75'] - df['q25']\n    df['tails'] = df['range'] / df['iqr']\n    df['dispersion'] = df['std'] / df['mean']\n    df['dispersion_2'] = df['iqr'] / df['median']\n    df['skew'] = df[features].skew(axis=1)\n    df['kurt'] = df[features].kurt(axis=1)\n    \n    df['median-max'] = df['median'] - df['max']\n    df['median-min'] = df['median'] - df['min']\n    #df['q99-q95'] = df['q99'] - df['q95']\n    #df['q99-q90'] = df['q99'] - df['q90']\n    #df['q01-q05'] = df['q01'] - df['q05']\n    #df['q01-q10'] =  df['q01'] - df['q10']\n    \n    gc.collect()\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:59:40.768113Z","iopub.execute_input":"2022-02-16T12:59:40.768506Z","iopub.status.idle":"2022-02-16T12:59:40.782931Z","shell.execute_reply.started":"2022-02-16T12:59:40.768465Z","shell.execute_reply":"2022-02-16T12:59:40.781519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = feature_engineering(train, train.columns[3:])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:59:42.79345Z","iopub.execute_input":"2022-02-16T12:59:42.794167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:58:00.179735Z","iopub.execute_input":"2022-02-15T21:58:00.180218Z","iopub.status.idle":"2022-02-15T21:58:00.184684Z","shell.execute_reply.started":"2022-02-15T21:58:00.180166Z","shell.execute_reply":"2022-02-15T21:58:00.183751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}