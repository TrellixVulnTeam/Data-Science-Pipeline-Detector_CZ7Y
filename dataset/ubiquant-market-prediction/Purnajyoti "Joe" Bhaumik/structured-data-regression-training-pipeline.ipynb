{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.decomposition import PCA\nimport pickle\nfrom sklearn import preprocessing\nfrom sklearn.manifold import SpectralEmbedding\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T14:51:37.374433Z","iopub.execute_input":"2022-02-03T14:51:37.37479Z","iopub.status.idle":"2022-02-03T14:51:38.768148Z","shell.execute_reply.started":"2022-02-03T14:51:37.374701Z","shell.execute_reply":"2022-02-03T14:51:38.767361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get the Data - The csv is very large, so we need to assign data types to control the memory required.","metadata":{}},{"cell_type":"code","source":"train_df =pd.read_pickle('../input/ump-train-picklefile/train.pkl')\n#train_df.info(verbose = True) # dataset is too large for pandas profiling (e.g. auto EDA tool)\ntrain_df = train_df.reset_index(drop = False)\ny_time = train_df.pop('time_id').values\ny = train_df.pop('target').values","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:51:59.777032Z","iopub.execute_input":"2022-02-03T14:51:59.777356Z","iopub.status.idle":"2022-02-03T14:52:41.830215Z","shell.execute_reply.started":"2022-02-03T14:51:59.777317Z","shell.execute_reply":"2022-02-03T14:52:41.828694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.pop('row_id')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:53:21.195463Z","iopub.execute_input":"2022-02-03T14:53:21.195762Z","iopub.status.idle":"2022-02-03T14:53:21.208146Z","shell.execute_reply.started":"2022-02-03T14:53:21.195732Z","shell.execute_reply":"2022-02-03T14:53:21.207377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the Data - Scale each feature of x to have a mean of 0 and standard deviation of 1. \n                   Reduce the dimensionality using PCA ","metadata":{}},{"cell_type":"code","source":"x = train_df.values\n# scaler = preprocessing.StandardScaler().fit(features)\n# pickle.dump(scaler, open('scaler.pkl','wb'))\n# features = scaler.transform(features)\n\n# pca = PCA(n_components=150, random_state=22)\n# pca.fit(features)\n# x = pca.transform(features)\n# pickle.dump(pca,  open('pca.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:53:33.195108Z","iopub.execute_input":"2022-02-03T14:53:33.195392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the base models - Using Stratified Kfolding creates multiple datasets with sample distributions equal to the overall training dataset. Each fold will train 1 model. A final regressor will then ensemble the models' using their predictions as training data.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\ni = 0\nmodels = []\nskf = StratifiedKFold(n_splits=30)\n\nfor train_index, test_index in skf.split(x, y_time):\n    regr = LinearRegression()\n    X_train, X_test = x[train_index], x[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    regr.fit(X_train, y_train)\n    pickle.dump(regr,  open('trained_lr'+str(i)+'.pkl', 'wb'))\n    models.append(regr)\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:05:13.442509Z","iopub.execute_input":"2022-02-02T16:05:13.443132Z","iopub.status.idle":"2022-02-02T16:12:47.795959Z","shell.execute_reply.started":"2022-02-02T16:05:13.443083Z","shell.execute_reply":"2022-02-02T16:12:47.795058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train final meta model - This model takes the predictions from the other models as input and produces a final prediction","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(columns=np.arange(len(models)))\n\nfor i, model in enumerate(models):\n    df[i]=model.predict(x)\n\nregr = LinearRegression()\nregr.fit(df.values, y)\n\npickle.dump(regr,  open('final_trained_lr.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:18:56.542403Z","iopub.execute_input":"2022-02-02T16:18:56.542773Z","iopub.status.idle":"2022-02-02T16:19:57.394999Z","shell.execute_reply.started":"2022-02-02T16:18:56.542739Z","shell.execute_reply":"2022-02-02T16:19:57.394308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Future Work: Use LSTM for time series prediction","metadata":{}},{"cell_type":"code","source":"# from keras.models import Sequential\n# from keras.layers import Dense\n# from keras.layers import LSTM\n\n# model = Sequential()\n# model.add(LSTM(50, input_shape=(x.shape[1], x.shape[2])))\n# model.add(Dense(1))\n# model.compile(loss = 'mae', optimizer = 'adam')\n# model.fit(x, y)\n\n# model.save('trained_lstm')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:12:52.605936Z","iopub.status.idle":"2022-02-02T16:12:52.609848Z","shell.execute_reply.started":"2022-02-02T16:12:52.60825Z","shell.execute_reply":"2022-02-02T16:12:52.609622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}