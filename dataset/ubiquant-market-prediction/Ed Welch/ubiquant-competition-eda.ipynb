{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ubiquant Market Prediction Competition:  Exploratory Data Analysis  \n\n### Statement of Business Task:  \n\n<font size='5'>\n\n# <a id='100'><span style=\"color:#1B03A3;\">---------- Insights from this EDA ----------</span></a>","metadata":{}},{"cell_type":"markdown","source":"<font size='3'>- There are 304 columns, 3,141,410 rows and no missing values. </font>     \n<font size='3'>- The target has been transformed, forcing the mean to 0.  </font>   \n<font size='3'>- The target has a normal distribution. </font>   \n<font size='3'>- There are 300 **anonymous features**, with lables f_0 up to f_299.</font>  \n<font size='3'>- Time Ids extend from 0 to 1211.</font>  \n<font size='3'>- The following time ids are not included in this dataset: 361, 368, 369, 370, 371, 372, 382, 402, 403.</font>      \n<font size='3'>- The total number of investments in the portfolio changes over the range of time ids.</font>  \n<font size='3'>- This competition appears to be predicting market volatility.</font>  \n<font size='3'>- The target variables could be a disguised measure of volatility.</font>[Source](https://www.kaggle.com/c/ubiquant-market-prediction/discussion/303397)  \n<font size='3'>- Many of the features range from around zero to a larger positive (or negative) number.  Know why.</font>","metadata":{}},{"cell_type":"markdown","source":"## <p style=\"background-color:#1B03A3; font-family:newtimeroman; color:white; font-size:180%; text-align:center; border-radius: 24px 0;\">Ubiquant EDA</p>\n\n## <span style=\"color:#1B03A3;text-align:center;\">-------------------- Table of Contents --------------------</span>\n\n<font size='3'>* **[Key Insights from this EDA](#100)**   </font>  \n<font size='3'>* **[About Ubiquant Investment, Competition Host:](#1)**   </font>  \n<font size='3'>* **[Competition Objective](#2)**   </font>  \n<font size='3'>* **[What Story is the Data Telling?](#3)**   </font>  \n<font size='3'>* **[Data](#4)**   </font>  \n<font size='3'>* ----**[Feature Columns](#5)**   </font>  \n<font size='3'>* ----**[Missing Values](#6)**   </font>  \n<font size='3'>* ----**[Time IDs](#7)**   </font>  \n<font size='3'>* ----**[Invidvidual Investment IDs](#8)**   </font>  \n<font size='3'>* ----**[Row IDs](#9)**   </font>  \n<font size='3'>* **[Target Analysis](#10)**   </font>  \n<font size='3'>* ----**[Target Distribution Plot](#11)**   </font>  \n<font size='3'>* ----**[Target Values](#12)**   </font>  \n<font size='3'>* **[Feature Analysis](#18)**   </font>  \n<font size='3'>* ----**[Boxplot Overview of Features](#14)**   </font>  \n<font size='3'>* ----**[Feature Correlation With Target](#15)**   </font>  \n<font size='3'>* **[Mutual Information of Features](#16)**   </font>  \n\n## <a id=\"1\"><span style=\"color:#1B03A3;\">About Ubiquant Investment, Competition Host:</span></a>\n[Source](https://www.kaggle.com/c/ubiquant-market-prediction)\n> <font size='3'> <span style=\"color:#1B03A3;\">**\"Ubiquant Investment (Beijing) Co., Ltd**</span> is a leading domestic quantitative hedge fund based in China.  Established in 2012, they rely on international talents in math and computer science along with cutting-edge technology to drive <span style=\"color:#1B03A3;\">**quantitative financial market investment.**</span> Overall, Ubiquant is committed to creating long-term, stable returns to investors.</font>\n> \n> <font size='3'><span style=\"color:#1B03A3;\">**In this competition**,</span> you’ll build a model that <span style=\"color:#1B03A3;\">**forecasts an investment's return rate.**</span> Train and test your algorithm on historical prices. Top entries will solve this real-world data science problem with as much accuracy as possible.</font>\n> \n><font size='3'><span style=\"color:#1B03A3;\">**If successful,**</span> you could improve the ability of quantitative researchers to forecast returns. This will enable investors at any scale to make better decisions. You may even discover you have a knack for financial datasets, opening up a world of new opportunities in many industries.\"<span>","metadata":{}},{"cell_type":"markdown","source":"# <a id='2'><span style=\"color:#1B03A3;\">Competition Objective</span></a>\n[Source](https://www.kaggle.com/c/ubiquant-market-prediction/overview/evaluation)  \n<font size='3'><span style=\"color:#1B03A3;\">**In this competition**</span> you’ll build a model that forecasts an investment's return rate. Train and test your algorithm on historical prices. Top entries will solve this real-world data science problem with as much accuracy as possible.\" </font> </div> \n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Submissions are evaluated**</span> on the mean of the Pearson correlation coefficient for each time ID. </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Welcome to Ubiquant Market Prediction competition**.</span> We hope this is a good opportunity to communicate with the world's top data scientists.</font> \n\n> - <font size='3'><span style=\"color:#1B03A3;\">**The features of the data set are all anonymous**,</span> so we will not respond to any questions related to the meaning of the features. Most of the problems are already covered on the data page.  </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**The mapping relationship between investment_id and a certain investment is fixed**,</span> but the investment_ids that appear in the train data, the public leaderboard, and the private leaderboard are not the same, some only appear in the train data, some only in public leaderboard and some only in the private leaderboard. </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**This dataset contains features derived from real historic data from thousands of investments.**</span> Your challenge is to predict the value of an <span style=\"color:#1B03A3;\">**obfuscated metric relevant for making trading decisions**.</span></font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**This is a code competition that relies on**</span> a time-series API to ensure models do not peek forward in time. To use the API, follow the instructions on the Evaluation page. When you submit your notebook, it will be rerun on an unseen test. This is also a forecasting competition, where the final private leaderboard will be determined using data gathered after the training period closes, which means that the public and private leaderboards will have zero overlap.</font>","metadata":{}},{"cell_type":"markdown","source":"# Problem Statement:\n\n## A better understanding of forecasting investment rate of returns is needed.","metadata":{}},{"cell_type":"markdown","source":"## Competion Host's Q&A\n\n[Source](https://www.kaggle.com/c/ubiquant-market-prediction/discussion/301693)\n   \n><span style=\"color:#1B03A3;\"><font size='3'>**Question**:</font></span> <font size='3'>Hi there,\n>are the investment_ids identical in train and test? Specifically,\n>do e.g. investment_id 17 in train and investment_id 17 in test correspond to the same investment?\n>do all investment_ids in test fall in the range 0…3773 which is present in train?\n>Thanks!  </font>\n\n><font size='3'><span style=\"color:#1B03A3;\">**Answer:**</span>  do e.g. investment_id 17 in train and investment_id 17 in test correspond to the same investment?\n>Yes</font>\n\n><font size='3'><span style=\"color:#1B03A3;\">**Question:**</span> Hi, during the time-series API, whether each batch returns a single “time_id\" includes all \"investment_id\"? </font> \n\n><font size='3'><span style=\"color:#1B03A3;\"> **Answer:**</span>  Each batch includes all rows associated with a time ID. As with the training data, not all time IDs necessarily have >data for every investment. </font> \n\n><font size='3'><span style=\"color:#1B03A3;\">**Question:**</span> I find 0~3773 investment_id in train.csv, but they are 2486 unique IDs. You say that:</font>\n\n><font size='3'>\"the investment_ids that appear in the <span style=\"color:#1B03A3;\">**train data**,</span> the <span style=\"color:#1B03A3;\">**public leaderboard**,</span> and the <span style=\"color:#1B03A3;\">**private leaderboard**</span> are <span style=\"color:#1B03A3;\">**not the same**,</span>  some only appear in the train data, some only in public leaderboard and some only in the private leaderboard.\"</font>\n\n><font size='3'>Is this mean is that there are over “3774\" investment_id in public/private leaderboard, or investment_id of 0~3773 that >are not in the train.csv are included in public/private leaderboard?</font>\n\n><font size='3'><span style=\"color:#1B03A3;\">**Answer:**</span> Hi Takamichi,  Over. The investment_id may exceed this range.  </font>\n\n><font size='3'><span style=\"color:#1B03A3;\">**Question\"** Hi,</span> does the time_id consistently correspond to the time with the same time gap by each id number? Or they have been randomized?  </font>\n\n> <font size='3'><span style=\"color:#1B03A3;\">**Chenqin Zhang Reply:**</span> A similar question about the API. Does the test_df from f_0 to f_1, f_2 etc… are all continuously? And is our goal to predict f_300 because it goes to f_299?</font>\n\n><font size='3'><span style=\"color:#1B03A3;\">**AbaoJiang Reply**</span> Hi @chenqinzhang,  Hi, does the time_id consistently correspond to the time with the same time gap by each id number? Or they have been randomized?  As the statement in data page says,  </font>\n\n> <font size='3'><span style=\"color:#1B03A3;\">**The time IDs are in order**,</span> but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.  I think the time gaps between time IDs aren't constant. Furthermore, there are also some missing time_ids existing.  </font>\n\n> <font size='3'><span style=\"color:#1B03A3;\">**Our objective is to predict**</span> the return rate of investments, which is presented in the column target in train.csv. The suffix of column name you mention only indicates feature ID, not the ordering of sequence.  </font>\n\n><font size='3'><span style=\"color:#1B03A3;\">**Gunes Evitan: Question**</span> Does time_id correspond to same time block for every investment_id? For example, are row_id 1_T and 2_T taken at the same time?  </font>\n\n><font size='3'><span style=\"color:#1B03A3;\">**Answer**</span> Seth Syun Competition Host Reply  \n>Hi Gunes, If you mean row_id 0_1 and 0_2, exactly right, they are taken at the same time. </font>\n\n><font size='3'><span style=\"color:#1B03A3;\"> **Question:**</span> I also want to confirm how we can make time series data from time & investment ids. If I have an investment id = 0 and then the time ids_____ does 0_1, 1_0, 2_0, ... form the investment ids historical time series data? </font>\n\n><font size='3'><span style=\"color:#1B03A3;\"> **Seth SyunCompetition Reply**</span> Hi RDizzl3, For investment_id=1, row_id 0_1,1_1,2_1 .. is  </font>\n","metadata":{}},{"cell_type":"markdown","source":"## Library","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom datatable import dt,f\nimport sys\nimport glob\nimport math\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import autocorrelation_plot\nfrom pandas.plotting import lag_plot\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom IPython.display import Image\nimport seaborn as sns\nsns.set()\n\nfrom statsmodels.tsa.stattools import adfuller, acf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.stattools import kpss\nimport statsmodels.api as sm\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport scipy as sp\nfrom scipy import stats\nfrom scipy.signal import periodogram\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom warnings import simplefilter\n\npd.set_option('max_columns', 64)\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\"axes\",labelweight=\"bold\",labelsize=\"large\",titleweight=\"bold\",titlesize=14,titlepad=10,)\nplot_params = dict(color=\"0.75\",style=\".-\",markeredgecolor=\"0.25\",markerfacecolor=\"0.25\",legend=False,)\n\n# memory reduction function\ndef reduce_mem_usage(df):\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        gc.collect()\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    del col_type,c_min,c_max,start_mem,end_mem,col\n    gc.collect()\n    \n    return df\ngc.collect()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-25T17:56:07.483079Z","iopub.execute_input":"2022-06-25T17:56:07.48335Z","iopub.status.idle":"2022-06-25T17:56:07.693629Z","shell.execute_reply.started":"2022-06-25T17:56:07.48332Z","shell.execute_reply":"2022-06-25T17:56:07.692788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='4'> Data</a>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**There are**</span> 304 columns in the original data.  Other than 'row_id', 'time_id', 'investment_id', and 'target', the remaining columns are features, 'f_0' to 'f_299'.  </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**There are**</span> 3,141,410 rows in the data.</font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Each 'time_id'**</span> includes a number of 'investment_id' values.  The 'investment_id' can be though of as a subset of the 'time_id' values.  Thus, the number of investments varies significantly over time.  Each investment consists of a 'row_id'.  Think of the 'row_id' as a mini time series for each investment??????</font>","metadata":{}},{"cell_type":"code","source":"MAX_ROWS = 25000 # LESS ROWS SPEEDS UP NOTEBOOK","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:07.69538Z","iopub.execute_input":"2022-06-25T17:56:07.695643Z","iopub.status.idle":"2022-06-25T17:56:07.705779Z","shell.execute_reply.started":"2022-06-25T17:56:07.695612Z","shell.execute_reply":"2022-06-25T17:56:07.704931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_df = reduce_mem_usage(dt.fread(\"../input/ubiquant-market-prediction/train.csv\", max_nrows = MAX_ROWS).to_pandas())\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:07.706906Z","iopub.execute_input":"2022-06-25T17:56:07.707183Z","iopub.status.idle":"2022-06-25T17:56:51.907221Z","shell.execute_reply.started":"2022-06-25T17:56:07.707151Z","shell.execute_reply":"2022-06-25T17:56:51.906252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:51.909783Z","iopub.execute_input":"2022-06-25T17:56:51.910119Z","iopub.status.idle":"2022-06-25T17:56:51.97656Z","shell.execute_reply.started":"2022-06-25T17:56:51.910074Z","shell.execute_reply":"2022-06-25T17:56:51.975981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Possibilities:\n\n> - <font size='4'>Objective:  To learn more about the features by trying to classify the features into groups.  Then studying the groups to learn more about the individual groups.</font>\n\n> - <font size='4'>Take 10 columns (features) like f_0 to f_10.  Train a classifer model on those 10 features.  Next, take all the other features and see if or HOW the model will classify them in those 10 feature positions.  </font>\n\n> - <font size='4'>Steps:</font>\n\n> - <font size='4'>1) Create a new notebook as if it were a classification problem.  Perhaps even use the recent TPS Feb 2022 model or something similar.</font>\n\n> - <font size='4'> <font size='4'>2)  Let the model train on that data and see what the result is.</font>\n\n> - <font size='4'>3)  If we end up with groups, we'll see what those groups have in common using ordinary EDA methods.</font>  \n\n> - <font size='4'>4)  Continue to refine results.</font>  \n\n> - <font size='4'>5)  Try to train a model on the data backwards, not just forward.  The results should be interesting.\n\n> - <font size='4'>6)  I could probably do this easily using one of the previous models with lightgbm.  ","metadata":{}},{"cell_type":"markdown","source":"### More Possibilities\n\n","metadata":{}},{"cell_type":"code","source":"train_df.sort_values(by=['time_id','investment_id'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:51.977707Z","iopub.execute_input":"2022-06-25T17:56:51.978068Z","iopub.status.idle":"2022-06-25T17:56:52.010376Z","shell.execute_reply.started":"2022-06-25T17:56:51.978025Z","shell.execute_reply":"2022-06-25T17:56:52.009577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sort_values(by=['row_id'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.011655Z","iopub.execute_input":"2022-06-25T17:56:52.012017Z","iopub.status.idle":"2022-06-25T17:56:52.047181Z","shell.execute_reply.started":"2022-06-25T17:56:52.011979Z","shell.execute_reply":"2022-06-25T17:56:52.046158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sort_values(by=['investment_id'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.048712Z","iopub.execute_input":"2022-06-25T17:56:52.049156Z","iopub.status.idle":"2022-06-25T17:56:52.082532Z","shell.execute_reply.started":"2022-06-25T17:56:52.049115Z","shell.execute_reply":"2022-06-25T17:56:52.081908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst = [i for i in range(1,50)]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.083634Z","iopub.execute_input":"2022-06-25T17:56:52.08402Z","iopub.status.idle":"2022-06-25T17:56:52.087677Z","shell.execute_reply.started":"2022-06-25T17:56:52.083984Z","shell.execute_reply":"2022-06-25T17:56:52.086772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id='5'>Feature Columns</a>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**There are**</span> 304 columns in the original data. Other than *'row_id',* *'time_id',* *'investment_id'*, and *'target'*, the remaining columns are features, 'f_0' to 'f_299'.</font>","metadata":{}},{"cell_type":"code","source":"gc.collect()\ntrain_columns=[]\ntrain_columns=train_df.columns.to_list()\nprint(train_columns)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.551933Z","iopub.status.idle":"2022-06-25T17:56:52.552265Z","shell.execute_reply.started":"2022-06-25T17:56:52.552096Z","shell.execute_reply":"2022-06-25T17:56:52.552114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id='6'>Missing Values</a>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Note:**</span>  There are no missing data points.  However, the investment Ids are not continuous and neither are the time Ids.  See below:</font>","metadata":{}},{"cell_type":"code","source":"gc.collect()\ntrain_df.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.553872Z","iopub.status.idle":"2022-06-25T17:56:52.55441Z","shell.execute_reply.started":"2022-06-25T17:56:52.554222Z","shell.execute_reply":"2022-06-25T17:56:52.554242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id = '7'> Time Ids</a>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Time Ids**</span> extend from 0 to 1211.  The following time ids are not included in this dataset: [361, 368, 369, 370, 371, 372, 382, 402, 403].  </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**The host has confirmed that the individual time_id values aren't necessarily of the same length:** </span></font> \n\n> - <font size='3'><span style=\"color:#1B03A3;\">**The time IDs are in order**,</span> but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set. I think the time gaps between time IDs aren't constant. Furthermore, there are also some missing time_ids existing.</font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**There are**</span> 1212 time Ids in this dataset.  Note, they are not consecutive.  See the time Ids not included in the dataset below.</font>","metadata":{}},{"cell_type":"code","source":"np.set_printoptions(threshold=sys.maxsize)\nnum_time_ids = np.sort(train_df['time_id'].unique())\ndiffs = np.diff(num_time_ids) != 1\ngc.collect()\nprint(f'Number of time Ids: {len(num_time_ids)}')\nindexes = np.nonzero(diffs)[0] + 1\ngroups = np.split(num_time_ids, indexes)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.55521Z","iopub.status.idle":"2022-06-25T17:56:52.555814Z","shell.execute_reply.started":"2022-06-25T17:56:52.555645Z","shell.execute_reply":"2022-06-25T17:56:52.555663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate Missing Time Ids\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Time Ids not included**</span> in this dataset: 361, 368, 369, 370, 371, 372, 382, 402, 403</font>","metadata":{}},{"cell_type":"code","source":"time_ids_missing = []\ncount=1\nfor i in groups:\n    if count == len(groups):\n        break\n    missing_between_groups = (groups[count][0]-i[-1])-1\n    if count < len(groups):\n        if missing_between_groups == 1:\n            missing=i[-1]+1\n            #print(f'Investment Id Ranges {i[0]} to {i[-1]} missing {missing_between_groups}  value(s) {missing}')\n            time_ids_missing.append(missing)\n        elif missing_between_groups >= 2:\n            for x in range(missing_between_groups):\n                missing= (i[-1] + x + 1)\n                #print(f'Investment Id Ranges {i[0]} to {i[-1]} missing {missing_between_groups}  value(s) {missing}')\n                time_ids_missing.append(missing)\n        count += 1\n    #else:\n        #print(f'Time Id Ranges {i[0]} to {i[-1]}')\ngc.collect()\nprint(f'Time Ids not included in this dataset: {time_ids_missing}') ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.556721Z","iopub.status.idle":"2022-06-25T17:56:52.557468Z","shell.execute_reply.started":"2022-06-25T17:56:52.557281Z","shell.execute_reply":"2022-06-25T17:56:52.557302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count of Time Id's Per Investment Distribution\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Notice the changes**</span> in the number of time_ids accross investments.</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**Also**,</span> notice the large increase in time_ids per investment toward the end of the data.</font>","metadata":{}},{"cell_type":"code","source":"time_ids_per_investment_dist = train_df.groupby(\"investment_id\")['time_id'].count()\nfig, ax = plt.subplots(figsize=(12,4))\nsns.histplot(time_ids_per_investment_dist, kde=True, bins=500, color='g')\nplt.title('time_id per investment dist')\nplt.show()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.558473Z","iopub.status.idle":"2022-06-25T17:56:52.558767Z","shell.execute_reply.started":"2022-06-25T17:56:52.558611Z","shell.execute_reply":"2022-06-25T17:56:52.558627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id='8'>Individual Investment Ids</a>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**There are**</span> 3579 unique 'investment_id' values, but they are not consecutive and they vary significantly over time. </font> \n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Investment Ids not included in this dataset:**</span>  5, 25, 27, 39, 96, 113, 119, 133, 153, 186, 210, 221, 223, 247, 256, 262, 288, 313, 320, 348, 355, 359, 380, 452, 456, 475, 477, 505, 519, 522, 530, 541, 545, 608, 635, 648, 661, 680, 684, 686, 692, 712, 737, 759, 779, 802, 825, 836, 853, 856, 927, 937, 945, 948, 964, 971, 981, 988, 1032, 1043, 1050, 1063, 1093, 1103, 1118, 1130, 1145, 1216, 1229, 1243, 1253, 1326, 1343, 1348, 1359, 1374, 1377, 1387, 1419, 1428, 1467, 1498, 1597, 1611, 1662, 1678, 1694, 1781, 1793, 1851, 1864, 1870, 1877, 1897, 1899, 1939, 1944, 1978, 1988, 2012, 2018, 2044, 2068, 2094, 2099, 2116, 2130, 2162, 2168, 2199, 2214, 2217, 2258, 2268, 2275, 2293, 2323, 2345, 2351, 2364, 2366, 2368, 2399, 2405, 2445, 2448, 2468, 2504, 2508, 2511, 2529, 2531, 2571, 2582, 2588, 2596, 2603, 2608, 2675, 2679, 2681, 2718, 2733, 2760, 2773, 2790, 2799, 2815, 2843, 2850, 2879, 2891, 2977, 2979, 2998, 3017, 3035, 3049, 3104, 3110, 3197, 3211, 3213, 3235, 3240, 3301, 3318, 3324, 3347, 3379, 3393, 3404, 3422, 3424, 3439, 3488, 3501, 3543, 3548, 3561, 3589, 3659, 3681, 3686, 3705, 3718, 3771.</font>\n","metadata":{}},{"cell_type":"code","source":"np.set_printoptions(threshold=sys.maxsize)\nnum_investment_id = np.sort(train_df['investment_id'].unique())\ndiffs = np.diff(num_investment_id) != 1\ndel time_ids_per_investment_dist\ngc.collect()\nprint(f'Number of investment Ids: {len(num_investment_id)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.560105Z","iopub.status.idle":"2022-06-25T17:56:52.560595Z","shell.execute_reply.started":"2022-06-25T17:56:52.560426Z","shell.execute_reply":"2022-06-25T17:56:52.560444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################### Keep this code block ######################\n\n# indexes = np.nonzero(diffs)[0] + 1\n# groups = np.split(num_investment_id, indexes)\n\n# ids_missing = []\n# count=1\n# for i in groups:\n#     if count < len(groups):\n#         if groups[count][0]-i[-1] == 2:\n#             missing=i[-1]+1\n#             # print(f'Investment Id Ranges {i[0]} to {i[-1]} missing {(groups[count][0]-i[-1])-1}  value(s) {missing}')\n#             ids_missing.append(missing)\n#         elif groups[count][0]-i[-1] > 2:\n#             missing=i[-1]+1\n#             # print(f'Investment Id Ranges {i[0]} to {i[-1]} missing {(groups[count][0]-i[-1])-1}  value(s) {missing}, {i[-1]+2}')\n#             ids_missing.append(i[-1]+2)\n#         count += 1\n# #     else:\n# #         print(f'Investment Id Ranges {i[0]} to {i[-1]}')\n# # print()\n# print(f'Investment Ids not included in this dataset: {ids_missing}') ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T17:56:52.561292Z","iopub.status.idle":"2022-06-25T17:56:52.561799Z","shell.execute_reply.started":"2022-06-25T17:56:52.561637Z","shell.execute_reply":"2022-06-25T17:56:52.561654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Investment Ids Over Time Id Distribution (Per Time Id)\n\n>  - <font size='3'><span style=\"color:#1B03A3;\">**Insights**:</span> Notice the number of investments per time_id starts out around 2300, becomes very volatile around 375 (time_id), then stabalizes into a somewhat steady uptrend until a few down splikes in the 800 to 1200 (time_id) range.</font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**As of right now**</span> (2/3/2022), I'm looking at the number of investment ids as a trade position.  Or think of it as the  size/composition of a trade position, or even the company's entire trade position at that time. </font> ","metadata":{}},{"cell_type":"code","source":"investment_ids_per_time_id = train_df.groupby('time_id')['investment_id'].count()\nfig, ax = plt.subplots()\nsns.lineplot(x=num_time_ids, y=investment_ids_per_time_id, ax=ax, color='g', alpha = .5)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.562959Z","iopub.status.idle":"2022-06-25T17:56:52.563504Z","shell.execute_reply.started":"2022-06-25T17:56:52.563317Z","shell.execute_reply":"2022-06-25T17:56:52.563336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='9'>Row Ids</a>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**There are**</span> 3,141,410 unique row ids in this dataset.  Each of these 'row_id's should be associated with a larger 'time_id'.  The time series should be constructed using the 'row_id' column.  Each row_id corresponds to a time_id and an investment_id.  </font>","metadata":{}},{"cell_type":"code","source":"rows = train_df['row_id'].sort_values(axis=0, ascending=True).unique()\ngc.collect()\nprint(f'Number of row ids: {len(rows)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.56444Z","iopub.status.idle":"2022-06-25T17:56:52.565Z","shell.execute_reply.started":"2022-06-25T17:56:52.56478Z","shell.execute_reply":"2022-06-25T17:56:52.5648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A Count of Row Ids Grouped by Time_Id. \n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Think of this chart**</span> as the amount of row_ids distributed accross time_ids.</font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Notice the large spike**</span> of row_ids between 2000 and 2500.  Could this be creation and unwinding of a very large trade position?</font>","metadata":{}},{"cell_type":"code","source":"row_ids_per_time_id = train_df.groupby(\"time_id\")['row_id'].count()\nfig, ax = plt.subplots(figsize=(10,4))\nsns.histplot(row_ids_per_time_id, kde=True, bins=500, color='g')\nplt.title('row_ids_per_time_id')\nplt.show()\ndel investment_ids_per_time_id\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.566018Z","iopub.status.idle":"2022-06-25T17:56:52.566614Z","shell.execute_reply.started":"2022-06-25T17:56:52.566419Z","shell.execute_reply":"2022-06-25T17:56:52.566441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Row Id Count Grouped By Investment Id\n\n> <font size='3'><span style=\"color:#1B03A3;\">**Insights:**</span>  Notice the similarities between this plot and the time_ids per investment_id distribution plot.  What is this data telling me?</font>","metadata":{}},{"cell_type":"code","source":"row_id_count_per_investment_id = train_df.groupby('investment_id')['row_id'].count()\nfig, ax = plt.subplots(figsize=(10,4))\nsns.histplot(row_id_count_per_investment_id, kde=True, bins=500, color='g')\nplt.title('Row Id Count Grouped By Investment Id')\nplt.show()\ngc.collect()\n# fig, ax = plt.subplots()\n# sns.histplot(x=num_investment_id, y=row_id_count_per_investment_id, ax=ax, color='g', bins=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.567718Z","iopub.status.idle":"2022-06-25T17:56:52.568141Z","shell.execute_reply.started":"2022-06-25T17:56:52.56795Z","shell.execute_reply":"2022-06-25T17:56:52.56797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='10'> Target Analysis</a>\n\n- <font size='3'>There are 3,141,410 targets in the data.  Each row in the data includes a target. </font> \n- <font size='3'>There are 2,168 unique target values in the data???? </font>\n- <font size='3'>The target, plotted over time shows a mostly normal distribution, with a slight left tilt.</font>\n- <font size='3'>No missing values.</font>\n","metadata":{}},{"cell_type":"code","source":"train_df.target.isna()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.569207Z","iopub.status.idle":"2022-06-25T17:56:52.569821Z","shell.execute_reply.started":"2022-06-25T17:56:52.569634Z","shell.execute_reply":"2022-06-25T17:56:52.569654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id='11'>Target Distribution Plot</a>\n\n> <font size='3'>-<span style=\"color:#1B03A3;\">**Shows a mostly**</span> normal distribution.  Slight left tilt, but only slight.  Why??</font>\n\n### Question:\n\n<font size='3'>Why does the normal distribution tilt ever so slightly to the left?  There has to be an explanation for this.</font>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14,6))\nsns.histplot(train_df, x=\"target\", bins=500, color='g')\nplt.title('Target distribution over time_id')\nplt.show()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.570659Z","iopub.status.idle":"2022-06-25T17:56:52.571484Z","shell.execute_reply.started":"2022-06-25T17:56:52.571283Z","shell.execute_reply":"2022-06-25T17:56:52.571306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_count =  train_df.target.count()\ntarget_unique = pd.DataFrame(train_df.target.unique()).count()\ngc.collect()\nprint(f'There are {target_count} targets in the data, {target_unique} of which are unique.')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.572468Z","iopub.status.idle":"2022-06-25T17:56:52.573164Z","shell.execute_reply.started":"2022-06-25T17:56:52.572912Z","shell.execute_reply":"2022-06-25T17:56:52.572943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id='12'>Unique Target Values</a>\n\n> <font size='3'>Number of unique target values grouped by investment_ids = 3579   </font>\n\n> <font size='3'>Number of unique target values grouped by time_ids = 1211   </font>\n\n> <font size='3'>Number of unique target values grouped by row_ids = 3,141,410   </font>\n","metadata":{}},{"cell_type":"code","source":"############### Keep This Code Block #########################\n# unique_target_values_grouped_by_investment_ids = train_df.groupby(\"investment_id\")['target'].unique().count()\n# unique_target_values_grouped_by_time_ids = train_df.groupby(\"time_id\")['target'].unique().count()\n# unique_target_values_grouped_by_row_ids = train_df.groupby(\"row_id\")['target'].unique().count()\n\n# print(f'Number of unique target_values_grouped_by_investment_ids = {unique_target_values_grouped_by_investment_ids}')\n# print(f'Number of unique_target_values_grouped_by_time_ids = {unique_target_values_grouped_by_time_ids}')\n# print(f'Number of unique_target_values_grouped_by_row_ids = {unique_target_values_grouped_by_row_ids}')\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.574651Z","iopub.status.idle":"2022-06-25T17:56:52.57532Z","shell.execute_reply.started":"2022-06-25T17:56:52.57505Z","shell.execute_reply":"2022-06-25T17:56:52.575077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############### Keep This Code Block #########################\n# unique_target_values_grouped_by_investment_ids\n# unique_target_values_grouped_by_time_ids\n# unique_target_values_grouped_by_row_ids","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.576522Z","iopub.status.idle":"2022-06-25T17:56:52.577148Z","shell.execute_reply.started":"2022-06-25T17:56:52.576888Z","shell.execute_reply":"2022-06-25T17:56:52.576914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count of Target Values Distributed over Time Periods\n\n> -<font size='3'><span style=\"color:green;\"></span>**Notice the spike** in target values between 2000 and 2500.  This increase is most likely associated with the spike in investment_ids.</font>","metadata":{}},{"cell_type":"code","source":"target_over_time = train_df.groupby(\"time_id\")['target'].count()\nfig, ax = plt.subplots(figsize=(10,5))\nsns.histplot(target_over_time, kde=True,bins=500,color='g')\nplt.title('Target distributed over time_id')\ndel target_unique\nplt.show()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.578376Z","iopub.status.idle":"2022-06-25T17:56:52.579002Z","shell.execute_reply.started":"2022-06-25T17:56:52.578725Z","shell.execute_reply":"2022-06-25T17:56:52.578752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Basic Statistics of Unique Target Values Grouped by Time Periods","metadata":{}},{"cell_type":"code","source":"############### Keep This Code Block #########################\n# pd.DataFrame(unique_target_values_grouped_by_time_ids.describe())","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.580096Z","iopub.status.idle":"2022-06-25T17:56:52.580966Z","shell.execute_reply.started":"2022-06-25T17:56:52.580664Z","shell.execute_reply":"2022-06-25T17:56:52.580693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Basic Statistics of the Count Target Values over Time Periods\n\n> -<font size='3'><span style=\"color:#1B03A3;\"> **Insights:** ? ?????????????????????\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Basic Statistics:**\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**count  =**</span>    1211  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**mean  =**</span>     2594.062758</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**std  =**</span>     475.552690</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**min  =**</span>      512</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**25  =**</span>      2252</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**50  =**</span>      2489</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**75  =**</span>      3030</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**max  =**</span>      3445</font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**What is** this data telling me? </span></font>\n","metadata":{}},{"cell_type":"code","source":"############### Keep This Code Block #########################\n# pd.DataFrame(target_over_time.describe())","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.582045Z","iopub.status.idle":"2022-06-25T17:56:52.582867Z","shell.execute_reply.started":"2022-06-25T17:56:52.582654Z","shell.execute_reply":"2022-06-25T17:56:52.582676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unique Target Values Grouped by Investment Ids\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Insights**:</span>  As can be seen in the plot below, most of the target values (grouped by investment ID) are centered around zero, with a slight shift below zero.  </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**The remaining**</span> target values cluster around -2.5 and from a range 1.3 to 2.5, with a few more values in the -2.5 area.  </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**What does the data**</span> wish to reveal?  </font>\n\n### Question:\n\n<font size='3'>Why are the target values (those centered around zero) shifted to the left?  More below zero?</font>","metadata":{}},{"cell_type":"code","source":"unique_target_values_grouped_by_investment_ids = train_df.groupby(\"investment_id\")['target'].unique()\nfig, ax = plt.subplots(figsize=(10,5))\nunique_target_values_grouped_by_investment_ids.hist()\nplt.title('Unique Target Values grouped by investment_id')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.583825Z","iopub.status.idle":"2022-06-25T17:56:52.58436Z","shell.execute_reply.started":"2022-06-25T17:56:52.58417Z","shell.execute_reply":"2022-06-25T17:56:52.58419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Basic Statistics of the Unique Target Values Grouped by Investment Ids","metadata":{}},{"cell_type":"code","source":"############### Keep This Code Block #########################\n# pd.DataFrame(unique_target_values_grouped_by_investment_ids.describe())","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.585328Z","iopub.status.idle":"2022-06-25T17:56:52.585809Z","shell.execute_reply.started":"2022-06-25T17:56:52.585632Z","shell.execute_reply":"2022-06-25T17:56:52.585652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Basic Statistics of the Count of Target Values Grouped by Investment Ids\n\n> - <span style=\"color:#1B03A3;\">**Basic Statistics:**</span>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**count**</span>    3579  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**mean**</span>     877.73  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**std**</span>        314.977  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**min**</span>          2  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**25**%</span>       683  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**50**% </span>      1009  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**75**% </span>      1131  </font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**max** </span>      1211  </font>","metadata":{}},{"cell_type":"code","source":"unique_target_values_grouped_by_investment_ids = train_df.groupby(\"investment_id\")['target'].count()\nunique_target_values_grouped_by_investment_ids.describe()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.586769Z","iopub.status.idle":"2022-06-25T17:56:52.587285Z","shell.execute_reply.started":"2022-06-25T17:56:52.587106Z","shell.execute_reply":"2022-06-25T17:56:52.587126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unique Target Values Grouped by Unique Time_Ids\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Insights**:</span> The majority of the target values (grouped by time_ids), are cluster around zero - slightly below and slightly above, with more above zero.</font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**There are also clusters**</span> in the -2.5 range and the + 2.5 range.  Smaller clusters exist around the -5 and +5 ranges, with tails extending both ways from there.</font>","metadata":{}},{"cell_type":"code","source":"unique_target_values_grouped_by_time_ids = train_df.groupby(\"time_id\")['target'].unique()\nfig, ax = plt.subplots(figsize=(10,5))\nunique_target_values_grouped_by_time_ids.hist()\nplt.title('Unique Target Values grouped by time_ids')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.588249Z","iopub.status.idle":"2022-06-25T17:56:52.588743Z","shell.execute_reply.started":"2022-06-25T17:56:52.588553Z","shell.execute_reply":"2022-06-25T17:56:52.588574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Basic Statistics of Unique Target Values Grouped by Time_Ids\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Basic Statistics:**</span></font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**count**</span>   3579</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**mean**</span>     877.734004</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**std**</span>      314.977410</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**min**</span>        2</font> \n> - <font size='3'><span style=\"color:#1B03A3;\">**25**%</span>      683</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**50**%</span>     1009</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**75**%</span>     1131</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**max**</span>     1211</font>","metadata":{}},{"cell_type":"code","source":"# pd.DataFrame(unique_target_values_grouped_by_time_ids.describe())","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.589709Z","iopub.status.idle":"2022-06-25T17:56:52.590214Z","shell.execute_reply.started":"2022-06-25T17:56:52.58998Z","shell.execute_reply":"2022-06-25T17:56:52.590009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Basic Statistics of the Count of Target Values Grouped by Time_Ids\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Insights:**</span> ? ????????????????????? </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**Basic Statistics:**</span> </font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**count  =**</span> 3579.000000</font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**mean   =**</span>  877.734004</span></font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**std    =**</span>  314.977410</span></font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**min    =**</span>    2.000000</span></font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**25     =**</span>  683.000000</span></font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**50     =**</span> 1009.000000</span></font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**75     =**</span> 1131.000000</span></font>\n> - <font size='3'><span style=\"color:#1B03A3;\">**max     =**</span>1211.000000</span></font>\n\n> - <font size='3'><span style=\"color:#1B03A3;\">**What is** this data telling me?</span></font>\n\n### Questions:\n\n<font size='3'>Why more target values to the right of zero?</font>\n","metadata":{}},{"cell_type":"code","source":"unique_target_values_grouped_by_time_ids = train_df.groupby(\"investment_id\")['target'].count()\ngc.collect()\nunique_target_values_grouped_by_time_ids.describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.59143Z","iopub.status.idle":"2022-06-25T17:56:52.591756Z","shell.execute_reply.started":"2022-06-25T17:56:52.591586Z","shell.execute_reply":"2022-06-25T17:56:52.591608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unique Target Values Groupd By Row Id\n\n> -<font size='3'><span style=\"color:#1B03A3;\"> **Insights**:</span></font>  \n> -<font size='3'><font size='3'><span style=\"color:#1B03A3;\">**This distribution**</span> looks quite similar to the \"row_ids to investment_ids chart.\"  Most likely because target values correlates with investment ids.  The more investments you have during a given time period, the more target ids you'll have, and the more row_ids as well.  </font>","metadata":{}},{"cell_type":"code","source":"unique_target_values_grouped_by_row_ids = train_df.groupby(\"time_id\")['target'].unique()\nfig, ax = plt.subplots(figsize=(10,5))\nunique_target_values_grouped_by_time_ids.hist(bins=500)\nplt.title('Unique Target Values grouped by row_ids')\nplt.show()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.592954Z","iopub.status.idle":"2022-06-25T17:56:52.593268Z","shell.execute_reply.started":"2022-06-25T17:56:52.593101Z","shell.execute_reply":"2022-06-25T17:56:52.593122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Basic Statistics of Unique Target Values Grouped by Row Ids\n\n> - <font size='3'>Insights:  Left Skewed data, probably because a larger trading position is correlated with more rows.  Except, that doesn't explain slight increase in Unique Target Values from the range 200 to 600.\n\n> - <font size='3'>Basic Statistics:</font>\n> - <font size='3'>**count**   211</font>\n> - <font size='3'>**mean**    2594.06</font>\n> - <font size='3'>**std**     475</font>\n> - <font size='3'>**min**     512</font>\n> - <font size='3'>**25**%     2252</font>\n> - <font size='3'>**50**%     2489</font>\n> - <font size='3'>**75**%     3030</font>\n> - <font size='3'>**max**     3445</font>\n\n### Question:\n<font size='3'>Why do the amount of Unique Target Values increase (then decrease) between 200 and 600? Do unique investment Ids do the same?</font>","metadata":{}},{"cell_type":"code","source":"############### Keep This Code Block #########################\n# pd.DataFrame(unique_target_values_grouped_by_row_ids.describe())","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.595291Z","iopub.status.idle":"2022-06-25T17:56:52.595636Z","shell.execute_reply.started":"2022-06-25T17:56:52.595447Z","shell.execute_reply":"2022-06-25T17:56:52.595479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Basic Statistics of the Count of Target Values Grouped by Row Ids\n\n> - <font size='3'>**count**    1211</font>\n> - <font size='3'>**mean**     2594.06</font>\n> - <font size='3'>**std**       475.55</font>\n> - <font size='3'>**min**       512</font>\n> - <font size='3'>**25**%      2252</font>\n> - <font size='3'>**50**%      2489</font>\n> - <font size='3'>**75**%      3030</font>\n> - <font size='3'>**max**      3445</font>","metadata":{}},{"cell_type":"code","source":"del unique_target_values_grouped_by_time_ids\nunique_target_values_grouped_by_row_ids = train_df.groupby(\"time_id\")['target'].count()\npd.DataFrame(unique_target_values_grouped_by_row_ids.describe())\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.597117Z","iopub.status.idle":"2022-06-25T17:56:52.59745Z","shell.execute_reply.started":"2022-06-25T17:56:52.597271Z","shell.execute_reply":"2022-06-25T17:56:52.597292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del unique_target_values_grouped_by_row_ids\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.598921Z","iopub.status.idle":"2022-06-25T17:56:52.599569Z","shell.execute_reply.started":"2022-06-25T17:56:52.599363Z","shell.execute_reply":"2022-06-25T17:56:52.599388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sort_values(by=['time_id','investment_id','row_id'], inplace=True)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.600588Z","iopub.status.idle":"2022-06-25T17:56:52.601292Z","shell.execute_reply.started":"2022-06-25T17:56:52.60104Z","shell.execute_reply":"2022-06-25T17:56:52.601068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_save_file = train_df.iloc[:10000,:]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.602368Z","iopub.status.idle":"2022-06-25T17:56:52.603054Z","shell.execute_reply.started":"2022-06-25T17:56:52.602806Z","shell.execute_reply":"2022-06-25T17:56:52.602833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_save_file.to_csv('./train_save_file_first_10000.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.604206Z","iopub.status.idle":"2022-06-25T17:56:52.60453Z","shell.execute_reply.started":"2022-06-25T17:56:52.604362Z","shell.execute_reply":"2022-06-25T17:56:52.604382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='18'>Features Analysis</a>\n\n### <a id='15'>Feature Correlation with Target</a>","metadata":{}},{"cell_type":"code","source":"train_df = train_df[[column for column in train_df if column not in ['target']] + ['target']]  # rearrange columns\ntrain_df = train_df.loc[:, train_df.columns != 'row_id']  # leave out row_id\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.605961Z","iopub.status.idle":"2022-06-25T17:56:52.606293Z","shell.execute_reply.started":"2022-06-25T17:56:52.606119Z","shell.execute_reply":"2022-06-25T17:56:52.606141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation_df = train_df.corr()\n\n# correlation = pd.load_csv('./correlation_df.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.607656Z","iopub.status.idle":"2022-06-25T17:56:52.608167Z","shell.execute_reply.started":"2022-06-25T17:56:52.60796Z","shell.execute_reply":"2022-06-25T17:56:52.607995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.plotting.lag_plot(train_df.f_3.iloc[:10000], lag=2)\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.609395Z","iopub.status.idle":"2022-06-25T17:56:52.609731Z","shell.execute_reply.started":"2022-06-25T17:56:52.60956Z","shell.execute_reply":"2022-06-25T17:56:52.609583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.autocorrelation_plot(train_df.target.iloc[0:10000])\n# pd.plotting.autocorrelation_plot(train_df.f_1.iloc[101:200])\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.61061Z","iopub.status.idle":"2022-06-25T17:56:52.610937Z","shell.execute_reply.started":"2022-06-25T17:56:52.610747Z","shell.execute_reply":"2022-06-25T17:56:52.610763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='14'>Boxplot Overview of Features</a>","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.612377Z","iopub.status.idle":"2022-06-25T17:56:52.612703Z","shell.execute_reply.started":"2022-06-25T17:56:52.612527Z","shell.execute_reply":"2022-06-25T17:56:52.61255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference:  https://medium.com/analytics-vidhya/exploratory-data-analysis-eda-of-non-seasonal-time-series-51923db4006e\nf, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_0 to f_30',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,2:33],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.613924Z","iopub.status.idle":"2022-06-25T17:56:52.614241Z","shell.execute_reply.started":"2022-06-25T17:56:52.614072Z","shell.execute_reply":"2022-06-25T17:56:52.614094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.autocorrelation_plot(train_df.f_4.iloc[:100], ax=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.615187Z","iopub.status.idle":"2022-06-25T17:56:52.615506Z","shell.execute_reply.started":"2022-06-25T17:56:52.61533Z","shell.execute_reply":"2022-06-25T17:56:52.615351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Various Features","metadata":{}},{"cell_type":"code","source":"pd.plotting.bootstrap_plot(train_df.f_4.iloc[:100000],fig=None, size=50, samples=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.617135Z","iopub.status.idle":"2022-06-25T17:56:52.617962Z","shell.execute_reply.started":"2022-06-25T17:56:52.617727Z","shell.execute_reply":"2022-06-25T17:56:52.617754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.autocorrelation_plot(train_df.f_10.iloc[:100], ax=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.619073Z","iopub.status.idle":"2022-06-25T17:56:52.619401Z","shell.execute_reply.started":"2022-06-25T17:56:52.61923Z","shell.execute_reply":"2022-06-25T17:56:52.619251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.bootstrap_plot(train_df.f_10.iloc[:100000],fig=None, size=50, samples=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.620449Z","iopub.status.idle":"2022-06-25T17:56:52.620752Z","shell.execute_reply.started":"2022-06-25T17:56:52.620595Z","shell.execute_reply":"2022-06-25T17:56:52.620611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.autocorrelation_plot(train_df.f_19.iloc[:100], ax=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.621676Z","iopub.status.idle":"2022-06-25T17:56:52.622033Z","shell.execute_reply.started":"2022-06-25T17:56:52.621818Z","shell.execute_reply":"2022-06-25T17:56:52.62184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.bootstrap_plot(train_df.f_19.iloc[:100000],fig=None, size=50, samples=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.623672Z","iopub.status.idle":"2022-06-25T17:56:52.624018Z","shell.execute_reply.started":"2022-06-25T17:56:52.623822Z","shell.execute_reply":"2022-06-25T17:56:52.623862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.autocorrelation_plot(train_df.f_19.iloc[:100], ax=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.62496Z","iopub.status.idle":"2022-06-25T17:56:52.625268Z","shell.execute_reply.started":"2022-06-25T17:56:52.625101Z","shell.execute_reply":"2022-06-25T17:56:52.625121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.bootstrap_plot(train_df.f_22.iloc[:100000],fig=None, size=50, samples=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.626348Z","iopub.status.idle":"2022-06-25T17:56:52.627147Z","shell.execute_reply.started":"2022-06-25T17:56:52.626924Z","shell.execute_reply":"2022-06-25T17:56:52.626955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_32 to f_61',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,33:64],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.628762Z","iopub.status.idle":"2022-06-25T17:56:52.629116Z","shell.execute_reply.started":"2022-06-25T17:56:52.628937Z","shell.execute_reply":"2022-06-25T17:56:52.62896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_62 to f_91',fontsize=10);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,64:94],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.630149Z","iopub.status.idle":"2022-06-25T17:56:52.63088Z","shell.execute_reply.started":"2022-06-25T17:56:52.630653Z","shell.execute_reply":"2022-06-25T17:56:52.63068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_92 to f_123',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,94:126],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.631896Z","iopub.status.idle":"2022-06-25T17:56:52.632226Z","shell.execute_reply.started":"2022-06-25T17:56:52.632054Z","shell.execute_reply":"2022-06-25T17:56:52.632077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_124 to f_154',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,126:157],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.633657Z","iopub.status.idle":"2022-06-25T17:56:52.63431Z","shell.execute_reply.started":"2022-06-25T17:56:52.634108Z","shell.execute_reply":"2022-06-25T17:56:52.634131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_155 to f_185',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,157:188],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.635412Z","iopub.status.idle":"2022-06-25T17:56:52.636019Z","shell.execute_reply.started":"2022-06-25T17:56:52.635778Z","shell.execute_reply":"2022-06-25T17:56:52.635804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_186 to f_207',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,188:210],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.637203Z","iopub.status.idle":"2022-06-25T17:56:52.637528Z","shell.execute_reply.started":"2022-06-25T17:56:52.637354Z","shell.execute_reply":"2022-06-25T17:56:52.637377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_208 to f_237',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,210:240],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.638554Z","iopub.status.idle":"2022-06-25T17:56:52.639304Z","shell.execute_reply.started":"2022-06-25T17:56:52.639095Z","shell.execute_reply":"2022-06-25T17:56:52.639122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_238 to f_262',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,240:265],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.640144Z","iopub.status.idle":"2022-06-25T17:56:52.640441Z","shell.execute_reply.started":"2022-06-25T17:56:52.640282Z","shell.execute_reply":"2022-06-25T17:56:52.640298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_263 to f_281',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,265:284],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.641885Z","iopub.status.idle":"2022-06-25T17:56:52.642207Z","shell.execute_reply.started":"2022-06-25T17:56:52.642033Z","shell.execute_reply":"2022-06-25T17:56:52.642056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(7,3),dpi=150,sharex=True)\nplt.suptitle('Comparison of Unscaled Features f_282 to f_299 + Target',fontsize=12);\nplt.xticks(fontsize=5)  # for xticks\n\n# feature columns are 2 - 302 (including target)\nsns.boxplot(data=train_df.iloc[:1000,284:303],ax=axes)\naxes.set_ylabel('Unscaled Values');\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.6434Z","iopub.status.idle":"2022-06-25T17:56:52.643745Z","shell.execute_reply.started":"2022-06-25T17:56:52.643564Z","shell.execute_reply":"2022-06-25T17:56:52.643589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Histogram subplots with 5 by 5 axes matrix.\n# f, axes = plt.subplots(5,5,figsize=(18,18),dpi=600);\n\n# # Change space around axes to prevent label overlap.\n# f.tight_layout(pad=2.0);\n\n# for row in range(5):\n#     for column in range(5):\n#         feature = 25 + (1 + row * 5 + column)\n#         sns.histplot(x=train_df.iloc[:1000,feature], ax=axes[row][column], bins=10);\n        \n# gc.collect()      ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.644818Z","iopub.status.idle":"2022-06-25T17:56:52.645172Z","shell.execute_reply.started":"2022-06-25T17:56:52.644998Z","shell.execute_reply":"2022-06-25T17:56:52.645022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='16'>Mutual Information</a>\n\n<font size='4'>According to Wikipedia, [mutual information](https://en.wikipedia.org/wiki/Mutual_information) \"quantifies the 'amount of information' obtained about one random variable by observing the other random variable.\"  In our application, 'random variables' are features.","metadata":{}},{"cell_type":"code","source":"# reference:  https://www.kaggle.com/ryanholbrook/mutual-information\ndef make_mi_scores(X, y):\n    mi_scores = mutual_info_regression(X, y)\n    # mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n\nmi_scores = make_mi_scores(train_df.iloc[:20000,2:152],train_df.target[0:20000])\nplt.figure(dpi=100, figsize=(8, 30))\n\nplot_mi_scores(mi_scores)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.646119Z","iopub.status.idle":"2022-06-25T17:56:52.646428Z","shell.execute_reply.started":"2022-06-25T17:56:52.64626Z","shell.execute_reply":"2022-06-25T17:56:52.646283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    mi_scores = make_mi_scores(train_df.iloc[0:20000,152:302],train_df.target[0:20000])\n    plt.figure(dpi=100, figsize=(8, 30))\n    plot_mi_scores(mi_scores)\n    gc.collect()\nexcept:\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.647671Z","iopub.status.idle":"2022-06-25T17:56:52.64802Z","shell.execute_reply.started":"2022-06-25T17:56:52.647816Z","shell.execute_reply":"2022-06-25T17:56:52.647837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    mi_scores = make_mi_scores(train_df.iloc[20000:40000,0:150],train_df.target[20000:40000])\n    plt.figure(dpi=100, figsize=(8, 30))\n    plot_mi_scores(mi_scores)\n    gc.collect()\nexcept:\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.649927Z","iopub.status.idle":"2022-06-25T17:56:52.65024Z","shell.execute_reply.started":"2022-06-25T17:56:52.650084Z","shell.execute_reply":"2022-06-25T17:56:52.650101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    mi_scores = make_mi_scores(train_df.iloc[20000:40000,150:302],train_df.target[20000:40000])\n    plt.figure(dpi=100, figsize=(8, 30))\n    plot_mi_scores(mi_scores)\n    gc.collect()\nexcept:\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.651024Z","iopub.status.idle":"2022-06-25T17:56:52.651318Z","shell.execute_reply.started":"2022-06-25T17:56:52.651161Z","shell.execute_reply":"2022-06-25T17:56:52.651178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    mi_scores = make_mi_scores(train_df.iloc[40000:60000,2:150],train_df.target[40000:60000])\n    plt.figure(dpi=100, figsize=(8,30))\n    plot_mi_scores(mi_scores)\n    gc.collect()\nexcept:\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.652738Z","iopub.status.idle":"2022-06-25T17:56:52.653528Z","shell.execute_reply.started":"2022-06-25T17:56:52.653314Z","shell.execute_reply":"2022-06-25T17:56:52.653342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    train_df.fillna(0,inplace=True)\n    mi_scores = make_mi_scores(train_df.iloc[40000:60000,150:302],train_df.target[40000:60000])\n    plt.figure(dpi=100, figsize=(8, 30))\n    plot_mi_scores(mi_scores)\n    gc.collect()\nexcept:\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T17:56:52.655031Z","iopub.status.idle":"2022-06-25T17:56:52.655513Z","shell.execute_reply.started":"2022-06-25T17:56:52.655332Z","shell.execute_reply":"2022-06-25T17:56:52.655358Z"},"trusted":true},"execution_count":null,"outputs":[]}]}