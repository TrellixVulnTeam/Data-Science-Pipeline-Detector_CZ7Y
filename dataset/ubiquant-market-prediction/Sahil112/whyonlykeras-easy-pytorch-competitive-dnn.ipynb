{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### points to take care of now onwards\n1. Add PCA components\n1. Search how to make the NN deeper\n1. Get it on the GPU\n1. Plot training losses with the validation losses\n1. **use KFold CV**","metadata":{}},{"cell_type":"markdown","source":"# usual imports","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\n\nimport matplotlib.pyplot as plt\nfrom scipy import stats# Imports\nimport torch\n\nimport torchvision\nimport torch.nn as nn\n\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","metadata":{"papermill":{"duration":7.781864,"end_time":"2022-01-25T15:39:09.265726","exception":false,"start_time":"2022-01-25T15:39:01.483862","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-19T12:00:35.629142Z","iopub.execute_input":"2022-02-19T12:00:35.629528Z","iopub.status.idle":"2022-02-19T12:00:37.847154Z","shell.execute_reply.started":"2022-02-19T12:00:35.629427Z","shell.execute_reply":"2022-02-19T12:00:37.846366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:00:37.848899Z","iopub.execute_input":"2022-02-19T12:00:37.849158Z","iopub.status.idle":"2022-02-19T12:00:37.961519Z","shell.execute_reply.started":"2022-02-19T12:00:37.849123Z","shell.execute_reply":"2022-02-19T12:00:37.960815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:00:37.96285Z","iopub.execute_input":"2022-02-19T12:00:37.963248Z","iopub.status.idle":"2022-02-19T12:00:37.980976Z","shell.execute_reply.started":"2022-02-19T12:00:37.963206Z","shell.execute_reply":"2022-02-19T12:00:37.980244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset","metadata":{"papermill":{"duration":0.015291,"end_time":"2022-01-25T15:39:09.296817","exception":false,"start_time":"2022-01-25T15:39:09.281526","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\ntrain.head(2)","metadata":{"papermill":{"duration":16.88418,"end_time":"2022-01-25T15:39:26.19638","exception":false,"start_time":"2022-01-25T15:39:09.3122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-19T12:00:37.983945Z","iopub.execute_input":"2022-02-19T12:00:37.984138Z","iopub.status.idle":"2022-02-19T12:00:55.003114Z","shell.execute_reply.started":"2022-02-19T12:00:37.984115Z","shell.execute_reply":"2022-02-19T12:00:55.002418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = train.drop(['target'], axis=1).values\ntargets = train[['target']].values\n\ninputs.shape, targets.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:00:55.004353Z","iopub.execute_input":"2022-02-19T12:00:55.004598Z","iopub.status.idle":"2022-02-19T12:01:02.574051Z","shell.execute_reply.started":"2022-02-19T12:00:55.004565Z","shell.execute_reply":"2022-02-19T12:01:02.573235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 80 % split number - just for splitting","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.018581Z","iopub.execute_input":"2022-02-12T07:05:50.020216Z","iopub.status.idle":"2022-02-12T07:05:50.028672Z","shell.execute_reply.started":"2022-02-12T07:05:50.020168Z","shell.execute_reply":"2022-02-12T07:05:50.027667Z"}}},{"cell_type":"code","source":"val_1 = int(0.8*inputs.shape[0])\nval_2 = int(0.2*inputs.shape[0])\nval_1, val_2","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:02.575373Z","iopub.execute_input":"2022-02-19T12:01:02.57564Z","iopub.status.idle":"2022-02-19T12:01:02.583483Z","shell.execute_reply.started":"2022-02-19T12:01:02.575604Z","shell.execute_reply":"2022-02-19T12:01:02.582755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.030025Z","iopub.execute_input":"2022-02-12T07:05:50.030959Z","iopub.status.idle":"2022-02-12T07:05:50.04492Z","shell.execute_reply.started":"2022-02-12T07:05:50.030913Z","shell.execute_reply":"2022-02-12T07:05:50.043616Z"}}},{"cell_type":"code","source":"batch_size = 2000\nTARGET_COLUMN = 'target'\ninput_size=302\noutput_size=1","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:02.584737Z","iopub.execute_input":"2022-02-19T12:01:02.585079Z","iopub.status.idle":"2022-02-19T12:01:02.591118Z","shell.execute_reply.started":"2022-02-19T12:01:02.585016Z","shell.execute_reply":"2022-02-19T12:01:02.590461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:02.592315Z","iopub.execute_input":"2022-02-19T12:01:02.592691Z","iopub.status.idle":"2022-02-19T12:01:02.710862Z","shell.execute_reply.started":"2022-02-19T12:01:02.592655Z","shell.execute_reply":"2022-02-19T12:01:02.710147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert to PyTorch dataset (DataLoader)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.046326Z","iopub.execute_input":"2022-02-12T07:05:50.048467Z","iopub.status.idle":"2022-02-12T07:05:53.061696Z","shell.execute_reply.started":"2022-02-12T07:05:50.048424Z","shell.execute_reply":"2022-02-12T07:05:53.060279Z"}}},{"cell_type":"code","source":"dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32))\ntrain_ds, val_ds = random_split(dataset, [val_1, val_2])\n\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=False) # future predict karna hai na\nval_loader = DataLoader(val_ds, batch_size*2)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:02.712147Z","iopub.execute_input":"2022-02-19T12:01:02.712395Z","iopub.status.idle":"2022-02-19T12:01:05.375022Z","shell.execute_reply.started":"2022-02-19T12:01:02.712357Z","shell.execute_reply":"2022-02-19T12:01:05.374211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_ds, val_ds, dataset, inputs, targets\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:05.37863Z","iopub.execute_input":"2022-02-19T12:01:05.378906Z","iopub.status.idle":"2022-02-19T12:01:05.56556Z","shell.execute_reply.started":"2022-02-19T12:01:05.378874Z","shell.execute_reply":"2022-02-19T12:01:05.56487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GPU Utilities\n#### these will help later to get our models/dataloaders on the GPU!","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:05.567135Z","iopub.execute_input":"2022-02-19T12:01:05.567666Z","iopub.status.idle":"2022-02-19T12:01:05.576476Z","shell.execute_reply.started":"2022-02-19T12:01:05.567626Z","shell.execute_reply":"2022-02-19T12:01:05.575682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check if GPU is avaliable","metadata":{}},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:05.577904Z","iopub.execute_input":"2022-02-19T12:01:05.578158Z","iopub.status.idle":"2022-02-19T12:01:05.632248Z","shell.execute_reply.started":"2022-02-19T12:01:05.578123Z","shell.execute_reply":"2022-02-19T12:01:05.631552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:05.633731Z","iopub.execute_input":"2022-02-19T12:01:05.633977Z","iopub.status.idle":"2022-02-19T12:01:05.642447Z","shell.execute_reply.started":"2022-02-19T12:01:05.63394Z","shell.execute_reply":"2022-02-19T12:01:05.64177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \"Push\" to the GPU","metadata":{}},{"cell_type":"code","source":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(train_loader, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:05.643821Z","iopub.execute_input":"2022-02-19T12:01:05.644073Z","iopub.status.idle":"2022-02-19T12:01:05.655356Z","shell.execute_reply.started":"2022-02-19T12:01:05.644037Z","shell.execute_reply":"2022-02-19T12:01:05.654654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This is the heart of the Neural Network!\n**feel free to edit the layers anytime**","metadata":{}},{"cell_type":"markdown","source":"A lot of credit for this goes to \n1. Akash N S, for his Jovian.ai Course. This notebook specially makes use of functions from here https://jovian.ai/aakashns-6l3/deep-learning-project-live\n1. @Pytonash's Recent notebook using Keras, and a very similar structure - End to end simple and powerful DNN with LeakyReLU - https://www.kaggle.com/pythonash/end-to-end-simple-and-powerful-dnn-with-leakyrelu\n3. General answers from StackOverflow like this one, which helps to make out where should features be placed and ordered https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout","metadata":{}},{"cell_type":"code","source":"class My_Kaggle_Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Activation functions have been chosen either as SiLU (called as Swish in Keras), and LeakyReLU\n        # I have used them in alternate, please comment if this is a good practice or not!\n        self.layers = nn.Sequential(nn.Linear(input_size, 64), \n                                    nn.BatchNorm1d(64), \n                                    nn.SiLU(), \n                                    \n                                    nn.Linear(64, 128), \n                                    nn.BatchNorm1d(128), \n                                    # nn.LeakyReLU(0.1), \n                                    nn.SiLU(),\n                                    nn.Dropout(0.4),\n                                    \n                                    nn.Linear(128, 256), \n                                    nn.BatchNorm1d(256), \n                                    nn.SiLU(), \n                                    nn.Dropout(0.4),\n                                    \n                                    nn.Linear(256, 512), \n                                    nn.BatchNorm1d(512), \n                                    # nn.LeakyReLU(0.1),\n                                    nn.SiLU(),\n                                    nn.Dropout(0.4), \n                                    \n                                    nn.Linear(512, 256), \n                                    nn.BatchNorm1d(256), \n                                    nn.SiLU(),\n                                    nn.Dropout(0.4),\n                                    \n                                    nn.Linear(256, 128), \n                                    nn.BatchNorm1d(128), \n                                    # nn.LeakyReLU(0.1),\n                                    nn.SiLU(),\n                                    nn.Dropout(0.4),\n                                    \n                                    nn.Linear(128, 8), \n                                    nn.BatchNorm1d(8), \n                                    nn.SiLU(), \n                                    nn.Dropout(0.4),\n                                    \n                                    nn.Linear(8, 1) )\n    \n        \n    def forward(self, x):\n        return self.layers(x)\n    \n    def training_step(self, batch):\n        torch.cuda.empty_cache()\n        gc.collect()\n        inputs, targets = batch \n        inputs.to(device)\n        targets.to(device)\n        \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        torch.cuda.empty_cache()\n        gc.collect()\n        inputs, targets = batch \n        inputs.to(device)\n        targets.to(device)\n        \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}\".format(epoch, result['train_loss'], result['val_loss']))\n    \nmodel = My_Kaggle_Model()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:05.657041Z","iopub.execute_input":"2022-02-19T12:01:05.657615Z","iopub.status.idle":"2022-02-19T12:01:05.695889Z","shell.execute_reply.started":"2022-02-19T12:01:05.657576Z","shell.execute_reply":"2022-02-19T12:01:05.695218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shift model to GPU\nmodel = to_device(model, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:05.697119Z","iopub.execute_input":"2022-02-19T12:01:05.697364Z","iopub.status.idle":"2022-02-19T12:01:08.545954Z","shell.execute_reply.started":"2022-02-19T12:01:05.69733Z","shell.execute_reply":"2022-02-19T12:01:08.545222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple functions for evaluating and fitting","metadata":{}},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()  # Setting to eval mode makes sure that dropouts are 'frozen'\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train() # Setting to train mode\n        train_losses = []\n        \n        for (i,batch) in enumerate(train_loader):\n            torch.cuda.empty_cache()\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            if (i%200 == 0): print('batch number -- ', i)\n            \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n#         # Early Stopping\n#         if (result['valid_loss'][epoch] > result['valid_loss'][epoch - 1]) & (epoch >0):\n#             trigger_times += 1\n#             print('trigger times ', trigger_times)\n            \n#             if trigger_times >= patience:\n#                 print('Early stopping!\\nStart to test process.')\n#                 return model\n#         else:\n#             print('trigger times: 0')\n#             trigger_times = 0\n            \n    return history","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:08.547224Z","iopub.execute_input":"2022-02-19T12:01:08.547467Z","iopub.status.idle":"2022-02-19T12:01:08.556912Z","shell.execute_reply.started":"2022-02-19T12:01:08.547435Z","shell.execute_reply":"2022-02-19T12:01:08.556152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking if everything is on the GPU","metadata":{}},{"cell_type":"code","source":"train_loader.device, val_loader.device","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:08.558284Z","iopub.execute_input":"2022-02-19T12:01:08.558635Z","iopub.status.idle":"2022-02-19T12:01:08.570633Z","shell.execute_reply.started":"2022-02-19T12:01:08.558598Z","shell.execute_reply":"2022-02-19T12:01:08.5698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:08.571694Z","iopub.execute_input":"2022-02-19T12:01:08.572352Z","iopub.status.idle":"2022-02-19T12:01:08.579145Z","shell.execute_reply.started":"2022-02-19T12:01:08.572311Z","shell.execute_reply":"2022-02-19T12:01:08.578305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.state_dict()['layers.0.weight']","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:08.580377Z","iopub.execute_input":"2022-02-19T12:01:08.580832Z","iopub.status.idle":"2022-02-19T12:01:08.666476Z","shell.execute_reply.started":"2022-02-19T12:01:08.580786Z","shell.execute_reply":"2022-02-19T12:01:08.665794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*observe how the weights are also on the GPU, so nice to see!*","metadata":{}},{"cell_type":"markdown","source":"# Train!","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-1","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:08.667586Z","iopub.execute_input":"2022-02-19T12:01:08.66794Z","iopub.status.idle":"2022-02-19T12:01:08.671722Z","shell.execute_reply.started":"2022-02-19T12:01:08.667904Z","shell.execute_reply":"2022-02-19T12:01:08.671076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:08.673043Z","iopub.execute_input":"2022-02-19T12:01:08.67387Z","iopub.status.idle":"2022-02-19T12:01:08.811749Z","shell.execute_reply.started":"2022-02-19T12:01:08.673832Z","shell.execute_reply":"2022-02-19T12:01:08.810303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = fit(10, learning_rate, model, train_loader, val_loader, opt_func=torch.optim.Adam)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:01:08.813017Z","iopub.execute_input":"2022-02-19T12:01:08.813289Z","iopub.status.idle":"2022-02-19T12:22:23.886082Z","shell.execute_reply.started":"2022-02-19T12:01:08.813233Z","shell.execute_reply":"2022-02-19T12:22:23.885349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:31.763299Z","iopub.execute_input":"2022-02-19T12:22:31.763565Z","iopub.status.idle":"2022-02-19T12:22:31.769225Z","shell.execute_reply.started":"2022-02-19T12:22:31.763536Z","shell.execute_reply":"2022-02-19T12:22:31.768417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !/opt/bin/nvidia-smi\n# optional function to check if you have a GPU or not","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:23.897197Z","iopub.execute_input":"2022-02-19T12:22:23.898092Z","iopub.status.idle":"2022-02-19T12:22:23.902654Z","shell.execute_reply.started":"2022-02-19T12:22:23.898062Z","shell.execute_reply":"2022-02-19T12:22:23.901872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train for more with lower learning rate\nhistory2 = fit(10, 5e-3, model, train_loader, val_loader, opt_func=torch.optim.Adam)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:23.904105Z","iopub.execute_input":"2022-02-19T12:22:23.904627Z","iopub.status.idle":"2022-02-19T12:22:23.912746Z","shell.execute_reply.started":"2022-02-19T12:22:23.904592Z","shell.execute_reply":"2022-02-19T12:22:23.910693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history2)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:23.904105Z","iopub.execute_input":"2022-02-19T12:22:23.904627Z","iopub.status.idle":"2022-02-19T12:22:23.912746Z","shell.execute_reply.started":"2022-02-19T12:22:23.904592Z","shell.execute_reply":"2022-02-19T12:22:23.910693Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**it is a good practice to check this curve and determine if our model is overfitting or not**","metadata":{}},{"cell_type":"code","source":"# train for more with lower learning rate\nhistory3 = fit(10, 5e-5, model, train_loader, val_loader, opt_func=torch.optim.Adam)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:23.904105Z","iopub.execute_input":"2022-02-19T12:22:23.904627Z","iopub.status.idle":"2022-02-19T12:22:23.912746Z","shell.execute_reply.started":"2022-02-19T12:22:23.904592Z","shell.execute_reply":"2022-02-19T12:22:23.910693Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Record results","metadata":{}},{"cell_type":"code","source":"history3[-1]","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:39.248783Z","iopub.execute_input":"2022-02-19T12:22:39.249151Z","iopub.status.idle":"2022-02-19T12:22:39.257259Z","shell.execute_reply.started":"2022-02-19T12:22:39.249114Z","shell.execute_reply":"2022-02-19T12:22:39.256544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate(model, train_loader), evaluate(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:40.532773Z","iopub.execute_input":"2022-02-19T12:22:40.534795Z","iopub.status.idle":"2022-02-19T12:22:53.623362Z","shell.execute_reply.started":"2022-02-19T12:22:40.534755Z","shell.execute_reply":"2022-02-19T12:22:53.621352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### important to save the model!","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'my_trained_model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:22:58.022949Z","iopub.execute_input":"2022-02-19T12:22:58.023193Z","iopub.status.idle":"2022-02-19T12:22:58.04257Z","shell.execute_reply.started":"2022-02-19T12:22:58.023167Z","shell.execute_reply":"2022-02-19T12:22:58.041865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# time to make predictions!","metadata":{}},{"cell_type":"code","source":"# val_ds[1][0].shape, val_ds[1][1].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:03.752087Z","iopub.execute_input":"2022-02-19T12:23:03.752385Z","iopub.status.idle":"2022-02-19T12:23:03.756169Z","shell.execute_reply.started":"2022-02-19T12:23:03.752351Z","shell.execute_reply":"2022-02-19T12:23:03.755286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple function to predict","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache() # just to clear some GPU cache memory","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:04.705133Z","iopub.execute_input":"2022-02-19T12:23:04.705855Z","iopub.status.idle":"2022-02-19T12:23:04.712271Z","shell.execute_reply.started":"2022-02-19T12:23:04.705785Z","shell.execute_reply":"2022-02-19T12:23:04.711467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lets see if it works on the train loader (it should!)","metadata":{}},{"cell_type":"code","source":"for batch in train_loader:\n    model.eval() # not strictly necessary to put it in eval mode, because we took adequate care earlier\n    data, target = batch\n    print('data.shape', data.shape)\n    print('data.device', data.device)\n    preds = model(data)\n    print('preds.shape', preds.shape)\n    break # this is just for checking, so I break after one round","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:06.87529Z","iopub.execute_input":"2022-02-19T12:23:06.876018Z","iopub.status.idle":"2022-02-19T12:23:06.922872Z","shell.execute_reply.started":"2022-02-19T12:23:06.875979Z","shell.execute_reply":"2022-02-19T12:23:06.922155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### and on the valid loader","metadata":{}},{"cell_type":"code","source":"for batch in val_loader:\n    model.eval()\n    data, target = batch\n    print('data.shape', data.shape)\n    print('data.device', data.device)\n    preds = model(data)\n    print('preds.shape', preds.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:09.236411Z","iopub.execute_input":"2022-02-19T12:23:09.236967Z","iopub.status.idle":"2022-02-19T12:23:09.302177Z","shell.execute_reply.started":"2022-02-19T12:23:09.236928Z","shell.execute_reply":"2022-02-19T12:23:09.301304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:5], target[:5]","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:09.44106Z","iopub.execute_input":"2022-02-19T12:23:09.441337Z","iopub.status.idle":"2022-02-19T12:23:09.451607Z","shell.execute_reply.started":"2022-02-19T12:23:09.441307Z","shell.execute_reply":"2022-02-19T12:23:09.450526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:09.630346Z","iopub.execute_input":"2022-02-19T12:23:09.630954Z","iopub.status.idle":"2022-02-19T12:23:09.757481Z","shell.execute_reply.started":"2022-02-19T12:23:09.630912Z","shell.execute_reply":"2022-02-19T12:23:09.756711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission Time!","metadata":{}},{"cell_type":"markdown","source":"### simple function to predict on the test dataframe","metadata":{}},{"cell_type":"code","source":"cols_order = ['investment_id' , 'time_id'] + features","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:11.550143Z","iopub.execute_input":"2022-02-19T12:23:11.551008Z","iopub.status.idle":"2022-02-19T12:23:11.555101Z","shell.execute_reply.started":"2022-02-19T12:23:11.550959Z","shell.execute_reply":"2022-02-19T12:23:11.554349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_for_test_data(test_data):\n    test_ds = TensorDataset(torch.tensor(test_data.values, dtype=torch.float32))\n    submission_try = []\n    \n    for x in test_ds:\n        model.eval()\n        input_x = x[0].unsqueeze(0).cuda()\n        pred = model(input_x)\n        submission_try.append(pred)\n        print(\"Prediction:\", pred)\n        \n    submission_values = [float(i.detach()) for i in submission_try]\n    return submission_values","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:29:44.819438Z","iopub.execute_input":"2022-02-19T12:29:44.820111Z","iopub.status.idle":"2022-02-19T12:29:44.826545Z","shell.execute_reply.started":"2022-02-19T12:29:44.820073Z","shell.execute_reply":"2022-02-19T12:29:44.824828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:24:25.575975Z","iopub.execute_input":"2022-02-19T12:24:25.576949Z","iopub.status.idle":"2022-02-19T12:24:25.598644Z","shell.execute_reply.started":"2022-02-19T12:24:25.576903Z","shell.execute_reply":"2022-02-19T12:24:25.59782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict_for_test_data(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:30:01.178969Z","iopub.execute_input":"2022-02-19T12:30:01.179222Z","iopub.status.idle":"2022-02-19T12:30:01.19588Z","shell.execute_reply.started":"2022-02-19T12:30:01.179193Z","shell.execute_reply":"2022-02-19T12:30:01.194934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### submit off!\nCredits to @Melanie7744 for informing about the submission API. Here is the link to her work https://www.kaggle.com/melanie7744/understanding-the-submission-api-for-newbies","metadata":{}},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    print(\"test_df as loaded by the API\")\n    display(test_df.head(), test_df.shape)\n    #display(sample_prediction_df.head(), sample_prediction_df.shape)\n    \n    # here you need to modify test_df to match the training data\n    test_df['time_id'] = test_df.row_id.str.split(\"_\", expand=True)[0].astype(\"int16\") #re-create time_id\n    test_df = test_df[cols_order]  \n    print(\"test_df after selecting/creating the features the model was trained with\")\n    display(test_df.head(), test_df.shape)\n    \n    # Call our function to make predictions\n    predictions = predict_for_test_data(test_df)\n    sample_prediction_df['target'] = predictions  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions\n    \n    # print(\"Predictions for this time_id\")\n    # display(sample_prediction_df)\n    # print(\"-----------time_id finished-----------\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T12:23:13.675363Z","iopub.execute_input":"2022-02-19T12:23:13.675927Z","iopub.status.idle":"2022-02-19T12:23:13.834702Z","shell.execute_reply.started":"2022-02-19T12:23:13.675887Z","shell.execute_reply":"2022-02-19T12:23:13.833473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}