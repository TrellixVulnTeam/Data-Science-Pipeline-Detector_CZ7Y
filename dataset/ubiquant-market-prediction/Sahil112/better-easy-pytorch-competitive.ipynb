{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### points to take care of now onwards\n1. Add PCA components\n1. Search how to make the NN deeper\n1. Get it on the GPU\n1. Plot training losses with the validation losses\n1. **use KFold CV**","metadata":{}},{"cell_type":"markdown","source":"# usual imports","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\n\nimport matplotlib.pyplot as plt\nfrom scipy import stats# Imports\nimport torch\n\nimport torchvision\nimport torch.nn as nn\n\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","metadata":{"papermill":{"duration":7.781864,"end_time":"2022-01-25T15:39:09.265726","exception":false,"start_time":"2022-01-25T15:39:01.483862","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-19T14:32:24.762864Z","iopub.execute_input":"2022-02-19T14:32:24.765345Z","iopub.status.idle":"2022-02-19T14:32:25.588874Z","shell.execute_reply.started":"2022-02-19T14:32:24.765247Z","shell.execute_reply":"2022-02-19T14:32:25.588036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:25.590191Z","iopub.execute_input":"2022-02-19T14:32:25.592136Z","iopub.status.idle":"2022-02-19T14:32:25.705796Z","shell.execute_reply.started":"2022-02-19T14:32:25.592094Z","shell.execute_reply":"2022-02-19T14:32:25.704113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:25.70721Z","iopub.execute_input":"2022-02-19T14:32:25.707547Z","iopub.status.idle":"2022-02-19T14:32:25.721038Z","shell.execute_reply.started":"2022-02-19T14:32:25.707509Z","shell.execute_reply":"2022-02-19T14:32:25.720328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset","metadata":{"papermill":{"duration":0.015291,"end_time":"2022-01-25T15:39:09.296817","exception":false,"start_time":"2022-01-25T15:39:09.281526","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\ntrain.head(2)","metadata":{"papermill":{"duration":16.88418,"end_time":"2022-01-25T15:39:26.19638","exception":false,"start_time":"2022-01-25T15:39:09.3122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-19T14:32:25.723399Z","iopub.execute_input":"2022-02-19T14:32:25.723652Z","iopub.status.idle":"2022-02-19T14:32:27.156311Z","shell.execute_reply.started":"2022-02-19T14:32:25.723618Z","shell.execute_reply":"2022-02-19T14:32:27.155535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train.loc[train['time_id'] > 1150]\ntrain = train.iloc[-50000:]","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.157562Z","iopub.execute_input":"2022-02-19T14:32:27.157845Z","iopub.status.idle":"2022-02-19T14:32:27.163438Z","shell.execute_reply.started":"2022-02-19T14:32:27.157808Z","shell.execute_reply":"2022-02-19T14:32:27.162721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = train.drop(['target'], axis=1).values\ntargets = train[['target']].values\n\ninputs.shape, targets.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.164982Z","iopub.execute_input":"2022-02-19T14:32:27.165285Z","iopub.status.idle":"2022-02-19T14:32:27.286216Z","shell.execute_reply.started":"2022-02-19T14:32:27.165239Z","shell.execute_reply":"2022-02-19T14:32:27.285445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 80 % split number - just for splitting","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.018581Z","iopub.execute_input":"2022-02-12T07:05:50.020216Z","iopub.status.idle":"2022-02-12T07:05:50.028672Z","shell.execute_reply.started":"2022-02-12T07:05:50.020168Z","shell.execute_reply":"2022-02-12T07:05:50.027667Z"}}},{"cell_type":"code","source":"val_1 = int(0.8*inputs.shape[0])\nval_2 = int(0.2*inputs.shape[0])\nval_1, val_2","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.28768Z","iopub.execute_input":"2022-02-19T14:32:27.288051Z","iopub.status.idle":"2022-02-19T14:32:27.294956Z","shell.execute_reply.started":"2022-02-19T14:32:27.288014Z","shell.execute_reply":"2022-02-19T14:32:27.294137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.030025Z","iopub.execute_input":"2022-02-12T07:05:50.030959Z","iopub.status.idle":"2022-02-12T07:05:50.04492Z","shell.execute_reply.started":"2022-02-12T07:05:50.030913Z","shell.execute_reply":"2022-02-12T07:05:50.043616Z"}}},{"cell_type":"code","source":"batch_size = 2000\nTARGET_COLUMN = 'target'\ninput_size=302\noutput_size=1","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.2963Z","iopub.execute_input":"2022-02-19T14:32:27.305971Z","iopub.status.idle":"2022-02-19T14:32:27.317303Z","shell.execute_reply.started":"2022-02-19T14:32:27.305929Z","shell.execute_reply":"2022-02-19T14:32:27.316569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.318547Z","iopub.execute_input":"2022-02-19T14:32:27.319101Z","iopub.status.idle":"2022-02-19T14:32:27.48256Z","shell.execute_reply.started":"2022-02-19T14:32:27.31907Z","shell.execute_reply":"2022-02-19T14:32:27.481712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert to PyTorch dataset (DataLoader)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.046326Z","iopub.execute_input":"2022-02-12T07:05:50.048467Z","iopub.status.idle":"2022-02-12T07:05:53.061696Z","shell.execute_reply.started":"2022-02-12T07:05:50.048424Z","shell.execute_reply":"2022-02-12T07:05:53.060279Z"}}},{"cell_type":"code","source":"dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32))\ntrain_ds, val_ds = random_split(dataset, [val_1, val_2])\n\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=False) # future predict karna hai na\nval_loader = DataLoader(val_ds, batch_size*2)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:34.554991Z","iopub.execute_input":"2022-02-19T14:32:34.55525Z","iopub.status.idle":"2022-02-19T14:32:34.601091Z","shell.execute_reply.started":"2022-02-19T14:32:34.555221Z","shell.execute_reply":"2022-02-19T14:32:34.600355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_ds, val_ds, dataset, inputs, targets\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:35.387613Z","iopub.execute_input":"2022-02-19T14:32:35.388126Z","iopub.status.idle":"2022-02-19T14:32:35.503297Z","shell.execute_reply.started":"2022-02-19T14:32:35.388086Z","shell.execute_reply":"2022-02-19T14:32:35.502576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GPU Utilities\n#### these will help later to get our models/dataloaders on the GPU!","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:35.753628Z","iopub.execute_input":"2022-02-19T14:32:35.754192Z","iopub.status.idle":"2022-02-19T14:32:35.764691Z","shell.execute_reply.started":"2022-02-19T14:32:35.754154Z","shell.execute_reply":"2022-02-19T14:32:35.763927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check if GPU is avaliable","metadata":{}},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:37.561093Z","iopub.execute_input":"2022-02-19T14:32:37.561689Z","iopub.status.idle":"2022-02-19T14:32:37.588341Z","shell.execute_reply.started":"2022-02-19T14:32:37.56163Z","shell.execute_reply":"2022-02-19T14:32:37.58759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:37.989129Z","iopub.execute_input":"2022-02-19T14:32:37.989876Z","iopub.status.idle":"2022-02-19T14:32:37.994963Z","shell.execute_reply.started":"2022-02-19T14:32:37.989837Z","shell.execute_reply":"2022-02-19T14:32:37.994145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \"Push\" to the GPU","metadata":{}},{"cell_type":"code","source":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(train_loader, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:38.418088Z","iopub.execute_input":"2022-02-19T14:32:38.418559Z","iopub.status.idle":"2022-02-19T14:32:38.422807Z","shell.execute_reply.started":"2022-02-19T14:32:38.418523Z","shell.execute_reply":"2022-02-19T14:32:38.421903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This is the heart of the Neural Network!\n**feel free to edit the layers anytime**","metadata":{}},{"cell_type":"markdown","source":"A lot of credit for this goes to \n1. Akash N S, for his Jovian.ai Course. This notebook specially makes use of functions from here https://jovian.ai/aakashns-6l3/deep-learning-project-live\n1. @Pytonash's Recent notebook using Keras, and a very similar structure - End to end simple and powerful DNN with LeakyReLU - https://www.kaggle.com/pythonash/end-to-end-simple-and-powerful-dnn-with-leakyrelu\n3. General answers from StackOverflow like this one, which helps to make out where should features be placed and ordered https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout","metadata":{}},{"cell_type":"code","source":"class My_Kaggle_Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Activation functions have been chosen either as SiLU (called as Swish in Keras), and LeakyReLU\n        # I have used them in alternate, please comment if this is a good practice or not!\n        self.layers = nn.Sequential(nn.Linear(input_size, 64), \n                                    nn.BatchNorm1d(64), \n                                    nn.SiLU(), \n                                    \n                                    nn.Linear(64, 128), \n                                    nn.BatchNorm1d(128), \n                                    nn.LeakyReLU(0.1), \n                                    # nn.SiLU(),\n                                    nn.Dropout(0.3),\n                                    \n                                    nn.Linear(128, 8), \n                                    nn.BatchNorm1d(8), \n                                    nn.SiLU(), \n                                    nn.Dropout(0.5),\n                                    \n                                    nn.Linear(8, 1) )\n    \n        \n    def forward(self, x):\n        return self.layers(x)\n    \n    def training_step(self, batch):\n        torch.cuda.empty_cache()\n        gc.collect()\n        inputs, targets = batch \n        inputs.to(device)\n        targets.to(device)\n        \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        torch.cuda.empty_cache()\n        gc.collect()\n        inputs, targets = batch \n        inputs.to(device)\n        targets.to(device)\n        \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}\".format(epoch, result['train_loss'], result['val_loss']))\n    \nmodel = My_Kaggle_Model()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:39.161434Z","iopub.execute_input":"2022-02-19T14:32:39.161888Z","iopub.status.idle":"2022-02-19T14:32:39.179105Z","shell.execute_reply.started":"2022-02-19T14:32:39.161852Z","shell.execute_reply":"2022-02-19T14:32:39.17818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shift model to GPU\nmodel = to_device(model, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:39.418774Z","iopub.execute_input":"2022-02-19T14:32:39.419157Z","iopub.status.idle":"2022-02-19T14:32:41.093006Z","shell.execute_reply.started":"2022-02-19T14:32:39.419121Z","shell.execute_reply":"2022-02-19T14:32:41.092236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple functions for evaluating and fitting","metadata":{}},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()  # Setting to eval mode makes sure that dropouts are 'frozen'\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD, patience = 2):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train() # Setting to train mode\n        train_losses = []\n        \n        for (i,batch) in enumerate(train_loader):\n            torch.cuda.empty_cache()\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            # if (i%200 == 0): print('batch number -- ', i)\n            \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n        # Early Stopping\n        if (history[epoch]['val_loss'] > history[epoch-1]['val_loss']) & (epoch > 0):\n            trigger_times += 1\n            print('trigger times ', trigger_times)\n            \n            if trigger_times >= patience:\n                print('Early stopping!\\nStart to test process.')\n                return model\n        else:\n            print('trigger times: 0')\n            trigger_times = 0\n            \n        # print('\\n')\n            \n    return history","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:42:14.790095Z","iopub.execute_input":"2022-02-19T14:42:14.79203Z","iopub.status.idle":"2022-02-19T14:42:14.806977Z","shell.execute_reply.started":"2022-02-19T14:42:14.791991Z","shell.execute_reply":"2022-02-19T14:42:14.806256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking if everything is on the GPU","metadata":{}},{"cell_type":"code","source":"train_loader.device, val_loader.device","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:41.106936Z","iopub.execute_input":"2022-02-19T14:32:41.107439Z","iopub.status.idle":"2022-02-19T14:32:41.119733Z","shell.execute_reply.started":"2022-02-19T14:32:41.107398Z","shell.execute_reply":"2022-02-19T14:32:41.118864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:41.121794Z","iopub.execute_input":"2022-02-19T14:32:41.122162Z","iopub.status.idle":"2022-02-19T14:32:41.128621Z","shell.execute_reply.started":"2022-02-19T14:32:41.122126Z","shell.execute_reply":"2022-02-19T14:32:41.127561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.state_dict()['layers.0.weight']","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:41.129864Z","iopub.execute_input":"2022-02-19T14:32:41.130619Z","iopub.status.idle":"2022-02-19T14:32:41.143515Z","shell.execute_reply.started":"2022-02-19T14:32:41.13058Z","shell.execute_reply":"2022-02-19T14:32:41.14287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*observe how the weights are also on the GPU, so nice to see!*","metadata":{}},{"cell_type":"markdown","source":"# Train!","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-1","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:41.735916Z","iopub.execute_input":"2022-02-19T14:32:41.73637Z","iopub.status.idle":"2022-02-19T14:32:41.740346Z","shell.execute_reply.started":"2022-02-19T14:32:41.736335Z","shell.execute_reply":"2022-02-19T14:32:41.739503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:43.427515Z","iopub.execute_input":"2022-02-19T14:32:43.428302Z","iopub.status.idle":"2022-02-19T14:32:43.542376Z","shell.execute_reply.started":"2022-02-19T14:32:43.428255Z","shell.execute_reply":"2022-02-19T14:32:43.541386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = fit(30, learning_rate, model, train_loader, val_loader, opt_func=torch.optim.Adam, patience = 4)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:43.624382Z","iopub.execute_input":"2022-02-19T14:32:43.624701Z","iopub.status.idle":"2022-02-19T14:35:18.921087Z","shell.execute_reply.started":"2022-02-19T14:32:43.624671Z","shell.execute_reply":"2022-02-19T14:35:18.920271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.673952Z","iopub.status.idle":"2022-02-19T14:32:27.674733Z","shell.execute_reply.started":"2022-02-19T14:32:27.674469Z","shell.execute_reply":"2022-02-19T14:32:27.674495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train for more with lower learning rate\n# history += fit(30, 1e-1, model, train_loader, val_loader, opt_func=torch.optim.Adam, patience = 4)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.675945Z","iopub.status.idle":"2022-02-19T14:32:27.676828Z","shell.execute_reply.started":"2022-02-19T14:32:27.676533Z","shell.execute_reply":"2022-02-19T14:32:27.676562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.677963Z","iopub.status.idle":"2022-02-19T14:32:27.678733Z","shell.execute_reply.started":"2022-02-19T14:32:27.678477Z","shell.execute_reply":"2022-02-19T14:32:27.678503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \nplot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:35:27.289095Z","iopub.execute_input":"2022-02-19T14:35:27.289787Z","iopub.status.idle":"2022-02-19T14:35:27.660607Z","shell.execute_reply.started":"2022-02-19T14:35:27.289746Z","shell.execute_reply":"2022-02-19T14:35:27.659737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**it is a good practice to check this curve and determine if our model is overfitting or not**","metadata":{}},{"cell_type":"markdown","source":"### Record results","metadata":{}},{"cell_type":"code","source":"history2 = fit(30, 5e-3, model, train_loader, val_loader, opt_func=torch.optim.Adam, patience = 4)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:36:05.468108Z","iopub.execute_input":"2022-02-19T14:36:05.468388Z","iopub.status.idle":"2022-02-19T14:38:40.629524Z","shell.execute_reply.started":"2022-02-19T14:36:05.468357Z","shell.execute_reply":"2022-02-19T14:38:40.62865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history2","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:39:30.041244Z","iopub.execute_input":"2022-02-19T14:39:30.041524Z","iopub.status.idle":"2022-02-19T14:39:30.045314Z","shell.execute_reply.started":"2022-02-19T14:39:30.04149Z","shell.execute_reply":"2022-02-19T14:39:30.044084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history2)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:39:23.455931Z","iopub.execute_input":"2022-02-19T14:39:23.456192Z","iopub.status.idle":"2022-02-19T14:39:23.685807Z","shell.execute_reply.started":"2022-02-19T14:39:23.456162Z","shell.execute_reply":"2022-02-19T14:39:23.685101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history3  = fit(30, 1e-3, model, train_loader, val_loader, opt_func=torch.optim.SGD, patience = 3)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:39:40.924464Z","iopub.execute_input":"2022-02-19T14:39:40.925022Z","iopub.status.idle":"2022-02-19T14:42:14.785934Z","shell.execute_reply.started":"2022-02-19T14:39:40.924981Z","shell.execute_reply":"2022-02-19T14:42:14.785136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history3)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:25.834819Z","iopub.execute_input":"2022-02-19T14:43:25.835185Z","iopub.status.idle":"2022-02-19T14:43:26.066821Z","shell.execute_reply.started":"2022-02-19T14:43:25.835144Z","shell.execute_reply":"2022-02-19T14:43:26.066108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history4  = fit(10, 1e-5, model, train_loader, val_loader, opt_func=torch.optim.Adam, patience = 3)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:42:34.234277Z","iopub.execute_input":"2022-02-19T14:42:34.234859Z","iopub.status.idle":"2022-02-19T14:43:25.832978Z","shell.execute_reply.started":"2022-02-19T14:42:34.234819Z","shell.execute_reply":"2022-02-19T14:43:25.832193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history4)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:26.067893Z","iopub.execute_input":"2022-02-19T14:43:26.068449Z","iopub.status.idle":"2022-02-19T14:43:26.290195Z","shell.execute_reply.started":"2022-02-19T14:43:26.068407Z","shell.execute_reply":"2022-02-19T14:43:26.289519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate(model, train_loader), evaluate(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:32:27.683737Z","iopub.status.idle":"2022-02-19T14:32:27.684479Z","shell.execute_reply.started":"2022-02-19T14:32:27.684241Z","shell.execute_reply":"2022-02-19T14:32:27.684275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### important to save the model!","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'maytimes_trained_model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:37.507516Z","iopub.execute_input":"2022-02-19T14:43:37.508204Z","iopub.status.idle":"2022-02-19T14:43:37.517408Z","shell.execute_reply.started":"2022-02-19T14:43:37.508163Z","shell.execute_reply":"2022-02-19T14:43:37.516631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# time to make predictions!","metadata":{}},{"cell_type":"code","source":"# val_ds[1][0].shape, val_ds[1][1].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:39.753968Z","iopub.execute_input":"2022-02-19T14:43:39.754798Z","iopub.status.idle":"2022-02-19T14:43:39.758697Z","shell.execute_reply.started":"2022-02-19T14:43:39.754743Z","shell.execute_reply":"2022-02-19T14:43:39.757646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple function to predict","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache() # just to clear some GPU cache memory","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:40.632271Z","iopub.execute_input":"2022-02-19T14:43:40.632889Z","iopub.status.idle":"2022-02-19T14:43:40.637298Z","shell.execute_reply.started":"2022-02-19T14:43:40.632851Z","shell.execute_reply":"2022-02-19T14:43:40.636274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lets see if it works on the train loader (it should!)","metadata":{}},{"cell_type":"code","source":"for batch in train_loader:\n    model.eval() # not strictly necessary to put it in eval mode, because we took adequate care earlier\n    data, target = batch\n    print('data.shape', data.shape)\n    print('data.device', data.device)\n    preds = model(data)\n    print('preds.shape', preds.shape)\n    # print(preds, target)\n    break # this is just for checking, so I break after one round","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:49.553088Z","iopub.execute_input":"2022-02-19T14:43:49.553427Z","iopub.status.idle":"2022-02-19T14:43:49.586092Z","shell.execute_reply.started":"2022-02-19T14:43:49.553391Z","shell.execute_reply":"2022-02-19T14:43:49.585354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### and on the valid loader","metadata":{}},{"cell_type":"code","source":"for batch in val_loader:\n    model.eval()\n    data, target = batch\n    print('data.shape', data.shape)\n    print('data.device', data.device)\n    preds = model(data)\n    print('preds.shape', preds.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:52.988484Z","iopub.execute_input":"2022-02-19T14:43:52.989065Z","iopub.status.idle":"2022-02-19T14:43:53.025821Z","shell.execute_reply.started":"2022-02-19T14:43:52.989026Z","shell.execute_reply":"2022-02-19T14:43:53.025039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:5], target[:5]","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:54.644552Z","iopub.execute_input":"2022-02-19T14:43:54.64516Z","iopub.status.idle":"2022-02-19T14:43:54.653901Z","shell.execute_reply.started":"2022-02-19T14:43:54.64512Z","shell.execute_reply":"2022-02-19T14:43:54.653005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:54.840451Z","iopub.execute_input":"2022-02-19T14:43:54.841107Z","iopub.status.idle":"2022-02-19T14:43:54.962576Z","shell.execute_reply.started":"2022-02-19T14:43:54.841066Z","shell.execute_reply":"2022-02-19T14:43:54.961857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission Time!","metadata":{}},{"cell_type":"markdown","source":"### simple function to predict on the test dataframe","metadata":{}},{"cell_type":"code","source":"cols_order = ['investment_id' , 'time_id'] + features","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:56.123924Z","iopub.execute_input":"2022-02-19T14:43:56.124495Z","iopub.status.idle":"2022-02-19T14:43:56.128345Z","shell.execute_reply.started":"2022-02-19T14:43:56.124457Z","shell.execute_reply":"2022-02-19T14:43:56.127593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_for_test_data(test_data):\n    test_ds = TensorDataset(torch.tensor(test_data.values, dtype=torch.float32))\n    submission_try = []\n    \n    for x in test_ds:\n        model.eval()\n        input_x = x[0].unsqueeze(0).cuda()\n        pred = model(input_x)\n        submission_try.append(pred)\n        print(\"Prediction:\", pred)\n        \n    submission_values = [float(i.detach()) for i in submission_try]\n    return submission_values","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:59.428208Z","iopub.execute_input":"2022-02-19T14:43:59.428787Z","iopub.status.idle":"2022-02-19T14:43:59.434977Z","shell.execute_reply.started":"2022-02-19T14:43:59.428736Z","shell.execute_reply":"2022-02-19T14:43:59.434194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:43:59.876229Z","iopub.execute_input":"2022-02-19T14:43:59.876945Z","iopub.status.idle":"2022-02-19T14:43:59.880464Z","shell.execute_reply.started":"2022-02-19T14:43:59.876906Z","shell.execute_reply":"2022-02-19T14:43:59.879611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict_for_test_data(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:44:00.304996Z","iopub.execute_input":"2022-02-19T14:44:00.305803Z","iopub.status.idle":"2022-02-19T14:44:00.309345Z","shell.execute_reply.started":"2022-02-19T14:44:00.305753Z","shell.execute_reply":"2022-02-19T14:44:00.308649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### submit off!\nCredits to @Melanie7744 for informing about the submission API. Here is the link to her work https://www.kaggle.com/melanie7744/understanding-the-submission-api-for-newbies","metadata":{}},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    print(\"test_df as loaded by the API\")\n    display(test_df.head(), test_df.shape)\n    #display(sample_prediction_df.head(), sample_prediction_df.shape)\n    \n    # here you need to modify test_df to match the training data\n    test_df['time_id'] = test_df.row_id.str.split(\"_\", expand=True)[0].astype(\"int16\") #re-create time_id\n    test_df = test_df[cols_order]  \n    print(\"test_df after selecting/creating the features the model was trained with\")\n    display(test_df.head(), test_df.shape)\n    \n    # Call our function to make predictions\n    predictions = predict_for_test_data(test_df)\n    sample_prediction_df['target'] = predictions  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions\n    \n    # print(\"Predictions for this time_id\")\n    # display(sample_prediction_df)\n    # print(\"-----------time_id finished-----------\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T14:44:01.209837Z","iopub.execute_input":"2022-02-19T14:44:01.210542Z","iopub.status.idle":"2022-02-19T14:44:01.455528Z","shell.execute_reply.started":"2022-02-19T14:44:01.210502Z","shell.execute_reply":"2022-02-19T14:44:01.45474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}