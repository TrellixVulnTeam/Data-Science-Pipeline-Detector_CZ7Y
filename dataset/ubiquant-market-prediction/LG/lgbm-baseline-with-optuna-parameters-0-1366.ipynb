{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A very simple notebook containing the following steps:\n- load the train set (parquet format)\n- reduce the memory usage\n- set the LGBM parameters optimised with Optuna\n- fit and submit","metadata":{}},{"cell_type":"markdown","source":"# 1. Utils","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n#     https://www.kaggle.com/code/edwardakalarrywelch/datatable-memory-reduction\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    \n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n     \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:04:36.336077Z","iopub.execute_input":"2022-03-23T15:04:36.337322Z","iopub.status.idle":"2022-03-23T15:04:36.359699Z","shell.execute_reply.started":"2022-03-23T15:04:36.337175Z","shell.execute_reply":"2022-03-23T15:04:36.357794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Load Libraries and Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom lightgbm import LGBMRegressor\n\nimport ubiquant\n\ndf = reduce_mem_usage(pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-23T15:04:38.72474Z","iopub.execute_input":"2022-03-23T15:04:38.72521Z","iopub.status.idle":"2022-03-23T15:09:18.452361Z","shell.execute_reply.started":"2022-03-23T15:04:38.725158Z","shell.execute_reply":"2022-03-23T15:09:18.450813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Modelling","metadata":{}},{"cell_type":"code","source":"features = ['investment_id'] + ['f_' + str(i) for i in range(100)]\n\n# Params from https://www.kaggle.com/code/valleyzw/ubiquant-lgbm-optimization\nparams = {'lambda_l1': 0.03627602394442367, 'lambda_l2': 0.43523855951142926, 'num_leaves': 114, 'feature_fraction': 0.9505625064462319,\n     'bagging_fraction': 0.9785558707339647, 'bagging_freq': 7, 'max_depth': -1, 'max_bin': 501, 'min_data_in_leaf': 374}\n\nmodel = LGBMRegressor(**params)\nmodel.fit(df[features].loc[df.time_id >= 600], df['target'].loc[df.time_id >= 600])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:09:18.45669Z","iopub.execute_input":"2022-03-23T15:09:18.458384Z","iopub.status.idle":"2022-03-23T15:11:08.402945Z","shell.execute_reply.started":"2022-03-23T15:09:18.45832Z","shell.execute_reply":"2022-03-23T15:11:08.401098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_importance(model, height=1, figsize=(20, 20))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:21:17.140129Z","iopub.execute_input":"2022-03-23T15:21:17.142023Z","iopub.status.idle":"2022-03-23T15:21:19.263792Z","shell.execute_reply.started":"2022-03-23T15:21:17.1419Z","shell.execute_reply":"2022-03-23T15:21:19.262535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Submission","metadata":{}},{"cell_type":"code","source":"env = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\n\nfor (test_df, sample_prediction_df) in iter_test:\n    print(test_df.head())\n    sample_prediction_df['target'] =  model.predict(test_df[features])  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:15:22.705481Z","iopub.execute_input":"2022-03-22T15:15:22.706423Z","iopub.status.idle":"2022-03-22T15:15:22.924055Z","shell.execute_reply.started":"2022-03-22T15:15:22.706353Z","shell.execute_reply":"2022-03-22T15:15:22.922728Z"},"trusted":true},"execution_count":null,"outputs":[]}]}