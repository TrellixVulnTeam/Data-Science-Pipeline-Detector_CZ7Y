{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"lunana  \nlast update 2022 04 06  \nゆっくりしていってね！  ","metadata":{}},{"cell_type":"markdown","source":"version 5 +Result","metadata":{}},{"cell_type":"markdown","source":"# Datasets  \n* ubiquant dnn r41 5folds ( Lunana )  \nhttps://www.kaggle.com/datasets/lunapandachan/ubiquant-dnn-r41-5folds  \n* ubiquant dnn r42 5folds ( Lunana )  \nhttps://www.kaggle.com/datasets/lunapandachan/ubiquant-dnn-r42-5folds  \n* ubiquant dnn lonnie ( Lunana )  \nhttps://www.kaggle.com/datasets/lunapandachan/ubiquant-dnn-lonnie  \n* ubiquant dnn lonnie 2 ( Lunana )  \nhttps://www.kaggle.com/datasets/lunapandachan/ubiquant-dnn-lonnie-2","metadata":{}},{"cell_type":"markdown","source":"# Result\nversion 1 ubiquant dnn r41 5folds + ubiquant dnn r42 5fold LB=0.149  \nversion 2 ubiquant dnn r41 5folds + ubiquant dnn r42 5folds + ubiquant dnn lonnie LB=0.150  \nversion 3 ubiquant dnn r42 5folds + ubiquant dnn lonnie LB=0.151  \nversion 4 ubiquant dnn lonnie + ubiquant dnn lonnie 2 LB=0.151","metadata":{}},{"cell_type":"markdown","source":"# EDA  \nhttps://www.kaggle.com/lunapandachan/ubiquant-eda-english  \n","metadata":{}},{"cell_type":"markdown","source":"# Add test  \n* Ubiquant DNN ver Chiranjeev ゆっくり実況 add test  \nseed=41,5folds,LB=0.148  \nseed=41,10folds,LB=0.149  \nseed=42,5folds,LB=0.149  \nhttps://www.kaggle.com/lunapandachan/ubiquant-dnn-ver-chiranjeev-add-test  \n\n* Ubiquant DNN ver Lonnie train ゆっくり実況 add test LB=0.152  \nval_loss LB=0.148  \nval_mae LB=0.149  \nval_mape LB=0.149  \nval_rmse LB=0.149  \nhttps://www.kaggle.com/lunapandachan/ubiquant-dnn-ver-lonnie-train-add-test","metadata":{}},{"cell_type":"markdown","source":"**霊夢:今日は2つのDNNを使って提出用ファイルを作るよ。**\n\n**Reimu: Today I'm going to use two DNNs to create a submission file.**  \n\n","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom scipy import stats\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import *\nimport warnings\n\nimport pickle\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:00.320144Z","iopub.execute_input":"2022-03-19T13:32:00.320738Z","iopub.status.idle":"2022-03-19T13:32:09.049478Z","shell.execute_reply.started":"2022-03-19T13:32:00.320651Z","shell.execute_reply":"2022-03-19T13:32:09.048767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DNN_1='../input/ubiquant-dnn-r41-5folds/'\nDNN_2='../input/ubiquant-dnn-r42-5folds/'\nDNN_3='../input/ubiquant-dnn-lonnie/'\nDNN_4='../input/ubiquant-dnn-lonnie-2/'","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:09.050971Z","iopub.execute_input":"2022-03-19T13:32:09.051237Z","iopub.status.idle":"2022-03-19T13:32:09.059611Z","shell.execute_reply.started":"2022-03-19T13:32:09.051201Z","shell.execute_reply":"2022-03-19T13:32:09.058328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nn_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:09.061804Z","iopub.execute_input":"2022-03-19T13:32:09.062158Z","iopub.status.idle":"2022-03-19T13:32:24.783677Z","shell.execute_reply.started":"2022-03-19T13:32:09.062122Z","shell.execute_reply":"2022-03-19T13:32:24.782949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ninvestment_id = train.pop(\"investment_id\").copy()\ninvestment_ids = list(investment_id.unique())\ninvestment_id_size = len(investment_ids) + 1\ninvestment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\ninvestment_id_lookup_layer.adapt(pd.DataFrame({\"investment_ids\":investment_ids}))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:24.785561Z","iopub.execute_input":"2022-03-19T13:32:24.785875Z","iopub.status.idle":"2022-03-19T13:32:27.737955Z","shell.execute_reply.started":"2022-03-19T13:32:24.78584Z","shell.execute_reply":"2022-03-19T13:32:27.737203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model DNN","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:27.739236Z","iopub.execute_input":"2022-03-19T13:32:27.7399Z","iopub.status.idle":"2022-03-19T13:32:27.743919Z","shell.execute_reply.started":"2022-03-19T13:32:27.739862Z","shell.execute_reply":"2022-03-19T13:32:27.742913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n\n    \n    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n\n\n\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:27.745337Z","iopub.execute_input":"2022-03-19T13:32:27.745632Z","iopub.status.idle":"2022-03-19T13:32:27.759869Z","shell.execute_reply.started":"2022-03-19T13:32:27.745596Z","shell.execute_reply":"2022-03-19T13:32:27.759083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlation(x, y, axis=-2):\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n    x = tf.convert_to_tensor(x)\n    y = math_ops.cast(y, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return tf.constant(1.0, dtype=x.dtype) - corr\n\ndef get_model2():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dropout(0.1)(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dropout(0.1)(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dropout(0.1)(investment_id_x)\n    \n    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n    feature_x = layers.Dropout(0.1)(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dropout(0.1)(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dropout(0.1)(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dropout(0.1)(x)\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse, correlation])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:27.761394Z","iopub.execute_input":"2022-03-19T13:32:27.76165Z","iopub.status.idle":"2022-03-19T13:32:27.781183Z","shell.execute_reply.started":"2022-03-19T13:32:27.761615Z","shell.execute_reply":"2022-03-19T13:32:27.780378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model3():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n    \n    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    feature_x = layers.Dense(256, activation='swish')(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n    output = layers.Dense(1)(x)\n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse, correlation])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:27.782438Z","iopub.execute_input":"2022-03-19T13:32:27.782719Z","iopub.status.idle":"2022-03-19T13:32:27.796892Z","shell.execute_reply.started":"2022-03-19T13:32:27.782685Z","shell.execute_reply":"2022-03-19T13:32:27.796158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:27.798388Z","iopub.execute_input":"2022-03-19T13:32:27.798659Z","iopub.status.idle":"2022-03-19T13:32:28.886459Z","shell.execute_reply.started":"2022-03-19T13:32:27.798624Z","shell.execute_reply":"2022-03-19T13:32:28.884442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:28.889744Z","iopub.execute_input":"2022-03-19T13:32:28.890258Z","iopub.status.idle":"2022-03-19T13:32:28.894849Z","shell.execute_reply.started":"2022-03-19T13:32:28.890217Z","shell.execute_reply":"2022-03-19T13:32:28.894137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodels=[]\nfor index in range(5):\n    model=get_model()\n    model = keras.models.load_model(DNN_1+f\"model_{index}\")\n#    models.append(model)\n    \nfor index in range(5):\n    model=get_model()\n    model = keras.models.load_model(DNN_2+f\"model_{index}\")\n#    models.append(model)\n    \nfor index in range(5):\n    model=get_model2()\n    model.load_weights(DNN_3+f\"model_{index}.tf\")\n    models.append(model)\n    \nfor index in range(5):\n    model=get_model3()\n    model.load_weights(DNN_4+f\"model_{index}.tf\")\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:28.895861Z","iopub.execute_input":"2022-03-19T13:32:28.896077Z","iopub.status.idle":"2022-03-19T13:32:44.948509Z","shell.execute_reply.started":"2022-03-19T13:32:28.896026Z","shell.execute_reply":"2022-03-19T13:32:44.947735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test(investment_id, feature):\n    return (investment_id, feature), 0\ndef make_test_dataset(feature, investment_id, batch_size=1024):\n    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature)))\n    ds = ds.map(preprocess_test)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\ndef inference(models, ds):\n    y_preds = []\n    for model in models:\n        y_pred = model.predict(ds)\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:44.951357Z","iopub.execute_input":"2022-03-19T13:32:44.951563Z","iopub.status.idle":"2022-03-19T13:32:44.960343Z","shell.execute_reply.started":"2022-03-19T13:32:44.951537Z","shell.execute_reply":"2022-03-19T13:32:44.959616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"inferenceの中でmodelの平均を出している","metadata":{}},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test() \nfor (test_df, sample_prediction_df) in iter_test:\n    ds = make_test_dataset(test_df[features], test_df[\"investment_id\"])\n    sample_prediction_df['target'] = inference(models, ds)\n    env.predict(sample_prediction_df) ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:44.961905Z","iopub.execute_input":"2022-03-19T13:32:44.962234Z","iopub.status.idle":"2022-03-19T13:32:47.952521Z","shell.execute_reply.started":"2022-03-19T13:32:44.962198Z","shell.execute_reply":"2022-03-19T13:32:47.951765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv(\"./submission.csv\")\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:32:47.953917Z","iopub.execute_input":"2022-03-19T13:32:47.954174Z","iopub.status.idle":"2022-03-19T13:32:47.965674Z","shell.execute_reply.started":"2022-03-19T13:32:47.95414Z","shell.execute_reply":"2022-03-19T13:32:47.964968Z"},"trusted":true},"execution_count":null,"outputs":[]}]}