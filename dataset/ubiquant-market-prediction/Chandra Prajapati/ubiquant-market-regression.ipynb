{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-18T13:54:58.423039Z","iopub.execute_input":"2022-04-18T13:54:58.423578Z","iopub.status.idle":"2022-04-18T13:54:58.429492Z","shell.execute_reply.started":"2022-04-18T13:54:58.423534Z","shell.execute_reply":"2022-04-18T13:54:58.428435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:54:58.446668Z","iopub.execute_input":"2022-04-18T13:54:58.449101Z","iopub.status.idle":"2022-04-18T13:54:59.614014Z","shell.execute_reply.started":"2022-04-18T13:54:58.44905Z","shell.execute_reply":"2022-04-18T13:54:59.613109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nn_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\nfeature_column = ['investment_id', 'time_id' ] + features\ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:54:59.616523Z","iopub.execute_input":"2022-04-18T13:54:59.616921Z","iopub.status.idle":"2022-04-18T13:55:16.85758Z","shell.execute_reply.started":"2022-04-18T13:54:59.616869Z","shell.execute_reply":"2022-04-18T13:55:16.85656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\n#print(train.info())","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:16.858911Z","iopub.execute_input":"2022-04-18T13:55:16.859137Z","iopub.status.idle":"2022-04-18T13:55:16.865011Z","shell.execute_reply.started":"2022-04-18T13:55:16.859109Z","shell.execute_reply":"2022-04-18T13:55:16.863977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,6))\nsns.histplot(train['target'])","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:16.867509Z","iopub.execute_input":"2022-04-18T13:55:16.867881Z","iopub.status.idle":"2022-04-18T13:55:23.603357Z","shell.execute_reply.started":"2022-04-18T13:55:16.867839Z","shell.execute_reply":"2022-04-18T13:55:23.60244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us try to understand the data\n1. There are 1211 time_id's recorded with min value 0 to some value and max value 1219.\n1. There are 3579 investment_id's recorded with min 0 and max 3773.","metadata":{}},{"cell_type":"code","source":"print(train['time_id'].nunique())\nprint(train['time_id'].min())\nprint(train['time_id'].max())\nprint(train['investment_id'].nunique())\nprint(train['investment_id'].min())\nprint(train['investment_id'].max())","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:23.604897Z","iopub.execute_input":"2022-04-18T13:55:23.605122Z","iopub.status.idle":"2022-04-18T13:55:23.664821Z","shell.execute_reply.started":"2022-04-18T13:55:23.605094Z","shell.execute_reply":"2022-04-18T13:55:23.663756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### let us check the role of time_id on the target and check if we have to consider it as an independent feature","metadata":{}},{"cell_type":"code","source":"time_grp_count = train.groupby('time_id')['investment_id'].count()\ntime_grp_mean = train.groupby('time_id')['target'].mean()\ntime_grp_std = train.groupby('time_id')['target'].std()\nplt.figure(figsize=(18,14))\nplt.subplot(4,1,1)\ntime_grp_count.plot(title = 'plt of no of counts of investment id in each time id')\nplt.legend()\nplt.subplot(4,1,2)\ntime_grp_mean.plot(title = 'plt of mean of target in each time id')\nplt.title('plt of mean of target in each time id')\nplt.subplot(4,1,3)\ntime_grp_std.plot(title='plt of std of target in each time id')\nplt.legend()\n\n#Let find the distribution of mean and std of investment_id\nplt.subplot(4,1,4)\ntime_grp_count.plot(kind='hist',bins=100)\nplt.title('hist plot of count of investments in time')\n\nplt.figure(figsize=(18,12))\nplt.subplot(2,1,1)\ntime_grp_mean.plot(kind='hist',bins=100)\nplt.title('hist plot of target mean of each investment id')\nplt.subplot(2,1,2)\nplt.title('hist plot of target std of each investment id')\ntime_grp_std.plot(kind='hist',bins=100)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:23.666231Z","iopub.execute_input":"2022-04-18T13:55:23.666487Z","iopub.status.idle":"2022-04-18T13:55:25.90184Z","shell.execute_reply.started":"2022-04-18T13:55:23.666455Z","shell.execute_reply":"2022-04-18T13:55:25.900894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. We can see that the count of investments in each time_id is uniform and there is trend of increasing investments over the time.\n2. There are certian times, when investment drops to very low value and in those times mean and std of target increases a lot in magnitude. Other times the mean is nearly zero and std is around 0.95.\n3. Higher investment ids have higher frequency of investment, means they are invested more number of times in respective time_id.","metadata":{}},{"cell_type":"markdown","source":"### let us check the role of investment_id on the target and check if we have to consider it as an independent feature","metadata":{}},{"cell_type":"code","source":"invest_grp_count = train.groupby('investment_id')['time_id'].count()\ninvest_grp_mean = train.groupby('investment_id')['target'].mean()\ninvest_grp_std = train.groupby('investment_id')['target'].std()\nplt.figure(figsize=(18,14))\nplt.subplot(3,1,1)\ninvest_grp_count.plot()\nplt.title('count of time_id in each investment id')\nplt.subplot(3,1,2)\ninvest_grp_mean.plot()\nplt.title('plot of mean of each investment id')\nplt.subplot(3,1,3)\ninvest_grp_std.plot()\nplt.title('plot of std of each investment id')\n\n#Let find the distribution of mean and std of investment_id\nplt.figure(figsize=(18,14))\nplt.subplot(3,1,1)\ninvest_grp_count.plot(kind='hist',bins=100)\nplt.title('hist plot of time_id in each investment id')\nplt.subplot(3,1,2)\ninvest_grp_mean.plot(kind='hist',bins=100)\nplt.title('hist plot of target mean of each investment id')\nplt.subplot(3,1,3)\nplt.title('hist plot of target std of each investment id')\ninvest_grp_std.plot(kind='hist',bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:25.903415Z","iopub.execute_input":"2022-04-18T13:55:25.903669Z","iopub.status.idle":"2022-04-18T13:55:28.100898Z","shell.execute_reply.started":"2022-04-18T13:55:25.903639Z","shell.execute_reply":"2022-04-18T13:55:28.099874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. We can see that the count of time_id in each investment_id is random and the target mean and target std in each investment_id is nearly zero and 0.9 respectively.\n2. the count of investments increase over the time\n2. The histogram curve of target mean and target std in investment_id do follow nearly normal distribution with shifted mean and std. \n3. From this plot and previous plot of time_id we can say that investment_id and time_id mostly behave in similar fahsion. Infact they are interelated. \n4. We may need to consider any one of them preferably the ivestment_id in the modeling.","metadata":{"execution":{"iopub.status.busy":"2022-04-13T07:18:20.421802Z","iopub.execute_input":"2022-04-13T07:18:20.422178Z","iopub.status.idle":"2022-04-13T07:18:20.431753Z","shell.execute_reply.started":"2022-04-13T07:18:20.42214Z","shell.execute_reply":"2022-04-13T07:18:20.43038Z"}}},{"cell_type":"markdown","source":"## Let us make a base model considering the pca on features f_0 to f_299","metadata":{}},{"cell_type":"code","source":"X = train.drop(['time_id','investment_id','target'], axis = 1)\nY = train['target']","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:28.102303Z","iopub.execute_input":"2022-04-18T13:55:28.102561Z","iopub.status.idle":"2022-04-18T13:55:32.566712Z","shell.execute_reply.started":"2022-04-18T13:55:28.102528Z","shell.execute_reply":"2022-04-18T13:55:32.565836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"n_pca = 40\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=n_pca)\npca.fit(X)\nX_pca = pca.transform(X)\nexp_var_ratio = pca.explained_variance_ratio_\nplt.figure(figsize = (12,6))\nplt.subplot(2,1,1)\nplt.plot(exp_var_ratio*100)\nplt.subplot(2,1,2)\nplt.plot(exp_var_ratio.cumsum()*100)\ncol = [f'f_{i}' for i in range(n_pca)]\nX_pca = pd.DataFrame(X_pca, columns = col)\nX_pca.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T10:57:17.763686Z","iopub.execute_input":"2022-04-18T10:57:17.764547Z","iopub.status.idle":"2022-04-18T10:58:17.397638Z","shell.execute_reply.started":"2022-04-18T10:57:17.764455Z","shell.execute_reply":"2022-04-18T10:58:17.397084Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso,LassoLars, BayesianRidge, TweedieRegressor, SGDRegressor, QuantileRegressor, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom scipy.stats import pearsonr","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:32.568285Z","iopub.execute_input":"2022-04-18T13:55:32.568519Z","iopub.status.idle":"2022-04-18T13:55:32.990213Z","shell.execute_reply.started":"2022-04-18T13:55:32.568491Z","shell.execute_reply":"2022-04-18T13:55:32.989367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=123)\nX_train.shape, X_val.shape, Y_train.shape, Y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:32.995327Z","iopub.execute_input":"2022-04-18T13:55:32.996069Z","iopub.status.idle":"2022-04-18T13:55:52.416564Z","shell.execute_reply.started":"2022-04-18T13:55:32.996024Z","shell.execute_reply":"2022-04-18T13:55:52.415689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #build and train the model\ndef build_model(X,Y):\n    model = LinearRegression()\n   #model = Ridge(alpha= 1, tol = 0.001)\n    #model = Lasso(alpha=0.0005, tol = 0.0001)\n    #model = ElasticNet(alpha=0.0001, l1_ratio=0.2)\n    #model = RandomForestRegressor(n_estimators=1000, min_samples_split=50,min_samples_leaf=50)\n    #model = DecisionTreeRegressor(min_samples_split=20, min_samples_leaf=10)\n    #model = GradientBoostingRegressor(learning_rate=0.1, n_estimators=200, subsample=1.0, \n    #criterion='friedman_mse', min_samples_split=20, min_samples_leaf=10, max_depth=5)\n    #model = TweedieRegressor(power=1, alpha=0.5, link='log')\n    #model = QuantileRegressor(alpha=0)\n    #model = SGDRegressor(loss='squared_error', penalty='l2', alpha=0.0001, l1_ratio=0.65, tol=0.001,)\n    #model = BayesianRidge( n_iter=800, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06)\n    model.fit(X,Y)\n    return model\n\n# predict the output and score\ndef predict(model, X_val,Y_val):\n    prediction = model.predict(X_val)\n    score = r2_score(Y_val, prediction)\n    pearson_score = pearsonr(Y_val, prediction)[0]\n    return pearson_score\n\nmodel = build_model(X_train, Y_train)\npearson_coef = predict(model, X_val, Y_val)\nprint(pearson_coef)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:55:52.417891Z","iopub.execute_input":"2022-04-18T13:55:52.418112Z","iopub.status.idle":"2022-04-18T13:56:44.350313Z","shell.execute_reply.started":"2022-04-18T13:55:52.418085Z","shell.execute_reply":"2022-04-18T13:56:44.349246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/test-data/example_test.csv')\nprint(test.shape)\ntest.head()\nX_test = test.drop(['row_id','time_id','investment_id'],axis=1)\nX_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.352157Z","iopub.execute_input":"2022-04-18T13:56:44.358005Z","iopub.status.idle":"2022-04-18T13:56:44.451413Z","shell.execute_reply.started":"2022-04-18T13:56:44.35792Z","shell.execute_reply":"2022-04-18T13:56:44.450384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"print","metadata":{}},{"cell_type":"code","source":"# preprocess test dataset\n#def preprocess_test(test):\n#    #test_pca = pca.transform(test)\n#    #col = [f'f_{i}' for i in range(n_pca)]\n#    #test_pca_df = pd.DataFrame(test_pca, columns = col)\n#    return test\n#test_pca_df = preprocess_test(X_test)\n#test_pca_df.head()\n\ndef predict_test(model, test):\n    test_pred = model.predict(test)\n    return test_pred\ntest_pred = predict_test(model, X_test) \ntest_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.457501Z","iopub.execute_input":"2022-04-18T13:56:44.460615Z","iopub.status.idle":"2022-04-18T13:56:44.479056Z","shell.execute_reply.started":"2022-04-18T13:56:44.460537Z","shell.execute_reply":"2022-04-18T13:56:44.478169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/test-data/example_sample_submission.csv')\nsample_submission['target'] = test_pred\nsample_submission\nsample_submission.to_csv('sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.480907Z","iopub.execute_input":"2022-04-18T13:56:44.481246Z","iopub.status.idle":"2022-04-18T13:56:44.49787Z","shell.execute_reply.started":"2022-04-18T13:56:44.481191Z","shell.execute_reply":"2022-04-18T13:56:44.497057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.drop(['row_id','investment_id'],axis=1)\n    #test_pca = pca.transform(test_df)\n    #test_pca_df = pd.DataFrame(test_pca, columns = [f'f_{i}' for i in range(n_pca)])\n    sample_prediction_df['target'] = model.predict(test_df)  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.50015Z","iopub.execute_input":"2022-04-18T13:56:44.500498Z","iopub.status.idle":"2022-04-18T13:56:44.597292Z","shell.execute_reply.started":"2022-04-18T13:56:44.500452Z","shell.execute_reply":"2022-04-18T13:56:44.596452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Including investment_id and time_d in the features","metadata":{}},{"cell_type":"markdown","source":"1. This basic model gave pearson score very less around 0.12. We can improve score by including the investment_id in the independent features.\n2. It can be included by creating new features using groupby method.\n","metadata":{}},{"cell_type":"code","source":"#train.groupby(by='investment_id')['target'].mean().to_dict()\n#train['invest_feature'] = train['investment_id'].map(train.groupby(by='investment_id')['target'].mean().to_dict())\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.598869Z","iopub.execute_input":"2022-04-18T13:56:44.599181Z","iopub.status.idle":"2022-04-18T13:56:44.603662Z","shell.execute_reply.started":"2022-04-18T13:56:44.599136Z","shell.execute_reply":"2022-04-18T13:56:44.60262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_pca_mod = pd.concat([X_pca, train['invest_feature']],axis=1)\n#X_pca_mod.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.605326Z","iopub.execute_input":"2022-04-18T13:56:44.605699Z","iopub.status.idle":"2022-04-18T13:56:44.615272Z","shell.execute_reply.started":"2022-04-18T13:56:44.605657Z","shell.execute_reply":"2022-04-18T13:56:44.614308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train, X_val, Y_train, Y_val = train_test_split(X_pca_mod, Y, test_size=0.2, shuffle=True, random_state=123)\n#print(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape)\n\n## build and train the model\n#def build_model(X,Y):\n#    model = LinearRegression()\n#    #model = Ridge(alpha= 1, tol = 5)\n#    #model = RandomForestRegressor(n_estimators=1000, min_samples_split=50,min_samples_leaf=50)\n#    #model = DecisionTreeRegressor()\n#    model.fit(X,Y)\n#    return model\n\n## predict the output and score\n#def predict(model, X_val,Y_val):\n#    prediction = model.predict(X_val)\n#    score = r2_score(Y_val, prediction)\n#   pearson_score = pearsonr(Y_val, prediction)[0]\n #   return pearson_score\n#\n#model = build_model(X_train, Y_train)\n#pearson_coef = predict(model, X_val, Y_val)\n#print(pearson_coef)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.616617Z","iopub.execute_input":"2022-04-18T13:56:44.61731Z","iopub.status.idle":"2022-04-18T13:56:44.626765Z","shell.execute_reply.started":"2022-04-18T13:56:44.617257Z","shell.execute_reply":"2022-04-18T13:56:44.62606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#invest_feature = test['investment_id'].map(train.groupby(by='investment_id')['target'].mean().to_dict())\n#invest_feature_df = pd.DataFrame(invest_feature).rename(columns={'investment_id':'invest_feature'})\n#invest_feature_df","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.628348Z","iopub.execute_input":"2022-04-18T13:56:44.628881Z","iopub.status.idle":"2022-04-18T13:56:44.643508Z","shell.execute_reply.started":"2022-04-18T13:56:44.628835Z","shell.execute_reply":"2022-04-18T13:56:44.6427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## preprocess test dataset\n#def preprocess_test(X):\n#    test_pca = pca.transform(X)\n#    col = [f'f_{i}' for i in range(75)]\n#    test_pca_df = pd.DataFrame(test_pca, columns = col)\n#   test_pca_df_mod = pd.concat([test_pca_df, invest_feature_df], axis=1)\n#    return test_pca_df_mod\n#test_pca_df_mod = preprocess_test(X_test)\n#print(test_pca_df_mod.shape)\n#\n#def predict_test(model, X):\n#    test_pred = model.predict(X)\n#    return test_pred\n#test_pred = predict_test(model, test_pca_df_mod) \n#test_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.644895Z","iopub.execute_input":"2022-04-18T13:56:44.645333Z","iopub.status.idle":"2022-04-18T13:56:44.655439Z","shell.execute_reply.started":"2022-04-18T13:56:44.645286Z","shell.execute_reply":"2022-04-18T13:56:44.65469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample_submission = pd.read_csv('../input/test-data/example_sample_submission.csv')\n#sample_submission['target'] = test_pred\n#sample_submission\n#sample_submission.to_csv('sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.657116Z","iopub.execute_input":"2022-04-18T13:56:44.657664Z","iopub.status.idle":"2022-04-18T13:56:44.667495Z","shell.execute_reply.started":"2022-04-18T13:56:44.657614Z","shell.execute_reply":"2022-04-18T13:56:44.66677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import ubiquant\n#env = ubiquant.make_env()   # initialize the environment\n#iter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\n#for (test_df, sample_prediction_df) in iter_test:\n#    #print(test_df)\n#    invest_feature = test_df['investment_id'].map(train.groupby(by='investment_id')['target'].mean().to_dict())\n#    invest_feature_df = pd.DataFrame(invest_feature).rename(columns={'investment_id':'invest_feature'})\n#    #print(invest_feature_df)\n#    test_df = test_df.drop(['row_id','investment_id'],axis=1)\n#    test_pca = pca.transform(test_df)\n#    test_pca_df = pd.DataFrame(test_pca, columns = [f'f_{i}' for i in range(75)])\n#    #print(test_pca_df)\n#    test_pca_df_mod = pd.concat([test_pca_df, invest_feature_df],axis=1)\n#    sample_prediction_df['target'] = model.predict(test_pca_df_mod)  # make your predictions here\n#    #print(sample_prediction_df)\n#    env.predict(sample_prediction_df)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.669061Z","iopub.execute_input":"2022-04-18T13:56:44.669645Z","iopub.status.idle":"2022-04-18T13:56:44.679611Z","shell.execute_reply.started":"2022-04-18T13:56:44.669582Z","shell.execute_reply":"2022-04-18T13:56:44.678867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#invest_feature = train['investment_id'].map(train.groupby(by='investment_id')['target'].mean().to_dict())\n#invest_feature.rename(columns={'investment_id': 'invest_feature'})\n#invest_feature = pd.DataFrame(invest_feature).rename(columns={'investment_id':'invest_feature'})\n\n#invest_feature","metadata":{"execution":{"iopub.status.busy":"2022-04-18T13:56:44.680915Z","iopub.execute_input":"2022-04-18T13:56:44.681393Z","iopub.status.idle":"2022-04-18T13:56:44.693653Z","shell.execute_reply.started":"2022-04-18T13:56:44.681347Z","shell.execute_reply":"2022-04-18T13:56:44.69275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}