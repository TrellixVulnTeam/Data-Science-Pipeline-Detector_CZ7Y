{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"From: https://www.kaggle.com/lucamassaron/training-data-to-feather-python-r-low-mem\n\nAdding: Time series split from sklearn","metadata":{}},{"cell_type":"markdown","source":"Feather files are fast to be read, they can be used both for Python (using pandas) and R, keep the dtype of your columns and reduce the overall memory usage.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import TimeSeriesSplit\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:46:43.08635Z","iopub.execute_input":"2022-01-23T19:46:43.088251Z","iopub.status.idle":"2022-01-23T19:46:43.093164Z","shell.execute_reply.started":"2022-01-23T19:46:43.088204Z","shell.execute_reply":"2022-01-23T19:46:43.092407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Data","metadata":{}},{"cell_type":"code","source":"training_path = '../input/ubiquant-market-prediction/train.csv'\n\ndtypes = {\n    'row_id': 'str',\n    'time_id': 'uint16',\n    'investment_id': 'uint16',\n    'target': 'float32',\n}\n\ndtypes.update({f'f_{i}': 'float32' for i in range(300)})\n\ntrain = pd.read_csv(training_path,usecols=list(dtypes.keys()),dtype=dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:27:43.504599Z","iopub.execute_input":"2022-01-23T19:27:43.505106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Time series split:\n\nTools to plot from: https://scikit-learn.org/stable/modules/cross_validation.html#time-series-split","metadata":{}},{"cell_type":"code","source":"np.random.seed(1338)\ncmap_data = plt.cm.Paired\ncmap_cv = plt.cm.coolwarm\nn_splits = 4\n\n# Generate the class/group data\nn_points = 100\nX = np.random.randn(100, 10)\n\npercentiles_classes = [0.1, 0.3, 0.6]\ny = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])\n\n# Evenly spaced groups repeated once\ngroups = np.hstack([[ii] * 10 for ii in range(10)])\n\n\ndef visualize_groups(classes, groups, name):\n    # Visualize dataset groups\n    fig, ax = plt.subplots()\n    ax.scatter(\n        range(len(groups)),\n        [0.5] * len(groups),\n        c=groups,\n        marker=\"_\",\n        lw=50,\n        cmap=cmap_data,\n    )\n    ax.scatter(\n        range(len(groups)),\n        [3.5] * len(groups),\n        c=classes,\n        marker=\"_\",\n        lw=50,\n        cmap=cmap_data,\n    )\n    ax.set(\n        ylim=[-1, 5],\n        yticks=[0.5, 3.5],\n        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n        xlabel=\"Sample index\",\n    )\n\ndef plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n\n    # Generate the training/testing visualizations for each CV split\n    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n        # Fill in indices with the training/test groups\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0\n\n        # Visualize the results\n        ax.scatter(\n            range(len(indices)),\n            [ii + 0.5] * len(indices),\n            c=indices,\n            marker=\"_\",\n            lw=lw,\n            cmap=cmap_cv,\n            vmin=-0.2,\n            vmax=1.2,\n        )\n\n    # Plot the data classes and groups at the end\n    ax.scatter(\n        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n    )\n\n    ax.scatter(\n        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n    )\n\n    # Formatting\n    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n    ax.set(\n        yticks=np.arange(n_splits + 2) + 0.5,\n        yticklabels=yticklabels,\n        xlabel=\"Sample index\",\n        ylabel=\"CV iteration\",\n        ylim=[n_splits + 2.2, -0.2],\n        xlim=[0, 100],\n    )\n    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:50:35.856402Z","iopub.execute_input":"2022-01-23T19:50:35.856758Z","iopub.status.idle":"2022-01-23T19:50:35.877317Z","shell.execute_reply.started":"2022-01-23T19:50:35.856722Z","shell.execute_reply":"2022-01-23T19:50:35.876646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Alway training from the beggining:","metadata":{}},{"cell_type":"code","source":"this_cv = TimeSeriesSplit(n_splits=5)\nfig, ax = plt.subplots(figsize=(6, 3))\nplot_cv_indices(this_cv, X, y, groups, ax, n_splits)\n\nax.legend(\n    [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n    [\"Testing set\", \"Training set\"],\n    loc=(1.02, 0.8),\n)\n# Make the legend fit\nplt.tight_layout()\nfig.subplots_adjust(right=0.7)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:56:33.976756Z","iopub.execute_input":"2022-01-23T19:56:33.97754Z","iopub.status.idle":"2022-01-23T19:56:34.239209Z","shell.execute_reply.started":"2022-01-23T19:56:33.977491Z","shell.execute_reply":"2022-01-23T19:56:34.238346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With maximum training size:","metadata":{}},{"cell_type":"code","source":"this_cv = TimeSeriesSplit(n_splits=5,max_train_size=25)\nfig, ax = plt.subplots(figsize=(6, 3))\nplot_cv_indices(this_cv, X, y, groups, ax, n_splits)\n\nax.legend(\n    [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n    [\"Testing set\", \"Training set\"],\n    loc=(1.02, 0.8),\n)\n# Make the legend fit\nplt.tight_layout()\nfig.subplots_adjust(right=0.7)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:56:36.533971Z","iopub.execute_input":"2022-01-23T19:56:36.534261Z","iopub.status.idle":"2022-01-23T19:56:36.787904Z","shell.execute_reply.started":"2022-01-23T19:56:36.534232Z","shell.execute_reply":"2022-01-23T19:56:36.787092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"More recents version include gap parameters but not our current version of sklearn:","metadata":{}},{"cell_type":"code","source":"import sklearn\n\nprint(sklearn.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T20:00:11.525696Z","iopub.execute_input":"2022-01-23T20:00:11.526494Z","iopub.status.idle":"2022-01-23T20:00:11.530699Z","shell.execute_reply.started":"2022-01-23T20:00:11.526446Z","shell.execute_reply":"2022-01-23T20:00:11.530002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = TimeSeriesSplit(n_splits=5, max_train_size=300)\n\nfor fold, (train_idx, test_idx) in enumerate(cv.split(train['time_id'].unique(),groups=train['time_id'].unique())):\n    \n    print('Fold: {}'.format(fold))\n\n    train.loc[(train['time_id'].isin(train_idx))].reset_index().to_feather('train_fold_'+str(fold)+'.feather')\n    train.loc[(train['time_id'].isin(test_idx))].reset_index().to_feather('test_fold_'+str(fold)+'.feather')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:44:15.810992Z","iopub.execute_input":"2022-01-23T19:44:15.811497Z","iopub.status.idle":"2022-01-23T19:44:15.832438Z","shell.execute_reply.started":"2022-01-23T19:44:15.811465Z","shell.execute_reply":"2022-01-23T19:44:15.831034Z"},"trusted":true},"execution_count":null,"outputs":[]}]}