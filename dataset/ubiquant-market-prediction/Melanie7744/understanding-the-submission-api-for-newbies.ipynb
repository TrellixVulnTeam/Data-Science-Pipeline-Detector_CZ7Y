{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time\n\nimport sklearn\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    i=0\n    for filename in filenames:\n        if i in range(15):\n            print(os.path.join(dirname, filename))\n            i = i+1\n        else: break","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-23T20:13:59.893991Z","iopub.execute_input":"2022-02-23T20:13:59.895355Z","iopub.status.idle":"2022-02-23T20:14:00.547376Z","shell.execute_reply.started":"2022-02-23T20:13:59.895261Z","shell.execute_reply":"2022-02-23T20:14:00.546368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submitting via API - what??? ðŸ¤”\nThis is my first competition using an API for submitting. I spend quite some time to understand the process. In this notebook I share my findings in order to save you time. If you like it, please upvote.\n","metadata":{}},{"cell_type":"markdown","source":"I want to show you how to:\n- make real predictions \n- handle the case when you created or removed some features\n- make predicitons with a model trained locally or in another Kaggle notebook\n- make weighted predictions with multiple models trained with different features\n\nFor speed reasons I use the parquet format and reduce the number of columns and rows. To use the parquet data, you will have to add this data source (on the right side: Data -> Add data -> Datasets & search for Ubiquant. And while you are there, don't forget to disable Internet)\nPlease check out this [great post](https://www.kaggle.com/c/ubiquant-market-prediction/discussion/301724) from Rob Mulla for more information on the parquet format.","metadata":{}},{"cell_type":"markdown","source":"## Reading the training data","metadata":{}},{"cell_type":"code","source":"%%time\ncol_subset = ['time_id','investment_id','f1','f_2','f_23','f_145','f_153','f_225','f_231'] #reduce the number of columns to read\nfirst_time_id_to_use = 1000 # reduce the number of rows\n\n#df_train = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet',columns=col_subset)\ndf_train = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\ndf_train = df_train.loc[df_train.time_id >= first_time_id_to_use]","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:14:00.549337Z","iopub.execute_input":"2022-02-23T20:14:00.549855Z","iopub.status.idle":"2022-02-23T20:14:40.385206Z","shell.execute_reply.started":"2022-02-23T20:14:00.549804Z","shell.execute_reply":"2022-02-23T20:14:40.38423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_train.shape)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:14:40.387152Z","iopub.execute_input":"2022-02-23T20:14:40.387759Z","iopub.status.idle":"2022-02-23T20:14:40.428217Z","shell.execute_reply.started":"2022-02-23T20:14:40.387705Z","shell.execute_reply":"2022-02-23T20:14:40.427208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training or loading a model\nLet's just train a simple model to get some predictions. No validation, nothing. It's supposed to be about the prediction process after all.","metadata":{}},{"cell_type":"code","source":"features_model_1 = ['time_id','investment_id','f_145','f_153','f_225','f_231'] # using only a small subset of features here\n\nX = df_train[features_model_1]\nprint(X.columns)\ny = df_train.target\n\nmodel_1 = LinearRegression()\nmodel_1.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:14:40.431969Z","iopub.execute_input":"2022-02-23T20:14:40.432599Z","iopub.status.idle":"2022-02-23T20:14:40.59128Z","shell.execute_reply.started":"2022-02-23T20:14:40.432534Z","shell.execute_reply":"2022-02-23T20:14:40.590038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you have your model already trained locally or in another Kaggle notebook you can load it. If it was trained in another Kaggle notebook, just add the training notebook to your working notebook (on the right side: Data -> Add data -> Notebook Output Files). Now all output from the training notebook is available to be loaded in this notebook.\n\nAdding a LightGBM:\n","metadata":{}},{"cell_type":"code","source":"import pickle\nfilename = '../input/k/melanie7744/using-lightgbm-for-feature-selection/finalized_model.sav'\nloaded_lgbm = pickle.load(open(filename, 'rb'))\n\nfeatures_loaded_lgbm = [col for col in df_train.columns if col.startswith(\"f\")] # this model was trained with all anonymized features\npreds = loaded_lgbm.predict(df_train[features_loaded_lgbm]) # this is just a sanity check, the predictions have to be made via the API\nprint(\"df_train.shape: \", df_train.shape, \"Number of predictions: \", len(preds))","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:14:40.593006Z","iopub.execute_input":"2022-02-23T20:14:40.593794Z","iopub.status.idle":"2022-02-23T20:14:48.907426Z","shell.execute_reply.started":"2022-02-23T20:14:40.593737Z","shell.execute_reply":"2022-02-23T20:14:48.906522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding a neural network (tensorflow/keras):","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nfilename = '../input/ubq-dnn/model.h5'\nloaded_NN = load_model(filename)\n\nfeatures_loaded_NN = [col for col in df_train.columns if col.startswith(\"f\")] # this model was trained with all anonymized features\npreds = loaded_NN.predict(df_train[features_loaded_NN]) # this is just a sanity check, the predictions have to be made via the API\nprint(\"df_train.shape: \", df_train.shape, \"Number of predictions: \", len(preds))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-23T20:14:48.90912Z","iopub.execute_input":"2022-02-23T20:14:48.909791Z","iopub.status.idle":"2022-02-23T20:16:24.098534Z","shell.execute_reply.started":"2022-02-23T20:14:48.909742Z","shell.execute_reply":"2022-02-23T20:16:24.096702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The example test data\nNow, let's look at the example test data frame. Pay attention to the columns. It's important to note that it has data for **four time_ids**.","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_parquet('../input/ubiquant-parquet/example_test.parquet')\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:16:24.102031Z","iopub.execute_input":"2022-02-23T20:16:24.102558Z","iopub.status.idle":"2022-02-23T20:16:24.197583Z","shell.execute_reply.started":"2022-02-23T20:16:24.102497Z","shell.execute_reply":"2022-02-23T20:16:24.1966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission via API\n\nFinally it's time to have a closer look at the API that is used for submission.\n\nPay attention to the columns of test_df. If you created or removed features (I did both for this demo) you need to do the same on test_df **within the for loop** and then call your model to predict.\n\nIf you look at the output below, you can see that the test data is split by time_id and each time_id is given to your model seperately. So your model will be called as many times as there are time_ids in the test data. This process makes sure that the model cannot use any data from future time_ids.\n\nEdit: \n- for Version 7 of this notebook, I created functions to preprocess the test data and make the predictions. This makes the code below cleaner. \n- Version 8 uses a loaded model to predict\n- in Version 9 multiple models, that have been trained with different features, are used. The predicition is averaged. For a simpler approach go back to version 7 or 8 of this notebook.\n- Version 10 includes an updated function for weighted predicitions, i.e. assigning different weights to the predicitions from different models\n- Version 11 has two loaded models","metadata":{}},{"cell_type":"code","source":"def preprocess(df, features):\n    df['time_id'] = df.row_id.str.split(\"_\", expand=True)[0].astype(\"int16\") #re-create time_id (if none of your models uses time_id this step is not necessary)\n    df = df[features]  \n    return df\n    \n    \ndef make_predictions(models, features, weights, df): \n    preds = [] # empty list to hold the predictions\n    sum_w = sum(weights)\n\n    for i,model in enumerate(models):\n        df_prepr = preprocess(df, features[i]) # preprocess data with matching features\n        pred = model.predict(df_prepr) # predict\n        if pred.shape == (df.shape[0],1): # handle different output format of NN predicitions\n            pred=pred.flatten()\n        preds.append(pred * weights[i]/sum_w) # weigh the predictions and collect them\n    \n    preds = np.sum(preds, axis=0) # sum the weighted predictions up\n    return preds # return prediction from all models","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:16:24.199794Z","iopub.execute_input":"2022-02-23T20:16:24.200167Z","iopub.status.idle":"2022-02-23T20:16:24.210668Z","shell.execute_reply.started":"2022-02-23T20:16:24.200108Z","shell.execute_reply":"2022-02-23T20:16:24.20952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_models = [model_1, loaded_lgbm, loaded_NN] # list the models to be used\nmy_features = [features_model_1, features_loaded_lgbm, features_loaded_NN]    # list the MATCHING features \nmy_weights = [1, 2, 2] # how much weight is given to each models prediction\n\n# some checks before calling the ubiquant API\nassert len(my_models) == len(my_features), \"The number of models must match the number of feature sets.\"\nassert len(my_weights) == len(my_models), \"For each model there need to be corresponding weights.\"","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:18:48.632708Z","iopub.execute_input":"2022-02-23T20:18:48.633504Z","iopub.status.idle":"2022-02-23T20:18:48.639907Z","shell.execute_reply.started":"2022-02-23T20:18:48.633427Z","shell.execute_reply":"2022-02-23T20:18:48.638791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    print(\"test_df as loaded by the API\\n\") \n    display(test_df.head(), test_df.shape)\n    \n    sample_prediction_df['target'] = make_predictions(my_models, my_features, my_weights, test_df) # using a custom function for preprocessing and predicting\n    env.predict(sample_prediction_df)   # register your predictions\n    \n    print(\"Predictions for this time_id\\n\")\n    display(sample_prediction_df)\n    print(\"-----------time_id finished-----------\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:19:28.622342Z","iopub.execute_input":"2022-02-23T20:19:28.622762Z","iopub.status.idle":"2022-02-23T20:19:29.538067Z","shell.execute_reply.started":"2022-02-23T20:19:28.622688Z","shell.execute_reply":"2022-02-23T20:19:29.537167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now you can continue with the normal submission process.","metadata":{}}]}