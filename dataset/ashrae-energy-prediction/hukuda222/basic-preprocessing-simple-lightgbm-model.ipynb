{"cells":[{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport tqdm\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport pickle\nimport random\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\n\nLOCAL = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"# preprocessing\nI created the data to be used this time with the following code, but this time it is running in a local environment because it takes more than 2 hours."},{"metadata":{"trusted":true},"cell_type":"code","source":"if LOCAL:\n    train_df = pd.read_csv('/kaggle/input/ashrae-energy-prediction/train.csv')\n    test_df = pd.read_csv('/kaggle/input/ashrae-energy-prediction/test.csv')\n    building = pd.read_csv('/kaggle/input/ashrae-energy-prediction/building_metadata.csv')\n    train_weather = pd.read_csv('/kaggle/input/ashrae-energy-prediction/weather_train.csv')\n    train_df = train_df.merge(building, on='building_id', how='left')\n    train_df = train_df.merge(train_weather, on=['site_id', 'timestamp'], how='left')\n    del train_weather\n    test_weather = pd.read_csv('/kaggle/input/ashrae-energy-prediction/weather_test.csv')\n    test_df = test_df.merge(building, on='building_id', how='left')\n    del building\n    test_df = test_df.merge(test_weather, on=['site_id', 'timestamp'], how='left')\n    del test_weather\n    gc.collect()\n\n    train_df[\"primary_use_cate\"]=float(np.nan)\n    test_df[\"primary_use_cate\"]=float(np.nan)\n    train_df[\"time_year\"]=float(np.nan)\n    train_df[\"time_month\"]=float(np.nan)\n    train_df[\"time_day\"]=float(np.nan)\n    train_df[\"time_hour\"]=float(np.nan)\n    test_df[\"time_year\"]=float(np.nan)\n    test_df[\"time_month\"]=float(np.nan)\n    test_df[\"time_day\"]=float(np.nan)\n    test_df[\"time_hour\"]=float(np.nan)\n\n    primary_use_cate = list(set(train_df[\"primary_use\"].values)|set(test_df[\"primary_use\"].values))\n    primary_use_label2int = {c:i for i,c in enumerate(primary_use_cate)}\n\n    for i in tqdm.tqdm(range(len(train_df))):\n        s = train_df.at[i,\"timestamp\"]\n        train_df.at[i,\"primary_use_cate\"] = primary_use_label2int[train_df.at[i,\"primary_use\"]]\n        train_df.at[i,\"time_year\"] = int(s[0:4])\n        train_df.at[i,\"time_month\"] = int(s[5:7])\n        train_df.at[i,\"time_day\"] = int(s[8:10])\n        train_df.at[i,\"time_hour\"] = int(s[11:13])\n    \n    for i in tqdm.tqdm(range(len(test_df))):\n        s = test_df.at[i,\"timestamp\"]\n        test_df.at[i,\"primary_use_cate\"] = primary_use_label2int[test_df.at[i,\"primary_use\"]]\n        test_df.at[i,\"time_year\"] = int(s[0:4])\n        test_df.at[i,\"time_month\"] = int(s[5:7])\n        test_df.at[i,\"time_day\"] = int(s[8:10])\n        test_df.at[i,\"time_hour\"] = int(s[11:13])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The elements that seem to contribute little was removed due to memory constraints."},{"metadata":{"trusted":true},"cell_type":"code","source":"if not LOCAL:\n    train_df = pickle.load(open(\"/kaggle/input/ashrae-preprocessed-data/train.pickle\",\"rb\"))\n    test_df = pickle.load(open(\"/kaggle/input/ashrae-preprocessed-data/test.pickle\",\"rb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://www.kaggle.com/divrikwicky/ashrae-lofo-feature-importance\n\ny_train = np.array(train_df[\"meter_reading\"])\ndel train_df['primary_use']\ndel train_df['meter_reading']\ndel train_df['year_built']\ndel train_df['floor_count']\ndel train_df['precip_depth_1_hr']\ndel train_df['wind_direction']\ndel train_df['sea_level_pressure']\ndel train_df['time_hour']\ndel train_df['timestamp']\n\ndel test_df['primary_use']\ndel test_df['row_id']\ndel test_df['year_built']\ndel test_df['floor_count']\ndel test_df['precip_depth_1_hr']\ndel test_df['wind_direction']\ndel test_df['sea_level_pressure']\ndel test_df['time_hour']\ndel test_df['timestamp']\n\nX_train = train_df\nX_test = test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=[0 for i in range(200)]\ndata_ori=[0 for i in range(21904701)]\nfor p in tqdm.tqdm(y_train):\n    data[int(np.log(p+1)*10)]+=1\n    data_ori[int(p)]+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([i for i in range(21904701)],data_ori)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, it is difficult to predict because of the wide distribution range."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([i for i in range(200)],data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So I decided to take the logarithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.log(y_train+1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train\nI think it's intuitive to use a regression algorithm in this competition."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"gc.collect()\nfolds = 3\nseed = 222\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_valid_pred = np.zeros(X_train.shape[0])\nmodels = []\n\nfor tr_idx, val_idx in kf.split(X_train, y_train):\n    tr_x, tr_y = X_train.iloc[tr_idx,:], y_train[tr_idx]\n    vl_x, vl_y = X_train.iloc[val_idx,:], y_train[val_idx]\n            \n    print(len(tr_x),len(vl_x))\n    tr_data = lgb.Dataset(tr_x, label=tr_y)\n    vl_data = lgb.Dataset(vl_x, label=vl_y)  \n    clf = lgb.LGBMRegressor(n_estimators=200,learning_rate=0.5,feature_fraction=0.9,\n            bagging_fraction=0.9,early_stopping_rounds=50)\n    clf.fit(tr_x, tr_y,\n        eval_set=[(vl_x, vl_y)],\n        verbose=True)\n    y_valid_pred[val_idx] += clf.predict(vl_x, num_iteration=clf.best_iteration_)\n    models.append(clf)\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# evaluation\nSince the minimum value is 0, it was clipped to do so."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"valid score is\",np.sqrt(sum(np.power(y_train-np.clip(y_valid_pred,0,None),2))/y_train.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# make submission\nI need to do the opposite of what was done in preprocessing."},{"metadata":{"trusted":true},"cell_type":"code","source":"res=np.zeros(41697600,dtype=float)\nfor i in tqdm.tqdm(range(0,41697600,27200)):\n    res[i:i+27200] = sum([np.clip(np.exp(model.predict(X_test.iloc[i:i+27200]))-1,0,None) for model in models])/folds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/ashrae-energy-prediction/sample_submission.csv')\nsubmission['meter_reading'] = res\nsubmission.to_csv('submission.csv', index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a way to reduce memory, and using it does not seem to require this effort to save memory for https://www.kaggle.com/hamditarek/reducing-memory-size-for-great-energy-predictor.<br>\nPlease let me know if you have any opinions or advice."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}