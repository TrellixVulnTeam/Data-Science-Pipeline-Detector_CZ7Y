{"cells":[{"metadata":{},"cell_type":"markdown","source":"# UCF Electrical and Chilled Water meter_readings\n\nSeveral others have released their scraped datasets and kernel demonstrating how they did it. For fairness to others, I decided to do likewise. Instead of sharing my web scraping and compilation code, I will be sharing the dataset directly with some brief analysis.\n\n** I scraped and compiled the dataset used in this kernel myself. Please upvote my [dataset](https://www.kaggle.com/teeyee314/ucf-building-meter-reading). **"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport feather\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read files\nucf = pd.read_feather('../input/ucf-building-meter-reading/site0.ft')\ntest_df = pd.read_csv('../input/ashrae-energy-prediction/test.csv', parse_dates=['timestamp'], dtype={'row_id':'int32', 'building_id':'int16', 'meter':'int8',})\nsub = pd.read_csv('../input/ashrae-half-and-half/submission.csv', dtype={'row_id':'int32', 'meter_reading':'float32'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission Post-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = test_df.merge(ucf, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"tmp = merged[~merged['meter_reading'].isna()][['row_id', 'meter_reading']]\ntmp2 = sub[merged['meter_reading'].isna()]\nfinal = pd.concat([tmp, tmp2], axis=0).reset_index(drop=True).sort_values(by='row_id')\nfinal['row_id'] = final['row_id'].astype('int32')\nfinal['meter_reading'] = final['meter_reading'].astype('float32')\nfinal.to_csv('submission.csv', chunksize=25000, index=False)\nfinal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"final mean:\", final['meter_reading'].mean())\nprint(\"final std:\", final['meter_reading'].std())\nprint(\"final min:\", final['meter_reading'].min())\nprint(\"final max:\", final['meter_reading'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Counterfactual Analysis of 1.10 Half Half submission\n\ncredit Vopani for: [this kernel](https://www.kaggle.com/rohanrao/ashrae-half-and-half)\n\ncredit kxx for: [this kernel](https://www.kaggle.com/kailex/ac-dc)\n\nWe will now look at a counterfactual. Knowing the labels to buildings 0-104 for the period 2017 through 2018, what would our RMSLE for buildings 0-104 for a model trained on first half/second half be? How bad or good are the half half LGBM model predictions?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# evaluation functions\ndef rmse(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(ypred - ytrue), axis=0))\ndef rmsle(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(np.log1p(ypred) - np.log1p(ytrue)), axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrue = merged[~merged['meter_reading'].isna()].sort_values(by='row_id')['meter_reading']\npred = sub[~merged['meter_reading'].isna()].sort_values(by='row_id')['meter_reading']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'RMSLE of buildings 0-104: {rmsle(ytrue, pred):.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_true = merged[~merged['meter_reading'].isna()].sort_values(by='row_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred = test_df.merge(sub, right_on='row_id', left_on='row_id', how='inner')\ndf_pred = df_pred[~merged['meter_reading'].isna()].sort_values(by='row_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot all predicted meter 1 by building_id from 2017-2018\n\nmeter = 1\nbuildings = set(range(105)).intersection(set(df_pred[df_pred['meter']==meter]['building_id'].unique()))\n\nfor i, building in enumerate(sorted(buildings)):\n    fig, ax = plt.subplots(figsize=(15,1))\n    plt.title(f\"Building {building} Meter {meter}\")\n    # plot meter_reading\n    idx = (df_pred['building_id'] == building) & (df_pred['meter'] == meter) \n    dates = matplotlib.dates.date2num(df_pred.loc[idx, 'timestamp'])\n    plt.plot_date(dates, df_pred.loc[idx, 'meter_reading'], '-', label='meter_reading')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot all ground truth (GT) meter 1 by building_id from 2017-2018\n\nmeter = 1\nbuildings = set(range(105)).intersection(set(df_true[df_true['meter']==meter]['building_id'].unique()))\n\nfor i, building in enumerate(sorted(buildings)):\n    fig, ax = plt.subplots(figsize=(15,1))\n    plt.title(f\"Building {building} Meter {meter}\")\n    # plot meter_reading\n    idx = (df_true['building_id'] == building) & (df_true['meter'] == meter) \n    dates = matplotlib.dates.date2num(df_true.loc[idx, 'timestamp'])\n    plt.plot_date(dates, df_true.loc[idx, 'meter_reading'], '-', label='meter_reading')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have actual test labels to compare our predictions against. We can see that the half half model cannot predict outliers. We can also see that for the Chilled Water meters, the outliers are fairly systematic. \n\nHopefully this kernel will help shed some insight and provide feedback for our own modeling process in terms of how good or bad our model predictions are compared to the GT labels."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}