{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/ashrae-energy-prediction/train.csv')\nweather_train = pd.read_csv('/kaggle/input/ashrae-energy-prediction/weather_train.csv')\nbuilding_metadata = pd.read_csv('/kaggle/input/ashrae-energy-prediction/building_metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">  Set the types of dataframe columns explicitly to reduce memory usage"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n#                     df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float32)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)\nweather_train = reduce_mem_usage(weather_train)\nbuilding_metadata = reduce_mem_usage(building_metadata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For a given column in the dataframe, calculate the Inter-quartile range and return along with the 1st and 3rd quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_iqr(col):\n    Q1 = col.quantile(0.25)\n    Q3 = col.quantile(0.75)\n    IQR = Q3 - Q1\n    return IQR, Q1, Q3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(df, weather_data, building_metadata, is_train=False):\n    \n    #Extract datetime related features\n    df['timestamp'] = pd.to_datetime(df.timestamp)\n    weather_data['timestamp'] = pd.to_datetime(weather_data.timestamp)\n    df['hour'] = df.timestamp.dt.hour\n    df['day'] = df.timestamp.dt.day\n    df['month'] = df.timestamp.dt.month\n    df['quarter'] = df.timestamp.dt.quarter\n    \n    #Merge with building_metadata and weather data\n    df = df.merge(building_metadata, left_on='building_id', right_on='building_id')\n    df = df.merge(weather_data, left_on=['site_id', 'timestamp'], right_on=['site_id', 'timestamp'])\n    \n    #eliminate outliers\n    if is_train:\n        IQR, Q1, Q3 = calculate_iqr(df['meter_reading'])\n        df = df[~((df['meter_reading'] < (Q1 - 1.5 * IQR)) |(df['meter_reading'] > (Q3 + 1.5 * IQR)))]\n        df['meter_reading'] = np.log1p(df.meter_reading)\n    \n#     del df['timestamp']\n    \n    #OHE\n    categorical_columns = ['month', 'meter', 'primary_use']\n    for col in categorical_columns:\n        df = pd.concat([df, pd.get_dummies(df[col]).rename(columns=lambda x: col + '_' + str(x))], axis=1, sort=False)\n#         del df[col]\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fe = feature_engineering(train, weather_train, building_metadata, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Monthly Average readings"},{"metadata":{"trusted":true},"cell_type":"code","source":"timestamp_grouped_data = train_fe.groupby('month')['meter_reading'].mean().reset_index()\nsns.lineplot(x='month', y='meter_reading', data=timestamp_grouped_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Hourly Average readings\n> > Usage is generally more during working hours "},{"metadata":{"trusted":true},"cell_type":"code","source":"hourly_grouped_data = train_fe.groupby('hour')['meter_reading'].mean().reset_index()\nsns.lineplot(x='hour', y='meter_reading', data=hourly_grouped_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Average usage hourly for each primary use"},{"metadata":{"trusted":true},"cell_type":"code","source":"primary_use_grouped_hourly = train_fe.groupby(['hour', 'primary_use'])['meter_reading'].mean().reset_index()\nhourly_primary_use_grid = sns.FacetGrid(primary_use_grouped_hourly, row='primary_use', height=2, aspect=3)\nhourly_primary_use_grid.map(sns.lineplot, 'hour', 'meter_reading')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Average usage monthly per primary use"},{"metadata":{"trusted":true},"cell_type":"code","source":"primary_use_grouped_monthly = train_fe.groupby(['month', 'primary_use'])['meter_reading'].mean().reset_index()\nmonthly_primary_use_grid = sns.FacetGrid(primary_use_grouped_monthly, row='primary_use', height=2, aspect=3)\nmonthly_primary_use_grid.map(sns.lineplot, 'month', 'meter_reading')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Total reading per meter type"},{"metadata":{"trusted":true},"cell_type":"code","source":"meter_type_grouped = train_fe.groupby(['meter'])['meter_reading'].sum().reset_index()\nsns.catplot(x='meter', y='meter_reading', data=meter_type_grouped, kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Meter type grouped monthly"},{"metadata":{"trusted":true},"cell_type":"code","source":"meter_grouped_monthly = train_fe.groupby(['meter', 'month'])['meter_reading'].mean().reset_index()\nmeter_type_month_grouped_grid = sns.FacetGrid(meter_grouped_monthly, row='meter', height=2, aspect=3)\nmeter_type_month_grouped_grid.map(sns.lineplot, 'month', 'meter_reading')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train_fe['meter_reading']\n\ncols_to_delete = ['month', 'meter', 'primary_use', 'meter_reading', 'timestamp']\nfor col in cols_to_delete:\n    del train_fe[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(train_fe, Y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n        \"objective\" : \"regression\", \"metric\" : \"rmse\", \"max_depth\" : 5,\n        \"num_leaves\" : 50, \"learning_rate\" : 0.01, \"bagging_fraction\" : 0.9,\n        \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.8\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"record = dict()\n\nmodel = lgb.train(params\n                      , lgb.Dataset(X_train, Y_train)\n                      , num_boost_round = 100\n                      , valid_sets = [lgb.Dataset(X_test, Y_test)]\n                      , verbose_eval = True\n                      , early_stopping_rounds = 20\n                      , callbacks = [lgb.record_evaluation(record)]\n                     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(model, importance_type='split', max_num_features=20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}