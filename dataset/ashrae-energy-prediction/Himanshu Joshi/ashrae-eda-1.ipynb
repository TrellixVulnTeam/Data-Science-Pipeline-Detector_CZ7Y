{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.patches as patches\n\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%time\nroot = '../input/ashrae-energy-prediction/'\ntrain_df = pd.read_csv(root + 'train.csv')\ntrain_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n\nweather_train_df = pd.read_csv(root + 'weather_train.csv')\nweather_train_df[\"timestamp\"] = pd.to_datetime(weather_train_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\ntest_df = pd.read_csv(root + 'test.csv')\ntest_df[\"timestamp\"] = pd.to_datetime(test_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\nweather_test_df = pd.read_csv(root + 'weather_test.csv')\nweather_test_df[\"timestamp\"] = pd.to_datetime(weather_test_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\nbuilding_meta_df = pd.read_csv(root + 'building_metadata.csv')\nsample_submission = pd.read_csv(root + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of train_df data', train_df.shape)\nprint('Size of weather_train_df data', weather_train_df.shape)\nprint('Size of weather_test_df data', weather_test_df.shape)\nprint('Size of building_meta_df data', building_meta_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Reducing memory\ntrain_df = reduce_mem_usage(train_df)\ntest_df = reduce_mem_usage(test_df)\n\nweather_train_df = reduce_mem_usage(weather_train_df)\nweather_test_df = reduce_mem_usage(weather_test_df)\nbuilding_meta_df = reduce_mem_usage(building_meta_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nplt.plot(train_df['meter_reading'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# No. of unique values in building id\ntrain_df.building_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_meter_reading = train_df.groupby(['timestamp'])['meter_reading'].sum()\nplt.figure(figsize = (16,5))\nplt.xlabel(\"timestamp\")\nplt.ylabel(\"meter_reading\")\nplt.plot(date_meter_reading)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_mtype_reading = train_df.groupby(['timestamp', 'meter'])['meter_reading'].agg(['min','max','median','sum'])\ndate_mtype_reading.columns = ['meter_reading_' + x for x in date_mtype_reading.columns]\ndate_mtype_reading.reset_index(inplace=True)\ndate_mtype_reading['Date'] = date_mtype_reading.timestamp.dt.date\ndate_mtype_reading.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"meter_reading_sum\", \n             hue=\"meter\", \n             data=date_mtype_reading, \n             palette=sns.color_palette('coolwarm', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"{0: electricity, 1: chilledwater, 2: steam, 3: hotwater}\nWhat is the difference between steam and hotwater, in terms of usage in building and for meter reading?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"meter_reading_max\", \n             hue=\"meter\", \n             data=date_mtype_reading, \n             palette=sns.color_palette('hls', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the spikes are caused because of the maximum meter readings for each building. Lets try to plot median, which will give a clear picture"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"meter_reading_median\", \n             hue=\"meter\", \n             data=date_mtype_reading, \n             palette=sns.color_palette('husl', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find what's the difference between values(variance or std) in meter_reading for a particular date. Although, median gives a clear picture, still want to confirm the numbers. OR plot the meter reading(scatter plot) for few dates and see the numbers. If the SD is less, we are good, else, this approach doesn't yield correct numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"building_meta_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_meta_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_meta_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_meta_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_meta_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"mean() of year_built is inf because sum is inf. Since, we have changed the dtype of columns to save memory usage, the sum() is coming out of range of float16."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Types of building in the data\nbuilding_meta_df['primary_use'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**UNIVARIATE ANALYSIS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.distplot(building_meta_df.square_feet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Year built is the year building is opened, as per the kaggle information\nbuilding_meta_df_temp = building_meta_df[pd.notnull(building_meta_df.year_built)]\nplt.figure(figsize = (16,5))\nsns.distplot(building_meta_df_temp.year_built)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_meta_df_temp = building_meta_df[pd.notnull(building_meta_df.floor_count)]\nplt.figure(figsize = (16,5))\nsns.distplot(building_meta_df_temp.floor_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,7))\nuse_plot = sns.countplot(building_meta_df_temp.primary_use)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check no. of buildings for each building type\nbuilding_meta_df_temp.primary_use.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Year built is the year building is opened, as per the kaggle information\nbuilding_meta_df_temp = building_meta_df[pd.notnull(building_meta_df.year_built)]\nplt.figure(figsize = (16,5))\nsns.distplot(building_meta_df_temp[building_meta_df_temp.primary_use == \"Education\"].year_built)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.distplot(building_meta_df_temp[building_meta_df_temp.primary_use == \"Entertainment/public assembly\"].year_built)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.distplot(building_meta_df_temp[building_meta_df_temp.primary_use == \"Public services\"].year_built)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.distplot(building_meta_df_temp[building_meta_df_temp.primary_use == \"Office\"].year_built)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.distplot(building_meta_df_temp[building_meta_df_temp.primary_use == \"Lodging/residential\"].year_built)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The boom in the real estate industry(especially for resindential purposes) that came during 2000s, is shown by the graph."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.scatterplot(x=\"square_feet\", y=\"floor_count\", data=building_meta_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the buildings below 2,00,000 square feet have floor count within range of 10. Can be used to impute missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"building_meta_df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No strong co-relations between any of the independent variables in building_meta dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"building_type_df = building_meta_df.groupby(['primary_use'])['square_feet','year_built', 'floor_count'].agg(['mean','max','min'])\nbuilding_type_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_type_df.columns = [building_type_df.columns[i][0] + '_' + building_type_df.columns[i][1] for i in range(0,len(building_type_df.columns))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill index of 'Food sales and service'\nbuilding_type_df.fillna(1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(building_meta_df)):\n    if(pd.isna(building_meta_df['year_built'][i])):\n        building_meta_df.loc[i,'year_built'] = building_type_df.loc[building_meta_df['primary_use'][i], 'year_built_mean']\n    if(pd.isna(building_meta_df['floor_count'][i])):\n        building_meta_df.loc[i,'floor_count'] = building_type_df.loc[building_meta_df['primary_use'][i], 'floor_count_mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check null values\nbuilding_meta_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get unique count of site id's in the data\nweather_train_df.site_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To check occurence of missing values\nplt.figure(figsize=(16,5))\nsns.heatmap(weather_train_df.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To check occurence of missing values\nplt.figure(figsize=(16,5))\nsns.heatmap(weather_test_df.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a date column from timestamp column\nweather_train_date_df = weather_train_df.copy()\nweather_train_date_df['Date'] = weather_train_df['timestamp'].dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df_temp = weather_train_df[pd.notnull(weather_train_df.air_temperature)]\nplt.figure(figsize = (16,5))\nsns.distplot(weather_train_df_temp.air_temperature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"air_temperature\", \n             data=weather_train_date_df, \n             palette=sns.color_palette('husl', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This graph is in line with train_df data. Because, as the air temperature increased, meter reading for chilled water got increase, while as the temperature decrease, meter reading for hot water and specially steam increased.\nWinter Season - 2016-01 to 2016-05 & 2016-10 to 2017-01\nsummer - 2016-05 to 2016-10\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df_temp = weather_train_df[pd.notnull(weather_train_df.cloud_coverage)]\nplt.figure(figsize = (16,5))\nsns.distplot(weather_train_df_temp.cloud_coverage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"cloud_coverage\", \n             data=weather_train_date_df, \n             palette=sns.color_palette('hls', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cloud coverage is almost constant with spikes ranging from 2 to 3 except for a few cases. Means, it might be partly sunny always, given the weather conditions.\nFEW = Few (1 to 2 oktas); SCT = Scattered (3 to 4 oktas)"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df_temp = weather_train_df[pd.notnull(weather_train_df.dew_temperature)]\nplt.figure(figsize = (16,5))\nsns.distplot(weather_train_df_temp.dew_temperature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"dew_temperature\", \n             data=weather_train_date_df, \n             palette=sns.color_palette('hls', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Information: The dewpoint temperature is the temperature at which the air can no longer \"hold\" all of the water vapor which is mixed with it, and some of the water vapor must condense into liquid water. The dew point is always lower than (or equal to) the air temperature.\n\nIf the air temperature cools to the dew point, or if the dew point rises to equal the air temperature, then dew, fog or clouds begin to form. At this point where the dew point temperature equals the air temperature, the relative humidity is 100%.\n\nTake away: Can include relative humidity column from air temperature and dew temperature."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(weather_train_df.precip_depth_1_hr.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df_temp = weather_train_df[pd.notnull(weather_train_df.precip_depth_1_hr)]\nplt.figure(figsize = (16,5))\nsns.distplot(weather_train_df_temp.precip_depth_1_hr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"precip_depth_1_hr\", \n             data=weather_train_date_df, \n             palette=sns.color_palette('hls', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The spikes might indicate that rain fall happened. Can look into the picture by plotting values of relative humidity. Should show same behaviour."},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df_temp = weather_train_df[pd.notnull(weather_train_df.wind_direction)]\nplt.figure(figsize = (16,5))\nsns.distplot(weather_train_df_temp.wind_direction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"wind_direction\", \n             data=weather_train_date_df, \n             palette=sns.color_palette('hls', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train_df_temp = weather_train_df[pd.notnull(weather_train_df.wind_speed)]\nplt.figure(figsize = (16,5))\nsns.distplot(weather_train_df_temp.wind_speed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\nsns.lineplot(x=\"Date\", \n             y=\"wind_speed\", \n             data=weather_train_date_df, \n             palette=sns.color_palette('hls', n_colors=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill the missing values using linear interpolation method in forward direction\nweather_train_df.interpolate(method='linear', limit_direction='forward', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill the missing values using linear interpolation method in backward direction to fill left-over values\nweather_train_df.interpolate(method='linear', limit_direction='backward', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join the train and building dataframes\ntrain_building_df = train_df.merge(building_meta_df, on=['building_id'], how='left')\ntrain_building_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_building_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_building_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_building_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df = train_building_df.merge(weather_train_df, on=['timestamp', 'site_id'], how='left')\ntrain_final_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for which timestamp and site id, values are not present in weather_data but present in training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df_temp = train_final_df.groupby('primary_use')['meter_reading'].agg(sum)\ntrain_final_df_temp.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since, no. of building which are high in count, have highest energy consumption, which shows a linear relationship with meter reading. And, also, since we are building a tree based model, label encoding is the best option for encoding."},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering\n1) relative humidity = dewtemperature/airtemperature\n2) building size = squarefee*floorcount"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_final_df['primary_use'] = le.fit_transform(train_final_df['primary_use'])\ntrain_final_df['primary_use'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Can change the label encoding, as it changed the orientation, need to think about it."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final_df['month'] = train_final_df.timestamp.dt.month\ntrain_final_df['hour'] = train_final_df.timestamp.dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take log of target variable to calculate rmse score for RMSLE\ntrain_final_df['meter_reading'] = np.log(train_final_df['meter_reading'] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoricals = [\"site_id\", \"building_id\", \"primary_use\", \"meter\",  \"cloud_coverage\"]\ntarget = train_final_df.pop('meter_reading')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_cols = list(train_final_df.columns)\nfeat_cols.remove('timestamp')\nfeat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nparams = {\n            'boosting_type': 'gbdt',\n            'objective': 'regression',\n            'metric': {'rmse'},\n            'subsample': 0.25,\n            'subsample_freq': 1,\n            'learning_rate': 0.4,\n            'num_leaves': 20,\n            'feature_fraction': 0.9,\n            'lambda_l1': 1,  \n            'lambda_l2': 1\n            }\n\nfolds = 4\nseed = 666\n\nkf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n\nmodels = []\n\nfor train_index, val_index in kf.split(train_final_df, train_final_df['building_id']):\n    train_X = train_final_df[feat_cols].iloc[train_index]\n    val_X = train_final_df[feat_cols].iloc[val_index]\n    train_y = target.iloc[train_index]\n    val_y = target.iloc[val_index]\n    lgb_train = lgb.Dataset(train_X, train_y, categorical_feature=categoricals)\n    lgb_eval = lgb.Dataset(val_X, val_y, categorical_feature=categoricals)\n    gbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=500,\n                valid_sets=(lgb_train, lgb_eval),\n                early_stopping_rounds=100,\n                verbose_eval = 100)\n    models.append(gbm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nmodel_dir = \"/kaggle/working/models/\"\nif(os.path.exists(model_dir) == False):\n    os.mkdir(model_dir)\nelse:\n    i=1\n    for model in models:\n        pkl_filename = model_dir +  'model_'+ str(i) + '.pkl'\n        print(pkl_filename)\n        with open(pkl_filename, 'wb') as file:\n            pickle.dump(model, file)\n            i = i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    lgb.plot_importance(model)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing unnecessary dataframes\nimport gc\ndel train_final_df, train_X, val_X, lgb_train, lgb_eval, train_y, val_y, target\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join the train and building dataframes\ntest_building_df = test_df.merge(building_meta_df, on=['building_id'], how='left')\ntest_building_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_building_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill the missing values using linear interpolation method in forward direction\nweather_test_df.interpolate(method='linear', limit_direction='forward', inplace=True)\n# Fill the missing values using linear interpolation method in backward direction\nweather_test_df.interpolate(method='linear', limit_direction='forward', inplace=True)\ntest_final_df = test_building_df.merge(weather_test_df, on=['timestamp', 'site_id'], how='left')\ntest_final_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_final_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot-> weather_train_df and weather_test_df after interpolation to see, if the graphs are changed or not. Should not change.\nPlot the distribution of all variables in both train and test. Get insights.\nUnderstand results properly, and do feature engineering. \nWhat to do with outliers? Some buildings have very high meter value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill null values with 0\ntest_final_df.fillna(0, inplace=True)\ntest_final_df['primary_use'] = le.fit_transform(test_final_df['primary_use'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_final_df[\"timestamp\"] = pd.to_datetime(test_final_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\ntest_final_df['month'] = test_final_df.timestamp.dt.month\ntest_final_df['hour'] = test_final_df.timestamp.dt.hour\ntest_final_df = test_final_df[feat_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\n# Summing up all the model predictions, divided by folds, and then taking exponent followed by subtraction from 1.\ni=0\nres=[]\nstep_size = 50000\nfor j in tqdm(range(int(np.ceil(test_final_df.shape[0]/50000)))):\n    res.append(np.expm1(sum([model.predict(test_final_df.iloc[i:i+step_size]) for model in models])/folds))\n    i+=step_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = np.concatenate(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/ashrae-energy-prediction/sample_submission.csv')\nsubmission['meter_reading'] = res\nsubmission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}