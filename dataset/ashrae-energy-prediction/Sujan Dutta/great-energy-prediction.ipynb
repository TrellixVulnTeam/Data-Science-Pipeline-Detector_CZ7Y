{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/test.csv\")\nweather_train = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/weather_train.csv\")\nweather_test = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/weather_test.csv\")\nbuilding_data = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/building_metadata.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reduce size"},{"metadata":{"trusted":true},"cell_type":"code","source":"# taken from https://www.kaggle.com/caesarlupum/ashrae-start-here-a-gentle-introduction\n\n## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\n\nweather_train = reduce_mem_usage(weather_train)\nweather_test = reduce_mem_usage(weather_test)\nbuilding_data = reduce_mem_usage(building_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check if everything's OK"},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How many types of building are there?"},{"metadata":{"trusted":true},"cell_type":"code","source":"building_data[\"primary_use\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merge everything"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(building_data, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(weather_train, left_on = [\"site_id\", \"timestamp\"], right_on = [\"site_id\", \"timestamp\"], how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot the time series of 1 building from each type"},{"metadata":{"trusted":true},"cell_type":"code","source":"edu_1 = train.loc[train['building_id'] == 1]\nent_10 = train.loc[train['building_id'] == 10]\nfood_179 = train.loc[train['building_id'] == 179]\nhealth_208 = train.loc[train['building_id'] == 208]\nlodg_6 = train.loc[train['building_id'] == 16]\ninds_672 = train.loc[train['building_id'] == 672]\noffice_9 = train.loc[train['building_id'] == 9]\nother_42 = train.loc[train['building_id'] == 42]\nparking_51 = train.loc[train['building_id'] == 51]\npublic_138 = train.loc[train['building_id'] == 138]\nrelig_186 = train.loc[train['building_id'] == 186]\nserv_892 = train.loc[train['building_id'] == 892]\ntech_575 = train.loc[train['building_id'] == 575]\nutil_285 = train.loc[train['building_id'] == 285]\nstorage_164 = train.loc[train['building_id'] == 164]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"edu_1.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Education\")\nent_10.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Entertainment\")\nfood_179.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Food\")\nhealth_208.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Healthcare\")\nlodg_6.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Lodging\")\ninds_672.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Industrial\")\noffice_9.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Office\")\nother_42.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Other\")\nparking_51.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Parking\")\npublic_138.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Public\")\nrelig_186.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Religious\")\nserv_892.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Services\")\ntech_575.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Technology\")\nutil_285.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Utility\")\nstorage_164.plot.line(x='timestamp', y='meter_reading',figsize=(20,5), title=\"Storage\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of meter_reading over primary_use for every site"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(16):\n    sns.catplot(x=\"primary_use\", y=\"meter_reading\", data=train.loc[train['site_id'] == i], height=10, aspect=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How the average meter_reading varies over primary_use?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(\"primary_use\")[\"meter_reading\"].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting timestamp"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"month\"] = train[\"timestamp\"].apply(lambda x : x.split(\" \")[0].split(\"-\")[1])\ntrain[\"day\"] = train[\"timestamp\"].apply(lambda x : x.split(\" \")[0].split(\"-\")[2])\ntrain[\"time\"] = train[\"timestamp\"].apply(lambda x : x.split(\" \")[1].split(\":\")[0])\ntrain[\"day_of_week\"] = pd.DatetimeIndex(train[\"timestamp\"].apply(lambda x : x.split(\" \")[0])).dayofweek\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of meter_reading over days_of_week and primary_use"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    sns.catplot(x=\"day_of_week\", y=\"meter_reading\", hue=\"primary_use\", data=train.loc[train['site_id'] == i], height=10, aspect=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = train.isnull().sum() * 100 / len(train)\nmissing_df = pd.DataFrame({'column_name': train.columns,\n                                 'percent_missing': missing})\nmissing_df.sort_values('percent_missing', inplace=True)\nmissing_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ----------------------------------------------\n### *thinking in progress...*\n\n### *If you find this kernel useful do upvote!*\n## As you are already into Data Science and ML, you may find my channel interesting...\n# [Normalized Nerd](https://www.youtube.com/channel/UC7Fs-Fdpe0I8GYg3lboEuXw)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}