{"cells":[{"metadata":{},"cell_type":"markdown","source":"# After prediction, draw on the graph and verify\nAs a precondition, there must be a prediction result in ashrae-great-energy. <br>\n-X axis is timestamp <br>\n-For the Y axis, Log function is applied to \"Meter Reading\" \n\n\n# 予測後、グラフに描画して検証する\n前提条件として、ashrae-great-energyにて予測結果が存在していること。<br>\n・X軸はtimestamp<br>\n・Y軸は、「Meter Reading」にLog関数を適用したものとする<br>\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport lightgbm as lgbm\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\nimport warnings\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n#np.seterr(divide='ignore', invalid='ignore')\n#numpy.seterr(all='raise')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    #code from\n    #https://www.kaggle.com/rohanrao/ashrae-half-and-half\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displayの行数と列数を増やす\n#display Increase the number of rows and columns in \npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 200)\nwarnings.simplefilter('ignore')\n#csvを読み込む\n#read csv\nbuilding = pd.read_csv('../input/ashrae-energy-prediction/building_metadata.csv')\nweather_train = pd.read_csv('../input/ashrae-energy-prediction/weather_train.csv')\nweather_test = pd.read_csv('../input/ashrae-energy-prediction/weather_test.csv')\ntrain = pd.read_csv('../input/ashrae-energy-prediction/train.csv') \ntest = pd.read_csv('../input/ashrae-energy-prediction/test.csv')\n\n#ここはテストデータから作成した予測データを読み込む\n#Load forecast data\n#submission_test = pd.read_csv('../input/ashrae-half-and-half/submission_13.csv')\nsubmission_test = pd.read_csv('../input/ashrae-test-leak-validation-and-more/submission.csv')\n\nle = LabelEncoder()\nbuilding.primary_use = le.fit_transform(building.primary_use)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def boundary_show_train_test(train,test):\n    \"\"\"\n    Training data and test data (test data has already been added with the predicted objective variable)\n    :param train:\n    :param test:\n    \"\"\"    \n    \n    datas = train.tail(100) \n    datas = datas.append(test.head(100))\n    \n    datas = datas.reset_index()\n    \n    return datas\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"----building------------------------------------------\")\ndisplay(building.head(5))\ndisplay(building.describe().T)\ndisplay(building.dtypes)\nprint(building.shape)\n\nprint(\"----weather_train------------------------------------------\")\ndisplay(weather_train.head(5))\ndisplay(weather_train.describe().T)\ndisplay(weather_train.dtypes)\nprint(weather_train.shape)\n\nprint(\"----train------------------------------------------\")\ndisplay(train.head(5))\ndisplay(train.describe().T)\ndisplay(train.dtypes)\nprint(train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#基礎的な統計量を出す\nprint(\"building\" + \"-\" * 50)\ndisplay(building.describe().T)\nprint(\"weather_train\" + \"-\" * 50)\ndisplay(weather_train.describe().T)\nprint(\"train\" + \"-\" * 50)\ndisplay(train.describe().T)\n\n#欠損を出す\nprint(\"train null\" + \"-\" * 50)\ndisplay(train.isnull().sum())\n\nprint(\"weather_train null\" + \"-\" * 50)\ndisplay(weather_train.isnull().sum())\n\nprint(\"building null\" + \"-\" * 50)\ndisplay(building.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####################################\n#Data merge\n####################################\n\n#訓練データとビル情報\ntrain = train.merge(building, on = 'building_id', how = 'left')\n\n#訓練データと気象データ\ntrain = train.merge(weather_train, on = ['site_id', 'timestamp'], how = 'left')\n\n#テストデータとビル情報\ntest = test.merge(building, on = 'building_id', how = 'left')\n\n#テストデータと気象データ\ntest = test.merge(weather_test, on = ['site_id', 'timestamp'], how = 'left')\n\n#テストデータと予測データ\ntest = test.merge(submission_test, on = 'row_id', how = 'left')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reduce_mem_usage\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del weather_train, weather_test,building, submission_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#時間によって変化があるため時間の処理が必要\ntrain[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\ntrain[\"hour\"] = np.uint8(train[\"timestamp\"].dt.hour)\ntrain[\"day\"] = np.uint8(train[\"timestamp\"].dt.day)\ntrain[\"weekday_name\"] = train[\"timestamp\"].dt.weekday_name \ntrain[\"weekday\"] = np.uint8(train[\"timestamp\"].dt.weekday)\ntrain[\"month\"] = np.uint8(train[\"timestamp\"].dt.month)\n\ntest[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\ntest[\"hour\"] = np.uint8(test[\"timestamp\"].dt.hour)\ntest[\"day\"] = np.uint8(test[\"timestamp\"].dt.day)\ntest[\"weekday_name\"] = test[\"timestamp\"].dt.weekday_name \ntest[\"weekday\"] = np.uint8(test[\"timestamp\"].dt.weekday)\ntest[\"month\"] = np.uint8(test[\"timestamp\"].dt.month)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#meter_readingをログに入れる\ntrain['meter_reading_log'] =  np.log1p(train['meter_reading'])\ntrain['square_feet_log'] =  np.log1p(train['square_feet'])\n\n#ビルごと、meterごと、月ごとの集計を出す\ndata = train.groupby(['building_id','meter','month']).sum()\ndata.to_csv(\"building_merter_month_meter_reading_sum.csv\")\n\n#ビルごと、meterごと、月ごとの集計を出す\ndata = train.groupby(['building_id','meter','month']).mean()\ndata.to_csv(\"building_merter_month__meter_reading_mean.csv\")\n\n\ndisplay(data)\n#check_validation_train_test(train,test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def building_plot(building_id,train, test,comment=\"\" ):\n    \"\"\"\n    building data plot\n    :param building_id:\n    :param train:\n    :param test:\n    :param comment:\n    \"\"\"\n\n    plt.rcParams['figure.figsize'] = (19,11)\n    plt.title(\"building_id_%d  %s\" % (building_id,comment ))\n    \n    ###########################################\n    #訓練とテストデータをbuilding_idでクエリする\n    ###########################################\n    \n    #訓練データ側\n    query_str = ('building_id == %s' % str(building_id) )\n    temp_df_train = train.query(query_str)\n    temp_df_train['meter_reading'] = np.log1p(temp_df_train['meter_reading'])\n    temp_df_train = temp_df_train.reset_index()\n    #日ごとのデータに変換する\n    group = temp_df_train.groupby([temp_df_train['timestamp'].dt.year,temp_df_train['timestamp'].dt.month,temp_df_train['timestamp'].dt.day, 'meter' ]).groups\n    #print(group)\n    \n    temp_df_train2 = pd.DataFrame(columns=[\"meter\",\"timestamp\",\"meter_reading\"])\n    \n    cnt = 0\n    for k ,v in group.items():\n        meter = k[3]\n        year =k[0]\n        month =k[1]\n        day =k[2]\n\n        report_data = temp_df_train.iloc[ v,:  ]\n        meter_reading_mean = report_data[\"meter_reading\"].mean()\n        time_day = pd.to_datetime(('%d-%d-%d') % (year, month,day))\n        tmp_se = pd.Series([meter,\n                            time_day,\n                            meter_reading_mean,\n                        ],index=temp_df_train2.columns, name=str(cnt)) \n        cnt +=1\n        temp_df_train2 = temp_df_train2.append(tmp_se)\n   \n\n    #テストデータ側\n    temp_df_test = test.query(query_str)\n    temp_df_test['meter_reading'] = np.log1p(temp_df_test['meter_reading'])\n    temp_df_test = temp_df_test.reset_index()\n    group = temp_df_test.groupby([temp_df_test['timestamp'].dt.year,temp_df_test['timestamp'].dt.month,temp_df_test['timestamp'].dt.day, 'meter' ]).groups\n    temp_df_train3 = pd.DataFrame(columns=[\"meter\",\"timestamp\",\"meter_reading\"])\n    \n    cnt = 0\n    for k ,v in group.items():\n        meter = k[3]\n        year =k[0]\n        month =k[1]\n        day =k[2]\n\n        report_data = temp_df_test.iloc[ v,:  ]\n        meter_reading_mean = report_data[\"meter_reading\"].mean()\n        time_day = pd.to_datetime(('%d-%d-%d') % (year, month,day))\n        tmp_se = pd.Series([meter,\n                            time_day,\n                            meter_reading_mean,\n                        ],index=temp_df_train2.columns, name=str(cnt)) \n        cnt +=1\n        temp_df_train3 = temp_df_train3.append(tmp_se)\n\n\n    \n    \n    \n    #境界線部分の作成\n    testdata = boundary_show_train_test(temp_df_train,temp_df_test)\n    #display(testdata)\n    testdata.to_csv((\"building_id_%s.csv\" % str(building_id)),encoding = 'utf-8-sig')    \n    \n    #グラフを書く(訓練側)\n    alpha = 0.5\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 0\"), x = 'timestamp', y = 'meter_reading', color = 'r',alpha=alpha,label = \"merter0\")\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 1\"), x = 'timestamp', y = 'meter_reading', color = 'g',alpha=alpha,label = \"merter1\")\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 2\"), x = 'timestamp', y = 'meter_reading', color = 'b',alpha=alpha,label = \"merter2\")\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 3\"), x = 'timestamp', y = 'meter_reading', color = 'c',alpha=alpha,label = \"merter3\")\n      \n    \n    #グラフを書く(テスト側)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 0\"), x = 'timestamp', y = 'meter_reading', color = 'r',alpha=alpha)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 1\"), x = 'timestamp', y = 'meter_reading', color = 'g',alpha=alpha)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 2\"), x = 'timestamp', y = 'meter_reading', color = 'b',alpha=alpha)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 3\"), x = 'timestamp', y = 'meter_reading', color = 'c',alpha=alpha)\n    \n    plt.ylabel('Log Meter Reading')\n\n    #訓練データとテストデータの境界線を書く\n    plt.axvline(x=pd.to_datetime(\"2017-01-01\"), color='b')\n    plt.text(pd.to_datetime(\"2017-01-01\"), ax.get_ylim()[1], \"Prediction Begin\",\n             horizontalalignment='center',\n             verticalalignment='center',\n             color='b',\n             bbox=dict(facecolor='white', alpha=0.9))    \n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_correlation_matrix_train(train_df):\n\n    #カラムの選択\n    train_df = train_df.reset_index()\n    train_df = train_df.loc[:, [\"meter_reading_log\",'floor_count','year_built',\"air_temperature\",\"cloud_coverage\",\"dew_temperature\",'precip_depth_1_hr','wind_direction','square_feet','sea_level_pressure']]\n    df_corr = train_df.corr()\n    display(df_corr)\n    sns.heatmap(df_corr, vmax=1, vmin=-1, center=0)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#訓練データで相関図を作る\n#display(train.head(5))\nmake_correlation_matrix_train(train )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building_id:29 meter:1 diff:6.173086  さらにmeter=0が壊滅的にやばい\n#building_plot(29,train ,test,comment=\"building_id:29 meter:1 diff:6.173086 resample before\")\n\n#research\n#3month_meter_reading 100 ander(site_id = 0 nasi(104nasi))\nbuilding = pd.read_csv('/kaggle/input/3month-meter-reading-zero/3month_meter_reading_zero.csv')\n\nbuilding = building[\"building_id\"].unique()\n\nfor i in building:\n    building_plot(i,train ,test,comment=\"3month-meter-reading 100 ander\")\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n#リサンプリングを試してみる\n#building_id = 29 meter=0\nbull29 = train[(train['building_id'] ==  29) &  (train['meter'] ==  0)]\ndisplay(bull29)\n#serial_num = pd.RangeIndex(start=1, stop=len(bull29.index) + 1, step=1)\n#bull29['No'] = serial_num\n\nbull29.set_index(\"timestamp\")\ndateTimeIndex = pd.DatetimeIndex(bull29['timestamp'])\nbull29.index = dateTimeIndex\nbull29 = bull29.resample('H').mean()\ndisplay(bull29)\nbull29 = bull29.reset_index()\n#trainデータからリサンプリング前の情報を削除\ntrain = train[ ~ ((train[\"building_id\"] == 29)  & (train.meter == 0) ) ]\ntrain.append(bull29)\ntrain.reset_index()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndisplay(train[ train['building_id'] == 29 & (train.meter == 0) ])\nbuilding_plot(29,train ,test,comment=\"building_id:29 meter:1 diff:6.173086 resample after\")\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"building_plot(1018,train ,test)\nbuilding_plot(1013,train ,test)\nbuilding_plot(740,train ,test)\nbuilding_plot(1022,train ,test)\nbuilding_plot(287,train ,test)\nbuilding_plot(279,train ,test)\nbuilding_plot(252,train ,test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ここには、訓練データとテストデータ(予測結果)において比較したいbuilding idを記載する\n#Here, enter the building id you want to compare between training data and test data\n\n#最も０メータが多いビル\nbuilding_plot(954,train ,test,comment=\"most 0 meter count\")\n\n#２番目に０メータが多いビル\nbuilding_plot(799,train ,test,comment=\"2nd 0 meter count\")\n\n#3番目に０メータが多いビル\nbuilding_plot(1232,train ,test,comment=\"3rd 0 meter count\")\n\n#4番目に０メータが多いビル\nbuilding_plot(1022,train ,test,comment=\"4th 0 meter count\")\n\n#5番目に０メータが多いビル\nbuilding_plot(1324,train ,test,comment=\"5th 0 meter count\")\n\n\n#分散値が最も低いmeter_reading「4.55E-12」\nbuilding_plot(740,train ,test,comment=\"most low dispersion\")\n\n#標準偏差が低いmeter_reading「0.000350764 meter=1」\nbuilding_plot(1018,train ,test,comment=\"meter_reading 0.000350764 meter=1\")\n\n\n#分散値が２番めに低いmeter_reading「0.007100055」\nbuilding_plot(636,train ,test,comment=\"2nd low dispersion\")\n\n#分散値が3番めに低いmeter_reading「0.014564584」\nbuilding_plot(637,train ,test,comment=\"3rd low dispersion\")\n\n#分散値が4番めに低いmeter_reading「0.017347898」\nbuilding_plot(846,train ,test,comment=\"4th low dispersion\")\n\n#分散の中間(ビルを1000個ならべたときの中間の位置)「650.9789」\nbuilding_plot(1082,train ,test,comment=\"middium 1 dispersion\")\n\n#分散の中間(ビルを1000個ならべたときの中間の位置)「654.3975」\nbuilding_plot(733,train ,test,comment=\"middium 2 dispersion\")\n\n\n#分散が最も多いmeter_reading「23370951000000」\nbuilding_plot(1099,train ,test,comment=\"most value dispersion\")\n\n#分散が２番めに多いmeter_reading「13617740000」\nbuilding_plot(778,train ,test,comment=\"2nd value dispersion\")\n\n\n\n#building_id:60 meter:1 diff:6.149655\nbuilding_plot(60,train ,test,comment=\"building_id:60 meter:1 diff:6.149655\")\n\n#building_id:803 meter:0 diff:7.762360\nbuilding_plot(803,train ,test,comment=\"building_id:803 meter:0 diff:7.762360\")\n\n#building_id:993 meter:0 diff:7.081440\nbuilding_plot(993,train ,test,comment=\"building_id:993 meter:0 diff:7.081440\")\n\n#building_id:993 meter:1 diff:7.570996\nbuilding_plot(993,train ,test,comment=\"building_id:993 meter:1 diff:7.570996\")\n\n#12/31日がエネルギー使用量０のビル\nbuilding_plot(28,train ,test,comment=\"12/31 meter_reading is 0\")\nbuilding_plot(43,train ,test,comment=\"12/31 meter_reading is 0\")\nbuilding_plot(103,train ,test,comment=\"12/31 meter_reading is 0\")\nbuilding_plot(191,train ,test,comment=\"12/31 meter_reading is 0\")\nbuilding_plot(263,train ,test,comment=\"12/31 meter_reading is 0\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all diff to csv\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def boundary_validation_train_test(train,test):\n    \"\"\"\n    boundary_validation_train_test\n    :param train:\n    :param test:\n    :return diff value\n    \"\"\"    \n\n    #３日分取得 訓練データ\n    datas = train.tail(72)\n    if len(datas) < 1:\n        return -1\n    datas[\"meter_reading\"] = np.log1p(datas[\"meter_reading\"])\n    \n    train_mean = datas['meter_reading'].mean()\n    \n    \n    #３日分取得 テストデータ\n    datas = test.head(72)\n    if len(datas) < 1:\n        return -1\n    datas[\"meter_reading\"] = np.log1p(datas[\"meter_reading\"])\n    test_mean = datas['meter_reading'].mean()   \n    \n    \n    \n    #datas = datas.append(test.head(72))\n    #datas = datas.reset_index()\n    \n    #if(len(datas) < 74 ):\n    #    return -1\n    \n    #meter_reading diff check \n    #np.log1p(temp_df_train['meter_reading'])\n    #display(datas)\n    #v_train = np.log1p(datas.loc[0][\"meter_reading\"])\n    #v_test = np.log1p(datas.loc[1][\"meter_reading\"])\n    \n    \n    return abs(train_mean - test_mean)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_validation_train_test(train,test):\n    #building id毎に訓練データと予測データの境界でmeter_readingが著しくずれているところを検出する\n\n    #訓練データ毎の繰り返し\n    building_ids = train['building_id'].unique()\n    building_ids.sort()\n\n    #boundary = 2.0 #しきい値の設定\n\n    list_df = pd.DataFrame(\n        columns=[\n            'building_id',\n            'meter',\n            'diff',\n            'count',\n            'train_mean',\n            'train_std',\n            'train_min',\n            'train_max'\n            \n            ])    \n    \n    error_building_ids = []\n    i = 0\n    for building_id in building_ids:\n        #print(building_id)\n        \n        #build idで抽出\n        query_str = ('building_id == %s' % str(building_id) )\n        temp_df_build_train = train.query(query_str)\n        temp_df_build_test = test.query(query_str)\n        \n        for meter in range(0,4):\n            #print(\"building_id\" + str(building_id) + \"meter:\" + str(meter))\n            query_str = ('meter == %s' % str(meter) )\n            temp_df_train = temp_df_build_train.query(query_str)\n            temp_df_test = temp_df_build_test.query(query_str)\n            diff = boundary_validation_train_test(temp_df_train,temp_df_test)\n            \n            if(diff == -1):\n                continue\n\n            temp_df_train[\"meter_reading\"] = np.log1p(temp_df_train[\"meter_reading\"])\n            tmp_se = pd.Series([building_id,\n                    meter,\n                    diff,\n                    temp_df_train.describe().at['count', 'meter_reading'],\n                    temp_df_train.describe().at['mean', 'meter_reading'],\n                    temp_df_train.describe().at['std', 'meter_reading'],\n                    temp_df_train.describe().at['min', 'meter_reading'],\n                    temp_df_train.describe().at['max', 'meter_reading']\n                                \n                    ],index=list_df.columns, name=str(i))\n            \n            list_df = list_df.append(tmp_se)\n            #display(list_df)\n            i += 1\n                \n            #if(diff > boundary):\n                #訓練データとテストデータで差が開いていると判定\n            #print(\"building_id:%d meter:%d diff:%f\" %(building_id,meter ,diff))\n            #error_building_ids.append(building_id)\n            \n            \n            \n    #boundary\n    #list(set(error_building_ids))\n    list_df.to_csv(\"check_validation_train_test.csv\",encoding = 'utf-8-sig')    \n    #このあとはbuild isの描画する処理","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building id毎に訓練データと予測データの境界でmeter_readingが著しくずれているところを検出する\ncheck_validation_train_test(train,test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}