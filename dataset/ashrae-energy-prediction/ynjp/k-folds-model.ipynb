{"cells":[{"metadata":{},"cell_type":"markdown","source":"Firstly, I refer the kernel(https://www.kaggle.com/aitude/ashrae-kfold-lightgbm-without-leak-1-08) to make this model,\nso thanks a lot Sandeep Kumar!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\nimport datetime\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#reduce the memory usage\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            # skip datetime type or categorical type\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using original data\nroot = Path('../input/ashrae-feather-format-for-fast-loading')\n\ntrain_df = pd.read_feather(root/'train.feather')\n# Remove outliers\ntrain_df = train_df [ train_df['building_id'] != 1099 ]\ntrain_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n\nbuilding_df = pd.read_feather(root/'building_metadata.feather')\nweather_df = pd.read_feather(root/'weather_train.feather')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = \"../input/ashrae-energy-prediction/\"\ntrain_df_csv = pd.read_csv(DATA_PATH + 'train.csv')\n\n# Remove outliers\ntrain_df_csv = train_df_csv[ train_df_csv['building_id'] != 1099 ]\ntrain_df_csv = train_df_csv.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n\nbuilding_df_csv = pd.read_csv(DATA_PATH + 'building_metadata.csv')\nweather_df_csv = pd.read_csv(DATA_PATH + 'weather_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['timestamp'] = train_df_csv['timestamp'].copy()\nweather_df['timestamp'] = weather_df_csv['timestamp'].copy()\ndel weather_df_csv, train_df_csv\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering\n- fill the null value and update some weather data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_weather(weather_df):\n    #find missing hours and add to weather dataframe\n    time_format = \"%Y-%m-%d %H:%M:%S\"\n    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n    \n    for site_id in range(16):\n        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n        missing_hour_data = pd.DataFrame(np.setdiff1d(hours_list, site_hours), columns=['timestamp'])\n        missing_hour_data['site_id'] = site_id\n        weather_df = pd.concat([weather_df, missing_hour_data])\n    weather_df.reset_index(drop=True)\n    \n    #Add date time features\n    weather_df['datetime'] = pd.to_datetime(weather_df['timestamp'])\n    weather_df['day'] = weather_df['datetime'].dt.day\n    weather_df['week'] = weather_df['datetime'].dt.week\n    weather_df['month'] = weather_df['datetime'].dt.month\n    \n    # update values group by site_id, day, month\n    weather_df = weather_df.set_index(['site_id', 'day', 'month'])\n    \n    for col in ['air_temperature', 'cloud_coverage', 'dew_temperature', 'sea_level_pressure', 'wind_direction', 'wind_speed',\\\n               'precip_depth_1_hr']:\n        mean_filter = weather_df.groupby(['site_id', 'day', 'month'])[col].mean()\n        mean_filter = pd.DataFrame(mean_filter.fillna(method='ffill'), columns=[col])\n        \n        weather_df.update(mean_filter, overwrite=False)\n        \n    weather_df = weather_df.reset_index()\n    weather_df = weather_df.drop(['datetime', 'day', 'week', 'month'], axis=1)\n    \n    return weather_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- add and remove some features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(df):\n    df.sort_values('timestamp')\n    df.reset_index(drop=True)\n    \n    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n    df[\"hour\"] = df[\"timestamp\"].dt.hour\n    df[\"weekday\"] = df[\"timestamp\"].dt.weekday\n    df['square_feet'] =  np.log1p(df['square_feet'])\n    \n    drop = [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n    df = df.drop(drop, axis=1)\n    gc.collect()\n    \n    # Encode Categorical Data\n    le = LabelEncoder()\n    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#weather data filling\nweather_df = fill_weather(weather_df)\n\n#memeory reduce\ntrain_df = reduce_mem_usage(train_df)\nbuilding_df = reduce_mem_usage(building_df)\nweather_df = reduce_mem_usage(weather_df)\n\n#mearge weather and building data into train data\ntrain_df = train_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\ntrain_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\ndel weather_df\ngc.collect()\n\ntrain_df = feature_engineering(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training k-folds model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_df.drop(['meter_reading'], axis=1)\ntrain_y = np.log1p(train_df['meter_reading'])\ndel train_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoricals = ['building_id', 'site_id', 'meter', 'primary_use', 'weekday']\nparams = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 1280,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"rmse\",\n}\nmodels = []\ny_pred = np.zeros((train_y.shape[0],))\nkf = KFold(n_splits=3)\nfor train_idx, valid_idx in kf.split(train_X):\n    train_features, train_target = train_X.loc[train_idx], train_y.loc[train_idx]\n    valid_features, valid_target = train_X.loc[valid_idx], train_y.loc[valid_idx]\n    \n    lgb_train = lgb.Dataset(train_features, label=train_target, categorical_feature=categoricals, free_raw_data=False)\n    lgb_valid = lgb.Dataset(valid_features, label=valid_target, categorical_feature=categoricals, free_raw_data=False)\n    \n    model = lgb.train(params, train_set=lgb_train, num_boost_round=1000, valid_sets=[lgb_train, lgb_valid],\\\n                     verbose_eval=25, early_stopping_rounds=50)\n    models.append(model)\n    y_pred[valid_idx] = model.predict(valid_features, num_iteration=model.best_iteration).reshape(y_pred[valid_idx].shape)\n    del train_features, train_target, valid_features, valid_target, lgb_train, lgb_valid\n    gc.collect()\nprint(\"final score(rmse) : \" + str(mean_squared_error(train_y, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_X, train_y, y_pred\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    lgb.plot_importance(model)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load and predict Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#load test and weather data\ntest_df = pd.read_feather(root/'test.feather')\ntest_df_csv = pd.read_csv(DATA_PATH + 'test.csv')\ntest_df['timestamp'] = test_df_csv['timestamp'].copy()\nrow_ids = test_df['row_id']\ntest_df = test_df.drop('row_id', axis=1)\nweather_df = pd.read_feather(root/'weather_test.feather')\nweather_df_csv = pd.read_csv(DATA_PATH + 'weather_test.csv')\nweather_df['timestamp'] = weather_df_csv['timestamp'].copy()\nweather_df = fill_weather(weather_df)\nweather_df = reduce_mem_usage(weather_df)\ntest_df = reduce_mem_usage(test_df)\n\n#merge\ntest_df = test_df.merge(building_df,left_on='building_id',right_on='building_id',how='left')\ntest_df = test_df.merge(weather_df,how='left',on=['timestamp','site_id'])\ndel weather_df, building_df, weather_df_csv, test_df_csv\ngc.collect()\n\ntest_df = feature_engineering(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfor model in models:\n    if  results == []:\n        results = np.expm1(model.predict(test_df, num_iteration=model.best_iteration)) / len(models)\n    else:\n        results += np.expm1(model.predict(test_df, num_iteration=model.best_iteration)) / len(models)\n    del model\n    gc.collect()\ndel test_df, models\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(results, 0, a_max=None)})\ndel row_ids,results\ngc.collect()\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}