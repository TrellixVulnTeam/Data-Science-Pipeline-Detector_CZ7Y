{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"credit to:\n@aitude for \nhttps://www.kaggle.com/aitude/ashrae-kfold-lightgbm-without-leak-1-08","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nimport datetime\nimport gc\nimport pickle\nfrom tqdm import tqdm_notebook as tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:45.321972Z","iopub.execute_input":"2021-08-09T07:52:45.322292Z","iopub.status.idle":"2021-08-09T07:52:45.328732Z","shell.execute_reply.started":"2021-08-09T07:52:45.322246Z","shell.execute_reply":"2021-08-09T07:52:45.327673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_train = pd.read_feather('../input/ashrae-great-energy-predictor-iii-featherdataset/train.feather')\n\nbuilding = pd.read_feather('../input/ashrae-great-energy-predictor-iii-featherdataset/building_metadata.feather')\nle = LabelEncoder()\nbuilding.primary_use = le.fit_transform(building.primary_use)\n\nDATA_PATH = \"../input/ashrae-energy-prediction/\"\nweather_train = pd.read_csv(DATA_PATH + 'weather_train.csv')\nweather_test = weather_df = pd.read_csv(DATA_PATH + 'weather_test.csv')\n# weather_train = pd.read_feather('../input/ashrae-great-energy-predictor-iii-featherdataset/weather_train.feather')\n# weather_test = pd.read_feather('../input/ashrae-great-energy-predictor-iii-featherdataset/weather_test.feather')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:45.330955Z","iopub.execute_input":"2021-08-09T07:52:45.331311Z","iopub.status.idle":"2021-08-09T07:52:46.313843Z","shell.execute_reply.started":"2021-08-09T07:52:45.331244Z","shell.execute_reply":"2021-08-09T07:52:46.312894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline model with raw data (without cleaning)","metadata":{}},{"cell_type":"code","source":"# # Remove outliers\n# df_train = df_train [ df_train['building_id'] != 1099 ]\n# df_train = df_train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:46.316112Z","iopub.execute_input":"2021-08-09T07:52:46.316523Z","iopub.status.idle":"2021-08-09T07:52:46.320689Z","shell.execute_reply.started":"2021-08-09T07:52:46.31642Z","shell.execute_reply":"2021-08-09T07:52:46.319774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # building_meter map\n\n# bm_cols = ['bm', 'weekday', 'hour',]\n# df_train['hour'] = df_train['timestamp'].dt.hour\n# df_train['weekday'] = df_train['timestamp'].dt.weekday\n# df_train['bm'] = df_train['building_id'].apply(lambda x: str(x)) + '_' + df_train['meter'].apply(lambda x: str(x))\n# bm = df_train.groupby(bm_cols)['meter_reading'].mean().rename('bm_week_hour').to_frame()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:46.322746Z","iopub.execute_input":"2021-08-09T07:52:46.32301Z","iopub.status.idle":"2021-08-09T07:52:46.332214Z","shell.execute_reply.started":"2021-08-09T07:52:46.322956Z","shell.execute_reply":"2021-08-09T07:52:46.331401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = df_train.merge(bm, right_index=True, left_on=bm_cols, how='left')\n# df_train.drop(['bm'], axis=1, inplace=True)\n# df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:46.333378Z","iopub.execute_input":"2021-08-09T07:52:46.333676Z","iopub.status.idle":"2021-08-09T07:52:46.346506Z","shell.execute_reply.started":"2021-08-09T07:52:46.333627Z","shell.execute_reply":"2021-08-09T07:52:46.345817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utility Functions","metadata":{}},{"cell_type":"code","source":"# Original code from https://www.kaggle.com/aitude/ashrae-missing-weather-data-handling by @aitude\n\ndef fill_weather_dataset(weather_df):\n    \n    # Find Missing Dates\n    time_format = \"%Y-%m-%d %H:%M:%S\"\n    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n    \n    missing_hours = []\n    for site_id in range(16):\n        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n        new_rows['site_id'] = site_id\n        weather_df = pd.concat([weather_df,new_rows])\n\n        weather_df = weather_df.reset_index(drop=True)           \n\n    # Add new Features\n    weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n    weather_df[\"day\"] = weather_df[\"timestamp\"].dt.day\n    weather_df[\"week\"] = weather_df[\"timestamp\"].dt.week\n    weather_df[\"month\"] = weather_df[\"timestamp\"].dt.month\n    \n    # Reset Index for Fast Update\n    weather_df = weather_df.set_index(['site_id','day','month'])\n\n    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n    weather_df.update(air_temperature_filler,overwrite=False)\n\n    # Step 1\n    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n    # Step 2\n    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n\n    weather_df.update(cloud_coverage_filler,overwrite=False)\n\n    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n    weather_df.update(due_temperature_filler,overwrite=False)\n\n    # Step 1\n    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n    # Step 2\n    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n\n    weather_df.update(sea_level_filler,overwrite=False)\n\n    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n    weather_df.update(wind_direction_filler,overwrite=False)\n\n    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n    weather_df.update(wind_speed_filler,overwrite=False)\n\n    # Step 1\n    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n    # Step 2\n    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n\n    weather_df.update(precip_depth_filler,overwrite=False)\n\n    weather_df = weather_df.reset_index()\n    weather_df = weather_df.drop(['day','week','month'],axis=1)\n        \n    return weather_df\n\n# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\"\n    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n    \"\"\"\n    \n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef features_engineering(df):\n    \n    # Sort by timestamp\n    df.sort_values(\"timestamp\")\n    df.reset_index(drop=True)\n    \n    # Add more features\n    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n    df[\"hour\"] = df[\"timestamp\"].dt.hour\n    df[\"weekday\"] = df[\"timestamp\"].dt.weekday\n    \n    df['square_feet'] =  np.log1p(df['square_feet'])\n    df['sm'] = df['site_id'].apply(lambda x: str(x)) + '_' + df['meter'].apply(lambda x: str(x))\n    \n    \n    # Remove Unused Columns\n    drop = [\"timestamp\",'site_id',\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n    df = df.drop(drop, axis=1)\n    gc.collect()\n    \n    # Encode Categorical Data\n    le = LabelEncoder()\n    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n    \n    # reduce memory\n    df = reduce_mem_usage(df, use_float16=True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:46.348774Z","iopub.execute_input":"2021-08-09T07:52:46.349081Z","iopub.status.idle":"2021-08-09T07:52:46.582394Z","shell.execute_reply.started":"2021-08-09T07:52:46.349036Z","shell.execute_reply":"2021-08-09T07:52:46.581221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(ypred - ytrue), axis=0))\ndef rmsle(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(np.log1p(ypred) - np.log1p(ytrue)), axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:46.58386Z","iopub.execute_input":"2021-08-09T07:52:46.584109Z","iopub.status.idle":"2021-08-09T07:52:46.598832Z","shell.execute_reply.started":"2021-08-09T07:52:46.584061Z","shell.execute_reply":"2021-08-09T07:52:46.597948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill Weather Information\n\nI'm using [this kernel](https://www.kaggle.com/aitude/ashrae-missing-weather-data-handling) to handle missing weather information.","metadata":{}},{"cell_type":"code","source":"weather_train = fill_weather_dataset(weather_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:52:46.60032Z","iopub.execute_input":"2021-08-09T07:52:46.60057Z","iopub.status.idle":"2021-08-09T07:53:05.434656Z","shell.execute_reply.started":"2021-08-09T07:52:46.600534Z","shell.execute_reply":"2021-08-09T07:53:05.433526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Memory Reduction","metadata":{}},{"cell_type":"code","source":"df_train = reduce_mem_usage(df_train,use_float16=True)\nbuilding = reduce_mem_usage(building,use_float16=True)\nweather_train = reduce_mem_usage(weather_train,use_float16=True)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-09T07:53:05.43638Z","iopub.execute_input":"2021-08-09T07:53:05.436749Z","iopub.status.idle":"2021-08-09T07:53:05.755798Z","shell.execute_reply.started":"2021-08-09T07:53:05.436694Z","shell.execute_reply":"2021-08-09T07:53:05.754943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge Data\n\nWe need to add building and weather information into training dataset.","metadata":{}},{"cell_type":"code","source":"df_train = df_train.merge(building, left_on='building_id',right_on='building_id',how='left')\ndf_train = df_train.merge(weather_train,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\ndel weather_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:53:05.757586Z","iopub.execute_input":"2021-08-09T07:53:05.75788Z","iopub.status.idle":"2021-08-09T07:53:15.394505Z","shell.execute_reply.started":"2021-08-09T07:53:05.757827Z","shell.execute_reply":"2021-08-09T07:53:15.393578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features Engineering","metadata":{}},{"cell_type":"code","source":"%%time\ndf_train = features_engineering(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:53:15.396116Z","iopub.execute_input":"2021-08-09T07:53:15.396523Z","iopub.status.idle":"2021-08-09T07:54:08.095329Z","shell.execute_reply.started":"2021-08-09T07:53:15.396429Z","shell.execute_reply":"2021-08-09T07:54:08.094121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:54:08.100541Z","iopub.execute_input":"2021-08-09T07:54:08.100826Z","iopub.status.idle":"2021-08-09T07:54:08.130993Z","shell.execute_reply.started":"2021-08-09T07:54:08.100778Z","shell.execute_reply":"2021-08-09T07:54:08.129922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features & Target Variables","metadata":{}},{"cell_type":"code","source":"y_train = np.log1p(df_train[\"meter_reading\"])\nX_train = df_train.drop('meter_reading', axis = 1)\ndel df_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:54:08.132974Z","iopub.execute_input":"2021-08-09T07:54:08.133354Z","iopub.status.idle":"2021-08-09T07:54:09.187631Z","shell.execute_reply.started":"2021-08-09T07:54:08.133285Z","shell.execute_reply":"2021-08-09T07:54:09.186806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  KFOLD LIGHTGBM Model","metadata":{}},{"cell_type":"code","source":"%%time\ncategorical_features = ['sm', \"building_id\", \"meter\", \"primary_use\", \"weekday\"]\nparams = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 1280,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"rmse\",\n    \"num_threads\": 2\n}\n\npred_L1 = []\nvalid_L1 = []\nseed = None\nkf = KFold(n_splits=3, random_state=seed)\n\nmodels = []\nfor train_index,test_index in kf.split(X_train):\n    train_features = X_train.loc[train_index]\n    train_target = y_train.loc[train_index]\n    \n    test_features = X_train.loc[test_index]\n    test_target = y_train.loc[test_index]\n    \n    d_training = lgb.Dataset(train_features, label=train_target,categorical_feature=categorical_features, free_raw_data=False)\n    d_test = lgb.Dataset(test_features, label=test_target,categorical_feature=categorical_features, free_raw_data=False)\n    \n    model = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_training,d_test], verbose_eval=25, early_stopping_rounds=50)\n    models.append(model)\n    pred_L1.append(model.predict(test_features))\n    valid_L1.append(test_target)\n    \n    del train_features, train_target, test_features, test_target, d_training, d_test\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T07:54:09.189079Z","iopub.execute_input":"2021-08-09T07:54:09.189335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_train, y_train\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Important Features","metadata":{}},{"cell_type":"code","source":"for model in models:\n    lgb.plot_importance(model)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Test Data","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_feather('../input/ashrae-great-energy-predictor-iii-featherdataset/test.feather')\nrow_ids = df_test[\"row_id\"]\ndf_test.drop(\"row_id\", axis=1, inplace=True)\ndf_test = reduce_mem_usage(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_test['hour'] = df_test['timestamp'].dt.hour\n# df_test['weekday'] = df_test['timestamp'].dt.weekday\n# df_test['bm'] = df_test['building_id'].apply(lambda x: str(x)) + '_' + df_test['meter'].apply(lambda x: str(x))\n# df_test = df_test.merge(bm, right_index=True, left_on=bm_cols, how='left')\n# df_test.drop('bm', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge Building Data","metadata":{}},{"cell_type":"code","source":"df_test = df_test.merge(building,left_on='building_id',right_on='building_id',how='left')\ndel building\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill Weather Information","metadata":{}},{"cell_type":"code","source":"weather_test = fill_weather_dataset(weather_test)\nweather_test = reduce_mem_usage(weather_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge Weather Data","metadata":{}},{"cell_type":"code","source":"df_test = df_test.merge(weather_test,how='left',on=['timestamp','site_id'])\ndel weather_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features Engineering","metadata":{}},{"cell_type":"code","source":"df_test = features_engineering(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"%%time\npred = []\nfor model in tqdm(models):\n    if  pred == []:\n        pred = np.expm1(model.predict(df_test, num_iteration=model.best_iteration)) / len(models)\n    else:\n        pred += np.expm1(model.predict(df_test, num_iteration=model.best_iteration)) / len(models)\n    del model\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"# save model to file\npickle.dump(models, open(\"models.pkl\", \"wb\"))\npickle.dump(pred_L1, open(\"pred_L1.pkl\", \"wb\"))\npickle.dump(valid_L1, open(\"valid_L1.pkl\", \"wb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_test, models\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(pred, 0, a_max=None)})\ndel row_ids, pred\ngc.collect()\nsubmission['meter_reading'] = submission['meter_reading'].astype('float32')\nsubmission['row_id'] = submission['row_id'].astype('int32')\nsubmission.to_csv(\"submission.csv\", index=False, chunksize=25000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"submission mean: {submission['meter_reading'].mean():.4f}\")\nprint(f\"submission std: {submission['meter_reading'].std():.4f}\")\nprint(f\"submission min: {submission['meter_reading'].min():.4f}\")\nprint(f\"submission max: {submission['meter_reading'].max():.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(np.log1p(submission['meter_reading'].values), kde=False);\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}