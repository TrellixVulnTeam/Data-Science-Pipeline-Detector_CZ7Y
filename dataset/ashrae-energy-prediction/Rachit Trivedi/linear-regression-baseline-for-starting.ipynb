{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing required libraries\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_log_error\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For training purpose, we have three datasets available in this compitition: train.csv, building_meta.csv and weather_train.csv. \"train.csv\" and \"building_meta.csv\" are related with each other through \"building_id\", \"building_meta.csv\" and \"weather_train.csv\" are related with each other through \"site_id\".\n\nAs I don't want to make the complex model in this baseline, let's focus on just \"train.csv\" and \"building_meta.csv\", so we don't need to consider all features related to weather."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#let's load datasets\n\ntrain_df = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/train.csv\")\nbilding_df = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/building_metadata.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining required dataset in single dataframe\n\ndf_train_building_left = pd.merge(train_df, bilding_df, on = \"building_id\", how = \"left\")\ndf_test_building_left = pd.merge(test_df, bilding_df, on = \"building_id\", how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step is to preprocess the dataframe, that includes, getting overall overview of datase, checking whether any column contain NaN (missing value), converting categorical text column to categorical int column."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_building_left.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking at first five columns, it seems that only \"floor_count\" column contains missing value, but it's good to check whether any other column contains missing value or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train_building_left:\n    print(column + \"\\t\" + str(df_train_building_left[column].isnull().any()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, now it's clear that only two columns: \"year_built\" and \"floor_count\" have missing values. In this baseline, I don't want to deal with missing values, so we will not consider these two columns in model building phase."},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting data into training and testing part\n\nX_train, X_test, y_train, y_test = train_test_split(df_train_building_left[[\"building_id\", \"meter\", \"site_id\", \"primary_use\", \"square_feet\"]], df_train_building_left[\"meter_reading\"], test_size = 0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying label encoding technique on \"primary_use\" column as it contains categorical text data\n\nlabel_encoder = preprocessing.LabelEncoder()\n\nX_train[\"primary_use\"] = label_encoder.fit_transform(X_train[\"primary_use\"])\nX_test[\"primary_use\"] = label_encoder.transform(X_test[\"primary_use\"])\n\n# Normalizing the dataset because \"square_feet\" is in different scale than other columns \n\nstandard_scaler = preprocessing.StandardScaler().fit(X_train)\n\nX_train = standard_scaler.transform(X_train)\nX_test = standard_scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a simple linear regression model on preprocessed data\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train.values)\ny_pred_lr = lin_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As human, we know that billing price can never be negative, but machine doesn't know this. There are high chances that linear regression predicts negative value due to Extrapolation problem. So, we need to replace all negative values with 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_lr[y_pred_lr < 0] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating accuracy\n\nprint(np.sqrt(mean_squared_log_error( y_test, y_pred_lr )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got 4.06 accuracy in here, so we might get the accuracy in the same range in actual test data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot importance of all features based on linear regression coefficients\n\n%matplotlib inline\nplt.bar([\"building_id\", \"meter\", \"site_id\", \"primary_use\", \"square_feet\"], lin_reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like building_id and site_id are important features than other three."},{"metadata":{},"cell_type":"markdown","source":"Now, we will apply the same process in actual training and testing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = preprocessing.LabelEncoder()\n\ndf_train_building_left[\"primary_use\"] = label_encoder.fit_transform(df_train_building_left[\"primary_use\"])\ndf_test_building_left[\"primary_use\"] = label_encoder.transform(df_test_building_left[\"primary_use\"])\n\nfinal_X_train = df_train_building_left[[\"building_id\", \"meter\", \"site_id\", \"primary_use\", \"square_feet\"]]\nfinal_X_test = df_test_building_left[[\"building_id\", \"meter\", \"site_id\", \"primary_use\", \"square_feet\"]]\n\nfinal_y_train = df_train_building_left[\"meter_reading\"]\n\nstandard_scaler = preprocessing.StandardScaler().fit(final_X_train)\nfinal_X_train = standard_scaler.transform(final_X_train)\nfinal_X_test = standard_scaler.transform(final_X_test)\n\nlin_reg = LinearRegression()\nlin_reg.fit(final_X_train, final_y_train.values)\ny_pred_lr = lin_reg.predict(final_X_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'row_id':df_test_building_left['row_id'], 'meter_reading':y_pred_lr})\n\nsubmission.to_csv(\"ashrae_prediction.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}