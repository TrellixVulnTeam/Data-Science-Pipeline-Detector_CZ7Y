{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"###### Library de base\nimport pandas as pd\nimport datetime\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\n###### Librabary Sklearn\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsRegressor\n\n###### Library LightGBM\n\n\n\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importation de la base"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Importation de toute la base\n##############\n\n\ntrain=pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/train.csv\",sep=\",\")\nweather_train=pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/weather_train.csv\",sep=\",\")\nbuilding_meta=pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/building_metadata.csv\",sep=',')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Definition de fonction\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"\n##############\n#### Fonction pour réduire la taille de la base\n##############\n\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# Source : https://www.kaggle.com/caesarlupum/ashrae-start-here-a-gentle-introduction\n\n\n##############\n#### Fonction pour calculer les données manquantes\n##############\n\ndef val_manq(df):\n    percent = (df.isnull().sum()).sort_values(ascending=False)\n    percent.plot(kind='bar', figsize = (20,10), fontsize=20)\n    plt.xlabel('Colonnes')\n    plt.ylabel('Nombre de lignes')\n    plt.title('Tot valeur manquante')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n##############\n#### Visualisation des valeurs manquantes\n##############\n\n\nval_manq(weather_train)\nplt.show()\nval_manq(train)\nplt.show()\nval_manq(building_meta)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remplissage des données manquantes\n\nprint(\"Date du début de l'étude : \"+ min(train[\"timestamp\"]))\nprint(\"Date de la fin de l'étude : \"+max(train[\"timestamp\"]))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### En comparant le nombre d'heure en 2016 et le nombre d'heure dans \n#### la base weather on comprend bien qu'il y a un pb.\n##############\n\n\nprint(\"Nombre d'heures dans l'année 2016 : \" + str(366*24)) \nprint(\"Nombre d'heures pour chaque site dans l'année 2016 : \" + str(366*24*16)) \nprint(\"Nombre d'heures dans la base weather : \" + str(len(weather_train[\"timestamp\"])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalement la base de données weather_train à autant de données que d'heures dans l'années 2016 multiplié par le nombre de lieu où des mesures ont été effectués, c'est à dire le nombre de site_id différents. Cependant en faisant les calculs nous nous sommes rendus compte qu'il manquait environ 1000 heures mesurés, 139773 lignes dans la base weather_train alors qu'il devrait en avoir 140544. Nous avons décidés de rajouter ses lignes manquantes.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Problème de date manquante\n##############\n\nformat_date = \"%Y-%m-%d %H:%M:%S\"\n\ndate_deb = min(weather_train[\"timestamp\"])\ndate_fin = max(weather_train[\"timestamp\"])\n\ndiff = 366*24 # Nombres d'heures pendant toute la durée de l'étude\n\ndébut = datetime.datetime.strptime(date_deb,format_date)\n# date time de la valeur de départ de l'étude\nfin = datetime.datetime.strptime(date_fin,format_date)\n# date time de la valeur de fin de l'étude\n\ndate_list = [(début + datetime.timedelta(hours=x)).strftime(format_date) for x in range(diff)]\n# Création d'une liste de date sous le format timestamp\n\nfor i in range(0,16):\n    heure_site = weather_train[weather_train[\"site_id\"]==i][\"timestamp\"]\n    heure_site = heure_site.values.tolist()\n    heure_manquante = list(set(date_list)-set(heure_site))\n    rangs_manquants = pd.DataFrame({'timestamp' : heure_manquante,'site_id' : i})\n    weather_train = pd.concat([rangs_manquants,weather_train],sort=False)\n# Créations des lignes manquantes de la base","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Création de nouvelles colonnes\n##############\n\nweather_train[\"datetime\"] = pd.to_datetime(weather_train[\"timestamp\"])\nweather_train[\"annee\"] = weather_train[\"datetime\"].dt.year\nweather_train[\"mois\"] = weather_train[\"datetime\"].dt.month\nweather_train[\"semaine\"] = weather_train[\"datetime\"].dt.week\nweather_train[\"jour\"] = weather_train[\"datetime\"].dt.day\nweather_train[\"heure\"] = weather_train[\"datetime\"].dt.hour\nweather_train.drop(columns=[\"datetime\"],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Remplisssage des données manquantes de la base weather par des moyennes\n##############\n\n\ncol_weather=[\"air_temperature\",\"cloud_coverage\",\"dew_temperature\",\"precip_depth_1_hr\",\"sea_level_pressure\",\"wind_direction\",\"wind_speed\"]\nmean_weather=weather_train.groupby([\"site_id\",\"mois\"]).transform(lambda x: x.fillna(x.mean()))\nfor col in col_weather:\n    weather_train[col] = mean_weather[col]\nweather_train=weather_train.fillna(method='ffill')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comme nous avons pu le voir nos bases possèdent de nombreuses données manquantes que se soit dans la base weather ou dans la base building_metadata.  \nPour la base weather nous remplancer les données manquantes par des approximations (i.e des moyennes) des valeurs du mois si celà est possible est sinon nous allons les remplacer par la valeur la plus proche non nulles dans la base.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Manipulation de la base"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Encoding d'une variables qualitative\n##############\n#A faire après les graphiques\n\nlabelencoder=LabelEncoder()\nbuilding_meta[\"primary_use\"] = labelencoder.fit_transform(building_meta[\"primary_use\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n##############\n#### Merge des 3 bases\n##############\n\n\n\ndf=pd.merge(train,building_meta, left_on='building_id', right_on='building_id')\ndf=pd.merge(df,weather_train, on=['timestamp','site_id'])\ndf = reduce_mem_usage(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Conversion d'unité d'un certain type de meter à un certain endroit\n##############\n\ndf.loc[(df[\"site_id\"] == 0) & (df[\"meter\"] == 0), \"meter_reading\"]=df.loc[(df[\"site_id\"] == 0) & (df[\"meter\"] == 0), \"meter_reading\"]*0.2931\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Vizualisation"},{"metadata":{"trusted":false},"cell_type":"code","source":"#matrice de correlation\ncorr= df.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nplt.figure(figsize = (10,10))\nax = sns.heatmap(corr.round(2), mask=mask,\n            vmin=-1,     \n            cmap='coolwarm',\n            annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"primary_use=building_meta[\"primary_use\"].value_counts().reset_index()\nprimary_use_perc=primary_use[\"primary_use\"]*100/sum(primary_use[\"primary_use\"])\nnom=['Education','Office','Entertainment/public assembly' ,'Public services','Lodging/residential' ,'Other' ,'Healthcare','Parking','Warehouse/storage','Manufacturing/industrial','Retail','Services','Technology/science','Food sales and service','Utility','Religious worship']\ny_position=range(0,len(primary_use))\n\n\nplt.figure(figsize=(10,10))\nA=plt.barh(y_position,primary_use_perc,\n       color='#66b3ff', align=\"center\")\nplt.yticks(y_position,nom)\n\nfor k in range(len(primary_use_perc)):\n    plt.text(primary_use_perc[k]+0.5,\n             y_position[k]-0.15, \n             str(round(primary_use_perc[k],2))+'%', \n             fontsize=15,\n             color='dimgrey')\n    \n\nplt.xlim([0, max(primary_use_perc)+10])\n# Enléve l'échelle de l'axe x\nplt.tick_params(\n    axis='x',          # changes apply to the x-axis\n    which='both',      # both major and minor ticks are affected\n    bottom=False,      # ticks along the bottom edge are off\n    top=False,         # ticks along the top edge are off\n    labelbottom=False) # labels along the bottom edge are off\nplt.xlabel(\"Pourcentage des batiments\")\nplt.ylabel('Type de chauffage')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Calcul des consommations moyennes de chaques meter type par semaine\n##############\n\nmediane_conso_semaine = df.groupby(['semaine']).median()\nmediane_conso_semaine_0 = df[df[\"meter\"]==0].groupby(['semaine']).median()\nmediane_conso_semaine_1 = df[df[\"meter\"]==1].groupby(['semaine']).median()\nmediane_conso_semaine_2 = df[df[\"meter\"]==2].groupby(['semaine']).median()\nmediane_conso_semaine_3 = df[df[\"meter\"]==3].groupby(['semaine']).median()\n\n##############\n#### Plot Standard\n##############\n\n\nplt.figure(figsize=(10,10))\nplt.plot(range(0,len(mediane_conso_semaine)),mediane_conso_semaine[\"meter_reading\"],label='mediane')\nplt.plot(range(0,len(mediane_conso_semaine)),mediane_conso_semaine_0[\"meter_reading\"],label='electricity')\nplt.plot(range(0,len(mediane_conso_semaine)),mediane_conso_semaine_1[\"meter_reading\"],label='chilledwater')\nplt.plot(range(0,len(mediane_conso_semaine)),mediane_conso_semaine_2[\"meter_reading\"],label='steam')\nplt.plot(range(0,len(mediane_conso_semaine)),mediane_conso_semaine_3[\"meter_reading\"],label='hotwater')\nplt.ylabel('Consomation en Kwh')\nplt.xlabel('Semaine')\nplt.legend()\n#plt.savefig('mediane_conso-semaine_primary_use.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Plot Log de la valeur\n##############\n\n\n\nplt.figure(figsize=(10,10))\nplt.plot(range(0,len(mediane_conso_semaine)),np.log(mediane_conso_semaine[\"meter_reading\"]),label='mediane')\nplt.plot(range(0,len(mediane_conso_semaine)),np.log(mediane_conso_semaine_0[\"meter_reading\"]),label='electricity')\nplt.plot(range(0,len(mediane_conso_semaine)),np.log(mediane_conso_semaine_1[\"meter_reading\"]),label='chilledwater')\nplt.plot(range(0,len(mediane_conso_semaine)),np.log(mediane_conso_semaine_2[\"meter_reading\"]),label='steam')\nplt.plot(range(0,len(mediane_conso_semaine)),np.log(mediane_conso_semaine_3[\"meter_reading\"]),label='hotwater')\nplt.ylabel('log de la Consomation en Kwh')\nplt.xlabel('Semaine')\nplt.legend()\nplt.savefig('semaine_conso.png')\n\ndel mediane_conso_semaine\ndel mediane_conso_semaine_0\ndel mediane_conso_semaine_1\ndel mediane_conso_semaine_2\ndel mediane_conso_semaine_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"############\n### meter_reading avant log\n############\nplt.figure(figsize=(10,10))\nplt.hist(train[\"meter_reading\"],bins=30,color='green')\nplt.ylabel('meter_reading count')\nplt.xlabel('value')\n#plt.savefig('meter_reading_no_log.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"############\n### meter_reading après log\n############\nplt.figure(figsize=(10,10))\nplt.hist(np.log1p(train[\"meter_reading\"]),bins=30,color='green')\nplt.ylabel('meter_reading count')\nplt.xlabel('value')\n#plt.savefig('meter_reading_log.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyse du site 13 :"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Représentation de \"indicator of the primary category of activities of the \n#### building\"\n##############\n\nfig, ax = plt.subplots(figsize=(10,8))\nsns.countplot(y='meter', data=df[df['site_id']==13])\n#plt.savefig('primary_use_build.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Représentation de \"indicator of the primary category of activities of the \n#### building\"\n##############\n\nfig, ax = plt.subplots(figsize=(10,8))\nsns.countplot(y='primary_use', data=df[df['site_id']==13])\n#plt.savefig('primary_use_build.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df[df['site_id'] == 13].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Consommation d'énergie en fonction des catégories d'utilisation des bâtiments et du type d'énergie "},{"metadata":{"trusted":false},"cell_type":"code","source":"\ntemp_df = df.groupby(\"primary_use\").meter_reading.sum().sort_values()\n\nplt.figure(figsize=(16,9))\ntemp_df.plot(kind=\"barh\")\nplt.xlabel(\"Sum of readings\")\nplt.ylabel(f\"Primary use\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\ntemp_df = df.groupby(\"meter\").meter_reading.sum().sort_values()\n\nplt.figure(figsize=(16,9))\ntemp_df.plot(kind=\"barh\")\nplt.xlabel(\"Sum of readings\")\nplt.ylabel(f\"Meter\")\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyse de la consommation d'énergie par site en total et par médiane"},{"metadata":{"trusted":false},"cell_type":"code","source":"\ntemp_df = df.groupby(\"site_id\").meter_reading.sum().sort_values()\n\nplt.figure(figsize=(16,9))\ntemp_df.plot(kind=\"barh\")\nplt.xlabel(\"Sum of readings\")\nplt.ylabel(f\"site_id\")\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"temp_df = df.groupby(\"site_id\").meter_reading.median().sort_values()\n\nplt.figure(figsize=(16,9))\ntemp_df.plot(kind=\"barh\")\nplt.xlabel(\"Sum of readings\")\nplt.ylabel(f\"site_id\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Représentation de la consomamtion des bâtiments par année de construction"},{"metadata":{"trusted":false},"cell_type":"code","source":"df['year_built_bin'] = pd.cut(x=df['year_built'], bins=[1955, 1960, 1965, 1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015, 2020])\ntemp_df = df.groupby(\"year_built_bin\").meter_reading.mean().sort_values()\n\n\nplt.figure(figsize=(16,9))\ntemp_df.plot(kind=\"barh\")\nplt.xlabel(\"Sum of readings\")\nplt.ylabel(f\"year_built\")\nplt.tight_layout()\nplt.savefig('building_built_moy_5grp.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"temp_df = df.groupby(\"year_built_bin\").meter_reading.median().sort_values()\n\n\nplt.figure(figsize=(16,9))\ntemp_df.plot(kind=\"barh\")\nplt.xlabel(\"Sum of readings\")\nplt.ylabel(f\"year_built\")\nplt.tight_layout()\nplt.savefig('building_built__med_5grp.png')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split des données en Apprentissage/Test"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Suppression des bases initiales\n##############\n\ndel train\ndel weather_train\ndel building_meta","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Création de la variable cible et des variables explicatioves\n#### Split en App/Test\n##############\n\ndf.drop(columns=[\"year_built\",\"floor_count\"],inplace=True)\n\n\nX=df.drop(columns=[\"meter_reading\",\"timestamp\",\"year_built_bin\"])\ny=np.log1p(df[\"meter_reading\"])\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n\ndel X\ndel y\ndel df\n\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modèle de Prédiction\n\n"},{"metadata":{},"cell_type":"markdown","source":"## KNN"},{"metadata":{},"cell_type":"markdown","source":"### Modèle de base"},{"metadata":{"trusted":false},"cell_type":"code","source":"knn = KNeighborsRegressor(n_jobs=-1, weights='distance') # K = 5 par défauts\nknn.fit(X_train,y_train)\ny_pred = knn.predict(X_test)\nprint('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recherche du meilleur modèle"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\nk_range = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\nerreur_knn = []\nfor i in range(0,len(k_range)):\n    knn = KNeighborsRegressor(n_neighbors=k_range[i],n_jobs=-1, weights='distance')\n    knn.fit(X_train_knn,y_train_knn)\n    y_pred = knn.predict(X_test_knn)\n    erreur = mean_squared_error(y_test_knn, y_pred)**0.5\n    erreur_knn.append(erreur)\n\ndel X_train_knn\ndel X_test_knn\ndel y_test_knn\ndel y_train_knn\ndel y_pred\n\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"erreur_knn","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(k_range,erreur_knn , marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4)\nplt.xlabel(\"Valeur de K\")\nplt.ylabel(\"Erreur du modèle\")\nplt.xticks(k_range,k_range);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Résultat de la recherche\nValeur = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70]  :  \n-Résultat = [1.660315121583663, 1.5799791843467181, 1.5444780998289551, 1.5241509842625436,1.5111512882369214, 1.5021696018398543,1.495729114354016, 1.4910569465040882, 1.4874995481154836, 1.4847853887052653, 1.4826815606432966, 1.481047281033797,1.4797644928403906, 1.4787621572620613]\n"},{"metadata":{},"cell_type":"markdown","source":"### Test du meilleur modèle"},{"metadata":{"trusted":false},"cell_type":"code","source":"knn_best = KNeighborsRegressor(n_jobs=-1, weights='distance', n_neighbors=55) \nknn_best.fit(X_train,y_train)\ny_pred = knn_best.predict(X_test)\nprint('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{},"cell_type":"markdown","source":"### Paramètre nécessaire"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Création de forets dans le but de réduire la demande mémoire\n##############\n\n\nfrom sklearn.ensemble import forest\ndef set_rf_samples(n):\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\nset_rf_samples(130000)\n\n\ndef reset_rf_samples():\n    \"\"\" Undoes the changes produced by set_rf_samples.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest de base"},{"metadata":{"trusted":false},"cell_type":"code","source":"model = RandomForestRegressor(random_state=0,\n                              n_jobs=-1); # n_estimators = 10\nmodel.fit(X_train,y_train);\n\ny_pred=model.predict(X_test);\nprint('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Importance des variables dans la foret d'arbre\n##############\n\nfeature_names = X_train.columns\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\nplt.figure(figsize=(10,10))\nplt.xlabel(\"Importance des Variables\")\nplt.barh(range(X_train.shape[1]), importances[indices],\n       color=\"r\", align=\"center\")\nplt.yticks(range(X_train.shape[1]), feature_names)\n#plt.xlim([-1, X_train.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recherche du meilleur modèle"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Choix des paramètres \n##############\n\n\nX_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n\n# Paramètre\n\nn_estimators =[10, 30, 50, 70, 100, 130, 160, 190, 220]\nerreur_rf = []\nfor i in range(0,len(n_estimators)):\n    rf = RandomForestRegressor(n_estimators=n_estimators[i],random_state=0,n_jobs=-1)\n    rf.fit(X_train_rf,y_train_rf)\n    y_pred = rf.predict(X_test_rf)\n    erreur = mean_squared_error(y_test_rf, y_pred)**0.5\n    erreur_rf.append(erreur)\n\ndel X_train_rf\ndel X_test_rf\ndel y_train_rf\ndel y_test_rf\n\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(erreur_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"erreur_n_estimators = erreur_rf\nplt.figure(figsize=(10,10))\nplt.plot(n_estimators,erreur_n_estimators, marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4);\nplt.xlabel(\"Nombre d'arbres\")\nplt.ylabel(\"Erreur\")\nplt.xticks(n_estimators,n_estimators);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Choix des paramètres \n##############\n\n\nX_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n\n# Paramètre\nmax_depth = [10,20, 30, 40, 50, 60, 70, 80, 90, 100, None]\nerreur_rf = []\nfor i in range(0,len(max_depth)):\n    rf = RandomForestRegressor(max_depth=max_depth[i],random_state=0,n_jobs=-1 )\n    rf.fit(X_train_rf,y_train_rf)\n    y_pred = rf.predict(X_test_rf)\n    erreur = mean_squared_error(y_test_rf, y_pred)**0.5\n    erreur_rf.append(erreur)\n\ndel X_train_rf\ndel X_test_rf\ndel y_train_rf\ndel y_test_rf\n\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(erreur_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"erreur_max_depth = erreur_rf\nplt.figure(figsize=(10,10))\nplt.plot(max_depth,erreur_max_depth, marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4);\nplt.xlabel(\"Profondeur maximale des arbres\")\nplt.ylabel(\"Erreur\")\nplt.xticks(max_depth[:-1],max_depth[:-1]); # Car le None ne peut pas être affiché","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Choix des paramètres \n##############\n\n\nX_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n\n# Paramètre\nmin_samples_split = [2, 5, 10, 20 ,30]\nerreur_rf = []\nfor i in range(0,len(min_samples_split)):\n    rf = RandomForestRegressor(min_samples_split=min_samples_split[i],random_state=0,n_jobs=-1 )\n    rf.fit(X_train_rf,y_train_rf)\n    y_pred = rf.predict(X_test_rf)\n    erreur = mean_squared_error(y_test_rf, y_pred)**0.5\n    erreur_rf.append(erreur)\n\ndel X_train_rf\ndel X_test_rf\ndel y_train_rf\ndel y_test_rf\n\ngc.collect();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(erreur_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"erreur_min_samples_split = erreur_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(min_samples_split,erreur_min_samples_split, marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4);\nplt.xlabel(\"Nombre minimum d'observations dans un noeud pour qu'une séparation soit effectuée\")\nplt.ylabel(\"Erreur\")\nplt.xticks(min_samples_split,min_samples_split); # Car le None ne peut pas être affiché","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Résultat de la recherche"},{"metadata":{},"cell_type":"markdown","source":"n_estimators = [10, 30, 50, 70, 100, 130, 160, 190, 220] :\n- erreur = [0.8361054027017335, 0.7968092040149114, 0.7896074110110385, 0.7867732388450902, 0.7832596986819509, 0.7817079650265579, 0.7804837745630923,0.7802371972002211, 0.7797987830671329]\n\nmax_depth = [10,20, 30, 40, 50, 60, 70, 80, 90, 100, None] :\n- erreur = [1.3591750963091456, 0.862434809822269, 0.8367067814091884, 0.836555349584275, 0.8361054027017335, 0.8361054027017335, 0.8361054027017335, 0.8361054027017335, 0.8361054027017335, 0.8361054027017335, 0.8361054027017335]\n\nmin_samples_split = [2, 5, 10, 20 ,30] :\n- erreur = [0.8361054027017335, 0.835373537152044, 0.8412791214927986, 0.8654151778058987, 0.8917872715630332]\n"},{"metadata":{},"cell_type":"markdown","source":"### Meilleur modèle\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_model_rf = RandomForestRegressor(max_depth=30,n_estimators = 130, min_samples_split= 5,random_state=0,n_jobs=-1 )\nbest_model_rf.fit(X_train,y_train)\ny_pred = best_model_rf.predict(X_test)\nerreur = mean_squared_error(y_test, y_pred)**0.5\nprint('The rmsle of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Reset des forêts\n##############\n\nreset_rf_samples()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting avec LightGBM"},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Création des DataSets de LightGBM & des paramètres de ses datasets\n##############\n\ncategorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\"]\n\nX_train_lgbm, X_test_lgbm, y_train_lgbm, y_test_lgbm = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n\n\nlgb_train = lgb.Dataset(X_train_lgbm, \n                        label=y_train_lgbm,\n                        categorical_feature=categorical_features,\n                        free_raw_data=False)\n\nlgb_eval = lgb.Dataset(X_test_lgbm, \n                       label=y_test_lgbm,\n                       categorical_feature=categorical_features,\n                       free_raw_data=False)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Paramètre du gradient boosting\n##############\nevals_result = {} \nparams_lgb = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"learning_rate\": 0.1,\n    \"feature_fraction\": 0.85,\n    \"metric\": \"rmse\",\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##############\n#### Entrainement du modele\n##############\n\nmodel_lgb = lgb.train(params_lgb, \n                train_set=lgb_train, \n                num_boost_round=1000, \n                valid_sets=[lgb_train,lgb_eval], \n                verbose_eval=50,\n                evals_result=evals_result,\n                early_stopping_rounds=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred=model_lgb.predict(X_test);\nprint('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgb.plot_importance(model_lgb, figsize=(10,10),grid=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}