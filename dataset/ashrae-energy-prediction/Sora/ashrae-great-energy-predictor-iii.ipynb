{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\nfrom scipy.stats import skew\nfrom scipy.stats import norm\nfrom scipy import stats\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.patches as patches\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport pathlib\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type != 'object' and col_type != 'datetime64[ns]':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)  # feather-format cannot accept float16\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = pathlib.Path('../input/ashrae-energy-prediction')\n\ndf_building = pd.read_csv(data_dir.joinpath('building_metadata.csv'))\ndf_weather_train = pd.read_csv(data_dir.joinpath('weather_train.csv'))\ndf_weather_test = pd.read_csv(data_dir.joinpath('weather_test.csv'))\ndf_train = pd.read_csv(data_dir.joinpath('train.csv'))\ndf_test = pd.read_csv(data_dir.joinpath('test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_building = reduce_mem_usage(df_building)\ndf_weather_train = reduce_mem_usage(df_weather_train)\ndf_weather_test = reduce_mem_usage(df_weather_test)\ndf_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather_train[\"datetime\"] = pd.to_datetime(df_weather_train[\"timestamp\"])\ndf_weather_train[\"day\"] = df_weather_train[\"datetime\"].dt.day\ndf_weather_train[\"week\"] = df_weather_train[\"datetime\"].dt.week\ndf_weather_train[\"month\"] = df_weather_train[\"datetime\"].dt.month\ndf_weather_train[\"year\"] = df_weather_train[\"datetime\"].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather_test[\"datetime\"] = pd.to_datetime(df_weather_test[\"timestamp\"])\ndf_weather_test[\"day\"] = df_weather_test[\"datetime\"].dt.day\ndf_weather_test[\"week\"] = df_weather_test[\"datetime\"].dt.week\ndf_weather_test[\"month\"] = df_weather_test[\"datetime\"].dt.month\ndf_weather_test[\"year\"] = df_weather_test[\"datetime\"].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Shape:', df_train.shape)\nprint('Test Shape:', df_test.shape)\nprint('Weather Train Shape:', df_weather_train.shape)\nprint('Weather Test Shape:', df_weather_test.shape)\nprint('Building Metadata Shape:', df_building.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df_train.head())\ndf_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df_test.head())\ndf_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df_weather_train.head())\ndf_weather_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df_weather_test.head())\ndf_weather_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df_building.head())\ndf_building.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.merge(df_building, on='building_id', how='left')\ndf_train = df_train.merge(df_weather_train, on=['site_id', 'timestamp'], how='left')\n\ndf_test = df_test.merge(df_building, on='building_id', how='left')\ndf_test = df_test.merge(df_weather_test, on=['site_id', 'timestamp'], how='left')\n\ndel df_building, df_weather_train, df_weather_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Shape:', df_train.shape)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(['timestamp','day','week','month','year'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dtypes\ndf_train.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing Value imputation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()[df_train.isnull().sum() !=0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n#Les colonnes énumérées ci-dessous ont des valeurs manquantes dans l'ensemble de données combiné (train + test)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Permet de visualiser le pourcentage d'entités manquantes dans le train\nmissing= df_train.isnull().sum()[df_train.isnull().sum() !=0]\nmissing=pd.DataFrame(missing.reset_index())\nmissing.rename(columns={'index':'features',0:'missing_count'},inplace=True)\nmissing['missing_count_percentage']=((missing['missing_count'])/20216100)*100\nplt.figure(figsize=(20,8))\nsns.barplot(y=missing['features'],x=missing['missing_count_percentage'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"les variables Year_built et floor_count represente plus de 60% de valeurs manquantes, pour cela nous alons les supprimer de notre jeu de donnée vu qu'ils n'apporte pas assez d'information."},{"metadata":{},"cell_type":"markdown","source":"\n1- supprimer les lignes avec des valeurs manquantes et voir les performances du modèle\n2- impute les valeurs manquantes avec moyenne et médiane ou peut être mode."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Permet de voir la propagation des données avant d'imputer les valeurs manquantes\nplt.plot(figsize=(15,10))\nsns.boxplot(df_train['wind_speed'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wind_speed semble avoir beaucoup de points aberrants - La médiane devrait avoir raison d'imputer les valeurs manquantes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['wind_speed'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['wind_speed'].fillna(df_train['wind_speed'].median(),inplace=True) \n# imputer avec Meadian, car il y a beaucoup de valeurs aberrantes\ndf_test['wind_speed'].fillna(df_test['wind_speed'].median(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le test nous montre qu'il y a plus de N/A\ndf_train['wind_speed'].isna().sum()\ndf_train['wind_speed'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_train['wind_direction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputation par la moyenne serait un moyen pour l'imputation \ndf_train['wind_direction'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['wind_direction'].fillna(df_train['wind_direction'].mean(),inplace=True) \n# imputer avec Meadian, car il y a beaucoup de valeurs aberrantes\ndf_test['wind_direction'].fillna(df_test['wind_direction'].mean(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le test nous montre qu'il y a plus de N/A\ndf_train['wind_direction'].isna().sum()\ndf_train['wind_direction'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_train['sea_level_pressure'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputation par la mediane serait un bon  moyen \ndf_train['sea_level_pressure'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['sea_level_pressure'].fillna(df_train['sea_level_pressure'].median(),inplace=True) \n# imputer avec Meadian, car il y a beaucoup de valeurs aberrantes\ndf_test['sea_level_pressure'].fillna(df_test['sea_level_pressure'].median(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le test nous montre qu'il y a plus de N/A\ndf_train['sea_level_pressure'].isna().sum()\ndf_train['sea_level_pressure'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_train['precip_depth_1_hr'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['precip_depth_1_hr'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['precip_depth_1_hr'].fillna(df_train['precip_depth_1_hr'].median(),inplace=True) \n# imputer avec Meadian, car il y a beaucoup de valeurs aberrantes\ndf_test['precip_depth_1_hr'].fillna(df_test['precip_depth_1_hr'].median(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le test nous montre qu'il y a plus de N/A\ndf_train['precip_depth_1_hr'].isna().sum()\ndf_train['precip_depth_1_hr'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_train['dew_temperature'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['dew_temperature'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['dew_temperature'].fillna(df_train['dew_temperature'].median(),inplace=True) \n# imputer avec Meadian, car il y a beaucoup de valeurs aberrantes\ndf_test['dew_temperature'].fillna(df_test['dew_temperature'].median(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le test nous montre qu'il y a plus de N/A\ndf_train['dew_temperature'].isna().sum()\ndf_train['dew_temperature'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_train['cloud_coverage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputation par la moyenne serait un moyen pour l'imputation \ndf_train['cloud_coverage'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['cloud_coverage'].fillna(df_train['cloud_coverage'].mean(),inplace=True) \n# imputer avec Moyenne, car il y a beaucoup de valeurs aberrantes\ndf_test['cloud_coverage'].fillna(df_test['cloud_coverage'].mean(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le test nous montre qu'il y a plus de N/A\ndf_train['cloud_coverage'].isna().sum()\ndf_train['cloud_coverage'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_train['air_temperature'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['air_temperature'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['air_temperature'].fillna(df_train['air_temperature'].median(),inplace=True) \n# imputer avec Meadian, car il y a beaucoup de valeurs aberrantes\ndf_test['air_temperature'].fillna(df_test['air_temperature'].median(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le test nous montre qu'il y a plus de N/A\ndf_train['air_temperature'].isna().sum()\ndf_train['air_temperature'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(['year_built','floor_count'],axis=1,inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.drop(['year_built','floor_count'],axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape,df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Statistique Descriptive**"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_train.describe().plot(kind=\"area\", fontsize=22, figsize=(18,8), table=True, colormap=\"rainbow\")\nplt.xlabel('',)\nplt.ylabel('value')\nplt.title(\"statistiques générales des variables\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df_train.plot(x='dew_temperature', y='meter_reading', kind='scatter')\nax.set_title(\"le relevé de compteur par rapport à la temperature du rosé\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Voir la distribution / histogramme des variables numériques ( )\ndf_train.loc[:, df_train.columns != 'building_id'].hist(figsize=(30, 20), bins=50);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['primary_use'].value_counts(normalize=True).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Correlation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize = (15,10))\nplt.title('Pearson Correlation of features')\nsns.heatmap(df_train.corr(), linewidths = 0.25, vmax = 1.0, square = True, cmap = 'cubehelix', linecolor = 'k', annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font = 'monospace')\ncmap = sns.diverging_palette(h_neg = 210, h_pos = 350, s = 90, l = 30, as_cmap = True)\nsns.clustermap(df_train.corr(), linewidths = 0.5, figsize = (13,13), cmap = cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf_train['meter']= le.fit_transform(df_train['meter']).astype(\"uint8\")\ndf_test['meter']= le.fit_transform(df_test['meter']).astype(\"uint8\")\ndf_train['primary_use']= le.fit_transform(df_train['primary_use']).astype(\"uint8\")\ndf_test['primary_use']= le.fit_transform(df_test['primary_use']).astype(\"uint8\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_train['meter_reading']\ndf_train = df_train.drop(['meter_reading'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(df_train,y,test_size=0.25,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (X_train.shape)\nprint (y_train.shape)\nprint (X_test.shape)\nprint (y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.linear_model import SGDRegressor, LinearRegression , Ridge , Lasso\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#On définit la métrique utilisée pour évaluer l'algorithme.\ndef rmsle(preds,targets, sample_weight = None, multioutput = 'uniform_average'):\n    # on applique la fonction exp afin de revenir au price de départ et avoir une idée réalise de l'erreur \n    return np.sqrt(np.sum((np.log(pred+1)-np.log(targets+1))**2)/len(targets))\n\ndef r2(preds, targets) : \n    # on applique la fonction exp afin de revenir au price de départ et avoir une idée réalise de l'erreur \n    preds = np.exp( preds )\n    targets =  np.exp(targets)\n    return 1- (np.sum((targets-preds)**2)/  np.sum( ( targets -  np.mean(targets))**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evuluate(model):\n    preds_train = model.predict(X_train)\n    preds_test = model.predict(X_test)\n    # on affiche  preds = f(y)\n    plt.figure()\n    plt.scatter(y_test, preds_test)  \n    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n    plt.xlabel('meter_reading')\n    plt.ylabel('prediction')\n    plt.title('pred = f(meter_reading)')\n    # les résidus\n    plt.figure()\n    plt.scatter(y_test, abs(preds_test - y_test))  \n    plt.xlabel('preds_meter_reading')\n    plt.ylabel('risidual')\n    plt.title('risidual = f(fitted_meter_reading)')   \n    plt.show()\n    rmsle_train = rmsle(preds_train, y_train)\n    rmsle_test = rmsle(preds_test, y_test)\n    r2_train = r2(preds_train, y_train)\n    r2_test = r2(preds_test, y_test)   \n    return rmsle_train, rmsle_test, r2_train, r2_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names =  ['model name', 'rmsle_train', 'rmsle_test','r2_train', 'r2_test']\nresults = pd.DataFrame(columns = col_names)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_model = LinearRegression()\nlinear_model.fit(X_train,y_train)\nrmsle_train, rmsle_test, r2_train, r2_test = evuluate(linear_model)\nnew_row = {'model name':\" linear regression\", 'rmsle_train':rmsle_train, 'rmsle_test':rmsle_test, 'r2_train':r2_train, 'r2_test':r2_test}\nresults = results.append(new_row, ignore_index=True)\nprint(\"{} train train rmsle : {:.3f} test rmsle : {:.3f} train r2 : {:.3f} test r2  : {:.3f}\".format(new_row['model name'],new_row['rmsle_train'], new_row['rmsle_test'] ,new_row['r2_train'], new_row['r2_test']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}