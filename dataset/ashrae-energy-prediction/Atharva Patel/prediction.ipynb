{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport gc\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_log_error\nimport hyperopt\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\nfrom hyperopt import space_eval\nimport time\nimport math\nfrom hyperopt.pyll.base import scope\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import plot_importance\nfrom tqdm import tqdm_notebook as tqdm\nimport catboost\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.preprocessing import LabelEncoder\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\nimport pprint\npp = pprint.PrettyPrinter(indent=4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"project_dir = '/kaggle/input/ashrae-energy-prediction'\ndata_dir = project_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(data_dir + \"/train.csv\")\nbuild = pd.read_csv(data_dir + \"/building_metadata.csv\")\nweather_train = pd.read_csv(data_dir + \"/weather_train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_df(train, build, weather, should_compress=False, should_create_dummies=True):    \n    train_build = train.merge(right=build,left_on=\"building_id\", right_on=\"building_id\", how=\"left\")\n    train_build = train_build.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n    train_build[\"month\"] = pd.to_datetime(train_build[\"timestamp\"]).dt.month.astype(np.int8)\n    train_build[\"year\"] = pd.to_datetime(train_build[\"timestamp\"]).dt.year\n    train_build[\"day_of_week\"] = pd.to_datetime(train_build[\"timestamp\"]).dt.dayofweek\n    dates_range = pd.date_range(start='2015-12-31', end='2019-01-01')\n    us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n    train_build['is_holiday'] = (pd.to_datetime(train_build['timestamp']).dt.date.astype('datetime64').isin(us_holidays))\n    train_build.loc[(train_build['day_of_week'] == 5) | (train_build['day_of_week'] == 6) , 'is_holiday'] = True\n    train_build[\"weekofmonth\"] = np.ceil(pd.to_datetime(train_build[\"timestamp\"]).dt.day/7).astype(np.int8)\n    month_season_bins = pd.IntervalIndex.from_tuples([(1, 2), (3, 5), (6, 8), (9, 11), (12, 12)])\n    encoder = LabelEncoder()\n    train_build[\"season\"] =  encoder.fit_transform(pd.cut(train_build[\"month\"], month_season_bins).astype(str)).astype(np.uint8)\n    train_build[\"hour\"] = pd.to_datetime(train_build[\"timestamp\"]).dt.hour.astype(np.int8)\n#     half = np.floor(pd.to_datetime(train_build[\"timestamp\"]).dt.minute/30).astype(np.int8)\n#     train_build[\"hour_half\"] = (train_build[\"hour\"] * 2 + half).astype(np.int8)\n    train_build[\"is_working_hour\"] = (train_build[\"hour\"] >= 8) & (train_build[\"hour\"] <= 18)\n    train_build['square_feet'] = np.log(train_build['square_feet'])\n    train_build[\"square_feet_per_floor\"] = train_build[\"square_feet\"]/train_build[\"floor_count\"]\n    train_build[\"square_feet_multiplied_by_floor\"] = train_build[\"square_feet\"] * train_build[\"floor_count\"]\n    train_build[\"age\"] = train_build[\"year\"] - train_build[\"year_built\"]\n    train_build.loc[(train_build['primary_use'] == \"Education\") & (train_build['month'] >= 6) & (train_build['month'] <= 8), 'is_vacation_month'] = np.int8(1)\n    train_build.loc[train_build['is_vacation_month']!=1, 'is_vacation_month'] = np.int8(0)\n    encoder = LabelEncoder()\n    train_build[\"primary_use\"] = encoder.fit_transform(train_build[\"primary_use\"]).astype(np.uint8)\n    \n    train_build_weather = train_build.merge(right=weather, left_on=[\"timestamp\", \"site_id\"], right_on=[\"timestamp\", \"site_id\"], how=\"left\")\n    train_build_weather[\"air_temperature_2\"] = train_build_weather[\"air_temperature\"] ** 2\n    train_build_weather[\"dew_temperature_2\"] = train_build_weather[\"dew_temperature\"] ** 2  \n    train_build_weather[\"wind_direction_cat\"] = train_build_weather[\"wind_direction\"]\n    replacement = {}\n    for i in range(0, 351, 30):\n        key = tuple(list(range(i, i+30)))\n        replacement[key] = i\n    for (key,value) in replacement.items():\n        train_build_weather[\"wind_direction_cat\"].replace(key, value, inplace=True)\n        gc.collect()\n    \n    beaufort = [(0, 0, 0.3), (1, 0.3, 1.6), (2, 1.6, 3.4), (3, 3.4, 5.5), (4, 5.5, 8), (5, 8, 10.8), (6, 10.8, 13.9), \n          (7, 13.9, 17.2), (8, 17.2, 20.8), (9, 20.8, 24.5), (10, 24.5, 28.5), (11, 28.5, 33), (12, 33, 200)]\n    \n    for item in beaufort:\n        train_build_weather.loc[(train_build_weather['wind_speed']>=item[1]) & (train_build_weather['wind_speed']<item[2]), 'beaufort_scale'] = item[0]\n        gc.collect()\n#     train_build_weather[\"is_weekend\"] = pd.to_datetime(train_build_weather[\"timestamp\"]).dt.dayofweek >= 5\n    \n    train_build_weather.drop(columns=[\"timestamp\"], inplace=True)    \n    if \"meter_reading\" in train_build_weather.columns:\n      train_build_weather[\"meter_reading\"] = np.log1p(train_build_weather['meter_reading']).astype(np.float32)\n    return train_build_weather\n\ncat_cols = [\n            \"hour\",\n            \"is_working_hour\",\n            \"is_holiday\",\n            \"day_of_week\",\n            \"season\",\n            \"is_vacation_month\",\n            \"site_id\", \n            \"building_id\", \n            \"meter\",\n            \"primary_use\",\n           \"wind_direction_cat\"\n           ]\ncols_drop_x = [\n               \"weekofmonth\", \n               \"year\",\n               \"year_built\", \n               \"meter_reading\",\n#                \"wind_direction\",\n               \"sea_level_pressure\",\n               \"wind_speed\",\n                \"wind_direction\",\n#     'precip_depth_1_hr'\n              ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_lgb(X_train, y_train, X_val, y_val, params):\n    train_data = lgb.Dataset(X_train.values, \n                             label=y_train.values.ravel(),\n                             feature_name=list(X_train.columns),\n                             categorical_feature=cat_cols\n                            )\n    validation_data = lgb.Dataset(X_val.values, \n                             label=y_val.values.ravel(),\n                             feature_name=list(X_val.columns),\n                             categorical_feature=cat_cols\n                            )\n    evals_result = {}\n    bst = lgb.train(params, train_data, \n                    valid_sets=[train_data, validation_data], \n                    valid_names=['train', 'val'], \n                    evals_result=evals_result, \n                    num_boost_round=10000,\n                    early_stopping_rounds=100,\n                    categorical_feature=cat_cols,\n                   verbose_eval=100)\n    return bst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\ndf = prepare_df(train, build, weather_train, should_compress=False, should_create_dummies=False).dropna(subset=[\"meter_reading\"])\ngc.collect()\n# X_train = df.drop(columns=cols_drop_x)\n# y_train = df[[\"meter_reading\"]]\n\ndf_train_1 = df[df[\"month\"] <= 6]\nX_train_1 = df_train_1.drop(columns=cols_drop_x)\ny_train_1 = df_train_1[[\"meter_reading\"]]\ndf_train_1_sample = df_train_1.sample(n=100000, random_state=7)\ndel(df_train_1)\ngarbage = gc.collect()\nX_train_1_sample = df_train_1_sample.drop(columns=cols_drop_x)\ny_train_1_sample = df_train_1_sample[[\"meter_reading\"]]\ndel(df_train_1_sample)\ngarbage = gc.collect()\ndf_train_2 = df[df[\"month\"] > 6]\nX_train_2 = df_train_2.drop(columns=cols_drop_x)\ny_train_2 = df_train_2[[\"meter_reading\"]]\ndf_train_2_sample = df_train_2.sample(n=100000, random_state=7)\ndel(df_train_2)\ngarbage = gc.collect()\nX_train_2_sample = df_train_2_sample.drop(columns=cols_drop_x)\ny_train_2_sample = df_train_2_sample[[\"meter_reading\"]]\ndel(df_train_2_sample)\ngarbage = gc.collect()\n\n# X_train_1 = df[df[\"weekofmonth\"] == 1].drop(columns=cols_drop_x)\n# y_train_1 = df[df[\"weekofmonth\"] == 1][[\"meter_reading\"]]\n# # X_train_2 = df[df[\"weekofmonth\"] == 2].drop(columns=cols_drop_x)\n# # y_train_2 = df[df[\"weekofmonth\"] == 2][[\"meter_reading\"]]\n# # X_train_3 = df[df[\"weekofmonth\"] == 3].drop(columns=cols_drop_x)\n# # y_train_3 = df[df[\"weekofmonth\"] == 3][[\"meter_reading\"]]\n# X_train_4 = df[df[\"weekofmonth\"] == 4].drop(columns=cols_drop_x)\n# y_train_4 = df[df[\"weekofmonth\"] == 4][[\"meter_reading\"]]\n\ndel (df)\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nbest_params_for_max_depths = [\n        #-1\n   {   \n    'bagging_fraction': 0.9,\n    'bagging_freq': 1,\n    'eval_metric': 'RMSE',\n    'feature_fraction': 0.85,\n#     'lambda_l1': 1,\n    'lambda_l2': 2,\n    'learning_rate': 0.05,\n    'loss_function': 'RMSE',\n    'max_bin': 250,\n    'max_depth': 20,\n    'metric': 'rmse',\n#     'min_sum_hessian_in_leaf': 30,\n    'num_leaves': 800,\n    'objective': 'regression',\n    'random_state': 42,\n    'verbose': None},\n#     {\n#         \"objective\": \"regression\",\n#     \"boosting\": \"gbdt\",#dart,gbdt\n#     \"num_leaves\": 45,\n#     \"learning_rate\": 0.02,\n#     \"feature_fraction\": 0.9,\n#     \"reg_lambda\": 2,\n#     \"metric\": \"rmse\"\n#     }\n]\n\nfor best_params in best_params_for_max_depths: \n    print(\"Training model with params: \")\n    \n    pp.pprint(best_params)\n    garbage = gc.collect()\n    \n#     bst = train_lgb(X_train, y_train, best_params)\n#     garbage = gc.collect()    \n#     models.append(bst)\n    \n    bst1 = train_lgb(X_train=X_train_1, y_train=y_train_1, X_val=X_train_2_sample, y_val=y_train_2_sample, params=best_params)\n    garbage = gc.collect()    \n    models.append(bst1)\n    \n    bst2 = train_lgb(X_train=X_train_2, y_train=y_train_2, X_val=X_train_1_sample, y_val=y_train_1_sample, params=best_params)\n    garbage = gc.collect()    \n    models.append(bst2)\n    \n#     bst3 = train_lgb(X_train_3, y_train_3, best_params)\n#     garbage = gc.collect()    \n#     models.append(bst3)\n    \n#     bst4 = train_lgb(X_train_4, y_train_4, best_params)\n#     garbage = gc.collect()    \n#     models.append(bst4)\n    \n    print(\"Done training for above params.\")\n    \ndel(X_train_1)\ndel(y_train_1)\ndel(X_train_2)\ndel(y_train_2)\ndel(X_train_1_sample)\ndel(y_train_1_sample)\ndel(X_train_2_sample)\ndel(y_train_2_sample)\n# del(X_train_3)\n# del(y_train_3)\n# del(X_train_4)\n# del(y_train_4)\n\n# del(X_train)\n# del(y_train)\n\ngarbage = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(data_dir + \"/test.csv\")\nweather_test = pd.read_csv(data_dir + \"/weather_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in tqdm( range(math.ceil(test.shape[0]/50000))):\n    gc.collect()\n    X = prepare_df(train=test.iloc[i*50000:min((i+1)*50000, test.shape[0])].drop(columns=[\"row_id\"]), build=build, weather=weather_test, should_compress=False, should_create_dummies=False)\n    X = X.drop(columns=[col for col in cols_drop_x if col != \"meter_reading\"])\n    preds = np.zeros(shape=(X.shape[0],))\n    for bst in models:\n        preds_temp = bst.predict(X)\n        preds_temp[preds_temp < 0] = 0\n        preds_temp = np.expm1(preds_temp)\n        preds += preds_temp\n    preds /= len(models)\n    y_preds += list(preds)\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(weather_test)\ndel(build)\ngarbage=gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame(data={\"row_id\": test[\"row_id\"], \"meter_reading\": y_preds})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}