{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Getting Started","metadata":{}},{"cell_type":"code","source":"!pip install pycaret","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\npd.set_option('max_rows', 90)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.neighbors import KNeighborsRegressor\nimport scipy.stats\nfrom sklearn.preprocessing import StandardScaler\nfrom pycaret.regression import setup, compare_models\nfrom sklearn.model_selection import KFold, cross_val_score\n\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import BayesianRidge, HuberRegressor, Ridge, OrthogonalMatchingPursuit\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\n\nimport optuna","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train0 = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest0 = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nsample_submission = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine Train and Test Sets","metadata":{}},{"cell_type":"code","source":"target = train0['SalePrice']\ntest_ids = test0['Id']\n\ntrain1 = train0.drop(['Id', 'SalePrice'], axis=1)\ntest1 = test0.drop('Id', axis=1)\n\ndata1 = pd.concat([train1, test1], axis=0).reset_index(drop=True)\ndata1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning","metadata":{}},{"cell_type":"code","source":"data2 = data1.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensure Proper Data Types","metadata":{}},{"cell_type":"code","source":"data2['MSSubClass'] = data2['MSSubClass'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill Categorical Missing Values","metadata":{}},{"cell_type":"code","source":"# Impute using a constant value\nfor column in [\n    'Alley',\n    'BsmtQual',\n    'BsmtCond',\n    'BsmtExposure',\n    'BsmtFinType1',\n    'BsmtFinType2',\n    'FireplaceQu',\n    'GarageType',\n    'GarageFinish',\n    'GarageQual',\n    'GarageCond',\n    'PoolQC',\n    'Fence',\n    'MiscFeature'\n]:\n    data2[column] = data2[column].fillna(\"None\")\n\n# Impute using the column mode\nfor column in [\n    'MSZoning',\n    'Utilities',\n    'Exterior1st',\n    'Exterior2nd',\n    'MasVnrType',\n    'Electrical',\n    'KitchenQual',\n    'Functional',\n    'SaleType'\n]:\n    data2[column] = data2[column].fillna(data2[column].mode()[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data3 = data2.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numeric Missing Values","metadata":{}},{"cell_type":"code","source":"def knn_impute(df, na_target):\n    df = df.copy()\n    \n    numeric_df = df.select_dtypes(np.number)\n    non_na_columns = numeric_df.loc[: ,numeric_df.isna().sum() == 0].columns\n    \n    y_train = numeric_df.loc[numeric_df[na_target].isna() == False, na_target]\n    X_train = numeric_df.loc[numeric_df[na_target].isna() == False, non_na_columns]\n    X_test = numeric_df.loc[numeric_df[na_target].isna() == True, non_na_columns]\n    \n    knn = KNeighborsRegressor()\n    knn.fit(X_train, y_train)\n    \n    y_pred = knn.predict(X_test)\n    \n    df.loc[df[na_target].isna() == True, na_target] = y_pred\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in [\n    'LotFrontage',\n    'MasVnrArea',\n    'BsmtFinSF1',\n    'BsmtFinSF2',\n    'BsmtUnfSF',\n    'TotalBsmtSF',\n    'BsmtFullBath',\n    'BsmtHalfBath',\n    'GarageYrBlt',\n    'GarageCars',\n    'GarageArea'\n]:\n    data3 = knn_impute(data3, column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data4 = data3.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"data4[\"SqFtPerRoom\"] = data4[\"GrLivArea\"] / (data4[\"TotRmsAbvGrd\"] +\n                                                       data4[\"FullBath\"] +\n                                                       data4[\"HalfBath\"] +\n                                                       data4[\"KitchenAbvGr\"])\n\ndata4['Total_Home_Quality'] = data4['OverallQual'] + data4['OverallCond']\n\ndata4['Total_Bathrooms'] = (data4['FullBath'] + (0.5 * data4['HalfBath']) +\n                               data4['BsmtFullBath'] + (0.5 * data4['BsmtHalfBath']))\n\ndata4[\"HighQualSF\"] = data4[\"1stFlrSF\"] + data4[\"2ndFlrSF\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data5 = data4.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Transformations","metadata":{}},{"cell_type":"markdown","source":"## Log Transform for Skewed Features","metadata":{}},{"cell_type":"code","source":"skew_df = pd.DataFrame(data5.select_dtypes(np.number).columns, columns=['Feature'])\nskew_df['Skew'] = skew_df['Feature'].apply(lambda feature: scipy.stats.skew(data5[feature]))\nskew_df['Absolute Skew'] = skew_df['Skew'].apply(abs)\nskew_df['Skewed'] = skew_df['Absolute Skew'].apply(lambda x: True if x >= 0.5 else False)\nskew_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in skew_df.query(\"Skewed == True\")['Feature'].values:\n    data5[column] = np.log1p(data5[column])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cosine Transform for Cyclical Features","metadata":{}},{"cell_type":"code","source":"data4['MoSold'] = (-np.cos(0.5236 * data5['MoSold']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data6 = data5.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode Categoricals","metadata":{}},{"cell_type":"code","source":"data6 = pd.get_dummies(data6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data7 = data6.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(data7)\n\ndata7 = pd.DataFrame(scaler.transform(data7), index=data7.index, columns=data7.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data8 = data7.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target Transformation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\n\nplt.subplot(1, 2, 1)\nsns.distplot(target, kde=True, fit=scipy.stats.norm)\nplt.title(\"Without Log Transform\")\n\nplt.subplot(1, 2, 2)\nsns.distplot(np.log(target), kde=True, fit=scipy.stats.norm)\nplt.xlabel(\"Log SalePrice\")\nplt.title(\"With Log Transform\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_target = np.log(target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"train_final = data8.loc[:train0.index.max(), :].copy()\ntest_final = data8.loc[train0.index.max() + 1:, :].reset_index(drop=True).copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection","metadata":{}},{"cell_type":"code","source":"# _ = setup(data=pd.concat([train_final, log_target], axis=1), target='SalePrice')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compare_models()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Optimization","metadata":{}},{"cell_type":"code","source":"# def br_objective(trial):\n#     n_iter = trial.suggest_int('n_iter', 50, 600)\n#     tol = trial.suggest_loguniform('tol', 1e-8, 10.0)\n#     alpha_1 = trial.suggest_loguniform('alpha_1', 1e-8, 10.0)\n#     alpha_2 = trial.suggest_loguniform('alpha_2', 1e-8, 10.0)\n#     lambda_1 = trial.suggest_loguniform('lambda_1', 1e-8, 10.0)\n#     lambda_2 = trial.suggest_loguniform('lambda_2', 1e-8, 10.0)\n    \n#     model = BayesianRidge(\n#         n_iter=n_iter,\n#         tol=tol,\n#         alpha_1=alpha_1,\n#         alpha_2=alpha_2,\n#         lambda_1=lambda_1,\n#         lambda_2=lambda_2\n#     )\n    \n#     model.fit(train_final, log_target)\n    \n#     cv_scores = np.exp(np.sqrt(-cross_val_score(model, train_final, log_target, scoring='neg_mean_squared_error', cv=kf)))\n    \n#     return np.mean(cv_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# study = optuna.create_study(direction='minimize')\n# study.optimize(br_objective, n_trials=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# study.best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bagging Ensemble","metadata":{}},{"cell_type":"code","source":"catboost_params = {\n    'iterations': 6000,\n    'learning_rate': 0.005,\n    'depth': 4,\n    'l2_leaf_reg': 1,\n    'eval_metric':'RMSE',\n    'early_stopping_rounds': 200,\n    'random_seed': 42\n}\n\nbr_params = {\n    'n_iter': 304,\n    'tol': 0.16864712769300896,\n    'alpha_1': 5.589616542154059e-07,\n    'alpha_2': 9.799343618469923,\n    'lambda_1': 1.7735725582463822,\n    'lambda_2': 3.616928181181732e-06\n}\n\nlightgbm_params = {\n    'num_leaves': 39,\n    'max_depth': 2,\n    'learning_rate': 0.13705339989856127,\n    'n_estimators': 273\n}\n\nridge_params = {\n    'alpha': 631.1412445239156\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    \"catboost\": CatBoostRegressor(**catboost_params, verbose=0),\n    \"br\": BayesianRidge(**br_params),\n    \"lightgbm\": LGBMRegressor(**lightgbm_params),\n    \"ridge\": Ridge(**ridge_params),\n    \"omp\": OrthogonalMatchingPursuit()\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, model in models.items():\n    model.fit(train_final, log_target)\n    print(name + \" trained.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"results = {}\n\nkf = KFold(n_splits=10)\n\nfor name, model in models.items():\n    result = np.exp(np.sqrt(-cross_val_score(model, train_final, log_target, scoring='neg_mean_squared_error', cv=kf)))\n    results[name] = result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, result in results.items():\n    print(\"----------\\n\" + name)\n    print(np.mean(result))\n    print(np.std(result))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine Predictions","metadata":{}},{"cell_type":"code","source":"final_predictions = (\n    0.4 * np.exp(models['catboost'].predict(test_final)) +\n    0.2 * np.exp(models['br'].predict(test_final)) +\n    0.2 * np.exp(models['lightgbm'].predict(test_final)) +\n    0.1 * np.exp(models['ridge'].predict(test_final)) +\n    0.1 * np.exp(models['omp'].predict(test_final))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.concat([test_ids, pd.Series(final_predictions, name='SalePrice')], axis=1)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('./submission.csv', index=False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Livestream Included!\n\n***\n\nThis notebook was created during a YouTube live session.  \nFor an in-depth guide, check it out here!  \nhttps://youtu.be/zwYHloLXH0c","metadata":{}}]}