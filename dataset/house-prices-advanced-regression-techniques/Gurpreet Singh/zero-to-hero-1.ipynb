{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Zero To Hero**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hey Folks!\n## Welcome to my kernel","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This kernel is develpoed for beginners which will help to clear many doubts.\nThis kernel will definately provide an idea about  \"How to deal with data\".\n> Before we move further let's understand the flow of the noteebook","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The flow of the notebook goes as\n1.  **Importing the data ** : we will import the data and will try to understand it\n2. **Treatment of sick data** : It includes processing of the data\n3. **Visualization techniques** : We will try to analyze our data and convert our magic numbers into beautiful & meaningfull graphs\n4. **EDA** : We will convert data into efficient trainable form\n4. **Feature Addition** : Adding new features to our dat set\n5. **Training Our Model**\n6. **Submitting our predictiom**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest_data=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ** ** Let's First try to understand the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the NaN values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting the colimns with high NaN values\nnan=[]\nfor i in x:\n    n=train_data[i].isnull().sum()\n    if n>0:\n        nan.append(i)\nnan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmmmm These are the troublesome \nSo we'll  treat these columns later","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Let's check the columns which have less unique values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"less=[]\nhigh=[]\nfor i in x:\n    l=train_data[i].nunique()\n    if l<50:\n        less.append(i)\n    else :\n        high.append(i)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will convert these columns with dummies","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Let's categorize the columns on basis of data types**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumeric = []\nfor i in train_data.columns:\n    if train_data[i].dtype in numeric_dtypes:\n        numeric.append(i)\n_=numeric.pop(0)\n_=numeric.pop(-1)\n# poped out Id,SalePrice  you will understand the reason later\nnumeric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = []\nfor i in x:\n    if train_data[i].dtypes == 'object':\n        category.append(i)\n    \ncategory    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## now we will understand data with the help of visualization techniques","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1,figsize=(15,7))\nsns.distplot(train_data['SalePrice'])\nplt.xlabel('Sales price')\nplt.ylabel('Frequency')\nplt.title('Sales Price Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Skew and kurt\nprint(\"Skewness: %f\" % train_data['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train_data['SalePrice'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need to correct the skewness of the price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# log(1+x) transform\ncorrected_price= np.log1p(train_data[\"SalePrice\"])\n#we will be substituting the value at last","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1,figsize=(15,7))\nsns.distplot(corrected_price)\nplt.xlabel('Sales price')\nplt.ylabel('Frequency')\nplt.title('Sales Price Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zones=train_data[['MSZoning','SalePrice']]\nsns.catplot(x='MSZoning',y='SalePrice',kind='swarm',data=zones)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z=zones.groupby(['MSZoning']).mean()\nz.plot(kind='bar')\n_=plt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbor=train_data[['LandContour','Neighborhood','SalePrice']]\nplt.figure(1,figsize=(25,10))\nsns.swarmplot(x=neighbor['Neighborhood'],y=neighbor['SalePrice'])\n_=plt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1,figsize=(25,10))\nsns.scatterplot(x=neighbor['Neighborhood'],y=neighbor['SalePrice'],hue=neighbor['LandContour'])\n_=plt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg = train_data[['BldgType','HouseStyle','OverallQual','OverallCond','SalePrice','MiscVal']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1,figsize=(15,7))\nsns.jointplot(x='OverallQual',y='SalePrice',data=bldg,kind='kde')\nplt.figure(2,figsize=(15,7))\nsns.jointplot(x='OverallCond',y='SalePrice',data=bldg,kind='kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg=bldg.groupby(['BldgType']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bldg['SalePrice'].plot(kind='bar')\nsns.regplot(x=bldg.OverallQual,y=bldg.SalePrice,units=bldg.OverallCond)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg.plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"garage=train_data[['GarageType','GarageFinish','GarageCars','GarageQual','GarageCond','SalePrice']]\ngarage.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g=garage.groupby(['GarageType'])\nga=g.plot(x='GarageFinish',y='SalePrice',alpha=.6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x=garage['SalePrice'],y=garage['GarageType'],hue=garage['GarageFinish'],join=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x=garage['GarageType'],y=garage['GarageCars'],hue=garage['GarageFinish'],color='blue',join=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g=g=garage.groupby(['GarageType']).mean()\ng['GarageCars']=g['GarageCars'].astype(int)\ng['SalePrice']=g['SalePrice'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=g['SalePrice'],y=g['GarageCars'],data=g,scatter=True,fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=g['GarageCars'],y=g['SalePrice'],data=g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"misc=train_data[['MiscVal','SaleType','SalePrice']]\nmisc.groupby(['SaleType']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='MiscVal',y='SalePrice',hue='SaleType',data=misc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='MiscVal',y='SalePrice',hue='SaleType',data=misc)\nplt.figure(1,figsize=(55,15))\n_=plt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date=train_data[['MoSold','YrSold','SalePrice','SaleCondition']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='YrSold',y='SalePrice',data=date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='MoSold',y='SalePrice',hue='YrSold',data=date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x='MoSold',y='SalePrice',hue='YrSold',data=date,join=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_data.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"Greens\", square=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although these graphs might appear as images for you by now, but with practise these graph would be speaking out loud for you","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = round(train_data.isnull().mean()*100,2)\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot(kind='bar')\nplt.figure(figsize=(15,7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EDA**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Combining train and test data and separating the label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#separating the label\ntrain = train_data.copy()\ntest=test_data.copy()\nlabel=train_data['SalePrice'].reset_index(drop=True)\ntrain=train.drop(['SalePrice'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining  the trainand test data\ndata=pd.concat([train,test]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing the Id column\ntrain_id=train['Id']\ntest_id=test['Id']\ndata=data.drop(['Id'],axis=1)\ndata.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filling the missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_nan=[]\nfor i in numeric:\n    for j in nan:\n        if i==j:\n            num_nan.append(j)\n            print(j)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so these are the columns which have missing value and have numeric data\n> if you don't know how to remove missing values take a look at this : https://www.kaggle.com/alexisbcook/missing-values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputing the numeric missing values\nfrom sklearn.impute import SimpleImputer\nimputer=SimpleImputer()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_data=pd.DataFrame(imputer.fit_transform(data[num_nan]))\nimp_data.columns=num_nan\ndata[num_nan]=imp_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we will add the categorial missing values manually","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# these are the columns whose missing values are to be added\ncat_nan=[set(nan)-set(num_nan)]\ncat_nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get started\nWe wil fill them with our intution by analyzing the data thoroughly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Alley'] = data['Alley'].fillna(data[\"Alley\"].mode()[0])\nfor i in ('BsmtCond','BsmtFinType1','BsmtFinType2','BsmtQual','BsmtExposure'):\n    data[i] = data[i].fillna('None')\ndata['Electrical'] = data['Electrical'].fillna('SBrkr')\ndata['MasVnrType']=data['MasVnrType'].fillna(data['MasVnrType'].mode()[0])\ndata['Fence'] = data['Fence'].fillna(data['Fence'].mode()[0])\nfor i in ('GarageFinish','GarageCond','GarageQual','GarageType'):\n    data[i]=data[i].fillna('None')\ndata['FireplaceQu'] = data['FireplaceQu'].fillna('Fire')    \ndata['MiscFeature']=data['MiscFeature'].fillna('Misc')\ndata['PoolQC']=data['PoolQC'].fillna('Pool')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# doing the final check if any mising value left by mistake\ndata.update(data[numeric].fillna(0))\ndata.update(data[category].fillna('None'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding New Features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Our Features Are Based Over Our Intution.\n\n\nWe will  try to create those features which would be directly related to the Sale Price and special features in it\n\nAnd will remove columns which are not useful enough","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Before  doing it dig deeply into the data description :https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding columns of average/good features\ndata['hasallutilities']=1*(data['Utilities'] == 'AllPub')\ndata['average']=1*(data['OverallQual'] == 5 | 6)\ndata['ext_qual']=1*(data['ExterQual'] == 'Gd')\ndata['fencing']=1*(data['Fence'] == 'GdPrv')\n\n#adding column on basis of features\ndata['total_qual'] = data['OverallQual'] + data['OverallCond']\ndata['total_floors_area'] =  data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\ndata['total_sqr'] =  data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\ndata['total_poarch_sf'] = (data['OpenPorchSF'] + data['3SsnPorch'] +data['EnclosedPorch'] + data['ScreenPorch'] +data['WoodDeckSF'])\n\n#adding columns for special features\ndata['hasfireplace'] = data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ndata['haspool'] = data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndata['has2ndfloor'] = data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasgarage'] = data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n\n# dropping some columns\ndata=data.drop(['PavedDrive','Street','PavedDrive'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding Our Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.get_dummies(data).reset_index(drop=True)\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check out other encoding techniques :https://www.kaggle.com/alexisbcook/categorical-variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Spliting back the train and test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data.iloc[:len(label),:]\ntest = data.iloc[len(label):,:]\ntrain.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Training the model**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Creating diffrent Models\n## 2. Cross Validation of data\n## 3. Selecting the best model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# for models\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n\n#for cross validation\nfrom sklearn.model_selection import KFold, cross_val_score\n\n#for calculation of error\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# RAndom Forest Regressor\nmodel1 = RandomForestRegressor(n_estimators=1000,max_depth=12,min_samples_split=5,min_samples_leaf=5,oob_score=True,random_state=50)\n\n#XGBRegressor\nmodel2 = XGBRegressor(n_estimators=5000,learning_rate=0.01,early_stopping_round=10,max_depth=4,min_child_weight=0,gamma=0.6,verbose=False,random_state=50)\n\n#Light LGB Regressor\nmodel3=  LGBMRegressor(objective='regression', \n                       num_leaves=6,\n                       learning_rate=0.01, \n                       n_estimators=5000,\n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.2,\n                       feature_fraction_seed=8,\n                       verbose=-1,\n                       random_state=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation of these models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def cv(model,x=train):\n    er = -1*cross_val_score(model,x,label,cv=10,scoring='neg_mean_absolute_error')\n    # root mean square \n    rmse=np.sqrt(er)\n    return rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"have a look if you don't get the above code :https://www.kaggle.com/alexisbcook/cross-validation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Calculating score of each model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#for RandomForest\nscore1=cv(model1)\nRf=[score1.mean(),score1.std()]\nRf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score2=cv(model2)\nXg_mean=score2.mean()\nXg_std=score2.std()\nXg=[Xg_mean,Xg_std]\nXg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score3=cv(model3)\nLg_mean=score3.mean()\nLg_std=score3.std()\nLg=[Lg_mean,Lg_std]\nLg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# what do you understand with this data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(train,label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting our data on test\npred= model2.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this is our predicted data\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pred,test.index,color='blue')\nplt.title(\"This is the Predicted Price\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_data['SalePrice'],train_data.index,color='green')\nplt.title(\"This was the trained Price\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id= np.array(range(1461,2920))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out1 =pd.DataFrame({\"Id\":Id,\"SalePrice\": pred})\nout1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out1.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"our data is submitted successfully","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Note**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## We are data scientist (thiugh not now) and we deal with real facts . And one real fact is that no one can become an expert with one notebook**\n**In this notebook  I have tried to provide max. information one can gain from a notebbok additional  techniques would have  create confusion , the msin aim for this draft is to get an idea about hoew thing work, so thie output submiited is not much efficient and precise .I would keep adding new version with more advanced stuffs, which will generate a more efficient and precise output.**\n\n## Till then get through with it and accept it as the first draft\n\n> \nTip : Never Submit your first draft in a competition , figure out more ways to improve results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Please upvote if you found it informative in any way","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Thank You For Giving Time To This Notebook","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}