{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>\n    <p style=\"text-align:center; font-size:180%\"> House Prices - Advanced Regression Techniques <br><br> üè°</p> \n</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2>\n    <p style=\"text-align:center; font-family:Verdana; letter-spacing:0.5px; font-size:120%\"> Predict sales prices and practice feature engineering, RFs, and gradient boosting \n    </p>\n</h2> \n    \n\n<center>\n    <img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/5407/media/housesbanner.png\"> \n</center>\n\n<br><br>\n\n**With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home. Resources:**\n\n* `train.csv` - the training set\n* `test.csv` - the test set\n* `data_description.txt` - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\n* `sample_submission.csv` - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms","metadata":{}},{"cell_type":"markdown","source":"<div style=\"display:fill;\n            border-radius:10px;\n            background-color:#246be3;\n            font-family:Verdana;\n            letter-spacing:1px;\n            border: 2px solid #002a6e; \n            text-align:center;\n            color:white; \n            font-size:120%\">\n\n<h2>Libraries and Settings<br> üìì</h2> </div>\n","metadata":{}},{"cell_type":"code","source":"# Data manipulation\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_squared_error\n\n# Maths\nimport numpy as np\n\n# Patching sklearn\n!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n\n\n# Model Building \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\n\nimport shap\nfrom catboost import Pool\nfrom catboost import CatBoostRegressor\n\n\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pprint\n\n# Lgbm\nfrom lightgbm import LGBMRegressor\nimport lightgbm as lgb\n\n\n# Settings\nsns.set(rc = {'figure.figsize': (26, 8)})\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style = \"ticks\", rc = custom_params)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:15:51.637917Z","iopub.execute_input":"2022-02-01T17:15:51.638292Z","iopub.status.idle":"2022-02-01T17:16:44.264168Z","shell.execute_reply.started":"2022-02-01T17:15:51.638171Z","shell.execute_reply":"2022-02-01T17:16:44.263237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"display:fill;\n            border-radius:10px;\n            background-color:#246be3;\n            font-family:Verdana;\n            letter-spacing:1px;\n            border: 2px solid #002a6e; \n            text-align:center;\n            color:white; \n            font-size:120%\">\n\n<h2>Data Loading and EDA <br> ü§ì</h2> </div>\n","metadata":{}},{"cell_type":"code","source":"# Data loading\ntrain_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv', index_col = 'Id')\ntest_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv', index_col = 'Id')\n\n# Drop Not relevant columns\ndef drop_nrv(df):\n    na_df = pd.DataFrame(df.isna().sum(), \n                         columns = ['Number of NaN'])\n    \n    na_df = na_df.sort_values('Number of NaN', \n                              ascending = False).head(10)\n    \n    na_df['Perc'] = round(na_df['Number of NaN']/len(train_data.index)*100, 2)\n    \n    # Drop columns that have more than 50% of NaN\n    to_drop = list(na_df[na_df['Perc'] > 50.00].index)\n    na_df['Perc'] = na_df['Perc'].astype(str) + '%'\n    df.drop(to_drop, \n            inplace = True, axis = 1)\n    \n    print(to_drop, ' columns have been removed (> 50% NaN)\\n', sep = '')\n    \n    return na_df, df.astype('float64', errors = 'ignore')\n\nprint('TRAIN DATA\\n')\nmissing_val_train, train_data = drop_nrv(train_data)\nprint(missing_val_train, '\\n\\n', '-'*80, '\\n', sep = '')\n\nprint('TEST DATA\\n')\nmissing_val_test, test_data = drop_nrv(test_data)\nprint(missing_val_test, '\\n\\n', '-'*80, '\\n', sep = '')\n\nprint(f'Train Data rows: {train_data.shape[0]} \\nTrain Data Columns: {train_data.shape[1]}\\n')\nprint(f'Test Data rows: {test_data.shape[0]} \\nTest Data Columns: {test_data.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:16:44.266184Z","iopub.execute_input":"2022-02-01T17:16:44.266501Z","iopub.status.idle":"2022-02-01T17:16:44.401782Z","shell.execute_reply.started":"2022-02-01T17:16:44.26646Z","shell.execute_reply":"2022-02-01T17:16:44.40084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def obj_int_identifier(train_data, test_data):\n\n    num_unique_val = pd.DataFrame(train_data.nunique(), columns = ['Unique Values']).sort_values(by = 'Unique Values')\n    cat = num_unique_val[num_unique_val['Unique Values']<=25].index\n    cont  = num_unique_val[num_unique_val['Unique Values']>25].index\n    \n    train_data_cont_var = train_data.filter(cont).columns\n    train_data_disc_var = train_data.filter(cat).columns\n    \n    print('Train data total columns: ', \n          len(train_data_cont_var)+len(train_data_disc_var), \n          '\\nContinuous Features: ', len(train_data_cont_var),\n          '\\nDiscrete Features: ', len(train_data_disc_var), '\\n', sep ='')\n    \n    test_data_cont_var = test_data.filter(cont).columns\n    test_data_disc_var = test_data.filter(cat).columns\n\n    print('Test data total columns: ', \n          len(test_data_cont_var)+len(test_data_disc_var), \n          '\\nContinuous Features: ', len(test_data_cont_var),\n          '\\nDiscrete Features: ', len(test_data_disc_var), sep ='')\n    \n    return train_data_cont_var, train_data_disc_var, test_data_cont_var, test_data_disc_var\n\ntrain_data_cont_var, train_data_disc_var, test_data_cont_var, test_data_disc_var = obj_int_identifier(train_data, test_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:16:44.404138Z","iopub.execute_input":"2022-02-01T17:16:44.404694Z","iopub.status.idle":"2022-02-01T17:16:45.336371Z","shell.execute_reply.started":"2022-02-01T17:16:44.404646Z","shell.execute_reply":"2022-02-01T17:16:45.33552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Align Features\ndef discrepancies_check(train, test):\n    dict_train = {}\n    dict_test = {}\n    \n    for el in train_data_disc_var:\n        dict_train[el] = train[el].unique().tolist()\n    \n    for el in test_data_disc_var:\n        dict_test[el] = test[el].unique().tolist()\n    \n    if dict_train.keys() == dict_test.keys():\n        print('Train and Test set have the same discrete features.\\nResults:')\n    else: \n        print('Pay attention, different discrete features in Train and Test!\\n')\n\n    dict_diff = {}\n    train_or_test = {}\n    \n    for key in dict_train.keys():\n        if set(dict_train[key]) ^ set(dict_test[key]) != set():\n            dict_diff[key] = list(set(dict_train[key]) ^ set(dict_test[key]))\n    \n    for key in dict_train.keys():\n        if (set(dict_test[key]) - set(dict_train[key]) != set()) & (set(dict_train[key]) - set(dict_test[key]) != set()):\n            train_or_test[key] = 'Both'        \n        elif set(dict_train[key]) - set(dict_test[key]) != set():\n            train_or_test[key] = 'Train'\n        elif set(dict_test[key]) - set(dict_train[key]) != set():\n            train_or_test[key] = 'Test'        \n        elif set(dict_train[key]) ^ set(dict_test[key]) == set():\n            pass\n        else:\n            print('Pay attention possible errors!')\n    \n    df = pd.DataFrame(index = dict_diff.keys(), columns = ['Discrepancies'])\n    df['Discrepancies'] = dict_diff.values()\n    \n    df1 = pd.DataFrame(index = train_or_test.keys(), columns = ['Where'])\n    df1['Where'] = train_or_test.values()\n    \n    final_df = df.merge(df1, right_index = True, left_index = True)\n    \n    return final_df\n    \ndiscrepancies_check(train_data, test_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:16:45.339337Z","iopub.execute_input":"2022-02-01T17:16:45.339638Z","iopub.status.idle":"2022-02-01T17:16:45.410366Z","shell.execute_reply.started":"2022-02-01T17:16:45.339595Z","shell.execute_reply":"2022-02-01T17:16:45.40954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\"> üìå Ex.1: in Train Utilities has NoSeWa, while in Test Utilities has nan.</div>","metadata":{}},{"cell_type":"code","source":"print('Utilities in Train data: ', train_data['Utilities'].unique(), '\\n',\n      'Utilities in Test data: ', test_data['Utilities'].unique(), sep = '')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:16:45.41179Z","iopub.execute_input":"2022-02-01T17:16:45.412255Z","iopub.status.idle":"2022-02-01T17:16:45.419058Z","shell.execute_reply.started":"2022-02-01T17:16:45.412213Z","shell.execute_reply":"2022-02-01T17:16:45.418222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\"> üìå Ex.2: in Train Electrical has Mix and nan, while in Test these observations are not present.</div>","metadata":{}},{"cell_type":"code","source":"print('Utilities in Train data: ', train_data['Electrical'].unique(), '\\n',\n      'Utilities in Test data: ', test_data['Electrical'].unique(), sep = '')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:16:45.420133Z","iopub.execute_input":"2022-02-01T17:16:45.420927Z","iopub.status.idle":"2022-02-01T17:16:45.434101Z","shell.execute_reply.started":"2022-02-01T17:16:45.420897Z","shell.execute_reply":"2022-02-01T17:16:45.433352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.1 Train Data Visualization","metadata":{}},{"cell_type":"code","source":"train_data[train_data_cont_var].hist(figsize=(26, 20), layout=(5, 4))\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:16:45.435373Z","iopub.execute_input":"2022-02-01T17:16:45.435578Z","iopub.status.idle":"2022-02-01T17:16:48.887739Z","shell.execute_reply.started":"2022-02-01T17:16:45.435553Z","shell.execute_reply":"2022-02-01T17:16:48.887109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(10, 6, figsize=(26, 40))\n\nfor variable, subplot in zip(train_data_disc_var, ax.flatten()):\n    sns.countplot(x  = train_data[variable], ax=subplot)\n    subplot.figure.tight_layout()\n    for label in subplot.get_xticklabels():\n        label.set_rotation(45)\n\nfig.delaxes(ax[9][3])\nfig.delaxes(ax[9][4])\nfig.delaxes(ax[9][5])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:16:48.888754Z","iopub.execute_input":"2022-02-01T17:16:48.889321Z","iopub.status.idle":"2022-02-01T17:17:40.959052Z","shell.execute_reply.started":"2022-02-01T17:16:48.889279Z","shell.execute_reply":"2022-02-01T17:17:40.958066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(train_data[train_data_cont_var])  \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:17:40.960545Z","iopub.execute_input":"2022-02-01T17:17:40.960853Z","iopub.status.idle":"2022-02-01T17:19:06.96826Z","shell.execute_reply.started":"2022-02-01T17:17:40.960811Z","shell.execute_reply":"2022-02-01T17:19:06.967293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train_data[train_data_cont_var].corr(), annot=True, annot_kws={\"size\": 15},fmt='.1f')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:19:06.970972Z","iopub.execute_input":"2022-02-01T17:19:06.971341Z","iopub.status.idle":"2022-02-01T17:19:08.674045Z","shell.execute_reply.started":"2022-02-01T17:19:06.97131Z","shell.execute_reply":"2022-02-01T17:19:08.673127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.2 Test Data Visualization","metadata":{}},{"cell_type":"code","source":"test_data[test_data_cont_var].hist(figsize=(26, 20), layout=(5, 4))\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:19:08.675307Z","iopub.execute_input":"2022-02-01T17:19:08.675538Z","iopub.status.idle":"2022-02-01T17:19:11.988914Z","shell.execute_reply.started":"2022-02-01T17:19:08.675508Z","shell.execute_reply":"2022-02-01T17:19:11.987993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(10, 6, figsize=(26, 40))\n\nfor variable, subplot in zip(train_data_disc_var, ax.flatten()):\n    sns.countplot(x  = train_data[variable], ax=subplot)\n    subplot.figure.tight_layout()\n    for label in subplot.get_xticklabels():\n        label.set_rotation(45)\n\nfig.delaxes(ax[9][2])\nfig.delaxes(ax[9][3])\nfig.delaxes(ax[9][4])\nfig.delaxes(ax[9][5])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:19:11.990119Z","iopub.execute_input":"2022-02-01T17:19:11.990381Z","iopub.status.idle":"2022-02-01T17:20:11.289054Z","shell.execute_reply.started":"2022-02-01T17:19:11.990351Z","shell.execute_reply":"2022-02-01T17:20:11.288371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(test_data[test_data_cont_var])  \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:20:11.290119Z","iopub.execute_input":"2022-02-01T17:20:11.290369Z","iopub.status.idle":"2022-02-01T17:21:25.038919Z","shell.execute_reply.started":"2022-02-01T17:20:11.290339Z","shell.execute_reply":"2022-02-01T17:21:25.038208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(test_data[test_data_cont_var].corr(), annot=True, annot_kws={\"size\": 15},fmt='.1f')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:25.040658Z","iopub.execute_input":"2022-02-01T17:21:25.041054Z","iopub.status.idle":"2022-02-01T17:21:26.65502Z","shell.execute_reply.started":"2022-02-01T17:21:25.041018Z","shell.execute_reply":"2022-02-01T17:21:26.654398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.3 Exploring High Correlations with `SalePrice`","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(3,2, figsize=(26,20))\n\nsns.boxplot(x=train_data['OverallQual'],\n            y=train_data['SalePrice'], \n            ax=ax[0,0]).set_title('OverallQual and SalePrice',\n                                fontsize = 20)\n\nsns.boxplot(x=train_data['OverallCond'],\n            y=train_data['SalePrice'], \n            ax=ax[1,0]).set_title('OverallCond and SalePrice',\n                                fontsize = 20)\n\nsns.scatterplot(x = train_data['YearBuilt'],\n                y = train_data['SalePrice'],\n                hue = train_data['OverallQual'],\n            ax=ax[0,1]).set_title('YearBuilt and SalePrice',\n                                  fontsize = 20)\n\nsns.scatterplot(x=train_data['GrLivArea'],\n                y=train_data['SalePrice'], \n                hue = train_data['OverallQual'],\n                ax=ax[1,1]).set_title('GrLivArea and SalePrice',\n                                      fontsize = 20)\n\nsns.boxplot(x = train_data['TotRmsAbvGrd'],\n            y = train_data['SalePrice'],\n            ax = ax[2,0]).set_title('TotRmsAbvGrd and SalePrice',\n                                  fontsize = 20)\n\nsns.scatterplot(x=train_data['TotalBsmtSF'],\n                y=train_data['SalePrice'], \n                hue = train_data['OverallQual'],\n                ax=ax[2,1]).set_title('TotalBsmtSF and SalePrice',\n                                      fontsize = 20)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:26.656156Z","iopub.execute_input":"2022-02-01T17:21:26.656787Z","iopub.status.idle":"2022-02-01T17:21:29.198956Z","shell.execute_reply.started":"2022-02-01T17:21:26.656753Z","shell.execute_reply":"2022-02-01T17:21:29.198283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"display:fill;\n            border-radius:10px;\n            background-color:#246be3;\n            font-family:Verdana;\n            letter-spacing:1px;\n            border: 2px solid #002a6e; \n            text-align:center;\n            color:white; \n            font-size:120%\">\n\n<h2>Feature Enineering<br> üßë‚Äçüè≠</h2> </div>","metadata":{}},{"cell_type":"markdown","source":"# 2.1 Imputing NaN\n\n## train_data","metadata":{}},{"cell_type":"code","source":"# For the categorical variable is better to track where the missing values are\ntrain_data[train_data_disc_var] = train_data[train_data_disc_var].fillna('missing')\n\n# The mean is used to fill NaN. As for GarageYrBlt 0 is used in order to track where the missing values are\nmiss_cont = pd.DataFrame(train_data[train_data_cont_var].isna().sum(), columns = ['missing']).sort_values('missing', ascending = False).head(3)\ntrain_data['LotFrontage'] = train_data['LotFrontage'].fillna(train_data['LotFrontage'].mean())\ntrain_data['GarageYrBlt'] = train_data['GarageYrBlt'].fillna(0)\ntrain_data['MasVnrArea'] = train_data['MasVnrArea'].fillna(train_data['MasVnrArea'].mean())\nmiss_cont","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:29.200225Z","iopub.execute_input":"2022-02-01T17:21:29.200615Z","iopub.status.idle":"2022-02-01T17:21:29.234761Z","shell.execute_reply.started":"2022-02-01T17:21:29.20057Z","shell.execute_reply":"2022-02-01T17:21:29.234174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## test_data","metadata":{}},{"cell_type":"code","source":"# For the categorical variable is better to track where the missing values are\ntest_data[test_data_disc_var] = test_data[test_data_disc_var].fillna('missing')\n\n# The mean is used to fill NaN. As for GarageYrBlt 0 is used in order to track where the missing values are\nmiss_cont = pd.DataFrame(test_data[test_data_cont_var].isna().sum(), columns = ['missing']).sort_values('missing', ascending = False).head(8)\ntest_data['LotFrontage'] = test_data['LotFrontage'].fillna(test_data['LotFrontage'].mean())\ntest_data['GarageYrBlt'] = test_data['GarageYrBlt'].fillna(0)\ntest_data['MasVnrArea'] = test_data['MasVnrArea'].fillna(test_data['MasVnrArea'].mean())\ntest_data['GarageArea'] = test_data['GarageArea'].fillna(test_data['MasVnrArea'].mean())\ntest_data['BsmtUnfSF'] = test_data['BsmtUnfSF'].fillna(test_data['MasVnrArea'].mean())\ntest_data['BsmtFinSF2'] = test_data['BsmtFinSF2'].fillna(test_data['MasVnrArea'].mean())\ntest_data['TotalBsmtSF'] = test_data['TotalBsmtSF'].fillna(test_data['MasVnrArea'].mean())\ntest_data['BsmtFinSF1'] = test_data['BsmtFinSF1'].fillna(test_data['MasVnrArea'].mean())\nmiss_cont","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:29.235991Z","iopub.execute_input":"2022-02-01T17:21:29.236459Z","iopub.status.idle":"2022-02-01T17:21:29.278442Z","shell.execute_reply.started":"2022-02-01T17:21:29.236418Z","shell.execute_reply":"2022-02-01T17:21:29.277878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Residual NanN in Train:',train_data.isna().sum().sum())\nprint('Residual NanN in Test:',test_data.isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:29.279702Z","iopub.execute_input":"2022-02-01T17:21:29.279908Z","iopub.status.idle":"2022-02-01T17:21:29.303557Z","shell.execute_reply.started":"2022-02-01T17:21:29.279883Z","shell.execute_reply":"2022-02-01T17:21:29.302785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check if something went wrong with columns until now\nprint(f'Train Data rows: {train_data.shape[0]} \\nTrain Data Columns: {train_data.shape[1]}\\n')\nprint(f'Test Data rows: {test_data.shape[0]} \\nTest Data Columns: {test_data.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:29.304884Z","iopub.execute_input":"2022-02-01T17:21:29.30509Z","iopub.status.idle":"2022-02-01T17:21:29.309697Z","shell.execute_reply.started":"2022-02-01T17:21:29.305063Z","shell.execute_reply":"2022-02-01T17:21:29.30904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.2 Transforming Skewed Distributions","metadata":{}},{"cell_type":"markdown","source":"## Train Data","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(12,2, figsize=(26,80))\ni = 0\n\nlog_t_train = [  'ScreenPorch', 'LotFrontage', 'EnclosedPorch', 'BsmtFinSF2', 'OpenPorchSF',\n                 'WoodDeckSF', 'MasVnrArea', '2ndFlrSF', 'SalePrice', '1stFlrSF',\n                 'GrLivArea', 'LotArea']\n\nfor col in log_t_train: \n    sns.histplot(data=train_data[train_data_cont_var], \n            x=col,\n            kde=True,\n            ax=ax[i,0]).set_title(f'Original {col}, skew: {round(train_data[train_data_cont_var][col].skew(),4)}',\n                                fontsize = 20)\n\n    sns.histplot(data=np.log1p(train_data[train_data_cont_var]), \n            x=col,\n            kde=True,\n            ax=ax[i,1]).set_title(f'Log transformed {col}, skew: {round(np.log1p(train_data[train_data_cont_var][col]).skew(),4)}',\n                                fontsize = 20)\n    i=i+1\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:29.310761Z","iopub.execute_input":"2022-02-01T17:21:29.311101Z","iopub.status.idle":"2022-02-01T17:21:37.21239Z","shell.execute_reply.started":"2022-02-01T17:21:29.311072Z","shell.execute_reply":"2022-02-01T17:21:37.211443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[log_t_train] = np.log1p(train_data[log_t_train])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:37.213613Z","iopub.execute_input":"2022-02-01T17:21:37.213836Z","iopub.status.idle":"2022-02-01T17:21:37.222661Z","shell.execute_reply.started":"2022-02-01T17:21:37.213807Z","shell.execute_reply":"2022-02-01T17:21:37.221573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Data","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(11,2, figsize=(26,80))\ni = 0\n\nlog_t_test = [  'ScreenPorch', 'LotFrontage', 'EnclosedPorch', 'BsmtFinSF2', 'OpenPorchSF',\n                 'WoodDeckSF', 'MasVnrArea', '2ndFlrSF', '1stFlrSF',\n                 'GrLivArea', 'LotArea']\n\nfor col in log_t_test: \n    sns.histplot(data=test_data[test_data_cont_var], \n            x=col,\n            kde=True,\n            ax=ax[i,0]).set_title(f'Original {col}, skew: {round(test_data[test_data_cont_var][col].skew(),4)}',\n                                fontsize = 20)\n\n    sns.histplot(data=np.log1p(test_data[test_data_cont_var]), \n            x=col,\n            kde=True,\n            ax=ax[i,1]).set_title(f'Log transformed {col}, skew: {round(np.log1p(test_data[test_data_cont_var][col]).skew(),4)}',\n                                fontsize = 20)\n    i=i+1","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:37.22396Z","iopub.execute_input":"2022-02-01T17:21:37.224268Z","iopub.status.idle":"2022-02-01T17:21:43.479722Z","shell.execute_reply.started":"2022-02-01T17:21:37.224224Z","shell.execute_reply":"2022-02-01T17:21:43.478807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data[log_t_test] = np.log1p(test_data[log_t_test])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:43.481059Z","iopub.execute_input":"2022-02-01T17:21:43.481309Z","iopub.status.idle":"2022-02-01T17:21:43.488617Z","shell.execute_reply.started":"2022-02-01T17:21:43.481275Z","shell.execute_reply":"2022-02-01T17:21:43.487669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check if something went wrong with columns until now\nprint(f'Train Data rows: {train_data.shape[0]} \\nTrain Data Columns: {train_data.shape[1]}\\n')\nprint(f'Test Data rows: {test_data.shape[0]} \\nTest Data Columns: {test_data.shape[1]}')\n\nprint('\\nResidual NanN in Train:',train_data.isna().sum().sum())\nprint('Residual NanN in Test:',test_data.isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:43.489793Z","iopub.execute_input":"2022-02-01T17:21:43.490012Z","iopub.status.idle":"2022-02-01T17:21:43.525476Z","shell.execute_reply.started":"2022-02-01T17:21:43.489983Z","shell.execute_reply":"2022-02-01T17:21:43.524822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.3 Variable encoding","metadata":{}},{"cell_type":"code","source":"# This function labels columns and returns the modified data frame\ndef ptp(col, df):\n    \n    le = preprocessing.LabelEncoder()\n    ptp_corr = dict()\n    \n    for name in col:\n        le.fit(df[name].ravel().astype('str'))\n        k = name  \n        c = dict()\n        \n        for el in le.classes_:\n            c[el] = int(le.transform(np.asarray(el).ravel()))\n        \n        ptp_corr[k] = c\n        df[name] = le.transform(df[name].ravel().astype('str'))\n    \n    return ptp_corr, df\n\nmap_p2p1, train_data_lab_enc = ptp(train_data_disc_var, train_data)\nmap_p2p2, test_data_lab_enc = ptp(test_data_disc_var, test_data)\n\n#Check if something went wrong with columns until now\nprint(f'Train Data rows: {train_data_lab_enc.shape[0]} \\nTrain Data Columns: {train_data_lab_enc.shape[1]}\\n')\nprint(f'Test Data rows: {test_data_lab_enc.shape[0]} \\nTest Data Columns: {test_data_lab_enc.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:43.526799Z","iopub.execute_input":"2022-02-01T17:21:43.527002Z","iopub.status.idle":"2022-02-01T17:21:43.817879Z","shell.execute_reply.started":"2022-02-01T17:21:43.526977Z","shell.execute_reply":"2022-02-01T17:21:43.817014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features Encoding\ndef var_encoding(train, test):\n    # Solving the problem of discrepancies between Train and test\n    train['Origin']='TrainData'\n    test['Origin']='TestData'\n    comprehensive = pd.concat([train, test])\n    \n    dummy = train_data_disc_var\n    \n    comprehensive = pd.get_dummies(comprehensive, columns=dummy)\n    \n    new_train = comprehensive[comprehensive['Origin']=='TrainData']\n    new_train.drop('Origin', inplace = True, axis = 1)\n    new_test = comprehensive[comprehensive['Origin']=='TestData']\n    new_test.drop('Origin', inplace = True, axis = 1)\n    new_test.drop('SalePrice', inplace = True, axis = 1)\n    \n    if set(new_train.columns) - set(dummy) == set(new_train.columns):\n        print('Original columns dropped from train_data!')\n    else:\n        print('Some original columns are still present in train_data, please check!')\n        \n    if set(new_test.columns) - set(dummy) == set(new_test.columns):\n        print('Original columns dropped from test_data!\\n')\n    else:\n        print('Some original columns are still present in test_data, please check!\\n')\n    \n    return new_train, new_test\n\nnew_train, new_test = var_encoding(train_data_lab_enc, test_data_lab_enc)\n\n#Check if something went wrong with columns until now\nprint(f'Train Data rows: {new_train.shape[0]} \\nTrain Data Columns: {new_train.shape[1]}\\n')\nprint(f'Test Data rows: {new_test.shape[0]} \\nTest Data Columns: {new_test.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:43.819395Z","iopub.execute_input":"2022-02-01T17:21:43.819665Z","iopub.status.idle":"2022-02-01T17:21:43.898245Z","shell.execute_reply.started":"2022-02-01T17:21:43.819634Z","shell.execute_reply":"2022-02-01T17:21:43.897354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"display:fill;\n            border-radius:10px;\n            background-color:#246be3;\n            font-family:Verdana;\n            letter-spacing:1px;\n            border: 2px solid #002a6e; \n            text-align:center;\n            color:white; \n            font-size:120%\">\n\n<h2>Model training<br> üßë‚Äçüè´</h2> </div>","metadata":{}},{"cell_type":"code","source":"new_train.reset_index(inplace = True)\nidx = new_train['Id']\nnew_train = new_train.drop(['Id'], axis = 1)\n\nX = new_train.drop(['SalePrice'], axis = 1)\ny = new_train['SalePrice']\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:43.89986Z","iopub.execute_input":"2022-02-01T17:21:43.900874Z","iopub.status.idle":"2022-02-01T17:21:43.910023Z","shell.execute_reply.started":"2022-02-01T17:21:43.900825Z","shell.execute_reply":"2022-02-01T17:21:43.909325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scaling_feat(train_set, test_set):\n    print(f'Dimensions before scaling: \\ntrain_set: {train_set.shape} \\ntest_set: {test_set.shape}')\n    \n    scaler = StandardScaler()\n\n    train_set_scaled = scaler.fit_transform(train_set)\n    test_set_scaled = scaler.transform(test_set)\n\n    train_set = pd.DataFrame(train_set_scaled, index=train_set.index, columns=train_set.columns)\n    test_set = pd.DataFrame(test_set_scaled, index=test_set.index, columns=test_set.columns)\n    \n    print(f'\\nDimensions after scaling: \\ntrain_set: {train_set.shape} \\ntest_set: {test_set.shape}')\n    \n    return train_set, test_set\n\ntrain_set, test_set = scaling_feat(X, new_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:43.914419Z","iopub.execute_input":"2022-02-01T17:21:43.915268Z","iopub.status.idle":"2022-02-01T17:21:43.970473Z","shell.execute_reply.started":"2022-02-01T17:21:43.915219Z","shell.execute_reply":"2022-02-01T17:21:43.969359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# 3.1 Catboost","metadata":{}},{"cell_type":"code","source":"train_x, validation_x, train_y, validation_y = train_test_split(train_set, \n                                                                y, \n                                                                test_size=0.1,\n                                                                random_state=1505)\n\ntrain_x.columns = train_set.columns\nvalidation_x.columns = train_set.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:21:43.971641Z","iopub.execute_input":"2022-02-01T17:21:43.97185Z","iopub.status.idle":"2022-02-01T17:21:43.987779Z","shell.execute_reply.started":"2022-02-01T17:21:43.971823Z","shell.execute_reply":"2022-02-01T17:21:43.986716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preforming a Grid Search to find the best combination of parameters\n\ngrid = {'iterations': [5000, 10000],\n        'learning_rate': [0.1, 0.05, 0.025],\n        'depth': [2, 3, 6],\n        'l2_leaf_reg': [0.1, 0.25, 0.5]}\n\nfinal_model = CatBoostRegressor(logging_level = 'Silent',\n                                od_type = 'Iter', \n                                od_wait = 100)\n\ngscv = GridSearchCV(estimator = final_model, param_grid = grid, scoring = 'neg_root_mean_squared_error', cv = 5)\n\n# Fitting the model\ngscv.fit(train_x, train_y)\n\n# Estimator with the best performance\nprint(gscv.best_estimator_)\n\n# Best score\nprint(gscv.best_score_)\n\n# Returns the best parameters\nprint(gscv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:29:49.323292Z","iopub.execute_input":"2022-02-01T17:29:49.324261Z","iopub.status.idle":"2022-02-01T18:39:57.640705Z","shell.execute_reply.started":"2022-02-01T17:29:49.324217Z","shell.execute_reply":"2022-02-01T18:39:57.63968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"{'depth': 3, 'iterations': 5000, 'l2_leaf_reg': 0.25, 'learning_rate': 0.025}","metadata":{}},{"cell_type":"code","source":"# Cat-Boost Regressor Validation\nparams = gscv.best_params_\n         \ncat = CatBoostRegressor(**params,\n                        random_seed = 1505)\n\ncat_model = cat.fit(train_x,\n                    train_y,\n                    plot = False,\n                    verbose = False)\n\ncatf_pred = cat_model.predict(validation_x)\ncatf_RMSE_score = mean_squared_error(validation_y, catf_pred, squared = True)\ncatf_RMSE_score","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:42:38.732336Z","iopub.execute_input":"2022-02-01T18:42:38.732639Z","iopub.status.idle":"2022-02-01T18:42:45.984803Z","shell.execute_reply.started":"2022-02-01T18:42:38.7326Z","shell.execute_reply":"2022-02-01T18:42:45.983593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_p = Pool(train_x)\nval_p = Pool(validation_x)\n\nexplainer = shap.TreeExplainer(cat_model) # insert your model\nshap_values = explainer.shap_values(train_p) # insert your train Pool object\n\nshap.initjs()\nshap.summary_plot(shap_values, train_x)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:42:45.986685Z","iopub.execute_input":"2022-02-01T18:42:45.987004Z","iopub.status.idle":"2022-02-01T18:42:47.91776Z","shell.execute_reply.started":"2022-02-01T18:42:45.986962Z","shell.execute_reply":"2022-02-01T18:42:47.916828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test CSV Submission\n\ntest_pred = cat_model.predict(test_set)\nsubmission = pd.DataFrame(test_set.index, columns = ['Id'])\ntest_pred = np.expm1(test_pred)\nsubmission['SalePrice'] = test_pred \nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:42:47.919024Z","iopub.execute_input":"2022-02-01T18:42:47.919325Z","iopub.status.idle":"2022-02-01T18:42:47.960793Z","shell.execute_reply.started":"2022-02-01T18:42:47.919292Z","shell.execute_reply":"2022-02-01T18:42:47.959936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.2 LGBMRegressor alternative model with Optuna ","metadata":{}},{"cell_type":"markdown","source":"```{python}\ndef objective(trial, data = X, target = y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, \n                                                        target, \n                                                        test_size=0.2,\n                                                        random_state=1505)\n   \n    param = {\n        'metric': 'rmse', \n        'random_state': 1505,\n        'n_estimators': 20000,\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n    }\n    \n    est = lgb.early_stopping(1000, first_metric_only=False, verbose=True)\n    logm = lgb.log_evaluation(period=10000, show_stdv=True)\n    \n    model = LGBMRegressor(**param)  \n    model.fit(train_x, \n              train_y,\n              eval_set = [(test_x,test_y)],\n              callbacks = [est, logm])\n    \n    preds = model.predict(test_x)    \n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:53:22.695979Z","iopub.execute_input":"2022-01-28T09:53:22.697032Z","iopub.status.idle":"2022-01-28T09:53:22.71112Z","shell.execute_reply.started":"2022-01-28T09:53:22.696973Z","shell.execute_reply":"2022-01-28T09:53:22.709995Z"}}},{"cell_type":"markdown","source":"```{python}\noptuna.logging.set_verbosity(optuna.logging.ERROR)\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:53:25.819954Z","iopub.execute_input":"2022-01-28T09:53:25.820411Z","iopub.status.idle":"2022-01-28T09:56:39.419276Z","shell.execute_reply.started":"2022-01-28T09:53:25.82036Z","shell.execute_reply":"2022-01-28T09:56:39.418385Z"}}},{"cell_type":"markdown","source":"```{python}\nprint(f\"\\tBest value (rmse): {study.best_value:.5f}\")\nprint(f\"\\tBest params:\")\n\nfor key, value in study.best_params.items():\n    print(f\"\\t\\t{key}: {value}\")\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:56:39.421457Z","iopub.execute_input":"2022-01-28T09:56:39.421758Z","iopub.status.idle":"2022-01-28T09:56:39.429896Z","shell.execute_reply.started":"2022-01-28T09:56:39.421715Z","shell.execute_reply":"2022-01-28T09:56:39.42889Z"}}},{"cell_type":"markdown","source":"```{python}\nparams = study.best_params   \nparams['random_state'] = 1505\nparams['n_estimators'] = 20000 \nparams['metric'] = 'rmse'\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:56:39.431384Z","iopub.execute_input":"2022-01-28T09:56:39.431695Z","iopub.status.idle":"2022-01-28T09:56:39.442397Z","shell.execute_reply.started":"2022-01-28T09:56:39.431656Z","shell.execute_reply":"2022-01-28T09:56:39.441502Z"}}},{"cell_type":"markdown","source":"```{python}\nparams['cat_smooth'] = params.pop('min_data_per_groups')\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:56:39.444569Z","iopub.execute_input":"2022-01-28T09:56:39.444933Z","iopub.status.idle":"2022-01-28T09:56:39.459091Z","shell.execute_reply.started":"2022-01-28T09:56:39.44489Z","shell.execute_reply":"2022-01-28T09:56:39.458246Z"}}},{"cell_type":"markdown","source":"```{python}\npreds = np.zeros(new_test.shape[0])\n\nkf = KFold(n_splits=10,\n                     random_state=1505,\n                     shuffle=True)\n\nrmse=[]  # list contains rmse for each fold\nn=0\n\nest = lgb.early_stopping(500, first_metric_only=False, verbose=True)\nlogm = lgb.log_evaluation(period=5000, show_stdv=True)\n\nfor trn_idx, test_idx in kf.split(X, y):\n    X_tr,X_val=X.iloc[trn_idx],X.iloc[test_idx]\n    y_tr,y_val=y.iloc[trn_idx],y.iloc[test_idx]\n    model = LGBMRegressor(**params)\n    model.fit(X_tr,\n              y_tr,\n              eval_set=[(X_val,y_val)],\n              callbacks = [est, logm])\n    preds+=model.predict(new_test)/kf.n_splits\n    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n    print(n+1,rmse[n])\n    n+=1\n\n```","metadata":{"execution":{"iopub.status.busy":"2022-02-01T09:49:45.53614Z","iopub.execute_input":"2022-02-01T09:49:45.536556Z","iopub.status.idle":"2022-02-01T09:49:45.56767Z","shell.execute_reply.started":"2022-02-01T09:49:45.536429Z","shell.execute_reply":"2022-02-01T09:49:45.566771Z"}}},{"cell_type":"markdown","source":"```{python}\n# Save predictions to file\noutput = pd.DataFrame({'Id': test_set.index,\n                       'SalePrice': np.exp(preds)})\n\n# Check format\noutput.head()\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:57:07.112906Z","iopub.execute_input":"2022-01-28T09:57:07.114968Z","iopub.status.idle":"2022-01-28T09:57:07.128291Z","shell.execute_reply.started":"2022-01-28T09:57:07.114926Z","shell.execute_reply":"2022-01-28T09:57:07.127517Z"}}},{"cell_type":"markdown","source":"```{python}\noutput.to_csv('submission.csv', index=False)\n```","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:57:07.129665Z","iopub.execute_input":"2022-01-28T09:57:07.129956Z","iopub.status.idle":"2022-01-28T09:57:07.143631Z","shell.execute_reply.started":"2022-01-28T09:57:07.129917Z","shell.execute_reply":"2022-01-28T09:57:07.142652Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}