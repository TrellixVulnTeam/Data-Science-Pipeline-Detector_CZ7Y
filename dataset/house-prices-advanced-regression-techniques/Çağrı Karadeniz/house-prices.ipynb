{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-11T05:20:53.48209Z","iopub.execute_input":"2022-01-11T05:20:53.482412Z","iopub.status.idle":"2022-01-11T05:20:53.509634Z","shell.execute_reply.started":"2022-01-11T05:20:53.482324Z","shell.execute_reply":"2022-01-11T05:20:53.508633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport numpy as np\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn import neighbors\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.preprocessing import OrdinalEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nmodels = [LGBMRegressor,\n          XGBRegressor,\n          GradientBoostingRegressor,\n          RandomForestRegressor,\n          DecisionTreeRegressor,\n          MLPRegressor,\n          KNeighborsRegressor,\n          SVR]\nlbe=LabelEncoder()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:21:00.955348Z","iopub.execute_input":"2022-01-11T05:21:00.95562Z","iopub.status.idle":"2022-01-11T05:21:03.328889Z","shell.execute_reply.started":"2022-01-11T05:21:00.95559Z","shell.execute_reply":"2022-01-11T05:21:03.327972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#collecting datas from sql\n\ndf=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\n\ntest=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\ntest2=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")[\"Id\"]\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:42:20.326471Z","iopub.execute_input":"2022-01-11T05:42:20.326748Z","iopub.status.idle":"2022-01-11T05:42:20.402965Z","shell.execute_reply.started":"2022-01-11T05:42:20.326716Z","shell.execute_reply":"2022-01-11T05:42:20.402104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=\"Id\",inplace=True)\ndf.drop(columns=\"MiscFeature\",inplace=True)\ndf.drop(columns=\"Condition2\",inplace=True)\ntest.drop(columns=\"Id\",inplace=True)\ntest.drop(columns=\"MiscFeature\",inplace=True)\ntest.drop(columns=\"Condition2\",inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:42:23.091765Z","iopub.execute_input":"2022-01-11T05:42:23.092577Z","iopub.status.idle":"2022-01-11T05:42:23.107323Z","shell.execute_reply.started":"2022-01-11T05:42:23.092523Z","shell.execute_reply":"2022-01-11T05:42:23.106416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    df[i].fillna(df[i].mode()[0],inplace=True)\nfor i in test.columns:\n    test[i].fillna(test[i].mode()[0],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:42:26.821568Z","iopub.execute_input":"2022-01-11T05:42:26.82184Z","iopub.status.idle":"2022-01-11T05:42:26.880462Z","shell.execute_reply.started":"2022-01-11T05:42:26.821811Z","shell.execute_reply":"2022-01-11T05:42:26.879698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_threshold(data,degisken):\n    Q1=data[degisken].quantile(0.01)\n    Q3=data[degisken].quantile(0.99)\n    Q_Inter_Range=Q3-Q1\n    alt_limit=Q1-1.5*Q_Inter_Range\n    ust_limit=Q3+1.5*Q_Inter_Range\n    return alt_limit,ust_limit\ndef threshold_degisimi(data,degisken):\n    alt_limit,ust_limit=outlier_threshold(data,degisken)\n    data.loc[(data[degisken] < alt_limit), degisken] = alt_limit\n    data.loc[(data[degisken] > ust_limit), degisken] = ust_limit\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:21:21.840461Z","iopub.execute_input":"2022-01-11T05:21:21.840732Z","iopub.status.idle":"2022-01-11T05:21:21.847724Z","shell.execute_reply.started":"2022-01-11T05:21:21.840703Z","shell.execute_reply":"2022-01-11T05:21:21.8471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def degisken_tiplerine_ayirma(data,cat_th,car_th):\n   \"\"\"\n   Veri:data parametresi ili fonksiyona girilen verinin değişkenlerin sınıflandırılması.\n   Parameters\n   ----------\n   data: pandas.DataFrame\n   İşlem yapılacak veri seti\n   cat_th:int\n   categoric değişken threshold değeri\n   car_th:int\n   Cardinal değişkenler için threshold değeri\n   Returns\n   -------\n    cat_deg:list\n    categorik değişken listesi\n    num_deg:list\n    numeric değişken listesi\n    car_deg:list\n    categoric ama cardinal değişken listesi\n   Examples\n   -------\n    df = dataset_yukle(\"breast_cancer\")\n    cat,num,car=degisken_tiplerine_ayirma(df,10,20)\n   Notes\n   -------\n    cat_deg + num_deg + car_deg = toplam değişken sayısı\n   \"\"\"\n\n\n   num_but_cat=[i for i in data.columns if data[i].dtypes !=\"O\" and data[i].nunique() < cat_th]\n\n   car_deg=[i for i in data.columns if data[i].dtypes == \"O\" and data[i].nunique() > car_th]\n\n   num_deg=[i for i in data.columns if data[i].dtypes !=\"O\" and i not in num_but_cat]\n\n   cat_deg = [i for i in data.columns if data[i].dtypes == \"O\" and i not in car_deg]\n\n   cat_deg = cat_deg+num_but_cat\n\n   print(f\"Dataset kolon/değişken sayısı: {data.shape[1]}\")\n   print(f\"Dataset satır/veri sayısı: {data.shape[0]}\")\n   print(\"********************************************\")\n   print(f\"Datasetin numeric değişken sayısı: {len(num_deg)}\")\n   print(f\"Datasetin numeric değişkenler: {num_deg}\")\n   print(\"********************************************\")\n   print(f\"Datasetin categoric değişken sayısı: {len(cat_deg)}\")\n   print(f\"Datasetin categoric değişkenler: {cat_deg}\")\n   print(\"********************************************\")\n   print(f\"Datasetin cardinal değişken sayısı: {len(car_deg)}\")\n   print(f\"Datasetin cardinal değişkenler: {car_deg}\")\n   print(\"********************************************\")\n\n   return cat_deg,num_deg,car_deg","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:21:22.743147Z","iopub.execute_input":"2022-01-11T05:21:22.743951Z","iopub.status.idle":"2022-01-11T05:21:22.754067Z","shell.execute_reply.started":"2022-01-11T05:21:22.743908Z","shell.execute_reply":"2022-01-11T05:21:22.753318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef feature_engineering(train,test,cat_deg,target):\n\n    for i in cat_deg:\n        l=0\n        while True:\n            r=pd.DataFrame(train.groupby(i).mean()[target].index.tolist(),train.groupby(i).mean()[target].values.tolist())\n            r=r.reset_index()\n            r=pd.DataFrame(r)\n            r.columns=[\"a\",\"b\"]\n            sozluk={}\n            for j in r.index:\n                sozluk[r[\"b\"][j]]=r[\"a\"][j]/(10**4)\n            train[i].replace(sozluk,inplace=True)\n            test[i].replace(sozluk, inplace=True)\n            l+=1\n            if l==len(train[i]):\n               break\n    return train,test","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:21:40.020615Z","iopub.execute_input":"2022-01-11T05:21:40.020877Z","iopub.status.idle":"2022-01-11T05:21:40.02995Z","shell.execute_reply.started":"2022-01-11T05:21:40.020849Z","shell.execute_reply":"2022-01-11T05:21:40.029147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:42:34.521626Z","iopub.execute_input":"2022-01-11T05:42:34.521949Z","iopub.status.idle":"2022-01-11T05:42:34.54937Z","shell.execute_reply.started":"2022-01-11T05:42:34.521915Z","shell.execute_reply":"2022-01-11T05:42:34.548456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_deg,num_deg,car_deg=degisken_tiplerine_ayirma(df,10,20)\ncat_deg=[i for i in cat_deg if i !=\"SalePrice\"]\ndata,test=feature_engineering(df,test,cat_deg+car_deg,\"SalePrice\")","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:22:01.654636Z","iopub.execute_input":"2022-01-11T05:22:01.655075Z","iopub.status.idle":"2022-01-11T05:30:23.658214Z","shell.execute_reply.started":"2022-01-11T05:22:01.65502Z","shell.execute_reply":"2022-01-11T05:30:23.657344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in data.columns:\n    data=threshold_degisimi(data,i)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Deleting Outliers\nclf = LocalOutlierFactor(n_neighbors = 20, contamination = 0.1)\nclf.fit_predict(data)\ndf_scores = clf.negative_outlier_factor_\nprint(np.sort(df_scores)[0:20])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T19:40:00.520555Z","iopub.execute_input":"2021-11-29T19:40:00.520891Z","iopub.status.idle":"2021-11-29T19:40:00.594399Z","shell.execute_reply.started":"2021-11-29T19:40:00.520857Z","shell.execute_reply":"2021-11-29T19:40:00.593513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"esik_deger = np.sort(df_scores)[6]\naykiri_tf = df_scores > esik_deger\ndata=data[df_scores>esik_deger]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T19:40:01.509409Z","iopub.execute_input":"2021-11-29T19:40:01.509976Z","iopub.status.idle":"2021-11-29T19:40:01.516617Z","shell.execute_reply.started":"2021-11-29T19:40:01.509931Z","shell.execute_reply":"2021-11-29T19:40:01.515907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"af=[]\naf=pd.DataFrame(af)\n\n#comparing models eachother\ndef model_olusturma(dff,model,af):\n    X = dff.drop(columns=\"SalePrice\")\n    X=scale(X)\n    y = dff[\"SalePrice\"]\n    y= np.log1p(y)\n\n    X_train, X_test, y_train, y_test = train_test_split(X,\n                                                        y,\n                                                        test_size=0.15,\n                                                        random_state=42)\n\n    Model=model().fit(X_train,y_train)\n    y_pred=Model.predict(X_test)\n    y_pred=np.expm1(y_pred)\n    y_test=np.expm1(y_test)\n    hata_score=np.sqrt(mean_squared_error(y_test,y_pred))\n    af[\"y_test\"] = y_test\n    af[\"\"+str(model)+\"\"]=y_pred\n    print(str(model),\"Hata değeri :\",hata_score)\n    return hata_score,af,df","metadata":{"execution":{"iopub.status.busy":"2021-11-29T19:40:05.547083Z","iopub.execute_input":"2021-11-29T19:40:05.548037Z","iopub.status.idle":"2021-11-29T19:40:05.55757Z","shell.execute_reply.started":"2021-11-29T19:40:05.547981Z","shell.execute_reply":"2021-11-29T19:40:05.556276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in models:\n    model_olusturma(data,i,af)\n    result = af.astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T19:40:07.818357Z","iopub.execute_input":"2021-11-29T19:40:07.819233Z","iopub.status.idle":"2021-11-29T19:40:13.752753Z","shell.execute_reply.started":"2021-11-29T19:40:07.819193Z","shell.execute_reply":"2021-11-29T19:40:13.751959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.drop(columns=\"SalePrice\")\nX=scale(X)\ny = data[\"SalePrice\"]\ny= np.log1p(y)\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                        y,\n                                                        test_size=0.15,\n                                                        random_state=42)\n\ngbm_model = GradientBoostingRegressor().fit(X_train, y_train)\ngbm_tuned = GradientBoostingRegressor(learning_rate = 0.1,\n                                     loss = \"lad\",\n                                     max_depth = 3,\n                                     n_estimators = 420,\n                                     subsample = 0.5).fit(X_train, y_train)\nresult[\"gbm_tuned\"]=result.y_test\ny_test = np.expm1(y_test)\ny_train = np.expm1(y_train)\n#result.gbm_tuned=gbm_tuned.predict(X_test)\n#print(np.sqrt(mean_squared_error(y_test, gbm_tuned.predict(X_test))),np.sqrt(mean_squared_log_error( y_test, gbm_tuned.predict(X_test) )))\nprint(np.sqrt(mean_squared_error(y_test, np.expm1(gbm_tuned.predict(X_test)))),np.sqrt(mean_squared_log_error( y_test, np.expm1(gbm_tuned.predict(X_test)) )))\n\ntest1=scale(test)\nson=np.expm1(gbm_tuned.predict(test1))\nson=pd.DataFrame(son)\nson.rename(columns={0:\"SalePrice\"},inplace=True)\nson_sonuc=pd.concat([test2,son],axis=1)\nson_sonuc.to_csv(\"submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}