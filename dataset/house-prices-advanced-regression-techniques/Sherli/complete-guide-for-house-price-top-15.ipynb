{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Housing Sales Price Prediction using Advanced Regression techniques","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LassoCV\nfrom sklearn import metrics \nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nimport numpy as np # linear algebra\nimport pandas as pd\n\nmin_val_corr = 0.4 ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntest_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Id = test_df['Id']\n\ntrain_df.drop('Id', axis=1, inplace=True)\ntest_df.drop('Id', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split the numeric and categorical data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"dataframe.dtypes.index - dtype. Pandas Index is an immutable ndarray implementing an ordered, sliceable set. It is the basic object which stores the axis labels for all pandas objects.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#train_category = train_df.dtypes[train_df.dtypes == \"object\"].index\n#test_numeric = test_df.dtypes[test_df.dtypes != \"object\"].index\n#test_category = test_df.dtypes[test_df.dtypes == \"object\"].index\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#train_df[train_numeric].columns\n#test_df[test_numeric].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#train_df[train_category].columns\n#test_df[train_category].columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Skew and Kurtosis of SalesPrice. Visualization of Sales Price through Distplot and Probplot**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Skewness: %f\" % train_df['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train_df['SalePrice'].kurt())\n\nfigure = plt.figure(figsize=(18,10))\nplt.subplot(1,2,1)\nsns.distplot(train_df['SalePrice'] , fit=norm);\n(mu, sigma) = norm.fit(train_df['SalePrice'])\nplt.ylabel('Frequency')\nplt.title('SalePrice Distribution')\n\nplt.subplot(1,2,2)\nstats.probplot(train_df['SalePrice'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sales price is right skewed. The reasons for right skewed predictive variable : Mean greater than mode, median greater than mode, Mean greater than median. This eventually affects the performance. So we Log transform the SalesPrice with np.log1p","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['SalePrice'] = np.log1p(train_df['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print out Skewness and Kurtosis\nprint(\"Skewness: %f\" % train_df['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train_df['SalePrice'].kurt())\n\nfigure = plt.figure(figsize=(18,10))\nplt.subplot(1,2,1)\nsns.distplot(train_df['SalePrice'] , fit=norm);\n(mu, sigma) = norm.fit(train_df['SalePrice'])\nplt.ylabel('Frequency')\nplt.title('SalePrice Distribution')\n\nplt.subplot(1,2,2)\nstats.probplot(train_df['SalePrice'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = train_df.select_dtypes(exclude='object').drop(['SalePrice'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outlier Detection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Univariate Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,20))\n\nfor i in range(len(num_features.columns)):\n    fig.add_subplot(9, 5, i+1)\n    sns.boxplot(y=num_features.iloc[:,i])\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bivariate Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,18))\nfor i in range(len(num_features.columns)):\n    fig.add_subplot(9, 5, i+1)\n    sns.scatterplot(num_features.iloc[:, i],train_df['SalePrice'])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = plt.figure(figsize=(15,15))\nax1 = plt.subplot2grid((3,2),(0,0))\nplt.scatter(x=train_df['GrLivArea'], y=train_df['SalePrice'], color=('yellowgreen'), alpha=0.5)\nplt.axvline(x=4600, color='r', linestyle='-')\nplt.title('Ground living Area- Price scatter plot', fontsize=15, weight='bold' )\n\nax1 = plt.subplot2grid((3,2),(0,1))\nplt.scatter(x=train_df['TotalBsmtSF'], y=train_df['SalePrice'], color=('red'),alpha=0.5)\nplt.axvline(x=5900, color='r', linestyle='-')\nplt.title('Basement Area - Price scatter plot', fontsize=15, weight='bold' )\n\nax1 = plt.subplot2grid((3,2),(1,0))\nplt.scatter(x=train_df['1stFlrSF'], y=train_df['SalePrice'], color=('deepskyblue'),alpha=0.5)\nplt.axvline(x=4000, color='r', linestyle='-')\nplt.title('First floor Area - Price scatter plot', fontsize=15, weight='bold' )\n\nax1 = plt.subplot2grid((3,2),(1,1))\nplt.scatter(x=train_df['MasVnrArea'], y=train_df['SalePrice'], color=('gold'),alpha=0.9)\nplt.axvline(x=1500, color='r', linestyle='-')\nplt.title('Masonry veneer Area - Price scatter plot', fontsize=15, weight='bold' )\n\nax1 = plt.subplot2grid((3,2),(2,0))\nplt.scatter(x=train_df['GarageArea'], y=train_df['SalePrice'], color=('orchid'),alpha=0.5)\nplt.axvline(x=1230, color='r', linestyle='-')\nplt.title('Garage Area - Price scatter plot', fontsize=15, weight='bold' )\n\nax1 = plt.subplot2grid((3,2),(2,1))\nplt.scatter(x=train_df['TotRmsAbvGrd'], y=train_df['SalePrice'], color=('tan'),alpha=0.9)\nplt.axvline(x=13, color='r', linestyle='-')\nplt.title('TotRmsAbvGrd - Price scatter plot', fontsize=15, weight='bold' )\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing Outliers**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\npos = [1298,523,297]\ntrain_df.drop(train_df.index[pos], inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing Values Imputation**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Combining train and test data in order to make imputing missing values easier, locating missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save target value for later\ny = train_df.SalePrice.values\n\n# In order to make imputing easier, we combine train and test data\ntrain_df.drop(['SalePrice'], axis=1, inplace=True)\ndataset = pd.concat((train_df, test_df)).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the total and percentage of missing values in dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = dataset.isnull().sum().sort_values(ascending=False)\ntotal = dataset.isnull().count().sort_values(ascending=False)\npercent = (dataset.isnull().sum() / dataset.isnull().count()).sort_values(ascending=False)\nMissing_values = pd.concat([missing,percent], axis=1, keys=['Missing','Percent'])\nMissing_values.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing values Imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\nmissing.plot(kind='bar',figsize=(20,8))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[missing.index].dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Numeric variables Imputation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC', 'MSSubClass'):\n    dataset[col] = dataset[col].fillna('None')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The reason we fill in these features with their mode (most common value) is because these features are mandatory in a house, meaning that if these values are missing it has to be because of the data, not because of the fact that the house is missing the feature.\nEx: For the 'Electrical' feature we fill in the most common value because every house has electricity, therefore it wouldn't make sense for there to be any missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'Functional', 'MSZoning', 'SaleType', 'Utilities'):\n    dataset[col] = dataset[col].fillna(dataset[col].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing Garage-Related Features which are numerical with 0 and 'None' for categorical\n\nA Garage-Related Feature with a missing value usually indicates there is no Garage","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    dataset[col] = dataset[col].fillna(0)\n    \nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    dataset[col] = dataset[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Impute Basement related features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    dataset[col] = dataset[col].fillna(0)\n\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    dataset[col] = dataset[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()[dataset.isnull().sum() > 0].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two features related to MasVnr that have missing values: 'MasVnrType' and 'MasVnrArea'.\n'MasVnrType' is a categorical feature that we need to impute with 'None'\n'MasVnrArea' is a categorical feature that we need to impute with 'MasVnrType'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['MasVnrType'] = dataset['MasVnrType'].fillna('None')\ndataset['MasVnrArea'] = dataset['MasVnrArea'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing LotFrontage with median based on 'Neighborhood'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# LotFrontage is correlated to the 'Neighborhood' feature because the LotFrontage for nearby houses will be really similar, so we fill in missing values by the median based off of Neighborhood\ndataset[\"LotFrontage\"] = dataset.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Changing Types\n* Create 'TotalSF' Feature\n* Create 'TotalBath' Feature\n* Create 'YrBuiltAndRemod' Feature\n* Create 'PorchSF' Feature\n* Creating Extra Features\n* Label Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list(dataset.select_dtypes(exclude='object').columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Change Datatypes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features 'MSSubClass', 'YrSold', 'OverallCond' and 'MoSold' are supposed to be categorical features so change their type\ndataset['MSSubClass'] = dataset['MSSubClass'].apply(str)\ndataset['YrSold'] = dataset['YrSold'].apply(str)\ndataset['MoSold'] = dataset['MoSold'].apply(str)\ndataset['OverallCond'] = dataset['OverallCond'].astype(str)\n\n# Features 'LotArea' and 'MasVnrArea' are supposed to be numerical features so change their type\ndataset['LotArea'] = dataset['LotArea'].astype(np.int64)\ndataset['MasVnrArea'] = dataset['MasVnrArea'].astype(np.int64)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create 'TotalSF' Feature**\n\nVisualize 'TotalBsmtSF' and '2ndFlrSF' and them together, Create 'TotalSF' for total surface area with those features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, (ax1, ax2, ax3,ax4) = plt.subplots(nrows=1, ncols=4)\nfigure.set_size_inches(20,10)\n_ = sns.regplot(train_df['TotalBsmtSF'], y, ax=ax1)\n_ = sns.regplot(train_df['1stFlrSF'], y, ax=ax2)\n_ = sns.regplot(train_df['2ndFlrSF'], y, ax=ax3)\n_ = sns.regplot(train_df['TotalBsmtSF'] + train_df['2ndFlrSF']+train_df['1stFlrSF'], y, ax=ax4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create 'TotalBath' Feature**\n\nVisualize 'BsmtFullBath', 'FullBath', 'BsmtHalfBath' and them together, Create 'TotalBath' for total number of bathrooms using those features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['TotalSF']=dataset['TotalBsmtSF']  + dataset['1stFlrSF'] + dataset['2ndFlrSF']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create TotalBath Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\nfigure.set_size_inches(14,10)\n_ = sns.barplot(train_df['BsmtFullBath'], y, ax=ax1)\n_ = sns.barplot(train_df['FullBath'], y, ax=ax2)\n_ = sns.barplot(train_df['BsmtHalfBath'], y, ax=ax3)\n_ = sns.barplot(train_df['BsmtFullBath'] + train_df['FullBath'] + train_df['BsmtHalfBath'] + train_df['HalfBath'], y, ax=ax4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['TotalBath']=dataset['BsmtFullBath'] + dataset['FullBath'] + (0.5*dataset['BsmtHalfBath']) + (0.5*dataset['HalfBath'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create 'YrBuiltAndRemod' Feature**\n\nVisualize 'YearBuilt', 'YearRemodAdd', and them together, Create 'YrBltAndRemod' for Year Built and Year remodel combined using those features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\nfigure.set_size_inches(18,8)\n_ = sns.regplot(train_df['YearBuilt'], y, ax=ax1)\n_ = sns.regplot(train_df['YearRemodAdd'],y, ax=ax2)\n_ = sns.regplot((train_df['YearBuilt']+train_df['YearRemodAdd'])/2, y, ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['YrBltAndRemod']=dataset['YearBuilt']+dataset['YearRemodAdd']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create 'PorchSF' Feature**\n\nVisualize 'OpenPorchSF', '3SsnPorch', 'EnclosedPorch', 'ScreenPorch', 'WoodDeckSF' and them together, Create 'Porch_SF' for total porch surface using those features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3)\nfigure.set_size_inches(20,10)\n_ = sns.regplot(train_df['OpenPorchSF'], y, ax=ax1)\n_ = sns.regplot(train_df['3SsnPorch'], y, ax=ax2)\n_ = sns.regplot(train_df['EnclosedPorch'], y, ax=ax3)\n_ = sns.regplot(train_df['ScreenPorch'], y, ax=ax4)\n_ = sns.regplot(train_df['WoodDeckSF'], y, ax=ax5)\n_ = sns.regplot((train_df['OpenPorchSF']+train_df['3SsnPorch']+train_df['EnclosedPorch']+train_df['ScreenPorch']+train_df['WoodDeckSF']), y, ax=ax6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Porch_SF'] = (dataset['OpenPorchSF'] + dataset['3SsnPorch'] + dataset['EnclosedPorch'] + dataset['ScreenPorch'] + dataset['WoodDeckSF'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating Extra Features**\n\nCreating useful extra features in order to strongly distinct data\n\nEx: 'Has2ndfloor' feature below indicates whether there is a 2ndfloor or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Has2ndfloor'] = dataset['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndataset['HasBsmt'] = dataset['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ndataset['HasFirePlace'] =dataset['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ndataset['Has2ndFlr']=dataset['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndataset['HasPool']=dataset['PoolArea'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Label Encoding**\n\nOur dataset cannot run with categorical columns so we must Label Encode these columns in order to make them numerical.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncategorical_col = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor col in categorical_col:\n    label = LabelEncoder() \n    label.fit(list(dataset[col].values)) \n    dataset[col] = label.transform(list(dataset[col].values))\n\nprint('Shape all_data: {}'.format(dataset.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **High Skewed Features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = dataset.dtypes[dataset.dtypes != 'object'].index\nskewed_features = dataset[num_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_features})\nskewness.head(15)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Skew Visualization**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_dataset = dataset.select_dtypes(exclude='object')\n\nfor i in range(len(numerical_dataset.columns)):\n    f, ax = plt.subplots(figsize=(7, 4))\n    fig = sns.distplot(numerical_dataset.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n    plt.xlabel(numerical_dataset.columns[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Perform BoxCox Transformation on skewed features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness = skewed_features[abs(skewed_features) > 0.75]\nskewed_features = skewness.index\n\nlam = 0.15\nfor i in skewed_features:\n    dataset[i] = boxcox1p(dataset[i], lam)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error , make_scorer\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.kernel_ridge import KernelRidge\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Preparation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hot-Encode Categorical features\ndataset = pd.get_dummies(dataset) \n\n# Splitting dataset back into X and test data\nX = dataset[:len(train_df)]\ntest = dataset[len(train_df):]\n\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split the data into train and validation set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Models Used\n\n1. Lassocv\n2. Ridge\n3. ElasticNet\n4. LightGBM\n5. XGBoost\n6. CATBoost\n7. Stacked","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Parameters**\n\n'kfolds' is used for cross validation, the list type variables are for the models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Indicate number of folds for cross validation\nkfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Parameters for models\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [0.00005, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lasso Regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lasso Model\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas = alphas2, random_state = 42, cv=kfolds))\n\n# Printing Lasso Score with Cross-Validation\nlasso_score = cross_val_score(lasso, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlasso_rmse = np.sqrt(-lasso_score.mean())\nprint(\"LASSO RMSE: \", lasso_rmse)\nprint(\"LASSO STD: \", lasso_score.std())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nlasso.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ridge Regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge = make_pipeline(RobustScaler(), RidgeCV(alphas = alphas_alt, cv=kfolds))\nridge_score = cross_val_score(ridge, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nridge_rmse =  np.sqrt(-ridge_score.mean())\n# Printing out Ridge Score and STD\nprint(\"RIDGE RMSE: \", ridge_rmse)\nprint(\"RIDGE STD: \", ridge_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nridge.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ElasticNet**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\nelastic_score = cross_val_score(elasticnet, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nelastic_rmse =  np.sqrt(-elastic_score.mean())\n\n# Printing out ElasticNet Score and STD\nprint(\"ELASTICNET RMSE: \", elastic_rmse)\nprint(\"ELASTICNET STD: \", elastic_score.std())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nelasticnet.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LightGBM**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lightgbm = make_pipeline(RobustScaler(),\n                        LGBMRegressor(objective='regression',num_leaves=5,\n                                      learning_rate=0.05, n_estimators=720,\n                                      max_bin = 55, bagging_fraction = 0.8,\n                                      bagging_freq = 5, feature_fraction = 0.2319,\n                                      feature_fraction_seed=9, bagging_seed=9,\n                                      min_data_in_leaf =6, \n                                      min_sum_hessian_in_leaf = 11))\n\n# Printing out LightGBM Score and STD\nlightgbm_score = cross_val_score(lightgbm, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlightgbm_rmse = np.sqrt(-lightgbm_score.mean())\nprint(\"LIGHTGBM RMSE: \", lightgbm_rmse)\nprint(\"LIGHTGBM STD: \", lightgbm_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nlightgbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost = make_pipeline(RobustScaler(),\n                        XGBRegressor(learning_rate =0.01, n_estimators=3460, \n                                     max_depth=3,min_child_weight=0 ,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,nthread=4,\n                                     scale_pos_weight=1,seed=27, \n                                     reg_alpha=0.00006))\n\n# Printing out XGBOOST Score and STD\nxgboost_score = cross_val_score(xgboost, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nxgboost_rmse = np.sqrt(-xgboost_score.mean())\nprint(\"XGBOOST RMSE: \", xgboost_rmse)\nprint(\"XGBOOST STD: \", xgboost_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nxgboost.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Stacked**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, \n                                            xgboost, lightgbm), \n                               meta_regressor=xgboost,\n                               use_features_in_secondary=True)\n\nstack_score = cross_val_score(stack_gen, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nstack_rmse = np.sqrt(-stack_score.mean())\nprint(\"STACK RMSE: \", stack_rmse)\nprint(\"STACK STD: \", stack_score.std())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Model for later\nstack_gen.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**View Model Performance**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'Model':['Lasso',\n            'Ridge',\n            'ElasticNet',\n            'LightGBM',\n            'XGBOOST',\n            'STACK'],\n    'Score':[lasso_rmse,\n             ridge_rmse,\n             elastic_rmse,\n             lightgbm_rmse,\n             xgboost_rmse,\n             stack_rmse\n            ]})\n\nsorted_result = results.sort_values(by='Score', ascending=True).reset_index(drop=True)\nsorted_result\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(14,8))\nplt.xticks(rotation='90')\nsns.barplot(x=sorted_result['Model'], y=sorted_result['Score'])\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Performance', fontsize=15)\nplt.ylim(0.10, 0.12)\nplt.title('RMSE', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stacking\n\nPredict every model, then combine every prediction into a final predictions used for submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict every model\nlasso_pred = lasso.predict(test)\nridge_pred = ridge.predict(test)\nelasticnet_pred = elasticnet.predict(test)\nlightgbm_pred = lightgbm.predict(test)\nxgboost_pred = xgboost.predict(test)\nstacked_pred = stack_gen.predict(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stacking: At this point we basically trained and predicted each model so we can combine its predictions into a 'final_predictions' variable for submission.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine predictions into final predictions\nfinal_predictions = np.expm1((0.2*elasticnet_pred) + (0.2*lasso_pred) + (0.2*ridge_pred) + \n               (0.1*xgboost_pred) + (0.1*lightgbm_pred) + (0.2*stacked_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submission**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['Id'] = test_Id\nsubmission['SalePrice'] = final_predictions\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}