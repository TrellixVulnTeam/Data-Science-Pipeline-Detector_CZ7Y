{"cells":[{"metadata":{"_uuid":"a1a7df56b031eba36694baaf214f89c68af8a11e"},"cell_type":"markdown","source":"# 定义问题"},{"metadata":{"_uuid":"4d1f146f26b5633489effb9b59b070cbb66af4c3"},"cell_type":"markdown","source":"* Kaggle描述： It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. \n\n预测房价 79个特征的数据集"},{"metadata":{"_uuid":"81291c776d83cbba0ac72a6d8e4a9a28f2135174"},"cell_type":"markdown","source":"# 获取数据"},{"metadata":{"_uuid":"efa26b2cc0e3dcd6cf153f67c076cd1d6d639b31"},"cell_type":"markdown","source":"Kaggle:https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"},{"metadata":{"_uuid":"5f7b5e0a6a71fe8a3d83f446828e853ae4fd9537"},"cell_type":"markdown","source":"# 数据预处理"},{"metadata":{"_uuid":"2cc41b5edc87dd1840a36e5fe26fe8965dc2d427"},"cell_type":"markdown","source":"## 导入环境库"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"be59f31f1215340832c8ee7df56bc250b3660300"},"cell_type":"code","source":"#load packages， 打印，便于可复现\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". format(sys.version))\n\nimport pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\nprint(\"pandas version: {}\". format(pd.__version__))\n\nimport matplotlib #collection of functions for scientific and publication-ready visualization\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\n\nimport numpy as np #foundational package for scientific computing\nprint(\"NumPy version: {}\". format(np.__version__))\n\nimport scipy as sp #collection of functions for scientific computing and advance mathematics\nprint(\"SciPy version: {}\". format(sp.__version__)) \n\nimport IPython\nfrom IPython import display #pretty printing of dataframes in Jupyter notebook\nprint(\"IPython version: {}\". format(IPython.__version__)) \n\nimport sklearn #collection of machine learning algorithms\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\n#misc libraries\nimport random\nimport time\n\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('-'*25)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90229b4a6f7eed39d1e5197c47b35d4c71a3a21c"},"cell_type":"markdown","source":"## 导入数据模型与可视化库"},{"metadata":{"trusted":true,"_uuid":"c124e6d452e95aecede08a12b9da6546807b1603"},"cell_type":"code","source":"#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fca6866d1ab0b3d463e34714a95d411a0756b19"},"cell_type":"markdown","source":"## 载入总览数据"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"875fc6ef32f1e419c01142745e97bdb3e11b5db9"},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\n'''\n预测SalePrice的值\n'''\n\n# train_df.columns \n# train_df.shape\ntrain_df.describe()\n# train_df.info()\n# print '%' * 40\n# test_df.info()\n# train_df.head(10)\n# train_df.info()\n# print train_df.describe(include = 'all')\n# print '%' * 40\n# test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77ce8f389724c89b510d7a9f0709ab81c59bbe64"},"cell_type":"markdown","source":"## 数据4C分析"},{"metadata":{"_uuid":"377ad1d5e16109824d8393e6a94345de9887ada8"},"cell_type":"markdown","source":"数据的：\n\n正确性：Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs.异常值\n\n完整性：NULL / NAN。删除/补全\n\n创造性：Feature engineering is when we use existing features to create new features to determine if they provide new signals to predict our outcome. For this dataset, we will create a title feature to determine if it played a role in survival.\n\n转变：类别数据 -> 独热编码"},{"metadata":{"_uuid":"858b7f9aa9afdd3e17aea41f29859fb4e81c034f"},"cell_type":"markdown","source":"### 【完整性】 (缺失值)"},{"metadata":{"_uuid":"7141dd4eaf906d12740dd68d8f8e38f19daca5c0"},"cell_type":"markdown","source":"https://discuss.analyticsvidhya.com/t/what-should-be-the-allowed-percentage-of-missing-values/2456\n\nI：允许的missing values的数目，先定25%"},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"c016415f5415037a98d80c150f33c49b6c0278eb"},"cell_type":"code","source":"# # Missing Data的百分比\n# total = train_df.isnull().sum().sort_values(ascending=False)\n# percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n# missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n# # print missing_data.head(20)\n\n# total2 = test_df.isnull().sum().sort_values(ascending=False)\n# percent2 = (test_df.isnull().sum()/test_df.isnull().count()).sort_values(ascending=False)\n# missing_data2 = pd.concat([total2, percent2], axis=1, keys=['Total', 'Percent'])\n# # print missing_data2.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2be00bbe4665dc836205441304795b215d063d9"},"cell_type":"code","source":"train_df.describe(include = 'all')\nprint ('%' * 40)\n\n# print train_df.loc[:,'MasVnrType']\n\n# train_df['MasVnrType'] = train_df['MasVnrType'].replace(['None'],None )\n# train_df.loc[:,'MasVnrType'] =  train_df['MasVnrType'].apply(lambda x: None if x == 'None' else x)\n# print type(train_df.loc[1,'MasVnrType'])\n\nlimit_missing_values = 0.25\ntrain_limit_missing_values = len(train_df) * limit_missing_values \nprint (\"Train columns with null values:\\n\", train_df.columns[train_df.isnull().sum().values > train_limit_missing_values])  # 依列为标准，column\nprint ('%'*40)\n\ntest_limit_missing_values = len(test_df) * limit_missing_values\nprint (\"Test columns with null values:\\n\", test_df.columns[test_df.isnull().sum().values > test_limit_missing_values])\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dadb1a37d013b5a8df08b4f2b64d850c9f1e5121"},"cell_type":"markdown","source":"丢弃过多空数据的列\n\n部分类别数据中的NA非未计数/计数误差，而是无（地下室，游泳池🏊等，填充字符串“None”）"},{"metadata":{"_uuid":"aa918630983aa834fafe43cc5090226efb9e52f8"},"cell_type":"markdown","source":"### 确定缺失列"},{"metadata":{"trusted":true,"_uuid":"f693f61a7a10b4a16e126332e8cfa228c36cad83"},"cell_type":"code","source":"missing_columns = list(train_df.columns[train_df.isnull().sum() != 0])\nprint (missing_columns)\n# train_df[missing_columns].describe(include = 'all')\nprint ('%' * 40)\ntest_missing_columns = list(test_df.columns[test_df.isnull().sum() != 0])\nprint (test_missing_columns)","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[],"trusted":true,"_uuid":"a462690ab1cba7d9a0977d326daed607a1b04c1d"},"cell_type":"code","source":"train_missing_numerical = list(train_df[missing_columns].dtypes[train_df[missing_columns].dtypes != 'object'].index)\ntrain_missing_category = [i for i in missing_columns if i not in train_missing_numerical]\n\ntest_missing_numerical = list(test_df[test_missing_columns].dtypes[test_df[test_missing_columns].dtypes != 'object'].index)\ntest_missing_category = [i for i in test_missing_columns if i not in test_missing_numerical]\n\nprint (\"Train missing numerical: \", train_missing_numerical, \"\\n\")\nprint (\"Train missing category: \", train_missing_category,  \"\\n\")\nprint (\"Test missing numerical: \", test_missing_numerical, \"\\n\")\nprint (\"Test missing category: \", test_missing_category, \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d6f2af9bd19b6bf601c9e850118e86ef19bc6e9"},"cell_type":"markdown","source":"### 类别特征缺失值填充"},{"metadata":{"trusted":true,"_uuid":"a68ec8308ebfac8dce09aec1723fa91f36d513c3"},"cell_type":"code","source":"# 取众数的特征\ntrain_categories_Mode = ['Electrical']\ntest_categories_Mode = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'KitchenQual', 'Functional', 'SaleType']\n\ntrain_categories_none = [i for i in train_missing_category if i not in train_categories_Mode]\ntest_categories_none = [i for i in test_missing_category if i not in test_categories_Mode]\n\n\n# 通过字符串“None”填充 \nfor category in train_categories_none:\n    train_df[category].fillna(\"None\", inplace=True)\n    \nfor category in test_categories_none:\n    test_df[category].fillna(\"None\", inplace=True)\n    \nfor category in train_categories_Mode:\n    train_df[category].fillna(train_df[category].mode()[0], inplace = True)\n\nfor category in test_categories_Mode:\n    test_df[category].fillna(test_df[category].mode()[0], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dc1f5b2762ef6eaa4ce8f7286bdd8d4b50d09b9"},"cell_type":"markdown","source":"### 数值特征缺失值填充"},{"metadata":{"trusted":true,"_uuid":"fd8209834977344003d9e3ac21660f37f2e528a1"},"cell_type":"code","source":"# 取0的数值特征\n\nfor col in ('GarageArea', 'GarageCars', 'GarageYrBlt'):\n    train_df[col] = train_df[col].fillna(0)\n    test_df[col] = test_df[col].fillna(0)\n    \nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    train_df[col] = train_df[col].fillna(0)\n    test_df[col] = test_df[col].fillna(0)\n    \n# 通过中位数填充\nfor column in train_missing_numerical:\n    train_df[column].fillna(train_df[column].median(), inplace=True)\n\nfor column in test_missing_numerical:\n    test_df[column].fillna(test_df[column].median(), inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e5ee94165723ced460133b07000c5505ab42af9"},"cell_type":"code","source":"print (train_df.isnull().sum().max())\nprint (test_df.isnull().sum().max())\n# print test_df.loc[test_df.isnull()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fef2178e4853ce43136c306d81c80d31cf63ba4"},"cell_type":"markdown","source":"# 探索性数据分析 EDA"},{"metadata":{"_uuid":"7f0d6a3db09c6da586962707623424e30e94c257"},"cell_type":"markdown","source":"感谢： https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python 提出的对数据进行探索的方法"},{"metadata":{"_uuid":"fba183a36d051ec44f13ecd081d2a87df177e8b4"},"cell_type":"markdown","source":"### 目标"},{"metadata":{"collapsed":true,"_uuid":"4f090517c8dac45cbd60e5e43dce7da3da616135"},"cell_type":"markdown","source":"1、In order to have some discipline in our analysis, we can create an Excel spreadsheet with the following columns:\n\n* <b>Variable</b> - Variable name.\n* <b>Type</b> -  There are two possible values for this field: 'numerical' or 'categorical'. \n* <b>Segment</b> - Identification of the variables' segment. We can define three possible segments: building, space or location. When we say 'building', we mean a variable that relates to the physical characteristics of the building (e.g. 'OverallQual'). When we say 'space', we mean a variable that reports space properties of the house (e.g. 'TotalBsmtSF'). Finally, when we say a 'location', we mean a variable that gives information about the place where the house is located (e.g. 'Neighborhood').\n* <b>Expectation</b> - Our expectation about the variable influence in 'SalePrice'. We can use a categorical scale with 'High', 'Medium' and 'Low' as possible values.\n    \n    重要，一一个一个阅读特征描述。是否影响我们购买房屋 -> 如果是，影响重要性？ -> 信息是否早已在其他变量中包含\n* <b>Conclusion</b> - Our conclusions about the importance of the variable, after we give a quick look at the data. We can keep with the same categorical scale as in 'Expectation'.\n* <b>Comments</b> - Any general comments that occured to us.\n"},{"metadata":{"_uuid":"9c1226a697ee8a4f04d301081acc6f70ef68da90"},"cell_type":"markdown","source":"2、we can filter the spreadsheet and look carefully to the variables with 'High' 'Expectation'. Then, we can rush into some scatter plots between those variables and 'SalePrice', filling in the 'Conclusion' column which is just the correction of our expectations."},{"metadata":{"scrolled":true,"_uuid":"8a3cc9fba620fa3f51baa8971adcdfc73ee13030"},"cell_type":"markdown","source":"### 目标数据的【身材】 SalePrice （单变量分布）"},{"metadata":{"_uuid":"22a9bb8b75282013eabcfe1a0aee1dd9a8bbb504"},"cell_type":"markdown","source":"*Everything started in our Kaggle party, when we were looking for a dance partner. After a while searching in the dance floor, we saw a girl, near the bar, using dance shoes. That's a sign that she's there to dance. We spend much time doing predictive modelling and participating in analytics competitions, so talking with girls is not one of our super powers. Even so, we gave it a try:*\n\n*'Hi, I'm Kaggly! And you? 'SalePrice'? What a beautiful name! You know 'SalePrice', could you give me some data about you? I just developed a model to calculate the probability of a successful relationship between two people. I'd like to apply it to us!'*"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"c408d897f9d95fa708030acae53d03f42e82b2c8"},"cell_type":"code","source":"train_df['SalePrice'].describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"3a9bb29ee9434a58958f73b814d27d7a64b4f509"},"cell_type":"code","source":"sns.distplot(train_df['SalePrice'], color='green')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bd2cda3919f78b9797bc48a9b917108c8d4dd30"},"cell_type":"markdown","source":"* <b> 正偏态分布 </b> 数据主要集中在10w ~ 25w之间"},{"metadata":{"trusted":true,"_uuid":"08b3a8504503407e8322cde69ab30d98cdc966e9"},"cell_type":"code","source":"print (\"偏度为 %f \" % train_df['SalePrice'].skew())\nprint (\"峰度为 %f\"  % train_df['SalePrice'].kurt())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3826df322e88770456bb89c8bfb8ecfecdeb0c61"},"cell_type":"markdown","source":"### 目标数据的Buddies and interests  （两个变量之间的关系）"},{"metadata":{"_uuid":"f1ca8b19e19a516cce080d74918d4390c211e3a0"},"cell_type":"markdown","source":"As soon as 'SalePrice' walked away, we went to Facebook. Yes, now this is getting serious. Notice that this is not stalking. It's just an intense research of an individual, if you know what I mean.\n\nAccording to her profile, we have some common friends. Besides Chuck Norris, we both know 'GrLivArea' and 'TotalBsmtSF'. Moreover, we also have common interests such as 'OverallQual' and 'YearBuilt'. This looks promising!\n\nTo take the most out of our research, we will start by looking carefully at the profiles of our common friends and later we will focus on our common interests."},{"metadata":{"_uuid":"147f5fa33004cc12bbc84428836c3a2ad1f59e80"},"cell_type":"markdown","source":"#### 同数值变量之间的关系 (散点图）"},{"metadata":{"trusted":true,"_uuid":"f38945c1d79f4d336b11b65627086069ac2a3db4"},"cell_type":"code","source":"var = 'BsmtFinSF1' # 房屋居住面积\n\n# concat - Series默认行合并； axis = 1，列合并\ndata = pd.concat([train_df['SalePrice'], train_df[var]], axis=1) \n# print dataFrame\ndata.plot.scatter(x=var, y='SalePrice', ylim = (0, 800000)) # y轴限制","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"273d2d04be739a40d82dbb2a58c64502e4ad386c"},"cell_type":"markdown","source":"房屋价格同居住面积（平方英尺）线性相关"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"a45f10f8dad6b8c83121a798af1042cddb5f992f"},"cell_type":"code","source":"var = 'TotalBsmtSF'  # 房屋地下室的面积\ndata = pd.concat([train_df['SalePrice'], train_df[var]], axis=1)\ndata.plot.scatter(x = var, y = 'SalePrice', ylim = (0, 800000))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d127522da7afff8263e0106a740de3206241bd14"},"cell_type":"markdown","source":"房屋价格同地下室的面积成强线性（指数？）相关\n\n存在一些无地下室的房屋，房屋价格分布在200000以内"},{"metadata":{"_uuid":"6304e28c19b71f01b86f7370190d2775995b427f"},"cell_type":"markdown","source":"#### 同类别变量之间的关系 （箱型图）"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"5904b6d529a8db8677de694769908b8f6f0701e5"},"cell_type":"code","source":"var = 'OverallQual'  # 房屋整体材料和光洁度的评估\ndata = pd.concat([train_df['SalePrice'], train_df[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)  # 横坐标类别，纵坐标目标变量\nfig.axis(ymin=0, ymax=800000);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9f50764d1ffc4cc6da3d78d5145e0ad5de26a39"},"cell_type":"markdown","source":"房屋价格同房屋整体材料和光洁度的评估强相关，整体评估分数越高，房屋价格越高"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"d8791dff90fcaa241636a78ae1f8d3260d00bde9"},"cell_type":"code","source":"var = 'YearBuilt'  # 房屋建造年份\ndata = pd.concat([train_df['SalePrice'], train_df[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))  # 改变大小\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)  # 横坐标类别，纵坐标目标变量\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);               # x如果都水平放置，会粘到一起。x倾斜90度，减少占的位置","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42eba562b690f1cc4b9b7cb64f2aa7630c713795"},"cell_type":"markdown","source":"虽然斜率小，但是新房相对于老房来说房屋价格相对较高"},{"metadata":{"_uuid":"893c3ca9478dc79f2fd1100533d2e6169f5cd2da"},"cell_type":"markdown","source":"#### 总结"},{"metadata":{"_uuid":"5524afd5b2ee6eb38f5f8f569e50ff3283e52222"},"cell_type":"markdown","source":"1、房屋居住面积和房屋地下室的面积同房屋价格呈正相关\n\n2、房屋整体材料质量和建造年份同房屋价格相关。其中房屋整体材料质量同房屋价格相关性更强\n\n以上：特征选择，主观性\n\nThe trick here seems to be the choice of the right features (feature selection) and not the definition of complex relationships between them (feature engineering).\n\nThat said, let's separate the wheat from the chaff.\n\n以下：特征工程，客观性"},{"metadata":{"_uuid":"dbbc6471077f76b9eaf1ed778055cb9f19bee556"},"cell_type":"markdown","source":"### 客观分析"},{"metadata":{"_uuid":"f287265355585ff5c0334e7c23ebf3c85653f77d"},"cell_type":"markdown","source":"####  把一些数值特征转化为类别特征"},{"metadata":{"trusted":true,"_uuid":"cc2e640414dbac3cc8849b71583a0e064c637c2d"},"cell_type":"code","source":"cols = ['MSSubClass', 'OverallCond', 'BedroomAbvGr', 'YrSold', 'MoSold']\n\nfor col in cols:\n    train_df[col] = train_df[col].apply(str)\n    test_df[col] = test_df[col].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfc03bda1cf0db694792e1e484a5d9627a30a294"},"cell_type":"markdown","source":"* <b>相关性矩阵</b>\n* <b>房屋价格相关性矩阵</b>\n* <b>最相关变量散点图</b>"},{"metadata":{"_uuid":"d6178f3d8f2c8ffaf346fa3c2d7b6fcfc6d35013"},"cell_type":"markdown","source":"#### 整体相关性矩阵"},{"metadata":{"trusted":true,"_uuid":"8b8feec5e32c95e7cfe7d00e23496fdb3f635154"},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0b414552caddf7dec86dcc693933c0730f09aa8"},"cell_type":"code","source":"train_df = train_df[['LotFrontage', 'SalePrice', 'MasVnrArea', '1stFlrSF']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a67ee19cd4647bdacbf1a4e9c1bfeee0c327db79"},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"475cfbc835a252c02fb4c60c1c52b6b0086138b9"},"cell_type":"code","source":"corrmat = train_df.corr()\nf, ax = plt.subplots(figsize=(16, 8))\nsns.heatmap(corrmat, vmax= .8, square=True);   # vmax 颜色区别，最浅的颜色在0.8","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a7fbe8e4408857d3ba35fc92a44a72c53a79b3f"},"cell_type":"markdown","source":"更加宏观\n\n1、“TotalBsmtSF” 同 “1stFlrSF”强相关，表达同样的信息\n\n2、“GarageCars”  同 “GarageArea”强相关，表达同样的信息\n\n3、验证“SalePrice” 同主观选择的特征相关，仍有部分特征需加入\"SalePrice\"预测"},{"metadata":{"_uuid":"6b0eceba09f56b7ab7b30f3bf7c066c092b05f30"},"cell_type":"markdown","source":"#### 目标变量相关性矩阵 (SalePrice，放大热力图）"},{"metadata":{"trusted":true,"_uuid":"ab452776d5c9b0c796c8beefe8b525672f55ca57"},"cell_type":"code","source":"# help(corrmat.nlargest)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"9c56190fe70464e5fffeed71119875180e653003"},"cell_type":"code","source":"# # cols = corrmat.nlargest(k, 'SalePrice').index\n# # print cols\n# len (train_df[cols].values)  # 数组，1460 * 10 | 转置 10 * 1460","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4db1516aba0b7bf3efc28fb05809d1817e2fc76"},"cell_type":"code","source":"old_features = ['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF']\ntrain_df['TotalSF'] = 0\ntest_df['TotalSF'] = 0\nfor i in old_features:\n    print (train_df['SalePrice'].corr(train_df[i]))\n    train_df['TotalSF'] += train_df[i]\n    test_df['TotalSF'] += test_df[i]\ntrain_df['SalePrice'].corr(train_df['TotalSF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07960b0c83c0a9611ad3d2fd36d207f7b8d0820a"},"cell_type":"code","source":"corrmat = train_df.corr().abs()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"0e520ae2cbc0ebab68ff6a81788b696ad8a3db6e"},"cell_type":"code","source":"#saleprice correlation matrix\nk = 36   #number of variables for heatmap，热力图变量数量 \n\n# nlargest - 根据SalePrice列排序，返回前10个跟SalePrice相关性最高的行\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index \n\n# cm = corrmat.loc[cols,cols] 同以下cm赋值相同\n# 训练集中取出目标列的样本，转置，计算10个特征之间的相关性\ncm = np.corrcoef(train_df[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ddef2411f6d021144ab0ef05f5b131a184057b2"},"cell_type":"code","source":"print (len(train_df.columns))\n# print len(drop_columns)\nprint (len(train_df.dtypes[train_df.dtypes == 'object'].index))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7033ecdd908763b6093da13a240db57238aa6edf"},"cell_type":"markdown","source":"\n\n1、确认主观特征选择变量'OverallQual'，'GrLivArea' ，'TotalBsmtSF'同房屋价格强相关\n\n2、因为“GarageCars” 同 “GarageArea”强相关，故选择同房屋价格相关性更高的“GarageCars”\n\n3、同上，选择“TotalBasmtSF”\n\n4、“TotRmsAbvGrd” 同“GrLivArea”强相关，选择“GrLivArea”\n\n5、\"YearBuilt\"【待】时间序列分析\n\n6、 \"FullBath\"浴室的品质，从箱型图中可以看出浴室的品质同房屋的价格呈正相关\n\n    同时存在一些无浴室的房屋"},{"metadata":{"_uuid":"19f8b29bb51737feea2f5bd60cd9777b627e4b6f"},"cell_type":"markdown","source":"#### 最相关变量散点图"},{"metadata":{"code_folding":[],"trusted":true,"_uuid":"19b4543db258629a8ac387d32ca130236c102588"},"cell_type":"code","source":"# cols","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"39e74adce35f12a59016c6a9e43f35f22bc09b83"},"cell_type":"code","source":"# #scatterplot\n# sns.set()\n# cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n# sns.pairplot(train_df[cols], size = 2.5)\n# plt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ea4d872d99b5ef0129515906b3606926786dc23"},"cell_type":"markdown","source":"# 特征分析"},{"metadata":{"_uuid":"d08c1eda9675c229dbfeae36bb1e472bb380dbd0"},"cell_type":"markdown","source":"### 【正确性】"},{"metadata":{"_uuid":"9feef240b0bed5277c249a48804c6fc6a2dfcbe9"},"cell_type":"markdown","source":"去除异常值"},{"metadata":{"_uuid":"5296649d3b265a60af34481a028db64bda051ad4"},"cell_type":"markdown","source":"1、TotalBsmtSF 为0 = 房屋中没有地下室，数据正常\n\n2、故仅针对GrLivArea 做异常值去除"},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"50203f115ee91ee73bf590d19b50c5608dd3c5c1"},"cell_type":"code","source":"# olss = []\n# numerical_features = ['GrLivArea']\n# for feature in numerical_features:\n    \n#     # 计算25%分位点\n#     Q1 = np.percentile(train_df[feature], 25)\n    \n#     # 计算75%分位点\n#     Q3 = np.percentile(train_df[feature], 75)\n#     print Q3\n    \n#     # 异常阶（1.5倍四分位距）IQR\n#     step = 1.5 * (Q3 - Q1)\n    \n#     print \"Feature\" + feature + \"Outlines\"\n#     print train_df[ (train_df[feature] <= Q1 - step) | (train_df[feature] >= Q3 + step)][numerical_features]\n#     ols = features_train[ (train_df[feature] <= Q1 - step) | (train_df[feature] >= Q3 + step)].index.tolist()\n#     olss.append(ols)\n    \n# olss_new = [ii for i in olss for ii in i]\n# # print olss_new\n\n# # 列表方法 .count(i) 统计列表中某个元素出现的次数\n# more_than_one = list(set([i for i in olss_new if olss_new.count(i) > 1]))\n# more_than_two = list(set([i for i in olss_new if olss_new.count(i) > 2]))\n# print len(more_than_one), len(more_than_two)\n\n# ## 移除异常点\n# # features_train_new = features_train.drop(features_train.index[olss_new]).reset_index(drop = True)\n# # labels_train_new = labels_train.drop(features_train.index[olss_new]).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"091f98ae1c631cdae7842ea5c9f2e0644ef59d61"},"cell_type":"code","source":"var = 'GrLivArea'\ndata = pd.concat([train_df['SalePrice'], train_df[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f972b3db3d4f322a8c633c5863895159489e9674"},"cell_type":"code","source":"# 从散点图中确定去除GrLivArea > 4000 且SalePrice < 200000的点\ntrain_df = train_df.drop(train_df[(train_df['GrLivArea'] > 4000) & (train_df['SalePrice'] < 200000)].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9251e5a27ab1e41a3cd9440887a6f27a35a53ac"},"cell_type":"markdown","source":"### 【创造性】"},{"metadata":{"_uuid":"ddf93f4acec6d2a4b35c3e6a33b017b50a934e1f"},"cell_type":"markdown","source":"删除相关性较弱的特征"},{"metadata":{"_uuid":"8bfcc88fc71d50793d03a0f1511aebabef461d06"},"cell_type":"markdown","source":"所有类别特征"},{"metadata":{"trusted":true,"_uuid":"fe109d3a931457ce43c1e67093252f243f211f24"},"cell_type":"code","source":"train_df.dtypes[(train_df.dtypes == 'object')].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcf85c38619cadef732e91bf4c6a080960f8e710"},"cell_type":"code","source":"var = 'BldgType'  # 房屋整体材料和光洁度的评估\ndata = pd.concat([train_df['SalePrice'], train_df[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)  # 横坐标类别，纵坐标目标变量\nfig.axis(ymin=0, ymax=800000);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2c984cabc2948dffc1d19bb11cb716bc5e16d11"},"cell_type":"markdown","source":"### 【倾斜数据处理】"},{"metadata":{"_uuid":"b14a69a49c8ca5d87fd1abc1a4d833c7d17c5ae1"},"cell_type":"markdown","source":"#### 预测值倾斜，对数处理"},{"metadata":{"_uuid":"c971aaf4d816ed96acb60e0b7d9b58f4539407bc"},"cell_type":"markdown","source":"* <b> 偏度 </b>  正态分布的偏度为0。若数据分布是对称的，偏度 = 0。\n\n     若偏度 > 0，分布为右偏，即分布有一条长尾在右；\n     \n     若偏度 < 0，分布为左偏，即分布有一条长尾在左。偏度的绝对值越大，说明分布的偏移程度越严重。\n\n\n* <b> 峰度 </b>  正态分布的峰度为0。\n\n    当峰度 > 0，它相比于正态分布要更陡峭或尾部更厚。\n    \n    峰度系数 < 0, 它相比于正态分布更平缓或尾部更薄。"},{"metadata":{"_uuid":"b8cd630314ba94b1450fb0249cabbe9bcb9cf931"},"cell_type":"markdown","source":"Normality - When we talk about normality what we mean is that the data should look like a normal distribution. This is important because several statistic tests rely on this (e.g. t-statistics). In this exercise we'll just check univariate normality for 'SalePrice' (which is a limited approach). Remember that univariate normality doesn't ensure multivariate normality (which is what we would like to have), but it helps. Another detail to take into account is that in big samples (>200 observations) normality is not such an issue.\n\nHowever, if we solve normality, we avoid a lot of other problems (e.g. heteroscedacity) so that's the main reason why we are doing this analysis.\n\n正态分布"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"735209cf0141c11a544c2f9e1f3cb6db821335bd"},"cell_type":"code","source":"train_df['SalePrice'] = np.log1p(train_df['SalePrice'])\nsns.distplot(train_df['SalePrice'], color='blue')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c539d24318af4f2844fddfd9123cd8b7cfe1bb8"},"cell_type":"code","source":"print (train_df['SalePrice'].skew())\ntrain_df['SalePrice'].kurt()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14a261550e0a9270fa8e063391f0d0745c451757"},"cell_type":"markdown","source":"### 【转化性】\nLabel Encoding 一些可以包含信息的类别特征\n\n**表达类别特征之间的高低顺序Excellent > Good > bad** \n\n每单位变化跟目标变量并没有关系！"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"c8f30c661cee60ca4c389aa93d4bde4090a3a277"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# categories = [i for i in train_df.columns if i not in cols]\n# process columns, apply LabelEncoder to categorical features\n\ncategories = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold', 'BedroomAbvGr']\n\nfor c in categories:\n    lbl = LabelEncoder() \n    train_df[c] = lbl.fit_transform(list(train_df[c].values))\n    test_df[c] = lbl.fit_transform(list(test_df[c].values))\n\n\n# shape        \nprint ('Shape all_data: {}'.format(train_df.shape))\nprint ('Shape all_data: {}'.format(test_df.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"a26caf7643e69af7c60420c62463f487a5883990"},"cell_type":"code","source":"numeric_features = list(train_df.dtypes[train_df.dtypes != 'object'].index)\nnumeric_features.remove('SalePrice')\nlen(numeric_features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eeabc5fad4fd0d645009ea61f09cab8de7a51371"},"cell_type":"markdown","source":"#### 转化后所有特征标准化"},{"metadata":{"trusted":true,"_uuid":"223fc2cc5d715301c1944c08fdd60c927c25e302"},"cell_type":"code","source":"# box-cox变换\nfrom scipy.special import boxcox1p\n# skewed_features = list(skewness)\nlam = 0.15\nfor feature in numeric_features:\n    #all_data[feat] += 1\n    train_df[feature] = boxcox1p(train_df[feature], lam)\n    test_df[feature] = boxcox1p(test_df[feature], lam)\n    \n#all_data[skewed_features] = np.log1p(all_data[skewed_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f282d50ad9937db318cdac7530c52861fa938ba8"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = StandardScaler()\nscaler.fit(train_df[numeric_features])\ntrain_df[numeric_features] = scaler.transform(train_df[numeric_features])\ntest_df[numeric_features] = scaler.transform(test_df[numeric_features])\n\n# scaler = MinMaxScaler()\n# scaler.fit(train_df[numeric_features])\n# train_df[numeric_features] = scaler.transform(train_df[numeric_features])\n# test_df[numeric_features] = scaler.transform(test_df[numeric_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c37ecbf16a15cb455168eb2cef7d1452b64ab02"},"cell_type":"code","source":"category_columns = train_df.dtypes[train_df.dtypes == 'object'].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08ee391774714449cd2d05be15f8b0ed73364ab5"},"cell_type":"code","source":"for i in category_columns:\n    if len(train_df[i].value_counts().index) <= 2:\n        print  (\"Train\\n\" +  i)\n        print  (train_df[i].value_counts())\n        \n    if len(test_df[i].value_counts().index) <= 2:\n        print (\"Test\\n\" + i)\n        print (test_df[i].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"851d4f1467b87679799b68de5c0ee4683a2bdaa1"},"cell_type":"code","source":"drop_columns = 'Utilities'\ntrain_df = train_df.drop(drop_columns, axis=1)\ntest_df = test_df.drop(drop_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c672efd6e1d9872ee5d1de3d44e47c0fea79f46"},"cell_type":"markdown","source":"#### 转化性"},{"metadata":{"trusted":true,"_uuid":"d15934815f4aa3709d75791d1b8204d9ae8833bc"},"cell_type":"code","source":"features_train = train_df.drop(['SalePrice'], axis=1)\nlabels_train = train_df['SalePrice']\nfeatures_test = test_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3000698edcb5511aee3c386a886daeeee7806941"},"cell_type":"markdown","source":"#### 独热编码其他与顺序无关的特征"},{"metadata":{"code_folding":[4],"trusted":true,"_uuid":"00311096a5a06e30a4fa82a1443ccc3acdfec18e"},"cell_type":"code","source":"features_train = pd.get_dummies(features_train)\nfeatures_test = pd.get_dummies(test_df)\n\nmissing_cols = set(features_train.columns) - set(features_test.columns)\nfor column in missing_cols:\n    features_test[column] = 0\n    \n# 保证测试集columns的顺序同训练集columns相同，特别重要！！！！！！\nfeatures_test = features_test[features_train.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6423499ab6d172243ce566d010ac96167d479235"},"cell_type":"code","source":"print (features_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edde03471a8eed7facd39a70dc3f8a0ca6646180"},"cell_type":"markdown","source":"### 分割训练和测试数据"},{"metadata":{"trusted":true,"_uuid":"cd393ac1ee24e34a2d8a8e876585e7f6238b4272"},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# # 分割features_train 和 labels_train, 测试集大小 = 20%，状态：随机，可复现\n# # 顺序：测试特征，训练特征，测试目标，训练目标\n\n# X_train, X_test, y_train, y_test = train_test_split(features_train, labels_train, test_size = 0.2, random_state = 42)\n\n# 输出数量观察\n\nX_train = features_train\ny_train = labels_train\nprint (len(X_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c68ebd42ceff635c7a5c5fc251adada0d7d1b263"},"cell_type":"markdown","source":"# 模型实现与融合"},{"metadata":{"_uuid":"ba6e5a8dd90cc061c4b213c90eac681a39c248d0"},"cell_type":"markdown","source":"## 分析问题，确定模型"},{"metadata":{"_uuid":"c31d292fa0b5e92e4c61cc9aeac05f8d8bc5096b"},"cell_type":"markdown","source":"问题为回归问题，可用模型：线性回归，决策树（C&RT决策树），随机森林，GBDT"},{"metadata":{"_uuid":"34f99a9a91e385d077648df1ba9075b07338c896"},"cell_type":"markdown","source":"## 首先用简单的模型进行试验，观察评分"},{"metadata":{"_uuid":"b98f3065e6e8306bc50be7095fe5dd62e9462671"},"cell_type":"markdown","source":"回归模型评分指标包括：\n\n1、SSE误差平方和， RMSE\n\n2、R-square（决定系数）"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"6cca6c1f077543e423b8809bb05da627e5c1541a"},"cell_type":"code","source":"# # 导入算法模型和评分标准 \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import fbeta_score, make_scorer, r2_score ,mean_squared_error\nfrom sklearn.linear_model import Lasso\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\n\n# def rmsle_cv(model, train, value):\n#     kf = KFold(5, shuffle=True, random_state=42).get_n_splits(train.values)\n#     rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n#     return rmse.mean()\n\n# # for key_num in range(10,25,3):\n\n# #     cols_model = cols[:key_num]\n# #     drop_columns = [i for i in corrmat.columns if i not in cols_model]\n# #     print drop_columns , \"\\n\"\n# #     X_train_model = X_train.drop(drop_columns, axis=1)\n\n# #         # 初始化,确定随机状态，可复现\n# #     reg1 = DecisionTreeRegressor(random_state = 42)\n# #     reg2 = LinearRegression()\n# #     reg3 = RandomForestRegressor(random_state = 42)\n# #     reg4 = XGBRegressor()\n# #     reg5 = Lasso(alpha=0.001, random_state= 42)\n# #     reg6 = SVR(kernel = 'rbf')\n# #     reg7 = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\n\n# #     # 建立字典，收集学习器的效果\n# #     # 学习，收集预测得分\n# #     results = {}\n# #     for reg in [reg1, reg2, reg3, reg4, reg5, reg6, reg7]:\n# #         # 回归器的名称\n# #         reg_name = reg.__class__.__name__\n# # #         reg.fit(X_train_model, y_train)\n# # #         pred_test = reg.predict(X_test_model)\n# # #         results[reg_name] = rmse(y_test, pred_test)\n# #         results[reg_name] = rmsle_cv(reg, X_train_model, y_train)\n# #     print key_num, \"---\", results\n# #     print '\\n'","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"9e74ad5c12fd5bcb3b6be8b2018b514b3961b5a8"},"cell_type":"code","source":"cols = cols[:22] \ndrop_columns = [i for i in corrmat.columns if i not in cols]\n\nprint (drop_columns , \"\\n\")\nX_train = X_train.drop(drop_columns, axis=1)\nprint (len(X_train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26e0c82fa24eb94e8f8a196d654d4cf54dc1baa7"},"cell_type":"code","source":"features_test = features_test.drop(drop_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2f207c5c25b103f072b916734a3baa4ada07ec7"},"cell_type":"markdown","source":"## 网格搜索调参"},{"metadata":{"trusted":true,"_uuid":"01c874505b1604ee0e68b195b5000c5cfff86a57"},"cell_type":"code","source":"from sklearn.metrics import fbeta_score, make_scorer, r2_score ,mean_squared_error\n\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37abaf3ddd48aae3511347f832f047474e103b53"},"cell_type":"markdown","source":"### 随机森林"},{"metadata":{"trusted":true,"_uuid":"5f0649c6e6f0128c846ac6df7c61f069ccbdaa92"},"cell_type":"code","source":"# 模型：RandomForest\n# 导入Grid\nfrom sklearn.model_selection import GridSearchCV\n\n# 初始化回归模型\nreg = RandomForestRegressor(random_state=42)\n\n# 确定参数列表\nparameters = {\n    'max_leaf_nodes': range(20, 100 ,10)\n}\n\n# 确定评分标准\nscorer = 'neg_mean_squared_error'\n\n# 回归模型使用网格搜索\ngrid_reg = GridSearchCV(reg, parameters, scoring = scorer)\n\n# 训练\ngrid_reg.fit(X_train, y_train)\n\n# grid_reg.cv_results_\n\n# 获得最佳拟合回归器\nbest_reg_rf = grid_reg.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"cc4d2864c05147aa40e34fc4d780cef3b4a06c7b"},"cell_type":"code","source":"# print grid_reg.best_estimator_\nprint (grid_reg.best_estimator_)\npred_rf = best_reg_rf.predict(X_train)\nrmsle(pred_rf, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2086bcb6c34d210030c748cb37b4473b4c7d217a"},"cell_type":"markdown","source":"### Lasso回归"},{"metadata":{"_uuid":"800e0a505ba9502b37a8623b74cc6fddd4bb320c"},"cell_type":"markdown","source":"一般来说，对于高维的特征数据，尤其线性关系是稀疏的，我们会采用Lasso回归。或者是要在一堆特征里面找出主要的特征，那么Lasso回归更是首选了。但是Lasso类需要自己对α调优，所以不是Lasso回归的首选，一般用到的是下一节要讲的LassoCV类。\n\nhttps://www.cnblogs.com/pinard/p/6026343.html"},{"metadata":{"trusted":true,"_uuid":"8539b3b3ad851264425f29b6fa6b9ce2d812e43c"},"cell_type":"code","source":"# 模型：线性回归\nfrom sklearn.model_selection import GridSearchCV\n\n# 初始化回归模型\nreg = Lasso( alpha=0.001, random_state= 42)\n\n# 确定参数列表\nparameters = {\n    'normalize': [True, False],\n    'alpha': [0, 0.0001, 0.0005, 0.001]\n}\n\n# 确定评分标准\nscorer = 'neg_mean_squared_error'\n\n# 回归模型使用网格搜索\ngrid_reg = GridSearchCV(reg, parameters, scoring = scorer)\n\n# 训练\ngrid_reg.fit(X_train, y_train)\n\n# 获得最佳拟合回归器\nbest_reg_lasso = grid_reg.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40295b99e14e365c88ae3cc5324ced3a8bcb9fe6"},"cell_type":"code","source":"print (grid_reg.best_estimator_)\npred_lasso = best_reg_lasso.predict(X_train)\nrmsle(pred_lasso, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"899a5a71c07689cf9f622cca90612ac96154a59f"},"cell_type":"markdown","source":"### ElasticNet"},{"metadata":{"_uuid":"afc22512bb97f6992685c22a2dc535b45a96d7ca"},"cell_type":"markdown","source":"弹性网络，结合L1和L2正则化"},{"metadata":{"trusted":true,"_uuid":"ed3de5886c0e2489b1b2d20c216c8908f3909f84"},"cell_type":"code","source":"reg = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state = 42)\n\nparameters = {\n    'alpha':[0, 0.0001, 0.0005, 0.001],\n    'l1_ratio':np.arange(0, 1, 0.1)\n}\n\nscorer = 'neg_mean_squared_error'\n\ngrid_reg = GridSearchCV(reg, parameters, scoring= scorer)\n\ngrid_reg.fit(X_train, y_train)\n\nbest_elasticNet_reg =  grid_reg.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6dcf722d0cc066643738bb1418bc8d48fd54480"},"cell_type":"code","source":"print (grid_reg.best_estimator_)\npred_elasticNet_reg = best_elasticNet_reg.predict(X_train)\nrmsle(pred_elasticNet_reg, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ee800453bee897863729d10fd9195d491eb6671"},"cell_type":"markdown","source":"\n### SVR_rbf "},{"metadata":{"trusted":true,"_uuid":"a8b9700a83a728fb6c45f430dd54995a186f7c31"},"cell_type":"code","source":"from sklearn.svm import SVR\n\nreg = SVR(kernel = 'rbf')\n\nparameters = {\n    'C': np.arange(1.1,2,0.1),\n    'gamma':np.arange(0,0.1,0.01)\n}\n\nscorer = 'neg_mean_squared_error'\n\ngrid_reg = GridSearchCV(reg, parameters, scoring = scorer)\n\ngrid_reg.fit(X_train, y_train)\n\nbest_reg_SVR = grid_reg.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bee99783ed827ab3a9475e90d5a68afb2fd99951"},"cell_type":"code","source":"print (grid_reg.best_estimator_)\npred_lasso = best_reg_lasso.predict(X_train)\nrmsle(pred_lasso, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1ce2c8f731ae8388d2e943f771d1ea5e5041316"},"cell_type":"markdown","source":"### Xgboost"},{"metadata":{"_uuid":"9110e3cc991971f2ea2b149b9bfc9ae9c035ebe7"},"cell_type":"markdown","source":"### 1、确定学习速率和tree_based 参数调优的估计器数目"},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"1a3812931791b543dd6e1321a31db1531ab15f29"},"cell_type":"code","source":"# # 确定最佳决策树的数量, xgboost中的cv函数来确定最佳的决策树数量, 提高Xgboost调参速度\n# # 后边有 early_stopping_rounds 个rmse没有下降的就停止\n# # 原话：\n# # Activates early stopping. CV error needs to decrease at least\n# #        every <early_stopping_rounds> round(s) to continue.\n# #        Last entry in evaluation history is the one from best iteration.\n\n# import xgboost as xgb\n# from xgboost.sklearn import XGBRegressor\n\n# def modelfit(alg, X_train, y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n    \n#     if useTrainCV:\n#         xgb_param = alg.get_xgb_params()\n#         xgtrain = xgb.DMatrix(X_train.values, label= y_train.values)\n#         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n#             metrics='rmse', early_stopping_rounds = early_stopping_rounds)\n#         alg.set_params(n_estimators=cvresult.shape[0])\n#         print cvresult\n\n#     #Fit the algorithm on the data\n#     alg.fit(X_train, y_train,eval_metric='rmse')\n\n#     #Predict training set:\n#     dtrain_predictions = alg.predict(X_train)\n\n#     # 模型训练报告\n#     print \"\\nModel Report\"\n#     print \"RMSE Score (Train): %f\" % rmse(y_train, dtrain_predictions)\n    \n#     # 特征重要性\n#     feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)[:10,]\n#     feat_imp.plot(kind='bar', title='Feature Importances')\n#     plt.ylabel('Feature Importance Score')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"f1210a967a1d2b3f242b81c6e0e9ef398bbccd52"},"cell_type":"code","source":"# 模型：Xgboost\nfrom sklearn.model_selection import GridSearchCV\n\nbest_reg_xgb = XGBRegressor(learning_rate= 0.01, n_estimators = 5000, \n                    max_depth= 4, min_child_weight = 1.5, gamma = 0.1, \n                   subsample = 0.7, colsample_bytree = 0.6, \n                   seed = 27)\n\n# modelfit(reg, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f64de806a2e87823142f506f95c6e2a0905e9d6f"},"cell_type":"code","source":"best_reg_xgb.fit(X_train, y_train)\npred_y_XGB = best_reg_xgb.predict(X_train)\nprint (rmsle(pred_y_XGB, y_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"235048ec79af0c1bb36dcf94bf20e1b6436caecf"},"cell_type":"markdown","source":"学习速率为0.1时，理想的决策树数目为115个"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"f6fb12eab4f875cd7f2b2892eeb052bece65c814"},"cell_type":"code","source":"# rmsle_cv(best_reg_xgb, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49acdf106b261deccc262a6159f85af2f4bdac0e"},"cell_type":"markdown","source":"### 2、调整Xgboost相关参数"},{"metadata":{"_uuid":"213f349c6c1791d3a57a2180cc28b284f118ed27"},"cell_type":"markdown","source":"#### max_depth 和 min_weight 参数调优"},{"metadata":{"_uuid":"05f42d2e13372b0f2eb676ae105dfa5a29ff993f"},"cell_type":"markdown","source":"max_depth 树的最大深度\n\nmin_child_weight 最小叶子节点样本权重和：\n\n\n"},{"metadata":{"code_folding":[0],"scrolled":true,"trusted":true,"_uuid":"2f7233fb84240644c88eba4cba870f56e617d2b2"},"cell_type":"code","source":"# param_test1 = {\n#     'max_depth': range(3,10,2),\n#     'min_child_weight': range(1,6,2)\n# }\n\n# scorer = make_scorer(rmse)\n\n# # 负均方误差\n# grid_reg1 = GridSearchCV(estimator=XGBRegressor(learning_rate=0.01, n_estimators=1605, \n#                                                 max_depth=5, min_child_weight = 1,gamma = 0,\n#                                                 subsample = 0.8, colsample_bytree = 0.8, seed = 27), \n#                          param_grid = param_test1, scoring = 'neg_mean_squared_error')\n# grid_reg1.fit(X_train, y_train)\n# grid_reg1.grid_scores_, grid_reg1.best_params_, grid_reg1.best_score_\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77e5fd9bba21e4b1b5150da8dcfdce500932afcd"},"cell_type":"markdown","source":"理想max_depth = 5， min_child_weight = 3，值附近细化调整"},{"metadata":{"code_folding":[0],"scrolled":true,"trusted":true,"_uuid":"e20a954888bb344a528b293a4592c561e00f0897"},"cell_type":"code","source":"# param_test1 = {\n#     'max_depth': [4, 5, 6],\n#     'min_child_weight': np.arange(1.0, 4.0, 0.5)\n# }\n\n# scorer = make_scorer(rmse)\n\n# # 负均方误差\n# grid_reg1 = GridSearchCV(estimator=XGBRegressor(learning_rate=0.1, n_estimators=115, \n#                                                 max_depth=5, min_child_weight = 1,gamma = 0,\n#                                                 subsample = 0.8, colsample_bytree = 0.8, seed = 27), \n#                          param_grid = param_test1, scoring = 'neg_mean_squared_error')\n# grid_reg1.fit(X_train, y_train)\n# grid_reg1.grid_scores_, grid_reg1.best_params_, grid_reg1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79d57a400579cb69e286ca65fc6db09b539c4f54"},"cell_type":"markdown","source":"'max_depth'理想值 4, 'min_child_weight' 理想值 1.5 交叉验证得分：0.016"},{"metadata":{"_uuid":"2cdaf07e746b8819d14ed17d0fa487c39e609627"},"cell_type":"markdown","source":"#### gamma参数调优"},{"metadata":{"_uuid":"4c67ed86d57ffc10d9440c4de2dc09e7376cffaf"},"cell_type":"markdown","source":"节点分裂所需的最小损失函数下降值"},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"b6adc11c46342d2a669733eff682d9b96d1749a2"},"cell_type":"code","source":"# param_test3 = {\n#     'gamma' : [i/10.0 for i in range(0,5)]\n# }\n\n\n# grid_reg1 = GridSearchCV(estimator=XGBRegressor(learning_rate=0.1, n_estimators=115, \n#                                                 max_depth=4, min_child_weight = 1.5,gamma = 0,\n#                                                 subsample = 0.8, colsample_bytree = 0.8, seed = 27), \n#                          param_grid = param_test3, scoring = 'neg_mean_squared_error')\n# grid_reg1.fit(X_train, y_train)\n# grid_reg1.grid_scores_, grid_reg1.best_params_, grid_reg1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05cc7c9314ec36fcfd19c7526c1a4e8d4f0aa36d"},"cell_type":"markdown","source":"学习速率为0.1的情况下，理想决策树115， 'max_depth'理想值 4, 'min_child_weight' 理想值 1.5， gamma为0"},{"metadata":{"_uuid":"8c0060323cbc54f5f7f52fbba2a5c519751ee48a"},"cell_type":"markdown","source":"#### 调整subsample 和 colsample_bytree 参数"},{"metadata":{"_uuid":"435bad95140c71d2dbed4210abb665a46a825b8d"},"cell_type":"markdown","source":"样本抽样和列抽样的比重"},{"metadata":{"code_folding":[0],"scrolled":true,"trusted":true,"_uuid":"4f4239cb785fa4f95a724d5cec03e3979a58c4d5"},"cell_type":"code","source":"# param_test4 = {\n#     'subsample':np.arange(0.5, 1.0 ,0.05),\n#     'colsample_bytree':np.arange(0.5, 1.0, 0.05)\n# }\n\n\n# grid_reg1 = GridSearchCV(estimator=XGBRegressor(learning_rate=0.1, n_estimators=115, \n#                                                 max_depth=4, min_child_weight = 1.5,gamma = 0,\n#                                                 subsample = 0.8, colsample_bytree = 0.8, seed = 27), \n#                          param_grid = param_test4, scoring = 'neg_mean_squared_error')\n# grid_reg1.fit(X_train, y_train)\n# grid_reg1.grid_scores_, grid_reg1.best_params_, grid_reg1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78fea01f13a6ebbc9508bf63235fd57c8fe7ca12"},"cell_type":"markdown","source":"学习速率为0.1的情况下，理想决策树115， 'max_depth'理想值 4, 'min_child_weight' 理想值 1.5， gamma为0, \n\ncolsample_bytree为0.6， subsample为0.7，MSE为0.0156"},{"metadata":{"_uuid":"526739681659f29ce7c0984ba15ea72536df38f7"},"cell_type":"markdown","source":"#### 3、正则化参数调优"},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"ae5fef017fcde1a6abe8d3b5395f68fc0fcd6ec4"},"cell_type":"code","source":"# param_test5 = {\n#     \"reg_alpha\":np.arange(0.0, 1.1, 0.1),\n#     \"reg_lambda\":np.arange(0.0, 1.1, 0.1)\n# }\n\n# grid_reg1 = GridSearchCV(estimator=XGBRegressor(learning_rate=0.1, n_estimators=115, \n#                                                 max_depth=4, min_child_weight = 1.5,gamma = 0,\n#                                                 subsample = 0.7, colsample_bytree = 0.6, seed = 27), \n#                          param_grid = param_test5, scoring = 'neg_mean_squared_error')\n# grid_reg1.fit(X_train, y_train)\n# grid_reg1.grid_scores_, grid_reg1.best_params_, grid_reg1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9beb8490c3f54069cdd380b8afd6fd0105c64fd4"},"cell_type":"markdown","source":"学习速率为0.1的情况下，理想决策树115， \n\n'max_depth'理想值 4, 'min_child_weight' 理想值 1.5， gamma为0,\n\ncolsample_bytree为0.6， subsample为0.7\n\nalpha为0.1，lambda为0\n\nMSE为0.0154"},{"metadata":{"_uuid":"500f7074f763fcd65d4a410779b0fd850d4e9ecc"},"cell_type":"markdown","source":"#### 4、降低学习速率，确定理想参数"},{"metadata":{"_uuid":"166e9a419ac298642302a4d767e303c01719dce4"},"cell_type":"markdown","source":"使用较低的学习速率，更多的决策树"},{"metadata":{"code_folding":[0],"scrolled":true,"trusted":true,"_uuid":"1eace648fc8bf5167290a96c79e685ed0295ea26"},"cell_type":"code","source":"# reg2 = XGBRegressor(learning_rate=0.1, n_estimators= 1000, \n#                          max_depth=4, min_child_weight = 1.5,gamma = 0,\n#                         subsample = 0.7, colsample_bytree = 0.6, seed = 27)\n\n# modelfit(reg2, X_train, y_train )","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"1744d4377b94a901c6bd7c7682ba3df9b6e32cdf"},"cell_type":"code","source":"# pred_y_test = reg2.predict(X_test)\n# rmse(pred_y_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c408fb50a8d75b670ce6fdcdff9ddb739fc16da6"},"cell_type":"markdown","source":"学习速率为0.01的情况下，理想决策树5000， \n\n'max_depth'理想值 4, 'min_child_weight' 理想值 1.5， gamma为0,\n\ncolsample_bytree为0.6， subsample为0.7\n\nalpha为0.1，lambda为0\n\nMSE为"},{"metadata":{"_uuid":"2ef9f1e7b566b274065e2169671bee4801b710c0"},"cell_type":"markdown","source":"1、仅靠参数的调整和模型的小幅优化，想要让模型的表现有个大幅度提升是不可能的\n\n2、要想让模型的表现有一个质的飞跃，需要依靠其他的手段：\n\n    1、特征工程(feature egineering) \n    \n    2、模型组合(stacking)"},{"metadata":{"_uuid":"c00c70c8cf2df8015885dc594d9ef7d998ba5e24"},"cell_type":"markdown","source":"## 模型融合"},{"metadata":{"trusted":true,"_uuid":"6faf98c2f6e44fe06223001f59823179a4596c4b"},"cell_type":"code","source":"from mlxtend.regressor import StackingRegressor\n\n# metal_reg = Lasso(alpha= 0.0, random_state=42)\nmetal_reg = SVR(kernel= 'rbf', C = 20)\n\nstregr = StackingRegressor(regressors = [ best_reg_lasso, best_elasticNet_reg], meta_regressor = metal_reg)\n\n# params = {'meta-lasso__alpha':[0.1, 1.0, 10.0] }\n\n# grid = GridSearchCV(estimator=stregr,\n#                     param_grid=params,\n#                     cv=5,\n#                     refit=True)\n\n# grid.fit(X_train, y_train)\n# for params, mean_score, scores in grid.grid_scores_:\n#     print(\"%0.3f +/- %0.2f %r\"\n#         % (mean_score, scores.std() / 2.0, params))\n\n\n# rmsle_cv(stregr, X_train, y_train).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e47084a9190ca73e3964ab4fa7af03e57b5cdff0"},"cell_type":"code","source":"stregr.fit(X_train, y_train)\nstacked_y_pred  = stregr.predict(X_train)\nrmsle(y_train, stacked_y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"743d73b3f0087840e0d2762ed150f2bd98b5d528"},"cell_type":"markdown","source":"### 学习曲线"},{"metadata":{"_uuid":"c966d752ac787b35aadf303ae6ddffc5abb2853d"},"cell_type":"markdown","source":"使用Sklearn中学习曲线函数：http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"e9b0078836fba86cbb60bbaea72df4c00a24c760"},"cell_type":"code","source":"# print(__doc__)\n\n# import numpy as np\n# import matplotlib.pyplot as plt\n# from sklearn.naive_bayes import GaussianNB\n# from sklearn.svm import SVC\n# from sklearn.datasets import load_digits\n# from sklearn.model_selection import learning_curve\n# from sklearn.model_selection import ShuffleSplit\n\n\n# def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n#                         n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n#     \"\"\"\n#     Generate a simple plot of the test and training learning curve.\n\n#     Parameters\n#     ----------\n#     estimator : object type that implements the \"fit\" and \"predict\" methods\n#         An object of that type which is cloned for each validation.\n\n#     title : string\n#         Title for the chart.\n\n#     X : array-like, shape (n_samples, n_features)\n#         Training vector, where n_samples is the number of samples and\n#         n_features is the number of features.\n\n#     y : array-like, shape (n_samples) or (n_samples, n_features), optional\n#         Target relative to X for classification or regression;\n#         None for unsupervised learning.\n\n#     ylim : tuple, shape (ymin, ymax), optional\n#         Defines minimum and maximum yvalues plotted.\n\n#     cv : int, cross-validation generator or an iterable, optional\n#         Determines the cross-validation splitting strategy.\n#         Possible inputs for cv are:\n#           - None, to use the default 3-fold cross-validation,\n#           - integer, to specify the number of folds.\n#           - An object to be used as a cross-validation generator.\n#           - An iterable yielding train/test splits.\n\n#         For integer/None inputs, if ``y`` is binary or multiclass,\n#         :class:`StratifiedKFold` used. If the estimator is not a classifier\n#         or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n#         Refer :ref:`User Guide <cross_validation>` for the various\n#         cross-validators that can be used here.\n\n#     n_jobs : integer, optional\n#         Number of jobs to run in parallel (default 1).\n#     \"\"\"\n#     plt.figure()\n#     plt.title(title)\n#     if ylim is not None:\n#         plt.ylim(*ylim)\n#     plt.xlabel(\"Training examples\")\n#     plt.ylabel(\"Score\")\n#     train_sizes, train_scores, test_scores = learning_curve(\n#         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n#     train_scores_mean = np.mean(train_scores, axis=1)\n#     train_scores_std = np.std(train_scores, axis=1)\n#     test_scores_mean = np.mean(test_scores, axis=1)\n#     test_scores_std = np.std(test_scores, axis=1)\n#     plt.grid()\n\n#     plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n#                      train_scores_mean + train_scores_std, alpha=0.1,\n#                      color=\"r\")\n#     plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n#                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n#     plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n#              label=\"Training score\")\n#     plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n#              label=\"Cross-validation score\")\n\n#     plt.legend(loc=\"best\")\n#     return plt","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[0],"trusted":true,"_uuid":"1e2ae254e13c524f235d0ca4dc3601e6bf451258"},"cell_type":"code","source":"# title = \"Learning Curves (Xgboost)\"\n# # Cross validation with 100 iterations to get smoother mean test and train\n# # score curves, each time with 20% data randomly selected as a validation set.\n# cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n\n# estimator = XGBRegressor()\n# plot_learning_curve(estimator, title, features_train, labels_train, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e3e374f8d56f2d7faf76b58e8b1cbc0154b9237"},"cell_type":"markdown","source":"# 预测目标数据"},{"metadata":{"trusted":true,"_uuid":"11b76453d85dc9250da258594e37bf812d2d2e79"},"cell_type":"code","source":"pred = np.expm1(stregr.predict(features_test) * 0.5 + best_reg_xgb.predict(features_test) * 0.5)\npred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfa7f33cd7c98d1a94aa5202d1930e6e114189cc"},"cell_type":"markdown","source":"# 输出结果"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"285318e0d81fd4e97729ec565ec368d362fa2e8c"},"cell_type":"code","source":"# 增加索引，列名，构建DataFrame，符合输出数据格式\n\ntest_df = pd.read_csv('../input/test.csv')\npredict_df = pd.DataFrame({'Id': test_df['Id'], 'SalePrice': pred})\n\n# DataFrame设定index\npredict_df = predict_df.set_index('Id')\n\n# 重命名DataFrame的列，列名 = 字典{原：替换后}\n# predict_df.rename(columns = {predict_df.columns[0]: 'Id'}, inplace=True)\n\npredict_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4409d2d71347d388742e8eb5a3ca4eac389b9f1c"},"cell_type":"code","source":"predict_df.to_csv('Submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b698e2d55c57e3eadbefd4cb3cadd3a0d0ff439"},"cell_type":"markdown","source":"# 待优化策略"},{"metadata":{"collapsed":true,"_uuid":"d2d9982b7c3251f62125cbfd0ea422da31c9bc9c"},"cell_type":"markdown","source":"ROUND 1：\n\nI：基础机器学习框架搭建,采用Random Forest 0.18129 \n\nII：Xgboost + 所有特征: 0.14339 ⬆️（可解释性差，容易过拟合）\n\nIII：只取相关性强数值特征 ：0.14870 ⬇️\n\nIV：相关性强数值特征 + Label Coder ：0.14628 ⬇️\n\nV: 部分数值特征转换为类别特征：Msubclass等：0.13902 ⬆️\n\nVI：部分类别特征Label coder有序；部分独热编码：0.13814 ⬆️\n\nVII：处理倾斜特征和目标变量：0.13806 ⬆️\n \nROUND2：\n\nI：XGboost调参 0.1325 -> 0.131 -> 0.12907  ⬆️\n\nII：多种算法stacking：0.12818 ⬆️\n\nIII：前10有效特征，融合stacking和xgb：0.12584 ⬆️\n\nIIII：过拟合较严重，简化模型，stacking去除RF：0.12138 ⬆️\n\n\n待优化点有：\n\n1、评分标准更改为Kaggle标准 ✅\n\n2、特征分析，创造新特征 ✅\n\n特征较多：74，如何选取以及探索恰当的特征？\n\n3、探索性分析，确定关键特征 ✅\n\n【探索性数据分析】\n\n4、Xgboost学习，调参  ✅\n\n5、集成方法 stacking   ✅\n\n6、模型有些过拟合，试图减少特征的数量 ✅\n\n\n待解决问题有：\n\n1、怎么判断模型存在过拟合？✅\n\n学习曲线，Learning curve\n\n2、线性回归为什么有负值 ✅\n\n在做类别数据 -> 数值转化时，训练集同测试集列名存在区别。只新增了测试集缺失的列，未调整列的顺序。\n注意：test = test[train.columns]\n\n3、XGboost调参技巧 ✅"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}