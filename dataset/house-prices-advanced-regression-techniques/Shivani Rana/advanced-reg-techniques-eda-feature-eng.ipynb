{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House Price Prediction - Advanced Regression Techniques","metadata":{}},{"cell_type":"markdown","source":"# ![](https://miro.medium.com/max/804/1*D6s2K1y7kjE14swcgITB1w.png)\n### House prices increase every year, so there is a need for a system to predict house prices in the future. House price prediction can help the developer determine the selling price of a house and can help the customer to arrange the right time to purchase a house.","metadata":{}},{"cell_type":"markdown","source":"\n#### In this Notebook, I have used Advanced Regression Techniques like **Ridge, Lasso & Polynomial Regression** in most simplystic manner with EDA.\n#### The speciality of this notebook is the detailed & bit by bit **feature engineering** done and its impact on model performance.","metadata":{}},{"cell_type":"markdown","source":"1. Exploratory Data Analysis\n2. Feature Engineering\n3. Model Building & Evaluation\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Exploratory Data Analysis    ","metadata":{}},{"cell_type":"code","source":"#Import necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n%matplotlib inline\npd.set_option('display.max_columns',500)\npd.set_option('display.max_rows',500)\npd.set_option('display.width', 500)\n#to display all the columns of dataframe","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:10.445097Z","iopub.execute_input":"2021-07-24T11:16:10.445578Z","iopub.status.idle":"2021-07-24T11:16:10.965212Z","shell.execute_reply.started":"2021-07-24T11:16:10.445472Z","shell.execute_reply":"2021-07-24T11:16:10.964414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read train.csv file\ndf = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:10.966929Z","iopub.execute_input":"2021-07-24T11:16:10.967529Z","iopub.status.idle":"2021-07-24T11:16:11.003812Z","shell.execute_reply.started":"2021-07-24T11:16:10.967472Z","shell.execute_reply":"2021-07-24T11:16:11.002986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:11.005492Z","iopub.execute_input":"2021-07-24T11:16:11.005969Z","iopub.status.idle":"2021-07-24T11:16:11.111434Z","shell.execute_reply.started":"2021-07-24T11:16:11.00592Z","shell.execute_reply":"2021-07-24T11:16:11.110402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:11.113407Z","iopub.execute_input":"2021-07-24T11:16:11.114036Z","iopub.status.idle":"2021-07-24T11:16:11.240859Z","shell.execute_reply.started":"2021-07-24T11:16:11.113989Z","shell.execute_reply":"2021-07-24T11:16:11.239837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for Corelation between Features\nplt.figure(figsize=(20, 10))\nsb.heatmap(df.corr(),yticklabels=True,cbar=True,cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:11.242412Z","iopub.execute_input":"2021-07-24T11:16:11.243004Z","iopub.status.idle":"2021-07-24T11:16:12.426711Z","shell.execute_reply.started":"2021-07-24T11:16:11.242957Z","shell.execute_reply":"2021-07-24T11:16:12.425431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check which feature has maximum corelation with our dependent feature- SalePrice\ndf.corr()[\"SalePrice\"].sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:12.428561Z","iopub.execute_input":"2021-07-24T11:16:12.429032Z","iopub.status.idle":"2021-07-24T11:16:12.448333Z","shell.execute_reply.started":"2021-07-24T11:16:12.428985Z","shell.execute_reply":"2021-07-24T11:16:12.447273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Here we can see that 'OverAllQual' is most corelated with 'SalePrice'.\n- Lets explore highly correlated features with 'Sale Price'.","metadata":{}},{"cell_type":"code","source":"sb.scatterplot(data = df, x = \"OverallQual\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:12.449791Z","iopub.execute_input":"2021-07-24T11:16:12.450322Z","iopub.status.idle":"2021-07-24T11:16:12.653506Z","shell.execute_reply.started":"2021-07-24T11:16:12.450275Z","shell.execute_reply":"2021-07-24T11:16:12.652763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sb.scatterplot(data = df, x = \"GrLivArea\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:12.654706Z","iopub.execute_input":"2021-07-24T11:16:12.655171Z","iopub.status.idle":"2021-07-24T11:16:12.852991Z","shell.execute_reply.started":"2021-07-24T11:16:12.65512Z","shell.execute_reply":"2021-07-24T11:16:12.852198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sb.scatterplot(data = df, x = \"GarageCars\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:12.855495Z","iopub.execute_input":"2021-07-24T11:16:12.856016Z","iopub.status.idle":"2021-07-24T11:16:13.076738Z","shell.execute_reply.started":"2021-07-24T11:16:12.855967Z","shell.execute_reply":"2021-07-24T11:16:13.075957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sb.scatterplot(data = df, x = \"GarageArea\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.078555Z","iopub.execute_input":"2021-07-24T11:16:13.079049Z","iopub.status.idle":"2021-07-24T11:16:13.289921Z","shell.execute_reply.started":"2021-07-24T11:16:13.078996Z","shell.execute_reply":"2021-07-24T11:16:13.289159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that there are houses with higher(10/10) quality but have very low prices.\n- There are high prices for larger living areas, but we can see some of the outliers also.Same goes for Garage Area too.\n- Number of garage cars also tend to follow the trend where higher the amount of cars is propotional to higher Sales Price.(Highest number 4 can be counted as exceptional)","metadata":{}},{"cell_type":"markdown","source":"### Check for Missing Values:","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.291142Z","iopub.execute_input":"2021-07-24T11:16:13.291574Z","iopub.status.idle":"2021-07-24T11:16:13.483501Z","shell.execute_reply.started":"2021-07-24T11:16:13.29152Z","shell.execute_reply":"2021-07-24T11:16:13.482781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def percent_missing_data(df):\n    missing_count = df.isna().sum().sort_values(ascending = False)\n    missing_percent = 100 * df.isna().sum().sort_values(ascending = False) / len(df)\n    \n    missing_count = pd.DataFrame(missing_count[missing_count > 0])\n    missing_percent = pd.DataFrame(missing_percent[missing_percent > 0])\n    \n    missing_table = pd.concat([missing_count,missing_percent], axis = 1)\n    missing_table.columns = [\"missing_count\", \"missing_percent\"]\n    \n    return missing_table","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.484683Z","iopub.execute_input":"2021-07-24T11:16:13.48501Z","iopub.status.idle":"2021-07-24T11:16:13.49128Z","shell.execute_reply.started":"2021-07-24T11:16:13.48498Z","shell.execute_reply":"2021-07-24T11:16:13.490496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = percent_missing_data(df)\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.492471Z","iopub.execute_input":"2021-07-24T11:16:13.492939Z","iopub.status.idle":"2021-07-24T11:16:13.538174Z","shell.execute_reply.started":"2021-07-24T11:16:13.492905Z","shell.execute_reply":"2021-07-24T11:16:13.537125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_object = df.select_dtypes(include = \"object\")\ndf_numeric = df.select_dtypes(exclude = \"object\")\ndf_object.shape , df_numeric.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.539562Z","iopub.execute_input":"2021-07-24T11:16:13.53985Z","iopub.status.idle":"2021-07-24T11:16:13.553954Z","shell.execute_reply.started":"2021-07-24T11:16:13.539823Z","shell.execute_reply":"2021-07-24T11:16:13.552926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-- Numerical variables are usually of 3 types:\n-- Continous variable \n-- Discrete Variables and \n-- Temporal(Date-Time Features) Variables","metadata":{}},{"cell_type":"code","source":"# list of variables that contain year information\nyear_feature = [feature for feature in df_numeric if 'Yr' in feature or 'Year' in feature]\nprint(\"Temporial feature Count : {}\".format(len(year_feature)))\nyear_feature","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.555345Z","iopub.execute_input":"2021-07-24T11:16:13.555828Z","iopub.status.idle":"2021-07-24T11:16:13.56376Z","shell.execute_reply.started":"2021-07-24T11:16:13.555798Z","shell.execute_reply":"2021-07-24T11:16:13.563004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Visualising the Temporal Datetime Variables\n## We will check whether there is a relation between year the house is sold and the sales price\n\ndf.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.565261Z","iopub.execute_input":"2021-07-24T11:16:13.565752Z","iopub.status.idle":"2021-07-24T11:16:13.777012Z","shell.execute_reply.started":"2021-07-24T11:16:13.56571Z","shell.execute_reply":"2021-07-24T11:16:13.77622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that House sales prices are actually decreasing over the time.","metadata":{}},{"cell_type":"code","source":"#Discrete Features\ndiscrete_feature=[feature for feature in df_numeric if len(df[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.778456Z","iopub.execute_input":"2021-07-24T11:16:13.77905Z","iopub.status.idle":"2021-07-24T11:16:13.789493Z","shell.execute_reply.started":"2021-07-24T11:16:13.779001Z","shell.execute_reply":"2021-07-24T11:16:13.788653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Continous Features\ncontinuous_feature=[feature for feature in df_numeric if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous feature Count: {}\".format(len(continuous_feature)))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.790719Z","iopub.execute_input":"2021-07-24T11:16:13.791185Z","iopub.status.idle":"2021-07-24T11:16:13.799973Z","shell.execute_reply.started":"2021-07-24T11:16:13.791151Z","shell.execute_reply":"2021-07-24T11:16:13.799221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for Outliers","metadata":{}},{"cell_type":"code","source":"for feature in continuous_feature:\n    data=df.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:13.80124Z","iopub.execute_input":"2021-07-24T11:16:13.801683Z","iopub.status.idle":"2021-07-24T11:16:14.458896Z","shell.execute_reply.started":"2021-07-24T11:16:13.801639Z","shell.execute_reply":"2021-07-24T11:16:14.457686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Handling Missing Values","metadata":{}},{"cell_type":"code","source":"missing_values = percent_missing_data(df)\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.460344Z","iopub.execute_input":"2021-07-24T11:16:14.460672Z","iopub.status.idle":"2021-07-24T11:16:14.492806Z","shell.execute_reply.started":"2021-07-24T11:16:14.460639Z","shell.execute_reply":"2021-07-24T11:16:14.491754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,4), dpi = 100)\nsb.barplot(x=missing_values.index,y='missing_percent', data=missing_values)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.494133Z","iopub.execute_input":"2021-07-24T11:16:14.494442Z","iopub.status.idle":"2021-07-24T11:16:14.802146Z","shell.execute_reply.started":"2021-07-24T11:16:14.494412Z","shell.execute_reply":"2021-07-24T11:16:14.801019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see column 'PoolQC' has maximum missing values.We can either drop it or decide to keep it if the feature is important for our model.\n- But first, we can deal with features that have less missing values.ie. less than 1% missing values.\n","metadata":{}},{"cell_type":"code","source":"#Extracting Features that have less than 1% missing values\nmissing_values[missing_values['missing_percent']<1]","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.803612Z","iopub.execute_input":"2021-07-24T11:16:14.804201Z","iopub.status.idle":"2021-07-24T11:16:14.816456Z","shell.execute_reply.started":"2021-07-24T11:16:14.804157Z","shell.execute_reply":"2021-07-24T11:16:14.815178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Electrical has only 1 missing value.It can be filled with mode\ndf['Electrical'].mode()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.818125Z","iopub.execute_input":"2021-07-24T11:16:14.8185Z","iopub.status.idle":"2021-07-24T11:16:14.828872Z","shell.execute_reply.started":"2021-07-24T11:16:14.818468Z","shell.execute_reply":"2021-07-24T11:16:14.827796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Electrical'] = df['Electrical'].fillna('SBrkr')\ndf['Electrical'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.83034Z","iopub.execute_input":"2021-07-24T11:16:14.830678Z","iopub.status.idle":"2021-07-24T11:16:14.840813Z","shell.execute_reply.started":"2021-07-24T11:16:14.830647Z","shell.execute_reply":"2021-07-24T11:16:14.839783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 'MasVnrArea' & 'MasVnrType' also have less than 1% missing values.\n","metadata":{}},{"cell_type":"code","source":"df['MasVnrArea'].value_counts(), df['MasVnrType'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.843988Z","iopub.execute_input":"2021-07-24T11:16:14.844319Z","iopub.status.idle":"2021-07-24T11:16:14.875574Z","shell.execute_reply.started":"2021-07-24T11:16:14.844289Z","shell.execute_reply":"2021-07-24T11:16:14.874548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- By going through that data,we can see that 'MasVnrArea' has values with 0, so missing values can be filled with '0'.\n- 'MasType' has category for None, so missing values can be filled with 'None'.\n","metadata":{}},{"cell_type":"code","source":"df['MasVnrArea']= df['MasVnrArea'].fillna(0)\ndf['MasVnrType']= df['MasVnrType'].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.877075Z","iopub.execute_input":"2021-07-24T11:16:14.877381Z","iopub.status.idle":"2021-07-24T11:16:14.883991Z","shell.execute_reply.started":"2021-07-24T11:16:14.87735Z","shell.execute_reply":"2021-07-24T11:16:14.882897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = percent_missing_data(df)\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.889262Z","iopub.execute_input":"2021-07-24T11:16:14.889595Z","iopub.status.idle":"2021-07-24T11:16:14.922704Z","shell.execute_reply.started":"2021-07-24T11:16:14.889564Z","shell.execute_reply":"2021-07-24T11:16:14.921715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- All the Basement related features have 2% missing values.\n- By going through data,we can find that Nan actually means that the house do not has a basement.So we can replace Nan values with 'None' which means no basement.\n- For Basement related numeric columns we will replace Nan values with zero.","metadata":{}},{"cell_type":"code","source":"# basement string features ==> fill with none\nbsmt_str_cols =  ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\ndf[bsmt_str_cols] = df[bsmt_str_cols].fillna('None')\n\n# basement numeric features ==> fill with 0\nbsmt_num_cols = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\ndf[bsmt_num_cols] = df[bsmt_num_cols].fillna(0)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.924786Z","iopub.execute_input":"2021-07-24T11:16:14.925119Z","iopub.status.idle":"2021-07-24T11:16:14.937193Z","shell.execute_reply.started":"2021-07-24T11:16:14.925089Z","shell.execute_reply":"2021-07-24T11:16:14.936155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = percent_missing_data(df)\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.938764Z","iopub.execute_input":"2021-07-24T11:16:14.939137Z","iopub.status.idle":"2021-07-24T11:16:14.968355Z","shell.execute_reply.started":"2021-07-24T11:16:14.939107Z","shell.execute_reply":"2021-07-24T11:16:14.967719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Here all the Garage related features has around 5% missing values.\n- We can fill those categories using mean and mode.(mean for numerical features and mode for categorical features)\n","metadata":{}},{"cell_type":"code","source":"# Garage string features ==> fill with Mode                                           \ndf['GarageType']= df['GarageType'].fillna('Attchd')    \ndf['GarageCond']= df['GarageCond'].fillna('TA') \ndf['GarageFinish']= df['GarageFinish'].fillna('Unf') \ndf['GarageQual']= df['GarageQual'].fillna('TA') \n\n# basement numeric features ==> fill with Mean\ndf['GarageYrBlt']= df['GarageYrBlt'].fillna(df.GarageYrBlt.mean()) \n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.969437Z","iopub.execute_input":"2021-07-24T11:16:14.969879Z","iopub.status.idle":"2021-07-24T11:16:14.979444Z","shell.execute_reply.started":"2021-07-24T11:16:14.969823Z","shell.execute_reply":"2021-07-24T11:16:14.978352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = percent_missing_data(df)\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:14.980774Z","iopub.execute_input":"2021-07-24T11:16:14.981104Z","iopub.status.idle":"2021-07-24T11:16:15.015419Z","shell.execute_reply.started":"2021-07-24T11:16:14.981074Z","shell.execute_reply":"2021-07-24T11:16:15.01474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Here some of the columns has more than 80% missing values. It is best option to drop them.","metadata":{}},{"cell_type":"code","source":"# Dropping columns with more than 80% missing values.\ndf = df.drop([\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\"], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.016432Z","iopub.execute_input":"2021-07-24T11:16:15.016834Z","iopub.status.idle":"2021-07-24T11:16:15.02254Z","shell.execute_reply.started":"2021-07-24T11:16:15.016794Z","shell.execute_reply":"2021-07-24T11:16:15.021797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = percent_missing_data(df)\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.023661Z","iopub.execute_input":"2021-07-24T11:16:15.024095Z","iopub.status.idle":"2021-07-24T11:16:15.059636Z","shell.execute_reply.started":"2021-07-24T11:16:15.024056Z","shell.execute_reply":"2021-07-24T11:16:15.058609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['FireplaceQu'].value_counts() , df['LotFrontage'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.06071Z","iopub.execute_input":"2021-07-24T11:16:15.061145Z","iopub.status.idle":"2021-07-24T11:16:15.076846Z","shell.execute_reply.started":"2021-07-24T11:16:15.061104Z","shell.execute_reply":"2021-07-24T11:16:15.075877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 'FireplaceQu' is categorical column, so missing values can be filled with 'None'.\n- But, 'LotFrontage' is numerical column and it also has outliers, so it can be filled with median.","metadata":{}},{"cell_type":"code","source":"df['FireplaceQu']= df['FireplaceQu'].fillna('None')    \ndf['LotFrontage']= df['LotFrontage'].fillna(df.LotFrontage.median())    ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.078297Z","iopub.execute_input":"2021-07-24T11:16:15.078894Z","iopub.status.idle":"2021-07-24T11:16:15.090878Z","shell.execute_reply.started":"2021-07-24T11:16:15.078832Z","shell.execute_reply":"2021-07-24T11:16:15.089728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values = percent_missing_data(df)\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.093923Z","iopub.execute_input":"2021-07-24T11:16:15.094322Z","iopub.status.idle":"2021-07-24T11:16:15.124568Z","shell.execute_reply.started":"2021-07-24T11:16:15.09429Z","shell.execute_reply":"2021-07-24T11:16:15.123792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Yayy!! There is no missing values now!","metadata":{}},{"cell_type":"markdown","source":"#### Numerical Features","metadata":{}},{"cell_type":"code","source":"df_numeric","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.125777Z","iopub.execute_input":"2021-07-24T11:16:15.126272Z","iopub.status.idle":"2021-07-24T11:16:15.168776Z","shell.execute_reply.started":"2021-07-24T11:16:15.126239Z","shell.execute_reply":"2021-07-24T11:16:15.167692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- numerical variables are skewed,so we can perform log normal distribution to prevent negative predictions.\n- We will only perform log normal distribution to columns which do not have any zero values.","metadata":{}},{"cell_type":"code","source":"num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n\nfor feature in num_features:\n    df[feature]=np.log(df[feature])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.170343Z","iopub.execute_input":"2021-07-24T11:16:15.170754Z","iopub.status.idle":"2021-07-24T11:16:15.180279Z","shell.execute_reply.started":"2021-07-24T11:16:15.17071Z","shell.execute_reply":"2021-07-24T11:16:15.17923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numeric","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.181909Z","iopub.execute_input":"2021-07-24T11:16:15.182202Z","iopub.status.idle":"2021-07-24T11:16:15.225875Z","shell.execute_reply.started":"2021-07-24T11:16:15.182175Z","shell.execute_reply":"2021-07-24T11:16:15.224717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Categorical Features:","metadata":{}},{"cell_type":"markdown","source":"- Let's Convert categorical features into numerical.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.227246Z","iopub.execute_input":"2021-07-24T11:16:15.227604Z","iopub.status.idle":"2021-07-24T11:16:15.295147Z","shell.execute_reply.started":"2021-07-24T11:16:15.227575Z","shell.execute_reply":"2021-07-24T11:16:15.293499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in df.select_dtypes(include = \"object\"):\n    labels_ordered=df.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    df[feature]=df[feature].map(labels_ordered)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.296686Z","iopub.execute_input":"2021-07-24T11:16:15.297375Z","iopub.status.idle":"2021-07-24T11:16:15.397681Z","shell.execute_reply.started":"2021-07-24T11:16:15.297342Z","shell.execute_reply":"2021-07-24T11:16:15.396553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.398782Z","iopub.execute_input":"2021-07-24T11:16:15.3991Z","iopub.status.idle":"2021-07-24T11:16:15.451539Z","shell.execute_reply.started":"2021-07-24T11:16:15.39907Z","shell.execute_reply":"2021-07-24T11:16:15.450509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.452885Z","iopub.execute_input":"2021-07-24T11:16:15.453296Z","iopub.status.idle":"2021-07-24T11:16:15.460935Z","shell.execute_reply.started":"2021-07-24T11:16:15.453249Z","shell.execute_reply":"2021-07-24T11:16:15.459729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Scaling","metadata":{}},{"cell_type":"code","source":"X = df.drop(['Id','SalePrice'],axis=1)\nY = df['SalePrice']","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.462283Z","iopub.execute_input":"2021-07-24T11:16:15.462576Z","iopub.status.idle":"2021-07-24T11:16:15.474283Z","shell.execute_reply.started":"2021-07-24T11:16:15.462548Z","shell.execute_reply":"2021-07-24T11:16:15.473073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.475567Z","iopub.execute_input":"2021-07-24T11:16:15.475841Z","iopub.status.idle":"2021-07-24T11:16:15.540588Z","shell.execute_reply.started":"2021-07-24T11:16:15.475814Z","shell.execute_reply":"2021-07-24T11:16:15.539525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard scaling our data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train) \nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.541844Z","iopub.execute_input":"2021-07-24T11:16:15.542157Z","iopub.status.idle":"2021-07-24T11:16:15.558301Z","shell.execute_reply.started":"2021-07-24T11:16:15.542127Z","shell.execute_reply":"2021-07-24T11:16:15.557265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape , X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.559769Z","iopub.execute_input":"2021-07-24T11:16:15.560081Z","iopub.status.idle":"2021-07-24T11:16:15.567146Z","shell.execute_reply.started":"2021-07-24T11:16:15.560047Z","shell.execute_reply":"2021-07-24T11:16:15.565989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Model Building & Evaluation","metadata":{}},{"cell_type":"markdown","source":"### Ridge Regression :","metadata":{}},{"cell_type":"code","source":"# Create the Ridge model\nfrom sklearn.linear_model import Ridge\nrid_reg = Ridge(alpha = 100)\nrid_reg.fit(X_train, Y_train)\n\nY_pred = rid_reg.predict(X_test)\n\n# testing the model\nfrom sklearn.metrics import r2_score,mean_absolute_error\nprint(\"MAE : \",mean_absolute_error(Y_test, Y_pred))\nprint('R2 SCORE : ',r2_score(Y_test, Y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.568671Z","iopub.execute_input":"2021-07-24T11:16:15.569018Z","iopub.status.idle":"2021-07-24T11:16:15.635257Z","shell.execute_reply.started":"2021-07-24T11:16:15.568988Z","shell.execute_reply":"2021-07-24T11:16:15.634015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, let's find best values for alpha and train model again\n\nalpha_list = []\nmse_list = []\nfor alpha_val in np.arange(0.01, 200):\n    ridge1 = Ridge(alpha = alpha_val)\n    ridge1.fit(X_train, Y_train)\n    alpha_list.append(alpha_val)\n    \n    # testing the model\n    Y_predict = ridge1.predict(X_test)\n    mse = mean_absolute_error(Y_test, Y_predict)\n    mse_list.append(mse)\n    \nalpha_list = pd.DataFrame(alpha_list)\nmse_list = pd.DataFrame(mse_list)\nalpha_mse = pd.concat([alpha_list, mse_list], axis = 1)\nalpha_mse.columns = [\"alpha_list\", \"mse_list\"]\n\nalpha_mse[alpha_mse[\"mse_list\"] == alpha_mse[\"mse_list\"].min()]","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:15.640636Z","iopub.execute_input":"2021-07-24T11:16:15.641124Z","iopub.status.idle":"2021-07-24T11:16:16.194157Z","shell.execute_reply.started":"2021-07-24T11:16:15.64107Z","shell.execute_reply":"2021-07-24T11:16:16.193096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the Ridge model using best alpha value:\nfrom sklearn.linear_model import Ridge\nrid_reg = Ridge(alpha = 8.01)\nrid_reg.fit(X_train, Y_train)\n\nY_pred_ridge = rid_reg.predict(X_test)\n\n# testing the model\nfrom sklearn.metrics import r2_score,mean_absolute_error\nridge_mae = mean_absolute_error(Y_test, Y_pred_ridge)\nridge_r2_score= r2_score(Y_test, Y_pred_ridge)\n\nprint(\"MAE for Ridge : \",ridge_mae)\nprint('R2 SCORE for Ridge: ',ridge_r2_score)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:16.199239Z","iopub.execute_input":"2021-07-24T11:16:16.201812Z","iopub.status.idle":"2021-07-24T11:16:16.220251Z","shell.execute_reply.started":"2021-07-24T11:16:16.201758Z","shell.execute_reply":"2021-07-24T11:16:16.218588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred.min()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:16.222202Z","iopub.execute_input":"2021-07-24T11:16:16.223091Z","iopub.status.idle":"2021-07-24T11:16:16.23179Z","shell.execute_reply.started":"2021-07-24T11:16:16.223043Z","shell.execute_reply":"2021-07-24T11:16:16.230396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsb.regplot(Y_pred_ridge,Y_test);","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:16.23377Z","iopub.execute_input":"2021-07-24T11:16:16.234554Z","iopub.status.idle":"2021-07-24T11:16:16.610766Z","shell.execute_reply.started":"2021-07-24T11:16:16.23451Z","shell.execute_reply":"2021-07-24T11:16:16.609837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lasso Regression","metadata":{}},{"cell_type":"code","source":"# Create Lasso model\nfrom sklearn.linear_model import Lasso\nls = Lasso(alpha = 0.8)\nls.fit(X_train, Y_train)\n\nY_pred = ls.predict(X_test)\n\n# testing the model\nfrom sklearn.metrics import mean_absolute_error\nprint(\"MAE : \",mean_absolute_error(Y_test, Y_pred))\n\nfrom sklearn.model_selection import cross_val_score\nprint('R2 SCORE : ',r2_score(Y_test, Y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:16.612751Z","iopub.execute_input":"2021-07-24T11:16:16.613457Z","iopub.status.idle":"2021-07-24T11:16:16.629354Z","shell.execute_reply.started":"2021-07-24T11:16:16.613414Z","shell.execute_reply":"2021-07-24T11:16:16.627898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, let's find best values for alpha and train model again\n\nalpha_list = []\nmse_list = []\nfor alpha_val in np.arange(0.01, 200):\n    ls1 = Lasso(alpha = alpha_val)\n    ls1.fit(X_train, Y_train)\n    alpha_list.append(alpha_val)\n    \n    # testing the model\n    Y_predict = ls1.predict(X_test)\n    mse = mean_absolute_error(Y_test, Y_predict)\n    mse_list.append(mse)\n    \nalpha_list = pd.DataFrame(alpha_list)\nmse_list = pd.DataFrame(mse_list)\nalpha_mse = pd.concat([alpha_list, mse_list], axis = 1)\nalpha_mse.columns = [\"alpha_list\", \"mse_list\"]\n\nalpha_mse[alpha_mse[\"mse_list\"] == alpha_mse[\"mse_list\"].min()]","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:16.631028Z","iopub.execute_input":"2021-07-24T11:16:16.631715Z","iopub.status.idle":"2021-07-24T11:16:17.663997Z","shell.execute_reply.started":"2021-07-24T11:16:16.631672Z","shell.execute_reply":"2021-07-24T11:16:17.662891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the Lasso model using best alpha value:\n\nls = Lasso(alpha = 0.01)\nls.fit(X_train, Y_train)\n\nY_pred_lasso = ls.predict(X_test)\n\n# testing the model\nlasso_mae = mean_absolute_error(Y_test, Y_pred_lasso)\nlasso_r2_score= r2_score(Y_test, Y_pred_lasso)\n\nprint(\"MAE for Lasso : \",lasso_mae)\nprint('R2 SCORE for Lasso : ',lasso_r2_score)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:17.665572Z","iopub.execute_input":"2021-07-24T11:16:17.666288Z","iopub.status.idle":"2021-07-24T11:16:17.693124Z","shell.execute_reply.started":"2021-07-24T11:16:17.66624Z","shell.execute_reply":"2021-07-24T11:16:17.692033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_lasso.min()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:17.694969Z","iopub.execute_input":"2021-07-24T11:16:17.695677Z","iopub.status.idle":"2021-07-24T11:16:17.703186Z","shell.execute_reply.started":"2021-07-24T11:16:17.695631Z","shell.execute_reply":"2021-07-24T11:16:17.702276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsb.regplot(x = Y_pred_lasso, y = Y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:17.704803Z","iopub.execute_input":"2021-07-24T11:16:17.705513Z","iopub.status.idle":"2021-07-24T11:16:18.081223Z","shell.execute_reply.started":"2021-07-24T11:16:17.705469Z","shell.execute_reply":"2021-07-24T11:16:18.080255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Polynomial Regression","metadata":{}},{"cell_type":"code","source":"#Import the poly conerter \nfrom sklearn.preprocessing import PolynomialFeatures\npolynomial_converter = PolynomialFeatures(degree=2,include_bias=False)\n\n#convert X data \npoly_features_train = polynomial_converter.fit_transform(X_train)\npoly_features_test = polynomial_converter.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:18.082836Z","iopub.execute_input":"2021-07-24T11:16:18.083597Z","iopub.status.idle":"2021-07-24T11:16:18.123496Z","shell.execute_reply.started":"2021-07-24T11:16:18.08355Z","shell.execute_reply":"2021-07-24T11:16:18.122791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import elastic net \nfrom sklearn.linear_model import ElasticNetCV\nelastic_model = ElasticNetCV(l1_ratio= 1,tol=0.01)\nelastic_model.fit(poly_features_train,Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:18.125014Z","iopub.execute_input":"2021-07-24T11:16:18.125707Z","iopub.status.idle":"2021-07-24T11:16:24.647722Z","shell.execute_reply.started":"2021-07-24T11:16:18.125662Z","shell.execute_reply":"2021-07-24T11:16:24.646698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_poly = elastic_model.predict(poly_features_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:24.649062Z","iopub.execute_input":"2021-07-24T11:16:24.649336Z","iopub.status.idle":"2021-07-24T11:16:24.658768Z","shell.execute_reply.started":"2021-07-24T11:16:24.64931Z","shell.execute_reply":"2021-07-24T11:16:24.657442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing model\npoly_mae = mean_absolute_error(Y_test, Y_pred_poly)\npoly_r2_score = r2_score(Y_test, Y_pred_poly)\nprint(\"MAE for Polynomial: \",poly_mae)\nprint('R2 SCORE for Polynomial: ',poly_r2_score)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:24.660432Z","iopub.execute_input":"2021-07-24T11:16:24.660895Z","iopub.status.idle":"2021-07-24T11:16:24.673043Z","shell.execute_reply.started":"2021-07-24T11:16:24.660835Z","shell.execute_reply":"2021-07-24T11:16:24.67161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred.min()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:24.67507Z","iopub.execute_input":"2021-07-24T11:16:24.6755Z","iopub.status.idle":"2021-07-24T11:16:24.690518Z","shell.execute_reply.started":"2021-07-24T11:16:24.675459Z","shell.execute_reply":"2021-07-24T11:16:24.689085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsb.regplot(Y_pred_poly,Y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:24.696245Z","iopub.execute_input":"2021-07-24T11:16:24.698998Z","iopub.status.idle":"2021-07-24T11:16:25.077815Z","shell.execute_reply.started":"2021-07-24T11:16:24.698939Z","shell.execute_reply":"2021-07-24T11:16:25.076483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = pd.DataFrame({\n    'Regression Model': ['Ridge','Lasso','Polynomial'],\n    'MAE Score': [\n        ridge_mae, \n        lasso_mae,\n        poly_mae ],\n    'R2 Score': [\n        ridge_r2_score, \n        lasso_r2_score,\n        poly_r2_score   \n    ]})\nprint(\"--- MODEL EVALUATION---\")\nmodels.sort_values(by='MAE Score', ascending=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:16:25.079691Z","iopub.execute_input":"2021-07-24T11:16:25.080152Z","iopub.status.idle":"2021-07-24T11:16:25.09967Z","shell.execute_reply.started":"2021-07-24T11:16:25.080106Z","shell.execute_reply":"2021-07-24T11:16:25.098431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that **Ridge Regression Model is best suitable** here.","metadata":{}},{"cell_type":"markdown","source":"## Consider **UPVOTING** if you find it useful.....","metadata":{}},{"cell_type":"markdown","source":"### Please share your valuable feedbacks and suggestions in comments.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}