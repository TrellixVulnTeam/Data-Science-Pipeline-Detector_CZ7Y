{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-17T08:53:54.350355Z","iopub.execute_input":"2021-10-17T08:53:54.35099Z","iopub.status.idle":"2021-10-17T08:53:55.148652Z","shell.execute_reply.started":"2021-10-17T08:53:54.35087Z","shell.execute_reply":"2021-10-17T08:53:55.147544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing data**","metadata":{}},{"cell_type":"code","source":"data_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndata_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nId = data_test['Id']","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.150268Z","iopub.execute_input":"2021-10-17T08:53:55.150591Z","iopub.status.idle":"2021-10-17T08:53:55.25211Z","shell.execute_reply.started":"2021-10-17T08:53:55.150557Z","shell.execute_reply":"2021-10-17T08:53:55.250737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that some columns contain NaN's","metadata":{}},{"cell_type":"markdown","source":"# **Filling NaN's**","metadata":{}},{"cell_type":"code","source":"data_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.254089Z","iopub.execute_input":"2021-10-17T08:53:55.254375Z","iopub.status.idle":"2021-10-17T08:53:55.290068Z","shell.execute_reply.started":"2021-10-17T08:53:55.254347Z","shell.execute_reply":"2021-10-17T08:53:55.288846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in list(data_test.columns):\n    if data_train[col].dtype=='object':\n        if data_train[col].nunique() != data_test[col].nunique():\n            print(col,\":\", data_train[col].nunique(), \"uniques in train\", data_test[col].nunique(), \"uniques in test\")\n#due to different number of unique values we have to work with both datasets together","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.291698Z","iopub.execute_input":"2021-10-17T08:53:55.292031Z","iopub.status.idle":"2021-10-17T08:53:55.368585Z","shell.execute_reply.started":"2021-10-17T08:53:55.291982Z","shell.execute_reply":"2021-10-17T08:53:55.367396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Due to different number of uniques in train and test set i will join train and test set to preprocess","metadata":{}},{"cell_type":"markdown","source":"Removing houses with very big price","metadata":{}},{"cell_type":"code","source":"q97 = data_train.SalePrice.quantile(0.99)\nq003 = data_train.SalePrice.quantile(0.003)\n\nprint('Removed outliers, price values in: [{:.2f}; {:.2f}]'.format(0, q97)) #best was 0.99\ndata_train = data_train[(data_train.SalePrice < q97)].reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T09:19:26.505289Z","iopub.execute_input":"2021-10-17T09:19:26.50704Z","iopub.status.idle":"2021-10-17T09:19:26.554689Z","shell.execute_reply.started":"2021-10-17T09:19:26.506953Z","shell.execute_reply":"2021-10-17T09:19:26.553689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Target = data_train.SalePrice\ndata_train=data_train.drop('SalePrice',axis=1)\n#saving target variable","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.403663Z","iopub.execute_input":"2021-10-17T08:53:55.40396Z","iopub.status.idle":"2021-10-17T08:53:55.41028Z","shell.execute_reply.started":"2021-10-17T08:53:55.403933Z","shell.execute_reply":"2021-10-17T08:53:55.409525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Join the train and the test set\ndata = pd.concat([data_train, data_test], keys = ['train', 'test'])\ndata = data.drop(['index', 'Id'],axis = 1)\nfeatures = list(data.columns)\nprint('detected {:d} features'.format(len(features)))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.411746Z","iopub.execute_input":"2021-10-17T08:53:55.41213Z","iopub.status.idle":"2021-10-17T08:53:55.45712Z","shell.execute_reply.started":"2021-10-17T08:53:55.412099Z","shell.execute_reply":"2021-10-17T08:53:55.455954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking year features","metadata":{"execution":{"iopub.status.busy":"2021-10-17T10:10:10.338878Z","iopub.execute_input":"2021-10-17T10:10:10.339286Z","iopub.status.idle":"2021-10-17T10:10:10.345476Z","shell.execute_reply.started":"2021-10-17T10:10:10.339254Z","shell.execute_reply":"2021-10-17T10:10:10.34426Z"}}},{"cell_type":"code","source":"Check_years = data.columns[data.columns.str.contains(pat = 'Year|Yr')] \ndata[Check_years.values].max().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.459665Z","iopub.execute_input":"2021-10-17T08:53:55.459963Z","iopub.status.idle":"2021-10-17T08:53:55.476427Z","shell.execute_reply.started":"2021-10-17T08:53:55.459935Z","shell.execute_reply":"2021-10-17T08:53:55.474872Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Replace_year = data.loc[(data['GarageYrBlt'] > 2050), 'GarageYrBlt'].index.tolist()\ndata.loc[Replace_year, 'GarageYrBlt'] = data['GarageYrBlt'].mode()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.478607Z","iopub.execute_input":"2021-10-17T08:53:55.479193Z","iopub.status.idle":"2021-10-17T08:53:55.4969Z","shell.execute_reply.started":"2021-10-17T08:53:55.479161Z","shell.execute_reply":"2021-10-17T08:53:55.49598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing NaNs","metadata":{}},{"cell_type":"code","source":"Na_perc = []\nfor feature in features:\n    percentage = len(data[feature][data[feature].isna() == True]) / len(data[feature])\n    Na_perc.append(percentage)\nNas = pd.DataFrame({'feature' : features, 'Na_perc': Na_perc}).sort_values(by = 'Na_perc', ascending = False)\nNas = Nas[Nas.Na_perc > 0.01]\n \nplt.figure(figsize=(7,7))\nplt.title('NaN percentage')\nplt.xlabel(\"Top features\")\nsns.barplot(x = Nas.Na_perc, y = Nas.feature, orient = 'h')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.498441Z","iopub.execute_input":"2021-10-17T08:53:55.499004Z","iopub.status.idle":"2021-10-17T08:53:55.862562Z","shell.execute_reply.started":"2021-10-17T08:53:55.498968Z","shell.execute_reply":"2021-10-17T08:53:55.861439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features=[]\ncat_features=[]\nord_features=[]\nfor feature in features:\n    if str(data[feature].dtype) == 'object':\n        data[feature] = data[feature].fillna('None')\n        #data_test[feature] = data_test[feature].fillna('None')\n        cat_features.append(feature)\n        pass\n    \n    if  str(data[feature].dtype)=='float64':\n        if data[feature].nunique() < 50:\n            ord_features.append(feature)\n            #data[feature] = data[feature].fillna(data[feature].mean())\n        else:\n            #data[feature] = data[feature].fillna(int(data[feature].mean()))\n            num_features.append(feature)\n        pass\n    \n    if str(data[feature].dtype) == 'int64':\n        #data_test[feature] =data_test[feature]\n        if data[feature].nunique() < 50:\n            ord_features.append(feature)\n            #data[feature] = data[feature].fillna(data[feature].mean())\n        else:\n            num_features.append(feature)\n            #data[feature] = data[feature].fillna(int(data[feature].mean()))\n        \n        pass\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.863827Z","iopub.execute_input":"2021-10-17T08:53:55.864136Z","iopub.status.idle":"2021-10-17T08:53:55.924959Z","shell.execute_reply.started":"2021-10-17T08:53:55.864107Z","shell.execute_reply":"2021-10-17T08:53:55.924212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import RobustScaler\nnum_ord_data = data[num_features + ord_features].copy()\nscaler = RobustScaler()\nnum_ord_data = scaler.fit_transform(num_ord_data)\nimputer = KNNImputer(n_neighbors = 10, weights = 'uniform')\nnum_ord_data = imputer.fit_transform(num_ord_data)\nnum_ord_data_transformed = pd.DataFrame(num_ord_data, columns = num_features + ord_features)\n#num_ord_data = scaler.inverse_transform(num_ord_data_transformed)\ntrans_back = scaler.inverse_transform(num_ord_data_transformed)\nnum_ord_data_transformed = pd.DataFrame(trans_back, columns = num_features + ord_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:55.926267Z","iopub.execute_input":"2021-10-17T08:53:55.926831Z","iopub.status.idle":"2021-10-17T08:53:56.598795Z","shell.execute_reply.started":"2021-10-17T08:53:55.926788Z","shell.execute_reply":"2021-10-17T08:53:56.596755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.reset_index()\nfor col in num_features + ord_features:\n    data[col] = num_ord_data_transformed[col]","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:56.659573Z","iopub.execute_input":"2021-10-17T08:53:56.659914Z","iopub.status.idle":"2021-10-17T08:53:56.738731Z","shell.execute_reply.started":"2021-10-17T08:53:56.659886Z","shell.execute_reply":"2021-10-17T08:53:56.738064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Numeric features:\", len(num_features))\nprint(\"Ordinal features:\", len(ord_features))\nprint(\"Categorical features:\", len(cat_features))\nif len(num_features) + len(ord_features) + len(cat_features) != len(features):\n    print(\"missing features\")\nelse:\n    print('no missing,', len(num_features) + len(ord_features) + len(cat_features), \"features\")","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:56.739894Z","iopub.execute_input":"2021-10-17T08:53:56.740454Z","iopub.status.idle":"2021-10-17T08:53:56.749125Z","shell.execute_reply.started":"2021-10-17T08:53:56.740406Z","shell.execute_reply":"2021-10-17T08:53:56.747773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_list_cat = []\nmax_list_ord = []\nidx_max_cat = []\nidx_max_ord = []\n\nfor feature in cat_features:\n    cat_vals = data[feature].value_counts(normalize=True)\n    max_list_cat.append(cat_vals.max())\n    idx_max_cat.append(cat_vals.idxmax())\n    \nmax_zero_percentage_num = []\nfor feature in num_features:\n    percentage = data[feature][data[feature] == 0].count() / len(data[feature])\n    max_zero_percentage_num.append(percentage)\n\nmax_zero_percentage_ord = []\nfor feature in ord_features:\n    ord_vals = data[feature].value_counts(normalize=True)\n    max_list_ord.append(ord_vals.max())\n    idx_max_ord.append(ord_vals.idxmax()) ","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:56.750827Z","iopub.execute_input":"2021-10-17T08:53:56.751247Z","iopub.status.idle":"2021-10-17T08:53:56.877101Z","shell.execute_reply.started":"2021-10-17T08:53:56.751213Z","shell.execute_reply":"2021-10-17T08:53:56.875282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zeroes_num = pd.DataFrame({'feature' : num_features, 'ratio' : max_zero_percentage_num}).sort_values(by = 'ratio', ascending=False)\nvals_ord = pd.DataFrame({'feature' : ord_features, 'ratio' : max_list_ord, 'top_value' : idx_max_ord}).sort_values(by = 'ratio', ascending = False)\nsingl_el = pd.DataFrame({'feature' : cat_features, 'ratio' : max_list_cat, 'top_value' : idx_max_cat}).sort_values(by = 'ratio', ascending = False)\n\nfig = plt.figure(figsize=(15,10))\n\nplt.subplot(1, 3, 1)\nplt.title('Max zero ratio in numeric data')\nplt.xlabel(\"Top features\")\nsns.barplot(x = zeroes_num.ratio, y = zeroes_num.feature, orient = 'h')\n\nplt.subplot(1, 3, 2)\nplt.title('Max zero ratio in numeric data')\nplt.xlabel(\"Top features\")\nsns.barplot(x = vals_ord.ratio, y = vals_ord.feature, orient = 'h')\n\nplt.subplot(1, 3, 3)\nplt.title('Max single element ratio')\nplt.xlabel(\"Top features\")\nsns.barplot(x = singl_el.ratio, y = singl_el.feature, orient = 'h')\nplt.subplots_adjust( bottom=None, right=None, top=None, wspace=1, hspace=None)\nplt.show()\n ","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:56.879155Z","iopub.execute_input":"2021-10-17T08:53:56.879627Z","iopub.status.idle":"2021-10-17T08:53:58.268137Z","shell.execute_reply.started":"2021-10-17T08:53:56.879579Z","shell.execute_reply":"2021-10-17T08:53:58.267155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adiing new features","metadata":{}},{"cell_type":"code","source":"data['TotalPorch'] = (data['ScreenPorch'] + data['EnclosedPorch'] + \n                         data['3SsnPorch'] + data['ScreenPorch'])\n\ndata['Rooms_kitchens'] = (data['TotRmsAbvGrd'] + data['BsmtFullBath'] + \n                             data['BsmtHalfBath'] + data['FullBath'] + \n                             data['HalfBath'])\n\ndata['Sqr_feet_per_room'] = ((data['1stFlrSF'] + \n                                 data['2ndFlrSF']) / data['TotRmsAbvGrd'])\ndata['lotfr_lotarea'] = (data['LotFrontage'] + data['LotArea']) / 2\n\ndata['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\n\ndata['cond_qual'] = (data['OverallCond'] * data['OverallQual'])\ndata['HouseAge'] = data['YrSold'] - data['YearBuilt'] + 1\n#data['TotalPorch'].fillna(data['TotalPorch'].mean())\n#data['Rooms_kitchens'].fillna(data['Rooms_kitchens'].mode())\n\n\nnum_features.append('TotalSF')\nnum_features.append('TotalPorch')\nnum_features.append('lotfr_lotarea')\nnum_features.append('HouseAge')\nord_features.append('Rooms_kitchens')\nord_features.append('cond_qual')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.271574Z","iopub.execute_input":"2021-10-17T08:53:58.271882Z","iopub.status.idle":"2021-10-17T08:53:58.290445Z","shell.execute_reply.started":"2021-10-17T08:53:58.271851Z","shell.execute_reply":"2021-10-17T08:53:58.288899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dealing with imbalanced features","metadata":{}},{"cell_type":"code","source":"imb_num_features = zeroes_num.feature.head(3)\nimb_ord_features = vals_ord[['feature', 'top_value']].head(5)\nimb_cat_features = singl_el.feature[singl_el.top_value == 'None'].head(16)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.294726Z","iopub.execute_input":"2021-10-17T08:53:58.295285Z","iopub.status.idle":"2021-10-17T08:53:58.308085Z","shell.execute_reply.started":"2021-10-17T08:53:58.295243Z","shell.execute_reply":"2021-10-17T08:53:58.306647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in imb_num_features:\n    data[feature][data[feature] != 0] = 0\n    data[feature][data[feature] == 0] = 1\n    num_features.remove(feature)\n    cat_features.append(feature)\nfor feature in imb_ord_features.feature:\n    data[feature][data[feature] != 0] = 0\n    data[feature][data[feature] == 0] = 1\n    ord_features.remove(feature)\n    cat_features.append(feature)\nfor feature in imb_cat_features:\n    data[feature][data[feature] != 'None'] = 'Present'","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.309685Z","iopub.execute_input":"2021-10-17T08:53:58.310094Z","iopub.status.idle":"2021-10-17T08:53:58.377134Z","shell.execute_reply.started":"2021-10-17T08:53:58.310065Z","shell.execute_reply":"2021-10-17T08:53:58.375736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Numeric features:\", len(num_features))\nprint(\"Ordinal features:\", len(ord_features))\nprint(\"Categorical features:\", len(cat_features))\nif len(num_features) + len(ord_features) + len(cat_features) != len(features):\n    print(\"missing features\")\nelse:\n    print('no missing,', len(num_features) + len(ord_features) + len(cat_features), \"features\")","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.378664Z","iopub.execute_input":"2021-10-17T08:53:58.378951Z","iopub.status.idle":"2021-10-17T08:53:58.388999Z","shell.execute_reply.started":"2021-10-17T08:53:58.378914Z","shell.execute_reply":"2021-10-17T08:53:58.387644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in cat_features:\n    ratio = data[feature][data[feature] == 'None'].count() / len(data[feature])\n    if ratio > 0.75: #best was 0.75\n        cat_features.remove(feature)\n        print('removed', feature)\nfor feature in ord_features:\n    ratio = data[feature][data[feature] == 0].count() / len(data[feature])\n    if ratio > 0.75: #best was 0.75\n        ord_features.remove(feature)\n        print('removed', feature)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.461075Z","iopub.execute_input":"2021-10-17T08:53:58.46154Z","iopub.status.idle":"2021-10-17T08:53:58.522248Z","shell.execute_reply.started":"2021-10-17T08:53:58.461495Z","shell.execute_reply":"2021-10-17T08:53:58.520948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I decided to use log of the data to prevent big values","metadata":{}},{"cell_type":"code","source":"for col in num_features:\n    data[col] = np.log(data[col] + 1)\nfor col in ord_features:\n    data[col] = np.log(data[col] + 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.524351Z","iopub.execute_input":"2021-10-17T08:53:58.524859Z","iopub.status.idle":"2021-10-17T08:53:58.560871Z","shell.execute_reply.started":"2021-10-17T08:53:58.524805Z","shell.execute_reply":"2021-10-17T08:53:58.559743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = data[data.level_0 == 'train'].drop(['level_0', 'level_1'], axis = 1)\ndata_test = data[data.level_0 == 'test'].drop(['level_0', 'level_1'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.633621Z","iopub.execute_input":"2021-10-17T08:53:58.633968Z","iopub.status.idle":"2021-10-17T08:53:58.65646Z","shell.execute_reply.started":"2021-10-17T08:53:58.633937Z","shell.execute_reply":"2021-10-17T08:53:58.654604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"Log of the price seems to be more normal","metadata":{}},{"cell_type":"code","source":"Target.hist(bins = 20)\nplt.show()\nTarget = np.log(Target + 1)\nTarget.hist(bins = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:58.658061Z","iopub.execute_input":"2021-10-17T08:53:58.6584Z","iopub.status.idle":"2021-10-17T08:53:59.036632Z","shell.execute_reply.started":"2021-10-17T08:53:58.658368Z","shell.execute_reply":"2021-10-17T08:53:59.035255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import cm\n\na = 8  # number of rows\nb = 3  # number of columns\nc = 1  # initialize plot counter\n\nfig = plt.figure(figsize=(21,35))\n\nfor feature in num_features:\n    plt.subplot(a, b, c)\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.scatter(data_train[feature], Target ,s = 2, label = feature, c=cm.cool(Target / Target.max()/2))\n    c = c + 1  ","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:53:59.037835Z","iopub.execute_input":"2021-10-17T08:53:59.038125Z","iopub.status.idle":"2021-10-17T08:54:02.017327Z","shell.execute_reply.started":"2021-10-17T08:53:59.038096Z","shell.execute_reply":"2021-10-17T08:54:02.016089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that some features have string correlation with the final price","metadata":{}},{"cell_type":"code","source":"a = 5  # number of rows\nb = 3  # number of columns\nc = 1  # initialize plot counter\n\nfig = plt.figure(figsize=(20,25))\n\nfor feature in ord_features:\n    plt.subplot(a, b, c)\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.scatter(data_train[feature], Target ,s = 2, label = feature, c=cm.cool(Target / Target.max()/2))\n    c = c + 1  ","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:02.01917Z","iopub.execute_input":"2021-10-17T08:54:02.01957Z","iopub.status.idle":"2021-10-17T08:54:04.227221Z","shell.execute_reply.started":"2021-10-17T08:54:02.019526Z","shell.execute_reply":"2021-10-17T08:54:04.226058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['SalePrice'] = Target","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:04.229094Z","iopub.execute_input":"2021-10-17T08:54:04.229519Z","iopub.status.idle":"2021-10-17T08:54:04.236328Z","shell.execute_reply.started":"2021-10-17T08:54:04.229478Z","shell.execute_reply":"2021-10-17T08:54:04.235066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Removing high collecalted variables","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(11,9)) \ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nmask  = np.triu(np.ones_like(data_train[num_features].corr(), dtype=bool))\nsns.heatmap(data_train[num_features].corr(),ax=ax,\n            cmap = cmap, square=True, linewidths=.5, cbar_kws={\"shrink\": .5},\n            mask=mask)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T09:32:49.480358Z","iopub.execute_input":"2021-10-17T09:32:49.48079Z","iopub.status.idle":"2021-10-17T09:32:50.026317Z","shell.execute_reply.started":"2021-10-17T09:32:49.480758Z","shell.execute_reply":"2021-10-17T09:32:50.024917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features.remove('GarageYrBlt')\nnum_features.remove('1stFlrSF')\nord_features.remove('MoSold')\nord_features.remove('YrSold')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.015003Z","iopub.status.idle":"2021-10-17T08:54:05.015509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph below shows how our features are correlated with the price","metadata":{}},{"cell_type":"code","source":"num_list = []\nord_list = []\nfor feature in num_features:\n    num_list.append(data_train[feature].corr(data_train.SalePrice))\n\nnumcorrs = pd.DataFrame({'num_feature' : num_features, 'corr': num_list}).sort_values(by = 'corr', ascending = False)\nfor feature in ord_features:\n    #print(feature,eda_data[feature].corr(eda_data.SalePrice))\n    ord_list.append(data_train[feature].corr(data_train.SalePrice))\n    #if abs(eda_data[feature].corr(eda_data.SalePrice)) < 0.1:\n    #    ord_features.remove(feature)\nordcorrs = pd.DataFrame({'ord_feature' : ord_features, 'corr': ord_list}).sort_values(by = 'corr', ascending = False)\nfig = plt.figure(figsize=(10,7))\nplt.subplot(1,2,1)\nplt.title('Correlation between numerical features and SalePrice')\nsns.barplot(x = numcorrs['corr'], y = numcorrs['num_feature'], orient = 'h')\nplt.subplot(1,2,2)\nplt.title('Correlation between ordinal features and SalePrice')\nsns.barplot(x = ordcorrs['corr'], y = ordcorrs['ord_feature'], orient = 'h')\nplt.subplots_adjust( bottom=None, right=None, top=None, wspace=1, hspace=None)\n    # compute correlation between sale price and other numeric features","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.019282Z","iopub.status.idle":"2021-10-17T08:54:05.02006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Removing the outliers","metadata":{}},{"cell_type":"markdown","source":"I will use Lasso model to remove the outliers by simply deleting rows with the largest residuals","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\ny_train = data_train['SalePrice']\ndata_train.drop('SalePrice', axis = 1)\ndata_train_dum = pd.get_dummies(data_train)\nlasso = Lasso()\nlasso.fit(data_train_dum, y_train)\nouts = ((lasso.predict(data_train_dum) - y_train)**2).to_frame().sort_values(by = 'SalePrice', ascending = False)\nbad_ind = outs[outs.SalePrice > 0.92].index.to_list() #best was 0.92\ndata_train = data_train.drop(bad_ind, axis = 0)\nTarget = Target.drop(bad_ind, axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.021755Z","iopub.status.idle":"2021-10-17T08:54:05.022438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting some new variables","metadata":{}},{"cell_type":"code","source":"data = pd.concat([data_train, data_test], keys = ['train', 'test']).reset_index()\ndata = data.drop('level_1', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.024364Z","iopub.status.idle":"2021-10-17T08:54:05.025061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used the min max scaling to move the data into [0, 1]","metadata":{}},{"cell_type":"code","source":"for col in num_features + ord_features:\n    data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n#for col in num_features + ord_features:\n#    data[col] = (data[col] - data[col].mean()) / data[col].std()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.026555Z","iopub.status.idle":"2021-10-17T08:54:05.027225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_features=num_features + cat_features + ord_features\nprint(\"Amount of features:\",len(final_features))\nfinal_data = data[final_features]","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.028754Z","iopub.status.idle":"2021-10-17T08:54:05.02943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are some new features got from combinations","metadata":{"execution":{"iopub.status.busy":"2021-10-17T10:20:09.901947Z","iopub.execute_input":"2021-10-17T10:20:09.902394Z","iopub.status.idle":"2021-10-17T10:20:09.91026Z","shell.execute_reply.started":"2021-10-17T10:20:09.902357Z","shell.execute_reply":"2021-10-17T10:20:09.908373Z"}}},{"cell_type":"code","source":"from itertools import combinations\n\nhigh_corr_num_features = ['GrLivArea', 'YearBuilt', 'YearRemodAdd', 'HouseAge']\nhigh_corr_ord_features = ['OverallQual', 'Rooms_kitchens', 'GarageCars', 'FullBath', 'Fireplaces', 'TotRmsAbvGrd']\n\nfor c_1, c_2 in combinations(final_data[high_corr_num_features], 2):\n    final_data['{0}x{1}'.format(c_1, c_2)] = final_data[c_1] * final_data[c_2]\n    final_data['{0}+{1}'.format(c_1, c_2)] = (final_data[c_1] + final_data[c_2]) / 2 \nfor c_1, c_2 in combinations(final_data[high_corr_ord_features], 2):\n    final_data['{0}x{1}'.format(c_1, c_2)] = final_data[c_1] * final_data[c_2]\n    #final_data['{0}+{1}'.format(c_1, c_2)] = (final_data[c_1] + final_data[c_2])/2\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.03074Z","iopub.status.idle":"2021-10-17T08:54:05.031395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final data","metadata":{}},{"cell_type":"markdown","source":"I used get_dummies method to create dummy vars for categorical columns","metadata":{}},{"cell_type":"code","source":"final_data_dummies=pd.get_dummies(final_data, drop_first = False)\nfinal_data_dummies['level']=data.level_0\nfinal_data_dummies_train=final_data_dummies[final_data_dummies.level=='train']\nfinal_data_dummies_test=final_data_dummies[final_data_dummies.level=='test']","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.032477Z","iopub.status.idle":"2021-10-17T08:54:05.032903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = final_data_dummies_train.drop('level',axis=1)\ny = Target\nX_test = final_data_dummies_test.drop('level', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.033691Z","iopub.status.idle":"2021-10-17T08:54:05.034102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Models and Tuning them with Hyperopt","metadata":{}},{"cell_type":"markdown","source":"There are some useful functions to measure the quality of the models","metadata":{}},{"cell_type":"code","source":"def evaluate(base_model, tuned_model, X_train, y_train, test_features, test_labels, fit_params=None):\n    base_model.fit(X_train, y_train)\n    predictions = base_model.predict(test_features)\n    print('Model Performance')\n    print('MSE = {:0.4f}'.format(mean_squared_error(predictions, test_labels, squared = False)))\n    \n    base_mse = mean_squared_error(predictions, test_labels)\n    if 'XGBRegressor' in str(tuned_model):\n        tuned_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (test_features, test_labels)], **fit_params)\n    elif 'LGBMRegressor' in str(tuned_model):\n        tuned_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (test_features, test_labels)], **fit_params)\n    else:\n        tuned_model.fit(X_train, y_train, **fit_params)\n    predictions = tuned_model.predict(test_features)\n    print('Model Performance')\n    print('MSE = {:0.4f}'.format(mean_squared_error(predictions, test_labels, squared = False)))\n    tuned_mse = mean_squared_error(predictions, test_labels)\n    print('Improvement of {:0.2f}%.'.format( 100 * (base_mse - tuned_mse) / base_mse))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.035106Z","iopub.status.idle":"2021-10-17T08:54:05.035485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperopt tuner class ","metadata":{}},{"cell_type":"code","source":"from hyperopt import hp, fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n\nclass HPOpt(object):\n\n    def __init__(self, x_train, x_test, y_train, y_test):\n        self.x_train = x_train\n        self.x_test  = x_test\n        self.y_train = y_train\n        self.y_test  = y_test\n\n    def process(self, fn_name, space, trials, algo, max_evals):\n        fn = getattr(self, fn_name)\n        try:\n            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n        except Exception as e:\n            return {'status': STATUS_FAIL,\n                    'exception': str(e)}\n        return result, trials\n\n    def xgb_reg(self, para):\n        reg = xgb.XGBRegressor(**para['reg_params'])\n        return self.train_reg(reg, para)\n    \n    def rf_reg(self, para):\n        reg = RandomForestRegressor(**para['reg_params'])\n        return self.train_reg(reg, para)\n    \n    def lasso_reg(self, para):\n        reg = linear_model.Lasso(**para['reg_params'])\n        return self.train_reg(reg, para)\n    \n    def elnet_reg(self, para):\n        reg = linear_model.ElasticNet(**para['reg_params'])\n        return self.train_reg(reg, para)\n\n    def lgb_reg(self, para):\n        reg = lgb.LGBMRegressor(**para['reg_params'])\n        return self.train_reg(reg, para)\n    \n    def svr_reg(self, para):\n        reg = SVR(**para['reg_params'])\n        return self.train_reg(reg, para)\n\n\n    def train_reg(self, reg, para):\n        if 'RandomForestRegressor'  in str(reg):\n            reg.fit(self.x_train, self.y_train)\n        elif 'Lasso' in str(reg):\n            reg.fit(self.x_train, self.y_train)\n        elif 'ElasticNet' in str(reg):\n            reg.fit(self.x_train, self.y_train)\n        elif 'SVR' in str(reg):\n            reg.fit(self.x_train, self.y_train)\n        else:   \n            reg.fit(self.x_train, self.y_train,\n                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n                **para['fit_params'])\n        pred = reg.predict(self.x_test)\n        loss = para['loss_func'](self.y_test, pred)\n        return {'loss': loss, 'status': STATUS_OK}","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.036301Z","iopub.status.idle":"2021-10-17T08:54:05.036687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.037433Z","iopub.status.idle":"2021-10-17T08:54:05.037815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lasso","metadata":{}},{"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\n\nlasso = linear_model.Lasso()\n\nalpha = {'alpha': [x / 25000 for x in range(1, 50, 1)],\n         'tol': [0.0000001], \n          'max_iter': [3000]}\n\n\nlasso.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.038593Z","iopub.status.idle":"2021-10-17T08:54:05.038971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_iter = range(100, 5000, 100)\n\nlasso_reg_params = {'alpha':              hp.uniform('alpha', 0.00000001, 0.5),\n                 'tol':                hp.uniform('tol', 0.0000001, 0.5),\n                 'max_iter':           hp.choice('max_iter', max_iter),\n                }\nlasso_fit_params = {\n                    'sample_weight' : None\n}\nobj = HPOpt(X_train, X_holdout, y_train, y_holdout)\n\n\n#rf_fit_params = {\n#    'sample_weight': None,\n#}\nlasso_para = dict()\nlasso_para['reg_params'] = lasso_reg_params\nlasso_para['fit_params'] = lasso_fit_params\nlasso_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n\nlasso_opt_para = obj.process(fn_name='lasso_reg', space=lasso_para, trials=Trials(), algo=tpe.suggest, max_evals=500)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.039735Z","iopub.status.idle":"2021-10-17T08:54:05.040143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best 0.0929 <- 0.1389","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.040874Z","iopub.status.idle":"2021-10-17T08:54:05.041293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso_opt_para\n#{'alpha': 0.0003423653832332181, 'max_iter': 14, 'tol': 0.021055934172052676}","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.042036Z","iopub.status.idle":"2021-10-17T08:54:05.042449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso_reg_opt_params = {'alpha':               lasso_opt_para[0]['alpha'],\n                        'tol':                 lasso_opt_para[0]['tol'],\n                        'max_iter':            max_iter[lasso_opt_para[0]['max_iter']],\n                        }\nlasso_opt = linear_model.Lasso(**lasso_reg_opt_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.043712Z","iopub.status.idle":"2021-10-17T08:54:05.044174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(lasso, lasso_opt, X_train, y_train, X_holdout, y_holdout, lasso_fit_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.045135Z","iopub.status.idle":"2021-10-17T08:54:05.045533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGB","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nxg_reg = xgb.XGBRegressor(learning_rate = 0.1,\n                          max_depth = 4, \n                          objective=\"reg:squarederror\", \n                          n_estimators=700)\nxg_reg.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.046745Z","iopub.status.idle":"2021-10-17T08:54:05.047168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj = HPOpt(X_train, X_holdout, y_train, y_holdout)\nbooster = ['gbtree']\nlearning_rate = np.arange(0.01, 0.7, 0.05)\nmax_depth = range(5, 20, 1)\nmin_child_weight = range(1, 20, 1)\nn_estimators = range(100, 5000, 100)\n\nxgb_reg_params = {\n    'booster':          hp.choice('booster',          booster),\n    'learning_rate':    hp.choice('learning_rate',    learning_rate),\n    'max_depth':        hp.choice('max_depth',        max_depth),\n    'min_child_weight': hp.choice('min_child_weight', min_child_weight),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.0001, 1),\n    'subsample':        hp.uniform('subsample', 0.0001, 1),\n    'n_estimators':     hp.choice('n_estimators',     n_estimators)\n}\nxgb_fit_params = {\n    'eval_metric': 'rmse',\n    'early_stopping_rounds': 10,\n    'verbose': False\n}\nxgb_para = dict()\nxgb_para['reg_params'] = xgb_reg_params\nxgb_para['fit_params'] = xgb_fit_params\nxgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n\nxgb_opt_para = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo = tpe.suggest, max_evals=120)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.048152Z","iopub.status.idle":"2021-10-17T08:54:05.048555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best 0.1000 <- 0.1422","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.049555Z","iopub.status.idle":"2021-10-17T08:54:05.049963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_reg_opt_params = {\n    'booster':          'gbtree',\n    'learning_rate':    learning_rate[xgb_opt_para[0]['learning_rate']],\n    'max_depth':        max_depth[xgb_opt_para[0]['max_depth']],\n    'min_child_weight': min_child_weight[xgb_opt_para[0]['min_child_weight']],\n    'colsample_bytree': xgb_opt_para[0]['colsample_bytree'],\n    'subsample':        xgb_opt_para[0]['subsample'],\n    'n_estimators':     n_estimators[xgb_opt_para[0]['n_estimators']]\n}\nxgb_reg_opt = xgb.XGBRegressor(**xgb_reg_opt_params)\nxgb_reg_opt_params","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.050835Z","iopub.status.idle":"2021-10-17T08:54:05.051248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(xg_reg, xgb_reg_opt, X_train, y_train, X_holdout, y_holdout, xgb_fit_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.052284Z","iopub.status.idle":"2021-10-17T08:54:05.052691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Support Vector Machine","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\n\nsvr_reg = SVR()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.053768Z","iopub.status.idle":"2021-10-17T08:54:05.054181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C = list(range(1, 100, 1))\nepsilon = [x / 2000 for x in range(1, 50, 1)]\ngamma = [x / 10000 for x in range(1, 50, 1)]\nsvr_reg_params = {\n              'C' : hp.choice('C', C),\n              'epsilon' : hp.uniform('epsilon', 0, 0.05),\n              'gamma' :   hp.uniform('gamma', 0, 0.05)}\n\nsvr_fit_params = {\n                    'sample_weight' : None\n}\nobj = HPOpt(X_train, X_holdout, y_train, y_holdout)\n\n\n\nsvr_para = dict()\nsvr_para['reg_params'] = svr_reg_params\nsvr_para['fit_params'] = svr_fit_params\nsvr_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n\nsvr_opt_para = obj.process(fn_name='svr_reg', space=svr_para, trials=Trials(), algo=tpe.suggest, max_evals=200)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.055129Z","iopub.status.idle":"2021-10-17T08:54:05.055524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best 0.092 <- 0.1163","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.056463Z","iopub.status.idle":"2021-10-17T08:54:05.056866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svr_opt_para","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.057805Z","iopub.status.idle":"2021-10-17T08:54:05.058211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svr_reg_opt_params = {  'kernel':        'rbf',\n                        'C':              C[svr_opt_para[0]['C']],\n                        'epsilon':         svr_opt_para[0]['epsilon'],\n                        'gamma':         svr_opt_para[0]['gamma'],\n                        }\n\nsvr_reg_opt = SVR(**svr_reg_opt_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.059267Z","iopub.status.idle":"2021-10-17T08:54:05.059672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(svr_reg, svr_reg_opt, X_train, y_train, X_holdout, y_holdout, svr_fit_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.060551Z","iopub.status.idle":"2021-10-17T08:54:05.06096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LGBM","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nlgb_reg = lgb.LGBMRegressor()\nlgb_reg.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.061892Z","iopub.status.idle":"2021-10-17T08:54:05.062473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj = HPOpt(X_train, X_holdout, y_train, y_holdout)\nreg_lambda = [0.01, 0.05, 0.1, 0.2, 0.5, 1, 2]\nlearning_rate = np.arange(0.01, 0.5, 0.05)\nreg_alpha = np.arange(0.01, 2, 0.05)\nmin_child_samples = range(1, 100, 1)\nnum_leaves = range(2, 200, 1)\nsubsample_freq = range(1, 200, 1)\nmax_depth = range(5, 20, 1)\nmin_child_weight = range(1, 20, 1)\nn_estimators = range(100, 5000, 100)\nmax_bin = range(2, 700, 1)\n\nLGBM_params = {'reg_lambda':                  hp.choice('reg_lambda', reg_lambda),\n                      'reg_alpha':            hp.choice('reg_alpha', reg_alpha),\n                      'min_child_samples':    hp.choice('min_child_samples', min_child_samples),\n                      'subsample':            hp.uniform('subsample', 0.01, 1), # bagging_fraction\n                      'subsample_freq':       hp.choice('subsample_freq', subsample_freq), # bagging_freq\n                      'num_leaves':           hp.choice('num_leaves', num_leaves),\n                      'max_depth':            hp.choice('max_depth', max_depth),\n                      'max_bin':              hp.choice('max_bin', max_bin),\n                      'learning_rate':        hp.choice('learning_rate', learning_rate),\n                      'colsample_bytree':     hp.uniform('colsample_bytree', 0.01, 1)} # feature_fraction \nlgb_fit_params = {\n    'eval_metric': 'rmse',\n    'early_stopping_rounds': 10,\n    'verbose': False\n}\nlgb_para = dict()\nlgb_para['reg_params'] = LGBM_params\nlgb_para['fit_params'] = lgb_fit_params\nlgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n\nlgb_opt_params = obj.process(fn_name='lgb_reg', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=300)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.063526Z","iopub.status.idle":"2021-10-17T08:54:05.063967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best 0.1048 <- 0.1191","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.064848Z","iopub.status.idle":"2021-10-17T08:54:05.065277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_reg_params = {\n    'reg_lambda':            reg_lambda[lgb_opt_params[0]['reg_lambda']],\n    'reg_alpha':             reg_alpha[lgb_opt_params[0]['reg_alpha']],\n    'min_child_samples':     min_child_samples[lgb_opt_params[0]['min_child_samples']],\n    'subsample':             lgb_opt_params[0]['subsample'], \n    'subsample_freq':        subsample_freq[lgb_opt_params[0]['subsample_freq']], # \n    'num_leaves':            num_leaves[lgb_opt_params[0]['num_leaves']],\n    'max_depth':             max_depth[lgb_opt_params[0]['max_depth']],\n    'max_bin':               max_bin[lgb_opt_params[0]['max_bin']],\n    'learning_rate':         learning_rate[lgb_opt_params[0]['learning_rate']],\n    'colsample_bytree':      lgb_opt_params[0]['colsample_bytree'] #  \n}\n\nlgb_opt = lgb.LGBMRegressor(**lgb_reg_params)\nlgb_opt.fit(X_train, y_train,\n                eval_set=[(X_train, y_train), (X_holdout, y_holdout)],\n                **lgb_para['fit_params'])\nprint(np.sqrt(mean_squared_error(lgb_opt.predict(X_holdout), y_holdout)))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.066244Z","iopub.status.idle":"2021-10-17T08:54:05.066669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(lgb_reg, lgb_opt, X_train, y_train, X_holdout, y_holdout, lgb_fit_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.067486Z","iopub.status.idle":"2021-10-17T08:54:05.067907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ElasticNet","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nbase_elnet = linear_model.ElasticNet()\nmax_iter = range(100, 5000, 100)\n\nelnet_reg_params = {'alpha':              hp.uniform('alpha', 0.00000001, 0.5),\n                    'tol':                hp.uniform('tol', 0.0000001, 0.5),\n                    'max_iter':           hp.choice('max_iter', max_iter),\n                    'l1_ratio':           hp.uniform('l1_ratio', 0.0000001, 0.5),\n                }\nelnet_fit_params = {\n                    'sample_weight' : None\n}\nobj = HPOpt(X_train, X_holdout, y_train, y_holdout)\n\n\n#rf_fit_params = {\n#    'sample_weight': None,\n#}\nelnet_para = dict()\nelnet_para['reg_params'] = elnet_reg_params\nelnet_para['fit_params'] = elnet_fit_params\nelnet_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n\nelnet_opt_para = obj.process(fn_name='elnet_reg', space=elnet_para, trials=Trials(), algo=tpe.suggest, max_evals=500)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.068817Z","iopub.status.idle":"2021-10-17T08:54:05.069256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best 0.0932 <- 0.1163","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.070186Z","iopub.status.idle":"2021-10-17T08:54:05.07061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elnet_opt_para","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.071459Z","iopub.status.idle":"2021-10-17T08:54:05.071895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elnet_reg_opt_params = {'alpha':               elnet_opt_para[0]['alpha'],\n                        'tol':                 elnet_opt_para[0]['tol'],\n                        'max_iter':            max_iter[elnet_opt_para[0]['max_iter']],\n                        'l1_ratio':            elnet_opt_para[0]['l1_ratio']\n                        }\nelnet_opt = linear_model.ElasticNet(**elnet_reg_opt_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.073051Z","iopub.status.idle":"2021-10-17T08:54:05.073472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(base_elnet, elnet_opt, X_train, y_train, X_holdout, y_holdout, elnet_fit_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.074383Z","iopub.status.idle":"2021-10-17T08:54:05.074805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.sqrt(mean_squared_error((lasso_opt.predict(X_holdout) \n                                  + xgb_reg_opt.predict(X_holdout) \n                                  + lgb_opt.predict(X_holdout) \n                                  + elnet_opt.predict(X_holdout)\n                                  + svr_reg_opt.predict(X_holdout)) / 5, y_holdout)))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.075695Z","iopub.status.idle":"2021-10-17T08:54:05.076153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best 0.0899 <- 0.11","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.07712Z","iopub.status.idle":"2021-10-17T08:54:05.077538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Averaging the predictions","metadata":{}},{"cell_type":"markdown","source":"I decided to combine the predictions of my models in order to prevent overfitting and to use advantages of all models. The idea is to make a weightened mean prediction and optimize it using Adam or SGD optimizers","metadata":{}},{"cell_type":"code","source":"import torch\np = torch.tensor([lasso_opt.predict(X_holdout),\n                  xgb_reg_opt.predict(X_holdout),\n                  lgb_opt.predict(X_holdout),\n                  elnet_opt.predict(X_holdout),\n                  svr_reg_opt.predict(X_holdout)])\ny = torch.tensor(np.array(y_holdout))\nw = torch.tensor([[1.],[1.], [1.], [1.], [1.]], requires_grad = True)\ndef f(p, y, w):\n    return torch.sqrt(torch.sum((y - torch.sum(w*p, dim = 0)/w.sum())**2)/len(y))\n\noptimizer = torch.optim.Adam([w], lr = 1)\nfor i in range(5000):\n    fun = f(p, y, w)\n    fun.backward()\n    optimizer.step()\n    optimizer.zero_grad()\nprint('best score', f(p, y, w))\nwf = np.array([[w.data[0]], [w.data[1]], [w.data[2]], [w.data[3]], [w.data[4]]])","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.078486Z","iopub.status.idle":"2021-10-17T08:54:05.078922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best 0.0892 <- 0.1127","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.079857Z","iopub.status.idle":"2021-10-17T08:54:05.080295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(wf)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.081098Z","iopub.status.idle":"2021-10-17T08:54:05.081508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see the difference between true and predicted values on a holdout set","metadata":{}},{"cell_type":"code","source":"predictions = np.array([lasso_opt.predict(X_holdout),\n                        xgb_reg_opt.predict(X_holdout),\n                        lgb_opt.predict(X_holdout),\n                        elnet_opt.predict(X_holdout),\n                        svr_reg_opt.predict(X_holdout)])\nplt.figure(figsize = (10, 9))\nplt.plot([10.5, 11, 12, 13],[10.5, 11, 12, 13])\nplt.xlabel('ensemble pred')\nplt.ylabel('true values')\nplt.scatter(np.sum((wf*predictions) / wf.sum(), axis = 0), y_holdout, c = 'red', alpha=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.082361Z","iopub.status.idle":"2021-10-17T08:54:05.082784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = np.array([lasso_opt.predict(X_test),\n               xgb_reg_opt.predict(X_test),\n               lgb_opt.predict(X_test),\n               elnet_opt.predict(X_test),\n               svr_reg_opt.predict(X_test)])\n\n\n\npred = np.sum((wf*pr)/wf.sum(), axis = 0)\n\npreds = pd.DataFrame({'Id' : Id, 'SalePrice': np.exp(pred)})\npreds.to_csv('sumb.csv', index = False)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:54:05.08357Z","iopub.status.idle":"2021-10-17T08:54:05.084004Z"},"trusted":true},"execution_count":null,"outputs":[]}]}