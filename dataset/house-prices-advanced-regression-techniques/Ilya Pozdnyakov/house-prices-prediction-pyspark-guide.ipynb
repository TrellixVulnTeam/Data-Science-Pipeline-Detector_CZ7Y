{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House Prices Prediction baseline (written on PySpark)\n**Task type:** Regression\n\n**Models used:** Linear Regression, RandomForest Regression\n\n<img src=\"http://www.freeiconspng.com/uploads/house-from-premier-builders-in-carthage-mo-64836--home-builders-5.png\" height=200 width=200>","metadata":{}},{"cell_type":"markdown","source":"*This notebook is a version of the solution to the Kaggle's **House Prices - Advanced Regression Techniques** competition. It was written using PySpark though the amount of data does not require using BigData techniques.*","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Installing PySpark in cause you don't have it preinstalled on your environment.**","metadata":{}},{"cell_type":"code","source":"!pip install pyspark","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Initiate Spark environment","metadata":{}},{"cell_type":"code","source":"from pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession, SQLContext\n\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import udf, col\n\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.mllib.evaluation import RegressionMetrics\n\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\nfrom pyspark.ml.evaluation import RegressionEvaluator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark_session = SparkSession.builder.master(\"local[2]\").appName(\"HousingRegression\").getOrCreate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark_context = spark_session.sparkContext","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark_sql_context = SQLContext(spark_context)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Loading data & EDA","metadata":{}},{"cell_type":"code","source":"TRAIN_INPUT = '../input/house-prices-advanced-regression-techniques/train.csv'\nTEST_INPUT = '../input/house-prices-advanced-regression-techniques/test.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First, let's us pandas to handle the missing data and do some visualizations.**","metadata":{}},{"cell_type":"code","source":"pd_train = pd.read_csv(TRAIN_INPUT)\npd_test = pd.read_csv(TEST_INPUT)\nna_cols = pd_train.columns[pd_train.isna().any()].tolist()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**QQ-plot**","metadata":{}},{"cell_type":"code","source":"# Let's Explore how SalePrice is distributed against normal theoretical quantiles\nfig = plt.figure()\nax = fig.add_subplot()\nres = stats.probplot(pd_train['SalePrice'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dist plot (normal vs factual distribution of SalePrice)**","metadata":{}},{"cell_type":"code","source":"sns.distplot(pd_train['SalePrice'] , fit=norm);\n\n# parameters\n(mu, sigma) = norm.fit(pd_train['SalePrice'])\n\nplt.suptitle('Normal distribution with mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#ax = plt.axes()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let's build a correlation matrix**","metadata":{}},{"cell_type":"code","source":"corr = pd_train.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr[['SalePrice']].sort_values(by='SalePrice',ascending=False).style.background_gradient(cmap='viridis', axis=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see that the top-10 features have a high correlation level with the target variable.**","metadata":{}},{"cell_type":"markdown","source":"**A good idea would be to create a new feature with 3-4 of top-features combined, which we will try later. [see \"New\" Feature]**","metadata":{}},{"cell_type":"markdown","source":"**Now let's explore the dataset for outliers.**","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, sharex=True, figsize=(15,5))\naxes[0].set_xlim(0,10)\n\nsns.scatterplot(data=pd_train, ax=axes[0], x='OverallQual', y='SalePrice')\naxes[0].set_title('OverallQual vs SalePrice')\nsns.scatterplot(data=pd_train, ax=axes[1], x='GarageCars', y='SalePrice')\naxes[1].set_title('GarageCars vs SalePrice')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, sharex=True, figsize=(15,5))\naxes[0].set_xlim(0, 6000)\n\nsns.scatterplot(data=pd_train, ax=axes[0], x='GrLivArea', y='SalePrice')\naxes[0].set_title('GrLivArea vs SalePrice')\nsns.scatterplot(data=pd_train, ax=axes[1], x='GarageArea', y='SalePrice')\naxes[1].set_title('GarageArea vs SalePrice')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, sharex=True, figsize=(15,5))\naxes[0].set_xlim(0, 6000)\n\nsns.scatterplot(data=pd_train, ax=axes[0], x='TotalBsmtSF', y='SalePrice')\naxes[0].set_title('TotalBsmtSF vs SalePrice')\nsns.scatterplot(data=pd_train, ax=axes[1], x='1stFlrSF', y='SalePrice')\naxes[1].set_title('1stFlrSF vs SalePrice')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling missing data: \n**determining the proportion of missing data from overall dataset.**","metadata":{}},{"cell_type":"code","source":"total = pd_train.isnull().sum().sort_values(ascending=False)\npercent = (pd_train.isnull().sum()/pd_train.shape[0]).sort_values(ascending=False)\n\nmissing = pd.concat([total, percent], axis=1, keys=['Total', 'Perc_missing'])\nmissing.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will remove features with missing proportion of more than 15% (thumb rule)\n\npd_train = pd_train.drop((missing[missing['Perc_missing'] >= 0.15]).index,1)\npd_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd_train['New'] = pd_train['OverallQual'] * pd_train['GarageArea'] * pd_train['GrLivArea']\npd_test['New'] = pd_test['OverallQual'] * pd_test['GarageArea'] * pd_test['GrLivArea']\n\n# As some of the contestants have noticed, this results in a spike in model performance later","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cols = list(pd_train.columns)\ntrain_cols.remove('SalePrice')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make test ds feature set same as in train ds\npd_test = pd_test[train_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd_test.columns[pd_test.isna().any()].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Althoug this is not the best solution to fill the NA-values with \"None\"/0, for most of the features \n# in the particular datas, it literally means \"None\"/0 (e.g. Garage Area, Garage Type, Condition) as the house\n# probably doesn't have the garage.\n\nfor col in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']:\n    pd_train[col] = pd_train[col].fillna(\"None\")\n    pd_test[col] = pd_test[col].fillna(\"None\")\n    \nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    pd_train[col] = pd_train[col].fillna(\"None\")\n    pd_test[col] = pd_test[col].fillna(\"None\")\n    \nfor col in ['GarageYrBlt', 'GarageArea', 'GarageCars']:\n    pd_train[col] = pd_train[col].fillna(0)\n    pd_test[col] = pd_test[col].fillna(0)\n    \npd_train['MasVnrType'] = pd_train['MasVnrType'].fillna(\"None\")\npd_test['MasVnrType'] = pd_test['MasVnrType'].fillna(\"None\")\n\npd_train['MasVnrArea'] = pd_train['MasVnrArea'].fillna(0)\npd_test['MasVnrArea'] = pd_test['MasVnrArea'].fillna(0)\n\npd_train['Electrical'] = pd_train['Electrical'].fillna(pd_train['Electrical'].mode()[0])\npd_test['Electrical'] = pd_test['Electrical'].fillna(pd_test['Electrical'].mode()[0])\n\nprint(pd_train.isnull().sum().max()) # check if any missing values are left\nprint(pd_test.isnull().sum().max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd_test['BsmtFinSF1'] = pd_test['BsmtFinSF1'].fillna(pd_test['BsmtFinSF1'].mean())\npd_test['BsmtFinSF2'] = pd_test['BsmtFinSF2'].fillna(pd_test['BsmtFinSF2'].mean())\npd_test['BsmtUnfSF'] = pd_test['BsmtUnfSF'].fillna(pd_test['BsmtUnfSF'].mean())\npd_test['TotalBsmtSF'] = pd_test['TotalBsmtSF'].fillna(pd_test['TotalBsmtSF'].mean())\npd_test['BsmtFullBath'] = pd_test['BsmtFullBath'].fillna(pd_test['BsmtFullBath'].mean())\npd_test['BsmtHalfBath'] = pd_test['BsmtHalfBath'].fillna(pd_test['BsmtHalfBath'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is how fillna is done in PySpark\n\n# train_df = train_df.na.fill('NoData', subset=['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'BsmtFinSF1',\n#       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n#       'BsmtHalfBath', 'KitchenQual', 'Functional', 'GarageCars', 'GarageArea','SaleType'])\n# test_df = test_df.na.fill('NoData', subset=['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'BsmtFinSF1',\n#       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n#       'BsmtHalfBath', 'KitchenQual', 'Functional', 'GarageCars', 'GarageArea','SaleType'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_columns = pd_train.select_dtypes(include=['object']).columns\npd_train[cat_columns] = pd_train[cat_columns].fillna('NoData')\npd_test[cat_columns] = pd_test[cat_columns].fillna('NoData')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling outliers: \n**the values are based on the scatterplots above.**","metadata":{}},{"cell_type":"code","source":"print(\"Dropping outliers resulted in %d instances in the new dataset\" % len(pd_train))\npd_train = pd_train.drop(pd_train[(pd_train['GrLivArea']>4500) \n                                & (pd_train['SalePrice']<300000)].index)\nprint(\"Dropping outliers resulted in %d instances in the new dataset\" % len(pd_train))\npd_train = pd_train.drop(pd_train[(pd_train['GrLivArea']>5500) \n                                | (pd_train['SalePrice']>500000)].index)\nprint(\"Dropping outliers resulted in %d instances in the new dataset\" % len(pd_train))\npd_train = pd_train.drop(pd_train[pd_train['GarageArea']>1100].index)\nprint(\"Dropping outliers resulted in %d instances in the new dataset\" % len(pd_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Spark DataFrames","metadata":{}},{"cell_type":"code","source":"train_df = spark_session.createDataFrame(pd_train)\ntest_df = spark_session.createDataFrame(pd_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.select([c for c in train_df.columns if c not in na_cols])\ntrain_cols = train_df.columns\ntrain_cols.remove('SalePrice')\ntest_df = test_df.select(train_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql.types import IntegerType\n\n# As PySpark DFs can be finicky, sometimes your have to explicitly cast certain data types to columns\n\ntest_df = test_df.withColumn(\"BsmtFinSF1\", test_df[\"BsmtFinSF1\"].cast(IntegerType()))\ntest_df = test_df.withColumn(\"BsmtFinSF2\", test_df[\"BsmtFinSF2\"].cast(IntegerType()))\ntest_df = test_df.withColumn(\"BsmtUnfSF\", test_df[\"BsmtUnfSF\"].cast(IntegerType()))\ntest_df = test_df.withColumn(\"TotalBsmtSF\", test_df[\"TotalBsmtSF\"].cast(IntegerType()))\ntest_df = test_df.withColumn(\"BsmtFullBath\", test_df[\"BsmtFullBath\"].cast(IntegerType()))\ntest_df = test_df.withColumn(\"BsmtHalfBath\", test_df[\"BsmtHalfBath\"].cast(IntegerType()))\ntest_df = test_df.withColumn(\"GarageCars\", test_df[\"GarageCars\"].cast(IntegerType()))\ntest_df = test_df.withColumn(\"GarageArea\", test_df[\"GarageArea\"].cast(IntegerType()))\n\n# train_df.printSchema()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining string columns to pass on to the String Indexer (= categorical feature encoding)\n\ntrain_string_columns = []\n\nfor col, dtype in train_df.dtypes:\n    if dtype == 'string':\n        train_string_columns.append(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer\n\nindexers = [StringIndexer(inputCol=column, outputCol=column+'_index', handleInvalid='keep').fit(train_df) for column in train_string_columns]\n\n\npipeline = Pipeline(stages=indexers)\ntrain_indexed = pipeline.fit(train_df).transform(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_indexed.columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_string_columns = []\n\nfor col, dtype in test_df.dtypes:\n    if dtype == 'string':\n        test_string_columns.append(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indexers2 = [StringIndexer(inputCol=column, outputCol=column+'_index', handleInvalid='keep').fit(test_df) for column in test_string_columns]\n\npipeline2 = Pipeline(stages=indexers2)\ntest_indexed = pipeline2.fit(test_df).transform(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_indexed.columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dtype(df,colname):\n    return [dtype for name, dtype in df.dtypes if name == colname][0]\n\nnum_cols_train = []\nfor col in train_indexed.columns:\n    if get_dtype(train_indexed,col) != 'string':\n        num_cols_train.append(str(col))\n        \nnum_cols_test = []\nfor col in test_indexed.columns:\n    if get_dtype(test_indexed,col) != 'string':\n        num_cols_test.append(str(col))\n\ntrain_indexed = train_indexed.select(num_cols_train)\ntest_indexed = test_indexed.select(num_cols_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_indexed.columns))\nprint(len(test_indexed.columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model building (MLlib)","metadata":{}},{"cell_type":"markdown","source":"**Before passing the data on to the PySpark model, we need to vectorize the data.**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.feature import VectorAssembler\nvectorAssembler = VectorAssembler(inputCols = train_indexed.drop(\"SalePrice\").columns, outputCol = 'features').setHandleInvalid(\"keep\")\n\ntrain_vector = vectorAssembler.transform(train_indexed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorAssembler2 = VectorAssembler(inputCols = test_indexed.columns, outputCol = 'features').setHandleInvalid(\"keep\")\n\ntest_vector = vectorAssembler2.transform(test_indexed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql.functions import lit\n\ntest_vector = test_vector.withColumn(\"SalePrice\", lit(0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#You can use this to scale all instances, however, as I checked, this did not improve the performance\n\n#from pyspark.ml.feature import StandardScaler\n#scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n#scalerModel = scaler.fit(train_vector)\n#scaled_train = scalerModel.transform(train_vector)\n\n#scalerModel2 = scaler.fit(test_vector)\n#scaled_test = scalerModel2.transform(test_vector)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\n\nsplits = train_vector.randomSplit([0.7, 0.3])\ntrain = splits[0]\nval = splits[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simple baseline (linreg)\n\nfrom pyspark.ml.regression import LinearRegression\n\nlr = LinearRegression(featuresCol = 'features', labelCol='SalePrice', maxIter=10, \n                      regParam=0.8, elasticNetParam=0.1) # It is always a good idea to play with hyperparameters.\nlr_model = lr.fit(train)\n\ntrainingSummary = lr_model.summary\nprint(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\nprint(\"r2: %f\" % trainingSummary.r2)\n\nlr_predictions = lr_model.transform(val)\nlr_predictions.select(\"prediction\",\"SalePrice\",\"features\").show(5)\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\nlr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n                 labelCol=\"SalePrice\",metricName=\"r2\")\nprint(\"R Squared (R2) on val data = %g\" % lr_evaluator.evaluate(lr_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A more complex model with RF\n\nfrom pyspark.ml.regression import RandomForestRegressor\n\nrf = RandomForestRegressor(featuresCol = 'features', labelCol='SalePrice', \n                           maxDepth=20, \n                           minInstancesPerNode=2,\n                           bootstrap=True\n                          )\nrf_model = rf.fit(train)\n\nrf_predictions = rf_model.transform(val)\nrf_predictions.select(\"prediction\",\"SalePrice\",\"features\").show(5)\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\nrf_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n                 labelCol=\"SalePrice\",metricName=\"r2\")\nprint(\"R Squared (R2) on val data = %g\" % rf_evaluator.evaluate(rf_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Making predictions & submission","metadata":{}},{"cell_type":"markdown","source":"**Let's convert the predictions in the .csv file for submission**","metadata":{}},{"cell_type":"code","source":"rf_predictions2 = rf_model.transform(test_vector)\n#rf_predictions2.printSchema()\npred = rf_predictions2.select(\"Id\",\"prediction\")\npred = pred.withColumnRenamed(\"prediction\",\"SalePrice\")\n\nfrom pyspark.sql.types import FloatType, IntegerType\n\n#pred.printSchema()\npred = pred.withColumn(\"Id\", pred[\"Id\"].cast(IntegerType()))\npred = pred.withColumn(\"SalePrice\", pred[\"SalePrice\"].cast(FloatType()))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_pd = pred.toPandas()\nsave = pred_pd.to_csv(\"submission.csv\", index=False)\nsave","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Conclusion","metadata":{}},{"cell_type":"markdown","source":"**PySpark offers way less flexibility in working with data & models. This notebook represents just an exercise in using it. As for this particular dataset, you'd better use classical instruments.**","metadata":{}},{"cell_type":"markdown","source":"**However, we achieved quite good metrics of R^2~0.9 with Linear Regression and Random Forest Regression.**","metadata":{}}]}