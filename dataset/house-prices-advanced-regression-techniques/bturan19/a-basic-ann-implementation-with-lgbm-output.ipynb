{"cells":[{"metadata":{"_uuid":"ff7e504461c2f36ab47af0972652f7806500e9a4"},"cell_type":"markdown","source":"**Hello,**\n\n**In this kernel, I will try maybe some kind of weird thing. Firstly I will imply a tree based model and will use the output of this model as it was a column in the dataset and try to implement a basic neural network.**\n\n**I am hoping to see that this strategy will give me an acceptable outcome**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")\ndf = pd.concat([df_train, df_test],axis=0, sort='False', ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d81e237e7b8f256baa5ea0d6956052245efa5c93"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"243e8f1b2ab766a88f5a41de75d361da5042e866"},"cell_type":"code","source":"df = df[df.columns.difference(['Id'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b12b841d9b8a7f36585815b21ab42274dbf3d87e"},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f06ed92a55e7ef00575e778f89ecdfb3c90d4b2"},"cell_type":"code","source":"df_test[\"Id\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63237f9b337e0a7803031f0fd19c595e15b00234"},"cell_type":"code","source":"ids = df_test[\"Id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deb754816f1108cee40af818e5bbbfcbfd1a81a1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afd2024ec93e459e8562f8dadfdd6502ae01e8d2"},"cell_type":"markdown","source":"Percantage of the empty values for each column is shown above. I feel like we can fill na's with zeros instead of dropping them"},{"metadata":{"trusted":true,"_uuid":"3cd251beaa41d057025a7851fc40ceaa4fb26b69"},"cell_type":"code","source":"df = df.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af08afc6cee06f07ed713585488026d6ac1dab7a"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cc7662e2f49041f20fbf115bbad6b5b2a53de14"},"cell_type":"code","source":"#Encoding categorical data\ndf = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c958c33e6a006c22794eb401e0aafc6a711aa970"},"cell_type":"code","source":"print(\"Shape of our dataset is {}\".format(df.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adee80f1e760f99e018fd466ec8b35521cfa6477"},"cell_type":"markdown","source":"# Lenght of train is 1460\n\nNow the current dataframe is like:"},{"metadata":{"trusted":true,"_uuid":"2e33681059712004e347984b641ecd0c35b7af8f"},"cell_type":"code","source":"df.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2dfa11a65ffbdee5c98ca0e7990a9d3477ae6c1"},"cell_type":"code","source":"df_train = df.iloc[:1460,:]\ndf_test = df.iloc[1460:,:]\nX_train = df_train[df_train.columns.difference(['SalePrice'])].values\ny_train = df_train[['SalePrice']].values\nX_test = df_test[df_test.columns.difference(['SalePrice'])].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5df61821301564250ce9e60a769381f5e32b859"},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer\npt_X = PowerTransformer(method='yeo-johnson', standardize=False)\nsc_y = StandardScaler()\nsc_X = StandardScaler()\ny_train = sc_y.fit_transform(y_train)\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c347cdfccbf800de72243f70f5c70eb6b250ca73"},"cell_type":"code","source":"y_train[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87e1c33d922cd6cb8f8d23c2a2c1f8d2bc1f0627"},"cell_type":"code","source":"y_t = y_train.flatten()\ny_t.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c1059f66b23ae11df75beb5cbc773a81052459c"},"cell_type":"code","source":"import lightgbm as lgb\n# create dataset for lightgbm\nlgb_train = lgb.Dataset(X_train, y_t)\n# specify your configurations as a dict\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': {'l2', 'l1'},\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': 0\n}\n\nprint('Starting training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=250)\n# predict\nlgbm_prediction_tr = gbm.predict(X_train, num_iteration=gbm.best_iteration)\nlgbm_prediction_te = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b5b46444e2deec1a2e7ea15923383885578aba2"},"cell_type":"markdown","source":"Now the result of lightgbm will be added to dataset"},{"metadata":{"trusted":true,"_uuid":"447ff0605aadc5740584f247cd2213a63795d366"},"cell_type":"code","source":"df_train[\"lgb\"] = lgbm_prediction_tr\ndf_test[\"lgb\"] = lgbm_prediction_te","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31770d1586f431c46abc2a87611af1c9ad6672ce"},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"093a7366e4f03754e4ae5e4c5a4a67948cecbabb"},"cell_type":"markdown","source":"SO, let's repeat it all"},{"metadata":{"trusted":true,"_uuid":"815fbb43870980aaaa7d88d28ada8157e0f20c91"},"cell_type":"code","source":"df = pd.concat([df_train, df_test],axis=0, sort='False', ignore_index = True)\ndf = df[df.columns.difference(['Id'])]\ndf_train = df.iloc[:1460,:]\ndf_test = df.iloc[1460:,:]\nX_train = df_train[df_train.columns.difference(['SalePrice'])].values\ny_train = df_train[['SalePrice']].values\nX_test = df_test[df_test.columns.difference(['SalePrice'])].values\npt_X = PowerTransformer(method='yeo-johnson', standardize=False)\nsc_y = StandardScaler()\nsc_X = StandardScaler()\ny_train = sc_y.fit_transform(y_train)\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03843a8c9715304fa75dfef042a840ede2f6a036"},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0965c84370fb7e61e8ea3c9708d39c5fe3895579"},"cell_type":"markdown","source":"I couldnt find a way to hide output of the cell below."},{"metadata":{"trusted":true,"_uuid":"2bc5c5816c613e7f32b92ffd0bc65af9a8fc1b1b"},"cell_type":"code","source":"#InÄ±tialising the ANN\nmodel = Sequential()\n#Adding the input layer and first hidden layer\nmodel.add(Dense(units =480, kernel_initializer='random_uniform', activation= 'tanh', \n                input_dim=X_train.shape[1]))\n#Add the second hidden layer\nmodel.add(Dense(units =480, kernel_initializer='random_uniform', activation= 'tanh'))\n#Add the second hidden layer\n\nmodel.add(Dense(units =10, kernel_initializer='random_uniform', activation= 'relu'))\n#The output layer\nmodel.add(Dense(units =1, kernel_initializer='random_uniform', activation= 'elu'))\n\n#Compiling the ANN\nopt = keras.optimizers.Adam(lr=0.0015, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(optimizer=opt, loss='mean_squared_logarithmic_error', metrics=['mse'])\n#Fitting the ANN to the training set\nmodel_filepath = 'min_vl_model.h5'\ncheckpoint = ModelCheckpoint(model_filepath, monitor = 'val_loss', verbose=1, save_best_only = True, mode='min' )\nmodel.fit(X_train,y_train, validation_split=0.07, batch_size=32, nb_epoch=3000, callbacks=[checkpoint])\nmodel.load_weights(model_filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea078dbdf2c78f8a9007d7da720b3bff276415ae"},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29bb1fe8792c28c2fd1637d0c3eb38b6f3119d66"},"cell_type":"code","source":"y_pred = sc_y.inverse_transform(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7ecd10e1bd7ab5573f21ca335bb23c40bcccf28"},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d3608de6ab8823c9db446ed34c4e7462725c8b7"},"cell_type":"code","source":"y_pred = pd.DataFrame(y_pred)\ny_pred[\"Id\"] = ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"791d97cfc3f5630774c562c5a648ee0ed07374be"},"cell_type":"code","source":"y_pred = y_pred.rename(columns={0: \"SalePrice\"})\ny_pred = y_pred[[\"Id\",\"SalePrice\"]]\ny_pred.to_csv(\"Submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ae4246cb485dcf95dfc5c9f4fcda3b32ec98e31"},"cell_type":"code","source":"y_pred.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}