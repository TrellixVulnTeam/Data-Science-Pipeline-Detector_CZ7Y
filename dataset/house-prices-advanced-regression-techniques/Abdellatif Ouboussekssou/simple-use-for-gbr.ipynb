{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. Relationship with Target Data\n    \n    In this Section we will discuss the relation between the target data which is \"SalePrice\" and *all the numerical features*, and see which one effect the target most."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing the libaries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    After that we will import Just the train file first for testing the regression and leave the test file until the end of the algorithm to apply."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndata.head(10)\n#Everything is good for now","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Before we go into this section we should study the target data \"SalePrice\"\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"data['SalePrice'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data['SalePrice'],linewidth=1.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['SalePrice'],color='red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Now we found some important point that our data have a positive skewness.that explain the value of the mean.\n"},{"metadata":{},"cell_type":"markdown","source":"Let's move to see the correlation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmap = data.corr()\nax = plt.subplots(figsize=(19, 16))\nsns.heatmap(corrmap, vmax=.8, square=True,cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here we are going to choose the most correlated features to target data \ncorr_cols=corrmap.nlargest(9,'SalePrice')['SalePrice'].index\nax = plt.subplots(figsize=(9, 7))\nsns.heatmap(np.corrcoef(data[corr_cols].values.T),cbar=True,cmap='coolwarm',\n           annot=True,square=True,fmt='.2f',annot_kws={'size':9},\n            xticklabels=corr_cols.values,yticklabels=corr_cols.values)\n#here we choose just best8 features the other below 0.5 so it better focus on the important one ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LAvsPrice=pd.concat([data['SalePrice'],data['GrLivArea']],axis=1)\nsns.regplot(x='GrLivArea',y='SalePrice',data=LAvsPrice)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice there is two point are far from regression line and these two may effect the study and make mislead to the predicted data so the solution here is to remove them."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sort_values(by='GrLivArea',ascending = False)[:2]\ndata=data.drop(data[data['Id']==1299].index)\ndata=data.drop(data[data['Id']==524].index)\nprint(\"done!!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LAvsPrice=pd.concat([data['SalePrice'],data['GrLivArea']],axis=1)\nsns.regplot(x='GrLivArea',y='SalePrice',data=LAvsPrice)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now everything looks good"},{"metadata":{},"cell_type":"markdown","source":"2. Testing to get best possible accuracy \n\n    In this section we are going to create the test and train data from the train file and test the data before moving to the test file."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.filter(['OverallQual', 'GrLivArea', 'GarageCars',\n      'TotalBsmtSF','1stFlrSF', 'FullBath','TotRmsAbvGrd'],axis=1)\n#notice here that we didnt include 'GarageArea' 'cause obviously is the same as 'GarageCars'\ny=data.filter(['SalePrice'],axis=1)\n\nX.head(10)\n#y.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to split the data we will make 10% for test the the rest for the train "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=40)\n\n#X_train\n#X_test\n#y_train\n#y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to use The Gradient Boosting Regressor but before we need to know what the best parameter to use also we are going to need GridSearchCV for this job."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nSelectedModel = GradientBoostingRegressor(learning_rate=0.05, max_depth=2, \n                                        min_samples_leaf=14,\n                                        min_samples_split=50, n_estimators=3000,\n                                        random_state=40)\nSelectedParameters = {'loss':('ls','huber','lad'\n                            ,'quantile'),'max_features':('auto','sqrt','log2')}\n\n\nGridSearchModel = GridSearchCV(SelectedModel,SelectedParameters,return_train_score=True)\nGridSearchModel.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(GridSearchModel.cv_results_.keys())\nGridSearchResults = pd.DataFrame(GridSearchModel.cv_results_)[['mean_test_score', 'std_test_score'\n                                                               , 'params' , 'rank_test_score' , 'mean_fit_time']]\n\nprint('All Results are :\\n', GridSearchResults )\nprint('Best Score is :', GridSearchModel.best_score_)\nprint('Best Parameters are :', GridSearchModel.best_params_)#this is what we need \nprint('Best Estimator is :', GridSearchModel.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To the next Step !!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#accourding to GridSearchCV the best parametre is {'loss': 'huber', 'max_features': 'sqrt'} \nGBR = GradientBoostingRegressor(learning_rate=0.05, loss='huber', max_depth=2, \n                                       max_features='sqrt', min_samples_leaf=14,\n                                       min_samples_split=50, n_estimators=3000,\n                                       random_state=42)\nGBR.fit(X_train, y_train)\nprint(\"done!!!\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Score\", GBR.score(X_train, y_train))\nprint(\"Test Score\", GBR.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the test data \ny_pred = GBR.predict(X_test)\nprint(\"done again !!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n#Calculating Mean Absolute Error\nMAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average')\nprint('Mean Absolute Error Value is : ', MAEValue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let move the last step which is importing the test data and apply the GBR algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"RealData=pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nRealData.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1=RealData.filter(['OverallQual', 'GrLivArea', 'GarageCars',\n      'TotalBsmtSF','1stFlrSF', 'FullBath','TotRmsAbvGrd'],axis=1)\n\nX1.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is some values are null so we need to get rid of them \nX1=X1.fillna(0)\nprint(\"coool!!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#repeat the same step we did with the train file ...\nsc0 = StandardScaler()\nX1 = sc0.fit_transform(X1)\n\n#now let create the file and save our prediction \n\nDoc=pd.DataFrame()\nDoc['Id']=RealData['Id']\nDoc['SalePrice']=np.round(GBR.predict(X1),2)\nprint(Doc['SalePrice'].head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Last Step is to save the file"},{"metadata":{"trusted":true},"cell_type":"code","source":"Doc.to_csv('SalePrice_submission.csv',index=False)\nprint('great !!! ')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}