{"nbformat_minor":1,"cells":[{"outputs":[],"source":"#changes:\n#based on https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n\nimport re","cell_type":"code","execution_count":null,"metadata":{"_uuid":"419a3bb05bb33bdf1f2bd65c6433d1bcc0f72174","_cell_guid":"2a5226ce-6939-4ce4-a35a-1081c839ad21","collapsed":true}},{"outputs":[],"source":"#load the datasets in dataframes\ntrain=pd.read_csv(\"../input/train.csv\")\ntest=pd.read_csv(\"../input/test.csv\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"6f4f40f5846767dacf67f6d441b0ddd0b34ed007","_cell_guid":"20b7a508-e856-41cd-befa-9926dec5ca07","collapsed":true}},{"outputs":[],"source":"#shape of the training data\ntrain.shape","cell_type":"code","execution_count":null,"metadata":{"_uuid":"945cd9568409458610def2a88323665e5879f429","_cell_guid":"30e020a7-41e7-4e13-9e52-dfec025306c5","collapsed":true}},{"outputs":[],"source":"#shape of the training data\ntest.shape","cell_type":"code","execution_count":null,"metadata":{"_uuid":"2b6764ccf020a3b859500048d596733f72aea96d","_cell_guid":"caf4bd07-9ed5-4d37-b1fc-8d26e06d19a9","collapsed":true}},{"outputs":[],"source":"#peek of the data\ntrain.head()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"0958a5159a7ad16c29f75bd17651c7ec35bb4e0f","_cell_guid":"b4f053f0-4e5b-4672-aa13-90cbb18a6f3c","collapsed":true}},{"outputs":[],"source":"#check datatypes\ntrain.dtypes","cell_type":"code","execution_count":null,"metadata":{"_uuid":"cb2021ceef7a6569e1c429c7b6ae261c10a99930","_cell_guid":"f90b3e0d-fe7f-49f4-811e-ea844b787d79","collapsed":true}},{"outputs":[],"source":"#peek of the data\ntest.head()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"750fb7625ae326a9c82e2a1df0f43ceeba3d6361","_cell_guid":"d7db1aa1-3d89-40fe-a204-1f84c5209aa0","collapsed":true}},{"outputs":[],"source":"#check the numbers of samples and features\nprint(\"The train data size before dropping Id feature is : {} \".format(train.shape))\nprint(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n\n#Save the 'Id' column\ntrain_ID = train['Id']\ntest_ID = test['Id']\n\n#Now drop the  'Id' colum since it's unnecessary for  the prediction process\ntrain.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)\n\n#check again the data size after dropping the 'Id' variable\nprint(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \nprint(\"The test data size after dropping Id feature is : {} \".format(test.shape))","cell_type":"code","execution_count":null,"metadata":{"_uuid":"8d16027fb2605d6684dbf4d7cb237b8e4d80a036","_cell_guid":"cbeb5b9e-3c97-4993-bdd2-a430508c63b2","collapsed":true}},{"outputs":[],"source":"#Let's explore outliers wrt GrLivArea in the training dataset\nfig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"cd4c86b6717cde9e3c740e84b5740c151c711d09","_cell_guid":"afa2c5da-cd91-4e8a-841a-11cb1a6f589c","collapsed":true}},{"source":"**At the bottom right two with large GrLivArea that are of a low price, are huge oultliers. Therefore, we can safely delete them.**","cell_type":"markdown","metadata":{"_uuid":"fdff5aa2a4d323ec3d199ae01489eaf0a2c322b8","_cell_guid":"8cf55f8d-8abf-474e-a570-ee0022d7aa8c"}},{"outputs":[],"source":"#Deleting outliers\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n\n#Check the plot again\nfig, ax = plt.subplots()\nax.scatter(train['GrLivArea'], train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"9c0c6f5789d596f0caeec0f3365de91166479fa5","_cell_guid":"2ced74d0-b530-4d8e-b1b9-0a45a371308d","collapsed":true}},{"outputs":[],"source":"#SalePrice is the target variable we need to predict\n#let's do some analysis on it\nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"990cfd16b9d6b20c1474a5fea8477cd492708a8a","_cell_guid":"bfae9306-7557-49b2-b02e-8e6c47374169","collapsed":true}},{"source":"**The target variable is right skewed. As (linear) models love normally distributed data , we need to transform this variable and make it more normally distributed.**","cell_type":"markdown","metadata":{"_uuid":"a348c5f4a988d4b50b624fb89e17a4647d04ddf3","_cell_guid":"4517473e-761d-49ca-9909-ced72d6fdd6c"}},{"source":"**Log-transformation of the target variable**","cell_type":"markdown","metadata":{"_uuid":"cae6b9f44e9516fc560b75007b96cbddcfbf5c24","_cell_guid":"0aeff924-4a94-4400-bc85-d07643c0af34"}},{"outputs":[],"source":"#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#Check the new distribution \nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"f69e6a75dbbfe8db7705f37220c1c609b82f3f40","_cell_guid":"6c4c742e-9ee8-48ab-87fb-3d960928a546","collapsed":true}},{"source":"**The skew seems now corrected and the data appears more normally distributed.**","cell_type":"markdown","metadata":{"_uuid":"1cff8f450d320e00553cb7f3481bebba7beebadd","_cell_guid":"3c26f5be-9f4c-4128-b5a2-57bb3ea9c0de"}},{"source":"**Correlation**","cell_type":"markdown","metadata":{"_uuid":"660838b43d98f071eec52310e6df56977010304f","_cell_guid":"ae72ebf8-4ce0-41f5-bab2-014673408117"}},{"outputs":[],"source":"#Correlation map to see how features are correlated with SalePrice\ncorrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"b0882106f0ad3df9a2b1369b1366b611a1889b4e","_cell_guid":"6e95243a-3557-45ec-a3cb-0c40d245e84d","collapsed":true}},{"source":"**Features engineering**","cell_type":"markdown","metadata":{"_uuid":"68ba76ff8cde29610a6407ae49384aa256c4d7fa","_cell_guid":"5b44a00e-d837-4d9f-8c16-036cfedcf65c"}},{"outputs":[],"source":"#first combine the train and test datasets and seperate the target variable\nntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"combined data size is : {}\".format(all_data.shape))","cell_type":"code","execution_count":null,"metadata":{"_uuid":"e9f56f4949b9300ea2c0dce4a13fad24045c11a6","_cell_guid":"ff0a37cd-b765-4cd3-aeaa-efd6468025e4","collapsed":true}},{"source":"**Missing data**","cell_type":"markdown","metadata":{"_uuid":"5fdb0ce8109170dfa58aa632bfb04d3651526377","_cell_guid":"260dfcc0-5f26-43da-9b51-f098e91649dd"}},{"outputs":[],"source":"#handling missing value in the combined dataset\nall_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"92bd6ad4eb43366d1d0b9fcf63563fd53eae42a2","_cell_guid":"b7e7b2e2-8738-4520-b83b-152910536c24","collapsed":true}},{"outputs":[],"source":"f, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"6eab682fa4dfd6f09b4cbbcd3fa6ea43a4c27908","_cell_guid":"dbfe4ab9-f7f6-4c5c-a487-aedb1a3fb37c","collapsed":true}},{"source":"**Imputing missing values**","cell_type":"markdown","metadata":{"_uuid":"4c30a511695386066d82b280b2fc0df9a2d812c1","_cell_guid":"d1565a04-53db-49be-9ab6-5434cafacb33"}},{"source":"**PoolQC : data description says NA means \"No Pool\". That make sense, given the huge ratio of missing value (+99%) and majority of houses have no Pool at all in general.**","cell_type":"markdown","metadata":{"_uuid":"e452232cbd19d628dfd51683758f6d5ba8b03e41","_cell_guid":"fab83930-3515-4cd5-b147-debd2f4e3d1f"}},{"outputs":[],"source":"all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"fa3751edb67e537d277777cfedb624d75200b93f","_cell_guid":"aa193e42-c3ed-439c-81ca-650f444f894b","collapsed":true}},{"source":"**MiscFeature : data description says NA means \"no misc feature\"**","cell_type":"markdown","metadata":{"_uuid":"a7e4da63f0759f1c1afb2e60138a1b69a2604e2e","_cell_guid":"498ebf6c-e4f1-4c82-99db-62e916ce7a3b"}},{"outputs":[],"source":"all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"cad23346cd968d7ad3a77658ee16c82521be0eb5","_cell_guid":"f9af8a76-1b07-42df-b73b-915c756712a3","collapsed":true}},{"source":"**Alley : data description says NA means \"no alley access\"**","cell_type":"markdown","metadata":{"_uuid":"21c6c1817b091d7532fc6f7da5ab5b732706e0fa","_cell_guid":"2c1bb29c-c234-4b6c-b616-bc5217fb1a95"}},{"outputs":[],"source":"all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"f4fe504d8342dbfe4540e3abc69d7571535e0f41","_cell_guid":"1960d3e1-5fc5-4dc5-8c6e-4ce11be0b41f","collapsed":true}},{"source":"**Fence : data description says NA means \"no fence\"**","cell_type":"markdown","metadata":{"_uuid":"03daa7bedf4f5718af5bbf660392c08f2eb36236","_cell_guid":"cf94602b-ef58-4bd2-b5f9-c71f7e8b06b1"}},{"outputs":[],"source":"all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"3deb2fe9fe6a9d18c907f5a8e23c3bcf3afc7bb3","_cell_guid":"3b9f5f9e-2450-4c01-98d0-f6a17ac282ff","collapsed":true}},{"source":"**FireplaceQu : data description says NA means \"no fireplace\"**","cell_type":"markdown","metadata":{"_uuid":"bc5ac984ea17bb45fcc809599f0242a71923f8ed","_cell_guid":"189bd0d2-103e-4292-a4a2-59cb59b8feef"}},{"outputs":[],"source":"all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"f284ad10f527d7439b9e03ad9b2deb4aef7bcff7","_cell_guid":"31aa6c5f-3ecd-4b2c-abff-11b53995bb90","collapsed":true}},{"source":"**LotFrontage : Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood**","cell_type":"markdown","metadata":{"_uuid":"6991d2d144e77ae9ddb4d3915b7af76c6e183fe2","_cell_guid":"622cc523-9926-43f3-9dbd-95034d776ebf"}},{"outputs":[],"source":"#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","cell_type":"code","execution_count":null,"metadata":{"_uuid":"c6917a0187d20a6bdd33c71071b358cecc519f79","_cell_guid":"1d3f7d28-6346-4263-a3e3-1d8c55b4581a","collapsed":true}},{"source":"**GarageType, GarageFinish, GarageQual and GarageCond : Replacing missing data with None**","cell_type":"markdown","metadata":{"_uuid":"6cd6777678f5dc966f8234e60c25bcbcb4e1654f","_cell_guid":"7dbf7b32-d656-488b-9800-53ffce2a734b"}},{"outputs":[],"source":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')","cell_type":"code","execution_count":null,"metadata":{"_uuid":"9aa1e0e362cffa6b7f0d331ada6377e7e88a523e","_cell_guid":"abecd6e5-2942-440b-a14c-385cc8aab00f","collapsed":true}},{"source":"**GarageYrBlt, GarageArea and GarageCars : Replacing missing data with 0 (Since No garage = no cars in such garage.)**","cell_type":"markdown","metadata":{"_uuid":"ce04333d5eb2336d74bf8af6ecb96f4fb6f733f3","_cell_guid":"9fe6cd8f-c1b4-446a-a332-57aa20c4f30c"}},{"outputs":[],"source":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"b129b74babbd18916fe22b913c5a85a644b3a9bb","_cell_guid":"570a4d91-5c93-4ca9-8b60-444451bc6e5b","collapsed":true}},{"source":"**BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath and BsmtHalfBath : missing values are likely zero for having no basement**","cell_type":"markdown","metadata":{"_uuid":"b0fe82b3a3eb1f3b8e32409c9a3b32d239dd9bbc","_cell_guid":"38569299-3eda-4f25-9c22-5aed331419ad"}},{"outputs":[],"source":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"5307ff81f870e0e222da5df5ac2de4469a527060","_cell_guid":"8600a960-8669-4628-90fd-3ec2e4619668","collapsed":true}},{"source":"**BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1 and BsmtFinType2 : For all these categorical basement-related features, NaN means that there is no basement.**","cell_type":"markdown","metadata":{"_uuid":"496db8cab9a0bf7e9f290a9e150b1a1e7a8b1d0e","_cell_guid":"f7759feb-63ff-4419-bd7a-a1a6a37a7c9b"}},{"outputs":[],"source":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')","cell_type":"code","execution_count":null,"metadata":{"_uuid":"adcdd911477e5706821ba10be07edfa54459f8b4","_cell_guid":"ff1df042-03d6-4f31-80bd-037a7de4256b","collapsed":true}},{"source":"**MasVnrArea and MasVnrType : NA most likely means no masonry veneer for these houses. We can fill 0 for the area and None for the type.**","cell_type":"markdown","metadata":{"_uuid":"a6b8a5080114195a4b3981f6a5a5565e93958717","_cell_guid":"f1a9164f-25cd-4eff-b661-092edc48b047"}},{"outputs":[],"source":"all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"5cd8f182efd42b4ece10e55e3aed0b991f8b2f4c","_cell_guid":"6be896ed-b427-4ea3-9756-0c5b9a65d70f","collapsed":true}},{"source":"**MSZoning (The general zoning classification) : 'RL' is by far the most common value. So we can fill in missing values with 'RL'**","cell_type":"markdown","metadata":{"_uuid":"bc9ee9f38ba0917c9389be5ed85dd2e40d069682","_cell_guid":"46143b2e-10ce-4cee-abab-455f7d375239"}},{"outputs":[],"source":"all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])","cell_type":"code","execution_count":null,"metadata":{"_uuid":"a9c11d0b7741eb63df1db1ecf750cd951fccdcbb","_cell_guid":"2033928d-0f23-40ee-a924-7bb34c1ef1b1","collapsed":true}},{"source":"**Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.**","cell_type":"markdown","metadata":{"_uuid":"306d2e03bd4fe4224ac8af32ddd298031caa6c71","_cell_guid":"2e5bc6ea-7ad3-4d11-a756-f326a2ec8b9a"}},{"outputs":[],"source":"all_data = all_data.drop(['Utilities'], axis=1)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"4af7eeb3a28a18c68e7159d6c0163bddc8e8d083","_cell_guid":"038ebb8e-258f-4e24-8eaa-691bd0c1edfe","collapsed":true}},{"source":"**Functional : data description says NA means typical**","cell_type":"markdown","metadata":{"_uuid":"6c0f39421817cddba58528c87de58c91638752b4","_cell_guid":"c3480954-3404-4d28-b849-28bcf8a01ab8"}},{"outputs":[],"source":"all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"2411173330c97afb372856989237530fc5b25511","_cell_guid":"8a2473c6-2a31-48c1-87f1-6f711f802324","collapsed":true}},{"source":"**Electrical : It has one NA value. Since this feature has mostly 'SBrkr', we can set that for the missing value.**","cell_type":"markdown","metadata":{"_uuid":"6834b5601006dc098aaa25a1f3e46610c8b62818","_cell_guid":"3d512311-9883-4ec5-90c4-df601b5558a5"}},{"outputs":[],"source":"all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])","cell_type":"code","execution_count":null,"metadata":{"_uuid":"55ddfc35052e389ed279026c96b0a6fc4e12edb2","_cell_guid":"0f779ef3-f8e4-45c9-b7b5-ecf567414553","collapsed":true}},{"source":"**KitchenQual: Only one NA value, and same as Electrical, we set 'TA' (which is the most frequent) for the missing value in KitchenQual.**","cell_type":"markdown","metadata":{"_uuid":"2bb20b42eeb06a2cdd3794de529c05f59022c59b","_cell_guid":"8e98984c-cf88-4290-bf60-962184d504da"}},{"outputs":[],"source":"all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])","cell_type":"code","execution_count":null,"metadata":{"_uuid":"1b08c361a99f58528a3913d20cf201c68afb1ba0","_cell_guid":"c7b0a230-755b-4c1e-b951-dc085bf6cb4c","collapsed":true}},{"source":"**Exterior1st and Exterior2nd : Again Both Exterior 1 & 2 have only one missing value. We will just substitute in the most common string**","cell_type":"markdown","metadata":{"_uuid":"b39393930514b4aec9035cbb805d3e83ee86fd30","_cell_guid":"1ec21460-2c2f-47e2-abe3-71c92053974c"}},{"outputs":[],"source":"all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])","cell_type":"code","execution_count":null,"metadata":{"_uuid":"334078b72c52edd1948449f240b969a07973174e","_cell_guid":"3f2ff057-2101-427d-8ae8-e14d19d9548e","collapsed":true}},{"source":"**SaleType : Fill in again with most frequent which is \"WD\"**","cell_type":"markdown","metadata":{"_uuid":"91f1726dcbcf44317e91c87b0e41c2916a76c4cd","_cell_guid":"b252e812-f570-42ba-ac6a-bb133b674baa"}},{"outputs":[],"source":"all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])","cell_type":"code","execution_count":null,"metadata":{"_uuid":"ca2acbd16761f6b9cf07823709bccc59fed01791","_cell_guid":"9ade2dfd-d039-4199-85ad-993eaf90a95a","collapsed":true}},{"source":"**MSSubClass : Na most likely means No building class. We can replace missing values with None**","cell_type":"markdown","metadata":{"_uuid":"921c3aca45c6a3d9f2fc5b48efa521561241021e","_cell_guid":"221f1192-8040-4f5a-b4e5-f67a03c912bf"}},{"outputs":[],"source":"all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","cell_type":"code","execution_count":null,"metadata":{"_uuid":"96c16600d6ef540e88834d98cad2efd3513748cd","_cell_guid":"5dc983b5-d463-4b16-b1bd-dc86068a6cbf","collapsed":true}},{"outputs":[],"source":"#Is there any remaining missing value?\nall_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()","cell_type":"code","execution_count":null,"metadata":{"_uuid":"c6bd830a267aec4d77c8b4209762550b3c7829fa","_cell_guid":"ec1f3267-bac0-4e40-9a2d-76cb8ad946c5","collapsed":true}},{"source":"**More features engeneering**","cell_type":"markdown","metadata":{"_uuid":"96247913bf8077c85de82bb2c7f323eb413f4d0f","_cell_guid":"765ad0aa-a3dc-4bff-affc-cd643264bf48"}},{"source":"**Transforming some numerical variables**","cell_type":"markdown","metadata":{"_uuid":"261b59f0f14a54d9d3a8c1aeb7f630123fc12f3d","_cell_guid":"f2a5cd25-762c-417e-8b3e-e93d716e25bc"}},{"outputs":[],"source":"all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"fa93c34e050b8bcca49e9cba1e02c4de76e59326","_cell_guid":"504fc41f-9b99-4631-b727-e7f5bfab27c5","collapsed":true}},{"source":"**Label Encoding some categorical variables that may contain information in their ordering set**","cell_type":"markdown","metadata":{"_uuid":"e6976e9aedd1ad451fac4df526e9b05deea3064e","_cell_guid":"b2280e91-928d-4b20-bf42-b808d1238e93"}},{"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))","cell_type":"code","execution_count":null,"metadata":{"_uuid":"46853459026d69cbf04da0fd1d9402fb05761d21","_cell_guid":"852376bb-c6a3-416f-9012-c4bd5ecb9371","collapsed":true}},{"source":"**Since area related features are very important to determine house prices, we add one more feature which is the total area of basement, first and second floor areas of each house**","cell_type":"markdown","metadata":{"_uuid":"86f0822eba85626cc23c54fd63976fbf7dc2fbe5","_cell_guid":"7d90f2d4-389c-419a-aec4-c20e8ce7af1d"}},{"outputs":[],"source":"# Adding total sqfootage feature \nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']","cell_type":"code","execution_count":null,"metadata":{"_uuid":"2562c57c99b9d7b8fc9f4845cc06d27cd8db6bd0","_cell_guid":"4baca11a-70a8-4c13-9404-760880ddb9c7","collapsed":true}},{"outputs":[],"source":"#Skewed features\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"330f58d3b671afd1cf1c07be4db453949d770d2e","_cell_guid":"af83ca06-bd6d-4340-be2b-5804d9c6755e","collapsed":true}},{"source":"**Box Cox Transformation of (highly) skewed features**","cell_type":"markdown","metadata":{"_uuid":"f1ad3ba1d21c499b07bc703fc3b07c16719b3600","_cell_guid":"a137020b-8c69-431d-aaa5-d4fe3a9c9498"}},{"outputs":[],"source":"skewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    all_data[feat] = boxcox1p(all_data[feat], lam)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"5bae41efc299b6a1323b9e60f2bc2ce3532cf165","_cell_guid":"6ea581f5-d09a-4f96-b497-6339989305f4","collapsed":true}},{"outputs":[],"source":"#Getting dummy categorical features\nall_data = pd.get_dummies(all_data)\nprint(all_data.shape)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"e91b7fb35f771a7b981e471facf330bab0bc2c8b","_cell_guid":"6ba9b18b-213f-4000-aedf-bd53121aa617","collapsed":true}},{"outputs":[],"source":"#recover the new train and test datasets\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]","cell_type":"code","execution_count":null,"metadata":{"_uuid":"90df03f7760f81d92747fc2b8de367352181870e","_cell_guid":"c8a0507a-5120-40f4-9af4-888536d59e41","collapsed":true}},{"source":"**Modelling**","cell_type":"markdown","metadata":{"_uuid":"2d2d3924d5464bf935974d2fd552796bcbaac5b2","_cell_guid":"83247e22-6d8d-4d79-afba-7e4866490c43"}},{"outputs":[],"source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","cell_type":"code","execution_count":null,"metadata":{"_uuid":"b81a322d7bb5f29104152bad961298a41de2c43e","_cell_guid":"55e879a9-15a2-4767-bb7a-980279e2ae46","collapsed":true}},{"source":"**Define a cross validation strategy**","cell_type":"markdown","metadata":{"_uuid":"dd3d036c54cf77a63c8a5cd86d5772b2d8fcb1b8","_cell_guid":"e6e98dae-f880-42ab-b5d0-3da03648c611"}},{"outputs":[],"source":"#Validation function\nn_folds = 5\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"fcf8d6b3cd80e61dbc34caf9f191907868dca145","_cell_guid":"f5f4283f-b035-44a1-9b7f-06a43c67543c","collapsed":true}},{"source":"**Base models**","cell_type":"markdown","metadata":{"_uuid":"cb9f9194eab3bc0ea57485a305c4082e8e390290","_cell_guid":"00de1491-c87a-4c79-a8b1-e72fc98d4cfb"}},{"source":"**LASSO Regression :\nThis model may be very sensitive to outliers. So we need to made it more robust on them. For that we use the sklearn's Robustscaler() method on pipeline**","cell_type":"markdown","metadata":{"_uuid":"70d6d67b71330f8c035efc814393083298c7cc69","_cell_guid":"f602572e-fd9d-494c-83fc-3a9ceaf34dc9"}},{"outputs":[],"source":"lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))","cell_type":"code","execution_count":null,"metadata":{"_uuid":"2d004ff4c9fd87709d7f2751cd03e9c4d1fbc73e","_cell_guid":"32b298b0-e1c5-4b1e-8652-1e8826dfe14f","collapsed":true}},{"source":"**Elastic Net Regression :\nagain made robust to outliers**","cell_type":"markdown","metadata":{"_uuid":"757302f40391f6061665e6892dd6e30375424ba7","_cell_guid":"3dab9cda-2e12-4d9c-9dcf-831f4cebe877"}},{"outputs":[],"source":"ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))","cell_type":"code","execution_count":null,"metadata":{"_uuid":"a92cf8c2e2fae796e2fb61830e896f15767d2025","_cell_guid":"ce28cc63-49d9-4847-a87f-8372d317e91e","collapsed":true}},{"source":"**Kernel Ridge Regression :**","cell_type":"markdown","metadata":{"_uuid":"3fe10e17ec99cc13b831110b1d31c0a84c9f164e","_cell_guid":"b759bed9-a278-40f5-953a-b041e3bf7ef6"}},{"outputs":[],"source":"KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"373a3cbd4c5b0d414959450e8e70a8d6556da82d","_cell_guid":"98cbcaa2-a524-4cf1-9e2d-a05bc4af7e93","collapsed":true}},{"source":"**Gradient Boosting Regression :\nWith huber loss that makes it robust to outliers**","cell_type":"markdown","metadata":{"_uuid":"c10d924499662675a27001487b3cd6012112f3ef","_cell_guid":"16984c66-b0e8-4334-b8e5-d72530ad25da"}},{"outputs":[],"source":"GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"73cb12197662b39d3b6aca1d7bc899f52531ffc5","_cell_guid":"004d6855-7d9c-4a24-8df2-cae66266f9f7","collapsed":true}},{"source":"**XGBoost :**","cell_type":"markdown","metadata":{"_uuid":"f5cb2ddfe104a7b679ca2bc73cb3a341188217df","_cell_guid":"f0c5441b-31f2-4b00-871c-026d96c59566"}},{"outputs":[],"source":"model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"d0d878cfd5a1fd9302cbead92e155aa089fd25f4","_cell_guid":"819a9ff9-ce8d-4c7f-8b3f-6473d80eac18","collapsed":true}},{"source":"**LightGBM :**","cell_type":"markdown","metadata":{"_uuid":"1da0bc8562f882feb06c972edb66005024ae9518","_cell_guid":"8fed4311-a85c-44da-ae38-bfad153ac0b3"}},{"outputs":[],"source":"model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","cell_type":"code","execution_count":null,"metadata":{"_uuid":"f7642fd2d8c9c55cd1c2164563999f5a0d44ff35","_cell_guid":"a8b81ef7-41ab-4182-ac57-256edd881952","collapsed":true}},{"source":"**Let's see how these base models perform on the data by evaluating the cross-validation rmsle error**","cell_type":"markdown","metadata":{"_uuid":"4bfd32f556d674573a4c2c83bcc2e2761993dc8f","_cell_guid":"4909da2c-6373-4021-ad51-474a89ae3ec4"}},{"outputs":[],"source":"score = rmsle_cv(lasso)\nprint(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(ENet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(KRR)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))","cell_type":"code","execution_count":null,"metadata":{"_uuid":"da598b24772fc46ef0b15dc318427a73498b38de","_cell_guid":"1207c826-5ad2-4fac-9dc7-ab10e76c3a10","collapsed":true}},{"source":"**Stacking models**","cell_type":"markdown","metadata":{"_uuid":"b5da96cd76a321a781a8565f50bb61037ae35a15","_cell_guid":"b83a077a-66e0-44fd-8a41-d44ef6dbad88"}},{"source":"**1.Averaging base models **","cell_type":"markdown","metadata":{"_uuid":"1cacf21ad3465f94e676f5b21f25c44ac985e840","_cell_guid":"591d8f80-b1d4-4422-9050-cbf5f0f25601"}},{"outputs":[],"source":"class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    # we define clones of the original models to fit the data in\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"outputs":[],"source":"#Averaged base models score\naveraged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\nscore = rmsle_cv(averaged_models)\nprint(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**Adding a Meta-model:\nIn this approach, we add a meta-model on averaged base models and use the out-of-folds predictions of these base models to train our meta-model.**","cell_type":"markdown","metadata":{}},{"source":"**The procedure, for the training part, may be described as follows:\n\n1. Split the total training set into two disjoint sets (here train and holdout )\n\n2. Train several base models on the first part (train)\n\n3. Test these base models on the second part (holdout)\n\n4. Use the predictions from 3) (called out-of-folds predictions) as the inputs, and the correct responses (target variable) as the outputs to train a higher level learner called meta-model.**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"#Stacking averaged Models Class\nclass StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n# We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"outputs":[],"source":"#Stacking Averaged models Score\nstacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),meta_model = lasso)\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**Ensembling StackedRegressor, XGBoost and LightGBM**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"#define a rmsle evaluation function\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**StackedRegressor:**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"#Final Training and Prediction\nstacked_averaged_models.fit(train.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(train.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\nprint(rmsle(y_train, stacked_train_pred))","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**XGBoost:**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"model_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**LightGBM:**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"model_lgb.fit(train, y_train)\nlgb_train_pred = model_lgb.predict(train)\nlgb_pred = np.expm1(model_lgb.predict(test.values))\nprint(rmsle(y_train, lgb_train_pred))","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**RMSE on the entire Train data when averaging**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"print('RMSLE score on train data:')\nprint(rmsle(y_train,stacked_train_pred*0.70 +\n               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**Ensemble prediction:**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"**Submission:**","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"sub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = ensemble\nsub.to_csv('submission_stacked.csv',index=False)","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"outputs":[],"source":"","cell_type":"code","execution_count":null,"metadata":{"_uuid":"9c063606f2dc6e5f29e6507916b3ca4d980bc853","_cell_guid":"16cec649-81a3-4b29-9a3b-065e03ea379e","collapsed":true}}],"nbformat":4,"metadata":{"language_info":{"version":"3.6.3","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","name":"python","nbconvert_exporter":"python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}