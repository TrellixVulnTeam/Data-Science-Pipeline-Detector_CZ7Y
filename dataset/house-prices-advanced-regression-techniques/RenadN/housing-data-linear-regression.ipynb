{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Housing Data Linear Regression","metadata":{}},{"cell_type":"markdown","source":"## Necessary Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:34:12.592772Z","iopub.execute_input":"2022-04-08T00:34:12.593371Z","iopub.status.idle":"2022-04-08T00:34:12.601477Z","shell.execute_reply.started":"2022-04-08T00:34:12.593326Z","shell.execute_reply":"2022-04-08T00:34:12.600647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA and Preliminary Data Visualization ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\ndisplay(df.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:32:05.546673Z","iopub.execute_input":"2022-04-08T00:32:05.547116Z","iopub.status.idle":"2022-04-08T00:32:05.58755Z","shell.execute_reply.started":"2022-04-08T00:32:05.547087Z","shell.execute_reply":"2022-04-08T00:32:05.586886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:32:13.318459Z","iopub.execute_input":"2022-04-08T00:32:13.318737Z","iopub.status.idle":"2022-04-08T00:32:13.341712Z","shell.execute_reply.started":"2022-04-08T00:32:13.31871Z","shell.execute_reply":"2022-04-08T00:32:13.340822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with pd.option_context('display.max_rows', None,\n                       'display.max_columns', None,\n                       'display.precision', 3,\n                       ):\n    display(df.describe())\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:31:48.530211Z","iopub.execute_input":"2022-04-08T00:31:48.530462Z","iopub.status.idle":"2022-04-08T00:31:48.639345Z","shell.execute_reply.started":"2022-04-08T00:31:48.530435Z","shell.execute_reply":"2022-04-08T00:31:48.638496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting histograms for all features","metadata":{}},{"cell_type":"code","source":"df.hist(bins=50, figsize=(30,15))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:32:35.038571Z","iopub.execute_input":"2022-04-08T00:32:35.038894Z","iopub.status.idle":"2022-04-08T00:32:41.609374Z","shell.execute_reply.started":"2022-04-08T00:32:35.038861Z","shell.execute_reply":"2022-04-08T00:32:41.608445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation Matrix to facilitate selecting features","metadata":{}},{"cell_type":"code","source":"with pd.option_context('display.max_rows', None,\n                       'display.max_columns', None,\n                       'display.precision', 3,\n                       ):\n    display(df.corr())","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:32:55.87414Z","iopub.execute_input":"2022-04-08T00:32:55.874906Z","iopub.status.idle":"2022-04-08T00:32:55.972755Z","shell.execute_reply.started":"2022-04-08T00:32:55.874867Z","shell.execute_reply":"2022-04-08T00:32:55.971652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A closer peek into the intricacies of the coorelation matrix:","metadata":{}},{"cell_type":"code","source":"correlation=df.corr(method='pearson').abs()\nsortedCorrelation=correlation.unstack().sort_values(ascending=False)\nwith pd.option_context('display.max_rows', None,\n                       'display.max_columns', None,\n                       'display.precision', 3,\n                       ):\n    display(sortedCorrelation)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:31:52.740278Z","iopub.status.idle":"2022-04-08T00:31:52.740632Z","shell.execute_reply.started":"2022-04-08T00:31:52.740465Z","shell.execute_reply":"2022-04-08T00:31:52.740489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Despite how tacky the above matrices look, they shed light on redundant features, not because they mainly comprise null values or aren't coorelated to the target data (SalePrice) but because they are very highly coorelated with one another. These attributes happen to be:\n* GarageCars     GarageArea\n* GarageCars     GarageArea\n* TotRmsAbvGrd   GrLivArea\n* TotalBsmtSF    1stFlrSF\n<br> Hence, 4 of the above features will be removed.","metadata":{}},{"cell_type":"markdown","source":"However, before taking further steps it's crucial to clean the data at hand before revisting the correlation matrix","metadata":{}},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"As seen above, some of the attributes consist mainly of null values (for instance, MiscFeature and PoolQC). Hence these features will hardly contribute anything to the model and will need to be removed since more than 5% of these features are null. I will also delete the columns discussed above.","metadata":{}},{"cell_type":"code","source":"dropColumns=['Alley','FireplaceQu','PoolQc','Fence','MiscFeature','TotalBsmtSF','TotRmsAbvGrd', 'YearBuilt','GarageArea']\ndfNew=df.loc[:, ~df.columns.isin(dropColumns)]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:33:07.201301Z","iopub.execute_input":"2022-04-08T00:33:07.201622Z","iopub.status.idle":"2022-04-08T00:33:07.208176Z","shell.execute_reply.started":"2022-04-08T00:33:07.20159Z","shell.execute_reply":"2022-04-08T00:33:07.207337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumOnly = dfNew.select_dtypes(include=numerics)\nfor (columnName, columnData) in numOnly.iteritems():\n    print('Colunm Name : ', columnName)\n    print(columnData.corr(dfNew['SalePrice']))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:41:37.236989Z","iopub.execute_input":"2022-04-08T00:41:37.237802Z","iopub.status.idle":"2022-04-08T00:41:37.266716Z","shell.execute_reply.started":"2022-04-08T00:41:37.237761Z","shell.execute_reply":"2022-04-08T00:41:37.266092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dropping more columns due to low correlation","metadata":{}},{"cell_type":"code","source":"dropColumns2=['YrSold','MoSold','MiscVal','3SsnPorch','BsmtHalfBath','LowQualFinSF','BsmtFinSF2','OverallCond','MSSubClass']\ndfNew=dfNew.loc[:, ~dfNew.columns.isin(dropColumns2)] #both categorical and numerical\nnumOnly=numOnly.loc[:, ~numOnly.columns.isin(dropColumns2)] #only numerical data ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:41:43.152613Z","iopub.execute_input":"2022-04-08T00:41:43.153317Z","iopub.status.idle":"2022-04-08T00:41:43.160691Z","shell.execute_reply.started":"2022-04-08T00:41:43.15327Z","shell.execute_reply":"2022-04-08T00:41:43.159798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Data (Numerical Columns Only)","metadata":{}},{"cell_type":"code","source":"y=numOnly['SalePrice']\nX=numOnly.drop(labels='SalePrice', axis=1)\nimp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nimp_mode.fit(X)\nX=imp_mode.transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:42:07.364779Z","iopub.execute_input":"2022-04-08T00:42:07.365561Z","iopub.status.idle":"2022-04-08T00:42:07.385927Z","shell.execute_reply.started":"2022-04-08T00:42:07.365511Z","shell.execute_reply":"2022-04-08T00:42:07.385321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:09.87943Z","iopub.execute_input":"2022-04-08T00:40:09.879828Z","iopub.status.idle":"2022-04-08T00:40:09.884981Z","shell.execute_reply.started":"2022-04-08T00:40:09.8798Z","shell.execute_reply":"2022-04-08T00:40:09.88442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preliminary Linear Regression with Numerical Columns Only","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=42)\nreg_all = LinearRegression()\nreg_all.fit(X_train, y_train)\ny_pred = reg_all.predict(X_test)\nreg_all.score(X_test, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:49:45.37023Z","iopub.execute_input":"2022-04-08T00:49:45.371023Z","iopub.status.idle":"2022-04-08T00:49:45.406075Z","shell.execute_reply.started":"2022-04-08T00:49:45.370982Z","shell.execute_reply":"2022-04-08T00:49:45.40351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## What if the data was normalized?","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaled_X = scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(scaled_X, y,test_size = 0.3, random_state=42)\nreg_all = LinearRegression()\nreg_all.fit(X_train, y_train)\ny_pred = reg_all.predict(X_test)\nreg_all.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:49:34.630952Z","iopub.execute_input":"2022-04-08T00:49:34.631264Z","iopub.status.idle":"2022-04-08T00:49:34.663989Z","shell.execute_reply.started":"2022-04-08T00:49:34.631234Z","shell.execute_reply":"2022-04-08T00:49:34.662357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I believe it seems to hardly do anything in this case","metadata":{}},{"cell_type":"markdown","source":"# Preliminary Cross-Validation with Numerical Columns Only ","metadata":{}},{"cell_type":"code","source":"reg = LinearRegression()\ncv_results = cross_val_score(reg, X, y, cv=5)\nprint(cv_results)\nnp.mean(cv_results)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:51:49.680656Z","iopub.execute_input":"2022-04-08T00:51:49.680925Z","iopub.status.idle":"2022-04-08T00:51:49.718457Z","shell.execute_reply.started":"2022-04-08T00:51:49.680898Z","shell.execute_reply":"2022-04-08T00:51:49.71753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It actually performed worse which is rather pitiful","metadata":{}},{"cell_type":"markdown","source":"# An Attempt at Regularized Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\nfor i in range(10,20,1):\n    \n    ridge = Ridge(alpha=i/10000000, normalize=True)\n    ridge.fit(X_train, y_train)\n    ridge_pred = ridge.predict(X_test)\n    print(ridge.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:57:55.950806Z","iopub.execute_input":"2022-04-08T00:57:55.951389Z","iopub.status.idle":"2022-04-08T00:57:55.991828Z","shell.execute_reply.started":"2022-04-08T00:57:55.951343Z","shell.execute_reply":"2022-04-08T00:57:55.990835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# An Attempt at Lasso Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\nX_train, X_test, y_train, y_test = train_test_split(X, y,\ntest_size = 0.3, random_state=42)\nlasso = Lasso(alpha=0.0001, normalize=True)\nlasso.fit(X_train, y_train)\nlasso_pred = lasso.predict(X_test)\nlasso.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:58:14.846516Z","iopub.execute_input":"2022-04-08T00:58:14.846804Z","iopub.status.idle":"2022-04-08T00:58:14.905708Z","shell.execute_reply.started":"2022-04-08T00:58:14.846775Z","shell.execute_reply":"2022-04-08T00:58:14.904834Z"},"trusted":true},"execution_count":null,"outputs":[]}]}