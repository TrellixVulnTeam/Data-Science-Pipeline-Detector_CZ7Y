{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tab2img","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-10T05:25:38.9069Z","iopub.execute_input":"2022-02-10T05:25:38.907177Z","iopub.status.idle":"2022-02-10T05:25:46.704664Z","shell.execute_reply.started":"2022-02-10T05:25:38.907149Z","shell.execute_reply":"2022-02-10T05:25:46.703924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction\n\nSo I am going to change the tabular data here into images and then apply a CNN to the result which is quite a novel approach to the problem. I do not think this will be very successful right from the start, however it is an experiment I've always wanted to do and an approach I really quite liked when applied to tabular data. I have seen this used successfully in a commercial project and I do believe that in general this approach can be effective. Particular as an additional means of analysing tabular data when also employing other methods. ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom PIL import Image\nfrom dateutil.parser import parse\nfrom typing import List\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nfrom torch import optim\nimport torch.nn as nn","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-10T05:25:46.70667Z","iopub.execute_input":"2022-02-10T05:25:46.70694Z","iopub.status.idle":"2022-02-10T05:25:46.714469Z","shell.execute_reply.started":"2022-02-10T05:25:46.70691Z","shell.execute_reply":"2022-02-10T05:25:46.713227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data\n\nWe will load the tabular data. Process it and transform the data to images.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\nnew_df = df.copy()\nfor col in df.select_dtypes(include='object').columns:\n    new_df = pd.get_dummies(new_df, columns=[col])\ndf = new_df\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:46.715781Z","iopub.execute_input":"2022-02-10T05:25:46.716028Z","iopub.status.idle":"2022-02-10T05:25:47.117867Z","shell.execute_reply.started":"2022-02-10T05:25:46.715998Z","shell.execute_reply":"2022-02-10T05:25:47.116876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will process the test set the same way and make sure it has the same columns","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\nnew_df = test_df.copy()\nfor col in test_df.select_dtypes(include='object').columns:\n    new_df = pd.get_dummies(new_df, columns=[col])\ntest_df = new_df\ntest_df.head()\n\n# add missing columns\nidx = 0\nfor col in df.columns:\n    if col not in test_df:\n        test_df.insert(idx, col, [0] * len(test_df))\n    idx = idx + 1\ntest_df.head()\n\ntest_df = test_df.drop(columns=[\"SalePrice\",\"Id\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:47.119529Z","iopub.execute_input":"2022-02-10T05:25:47.119828Z","iopub.status.idle":"2022-02-10T05:25:47.529245Z","shell.execute_reply.started":"2022-02-10T05:25:47.119792Z","shell.execute_reply":"2022-02-10T05:25:47.528333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seperate tabular data to X and y","metadata":{}},{"cell_type":"code","source":"y = df[\"SalePrice\"]\nX = df.drop(columns=[\"SalePrice\",\"Id\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:47.531634Z","iopub.execute_input":"2022-02-10T05:25:47.531886Z","iopub.status.idle":"2022-02-10T05:25:47.540287Z","shell.execute_reply.started":"2022-02-10T05:25:47.531859Z","shell.execute_reply":"2022-02-10T05:25:47.53909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seperate training and validation sets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\ntrain_ratio = 0.90\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1 - train_ratio, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:47.541951Z","iopub.execute_input":"2022-02-10T05:25:47.542241Z","iopub.status.idle":"2022-02-10T05:25:47.556296Z","shell.execute_reply.started":"2022-02-10T05:25:47.542205Z","shell.execute_reply":"2022-02-10T05:25:47.555234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scale X and y","metadata":{}},{"cell_type":"code","source":"scaler = preprocessing.MinMaxScaler().fit(X_train)\nX_scaled_train = scaler.transform(X_train)\nX_scaled_val = scaler.transform(X_val)\nX_scaled_test = scaler.transform(test_df)\ny_scaler =  preprocessing.StandardScaler().fit(y_train.values.reshape(-1, 1))\ny_scaled_train = y_scaler.transform(y_train.values.reshape(-1, 1))\ny_scaled_val = y_scaler.transform(y_val.values.reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:47.557787Z","iopub.execute_input":"2022-02-10T05:25:47.558112Z","iopub.status.idle":"2022-02-10T05:25:47.603237Z","shell.execute_reply.started":"2022-02-10T05:25:47.558077Z","shell.execute_reply":"2022-02-10T05:25:47.602483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert tabular data to images","metadata":{}},{"cell_type":"code","source":"from tab2img.converter import Tab2Img\nmodel = Tab2Img()\ntrain_images = model.fit_transform(X_scaled_train, y_scaled_train)\nval_images = model.transform(X_scaled_val)\ntest_images = model.transform(X_scaled_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:47.604683Z","iopub.execute_input":"2022-02-10T05:25:47.604962Z","iopub.status.idle":"2022-02-10T05:25:47.630231Z","shell.execute_reply.started":"2022-02-10T05:25:47.60493Z","shell.execute_reply":"2022-02-10T05:25:47.629167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's visualize the images","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(2,5)\nfor i in range(10):\n    nparray = test_images[i].reshape(17,17)\n    image = Image.fromarray(nparray * 255)\n    ax[i%2][i//2].imshow(image)\nfig.show()\n\nfig,ax = plt.subplots(2,5)\nfor i in range(10):\n    nparray = train_images[i].reshape(17,17)\n    image = Image.fromarray(nparray * 255)\n    ax[i%2][i//2].imshow(image)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:47.632279Z","iopub.execute_input":"2022-02-10T05:25:47.632533Z","iopub.status.idle":"2022-02-10T05:25:49.437805Z","shell.execute_reply.started":"2022-02-10T05:25:47.632503Z","shell.execute_reply":"2022-02-10T05:25:49.436838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the Custom Dataset Class\n\nWe need this to be able to load the image and label into the model we will create. So we will create a custom dataset to handle this","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n  def __init__(self, X, y, BatchSize, transform):\n    super().__init__()\n    self.BatchSize = BatchSize\n    self.y = y\n    self.X = X\n    self.transform = transform\n    \n  def num_of_batches(self):\n    \"\"\"\n    Detect the total number of batches\n    \"\"\"\n    return math.floor(len(self.list_IDs) / self.BatchSize)\n\n  def __getitem__(self,idx):\n    class_id = self.y[idx]\n    img = self.transform(np.nan_to_num(self.X[idx]))\n    return img, torch.tensor(class_id)\n\n  def __len__(self):\n    return len(self.X)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:49.43919Z","iopub.execute_input":"2022-02-10T05:25:49.439443Z","iopub.status.idle":"2022-02-10T05:25:49.449201Z","shell.execute_reply.started":"2022-02-10T05:25:49.439412Z","shell.execute_reply":"2022-02-10T05:25:49.448109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Instantiate the Datasets\n\nWe will form them into torch dataloaders to make the data easier to work with. We are also going to put in a minor amount of image augmentation in the train dataset.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize([0.5], [0.5])\n            ])\n\ndataset_stages = ['train', 'val', 'test']\n\nbatch_size = 32\nimage_datasets = {'train' : CustomDataset(train_images, y_train.values, batch_size, transform), 'val' : CustomDataset(val_images, y_val.values, batch_size, transform), 'test' : CustomDataset(test_images, range(0,len(test_df)), batch_size, transform)}\ndataloaders = {'train' : DataLoader(image_datasets['train'], batch_size=image_datasets['train'].BatchSize, shuffle=True, num_workers=0), \n               'val' : DataLoader(image_datasets['val'], batch_size=image_datasets['val'].BatchSize, shuffle=True, num_workers=0), \n               'test' : DataLoader(image_datasets['test'], batch_size=image_datasets['test'].BatchSize, shuffle=False, num_workers=0)}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:49.450875Z","iopub.execute_input":"2022-02-10T05:25:49.451917Z","iopub.status.idle":"2022-02-10T05:25:49.464346Z","shell.execute_reply.started":"2022-02-10T05:25:49.451866Z","shell.execute_reply":"2022-02-10T05:25:49.463339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check an image from the dataset","metadata":{}},{"cell_type":"code","source":"image = transforms.ToPILImage()(image_datasets['train'][412][0].cpu()).convert(\"RGB\")\ndisplay(image)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:49.46583Z","iopub.execute_input":"2022-02-10T05:25:49.466039Z","iopub.status.idle":"2022-02-10T05:25:49.48273Z","shell.execute_reply.started":"2022-02-10T05:25:49.466014Z","shell.execute_reply":"2022-02-10T05:25:49.482148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a Training Function","metadata":{}},{"cell_type":"code","source":"import time\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n            num_batches = 0\n            outputs = None\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                # Loading Bar\n                if (phase == 'train'):\n                    num_batches += 1\n                    percentage_complete = ((num_batches * batch_size) / (dataset_sizes[phase])) * 100\n                    percentage_complete = np.clip(percentage_complete, 0, 100)\n                    print(\"{:0.2f}\".format(percentage_complete), \"% complete\", end=\"\\r\")\n\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs.float(), labels.unsqueeze(-1))\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        # TODO: try removal\n                        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_correct = 0\n                for i in  range(0,len(outputs)):\n                    label = labels.unsqueeze(1).float()[i]\n                    running_correct += abs(abs(outputs[i]) -  abs(label))\n                running_corrects += running_correct\n                    \n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            \n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            #epoch_acc = sum(epoch_acc) / len(epoch_acc)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc.item()))\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:49.486406Z","iopub.execute_input":"2022-02-10T05:25:49.486692Z","iopub.status.idle":"2022-02-10T05:25:49.506287Z","shell.execute_reply.started":"2022-02-10T05:25:49.486661Z","shell.execute_reply":"2022-02-10T05:25:49.505009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load up Shufflenet\n\nHere I will change the first layer to suit a smaller image and the classification layer will be changed for a regression problem","metadata":{}},{"cell_type":"code","source":"from torchvision import models\nfrom torch.optim import lr_scheduler\n\nclass Net(nn.Module):   \n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.cnn_layers = nn.Sequential(\n            # Defining a 2D convolution layer\n            nn.Conv2d(1, 4, kernel_size=2, stride=1, padding=1),\n            nn.BatchNorm2d(4),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Defining another 2D convolution layer\n            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(4),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.linear_layers = nn.Sequential(\n            nn.Linear(64, 64),\n            nn.Linear(64, 64),\n            nn.Linear(64, 64),\n            nn.Linear(64, 64),\n            nn.Linear(64, 1)\n        )\n\n    # Defining the forward pass    \n    def forward(self, x):\n        x = self.cnn_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear_layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:49.510668Z","iopub.execute_input":"2022-02-10T05:25:49.511074Z","iopub.status.idle":"2022-02-10T05:25:49.526849Z","shell.execute_reply.started":"2022-02-10T05:25:49.511022Z","shell.execute_reply":"2022-02-10T05:25:49.525775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"model_ft = Net()\n\ncriterion = nn.L1Loss()\n\noptimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\nmodel_ft = train_model(model_ft.to(device), criterion, optimizer_ft, exp_lr_scheduler, 30)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:26:28.143351Z","iopub.execute_input":"2022-02-10T05:26:28.144416Z","iopub.status.idle":"2022-02-10T05:26:38.321176Z","shell.execute_reply.started":"2022-02-10T05:26:28.144357Z","shell.execute_reply":"2022-02-10T05:26:38.320303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Submission","metadata":{}},{"cell_type":"code","source":"outputs = None\npredictions = []\nfor inputs, labels in dataloaders['test']:\n    model_ft.eval()\n    \n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    outputs = model_ft(inputs)\n    outputs = outputs.cpu().detach().numpy().squeeze()\n    for o in outputs:\n        predictions.append(o)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:25:59.927942Z","iopub.execute_input":"2022-02-10T05:25:59.928709Z","iopub.status.idle":"2022-02-10T05:26:00.192424Z","shell.execute_reply.started":"2022-02-10T05:25:59.928665Z","shell.execute_reply":"2022-02-10T05:26:00.191772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\nsubmission_df[\"SalePrice\"] = predictions\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T05:26:00.194025Z","iopub.execute_input":"2022-02-10T05:26:00.194587Z","iopub.status.idle":"2022-02-10T05:26:00.212813Z","shell.execute_reply.started":"2022-02-10T05:26:00.194545Z","shell.execute_reply":"2022-02-10T05:26:00.212174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nThe accuracy here isn't going to win the leaderboard but I think it is interesting how much was achieved given how experimental an approach this is and the admittedly odd usage of CNN in this. I am very happy with the outcome. I must admit it took me quite a few revisions to get this off the ground and there were many bugs and issues that came up. I think this is now a tool in my toolbelt for the future though and I hope it can help you too. ","metadata":{}}]}