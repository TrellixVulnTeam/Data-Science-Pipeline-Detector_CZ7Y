{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom pandas.api.types import CategoricalDtype\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom xgboost import XGBRegressor\nfrom sklearn.feature_selection import mutual_info_regression\nfrom category_encoders import MEstimateEncoder\nimport optuna\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:06.429467Z","iopub.execute_input":"2021-11-15T11:53:06.429983Z","iopub.status.idle":"2021-11-15T11:53:08.751546Z","shell.execute_reply.started":"2021-11-15T11:53:06.429888Z","shell.execute_reply":"2021-11-15T11:53:08.7506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's set some defaults.","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', 80)\nmetric = 'RMSLE'","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:08.753486Z","iopub.execute_input":"2021-11-15T11:53:08.753854Z","iopub.status.idle":"2021-11-15T11:53:08.758929Z","shell.execute_reply.started":"2021-11-15T11:53:08.753816Z","shell.execute_reply":"2021-11-15T11:53:08.757724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read and Preprocess Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\ndf_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv', index_col='Id')\nprint(df_train.shape)\nprint(df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:08.760196Z","iopub.execute_input":"2021-11-15T11:53:08.760457Z","iopub.status.idle":"2021-11-15T11:53:08.862272Z","shell.execute_reply.started":"2021-11-15T11:53:08.760427Z","shell.execute_reply":"2021-11-15T11:53:08.861368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data has 80 columns (plus the target column we're trying to predict - *SalePrice*).","metadata":{}},{"cell_type":"markdown","source":"We'll concatenate training and test data to preprocess them together.","metadata":{}},{"cell_type":"code","source":"df = pd.concat([df_train, df_test])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:08.864342Z","iopub.execute_input":"2021-11-15T11:53:08.864976Z","iopub.status.idle":"2021-11-15T11:53:08.887656Z","shell.execute_reply.started":"2021-11-15T11:53:08.864931Z","shell.execute_reply":"2021-11-15T11:53:08.886707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspect Values of Categorical Columns","metadata":{}},{"cell_type":"code","source":"for col in df.select_dtypes(['object']):\n    print(f'{col}:\\n{df[col].unique()}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:08.890128Z","iopub.execute_input":"2021-11-15T11:53:08.890421Z","iopub.status.idle":"2021-11-15T11:53:08.941134Z","shell.execute_reply.started":"2021-11-15T11:53:08.890388Z","shell.execute_reply":"2021-11-15T11:53:08.939857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The *Exterior2nd* column contains some typos. Let's fix them.","metadata":{}},{"cell_type":"code","source":"df['Exterior2nd'] = df['Exterior2nd'].replace({'Wd Shng': 'WdShing', 'CmentBd': 'CemntBd', 'Brk Cmn': 'BrkComm'})","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:08.942333Z","iopub.execute_input":"2021-11-15T11:53:08.942563Z","iopub.status.idle":"2021-11-15T11:53:08.951998Z","shell.execute_reply.started":"2021-11-15T11:53:08.942535Z","shell.execute_reply":"2021-11-15T11:53:08.950456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are values that are not consistent with the provided *data_description.txt* file. Let's fix these too.","metadata":{}},{"cell_type":"code","source":"df['MSZoning'] = df['MSZoning'].replace({'C (all)': 'C'})\ndf['Neighborhood'] = df['Neighborhood'].replace({'NAmes': 'Names'})\ndf['BldgType'] = df['BldgType'].replace({'2fmCon': '2FmCon', 'Duplex': 'Duplx', 'Twnhs': 'TwnhsI'})","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:08.953525Z","iopub.execute_input":"2021-11-15T11:53:08.954245Z","iopub.status.idle":"2021-11-15T11:53:08.968936Z","shell.execute_reply.started":"2021-11-15T11:53:08.954194Z","shell.execute_reply":"2021-11-15T11:53:08.968251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspect Values of Numerical Columns\nLet's look at the range of numerical values to see if there are any problems.","metadata":{}},{"cell_type":"code","source":"df.select_dtypes('number').aggregate(['min', 'max', 'mean']).T","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:08.970305Z","iopub.execute_input":"2021-11-15T11:53:08.970703Z","iopub.status.idle":"2021-11-15T11:53:09.0422Z","shell.execute_reply.started":"2021-11-15T11:53:08.970672Z","shell.execute_reply":"2021-11-15T11:53:09.041262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice that the *GarageYrBlt* column which describes the year the garage was built has impossible values (as high as 2207).\n\nLet's replace those values with the year the house was built.","metadata":{}},{"cell_type":"code","source":"df['GarageYrBlt'] = df['GarageYrBlt'].where(df['GarageYrBlt'] <= 2010, df['YearBuilt'])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.043575Z","iopub.execute_input":"2021-11-15T11:53:09.044392Z","iopub.status.idle":"2021-11-15T11:53:09.052536Z","shell.execute_reply.started":"2021-11-15T11:53:09.044347Z","shell.execute_reply":"2021-11-15T11:53:09.05145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we compile all of these steps in a function for later reuse.","metadata":{}},{"cell_type":"code","source":"def clean(df):\n    df['Exterior2nd'] = df['Exterior2nd'].replace({'Wd Shng': 'WdShing', 'CmentBd': 'CemntBd', 'Brk Cmn': 'BrkComm'})\n    df['MSZoning'] = df['MSZoning'].replace({'C (all)': 'C'})\n    df['Neighborhood'] = df['Neighborhood'].replace({'NAmes': 'Names'})\n    df['BldgType'] = df['BldgType'].replace({'2fmCon': '2FmCon', 'Duplex': 'Duplx', 'Twnhs': 'TwnhsI'})\n    df['GarageYrBlt'] = df['GarageYrBlt'].where(df['GarageYrBlt'] <= 2010, df['YearBuilt'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.054376Z","iopub.execute_input":"2021-11-15T11:53:09.055002Z","iopub.status.idle":"2021-11-15T11:53:09.065748Z","shell.execute_reply.started":"2021-11-15T11:53:09.054957Z","shell.execute_reply":"2021-11-15T11:53:09.064669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding","metadata":{}},{"cell_type":"markdown","source":"3 of the numerical columns in the data (*MSSubClass*, *OverallQual*, and *OverallCond*) are actually categorical.\n\nWe define the nominal and ordinal features' categories and levels according to the data description.","metadata":{}},{"cell_type":"code","source":"# The nominal (unordered) categorical features\nnominal_categories = {\n    \"MSSubClass\": CategoricalDtype(categories=['None', 20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 150, 160, 180, 190]),\n    \"MSZoning\": CategoricalDtype(categories=['None', 'A', 'C', 'FV', 'I', 'RH', 'RL', 'RP', 'RM']),\n    \"Street\": CategoricalDtype(categories=['None', 'Grvl', 'Pave']),\n    \"Alley\": CategoricalDtype(categories=['None', 'Grvl', 'Pave']),\n    \"LandContour\": CategoricalDtype(categories=['None', 'Lvl', 'Bnk', 'HLS', 'Low']), # ordinal?\n    \"LotConfig\": CategoricalDtype(categories=['None', 'Inside', 'Corner', 'CulDSac', 'FR2', 'FR3']), # ordinal?\n    \"Neighborhood\": CategoricalDtype(categories=['None', 'Blmngtn', 'Blueste', 'BrDale', 'BrkSide', 'ClearCr', 'CollgCr', 'Crawfor', 'Edwards', 'Gilbert', 'IDOTRR', 'MeadowV', 'Mitchel', 'Names', 'NoRidge', 'NPkVill', 'NridgHt', 'NWAmes', 'OldTown', 'SWISU', 'Sawyer', 'SawyerW', 'Somerst', 'StoneBr', 'Timber', 'Veenker']),\n    \"Condition1\": CategoricalDtype(categories=['None', 'Artery', 'Feedr', 'Norm', 'RRNn', 'RRAn', 'PosN', 'PosA', 'RRNe', 'RRAe']),\n    \"Condition2\": CategoricalDtype(categories=['None', 'Artery', 'Feedr', 'Norm', 'RRNn', 'RRAn', 'PosN', 'PosA', 'RRNe', 'RRAe']),\n    \"BldgType\": CategoricalDtype(categories=['None', '1Fam', '2FmCon', 'Duplx', 'TwnhsE', 'TwnhsI']),\n    \"HouseStyle\": CategoricalDtype(categories=['None', '1Story', '1.5Fin', '1.5Unf', '2Story', '2.5Fin', '2.5Unf', 'SFoyer', 'SLvl']),\n    \"RoofStyle\": CategoricalDtype(categories=['None', 'Flat', 'Gable', 'Gambrel', 'Hip', 'Mansard', 'Shed']),\n    \"RoofMatl\": CategoricalDtype(categories=['None', 'ClyTile', 'CompShg', 'Membran', 'Metal', 'Roll', 'Tar&Grv', 'WdShake', 'WdShngl']),\n    \"Exterior1st\": CategoricalDtype(categories=['None', 'AsbShng', 'AsphShn', 'BrkComm', 'BrkFace', 'CBlock', 'CemntBd', 'HdBoard', 'ImStucc', 'MetalSd', 'Other', 'Plywood', 'PreCast', 'Stone', 'Stucco', 'VinylSd', 'Wd Sdng', 'WdShing']),\n    \"Exterior2nd\": CategoricalDtype(categories=['None', 'AsbShng', 'AsphShn', 'BrkComm', 'BrkFace', 'CBlock', 'CemntBd', 'HdBoard', 'ImStucc', 'MetalSd', 'Other', 'Plywood', 'PreCast', 'Stone', 'Stucco', 'VinylSd', 'Wd Sdng', 'WdShing']),\n    \"MasVnrType\": CategoricalDtype(categories=['None', 'BrkCmn', 'BrkFace', 'CBlock', 'Stone']),\n    \"Foundation\": CategoricalDtype(categories=['None', 'BrkTil', 'CBlock', 'PConc', 'Slab', 'Stone', 'Wood']),\n    \"Heating\": CategoricalDtype(categories=['None', 'Floor', 'GasA', 'GasW', 'Grav', 'OthW', 'Wall']),\n    \"GarageType\": CategoricalDtype(categories=['None', '2Types', 'Attchd', 'Basment', 'BuiltIn', 'CarPort', 'Detchd']),\n    \"MiscFeature\": CategoricalDtype(categories=['None', 'Elev', 'Gar2', 'Othr', 'Shed', 'TenC']),\n    \"SaleType\": CategoricalDtype(categories=['None', 'WD', 'CWD', 'VWD', 'New', 'COD', 'Con', 'ConLw', 'ConLI', 'ConLD', 'Oth']),\n    \"SaleCondition\": CategoricalDtype(categories=['None', 'Normal', 'Abnorml', 'AdjLand', 'Alloca', 'Family', 'Partial'])\n}\n\n# The ordinal (ordered) categorical features \nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(1,11))\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"IR3\", \"IR2\", \"IR1\", \"Reg\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj2\", \"Maj1\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"FuseP\", \"FuseF\", \"Mix\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\n# Add None level for missing values\nordered_levels = {key: ['None'] + value for key, value in ordered_levels.items()}","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.06802Z","iopub.execute_input":"2021-11-15T11:53:09.06879Z","iopub.status.idle":"2021-11-15T11:53:09.101505Z","shell.execute_reply.started":"2021-11-15T11:53:09.068744Z","shell.execute_reply":"2021-11-15T11:53:09.100146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now we can convert the categorical columns to their respective categorical types.","metadata":{}},{"cell_type":"code","source":"def encode(df):\n    # Nominal categories\n    for col, cats in nominal_categories.items():\n        df[col] = df[col].astype(cats)\n    # Ordinal categories\n    for col, levels in ordered_levels.items():\n        df[col] = df[col].astype(CategoricalDtype(levels, ordered=True))\n    return df\n\ndf = encode(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.103287Z","iopub.execute_input":"2021-11-15T11:53:09.103931Z","iopub.status.idle":"2021-11-15T11:53:09.191651Z","shell.execute_reply.started":"2021-11-15T11:53:09.103889Z","shell.execute_reply":"2021-11-15T11:53:09.190468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imputation\nLet's first look at how many missing values we have and the columns where they're located.","metadata":{}},{"cell_type":"code","source":"nan_by_col = df.isnull().sum().drop(labels='SalePrice')\ncols_with_nan = nan_by_col[nan_by_col > 0]\nprint(f'There are {len(cols_with_nan)} columns with missing values:\\n{cols_with_nan.sort_values(ascending=False)}')\nprint(f'Total number of missing entries: {nan_by_col.sum()}')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.19337Z","iopub.execute_input":"2021-11-15T11:53:09.193672Z","iopub.status.idle":"2021-11-15T11:53:09.219198Z","shell.execute_reply.started":"2021-11-15T11:53:09.193618Z","shell.execute_reply":"2021-11-15T11:53:09.21762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will impute with the TA/Typical/Average/Normal level whenever the column has that level but lacks a *NA/None* level.","metadata":{}},{"cell_type":"code","source":"cols_with_typical = ['ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual']\ndf[cols_with_typical] = df[cols_with_typical].fillna('TA')\ndf['Functional'] = df['Functional'].fillna('Typ')\ndf['Electrical'] = df['Electrical'].fillna('FuseA')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.222976Z","iopub.execute_input":"2021-11-15T11:53:09.223367Z","iopub.status.idle":"2021-11-15T11:53:09.239704Z","shell.execute_reply.started":"2021-11-15T11:53:09.223316Z","shell.execute_reply":"2021-11-15T11:53:09.238056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the values of the *Utilities* column are equal to *AllPub* except one. So we'll impute with that.","metadata":{}},{"cell_type":"code","source":"print(df['Utilities'].value_counts())\ndf['Utilities'] = df['Utilities'].fillna('AllPub')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.242004Z","iopub.execute_input":"2021-11-15T11:53:09.242421Z","iopub.status.idle":"2021-11-15T11:53:09.255456Z","shell.execute_reply.started":"2021-11-15T11:53:09.242378Z","shell.execute_reply":"2021-11-15T11:53:09.25399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the rest of the categorical columns, we'll just impute with *\\\"None\\\"*.","metadata":{}},{"cell_type":"code","source":"categorical_columns = df.select_dtypes('category').columns\ndf[categorical_columns] = df[categorical_columns].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.257081Z","iopub.execute_input":"2021-11-15T11:53:09.258243Z","iopub.status.idle":"2021-11-15T11:53:09.299574Z","shell.execute_reply.started":"2021-11-15T11:53:09.258193Z","shell.execute_reply":"2021-11-15T11:53:09.29845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All that's left are numerical columns. We will impute 0 for these.","metadata":{}},{"cell_type":"code","source":"# We have to remove the target column (SalePrice) from the list of numerical columns before imputing\nnumerical_columns = df.select_dtypes('number').columns.drop('SalePrice')\ndf[numerical_columns] = df[numerical_columns].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.301209Z","iopub.execute_input":"2021-11-15T11:53:09.304513Z","iopub.status.idle":"2021-11-15T11:53:09.323063Z","shell.execute_reply.started":"2021-11-15T11:53:09.304443Z","shell.execute_reply":"2021-11-15T11:53:09.322273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All of these steps are summarized in this function.","metadata":{}},{"cell_type":"code","source":"def impute(df):\n    nan_by_col = df.isnull().sum().drop(labels='SalePrice')\n    cols_with_nan = nan_by_col[nan_by_col > 0]\n\n    cols_with_typical = ['ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual']\n    df[cols_with_typical] = df[cols_with_typical].fillna('TA')\n    df['Functional'] = df['Functional'].fillna('Typ')\n    df['Electrical'] = df['Electrical'].fillna('FuseA')\n\n    df['Utilities'] = df['Utilities'].fillna('AllPub')\n\n    categorical_columns = df.select_dtypes('category').columns\n    df[categorical_columns] = df[categorical_columns].fillna('None')\n\n    numerical_columns = df.select_dtypes('number').columns.drop('SalePrice')\n    df[numerical_columns] = df[numerical_columns].fillna(0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.325523Z","iopub.execute_input":"2021-11-15T11:53:09.326366Z","iopub.status.idle":"2021-11-15T11:53:09.337677Z","shell.execute_reply.started":"2021-11-15T11:53:09.326313Z","shell.execute_reply":"2021-11-15T11:53:09.33637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    # Read data\n    df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\n    df_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv', index_col='Id')\n    # Merge the splits so we can process them together\n    df = pd.concat([df_train, df_test])\n    # Preprocessing\n    df = clean(df)\n    df = encode(df)\n    df = impute(df)\n    # Reform splits\n    df_train = df.loc[df_train.index, :]\n    df_test = df.loc[df_test.index, :]\n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.339568Z","iopub.execute_input":"2021-11-15T11:53:09.340117Z","iopub.status.idle":"2021-11-15T11:53:09.352526Z","shell.execute_reply.started":"2021-11-15T11:53:09.340061Z","shell.execute_reply":"2021-11-15T11:53:09.351554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Establish a Baseline Score","metadata":{}},{"cell_type":"code","source":"df_train, df_test = load_data()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.354263Z","iopub.execute_input":"2021-11-15T11:53:09.354838Z","iopub.status.idle":"2021-11-15T11:53:09.565912Z","shell.execute_reply.started":"2021-11-15T11:53:09.354792Z","shell.execute_reply":"2021-11-15T11:53:09.565053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_dataset(X, y, model=XGBRegressor(), metric='MAE'):\n    # Label encoding for categoricals\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    if (metric == 'RMSLE'):\n        y = np.log(y)\n    score = cross_val_score(\n        model, X, y, cv=5, scoring=\"neg_mean_squared_error\",\n    )\n    score = -1 * score.mean()\n    if (metric == 'RMSLE'):\n        score = np.sqrt(score)\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.568587Z","iopub.execute_input":"2021-11-15T11:53:09.569329Z","iopub.status.idle":"2021-11-15T11:53:09.576245Z","shell.execute_reply.started":"2021-11-15T11:53:09.569279Z","shell.execute_reply":"2021-11-15T11:53:09.57534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.copy()\ny_train = X_train.pop(\"SalePrice\")\n\nbaseline_score = score_dataset(X_train, y_train, metric=metric)\nprint(f\"Baseline score: {baseline_score:.5f} {metric}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:09.577835Z","iopub.execute_input":"2021-11-15T11:53:09.578731Z","iopub.status.idle":"2021-11-15T11:53:12.965138Z","shell.execute_reply.started":"2021-11-15T11:53:09.578674Z","shell.execute_reply":"2021-11-15T11:53:12.964411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"markdown","source":"To find out which features are more useful for predicting the target variable, we calculate the MI (Mutual Information) score for each one of them.","metadata":{}},{"cell_type":"code","source":"def make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:12.966251Z","iopub.execute_input":"2021-11-15T11:53:12.967035Z","iopub.status.idle":"2021-11-15T11:53:12.974097Z","shell.execute_reply.started":"2021-11-15T11:53:12.966997Z","shell.execute_reply":"2021-11-15T11:53:12.973408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.copy()\ny_train = X_train.pop(\"SalePrice\")\n\nmi_scores = make_mi_scores(X_train, y_train)\nmi_scores.round(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:12.976382Z","iopub.execute_input":"2021-11-15T11:53:12.976893Z","iopub.status.idle":"2021-11-15T11:53:15.504507Z","shell.execute_reply.started":"2021-11-15T11:53:12.976856Z","shell.execute_reply":"2021-11-15T11:53:15.503525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function lets us drop any features with an MI score of 0.","metadata":{}},{"cell_type":"code","source":"def drop_uninformative(df, mi_scores):\n    return df.loc[:, mi_scores > 0.0]","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:15.505675Z","iopub.execute_input":"2021-11-15T11:53:15.505896Z","iopub.status.idle":"2021-11-15T11:53:15.510659Z","shell.execute_reply.started":"2021-11-15T11:53:15.505869Z","shell.execute_reply":"2021-11-15T11:53:15.509703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.copy()\ny_train = X_train.pop(\"SalePrice\")\nX_train = drop_uninformative(X_train, mi_scores)\nscore_dataset(X_train, y_train, metric=metric)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:57:02.253938Z","iopub.execute_input":"2021-11-15T11:57:02.254347Z","iopub.status.idle":"2021-11-15T11:57:05.560048Z","shell.execute_reply.started":"2021-11-15T11:57:02.254303Z","shell.execute_reply":"2021-11-15T11:57:05.559135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"X_train = df_train.copy()\ny_train = X_train.pop(\"SalePrice\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.78377Z","iopub.execute_input":"2021-11-13T23:04:32.783995Z","iopub.status.idle":"2021-11-13T23:04:32.795471Z","shell.execute_reply.started":"2021-11-13T23:04:32.783967Z","shell.execute_reply":"2021-11-13T23:04:32.794675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encode(df):\n    X = df.copy()\n    for col in X.select_dtypes([\"category\"]):\n        X[col] = X[col].cat.codes\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.797063Z","iopub.execute_input":"2021-11-13T23:04:32.797366Z","iopub.status.idle":"2021-11-13T23:04:32.80348Z","shell.execute_reply.started":"2021-11-13T23:04:32.797332Z","shell.execute_reply":"2021-11-13T23:04:32.802524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mathematical_transforms(df):\n    X = pd.DataFrame()\n    X[\"LivLotRatio\"] = df['GrLivArea'] / df['LotArea']\n    X[\"Spaciousness\"] = (df['1stFlrSF'] + df['2ndFlrSF']) / df['TotRmsAbvGrd']\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.805856Z","iopub.execute_input":"2021-11-13T23:04:32.806514Z","iopub.status.idle":"2021-11-13T23:04:32.816113Z","shell.execute_reply.started":"2021-11-13T23:04:32.806466Z","shell.execute_reply":"2021-11-13T23:04:32.815434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def interactions(df):\n    X = pd.get_dummies(df.BldgType, prefix=\"Bldg\")\n    X = X.mul(df.GrLivArea, axis=0)\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.817213Z","iopub.execute_input":"2021-11-13T23:04:32.817808Z","iopub.status.idle":"2021-11-13T23:04:32.83079Z","shell.execute_reply.started":"2021-11-13T23:04:32.817769Z","shell.execute_reply":"2021-11-13T23:04:32.829932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def counts(df):\n    X = pd.DataFrame()\n    X[\"PorchTypes\"] = df[[\n        \"WoodDeckSF\",\n        \"OpenPorchSF\",\n        \"EnclosedPorch\",\n        \"3SsnPorch\",\n        \"ScreenPorch\",\n    ]].gt(0.0).sum(axis=1)\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.832093Z","iopub.execute_input":"2021-11-13T23:04:32.832328Z","iopub.status.idle":"2021-11-13T23:04:32.843153Z","shell.execute_reply.started":"2021-11-13T23:04:32.8323Z","shell.execute_reply":"2021-11-13T23:04:32.842331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def group_transforms(df):\n    X = pd.DataFrame()\n    X[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.844632Z","iopub.execute_input":"2021-11-13T23:04:32.845379Z","iopub.status.idle":"2021-11-13T23:04:32.85612Z","shell.execute_reply.started":"2021-11-13T23:04:32.845332Z","shell.execute_reply":"2021-11-13T23:04:32.855467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pca_inspired(df):\n    X = pd.DataFrame()\n    X[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n    X[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.857104Z","iopub.execute_input":"2021-11-13T23:04:32.857483Z","iopub.status.idle":"2021-11-13T23:04:32.868742Z","shell.execute_reply.started":"2021-11-13T23:04:32.857447Z","shell.execute_reply":"2021-11-13T23:04:32.868145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=5)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.86985Z","iopub.execute_input":"2021-11-13T23:04:32.870202Z","iopub.status.idle":"2021-11-13T23:04:32.888869Z","shell.execute_reply.started":"2021-11-13T23:04:32.870173Z","shell.execute_reply":"2021-11-13T23:04:32.888054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Final Feature Set","metadata":{}},{"cell_type":"code","source":"def create_features(df_train, df_test=None):\n    X_train = df_train.copy()\n    y_train = X_train.pop(\"SalePrice\")\n    mi_scores = make_mi_scores(X_train, y_train)\n    # Combine splits if test data is given\n    #\n    # If we're creating features for test set predictions, we should\n    # use all the data we have available. After creating our features,\n    # we'll recreate the splits.\n    if df_test is not None:\n        X_test = df_test.copy()\n        X_test.pop(\"SalePrice\")\n        X_train = pd.concat([X_train, X_test])\n\n    X_train = drop_uninformative(X_train, mi_scores)\n    X_train = X_train.join(mathematical_transforms(X_train))\n    #X_train = X_train.join(interactions(X_train))\n    X_train = X_train.join(counts(X_train))\n    X_train = X_train.join(group_transforms(X_train))\n    X_train = X_train.join(pca_inspired(X_train))\n    X_train = label_encode(X_train)\n\n    # Reform splits\n    if df_test is not None:\n        X_test = X_train.loc[df_test.index, :]\n        X_train.drop(df_test.index, inplace=True)\n\n    # Target encoding\n    encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n    X_train = X_train.join(encoder.fit_transform(X_train, y_train, cols=[\"MSSubClass\"]))\n    if df_test is not None:\n        X_test = X_test.join(encoder.transform(X_test))\n        return X_train, X_test\n    else:\n        return X_train\n\ndf_train, df_test = load_data()\nX_train = create_features(df_train)\ny_train = df_train[\"SalePrice\"]\nscore_dataset(X_train, y_train, metric=metric)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:32.890132Z","iopub.execute_input":"2021-11-13T23:04:32.890468Z","iopub.status.idle":"2021-11-13T23:04:39.045122Z","shell.execute_reply.started":"2021-11-13T23:04:32.89044Z","shell.execute_reply":"2021-11-13T23:04:39.044191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"markdown","source":"We will use optuna to optimize our XGBoost regressor's hyperparameters.","metadata":{}},{"cell_type":"code","source":"X_train = create_features(df_train)\ny_train = df_train[\"SalePrice\"]\n\nxgb_params = dict(\n    max_depth=6,           # maximum depth of each tree - try 2 to 10\n    learning_rate=0.01,    # effect of each tree - try 0.0001 to 0.1\n    n_estimators=1000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n    min_child_weight=1,    # minimum number of houses in a leaf - try 1 to 10\n    colsample_bytree=0.7,  # fraction of features (columns) per tree - try 0.2 to 1.0\n    subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n    reg_alpha=0.5,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n    reg_lambda=1.0,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n    num_parallel_tree=1,   # set > 1 for boosted random forests\n)\n\nxgb = XGBRegressor(**xgb_params)\nscore_dataset(X_train, y_train, xgb, metric=metric)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:04:39.046408Z","iopub.execute_input":"2021-11-13T23:04:39.046895Z","iopub.status.idle":"2021-11-13T23:05:10.987951Z","shell.execute_reply.started":"2021-11-13T23:04:39.046857Z","shell.execute_reply":"2021-11-13T23:05:10.987066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    xgb_params = dict(\n        max_depth=trial.suggest_int(\"max_depth\", 2, 20),\n        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),\n        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n    )\n    xgb = XGBRegressor(**xgb_params)\n    return score_dataset(X_train, y_train, xgb, metric=metric)\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50)\nxgb_params = study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:05:10.98937Z","iopub.execute_input":"2021-11-13T23:05:10.989594Z","iopub.status.idle":"2021-11-13T23:05:10.999118Z","shell.execute_reply.started":"2021-11-13T23:05:10.989565Z","shell.execute_reply":"2021-11-13T23:05:10.997978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model and Create Submission","metadata":{}},{"cell_type":"code","source":"X_train, X_test = create_features(df_train, df_test)\ny_train = df_train[\"SalePrice\"]\n\nxgb = XGBRegressor(**xgb_params)\n# XGB minimizes MSE, but competition loss is RMSLE\n# So, we need to log-transform y to train and exp-transform the predictions\nxgb.fit(X_train, np.log(y_train))\npredictions = np.exp(xgb.predict(X_test))\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('my_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T23:08:44.157741Z","iopub.execute_input":"2021-11-13T23:08:44.158326Z","iopub.status.idle":"2021-11-13T23:09:34.893489Z","shell.execute_reply.started":"2021-11-13T23:08:44.15829Z","shell.execute_reply":"2021-11-13T23:09:34.892735Z"},"trusted":true},"execution_count":null,"outputs":[]}]}