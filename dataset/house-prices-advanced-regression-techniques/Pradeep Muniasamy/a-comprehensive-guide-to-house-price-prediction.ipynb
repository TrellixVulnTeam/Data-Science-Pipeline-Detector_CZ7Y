{"cells":[{"metadata":{},"cell_type":"markdown","source":"## About the problem\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Key Take aways**\n\n1)Creative feature engineering \n\n2)Advanced regression techniques like random forest and gradient boosting**(Which I am currently working)**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Loading the necessary Packages**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno as msno #visualize the distribution of NaN values. \nimport seaborn as sns #visualization\nimport matplotlib.pyplot as plt #visualization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading the Files**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration and Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.distplot(train_df.SalePrice, color=\"tomato\")\nplt.title(\"Target distribution in train\")\nplt.ylabel(\"Density\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n\nAbove Figure shows that the target variable is normally distributed","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Understanding the distribution of Missing Data**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"isna_train = train_df.isnull().sum().sort_values(ascending=False)\nisna_test = test_df.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplot(2,1,1)\nplt_1=isna_train[:20].plot(kind='bar')\nplt.ylabel('Train Data')\nplt.subplot(2,1,2)\nisna_test[:20].plot(kind='bar')\nplt.ylabel('Test Data')\nplt.xlabel('Number of features which are NaNs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n>  From this plot, It is clear that missing data is distributed in equally in both train and test dataset. So we have to figure out a general method to handle the missing values from both the dataset\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Handling the Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_df.isnull().sum()/len(train_df)).sort_values(ascending=False)[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percentage=(train_df.isnull().sum()/len(train_df)).sort_values(ascending=False)[:20]\nprint(missing_percentage.index[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping the columns that have more than 30% of missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percentage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop(missing_percentage.index[:5],1)\ntest_df=test_df.drop(missing_percentage.index[:5],1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Imputing the missing values**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Finding whether the columns with missing has any pattern or wether they are normally distributed. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percentage.index[5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the columns whether they are categorical or numerical\ncols = train_df[missing_percentage.index[5:]].columns\nnum_cols = train_df[missing_percentage.index[5:]]._get_numeric_data().columns\nprint(\"Numerical Columns\",num_cols)\ncat_cols=list(set(cols) - set(num_cols))\nprint(\"Categorical Columns:\",cat_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Numerical values distribution**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as py\nplt.figure(figsize=[12,10])\nplt.subplot(331)\nsns.distplot(train_df['LotFrontage'].dropna().values)\nplt.subplot(332)\nsns.distplot(train_df['GarageYrBlt'].dropna().values)\nplt.subplot(333)\nsns.distplot(train_df['MasVnrArea'].dropna().values)\npy.suptitle(\"Distribution of data before Filling NA'S\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations**\n\n1)LotFrontage is normally distributed hence we can impute it with mean\n\n2)GarageYrBlt is skewed so we can either fill it with median\n\n3)MasVnrArea is skewed so we can either fill it with median\n\nTo get better results we can localize this imputations generally houses structure will be common for a particular location so I am localizing this data based on Neihbourhood","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['LotFrontage']=train_df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ntrain_df['GarageYrBlt']=train_df.groupby('Neighborhood')['GarageYrBlt'].transform(lambda x: x.fillna(x.median()))\ntrain_df['MasVnrArea']=train_df.groupby('Neighborhood')['MasVnrArea'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as py\nplt.figure(figsize=[12,10])\nplt.subplot(331)\nsns.distplot(train_df['LotFrontage'].values)\nplt.subplot(332)\nsns.distplot(train_df['GarageYrBlt'].values)\nplt.subplot(333)\nsns.distplot(train_df['MasVnrArea'].values)\npy.suptitle(\"Distribution of data after Filling NA'S\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Just ensuring the distribution of data before and after filling the missing values remain's the same** It's always good to have distrivution same before and after imputing the missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['LotFrontage']=test_df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ntest_df['GarageYrBlt']=test_df.groupby('Neighborhood')['GarageYrBlt'].transform(lambda x: x.fillna(x.median()))\ntest_df['MasVnrArea']=test_df.groupby('Neighborhood')['MasVnrArea'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Categorical Missing value imputation**\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Usually Categorical Variables are imputed with mode but it won't make sense(Houses in Newyork has different features compared to San Francisco) in all cases so in order to make them loaclized based on Neighborhood and we can impute the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in cat_cols:\n    train_df[column]=train_df.groupby('Neighborhood')[column].transform(lambda x: x.fillna(x.mode()))\n    test_df[column]=test_df.groupby('Neighborhood')[column].transform(lambda x: x.fillna(x.mode()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Finding the categorical and numerical feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = train_df._get_numeric_data().columns\nprint(\"Numerical Columns\",num_cols)\ncat_cols=list(set(cols) - set(num_cols))\nprint(\"Categorical Columns:\",cat_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Neighbourhood wise salesprice distribution**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Neighbour=train_df.groupby(['Neighborhood','YearBuilt'])['SalePrice']\nNeighbour=Neighbour.describe()['mean'].to_frame()\nNeighbour=Neighbour.reset_index(level=[0,1])\nNeighbour=Neighbour.groupby('Neighborhood')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Neighbour_index=train_df['Neighborhood'].unique()\nfig = plt.figure(figsize=(50,12))\nfig.suptitle('Yearwise Trend of each Neighborhood')\nfor num in range(1,25):\n    temp=Neighbour.get_group(Neighbour_index[num])\n    ax = fig.add_subplot(5,5,num)\n    ax.plot(temp['YearBuilt'], temp['mean'])\n    ax.set_title(temp['Neighborhood'].unique())\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Label Encoding All the Categorical variables**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the columns whether they are categorical or numerical\ncols = train_df.columns\nnum_cols = train_df._get_numeric_data().columns\nprint(\"Numerical Columns\",num_cols)\ncat_cols=list(set(cols) - set(num_cols))\nprint(\"Categorical Columns:\",cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfor i in cat_cols:\n    train_df[i]=LabelEncoder().fit_transform(train_df[i].astype(str)) \n    test_df[i]=LabelEncoder().fit_transform(test_df[i].astype(str)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,10))\nsns.heatmap(train_df.corr(),ax=ax,annot= False,linewidth= 0.02,linecolor='black',fmt='.2f',cmap = 'Blues_r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#price range correlation\ncorr=train_df.corr()\ncorr=corr.sort_values(by=[\"SalePrice\"],ascending=False).iloc[0].sort_values(ascending=False)\nplt.figure(figsize=(15,20))\nsns.barplot(x=corr.values, y=corr.index.values);\nplt.title(\"Correlation Plot\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Forming a new dataset that has columns having more than 0.15 correlation\nindex=[]\nTrain=pd.DataFrame()\nY=train_df['SalePrice']\nfor i in range(0,len(corr)):\n    if corr[i] > 0.15 and corr.index[i]!='SalePrice':\n        index.append(corr.index[i])\nX=train_df[index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Forming New Features**\n\nSome of the features represent the same so instead of having them individually we can combine them and get new features\n\nThanks for the discussion https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/106618#latest-616788","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Description of new features**\n\n1)**cond*qual** - representative of Overall condition and quality.\n\n2)**home_age_when_sold** - Age of Home When sold\n\n3)**garage_age_when_sold** -Age of garage when sold\n\n4)**TotalSF** - Total Square Foot\n\n5)**total_porch_area** - Total Porch Area\n\n6)**Totalsqrfootage** - Total Square Foot\n\n7)**Total_Bathrooms** - Total Bathrooms\n\nNow, It makes sense right? \nThese are certain things we would usually consider for when we are planning to buy a house\n\n","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"X['cond*qual'] = (train_df['OverallCond'] * train_df['OverallQual']) / 100.0\nX['home_age_when_sold'] = train_df['YrSold'] - train_df['YearBuilt']\nX['garage_age_when_sold'] = train_df['YrSold'] - train_df['GarageYrBlt']\nX['TotalSF'] = train_df['TotalBsmtSF'] + train_df['1stFlrSF'] + train_df['2ndFlrSF'] \nX['total_porch_area'] = train_df['WoodDeckSF'] + train_df['OpenPorchSF'] + train_df['EnclosedPorch'] + train_df['3SsnPorch'] + train_df['ScreenPorch'] \nX['Totalsqrfootage'] = (train_df['BsmtFinSF1'] + train_df['BsmtFinSF2'] +train_df['1stFlrSF'] + train_df['2ndFlrSF'])\nX['Total_Bathrooms'] = (train_df['FullBath'] + (0.5 * train_df['HalfBath']) +train_df['BsmtFullBath'] + (0.5 * train_df['BsmtHalfBath']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['cond*qual'] = (test_df['OverallCond'] * test_df['OverallQual']) / 100.0\ntest_df['home_age_when_sold'] = test_df['YrSold'] - test_df['YearBuilt']\ntest_df['garage_age_when_sold'] =test_df['YrSold'] - test_df['GarageYrBlt']\ntest_df['TotalSF'] = test_df['TotalBsmtSF'] + test_df['1stFlrSF'] + test_df['2ndFlrSF'] \ntest_df['total_porch_area'] = test_df['WoodDeckSF'] +test_df['OpenPorchSF'] + test_df['EnclosedPorch'] + test_df['3SsnPorch'] + test_df['ScreenPorch'] \ntest_df['Totalsqrfootage'] = (test_df['BsmtFinSF1'] + test_df['BsmtFinSF2'] +test_df['1stFlrSF'] + test_df['2ndFlrSF'])\ntest_df['Total_Bathrooms'] = (test_df['FullBath'] + (0.5 * test_df['HalfBath']) +test_df['BsmtFullBath'] + (0.5 * test_df['BsmtHalfBath']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Old_Cols=['OverallCond','OverallQual','YrSold','YearBuilt','YrSold','GarageYrBlt','TotalBsmtSF','1stFlrSF','2ndFlrSF','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','BsmtFinSF1','BsmtFinSF2','1stFlrSF','2ndFlrSF','FullBath','HalfBath','BsmtFullBath','BsmtHalfBath']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_cols=[]\nfor i in X.columns:\n    if i not in Old_Cols and i!='SalePrice':\n        Final_cols.append(i)\nX=X[Final_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interesting insights**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,16))\n\nplt.subplot(2, 2, 1)\nplt.scatter(X['home_age_when_sold'],Y)\nplt.title(\"Home Age Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel(\"Home Age\")\n\nplt.subplot(2, 2, 2)\nplt.scatter(X['Total_Bathrooms'],Y)\nplt.title(\"Total_Bathrooms Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel(\"Total_Bathrooms\")\n\nplt.subplot(2, 2, 3)\nplt.scatter(X['TotalSF'],Y)\nplt.title(\"TotalSF Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel('TotalSF')\n\nplt.subplot(2, 2, 4)\nplt.scatter(X[ 'cond*qual'],Y)\nplt.title(\"House Condition Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel('cond*qual')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution of Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=pd.DataFrame()\ntemp=X\ntemp['SalePrice']=Y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding the outliers**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, len(temp.columns), 5):\n    sns.pairplot(data=temp,\n                x_vars=temp.columns[i:i+5],\n                y_vars=['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations:**\n\nFrom this graph we can see outlier's are in every column's but outlier removal is not always good. So, **LotArea**\nhas a very big outlier I am removing that alone","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deleting outliers\ntemp = temp.drop(temp[(temp['LotArea']>100000) ].index)\n\n#Check the graphic again\nfig, ax = plt.subplots()\nax.scatter(temp['LotArea'], temp['SalePrice'])\nplt.ylabel('LotArea', fontsize=13)\nplt.xlabel('LotArea', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=temp.loc[:, temp.columns != 'SalePrice']\nY=temp['SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=test_df[Final_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Correlation plot for new dataset formed**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=X\ntemp[\"SalePrice\"]=Y\n#price range correlation\nfig,ax = plt.subplots(figsize=(10,10))\nsns.heatmap(temp.corr(),ax=ax,annot= False,linewidth= 0.02,linecolor='black',fmt='.2f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n\n1)The newly formed Data has more meaningful columns compared to the original dataset\n\n2)**Home age when sold** and **Garage age when sold** having negative correlation with SalePrice make sense as we know, Price of building decreases as it ages.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_cols=[]\nfor i in X.columns:\n    if i not in Old_Cols and i!='SalePrice':\n        Final_cols.append(i)\nX=X[Final_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.fillna(test_df.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XG Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\nmodel_xgb.fit(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model_xgb.predict(test_df)\npred_xgb = pd.DataFrame()\npred_xgb['Id']=test['Id']\npred_xgb['SalePrice'] = prediction\npred_xgb.to_csv(\"../working/submission_xgb.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gradient Boosting**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\nGBoost.fit(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = GBoost.predict(test_df)\npred_GB = pd.DataFrame()\npred_GB['Id']=test['Id']\npred_GB['SalePrice'] = prediction\npred_GB.to_csv(\"../working/submission_GB.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Light GB**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\nmodel_lgb.fit(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model_lgb.predict(test_df)\npred_LGB = pd.DataFrame()\npred_LGB['Id']=test['Id']\npred_LGB['SalePrice'] = prediction\npred_LGB.to_csv(\"../working/submission_LGB.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CatBoost Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\ncb_model = CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\ncb_model.fit(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = cb_model.predict(test_df)\npred_CB = pd.DataFrame()\npred_CB['Id']=test['Id']\npred_CB['SalePrice'] = prediction\npred_CB.to_csv(\"../working/submission_CB.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensembling Weighted average\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ensemble = pd.DataFrame()\npred_ensemble['Id']=test['Id']\npred_ensemble['SalePrice'] =( 0.6* pred_xgb['SalePrice'] +0.1* pred_CB['SalePrice']+0.2*pred_GB['SalePrice'] +0.1*pred_LGB['SalePrice'])\npred_ensemble.to_csv(\"../working/submission_ensemble.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Please upvote if you like this kernel","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**I will be working extensively on the coming days on the modelling part to get good results**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Any suggestions please let me know through your comments","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}