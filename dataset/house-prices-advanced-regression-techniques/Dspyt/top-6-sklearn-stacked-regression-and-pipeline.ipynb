{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing libraries**","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder,RobustScaler, PowerTransformer, PolynomialFeatures\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, StackingRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, ElasticNet, LassoLars, Lasso, RidgeCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.feature_selection import SelectFromModel\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew, boxcox_normmax\nfrom scipy.special import boxcox1p\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt  \n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing and Saving Data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\nsub = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)|(train['SalePrice']<36000)].index)\nfig, ax = plt.subplots()\nax.scatter(train['GrLivArea'], train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target value transformation","metadata":{}},{"cell_type":"code","source":"def plot_dist(var):\n    sns.distplot(var, fit=norm);\n    (mu, sigma) = norm.fit(var)\n\n    #plot the distribution\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n                loc='best')\n    plt.ylabel('Frequency')\n    plt.title('Distribution')\n\n    #QQ-plot\n    plt.figure()\n    stats.probplot(var, plot=plt)\n    plt.show()\n\nplot_dist(train['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Non-normality disappears after log(1+x) transformation**","metadata":{}},{"cell_type":"code","source":"train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\nplot_dist(train['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Independent variables Imputing","metadata":{}},{"cell_type":"code","source":"ntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in (\"FireplaceQu\", \"Fence\",\"Alley\", \"MiscFeature\", \"PoolQC\", 'GarageType',\\\n            'GarageFinish', 'GarageQual', 'GarageCond',\"MasVnrType\",'MSSubClass',\\\n           'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\n\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2',\\\n            'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\\\n           \"MasVnrArea\"):\n    all_data[col] = all_data[col].fillna(0)\n\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data = all_data.drop(['Utilities'], axis=1)\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data.isnull().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{"trusted":true}},{"cell_type":"code","source":"all_data['exists_garage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nall_data['exists_bsmt'] = all_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nall_data[\"OverallGrade\"] = all_data[\"OverallQual\"] * all_data[\"OverallCond\"]\nall_data['Total_Bath'] = all_data['FullBath'] + (0.5 * all_data['HalfBath']) + all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath'])\nall_data[\"SimplOverallCond\"] = all_data.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                       4 : 2, 5 : 2, 6 : 2, # average\n                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                      })\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)\nall_data['OverallQual']=all_data['OverallQual'].astype(str)\nall_data['GarageYrBlt']=all_data['GarageYrBlt'].astype(str)\nall_data['GarageCars']=all_data['GarageCars'].astype(str)\nall_data['BedroomAbvGr']=all_data['BedroomAbvGr'].astype(str)\nall_data['HalfBath']=all_data['HalfBath'].astype(str)\n\n\nobject_feats = all_data.dtypes[all_data.dtypes == \"object\"].index.tolist()\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Eliminating Skewness of features","metadata":{}},{"cell_type":"code","source":"skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\nsk = skewed_feats[abs(skewed_feats)>0.5].index.to_list()\nall_data[sk] = np.log1p(all_data[sk])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and Predicting","metadata":{}},{"cell_type":"code","source":"train = all_data[:ntrain]\ntest  = all_data[ntrain:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(handle_unknown='ignore'), object_feats),\n        ('num', RobustScaler() , numeric_feats)\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xg = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\nclf_xg = Pipeline(steps=[\n                    ('pre', preprocessor),\n                    ('poly', PolynomialFeatures(2)),\n                    ('selection', SelectFromModel(estimator=RandomForestRegressor(n_estimators=300, random_state=1))),\n                    ('a', xg),\n                    ])\n\nclf_xg.fit(train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lg = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf=6, min_sum_hessian_in_leaf = 11)\nclf_lg = Pipeline(steps=[\n                    ('pre', preprocessor),\n                    ('a', lg),\n                    ])\n\nclf_lg.fit(train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators = [\n('', RandomForestRegressor(n_estimators=300,random_state=1)),\n('kernel_ridge', KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)),\n('Boosting', GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', \\\n                                       min_samples_leaf=15, min_samples_split=10, loss='huber',random_state=1)),\n('elasticnet', ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)),\n('lasso', Lasso(alpha = 0.0005, random_state=1)),\n             ]\nstack_reg = StackingRegressor(estimators = estimators, final_estimator = RandomForestRegressor(n_estimators = 500 ,random_state=1), n_jobs=-1)\n\nclf = Pipeline(steps=[\n                    ('pre', preprocessor),\n                    ('a', stack_reg),\n                    ])\nclf.fit(train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clf.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = {\n    'a__final_estimator__n_estimators': [200, 300, 400, 500, 600],\n}\nStack = GridSearchCV(clf, param, scoring='accuracy', cv=10).fit(train, y_train)\nprint(Stack.best_estimator_)\nprint('best score:')\nprint(Stack.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = 0.5*np.expm1(Stack.best_estimator_.predict(test)) + 0.25*np.expm1(clf_xg.predict(test))+ 0.25*np.expm1(clf_lg.predict(test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['SalePrice'] = predictions\nsub.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}