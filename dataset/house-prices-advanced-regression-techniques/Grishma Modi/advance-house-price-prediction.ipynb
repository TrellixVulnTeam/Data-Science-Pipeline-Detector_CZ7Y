{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Display all the columns of the dataframe\npd.pandas.set_option('display.max_columns',None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n\n## print shape of dataset with rows and columns\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## print the top5 records\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## 1 -step make the list of features which has missing values\nfeatures_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n## 2- step print the feature name and the percentage of missing values\n\nfor feature in features_with_na:\n    print(feature, np.round(dataset[feature].isnull().mean(), 4),  ' % missing values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features_with_na:\n    data = dataset.copy()\n    \n    # let's make a variable that indicates 1 if the observation was missing or zero otherwise\n    data[feature] = np.where(data[feature].isnull(), 1, 0)\n    \n    # let's calculate the mean SalePrice where the information is missing or present\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Id of Houses {}\".format(len(dataset.Id)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of numerical variables\nnumerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'O']\n\nprint('Number of numerical variables: ', len(numerical_features))\n\n# visualise the numerical variables\ndataset[numerical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's explore the content of these year variables \nfor feature in year_feature:\n    print(feature,dataset[feature].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets analyze the Temporal Datetime Variables\n## We will check whether there is a relation between year the house is sold and the sales price\n\ndataset.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in year_feature:\n    if feature!='YrSold':\n        data=dataset.copy()\n        ## We will capture the difference between year variable and year the house was sold for\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature=[feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_feature\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[discrete_feature].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in discrete_feature:\n    data = dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data = dataset.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"count\")\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data = dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [feature for feature in dataset.columns if data[feature].dtypes==\"O\"]\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[categorical_features].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(dataset[feature].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    data = dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#always remember there is a chance of data leakage so we need to split the data first and then apply feature engineering\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes==\"O\" ]\nfor feature in features_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_cat_feature(dataset,features_nan):\n    data = dataset.copy()\n    data[features_nan] = data[features_nan].fillna('Missing')\n    return data\ndataset = replace_cat_feature(dataset,features_nan)\ndataset[features_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n\n## We will print the numerical nan variables and percentage of missing values\n\nfor feature in numerical_with_nan:\n    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in numerical_with_nan:\n    ## We will replace by using median since there are outliers\n    median_value=dataset[feature].median()\n    \n    ## create a new feature to capture nan values\n    dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median_value,inplace=True)\n    \ndataset[numerical_with_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    dataset[feature]=dataset['YrSold']-dataset[feature]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnum_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n\nfor feature in num_features:\n    dataset[feature]=np.log(dataset[feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features=[feature for feature in dataset.columns if dataset[feature].dtype=='O']\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    temp = dataset.groupby(feature)['SalePrice'].count()/len(dataset)\n    temp_df = temp[temp>0.01].index\n    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    labels_ordered=dataset.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    dataset[feature]=dataset[feature].map(labels_ordered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaling_feature=[feature for feature in dataset.columns if feature not in ['Id','SalePerice'] ]\nlen(scaling_feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaling_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice']]\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(dataset[feature_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.transform(dataset[feature_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n                    axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('X_train.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}