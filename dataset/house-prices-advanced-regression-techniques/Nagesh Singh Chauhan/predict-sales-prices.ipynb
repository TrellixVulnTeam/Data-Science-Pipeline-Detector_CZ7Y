{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predict sales prices"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns',100)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import OrdinalEncoder,LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\nfrom sklearn.model_selection import RepeatedKFold,cross_val_score,train_test_split\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n\ntest=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of features: {}'.format(train.shape[1]))\nprint('Number of entries: {}'.format(train.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting heatmap of missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17, 5))\nsns.heatmap(train.isnull(), cbar=True, cmap='Set3')\nplt.xlabel(\"Column_Name\", size=14, weight=\"bold\")\nplt.title(\"Places of missing values in column\",fontweight=\"bold\",size=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Percentage of missing values in each column of train dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dealing with missing data\ntrain = train.drop((missing_data[missing_data['Total'] > 1]).index,1)\ntrain = train.drop(train.loc[train['Electrical'].isnull()].index)\ntrain.isnull().sum().max() #just checking that there's no missing data missing...","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow, we dont have any missing values. Now let us do the same for test data."},{"metadata":{},"cell_type":"markdown","source":"### Percentage of missing values in each column of test dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data\ntotal_ = test.isnull().sum().sort_values(ascending=False)\npercent_ = (test.isnull().sum()/test.isnull().count()).sort_values(ascending=False)\nmissing_data_ = pd.concat([total_, percent_], axis=1, keys=['Total', 'Percent'])\nmissing_data_.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dealing with missing data\ntest = test.drop((missing_data_[missing_data_['Total'] > 1]).index,1)\ntest = test.drop(test.loc[test['Electrical'].isnull()].index)\ntest.isnull().sum().max() #just checking that there's no missing data missing...","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check statics of the train dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sale price ranges in between 34900 and 755000"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Lets plot histogram for prices less than 500000\nhist_price1=train[\"SalePrice\"][train[\"SalePrice\"]<500000].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Lets plot histogram for prices more than 500000\nhist_price2=train[\"SalePrice\"][train[\"SalePrice\"]>500000].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Handling outliers by removing entries having price > 500000\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train[\"SalePrice\"]<500000]\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"##Data cleaning\n#remove duplicates if any\ntrain.duplicated().sum()\ntrain.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding all columns with Categorical & Numerical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For train data\ncategorical_train=[cat for cat in train.columns if train[cat].dtype=='object']\nnumerical_train=[cat for cat in train.columns if train[cat].dtype=='int64' or train[cat].dtype=='float64']\n\n#For test data\ncategorical_test=[cat for cat in test.columns if test[cat].dtype=='object']\nnumerical_test=[cat for cat in test.columns if test[cat].dtype=='int64' or test[cat].dtype=='float64']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(categorical_train, '\\n\\n',categorical_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using the StandardScaler library to Standardize the numeric values"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss= StandardScaler()\ntrain[numerical_train]= ss.fit_transform(train[numerical_train])\ntest[numerical_test]= ss.fit_transform(test[numerical_test])\n#train.head()\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling Categorical Data using Get_Dummies()"},{"metadata":{"trusted":true},"cell_type":"code","source":"train1= pd.get_dummies(train, columns=categorical_train, drop_first= True)\ntest1= pd.get_dummies(test, columns=categorical_test, drop_first= True)\ntrain1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concatenating the Original Dataset & the One after creating Dummies(get_dummies() creates a new DF containing JUST the dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"train2=pd.concat([train,train1],axis=1)\ntest2=pd.concat([test,test1],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the columns already concatenated after Get_Dummies()"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train2.drop(categorical_train,axis=1)\ntest=test2.drop(categorical_test,axis=1)\n# test123=test.copy()\n# train\nid=test['Id'].iloc[:,1]\nid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train['SalePrice'].iloc[:,1]\nX=train.drop(['Id','SalePrice'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the dataset into test and training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting the dataset into test and training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Dimensions of the training feature matrix: {}'.format(X_train.shape))\nprint('Dimensions of the training target vector: {}'.format(y_train.shape))\nprint('Dimensions of the test feature matrix: {}'.format(X_test.shape))\nprint('Dimensions of the test target vector: {}'.format(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building a regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient Boosting Regressor\ngbreg=GradientBoostingRegressor()\ngbreg.fit(X_train,y_train)\n\ny_pred_gb=gbreg.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nprint(\"R2 score: \",r2_score(y_test,y_pred_gb)*100)\nprint(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_pred_gb)))\n\n\n#Error\nerror_diff = pd.DataFrame({'Actual Values': np.array(y_test), 'Predicted Values': y_pred_gb})\nprint(error_diff.head(5))\n\n#Visualize the error\ndf1 = error_diff.head(25)\ndf1.plot(kind='bar',figsize=(10,7))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random forest regression \n\nregrRM2 = RandomForestRegressor(n_estimators=200, max_depth = 50, min_samples_split = 5,min_samples_leaf =4)\nregrRM2.fit(X_train, y_train)\n\ny_pred_rf=regrRM2.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nprint(\"R2 score: \",r2_score(y_test,y_pred_rf)*100)\nprint(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_pred_rf)))\n\n#Error\nerror_diff = pd.DataFrame({'Actual Values': np.array(y_test), 'Predicted Values': y_pred_rf})\nprint(error_diff.head(5))\n\n#Visualize the error\ndf1 = error_diff.head(25)\ndf1.plot(kind='bar',figsize=(10,7))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}