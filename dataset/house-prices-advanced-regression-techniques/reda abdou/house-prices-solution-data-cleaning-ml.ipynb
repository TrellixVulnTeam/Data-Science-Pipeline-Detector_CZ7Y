{"cells":[{"metadata":{},"cell_type":"markdown","source":"Today, in this notebook, we'll try to solve the problem of house prices, first we'll clean the data, then we'll use Machine Learning regression algorithmes to predict the selling price of a house based on 79 characteristics."},{"metadata":{},"cell_type":"markdown","source":"Let's load the required libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n#import matplotlib.pyplot as plt\n#import seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import train and test data sets, display the first 5 lines of the train data set and explore their shapes"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#remove outliers\ntrain=train.drop(index=[523,1298],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('th train data has {} rows and {} features'.format(train.shape[0],train.shape[1]))\nprint('the test data has {} rows and {} features'.format(test.shape[0],test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll combine these two data sets using the concat attribute"},{"metadata":{"trusted":false},"cell_type":"code","source":"data=pd.concat([train.iloc[:,:-1],test],axis=0)\nprint('tha data has {} rows and {} features'.format(data.shape[0],data.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In our data set we have 80 features, check their names and data types using the dataframe attributes: columns and info"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems we have some features with null values, we'll deal with these values after"},{"metadata":{},"cell_type":"markdown","source":"We'll divide the data into numerical and categorical data and verify their descriptive statistics"},{"metadata":{"trusted":false},"cell_type":"code","source":"num_features=data.select_dtypes(include=['int64','float64'])\ncategorical_features=data.select_dtypes(include='object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"num_features.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"categorical_features.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"display the columns with the number of missing values"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False)[:34]\n#print(categorical_features.isnull().sum().sort_values(ascending=False)[:23])\n#num_features.isnull().sum().sort_values(ascending=False)[:11]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that we have 34 features with NaN values, before processing these values, it is important to know exactly what each feature means by reading the data description file"},{"metadata":{"trusted":false},"cell_type":"code","source":"f = open(\"/kaggle/input/data_description.txt\", \"r\")\n#print(f.read())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After reading the description, there is the way we will impute and cleaning the missing values:\n1. impute the mean value to certain numerical features.\n2. create a new class 'other' for certain categorical features.\n3. use the mode value for the other categotical features.\n4. drop the ID and certain unnecessary features"},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop(columns=['Id','Street','PoolQC','Utilities'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#data['LotFrontage'].fillna(int(data['LotFrontage'].mean()),inplace=True)\ndata['LotFrontage'] = data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['LotFrontage'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#create a new class 'other'\nfeatures=['Electrical','KitchenQual','SaleType','Exterior2nd','Exterior1st','Alley','Fence', 'MiscFeature','FireplaceQu','GarageCond','GarageQual','GarageFinish','GarageType','BsmtCond','BsmtExposure','BsmtQual','BsmtFinType2','BsmtFinType1','MasVnrType']\nfor name in features:\n    data[name].fillna('Other',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data[features].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['MSZoning'] = data.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n#data.MSZoning = data.groupby(['MSSubClass'])['MSZoning'].transform(lambda x: x.fillna(x.value_counts()[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['Functional']=data['Functional'].fillna('typ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"mode=['Electrical','KitchenQual','SaleType','Exterior2nd','Exterior1st']\nfor name in mode:\n    data[name].fillna(data[name].mode()[0],inplace=True)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"zero=['GarageArea','GarageYrBlt','MasVnrArea','BsmtHalfBath','BsmtHalfBath','BsmtFullBath','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','GarageCars']\nfor name in zero:\n    data[name].fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's great, our dataset no longer has any missing values. "},{"metadata":{},"cell_type":"markdown","source":"Another pre-processing step is to transform categorical features into numerical features"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.loc[data['MSSubClass']==60, 'MSSubClass']=0\ndata.loc[(data['MSSubClass']==20)|(data['MSSubClass']==120), 'MSSubClass']=1\ndata.loc[data['MSSubClass']==75, 'MSSubClass']=2\ndata.loc[(data['MSSubClass']==40)|(data['MSSubClass']==70)|(data['MSSubClass']==80), 'MSSubClass']=3\ndata.loc[(data['MSSubClass']==50)|(data['MSSubClass']==85)|(data['MSSubClass']==90)|(data['MSSubClass']==160)|(data['MSSubClass']==190), 'MSSubClass']=4\ndata.loc[(data['MSSubClass']==30)|(data['MSSubClass']==45)|(data['MSSubClass']==180), 'MSSubClass']=5\ndata.loc[(data['MSSubClass']==150), 'MSSubClass']=6","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"object_features = data.select_dtypes(include='object').columns\nobject_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def dummies(d):\n    dummies_df=pd.DataFrame()\n    object_features = d.select_dtypes(include='object').columns\n    for name in object_features:\n        dummies = pd.get_dummies(d[name], drop_first=False)\n        dummies = dummies.add_prefix(\"{}_\".format(name))\n        dummies_df=pd.concat([dummies_df,dummies],axis=1)\n    return dummies_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dummies_data=dummies(data)\ndummies_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data=data.drop(columns=object_features,axis=1)\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final_data=pd.concat([data,dummies_data],axis=1)\nfinal_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have fun now with Machine Learning and the Regression algorithms "},{"metadata":{"trusted":false},"cell_type":"code","source":"#Re-spliting the data into train and test datasets\ntrain_data=final_data.iloc[:1458,:]\ntest_data=final_data.iloc[1458:,:]\nprint(train_data.shape)\ntest_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# X: independent variables and y: target variable\nX=train_data\ny=train.loc[:,'SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import Ridge, RidgeCV, LassoCV, ElasticNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_las_cv = LassoCV(alphas=(0.0001, 0.0005, 0.001, 0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10))\nmodel_las_cv.fit(X,y)\nlas_cv_preds=model_las_cv.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_ridge_cv = RidgeCV(alphas=(0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10))\nmodel_ridge_cv.fit(X, y)\nridge_cv_preds=model_ridge_cv.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_ridge = Ridge(alpha=10, solver='auto')\nmodel_ridge.fit(X, y)\nridge_preds=model_ridge.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_en = ElasticNet(random_state=1, alpha=0.00065, max_iter=3000)\nmodel_en.fit(X, y)\nen_preds=model_en.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_xgb = xgb.XGBRegressor(learning_rate=0.01,n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.00006)\nmodel_xgb.fit(X, y)\nxgb_preds=model_xgb.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_gbr = GradientBoostingRegressor(n_estimators=3000, \n                                learning_rate=0.05, \n                                max_depth=4, \n                                max_features='sqrt', \n                                min_samples_leaf=15, \n                                min_samples_split=10, \n                                loss='huber', \n                                random_state =42)\nmodel_gbr.fit(X, y)\ngbr_preds=model_gbr.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_lgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=5000,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n                                       #min_data_in_leaf=2,\n                                       #min_sum_hessian_in_leaf=11\n                                       )\nmodel_lgbm.fit(X, y)\nlgbm_preds=model_lgbm.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final_predictions = 0.3 * lgbm_preds + 0.3 * gbr_preds + 0.1 * xgb_preds + 0.3 * ridge_cv_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#display the first 5 predictions of sale price\nfinal_predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#make the submission data frame\nsubmission = {\n    'Id': test.Id.values,\n    'SalePrice': final_predictions + 0.007 * final_predictions\n}\nsolution = pd.DataFrame(submission)\nsolution.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#make the submission file\nsolution.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}