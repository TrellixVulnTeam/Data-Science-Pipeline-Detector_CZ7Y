{"cells":[{"metadata":{},"cell_type":"markdown","source":"Boston House Price is a very good dataset to analyze Regression problem.\n\nStart from the EXPLORATION of Multivariate Data Analysis:\n\nhttps://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n\nAnd refer to the wonderful solution:\n\nhttps://www.kaggle.com/jesucristo/1-house-prices-solution-top-1\n\nNow we begin our Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom scipy.stats import norm, skew\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"ls ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['SalePrice'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Pearson Correlation Matrix of Features\n\nHeatmap of correlation is the best way to overview the data features."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train.corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(corr_matrix, cmap=plt.cm.RdBu_r)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 2 highlighted red block get to my first sight. (Red means high correlation here)\n\n- TotalBsmtSF and 1stFlrSF: the square feet of basement(TotalBsmtSF) area is probably very similiar to the 1st floor(1stFlrSF)\n- GarageCars and GarageArea: the number of cars(GarageCars) in Garage is decided by its size(GarageArea)\n\nI think we don't care about the most negative correlated features in the highlighted blue blocks here. In current topic, the target is **Linear Regression**, pick out the most significantly related variables is more important."},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix of 'SalePrice'\n\nReduce the Scope of Heatmap"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"k = 10\ncols = corr_matrix.nlargest(k, 'SalePrice')['SalePrice'].index\nk_corr_matrix = train[cols].corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(k_corr_matrix, annot=True, cmap=plt.cm.RdBu_r)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most correlated features with `SalePrice`:\n\n- OverallQual: **Rates** the overall material and finish of the house\n- GrLivArea: Above grade (ground) living **area square feet**\n- GarageCars and GarageArea: the most strongly correlated features, twin brothers of **Garage**\n- TotalBsmtSf and 1stFlrSF: **square feet** of basement and 1st floor\n- FullBath: Full **bathrooms** above grade, for urgency of ...\n- TotRmsAbvGrd: **Total rooms** above grade (does not include bathrooms)\n- YearBuilt: Original construction date decides the **years** of house\n\nRates, area square feet, Garage, bathrooms, total rooms, years, etc. These features is highly related to house price when taken into our real life, the correlation heatmap is really make sence."},{"metadata":{},"cell_type":"markdown","source":"### Pairplot\n\nAnother wonderful tool in @seaborn"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train[cols], height=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What we can find from the `Pairplot` figure above about variables relationship?\n\n1. `TotalBsmtSF` and `GrLivArea`: dots drawing a linear line like a upperbound, means that most of the basement area is not bigger than above ground living area, this make sense. It is a house, not a bunker\n2. `GrLivArea ~ SalePrice` and `TotalBsmtSF ~ SalePrice` is linear related, those 2 continuous variable is both about **area square feet** and they are highly related to house `SalePrice`\n3. `YearBuilt ~ SalePrice` dot clouds appears to be like an exponential function\n\nAnd the categorical varibles `OverallQual`, `GarageCars`, `FullBath` is also positive correlated to `SalePrice`."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 30))\nfor idx, f in enumerate(['OverallQual', 'GrLivArea', 'GarageArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', \n                         'FullBath', 'TotRmsAbvGrd','YearBuilt']):\n    plt.subplot(9, 2, 2*idx+1)\n    sns.distplot(train[f])\n    plt.subplot(9, 2, 2*idx+2)\n    sns.scatterplot(x=f, y='SalePrice', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 12))\ntrain.corr()['SalePrice'].sort_values().plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SalePrice\n\nAnalyze the target variable first. Does it a normal distribution?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution histogram for ourt target: SalePrice\nsns.distplot(train['SalePrice'], fit=norm)\n\n(mu, sigma) = norm.fit(train['SalePrice'])\nplt.legend(['Normal dist ($\\mu=${:.2f}, $\\sigma=${:.2f})'.format(mu, sigma)])\nplt.ylabel('Frequency')\nplt.title('SalePrice Distribution')\n\n# normal probability plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness and kurtosis\nprint('mu: %.2f, sigma: %.2f' % (mu, sigma))\nprint(\"Skewness: %f\" % train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train['SalePrice'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `SalePrice` is not rightly normal. Shows deflecting to left, positive \"skewness\", and not follow the diagonal line.\n\n**Statistics: in case of positive skewness, log transformations works well**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying log transformation\ntrain['SalePriceLog'] = np.log1p(train['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution histogram and normal probability plot\n(mu, sigma) = norm.fit(train['SalePriceLog'])\n\nsns.distplot(train['SalePriceLog'], fit=norm)\nplt.legend(['Normal dist ($\\mu=${:.2f}, $\\sigma=${:.2f})'.format(mu, sigma)])\n\nfig = plt.figure()\nstats.probplot(train['SalePriceLog'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness and kurtosis\nprint('mu: %.2f, sigma: %.2f' % (mu, sigma))\nprint(\"Skewness: %f\" % train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train['SalePrice'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The left skew is corrected and the data appears more normally distributed."},{"metadata":{},"cell_type":"markdown","source":"## Outliers"},{"metadata":{},"cell_type":"markdown","source":"### SalePrice Distribution\n\nStandardize the data and see if there're any outlier points. \n\nStandardization means converting data values to be with mean of 0 and standard deviation of 1 ($x \\sim \\mathcal{N}(0, 1)$). \n\n$$x=\\frac{x-\\mu}{\\sigma}$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_price_scaled = StandardScaler().fit_transform(train['SalePrice'][:, np.newaxis])\n\nsns.distplot(sale_price_scaled, fit=norm)\n\nlow_range = sale_price_scaled[sale_price_scaled[:, 0].argsort()[:10]]\nhigh_range = sale_price_scaled[sale_price_scaled[:, 0].argsort()[-10:]]\nprint(f'outer range (low) of the distribution: \\n{low_range}')\nprint(f'outer range (high) of the distribution: \\n{high_range}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Low range is within 2 standard deviations ($-2\\sigma$)\n- High range like the 7.x values are really out of range\n\nAt least, the 2 points with value greater than 7 should be considered as an outlier."},{"metadata":{},"cell_type":"markdown","source":"### Scatter Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x='GrLivArea', y='SalePrice', ylim=(0, 800000), xlim=(0, 6000))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 2 points in the bottom right are outside of the crowd and definetly outliers.\n\nThe 2 points in the upper right greater than 4000 in x-axis could also be considered as outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['GrLivArea'] < 4000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x='GrLivArea', y='SalePrice', ylim=(0, 800000), xlim=(0, 6000))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"### Quantitative and Qualitative"},{"metadata":{"trusted":true},"cell_type":"code","source":"quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\nquantitative.remove('SalePrice')\nquantitative.remove('Id')\nquantitative.sort()\nqualitative = [f for f in train.columns if train.dtypes[f] == 'object']\nqualitative.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# continuous variable\nquantitative","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical variable\nqualitative","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concat all data\n\nConcatenate the train and test data to analyze"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.reset_index(drop=True, inplace=True)\ny_train = train['SalePriceLog']\nX_train = train.drop(['SalePrice', 'SalePriceLog'], axis=1)\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat([X_train, test], axis=0, sort=False)\nall_data.drop(['Id'], axis=1, inplace=True)\nall_data.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"all_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Data"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"na_total = all_data.isnull().sum().sort_values(ascending=False)\nna_ratio = (all_data.isnull().sum() / all_data.shape[0]).sort_values(ascending=False)\nmissing_data = pd.concat([na_total, na_ratio], axis=1, keys=['Total', 'Ratio'])\nmissing_data.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most value of these 4 features are missing and they have no pattern , just delete them\nplt.figure(figsize=(16, 12))\nfor idx, f in enumerate(['PoolQC', 'Utilities', 'Street', 'MiscFeature']):\n    plt.subplot(2, 2, idx+1)\n    sns.scatterplot(x='SalePrice', y=f, data=train)\n\nall_data.drop(['PoolQC', 'Utilities', 'Street', 'MiscFeature', ], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the `data_description`, value NA means \"None\" for these `categorical features`, Fiil NA with **None** for them"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Alley'].fillna('None', inplace=True)\nall_data['Fence'].fillna('None', inplace=True)\nall_data['FireplaceQu'].fillna('None', inplace=True)\n\nall_data['GarageQual'].fillna('None', inplace=True)\nall_data['GarageFinish'].fillna('None', inplace=True)\nall_data['GarageCond'].fillna('None', inplace=True)\nall_data['GarageType'].fillna('None', inplace=True)\n\nall_data['BsmtExposure'].fillna('None', inplace=True)\nall_data['BsmtCond'].fillna('None', inplace=True)\nall_data['BsmtQual'].fillna('None', inplace=True)\nall_data['BsmtFinType2'].fillna('None', inplace=True)\nall_data['BsmtFinType1'].fillna('None', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the `categorical features` without what NA means, fill the NA with the **mode**, \nwhich means most categorical type of the feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['MasVnrType'].fillna('None', inplace=True)\nall_data['HasMasVnr'] = all_data['MasVnrType'].apply(lambda x: 0 if x == 'None' else 1)\n\nall_data['MSZoning'] = all_data.groupby(['MSSubClass'])['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\nall_data['Functional'].fillna('Typ', inplace=True)\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['GarageYrBlt'] = (all_data['YearBuilt'] + all_data['YearRemodAdd']) /2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='SalePrice', y='MasVnrArea',hue='MasVnrType', data=train, legend=None)\nall_data['MasVnrArea'] = all_data.groupby(['MasVnrType'])['MasVnrArea'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(all_data[all_data['GarageCars'].isnull()][['GarageArea', 'GarageCars', 'GarageType', 'GarageYrBlt', 'GarageQual']])\nall_data['GarageArea'].fillna(0, inplace=True)\nall_data['GarageCars'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(all_data[all_data['TotalBsmtSF'].isnull()][\n    ['TotalBsmtSF', 'BsmtQual', 'BsmtCond', 'BsmtFinSF2', 'BsmtUnfSF', 'BsmtFinSF1', 'BsmtFullBath','BsmtHalfBath']])\nall_data['TotalBsmtSF'].fillna(0, inplace=True)\nall_data['BsmtUnfSF'].fillna(0, inplace=True)\nall_data['BsmtFinSF1'].fillna(0, inplace=True)\nall_data['BsmtFinSF2'].fillna(0, inplace=True)\nall_data['BsmtFullBath'].fillna(0, inplace=True)\nall_data['BsmtHalfBath'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns scatter plot might be very usefull to see the data distribution with different categories\n# sns.scatterplot(x='SalePrice', y='MasVnrArea',hue='MasVnrType', data=train, legend=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge mutiple related or same kind of categorical features to creat a new one"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['YrBltAndRemod']=all_data['YearBuilt']+all_data['YearRemodAdd']\nall_data['TotalSF']=all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n\nall_data['TotalSqrFootage'] = (all_data['BsmtFinSF1'] + all_data['BsmtFinSF2'] +\n                                 all_data['1stFlrSF'] + all_data['2ndFlrSF'])\n\nall_data['TotalBathrooms'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) +\n                               all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))\n\nall_data['TotalPorchSF'] = (all_data['OpenPorchSF'] + all_data['3SsnPorch'] +\n                              all_data['EnclosedPorch'] + all_data['ScreenPorch'] +\n                              all_data['WoodDeckSF'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simplified features"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['has2ndfloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nall_data['hasgarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nall_data['hasbsmt'] = all_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nall_data['hasfireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some of the non-numeric predictors are stored as numbers; we convert them into strings \nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.get_dummies(all_data).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\n\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge, ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.svm import SVR\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nfrom mlxtend.regressor import StackingCVRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = all_data.iloc[:len(y_train), :]\nX_test = all_data.iloc[len(y_train):, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a cross validation strategy\n\nUse `cross_val_score` to get the **root mean square error**, which is the score method for current regression problem\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse_cv(model):\n    mse = cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n    rmse = np.sqrt(-mse)\n    print(f'{model.__class__.__name__} score: {rmse.mean():.4f}, {rmse.std():.4f}')\n    #return(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GridSearchCV to tune Model parameters\n\nUse `GridSearchCV` to find the best parameters"},{"metadata":{},"cell_type":"markdown","source":"> #### Lasso"},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso = Lasso()\nlasso_search = GridSearchCV(lasso, {'alpha': np.logspace(-4, -3, 5)}, cv=5, scoring=\"neg_mean_squared_error\")\nlasso_search.fit(X_train, y_train)\nlasso_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_model = make_pipeline(RobustScaler(), Lasso(alpha=0.0005, random_state=1))\nrmse_cv(lasso_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge = Ridge()\nridge_search = GridSearchCV(ridge, {'alpha': np.linspace(10, 30, 10)}, cv=5, scoring=\"neg_mean_squared_error\")\nridge_search.fit(X_train, y_train)\nridge_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_model = make_pipeline(RobustScaler(), Ridge(alpha=19))\nrmse_cv(ridge_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### ElasticNet, hybrid of Lasso and Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"enet = ElasticNet()\nenet_search = GridSearchCV(enet, {'alpha': np.linspace(0.0001, 0.001, 10), 'l1_ratio':np.linspace(0.5, 1.5, 10)}, cv=5, scoring=\"neg_mean_squared_error\")\nenet_search.fit(X_train, y_train)\nenet_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enet_model = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0004, l1_ratio=1.4, random_state=3))\nrmse_cv(enet_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### Gradient Boost Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"gbdt_model = GradientBoostingRegressor(learning_rate=0.05, min_samples_leaf=5, min_samples_split=10, max_depth=4, n_estimators=3000)\nrmse_cv(gbdt_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestRegressor(min_samples_leaf=4, min_samples_split=8)\nrmse_cv(rf_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"svr_model = make_pipeline(RobustScaler(), SVR(C=20, epsilon=0.005, gamma=0.0003))\nrmse_cv(svr_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = XGBRegressor(learning_rate=0.01, max_depth=5, n_estimators=3000, \n                         n_thread=-1, n_jobs=-1, objective='reg:squarederror')\nrmse_cv(xgb_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### Light GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model = LGBMRegressor(objective='regression',\n                    learning_rate=0.01, max_depth=5, num_leaves=4, \n                    n_estimators=3000)\nrmse_cv(lgb_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### Stacked Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"stack_model = StackingCVRegressor([lasso_model, ridge_model, enet_model, gbdt_model, rf_model, svr_model, xgb_model, lgb_model], \n                                  meta_regressor=lgb_model,\n                                  use_features_in_secondary=True)\n# rmse_cv(stack_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_model = lasso_model.fit(X_train, y_train)\nridge_model = ridge_model.fit(X_train, y_train)\nenet_model = enet_model.fit(X_train, y_train)\ngbdt_model = gbdt_model.fit(X_train, y_train)\nrf_model = rf_model.fit(X_train, y_train)\nsvr_model = svr_model.fit(X_train, y_train)\nxgb_model = xgb_model.fit(X_train, y_train)\nlgb_model = lgb_model.fit(X_train, y_train)\nstack_model = stack_model.fit(np.array(X_train), np.array(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_models_predict(X):\n    return ((0.1 * enet_model.predict(X)) + \\\n            (0.1 * ridge_model.predict(X)) + \\\n            (0.1 * lasso_model.predict(X)) + \\\n            (0.15 * gbdt_model.predict(X)) + \\\n            (0.15 * xgb_model.predict(X)) + \\\n            (0.1 * lgb_model.predict(X)) + \\\n            (0.075 * rf_model.predict(X)) + \\\n            (0.075 * svr_model.predict(X)) + \\\n            (0.15 * stack_model.predict(np.array(X)))\n           )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSLE score on train data:')\nprint(rmsle(y_train, combine_models_predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"log_result = combine_models_predict(X_test)\nresult = np.expm1(log_result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = test['Id']\nsub['SalePrice'] = result\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}