{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"font-size:300%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Introduction to Pycaret</h1>\n\n<img src=\"https://pycaret.org/wp-content/uploads/2021/02/pycaret2.3.png\" width=\"450px\"> <img src=\"https://i1.wp.com/pycaret.org/wp-content/uploads/2020/04/thumbnail.png?fit=1166%2C656&ssl=1\" width=\"500px\">\n\n\n\n<img align=center src=\"https://cdn.dribbble.com/users/18013/screenshots/12600021/media/3cb1d96666688e41589a638d48cd4674.png\" width=\"500px\">\n\n<cite>Image from www.dribbble.com by Vitaliy Sokovikov</cite>\n\n<li style=\"font-size:120%; font-family:monospace\"> PyCaret is a low-code machine learning library in Python that allows you to go from preparing your data to deploying your model in less time, so you can spend time doing something else while waiting for your model training üòé\n</li>\n\n\n<li style=\"font-size:120%; font-family:monospace\"> You can read the documentation of PyCaret at https://pycaret.org or https://pycaret.readthedocs.io/en/latest/\n</li>\n\n<li style=\"font-size:120%; font-family:monospace\">and a similar low-code ML library called LazyPredict at https://lazypredict.readthedocs.io/en/latest/\n</li>","metadata":{}},{"cell_type":"markdown","source":"# Intro to Pycaret","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Let's turn on Accelerator in Kaggle kernel and begin with PyCaret! üé¢ </h1>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">  üìå First, we will be using PyCaret on the diabetes dataset for classification</div>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Pycaret Installation ‚ú®</h1>","metadata":{}},{"cell_type":"code","source":"# Install Pycaret\n!pip install pycaret -q","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-07T08:51:49.218128Z","iopub.execute_input":"2021-06-07T08:51:49.218502Z","iopub.status.idle":"2021-06-07T08:52:33.010148Z","shell.execute_reply.started":"2021-06-07T08:51:49.218425Z","shell.execute_reply":"2021-06-07T08:52:33.009067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">  üìå We have two choice which are importing dataset from Kaggle or from Pycaret dataset itself (two of them are the same except for the column name)</div>","metadata":{}},{"cell_type":"code","source":"# importing dataset\nimport pandas as pd\ndf = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:52:33.011927Z","iopub.execute_input":"2021-06-07T08:52:33.012204Z","iopub.status.idle":"2021-06-07T08:52:33.063439Z","shell.execute_reply.started":"2021-06-07T08:52:33.012174Z","shell.execute_reply":"2021-06-07T08:52:33.062522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing dataset from PyCaret\nfrom pycaret.datasets import get_data\ndiabetes = get_data('diabetes')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:52:33.065067Z","iopub.execute_input":"2021-06-07T08:52:33.065323Z","iopub.status.idle":"2021-06-07T08:52:33.254914Z","shell.execute_reply.started":"2021-06-07T08:52:33.065298Z","shell.execute_reply":"2021-06-07T08:52:33.253912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> importing classification module and initializing setup üê±‚Äçüë§</h1>","metadata":{}},{"cell_type":"code","source":"# import a classification module of PyCaret\nfrom pycaret.classification import *","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:52:33.256661Z","iopub.execute_input":"2021-06-07T08:52:33.257253Z","iopub.status.idle":"2021-06-07T08:52:36.375446Z","shell.execute_reply.started":"2021-06-07T08:52:33.257199Z","shell.execute_reply":"2021-06-07T08:52:36.374482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">  üìå Running the below command and the module will automatically preprocesses the data and then creates a dataframe</div>","metadata":{}},{"cell_type":"markdown","source":"\n<li style=\"font-size:100%; font-family:monospace\"><b></b>you can put the whole dataframe in the \"data\" parameter and put the target variable in \"target\"\n</li>\n<li style=\"font-size:100%; font-family:monospace\"><b></b>parameter silent = True will ignore pops up message</li>","metadata":{}},{"cell_type":"code","source":"clf = setup(data = df, target = 'Outcome', silent = True, session_id = 123)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:52:36.37666Z","iopub.execute_input":"2021-06-07T08:52:36.376988Z","iopub.status.idle":"2021-06-07T08:52:37.706778Z","shell.execute_reply.started":"2021-06-07T08:52:36.376958Z","shell.execute_reply":"2021-06-07T08:52:37.705752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">  You can see that the setup process preprocess the data and create a train/test set automatically for us</div>","metadata":{}},{"cell_type":"code","source":"# run compare_models and save top 5 models based on 'Accuracy'\ntop_five = compare_models(n_select = 5)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:52:37.708272Z","iopub.execute_input":"2021-06-07T08:52:37.708666Z","iopub.status.idle":"2021-06-07T08:55:00.880113Z","shell.execute_reply.started":"2021-06-07T08:52:37.708626Z","shell.execute_reply":"2021-06-07T08:55:00.879233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\">Create the Best Model Performance (result can be different in each run)</h1>","metadata":{}},{"cell_type":"code","source":"catboost = create_model('catboost')   ","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:55:00.881482Z","iopub.execute_input":"2021-06-07T08:55:00.881769Z","iopub.status.idle":"2021-06-07T08:55:17.233338Z","shell.execute_reply.started":"2021-06-07T08:55:00.881741Z","shell.execute_reply":"2021-06-07T08:55:17.232285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuning the model","metadata":{}},{"cell_type":"code","source":"# tune the best performance model\ntuned_catboost = tune_model(catboost)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:55:17.235761Z","iopub.execute_input":"2021-06-07T08:55:17.236055Z","iopub.status.idle":"2021-06-07T08:55:34.296103Z","shell.execute_reply.started":"2021-06-07T08:55:17.236027Z","shell.execute_reply":"2021-06-07T08:55:34.295033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tune multiple models dynamically (tuning top 5 model)\ntuned_top5 = [tune_model(i) for i in top_five]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:55:34.297923Z","iopub.execute_input":"2021-06-07T08:55:34.298206Z","iopub.status.idle":"2021-06-07T08:56:33.132804Z","shell.execute_reply.started":"2021-06-07T08:55:34.298177Z","shell.execute_reply":"2021-06-07T08:56:33.13193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter of each of tuned_top5 model","metadata":{}},{"cell_type":"code","source":"tuned_top5","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:33.133986Z","iopub.execute_input":"2021-06-07T08:56:33.134247Z","iopub.status.idle":"2021-06-07T08:56:33.142484Z","shell.execute_reply.started":"2021-06-07T08:56:33.134221Z","shell.execute_reply":"2021-06-07T08:56:33.141347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize model performance\n<div class=\"alert alert-block alert-info\">  PyCaret uses high-level library Yellowbrick for creating these visualizations.</div>","metadata":{}},{"cell_type":"code","source":"tuned_model_1 = tuned_top5[0] \ntuned_model_2 = tuned_top5[1]\ntuned_model_3 = tuned_top5[2] \ntuned_model_4 = tuned_top5[3]\ntuned_model_5 = tuned_top5[4]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:33.143914Z","iopub.execute_input":"2021-06-07T08:56:33.144257Z","iopub.status.idle":"2021-06-07T08:56:33.152431Z","shell.execute_reply.started":"2021-06-07T08:56:33.144225Z","shell.execute_reply":"2021-06-07T08:56:33.151387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(tuned_catboost)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:33.154907Z","iopub.execute_input":"2021-06-07T08:56:33.155173Z","iopub.status.idle":"2021-06-07T08:56:33.453231Z","shell.execute_reply.started":"2021-06-07T08:56:33.155147Z","shell.execute_reply":"2021-06-07T08:56:33.452326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(tuned_model_2)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:33.45608Z","iopub.execute_input":"2021-06-07T08:56:33.456347Z","iopub.status.idle":"2021-06-07T08:56:33.653931Z","shell.execute_reply.started":"2021-06-07T08:56:33.456321Z","shell.execute_reply":"2021-06-07T08:56:33.653079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(tuned_model_3)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:33.655065Z","iopub.execute_input":"2021-06-07T08:56:33.655327Z","iopub.status.idle":"2021-06-07T08:56:33.900194Z","shell.execute_reply.started":"2021-06-07T08:56:33.655303Z","shell.execute_reply":"2021-06-07T08:56:33.899254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(tuned_model_4)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:33.901423Z","iopub.execute_input":"2021-06-07T08:56:33.901685Z","iopub.status.idle":"2021-06-07T08:56:34.159943Z","shell.execute_reply.started":"2021-06-07T08:56:33.90166Z","shell.execute_reply":"2021-06-07T08:56:34.158884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(tuned_model_5)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:34.161924Z","iopub.execute_input":"2021-06-07T08:56:34.162355Z","iopub.status.idle":"2021-06-07T08:56:34.363612Z","shell.execute_reply.started":"2021-06-07T08:56:34.162313Z","shell.execute_reply":"2021-06-07T08:56:34.362611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Isn't that amazing? It's just one line of code!","metadata":{}},{"cell_type":"markdown","source":"# Interpret the model \nThis function supports tree based models for binary classification: lightgbm, catboost, et, xgboost, rf, dt.)","metadata":{}},{"cell_type":"code","source":"interpret_model(tuned_catboost)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:34.364764Z","iopub.execute_input":"2021-06-07T08:56:34.36505Z","iopub.status.idle":"2021-06-07T08:56:42.139104Z","shell.execute_reply.started":"2021-06-07T08:56:34.365024Z","shell.execute_reply":"2021-06-07T08:56:42.128032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AutoML\nThe following function returns the best model out of all models created in the current active environment based on metric defined in optimize parameter. Run this code at the end of  your script.","metadata":{}},{"cell_type":"code","source":"# using recall \nautoml_model = automl(optimize = 'f1')\nautoml_model","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:42.140469Z","iopub.execute_input":"2021-06-07T08:56:42.140775Z","iopub.status.idle":"2021-06-07T08:56:43.805592Z","shell.execute_reply.started":"2021-06-07T08:56:42.140743Z","shell.execute_reply":"2021-06-07T08:56:43.804547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"markdown","source":"The predict_model function allows us to predict data from the experiment or new unseen data. ","metadata":{}},{"cell_type":"code","source":"prediction = predict_model(automl_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:43.806778Z","iopub.execute_input":"2021-06-07T08:56:43.80705Z","iopub.status.idle":"2021-06-07T08:56:44.053859Z","shell.execute_reply.started":"2021-06-07T08:56:43.807025Z","shell.execute_reply":"2021-06-07T08:56:44.052687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:44.054857Z","iopub.execute_input":"2021-06-07T08:56:44.055136Z","iopub.status.idle":"2021-06-07T08:56:44.08865Z","shell.execute_reply.started":"2021-06-07T08:56:44.055103Z","shell.execute_reply":"2021-06-07T08:56:44.087719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blending Model\nThis function automatically create voting classifer based on the model we passed into the \"estimator list\" parameter","metadata":{}},{"cell_type":"code","source":"# specify the model in \"estimator_list\" parameter\nblended_top5 = blend_models(estimator_list = tuned_top5) \nblended_top5","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:44.089869Z","iopub.execute_input":"2021-06-07T08:56:44.090152Z","iopub.status.idle":"2021-06-07T08:56:50.759823Z","shell.execute_reply.started":"2021-06-07T08:56:44.090124Z","shell.execute_reply":"2021-06-07T08:56:50.759055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Emsemble Model","metadata":{}},{"cell_type":"code","source":"# ensemble top 5 tuned models\nbagged_top5 = [ensemble_model(i) for i in tuned_top5]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:56:50.760814Z","iopub.execute_input":"2021-06-07T08:56:50.761098Z","iopub.status.idle":"2021-06-07T08:57:50.258122Z","shell.execute_reply.started":"2021-06-07T08:56:50.761073Z","shell.execute_reply":"2021-06-07T08:57:50.257365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving and loading the Model\nThe following function save any model you want. After running it, you can check the file in the output folder on your right","metadata":{}},{"cell_type":"code","source":"# specify which model you want to save in the first parameter, name in the second\nsave_model(automl_model, model_name='automl-model')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:57:50.261702Z","iopub.execute_input":"2021-06-07T08:57:50.262086Z","iopub.status.idle":"2021-06-07T08:57:50.510013Z","shell.execute_reply.started":"2021-06-07T08:57:50.262058Z","shell.execute_reply":"2021-06-07T08:57:50.509349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nloaded_model = load_model('automl-model')\nprint(loaded_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:57:50.511683Z","iopub.execute_input":"2021-06-07T08:57:50.512004Z","iopub.status.idle":"2021-06-07T08:57:50.531821Z","shell.execute_reply.started":"2021-06-07T08:57:50.511976Z","shell.execute_reply":"2021-06-07T08:57:50.530896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bonus section on Classification (applying feature engineering) \nYou can check how to do a feature engineering here https://www.kaggle.com/vincentlugat/pima-indians-diabetes-eda-prediction-0-906\n\n","metadata":{}},{"cell_type":"code","source":"# Data preprocessing\ndef replace_missing(data):\n    data[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = data[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.NaN)\n    return data\n\ndef median_target(data,var):   \n    temp = data[data[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp\n\ndef replace_median(data):\n    null_columns = ['BloodPressure', 'BMI', 'SkinThickness', 'Glucose', 'Insulin']\n    for i in null_columns:\n        f = median_target(data, i)\n        data.loc[(data['Outcome'] == 0 ) & (data[i].isnull()), i] = f[[i]].values[0][0]\n        data.loc[(data['Outcome'] == 1 ) & (data[i].isnull()), i] = f[[i]].values[1][0]\n    return data\n\ndef feature_engineering(data):\n    data.loc[:,'N1']=0\n    data.loc[(data['Age']<=30) & (data['Glucose']<=120),'N1']=1\n\n    data.loc[:,'N2']=0\n    data.loc[(data['BMI']<=30),'N2']=1\n\n    data.loc[:,'N3']=0\n    data.loc[(data['Age']<=30) & (data['Pregnancies']<=6),'N3']=1\n\n    data.loc[:,'N3_1']=0\n    data.loc[(data['Glucose']<=110) & (data['Pregnancies']<=5),'N3_1']=1\n\n    data.loc[:,'N4']=0\n    data.loc[(data['Glucose']<=105) & (data['BloodPressure']<=80),'N4']=1\n\n    data.loc[:,'N4_1']=0\n    data.loc[(data['Age']<=30) & (data['Pregnancies']<=6),'N4_1']=1\n\n    data.loc[:,'N5']=0\n    data.loc[(data['SkinThickness']<=20) ,'N5']=1\n\n    data.loc[:,'N6']=0\n    data.loc[(data['BMI']<30) & (data['SkinThickness']<=20),'N6']=1\n\n    data.loc[:,'N7']=0\n    data.loc[(data['Glucose']<=105) & (data['BMI']<=30),'N7']=1\n\n    data.loc[:,'N7_1']=0\n    data.loc[(data['BMI']<30) & (data['SkinThickness']<=20),'N7_1']=1\n\n    data.loc[:,'N9']=0\n    data.loc[(data['Insulin']<200),'N9']=1\n\n    data.loc[:,'N10']=0\n    data.loc[(data['BloodPressure']<80),'N10']=1\n\n    data.loc[:,'N11']=0\n    data.loc[(data['Pregnancies']<4) & (data['Pregnancies']!=0) ,'N11']=1\n\n    # highly correlate data\n\n    data['N0'] = data['BMI'] * data['SkinThickness']\n\n    data['N8'] =  data['Pregnancies'] / data['Age']\n\n    data['N13'] = data['Glucose'] / data['DiabetesPedigreeFunction']\n\n    data['N12'] = data['Age'] * data['DiabetesPedigreeFunction']\n\n    data['N14'] = data['Age'] / data['Insulin']\n\n    data['N15'] = data['BMI'] / data['Insulin']\n    return data\n\ndef prepare_data(data):\n    cat_cols   = data.nunique()[data.nunique() < 12].keys().tolist()\n    cat_cols   = [x for x in cat_cols]\n    #numerical columns\n    num_cols   = [x for x in data.columns if x not in cat_cols]\n    #Binary columns with 2 values\n    bin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n    #Columns more than 2 values\n    multi_cols = [i for i in cat_cols if i not in bin_cols]\n\n    #Label encoding Binary columns\n    le = LabelEncoder()\n    for i in bin_cols :\n        data[i] = le.fit_transform(data[i])\n        \n    #Duplicating columns for multi value columns\n    data = pd.get_dummies(data = data,columns = multi_cols )\n\n    #Scaling Numerical columns\n    std = StandardScaler()\n    scaled = std.fit_transform(data[num_cols])\n    scaled = pd.DataFrame(scaled,columns=num_cols)\n\n    #dropping original values merging scaled values for numerical columns\n    df_data_og = data.copy()\n    data = data.drop(columns = num_cols,axis = 1)\n    data = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:57:50.533337Z","iopub.execute_input":"2021-06-07T08:57:50.533731Z","iopub.status.idle":"2021-06-07T08:57:50.561536Z","shell.execute_reply.started":"2021-06-07T08:57:50.533689Z","shell.execute_reply":"2021-06-07T08:57:50.560662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, LabelEncoder\ndf_rms = replace_missing(df)\ndf_rm = replace_median(df_rms)\ndf_fe = feature_engineering(df_rm)\nprepared_data = prepare_data(df_fe)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:57:50.562781Z","iopub.execute_input":"2021-06-07T08:57:50.563177Z","iopub.status.idle":"2021-06-07T08:57:50.68079Z","shell.execute_reply.started":"2021-06-07T08:57:50.563138Z","shell.execute_reply":"2021-06-07T08:57:50.680005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepared_data","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:57:50.682177Z","iopub.execute_input":"2021-06-07T08:57:50.682723Z","iopub.status.idle":"2021-06-07T08:57:50.712499Z","shell.execute_reply.started":"2021-06-07T08:57:50.682693Z","shell.execute_reply":"2021-06-07T08:57:50.711166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_new = setup(data = prepared_data, target = 'Outcome', silent = True, session_id = 125)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:57:50.713834Z","iopub.execute_input":"2021-06-07T08:57:50.71419Z","iopub.status.idle":"2021-06-07T08:57:51.674281Z","shell.execute_reply.started":"2021-06-07T08:57:50.71415Z","shell.execute_reply":"2021-06-07T08:57:51.6733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run compare_models and save top 5 models\ntop_five = compare_models(n_select = 5)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:57:51.67554Z","iopub.execute_input":"2021-06-07T08:57:51.675811Z","iopub.status.idle":"2021-06-07T09:00:16.835331Z","shell.execute_reply.started":"2021-06-07T08:57:51.675785Z","shell.execute_reply":"2021-06-07T09:00:16.834394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After we applied feature engineering, we can see a big improvement of each model","metadata":{}},{"cell_type":"markdown","source":"# Regression","metadata":{}},{"cell_type":"code","source":"car_data = pd.read_csv('../input/car-price-prediction/CarPrice_Assignment.csv')\ncar_data","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:00:16.836343Z","iopub.execute_input":"2021-06-07T09:00:16.83659Z","iopub.status.idle":"2021-06-07T09:00:16.89131Z","shell.execute_reply.started":"2021-06-07T09:00:16.836566Z","shell.execute_reply":"2021-06-07T09:00:16.890264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pycaret.regression import *","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:00:16.892537Z","iopub.execute_input":"2021-06-07T09:00:16.892801Z","iopub.status.idle":"2021-06-07T09:00:16.899634Z","shell.execute_reply.started":"2021-06-07T09:00:16.892775Z","shell.execute_reply":"2021-06-07T09:00:16.898787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rgs = setup(data = car_data,  target = 'price', silent = True, session_id = 124)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:00:16.900861Z","iopub.execute_input":"2021-06-07T09:00:16.901146Z","iopub.status.idle":"2021-06-07T09:00:17.972286Z","shell.execute_reply.started":"2021-06-07T09:00:16.90112Z","shell.execute_reply":"2021-06-07T09:00:17.971313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run compare_models and save top 5 models \ntop_five_r = compare_models(n_select = 5)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:00:17.973526Z","iopub.execute_input":"2021-06-07T09:00:17.973825Z","iopub.status.idle":"2021-06-07T09:03:01.761921Z","shell.execute_reply.started":"2021-06-07T09:00:17.973798Z","shell.execute_reply":"2021-06-07T09:03:01.761091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catboost = create_model('catboost')   ","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:03:01.762974Z","iopub.execute_input":"2021-06-07T09:03:01.76335Z","iopub.status.idle":"2021-06-07T09:03:14.858731Z","shell.execute_reply.started":"2021-06-07T09:03:01.763322Z","shell.execute_reply":"2021-06-07T09:03:14.857747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tune the best performance model\ntuned_catboost = tune_model(catboost)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:03:14.859881Z","iopub.execute_input":"2021-06-07T09:03:14.86016Z","iopub.status.idle":"2021-06-07T09:04:23.505329Z","shell.execute_reply.started":"2021-06-07T09:03:14.860122Z","shell.execute_reply":"2021-06-07T09:04:23.504374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(tuned_catboost)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:04:23.50669Z","iopub.execute_input":"2021-06-07T09:04:23.507036Z","iopub.status.idle":"2021-06-07T09:04:23.789717Z","shell.execute_reply.started":"2021-06-07T09:04:23.507006Z","shell.execute_reply":"2021-06-07T09:04:23.788822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpret_model(tuned_catboost)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:04:23.790993Z","iopub.execute_input":"2021-06-07T09:04:23.791289Z","iopub.status.idle":"2021-06-07T09:04:24.812868Z","shell.execute_reply.started":"2021-06-07T09:04:23.79126Z","shell.execute_reply":"2021-06-07T09:04:24.811707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using recall \nautoml_model = automl(optimize = 'MAE')\nautoml_model","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:04:24.81408Z","iopub.execute_input":"2021-06-07T09:04:24.814352Z","iopub.status.idle":"2021-06-07T09:04:26.159972Z","shell.execute_reply.started":"2021-06-07T09:04:24.814324Z","shell.execute_reply":"2021-06-07T09:04:26.158918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The predict_model function below produces predictions for the holdout datasets used for validating the model during cross-validation. The code also gives us a dataframe with performance statistics for the predictions generated by the AutoML model.","metadata":{}},{"cell_type":"code","source":"pred_holdouts = predict_model(automl_model)\npred_holdouts.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:04:26.161207Z","iopub.execute_input":"2021-06-07T09:04:26.161472Z","iopub.status.idle":"2021-06-07T09:04:26.437779Z","shell.execute_reply.started":"2021-06-07T09:04:26.161445Z","shell.execute_reply":"2021-06-07T09:04:26.436883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also produce predictions on the entire dataset","metadata":{}},{"cell_type":"code","source":"new_data = car_data.copy()\nnew_data.drop(['price'], axis=1, inplace=True)\npredictions = predict_model(automl_model, data=new_data)\npredictions.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:04:26.439917Z","iopub.execute_input":"2021-06-07T09:04:26.440647Z","iopub.status.idle":"2021-06-07T09:04:26.789305Z","shell.execute_reply.started":"2021-06-07T09:04:26.440601Z","shell.execute_reply":"2021-06-07T09:04:26.788289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-size:210%; font-family:monospace; background:#3CB371; color:white; text-align:center; border:10px solid ; padding:25px;\"> Thank you for reading and there are more to come! If you found this helpful, please upvote üòä </h1> \n","metadata":{}}]}