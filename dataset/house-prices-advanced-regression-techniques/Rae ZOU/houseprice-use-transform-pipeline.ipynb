{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport sklearn\n\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sklearn.__version__","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the dataset","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(r'../input/house-prices-advanced-regression-techniques/train.csv')\ndata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove irrelevant variables\ndata = data.drop(\"Id\", axis=1)\ndata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create the test set\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains a mixture of categorical and numerical columns, `dtypes: float64(3), int64(34), object(43)`. There are continuous, nominal, and ordinal data types.\nIt also has missing data which indicates we need to apply transformation `ColumnTransformer` for different columns of data.  \n\nFor continuous columns, use `SimpleImputer` with `strategy='mean'` to handle missing values, then apply `StandardScaler` to normalize data.\n\nFor ordinal columns and norminal columns, use `SimpleImputer` with `strategy='most_frequent` to handle missing values, and use `OrdinalEncoder` and `OneHotEncoder` to convert categorical values to numerical values.","metadata":{}},{"cell_type":"code","source":"train_data.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore the training set to gain insights","metadata":{}},{"cell_type":"code","source":"# compute the standard correlation coefficient\nhousing = train_data.copy()\n\ncorr_matrix = housing.corr()\ncorr_matrix[\"SalePrice\"].sort_values(ascending=False)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nattributes = [\"SalePrice\",\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"GarageArea\", \"TotalBsmtSF\"]\nscatter_matrix(housing[attributes], figsize=(12, 12));","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There is a positive correlation between the `SalePrice` and `OverallQual`, `GrLivArea`, `GarageCar` and  `GarageArea`.","metadata":{}},{"cell_type":"markdown","source":"### Select one machine learning model, train, optimise","metadata":{}},{"cell_type":"code","source":"# separate the predictors and the labels\nX_train = train_data.drop(\"SalePrice\", axis=1)\ny_train = train_data[\"SalePrice\"].copy()  # save the labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Identify all ordinal_columns: all quality related","metadata":{}},{"cell_type":"code","source":"X_train['OverallQual'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['ExterQual'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['BsmtFinType1'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['BsmtFinType2'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['HeatingQC'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['LowQualFinSF'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['KitchenQual'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['FireplaceQu'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['PoolQC'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['Fence'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['GarageQual'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getOrdinalPip(order):\n    return Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                             ('encoder', OrdinalEncoder(categories=order,\n                                                        handle_unknown='use_encoded_value', # New in version 0.24\n                                                        unknown_value=-1,)),\n                             ('scaler', StandardScaler())])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ordinal_columns = ['HeatingQC', 'GarageQual','FireplaceQu','KitchenQual','ExterQual']\n# drop all ordinal columns\ndef drop_ordinal(df):\n    X_train_dump = df.drop(columns=ordinal_columns)\n    return X_train_dump    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import make_column_selector as selector\nfrom sklearn.compose import ColumnTransformer\n\n# a function for getting all categorical_columns\ndef get_categorical_columns(df):\n    categorical_columns_selector = selector(dtype_include=object)\n    categorical_columns = categorical_columns_selector(drop_ordinal(df))\n    return categorical_columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a function for getting all numerical_columns\ndef get_numerical_columns(df):\n    numerical_columns_selector = selector(dtype_exclude=object)\n    numerical_columns = numerical_columns_selector(df)\n    return numerical_columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_numerical_columns(X_train)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_categorical_columns(X_train)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ordinal_pipeline(order):\n    return Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                             ('encoder', OrdinalEncoder(categories=order,\n                                                        handle_unknown='error',\n                                                        unknown_value=None,)),\n                             ('scaler', StandardScaler())])\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n# a function for Transformation the data\ndef my_transformation(df):\n    df = df.copy()\n    \n    numerical_columns = get_numerical_columns(df)\n    nominal_columns = get_categorical_columns(df)\n    ordinal_columns = ['GarageQual']\n    ordinal_columns1 = ['FireplaceQu']\n    ordinal_columns2 = ['HeatingQC']\n    order1 = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]\n  \n    ordinal_columns3 = ['KitchenQual']\n    ordinal_columns4 = ['ExterQual']\n    order2 = [['Fa', 'TA', 'Gd', 'Ex']]\n    \n    numerical_pipeline = Pipeline([('imputer', SimpleImputer(strategy='mean')),\n                               ('scaler', StandardScaler())])\n    nominal_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                             ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n    ordinal_pipeline1 = get_ordinal_pipeline(order1)\n    ordinal_pipeline2 = get_ordinal_pipeline(order2)\n\n    preprocessor = ColumnTransformer([\n        ('numerical_transformer', numerical_pipeline, numerical_columns),\n        ('nominal_transformer', nominal_pipeline, nominal_columns),\n        ('ordinal_transformer', ordinal_pipeline1, ordinal_columns),\n        ('ordinal_transformer1', ordinal_pipeline1, ordinal_columns1),\n        ('ordinal_transformer2', ordinal_pipeline1, ordinal_columns2),\n        ('ordinal_transformer3', ordinal_pipeline2, ordinal_columns3),\n        ('ordinal_transformer4', ordinal_pipeline2, ordinal_columns4),\n    ])\n    \n    preprocessor.fit(df)\n    \n    return preprocessor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor= my_transformation(X_train)\nX_train_prepared = preprocessor.transform(X_train)\nX_train_prepared.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# a function for tuning the model with hyper-parameter\ndef tune_model(model, param_grid, X_train_prepared):\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n    grid_search.fit(X_train_prepared, y_train);\n    print('grid_search.best_estimator_: ', grid_search.best_estimator_)\n    final_model = grid_search.best_estimator_\n    return final_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\ndef showPerformance(clf):\n    y_train_pred = clf.predict(X_train_prepared)\n    \n    print(\"RMSE train: \", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n    scores = cross_val_score(lin_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=3)\n    lin_rmse_scores = np.sqrt(-scores)\n    print(\"Validation score RMSE Mean:\", lin_rmse_scores.mean(), \"; Standard deviation:\", lin_rmse_scores.std())\n    print(\"Training set score: {:.2f}\".format(clf.score(X_train_prepared, y_train)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train a Linear Regression model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train_prepared, y_train);\nshowPerformance(lin_reg)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Use RidgeCV","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import RidgeCV\nridge = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10], cv=5).fit(X_train_prepared, y_train)\n\nprint(\"alpha = \", ridge.alpha_)\nshowPerformance(ridge)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Use LassoCV","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV\nlasso = LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10], max_iter=10000, cv=5).fit(X_train_prepared, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"alpha = \", lasso.alpha_)\nprint(\"Number of features used:\", np.sum(lasso.coef_ != 0))\nshowPerformance(lasso)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Use ElasticNet","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nelastic =  ElasticNet(max_iter=1e7)\nelastic.fit(X_train_prepared, y_train)\n\nshowPerformance(elastic)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {\n            'alpha'     : [0.1, 1, 10, 0.01],\n            'l1_ratio'  :  np.arange(0.40,1.00,0.10),\n            'tol'       : [0.0001,0.001]\n            }\n\nfinal_model_elastic = tune_model(elastic, param_grid, X_train_prepared)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showPerformance(final_model_elastic)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Use VotingRegressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\n\ner = VotingRegressor([('ridge', ridge), ('lasso', lasso)], weights=[1,2])\ner.fit(X_train_prepared, y_train)\n\nshowPerformance(er)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test model performance on test data","metadata":{}},{"cell_type":"code","source":"X_test = test_data.drop(\"SalePrice\", axis=1)\ny_test = test_data[\"SalePrice\"].copy()\nX_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_prepared = preprocessor.transform(X_test) \nX_test_prepared.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import median_absolute_error\nfrom sklearn.metrics import mean_absolute_percentage_error # New in version 0.24\n# show the model permormance on test data\ndef perfor_test(model):\n    y_test_predicted = model.predict(X_test_prepared)\n    print(f\"Mean absolute error (MAE): \" f\"{mean_absolute_error(y_test, y_test_predicted):.4f} $\")\n    print(f\"Median absolute error (MedAE): \" f\"{median_absolute_error(y_test, y_test_predicted):.4f} $\")\n    print(f\"Mean absolute percentage error (MAPE): \" f\"{mean_absolute_percentage_error(y_test, y_test_predicted) * 100:.4f} %\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfor_test(lin_reg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfor_test(lasso)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfor_test(ridge)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfor_test(er)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfor_test(elastic)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n# plot the regression\ndef plot_reg(model):\n    y_test_predicted = model.predict(X_test_prepared)\n    predicted_actual = {\"True values ($)\": y_test, \"Predicted values ($)\": y_test_predicted}\n    predicted_actual = pd.DataFrame(predicted_actual)\n    \n    sns.scatterplot(data=predicted_actual,\n                     x=\"True values ($)\", y=\"Predicted values ($)\",\n                     color=\"black\", alpha=0.5)\n    plt.axline((0, 0), slope=1, label=\"Perfect fit\")\n    plt.axis('square')\n    plt.title(\"Regression using a model without \\ntarget transformation\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_reg(er)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model tends to under-estimate the price of the house.","metadata":{}},{"cell_type":"markdown","source":"#### Apply a target transformation","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\nfrom sklearn.compose import TransformedTargetRegressor\n\ndef target_transform(model):\n    quantile_transformer = QuantileTransformer(n_quantiles=900, output_distribution=\"normal\")\n    model_transformed_target = TransformedTargetRegressor(regressor=model,\n                                transformer=quantile_transformer)\n\n    model_transformed_target.fit(X_train_prepared, y_train)\n    return model_transformed_target","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfor_test(target_transform(lasso))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfor_test(target_transform(er))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_reg(target_transform(lasso))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Output predictions","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(r'../input/house-prices-advanced-regression-techniques/test.csv')\nID = test[\"Id\"]\ntest = test.drop(\"Id\", axis=1)\ntest.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ID.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prepared = preprocessor.transform(test) \ntest_prepared.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = target_transform(er).predict(test_prepared)\nprediction = pd.DataFrame(data={\"Id\":ID,\"SalePrice\":prediction}).to_csv('prediction.csv', index= False)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = pd.read_csv(r'../input/prediction/prediction.csv')\nres.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}