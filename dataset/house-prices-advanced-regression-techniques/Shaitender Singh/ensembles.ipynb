{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#delete \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntest=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ID=train['Id']\ntest_ID=test['Id']\ntrain.drop(\"Id\",axis=1,inplace=True)\ntest.drop(\"Id\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(30,30))\nsns.heatmap(train.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train[train[\"GrLivArea\"]<4500]\ntrain.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['SalePrice']=np.log1p(train['SalePrice'])\ny=train['SalePrice']\ntrain_features=train.drop('SalePrice',axis=1)\ntest_features=test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=pd.concat([train_features,test_features],axis=0)\nnumeric_t = [f for f in features.columns if features.dtypes[f] != 'object']\nchar_t = [f for f in features.columns if features.dtypes[f] == 'object']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in numeric_t:\n    if features[col].isnull().sum()>0:\n        print(\"{} is lack of {}\".format(col,features[col].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in char_t:\n    if features[col].isnull().sum()>0:\n        print(\"{} is lack of {}\".format(col,features[col].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['MSSubClass'] = features['MSSubClass'].astype(str)\nfeatures['YrSold'] = features['YrSold'].astype(str)\nfeatures['MoSold'] = features['MoSold'].astype(str)\nfeatures['Functional']=features['Functional'].fillna('Typ')\nfeatures['Electrical'] = features['Electrical'].fillna(\"SBrkr\")\nfeatures['KitchenQual'] = features['KitchenQual'].fillna(\"TA\")\nfeatures['Exterior1st']=features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])\nfeatures['Exterior2nd']=features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\nfeatures['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\nfeatures[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    features[col] = features[col].fillna(0)\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    features[col] = features[col].fillna('None')\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    features[col] = features[col].fillna('None')\n    features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n\nobjects = []\nfor i in features.columns:\n    if features[i].dtype == object:\n        objects.append(i)\nfeatures.update(features[objects].fillna('None'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics.append(i)\nfeatures.update(features[numerics].fillna(0))\n\nnumerics2 = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics2.append(i)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import skew  # for some statistics\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nskew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nfor i in skew_index:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\nfeatures['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\nfeatures['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n\nfeatures['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n                                 features['1stFlrSF'] + features['2ndFlrSF'])\n\nfeatures['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n\nfeatures['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n                              features['EnclosedPorch'] + features['ScreenPorch'] +\n                              features['WoodDeckSF'])\nfeatures['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_features = pd.get_dummies(features).reset_index(drop=True)\nprint(final_features.shape)\nX = final_features.iloc[:len(y), :]\nX_sub = final_features.iloc[len(X):, :]\nprint('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n\noutliers = [30, 88, 462, 631, 1322]\nX = X.drop(X.index[outliers])\ny = y.drop(y.index[outliers])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overfit = []\nfor i in X.columns:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros / len(X) * 100 > 99.94:\n        overfit.append(i)\n\noverfit = list(overfit)\noverfit.append('MSZoning_C (all)')\n\nX = X.drop(overfit, axis=1).copy()\nX_sub = X_sub.drop(overfit, axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  #\nfrom datetime import datetime\n\nfrom scipy.stats import skew  # for some statistics\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\nfrom mlxtend.regressor import StackingCVRegressor\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rmsle\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\n\n# build our model scoring function\ndef cv_rmse(model, X=X):\n    rmse = np.sqrt(-cross_val_score(model, X, y,\n                                    scoring=\"neg_mean_squared_error\",\n                                    cv=kfolds))\n    return (rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nkfolds=KFold(n_splits=10,shuffle=True,random_state=42)\nscale=RobustScaler().fit(X)\nX1=scale.transform(X)\nfrom sklearn.linear_model import Ridge\n\nmodel=Ridge()\nrid_param_grid = {\"alpha\":[19.8]}\ngrid_search= GridSearchCV(model,param_grid=rid_param_grid,cv=kfolds,scoring=\"neg_mean_squared_error\",n_jobs= 10, verbose = 1)\ngrid_search.fit(X1,y)\nrid_best=grid_search.best_estimator_\nnp.sqrt(-grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nmodel=Lasso()\nlas_param_grid = {\"alpha\":[0.0005963623316594642]}\ngrid_search= GridSearchCV(model,param_grid=las_param_grid,cv=kfolds,scoring=\"neg_mean_squared_error\",n_jobs= 10, verbose = 1)\ngrid_search.fit(X1,y)\nlas_best=grid_search.best_estimator_\nnp.sqrt(-grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nmodel=ElasticNet()\nela_param_grid = {\"alpha\":[0.0006951927961775605],\n                 \"l1_ratio\":[0.90]}\ngrid_search= GridSearchCV(model,param_grid=ela_param_grid,cv=kfolds,scoring=\"neg_mean_squared_error\",n_jobs= 10, verbose = 1)\ngrid_search.fit(X1,y)\nela_best=grid_search.best_estimator_\nnp.sqrt(-grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nmodel=SVR()\nsvr_param_grid = {\"C\":[66],\n                 \"gamma\":[6.105402296585326e-05]}\ngrid_search= GridSearchCV(model,param_grid=svr_param_grid,cv=kfolds,scoring=\"neg_mean_squared_error\",n_jobs= 10, verbose = 1)\ngrid_search.fit(X1,y)\nsvr_best=grid_search.best_estimator_\nnp.sqrt(-grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=GradientBoostingRegressor()\ngbdt_param_grid = {\"n_estimators\":[2200],\n                 \"learning_rate\":[0.05],\n                   \"max_depth\":[3],\n                   \"max_features\":[\"sqrt\"],\n                   \"min_samples_leaf\":[5],\n                   \"min_samples_split\":[12],\n                   \"loss\":[\"huber\"]\n                  }\n                   \n                   \n                   \ngrid_search= GridSearchCV(model,param_grid=gbdt_param_grid,cv=kfolds,scoring=\"neg_mean_squared_error\",n_jobs= 10, verbose = 1)\ngrid_search.fit(X1,y)\ngbdt_best=grid_search.best_estimator_\nnp.sqrt(-grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LGBMRegressor()\nlgbm_param_grid = {\n                   'objective':['regression'], \n                   'max_depth':[5],\n                   'num_leaves':[12],\n                   'learning_rate':[0.005], \n                    'n_estimators':[5500],\n                    'max_bin':[190], \n                    'bagging_fraction':[0.2],\n                    'feature_fraction':[0.2]                  \n                  }\n                   \n                   \n                   \ngrid_search= GridSearchCV(model,param_grid=lgbm_param_grid,cv=kfolds,scoring=\"neg_mean_squared_error\",n_jobs= 10, verbose = 1)\ngrid_search.fit(X1,y)\nlgbm_best=grid_search.best_estimator_\nnp.sqrt(-grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nkfolds=KFold(n_splits=5,shuffle=True,random_state=42)\nscale=RobustScaler().fit(X)\nX1=scale.transform(X)\nmodel=XGBRegressor()\nxgb_param_grid = {\"n_estimators\":[3000],\n                 \"learning_rate\":[0.01],\n                   \"max_depth\":[3],\n                   \"subsample\":[0.8],\n                \"colsample_bytree\":[0.8],\n                 \"gamma\":[0],\n                \"objective\":['reg:linear'],\n                \"min_child_weight\":[2], \n                \"reg_alpha\":[0.1],\n                \"reg_lambda\":[0.5]\n                  }\n                   \n                   \n                   \ngrid_search= GridSearchCV(model,param_grid=xgb_param_grid,cv=kfolds,scoring=\"neg_mean_squared_error\",n_jobs= 10, verbose = 1)\ngrid_search.fit(X1,y)\nxgb_best=grid_search.best_estimator_\nnp.sqrt(-grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stack_gen = StackingCVRegressor(regressors=(rid_best, las_best, ela_best,\n                                            gbdt_best, xgb_best, lgbm_best),\n                                meta_regressor=xgb_best,\n                                use_features_in_secondary=True)\nstack_gen.fit(np.array(X1), np.array(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sub=scale.transform(X_sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def blend_models_predict(X):\n    return ((0.1 * ela_best.predict(X)) + \\\n            (0.1 * las_best.predict(X)) + \\\n            (0.1 * rid_best.predict(X)) + \\\n            (0.1 * svr_best.predict(X)) + \\\n            (0.1 * gbdt_best.predict(X)) + \\\n            (0.1 * xgb_best.predict(X)) + \\\n            (0.1 * lgbm_best.predict(X)) + \\\n            (0.3 * stack_gen.predict(np.array(X))))\n            \nprint('RMSLE score on train data:')\nprint(rmsle(y, blend_models_predict(X1)))\n\nprint('Predict submission', datetime.now(),)\nsubmission = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\nsubmission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_1 = pd.read_csv('../input/top-10-0-10943-stacking-mice-and-brutal-force/House_Prices_submit.csv')\nsub_2 = pd.read_csv('../input/hybrid-svm-benchmark-approach-0-11180-lb-top-2/hybrid_solution.csv')\nsub_3 = pd.read_csv('../input/lasso-model-for-regression-problem/lasso_sol22_Median.csv')\nsubmission.iloc[:,1] = np.floor((0.25 * np.floor(np.expm1(blend_models_predict(X_sub)))) + \n                                (0.25 * sub_1.iloc[:,1]) + \n                                (0.25 * sub_2.iloc[:,1]) + \n                                (0.25 * sub_3.iloc[:,1]))\n\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}