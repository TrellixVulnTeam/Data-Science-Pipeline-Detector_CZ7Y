{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input/house-prices-advanced-regression-techniques'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-10T06:07:06.688341Z","iopub.execute_input":"2021-07-10T06:07:06.688919Z","iopub.status.idle":"2021-07-10T06:07:06.701451Z","shell.execute_reply.started":"2021-07-10T06:07:06.688823Z","shell.execute_reply":"2021-07-10T06:07:06.700147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:10:41.67083Z","iopub.execute_input":"2021-07-10T06:10:41.671162Z","iopub.status.idle":"2021-07-10T06:10:42.693347Z","shell.execute_reply.started":"2021-07-10T06:10:41.671133Z","shell.execute_reply":"2021-07-10T06:10:42.692386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing train and test data\ntrain_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:11:15.996046Z","iopub.execute_input":"2021-07-10T06:11:15.996438Z","iopub.status.idle":"2021-07-10T06:11:16.081002Z","shell.execute_reply.started":"2021-07-10T06:11:15.996403Z","shell.execute_reply":"2021-07-10T06:11:16.080207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lokking at the train data to observe X and y i.e. input and output\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:14:04.873985Z","iopub.execute_input":"2021-07-10T06:14:04.874468Z","iopub.status.idle":"2021-07-10T06:14:04.918596Z","shell.execute_reply.started":"2021-07-10T06:14:04.874437Z","shell.execute_reply":"2021-07-10T06:14:04.917907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lokking at the test data to observe X and y i.e. input and output\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:14:41.634136Z","iopub.execute_input":"2021-07-10T06:14:41.634491Z","iopub.status.idle":"2021-07-10T06:14:41.660453Z","shell.execute_reply.started":"2021-07-10T06:14:41.63446Z","shell.execute_reply":"2021-07-10T06:14:41.65935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Observing the shape of train and test data\ntrain_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:18:47.155257Z","iopub.execute_input":"2021-07-10T06:18:47.155615Z","iopub.status.idle":"2021-07-10T06:18:47.162184Z","shell.execute_reply.started":"2021-07-10T06:18:47.155582Z","shell.execute_reply":"2021-07-10T06:18:47.161234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Taking insights from the dataset(EDA)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:19:43.264537Z","iopub.execute_input":"2021-07-10T06:19:43.264886Z","iopub.status.idle":"2021-07-10T06:19:43.269362Z","shell.execute_reply.started":"2021-07-10T06:19:43.26485Z","shell.execute_reply":"2021-07-10T06:19:43.268702Z"}}},{"cell_type":"code","source":"# Observing the Column output GrLivArea against Output SalePrice\n# To check for outliers\nplt.scatter(train_df.GrLivArea, train_df.SalePrice)\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:21:10.807632Z","iopub.execute_input":"2021-07-10T06:21:10.808104Z","iopub.status.idle":"2021-07-10T06:21:11.075119Z","shell.execute_reply.started":"2021-07-10T06:21:10.808069Z","shell.execute_reply":"2021-07-10T06:21:11.074292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing the outliers\ntrain_df = train_df.drop(train_df[\n    (train_df['GrLivArea']>4000) & (train_df['SalePrice']<300000)].index)\nplt.scatter(train_df.GrLivArea, train_df.SalePrice)\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:23:12.525043Z","iopub.execute_input":"2021-07-10T06:23:12.525381Z","iopub.status.idle":"2021-07-10T06:23:12.706523Z","shell.execute_reply.started":"2021-07-10T06:23:12.525348Z","shell.execute_reply":"2021-07-10T06:23:12.705621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the shape of train data again\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:23:34.552504Z","iopub.execute_input":"2021-07-10T06:23:34.552888Z","iopub.status.idle":"2021-07-10T06:23:34.557762Z","shell.execute_reply.started":"2021-07-10T06:23:34.552855Z","shell.execute_reply":"2021-07-10T06:23:34.55696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing the Saleprice variable.\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nsns.distplot(train_df['SalePrice'] , fit=norm)\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_df['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_df['SalePrice'], plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:23:50.761651Z","iopub.execute_input":"2021-07-10T06:23:50.76221Z","iopub.status.idle":"2021-07-10T06:23:51.525892Z","shell.execute_reply.started":"2021-07-10T06:23:50.762166Z","shell.execute_reply":"2021-07-10T06:23:51.524958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain_df[\"SalePrice\"] = np.log1p(train_df[\"SalePrice\"])\n\n#Check the new distribution \nsns.distplot(train_df['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_df['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_df['SalePrice'], plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:24:17.540791Z","iopub.execute_input":"2021-07-10T06:24:17.541164Z","iopub.status.idle":"2021-07-10T06:24:18.115123Z","shell.execute_reply.started":"2021-07-10T06:24:17.541134Z","shell.execute_reply":"2021-07-10T06:24:18.114235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:24:48.171782Z","iopub.execute_input":"2021-07-10T06:24:48.172399Z","iopub.status.idle":"2021-07-10T06:24:48.178269Z","shell.execute_reply.started":"2021-07-10T06:24:48.172362Z","shell.execute_reply":"2021-07-10T06:24:48.177238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Save the 'Id' column\ntrain_ID = train_df['Id']\ntest_ID = test_df['Id']\n\nprint(\"train shape before dropping id: {}\".format(train_df.shape))\nprint(\"test shape before dropping id: {}\".format(test_df.shape))\n\n#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain_df.drop(\"Id\", axis = 1, inplace = True)\ntest_df.drop(\"Id\", axis = 1, inplace = True)\n\nprint(\"train shape after dropping id: {}\".format(train_df.shape))\nprint(\"test shape after dropping id: {}\".format(test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:25:03.258192Z","iopub.execute_input":"2021-07-10T06:25:03.258748Z","iopub.status.idle":"2021-07-10T06:25:03.271082Z","shell.execute_reply.started":"2021-07-10T06:25:03.258706Z","shell.execute_reply":"2021-07-10T06:25:03.269984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>We will not remove outliers\nfrom every feature as it may affect the model\nsince test set will have outliers too and our model \nneeds to be robust against them </h2>","metadata":{}},{"cell_type":"code","source":"# Analysing the LotArea Feature against SalePrice\nplt.scatter(train_df.LotArea, train_df.SalePrice)\nplt.xlabel('LotArea')\nplt.ylabel('SalePrice')\n# it shows outliers in it","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:25:25.32091Z","iopub.execute_input":"2021-07-10T06:25:25.323079Z","iopub.status.idle":"2021-07-10T06:25:25.493314Z","shell.execute_reply.started":"2021-07-10T06:25:25.322996Z","shell.execute_reply":"2021-07-10T06:25:25.492521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing Lotfrontage against SalePrice\nplt.scatter(train_df.LotFrontage, train_df.SalePrice)\nplt.xlabel('LotFrontage')\nplt.ylabel('SalePrice')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:26:58.26966Z","iopub.execute_input":"2021-07-10T06:26:58.270269Z","iopub.status.idle":"2021-07-10T06:26:58.436228Z","shell.execute_reply.started":"2021-07-10T06:26:58.270233Z","shell.execute_reply":"2021-07-10T06:26:58.435242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing the OverallQual feature to draw pie chart\ntrain_df['OverallQual'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:27:22.548224Z","iopub.execute_input":"2021-07-10T06:27:22.54857Z","iopub.status.idle":"2021-07-10T06:27:22.557942Z","shell.execute_reply.started":"2021-07-10T06:27:22.548537Z","shell.execute_reply":"2021-07-10T06:27:22.556517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Average', 'Above Average', 'Good', 'Very Good', 'Below Average','Excellent', 'Fair', 'Very Excellent', 'Poor', 'Very Poor' ]\nexplode = (0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.2, 0.3, 0.4, 0.6)\n\nfig, ax = plt.subplots()\nax.pie(train_df['OverallQual'].value_counts(), explode=explode,\n       labels=labels, autopct='%1.1f%%', shadow=True, startangle=30)\nax.axis('equal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:28:08.116588Z","iopub.execute_input":"2021-07-10T06:28:08.117005Z","iopub.status.idle":"2021-07-10T06:28:08.313204Z","shell.execute_reply.started":"2021-07-10T06:28:08.116968Z","shell.execute_reply":"2021-07-10T06:28:08.312183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing OverallQual against SalePrice in barplot\nimport seaborn as sns\nfig = sns.barplot(x='OverallQual', y='SalePrice', data=train_df)\nfig.set_xticklabels(labels=['Very Poor', 'Poor', 'Fair', 'Below Average', 'Average', 'Above Average', 'Good', 'Very Good', 'Excellent', 'Very Excellent'], rotation=90);","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:28:54.19306Z","iopub.execute_input":"2021-07-10T06:28:54.193563Z","iopub.status.idle":"2021-07-10T06:28:54.622505Z","shell.execute_reply.started":"2021-07-10T06:28:54.19353Z","shell.execute_reply":"2021-07-10T06:28:54.621575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing FOundation feature for pie chart\ntrain_df['Foundation'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:29:13.187433Z","iopub.execute_input":"2021-07-10T06:29:13.187803Z","iopub.status.idle":"2021-07-10T06:29:13.196393Z","shell.execute_reply.started":"2021-07-10T06:29:13.18777Z","shell.execute_reply":"2021-07-10T06:29:13.195499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Concrete', 'Cinder block', 'Brick&tile', 'Slab', 'Stone', 'Wood']\nexplode = (0, 0.0, 0.0, 0.1, 0.3, 0.5)\n\nfig, ax = plt.subplots()\nax.pie(train_df['Foundation'].value_counts(), explode=explode,\n       labels=labels, autopct='%1.1f%%', shadow=True, startangle=30)\nax.axis('equal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:29:34.849251Z","iopub.execute_input":"2021-07-10T06:29:34.849598Z","iopub.status.idle":"2021-07-10T06:29:34.993041Z","shell.execute_reply.started":"2021-07-10T06:29:34.849567Z","shell.execute_reply":"2021-07-10T06:29:34.991937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing FOundation against SalePrice for barplot\nfig1=sns.barplot(x='Foundation', y='SalePrice', data=train_df)\nfig1.set_xticklabels(labels=['Contrete', 'Cinder Block', 'Brick&Tile', 'Wood', 'Slab', 'Stone'], rotation=90)\nplt.xlabel(\"Types of Foundation\")","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:30:08.881455Z","iopub.execute_input":"2021-07-10T06:30:08.881794Z","iopub.status.idle":"2021-07-10T06:30:09.226427Z","shell.execute_reply.started":"2021-07-10T06:30:08.881765Z","shell.execute_reply":"2021-07-10T06:30:09.225401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing GarageCars against SalePrice from dataframe to use it in barplot\ncheck = train_df[['GarageCars', 'SalePrice']]\ncheck","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:30:31.826748Z","iopub.execute_input":"2021-07-10T06:30:31.827103Z","iopub.status.idle":"2021-07-10T06:30:31.841709Z","shell.execute_reply.started":"2021-07-10T06:30:31.827071Z","shell.execute_reply":"2021-07-10T06:30:31.840733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating pivot table to check GarageCars against SalePrice using aggregate function\npd.pivot_table(check, values='SalePrice', index=['GarageCars'], aggfunc=np.sum)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:30:52.600802Z","iopub.execute_input":"2021-07-10T06:30:52.601154Z","iopub.status.idle":"2021-07-10T06:30:52.619547Z","shell.execute_reply.started":"2021-07-10T06:30:52.601126Z","shell.execute_reply":"2021-07-10T06:30:52.618626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = sns.barplot(x='GarageCars', y='SalePrice', data=train_df)\nfig.set_xticklabels(labels=['4 car', 'no car', '3 car', '2 car', '1 car'], rotation=90)\nplt.xlabel('No of cars in garage')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:31:08.148398Z","iopub.execute_input":"2021-07-10T06:31:08.148869Z","iopub.status.idle":"2021-07-10T06:31:08.422814Z","shell.execute_reply.started":"2021-07-10T06:31:08.148838Z","shell.execute_reply":"2021-07-10T06:31:08.421883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking max value count for each value to use it in plot\ntrain_df['Fireplaces'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:31:33.357884Z","iopub.execute_input":"2021-07-10T06:31:33.358211Z","iopub.status.idle":"2021-07-10T06:31:33.365527Z","shell.execute_reply.started":"2021-07-10T06:31:33.358185Z","shell.execute_reply":"2021-07-10T06:31:33.364683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing Fireplaces against SalePrice\nfig2 = sns.barplot(x='Fireplaces', y='SalePrice', data=train_df)\nfig2.set_xticklabels(labels=['3 fireplace', '2fireplace', '1 fireplace', 'No fireplace'], rotation=90)\nplt.xlabel('No of fireplace')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:31:53.599794Z","iopub.execute_input":"2021-07-10T06:31:53.600133Z","iopub.status.idle":"2021-07-10T06:31:53.849493Z","shell.execute_reply.started":"2021-07-10T06:31:53.600104Z","shell.execute_reply":"2021-07-10T06:31:53.848545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Analysing the skewness and kurtosis of some features to understand the \nvariation of the data</h1>","metadata":{}},{"cell_type":"code","source":"# Using displot instead of distplot which is deprecating in next version\nsns.displot(x='LotArea', data=train_df, kde=True)\nskew_ness = str(train_df['LotArea'].skew())\nkurt_ = str(train_df['LotArea'].kurt())\nplt.legend([skew_ness, kurt_], title='skewness&kurtosis')\nplt.title(\"before transform\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:32:44.13611Z","iopub.execute_input":"2021-07-10T06:32:44.136449Z","iopub.status.idle":"2021-07-10T06:32:45.210559Z","shell.execute_reply.started":"2021-07-10T06:32:44.13642Z","shell.execute_reply":"2021-07-10T06:32:45.209683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(x='GrLivArea', data=train_df, kde=True)\nskew_ness=str(train_df['GrLivArea'].skew())\nkurt_=str(train_df['GrLivArea'].kurt())\nplt.legend([skew_ness, kurt_], title='skewness&kurtosis')\nplt.title('before transform')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:33:16.062112Z","iopub.execute_input":"2021-07-10T06:33:16.06246Z","iopub.status.idle":"2021-07-10T06:33:16.421954Z","shell.execute_reply.started":"2021-07-10T06:33:16.06243Z","shell.execute_reply":"2021-07-10T06:33:16.420805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(x=train_df['LotFrontage'],kde=True)\nskew_ness = str(train_df['LotFrontage'].skew())\nkurt_ = str(train_df['LotFrontage'].kurt())\nplt.legend([skew_ness, kurt_], title='skewness&kurtosis')\nplt.title('before apply')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:33:41.529513Z","iopub.execute_input":"2021-07-10T06:33:41.529905Z","iopub.status.idle":"2021-07-10T06:33:41.979515Z","shell.execute_reply.started":"2021-07-10T06:33:41.52987Z","shell.execute_reply":"2021-07-10T06:33:41.978731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(x='OverallQual', data=train_df, kde=True)\nskew_ness = str(train_df['OverallQual'].skew())\nkurt_ = str(train_df['OverallQual'].kurt())\nplt.legend([skew_ness, kurt_], title='skewness&kurtosis')\nplt.title(\"before transform\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:34:09.60241Z","iopub.execute_input":"2021-07-10T06:34:09.603094Z","iopub.status.idle":"2021-07-10T06:34:09.959348Z","shell.execute_reply.started":"2021-07-10T06:34:09.603058Z","shell.execute_reply":"2021-07-10T06:34:09.958633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(x='LotFrontage', data=train_df, kde=True)\nskew_ness = str(train_df['LotFrontage'].skew())\nkurt_ = str(train_df['LotFrontage'].kurt())\nplt.legend([skew_ness, kurt_], title='skewness&kurtosis')\nplt.title('before transform')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:34:30.730885Z","iopub.execute_input":"2021-07-10T06:34:30.731362Z","iopub.status.idle":"2021-07-10T06:34:31.169766Z","shell.execute_reply.started":"2021-07-10T06:34:30.731334Z","shell.execute_reply":"2021-07-10T06:34:31.169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(x='GrLivArea', data=train_df, kde=True)\nskew_ness = str(train_df['GrLivArea'].skew())\nkurt_ = str(train_df['GrLivArea'].kurt())\nplt.legend([skew_ness, kurt_], title='skewness&kurtosis')\nplt.title('before transform')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:34:58.582993Z","iopub.execute_input":"2021-07-10T06:34:58.583464Z","iopub.status.idle":"2021-07-10T06:34:58.940616Z","shell.execute_reply.started":"2021-07-10T06:34:58.583436Z","shell.execute_reply":"2021-07-10T06:34:58.939936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(x='LotArea', data=train_df, kde=True)\nskew_ness = str(train_df['LotArea'].skew())\nkurt_ = str(train_df['LotArea'].kurt()) \nplt.legend([skew_ness, kurt_], title='skewness&kurtosis')\nplt.title('before transform')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:35:26.748229Z","iopub.execute_input":"2021-07-10T06:35:26.748747Z","iopub.status.idle":"2021-07-10T06:35:27.689024Z","shell.execute_reply.started":"2021-07-10T06:35:26.748715Z","shell.execute_reply":"2021-07-10T06:35:27.687982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the length of train and test and concatenating to make a single df\ntrain_range = train_df.shape[0]  # 1458\ntest_range = test_df.shape[0]  # 1459\ny_train = train_df.SalePrice.values # saving target variable\ntotal_data = pd.concat((train_df, test_df)).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:35:54.646632Z","iopub.execute_input":"2021-07-10T06:35:54.647007Z","iopub.status.idle":"2021-07-10T06:35:54.669009Z","shell.execute_reply.started":"2021-07-10T06:35:54.646974Z","shell.execute_reply":"2021-07-10T06:35:54.667826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shape of total_data\ntotal_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:36:14.414317Z","iopub.execute_input":"2021-07-10T06:36:14.414654Z","iopub.status.idle":"2021-07-10T06:36:14.420927Z","shell.execute_reply.started":"2021-07-10T06:36:14.414623Z","shell.execute_reply":"2021-07-10T06:36:14.419758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping target variable\ntotal_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"total_data size is : {}\".format(total_data.shape))\ntotal_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:36:34.024159Z","iopub.execute_input":"2021-07-10T06:36:34.024495Z","iopub.status.idle":"2021-07-10T06:36:34.063142Z","shell.execute_reply.started":"2021-07-10T06:36:34.024468Z","shell.execute_reply":"2021-07-10T06:36:34.062419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting unique value in each categorical column\ncat_col =total_data.select_dtypes(include=['object'])\n\nfor i in list(cat_col.columns):\n    print(\"We have {} unique value in {} column: {}.\".format(len(cat_col[i].unique()), \n                                                     i, cat_col[i].unique()))\n    print('*'*140)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:36:58.000561Z","iopub.execute_input":"2021-07-10T06:36:58.000942Z","iopub.status.idle":"2021-07-10T06:36:58.047401Z","shell.execute_reply.started":"2021-07-10T06:36:58.000909Z","shell.execute_reply":"2021-07-10T06:36:58.046441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# divide data into categorical and numerical features\ncat, num = [], []\nfor i in total_data.columns:\n    d = total_data.dtypes[i]\n    if d == 'object':\n        cat.append(i)\n    else:\n        num.append(i)\n\nprint(\"Categorical: {}\".format(cat))\nprint(\"Numerical: {}\".format(num))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:37:28.991266Z","iopub.execute_input":"2021-07-10T06:37:28.991587Z","iopub.status.idle":"2021-07-10T06:37:29.00624Z","shell.execute_reply.started":"2021-07-10T06:37:28.991559Z","shell.execute_reply":"2021-07-10T06:37:29.005177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking length of categorical and numerical\nprint(\"Length of categorical: {}\".format(len(cat)))\nprint(\"Length of numerical: {}\".format(len(num)))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:37:47.375838Z","iopub.execute_input":"2021-07-10T06:37:47.376164Z","iopub.status.idle":"2021-07-10T06:37:47.381592Z","shell.execute_reply.started":"2021-07-10T06:37:47.376136Z","shell.execute_reply":"2021-07-10T06:37:47.380504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking unique in catgeorical column by using our categorical list\nfor i in cat:\n    print(i, \"-\"*(30-len(i)), len(total_data[i].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:38:05.417702Z","iopub.execute_input":"2021-07-10T06:38:05.418058Z","iopub.status.idle":"2021-07-10T06:38:05.453737Z","shell.execute_reply.started":"2021-07-10T06:38:05.418027Z","shell.execute_reply":"2021-07-10T06:38:05.4528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking %  of missing value in categorical features\ncat_feature = [feature for feature in cat if total_data[feature].isnull().sum()]\nfor feature in cat_feature:\n    print(\"{}: {} %\".format(feature, round((total_data[feature].isnull().sum()\n                                          /len(total_data[feature]))*100, 3)))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:38:31.601848Z","iopub.execute_input":"2021-07-10T06:38:31.60222Z","iopub.status.idle":"2021-07-10T06:38:31.633896Z","shell.execute_reply.started":"2021-07-10T06:38:31.60219Z","shell.execute_reply":"2021-07-10T06:38:31.632914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing % in numerical features\nnum_feature = [feature for feature in num if total_data[feature].isnull().sum()]\nfor feature in num_feature:\n    print(\"{}: {} %\".format(feature, round((total_data[feature].isnull().sum()\n                                            /len(total_data[feature]))*100, 3)))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:38:54.481461Z","iopub.execute_input":"2021-07-10T06:38:54.481813Z","iopub.status.idle":"2021-07-10T06:38:54.499443Z","shell.execute_reply.started":"2021-07-10T06:38:54.481783Z","shell.execute_reply":"2021-07-10T06:38:54.498813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing value in overall whole data\ntotal_data_na = (total_data.isnull().sum() / len(total_data)) * 100\n\ntotal_data_na","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:39:29.944971Z","iopub.execute_input":"2021-07-10T06:39:29.945294Z","iopub.status.idle":"2021-07-10T06:39:29.961122Z","shell.execute_reply.started":"2021-07-10T06:39:29.945265Z","shell.execute_reply":"2021-07-10T06:39:29.960085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking columns where there's no missing value\n(total_data_na[total_data_na == 0].index)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:39:49.863311Z","iopub.execute_input":"2021-07-10T06:39:49.863694Z","iopub.status.idle":"2021-07-10T06:39:49.871012Z","shell.execute_reply.started":"2021-07-10T06:39:49.863647Z","shell.execute_reply":"2021-07-10T06:39:49.869767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Another way to check missing ratios\ntotal_data_na = total_data_na.drop(total_data_na[total_data_na == 0].index).sort_values(ascending=False)[:30]\n\ntotal_data_na","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:40:06.814594Z","iopub.execute_input":"2021-07-10T06:40:06.814957Z","iopub.status.idle":"2021-07-10T06:40:06.824092Z","shell.execute_reply.started":"2021-07-10T06:40:06.814926Z","shell.execute_reply":"2021-07-10T06:40:06.823331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating dataframe of missing data values\nmissing_data = pd.DataFrame({'Missing Ratio' :total_data_na})\nmissing_data.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:40:30.31165Z","iopub.execute_input":"2021-07-10T06:40:30.312219Z","iopub.status.idle":"2021-07-10T06:40:30.32402Z","shell.execute_reply.started":"2021-07-10T06:40:30.312176Z","shell.execute_reply":"2021-07-10T06:40:30.323081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting missing values\nplt.subplots(figsize=(15,12))\nplt.xticks(rotation='90')\nsns.barplot(x=total_data_na.index, y=total_data_na)\n\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing value', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=25)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:45:37.340874Z","iopub.execute_input":"2021-07-10T06:45:37.341201Z","iopub.status.idle":"2021-07-10T06:45:37.787089Z","shell.execute_reply.started":"2021-07-10T06:45:37.341171Z","shell.execute_reply":"2021-07-10T06:45:37.785948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>poolQC - NA means no pool, so replacing with None</h3>\n<h3>Miscfeature - NA means no miscfeature, so replacing with None</h3>\n<h3>Alley - NA means no Alley access, so replacing with None</h3>\n<h3>Fence - NA means no fence, so replacing with None</h3>\n<h3>FireplaceQu - NA means no fireplace, so replacing with None</h3>","metadata":{}},{"cell_type":"code","source":"# Filling missing values with none values \ntotal_data[\"PoolQC\"] = total_data[\"PoolQC\"].fillna(\"None\")\ntotal_data[\"MiscFeature\"] = total_data[\"MiscFeature\"].fillna(\"None\")\ntotal_data[\"Alley\"] = total_data[\"Alley\"].fillna(\"None\")\ntotal_data[\"Fence\"] = total_data[\"Fence\"].fillna(\"None\")\ntotal_data[\"FireplaceQu\"] = total_data[\"FireplaceQu\"].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:47:04.584355Z","iopub.execute_input":"2021-07-10T06:47:04.584704Z","iopub.status.idle":"2021-07-10T06:47:04.596271Z","shell.execute_reply.started":"2021-07-10T06:47:04.58466Z","shell.execute_reply":"2021-07-10T06:47:04.595301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Area of each street is connected so replacing missing value with median\ntotal_data[\"LotFrontage\"]=total_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:47:28.674055Z","iopub.execute_input":"2021-07-10T06:47:28.674513Z","iopub.status.idle":"2021-07-10T06:47:28.69279Z","shell.execute_reply.started":"2021-07-10T06:47:28.674473Z","shell.execute_reply":"2021-07-10T06:47:28.691901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replacing with most frequent value in the column which is None\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    total_data[col] =total_data[col].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:47:49.158375Z","iopub.execute_input":"2021-07-10T06:47:49.158765Z","iopub.status.idle":"2021-07-10T06:47:49.166837Z","shell.execute_reply.started":"2021-07-10T06:47:49.158731Z","shell.execute_reply":"2021-07-10T06:47:49.165822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing missing with 0 (No garage = no cars in such garage)\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    total_data[col] = total_data[col].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:48:05.75432Z","iopub.execute_input":"2021-07-10T06:48:05.754648Z","iopub.status.idle":"2021-07-10T06:48:05.76052Z","shell.execute_reply.started":"2021-07-10T06:48:05.754618Z","shell.execute_reply":"2021-07-10T06:48:05.759492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing value in these feature means no basement (replace with 0)\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    total_data[col] = total_data[col].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:48:22.483809Z","iopub.execute_input":"2021-07-10T06:48:22.484141Z","iopub.status.idle":"2021-07-10T06:48:22.491501Z","shell.execute_reply.started":"2021-07-10T06:48:22.484109Z","shell.execute_reply":"2021-07-10T06:48:22.490686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NaN means in these column is no basement\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    total_data[col] = total_data[col].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:48:38.773589Z","iopub.execute_input":"2021-07-10T06:48:38.774168Z","iopub.status.idle":"2021-07-10T06:48:38.782322Z","shell.execute_reply.started":"2021-07-10T06:48:38.774135Z","shell.execute_reply":"2021-07-10T06:48:38.781196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NA means no masonry veneer for houses. (Fill zero for area and None for type)\ntotal_data[\"MasVnrType\"] = total_data[\"MasVnrType\"].fillna(\"None\")\ntotal_data[\"MasVnrArea\"] = total_data[\"MasVnrArea\"].fillna(0)\n\n# Filling MSZoning with most common value 'RL'\ntotal_data['MSZoning'] = total_data['MSZoning'].fillna(total_data['MSZoning'].mode()[0])\n\n# For Utilitites, most of the records are 'AllPub'. It won't help in prediction\ntotal_data = total_data.drop(['Utilities'], axis=1)\n\n# data description says- Assume typical(Typ) unless deductions are warranted\ntotal_data[\"Functional\"] = total_data[\"Functional\"].fillna(\"Typ\")\n\n# replacing with most repeated \"SBrkr\" value\ntotal_data['Electrical'] = total_data['Electrical'].fillna(total_data['Electrical'].mode()[0])\n\n# set \"TA\" most frequent in place of missing value\ntotal_data['KitchenQual'] = total_data['KitchenQual'].fillna(total_data['KitchenQual'].mode()[0])\n\n# replacing with most common value \ntotal_data['Exterior1st'] = total_data['Exterior1st'].fillna(total_data['Exterior1st'].mode()[0])\ntotal_data['Exterior2nd'] = total_data['Exterior2nd'].fillna(total_data['Exterior2nd'].mode()[0])\n\n# replacing with most common value again\ntotal_data['SaleType'] = total_data['SaleType'].fillna(total_data['SaleType'].mode()[0])\n\n# MSSubClass-type of dwelling, NA means no building class. (fill with None)\ntotal_data['MSSubClass'] = total_data['MSSubClass'].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:49:07.929354Z","iopub.execute_input":"2021-07-10T06:49:07.929751Z","iopub.status.idle":"2021-07-10T06:49:07.950749Z","shell.execute_reply.started":"2021-07-10T06:49:07.929715Z","shell.execute_reply":"2021-07-10T06:49:07.94955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check remaining missing values if any \ntotal_data_na = (total_data.isnull().sum()/len(total_data))*100\ntotal_data_na = total_data_na.drop(total_data_na[total_data_na==0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({\"missing ratio\":total_data_na})\nmissing_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:49:24.077111Z","iopub.execute_input":"2021-07-10T06:49:24.077454Z","iopub.status.idle":"2021-07-10T06:49:24.096563Z","shell.execute_reply.started":"2021-07-10T06:49:24.077424Z","shell.execute_reply":"2021-07-10T06:49:24.095755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting some column feature who are int but should be str\n\ntotal_data['MSSubClass'].dtype, total_data['YrSold'].dtype","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:51:42.776949Z","iopub.execute_input":"2021-07-10T06:51:42.777291Z","iopub.status.idle":"2021-07-10T06:51:42.783816Z","shell.execute_reply.started":"2021-07-10T06:51:42.777262Z","shell.execute_reply":"2021-07-10T06:51:42.782974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MSSubClass=The building class\ntotal_data['MSSubClass'] = total_data['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\ntotal_data['OverallCond'] = total_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\ntotal_data['YrSold'] = total_data['YrSold'].astype(str)\ntotal_data['MoSold'] = total_data['MoSold'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:52:02.152552Z","iopub.execute_input":"2021-07-10T06:52:02.153034Z","iopub.status.idle":"2021-07-10T06:52:02.1673Z","shell.execute_reply.started":"2021-07-10T06:52:02.153004Z","shell.execute_reply":"2021-07-10T06:52:02.166627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# process columns, apply LabelEncoder to categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\n\nfor c in cols:\n    lbl = LabelEncoder()\n    lbl.fit(list(total_data[c].values))\n    total_data[c] = lbl.transform(list(total_data[c].values))\n# shape        \nprint('Shape all_data: {}'.format(total_data.shape))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:52:23.931044Z","iopub.execute_input":"2021-07-10T06:52:23.931585Z","iopub.status.idle":"2021-07-10T06:52:24.143152Z","shell.execute_reply.started":"2021-07-10T06:52:23.931552Z","shell.execute_reply":"2021-07-10T06:52:24.142058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding one extra feature -> total sqfootage feature \ntotal_data['TotalSF'] = total_data['TotalBsmtSF'] + total_data['1stFlrSF'] + total_data['2ndFlrSF']","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:52:39.787571Z","iopub.execute_input":"2021-07-10T06:52:39.787927Z","iopub.status.idle":"2021-07-10T06:52:39.793835Z","shell.execute_reply.started":"2021-07-10T06:52:39.787895Z","shell.execute_reply":"2021-07-10T06:52:39.79272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking numerical feature again\nnumeric_feats = total_data.dtypes[total_data.dtypes != 'object' ].index\nnumeric_feats","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:52:52.713544Z","iopub.execute_input":"2021-07-10T06:52:52.713996Z","iopub.status.idle":"2021-07-10T06:52:52.721754Z","shell.execute_reply.started":"2021-07-10T06:52:52.713962Z","shell.execute_reply":"2021-07-10T06:52:52.720643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking skewness level on numerical features to remove\nskewed_feats = total_data[numeric_feats].apply(lambda x: skew(x.dropna())).\\\nsort_values(ascending=False)\nskewness = pd.DataFrame({\"Skewness \": skewed_feats})\nskewness.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:53:16.410395Z","iopub.execute_input":"2021-07-10T06:53:16.410726Z","iopub.status.idle":"2021-07-10T06:53:16.606488Z","shell.execute_reply.started":"2021-07-10T06:53:16.410698Z","shell.execute_reply":"2021-07-10T06:53:16.605647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying boxcox on those features having skewness > 0.75\nskewness = skewness[abs(skewness)>0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\n\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    total_data[feat] = boxcox1p(total_data[feat], lam)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:53:32.262941Z","iopub.execute_input":"2021-07-10T06:53:32.263295Z","iopub.status.idle":"2021-07-10T06:53:32.306742Z","shell.execute_reply.started":"2021-07-10T06:53:32.263266Z","shell.execute_reply":"2021-07-10T06:53:32.305613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:53:51.707317Z","iopub.execute_input":"2021-07-10T06:53:51.707656Z","iopub.status.idle":"2021-07-10T06:53:51.714041Z","shell.execute_reply.started":"2021-07-10T06:53:51.707627Z","shell.execute_reply":"2021-07-10T06:53:51.71314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Coverting features into dummies for expanding\n# dimensions for convenient access\ntotal_data = pd.get_dummies(total_data)\nprint(total_data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:54:02.646431Z","iopub.execute_input":"2021-07-10T06:54:02.646787Z","iopub.status.idle":"2021-07-10T06:54:02.678444Z","shell.execute_reply.started":"2021-07-10T06:54:02.646754Z","shell.execute_reply":"2021-07-10T06:54:02.677451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting total data back to train and test\ntrain = total_data[:train_range]\ntest = total_data[train_range:]\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:54:22.479423Z","iopub.execute_input":"2021-07-10T06:54:22.479775Z","iopub.status.idle":"2021-07-10T06:54:22.486228Z","shell.execute_reply.started":"2021-07-10T06:54:22.479743Z","shell.execute_reply":"2021-07-10T06:54:22.485325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing different models to try on our dataset\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:54:38.853571Z","iopub.execute_input":"2021-07-10T06:54:38.853991Z","iopub.status.idle":"2021-07-10T06:54:39.21563Z","shell.execute_reply.started":"2021-07-10T06:54:38.853955Z","shell.execute_reply":"2021-07-10T06:54:39.214816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 5\n# defining our own function to get root\n# mean square value using 5 fold split\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:54:54.029506Z","iopub.execute_input":"2021-07-10T06:54:54.03015Z","iopub.status.idle":"2021-07-10T06:54:54.035124Z","shell.execute_reply.started":"2021-07-10T06:54:54.030113Z","shell.execute_reply":"2021-07-10T06:54:54.034371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Passing RobustScaler() to make the lasso model more robust to outlier\nlasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005, random_state=1))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:55:08.702344Z","iopub.execute_input":"2021-07-10T06:55:08.702845Z","iopub.status.idle":"2021-07-10T06:55:08.707193Z","shell.execute_reply.started":"2021-07-10T06:55:08.702814Z","shell.execute_reply":"2021-07-10T06:55:08.706084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Passing RobustScaler() to make the Enet model more robust to outlier\nEnet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005,\n                                                l1_ratio=.9, random_state=3))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:58:45.983499Z","iopub.execute_input":"2021-07-10T06:58:45.98411Z","iopub.status.idle":"2021-07-10T06:58:45.988722Z","shell.execute_reply.started":"2021-07-10T06:58:45.984075Z","shell.execute_reply":"2021-07-10T06:58:45.987776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"krr = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:58:57.53403Z","iopub.execute_input":"2021-07-10T06:58:57.534347Z","iopub.status.idle":"2021-07-10T06:58:57.537817Z","shell.execute_reply.started":"2021-07-10T06:58:57.53432Z","shell.execute_reply":"2021-07-10T06:58:57.537162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# passing huber loss to make it robust to outliers\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T06:59:24.931289Z","iopub.execute_input":"2021-07-10T06:59:24.931778Z","iopub.status.idle":"2021-07-10T06:59:24.935658Z","shell.execute_reply.started":"2021-07-10T06:59:24.931746Z","shell.execute_reply":"2021-07-10T06:59:24.935022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:00:00.908135Z","iopub.execute_input":"2021-07-10T07:00:00.910085Z","iopub.status.idle":"2021-07-10T07:00:00.915084Z","shell.execute_reply.started":"2021-07-10T07:00:00.910047Z","shell.execute_reply":"2021-07-10T07:00:00.914382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = rmsle_cv(lasso)\nprint(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:00:05.731699Z","iopub.execute_input":"2021-07-10T07:00:05.732287Z","iopub.status.idle":"2021-07-10T07:00:06.525621Z","shell.execute_reply.started":"2021-07-10T07:00:05.732252Z","shell.execute_reply":"2021-07-10T07:00:06.524419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = rmsle_cv(Enet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:00:22.063526Z","iopub.execute_input":"2021-07-10T07:00:22.06389Z","iopub.status.idle":"2021-07-10T07:00:22.791477Z","shell.execute_reply.started":"2021-07-10T07:00:22.063859Z","shell.execute_reply":"2021-07-10T07:00:22.790316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = rmsle_cv(krr)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:00:36.834208Z","iopub.execute_input":"2021-07-10T07:00:36.83453Z","iopub.status.idle":"2021-07-10T07:00:37.372271Z","shell.execute_reply.started":"2021-07-10T07:00:36.834502Z","shell.execute_reply":"2021-07-10T07:00:37.370648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = rmsle_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:00:49.209597Z","iopub.execute_input":"2021-07-10T07:00:49.21018Z","iopub.status.idle":"2021-07-10T07:01:35.507077Z","shell.execute_reply.started":"2021-07-10T07:00:49.210134Z","shell.execute_reply":"2021-07-10T07:01:35.506121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:01:40.010554Z","iopub.execute_input":"2021-07-10T07:01:40.010932Z","iopub.status.idle":"2021-07-10T07:02:03.598933Z","shell.execute_reply.started":"2021-07-10T07:01:40.010896Z","shell.execute_reply":"2021-07-10T07:02:03.598018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Stacking of models</h3>","metadata":{}},{"cell_type":"code","source":"class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self,models):\n        self.models = models\n        \n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        for model in self.models_:\n            model.fit(X, y)\n            \n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack([model.predict(X)\n                                       for model in self.models_])\n        return np.mean(predictions, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:02:06.787311Z","iopub.execute_input":"2021-07-10T07:02:06.787641Z","iopub.status.idle":"2021-07-10T07:02:06.794375Z","shell.execute_reply.started":"2021-07-10T07:02:06.787613Z","shell.execute_reply":"2021-07-10T07:02:06.793393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Averaging the score\naveraged_models = AveragingModels(models = (Enet, GBoost, krr, lasso))\n\nscore = rmsle_cv(averaged_models)\nprint(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:02:21.884762Z","iopub.execute_input":"2021-07-10T07:02:21.885249Z","iopub.status.idle":"2021-07-10T07:03:09.854655Z","shell.execute_reply.started":"2021-07-10T07:02:21.885211Z","shell.execute_reply":"2021-07-10T07:03:09.853551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Stacking using a meta model</h3>","metadata":{}},{"cell_type":"markdown","source":"<h4>Approach - we add a meta-model on averaged base models and use the out-of-folds predictions of these base models to train our meta-model. </h4>","metadata":{}},{"cell_type":"code","source":"class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:03:14.418089Z","iopub.execute_input":"2021-07-10T07:03:14.418413Z","iopub.status.idle":"2021-07-10T07:03:14.427747Z","shell.execute_reply.started":"2021-07-10T07:03:14.418385Z","shell.execute_reply":"2021-07-10T07:03:14.426682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Averaging the score again\nstacked_averaged_models = StackingAveragedModels(base_models = (Enet, GBoost, krr),\n                                                 meta_model = lasso)\n\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:03:25.031073Z","iopub.execute_input":"2021-07-10T07:03:25.031598Z","iopub.status.idle":"2021-07-10T07:06:57.038812Z","shell.execute_reply.started":"2021-07-10T07:03:25.031549Z","shell.execute_reply":"2021-07-10T07:06:57.037777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defined function to get rmse\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:06:57.040724Z","iopub.execute_input":"2021-07-10T07:06:57.041333Z","iopub.status.idle":"2021-07-10T07:06:57.047755Z","shell.execute_reply.started":"2021-07-10T07:06:57.041289Z","shell.execute_reply":"2021-07-10T07:06:57.046609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the stacked model and predicting\nstacked_averaged_models.fit(train.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(train.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\nprint(rmsle(y_train, stacked_train_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:06:57.04995Z","iopub.execute_input":"2021-07-10T07:06:57.050359Z","iopub.status.idle":"2021-07-10T07:07:44.832767Z","shell.execute_reply.started":"2021-07-10T07:06:57.050321Z","shell.execute_reply":"2021-07-10T07:07:44.831642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb model prediction\nmodel_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:07:44.838231Z","iopub.execute_input":"2021-07-10T07:07:44.840986Z","iopub.status.idle":"2021-07-10T07:07:51.464928Z","shell.execute_reply.started":"2021-07-10T07:07:44.840922Z","shell.execute_reply":"2021-07-10T07:07:51.464133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ensembling the model\nensemble = stacked_pred*0.70 + xgb_pred*0.30","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:11:34.714995Z","iopub.execute_input":"2021-07-10T07:11:34.715503Z","iopub.status.idle":"2021-07-10T07:11:34.719238Z","shell.execute_reply.started":"2021-07-10T07:11:34.715473Z","shell.execute_reply":"2021-07-10T07:11:34.718565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating submission file\nsub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = ensemble\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T07:11:36.374598Z","iopub.execute_input":"2021-07-10T07:11:36.374966Z","iopub.status.idle":"2021-07-10T07:11:36.388472Z","shell.execute_reply.started":"2021-07-10T07:11:36.374935Z","shell.execute_reply":"2021-07-10T07:11:36.387574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>This EDA+Regression notebook is a combination of two notebooks I was referring while housing regression competition. I loved the code of these notebooks so much that I thought of saving and sharing with all of you. I loved the insights of the creator of these 2 notebooks. I'm mentioning the link for further reference if you want.</h3>","metadata":{}},{"cell_type":"markdown","source":"<h4><a href= \"https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\">Click here for first link- Top 4%</a></h4>\n<h4><a href= \"https://www.kaggle.com/bakar31/eda-house-price-prediction\">Click here for second link</a></h4>","metadata":{}}]}