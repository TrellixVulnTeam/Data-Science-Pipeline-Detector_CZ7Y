{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [🏠 House Prices: What factors make people pay more? 🔎](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)","metadata":{}},{"cell_type":"markdown","source":"Suppose you are a Data Scientist hired by a Real Estate Company known as `Abode Inc`. The CEO wants to identify the top factors that influence the house prices. They have given you a dataset and want you to come up with useful insights that can help grow their business and become more profitable. What suggestions would you give to the CEO of Abode Inc.? ","metadata":{}},{"cell_type":"markdown","source":"The focus of this notebook is to explore techniques to understand and interpret the models and not achieve a top LB score. The aim is to simulate how one would tackle a real world ML problem for a business use case. **This work completely is inspired by [fastai machine learning](https://course18.fast.ai/ml.html) course.**","metadata":{}},{"cell_type":"markdown","source":"# 🏁 Preliminaries","metadata":{}},{"cell_type":"code","source":"# Install packages\n! pip install -q dtreeviz\n! pip install -q scikit-misc","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:31.293446Z","iopub.execute_input":"2021-09-08T19:04:31.293855Z","iopub.status.idle":"2021-09-08T19:04:52.494212Z","shell.execute_reply.started":"2021-09-08T19:04:31.293772Z","shell.execute_reply":"2021-09-08T19:04:52.493351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import packages.\nimport scipy\nfrom scipy.cluster import hierarchy as hc\nimport re, math, pathlib, numbers, functools, IPython, graphviz\nimport numpy as np \nimport pandas as pd\nimport altair as alt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport category_encoders as ce\nfrom pathlib import Path\nfrom pdpbox import pdp, get_dataset, info_plots\nfrom concurrent.futures import ProcessPoolExecutor\nfrom sklearn import metrics, ensemble, model_selection, tree\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate, cross_val_predict\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder, StandardScaler, FunctionTransformer\nfrom sklearn.impute import SimpleImputer, MissingIndicator\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.tree import export_graphviz\n\n# Settings\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2\npd.options.display.max_columns=100\npd.options.display.max_rows=100\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:52.495618Z","iopub.execute_input":"2021-09-08T19:04:52.495898Z","iopub.status.idle":"2021-09-08T19:04:54.486055Z","shell.execute_reply.started":"2021-09-08T19:04:52.495867Z","shell.execute_reply":"2021-09-08T19:04:54.485071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data\npath = Path('/kaggle/input/house-prices-advanced-regression-techniques/')\ntrain = pd.read_csv(path/'train.csv')\ntest = pd.read_csv(path/'test.csv')\nsample = pd.read_csv(path/'sample_submission.csv')\ntrain.SalePrice = np.log(train.SalePrice)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:54.489474Z","iopub.execute_input":"2021-09-08T19:04:54.489789Z","iopub.status.idle":"2021-09-08T19:04:54.61708Z","shell.execute_reply.started":"2021-09-08T19:04:54.489761Z","shell.execute_reply":"2021-09-08T19:04:54.616108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility Code","metadata":{}},{"cell_type":"markdown","source":"In this block, I define some utility functions that I will call repeatedly in the notebook. This allows me to reduce code redundancy and keep the notebook crisp and precise.","metadata":{}},{"cell_type":"code","source":"# Inspect the data.\ndef check_features(df):\n    return pd.DataFrame({'unique_values': df.nunique(),'type': df.dtypes,'pct_missing': df.isna().sum()/len(df) * 100}).sort_values(by = 'pct_missing', ascending=False) \n\n# Function to get rmse.\ndef rmse(targets, preds): \n    return metrics.mean_squared_error(targets, preds, squared=False)\n\n# Impute missing values.\ndef missing_cats(df, cats): \n    return df[cats].fillna('#na#')\n\n# Functions to fit train and evaluate a model.\ndef mfe(model, x_train, y_train, x_val, y_val):\n    model.fit(x_train, y_train)\n    preds_train = model.predict(x_train); preds_val = model.predict(x_val)\n    rmse_train = rmse(y_train, preds_train); rmse_val = rmse(y_val, preds_val) # Calculate train & validation rmse.\n    r2_train = metrics.r2_score(y_train, preds_train); r2_val = metrics.r2_score(y_val, preds_val) # Calculate train & validation R2.\n    result = pd.DataFrame({'rmse_train': rmse_train, 'rmse_val': rmse_val, 'r2_train': r2_train, 'r2_val': r2_val}, index=['metrics'])\n    display(result)\n    \n# Get permutation importance as a dataframe.   \ndef get_pi(model, x, y):\n    imp = permutation_importance(model, x, y, scoring='neg_root_mean_squared_error', n_repeats=2, n_jobs=4, random_state=1)\n    df_pi = pd.DataFrame({'features': x.columns, 'imp': imp.importances_mean}, index=None).astype({'imp': np.float64}).sort_values(by='imp', ascending=False).reset_index(drop=True)\n    return df_pi    \n\n# Get feature importance as a df.\ndef get_fi(model, x):\n    return pd.DataFrame(np.stack([x.columns, model.feature_importances_], axis=1), columns=['features', 'imp']).astype({'imp':np.float32}).sort_values(by='imp', ascending=False).reset_index(drop=True) \n\n# Plot feature importance. \ndef plot_fi(model, x, n=None, ax=None):\n    if n is None: n = len(x.columns)\n    df_fi = pd.DataFrame({'features':x.columns, 'imp':(model.feature_importances_)}).sort_values(by='imp', ascending=False).iloc[:n, :]    \n    df_fi.sort_values(by='imp', ascending=False).plot.barh(x='features', y='imp', figsize=(10,6), ax=ax);\n\n# Plot permutation importance.    \ndef plot_pi(model, x, y, n=None, ax=None):\n    if n is None: n = len(x.columns)\n    imp = permutation_importance(model, x, y, scoring='neg_root_mean_squared_error', n_repeats=2, n_jobs=4, random_state=1)\n    df_imp = pd.DataFrame({'features': x.columns, 'imp': imp.importances_mean}, index=None).astype({'imp': np.float64}).sort_values(by='imp', ascending=False).iloc[:n]\n    df_imp.sort_values(by='imp', ascending=False).plot.barh(x='features', y='imp', figsize=(10,6), ax=ax);\n\n# Pipeline for categorical feature transformation.\ndef preproc(cat_feats, cont_feats):\n    cat_tfms = Pipeline(steps=[\n        ('cat_ordenc', ce.OrdinalEncoder(return_df=True, handle_unknown='value', handle_missing='value'))\n    ])\n    # Pipeline for numeric feature transformation.\n    cont_tfms = Pipeline(steps=[\n        ('cont_imputer', SimpleImputer(missing_values=np.nan, strategy='median'))\n    ])\n    # Transform cat & cont features separately and concatenate the features\n    ctf = ColumnTransformer(transformers=[\n        ('cat_tfms', cat_tfms, cat_feats),\n        ('cont_tfms', cont_tfms, cont_feats)\n    ], remainder='passthrough')\n    return ctf\n\n# Function to submit. \ndef submit(preds_test,fname=None):\n    preds = np.exp(preds_test)\n    df_preds = pd.DataFrame({'Id':test.Id , 'SalePrice': preds})\n    df_preds.to_csv(fname ,index=False)\n\ndef cluster_feats(xs, fsize=(10,6)):\n    corr = np.round(scipy.stats.spearmanr(xs).correlation, 4)\n    corr_condensed = hc.distance.squareform(1-corr)\n    z = hc.linkage(corr_condensed, method='average')\n    fig = plt.figure(figsize=fsize)\n    dendrogram = hc.dendrogram(z, labels=xs.columns, orientation='left', leaf_font_size=12)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:54.618812Z","iopub.execute_input":"2021-09-08T19:04:54.619131Z","iopub.status.idle":"2021-09-08T19:04:54.678805Z","shell.execute_reply.started":"2021-09-08T19:04:54.619101Z","shell.execute_reply":"2021-09-08T19:04:54.677854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:27:52.075824Z","iopub.execute_input":"2021-09-08T19:27:52.076228Z","iopub.status.idle":"2021-09-08T19:27:52.177926Z","shell.execute_reply.started":"2021-09-08T19:27:52.076197Z","shell.execute_reply":"2021-09-08T19:27:52.176772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check number of train & test examples\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:54.680355Z","iopub.execute_input":"2021-09-08T19:04:54.680682Z","iopub.status.idle":"2021-09-08T19:04:54.728988Z","shell.execute_reply.started":"2021-09-08T19:04:54.680653Z","shell.execute_reply":"2021-09-08T19:04:54.728072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values in train & test sets.\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\ntrain.isnull().sum().to_frame(name='num_missing').query('num_missing>0').sort_values(by='num_missing', ascending=False).plot.barh(ax=ax1, figsize=(10,6));\ntest.isnull().sum().to_frame(name='num_missing').query('num_missing>0').sort_values(by='num_missing', ascending=False).plot.barh(ax=ax2, figsize=(10,6));\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:54.73016Z","iopub.execute_input":"2021-09-08T19:04:54.73048Z","iopub.status.idle":"2021-09-08T19:04:55.93975Z","shell.execute_reply.started":"2021-09-08T19:04:54.730451Z","shell.execute_reply":"2021-09-08T19:04:55.936521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Here we create objects that store predictors and target variables. Also we create list that store the numeric and categorical features. This will come in handy in the later sections since sklearn returns a numpy array after preprocessing the data and we need to convert it to pandas dataframe.","metadata":{}},{"cell_type":"code","source":"# Define feature types.\ntarget = ['SalePrice']\ncat_feats = train.drop(columns=['Id', 'SalePrice']).select_dtypes(include='object').columns.tolist()\ncont_feats = train.drop(columns=['Id', 'SalePrice']).select_dtypes(include=np.number).columns.tolist()\nall_feats = cat_feats + cont_feats\nlen(train.columns), len(cat_feats), len(cont_feats)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:55.941262Z","iopub.execute_input":"2021-09-08T19:04:55.941709Z","iopub.status.idle":"2021-09-08T19:04:55.99598Z","shell.execute_reply.started":"2021-09-08T19:04:55.941673Z","shell.execute_reply":"2021-09-08T19:04:55.994726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this step we definine `pipelines` for sequential preprocessing of our numeric and categorical features. Then we create a column transformer object to apply these preprocessing steps to the specific numeric and categorical features. We can then use our `ctf` object to transform our train validation and test datasets in just one step. This is very helpful in making our code cleaner and maintaining it.  ","metadata":{}},{"cell_type":"code","source":"# Pipeline for categorical feature transformation.\ncat_tfms = Pipeline(steps=[\n    ('cat_ordenc', ce.OrdinalEncoder(return_df=True, handle_unknown='value', handle_missing='value'))\n])\n\n# Pipeline for numeric feature transformation.\ncont_tfms = Pipeline(steps=[\n    ('cont_imputer', SimpleImputer(missing_values=np.nan, strategy='median'))\n])\n\n# Transform cat & cont features separately and concatenate the features.\nctf = ColumnTransformer(transformers=[\n    ('cat_tfms', cat_tfms, cat_feats),\n    ('cont_tfms', cont_tfms, cont_feats)\n], remainder='passthrough')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:56.00009Z","iopub.execute_input":"2021-09-08T19:04:56.000432Z","iopub.status.idle":"2021-09-08T19:04:56.04299Z","shell.execute_reply.started":"2021-09-08T19:04:56.000402Z","shell.execute_reply":"2021-09-08T19:04:56.041953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform the data.\nX = train[all_feats]\ny = train.SalePrice\n\n# Split the data.\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size=.2, shuffle=True, random_state=42)\n\n# Transform the train, valid & test sets.\nx_train_tf = pd.DataFrame(ctf.fit_transform(x_train), columns=all_feats)\nx_val_tf = pd.DataFrame(ctf.transform(x_val), columns=all_feats)\nx_test_tf = pd.DataFrame(ctf.transform(test[all_feats]), columns=all_feats)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:54:04.299544Z","iopub.execute_input":"2021-09-09T07:54:04.299956Z","iopub.status.idle":"2021-09-09T07:54:04.362671Z","shell.execute_reply.started":"2021-09-09T07:54:04.299848Z","shell.execute_reply":"2021-09-09T07:54:04.361266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map the categorical features to encodings.\nordenc_map = dict()\nfor feat in cat_feats: ordenc_map[feat] = dict(zip(x_train[feat], x_train_tf[feat]))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:56.403058Z","iopub.execute_input":"2021-09-08T19:04:56.403512Z","iopub.status.idle":"2021-09-08T19:04:56.465126Z","shell.execute_reply.started":"2021-09-08T19:04:56.403468Z","shell.execute_reply":"2021-09-08T19:04:56.463778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting a Random Forest Model","metadata":{}},{"cell_type":"markdown","source":"Let's fit a Random Forest model to our training data and see how it performs. Here we use the `mfe()` utility functions to perform the model fit and training.","metadata":{}},{"cell_type":"code","source":"# Define a random forest model.\nrf1 = RandomForestRegressor(\n    n_estimators=40, max_depth=None, min_samples_leaf=1, min_samples_split=2,\n    max_features=.7, max_samples=None, n_jobs=-1, random_state=1)\n\n# Call the utility function for model fitting & evaluation.\nmfe(rf1, x_train_tf, y_train, x_val_tf, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:56.466519Z","iopub.execute_input":"2021-09-08T19:04:56.466885Z","iopub.status.idle":"2021-09-08T19:04:57.066612Z","shell.execute_reply.started":"2021-09-08T19:04:56.466843Z","shell.execute_reply":"2021-09-08T19:04:57.065605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How does the model work?","metadata":{}},{"cell_type":"markdown","source":"Random Forests are based on the idea of Bagging, which basically says that if we build 5 different models on randomly sampled subsets of our data, then we have models that are somewhat predictive and not correlated with each other. This means that these five models have found different insights into the relationships in the data. If we take the average of these five models, we are essentially bringing insights from each of them. This idea of averaging models is a technique called **ensembling**. Suppose we created a large number of big, deep massively overfittig trees but each one fit to only 10% of our data. They overfit terribly, but since they all are fit on different random samples, they all overfit in different ways. In other words, they have errors, but the errors are random and the average of a buch of random errors is zero. So, if we take the average of these trees trained on different random subsets, the error will average out to zero and what is left is the true relationship. This is the essence of **Random Forests**\n\nThe building block of a Random Forest is a Decision Trees. In order to understand how it how it works, let's understand the working of a Decision Tree first. We will be covering the regression context here, but classification is also quite similar. Let's take the example of the problem we are working on. Here we have 80 features in our dataset. All of these features are represented as numeric values after preprocessing the data. For all the values that each of these 80 featutes take, we try to split out data and record a metric that tells us how good the split is. The feature & value that gives the best values of the metric becomes out root node. After splitting the root node, we get the left and right nodes. These can be further split using the same method as described above. The splitting continues untill we are restrained by the different stopping criteria such as max_depth, min_samples_leaf, max_leaves etc. \n\nThe metric that we use to determine the quality of a split can be `mean_squared_error` or `root_mean_squared_error` in the regression setting. The way we calculate the metric for is split is that after we split the node on a particular value, we calculate the mean squared error for each resulting node. We just average the target value in each of the nodes and take it as our prediction. Now, to calculate the metric for the split we take a weighted average of `mse` by the number of samples in each of the nodes. This ensures that we do not consider splits with very little number of samples in the nodes. \n\nNow let's say that we built 40 Decision Trees in our Random Forest, now to calculate the prediction for a given observation, we would pass that observation through all the 40 DTs and just take the average of the 40 outputs and consider it as our prediction. This was a very brief and high level summary of how the models work. The plots below help us visualize how our RF model splits out data. We can see that the first split is created on the feature `OverallQual` and on the value `6.5`. This results in creation of two nodes that have a lower `mse` of `0.08` and `0.09` respectively. ","metadata":{}},{"cell_type":"code","source":"# Using the dtreeviz library to visualize how tree splits the data.\nfrom dtreeviz.trees import *\nregr = tree.DecisionTreeRegressor(max_depth=3)\nregr.fit(x_train_tf, y_train)\n\ndtreeviz(\n    regr,\n    x_train_tf,\n    y_train,\n    target_name='SalePrice',\n    feature_names=x_train_tf.columns,\n    orientation='LR')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:04:57.069867Z","iopub.execute_input":"2021-09-08T19:04:57.070168Z","iopub.status.idle":"2021-09-08T19:05:00.239556Z","shell.execute_reply.started":"2021-09-08T19:04:57.070139Z","shell.execute_reply":"2021-09-08T19:05:00.238499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vizualizing a tree using graphviz library\ndot_data = tree.export_graphviz(regr, out_file=None, \n                                feature_names=x_train_tf.columns,\n                                rotate=True,\n                                filled=True)\ngraphviz.Source(dot_data, format=\"png\") ","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:00.240992Z","iopub.execute_input":"2021-09-08T19:05:00.241328Z","iopub.status.idle":"2021-09-08T19:05:00.345432Z","shell.execute_reply.started":"2021-09-08T19:05:00.241282Z","shell.execute_reply":"2021-09-08T19:05:00.343976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How confident are we of the predictions generated by the model?","metadata":{}},{"cell_type":"markdown","source":"We can use the `predict()` method on our estimator and pass it the data to get the predictions. In the real world scenario, along with the predictions, we also want to know how confident we are about the prediciton. We would be less confident of a prediction, if it has not seen many observations of the similar kind. In such a scenario, we would not expect any of the trees to have a definite path through that is designed to help us predict the observation correctly. As this observations passes through different trees in our RF, it is going to end up in very different places. For this observation, it would make sense to look at the standard deviations of the predictions from the different trees.If the standard deviation is high, that means each tree is giving us a very different estimate of this observation's prediciton. So the standard deviation of the predictions across the trees gives us at least relative understanding of how confident we are of this prediction. You can use this confidence interval for two main purposes:\n* We can look at the average confidence interval by group to find out if there are groups you do not seem to have confidence about.\n* We can look at the confidence for specific observations in our data. For example let's say we have put our House Price model in production and it says that a particular house can sell for a large amount, but the confidence is quite low. In that case, we might want to change the business decision and sell it at a lower price.","metadata":{}},{"cell_type":"code","source":"preds = np.stack([tree.predict(x_val_tf) for tree in rf1.estimators_], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:00.347522Z","iopub.execute_input":"2021-09-08T19:05:00.347989Z","iopub.status.idle":"2021-09-08T19:05:00.486575Z","shell.execute_reply.started":"2021-09-08T19:05:00.347938Z","shell.execute_reply":"2021-09-08T19:05:00.485566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:00.488176Z","iopub.execute_input":"2021-09-08T19:05:00.488611Z","iopub.status.idle":"2021-09-08T19:05:00.532154Z","shell.execute_reply.started":"2021-09-08T19:05:00.488567Z","shell.execute_reply":"2021-09-08T19:05:00.530611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:, 0].mean(), preds[:, 0].std() ","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:00.535058Z","iopub.execute_input":"2021-09-08T19:05:00.535682Z","iopub.status.idle":"2021-09-08T19:05:00.579589Z","shell.execute_reply.started":"2021-09-08T19:05:00.535639Z","shell.execute_reply":"2021-09-08T19:05:00.578241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Which features are more important than others?","metadata":{}},{"cell_type":"markdown","source":"It's great to have a model that gives you the highest accuracy or the lowest error rate, but it's equally important to understand and interpret your model's predictions. In this case, knowing which features are most predictive of price helps us understand what factors are people willing to pay for. This can sometimes be more important in a business scenario where the company can then focus in improving things that matter more to their customers and make more profit. **Feature Importances** proves to be a very handy tool when it comes to model interpretation. In this notebook, we will discuss two common ways to calculating feature importances and their pros and cons.\n\nRandom Forest Default Feature Importance\n* scikit-learn uses the mean decrease in impurity mechanism to calculate feature importance. \n* The mean decrease in impurity importance of a feature is computed by measuring how effective the feature is at reducing uncertainty (classifiers) or variance (regressors) when creating decision trees within RFs\n* This mechanism of computing feature importance can be biased as it tends to inflate the feature importances of continuous and high cardinality categorical variables.\n\nPermutation Importance\n* The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled. \n* In this method, we take a trained model and record the R2 on validation data. Then we randomly shuffle one feature at a time and record the drop in R2 score. This drop in R2 score becomes the importance of that feature.  \n* The permutation mechanism is much more computationally expensive than the mean decrease in impurity mechanism, but the results are more reliable.\n* Permutation importance is less reliable when features are collinear, permutating one feature will have little effect on the models performance because it can get the same information from a correlated feature. \n* One way to handle multicollinear features is by performing hierarchical clustering on the Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster. We will discuss this in the next section.\n\nIn the utility code section, I have provided the code for computing feature importance by both the techniques discussed above. Please take a look at the `plot_fi()` and `plot_pi()` functions. We will be using them below. For a more detailed study of this topic please refer to [this](https://explained.ai/rf-importance/#4) excellent resource.\n\n","metadata":{}},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2)\nplot_fi(rf1, x_train_tf, n=30, ax=ax1) # Feature Importance plot\nplot_pi(rf1, x_val_tf, y_val, n=30, ax=ax2) # Permutation Importance plot\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:00.580797Z","iopub.execute_input":"2021-09-08T19:05:00.581278Z","iopub.status.idle":"2021-09-08T19:05:09.095466Z","shell.execute_reply.started":"2021-09-08T19:05:00.581225Z","shell.execute_reply":"2021-09-08T19:05:09.0942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Which features are similar to each other(redundant features) ?","metadata":{}},{"cell_type":"markdown","source":"We have already seen that the variables which are basically measuring the same thing can confuse our variable importance. They can also make our Random Forest slightly less good because it requires more computation to do the same thing and there are more columns to check. In order to find redundant features, we will use a technique called hierarchical or agglomerative clustering. Cluster analysis is something where we are trying to look at objects, they can be rows in the dataset or columns and find which ones are similar to each other. In hierarchical or agglomerated clustering, we look at every pair of objects and say which two objects are the closest. We then take the closest pair, delete them, and replace them with the midpoint of the two. Then repeat that again and again. Since we are removing points and replacing them with their averages, you are gradually reducing a number of points by pairwise combining. The cool thing is, you can plot that. I have defined a function called `cluster_feats()` in the utility code that helps us plot it.\nThe horizontal axis in the plot indicates how similar are the two points that are being compared. If they are closer to the right, that means that they are very similar. We can see that `MiscVal` and `MiscFeature` are very close to each other and kind of measure the same thing. Similarly `Exterior2nd` and `Exterior1st` are very close to each other. So to move forward, we can decide a cut-off threshold, beyond which either can decide to keep one feature per cluster or combine the similar features in some way.\n","metadata":{}},{"cell_type":"code","source":"cluster_feats(x_train_tf, fsize=(12,18))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:09.097005Z","iopub.execute_input":"2021-09-08T19:05:09.097321Z","iopub.status.idle":"2021-09-08T19:05:10.487185Z","shell.execute_reply.started":"2021-09-08T19:05:09.097278Z","shell.execute_reply":"2021-09-08T19:05:10.485974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's remove some features and see how it impacts our rmse.","metadata":{}},{"cell_type":"markdown","source":"Here we use the `get_pi()` utility function to get the permutation importance of the features as a dataframe sorted in descending order. Then we create a list `n_feats` to store the different number of features that we want to use to fit our model. We then fit the model for each of these number of features and store the rmse for each iteration in the errors list. Then we plot a graph between the rmse and number of iterations. ","metadata":{}},{"cell_type":"code","source":"pi = get_pi(rf1, x_val_tf, y_val)\nerrors = []\nn_feats = [5,8,13,17,20,25,28,30,40,50,60,70,79]\nfor n in n_feats:\n    m = RandomForestRegressor(n_estimators=40, max_depth=None, min_samples_leaf=1, min_samples_split=2, max_features=None, max_samples=None, n_jobs=-1, random_state=1)\n    f = pi[:n].features.tolist()\n    m.fit(x_train_tf.loc[:, f], y_train)\n    preds_val = m.predict(x_val_tf.loc[:, f])\n    errors.append(rmse(y_val, preds_val))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:10.488526Z","iopub.execute_input":"2021-09-08T19:05:10.488832Z","iopub.status.idle":"2021-09-08T19:05:20.507633Z","shell.execute_reply.started":"2021-09-08T19:05:10.488802Z","shell.execute_reply":"2021-09-08T19:05:20.506719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe from the plot below that the rmse decreases rapidly until we get to using 20 features in our model, desceases further till about 28 features and then starts to decrease. In the real world scenario, depending on the usecase sometimes it relevant to trade off very small amounts of model improvement in favor of a simpler model which is simpler has less number of features and is easier to maintain. So, in this case, we will select the top 25 features by permutation importance for furthur analysis.","metadata":{}},{"cell_type":"code","source":"# RMSE vs Num Features.\nfig, ax = plt.subplots(1, 1, figsize=(8,6))\nax.plot(n_feats, errors);\nax.set(title = \"RMSE vs Num Features\", xlabel = \"Features\", ylabel = \"RMSE\");","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:20.508904Z","iopub.execute_input":"2021-09-08T19:05:20.509189Z","iopub.status.idle":"2021-09-08T19:05:20.775741Z","shell.execute_reply.started":"2021-09-08T19:05:20.509163Z","shell.execute_reply":"2021-09-08T19:05:20.774662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pi = get_pi(rf1, x_val_tf, y_val)\nto_keep = pi.iloc[:20].features.tolist()\nx_train_imp = x_train_tf[to_keep]\nx_val_imp = x_val_tf[to_keep]","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:20.776974Z","iopub.execute_input":"2021-09-08T19:05:20.77726Z","iopub.status.idle":"2021-09-08T19:05:25.620033Z","shell.execute_reply.started":"2021-09-08T19:05:20.777232Z","shell.execute_reply":"2021-09-08T19:05:25.618979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf2 = RandomForestRegressor(\n    n_estimators=40, max_depth=None, min_samples_leaf=1, min_samples_split=2,\n    max_features=.7, max_samples=None, n_jobs=-1, random_state=1)\n\nmfe(rf2, x_train_imp, y_train, x_val_imp, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:25.621522Z","iopub.execute_input":"2021-09-08T19:05:25.621834Z","iopub.status.idle":"2021-09-08T19:05:26.109784Z","shell.execute_reply.started":"2021-09-08T19:05:25.621803Z","shell.execute_reply":"2021-09-08T19:05:26.108455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that after removing the features the rmse has improved. That's quite surprising. We are are getting a better score with just 30 features, as compared to when we wee using 80. Let's ty and understand what these features mean and how can we find more relevant features. Let's plot the feature importances again to see which features come at the top.","metadata":{}},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2)\nplot_fi(rf2, x_train_tf[to_keep], ax=ax1) # Feature Importance plot\nplot_pi(rf2, x_val_tf[to_keep], y_val, ax=ax2) # Permutation Importance plot\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:26.113404Z","iopub.execute_input":"2021-09-08T19:05:26.113883Z","iopub.status.idle":"2021-09-08T19:05:29.059226Z","shell.execute_reply.started":"2021-09-08T19:05:26.113832Z","shell.execute_reply":"2021-09-08T19:05:29.058179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we plot the dendrogram again to check which features in our 25 selected features are similar and can be combined or discarded.","metadata":{}},{"cell_type":"code","source":"cluster_feats(x_train_tf[to_keep], fsize=(8,8))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:29.060832Z","iopub.execute_input":"2021-09-08T19:05:29.061139Z","iopub.status.idle":"2021-09-08T19:05:29.451133Z","shell.execute_reply.started":"2021-09-08T19:05:29.061107Z","shell.execute_reply":"2021-09-08T19:05:29.449987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_features(train[to_keep])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:29.452425Z","iopub.execute_input":"2021-09-08T19:05:29.452719Z","iopub.status.idle":"2021-09-08T19:05:29.523189Z","shell.execute_reply.started":"2021-09-08T19:05:29.452691Z","shell.execute_reply":"2021-09-08T19:05:29.5224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Partial Dependence Plots","metadata":{}},{"cell_type":"markdown","source":"What is the relationship between `SalePrice` and `Yearbuilt` all other things being equal?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,6))\nax.scatter(train.YearBuilt, train.SalePrice, alpha=.3);\nax.set(title='YearBuilt vs SalePrice');","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:42:03.949416Z","iopub.execute_input":"2021-09-08T19:42:03.949805Z","iopub.status.idle":"2021-09-08T19:42:04.258471Z","shell.execute_reply.started":"2021-09-08T19:42:03.949769Z","shell.execute_reply":"2021-09-08T19:42:04.257455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotnine import *\nggplot(train, aes('YearBuilt', 'SalePrice'))+stat_smooth(se=True, method='loess')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:29.783208Z","iopub.execute_input":"2021-09-08T19:05:29.783656Z","iopub.status.idle":"2021-09-08T19:05:32.138464Z","shell.execute_reply.started":"2021-09-08T19:05:29.783612Z","shell.execute_reply":"2021-09-08T19:05:32.137206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the partial dependence plot.\npdp_goals = pdp.pdp_isolate(model=rf2, dataset=x_val_tf, model_features=to_keep, feature='YearBuilt')\npdp.pdp_plot(pdp_goals, 'YearBuilt')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:07:21.056574Z","iopub.execute_input":"2021-09-08T19:07:21.056968Z","iopub.status.idle":"2021-09-08T19:07:22.57335Z","shell.execute_reply.started":"2021-09-08T19:07:21.056938Z","shell.execute_reply":"2021-09-08T19:07:22.572279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tree Interpretor: What happens to an observation as it passes through our model?","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict & Submit","metadata":{}},{"cell_type":"code","source":"x_test_tf","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:32.576522Z","iopub.status.idle":"2021-09-08T19:05:32.576975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = rf2.predict(x_test_tf[to_keep])\nsubmit(y_test,fname='subm1.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:32.578052Z","iopub.status.idle":"2021-09-08T19:05:32.578513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import json\n# !mkdir ~/.kaggle\n# !touch ~/.kaggle/kaggle.json\n# api_token = {\"username\":\"adityabhat\",\"key\":\"077eab99785d783113fedbf2698bcc53\"}\n# with open('/root/.kaggle/kaggle.json', 'w') as file:\n#     json.dump(api_token, file)\n# !chmod 600 ~/.kaggle/kaggle.json","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:32.579443Z","iopub.status.idle":"2021-09-08T19:05:32.57987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle competitions submit -c house-prices-advanced-regression-techniques -f sub3.csv -m \"Message\"","metadata":{"execution":{"iopub.status.busy":"2021-09-08T19:05:32.580863Z","iopub.status.idle":"2021-09-08T19:05:32.581281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}