{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Competition description\n\n'''\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling \nor the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences \nprice negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition \nchallenges you to predict the final price of each home.\n'''\n\n# Importing libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nimport sklearn.linear_model as linear_model\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import make_scorer, r2_score\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n# Ignorar warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n'''\nSteps:\n\n1. Collecting data\n2. Cleaning data\n3. Exploratory data analysis\n4. Model building\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SalePrice = train['SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SalePrice.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## concatenating train and test\n\ndf = pd.concat((train, test))\nprint(\"Shape of df: \", df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Verificando número de variáveis numéricas\n\nnumericalFeatures = df.select_dtypes(include = [np.number])\nprint(\"The number of numerical features is: {}\".format(numericalFeatures.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numericalFeatures.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Verificando número de variáveis categóricas\n\ncategoricalFeatures = df.select_dtypes(exclude = [np.number])\nprint(\"The number of categorical features is: {}\".format(categoricalFeatures.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoricalFeatures.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking data distribution only in the training set\n\nplt.subplots(figsize=(12,9))\nsns.distplot(train['SalePrice'], fit=stats.norm)\n\n# Get the fitted parameters used by the function\n(mu, sigma) = stats.norm.fit(train['SalePrice'])\n\n# Plot with the distribution\nplt.legend(['Normal dist. ($/mu=$ {:.2f} and $/sigma=$ {:.2f})'.format(mu, sigma)], loc='best')\n\n# Probability plot\nfig=plt.figure()\nstats.probplot(train['SalePrice'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = numericalFeatures.corr()\n\nsns.set(style=\"white\")\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(20, 10))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Correlation greater than 0.5\n\ntop_feature = corr.index[abs(corr['SalePrice']>0.5)]\nplt.subplots(figsize=(12,8))\ntop_corr = df[top_feature].corr()\nsns.heatmap(top_corr, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catFeatures = categoricalFeatures.columns\ntrain[catFeatures] = train[catFeatures].fillna('Missing')\n\n# Onward...\nanova = {'feature':[], 'f':[], 'p':[]}\nfor cat in catFeatures:\n  group_prices = []\n  for group in train[cat].unique():\n      group_prices.append(train[train[cat] == group]['SalePrice'].values)\n  f, p = stats.f_oneway(*group_prices)\n  anova['feature'].append(cat)\n  anova['f'].append(f)\n  anova['p'].append(p)\nanova = pd.DataFrame(anova)\nanova = anova[['feature','f','p']]\nanova.sort_values('p', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anova","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Null hypothesis (H0): There is no difference\n\nIf P<0.05 we can reject H0\n\nThe features Street, LandSlope and Utilities have P>0.05, which means, they make difference in sales price.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['SalePrice', 'Id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checando colunas com valores nulos\nnullValues = (df.isnull().sum() / len(df)) * 100\nnullValues = round(nullValues.drop(nullValues[nullValues == 0].index).sort_values(ascending=False)[:30],2)\nmissingData = pd.DataFrame({'Percente of null values' :nullValues})\nmissingData.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Percentage of null values\n\nf, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=nullValues.index, y=nullValues)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of null values', fontsize=15)\nplt.title('Percent null values by feature', fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Change the categorical features related to the quality of the house\n\nnumber = LabelEncoder()\ndf['Alley'] = number.fit_transform(df['Alley'].astype('str'))\ndf['LotShape'] = number.fit_transform(df['LotShape'].astype('str'))\ndf['LandContour'] = number.fit_transform(df['LandContour'].astype('str'))\ndf['Utilities'] = number.fit_transform(df['Utilities'].astype('str'))\ndf['LandSlope'] = number.fit_transform(df['LandSlope'].astype('str'))\ndf['ExterQual'] = number.fit_transform(df['ExterQual'].astype('str'))\ndf['BsmtQual'] = number.fit_transform(df['BsmtQual'].astype('str'))\ndf['BsmtCond'] = number.fit_transform(df['BsmtCond'].astype('str'))\ndf['BsmtExposure'] = number.fit_transform(df['BsmtExposure'].astype('str'))\ndf['BsmtFinType1'] = number.fit_transform(df['BsmtFinType1'].astype('str'))\ndf['BsmtFinType2'] = number.fit_transform(df['BsmtFinType2'].astype('str'))\ndf['HeatingQC'] = number.fit_transform(df['HeatingQC'].astype('str'))\ndf['KitchenQual'] = number.fit_transform(df['KitchenQual'].astype('str'))\ndf['Functional'] = number.fit_transform(df['Functional'].astype('str'))\ndf['FireplaceQu'] = number.fit_transform(df['FireplaceQu'].astype('str'))\ndf['GarageFinish'] = number.fit_transform(df['GarageFinish'].astype('str'))\ndf['GarageQual'] = number.fit_transform(df['GarageQual'].astype('str'))\ndf['GarageFinish'] = number.fit_transform(df['GarageFinish'].astype('str'))\ndf['GarageCond'] = number.fit_transform(df['GarageCond'].astype('str'))\ndf['PavedDrive'] = number.fit_transform(df['PavedDrive'].astype('str'))\ndf['PoolQC'] = number.fit_transform(df['PoolQC'].astype('str'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(['YrSold', 'MoSold']).Id.count().plot(kind='bar', figsize=(14,4))\nplt.title(\"Sale date\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conversion from numeric feature to Category features\n\ndf['MSSubClass'] = df.MSSubClass.apply(lambda x: str(x))\ndf['MoSold'] = df.MoSold.apply(lambda x: str(x))\ndf['YrSold'] = df.YrSold.apply(lambda x: str(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MSSubClass'] = number.fit_transform(df['MSSubClass'].astype('str'))\ndf['MoSold'] = number.fit_transform(df['MoSold'].astype('str'))\ndf['YrSold'] = number.fit_transform(df['YrSold'].astype('str'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns[df.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lot Frontage (how can there be no street infront of the lot) Hence we replace it with the median value\ndf.LotFrontage = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\n# Garage Year Built, if missing we can set it to zero\ndf.GarageYrBlt.fillna(0, inplace=True)\n\n# Masonary Veneer Area here most values are zero\ndf.MasVnrArea.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns[df.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Electrical.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Electrical.fillna(df.Electrical.mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.MasVnrType.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First let's correct our assignment\ndf.MasVnrType.replace({'Missing':'None'}, inplace=True)\n\n# Second, we are going to replace them with the mean value\ndf.loc[(df.MasVnrType == 'None') & (df.MasVnrArea > 1), 'MasVnrType'] = 'BrkFace' # Most common\ndf.loc[(df.MasVnrType == 'None') & (df.MasVnrArea == 1), 'MasVnrType'] = 0  # M1 sq ft is basically 0\n\nfor vnr_type in df.MasVnrType.unique():\n    # so here we set area equal to the mean of the given veneer type\n    df.loc[(df.MasVnrType == vnr_type) & (df.MasVnrArea == 0), 'MasVnrArea'] = df[df.MasVnrType == vnr_type].MasVnrArea.mean()\n    \ndf.MasVnrType.fillna(df.MasVnrType.mode()[0], inplace=True)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.GarageType.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.GarageType.fillna(df.GarageType.mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Fence.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Fence.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.MiscFeature.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.MiscFeature.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.GarageArea.fillna(df.GarageArea.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.SaleType.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.SaleType.fillna(df.SaleType.mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.GarageCars.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.GarageCars.fillna(df.GarageCars.mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.BsmtFinSF1.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.BsmtFinSF1.fillna(df.BsmtFinSF1.mean(), inplace=True)\ndf.BsmtFinSF2.fillna(df.BsmtFinSF2.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.BsmtFullBath.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.BsmtFullBath.fillna(df.BsmtFullBath.mode()[0], inplace=True)\ndf.BsmtHalfBath.fillna(df.BsmtHalfBath.mode()[0], inplace=True)\ndf.Exterior1st.fillna(df.Exterior1st.mode()[0], inplace=True)\ndf.Exterior2nd.fillna(df.Exterior2nd.mode()[0], inplace=True)\ndf.BsmtUnfSF.fillna(df.BsmtUnfSF.mode()[0], inplace=True)\ndf.MSZoning.fillna(df.MSZoning.mode()[0], inplace=True)\ndf.TotalBsmtSF.fillna(df.TotalBsmtSF.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns[df.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating total square feet (area)\n\ndf['Total_SF'] = df.TotalBsmtSF + df.GrLivArea\ndf['TotalFloorSF'] = df['1stFlrSF'] + df['2ndFlrSF']\ndf['TotalPorchSF'] = df.OpenPorchSF + df.EnclosedPorch + df['3SsnPorch'] + df['ScreenPorch']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's create some boolean features (Yes-No type)\n\ndf['HasBasement'] = df.TotalBsmtSF.apply(lambda x: 1 if x>0 else 0)\ndf['HasGarage'] = df.GarageArea.apply(lambda x: 1 if x>0 else 0)\ndf['HasPorch'] = df.TotalPorchSF.apply(lambda x: 1 if x>0 else 0)\ndf['HasPool'] = df.PoolArea.apply(lambda x: 1 if x>0 else 0)\ndf['WasRemodeled'] = (df.YearRemodAdd != df.YearBuilt).astype(np.int64)\ndf['IsNew'] = (df.YearBuilt > 2000).astype(np.int64)\ndf['WasCompleted'] = (df.SaleCondition != 'Partial').astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"booleanFeatures = ['HasBasement','HasGarage','HasPorch','HasPool','WasRemodeled','IsNew','WasCompleted']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numericalFeatures = numericalFeatures.drop(['Id','SalePrice'], axis=1)\nnumFeatures = numericalFeatures.columns\ncatFeatures = categoricalFeatures.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numFeatures = [f for f in numFeatures if f not in booleanFeatures]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total Bathrooms\n\ndf['TotalBathrooms'] = df.FullBath + 0.5*df.HalfBath + df.BsmtFullBath + 0.5*df.BsmtHalfBath","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in numFeatures:\n  df.loc[:,f] = np.log1p(df[f])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SalePrice = np.log1p(SalePrice)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfColumns = df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checando distribuição dos dados no dataset de treinamento\n\nplt.subplots(figsize=(12,9))\nsns.distplot(SalePrice, fit=stats.norm)\n\n# Get the fitted parameters used by the function\n(mu, sigma) = stats.norm.fit(SalePrice)\n\n# Plot with the distribution\nplt.legend(['Normal dist. ($/mu=$ {:.2f} and $/sigma=$ {:.2f})'.format(mu, sigma)], loc='best')\n\n# Probability plot\nfig=plt.figure()\nstats.probplot(SalePrice, plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling dataset with robust scaler\n\nscaler = StandardScaler()\n\ndf.loc[:, numFeatures] = scaler.fit_transform(df[numFeatures])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainLen = len(train)\ny_train = SalePrice\nx_train = df[:trainLen]\nx_test = df[trainLen:]\n\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(len(y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, x_train, y_train):\n    cv = KFold(n_splits = 3, shuffle=True, random_state = 45)\n    r2 = make_scorer(r2_score)\n    r2_val_score = cross_val_score(model, x_train, y_train, cv=cv, scoring = r2)\n    score = [r2_val_score.mean()]\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rsme(model, x, y):\n  cv_scores = -cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=10)\n  return np.sqrt(cv_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Tuning parameters\n\nparam_grid = {'alpha':[0.0001,0.001,0.01,1.,5.,10.,25.],'max_iter':[50000]}\nlasso = GridSearchCV(Lasso(), cv=5, param_grid=param_grid, scoring='neg_mean_squared_error')\nlasso.fit(x_train, y_train)\nalpha = lasso.best_params_['alpha']\n\n# Home in\nparam_grid = {'alpha':[x/100. * alpha for x in range(50,150,5)],'max_iter':[50000]}\nlasso = GridSearchCV(Lasso(), cv=5, param_grid=param_grid, scoring='neg_mean_squared_error')\nlasso.fit(x_train, y_train)\nalpha = lasso.best_params_['alpha']\nlasso = lasso.best_estimator_\n\nprint('Lasso -> Train RSME: {:,.5f}| alpha {:,.5f}'.format(rsme(lasso,x_train,y_train).mean(),alpha))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefs = pd.DataFrame({'coefs':lasso.coef_,'Positive':lasso.coef_>0}, index=dfColumns)\ncoefs['coefs_abs'] = np.abs(coefs.coefs)\nprint('Lasso dropped {} of {} features.'.format(sum(coefs.coefs==0), coefs.shape[0]))\n\ntop_coefs = coefs.sort_values('coefs_abs', ascending=False).head(30)\nplt.figure(figsize=(8,10))\nsns.barplot(top_coefs.coefs_abs, top_coefs.index, orient='h', hue=top_coefs.Positive)\nplt.title=('Lasso Regression: Top Features')\nplt.xlabel('Absolute Coeficient')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression\n\nLR = linear_model.LinearRegression()\nacc_LR = test_model(LR, x_train, y_train)\n\nLR_rsme = rsme(LR, x_train, y_train)\n\nprint('Score: {:.5f}'.format((acc_LR[0])))\nprint('RSME: {:.5f}'.format(LR_rsme.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Regressor\n\nsvr_reg = SVR(kernel='rbf')\nacc_SVR = test_model(svr_reg, x_train, y_train)\n\nsvr_rsme = rsme(svr_reg, x_train, y_train)\nprint('Score: {:.5f}'.format((acc_SVR[0])))\nprint('RSME: {:.5f}'.format(svr_rsme.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree\ndt_reg = DecisionTreeRegressor(random_state=21)\nacc_tree = test_model(dt_reg, x_train, y_train)\n\ndt_rsme = rsme(dt_reg, x_train, y_train)\nprint('Score: {:.5f}'.format((acc_tree[0])))\nprint('RSME: {:.5f}'.format(dt_rsme.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nrf_reg = RandomForestRegressor(n_estimators = 1000, random_state=51)\nacc_rf = test_model(rf_reg, x_train, y_train)\n\nrf_rsme = rsme(rf_reg, x_train, y_train)\nprint('Score: {:.5f}'.format((acc_rf[0])))\nprint('RSME: {:.5f}'.format(rf_rsme.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bagging Regressor\nbr_reg = BaggingRegressor(n_estimators=1000, random_state=51)\nacc_br = test_model(br_reg, x_train, y_train)\n\nbr_rsme = rsme(br_reg, x_train, y_train)\nprint('Score: {:.5f}'.format((acc_br[0])))\nprint('RSME: {:.5f}'.format(br_rsme.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient Boosting Regressor\ngbr_reg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, loss='ls', random_state=51)\nacc_gbr = test_model(gbr_reg, x_train, y_train)\n\ngbr_rsme = rsme(gbr_reg, x_train, y_train)\nprint('Score: {:.5f}'.format((acc_gbr[0])))\nprint('RSME: {:.5f}'.format(gbr_rsme.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\n\nxgb_reg = xgb.XGBRegressor(colsample_bytree=0.2, \n                        gamma=0.0,\n                        learning_rate=0.05,\n                        max_depth=6,\n                        min_child_weight=1.5,\n                        n_estimators=7200,\n                        reg_alpha=0.9,\n                        reg_lambda=0.6,\n                        subsample=0.2,\n                        seed=42,\n                        silent=1)\n\nacc_xgb = test_model(xgb_reg,x_train[top_coefs.index], y_train)\nxgb_rsme = rsme(xgb_reg, x_train[top_coefs.index], y_train)\n\nprint('Score: {:.5f}'.format((acc_xgb[0])))\nprint('RSME: {:.5f}'.format(xgb_rsme.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'Model': ['Linear Regression', 'Support Vector Regressor', \n              'Decision Tree', 'Random Forest', 'Bagging Regressor', 'Gradient Boosting Regressor ','XGBoost'],\n    'Score': [acc_LR[0], acc_SVR[0], acc_tree[0], acc_rf[0], acc_br[0], acc_gbr[0], acc_xgb[0]],\n    'RSME': [LR_rsme[0], svr_rsme[0], dt_rsme[0], rf_rsme[0], br_rsme[0], gbr_rsme[0], xgb_rsme[0]]\n})\n\nresult = results.sort_values(by='RSME', ascending=True)\nresult = result.set_index('Model')\ndisplay(result.head(8))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}