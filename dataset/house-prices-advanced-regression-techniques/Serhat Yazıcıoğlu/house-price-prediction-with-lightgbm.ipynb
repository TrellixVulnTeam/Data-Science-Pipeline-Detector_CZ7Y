{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the libraries necessary for the exercise.\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading dataset\ntrain = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntest = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\ndf = train.append(test).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# First look at the dataset\ndef check_df(dataframe):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\n\ncheck_df(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# With this function, we were able to separate the variables in the data set as categorical and numerical.\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    \n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, cat_but_car, num_cols, num_but_cat\n\n\ncat_cols, cat_but_car, num_cols, num_but_cat = grab_col_names(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Class numbers of categorical variables and their proportion in the data set of the classes\ndef cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\n        \n\nfor col in cat_cols:\n    cat_summary(df, col)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for col in cat_but_car:\n    cat_summary(df, col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for col in num_but_cat:\n    cat_summary(df, col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Returns the descriptive statistics of numerical variables\ndef num_summary(dataframe, numerical_col):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\nfor col in num_cols:\n    num_summary(df, col)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def find_correlation(dataframe, numeric_cols, target, corr_limit=0.60):\n    high_correlations = []\n    low_correlations = []\n    for col in numeric_cols:\n        if col == target:\n            pass\n        else:\n            correlation = dataframe[[col, target]].corr().loc[col, target]\n            print(col, correlation)\n            if abs(correlation) > corr_limit:\n                high_correlations.append(col + \": \" + str(correlation))\n            else:\n                low_correlations.append(col + \": \" + str(correlation))\n    return low_correlations, high_correlations\n\n\nlow_corrs, high_corrs = find_correlation(df, num_cols, \"SalePrice\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"low_corrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_corrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Examining the categorical variables together with the target variable\ndef target_summary_with_cat(dataframe, target, categorical_cols):\n    for categorical_col in categorical_cols:\n        print(categorical_col)\n        print(\"*************************\")\n        print(pd.DataFrame({\"RATIO\": 100 * dataframe[categorical_col].value_counts() / dataframe.shape[0],\n                            \"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n\n\ntarget_summary_with_cat(df, \"SalePrice\", cat_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rare Analysis"},{"metadata":{},"cell_type":"markdown","source":"**We observed the distributions of the classes of categorical variables in the data set.**\n\n**We combined the variability of the classes we examined according to the mean and median values in the dependent variable and their classes according to the observation rate in the data set.**\n\n**While doing these merging operations, we combined ordinality if there is no structural difference.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"MSZoning\"] = np.where(df.MSZoning.isin([\"RH\", \"RM\"]), \"Rare\", df[\"MSZoning\"])\ndf[\"LotShape\"] = np.where(df.LotShape.isin([\"IR1\", \"IR2\", \"IR3\"]), \"Rare\", df[\"LotShape\"])\ndf[\"LotConfig\"] = np.where(df.LotConfig.isin([\"FR2\", \"FR3\"]), \"FRRare\", df[\"LotConfig\"])\n\ndf[\"GarageQual\"] = np.where(df.GarageQual.isin([\"Fa\", \"Po\"]), \"Rare\", df[\"GarageQual\"])\n\ndf[\"BsmtFinType2\"] = np.where(df.BsmtFinType2.isin([\"GLQ\", \"ALQ\"]), \"RareExcellent\", df[\"BsmtFinType2\"])\ndf[\"BsmtFinType2\"] = np.where(df.BsmtFinType2.isin([\"BLQ\", \"LwQ\", \"Rec\"]), \"RareGood\", df[\"BsmtFinType2\"])\n\ndf[\"Heating\"] = np.where(df.Heating.isin([\"GasA\", \"GasW\", \"OthW\"]), \"RareGas\", df[\"Heating\"])\ndf[\"Heating\"] = np.where(df.Heating.isin([\"Floor\", \"Grav\", \"Wall\"]), \"Rare\", df[\"Heating\"])\n\ndf[\"GarageQual\"] = np.where(df.GarageQual.isin([\"TA\", \"Gd\"]), \"RareGood\", df[\"GarageQual\"])\ndf[\"GarageQual\"] = np.where(df.GarageQual.isin([\"Po\", \"Fa\"]), \"RarePoor\", df[\"GarageQual\"])\n\ndf[\"LandSlope\"] = np.where(df.LandSlope.isin([\"Mod\", \"Sev\"]), \"Rare\", df[\"LandSlope\"])\n\ndf[\"Condition1\"] = np.where(df.Condition1.isin([\"Artery\", \"Feedr\"]), \"Rare_art_feed\", df[\"Condition1\"])\ndf[\"Condition1\"] = np.where(df.Condition1.isin([\"PosA\", \"PosN\"]), \"RarePos\", df[\"Condition1\"])\ndf[\"Condition1\"] = np.where(df.Condition1.isin([\"RRNe\", \"RRNn\"]), \"RareRRN\", df[\"Condition1\"])\n\ndf[\"Fireplaces\"] = np.where(df.Fireplaces.isin([\"2\", \"3\", \"4\"]), \"Rare234\", df[\"Fireplaces\"])\ndf[\"GarageCars\"] = np.where(df.GarageCars.isin([\"4.000\", \"5.000\"]), \"Rare\", df[\"GarageCars\"])\n\ndf[\"BsmtCond\"] = np.where(df.BsmtCond.isin([\"Gd\", \"TA\"]), \"RareGdTA\", df[\"BsmtCond\"])\ndf[\"BsmtExposure\"] = np.where(df.BsmtExposure.isin([\"Av\", \"Mn\"]), \"RareAvMn\", df[\"BsmtExposure\"])\ndf[\"BsmtFinType1\"] = np.where(df.BsmtFinType1.isin([\"BLQ\", \"LwQ\"]), \"RareBLwQ\", df[\"BsmtFinType1\"])\ndf[\"BsmtFinType1\"] = np.where(df.BsmtFinType1.isin([\"ALQ\", \"Rec\"]), \"RareAlRec\", df[\"BsmtFinType1\"])\n\ndf.loc[332, \"BsmtFinType1\"] = np.NaN\n\ndf[\"ExterCond\"] = np.where(df.ExterCond.isin([\"Ex\", \"Gd\", \"TA\"]), \"RareGood\", df[\"ExterCond\"])\ndf[\"ExterCond\"] = np.where(df.ExterCond.isin([\"Fa\", \"Po\"]), \"RarePoor\", df[\"ExterCond\"])\ndf[\"Foundation\"] = np.where(df.Foundation.isin([\"BrkTil\", \"Stone\"]), \"RareBrkSt\", df[\"Foundation\"])\ndf[\"Foundation\"] = np.where(df.Foundation.isin([\"CBlock\", \"Wood\"]), \"RareCBWood\", df[\"Foundation\"])\n\ndf[\"BldgType\"] = np.where(df.BldgType.isin([\"Duplex\", \"Twnhs\"]), \"RareDupTwnhs\", df[\"BldgType\"])\n\ndf[\"Exterior1st\"] = np.where(df.Exterior1st.isin([\"AsbShng\", \"AsphShn\", \"CBlock\"]), \"RareAsphShnCB\", df[\"Exterior1st\"])\ndf[\"Exterior1st\"] = np.where(df.Exterior1st.isin([\"HdBoard\", \"Stucco\", \"Wd Sdng\", \"WdShing\"]), \"RareHSwd\",\n                             df[\"Exterior1st\"])\ndf[\"Exterior1st\"] = np.where(df.Exterior1st.isin([\"CemntBd\", \"Stone\", \"ImStucc\"]), \"RareHSwd\", df[\"Exterior1st\"])\ndf[\"Exterior1st\"] = np.where(df.Exterior1st.isin([\"Plywood\", \"BrkFace\"]), \"RarePlBrk\", df[\"Exterior1st\"])\n\ndf[\"Exterior2nd\"] = np.where(df.Exterior2nd.isin([\"AsbShng\", \"CBlock\"]), \"RarePlBrk\", df[\"Exterior2nd\"])\ndf[\"Exterior2nd\"] = np.where(df.Exterior2nd.isin([\"AsphShn\", \"Wd Sdng\", \"Wd Shng\", \"Stucco\", \"MetalSd\", \"Brk Cmn\"]), \"Rareawwsmb\", df[\"Exterior2nd\"])\ndf[\"Exterior2nd\"] = np.where(df.Exterior2nd.isin([\"HdBoard\", \"BrkFace\", \"Plywood\", \"Stone\"]), \"RareBPS\", df[\"Exterior2nd\"])\n\ndf[\"GarageType\"] = np.where(df.GarageType.isin([\"2Types\", \"Basment\"]), \"Rare2TyBas\", df[\"GarageType\"])\ndf[\"GarageType\"] = np.where(df.GarageType.isin([\"CarPort\", \"Detchd\"]), \"Rare2CarDetch\", df[\"GarageType\"])\n\ndf[\"Fence\"] = np.where(df.Fence.isin([\"GdPrv\", \"MnPrv\", \"GdWo\", \"MnWw\"]), \"Rare\",df[\"Fence\"]) \n\ndf[\"SaleType\"] = np.where(df.SaleType.isin([\"WD\", \"CWD\"]), \"RareWd\", df[\"SaleType\"])\ndf[\"SaleType\"] = np.where(df.SaleType.isin([\"ConLw\", \"ConLI\", \"ConLD\"]), \"RareConL\", df[\"SaleType\"])\n\ndf[\"SaleCondition\"] = np.where(df.SaleCondition.isin([\"Abnorml\", \"Family\", \"Alloca\"]), \"RareAbFaAll\",df[\"SaleCondition\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"NEW_TOTALQUAL_index\"] = df[\"OverallQual\"] * df[\"GarageArea\"] * df[\"GrLivArea\"]\n\ndf[\"NEW_HeatingQC_index\"] = df.loc[df[\"HeatingQC\"] == \"Ex\", \"HeatingQC\"] = 5\ndf[\"NEW_HeatingQC_index\"] = df.loc[df[\"HeatingQC\"] == \"Gd\", \"HeatingQC\"] = 4\ndf[\"NEW_HeatingQC_index\"] = df.loc[df[\"HeatingQC\"] == \"TA\", \"HeatingQC\"] = 3\ndf[\"NEW_HeatingQC_index\"] = df.loc[df[\"HeatingQC\"] == \"Fa\", \"HeatingQC\"] = 2\ndf[\"NEW_HeatingQC_index\"] = df.loc[df[\"HeatingQC\"] == \"Po\", \"HeatingQC\"] = 1\n\ndf[\"NEW_Yr_sold\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\n\ndf[\"NEW_Yr_sold_index\"] = pd.qcut(df[\"NEW_Yr_sold\"], q=5, labels=[5, 4, 3, 2, 1])\n\ndf[\"NEW_Yr_sold_index\"] = df[\"NEW_Yr_sold_index\"].astype(int)\n\ndf[\"NEW_ONE_HeatingQC_index\"] = df[\"NEW_HeatingQC_index\"] * df[\"NEW_Yr_sold_index\"]\n\ndf['NEW_TotalSF'] = (df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'])\n\ndf['NEW_YrBltAndRemod'] = df['YearRemodAdd'] - df['YearBuilt']\n\ndf[\"NEW_YrBltAndRemod\"].min()\n\ndf['NEW_Total_sqr_footage'] = (df['BsmtFinSF1'] + df['BsmtFinSF2'] + df['1stFlrSF'] + df['2ndFlrSF'])\n\ndf['NEW_Total_Bathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))\n\ndf['NEW_Total_porch_sf'] = (df['OpenPorchSF'] + df['3SsnPorch'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF'])\n\ndf[\"NEW_AREA\"] = df[\"GrLivArea\"] + df[\"GarageArea\"]\n\ndf['TotalLot'] = df['LotFrontage'] + df['LotArea']\n\ndf['TotalBsmtFin'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n\ndf['TotalSF'] = df['TotalBsmtSF'] + df['2ndFlrSF']\n\ndf['TotalBath'] = df['FullBath'] + df['HalfBath']\n\ndf['TotalPorch'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['ScreenPorch']\n\ndf.loc[(df['MoSold'] >= 3) & (df['MoSold'] <= 5), 'New_MoSold_index'] = 'Spring'\n\ndf.loc[(df['MoSold'] >= 6) & (df['MoSold'] <= 8), 'New_MoSold_index'] = 'Summer'\n\ndf.loc[(df['MoSold'] >= 9) & (df['MoSold'] <= 11), 'New_MoSold_index'] = 'Autumn'\n\ndf.loc[df[\"New_MoSold_index\"].isnull(), \"New_MoSold_index\"] = \"Winter\"\n\ndf[\"New_SqFtPerRoom\"] = df[\"GrLivArea\"] / (df[\"TotRmsAbvGrd\"] + df[\"FullBath\"] + df[\"HalfBath\"] + df[\"KitchenAbvGr\"])\n\ndf[\"New_Garage_Area_ratio\"] = (df[\"GarageArea\"] / df[\"LotArea\"]) * 100\n\ndf[\"New_LotQuall\"] = df[\"OverallQual\"] * df[\"LotArea\"]\n\ndf[\"New_QuallYear\"] = (df[\"YrSold\"].max() - df[\"YearBuilt\"]) * df[\"OverallQual\"]\n\ndf[\"New_Totall_Area\"] = df[\"GarageArea\"] + df[\"GrLivArea\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = [\"Street\", \"Alley\", \"LandContour\", \"Utilities\", \"LandSlope\", \"Condition2\",\n             \"Heating\", \"PoolQC\", \"MiscFeature\", \"KitchenAbvGr\", \"BedroomAbvGr\",\n             \"RoofMatl\", \"FireplaceQu\",\n             \"RoofStyle\", \"ExterQual\", \"Electrical\", \"Functional\", \"FireplaceQu\"]\n\ndf.drop(drop_list, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[\"Fence\"] == \"Rare\", \"Fence\"] = 1\ndf.loc[df[\"Fence\"].isnull(), \"Fence\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_encoder(dataframe, binary_col):\n    labelencoder = preprocessing.LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cols = [col for col in df.columns if df[col].dtypes == \"O\"\n               and len(df[col].unique()) == 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    label_encoder(df, col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One-Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_cols = [col for col in df.columns if 10 >= len(df[col].unique()) > 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = one_hot_encoder(df, ohe_cols, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_cols = [col for col in df.columns if df[col].isnull().sum() > 0 and \"SalePrice\" not in col]\n\ndf[nan_cols] = df[nan_cols].apply(lambda x: x.fillna(x.median()), axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting an upper and lower limit for outliers\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.25)\n    quartile3 = dataframe[variable].quantile(0.75)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The function that examines whether there is an outlier according to the threshold values we have determined.\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing outliers with upper and lower limit\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_col = [col for col in num_cols if col not in [\"SalePrice\", \"OverallQual\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in out_col:\n    print(col, check_outlier(df, col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in out_col:\n    replace_with_thresholds(df, i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"robust_col = [col for col in df.columns if df[col].nunique() > 2 and col not in [\"Id\", \"SalePrice\"]]\n\nfor col in robust_col:\n    transformer = RobustScaler().fit(df[[col]])\n    df[col] = transformer.transform(df[[col]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[df['SalePrice'].notnull()]\ntest = df[df['SalePrice'].isnull()].drop(\"SalePrice\", axis=1)\n\nX = train.drop(['SalePrice', \"Id\"], axis=1)\ny = train[\"SalePrice\"]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=46)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model = LGBMRegressor().fit(X_train, y_train)\ny_pred = lgb_model.predict(X_val)\nnp.sqrt(mean_squared_error(y_val, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model = LGBMRegressor()\n\nlgbm_params = {\"learning_rate\": [0.01, 0.1],\n               \"n_estimators\": [500, 1000],\n               \"max_depth\": [3, 5, 8],\n               \"feature_fraction\": [0.01, 0.001, 0, 1],\n               \"colsample_bytree\": [1, 0.8, 0.5],\n               'num_leaves': [2, 3, 4, 5]}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_cv_model = GridSearchCV(lgb_model,\n                             lgbm_params,\n                             cv=10,\n                             n_jobs=-1,\n                             verbose=2).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_tuned = LGBMRegressor(**lgbm_cv_model.best_params_).fit(X_train, y_train)\ny_pred = lgbm_tuned.predict(X_val)\nnp.sqrt(mean_squared_error(y_val, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}