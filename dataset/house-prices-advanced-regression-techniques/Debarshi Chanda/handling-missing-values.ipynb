{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\"> Handling Missing Values</h1>\n<br>\n\n![](https://fintechprofessor.com/wp-content/uploads/2019/12/close-up-texture-of-a-white-jigsaw-puzzle-in-assembled-state-with-missing-elements-forming-a-blue-pad_t20_WxKR61.jpg)","metadata":{}},{"cell_type":"markdown","source":"<div class = 'alert alert-info' style = 'color:blue'> ðŸ’¡ This notebook is part of the <a href=\"http://iitg.ac.in/sa/caciitg/course\" style=\"color: #002d5e\">Summer Analytics 2021</a> course curated by <a href=\"https://www.linkedin.com/company/caciitg/mycompany/\" style=\"color: black\">Consulting & Analytics Club, IIT Guwahati</a>. This notebook intends to introduce the readers to various different Imputaion techniques and How to deal with missing values in general with the help of <i>pandas</i> and <i>sklearn</i></div>","metadata":{}},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center \" >Table of Contents</h1>\n\n\n* [1. Introduction](#1)\n    * [1.1 Import Required Libraries](#1.1)\n    * [1.2 Exploring the Data](#1.2)\n    * [1.3 Helper Function](#1.3)\n* [2. Dropping Rows and Columns](#2)\n    * [2.1 Dropping Rows with Missing Values](#2.1)\n    * [2.2 Dropping Columns with Missing Values](#2.2)\n* [3. Univariate vs Multivariate Imputation](#3)\n    * [3.1 Univariate Imputation](#3.1)\n        * [3.1.1 Simple Imputer](#3.1.1)\n    * [3.2 Multivariate Imputation](#3.2)\n        * [3.2.1 KNN Imputer](#3.2.1)\n        * [3.2.2 Iterative Imputer](#3.2.2)\n* [4. Missing Indicator](#4)\n* [5. Missing Indicator + Iterative Imputer](#5)\n* [6. Further Readings](#6)","metadata":{}},{"cell_type":"markdown","source":"<a id = '1'></a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 1. Introduction </h2>","metadata":{}},{"cell_type":"markdown","source":"<a id = '1.1'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">1.1 Import Required Libraries</h2>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.impute import KNNImputer\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# displays all the columns\npd.set_option('display.max_columns', None)\nplt.rcParams[\"figure.figsize\"] = (18, 8);","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:51:25.332054Z","iopub.execute_input":"2021-05-23T15:51:25.332603Z","iopub.status.idle":"2021-05-23T15:51:25.339905Z","shell.execute_reply.started":"2021-05-23T15:51:25.332557Z","shell.execute_reply":"2021-05-23T15:51:25.339006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '1.2'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight:normal; border-radius: 100px 100px; text-align: center\">1.2 Exploring the Data </h2>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:26:22.168421Z","iopub.execute_input":"2021-05-23T15:26:22.168764Z","iopub.status.idle":"2021-05-23T15:26:22.255548Z","shell.execute_reply.started":"2021-05-23T15:26:22.168733Z","shell.execute_reply":"2021-05-23T15:26:22.25446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:26:22.691495Z","iopub.execute_input":"2021-05-23T15:26:22.691823Z","iopub.status.idle":"2021-05-23T15:26:22.698102Z","shell.execute_reply.started":"2021-05-23T15:26:22.691778Z","shell.execute_reply":"2021-05-23T15:26:22.697061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-23T15:26:23.363763Z","iopub.execute_input":"2021-05-23T15:26:23.364121Z","iopub.status.idle":"2021-05-23T15:26:23.395478Z","shell.execute_reply.started":"2021-05-23T15:26:23.364091Z","shell.execute_reply":"2021-05-23T15:26:23.394465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">We have 81 columns in total, 80 of them are feature columns and <code>SalePrice</code> is the target column</span>","metadata":{}},{"cell_type":"code","source":"feature_cols = [col for col in df.columns if col not in ['SalePrice']]\ntarget_cols = ['SalePrice']\n\ncat_cols = [col for col in feature_cols if df[col].dtype == 'O']\ncont_cols = [col for col in feature_cols if col not in cat_cols]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:26:24.813769Z","iopub.execute_input":"2021-05-23T15:26:24.814241Z","iopub.status.idle":"2021-05-23T15:26:24.819162Z","shell.execute_reply.started":"2021-05-23T15:26:24.81421Z","shell.execute_reply":"2021-05-23T15:26:24.818476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:51:28.559446Z","iopub.execute_input":"2021-05-23T15:51:28.559799Z","iopub.status.idle":"2021-05-23T15:51:29.980999Z","shell.execute_reply.started":"2021-05-23T15:51:28.559766Z","shell.execute_reply":"2021-05-23T15:51:29.980093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '1.3'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">1.3 Helper Function</h2>","metadata":{}},{"cell_type":"code","source":"def encode_missing_columns(df, col):\n    le = LabelEncoder()\n    \n    # gets unique values w/o NaN\n    unique_without_nan = pd.Series([i for i in df[col].unique() if type(i) == str])\n    le.fit(unique_without_nan) # Fit on unique values\n    \n    # Set transformed col leaving np.NaN as they are\n    df[col] = df[col].apply(lambda x: le.transform([x])[0] if type(x) == str else x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take an example to understand what this function is doing <br>\nSuppose we have a column `['apple', 'mango', 'banana', 'apple', 'banana', NaN]`","metadata":{}},{"cell_type":"code","source":"demo_col = pd.Series(['apple', 'mango', 'banana', 'apple', 'banana', np.NaN])\nprint(f'Unique Values in the Column: {demo_col.unique()}')\nprint(f'Unique Values of type string: {[i for i in demo_col.unique() if type(i) == str]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nunique_without_nan = pd.Series([i for i in demo_col.unique() if type(i) == str])\nle.fit(unique_without_nan)\ndemo_col.apply(lambda x: le.transform([x])[0] if type(x) == str else x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '2'></a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 2. Dropping Rows and Columns </h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">This isn't an imputation technique, but this might be the first thing that comes in mind to deal with missing values</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '2.1'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">2.1 Dropping Rows with Missing Values</h2>","metadata":{}},{"cell_type":"code","source":"sum(df.isna().sum(axis=1) > 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">If we drop all the rows with any missing value we aren't left with any row</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '2.2'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">2.2 Dropping Columns with Missing Values</h2>","metadata":{}},{"cell_type":"code","source":"sum(df.isna().sum(axis=0) > 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">If we drop all columns with missing values we lose 19 columns</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '3'></a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 3. Univariate vs Multivariate Imputation </h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. <code>SimpleImputer</code>). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. <code>IterativeImputer</code>).</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '3.1'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.1 Univariate Imputation</h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">We can impute missing values with a provided constant value, or using the statistics (mean, median or most frequent) of each column.</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '3.1.1'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 28px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.1.1 Simple Imputer</h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Imputing Continuous Variables</span>","metadata":{}},{"cell_type":"code","source":"df_simple_imputer = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='mean')\n\ndf_simple_imputer[cont_cols] = imputer.fit_transform(df_simple_imputer[cont_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Imputing Categorical Variables</span>","metadata":{}},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='most_frequent')\n\ndf_simple_imputer[cat_cols] = imputer.fit_transform(df_simple_imputer[cat_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_simple_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '3.2'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.2 Multivariate Imputation</h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">A strategy for imputing missing values by modeling each feature with missing values as a function of other features</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '3.2.1'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 28px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.2.1 KNN Imputer</h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">KNNImputer doesn't work on strings so we need to encode the strings into float or int keeping the <code>NaN</code> values</span> <br>\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">This is where we will use the helper function we defined earlier</span>","metadata":{}},{"cell_type":"code","source":"df_knn_imputer = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cat_cols:\n    encode_missing_columns(df_knn_imputer, col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_imputer = KNNImputer(n_neighbors=5)\n\ndf_knn_imputer[feature_cols] = knn_imputer.fit_transform(df_knn_imputer[feature_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_knn_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '3.2.2'></a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 28px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.2.2 Iterative Imputer</h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Like KNNImputer, Iterative Imputer also doesn't work on strings</span>","metadata":{}},{"cell_type":"code","source":"df_iterative_imputer = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cat_cols:\n    encode_missing_columns(df_iterative_imputer, col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itr_imputer = IterativeImputer()\n\ndf_iterative_imputer[feature_cols] = itr_imputer.fit_transform(df_iterative_imputer[feature_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_iterative_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '4'></a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 4. Missing Indicator </h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Most of the times the missing values are not randomly distributed across observations but are distributed within one or more sub-samples. Therefore, missingness itself might be a good indicator to classify the labels</span>","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import MissingIndicator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_miss = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"miss_indicator = MissingIndicator()\n\nX_miss = miss_indicator.fit_transform(df_miss[feature_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_miss.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Recall that in <a href=\"#2.2\">Section 2.2</a> we had seen that if we drop all columns with missing values we lose 19 columns</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '5'></a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 5. Missing Indicator + Iterative Imputer </h2>","metadata":{}},{"cell_type":"code","source":"df_miss_itr = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cat_cols:\n    encode_missing_columns(df_miss_itr, col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting add_indicator=True returns missing indicators alongwith the imputed dataframe\nitr_imputer = IterativeImputer(add_indicator=True) \n\nX = itr_imputer.fit_transform(df_miss_itr[feature_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">We have 99 feature columns now (80 original features + 19 missing indicator features) and 1 target column</span>","metadata":{}},{"cell_type":"markdown","source":"<a id = '6'></a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 6. Further Readings </h2>","metadata":{}},{"cell_type":"markdown","source":"1. [KNN Imputer Algorithm](https://www.youtube.com/watch?v=AHBHMQyD75U&list=PLlg4M31xJeYa7XcJZWypot8l7R-0E65Ls)\n2. [Iterative Imputer Algorithm](https://www.youtube.com/watch?v=WPiYOS3qK70&list=PLlg4M31xJeYa7XcJZWypot8l7R-0E65Ls)","metadata":{}}]}