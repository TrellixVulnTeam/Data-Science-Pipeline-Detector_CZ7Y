{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport plotly.express as px\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# House Prices: Advanced Regression Techniques\n\nThis project covers the advanced regression techniques as the dataset contains a lot of variable that are both categorical variables and linear values variables.According to me, this should be project after a kaggler is comfortable with making models and understanding the scores.For my model building , right now I am considering only root mean squared error values and R-squared value.\n\nFor further scoring, I was planning to use Adjusted R-squared value.\n\nDetails on accuracy for R-squared:\n\n**R-squared** is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively. R-squared measures the strength of the relationship between your model and the dependent variable on a convenient 0 â€“ 100% scale.\n\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_data=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ntrain_data=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\nsample_submission=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')\n\nbackup_data=train_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our predicted variable is the **SalePrice** which would be calculated from the several predictor variables that we have.Currently, we don't know anything about any of the details.\n\nThere are around 80 columns and 1460 rows.There are a lot of columns that may affect the SalePrice .For that one need to do comprehensive exploration of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_column=train_data[['SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking train data\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking test data\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Sample submission data\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The pandas describe function gives us a basic information on the values of variable.From understanding of the describe function, The House Sale Prices have a minimum of 34.9 K dollars to 755 K."},{"metadata":{"trusted":true},"cell_type":"code","source":"target_column.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from below, the graph is a normal distribution curve with values between 100K and 300K.\n\nAbout Gaussian Normal Distribution Curve:\n\n    Gaussian distribution (also known as normal distribution) is a bell-shaped curve, and it is assumed that during any measurement values will follow a normal\n    distribution with an equal number of measurements above and below the mean value.\n    \n    In statistics, the theoretical curve that shows how often an experiment will produce a particular result. The curve is symmetrical and bell shaped, showing that \n    trials will usually give a result near the average, but will occasionally deviate by large amounts. \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.distplot(target_column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for Null values\n\nNull values can be treated mostly in 2 ways: \n    \n       1. Either delete the whole row - This option I usually use when the data records that needs to be removed are not that important and **WOULD NOT** not help \n       in our model building.\n       \n       2.Imputing the values with mean or a median.I perfer to choose median over mean as I think that mean gets affected by outliers so I prefer median as a way to \n       impute values."},{"metadata":{},"cell_type":"markdown","source":"## Removing Outliers \n\nFor removing outliers I came across with the several kernels in which people have ran the below code to remove the outliers.I am still trying to understand as how these were constituted as outliers.Here is the discussion thread.\n\nhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/146728\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# As suggested by many participants, we remove several outliers\ntrain_data.drop(train_data[(train_data['OverallQual']<5) & (train_data['SalePrice']>200000)].index, inplace=True)\ntrain_data.drop(train_data[(train_data['GrLivArea']>4000) & (train_data['SalePrice']<300000)].index, inplace=True)\ntrain_data.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxplot(column_name,data):\n    title='Box plot for column- {0}'.format(column_name)\n    #print(title)\n    plt.title(title)\n    sns.boxplot(x=column_name,data=data)\n    details_na='The total number of NA Values for column - {1} is {0}' .format(data[column_name].isna().sum(),column_name)\n    print(details_na)\n    \ndef drop_column(data,column_name):\n    train_data=data\n    if column_name in data.columns:\n        train_data=data.drop(columns=[column_name],axis=1)\n        return train_data\n    else:\n        print('Column already removed from dataset Or column not present \\n')\n        print(' ,'.join (data.columns))\n        return train_data\n    \ndef remove_outliers(column_name,data):\n    quantile_1=data[column_name].quantile(0.25)\n    quantile_3=data[column_name].quantile(0.75)\n    iqr=quantile_3-quantile_1\n    lower=quantile_1-1.5*iqr\n    upper=quantile_1+1.5*iqr\n    data[column_name]=data[(data[column_name]>lower)& (data[column_name]<upper)][column_name]\n    return data[column_name]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have divided sets into 3 parts -\n\n    1. Object type variables \n    2. Integer type variables -- The missing values would be added with **median** values\n    3. Integer turned Category variables "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Convert to category variable\n## Dividing the list between object type variables and int variables and then subsetting it\n\nobj_type_variables = [column for column in train_data.columns if train_data[column].dtype in ['object']]\nobject_data=train_data[obj_type_variables]\nobject_data_test=test_data[obj_type_variables]\n\nobj_new_list=['MSSubClass','OverallQual','OverallCond','BsmtFullBath','GarageCars','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd'\n              ,'Fireplaces','MoSold']\ntrain_data[obj_new_list]=train_data[obj_new_list].apply(lambda column:column.astype('object'))\ntest_data[obj_new_list]=test_data[obj_new_list].apply(lambda column:column.astype('object'))\n\ncategory_data=train_data[obj_new_list]\ncategory_data_test=test_data[obj_new_list]\n\nint_type_variables = [column for column in train_data.columns if train_data[column].dtype in ['int64','float64']]\nint_data=train_data[int_type_variables]\nint_data_test=test_data[int_type_variables[:-1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(int_type_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data[obj_new_list].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We would be replacing the removing values with median values.I choose median values over mean values as means get affected with outliers while it is not the same case with median values"},{"metadata":{"trusted":true},"cell_type":"code","source":"object_data_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Replacing NaN values for categorical features\n\n    1. Alley variable contains 2 variables,rest has been replaced with None Variable\n    2. For the rest values, I took up the mode values i.e. the higher categorical variables is taken\n    3. For some higher NaN values,I will replace it with NA"},{"metadata":{"trusted":true},"cell_type":"code","source":"object_data['BsmtExposure'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=['BsmtHalfBath', 'BsmtFullBath', 'GarageCars']\nfor i in x:\n    print(train_data[i].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nobject_data['Alley']=object_data['Alley'].fillna(\"Grvl\")\nobject_data['BsmtQual']=object_data['BsmtQual'].fillna(\"TA\")\nobject_data['BsmtCond']=object_data['BsmtCond'].fillna(\"TA\")\nobject_data['BsmtExposure']=object_data['BsmtExposure'].fillna(\"No\")\nobject_data['BsmtFinType1']=object_data['BsmtFinType1'].fillna(\"Unf\")\nobject_data['BsmtFinType2']=object_data['BsmtFinType2'].fillna(\"Unf\")\nobject_data['Electrical']=object_data['Electrical'].fillna(\"SBrkr\")\nobject_data['FireplaceQu']=object_data['FireplaceQu'].fillna(\"Gd\")\nobject_data['GarageType']=object_data['GarageType'].fillna(\"Attchd\")\nobject_data['GarageFinish']=object_data['GarageFinish'].fillna(\"Unf\")\nobject_data['GarageQual']=object_data['GarageQual'].fillna(\"TA\")\nobject_data['GarageCond']=object_data['GarageCond'].fillna(\"TA\")\nobject_data['PoolQC']=object_data['GarageCond'].fillna(\"TA\")\nobject_data['Fence']=object_data['Fence'].fillna(\"MnPrv\")\nobject_data['MiscFeature']=object_data['MiscFeature'].fillna(\"Shed\")\n\ntrain_data['BsmtHalfBath']=train_data['BsmtHalfBath'].fillna(\"0\")\ntrain_data['BsmtFullBath']=train_data['BsmtFullBath'].fillna(\"0\")\ntrain_data['GarageCars']=train_data['GarageCars'].fillna(\"2\")\n\n\n\nobject_data_test['Alley']=object_data_test['Alley'].fillna(\"Grvl\")\nobject_data_test['BsmtQual']=object_data_test['BsmtQual'].fillna(\"TA\")\nobject_data_test['BsmtCond']=object_data_test['BsmtCond'].fillna(\"TA\")\nobject_data_test['BsmtExposure']=object_data_test['BsmtExposure'].fillna(\"No\")\nobject_data_test['BsmtFinType1']=object_data_test['BsmtFinType1'].fillna(\"Unf\")\nobject_data_test['BsmtFinType2']=object_data_test['BsmtFinType2'].fillna(\"Unf\")\nobject_data_test['Electrical']=object_data_test['Electrical'].fillna(\"SBrkr\")\nobject_data_test['FireplaceQu']=object_data_test['FireplaceQu'].fillna(\"Gd\")\nobject_data_test['GarageType']=object_data_test['GarageType'].fillna(\"Attchd\")\nobject_data_test['GarageFinish']=object_data_test['GarageFinish'].fillna(\"Unf\")\nobject_data_test['GarageQual']=object_data_test['GarageQual'].fillna(\"TA\")\nobject_data_test['GarageCond']=object_data_test['GarageCond'].fillna(\"TA\")\nobject_data_test['PoolQC']=object_data_test['GarageCond'].fillna(\"TA\")\nobject_data_test['Fence']=object_data_test['Fence'].fillna(\"MnPrv\")\nobject_data_test['MiscFeature']=object_data_test['MiscFeature'].fillna(\"Shed\")\n\ntest_data['BsmtHalfBath']=test_data['BsmtHalfBath'].fillna(\"0\")\ntest_data['BsmtFullBath']=test_data['BsmtFullBath'].fillna(\"0\")\ntest_data['GarageCars']=test_data['GarageCars'].fillna(\"2\")\n\n\n#object_data['MiscFeature'].value_counts()\n#train_data_X_int=train_data_X_int.fillna(train_data_X_int.median())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['GarageCars'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing Data\n\nI used basic preprocessing i.e. filling missing values, didnt remove any outliers and created a base model which gave out a score of around 85%.I am now trying to build a model after properly cleaning the data i.e. removing outliers , filling NA's with proper values.\n\nI referenced some of the top voted kernels therefore I hope that after I clean the data, the result would be a little better.I will comment out on the box plots after I have visualised on it."},{"metadata":{},"cell_type":"markdown","source":"### Working on integer related data\n\nI am making box job and trying to get an understanding if we have need to clear any outliers.Simultaneously, I will fill the missing values.For that I have created a function as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot('SalePrice',target_column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As understood from the target column, the box plot depicts some of the outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_data=int_data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Heat Map for the data\n\nHeat map helps to find out the correlation between variables.The corr() function uses Pearson Correlation.I used heatmap because I wanted to check if a high correlation is affected by variables to the target variables.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,30))\nsns.heatmap(corr_data,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nUnderstanding from the above correlation map, I am going to take on some of the variables that have got high correlation and understand the flow information.Below is the relation of variables between each other\n\n            |Column Name               |Correlated Columns with high correlation|\n            \n            |--------------------------|----------------------------------------|\n            \n            |MSSubClass                |LotFrontage,TotalBsmtSF,1stFlrSF        |\n            |LotFrontage               |  NA                                    |\n            |LotArea                   |  NA                                    |\n            |OverallQual               | GrLivArea                              |\n            |OverallCond               | GarageYrBlt                            |\n            |YearBuilt                 |EnclosedPorch,GarageYrBlt,YearRemodAdd  |\n            |YearRemodAdd              |GarageYrBlt                             |\n            |MasVnrArea                |  NA                                    |\n            |BsmtFinSF1                |BsmtFullBath                            |\n            |BsmtFinSF2                |  NA                                    |\n            |BsmtUnfSF                 |BsmtFullBath                            |\n            |TotalBsmtSF               |1stFlrSF                                |\n            |1stFlrSF                  |  NA                                    |\n            |2ndFlrSF                  | GrLivArea                              |\n            |LowQualFinSF              |  NA                                    |\n            |GrLivArea                 |  NA                                    |\n            |BsmtFullBath              |  NA                                    |\n            |BsmtHalfBath              |  NA                                    |\n            |FullBath                  |  NA                                    |\n            |HalfBath                  |  NA                                    |\n            |BedroomAbvGr              |Fireplaces                              |\n            |KitchenAbvGr              |  NA                                    |\n            |TotRmsAbvGrd              |  NA                                    |\n            |Fireplaces                |  NA                                    |\n            |GarageYrBlt               | EnclosedPorch                          |\n            |GarageCars                | GarageArea                             |\n            |GarageArea                |  NA                                    |\n            |WoodDeckSF                |  NA                                    |\n            |OpenPorchSF               |  NA                                    |\n            |EnclosedPorch             |  NA                                    |\n            |3SsnPorch                 |  NA                                    |\n            |ScreenPorch               |  NA                                    |\n            |PoolArea                  |  NA                                    |\n            |MiscVal                   |  NA                                    |\n            |MoSold                    |  NA                                    |\n            |YrSold                    |  NA                                    |\n            \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pair_plot_data_inbetween_variables=train_data[['MSSubClass',\n          'LotFrontage',\n         'TotalBsmtSF',\n         'OverallQual',\n         'GrLivArea',\n         'OverallCond',\n         'YearBuilt',\n         'EnclosedPorch',\n         'GarageYrBlt',\n         'YearRemodAdd',\n         'BsmtFinSF1',\n         'BsmtFullBath',\n         'BsmtUnfSF',\n         '1stFlrSF',\n         '2ndFlrSF',\n         'BedroomAbvGr',\n         'Fireplaces',\n         'GarageCars',\n         'GarageArea'\n         ]]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pair_plot_data_inbetween_variables.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After shortlisting the variables, I built a pair plot between the variables which have either a high positive correlation or a negative correlation."},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(30,30))\n#sns.pairplot(pair_plot_data_inbetween_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pair_plot_data_target_variable=train_data[[\n    'SalePrice',\n    'OverallQual',\n    'TotalBsmtSF',\n    '1stFlrSF',\n    'GrLivArea',\n    'GarageCars',\n    'GarageArea'\n]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below pair plot is created with respect to the SalePrice(target variable) with other variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(pair_plot_data_target_variable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating graphs between SalePrice and ['GarageArea','GrLivArea','1stFlrSF','TotalBsmtSF']\n\nplt.figure(figsize=(9,9))\nsns.relplot(x=\"SalePrice\",\n                y=\"GrLivArea\",\n                col=\"BldgType\",\n                hue=\"OverallQual\",\n                kind=\"scatter\",\n                height=10,\n                aspect=0.3,\n                data=train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph is between SalePrice and GrLivArea(Above grade (ground) living area square feet), divided across Building Type and Overall Quality of values.\n\nAs understood from the above the records, building type for 1Fam has a large number of records and it is a positive trend i.e. with the increase in SalePrice there is a increase in Quality."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,9))\nsns.relplot(x=\"SalePrice\",\n                y=\"GarageArea\",\n                col=\"GarageCars\",\n                hue=\"GarageQual\",\n                kind=\"scatter\",\n                height=10,\n                aspect=0.3,\n                data=train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph is between SalePrice and Garage Area.The Graph is spreaded for Garage Cars as 3 while for GarageCars=2 the no. of records is high as compared to the other records.Also, the no. of records for Average Garage quality is high."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(train_data, x=\"SalePrice\", y=\"1stFlrSF\", color=\"OverallQual\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph shows the flow between SalePrice and 1stFlrSF.The Overall Quality would show the flow of the SalePrice values."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(train_data, x=\"SalePrice\", y=\"TotalBsmtSF\", color=\"OverallQual\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Building\n\nFor Model building, I am first creating a base model that considers all variables for our predictor variables and predicted variable is our SalePrice.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(obj_type_variables)\n#print(int_type_variables)\nint_selected=int_type_variables[1:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[obj_type_variables].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data[obj_type_variables].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data[obj_type_variables].shape[0])\nprint(test_data[obj_type_variables].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_type_variables=obj_type_variables+obj_new_list\nobj_type_variables=list(set(obj_type_variables))\n\ntrain_data_X_obj = train_data[obj_type_variables].apply(lambda column: column.astype('category').cat.codes)\ntest_data_X_obj=test_data[obj_type_variables].apply(lambda column: column.astype('category').cat.codes) \n\n\n#train_data_X_obj = train_data[obj_type_variables].apply(lambda column: column.astype('category'))\n#test_data_X_obj=test_data[obj_type_variables].apply(lambda column: column.astype('category'))\n\n#train_data_X_obj = pd.get_dummies(train_data_X_obj)\n#test_data_X_obj = pd.get_dummies(test_data_X_obj)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combined_data = pd.concat((train_data[obj_type_variables], test_data[obj_type_variables]), sort=False).reset_index(drop=True)\n#combined_data_dummies=pd.get_dummies(combined_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data_X_obj=combined_data_dummies.iloc[:train_data[obj_type_variables].shape[0]].reset_index(drop=True)\n#test_data_X_obj = combined_data_dummies.iloc[train_data[obj_type_variables].shape[0]:].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data_X_obj.shape)\nprint(test_data_X_obj.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_X_int=train_data[int_selected]\ntest_data_X_int=test_data[int_selected]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking for missing values and imputing them\nprint('Checking for categorical variables for missing values')\nprint(train_data_X_obj.isna().sum())\nprint('Checking for integer variables for missing values')\n\nprint(train_data_X_int.isna().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_X_int=train_data_X_int.fillna(train_data_X_int.median())\ntest_data_X_int=test_data_X_int.fillna(train_data_X_int.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaler=StandardScaler()\n#scaler=RobustScaler()\n#scaler=MinMaxScaler()\n#train_data_X_int=pd.DataFrame(scaler.fit_transform(train_data_X_int),columns=train_data_X_int.columns)\n#test_data_X_int=pd.DataFrame(scaler.fit_transform(test_data_X_int),columns=test_data_X_int.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Y=train_data['SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X=train_data_X_int.merge(train_data_X_obj,left_index=True,right_index=True).reset_index(drop=True)\ntest_X=test_data_X_int.merge(test_data_X_obj,left_index=True,right_index=True).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_X.shape)\nprint(train_Y.shape)\nprint(test_X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X.columns[test_X.isna().any()].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_X.shape)\nprint(train_Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(train_X, train_Y,test_size = .3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I divided dataset into 70-30 ratio so that we can test our scenarios."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrf = RandomForestRegressor()\nparams = {\"max_depth\":[15,20,25], \"n_estimators\":[24,30,36]}\nrf_reg = GridSearchCV(rf, params, cv = 10, n_jobs =10)\nrf_reg.fit(X_train, Y_train)\nprint(rf_reg.best_estimator_)\nbest_estimator=rf_reg.best_estimator_\ny_pred_test = best_estimator.predict(X_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Square Error test = ' + str(mean_squared_error(Y_test, y_pred_test,squared=False)))\nprint('Root Mean Square Error test = ' + str((mean_squared_error(np.log(Y_test), np.log(y_pred_test),squared=False))))\n\nprint ('R2 square '+str(r2_score(Y_test, y_pred_test))) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_train.columns))\nprint(len(set(X_train.columns)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from xgboost import XGBRegressor\n#xgb_regressor = XGBRegressor(learning_rate=0.02,n_estimators = 2400,max_depth=3, min_child_weight=0.01,gamma=0, subsample=0.7,\n#                                     colsample_bytree=0.7,objective='reg:linear', nthread=-1, scale_pos_weight=1, seed=27,reg_alpha=0.00006)\n#xgb_regressor.fit(X_train,Y_train)\n#y_pred_test=xgb_regressor.predict(X_test)\n#\n#mean_squared_error(Y_test, y_pred_test)\n#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngb_regressor = GradientBoostingRegressor(n_estimators=1992, learning_rate=0.03, max_depth=3, max_features='sqrt', min_samples_leaf=15, min_samples_split=8, loss='huber', random_state =42)\ngb_regressor.fit(X_train,Y_train)\ny_pred_test=gb_regressor.predict(X_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Square Error test = ' + str(mean_squared_error(Y_test, y_pred_test,squared=False)))\nprint('Root Mean Square Error test = ' + str((mean_squared_error(np.log(Y_test), np.log(y_pred_test),squared=False))))\n\nprint ('R2 square '+str(r2_score(Y_test, y_pred_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_test = best_estimator.predict(test_X)\npred_test = gb_regressor.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')\nsubmission=pd.DataFrame({\"Id\":sample_submission['Id'],\"SalePrice\":pred_test})\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" I have taken the references from the below sites and kernels.Thanks a lot guys!!!!!\n \n \n     https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis/\n    \n    https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n    \n    https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n    \n    https://www.kaggle.com/janvichokshi/advanced-regression-techniques\n    \n    https://statisticsbyjim.com/regression/interpret-r-squared-regression/\n    \n    https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n    \n    https://www.kaggle.com/agehsbarg/top-10-0-10943-stacking-mice-and-brutal-force"},{"metadata":{},"cell_type":"markdown","source":"P.S.\nI making more changes to this kernel I think I can make better models by using other variants and doing feature selections.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}