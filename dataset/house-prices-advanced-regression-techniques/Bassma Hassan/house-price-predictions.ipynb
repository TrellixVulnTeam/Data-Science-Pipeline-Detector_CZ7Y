{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-15T13:22:45.134814Z","iopub.execute_input":"2021-08-15T13:22:45.135247Z","iopub.status.idle":"2021-08-15T13:22:45.152807Z","shell.execute_reply.started":"2021-08-15T13:22:45.135157Z","shell.execute_reply":"2021-08-15T13:22:45.151772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns', 100)\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn import preprocessing\nfrom sklearn import feature_selection\nimport warnings\nwarnings.filterwarnings('ignore')\nSEED = 42","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:22:49.447847Z","iopub.execute_input":"2021-08-15T13:22:49.448186Z","iopub.status.idle":"2021-08-15T13:22:50.729141Z","shell.execute_reply.started":"2021-08-15T13:22:49.448158Z","shell.execute_reply":"2021-08-15T13:22:50.727949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:05.087141Z","iopub.execute_input":"2021-08-15T13:24:05.087544Z","iopub.status.idle":"2021-08-15T13:24:05.137068Z","shell.execute_reply.started":"2021-08-15T13:24:05.087512Z","shell.execute_reply":"2021-08-15T13:24:05.136077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:07.487068Z","iopub.execute_input":"2021-08-15T13:24:07.487435Z","iopub.status.idle":"2021-08-15T13:24:07.531423Z","shell.execute_reply.started":"2021-08-15T13:24:07.487405Z","shell.execute_reply":"2021-08-15T13:24:07.530495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Visualization**","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:18.859633Z","iopub.execute_input":"2021-08-15T13:24:18.860027Z","iopub.status.idle":"2021-08-15T13:24:18.943296Z","shell.execute_reply.started":"2021-08-15T13:24:18.859997Z","shell.execute_reply":"2021-08-15T13:24:18.942164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:21.797605Z","iopub.execute_input":"2021-08-15T13:24:21.797998Z","iopub.status.idle":"2021-08-15T13:24:21.868588Z","shell.execute_reply.started":"2021-08-15T13:24:21.797967Z","shell.execute_reply":"2021-08-15T13:24:21.867543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:27.180491Z","iopub.execute_input":"2021-08-15T13:24:27.180868Z","iopub.status.idle":"2021-08-15T13:24:27.188845Z","shell.execute_reply.started":"2021-08-15T13:24:27.180839Z","shell.execute_reply":"2021-08-15T13:24:27.187692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:29.569485Z","iopub.execute_input":"2021-08-15T13:24:29.569894Z","iopub.status.idle":"2021-08-15T13:24:29.576164Z","shell.execute_reply.started":"2021-08-15T13:24:29.569853Z","shell.execute_reply":"2021-08-15T13:24:29.575052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:31.804052Z","iopub.execute_input":"2021-08-15T13:24:31.804409Z","iopub.status.idle":"2021-08-15T13:24:31.840278Z","shell.execute_reply.started":"2021-08-15T13:24:31.804381Z","shell.execute_reply":"2021-08-15T13:24:31.839117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = [train_data, test_data]\nfor df in dfs:\n    temp = df.isnull().sum()\n    print(temp.loc[temp!=0], '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:33:40.719688Z","iopub.execute_input":"2021-08-15T13:33:40.720198Z","iopub.status.idle":"2021-08-15T13:33:40.748076Z","shell.execute_reply.started":"2021-08-15T13:33:40.720166Z","shell.execute_reply":"2021-08-15T13:33:40.746433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:24:43.262645Z","iopub.execute_input":"2021-08-15T13:24:43.263045Z","iopub.status.idle":"2021-08-15T13:24:43.293519Z","shell.execute_reply.started":"2021-08-15T13:24:43.263012Z","shell.execute_reply":"2021-08-15T13:24:43.292486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['LT_Salesprice']=np.log1p(train_data['SalePrice'])\nplt.hist(train_data['LT_Salesprice'],color = 'black')\nplt.show()\ntrain_data['LT_Salesprice'].skew()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T13:25:25.851926Z","iopub.execute_input":"2021-08-15T13:25:25.852305Z","iopub.status.idle":"2021-08-15T13:25:26.032026Z","shell.execute_reply.started":"2021-08-15T13:25:25.85227Z","shell.execute_reply":"2021-08-15T13:25:26.030985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets explore the correlations in our data set \nplt.figure(figsize=(20,20))\nsns.heatmap(train_data.corr())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Cleaning**","metadata":{}},{"cell_type":"code","source":"def data_cleaning(df):\n    \n\n\n    #Handling Null Values\n    df['MSZoning'].fillna(value = df['MSZoning'].mode()[0],inplace=True)\n    df.drop(['Alley','FireplaceQu','PoolQC','MiscFeature','Fence'], axis = 'columns',inplace = True)\n    df['LotFrontage'].fillna(df['LotFrontage'].dropna().mean(),inplace = True)\n    \n    for Bsmt in ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1',\n                 'BsmtFinType2','BsmtFinSF1','BsmtUnfSF','BsmtFinSF2','BsmtFullBath','BsmtHalfBath','TotalBsmtSF'] :\n        df[Bsmt].fillna((df[Bsmt].mode()[0]),inplace=True)\n       \n    for garage in ['GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond','GarageCars','GarageArea']:\n        df[garage].fillna((df[garage].mode()[0]),inplace=True)   \n    \n    for other in ['SaleType','Functional','KitchenQual',\n                  'Electrical','MasVnrType','Exterior1st','Exterior2nd','Utilities','MasVnrArea']:\n        df[other].fillna((df[other].mode()[0]),inplace=True)  \n    \n    # print(df.isnull().sum())\n    \n    \n    # List of numerical variables\n    numerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n    print('Number of numerical variables: ', len(numerical_features))\n    \n    # Visualise the numerical variables\n    df[numerical_features].head()\n    \n    #Some Features aren't numerical as well as categorical.So we need to make few changes in it.\n    year_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\n    year_feature\n    df.groupby('YrSold')['SalePrice'].median().plot()\n    plt.show()\n    \n    #Numerical features are of two types - Discrete & Continuos\n    discrete_feature = [feature for feature in numerical_features if len(df[feature].unique())<25 and feature not in year_feature+['id']]\n      \n    continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature+year_feature+['Id']]\n    \n    for feature in continuous_feature :\n        data = df.copy()\n        if 0 in data[feature].unique() :\n            pass\n        else:\n            data[feature] = np.log(data[feature])\n            data['SalePrice'] = np.log(data['SalePrice'])\n            plt.scatter(data[feature],data['SalePrice'])\n            plt.xlabel(feature)\n            plt.ylabel('Salesprice')\n            plt.show()\n            \n    #Outliers\n    #If u have lots of outliers replace nan with mode or median\n    for feature in continuous_feature :\n        data = df.copy()\n        if 0 in data[feature].unique() :\n            pass\n        else:\n            data[feature] = np.log(data[feature])\n            data.boxplot(column=feature)\n            plt.ylabel(feature)\n            plt.title(feature)\n            plt.show()\n            \n    #Changing the years column to numerical data        \n    for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n        df[feature]=df['YrSold']-df[feature]\n        \n    #Categorical Features\n    categorical_features=[feature for feature in df.columns if df[feature].dtypes=='O']\n    len(categorical_features)  \n    for feature in categorical_features:\n        temp=df.groupby(feature)['SalePrice'].count()/len(df)\n        temp_df=temp[temp>0.01].index\n        df[feature]=np.where(df[feature].isin(temp_df),df[feature],'Rare_var')\n    df.shape    \n    \n    for features in categorical_features:\n        dummies = pd.get_dummies(df[features])\n        merged = pd.concat([df,dummies],axis = 'columns')\n        df = merged.copy()\n    \n    for feature in categorical_features:\n        df.drop(feature, axis = 'columns',inplace = True)\n        \n    df.drop('LT_Salesprice', axis = 'columns',inplace = True) \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Merging Train & Test Data**","metadata":{}},{"cell_type":"code","source":"Dataset = pd.concat([train_data,test_data])\nclean_data = data_cleaning(Dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Splitting the Merged data into train and test data as before**","metadata":{}},{"cell_type":"code","source":"clean_test = clean_data.iloc[1460:,:]\nclean_test.to_csv('CleanTestData.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train = clean_data.iloc[:1460,:]\nclean_train.to_csv('CleanTrainData.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = clean_train.drop('SalePrice',axis = 'columns')\ny_train = clean_train.SalePrice\nX_test = clean_test.drop('SalePrice',axis = 'columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RandomForestRegressor**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators = 25)\n# scaler.inverse_transform(X_test)\nmodel.fit(X_train,y_train)\ny_test = model.predict(X_test)\ny_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Exporting Predicted Values**","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame(columns=['Id', 'SalePrice'])\nsubmission['Id'] = X_test['Id']\nsubmission['SalePrice'] = y_test\n\nsubmission.to_csv('MySubmission.csv', index=False)\nprint(\"submission succesfull\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}