{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-06T08:51:57.452965Z","iopub.execute_input":"2022-03-06T08:51:57.453402Z","iopub.status.idle":"2022-03-06T08:51:58.421371Z","shell.execute_reply.started":"2022-03-06T08:51:57.453275Z","shell.execute_reply":"2022-03-06T08:51:58.42045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the training dataset to do the EDA","metadata":{}},{"cell_type":"code","source":"train_dataset = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:51:58.423384Z","iopub.execute_input":"2022-03-06T08:51:58.423689Z","iopub.status.idle":"2022-03-06T08:51:58.464282Z","shell.execute_reply.started":"2022-03-06T08:51:58.423648Z","shell.execute_reply":"2022-03-06T08:51:58.463662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Look at the training dataset","metadata":{}},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:51:58.465406Z","iopub.execute_input":"2022-03-06T08:51:58.46611Z","iopub.status.idle":"2022-03-06T08:51:58.505276Z","shell.execute_reply.started":"2022-03-06T08:51:58.466076Z","shell.execute_reply":"2022-03-06T08:51:58.504251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now since you got the idea, its better to look at what the data contains overall","metadata":{}},{"cell_type":"code","source":"train_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:51:58.50678Z","iopub.execute_input":"2022-03-06T08:51:58.507269Z","iopub.status.idle":"2022-03-06T08:51:58.540477Z","shell.execute_reply.started":"2022-03-06T08:51:58.507224Z","shell.execute_reply":"2022-03-06T08:51:58.539746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are in total 1460 entries that means 1460 rows and 81 columns.\n- We can also see that some columns are integer, some are float and some are object that means categories","metadata":{}},{"cell_type":"markdown","source":"#### The objective of the assignment is to find the SalePrice for a dataset.\n- Its better to check for the saleprice column and get some more insight, like what's the minimum price, maximum price ","metadata":{"execution":{"iopub.status.busy":"2022-03-04T07:58:40.811188Z","iopub.execute_input":"2022-03-04T07:58:40.811961Z","iopub.status.idle":"2022-03-04T07:58:40.854166Z","shell.execute_reply.started":"2022-03-04T07:58:40.811917Z","shell.execute_reply":"2022-03-04T07:58:40.8533Z"}}},{"cell_type":"code","source":"train_dataset.get(\"SalePrice\").describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:51:58.54235Z","iopub.execute_input":"2022-03-06T08:51:58.542583Z","iopub.status.idle":"2022-03-06T08:51:58.552605Z","shell.execute_reply.started":"2022-03-06T08:51:58.542556Z","shell.execute_reply":"2022-03-06T08:51:58.551935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(16, 16))\nsns.distplot(train_dataset.get(\"SalePrice\"), kde=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:51:58.553861Z","iopub.execute_input":"2022-03-06T08:51:58.554229Z","iopub.status.idle":"2022-03-06T08:51:58.895092Z","shell.execute_reply.started":"2022-03-06T08:51:58.554188Z","shell.execute_reply":"2022-03-06T08:51:58.894086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now lets look at the correlation between different features of the dataset","metadata":{}},{"cell_type":"code","source":"corrmat = train_dataset.corr()\nf, ax = plt.subplots(figsize=(16, 16))\nsns.heatmap(corrmat, vmax=.8, square=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:51:58.896426Z","iopub.execute_input":"2022-03-06T08:51:58.897048Z","iopub.status.idle":"2022-03-06T08:51:59.901562Z","shell.execute_reply.started":"2022-03-06T08:51:58.897009Z","shell.execute_reply":"2022-03-06T08:51:59.90086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Its hard to find features that are most correlated to saleprice\n\n# Lets find top 10 features that best affects SalePrice and plot the heatmap for it","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,16))\ncolumns = corrmat.nlargest(10, 'SalePrice')['SalePrice'].index\ncorrelation_matrix = np.corrcoef(train_dataset[columns].values.T)\nsns.set(font_scale=1.25)\nheat_map = sns.heatmap(correlation_matrix, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=columns.values, xticklabels=columns.values)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:51:59.902564Z","iopub.execute_input":"2022-03-06T08:51:59.903367Z","iopub.status.idle":"2022-03-06T08:52:00.61345Z","shell.execute_reply.started":"2022-03-06T08:51:59.903295Z","shell.execute_reply":"2022-03-06T08:52:00.612818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Taking care of missing data\n### Now since we got the most features, lets try to look deeper into the data and find other features that may affect the SalePrice\n#### There may also be some features that may not affect the SalePrice due to less data or some other data discrepancy\n\n### - The best way to find out is taking care of the missing data","metadata":{}},{"cell_type":"code","source":"# Taking care of missing data\n\n# First find out all the columns that have missing data and arrange in descending order\ntotal = train_dataset.isna().sum().sort_values(ascending=False)\n\n# concatenate this data into dataframe\nmissing_data = pd.concat([total], axis=1, keys=[\"Total\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.614493Z","iopub.execute_input":"2022-03-06T08:52:00.615124Z","iopub.status.idle":"2022-03-06T08:52:00.625336Z","shell.execute_reply.started":"2022-03-06T08:52:00.615091Z","shell.execute_reply":"2022-03-06T08:52:00.624354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets view the columns that have the most missing data","metadata":{}},{"cell_type":"code","source":"missing_data.head(30)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.62664Z","iopub.execute_input":"2022-03-06T08:52:00.627138Z","iopub.status.idle":"2022-03-06T08:52:00.643515Z","shell.execute_reply.started":"2022-03-06T08:52:00.627103Z","shell.execute_reply":"2022-03-06T08:52:00.642715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## There are three options to deal with the missing data\n- Delete the columns\n- Fill the missing data with mean or mode\n- Delete only the row\nSince columns like `PoolQC`, `MiscFeature`, `Alley` etc. have more missing data we can drop it.\nI personally chose to delete all the columns which has missing data more than 1.\nFor `Electrical` feature, let's drop the row for that index","metadata":{}},{"cell_type":"code","source":"# dropping the columns where missing data is more than 1\ntrain_dataset = train_dataset.drop((missing_data[missing_data.get(\"Total\") > 1]).index, 1)\n\n# Drop the row entry\ntrain_dataset = train_dataset.drop(train_dataset.loc[train_dataset.get(\"Electrical\").isna()].index)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.644815Z","iopub.execute_input":"2022-03-06T08:52:00.645111Z","iopub.status.idle":"2022-03-06T08:52:00.659072Z","shell.execute_reply.started":"2022-03-06T08:52:00.645072Z","shell.execute_reply":"2022-03-06T08:52:00.658076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check if there is any missing data remaining","metadata":{}},{"cell_type":"code","source":"train_dataset.isna().sum().max()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.660266Z","iopub.execute_input":"2022-03-06T08:52:00.660636Z","iopub.status.idle":"2022-03-06T08:52:00.672324Z","shell.execute_reply.started":"2022-03-06T08:52:00.660605Z","shell.execute_reply":"2022-03-06T08:52:00.671332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Look at the shape of the training data after removing the columns","metadata":{}},{"cell_type":"code","source":"train_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.673509Z","iopub.execute_input":"2022-03-06T08:52:00.674296Z","iopub.status.idle":"2022-03-06T08:52:00.679358Z","shell.execute_reply.started":"2022-03-06T08:52:00.674255Z","shell.execute_reply":"2022-03-06T08:52:00.678818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The columns has reduced from 81 to 63","metadata":{}},{"cell_type":"markdown","source":"### Taking care of the categorical data\n#### Since we cannot measure categorical variables it makes sense to convert it into numbers to keep track or measure them\n# Encoding the categorical variables","metadata":{}},{"cell_type":"code","source":"# Encoding the categorical variables with one hot encoding\n\n# First getting all the columns with categories\ncategories = list(train_dataset.select_dtypes([\"object\"]))\n\n# Applying one hot encoding \nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categories)], remainder='passthrough')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.682631Z","iopub.execute_input":"2022-03-06T08:52:00.683378Z","iopub.status.idle":"2022-03-06T08:52:00.837221Z","shell.execute_reply.started":"2022-03-06T08:52:00.683335Z","shell.execute_reply":"2022-03-06T08:52:00.836276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_dataset.drop(['Id', 'SalePrice'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.838513Z","iopub.execute_input":"2022-03-06T08:52:00.838846Z","iopub.status.idle":"2022-03-06T08:52:00.846141Z","shell.execute_reply.started":"2022-03-06T08:52:00.838805Z","shell.execute_reply":"2022-03-06T08:52:00.84527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.847057Z","iopub.execute_input":"2022-03-06T08:52:00.847908Z","iopub.status.idle":"2022-03-06T08:52:00.879427Z","shell.execute_reply.started":"2022-03-06T08:52:00.847859Z","shell.execute_reply":"2022-03-06T08:52:00.878706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It should be noted that test dataset and the train dataset should have same number of columns to transform the test data ","metadata":{}},{"cell_type":"code","source":"print(X.shape)\ntest_dataset = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\ntest_dataset = test_dataset.drop((missing_data[missing_data.get(\"Total\") > 1]).index, 1)\nprint(test_dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.880503Z","iopub.execute_input":"2022-03-06T08:52:00.880706Z","iopub.status.idle":"2022-03-06T08:52:00.915599Z","shell.execute_reply.started":"2022-03-06T08:52:00.880681Z","shell.execute_reply":"2022-03-06T08:52:00.914699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = ct.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.916952Z","iopub.execute_input":"2022-03-06T08:52:00.917159Z","iopub.status.idle":"2022-03-06T08:52:00.947575Z","shell.execute_reply.started":"2022-03-06T08:52:00.917133Z","shell.execute_reply":"2022-03-06T08:52:00.946954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.94848Z","iopub.execute_input":"2022-03-06T08:52:00.949263Z","iopub.status.idle":"2022-03-06T08:52:00.955557Z","shell.execute_reply.started":"2022-03-06T08:52:00.949216Z","shell.execute_reply":"2022-03-06T08:52:00.954513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_dataset.drop([\"Id\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.957081Z","iopub.execute_input":"2022-03-06T08:52:00.957431Z","iopub.status.idle":"2022-03-06T08:52:00.967674Z","shell.execute_reply.started":"2022-03-06T08:52:00.957402Z","shell.execute_reply":"2022-03-06T08:52:00.966964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.970534Z","iopub.execute_input":"2022-03-06T08:52:00.971067Z","iopub.status.idle":"2022-03-06T08:52:00.991392Z","shell.execute_reply.started":"2022-03-06T08:52:00.971025Z","shell.execute_reply":"2022-03-06T08:52:00.990722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Taking care of missing data in the test dataset \n### - If we remove the columns according to missing data inside the test dataset then there may occur a situation where the shape of dataset may change and so we will not be able to apply encoding on the dataset\n#### To tackle this situation we will fill the missing data with mean and mode\n- Mean will be for integer or float datatypes and Mode will be for categorical variables","metadata":{}},{"cell_type":"code","source":"# Looping through all the missing data columns\nfor i in X_test.isna().columns:\n    # Checking if the datatype is not an object and replacing it with mean value\n    if X_test.dtypes[i] != \"object\":\n        X_test[i] = X_test[i].fillna(X_test[i].mean())\n    else:\n        X_test[i] = X_test[i].fillna(X_test[i].mode()[0])\nX_test.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:00.992412Z","iopub.execute_input":"2022-03-06T08:52:00.992717Z","iopub.status.idle":"2022-03-06T08:52:01.036774Z","shell.execute_reply.started":"2022-03-06T08:52:00.992691Z","shell.execute_reply":"2022-03-06T08:52:01.036085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check if there is any missing value inside X_test","metadata":{}},{"cell_type":"code","source":"X_test.isna().sum().max()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.037816Z","iopub.execute_input":"2022-03-06T08:52:01.038142Z","iopub.status.idle":"2022-03-06T08:52:01.046123Z","shell.execute_reply.started":"2022-03-06T08:52:01.038115Z","shell.execute_reply":"2022-03-06T08:52:01.045416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Now since there is no missing value we can transform the data according to the encoding that we applied for the training dataset","metadata":{}},{"cell_type":"code","source":"X_test = ct.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.047178Z","iopub.execute_input":"2022-03-06T08:52:01.047486Z","iopub.status.idle":"2022-03-06T08:52:01.080662Z","shell.execute_reply.started":"2022-03-06T08:52:01.04746Z","shell.execute_reply":"2022-03-06T08:52:01.079505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.081787Z","iopub.execute_input":"2022-03-06T08:52:01.082009Z","iopub.status.idle":"2022-03-06T08:52:01.087794Z","shell.execute_reply.started":"2022-03-06T08:52:01.081983Z","shell.execute_reply":"2022-03-06T08:52:01.086928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that shape of X and X_test is same. It may happen that test dataset may not have all the categorical values that appears in train dataset. In such situations concatenate training and test data and apply encoding so that the shape of columns remain same","metadata":{}},{"cell_type":"code","source":"# This is the dependent variable from training data which we have to predict\ny = train_dataset.SalePrice","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.08896Z","iopub.execute_input":"2022-03-06T08:52:01.089179Z","iopub.status.idle":"2022-03-06T08:52:01.099384Z","shell.execute_reply.started":"2022-03-06T08:52:01.089151Z","shell.execute_reply":"2022-03-06T08:52:01.0987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split the training data into training and validating dataset to train the model. Later depending on the score we can apply same model on the test dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.100552Z","iopub.execute_input":"2022-03-06T08:52:01.100979Z","iopub.status.idle":"2022-03-06T08:52:01.158044Z","shell.execute_reply.started":"2022-03-06T08:52:01.100945Z","shell.execute_reply":"2022-03-06T08:52:01.157316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Linear Regression Model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.159321Z","iopub.execute_input":"2022-03-06T08:52:01.159705Z","iopub.status.idle":"2022-03-06T08:52:01.517351Z","shell.execute_reply.started":"2022-03-06T08:52:01.159674Z","shell.execute_reply":"2022-03-06T08:52:01.516414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This prediction values are on the training dataset\ny_pred = regressor.predict(X_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.518934Z","iopub.execute_input":"2022-03-06T08:52:01.51925Z","iopub.status.idle":"2022-03-06T08:52:01.523364Z","shell.execute_reply.started":"2022-03-06T08:52:01.519208Z","shell.execute_reply":"2022-03-06T08:52:01.522818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Score of the model\nregressor.score(X_val, y_val)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.524363Z","iopub.execute_input":"2022-03-06T08:52:01.525127Z","iopub.status.idle":"2022-03-06T08:52:01.53737Z","shell.execute_reply.started":"2022-03-06T08:52:01.52509Z","shell.execute_reply":"2022-03-06T08:52:01.536813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the RMSE root mean squared error\nfrom sklearn.metrics import mean_squared_error\nprint(f\"Mean square error: {mean_squared_error(np.log2(y_val), np.log2(y_pred))}\")\nprint(f\"Root mean square error: {mean_squared_error(np.log2(y_val), np.log2(y_pred), squared=False)}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.538323Z","iopub.execute_input":"2022-03-06T08:52:01.538844Z","iopub.status.idle":"2022-03-06T08:52:01.55068Z","shell.execute_reply.started":"2022-03-06T08:52:01.538809Z","shell.execute_reply":"2022-03-06T08:52:01.549334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying the same model on test dataset and predicting the values","metadata":{}},{"cell_type":"code","source":"test_preds = regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.552375Z","iopub.execute_input":"2022-03-06T08:52:01.552951Z","iopub.status.idle":"2022-03-06T08:52:01.563097Z","shell.execute_reply.started":"2022-03-06T08:52:01.552908Z","shell.execute_reply":"2022-03-06T08:52:01.56219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.564782Z","iopub.execute_input":"2022-03-06T08:52:01.565376Z","iopub.status.idle":"2022-03-06T08:52:01.575116Z","shell.execute_reply.started":"2022-03-06T08:52:01.565333Z","shell.execute_reply":"2022-03-06T08:52:01.574493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset.Id.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.575942Z","iopub.execute_input":"2022-03-06T08:52:01.576627Z","iopub.status.idle":"2022-03-06T08:52:01.588167Z","shell.execute_reply.started":"2022-03-06T08:52:01.576595Z","shell.execute_reply":"2022-03-06T08:52:01.587327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Notice that the shape of the rows of the test dataset before modifying data is same as rows after taking care of the missing data of test dataset","metadata":{}},{"cell_type":"markdown","source":"# Saving the dataset into csv file for submission","metadata":{}},{"cell_type":"code","source":"# output = pd.DataFrame({'Id': test_dataset.Id,\n#                       'SalePrice': test_preds})\n# output.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.58958Z","iopub.execute_input":"2022-03-06T08:52:01.589817Z","iopub.status.idle":"2022-03-06T08:52:01.597582Z","shell.execute_reply.started":"2022-03-06T08:52:01.589791Z","shell.execute_reply":"2022-03-06T08:52:01.596799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### - This is the basic predictions of house prices using basic regression technique. Yet to perform Decision Tree Random Forest, Ridge, Lasso and Elastic Net","metadata":{}},{"cell_type":"markdown","source":"#### Linear Regression Scored 0.45","metadata":{}},{"cell_type":"markdown","source":"# Training DecisionTreeRegressor model on the whole dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndregressor = DecisionTreeRegressor(max_depth=10, random_state=142)\ndregressor.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.598569Z","iopub.execute_input":"2022-03-06T08:52:01.598991Z","iopub.status.idle":"2022-03-06T08:52:01.741689Z","shell.execute_reply.started":"2022-03-06T08:52:01.598958Z","shell.execute_reply":"2022-03-06T08:52:01.741101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = dregressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.742666Z","iopub.execute_input":"2022-03-06T08:52:01.743045Z","iopub.status.idle":"2022-03-06T08:52:01.748318Z","shell.execute_reply.started":"2022-03-06T08:52:01.743018Z","shell.execute_reply":"2022-03-06T08:52:01.747642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dregressor.score(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.749528Z","iopub.execute_input":"2022-03-06T08:52:01.749885Z","iopub.status.idle":"2022-03-06T08:52:01.761676Z","shell.execute_reply.started":"2022-03-06T08:52:01.749856Z","shell.execute_reply":"2022-03-06T08:52:01.761035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output = pd.DataFrame({'Id': test_dataset.Id,\n#                       'SalePrice': y_preds})\n# output.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.762635Z","iopub.execute_input":"2022-03-06T08:52:01.763419Z","iopub.status.idle":"2022-03-06T08:52:01.771351Z","shell.execute_reply.started":"2022-03-06T08:52:01.763385Z","shell.execute_reply":"2022-03-06T08:52:01.770469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Before the max_depth was 2 and it changed the score from 0.45 to 0.28\n- Now again when max_depth was changed to 10 then the score changed from 0.28 to 0.20037","metadata":{}},{"cell_type":"markdown","source":"# Ensemble Methods","metadata":{}},{"cell_type":"markdown","source":"# Applying Random Forest Regression on dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_regressor = RandomForestRegressor(max_depth=15, n_estimators=100, random_state=42)\nrf_regressor.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:01.772632Z","iopub.execute_input":"2022-03-06T08:52:01.772856Z","iopub.status.idle":"2022-03-06T08:52:10.471533Z","shell.execute_reply.started":"2022-03-06T08:52:01.772831Z","shell.execute_reply":"2022-03-06T08:52:10.470715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = rf_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:10.476694Z","iopub.execute_input":"2022-03-06T08:52:10.477353Z","iopub.status.idle":"2022-03-06T08:52:10.523503Z","shell.execute_reply.started":"2022-03-06T08:52:10.477308Z","shell.execute_reply":"2022-03-06T08:52:10.522606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- RandomForestRegressor score was 0.153 when n_estimators were changed the score changed to 0.15065\n- n_estimators = 100 and max_depth=15 changed the score to 0.14542","metadata":{}},{"cell_type":"markdown","source":"## Applying Boosting Techniques like Gradient Boosting and XGBoost","metadata":{}},{"cell_type":"markdown","source":"# Gradient Boosting\n- Applying it from hands on machine learning book","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbrt = GradientBoostingRegressor(max_depth=15, n_estimators=100, learning_rate=1.0)\ngbrt.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:10.524632Z","iopub.execute_input":"2022-03-06T08:52:10.524893Z","iopub.status.idle":"2022-03-06T08:52:14.296605Z","shell.execute_reply.started":"2022-03-06T08:52:10.524862Z","shell.execute_reply":"2022-03-06T08:52:14.295591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = gbrt.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:14.298106Z","iopub.execute_input":"2022-03-06T08:52:14.298417Z","iopub.status.idle":"2022-03-06T08:52:14.325997Z","shell.execute_reply.started":"2022-03-06T08:52:14.298369Z","shell.execute_reply":"2022-03-06T08:52:14.325233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- This is not better than random forest regressor","metadata":{}},{"cell_type":"markdown","source":"# Applying XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:14.327769Z","iopub.execute_input":"2022-03-06T08:52:14.328008Z","iopub.status.idle":"2022-03-06T08:52:14.433307Z","shell.execute_reply.started":"2022-03-06T08:52:14.327975Z","shell.execute_reply":"2022-03-06T08:52:14.432515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the model on dataset","metadata":{}},{"cell_type":"code","source":"xgb_reg = xgboost.XGBRegressor()\nxgb_reg.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:14.434539Z","iopub.execute_input":"2022-03-06T08:52:14.434802Z","iopub.status.idle":"2022-03-06T08:52:15.200207Z","shell.execute_reply.started":"2022-03-06T08:52:14.434748Z","shell.execute_reply":"2022-03-06T08:52:15.199275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = xgb_reg.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:15.201205Z","iopub.execute_input":"2022-03-06T08:52:15.201409Z","iopub.status.idle":"2022-03-06T08:52:15.214931Z","shell.execute_reply.started":"2022-03-06T08:52:15.201384Z","shell.execute_reply":"2022-03-06T08:52:15.214261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The xgboost gives better score than any other model above.","metadata":{}},{"cell_type":"markdown","source":"# Applying regularized Linear models\n- Ridge\n- Lasso\n- ElasticNet\nIdea behind this is to constraint the weights of the model","metadata":{}},{"cell_type":"markdown","source":"# Ridge Regression","metadata":{}},{"cell_type":"markdown","source":"### Making a linear ridge regressor model","metadata":{}},{"cell_type":"code","source":"# from sklearn.linear_model import Ridge\n# ridge_reg = Ridge(alpha=1, solver=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:53:35.481424Z","iopub.execute_input":"2022-03-06T08:53:35.481715Z","iopub.status.idle":"2022-03-06T08:53:35.4858Z","shell.execute_reply.started":"2022-03-06T08:53:35.481682Z","shell.execute_reply":"2022-03-06T08:53:35.485176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the data ","metadata":{}},{"cell_type":"code","source":"# ridge_reg.fit(X, y)\n# ridge_reg.score(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:16:23.277703Z","iopub.execute_input":"2022-03-06T09:16:23.278533Z","iopub.status.idle":"2022-03-06T09:16:23.292716Z","shell.execute_reply.started":"2022-03-06T09:16:23.278496Z","shell.execute_reply":"2022-03-06T09:16:23.292122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting the data","metadata":{}},{"cell_type":"code","source":"# y_preds = ridge_reg.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:57:31.23247Z","iopub.execute_input":"2022-03-06T08:57:31.232735Z","iopub.status.idle":"2022-03-06T08:57:31.237649Z","shell.execute_reply.started":"2022-03-06T08:57:31.232704Z","shell.execute_reply":"2022-03-06T08:57:31.23704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lasso Regression\n- Benefit is that it will try to completely eliminate the least important features","metadata":{}},{"cell_type":"code","source":"# from sklearn.linear_model import Lasso\n# # alpha_values = np.arange(0, 1, 0.1).tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:07:15.588342Z","iopub.execute_input":"2022-03-06T09:07:15.588893Z","iopub.status.idle":"2022-03-06T09:07:15.593674Z","shell.execute_reply.started":"2022-03-06T09:07:15.588858Z","shell.execute_reply":"2022-03-06T09:07:15.593108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finding the best alpha values","metadata":{}},{"cell_type":"code","source":"# Apply when you want to find the best max_score\n# max_score = 0\n# best_alpha_value = 0\n# for i in alpha_values:\n#     lasso_reg = Lasso(alpha=i)\n#     lasso_reg.fit(X_train, y_train)\n#     current_score = lasso_reg.score(X_val, y_val)\n#     print(f\"Score and alpha value: {current_score} ---- {i}\")\n#     if current_score > max_score:\n#         max_score = current_score\n#         best_alpha_value = i\n# print(max_score, best_alpha_value)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:11:09.350565Z","iopub.execute_input":"2022-03-06T09:11:09.351436Z","iopub.status.idle":"2022-03-06T09:11:19.301899Z","shell.execute_reply.started":"2022-03-06T09:11:09.351388Z","shell.execute_reply":"2022-03-06T09:11:19.300243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# alpha_space = np.linspace(0, 1, 50)\n# params_grid = {'alpha':alpha_space}\n# lasso = Lasso()\n\n# lasso_cv = GridSearchCV(lasso, params_grid, cv=10, scoring = 'neg_root_mean_squared_error')\n# lasso_cv.fit(X_train,y_train)\n# lasso_cv.score(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:37:17.30189Z","iopub.execute_input":"2022-03-06T09:37:17.302188Z","iopub.status.idle":"2022-03-06T09:37:17.306168Z","shell.execute_reply.started":"2022-03-06T09:37:17.302158Z","shell.execute_reply":"2022-03-06T09:37:17.305365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_preds = lasso_cv.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:25:59.980433Z","iopub.status.idle":"2022-03-06T09:25:59.981339Z","shell.execute_reply.started":"2022-03-06T09:25:59.98105Z","shell.execute_reply":"2022-03-06T09:25:59.981082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ElasticNet Regressor","metadata":{}},{"cell_type":"code","source":"# Uncomment when you want to apply elastic net strategy\n# from sklearn.linear_model import  ElasticNet\n# elastic_net_regressor = ElasticNet(alpha=0.1, l1_ratio=0.5)\n# elastic_net_regressor.fit(X_train, y_train)\n# y_preds = elastic_net_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:36:38.933735Z","iopub.execute_input":"2022-03-06T09:36:38.934033Z","iopub.status.idle":"2022-03-06T09:36:39.968476Z","shell.execute_reply.started":"2022-03-06T09:36:38.934003Z","shell.execute_reply":"2022-03-06T09:36:39.967685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'Id': test_dataset.Id,\n                      'SalePrice': y_preds})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:52:15.334571Z","iopub.status.idle":"2022-03-06T08:52:15.334944Z","shell.execute_reply.started":"2022-03-06T08:52:15.334731Z","shell.execute_reply":"2022-03-06T08:52:15.334752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Till now the best approach was using xgboost.\n- We applied almost all regressor models\n#### - It is worthy to note that to improve the accuracy of our model we can approach the problem a little differently while doing Data Preprocessing and feature engineering and then again apply the same model and see which one is better. \n#### Another approach can be applying the feature engineering and then training the data on a blend of model\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}