{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"------------------------------------------\n------------------------------------------\n\n# <p style=\"background-color:#CCE3F2; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 15px 50px;\">Object Oriented Programming (OOP) approach for <br>Data Science problems.</p>\n\n\n# <p style=\"background-color:gray; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 10px 100px; color:black; hight:max\"> Upvote my work if you found it useful.üéØ </p>\n\n------------------------------------------\n------------------------------------------\n","metadata":{"papermill":{"duration":0.03438,"end_time":"2021-07-27T22:14:20.818237","exception":false,"start_time":"2021-07-27T22:14:20.783857","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<p style=\"background-color:#CCE3F2; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 10px 500px;\"><b>Introduction\n    </b>\n</p>\n<b>The objective of this project is to apply Object Oriented Programming(OOP) approach for Data Science problems.<br>\nObject oriented programming is largely based on personal experience and is open to development. For this reason, code design can be improved according to the comments to be made for the kernel. Comments and criticisms will provide a better code design.<br>\nThis project consists of five classes:</b>\n<ul>\n    <li>Class I   : <a href=\"#hpopp_class\"><b>HouseObjectOriented Class.</b></a></li>\n    <ul>\n        <li>1) Adds the data to the object.\n        <li>2) Concats the data in one DataFrame.\n        <li>3) Shows information about the data.\n        <li>4) Preprocess the data before Ml part.\n        <li>5) Adds the data after Preprocessing for the ML part.</li>\n    </ul><br>\n    <li>Class II  : <a href=\"#info_class\"><b>Information Class.</b></a></li>\n    <ul>\n        <li>1) Calculates the missing values.\n        <li>2) Gets feature dtypes.\n        <li>3) Gets feature names.\n        <li>4) Gets shape of the data.\n        <li>5) Prints all of these information.</li>\n    </ul><br>\n    <li>Class III : <a href=\"#pre_process_class\"><b>Pre-processing Class.</b></a></li>\n    <ul>\n        <li>1) Drops the unwanted columns and rows.\n        <li>2) Fills the null values with (mean, meadian, zero,....etc).\n        <li>3) Applys feature engineering to the data like adding new columns, transforming columns,...etc.\n        <li>4) Encodes the data using label encoder to be able to apply ML algorithms.\n        <li>5) Converts your data to dummies values.\n        <li>6) Normalizes the data before ML.</li>\n    </ul><br>\n    <li>Class IV  : <a href=\"#processor_class\"><b>Preprocessor Class</b></a></li>\n    <ul>\n        <li>1) Applys the Pre_processing techniques and returns the new data.</li>\n    </ul><br>\n    <li>Class V   : <a href=\"#ml_class\"><b>ML Class</b></a></li>\n    <ul>\n        <li>1) Initializes the ML algorithms.\n        <li>2) Show the available ML algorithms.\n        <li>3) Applys Train-Test evaluation and shows the results.\n        <li>4) Applys Cross-Validation evaluation and shows the results.\n        <li>5) Visualizes the results of Train-Test and Cross-Validation evaluations.\n        <li>6) Find the best model and then fits it to the data.\n        <li>7) Show the Predictions in a DataFrame.\n        <li>8) Save the predictions to a csv file.</li>\n    </ul>\n</ul>\n<br>\n<p style=\"background-color:#CCE3F2; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 10px 100px;\"><a id=\"outlines\">Outlines : </a></p>\n<ul>\n    <li><a href=\"#1.0\"><b>Create HouseObjectOriented object</b></a>\n    <li><a href=\"#1.1\"><b>Adding our data</b></a>\n    <li><a href=\"#2.0\"><b>Display Information about the data</b></a>\n    <li><a href=\"#3.0\"><b>Pre-Process the data</b></a>\n    <li><a href=\"#2.1\"><b>Display Information about the data after Pre-Processing</b></a>\n    <li><a href=\"#4.0\"><b>Create a Machine Learning object</b></a>\n    <li><a href=\"#4.1\"><b>Show the available algorithms</b></a>\n    <li><a href=\"#4.2\"><b>Initialize the ML Regressors</b></a>\n    <li><a href=\"#4.3\"><b>Train-Test Validation</b></a>\n    <li><a href=\"#4.4\"><b>Visualize the results of train-test validation</b></a>\n    <li><a href=\"#4.5\"><b>Applying Cross-Validation</b></a>\n    <li><a href=\"#4.6\"><b>Visualize the results of Cross-Validation</b></a>\n    <li><a href=\"#4.7\"><b>Find the best model and fit it to the data</b></a>\n    <li><a href=\"#4.8\"><b>Predict and show the prediction</b></a>\n    <li><a href=\"#4.9\"><b>Save the predictions to a csv file</b></a></li>\n</ul>","metadata":{"papermill":{"duration":0.034354,"end_time":"2021-07-27T22:14:20.88527","exception":false,"start_time":"2021-07-27T22:14:20.850916","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<b><a href='https://www.kaggle.com/serkanpeldek/object-oriented-titanics'>Recommended Notebook</a>   ","metadata":{"papermill":{"duration":0.033176,"end_time":"2021-07-27T22:14:20.951443","exception":false,"start_time":"2021-07-27T22:14:20.918267","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:center; border-radius: 15px 50px;\">Importing necessary modules and librariesüìö</p>","metadata":{"papermill":{"duration":0.032791,"end_time":"2021-07-27T22:14:21.018011","exception":false,"start_time":"2021-07-27T22:14:20.98522","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#main libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport warnings\n\n#visualization libraries\nimport plotly \nimport plotly.graph_objs as go\nimport plotly.io as pio\nimport plotly.express as px\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks as cf\n\n#machine learning libraries:\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate, train_test_split, KFold, cross_val_score\nfrom sklearn.preprocessing  import StandardScaler, LabelEncoder, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport xgboost as xgb\n\n# You can go offline on demand by using\ncf.go_offline() \n\n# initiate notebook for offline plot\ninit_notebook_mode(connected=False)         \n\n# set some display options:\ncolors = px.colors.qualitative.Prism\npio.templates.default = \"plotly_white\"\n\n# see our files:\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"papermill":{"duration":5.319232,"end_time":"2021-07-27T22:14:26.370664","exception":false,"start_time":"2021-07-27T22:14:21.051432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:15.67226Z","iopub.execute_input":"2021-09-28T21:16:15.672635Z","iopub.status.idle":"2021-09-28T21:16:15.853006Z","shell.execute_reply.started":"2021-09-28T21:16:15.672601Z","shell.execute_reply":"2021-09-28T21:16:15.851897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\nprint(\"Warnings were ignored\")","metadata":{"papermill":{"duration":0.146625,"end_time":"2021-07-27T22:14:26.657113","exception":false,"start_time":"2021-07-27T22:14:26.510488","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:15.854736Z","iopub.execute_input":"2021-09-28T21:16:15.855121Z","iopub.status.idle":"2021-09-28T21:16:15.860559Z","shell.execute_reply.started":"2021-09-28T21:16:15.855084Z","shell.execute_reply":"2021-09-28T21:16:15.859657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:center; border-radius: 15px 50px;\">Creating our Classes üêç</p>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"info_class\"></a>\n<h1>Information Class</h1>","metadata":{"papermill":{"duration":0.135998,"end_time":"2021-07-27T22:14:26.927098","exception":false,"start_time":"2021-07-27T22:14:26.7911","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Information:\n    \"\"\"\n    This class shows some information about the dataset\n    \"\"\"\n    def __init__(self):\n        \n        print()\n        print('Information object is created')\n        print()\n        \n    def get_missing_values(self, data):\n        \"\"\"\n        This function finds the missing values in the dataset\n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n        The data you want to see information about\n        \n        Returns\n        ----------\n        A Pandas Series contains the missing values in descending order\n        \"\"\"\n        #get the sum of all missing values in the dataset\n        missing_values = data.isnull().sum()\n        #sorting the missing values in a pandas Series\n        missing_values = missing_values.sort_values(ascending=False)\n        \n        #returning the missing values Series\n        return missing_values\n    \n    def _info_(self, data):\n        \"\"\"\n        This function shows some information about the data like \n        Feature names,data type, number of missing values for each feature \n        and ten samples of each feature\n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n            The data you want to see information about\n        \n        Returns\n        ----------\n        Information about the DataFrame\n        \"\"\"\n        self.data=data\n        feature_dtypes=self.data.dtypes\n        self.missing_values=self.get_missing_values(self.data)\n        feature_names=self.missing_values.index.values\n        missing_values=self.missing_values.values\n        rows, columns=data.shape\n\n        print(\"=\" * 50)\n        print('====> This data contains {} rows and {} columns'.format(rows,columns))\n        print(\"=\" * 50)\n        print()\n        \n        print(\"{:13} {:13} {:30} {:15}\".format('Feature Name'.upper(),\n                                               'Data Format'.upper(),\n                                               'Null values(Num-Perc)'.upper(),\n                                               'Seven Samples'.upper()))\n        for feature_name, dtype, missing_value in zip(feature_names,feature_dtypes[feature_names],missing_values):\n            print(\"{:15} {:14} {:20}\".format(feature_name,\n                                             str(dtype), \n                                             str(missing_value) + ' - ' + \n                                             str(round(100*missing_value/sum(self.missing_values),3))+' %'), end=\"\")\n\n            for i in np.random.randint(0,len(data),7):\n                print(data[feature_name].iloc[i], end=\",\")\n            print()\n\n        print(\"=\"*50)","metadata":{"papermill":{"duration":0.158011,"end_time":"2021-07-27T22:14:27.221989","exception":false,"start_time":"2021-07-27T22:14:27.063978","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:15.862218Z","iopub.execute_input":"2021-09-28T21:16:15.862515Z","iopub.status.idle":"2021-09-28T21:16:15.87555Z","shell.execute_reply.started":"2021-09-28T21:16:15.862465Z","shell.execute_reply":"2021-09-28T21:16:15.874095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"pre_process_class\"></a>\n<h1>Data pre-processing Class</h1>","metadata":{"papermill":{"duration":0.134881,"end_time":"2021-07-27T22:14:27.490634","exception":false,"start_time":"2021-07-27T22:14:27.355753","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Pre_processing:\n    \"\"\"\n    This class prepares the data berfore applying ML\n    \"\"\"\n    def __init__(self):\n        \n        print()\n        print('pre-processing object is created')\n        print()        \n        \n    def drop(self, data, drop_strategies):\n        \"\"\"\n        This function is used to drop a column or row from the dataset.\n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n            The data you want to drop data from.\n        drop_strategies : A list of tuples, each tuple has the data to drop,\n        and the axis(0 or 1)\n        \n        Returns\n        ----------\n        A new dataset after dropping the unwanted data.\n        \"\"\"\n        \n        self.data=data\n        \n        for columns, ax in drop_strategies:\n            if len(columns)==1:\n                self.data=self.data.drop(labels=column, axis=ax)\n            else:\n                for column in columns:\n                    self.data=self.data.drop(labels=column, axis=ax)\n        return self.data\n\n    def fillna(self, ntrain, fill_strategies):       \n        \"\"\"\n        This function fills NA/NaN values in a specific column using a specified method(zero,mean,...)\n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n            The data you want to impute its missing values\n        fill_strategies : A dictionary, its keys represent the columns, \n        and the values represent the value to use to fill the Nulls.\n        \n        Returns\n        ----------\n        A new dataset without null values.\n        \"\"\"\n        def fill(column, fill_with):\n            \n                if str(fill_with).lower() in ['zero', 0]:\n                    self.data[column].fillna(0, inplace=True)\n                elif str(fill_with).lower()=='mode':\n                    self.data[column].fillna(self.data[column].mode()[0], inplace=True)\n                elif str(fill_with).lower()=='mean':\n                    self.data[column].fillna(self.data[column].mean(), inplace=True)\n                elif str(fill_with).lower()=='median':\n                    self.data[column].fillna(self.data[column].median(), inplace=True)\n                else:\n                    self.data[column].fillna(fill_with, inplace=True)\n\n                return self.data\n            \n        #LotFrontage: Linear feet of street connected to property\n        self.data['LotFrontage'] = self.data.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median())).values\n\n        # Meaning that NO Masonry veneer\n        self.data['MSZoning'] = self.data['MSZoning'].transform(lambda x: x.fillna(x.mode().values[0]))\n\n        #imputing columns according to its strategy\n        for columns, strategy in fill_strategies:\n            if len(columns)==1:\n                fill(columns[0], strategy)\n            else:\n                for column in columns:\n                    fill(column, strategy)\n\n        return self.data\n    \n    def feature_engineering(self):\n        \"\"\"\n        This function is used to apply some feature engineering on the data.\n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n            The data you want to apply feature engineering on.\n        \n        Returns\n        ----------\n        A new dataset with new columns and some additions.\n        \"\"\"\n        # creating new columns\n        self.data['TotalSF'] = self.data['TotalBsmtSF'] + self.data['1stFlrSF'] + self.data['2ndFlrSF']\n                \n        # Convert some columns from numeric to string\n        self.data[['YrSold','MSSubClass','MoSold','OverallCond']] = self.data[['YrSold','MSSubClass','MoSold','OverallCond']].astype(str)\n        \n        # Convert some columns from numeric to int\n        self.data[['BsmtHalfBath','BsmtFinSF1', 'BsmtFinSF2','BsmtFullBath','BsmtUnfSF','GarageCars','GarageArea']]\\\n        =self.data[['BsmtHalfBath','BsmtFinSF1', 'BsmtFinSF2','BsmtFullBath','BsmtUnfSF','GarageCars','GarageArea']].astype(int)\n\n        return self.data    \n   \n    def label_encoder(self, columns):\n        \"\"\"\n        This function is used to encode the data to categorical values to benefit from increasing or \n        decreasing to build the model    \n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n            The data you want to encode.\n        columns : columns to convert.\n        \n        Returns\n        ----------\n        A dataset without categorical data.\n        \"\"\"\n\n        # Convert all categorical collumns to numeric values\n        lbl = LabelEncoder() \n        \n        self.data[columns] = self.data[columns].apply(lambda x:lbl.fit_transform(x.astype(str)).astype(int))\n        \n        return self.data \n    \n    def get_dummies(self, columns):\n        \"\"\"\n        This function is used to convert the data to dummies values.\n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n            The data you want to convert.\n        \n        Returns\n        ----------\n        A dataset with dummies.\n        \"\"\"\n        \n        # convert our categorical columns to dummies\n        for col in columns:\n            dumm = pd.get_dummies(self.data[col], prefix = col, dtype=int)\n            self.data = pd.concat([self.data, dumm], axis=1)\n\n        self.data.drop(columns, axis=1, inplace=True)\n        \n        return self.data\n        \n    def norm_data(self, columns):\n        \"\"\"\n        This function is used to normalize the data.   \n        ...\n        Attributes\n        ----------\n        data : Pandas DataFrame\n            The data you want to normalize.\n        \n        Returns\n        ----------\n        A new normalized dataset.\n        \"\"\"\n        \n        # Normalize our numeric data\n        self.data[columns] = self.data[columns].apply(lambda x:np.log1p(x)) #Normalize the data with Logarithms\n        \n        return self.data      ","metadata":{"papermill":{"duration":0.162303,"end_time":"2021-07-27T22:14:27.787778","exception":false,"start_time":"2021-07-27T22:14:27.625475","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:15.982972Z","iopub.execute_input":"2021-09-28T21:16:15.983464Z","iopub.status.idle":"2021-09-28T21:16:16.00987Z","shell.execute_reply.started":"2021-09-28T21:16:15.983415Z","shell.execute_reply":"2021-09-28T21:16:16.008649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"# <h1>Processor Class</h1>\n<a id=\"processor_class\"></a>","metadata":{"papermill":{"duration":0.135022,"end_time":"2021-07-27T22:14:28.057664","exception":false,"start_time":"2021-07-27T22:14:27.922642","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Preprocessor:\n    \n    def __init__(self):\n        self.data=None\n        self._preprocessor=Pre_processing()\n\n    def _process(self, data, ntrain):\n\n        self.data=data\n        \n        self.ntrain=ntrain\n        \n        cols_drop=['Utilities', 'OverallQual','TotRmsAbvGrd']\n        \n        # Numeric columns\n        num_cols = ['LotFrontage','LotArea','YearBuilt','YearRemodAdd','MasVnrArea',\n                    'BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF', '1stFlrSF', '2ndFlrSF', \n                    'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath', \n                    'BedroomAbvGr','KitchenAbvGr','Fireplaces','GarageYrBlt','GarageCars','GarageArea', \n                    'WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal']\n\n        # Categorical columns\n        cat_cols = ['MSSubClass','MSZoning','Street','Alley','LotShape','LandContour','LotConfig','LandSlope', \n                    'Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl', \n                    'Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual', \n                    'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir', \n                    'Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish', \n                    'GarageQual','GarageCond','PavedDrive','PoolQC','Fence','MiscFeature','MoSold','SaleType', \n                    'SaleCondition','OverallCond', 'YrSold']\n        \n        drop_strategies=[(cols_drop,1)]\n\n        fill_strategies=[(['BsmtFinType2','BsmtQual','BsmtCond','ExterQual','ExterCond','MasVnrArea',\n                          'TotalBsmtSF','HeatingQC','BsmtHalfBath','BsmtFinSF1','BsmtFinSF2','GarageYrBlt',\n                          'BsmtFullBath','BsmtUnfSF','GarageCars','GarageArea','MasVnrArea'],0),\n                         (['FireplaceQu','GarageQual','GarageCond','BsmtFinType1','MasVnrType',\n                          'BsmtExposure','GarageFinish','PoolQC','Fence','LandSlope','GarageType',\n                          'LotShape','PavedDrive','Street','Alley','CentralAir','MiscFeature',\n                          'MSSubClass','OverallCond','YrSold','MoSold'],'NA'),\n                         (['Functional'],'Typ'), # Typical Functionality\n                         (['KitchenQual'],'TA'),\n                         (['LotFrontage'],'median'),\n                         (['MSZoning'],'mode'),\n                         (['SaleType','Exterior1st','Exterior2nd','SaleType'],'Oth'), #other\n                         (['Electrical'],'SBrkr')]  # Standard Circuit Breakers & Romex\n\n        #drop\n        self.data = self._preprocessor.drop(self.data, drop_strategies)\n        \n        #fill nulls\n        self.data = self._preprocessor.fillna(self.ntrain, fill_strategies)\n        \n        #feature engineering\n        self.data = self._preprocessor.feature_engineering()\n        \n        #label encoder\n        self.data = self._preprocessor.label_encoder(cat_cols)\n        \n        #normalizing\n#         self.data = self._preprocessor.norm_data(self.data, num_cols)\n        \n        #get dummies\n        self.data = self._preprocessor.get_dummies(cat_cols)\n        return self.data","metadata":{"papermill":{"duration":0.152772,"end_time":"2021-07-27T22:14:28.346008","exception":false,"start_time":"2021-07-27T22:14:28.193236","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:16.012298Z","iopub.execute_input":"2021-09-28T21:16:16.012734Z","iopub.status.idle":"2021-09-28T21:16:16.030775Z","shell.execute_reply.started":"2021-09-28T21:16:16.012701Z","shell.execute_reply":"2021-09-28T21:16:16.029587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<h1>Machine Learning Class</h1>\n<a id=\"ml_class\"></a>","metadata":{"papermill":{"duration":0.136796,"end_time":"2021-07-27T22:14:28.618505","exception":false,"start_time":"2021-07-27T22:14:28.481709","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ML: \n    def __init__(self, data, ytrain, testID, test_size, ntrain):\n         \n        print()\n        print('Machine Learning object is created')\n        print()\n\n        self.data=data\n        self.ntrain=ntrain\n        self.test_size=test_size\n        self.train=self.data[:self.ntrain]\n        self.test=self.data[self.ntrain:]\n        self.testID=testID\n        self.ytrain=ytrain\n        \n        self.reg_models={}\n\n        # define models to test:\n        self.base_models = {\n            \"Elastic Net\":make_pipeline(RobustScaler(),                   #Elastic Net model(Regularized model)\n                                        ElasticNet(alpha=0.0005,\n                                                   l1_ratio=0.9)),\n            \"Kernel Ridge\" : KernelRidge(),                               #Kernel Ridge model(Regularized model)\n            \"Bayesian Ridge\" : BayesianRidge(compute_score=True,          #Bayesian Ridge model\n                                            fit_intercept=True,\n                                            n_iter=200,\n                                            normalize=False),                             \n            \"Lasso\" : make_pipeline(RobustScaler(), Lasso(alpha =0.0005,   #Lasso model(Regularized model)\n                                                          random_state=2021)),\n            \"Lasso Lars Ic\" : LassoLarsIC(criterion='aic',                  #LassoLars IC model \n                                        fit_intercept=True,\n                                        max_iter=200,\n                                        normalize=True,\n                                        precompute='auto',\n                                        verbose=False), \n            \"Random Forest\": RandomForestRegressor(n_estimators=300),      #Random Forest model\n            \"Svm\": SVR(),                                                  #Support Vector Machines\n            \"Xgboost\": XGBRegressor(),                                     #XGBoost model                                             \n            \"Gradient Boosting\":make_pipeline(StandardScaler(),\n                                             GradientBoostingRegressor(n_estimators=3000, #GradientBoosting model\n                                                                       learning_rate=0.005,     \n                                                                       max_depth=4, max_features='sqrt',\n                                                                       min_samples_leaf=15, min_samples_split=10, \n                                                                       loss='huber', random_state = 2021))}\n        \n    def init_ml_regressors(self, algorithms):\n        \n        if algorithms.lower()=='all':\n            for model in self.base_models.keys():\n                self.reg_models[model.title()]=self.base_models[model.title()]\n                print(model.title(),(20-len(str(model)))*'=','>','Initialized')\n            \n        else:\n            for model in algorithms:\n                if model.lower() in [x.lower() for x in self.base_models.keys()]:\n                    print(self.base_models[model])\n                    print(model.title(),(20-len(str(model)))*'=','>','Initialized')\n\n                else:\n                    print(model.title(),(20-len(str(model)))*'=','>','Not Initialized')\n                    print('# Only (Elastic Net,Kernel Ridge,Lasso,Random Forest,SVM,XGBoost,LGBM,Gradient Boosting,Linear Regression)')    \n    \n\n    def show_available(self):\n        print(50*'=')\n        print('You can fit your data with the following models')\n        print(50*'=','\\n')\n        for model in [m.title() for m in self.base_models.keys()]:\n            print(model)\n        print('\\n',50*'=','\\n')\n        \n    def train_test_eval_show_results(self, show=True):\n        \n        if not self.reg_models:\n            raise TypeError('Add models first before fitting')\n      \n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.train, self.ytrain, \n                                                                                test_size=self.test_size, random_state=2021)\n\n        #Preprocessing, fitting, making predictions and scoring for every model:\n        self.result_data = {'R^2':{'Training':{},'Testing':{}},\n                            'Adjusted R^2':{'Training':{},'Testing':{}},\n                            'MAE':{'Training':{},'Testing':{}},\n                            'MSE':{'Training':{},'Testing':{}},\n                            'RMSE':{'Training':{},'Testing':{}}}\n        \n        self.p = train.shape[1]\n        self.train_n = self.X_train.shape[0]\n        self.test_n = self.X_test.shape[0]\n        \n        for name in self.reg_models: \n            #fitting the model\n            model = self.reg_models[name].fit(self.X_train, self.y_train)\n            \n            #make predictions with train and test datasets\n            y_pred_train = model.predict(self.X_train)\n            y_pred_test = model.predict(self.X_test)\n\n            #calculate the R-Squared for training and testing\n            r2_train,r2_test = model.score(self.X_train, self.y_train),\\\n                               model.score(self.X_test, self.y_test)\n            self.result_data['R^2']['Training'][name],\\\n            self.result_data['R^2']['Testing'][name] = r2_train, r2_test\n\n            #calculate the Adjusted R-Squared for training and testing\n            adj_train, adj_test = (1-(1-r2_train)*(self.train_n-1)/(self.train_n-self.p-1)) ,\\\n                                  (1-(1-r2_test)*(self.train_n-1)/(self.train_n-self.p-1))\n            self.result_data['Adjusted R^2']['Training'][name],\\\n            self.result_data['Adjusted R^2']['Testing'][name] = adj_train, adj_test\n\n            #calculate the Mean absolute error for training and testing\n            mae_train, mae_test = mean_absolute_error(self.y_train, y_pred_train),\\\n                                  mean_squared_error(self.y_test, y_pred_test)         \n            self.result_data['MAE']['Training'][name],\\\n            self.result_data['MAE']['Testing'][name] = mae_train, mae_test\n\n            #calculate Mean square error for training and testing\n            mse_train, mse_test = mean_squared_error(self.y_train, y_pred_train),\\\n                                  mean_squared_error(self.y_test, y_pred_test)\n            self.result_data['MSE']['Training'][name],\\\n            self.result_data['MSE']['Testing'][name] = mse_train, mse_test\n\n            #calculate Root mean error for training and testing    \n            rmse_train, rmse_test = np.sqrt(mse_train), np.sqrt(mse_test)\n            self.result_data['RMSE']['Training'][name],\\\n            self.result_data['RMSE']['Testing'][name] = rmse_train, rmse_test\n            \n            if show:\n                print('\\n',25*'=','{}'.format(name),25*'=')\n                print(10*'*','Training',23*'*','Testing',10*'*')\n                print('R^2    : ',r2_train,' '*(25-len(str(r2_train))),r2_test) \n                print('Adj R^2: ',adj_train,' '*(25-len(str(adj_train))),adj_test) \n                print('MAE    : ',mae_train,' '*(25-len(str(mae_train))),mae_test) \n                print('MSE    : ',mse_train,' '*(25-len(str(mse_train))),mse_test) \n                print('RMSE   : ',rmse_train,' '*(25-len(str(rmse_train))),rmse_test)\n \n    def cv_eval_show_results(self, num_models=4, n_folds=5, show=False):\n        \n        # prepare configuration for cross validation test\n        #Create two dictionaries to store the results of R-Squared and RMSE \n        self.r_2_results = {'R-Squared':{},'Mean':{},'std':{}}   \n        self.rmse_results = {'RMSE':{},'Mean':{},'std':{}}\n        \n        #create a dictionary contains best Adjusted R-Squared results, then sort it\n        adj=self.result_data['Adjusted R^2']['Testing']\n        adj_R_sq_sort=dict(sorted(adj.items(), key=lambda x:x[1], reverse=True))\n        \n        #check the number of models to visualize results\n        if str(num_models).lower()=='all':\n            models_name={i:adj_R_sq_sort[i] for i in list(adj_R_sq_sort.keys())}\n            print()\n            print('Apply Cross-Validation for {} models'.format(num_models))\n            print()\n            \n        else:\n            print()\n            print('Apply Cross-Validation for {} models have highest Adjusted R-Squared value on Testing'.format(num_models))\n            print()\n            \n            num_models=min(num_models,len(self.base_models.keys()))\n            models_name={i:adj_R_sq_sort[i] for i in list(adj_R_sq_sort.keys())[:num_models]}\n        \n        models_name=dict(sorted(models_name.items(), key=lambda x:x[1], reverse=True))\n        \n        #create Kfold for the cross-validation\n        kfold = KFold(n_splits=n_folds, shuffle=True, random_state=2021).get_n_splits(self.train)\n        \n        \n        for name,_ in models_name.items():\n            model = self.base_models[name]\n            r_2 = cross_val_score(model, self.train, self.ytrain,    #R-Squared \n                                  scoring='r2', cv=kfold)          \n            rms = np.sqrt(-cross_val_score(model, self.train, self.ytrain, #RMSE\n                                           cv=kfold, scoring='neg_mean_squared_error'))\n\n            #save the R-Squared reults\n            self.r_2_results['R-Squared'][name] = r_2\n            self.r_2_results['Mean'][name] = r_2.mean()\n            self.r_2_results['std'][name] = r_2.std()\n\n            #save the RMSE reults\n            self.rmse_results['RMSE'][name] = rms\n            self.rmse_results['Mean'][name] = rms.mean()\n            self.rmse_results['std'][name] = rms.std()\n            \n            print(name,(30-len(name))*'=','>','is Done!')\n            \n        if show : return self.r_2_results, self.rmse_results\n        \n    def visualize_results(self, \n                          cv_train_test,\n                          metrics=['r_squared','adjusted r_squared','mae','mse','rmse'],\n                          metrics_cv=['r_squared','rmse']):\n        \n        if cv_train_test.lower()=='cv':\n            \n            #visualize the results of R-Squared CV for each model\n            self.r_2_cv_results = pd.DataFrame(index=self.r_2_results['R-Squared'].keys())\n            #append the max R-Squared for each model to the dataframe\n            self.r_2_cv_results['Max'] = [self.r_2_results['R-Squared'][m].max() for m in self.r_2_results['R-Squared'].keys()]\n            #append the mean of all R-Squared for each model to the dataframe\n            self.r_2_cv_results['Mean'] = [self.r_2_results['Mean'][m] for m in self.r_2_results['Mean'].keys()]\n            #append the min R-Squared for each model to the dataframe\n            self.r_2_cv_results['Min'] = [self.r_2_results['R-Squared'][m].min() for m in self.r_2_results['R-Squared'].keys()]\n            #append the std of all R-Squared for each model to the dataframe\n            self.r_2_cv_results['std'] = [self.r_2_results['std'][m] for m in self.r_2_results['std'].keys()]\n\n            #visualize the results of RMSE CV for each model\n            self.rmse_cv_results = pd.DataFrame(index=self.rmse_results['RMSE'].keys())\n            #append the max R-Squared for each model to the dataframe\n            self.rmse_cv_results['Max'] = [self.rmse_results['RMSE'][m].max() for m in self.rmse_results['RMSE'].keys()]\n            #append the mean of all R-Squared for each model to the dataframe\n            self.rmse_cv_results['Mean'] = [self.rmse_results['Mean'][m] for m in self.rmse_results['Mean'].keys()]\n            #append the min R-Squared for each model to the dataframe\n            self.rmse_cv_results['Min'] = [self.rmse_results['RMSE'][m].min() for m in self.rmse_results['RMSE'].keys()]\n            #append the std of all R-Squared for each model to the dataframe\n            self.rmse_cv_results['std'] = [self.rmse_results['std'][m] for m in self.rmse_results['std'].keys()]\n\n            for parm in metrics_cv:\n                if parm.lower() in ['rmse','root mean squared']:\n                    self.rmse_cv_results = self.rmse_cv_results.sort_values(by='Mean',ascending=True)\n                    self.rmse_cv_results.iplot(kind='bar',\n                                               title='Maximum, Minimun, Mean values and standard deviation <br>For RMSE values for each model')\n                    self.scores = pd.DataFrame(self.rmse_results['RMSE'])\n                    self.scores.iplot(kind='box',\n                                      title='Box plot for the variation of RMSE values for each model')\n\n                elif parm.lower() in ['r_squared','rsquared','r squared']:\n                    self.r_2_cv_results = self.r_2_cv_results.sort_values(by='Mean',ascending=False)\n                    self.r_2_cv_results.iplot(kind='bar',\n                                              title='Max, Min, Mean, and standard deviation <br>For R-Squared values for each model')\n                    self.scores = pd.DataFrame(self.r_2_results['R-Squared'])\n                    self.scores.iplot(kind='box',\n                                 title='Box plot for the variation of R-Squared for each model')\n                else:\n                    print('Not avilable')\n                    \n        elif cv_train_test.lower()=='train test':\n            R_2 = pd.DataFrame(self.result_data['R^2']).sort_values(by='Testing',ascending=False)\n            Adjusted_R_2 = pd.DataFrame(self.result_data['Adjusted R^2']).sort_values(by='Testing',ascending=False)\n            MAE = pd.DataFrame(self.result_data['MAE']).sort_values(by='Testing',ascending=True)\n            MSE = pd.DataFrame(self.result_data['MSE']).sort_values(by='Testing',ascending=True)\n            RMSE = pd.DataFrame(self.result_data['RMSE']).sort_values(by='Testing',ascending=True)\n\n            for parm in metrics:\n                if parm.lower()=='r_squared':\n                    #order the results by testing values\n                    fig=px.line(data_frame=R_2.reset_index(),\n                                x='index',y=['Training','Testing'],\n                                title='R-Squared for training and testing')\n                    fig.show()\n\n                elif parm.lower()=='adjusted r_squared':\n                    #order the results by testing values\n                    fig=px.line(data_frame=Adjusted_R_2.reset_index(),\n                                x='index',y=['Training','Testing'],\n                                title='Adjusted R-Squared for training and testing')\n                    fig.show()\n\n                elif parm.lower()=='mae':\n                    #order the results by testing values\n                    fig=px.line(data_frame=MAE.reset_index(),\n                                x='index',y=['Training','Testing'],\n                                title='Mean absolute error for training and testing')\n                    fig.show()\n\n                elif parm.lower()=='mse':\n                    #order the results by testing values\n                    fig=px.line(data_frame=MSE.reset_index(),\n                                x='index',y=['Training','Testing'],\n                                title='Mean square error for training and testing')\n                    fig.show()\n\n                elif parm.lower()=='rmse':\n                    #order the results by testing values\n                    fig=px.line(data_frame=RMSE.reset_index(),\n                                x='index',y=['Training','Testing'],\n                                title='Root mean square error for training and testing')\n                    fig.show()\n\n                else:\n                    print('Only (R_Squared, Adjusted R_Squared, MAE, MSE, RMSE)')\n\n        else:\n            raise TypeError('Only (CV , Train Test)')\n            \n    def fit_best_model(self):\n        self.models=list(self.r_2_results['Mean'].keys())\n        self.r_2_results_vals=np.array([r for _,r in self.r_2_results['Mean'].items()])\n        self.rmse_results_vals=np.array([r for _,r in self.rmse_results['Mean'].items()])\n        self.best_model_name=self.models[np.argmax(self.r_2_results_vals-self.rmse_results_vals)]\n        print()\n        print(30*'=')\n        print('The best model is ====> ',self.best_model_name)\n        print('It has the highest (R-Squared) and the lowest (Root Mean Square Erorr)')\n        print(30*'=')\n        print()\n        self.best_model=self.base_models[self.best_model_name]\n        self.best_model.fit(self.train, self.ytrain)\n        print(self.best_model_name,' is fitted to the data!')\n        print()\n        print(30*'=')\n        self.y_pred=self.best_model.predict(self.test)\n        self.y_pred=np.expm1(self.y_pred)              #using expm1 (The inverse of log1p)\n        self.temp=pd.DataFrame({\"Id\": self.testID,\n                                \"SalePrice\": self.y_pred })\n    \n    def show_predictions(self):\n        return self.temp\n    \n    def save_predictions(self, file_name):\n        self.temp.to_csv('{}.csv'.format(file_name))","metadata":{"papermill":{"duration":0.377165,"end_time":"2021-07-27T22:14:29.134381","exception":false,"start_time":"2021-07-27T22:14:28.757216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:16.04239Z","iopub.execute_input":"2021-09-28T21:16:16.042818Z","iopub.status.idle":"2021-09-28T21:16:16.115778Z","shell.execute_reply.started":"2021-09-28T21:16:16.042784Z","shell.execute_reply":"2021-09-28T21:16:16.114635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"hpopp_class\"></a>\n<h1>House Price OOP class</h1>","metadata":{"papermill":{"duration":0.134929,"end_time":"2021-07-27T22:14:29.406192","exception":false,"start_time":"2021-07-27T22:14:29.271263","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class HouseObjectOriented:\n    \"\"\"\n    param train: train data will be used for modelling\n    param test:  test data will be used for model evaluation\n    \"\"\"\n    def __init__(self):\n        #properties\n        self.ntrain=None\n        self.testID=None\n        self.y_train=None\n        self.train=None\n        self.test=None\n        self._info=Information()\n        self._Preprocessor = Preprocessor()\n        \n        print()\n        print('HouseObjectOriented object is created')\n        print()\n        \n    def add_data(self, train, test):\n        #properties\n        self.ntrain=train.shape[0]\n        self.testID=test.reset_index().drop('index',axis=1)['Id']\n        self.y_train=train['SalePrice'].apply(lambda x:np.log1p(x))\n        self.train=train.drop('SalePrice', axis=1)\n        self.test=test\n        \n        # concatinating the whole data\n        self.data=self.concat_data(self.train, self.test)\n        self.orig_data=self.data.copy()\n        print()\n        print('Your data has been added')\n        print()\n\n    def concat_data(self, train, test):\n        \n        data = pd.concat([self.train.set_index('Id'), self.test.set_index('Id')]).reset_index(drop=True)\n\n        return data\n    \n    #using the objects\n    def information(self):\n        \"\"\"\n        using _info object gives summary about dataset\n        :return:\n        \"\"\"\n        print(self._info._info_(self.data))\n\n\n    def preprocessing(self):\n        \n        \"\"\"\n        preprocess the data before applying Ml algorithms\n        \"\"\"\n        self.data=self._Preprocessor._process(self.data, self.ntrain)\n\n        print()\n        print('Data has been Pre-Processed')\n        print()\n        \n    class visualizer:\n        \n        def __init__(self, House_Price_OOP):\n            \n            self.hp=House_Price_OOP\n            self.data=self.hp.data\n            self.ytrain=self.hp.y_train  \n            self.ntrain=self.hp.ntrain\n            self.testID=self.hp.testID\n            self.data_vis=data_visualization  \n            \n            \n        def box_plot(self, columns):\n            \n            self.data_vis.box_plot(columns)\n            \n            \n        def box_plot(self, columns):\n            \n            self.data_vis.box_plot(columns)\n        \n        \n        def bar_plot(self, columns):\n            \n            self.data_vis.bar_plot(columns)\n            \n        \n    class ml:\n        \n        def __init__(self, House_Price_OOP):\n            \n            self.hp=House_Price_OOP\n            self.data=self.hp.data\n            self.ytrain=self.hp.y_train  \n            self.ntrain=self.hp.ntrain\n            self.testID=self.hp.testID\n            self._ML_=ML(data=self.data, ytrain=self.ytrain,\n                         testID=self.testID, test_size=0.2, ntrain=self.ntrain)\n        \n        def show_available_algorithms(self):\n            \n            self._ML_.show_available()\n        \n        \n        def init_regressors(self, num_models='all'):\n        \n            self._ML_.init_ml_regressors(num_models)\n        \n        \n        def train_test_validation(self, show_results=True):\n        \n            self._ML_.train_test_eval_show_results(show=show_results)\n\n            \n        def cross_validation(self, num_models=4, n_folds=5, show_results=False):\n            \n            self._ML_.cv_eval_show_results(num_models=num_models, n_folds=n_folds, show=show_results)\n\n            \n        def visualize_trai_test(self, metrics=['r_squared','adjusted r_squared','mae','mse','rmse']):\n            \n            self._ML_.visualize_results(cv_train_test='train test', metrics=metrics)\n\n            \n        def visualize_cv(self, metrics=['r_squared','rmse']):\n            \n            self._ML_.visualize_results(cv_train_test='cv', metrics_cv=metrics)   \n            \n            \n        def fit_best_model(self):\n            \n            self._ML_.fit_best_model()\n\n            \n        def show_predictions(self):\n            \n            return self._ML_.show_predictions()\n\n        def save_predictions(self, file_name):\n            \n            self._ML_.save_predictions(file_name)\n            print('The prediction is saved')","metadata":{"papermill":{"duration":0.156693,"end_time":"2021-07-27T22:14:29.696838","exception":false,"start_time":"2021-07-27T22:14:29.540145","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:16.183265Z","iopub.execute_input":"2021-09-28T21:16:16.183682Z","iopub.status.idle":"2021-09-28T21:16:16.207311Z","shell.execute_reply.started":"2021-09-28T21:16:16.183645Z","shell.execute_reply":"2021-09-28T21:16:16.206108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:center; border-radius: 15px 50px;\">Creating Objects of our Classes</p>","metadata":{}},{"cell_type":"code","source":"#collect the data\ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"papermill":{"duration":0.216353,"end_time":"2021-07-27T22:14:30.051202","exception":false,"start_time":"2021-07-27T22:14:29.834849","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:16.209009Z","iopub.execute_input":"2021-09-28T21:16:16.209314Z","iopub.status.idle":"2021-09-28T21:16:16.275501Z","shell.execute_reply.started":"2021-09-28T21:16:16.209283Z","shell.execute_reply":"2021-09-28T21:16:16.274439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.0\"></a>\n<h1>Create HouseObjectOriented object</h1>","metadata":{"papermill":{"duration":0.138214,"end_time":"2021-07-27T22:14:30.334645","exception":false,"start_time":"2021-07-27T22:14:30.196431","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#create HouseObjectOriented object\nHOOP = HouseObjectOriented()","metadata":{"papermill":{"duration":0.14706,"end_time":"2021-07-27T22:14:30.621105","exception":false,"start_time":"2021-07-27T22:14:30.474045","status":"completed"},"tags":[],"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-09-28T21:16:16.278188Z","iopub.execute_input":"2021-09-28T21:16:16.278659Z","iopub.status.idle":"2021-09-28T21:16:16.284808Z","shell.execute_reply.started":"2021-09-28T21:16:16.278611Z","shell.execute_reply":"2021-09-28T21:16:16.283543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h1>Adding our data</h1>","metadata":{"papermill":{"duration":0.13702,"end_time":"2021-07-27T22:14:30.896584","exception":false,"start_time":"2021-07-27T22:14:30.759564","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#adding the data \nHOOP.add_data(train, test)","metadata":{"papermill":{"duration":0.185376,"end_time":"2021-07-27T22:14:31.219055","exception":false,"start_time":"2021-07-27T22:14:31.033679","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:16.287148Z","iopub.execute_input":"2021-09-28T21:16:16.287602Z","iopub.status.idle":"2021-09-28T21:16:16.331773Z","shell.execute_reply.started":"2021-09-28T21:16:16.287556Z","shell.execute_reply":"2021-09-28T21:16:16.330637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<a id=\"2.0\"></a>\n<h1>Display Information about the data</h1>","metadata":{"papermill":{"duration":0.135392,"end_time":"2021-07-27T22:14:31.49045","exception":false,"start_time":"2021-07-27T22:14:31.355058","status":"completed"},"tags":[]}},{"cell_type":"code","source":"HOOP.information()","metadata":{"papermill":{"duration":0.366321,"end_time":"2021-07-27T22:14:31.992447","exception":false,"start_time":"2021-07-27T22:14:31.626126","status":"completed"},"tags":[],"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-09-28T21:16:16.333583Z","iopub.execute_input":"2021-09-28T21:16:16.334022Z","iopub.status.idle":"2021-09-28T21:16:16.456725Z","shell.execute_reply.started":"2021-09-28T21:16:16.333967Z","shell.execute_reply":"2021-09-28T21:16:16.452282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3.0\"></a>\n<h1>Pre-Process the data</h1>","metadata":{"papermill":{"duration":0.136544,"end_time":"2021-07-27T22:14:32.267483","exception":false,"start_time":"2021-07-27T22:14:32.130939","status":"completed"},"tags":[]}},{"cell_type":"code","source":"HOOP.preprocessing()","metadata":{"papermill":{"duration":0.757755,"end_time":"2021-07-27T22:14:33.162693","exception":false,"start_time":"2021-07-27T22:14:32.404938","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:16.478344Z","iopub.execute_input":"2021-09-28T21:16:16.478719Z","iopub.status.idle":"2021-09-28T21:16:16.994261Z","shell.execute_reply.started":"2021-09-28T21:16:16.478689Z","shell.execute_reply":"2021-09-28T21:16:16.993539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2.1\"></a>\n<h1>Display Information about the data after Pre-Processing</h1>","metadata":{"papermill":{"duration":0.137746,"end_time":"2021-07-27T22:14:33.440626","exception":false,"start_time":"2021-07-27T22:14:33.30288","status":"completed"},"tags":[]}},{"cell_type":"code","source":"HOOP.information()","metadata":{"papermill":{"duration":0.743134,"end_time":"2021-07-27T22:14:34.321949","exception":false,"start_time":"2021-07-27T22:14:33.578815","status":"completed"},"tags":[],"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-09-28T21:16:16.995169Z","iopub.execute_input":"2021-09-28T21:16:16.995416Z","iopub.status.idle":"2021-09-28T21:16:17.443547Z","shell.execute_reply.started":"2021-09-28T21:16:16.995391Z","shell.execute_reply":"2021-09-28T21:16:17.437329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4.0\"></a>\n<h1>Create a Machine Learning object</h1>","metadata":{"papermill":{"duration":0.138342,"end_time":"2021-07-27T22:14:34.600941","exception":false,"start_time":"2021-07-27T22:14:34.462599","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML = HOOP.ml(HOOP)","metadata":{"papermill":{"duration":0.154707,"end_time":"2021-07-27T22:14:34.894966","exception":false,"start_time":"2021-07-27T22:14:34.740259","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:17.444884Z","iopub.execute_input":"2021-09-28T21:16:17.445179Z","iopub.status.idle":"2021-09-28T21:16:17.46559Z","shell.execute_reply.started":"2021-09-28T21:16:17.44515Z","shell.execute_reply":"2021-09-28T21:16:17.455683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4.1\"></a>\n<h1>Show the available algorithms</h1>","metadata":{"papermill":{"duration":0.1411,"end_time":"2021-07-27T22:14:35.178736","exception":false,"start_time":"2021-07-27T22:14:35.037636","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.show_available_algorithms()","metadata":{"papermill":{"duration":0.152037,"end_time":"2021-07-27T22:14:35.473315","exception":false,"start_time":"2021-07-27T22:14:35.321278","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:17.468094Z","iopub.execute_input":"2021-09-28T21:16:17.46842Z","iopub.status.idle":"2021-09-28T21:16:17.476362Z","shell.execute_reply.started":"2021-09-28T21:16:17.468391Z","shell.execute_reply":"2021-09-28T21:16:17.475355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4.2\"></a>\n<h1>Initialize the ML Regressors</h1>","metadata":{"papermill":{"duration":0.144906,"end_time":"2021-07-27T22:14:35.757913","exception":false,"start_time":"2021-07-27T22:14:35.613007","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.init_regressors('all')","metadata":{"papermill":{"duration":0.153953,"end_time":"2021-07-27T22:14:36.060606","exception":false,"start_time":"2021-07-27T22:14:35.906653","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:17.478128Z","iopub.execute_input":"2021-09-28T21:16:17.478428Z","iopub.status.idle":"2021-09-28T21:16:17.49052Z","shell.execute_reply.started":"2021-09-28T21:16:17.478387Z","shell.execute_reply":"2021-09-28T21:16:17.48954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4.3\"></a>\n<h1>Train-Test Validation</h1>","metadata":{"papermill":{"duration":0.140503,"end_time":"2021-07-27T22:14:36.341029","exception":false,"start_time":"2021-07-27T22:14:36.200526","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.train_test_validation()","metadata":{"papermill":{"duration":23.940244,"end_time":"2021-07-27T22:15:00.421872","exception":false,"start_time":"2021-07-27T22:14:36.481628","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:17.492519Z","iopub.execute_input":"2021-09-28T21:16:17.492954Z","iopub.status.idle":"2021-09-28T21:16:41.549416Z","shell.execute_reply.started":"2021-09-28T21:16:17.492902Z","shell.execute_reply":"2021-09-28T21:16:41.54852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4.4\"></a>\n<h1>Visualize the results of train-test validation</h1>","metadata":{"papermill":{"duration":0.142573,"end_time":"2021-07-27T22:15:00.71188","exception":false,"start_time":"2021-07-27T22:15:00.569307","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.visualize_trai_test()","metadata":{"papermill":{"duration":0.640016,"end_time":"2021-07-27T22:15:01.496073","exception":false,"start_time":"2021-07-27T22:15:00.856057","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:41.550632Z","iopub.execute_input":"2021-09-28T21:16:41.550918Z","iopub.status.idle":"2021-09-28T21:16:41.938437Z","shell.execute_reply.started":"2021-09-28T21:16:41.550891Z","shell.execute_reply":"2021-09-28T21:16:41.937615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4.5\"></a>\n<h1>Applying Cross-Validation</h1>","metadata":{"papermill":{"duration":0.178344,"end_time":"2021-07-27T22:15:01.855355","exception":false,"start_time":"2021-07-27T22:15:01.677011","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.cross_validation('all')","metadata":{"papermill":{"duration":218.377499,"end_time":"2021-07-27T22:18:40.412828","exception":false,"start_time":"2021-07-27T22:15:02.035329","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:16:41.940005Z","iopub.execute_input":"2021-09-28T21:16:41.94041Z","iopub.status.idle":"2021-09-28T21:20:26.787317Z","shell.execute_reply.started":"2021-09-28T21:16:41.940365Z","shell.execute_reply":"2021-09-28T21:20:26.78637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4.6\"></a>\n<h1>Visualize the results of Cross-Validation</h1>","metadata":{"papermill":{"duration":0.177398,"end_time":"2021-07-27T22:18:40.766195","exception":false,"start_time":"2021-07-27T22:18:40.588797","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.visualize_cv()","metadata":{"papermill":{"duration":0.450198,"end_time":"2021-07-27T22:18:41.397118","exception":false,"start_time":"2021-07-27T22:18:40.94692","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:20:26.788605Z","iopub.execute_input":"2021-09-28T21:20:26.788893Z","iopub.status.idle":"2021-09-28T21:20:27.078102Z","shell.execute_reply.started":"2021-09-28T21:20:26.788866Z","shell.execute_reply":"2021-09-28T21:20:27.076819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4.7\"></a>\n<h1>Find the best model and fit it to the data</h1>","metadata":{"papermill":{"duration":0.205173,"end_time":"2021-07-27T22:18:41.809678","exception":false,"start_time":"2021-07-27T22:18:41.604505","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.fit_best_model()","metadata":{"papermill":{"duration":10.975436,"end_time":"2021-07-27T22:18:52.997261","exception":false,"start_time":"2021-07-27T22:18:42.021825","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:20:27.07977Z","iopub.execute_input":"2021-09-28T21:20:27.080215Z","iopub.status.idle":"2021-09-28T21:20:38.538612Z","shell.execute_reply.started":"2021-09-28T21:20:27.080172Z","shell.execute_reply":"2021-09-28T21:20:38.537437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4.8\"></a>\n<h1>Predict and show the prediction</h1>","metadata":{"papermill":{"duration":0.20896,"end_time":"2021-07-27T22:18:53.415667","exception":false,"start_time":"2021-07-27T22:18:53.206707","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ML.show_predictions()","metadata":{"papermill":{"duration":0.224229,"end_time":"2021-07-27T22:18:53.847977","exception":false,"start_time":"2021-07-27T22:18:53.623748","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:20:38.540248Z","iopub.execute_input":"2021-09-28T21:20:38.540677Z","iopub.status.idle":"2021-09-28T21:20:38.564107Z","shell.execute_reply.started":"2021-09-28T21:20:38.540632Z","shell.execute_reply":"2021-09-28T21:20:38.562995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4.9\"></a>\n<h1>Save the predictions to a csv file</h1>","metadata":{"papermill":{"duration":0.203056,"end_time":"2021-07-27T22:18:54.252516","exception":false,"start_time":"2021-07-27T22:18:54.04946","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ML.save_predictions('Results')","metadata":{"papermill":{"duration":0.210967,"end_time":"2021-07-27T22:18:54.668673","exception":false,"start_time":"2021-07-27T22:18:54.457706","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-28T21:20:38.565643Z","iopub.execute_input":"2021-09-28T21:20:38.566081Z","iopub.status.idle":"2021-09-28T21:20:38.57054Z","shell.execute_reply.started":"2021-09-28T21:20:38.566044Z","shell.execute_reply":"2021-09-28T21:20:38.569056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#outlines\"><b>Up to outlines</b>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" style='color:red' > If you liked the notebook or learned something please <b>Upvote</b>! </h2>\n<p style=\"background-color:skyblue; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 10px 100px;\">You can also see:</p>\n<ul>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/predicting-the-survival-of-titanic-top-6'>Predicting the Survival of Titanic (Top 6%)</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/house-price-prediction-top-8'>\n‚úî House Price prediction(Top 8%)</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/prediction-of-heart-disease-machine-learning'>Prediction of Heart Disease (Machine Learning)</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/data-exploration-and-visualization-uber-data'>Data exploration and visualization(Uber Data)</a><br>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/hotel-booking-eda-cufflinks-and-plotly'>Hotel booking EDA (Cufflinks and plotly)\n</a><br>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/suicide-rates-visualization-and-geographic-maps/edit/run/53135916'>Suicide Rates visualization and Geographic maps</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/superstore-data-analysis-with-plotly-clustering'>Superstore Data Analysis With Plotly(Clustering)</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/superstore-analysis-with-cufflinks-and-pandas'>Superstore Analysis With Cufflinks and pandas</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/learn-data-analysis-using-sql-and-pandas'>Learn Data Analysis using SQL and Pandas</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/european-soccer-database-with-sqlite3'>European soccer database with sqlite3</a>\n<li><b><a href='https://www.kaggle.com/alaasedeeq/chinook-questions-with-sqlite'>Chinook data questions with sqlite3</a>","metadata":{"papermill":{"duration":0.202593,"end_time":"2021-07-27T22:18:55.074313","exception":false,"start_time":"2021-07-27T22:18:54.87172","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### <h1 align=\"center\" style=\"color:red \">Thanks for reading</h1>","metadata":{"papermill":{"duration":0.205077,"end_time":"2021-07-27T22:18:55.482266","exception":false,"start_time":"2021-07-27T22:18:55.277189","status":"completed"},"tags":[]}}]}