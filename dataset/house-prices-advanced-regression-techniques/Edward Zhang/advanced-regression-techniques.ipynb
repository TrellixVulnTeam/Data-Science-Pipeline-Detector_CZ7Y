{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Introduction**","metadata":{}},{"cell_type":"markdown","source":"***Greetings buyers, Welcome to the Housing Market!***","metadata":{}},{"cell_type":"markdown","source":"**To whom does this notebook appeal to?**\n* If you are just getting started and know some basic modeling strategies such as Regression and Classification, but want to increase your model accuracy a lot!\n* This notebook aims at basic EDA, Feature engineering, and most importantly HYPER PARAMATER TUNING! With **RANDOMSEARCHCV** and **XGBOOST**\n","metadata":{}},{"cell_type":"markdown","source":"![](https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2020/08/1440/810/House-For-Sale-iStock.jpg?ve=1&tl=1)","metadata":{}},{"cell_type":"markdown","source":"[](https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2020/08/1440/810/House-For-Sale-iStock.jpg?ve=1&tl=1)","metadata":{}},{"cell_type":"markdown","source":"# **Lets get started!**","metadata":{}},{"cell_type":"markdown","source":"**Basic Table of Contents**\n1. Data Cleaning\n2. PCA\n3. Modeling\n4. Lets TUNE our model! (XGBOOST) (RandomSearchCV)","metadata":{}},{"cell_type":"markdown","source":"**We first need a few things imported...**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\n#filter out warnings\nimport warnings \nwarnings.filterwarnings('ignore')\n\n#To style plots\nplt.style.use('fivethirtyeight')\n\n#cycle the colors\nfrom itertools import cycle\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n\n#Get the kaggle input\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ntrain.head()\nprint(train.shape)\nprint(test.shape)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Missing Values**","metadata":{}},{"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False)[0:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train.isnull(),yticklabels=False,cbar='BuPu')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n'''train['LotFrontage'] = train['LotFrontage'].fillna(train['LotFrontage'].mean)\ntrain.drop(['Alley'], axis = 1, inplace=True)\n\ntrain['BsmtCond']=train['BsmtCond'].fillna(train['BsmtCond'].mode()[0])\ntrain['BsmtQual']=train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])\ntrain.drop(['PoolQC'], axis = 1, inplace=True)\ntrain.drop(['Fence'], axis = 1, inplace=True)    \ntrain.drop(['MiscFeature'], axis = 1, inplace=True)'''\n\n\n#clean the train data\nfor i in list(train.columns):\n    dtype = train[i].dtype\n    values = 0\n    if(dtype == float or dtype == int):\n        method = 'mean'\n    else:\n        method = 'mode'\n    if(train[i].notnull().sum() / 1460 <= .5):\n        train.drop(i, axis = 1, inplace=True)\n    elif method == 'mean':\n        train[i]=train[i].fillna(train[i].mean())\n\n    else:\n        train[i]=train[i].fillna(train[i].mode()[0])\n        print(train[i])\n\n\n#clean the test data\nfor i in list(test.columns):\n    dtype = test[i].dtype\n    values = 0\n    if(dtype == float or dtype == int):\n        method = 'mean'\n    else:\n        method = 'mode'\n    if(test[i].notnull().sum() / 1460 <= .5):\n        test.drop(i, axis = 1, inplace=True)\n    elif method == 'mean':\n        test[i]=test[i].fillna(test[i].mean())\n\n    else:\n        test[i]=test[i].fillna(test[i].mode()[0])\n\n\ntrain.head()\ntest.shape","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(columns=['Id'], inplace=True)\ntrain.dropna(inplace=True)\n\ntrain.drop(columns=['Id'], inplace=True)\nprint(train.shape)\nprint(test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().any().any()\ntrain.head()\n#df1=pd.get_dummies(train['MSZoning'],drop_first=True)\n#print(df1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"markdown","source":"Let's first take a look at the distrubution of house prices.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(train.SalePrice,linewidth=2,color=next(color_cycle))\nplt.title('Distribution Plot for Sales Prices')\nplt.ylabel('Sales Price');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rearange the prices from lowest to highest.\n","metadata":{}},{"cell_type":"code","source":"#sort the values\nplt.figure(figsize=(15,5))\nplt.plot(train.SalePrice.sort_values().reset_index(drop=True),color=next(color_cycle))\nplt.title('Distribution Plot for Sales Prices')\nplt.ylabel('Sales Price');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MS Zoning**","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(train,x=train.index, y='SalePrice', labels={'x':'Index'},\n                 color=train.MSZoning, template=\"seaborn\",\n                 title='Sale Price distriution of MSZoning')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter(train,x=train.index, y='SalePrice', labels={'x':'Index'},\n                 color=train.Street, template=\"seaborn\",\n                 title='Sale Price distriution ---> Street')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,2,1)\nplt.scatter(x=train[train.LotConfig == 'FR3'].index,\n           y=train[train.LotConfig == 'FR3'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of FR3 value of LotConfig')\n\nplt.subplot(2,2,2)\nplt.scatter(x=train[train.LotConfig == 'CulDSac'].index,\n           y=train[train.LotConfig == 'CulDSac'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of CulDSac value of LotConfig')\n\nplt.subplot(2,2,3)\nplt.scatter(x=train[train.LotConfig == 'Corner'].index,\n           y=train[train.LotConfig == 'Corner'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of Corner value of LotConfig')\n\nplt.subplot(2,2,4)\nplt.scatter(x=train[train.LotConfig == 'FR2'].index,\n           y=train[train.LotConfig == 'FR2'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution of FR2 value of  LotConfig');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['MSZoning', 'Street',\n       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', \n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n       'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n       'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_test_data = pd.concat([train, test], axis = 0)\nprint(test.shape)\nprint(train.shape)\n\ntrain_test_data.head()\ntrain_test_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Catagorical Variables**\n","metadata":{}},{"cell_type":"code","source":"def One_hot_encoding(columns):\n    df_final=train_test_data\n    i=0\n    for fields in columns:\n        df1=pd.get_dummies(train_test_data[fields],drop_first=True)\n        \n        train_test_data.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:           \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([train_test_data,df_final],axis=1)\n        \n    return df_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_data = One_hot_encoding(columns)\nprint(train_test_data.shape)\ntrain_test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_data.columns.duplicated()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_data =train_test_data.loc[:,~train_test_data.columns.duplicated()]\n\ntrain_test_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature Engineering**","metadata":{}},{"cell_type":"code","source":"from scipy.stats import norm, skew\nfrom scipy import stats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this notebook, I am just going to scale the data, not making any new columns.","metadata":{}},{"cell_type":"code","source":"sns.distplot(train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets log the data, so that it can be linear.","metadata":{}},{"cell_type":"code","source":"train[\"SalePrice\"] = np.log(train[\"SalePrice\"])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nres = stats.probplot(train['SalePrice'], plot=plt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Train=train_test_data.iloc[:1460,:]\ndf_Test=train_test_data.iloc[1460:,:]\nprint(df_Test.shape)\n\ndf_Test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Test.drop(['SalePrice'],axis=1,inplace=True)\nX_train_final=df_Train.drop(['SalePrice'],axis=1)\ny_train_final=df_Train['SalePrice']\nX_train_final.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **PCA -- Principal Component Analysis**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n#make the data into a normal distrubition\n#mean = 0 \nX_std = StandardScaler().fit_transform(X_train_final)\n\nmy_columns = X_train_final.columns\nnew_df = pd.DataFrame(X_std, columns=my_columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2)\ndf_pca = pca.fit_transform(new_df)\nprint(df_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize =(8, 6))\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c = y_train_final, cmap ='plasma')\n# labeling x and y axes\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODELING**","metadata":{}},{"cell_type":"markdown","source":"Lets do some modeling now!","metadata":{}},{"cell_type":"markdown","source":"# **Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n#split the data set into train and test\nX_train, X_test, y_train, y_test = train_test_split(X_train_final, y_train_final)\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)\n\n#Accuracy\nprint(\"R-Squared Value for Training Set: \",linreg.score(X_train, y_train))\nprint(\"R-Squared Value for Test Set: \",linreg.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **KNN Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\nknnreg = KNeighborsRegressor(n_neighbors = 2)\nknnreg.fit(X_train, y_train)\n\nprint('R-squared train score:',knnreg.score(X_train, y_train))\nprint('R-squared test score: ',knnreg.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Ridge**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nridge = Ridge()\nridge.fit(X_train, y_train)\nprint('R-squared train score:',ridge.score(X_train, y_train))\nprint('R-squared test score: ',ridge.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Normalization**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nridge = Ridge(alpha=20)\nridge.fit(X_train_scaled, y_train)\n\n\nprint('R-squared score (training): {:.3f}'.format(ridge.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(ridge.score(X_test_scaled, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Lasso Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nlasso = Lasso(max_iter = 10000)\nlasso.fit(X_train, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test, y_test)))\n\nlasso = Lasso(alpha=100, max_iter = 10000)\nlasso.fit(X_train_scaled, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test_scaled, y_test)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nlasso.fit(X_train_scaled, y_train)\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test_scaled, y_test)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\nGBoost.fit(X_train_final, y_train_final)\n\ny_pred = GBoost.predict(df_Test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **HyperTuning**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nregressor = RandomForestClassifier()\nregressor.fit(X_train_scaled, y_train)\nprint('R-squared score (training): {:.3f}'.format(regressor.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(regressor.score(X_test_scaled, y_test)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [100,200, 300, 500,700, 900]\ncriterion = ['gini', 'entropy']\ndepth = [3,5,10,15]\nmin_split=[2,3,4]\nmin_leaf=[2,3,4]\nbootstrap = ['True', 'False']\nverbose = [5]\n\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':depth,\n    'criterion':criterion,\n    'bootstrap':bootstrap,\n    'verbose':verbose,\n    'min_samples_split':min_split,\n    'min_samples_leaf':min_leaf\n    }\n\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n                               param_distributions=hyperparameter_grid,\n                               cv=5, \n                               scoring = 'neg_mean_absolute_error',\n                               n_jobs = 4, \n                               return_train_score = True,\n                               random_state=42)'''\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#random_cv.fit(X_train_final,y_train_final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#random_cv.best_estimator_#","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressor = RandomForestClassifier(bootstrap='False', max_depth=15, min_samples_leaf=4,n_estimators=900, verbose=5)\n#regressor.fit(X_train_final,y_train_final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = regressor.predict(df_Test)\n#y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prediction=pd.DataFrame(y_pred)\n#samp = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n#print(samp['Id'])\n#sub = pd.concat([samp['Id'],prediction], axis=1)\n#sub.columns=['Id','SalePrice']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(sub)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub.to_csv('My_submission.csv',index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **XGBOOST**","metadata":{}},{"cell_type":"code","source":"import xgboost\nregressor=xgboost.XGBRegressor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''n_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\nbase_score=[0.25,0.5,0.75,1]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#random_cv.fit(X_train_final,y_train_final)\n#andom_cv.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, missing=None, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressor.fit(X_train_final,y_train_final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = regressor.predict(df_Test)\n#y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=pd.DataFrame(y_pred)\nsamp = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nsub = pd.concat([samp['Id'],pred], axis=1)\nsub.columns=['Id','SalePrice']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('My_sub1.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hope you enjoyed the notebook! Please drop a upvote if this notebook helped you out!**\n\n**Have a great day, peace!**","metadata":{}}]}