{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error as MAERROR\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.032058Z","iopub.execute_input":"2022-01-28T09:42:25.032456Z","iopub.status.idle":"2022-01-28T09:42:25.60249Z","shell.execute_reply.started":"2022-01-28T09:42:25.032386Z","shell.execute_reply":"2022-01-28T09:42:25.601377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.607015Z","iopub.execute_input":"2022-01-28T09:42:25.607225Z","iopub.status.idle":"2022-01-28T09:42:25.617166Z","shell.execute_reply.started":"2022-01-28T09:42:25.607197Z","shell.execute_reply":"2022-01-28T09:42:25.616219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hp = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\nhppred = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.618589Z","iopub.execute_input":"2022-01-28T09:42:25.618815Z","iopub.status.idle":"2022-01-28T09:42:25.679499Z","shell.execute_reply.started":"2022-01-28T09:42:25.618786Z","shell.execute_reply":"2022-01-28T09:42:25.678334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Have a glimpse of the data\nhp.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.68161Z","iopub.execute_input":"2022-01-28T09:42:25.681943Z","iopub.status.idle":"2022-01-28T09:42:25.714953Z","shell.execute_reply.started":"2022-01-28T09:42:25.681894Z","shell.execute_reply":"2022-01-28T09:42:25.714034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hp.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-28T09:42:25.716515Z","iopub.execute_input":"2022-01-28T09:42:25.717574Z","iopub.status.idle":"2022-01-28T09:42:25.744001Z","shell.execute_reply.started":"2022-01-28T09:42:25.717521Z","shell.execute_reply":"2022-01-28T09:42:25.742922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shape","metadata":{}},{"cell_type":"code","source":"# what is the shape\nprint(hp.shape)\nprint(hppred.shape)\n# there are 1460 rows and 81 columns in training data\n# (1459,80) in testing data. So one column is missing in test data.","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.745185Z","iopub.execute_input":"2022-01-28T09:42:25.74554Z","iopub.status.idle":"2022-01-28T09:42:25.759513Z","shell.execute_reply.started":"2022-01-28T09:42:25.74549Z","shell.execute_reply":"2022-01-28T09:42:25.758436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# so there NANs. Are there missing values?","metadata":{}},{"cell_type":"code","source":"hp.isna().head() # isnull() also works","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-28T09:42:25.761234Z","iopub.execute_input":"2022-01-28T09:42:25.76238Z","iopub.status.idle":"2022-01-28T09:42:25.797981Z","shell.execute_reply.started":"2022-01-28T09:42:25.762262Z","shell.execute_reply":"2022-01-28T09:42:25.797093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hp.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.799596Z","iopub.execute_input":"2022-01-28T09:42:25.800086Z","iopub.status.idle":"2022-01-28T09:42:25.827017Z","shell.execute_reply.started":"2022-01-28T09:42:25.800039Z","shell.execute_reply":"2022-01-28T09:42:25.825735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hp.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.828255Z","iopub.execute_input":"2022-01-28T09:42:25.828526Z","iopub.status.idle":"2022-01-28T09:42:25.84664Z","shell.execute_reply.started":"2022-01-28T09:42:25.828494Z","shell.execute_reply":"2022-01-28T09:42:25.845612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colnasum_tr = hp.isnull().sum().sort_values(ascending=False) \ncolnasum_pr = hppred.isnull().sum().sort_values(ascending=False) \nprint(colnasum_tr)\nprint(colnasum_pr)\n# We get a Series with index as column names and values are number of NANs or missing values","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.850067Z","iopub.execute_input":"2022-01-28T09:42:25.850399Z","iopub.status.idle":"2022-01-28T09:42:25.879524Z","shell.execute_reply.started":"2022-01-28T09:42:25.850339Z","shell.execute_reply":"2022-01-28T09:42:25.878622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can plot the above Series.Pandas has elementary ploting \nhp.isnull().sum().plot() # \n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:25.880837Z","iopub.execute_input":"2022-01-28T09:42:25.881206Z","iopub.status.idle":"2022-01-28T09:42:26.138182Z","shell.execute_reply.started":"2022-01-28T09:42:25.88117Z","shell.execute_reply":"2022-01-28T09:42:26.137288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can plot just a few values of the Series\nhp.isnull().sum().iloc[0:20].plot()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-28T09:42:26.139643Z","iopub.execute_input":"2022-01-28T09:42:26.140306Z","iopub.status.idle":"2022-01-28T09:42:26.361896Z","shell.execute_reply.started":"2022-01-28T09:42:26.140252Z","shell.execute_reply":"2022-01-28T09:42:26.361116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hppred.isnull().sum().plot()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.36626Z","iopub.execute_input":"2022-01-28T09:42:26.366695Z","iopub.status.idle":"2022-01-28T09:42:26.603402Z","shell.execute_reply.started":"2022-01-28T09:42:26.366653Z","shell.execute_reply":"2022-01-28T09:42:26.602405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# what are the columns with NANs ","metadata":{}},{"cell_type":"code","source":"colna = colnasum_tr[colnasum_tr >0]\nprint(colna)\ncolna.shape\n# so there are 19 columns having NANs","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-28T09:42:26.605286Z","iopub.execute_input":"2022-01-28T09:42:26.605667Z","iopub.status.idle":"2022-01-28T09:42:26.613072Z","shell.execute_reply.started":"2022-01-28T09:42:26.605621Z","shell.execute_reply":"2022-01-28T09:42:26.61244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let us first try to analyze by dropping the columns with NANs","metadata":{}},{"cell_type":"code","source":"hp_dna = hp.dropna(axis=1)\nhppred_dna = hppred.dropna(axis=1)\n\nhp_dna","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.614236Z","iopub.execute_input":"2022-01-28T09:42:26.614659Z","iopub.status.idle":"2022-01-28T09:42:26.673212Z","shell.execute_reply.started":"2022-01-28T09:42:26.614628Z","shell.execute_reply":"2022-01-28T09:42:26.67252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check no missing values\nhp_dna.isnull().sum().sum()\n# No NANs or missing values","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.674529Z","iopub.execute_input":"2022-01-28T09:42:26.674869Z","iopub.status.idle":"2022-01-28T09:42:26.687107Z","shell.execute_reply.started":"2022-01-28T09:42:26.674839Z","shell.execute_reply":"2022-01-28T09:42:26.686227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Identify the target column ","metadata":{}},{"cell_type":"code","source":"# first list the columns\ncols = hp_dna.columns\n# find out columns with 'Sales' in their names\ncolsale = [col for col in cols if 'Sale' in col]\ncolsale\n# Of ['SaleType', 'SaleCondition', 'SalePrice'] 'SalePrice' is our target variable","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.688711Z","iopub.execute_input":"2022-01-28T09:42:26.689494Z","iopub.status.idle":"2022-01-28T09:42:26.702918Z","shell.execute_reply.started":"2022-01-28T09:42:26.689455Z","shell.execute_reply":"2022-01-28T09:42:26.701853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first list the columns\ncolspr = hppred_dna.columns\n# find out columns with 'Sales' in their names\ncolsale = [col for col in colspr if 'Sale' in col]\ncolsale\n# oops! prediction data has no 'SalePrice' and 'SaleType' columns\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.704086Z","iopub.execute_input":"2022-01-28T09:42:26.704317Z","iopub.status.idle":"2022-01-28T09:42:26.718025Z","shell.execute_reply.started":"2022-01-28T09:42:26.704289Z","shell.execute_reply":"2022-01-28T09:42:26.717116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# So the columns in hptest_dna and hp_dna might be different. So first we got to figure out which columns match and which don't","metadata":{}},{"cell_type":"code","source":"pd.Series(cols).equals(colspr)\n# Output 'False' implies both have different columns","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.719914Z","iopub.execute_input":"2022-01-28T09:42:26.720579Z","iopub.status.idle":"2022-01-28T09:42:26.734388Z","shell.execute_reply.started":"2022-01-28T09:42:26.720528Z","shell.execute_reply":"2022-01-28T09:42:26.733416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print columns which match in both\ncolsmatch = [col2 for col1 in cols for col2 in colspr if col1 == col2]\nprint(colsmatch)\nprint('')\nprint('NUmber of matching columns=', len(colsmatch))","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.735867Z","iopub.execute_input":"2022-01-28T09:42:26.736146Z","iopub.status.idle":"2022-01-28T09:42:26.751702Z","shell.execute_reply.started":"2022-01-28T09:42:26.736113Z","shell.execute_reply":"2022-01-28T09:42:26.750709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number of matching columns in both are 46. So form another training and testing sets with just these matching forms.","metadata":{}},{"cell_type":"code","source":"hp_dna_X = hp_dna[colsmatch]\nhp_dna_prX = hppred_dna[colsmatch]\nhp_y = hp_dna['SalePrice']","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.753069Z","iopub.execute_input":"2022-01-28T09:42:26.753521Z","iopub.status.idle":"2022-01-28T09:42:26.767426Z","shell.execute_reply.started":"2022-01-28T09:42:26.753485Z","shell.execute_reply":"2022-01-28T09:42:26.766329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the data into training and testing data","metadata":{}},{"cell_type":"code","source":"# Split into validation and training data\nhptrain_X, hpval_X, hptrain_y, hpval_y = train_test_split(hp_dna_X, hp_y, random_state=2)\nhptrain_X.reset_index(inplace=True) \nhptrain_X.pop('index')\nhpval_X.reset_index(inplace=True)\nhpval_X.pop('index')\nhpval_X.head() \n#train_y= hptrain_y.reset_index()\n#train_y.pop('index')\n#hptrain_y\n\n# above things are done because the output of test-train-split will have random index values. So that index\n# must be removed and a new index is placed","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.768883Z","iopub.execute_input":"2022-01-28T09:42:26.76913Z","iopub.status.idle":"2022-01-28T09:42:26.805654Z","shell.execute_reply.started":"2022-01-28T09:42:26.769098Z","shell.execute_reply":"2022-01-28T09:42:26.804721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let us first work with numeric columns only\nXtr_int = hptrain_X.select_dtypes(include = int)\nXval_int = hpval_X.select_dtypes(include = int)\nXpr_int = hp_dna_prX.select_dtypes(include = int)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.807335Z","iopub.execute_input":"2022-01-28T09:42:26.808037Z","iopub.status.idle":"2022-01-28T09:42:26.830014Z","shell.execute_reply.started":"2022-01-28T09:42:26.807982Z","shell.execute_reply":"2022-01-28T09:42:26.828976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's use the Random Forest regressor ","metadata":{}},{"cell_type":"code","source":"RFmodel = RandomForestRegressor(random_state=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.832227Z","iopub.execute_input":"2022-01-28T09:42:26.832842Z","iopub.status.idle":"2022-01-28T09:42:26.838099Z","shell.execute_reply.started":"2022-01-28T09:42:26.832793Z","shell.execute_reply":"2022-01-28T09:42:26.837062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit the model","metadata":{}},{"cell_type":"code","source":"RFmodel.fit(Xtr_int,hptrain_y)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:26.839169Z","iopub.execute_input":"2022-01-28T09:42:26.840136Z","iopub.status.idle":"2022-01-28T09:42:27.807252Z","shell.execute_reply.started":"2022-01-28T09:42:26.840094Z","shell.execute_reply":"2022-01-28T09:42:27.806332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute the MAE for Xtr_int","metadata":{}},{"cell_type":"code","source":"Xtr_int_mae = MAERROR(RFmodel.predict(Xtr_int),hptrain_y)\nprint(Xtr_int_mae)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.808575Z","iopub.execute_input":"2022-01-28T09:42:27.808933Z","iopub.status.idle":"2022-01-28T09:42:27.846453Z","shell.execute_reply.started":"2022-01-28T09:42:27.80889Z","shell.execute_reply":"2022-01-28T09:42:27.845556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute the MAE for Xval_int","metadata":{}},{"cell_type":"code","source":"pred_valy = RFmodel.predict(Xval_int)\nXval_int_mae = MAERROR(pred_valy,hpval_y)\nprint(Xval_int_mae)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.849961Z","iopub.execute_input":"2022-01-28T09:42:27.850212Z","iopub.status.idle":"2022-01-28T09:42:27.874835Z","shell.execute_reply.started":"2022-01-28T09:42:27.850183Z","shell.execute_reply":"2022-01-28T09:42:27.874095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on test data\n#pred_y = RFmodel.predict(Xpr_int)\n#pred_y.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.876597Z","iopub.execute_input":"2022-01-28T09:42:27.877316Z","iopub.status.idle":"2022-01-28T09:42:27.881123Z","shell.execute_reply.started":"2022-01-28T09:42:27.877251Z","shell.execute_reply":"2022-01-28T09:42:27.880456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Refine the results by exploring the data and refining the model. Let's visualize the data and get some idea about correlations","metadata":{}},{"cell_type":"markdown","source":"# Above plot shows that predicted distribution has sharply decaying tail.","metadata":{}},{"cell_type":"markdown","source":"#  Refinement-1 of the model:","metadata":{}},{"cell_type":"markdown","source":"## Let us add categorical variables as well into analysis","metadata":{"execution":{"iopub.status.busy":"2022-01-26T18:03:24.028703Z","iopub.execute_input":"2022-01-26T18:03:24.029106Z","iopub.status.idle":"2022-01-26T18:03:24.03243Z","shell.execute_reply.started":"2022-01-26T18:03:24.029067Z","shell.execute_reply":"2022-01-26T18:03:24.031784Z"}}},{"cell_type":"code","source":"hptrain_X.select_dtypes(object).shape","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.882572Z","iopub.execute_input":"2022-01-28T09:42:27.883Z","iopub.status.idle":"2022-01-28T09:42:27.897908Z","shell.execute_reply.started":"2022-01-28T09:42:27.882958Z","shell.execute_reply":"2022-01-28T09:42:27.896823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check which columns have 'object' data types\nobjs = (hptrain_X.dtypes == 'object')\n# print out names of object columns\nprint(objs[objs],'\\n')\n\n# make a list of those columns\nObjCols = list(objs[objs].index)\n#print(ObjCols,'\\n')\n\n# Check that the same list of 'objcols' works for the testing data \nobjs2 = (hp_dna_prX.dtypes == 'object')\nObjCols2 = np.array(list(objs2[objs2].index))\n#print(ObjCols2,'\\n')\nprint(np.array_equal(ObjCols2,ObjCols)) ","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.899485Z","iopub.execute_input":"2022-01-28T09:42:27.899725Z","iopub.status.idle":"2022-01-28T09:42:27.911723Z","shell.execute_reply.started":"2022-01-28T09:42:27.899697Z","shell.execute_reply":"2022-01-28T09:42:27.910585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Because of the finiteness of the sample data, the number of unique variables per a categorical column are different between the training, validation and test samples as the next cell shows","metadata":{}},{"cell_type":"code","source":"print(hpval_X[ObjCols].nunique().sum(),hptrain_X[ObjCols].nunique().sum(),hp_dna_prX[ObjCols].nunique().sum())","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.913214Z","iopub.execute_input":"2022-01-28T09:42:27.914113Z","iopub.status.idle":"2022-01-28T09:42:27.940449Z","shell.execute_reply.started":"2022-01-28T09:42:27.914063Z","shell.execute_reply":"2022-01-28T09:42:27.93941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Therefore, retain only those object columns which have same number of unique values for the categorical variables","metadata":{}},{"cell_type":"code","source":"stmt1 = hptrain_X[ObjCols].nunique() == hpval_X[ObjCols].nunique() \nstmt2 = hptrain_X[ObjCols].nunique() == hp_dna_prX[ObjCols].nunique()\nstmt3 = (stmt1) & (stmt2)\nObjColsCmn = list(stmt3[stmt3].index)\nprint('\\n','Object columns that have same nunique() values in \\\n      train,validate and test samples are',ObjColsCmn,'\\n')\n# Now form a dataframe of above object columns for training, validation and test sets \nXtrain = hptrain_X[ObjCols][ObjColsCmn]\nXval = hpval_X[ObjCols][ObjColsCmn]\nXpr = hp_dna_prX[ObjCols][ObjColsCmn]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.941601Z","iopub.execute_input":"2022-01-28T09:42:27.941817Z","iopub.status.idle":"2022-01-28T09:42:27.977681Z","shell.execute_reply.started":"2022-01-28T09:42:27.941789Z","shell.execute_reply":"2022-01-28T09:42:27.976736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's use the OneHotEncoder from scikit-learn","metadata":{}},{"cell_type":"code","source":"Ohe = OneHotEncoder(handle_unknown='error',sparse=False)\n\n# Do the OneHotEncoding on training, validation and testing datasets\nOheObjXtrain = pd.DataFrame(Ohe.fit_transform(Xtrain),columns=Ohe.get_feature_names(ObjColsCmn)) # these are the columns corresponding to object columns are OHE\nOheObjXval = pd.DataFrame(Ohe.fit_transform(Xval),columns=Ohe.get_feature_names(ObjColsCmn)) # these are the columns corresponding to object columns are OHE\nOheObjXpr = pd.DataFrame(Ohe.fit_transform(Xpr),columns=Ohe.get_feature_names(ObjColsCmn)) # these are the columns corresponding to object columns are OHE\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:27.979039Z","iopub.execute_input":"2022-01-28T09:42:27.979766Z","iopub.status.idle":"2022-01-28T09:42:28.021335Z","shell.execute_reply.started":"2022-01-28T09:42:27.979718Z","shell.execute_reply":"2022-01-28T09:42:28.02042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check that the number of columns OneHotEncoded(OHE) dataframes are same\nprint('shape of training sample is ',Xtrain.shape,' and shape of its OHE dataframe is ',OheObjXtrain.shape)\nprint('shape of validation sample is ',Xval.shape,' and shape of its OHE dataframe is ',OheObjXval.shape)\nprint('shape of test sample is ',Xpr.shape,' and shape of its OHE dataframe is ',OheObjXpr.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:28.022643Z","iopub.execute_input":"2022-01-28T09:42:28.023514Z","iopub.status.idle":"2022-01-28T09:42:28.030946Z","shell.execute_reply.started":"2022-01-28T09:42:28.023474Z","shell.execute_reply":"2022-01-28T09:42:28.029914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now replace the categorical columns in the datasets with the OneHotEncoded columns","metadata":{}},{"cell_type":"code","source":"#drop the categorical columns\nXtrainObjDrop= hptrain_X.drop(ObjCols,axis=1)\nXvalObjDrop= hpval_X.drop(ObjCols,axis=1)\nXprObjDrop= hp_dna_prX.drop(ObjCols,axis=1)\n\n#concat the dataframes(hereafter call DF) with OneHotEncoded columns\nXtr = pd.concat([XtrainObjDrop,OheObjXtrain],axis =1)\nXval = pd.concat([XvalObjDrop,OheObjXval],axis =1)\nXpr = pd.concat([XprObjDrop,OheObjXpr],axis =1)\n\n#print shape\nprint('Shape of training set is',XtrainObjDrop.shape)\nprint(hpval_X.shape,hptrain_X.shape)\nprint(Xval.shape,Xtr.shape,Xpr.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:28.032412Z","iopub.execute_input":"2022-01-28T09:42:28.032771Z","iopub.status.idle":"2022-01-28T09:42:28.04996Z","shell.execute_reply.started":"2022-01-28T09:42:28.032714Z","shell.execute_reply":"2022-01-28T09:42:28.048986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now let's throw the data into RandomForest and see what comes out!","metadata":{}},{"cell_type":"code","source":"# instatiate the model class\nRFmodel = RandomForestRegressor(random_state=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:28.050979Z","iopub.execute_input":"2022-01-28T09:42:28.051406Z","iopub.status.idle":"2022-01-28T09:42:28.0579Z","shell.execute_reply.started":"2022-01-28T09:42:28.051346Z","shell.execute_reply":"2022-01-28T09:42:28.057124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit\nRFmodel.fit(Xtr.iloc[:,1:],hptrain_y) #id actually doesn't play a role so don't use it","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:28.059316Z","iopub.execute_input":"2022-01-28T09:42:28.059779Z","iopub.status.idle":"2022-01-28T09:42:29.36638Z","shell.execute_reply.started":"2022-01-28T09:42:28.059747Z","shell.execute_reply":"2022-01-28T09:42:29.365445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute MAE for Xtr","metadata":{}},{"cell_type":"code","source":"Xtr_mae = MAERROR(RFmodel.predict(Xtr.iloc[:,1:]),hptrain_y)\nprint(Xtr_mae)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:29.367827Z","iopub.execute_input":"2022-01-28T09:42:29.368073Z","iopub.status.idle":"2022-01-28T09:42:29.406524Z","shell.execute_reply.started":"2022-01-28T09:42:29.368043Z","shell.execute_reply":"2022-01-28T09:42:29.405573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute MAE for Xval","metadata":{}},{"cell_type":"code","source":"\nXval_mae = MAERROR(RFmodel.predict(Xval.iloc[:,1:]),hpval_y)\nprint(Xval_mae)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:29.4083Z","iopub.execute_input":"2022-01-28T09:42:29.408586Z","iopub.status.idle":"2022-01-28T09:42:29.437311Z","shell.execute_reply.started":"2022-01-28T09:42:29.408554Z","shell.execute_reply":"2022-01-28T09:42:29.436519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict 'SalesPrice' for testing data and also get the MAE","metadata":{}},{"cell_type":"code","source":"pred_y = RFmodel.predict(Xpr.iloc[:,1:])\npred_y.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:29.442639Z","iopub.execute_input":"2022-01-28T09:42:29.443177Z","iopub.status.idle":"2022-01-28T09:42:29.489681Z","shell.execute_reply.started":"2022-01-28T09:42:29.443132Z","shell.execute_reply":"2022-01-28T09:42:29.488918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'Id': Xpr.Id,\n                       'SalePrice': pred_y})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T09:42:29.491151Z","iopub.execute_input":"2022-01-28T09:42:29.49198Z","iopub.status.idle":"2022-01-28T09:42:29.505067Z","shell.execute_reply.started":"2022-01-28T09:42:29.49194Z","shell.execute_reply":"2022-01-28T09:42:29.503834Z"},"trusted":true},"execution_count":null,"outputs":[]}]}