{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 1) Introduction </h1>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 2) Load Required Libraries </h1>","metadata":{}},{"cell_type":"code","source":"# Read Data\nimport numpy as np                     # Linear Algebra (calculate the mean and standard deviation)\nimport pandas as pd                    # manipulate data, data processing, load csv file I/O (e.g. pd.read_csv)\n\n# Visualization\nimport seaborn as sns                  # Visualization using seaborn\nimport matplotlib.pyplot as plt        # Visualization using matplotlib\n%matplotlib inline\nimport plotly                          # Visualization using Plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\n\n# style\nplt.style.use(\"fivethirtyeight\")       # Set Graphs Background style using matplotlib\nsns.set_style(\"darkgrid\")              # Set Graphs Background style using seaborn\n\n# ML model building; Pre Processing & Evaluation\nfrom sklearn.model_selection import train_test_split                     # split  data into training and testing sets\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge          # Linear Regression, Lasso and Ridge\nfrom sklearn.linear_model import LogisticRegression                      # Logistic Regression\nfrom sklearn.tree import DecisionTreeRegressor                           # Decision tree Regression\nfrom sklearn.ensemble import RandomForestRegressor                       # this will make a Random Forest Regression\nfrom sklearn import svm                                                  # this will make a SVM classificaiton\nfrom sklearn.svm import SVC                                              # import SVC from SVM\nimport xgboost\nfrom sklearn.metrics import confusion_matrix, classification_report      # this creates a confusion matrix\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.metrics import roc_curve,auc                                # ROC\nfrom sklearn.preprocessing import StandardScaler                         # Standard Scalar\nfrom sklearn.model_selection import GridSearchCV                         # this will do cross validation\nfrom sklearn.decomposition import PCA                                    # to perform PCA to plot the data\n\nimport warnings                                                          # Ignore Warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 3) Read Data </h1>","metadata":{}},{"cell_type":"code","source":"# Import first 5 rows\ntrain = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.head())\ndisplay(test.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking dimension (num of rows and columns) of dataset\nprint(\"Training data shape (Rows, Columns):\",train.shape)\nprint(\"Test data shape (Rows, Columns):\",test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for Numerical and Categorical features","metadata":{}},{"cell_type":"code","source":"# check dataframe structure like columns and its counts, datatypes & Null Values\ntrain.info()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Our dataset features consists of three datatypes\n     1. float\n     2. integer\n     3. object\n- Total numerical features are 38\n- Total categorical features are 43\n- Also we don't have complete data for all of our features","metadata":{}},{"cell_type":"code","source":"# check dataframe structure like columns and its counts, datatypes & Null Values\ntest.info()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# descriptive statistics (numerical columns)\ntrain.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- for **each feature** it provides below:\n\n     1. count       --->  total no of data points\n     2. statistics  --->  mean, standard deviation\n     3. min & max   --->  values of feature\n     4. percentile  --->  25%, 50%, 75%","metadata":{}},{"cell_type":"code","source":"test.dtypes.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Our dataset features consists of three datatypes\n     1. float\n     2. integer\n     3. object\n- Total numerical features are 37\n- Total categorical features are 43\n- Also we don't have complete data for all of our features","metadata":{}},{"cell_type":"code","source":"# Gives number of data points in each variable\ntrain.count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge the train and test data and inspect the data type\nmerged = pd.concat([train, test], axis=0, sort=True)\ndisplay(merged.dtypes.value_counts())\nprint('Dimensions of data:', merged.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge the train and test data and inspect the data type\nmerged = pd.concat([train, test], axis=0, sort=True)\ndisplay(merged.dtypes.value_counts())\nprint('Dimensions of data:', merged.shape)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 4) EDA (Exploratory Data Analysis) </h1>\n\n- EDA is a way of **Visualizing, Summarizing and interpreting** the information that is **hidden in rows and column** format.","metadata":{}},{"cell_type":"code","source":"train['MSZoning'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Dataset\n#### a. Numeric Features","metadata":{}},{"cell_type":"code","source":"numeric_cols_train = train.select_dtypes(include=[np.number])\ndisplay(numeric_cols_train.head())\nprint('\\n')\nnumeric_cols_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_cols_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b. Categorical Features","metadata":{}},{"cell_type":"code","source":"categorical_cols_train = train.select_dtypes(include=[np.object])\ndisplay(categorical_cols_train.head())\nprint('\\n')\ncategorical_cols_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Dataset\n#### a. Numeric Features","metadata":{}},{"cell_type":"code","source":"numeric_cols_test = test.select_dtypes(exclude='object')\ndisplay(numeric_cols_test.head())\nprint('\\n')\nnumeric_cols_test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b. Categorical Features","metadata":{}},{"cell_type":"code","source":"categorical_cols_test = test.select_dtypes(include=[np.object])\ndisplay(categorical_cols_test.head())\nprint('\\n')\ncategorical_cols_test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Steps involved in EDA:\n1. Find Unwanted Columns\n- Find Missing Values\n- Find Features with one value\n- Explore the Categorical Features\n- Find Categorical Feature Distribution\n- Relationship between Categorical Features and Label\n- Explore the Numerical Features\n- Find Discrete Numerical Features\n- Relation between Discrete numerical Features and Labels\n- Find Continous Numerical Features\n- Distribution of Continous Numerical Features\n- Relation between Continous numerical Features and Labels\n- Find Outliers in numerical features\n- Explore the Correlation between numerical features","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.1) Find Unwanted Columns </h1>","metadata":{}},{"cell_type":"markdown","source":"- There is no unwanted column present in given dataset to remove.\n\n     EX: ID","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.2) Missing Values </h1>","metadata":{}},{"cell_type":"markdown","source":"- Checking missing values by below methods:\n\n     1. df.isnull().sum()\n        - It returns null values for each column\n          \n     2. isnull().any()\n        - It returns True if column have NULL Values\n        - It returns False if column don't have NULL Values\n          \n     3. Heatmap()\n        - Missing value representation using heatmap.\n          \n     4. Percentage of Missing values","metadata":{}},{"cell_type":"code","source":"# Listing Number of missing values by feature column wise\ntrain_missing = train.isnull().sum().sort_values(ascending=False)\ntrain_missing = train_missing[train_missing > 0]\ntrain_missing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Listing Number of missing values by feature column wise\ntest_missing = test.isnull().sum().sort_values(ascending=False)\ntest_missing = test_missing[test_missing > 0]\ntest_missing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# any() check null values by columns\ntrain.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17,10))\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17,10))\nsns.heatmap(test.isnull(), yticklabels=False, cbar=False, cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- All columns have **more than 1 unique value.** No feature found with one value.\n\n\n- There could be chance of only one category in a particular feature. In Categorical features, suppose gender column we have only one value ie male.Then there is no use of that feature in dataset. ","metadata":{}},{"cell_type":"code","source":"# Percentage of Missing values in train dataset\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = ((train.isnull().sum()/train.isnull().count())*100).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, join='outer', keys=['Total Missing Count', '% of Total Observations'])\nmissing_data.index.name =' Numeric cols'\n\nmissing_data.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of Missing values in train dataset\ntotal = test.isnull().sum().sort_values(ascending=False)\npercent = ((test.isnull().sum()/test.isnull().count())*100).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, join='outer', keys=['Total Missing Count', '% of Total Observations'])\nmissing_data.index.name =' Numeric cols'\n\nmissing_data.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Find Features with one value","metadata":{}},{"cell_type":"code","source":"for column in train.columns:\n    print(column,train[column].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4. Explore the Categorical Features","metadata":{}},{"cell_type":"code","source":"categorical_features = [feature for feature in train.columns if train[feature].dtypes=='O']\ncategorical_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(train[feature].unique())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. Find Categorical Feature Distribution","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(round(len(categorical_cols_train.columns) / 3), 3, figsize=(12, 30))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(categorical_cols_train.columns):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n        sns.countplot(x=categorical_cols_train.columns[i], alpha=0.7, data=categorical_cols_train, ax=ax)\n\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6. Relationship between Categorical Features and Label","metadata":{}},{"cell_type":"code","source":"# Find out the relationship between categorical variable and dependent varaible\nplt.figure(figsize=(15,70), facecolor='white')\nplotnumber =1\nfor feature in categorical_features:\n    ax = plt.subplot(11,4,plotnumber)\n    data=train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plotnumber+=1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7. Explore the Numerical Features","metadata":{}},{"cell_type":"code","source":"numerical_features = train.select_dtypes(exclude='object')\nnumerical_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8. Find Discrete Numerical Features","metadata":{}},{"cell_type":"code","source":"discrete_feature=[feature for feature in numerical_features if len(train[feature].unique())<25]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 9. Find Continous Numerical Features","metadata":{}},{"cell_type":"code","source":"continuous_features=[feature for feature in numerical_features if feature not in discrete_feature+['target']]\nprint(\"Continuous feature Count {}\".format(len(continuous_features)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"continuous_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 10. Distribution of Continous Numerical Features","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5,4, figsize=(16,16))\nsns.distplot(train['LotFrontage'], bins = 20, ax=ax[0,0]) \nsns.distplot(train.LotArea, bins = 20, ax=ax[0,1]) \nsns.distplot(train.YearBuilt, bins = 20, ax=ax[0,2]) \nsns.distplot(train.YearRemodAdd, bins = 20, ax=ax[0,3])\nsns.distplot(train.MasVnrArea, bins = 20, ax=ax[1,0]) \nsns.distplot(train.BsmtFinSF1, bins = 20, ax=ax[1,1]) \nsns.distplot(train.BsmtUnfSF, bins = 20, ax=ax[1,3])\nsns.distplot(train.TotalBsmtSF, bins = 20, ax=ax[2,0])\nsns.distplot(train['1stFlrSF'], bins = 20, ax=ax[2,1])\nsns.distplot(train['2ndFlrSF'], bins = 20, ax=ax[2,2])\nsns.distplot(train.GrLivArea, bins = 20, ax=ax[2,3])\nsns.distplot(train.GarageYrBlt, bins = 20, ax=ax[3,0])\nsns.distplot(train.GarageArea, bins = 20, ax=ax[3,1])\nsns.distplot(train.WoodDeckSF, bins = 20, ax=ax[3,2])\nsns.distplot(train.OpenPorchSF, bins = 20, ax=ax[3,3])\nsns.distplot(train.SalePrice, bins = 20, ax=ax[4,2])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- it seems all continuous features are not normally distributed\n\n- **MasVnrArea, BsmtFinSF1, BsmtUnfSF, 2ndFlrSF, GrLivArea & SalePrice** are **right skewed**\n\n- **YearBuilt,GarageYrBlt,GarageArea,YearRemodAdd** is **left skewed**.","metadata":{}},{"cell_type":"markdown","source":"#### 11. Relation between Continous numerical Features and Labels","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor feature in continuous_features:\n    data=train.copy()\n    ax = plt.subplot(12,3,plotnumber)\n    plt.scatter(train[feature],train['SalePrice'])\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plotnumber+=1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.3) Outliers </h1>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,18))\noutliers = train.drop(['Id', 'SalePrice'], axis=1)\nsns.boxplot(data=outliers, orient='h', palette='Set2');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_IQR = train[['MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', '2ndFlrSF', 'GrLivArea', 'YearBuilt', 'GarageYrBlt',\n                   'GarageArea', 'YearRemodAdd']]\nQ1 = train_IQR.quantile(0.25)\nQ3 = train_IQR.quantile(0.75)\nIQR = Q3 - Q1\nIQR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here are the outliers\n\ntrain_IQR_clean = train_IQR[~((train_IQR < (Q1 - 1.5*IQR)) | (train_IQR > (Q3 + 1.5*IQR))).any(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxplot() showing outlier\nbox = train_IQR_clean\nplt.figure(figsize=(12,10))\nsns.boxplot(data=box)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.4) Relation between Features </h1>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.4.1) The correlation between the continuos variables </h1>\n\na. Pearson Correlation\n\nb. Spearman Correlation\n\nc. kendall","metadata":{}},{"cell_type":"code","source":"# Pearson Correlation\nplt.figure(figsize=(23,18))\nsns.heatmap(outliers.corr(method='pearson'), cbar=False, annot=True, fmt='.1f', linewidth=0.2, cmap='summer');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spearman Correlation\nplt.figure(figsize=(23,18))\nsns.heatmap(outliers.corr(method='spearman'), cbar=False, annot=True, fmt='.1f', linewidth=0.2, cmap='viridis');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,14))\ncorr = outliers.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nax.text(-1.1, -0.7, 'Correlation between the Features', fontsize=20, fontweight='bold', fontfamily='serif')\nsns.heatmap(corr, mask=mask, annot=False, fmt='.2f', linewidth=0.2, cbar=True, cmap='coolwarm');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = numeric_cols_train.drop('SalePrice', axis=1).corr()\nplt.figure(figsize=(17, 14))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- A lot of features seems to be correlated between each other but some of them such as **YearBuild/GarageYrBlt** may just indicate a price inflation over the years. As for **1stFlrSF/TotalBsmtSF**, it is normal that the more the 1st floor is large (considering many houses have only 1 floor), the more the total basement will be large.\n\n- There is a strong negative correlation between **BsmtUnfSF and BsmtFinSF2**.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,12))\ncorr = numeric_cols_train.corr()\nk= 11\ncols = corr.nlargest(k,'SalePrice')['SalePrice'].index\nprint(cols)\ncm = np.corrcoef(train[cols].values.T)\nsns.heatmap(cm, cmap='viridis', vmax=.8, annot=True, linewidth=2, linecolor=\"white\", xticklabels = cols.values,\n            yticklabels = cols.values, square=True, annot_kws = {'size':12})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 'GarageCars' and 'GarageArea' are strongly correlated variables. It is because the number of cars that fit into the garage is a consequence of the garage area. 'GarageCars' and 'GarageArea' are like twin brothers. So it is hard to distinguish between the two. Therefore, we just need one of these variables in our analysis (we can keep 'GarageCars' since its correlation with 'SalePrice' is higher).\n\n\n- 'TotRmsAbvGrd' and 'GrLivArea', twins","metadata":{}},{"cell_type":"code","source":"# kendall\nfig, ax = plt.subplots(1, 3, figsize=(20 , 8))\n\nfeature_lst = ['LotFrontage', 'LotArea', 'YearBuilt','MasVnrArea','OpenPorchSF', 'GarageYrBlt', 'GarageArea', 'OpenPorchSF', 'WoodDeckSF', 'KitchenAbvGr', 'TotRmsAbvGrd']\n\ncorr = train[feature_lst].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nfor idx, method in enumerate(['pearson', 'kendall', 'spearman']):\n    sns.heatmap(train[feature_lst].corr(method=method), ax=ax[idx],\n            square=True, annot=True, fmt='.1f', center=0, linewidth=2,\n            cbar=False, cmap=sns.diverging_palette(240, 10, as_cmap=True),\n            mask=mask\n           ) \n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')     \n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.4.2) The correlation between the continuos variables </h1>","metadata":{}},{"cell_type":"code","source":"train.corr()['SalePrice'].sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = train.drop(['SalePrice'], axis=1)\na.corrwith(train['SalePrice']).plot(kind='bar', figsize=(18,14), color=['salmon'])\nplt.title('Correlation b/n target and Independant features')\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.5) Skewness and Kurtosis </h1>","metadata":{}},{"cell_type":"markdown","source":"- Skewness tells us about the symmetry in a distribution.\n\n* If the **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.\n  \n* If the **skewness** is **between -1 to -0.5 or 0.5 to 1** then data is **moderately skewed**.\n  \n* If the **skewness** is **less than -1 and greater than +1** then our data is **heavily skewed**.","metadata":{}},{"cell_type":"code","source":"train.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In our above data,\n    1. LotArea\n    2. LowQualFinSF\n    3. 3SsnPorch\n    4. PoolArea\n    5. MiscVal\n- Are highly positively,right skewed.","metadata":{}},{"cell_type":"code","source":"test.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking Skewness for feature \"SalePrice\"\nsns.distplot(train['SalePrice'])\nSkew_SalePrice = train['SalePrice'].skew()\nplt.title(\"Skew:\"+str(Skew_SalePrice))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SalePrice right skewed; log transform)\nsns.distplot(np.log(train['SalePrice']+1))\nSkew_SalePrice_Log = np.log(train['SalePrice']+1).skew()\nplt.title(\"Skew:\"+str(Skew_SalePrice_Log))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a) Checking Skewness for feature \"LotArea\"\n# Checking the skewness of \"LotArea\" attributes\ntrain['LotArea'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating the square for the column df['LotArea'] column\nlog_LotArea_train = np.log(train['LotArea'])\nlog_LotArea_train.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# b) Checking Skewness for feature \"LowQualFinSF\"\n# Checking the skewness of \"LowQualFinSF\" attributes\ntrain['LowQualFinSF'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating the square for the column df['LowQualFinSF'] column\nrecipr_LowQualFinSF_train = np.reciprocal(train['LowQualFinSF'])\nrecipr_LowQualFinSF_train.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# c) Checking Skewness for feature \"3SsnPorch\"\n# Checking the skewness of \"3SsnPorch\" attributes\ntrain['3SsnPorch'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performing the log transformation using numpy\nrecipr_3SsnPorch_train = np.reciprocal(train['3SsnPorch'])\nrecipr_3SsnPorch_train.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d) Checking Skewness for feature \"PoolArea\"\n# Checking the skewness of \"PoolArea\" attributes\ntrain['PoolArea'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performing the log transformation using numpy\ncuberoot_PoolArea_train = np.cbrt(train['PoolArea'])\ncuberoot_PoolArea_train.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# e) Checking Skewness for feature \"MiscVal\"\n# Checking the skewness of \"MiscVal\" attributes\ntrain['MiscVal'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performing the log transformation using numpy\nrecipr_MiscVal_train = np.reciprocal(train['MiscVal'])\nrecipr_MiscVal_train.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_skew = pd.concat([log_LotArea_train, recipr_LowQualFinSF_train, recipr_3SsnPorch_train,\n                        recipr_MiscVal_train], axis=1)\ntrain_skew","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['LotArea','LowQualFinSF','3SsnPorch','MiscVal'], inplace=True, axis=1)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train = pd.concat([train, train_skew], axis=1)\nnew_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_cols_test.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In our above data,\n    1. LowQualFinSF\n    2. 3SsnPorch\n    3. PoolArea\n    4. MiscVal\n- Are highly positively,right skewed.","metadata":{}},{"cell_type":"code","source":"# a) Checking Skewness for feature \"LowQualFinSF\"\n# Checking the skewness of \"LowQualFinSF\" attributes\ntest['LowQualFinSF'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performing the cube root transformation using numpy\ncube_root_LowQualFinSF_test = np.cbrt(test['LowQualFinSF'])\ncube_root_LowQualFinSF_test.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# b) Checking Skewness for feature \"3SsnPorch\"\n# Checking the skewness of \"3SsnPorch\" attributes\ntest['3SsnPorch'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performing the cube root transformation using numpy\ncube_root_3SsnPorch_test = np.cbrt(test['3SsnPorch'])\ncube_root_3SsnPorch_test.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# c) Checking Skewness for feature \"PoolArea\"\n# Checking the skewness of \"PoolArea\" attributes\ntest['PoolArea'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performing the cube root transformation using numpy\nrecipr_PoolArea_test = np.reciprocal(test['PoolArea'])\nrecipr_PoolArea_test.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d) Checking Skewness for feature \"MiscVal\"\n# Checking the skewness of \"MiscVal\" attributes\ntest['MiscVal'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performing the cube root transformation using numpy\ncube_root_MiscVal_test = np.cbrt(test['MiscVal'])\ncube_root_MiscVal_test.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 5) Data Visualization </h1>\n\n- Used below **visualisation libraries**\n\n     1. Matplotlib\n     2. Seaborn (statistical data visualization)\n     \n### 1. Categorical\n\n- Categorical data :\n\n     1. Numerical Summaries\n     2. Histograms\n     3. Pie Charts\n\n\n### 2. Univariate Analysis\n\n- Univariate Analysis : data consists of **only one variable (only x value)**.\n\n     1. Line Plots / Bar Charts\n     2. Histograms\n     3. Box Plots \n     4. Count Plots\n     5. Descriptive Statistics techniques\n     6. Violin Plot","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> 5.1) Univariate Analysis </h1>","metadata":{}},{"cell_type":"markdown","source":"### 1. Histogram","metadata":{}},{"cell_type":"code","source":"# Histogram for \"SalePrice\"\nplt.figure(figsize=(9,7))\nsns.distplot(train['SalePrice']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- With this information we can see that the prices are skewed right and some outliers lies above ~500,000. We will eventually want to get rid of the them to get a normal distribution of the independent variable (SalePrice) for machine learning","metadata":{}},{"cell_type":"code","source":"# Histogram for \"Numerical Features in train dataset\"\nnumeric_cols_train.hist(figsize=(16, 20), bins=50, xlabelsize=7, ylabelsize=7);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Histogram for \"Numerical Features in test dataset\"\nnumeric_cols_test.hist(figsize=(16, 20), bins=50, xlabelsize=7, ylabelsize=7);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> 5.2) Bivariate Analysis </h1>\n\n- **Bivariate Analysis** : data involves **two different variables**.\n\n     1. Bar Charts\n     2. Scatter Plots\n     3. FacetGrid\n     \n\n-  There are **three** types of bivariate analysis\n\n     1. Numerical & Numerical\n     2. Categorical & Categorical\n     3. Numerical & Categorical","metadata":{}},{"cell_type":"markdown","source":"### 1. Line Plot","metadata":{}},{"cell_type":"markdown","source":"#### YrSold Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Line Plot between \"YrSold\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['YrSold'], y=train['SalePrice'])\n\nplt.xlabel('YrSold', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('YrSold Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### YearBuilt Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Line Plot between \"YearBuilt\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['YearBuilt'], y=train['SalePrice'])\n\nplt.xlabel('YearBuilt', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('YearBuilt Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### MoSold Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Line Plot between \"MoSold\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['MoSold'], y=train['SalePrice'])\n\nplt.xlabel('MoSold', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('MoSold Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### OverallQual Vs SalePrice","metadata":{}},{"cell_type":"code","source":"train['OverallQual'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Line Plot between \"OverallQual\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['OverallQual'], y=train['SalePrice'])\n\nplt.xlabel('OverallQual', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('OverallQual Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### SaleCondition Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Line Plot between \"SaleCondition\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['SaleCondition'], y=train['SalePrice'])\n\nplt.xlabel('SaleCondition', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('SaleCondition Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Scatter Plot","metadata":{}},{"cell_type":"markdown","source":"#### OverallQual Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"OverallQual\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(x=train['OverallQual'], y=train['SalePrice'])\n\nplt.xlabel('OverallQual', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('OverallQual Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GrLivArea Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"GrLivArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.GrLivArea, train.SalePrice)\n\nplt.xlabel('GrLivArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('GrLivArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GarageArea Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"GarageArea\" and \"target\" variable\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.GarageArea, train.SalePrice)\n\nplt.xlabel('GarageArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('GarageArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TotalBsmtSF Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"TotalBsmtSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.TotalBsmtSF, train.SalePrice)\n\nplt.xlabel('TotalBsmtSF', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('TotalBsmtSF Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  1stFlrSF Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"1stFlrSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train['1stFlrSF'], train.SalePrice)\n\nplt.xlabel('1stFlrSF', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('1stFlrSF Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### SalePrice vs MasVnrArea","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"MasVnrArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.MasVnrArea, train.SalePrice)\n\nplt.xlabel('MasVnrArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('MasVnrArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter Plot between \"MasVnrArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(np.sqrt(train['MasVnrArea']),np.log(train['SalePrice']))\n\nplt.xlabel('Sqrt_MasVnrArea', fontsize=15, fontweight='bold')\nplt.ylabel('log_SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('Sqrt_MasVnrArea Vs log_SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### MSSubClass Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"MSSubClass\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['MSSubClass'], train['SalePrice'])\n\nplt.xlabel('MSSubClass', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('MSSubClass Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### LotFrontage Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"LotFrontage\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['LotFrontage'], train['SalePrice'])\n\nplt.xlabel('LotFrontage', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('LotFrontage Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Observed **Outliers**","metadata":{}},{"cell_type":"markdown","source":"#### LotArea Vs SalePrice","metadata":{}},{"cell_type":"markdown","source":"# Scatter Plot between \"LotArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['LotArea'], train['SalePrice'])\n\nplt.xlabel('LotArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('LotArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{}},{"cell_type":"markdown","source":"- Observed **Outliers** and **non-linear** relationship","metadata":{}},{"cell_type":"markdown","source":"# Scatter Plot between \"LotArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(np.log(train['LotArea']), np.log(train['SalePrice']))\n\nplt.xlabel('log_LotArea', fontsize=15, fontweight='bold')\nplt.ylabel('log_SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('log_LotArea Vs log_SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{}},{"cell_type":"markdown","source":"#### TotRmsAbvGrd Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"TotRmsAbvGrd\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['TotRmsAbvGrd'], train['SalePrice'])\n\nplt.xlabel('TotRmsAbvGrd', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('TotRmsAbvGrd Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### CentralAir Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"CentralAir\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['CentralAir'], train['SalePrice'])\n\nplt.xlabel('CentralAir', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('CentralAir Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### KitchenAbvGr Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"KitchenAbvGr\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['KitchenAbvGr'], train['SalePrice'])\n\nplt.xlabel('KitchenAbvGr', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('KitchenAbvGr Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### OpenPorchSF Vs SalePrice","metadata":{}},{"cell_type":"code","source":"# Scatter Plot between \"OpenPorchSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['OpenPorchSF'], train['SalePrice'])\n\nplt.xlabel('OpenPorchSF', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('OpenPorchSF Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter Plot between \"OpenPorchSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(np.log(train['OpenPorchSF']),np.log(train['SalePrice']))\n\nplt.xlabel('log_OpenPorchSF', fontsize=15, fontweight='bold')\nplt.ylabel('log_SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('log_OpenPorchSF Vs log_SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Box Plot","metadata":{}},{"cell_type":"code","source":"# Box Plot for \"BsmtExposure\" & \"SalePrice\"\nplt.figure(figsize = (10, 6))\nsns.boxplot(x='BsmtExposure', y='SalePrice', data=train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box Plot for \"SaleCondition\" & \"SalePrice\"\nplt.figure(figsize = (12, 6))\nsns.boxplot(x='SaleCondition', y='SalePrice', data=train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box Plot for \"Neighborhood\" & \"SalePrice\"\nplt.figure(figsize=(15, 9))\nsns.boxplot(x='Neighborhood', y=\"SalePrice\", data=train)\nplt.xticks(rotation=90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Count Plot","metadata":{}},{"cell_type":"code","source":"# Count Plot for \"Neighborhood\"\nplt.figure(figsize = (15, 9))\nsns.countplot(x = 'Neighborhood', data = train)\nxt = plt.xticks(rotation=45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_feat = set(train._get_numeric_data().columns)\nfeat = set(train.columns)\ncat_feat = list(feat-num_feat)\nprint(\"total categoricalfeatures : \"+str(len(cat_feat)))\n\ny='SalePrice'\nfor i,j in enumerate(cat_feat):\n    \n    sns.catplot(x=j, y=y, data=train, alpha=0.5)\n    plt.xticks(rotation=90)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> 5.3) Multivariate Analysis </h1>\n\n- 1. Pair Plot\n    \n    Pair Plot between 'SalePrice' and correlated variables","metadata":{}},{"cell_type":"code","source":"sns.set()\ncolumns = ['SalePrice','OverallQual','TotalBsmtSF','GrLivArea','GarageArea','FullBath','YearBuilt','YearRemodAdd']\nsns.pairplot(train[columns], height = 2, kind ='scatter', diag_kind='kde')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop Features have more missing values","metadata":{}},{"cell_type":"code","source":"# Drop columns of train dataset with more than 25% of missing data\n\ntrain.drop(columns=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], inplace=True, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop columns of test dataset with more than 25% of missing data\n\ntest.drop(columns=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], inplace=True, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### filling nan values of categorical features by their mode and numeric ones by thier mean.","metadata":{}},{"cell_type":"code","source":"df = [train, test]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # train data\n    \n      # Numeric Features\n        \n    train['LotFrontage'] = train['LotFrontage'].fillna(train['LotFrontage'].mean())  # float\n    train['GarageYrBlt'] = train['GarageYrBlt'].fillna(train['GarageYrBlt'].mean())  # float\n    train['MasVnrArea'] = train['MasVnrArea'].fillna(train['MasVnrArea'].mean())     # float\n    \n      # Categorical Features\n        \n    train['GarageCond'] = train['GarageCond'].fillna(train['GarageCond'].mode()[0])\n    train['GarageQual'] = train['GarageQual'].fillna(train['GarageQual'].mode()[0])\n    train['GarageFinish'] = train['GarageFinish'].fillna(train['GarageFinish'].mode()[0])\n    train['GarageType'] = train['GarageType'].fillna(train['GarageType'].mode()[0])\n    train['BsmtFinType2'] = train['BsmtFinType2'].fillna(train['BsmtFinType2'].mode()[0])\n    train['BsmtExposure'] = train['BsmtExposure'].fillna(train['BsmtExposure'].mode()[0])\n    train['BsmtFinType1'] = train['BsmtFinType1'].fillna(train['BsmtFinType1'].mode()[0])\n    train['BsmtQual'] = train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])\n    train['BsmtCond'] = train['BsmtCond'].fillna(train['BsmtCond'].mode()[0])\n    train['MasVnrType'] = train['MasVnrType'].fillna(train['MasVnrType'].mode()[0])\n    train['Electrical'] = train['Electrical'].fillna(train['Electrical'].mode()[0])\n    \n    # test data\n    \n      # Numeric Featurestrain\n        \n    test['LotFrontage'] = test['LotFrontage'].fillna(test['LotFrontage'].mean())  # float\n    test['GarageYrBlt'] = test['GarageYrBlt'].fillna(test['GarageYrBlt'].mean())  # float\n    test['MasVnrArea'] = test['MasVnrArea'].fillna(test['MasVnrArea'].mean())     # float\n    test['BsmtHalfBath'] = test['BsmtHalfBath'].fillna(test['BsmtHalfBath'].mean())\n    test['BsmtFullBath'] = test['BsmtFullBath'].fillna(test['BsmtFullBath'].mean())\n    test['GarageArea'] = test['GarageArea'].fillna(test['GarageArea'].mean())\n    test['BsmtFinSF1'] = test['BsmtFinSF1'].fillna(test['BsmtFinSF1'].mean())\n    test['BsmtFinSF2'] = test['BsmtFinSF2'].fillna(test['BsmtFinSF2'].mean())\n    test['BsmtUnfSF'] = test['BsmtUnfSF'].fillna(test['BsmtUnfSF'].mean())\n    test['TotalBsmtSF'] = test['TotalBsmtSF'].fillna(test['TotalBsmtSF'].mean())\n    test['GarageCars'] = test['GarageCars'].fillna(test['GarageCars'].mean())\n    \n      # Categorical Features\n        \n    test['GarageCond'] = test['GarageCond'].fillna(test['GarageCond'].mode()[0])\n    test['GarageQual'] = test['GarageQual'].fillna(test['GarageQual'].mode()[0])\n    test['GarageFinish'] = test['GarageFinish'].fillna(test['GarageFinish'].mode()[0])\n    test['GarageType'] = test['GarageType'].fillna(test['GarageType'].mode()[0])\n    test['BsmtQual'] = test['BsmtQual'].fillna(test['BsmtQual'].mode()[0])\n    test['BsmtCond'] = test['BsmtCond'].fillna(test['BsmtCond'].mode()[0])\n    test['BsmtFinType2'] = test['BsmtFinType2'].fillna(test['BsmtFinType2'].mode()[0])\n    test['BsmtExposure'] = test['BsmtExposure'].fillna(test['BsmtExposure'].mode()[0])\n    test['BsmtFinType1'] = test['BsmtFinType1'].fillna(test['BsmtFinType1'].mode()[0])\n    test['MasVnrType'] = test['MasVnrType'].fillna(test['MasVnrType'].mode()[0])\n    test['MSZoning'] = test['MSZoning'].fillna(test['MSZoning'].mode()[0])\n    test['Utilities'] = test['Utilities'].fillna(test['Utilities'].mode()[0])\n    test['Functional'] = test['Functional'].fillna(test['Functional'].mode()[0])\n    test['KitchenQual'] = test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\n    test['SaleType'] = test['SaleType'].fillna(test['SaleType'].mode()[0])\n    test['Exterior2nd'] = test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\n    test['Exterior1st'] = test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17,10))\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17,10))\nsns.heatmap(test.isnull(), yticklabels=False, cbar=False, cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 6) Model building and Evaluation </h1>","metadata":{}},{"cell_type":"markdown","source":"### OneHotEncoding","metadata":{}},{"cell_type":"code","source":"# Transform discrete values to columns with 1 and 0s\ntrain_OHE = pd.get_dummies(train)\n\n# Do the same for competition data\ntest_OHE = pd.get_dummies(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_OHE.head())\ndisplay(test_OHE.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,12))\ncorr = numeric_cols_train.corr()\nk= 11\ncols = corr.nlargest(k,'SalePrice')['SalePrice'].index\nprint(cols)\ncm = np.corrcoef(train[cols].values.T)\nsns.heatmap(cm, cmap='viridis', vmax=.8, annot=True, linewidth=2, linecolor=\"white\", xticklabels = cols.values,\n            yticklabels = cols.values, square=True, annot_kws = {'size':12})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Data Shape (Rows,Columns):\",train_OHE.shape)\nprint(\"Competition Data Shape (Rows,Columns):\", test_OHE.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There is a differece between features in the training data set and the test data set\n# We will try dropping the features that are not present in both sets\n\nmissingFeatures_train = list(set(train_OHE.columns.values) - set(test_OHE.columns.values))\ntrain_OHE = train_OHE.drop(missingFeatures_train, axis=1)\n\nmissingFeatures_test = list(set(test_OHE.columns.values) - set(train_OHE.columns.values))\ntest_OHE = test_OHE.drop(missingFeatures_test, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Data Shape (Rows,Columns):\",train_OHE.shape)\nprint(\"Competition Data Shape (Rows,Columns):\", test_OHE.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Independant variable\nX = train_OHE                     # All rows & columns exclude Target features\n\n# Dependant variable\ny = train['SalePrice']        # Only target feature","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split  data into training and testing sets of 80:20 ratio\n# 20% of test size selected\n# random_state is random seed\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shape of X & Y test / train\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.1) Linear Regression / Lasso / Ridge </h1>","metadata":{}},{"cell_type":"code","source":"LinReg = LinearRegression()\nLinReg.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lasso Regression\nlasso = Lasso()\nlasso.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ridge Regression\nridge = Ridge()\nridge.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_LinReg = LinReg.predict(X_test)\ny_pred_lasso = lasso.predict(X_test)\ny_pred_ridge = ridge.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train_LinReg = LinReg.predict(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Linear Regression : Train Score {:.2f} & Test Score {:.2f}\".format(LinReg.score(X_train, y_train), LinReg.score(X_test, y_test)))\nprint(\"Lasso Regression : Train Score {:.2f} & Test Score {:.2f}\".format(lasso.score(X_train, y_train), lasso.score(X_test, y_test)))\nprint(\"Ridge Regression : Train Score {:.2f} & Test Score {:.2f}\".format(ridge.score(X_train, y_train), ridge.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n\nprint(\"\"\"LinearRegression \\t {:.2f} \\t\\t {:.2f} \\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_LinReg)),\n            mean_squared_error(y_test, y_pred_LinReg),\n            mean_absolute_error(y_test, y_pred_LinReg),\n            r2_score(y_test, y_pred_LinReg)))\n\nprint(\"\"\"LassoRegression \\t {:.2f} \\t\\t {:.2f} \\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_lasso)),\n            mean_squared_error(y_test, y_pred_lasso),\n            mean_absolute_error(y_test, y_pred_lasso),\n            r2_score(y_test, y_pred_lasso)))\n\nprint(\"\"\"RidgeRegression \\t {:.2f} \\t\\t {:.2f} \\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_ridge)),\n            mean_squared_error(y_test, y_pred_ridge),\n            mean_absolute_error(y_test, y_pred_ridge),\n            r2_score(y_test, y_pred_ridge)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Predictions\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(12,4))\n\nax1.scatter(y_pred_LinReg, y_test, s=20)\nax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nax1.set_ylabel(\"True\")\nax1.set_xlabel(\"Predicted\")\nax1.set_title(\"Linear Regression\")\n\nax2.scatter(y_pred_lasso, y_test, s=20)\nax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nax2.set_ylabel(\"True\")\nax2.set_xlabel(\"Predicted\")\nax2.set_title(\"Lasso Regression\")\n\nax3.scatter(y_pred_ridge, y_test, s=20)\nax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nax3.set_ylabel(\"True\")\nax3.set_xlabel(\"Predicted\")\nax3.set_title(\"Ridge Regression\")\nfig.suptitle(\"True vs Predicted\")\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,8))\n\nplt.scatter(y_pred_train_LinReg, y_train, c = \"blue\",  label = \"Training data\")\nplt.scatter(y_pred_LinReg, y_test, c = \"black\",  label = \"Test data\")\nplt.plot(y_train, y_train, alpha=0.3, c='r')\n\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Real values\")\n\nplt.title(\"Linear regression\")\n\nplt.legend(loc = \"upper left\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,8))\n\nplt.scatter(y_train, y_pred_train_LinReg)\nplt.plot(y_train, y_train, alpha=0.3, c='r')\n\nplt.xlabel(\"Sales\", fontsize=15, fontweight='bold')\nplt.ylabel(\"Predicted Sales\", fontsize=15, fontweight='bold')\n\nplt.title(\"Training Data Fit\", fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,8))\nplt.scatter(y_test, y_pred_LinReg)\nplt.plot(y_test, y_test, alpha=0.3, c='r')\n\nplt.xlabel(\"Sales\", fontsize=15, fontweight='bold')\nplt.ylabel(\"Predicted Sales\", fontsize=15, fontweight='bold')\n\nplt.title(\"Test Data Fit\", fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = (y_test-y_pred_LinReg)\nsns.distplot(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_train-y_pred_train_LinReg, y_train)\nplt.title(\"Residual Vs  Actual SalePrice for train data\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test-y_pred_LinReg, y_test)\nplt.title(\"Residual Vs  Actual SalePrice for test data\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.2) Decision Tree </h1>","metadata":{}},{"cell_type":"code","source":"DTR = DecisionTreeRegressor()\nDTR.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_DTR = DTR.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(DTR.score(X_train, y_train), DTR.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model\\t\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Decision Tree Regressor \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_DTR)),\n            mean_squared_error(y_test, y_pred_DTR),\n            mean_absolute_error(y_test, y_pred_DTR),\n            r2_score(y_test, y_pred_DTR)))\n\nplt.scatter(y_test, y_pred_DTR)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.title(\"Decision Tree Regressor\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tuning Hyperparameter max_depth & min_sam_split of DecisionTreeRegressor\nmax_d = list(range(1,10))\nmin_sam_split = list(range(10,50,15))\ngridcv = GridSearchCV(DTR, param_grid={'max_depth':max_d, 'min_samples_split':min_sam_split}, n_jobs=-1)\ngridcv.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Parameters :\", gridcv.best_params_)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(gridcv.score(X_train, y_train), gridcv.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.3) Random Forest </h1>","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor()\nrf.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = rf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(rf.score(X_train, y_train), rf.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.4) Logistic Regression </h1>","metadata":{}},{"cell_type":"code","source":"LogReg = LogisticRegression()\nLogReg.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_Log = LogReg.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(LogReg.score(X_train, y_train), LogReg.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.5) XGBoost </h1>","metadata":{}},{"cell_type":"code","source":"import xgboost\nreg_xgb = xgboost.XGBRegressor()\nreg_xgb.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting X_test\ny_pred_xgb = reg_xgb.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_xgb.score(X_train,y_train),reg_xgb.score(X_test,y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score Summary :","metadata":{}},{"cell_type":"code","source":"models = [LinReg, DTR, rf, reg_xgb]\nnames = [\"Linear Regression\", \"Decision Tree Regressor\", \"Random Forest Regressor\", \"XGBoost\"]\nrmses = []\n\nfor model in models:\n    rmses.append(np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n\nx = np.arange(len(names)) \nwidth = 0.3\n\nfig, ax = plt.subplots(figsize=(10,7))\nrects = ax.bar(x, rmses, width)\nax.set_ylabel('RMSE')\nax.set_xlabel('Models')\n\nax.set_title('RMSE with Different Algorithms')\n\nax.set_xticks(x)\nax.set_xticklabels(names, rotation=45)\n\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_OHE = rf.predict(test_OHE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'Id': df.Id, 'SalePrice': y_pred_test_OHE})\nsubmission.to_csv('Housing_submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}