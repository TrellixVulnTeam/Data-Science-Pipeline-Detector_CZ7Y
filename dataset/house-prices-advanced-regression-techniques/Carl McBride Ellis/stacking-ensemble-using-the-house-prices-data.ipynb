{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Stacking ensemble using House Prices data\n\nThis is a short example of using the Scikit-learn [Stacking Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html) which implements the stacked generalization technique.\n\nFor the ensemble base learners we shall use [XGBoost](https://github.com/dmlc/xgboost), [CatBoost](https://github.com/catboost/catboost), and the [Regularized Greedy Forest (RGF)](https://github.com/RGF-team/rgf/tree/master/python-package) (See my notebook [\"Introduction to the Regularized Greedy Forest\"](https://www.kaggle.com/carlmcbrideellis/introduction-to-the-regularized-greedy-forest) for more details).\nFor the meta estimator we shall use the [Random Forest Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n\n### Install the Regularized Greedy Forest (`rgf_python`):","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install rgf_python","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### set up the House Prices competition data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas  as pd\nimport numpy   as np\n\n#===========================================================================\n# read in the data\n#===========================================================================\ntrain_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest_data  = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n\n#===========================================================================\n# select some features\n#===========================================================================\nfeatures = ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', \n        'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', \n        'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', \n        'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', \n        'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n        'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', \n        'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', \n        'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n\n#===========================================================================\n#===========================================================================\nX_train       = train_data[features]\ny_train       = train_data[\"SalePrice\"]\nX_test        = test_data[features]\n\n#===========================================================================\n# imputation; substitute any 'NaN' with mean value\n#===========================================================================\nX_train      = X_train.fillna(X_train.mean())\nX_test       = X_test.fillna(X_test.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### build and run the ensemble","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from rgf.sklearn import RGFRegressor\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.model_selection import train_test_split\n\nestimators =  [('xgb',xgb.XGBRegressor(n_estimators  = 750,learning_rate = 0.02, max_depth = 5)),\n               ('cat',CatBoostRegressor(loss_function='RMSE', verbose=False)),\n               ('RGF',RGFRegressor(max_leaf=500, algorithm=\"RGF_Sib\", test_interval=100, loss=\"LS\"))]\n\nensemble = StackingRegressor(estimators      =  estimators,\n                             final_estimator =  RandomForestRegressor())\n\n# Fit ensemble using cross-validation\nX_tr, X_te, y_tr, y_te = train_test_split(X_train,y_train)\nensemble.fit(X_tr, y_tr).score(X_te, y_te)\n\n# Prediction\npredictions = ensemble.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### now write out the `submission.csv` file:","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"output = pd.DataFrame({\"Id\":test_data.Id, \"SalePrice\":predictions})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Links\n* [David H.Wolpert \"Stacked generalization\", Neural Networks Vol 5, pp. 241-259 (1992)](https://www.sciencedirect.com/science/article/abs/pii/S0893608005800231)\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}