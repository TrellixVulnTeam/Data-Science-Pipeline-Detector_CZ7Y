{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"94354be7-5f5b-4590-a29d-23349d774321","_uuid":"f682ebb7b3575d95e39b2447f40f1e3f03c6c2e4"},"source":"# Kaggle Competition: House Price Regression\nFor this competiton, we are given a data set of 1,460 homes, each with a few dozen features of types: float, integer, and categorical. We are tasked with building a regression model to estimate a home's sale price. Since this is my first kaggle competition, and I'm still quite new to machine learning techniques, I'm going to use this problem as a way to explore common classifiers, namely:\n\n* random trees and\n* random forests.\n\nI appreciate any feedback! \n\nLet's get started by importing some libraries and getting the training data..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d6e2e5e-97f6-4343-8462-917adfb59a04","_uuid":"e5797fdf56e17bb2dd46df99026300101ee7e5f8"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # some plotting!\nimport seaborn as sns # so pretty!\nfrom scipy import stats # I might use this\nfrom sklearn.ensemble import RandomForestClassifier # checking if this is available\n# from sklearn import cross_validation\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3e56148-aeb9-43bf-ba55-a3f4d4535798","_uuid":"58c6afdc57a0c70bca9066dc9999b6e1a7b6e03b"},"source":"# import the training data set and make sure it's in correctly...\ntrain = pd.read_csv('../input/train.csv')\ntrain_original = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6db033b7-4e89-4b27-a81d-e1608f1ceb0c","_uuid":"7ab0a053788332c364000ceff35c88be38c1e6bc"},"source":"# Feature First Impressions\nIt looks like we have integer, float, and object (categorical) features. Also, it looks like some of the features only pertain to a small portion of the 1,460 samples. For now, let's ignore those features where data is missing.\n\n## Pre-processing Categorical Features\nLet's declare a quick function to convert categorical features into integer features, with the most common category of the feature being converted to integer 0, the next most common to 1, and so on. This may be useful later."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8be03658-8732-4265-844b-7e483419e9ae","_uuid":"c31611d88331f4c8d21f48c1cc604aab30c52555","scrolled":true},"source":"# define a function to convert an object (categorical) feature into an int feature\n# 0 = most common category, highest int = least common.\ndef getObjectFeature(df, col, datalength=1460):\n    if df[col].dtype!='object': # if it's not categorical..\n        print('feature',col,'is not an object feature.')\n        return df\n    elif len([i for i in df[col].T.notnull() if i == True])!=datalength: # if there's missing data..\n        print('feature',col,'is missing data.')\n        return df\n    else:\n        df1 = df\n        counts = df1[col].value_counts() # get the counts for each label for the feature\n        df1[col] = [counts.index.tolist().index(i) for i in df1[col]] # do the conversion\n        return df1 # make the new (integer) column from the conversion\n# and test the function...\nfcntest = getObjectFeature(train,'LotShape')\nfcntest.head(10)"},{"cell_type":"markdown","metadata":{},"source":"# Target Variable Analysis: Is it Normal?\n\n*This section was added after my first submission*\n\nAfter going through a few other kernels on this problem to learn from the masters, I realized that checking for target variable normality (and enforcing normality through a transform) is helpful in developing accurate regression models. Namely, I want to cite [Marcelino's](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) and [Serigne's](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard) kernels, from which I learned a ton.\n\nSo let's take a look at the Sale Price data and check for normality, and try to correct it otherwise..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"#histogram and normal probability plot\nfrom scipy.stats import norm\nsns.distplot(train['SalePrice'],fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)"},{"cell_type":"markdown","metadata":{},"source":"So, certainly not normal: we have right-skewness and the data is a bit peak-y. Let's apply a log transform on the data and see what happens..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"train['SalePrice'] = np.log(train['SalePrice'])\nsns.distplot(train['SalePrice'],fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)"},{"cell_type":"markdown","metadata":{},"source":"## A Better Fit!\n\nThat looks much more normal, which will hopefully improve the regressions. We just have to remember to transform the output data back using an exponentiation before we submit anything."},{"cell_type":"markdown","metadata":{"collapsed":true,"_cell_guid":"ef71184e-bbd8-479a-b8b4-6c94629e2918","_uuid":"b1f415a7e2154348d8f20684d15e4a3a15be0df3"},"source":"# First things first: A Random Tree Regressor\nTo start off, let's try to train a simple model using ONLY the features on the \"benchmark\" solution provided with the data for this competition. Those features are:\n* Year and month of sale,\n* Lot square footage, and\n*  Number of bedrooms.\n\nWe will go for a very simple decision tree regression first. We can test for performance and overfitting using k-fold validation; here we take $k=10$. First, we take the data and make it useful...\n"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae5dd19c-df17-4562-9d5c-a8a076d64229","_uuid":"b3e74ba5ae7f11f8a70c0a77a46dac43ea18a6ce","scrolled":true},"source":"from sklearn.tree import DecisionTreeRegressor as dtr\n# define the training data X...\nX = train[['MoSold','YrSold','LotArea','BedroomAbvGr']]\nY = train[['SalePrice']]\n# and the data for the competition submission...\nX_test = test[['MoSold','YrSold','LotArea','BedroomAbvGr']]\nprint(X.head())\nprint(Y.head())"},{"cell_type":"markdown","metadata":{"_cell_guid":"096c5d89-fbd1-4e03-a659-1ae97cc45a46","_uuid":"d259de022bf19d4ed9e5fa236be29641f215544c"},"source":"... and now we can use cross validation to see how well a proposed regression model performs. \n\n## Explained Variance as a Performance Metric\nFor now, we use explained variance, $EV$, as a metric to evaluate the performance of a model:\n\n$EV = 1 - \\frac{Var(y-\\bar{y})}{Var(y)}$\n\nwhere $y$ is the true price, $\\bar{y}$ is the estimated price from the model, and $Var(\\cdot)$ is the variance. The $\\bar{y}$ estimates come from predictions made on the data witheld from training in each round of cross-validation. See: \nhttp://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score \n\nLet's apply this metric..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df991ec7-1f55-4f84-9f56-70000ac2d516","_uuid":"6ad15048ea3fdd3b6cb0a4f3228f6ba6dcf8e3fd"},"source":"# let's set up some cross-validation analysis to evaluate our model and later models...\nfrom sklearn.model_selection import cross_val_score\n# try fitting a decision tree regression model...\nDTR_1 = dtr(max_depth=None) # declare the regression model form. Let the depth be default.\n# DTR_1.fit(X,Y) # fit the training data\nscores_dtr = cross_val_score(DTR_1, X, Y, cv=10,scoring='explained_variance') # 10-fold cross validation\nprint('scores for k=10 fold validation:',scores_dtr)\nprint(\"Est. explained variance: %0.2f (+/- %0.2f)\" % (scores_dtr.mean(), scores_dtr.std() * 2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"69bbfc96-1c74-4f24-ab98-4e9223e73b6d","_uuid":"751e8acedd768ab5284a85d2d583881c7cef1edd"},"source":"## The Random Tree Regressor: A Terrible Model\nWow, that's.... super bad. For explained variance, the best possible result is 1, which would correspond to $Var(y-y_{est})=0$. Values below 1 indicate error in the regression. Negative values imply $Var(y-\\bar{y}) > Var(y)$, which is frankly embarrasing.\n\n# Seeing the Random Forest for the Trees\n\nSo, using one tree is a bad idea... but what if we consider an ensemble of trees? Let's use a random forest regressor instead. We will consider forests with varying numbers of trees (estimators), each of which provides a weak regression solution that can be averaged to get the overall regression output. See: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c56b39d0-1a14-4966-9bfe-24a20c563558","_uuid":"122cc69b32ee96b793c53ca50f6476409cca6179","scrolled":true},"source":"from sklearn.ensemble import RandomForestRegressor as rfr\nestimators = [2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\nmean_rfrs = []\nstd_rfrs_upper = []\nstd_rfrs_lower = []\nyt = [i for i in Y['SalePrice']] # quick pre-processing of the target\nnp.random.seed(11111)\nfor i in estimators:\n    model = rfr(n_estimators=i,max_depth=None)\n    scores_rfr = cross_val_score(model,X,yt,cv=10,scoring='explained_variance')\n    print('estimators:',i)\n#     print('explained variance scores for k=10 fold validation:',scores_rfr)\n    print(\"Est. explained variance: %0.2f (+/- %0.2f)\" % (scores_rfr.mean(), scores_rfr.std() * 2))\n    print('')\n    mean_rfrs.append(scores_rfr.mean())\n    std_rfrs_upper.append(scores_rfr.mean()+scores_rfr.std()*2) # for error plotting\n    std_rfrs_lower.append(scores_rfr.mean()-scores_rfr.std()*2) # for error plotting"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f0ef18d-aa80-4d2c-b114-c412ca540182","_uuid":"dda9791f267bd35548367df30d584db61bcd1deb"},"source":"# and plot...\nfig = plt.figure(figsize=(12,8))\nax = fig.add_subplot(111)\nax.plot(estimators,mean_rfrs,marker='o',\n       linewidth=4,markersize=12)\nax.fill_between(estimators,std_rfrs_lower,std_rfrs_upper,\n                facecolor='green',alpha=0.3,interpolate=True)\nax.set_ylim([-.3,1])\nax.set_xlim([0,80])\nplt.title('Expected Variance of Random Forest Regressor')\nplt.ylabel('Expected Variance')\nplt.xlabel('Trees in Forest')\nplt.grid()\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"4fcacac7-e145-4ec4-a7a6-6e55d7c9139f","_uuid":"ffa2f0e946c1e677f94ae92c765c02f906934d6c"},"source":"## Random Forests: A Slight Improvement\n\nYeah, the results are still absolutely awful. But, at least the estimated means for explained variance are positive, which is a small improvement. We probably need more features, considering how poor even heavily populated forests perform. Let's start by adding a few more features and seeing what happens..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"edf4d7ce-fbf8-4b31-b8a5-29da7ab45248","_uuid":"edaf5660f3d3339c254d5695931bc54bb1ebc102"},"source":"# list all the features we want. This is still arbitrary...\nincluded_features = ['MoSold','YrSold','LotArea','BedroomAbvGr', # original data\n                    'FullBath','HalfBath','TotRmsAbvGrd', # bathrooms and total rooms\n                    'YearBuilt','YearRemodAdd', # age of the house\n                    'LotShape','Utilities'] # some categoricals \n# define the training data X...\nX = train[included_features]\nY = train[['SalePrice']]\n# and the data for the competition submission...\nX_test = test[included_features]\n# transform categorical data if included in X...\nfor col in list(X):\n    if X[col].dtype=='object':\n        X = getObjectFeature(X, col)\nX.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66a173d7-46a6-4a6b-8677-58386ba853f4","_uuid":"3ce526949e9a87062646cbacfd704592ad4247af","scrolled":true},"source":"# define the number of estimators to consider\nestimators = [2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\nmean_rfrs = []\nstd_rfrs_upper = []\nstd_rfrs_lower = []\nyt = [i for i in Y['SalePrice']]\nnp.random.seed(11111)\n# for each number of estimators, fit the model and find the results for 8-fold cross validation\nfor i in estimators:\n    model = rfr(n_estimators=i,max_depth=None)\n    scores_rfr = cross_val_score(model,X,yt,cv=10,scoring='explained_variance')\n    print('estimators:',i)\n#     print('explained variance scores for k=10 fold validation:',scores_rfr)\n    print(\"Est. explained variance: %0.2f (+/- %0.2f)\" % (scores_rfr.mean(), scores_rfr.std() * 2))\n    print(\"\")\n    mean_rfrs.append(scores_rfr.mean())\n    std_rfrs_upper.append(scores_rfr.mean()+scores_rfr.std()*2) # for error plotting\n    std_rfrs_lower.append(scores_rfr.mean()-scores_rfr.std()*2) # for error plotting"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b3ed5f8-f245-4102-bab7-c6955d9c9bfe","_uuid":"6941d18cfcb484520d312544acace6948a8968cf"},"source":"# and plot...\nfig = plt.figure(figsize=(12,8))\nax = fig.add_subplot(111)\nax.plot(estimators,mean_rfrs,marker='o',\n       linewidth=4,markersize=12)\nax.fill_between(estimators,std_rfrs_lower,std_rfrs_upper,\n                facecolor='green',alpha=0.3,interpolate=True)\nax.set_ylim([-.2,1])\nax.set_xlim([0,80])\nplt.title('Expected Variance of Random Forest Regressor')\nplt.ylabel('Expected Variance')\nplt.xlabel('Trees in Forest')\nplt.grid()\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"4816d291-3126-49c7-805b-84d9bc92343e","_uuid":"6d54bddf980fefae0f80397a10157450b338aacb"},"source":"Clearly better, but still pretty bad. At least we are moving in the right direction (towards expected variance of 1). \n\n# Scientific-ish Feature Analysis to Improve Random Forest Regressors\nLet's stick with random forest regression for now, but let's try to be more scientific about the features we select for training the forests. Let's do some feature analysis.\n\nFirst, let's collect all the available features and transform the categorical features where necessary...."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ad6e975-9916-47da-a9ce-eb80e8774028","_uuid":"f3153e033e0cfeaa7e09c3aead9ab58ce67e50d0","scrolled":true},"source":"import sklearn.feature_selection as fs # feature selection library in scikit-learn\ntrain = pd.read_csv('../input/train.csv') # get the training data again just in case\ntrain['SalePrice'] = np.log(train['SalePrice'])\n# first, let's include every feature that has data for all 1460 houses in the data set...\nincluded_features = [col for col in list(train)\n                    if len([i for i in train[col].T.notnull() if i == True])==1460\n                    and col!='SalePrice' and col!='id']\n# define the training data X...\nX = train[included_features] # the feature data\nY = train[['SalePrice']] # the target\nyt = [i for i in Y['SalePrice']] # the target list \n# and the data for the competition submission...\nX_test = test[included_features]\n# transform categorical data if included in X...\nfor col in list(X):\n    if X[col].dtype=='object':\n        X = getObjectFeature(X, col)\nX.head()\n# Y.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b9debd8f-869b-4a6b-8976-843f9b04cc96","_uuid":"eea43e42afc89a5191af12aa5e9c22fbdfd83e48"},"source":"## Mutual Information Regression Metric for Feature Ranking\nWe will use mutual information regression for feature ranking and selection. This metric measures the dependence between two random variables, in this case each feature in the data set and the sales price regression target. Note that this doesn't consider combinations of feature values (for example, the dependence between *sales price* and *the year of sale* combined with *overall quality*), which may also be useful.\n\nSee: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1195f0fb-c5c2-41dc-9449-c9e127cbf890","_uuid":"7294912521220af1003f16a90fbf14d813e18dfb","scrolled":true},"source":"mir_result = fs.mutual_info_regression(X, yt) # mutual information regression feature ordering\nfeature_scores = []\nfor i in np.arange(len(included_features)):\n    feature_scores.append([included_features[i],mir_result[i]])\nsorted_scores = sorted(np.array(feature_scores), key=lambda s: float(s[1]), reverse=True) \nprint(np.array(sorted_scores))"},{"cell_type":"markdown","metadata":{"_cell_guid":"be648519-0249-456b-8114-94e6f1103809","_uuid":"ad5719ab90c8fe8f01c7301706062fd34fc1a9eb"},"source":"## MIR Results: What do homebuyers care about?\nWell, it seems like the most important factors (with respect to sales price) are overall quality, amount of living area, garage car capacity, kitchen quality, and exterior material quality. These seem like fairly intuitve results, at least for somebody with a distant notion of what matters when selecting a house (me).\n\nLet's plot the results next to each other for a better visualization..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"77da7f0f-3900-4316-9906-7ca41fd3e523","_uuid":"edcd23ce7880e95d22c0b76923a0cc8fe8246ad4"},"source":"# and plot...\nfig = plt.figure(figsize=(13,6))\nax = fig.add_subplot(111)\nind = np.arange(len(included_features))\nplt.bar(ind,[float(i) for i in np.array(sorted_scores)[:,1]])\nax.axes.set_xticks(ind)\nplt.title('Feature Importances (Mutual Information Regression)')\nplt.ylabel('Importance')\n# plt.xlabel('Trees in Forest')\n# plt.grid()\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e3c59abe-adab-425b-90a2-2652e7a4ed70","_uuid":"8355d324e2810d35cbec80101fdd237b419a3c51"},"source":"## Feature Pruning\nIt seems like the top few dozen features are fairly important... let's take the top 15, 20, 30, 40, and 50 features to train the random forest regressor model we've been working with and compare the performances. We will wrap the necessary model building and plotting code in functions first."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"95ceb5da-6d6d-4b92-b97f-807d98010895","_uuid":"791986216af0b9178d053bef178c8adcd3167a1c"},"source":"# define a function to do the necessary model building....\ndef getModel(sorted_scores,train,numFeatures):\n    included_features = np.array(sorted_scores)[:,0][:numFeatures] # ordered list of important features\n    # define the training data X...\n    X = train[included_features]\n    Y = train[['SalePrice']]\n    # transform categorical data if included in X...\n    for col in list(X):\n        if X[col].dtype=='object':\n            X = getObjectFeature(X, col)\n    # define the number of estimators to consider\n    estimators = [2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n    mean_rfrs = []\n    std_rfrs_upper = []\n    std_rfrs_lower = []\n    yt = [i for i in Y['SalePrice']]\n    np.random.seed(11111)\n    # for each number of estimators, fit the model and find the results for 8-fold cross validation\n    for i in estimators:\n        model = rfr(n_estimators=i,max_depth=None)\n        scores_rfr = cross_val_score(model,X,yt,cv=10,scoring='explained_variance')\n        mean_rfrs.append(scores_rfr.mean())\n        std_rfrs_upper.append(scores_rfr.mean()+scores_rfr.std()*2) # for error plotting\n        std_rfrs_lower.append(scores_rfr.mean()-scores_rfr.std()*2) # for error plotting\n    return mean_rfrs,std_rfrs_upper,std_rfrs_lower\n\n# define a function to plot the model expected variance results...\ndef plotResults(mean_rfrs,std_rfrs_upper,std_rfrs_lower,numFeatures):\n    fig = plt.figure(figsize=(12,8))\n    ax = fig.add_subplot(111)\n    ax.plot(estimators,mean_rfrs,marker='o',\n           linewidth=4,markersize=12)\n    ax.fill_between(estimators,std_rfrs_lower,std_rfrs_upper,\n                    facecolor='green',alpha=0.3,interpolate=True)\n    ax.set_ylim([-.2,1])\n    ax.set_xlim([0,80])\n    plt.title('Expected Variance of Random Forest Regressor: Top %d Features'%numFeatures)\n    plt.ylabel('Expected Variance')\n    plt.xlabel('Trees in Forest')\n    plt.grid()\n    plt.show()\n    return"},{"cell_type":"markdown","metadata":{"_cell_guid":"3a8c9e3d-1251-4258-a571-90c913fcbb06","_uuid":"6a3ad8000ca86b0dd4d1474213b85254774df6dd"},"source":"...and let's run the regression model fitting for each of the scenarios listed before..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3219ce7d-8eed-4574-9269-f2c9634e08a4","_uuid":"f84a0bd5d4773e3fe6c8b4ce4fe1ac6fc8b692bf","scrolled":false},"source":"# top 15...\nmean_rfrs,std_rfrs_upper,std_rfrs_lower = getModel(sorted_scores,train,15)\nplotResults(mean_rfrs,std_rfrs_upper,std_rfrs_lower,15)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9a77b93-6aef-4750-a6d4-7eed12a9aefd","_uuid":"164bd4d18c9eacd89af87266bed68c25142603d2"},"source":"# top 20...\nmean_rfrs,std_rfrs_upper,std_rfrs_lower = getModel(sorted_scores,train,20)\nplotResults(mean_rfrs,std_rfrs_upper,std_rfrs_lower,20)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9df514c1-2a4d-4796-8dde-68fe3a4fe457","_uuid":"722dd06605b7f71cc9f420ff527164d817579dab"},"source":"# top 30...\nmean_rfrs,std_rfrs_upper,std_rfrs_lower = getModel(sorted_scores,train,30)\nplotResults(mean_rfrs,std_rfrs_upper,std_rfrs_lower,30)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa73c89a-1c06-4dc9-83b3-c4c6ddc89f9a","_uuid":"2f3e6cf074a8b07279ed1118048beccfc8fe2503","scrolled":false},"source":"# top 40...\nmean_rfrs,std_rfrs_upper,std_rfrs_lower = getModel(sorted_scores,train,40)\nplotResults(mean_rfrs,std_rfrs_upper,std_rfrs_lower,40)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9c0fa0e-65e5-41b0-8a9c-edd9df54962d","_uuid":"54f0a18ea74f7487e7d16939a1b7647a01a56bbe"},"source":"# top 50...\nmean_rfrs,std_rfrs_upper,std_rfrs_lower = getModel(sorted_scores,train,50)\nplotResults(mean_rfrs,std_rfrs_upper,std_rfrs_lower,50)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c6cf58c2-cdcf-46cd-93eb-b11a1a598c0e","_uuid":"7b5cd64a9ba7f13bb622327d958be62e7cfa23e4"},"source":"# Random Forest Regression Impressions\nIt seems like the mean expected variance of the regressions stops improving at around 20 features and 20 to 30 trees in the forest. The deviation in the expected variance score decreases with increasing features, which is intuitive. The 40-feature and 50-feature results look almost identical, probably because the 40th- to 50th-most important features are barely significant. Let's only consider the top 40 features from here on out."},{"cell_type":"markdown","metadata":{"collapsed":true,"_cell_guid":"84e5185e-03c4-41db-829b-75400f817541","_uuid":"c0f52fad586afd216fac020e139057167e25a092"},"source":"# The Finale: Building the Output for Submission\nNow, let's take the best regression model we have and build the competition output. For this model, we have:\n* A random forest resgression model, incorporating\n* the 40 most prominent features according to an MIR analysis, and\n* 60 regressor trees per forest, and\n* the default sklearn settings for the rest of the model parameters.\n\nSo let's apply this model to the test data and generate the submission!"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d184d0d-5691-48cc-81c5-0e950adbf76d","_uuid":"5ae838eab461d7fb7ee9cc56c38be8252a957753","scrolled":true},"source":"# build the model with the desired parameters...\nnumFeatures = 40 # the number of features to inlcude\ntrees = 60 # trees in the forest\nincluded_features = np.array(sorted_scores)[:,0][:numFeatures]\n# define the training data X...\nX = train[included_features]\nY = train[['SalePrice']]\n# transform categorical data if included in X...\nfor col in list(X):\n    if X[col].dtype=='object':\n        X = getObjectFeature(X, col)\nyt = [i for i in Y['SalePrice']]\nnp.random.seed(11111)\nmodel = rfr(n_estimators=trees,max_depth=None)\nscores_rfr = cross_val_score(model,X,yt,cv=10,scoring='explained_variance')\nprint('explained variance scores for k=10 fold validation:',scores_rfr)\nprint(\"Est. explained variance: %0.2f (+/- %0.2f)\" % (scores_rfr.mean(), scores_rfr.std() * 2))\n# fit the model\nmodel.fit(X,yt)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"29b92fc3-7133-4cb4-9ab9-739a305d7bf3","_uuid":"bd073fcc63ac9aa70e4a4aee6b143d72cd49fc54"},"source":"# let's read the test data to be sure...\ntest = pd.read_csv('../input/test.csv')"},{"cell_type":"markdown","metadata":{"_cell_guid":"9faf2c25-63a0-4a3b-a719-e649d8ea33a6","_uuid":"f4a54b3d44b88e81388580931978950a4c644d1e"},"source":"We will tweak the pre-processing function from before to handle missing data better, too..."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"3cc55499-aeca-450b-a756-91e5e441890f","_uuid":"aab6242664bb2db8d1f24c1feeddd73aeb05c1ba"},"source":"# re-define a function to convert an object (categorical) feature into an int feature\n# 0 = most common category, highest int = least common.\ndef getObjectFeature(df, col, datalength=1460):\n    if df[col].dtype!='object': # if it's not categorical..\n        print('feature',col,'is not an object feature.')\n        return df\n    else:\n        df1 = df\n        counts = df1[col].value_counts() # get the counts for each label for the feature\n#         print(col,'labels, common to rare:',counts.index.tolist()) # get an ordered list of the labels\n        df1[col] = [counts.index.tolist().index(i) \n                    if i in counts.index.tolist() \n                    else 0 \n                    for i in df1[col] ] # do the conversion\n        return df1 # make the new (integer) column from the conversion"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fe77768-059d-4284-88f5-ca6a46008937","_uuid":"9a2bc6ae752ba1209a36600a386d404fee91c207","scrolled":true},"source":"# apply the model to the test data and get the output...\nX_test = test[included_features]\nfor col in list(X_test):\n    if X_test[col].dtype=='object':\n        X_test = getObjectFeature(X_test, col, datalength=1459)\n# print(X_test.head(20))\ny_output = model.predict(X_test.fillna(0)) # get the results and fill nan's with 0\nprint(y_output)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"# transform the data to be sure\ny_output = np.exp(y_output)\nprint(y_output)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a04026a3-14ef-40d4-88a7-c660c9d5be3a","_uuid":"e2c184860e127997104d0e8f2036016ffe558027"},"source":"# define the data frame for the results\nsaleprice = pd.DataFrame(y_output, columns=['SalePrice'])\n# print(saleprice.head())\n# saleprice.tail()\nresults = pd.concat([test['Id'],saleprice['SalePrice']],axis=1)\nresults.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"aac2812a-dc81-4401-982d-63b474746a43","_uuid":"42df785bfa8de18add8d35aef43fcba1606704ba"},"source":"# and write to output\nresults.to_csv('housepricing_submission.csv', index = False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b03f8434-b4a8-47c8-b2b7-0bbed5ad3df5","_uuid":"b251baf557da53eaf9c455880cd6d9c0816d00f3"},"source":"So, there's my random forest regression for the house price data set. I appreciate any feedback, comments, corrections, improvements!"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"9a8ce167-f955-4d8f-b45f-08089f4bf323","_uuid":"9896a917f711813fd9ef796f97f47e2216e252a2"},"source":""}],"metadata":{"language_info":{"file_extension":".py","version":"3.6.3","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}