{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports and Configuration ##","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport copy\nfrom pathlib import Path\n\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.display import display\n\nfrom pandas.api.types import CategoricalDtype\nfrom category_encoders import MEstimateEncoder\nfrom category_encoders.cat_boost import CatBoostEncoder\n\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.linear_model import LarsCV\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor, Pool\nfrom lightgbm import LGBMRegressor\n\nfrom sklearn.ensemble import VotingRegressor\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.neighbors import LocalOutlierFactor\n\n# for Box-Cox Transformation\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n# for min_max scaling\nfrom mlxtend.preprocessing import minmax_scaling\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=18,\n    titlepad=10,\n)\n\ntarget = 'SalePrice'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:05:50.697424Z","iopub.execute_input":"2022-03-10T08:05:50.697977Z","iopub.status.idle":"2022-03-10T08:05:59.602504Z","shell.execute_reply.started":"2022-03-10T08:05:50.697885Z","shell.execute_reply":"2022-03-10T08:05:59.601202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simple_impute(df):\n    numerical = []\n    categorical = []\n    enc = OrdinalEncoder()\n    for name in df.select_dtypes(['float64', 'int64']):\n        df[name] = df[name].fillna(0)\n        numerical.append(name)\n    for name in df.select_dtypes(\"object\"):\n        df[name] = df[name].fillna(\"None\")\n        categorical.append(name)\n    df[categorical] = enc.fit_transform(df[categorical])    \n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:05:59.606792Z","iopub.execute_input":"2022-03-10T08:05:59.60713Z","iopub.status.idle":"2022-03-10T08:05:59.613529Z","shell.execute_reply.started":"2022-03-10T08:05:59.607101Z","shell.execute_reply":"2022-03-10T08:05:59.612757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv', index_col=\"Id\")\ndf_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv', index_col=\"Id\")\ndf_description = pd.read_csv('../input/description/housing.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:05:59.615254Z","iopub.execute_input":"2022-03-10T08:05:59.615684Z","iopub.status.idle":"2022-03-10T08:05:59.723165Z","shell.execute_reply.started":"2022-03-10T08:05:59.615648Z","shell.execute_reply":"2022-03-10T08:05:59.722145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore dataset","metadata":{}},{"cell_type":"markdown","source":"#### Make feature descriptions dictionary","metadata":{}},{"cell_type":"code","source":"description = dict()\ncurr = ''\nfor index, row in df_description.iterrows():\n    txt = str(row['a'])\n    if ':' in txt:\n        if curr != '':\n            description[curr] = item\n        column = txt.split(':')[0]\n        desc = txt.split(':')[1]\n        curr = column\n        if curr in ['Bedroom', 'Kitchen']: curr += 'AbvGr' # correct error in data_description.txt\n        item = dict()\n        item['description'] = desc\n        item['values'] = dict()\n    else:\n        n = txt\n        v = row['b']\n        item['values'][n] = v\nitem = dict()\nitem['description'] = 'Condition of sale'\nitem['values'] = dict()\ndescription['SaleCondition'] = item \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:05:59.725114Z","iopub.execute_input":"2022-03-10T08:05:59.72551Z","iopub.status.idle":"2022-03-10T08:05:59.785839Z","shell.execute_reply.started":"2022-03-10T08:05:59.725467Z","shell.execute_reply":"2022-03-10T08:05:59.784691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MI scores","metadata":{}},{"cell_type":"code","source":"def make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:05:59.787319Z","iopub.execute_input":"2022-03-10T08:05:59.787668Z","iopub.status.idle":"2022-03-10T08:05:59.795879Z","shell.execute_reply.started":"2022-03-10T08:05:59.787628Z","shell.execute_reply":"2022-03-10T08:05:59.794893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scorer(estimator, X, y):\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    log_y = np.log(y)\n    scores = cross_val_score(\n        estimator, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n    )\n    score = -1 * scores.mean()\n    score = np.sqrt(score)\n    return score   ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:05:59.797074Z","iopub.execute_input":"2022-03-10T08:05:59.797344Z","iopub.status.idle":"2022-03-10T08:05:59.807928Z","shell.execute_reply.started":"2022-03-10T08:05:59.797318Z","shell.execute_reply":"2022-03-10T08:05:59.807012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset_info(train, test):\n    X = train.copy()\n    X['df'] = 'train'\n    X_test = test.copy()\n    X_test['df'] = 'test'\n    \n    X_all = pd.concat([X, X_test], ignore_index=True)\n    X_all_missing = X_all.isnull()\n    X_missing = X.isnull()\n    types = dict(X_all.dtypes) \n    \n    Z = X.copy()\n    Z = simple_impute(Z)\n    yz = Z.pop(target)\n    mi_scores = pd.DataFrame(make_mi_scores(Z, yz))\n    \n    train_Z, val_Z, train_yz, val_yz = train_test_split(Z, yz, random_state=1)\n    first_model = XGBRegressor(n_estimators=100, random_state=1).fit(train_Z, train_yz)\n    perm = PermutationImportance(first_model, random_state=1).fit(val_Z, val_yz)\n    feature_importances = pd.DataFrame(perm.feature_importances_, index=Z.columns)\n    \n    correlation = X.corr()\n   \n    for feature in X.columns.values.tolist():\n        if feature in ['df', target]: \n            continue\n        \n        print(feature)\n        print('_'*20)\n        if feature in description:\n            print(description[feature]['description'])\n        dtype = types[feature]\n        nunique = len(X_all[feature].unique())\n        print('dtype:', dtype, end=' ')\n        if  dtype == 'int64' and nunique<20:\n            print('AS OBJECT', end='')\n        print()    \n        if dtype == 'object' or (dtype == 'int64' and nunique<20):\n            if feature in description:\n                print('values meaning:', end=' ')\n                for v in description[feature]['values']:\n                    print(v.strip(), ':', description[feature]['values'][v], end=', ')\n                print()\n            print('unique values:', nunique, '[', end='')\n            for v in X_all[feature].unique():\n                print(v, end=', ')\n            print(']')\n        null = X[feature].isnull().sum()\n        test_null = X_test[feature].isnull().sum()\n        if null > 0 or test_null > 0:\n            print(f\"Missing values, train: {null} ({100*null/X.shape[0]:.1f}%), test: {test_null} ({100*test_null/X_test.shape[0]:.1f}%)\")\n        if dtype != 'object':\n            print(f\"Train min: {X[feature].min()}, mean: {X[feature].mean():.3f}, max: {X[feature].max()}, std: {X[feature].std():.3f}\")\n        \n        print(f\"MI score: {mi_scores.loc[feature]['MI Scores']}\")\n        print(f\"Feature importance: {feature_importances.loc[feature][0]}\")\n        if feature in correlation.columns:\n            print('\\nCorrelation with target and top most correlated features:')\n            tmcf =np.abs(correlation.loc[feature]).drop(labels=[feature, target]).sort_values(ascending=False).index.tolist()[:5]\n            top_most_correlated_features = correlation.loc[feature][[target]+tmcf]\n            fig, ax = plt.subplots(1, 1, figsize=(12, 1.2))\n            sns.heatmap(data=pd.DataFrame(top_most_correlated_features).T, annot=True, cbar=False)\n        \n        n = 2\n        fig, ax = plt.subplots(1, n, figsize=(12, 3))\n        if dtype == 'object' or (dtype == 'int64' and nunique<20):\n            sns.countplot(data=X_all, x=feature, hue='df', ax=ax[0])\n            sns.violinplot(x=feature,y=target,data=X, ax=ax[1])\n        else:   \n            sns.kdeplot(data=X_all, x=feature, hue='df', ax=ax[0]) \n            sns.regplot(x=X[feature], y=X[target], line_kws={'color': 'r'}, ax=ax[1])\n        plt.show()\n        print()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:05:59.80906Z","iopub.execute_input":"2022-03-10T08:05:59.809353Z","iopub.status.idle":"2022-03-10T08:05:59.833754Z","shell.execute_reply.started":"2022-03-10T08:05:59.80932Z","shell.execute_reply":"2022-03-10T08:05:59.832787Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"code","source":"dataset_info(df_train, df_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:05:59.835221Z","iopub.execute_input":"2022-03-10T08:05:59.835672Z","iopub.status.idle":"2022-03-10T08:06:57.269178Z","shell.execute_reply.started":"2022-03-10T08:05:59.835626Z","shell.execute_reply":"2022-03-10T08:06:57.267921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target distribution","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 4)) \nsns.distplot(a=df_train[target], fit=norm, ax=ax[0])\nstats.probplot(df_train[target], plot=ax[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:06:57.273276Z","iopub.execute_input":"2022-03-10T08:06:57.273744Z","iopub.status.idle":"2022-03-10T08:06:58.166625Z","shell.execute_reply.started":"2022-03-10T08:06:57.273705Z","shell.execute_reply":"2022-03-10T08:06:58.165521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### After log transform","metadata":{}},{"cell_type":"code","source":"def log_transform(X, column):\n    df = X.copy()\n    df[column] = np.log1p(df[column])\n    return df\n\ndf = log_transform(df_train, target)\nfig, ax = plt.subplots(1, 2, figsize=(12, 4)) \nsns.distplot(a=df[target], fit=norm, ax=ax[0])\nstats.probplot(df[target], plot=ax[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:06:58.168683Z","iopub.execute_input":"2022-03-10T08:06:58.168988Z","iopub.status.idle":"2022-03-10T08:06:58.754739Z","shell.execute_reply.started":"2022-03-10T08:06:58.168959Z","shell.execute_reply":"2022-03-10T08:06:58.753595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def ht(df):\n    display(df.head(2))\n    display(df.tail(2))\n    display(df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:06:58.756434Z","iopub.execute_input":"2022-03-10T08:06:58.756884Z","iopub.status.idle":"2022-03-10T08:06:58.7627Z","shell.execute_reply.started":"2022-03-10T08:06:58.756831Z","shell.execute_reply":"2022-03-10T08:06:58.761304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    # Read data\n    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n    # Merge the splits so we can process them together\n    df = pd.concat([df_train, df_test])\n    # Preprocessing\n    df = clean(df)\n    df = handleNA(df)\n    df = encode(df)\n    df = impute(df)\n    # Reform splits\n    df_train = df.loc[df_train.index, :]\n    df_test = df.loc[df_test.index, :]\n    return df_train, df_test\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:06:58.764152Z","iopub.execute_input":"2022-03-10T08:06:58.764464Z","iopub.status.idle":"2022-03-10T08:06:58.775544Z","shell.execute_reply.started":"2022-03-10T08:06:58.764435Z","shell.execute_reply":"2022-03-10T08:06:58.774807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clean Data ","metadata":{}},{"cell_type":"code","source":"def clean(df):\n    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Wd Shng\": \"WdShing\"})\n    # Some values of GarageYrBlt are corrupt, so we'll replace them\n    # with the year the house was built\n    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(df.GarageYrBlt <= 2010, df.YearBuilt)\n    # Names beginning with numbers are awkward to work with\n    df.rename(columns={\n        \"1stFlrSF\": \"FirstFlrSF\",\n        \"2ndFlrSF\": \"SecondFlrSF\",\n        \"3SsnPorch\": \"Threeseasonporch\",\n    }, inplace=True,\n    )\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:06:58.776564Z","iopub.execute_input":"2022-03-10T08:06:58.776988Z","iopub.status.idle":"2022-03-10T08:06:58.792116Z","shell.execute_reply.started":"2022-03-10T08:06:58.776957Z","shell.execute_reply":"2022-03-10T08:06:58.791145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode the Statistical Data Type ###","metadata":{}},{"cell_type":"code","source":"# The nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]\n\n# The ordinal (ordered) categorical features \n\n# Pandas calls the categories \"levels\"\nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(10))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\n# Add a None level for missing values\nordered_levels = {key: [\"None\"] + value for key, value in ordered_levels.items()}\n\ndef encode(df):\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            df[name].cat.add_categories(\"None\", inplace=True)\n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels, ordered=True))\n    return df\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:06:58.793674Z","iopub.execute_input":"2022-03-10T08:06:58.794084Z","iopub.status.idle":"2022-03-10T08:06:58.809464Z","shell.execute_reply.started":"2022-03-10T08:06:58.794042Z","shell.execute_reply":"2022-03-10T08:06:58.808571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handle Missing Values ###","metadata":{}},{"cell_type":"code","source":"def handleNA(X):\n    # Thanks YatishDua\n    df = X.copy()\n    df['Alley'].fillna(value='No alley access',inplace=True)    \n    df['BsmtQual'].fillna(value='No Basement',inplace=True)\n    df['BsmtCond'].fillna(value='No Basement',inplace=True)\n    df['BsmtExposure'].fillna(value='No Basement',inplace=True)\n    df['BsmtFinType1'].fillna(value='No Basement',inplace=True)    \n    df['BsmtFinType2'].fillna(value='No Basement',inplace=True)    \n    df['FireplaceQu'].fillna(value='No Fireplace',inplace=True)    \n    df['GarageType'].fillna(value='No Garage',inplace=True)  \n    df['GarageYrBlt'].fillna(value=0,inplace=True)\n    df['GarageFinish'].fillna(value='No Garage',inplace=True)\n    df['GarageQual'].fillna(value='No Garage',inplace=True)\n    df['GarageCond'].fillna(value='No Garage',inplace=True)\n    df['MasVnrType'].fillna(value='None',inplace=True)\n    df['MasVnrArea'].fillna(value=0.0,inplace=True)\n    df['PoolQC'].fillna(value='No Pool',inplace=True)    \n    df['Fence'].fillna(value='No Fence',inplace=True)\n    df['MiscFeature'].fillna(value='None',inplace=True)\n    return df\n\ndef impute(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:06:58.810897Z","iopub.execute_input":"2022-03-10T08:06:58.811377Z","iopub.status.idle":"2022-03-10T08:06:58.82811Z","shell.execute_reply.started":"2022-03-10T08:06:58.811346Z","shell.execute_reply":"2022-03-10T08:06:58.827055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline","metadata":{}},{"cell_type":"markdown","source":"### Scoring function","metadata":{}},{"cell_type":"code","source":"def score_dataset(X, y, model=XGBRegressor(), cv=5):\n    # Label encoding for categoricals\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    log_y = np.log(y)\n    scores = cross_val_score(\n        model, X, log_y, cv=cv, scoring=\"neg_mean_squared_error\",\n    )\n    score = -1 * scores.mean()\n    score = np.sqrt(score)\n    scores_sqrt = [np.sqrt(-1*x) for x in scores]\n    return score, scores_sqrt\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:06:58.829701Z","iopub.execute_input":"2022-03-10T08:06:58.830243Z","iopub.status.idle":"2022-03-10T08:06:58.844762Z","shell.execute_reply.started":"2022-03-10T08:06:58.830208Z","shell.execute_reply":"2022-03-10T08:06:58.843728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Baseline","metadata":{}},{"cell_type":"code","source":"X, X_test = load_data()\ny = X.pop(target)\n\nbaseline_score, scores = score_dataset(X, y)\nprint(f\"Baseline score: {baseline_score:.5f}\", scores)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:06:58.846102Z","iopub.execute_input":"2022-03-10T08:06:58.846678Z","iopub.status.idle":"2022-03-10T08:07:00.930822Z","shell.execute_reply.started":"2022-03-10T08:06:58.846632Z","shell.execute_reply":"2022-03-10T08:07:00.929951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop uninformative features","metadata":{}},{"cell_type":"code","source":"mi_scores = make_mi_scores(X, y)\n\ndef drop_uninformative(df, mi_scores):\n    return df.loc[:, mi_scores > 0.0]\n\nX = drop_uninformative(X, mi_scores)\nscore_dataset(X, y)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:07:00.934853Z","iopub.execute_input":"2022-03-10T08:07:00.936928Z","iopub.status.idle":"2022-03-10T08:07:05.123803Z","shell.execute_reply.started":"2022-03-10T08:07:00.936871Z","shell.execute_reply":"2022-03-10T08:07:05.122949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Features","metadata":{}},{"cell_type":"code","source":"def label_encode(df):\n    X = df.copy()\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.127887Z","iopub.execute_input":"2022-03-10T08:07:05.130564Z","iopub.status.idle":"2022-03-10T08:07:05.136925Z","shell.execute_reply.started":"2022-03-10T08:07:05.130504Z","shell.execute_reply":"2022-03-10T08:07:05.135791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mathematical_transforms(df):\n    X = pd.DataFrame()  # dataframe to hold new features\n    X[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n    X[\"Spaciousness\"] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n    return X\n\ndef interactions(df):\n    X = pd.get_dummies(df.BldgType, prefix=\"Bldg\")\n    X = X.mul(df.GrLivArea, axis=0)\n    return X\n\ndef counts(df):\n    X = pd.DataFrame()\n    X[\"PorchTypes\"] = df[[\n        \"WoodDeckSF\",\n        \"OpenPorchSF\",\n        \"EnclosedPorch\",\n        \"ScreenPorch\",\n    ]].gt(0.0).sum(axis=1)\n    return X\n\ndef group_transforms(df):\n    X = pd.DataFrame()\n    X[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n    return X","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:07:05.138862Z","iopub.execute_input":"2022-03-10T08:07:05.139221Z","iopub.status.idle":"2022-03-10T08:07:05.152211Z","shell.execute_reply.started":"2022-03-10T08:07:05.13918Z","shell.execute_reply":"2022-03-10T08:07:05.151236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_features(all_data):\n    X = pd.DataFrame()\n\n    X['TotalSF'] = (all_data['TotalBsmtSF'] \n                           + all_data['FirstFlrSF'] \n                           + all_data['SecondFlrSF'])\n\n    X['YrBltAndRemod'] = all_data['YearBuilt'] + all_data['YearRemodAdd']\n\n    X['Total_sqr_footage'] = (all_data['BsmtFinSF1'] \n                                     + all_data['BsmtFinSF2'] \n                                     + all_data['FirstFlrSF'] \n                                     + all_data['SecondFlrSF']\n                                    )\n\n\n    X['Total_Bathrooms'] = (all_data['FullBath'] \n                                   + (0.5 * all_data['HalfBath']) \n                                   + all_data['BsmtFullBath'] \n                                   + (0.5 * all_data['BsmtHalfBath'])\n                                  )\n\n\n    X['Total_porch_sf'] = (all_data['OpenPorchSF'] \n                                  + all_data['Threeseasonporch'] \n                                  + all_data['EnclosedPorch'] \n                                  + all_data['ScreenPorch'] \n                                  + all_data['WoodDeckSF']\n                                 )\n    X['haspool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n    X['has2ndfloor'] = all_data['SecondFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n    X['hasgarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n    X['hasbsmt'] = all_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n    X['hasfireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)    \n    \n    return X","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.153594Z","iopub.execute_input":"2022-03-10T08:07:05.153943Z","iopub.status.idle":"2022-03-10T08:07:05.166342Z","shell.execute_reply.started":"2022-03-10T08:07:05.153906Z","shell.execute_reply":"2022-03-10T08:07:05.165043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Latitude & Longitude\n*Thanks YatishDua*","metadata":{}},{"cell_type":"code","source":"dict_neighbor = {\n'NAmes'  :{'lat': 42.045830,'lon': -93.620767},\n'CollgCr':{'lat': 42.018773,'lon': -93.685543},\n'OldTown':{'lat': 42.030152,'lon': -93.614628},\n'Edwards':{'lat': 42.021756,'lon': -93.670324},\n'Somerst':{'lat': 42.050913,'lon': -93.644629},\n'Gilbert':{'lat': 42.060214,'lon': -93.643179},\n'NridgHt':{'lat': 42.060357,'lon': -93.655263},\n'Sawyer' :{'lat': 42.034446,'lon': -93.666330},\n'NWAmes' :{'lat': 42.049381,'lon': -93.634993},\n'SawyerW':{'lat': 42.033494,'lon': -93.684085},\n'BrkSide':{'lat': 42.032422,'lon': -93.626037},\n'Crawfor':{'lat': 42.015189,'lon': -93.644250},\n'Mitchel':{'lat': 41.990123,'lon': -93.600964},\n'NoRidge':{'lat': 42.051748,'lon': -93.653524},\n'Timber' :{'lat': 41.998656,'lon': -93.652534},\n'IDOTRR' :{'lat': 42.022012,'lon': -93.622183},\n'ClearCr':{'lat': 42.060021,'lon': -93.629193},\n'StoneBr':{'lat': 42.060227,'lon': -93.633546},\n'SWISU'  :{'lat': 42.022646,'lon': -93.644853}, \n'MeadowV':{'lat': 41.991846,'lon': -93.603460},\n'Blmngtn':{'lat': 42.059811,'lon': -93.638990},\n'BrDale' :{'lat': 42.052792,'lon': -93.628820},\n'Veenker':{'lat': 42.040898,'lon': -93.651502},\n'NPkVill':{'lat': 42.049912,'lon': -93.626546},\n'Blueste':{'lat': 42.010098,'lon': -93.647269}\n}\n\ndef lat_lon(df):\n    X = df.copy()\n    X['Lat'] = [dict_neighbor[n]['lat'] for n in df['Neighborhood']]\n    X['Lon'] = [dict_neighbor[n]['lon'] for n in df['Neighborhood']]   \n    return X","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.168628Z","iopub.execute_input":"2022-03-10T08:07:05.16941Z","iopub.status.idle":"2022-03-10T08:07:05.18781Z","shell.execute_reply.started":"2022-03-10T08:07:05.169344Z","shell.execute_reply":"2022-03-10T08:07:05.186476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# k-Means Clustering","metadata":{}},{"cell_type":"code","source":"cluster_features = [\n    \"LotArea\",\n    \"TotalBsmtSF\",\n    \"FirstFlrSF\",\n    \"SecondFlrSF\",\n    \"GrLivArea\",\n]\n\ndef cluster_labels(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    X_new = pd.DataFrame()\n    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n    return X_new\n\ndef cluster_distance(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=20, n_init=50, random_state=0)\n    X_cd = kmeans.fit_transform(X_scaled)\n    # Label features and join to dataset\n    X_cd = pd.DataFrame(\n        X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])]\n    )\n    return X_cd","metadata":{"_kg_hide-input":true,"lines_to_next_cell":2,"execution":{"iopub.status.busy":"2022-03-10T08:07:05.189216Z","iopub.execute_input":"2022-03-10T08:07:05.189726Z","iopub.status.idle":"2022-03-10T08:07:05.205063Z","shell.execute_reply.started":"2022-03-10T08:07:05.189692Z","shell.execute_reply":"2022-03-10T08:07:05.204244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Principal Component Analysis","metadata":{}},{"cell_type":"code","source":"def apply_pca(X, standardize=True):\n    # Standardize\n    if standardize:\n        X = (X - X.mean(axis=0)) / X.std(axis=0)\n\n    # Create principal components\n    pca = PCA()\n    X_pca = pca.fit_transform(X)\n    # Convert to dataframe\n    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n    X_pca = pd.DataFrame(X_pca, columns=component_names)\n    # Create loadings\n    loadings = pd.DataFrame(\n        pca.components_.T,  # transpose the matrix of loadings\n        columns=component_names,  # so the columns are the principal components\n        index=X.columns,  # and the rows are the original features\n    )\n    return pca, X_pca, loadings\n\ndef plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:07:05.206426Z","iopub.execute_input":"2022-03-10T08:07:05.206889Z","iopub.status.idle":"2022-03-10T08:07:05.225044Z","shell.execute_reply.started":"2022-03-10T08:07:05.20684Z","shell.execute_reply":"2022-03-10T08:07:05.224005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [\n    \"GarageArea\",\n    \"YearRemodAdd\",\n    \"TotalBsmtSF\",\n    \"GrLivArea\",\n]\n\nprint(\"Correlation with SalePrice:\\n\")\nprint(df[features].corrwith(df.SalePrice))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.226428Z","iopub.execute_input":"2022-03-10T08:07:05.226947Z","iopub.status.idle":"2022-03-10T08:07:05.251203Z","shell.execute_reply.started":"2022-03-10T08:07:05.226905Z","shell.execute_reply":"2022-03-10T08:07:05.250146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Z = X.copy()\n# y = Z.pop(\"SalePrice\")\nZ = Z.loc[:, features]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.254828Z","iopub.execute_input":"2022-03-10T08:07:05.255388Z","iopub.status.idle":"2022-03-10T08:07:05.262946Z","shell.execute_reply.started":"2022-03-10T08:07:05.255334Z","shell.execute_reply":"2022-03-10T08:07:05.261927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca, Z_pca, loadings = apply_pca(Z)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.268473Z","iopub.execute_input":"2022-03-10T08:07:05.268913Z","iopub.status.idle":"2022-03-10T08:07:05.321846Z","shell.execute_reply.started":"2022-03-10T08:07:05.268877Z","shell.execute_reply":"2022-03-10T08:07:05.320802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loadings","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.323885Z","iopub.execute_input":"2022-03-10T08:07:05.324176Z","iopub.status.idle":"2022-03-10T08:07:05.340947Z","shell.execute_reply.started":"2022-03-10T08:07:05.324148Z","shell.execute_reply":"2022-03-10T08:07:05.340036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 3))\nsns.heatmap(loadings, annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.342149Z","iopub.execute_input":"2022-03-10T08:07:05.342441Z","iopub.status.idle":"2022-03-10T08:07:05.752532Z","shell.execute_reply.started":"2022-03-10T08:07:05.342409Z","shell.execute_reply":"2022-03-10T08:07:05.751719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_variance(pca)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:05.753716Z","iopub.execute_input":"2022-03-10T08:07:05.754176Z","iopub.status.idle":"2022-03-10T08:07:06.156777Z","shell.execute_reply.started":"2022-03-10T08:07:05.754129Z","shell.execute_reply":"2022-03-10T08:07:06.155724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pca_inspired(df):\n    X = pd.DataFrame()\n    X[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n    X[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n    return X\n\ndef pca_components(df, features):\n    X = df.loc[:, features]\n    _, X_pca, _ = apply_pca(X)\n    return X_pca\n\npca_features = [\n    \"GarageArea\",\n    \"YearRemodAdd\",\n    \"TotalBsmtSF\",\n    \"GrLivArea\",\n]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:07:06.158193Z","iopub.execute_input":"2022-03-10T08:07:06.15849Z","iopub.status.idle":"2022-03-10T08:07:06.164675Z","shell.execute_reply.started":"2022-03-10T08:07:06.158463Z","shell.execute_reply":"2022-03-10T08:07:06.163695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation","metadata":{}},{"cell_type":"code","source":"def corrplot(df, method=\"pearson\", annot=True, **kwargs):\n    sns.clustermap(\n        df.corr(method),\n        vmin=-1.0,\n        vmax=1.0,\n        cmap=\"icefire\",\n        method=\"complete\",\n        annot=annot,\n        **kwargs,\n    )\n\ncorrplot(df_train, annot=None)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:06.166038Z","iopub.execute_input":"2022-03-10T08:07:06.166332Z","iopub.status.idle":"2022-03-10T08:07:07.927467Z","shell.execute_reply.started":"2022-03-10T08:07:06.166304Z","shell.execute_reply":"2022-03-10T08:07:07.926686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def indicate_outliers(df):\n#     X_new = pd.DataFrame()\n#     X_new[\"Outlier\"] = (df.Neighborhood == \"Edwards\") & (df.SaleCondition == \"Partial\")\n#     return X_new\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:07.928487Z","iopub.execute_input":"2022-03-10T08:07:07.92892Z","iopub.status.idle":"2022-03-10T08:07:07.933226Z","shell.execute_reply.started":"2022-03-10T08:07:07.928888Z","shell.execute_reply":"2022-03-10T08:07:07.932211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target Encoding","metadata":{}},{"cell_type":"code","source":"class CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=5)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-10T08:07:07.9347Z","iopub.execute_input":"2022-03-10T08:07:07.935301Z","iopub.status.idle":"2022-03-10T08:07:07.946818Z","shell.execute_reply.started":"2022-03-10T08:07:07.935244Z","shell.execute_reply":"2022-03-10T08:07:07.945859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Final Feature Set","metadata":{}},{"cell_type":"code","source":"def create_features(df, df_test=None):\n\n    X = df.copy()\n    y = X.pop(target)\n    mi_scores = make_mi_scores(X, y)\n\n    if df_test is not None:\n        X_test = df_test.copy()\n        if target in X_test.columns:\n            X_test.pop(target)\n        X = pd.concat([X, X_test])\n        \n    X = drop_uninformative(X, mi_scores)\n    \n    X = X.join(mathematical_transforms(X))\n    X = X.join(interactions(X))\n    X = X.join(counts(X))\n    X = X.join(group_transforms(X))\n    \n#     X = X.join(add_features(X))\n    \n    X = lat_lon(X)\n    \n    X = X.join(pca_inspired(X))\n\n    X = label_encode(X)\n\n    # Reform splits\n    if df_test is not None:\n        X_test = X.loc[df_test.index, :]\n        X.drop(df_test.index, inplace=True)\n\n    # Target Encoder\n    encoder = CrossFoldEncoder(CatBoostEncoder, a=1)\n    X = X.join(encoder.fit_transform(X, y, cols=[\"Neighborhood\", \"MSSubClass\"]))\n    if df_test is not None:\n        X_test = X_test.join(encoder.transform(X_test))\n\n    if df_test is not None:\n        return X, X_test\n    else:\n        return X","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:07.947939Z","iopub.execute_input":"2022-03-10T08:07:07.948376Z","iopub.status.idle":"2022-03-10T08:07:07.961993Z","shell.execute_reply.started":"2022-03-10T08:07:07.948338Z","shell.execute_reply":"2022-03-10T08:07:07.961237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load, preprocess and add features","metadata":{}},{"cell_type":"code","source":"df_train, df_test = load_data()\nX_train, X_test = create_features(df_train, df_test)\ny_train = df_train.loc[:, target]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:07.96303Z","iopub.execute_input":"2022-03-10T08:07:07.963428Z","iopub.status.idle":"2022-03-10T08:07:11.192171Z","shell.execute_reply.started":"2022-03-10T08:07:07.963392Z","shell.execute_reply":"2022-03-10T08:07:11.191197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score once more","metadata":{}},{"cell_type":"code","source":"print(f\"Baseline score: {baseline_score:.5f}\")\nnew_score, scores = score_dataset(X_train, y_train)\nprint(f\"New score: {new_score:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:11.193649Z","iopub.execute_input":"2022-03-10T08:07:11.194052Z","iopub.status.idle":"2022-03-10T08:07:13.549599Z","shell.execute_reply.started":"2022-03-10T08:07:11.194011Z","shell.execute_reply":"2022-03-10T08:07:13.548666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New features","metadata":{}},{"cell_type":"code","source":"new_features = X_train.columns.tolist()[-16:]\nprint(new_features)\ndataset_info(pd.concat([X_train[new_features], y_train], axis=1), X_test[new_features])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:13.551006Z","iopub.execute_input":"2022-03-10T08:07:13.551581Z","iopub.status.idle":"2022-03-10T08:07:27.554561Z","shell.execute_reply.started":"2022-03-10T08:07:13.551536Z","shell.execute_reply":"2022-03-10T08:07:27.553552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's see the map","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objs as go\n\nneighborhoods = pd.DataFrame(dict_neighbor).T\nmsp = df_train.groupby('Neighborhood').SalePrice.agg([np.mean])\nneighborhoods['msp'] = msp\n\nfig = go.Figure(go.Scattermapbox(lat=neighborhoods['lat'],\n                                 lon=neighborhoods['lon'],\n                                 text=neighborhoods.index,\n                                 hoverinfo=\"text\",\n                                 marker=dict(colorbar=dict(title=\"Mean SalePrice\"),\n                                             color=neighborhoods['msp'],\n                                             size=15)\n                                ), layout= {'height': 800, 'width': 800}\n               )\nmap_center = go.layout.mapbox.Center(lat=(neighborhoods['lat'].max()+neighborhoods['lat'].min())/2,\n                                     lon=(neighborhoods['lon'].max()+neighborhoods['lon'].min())/2)\nfig.update_layout(mapbox_style=\"open-street-map\", mapbox=dict(center=map_center, zoom=12))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:27.55607Z","iopub.execute_input":"2022-03-10T08:07:27.556371Z","iopub.status.idle":"2022-03-10T08:07:28.228524Z","shell.execute_reply.started":"2022-03-10T08:07:27.55634Z","shell.execute_reply":"2022-03-10T08:07:28.227448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Permutation Importance","metadata":{}},{"cell_type":"code","source":"X = create_features(df_train)\ny = df_train.loc[:, \"SalePrice\"]\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nfirst_model = XGBRegressor(n_estimators=50, random_state=1).fit(train_X, train_y)\n\nperm = PermutationImportance(first_model, random_state=1).fit(val_X, val_y)\n\neli5.show_weights(perm, feature_names = X.columns.tolist(), top=None)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:28.229824Z","iopub.execute_input":"2022-03-10T08:07:28.230138Z","iopub.status.idle":"2022-03-10T08:07:32.86985Z","shell.execute_reply.started":"2022-03-10T08:07:28.230108Z","shell.execute_reply":"2022-03-10T08:07:32.868752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi = pd.DataFrame(perm.feature_importances_, index=X.columns)\nfi.columns = ['score']\nimportant_features = list(fi[fi.score > 0].index)\nprint('Important features', len(important_features), 'of', len(X.columns))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:32.871392Z","iopub.execute_input":"2022-03-10T08:07:32.871851Z","iopub.status.idle":"2022-03-10T08:07:32.880359Z","shell.execute_reply.started":"2022-03-10T08:07:32.871807Z","shell.execute_reply":"2022-03-10T08:07:32.879198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compare regressors","metadata":{}},{"cell_type":"code","source":"regressors = []\nregressors.append(('Linear', LinearRegression()))\nregressors.append(('Ridge', Ridge()))\nregressors.append(('Lasso', Lasso()))\nregressors.append(('Elastic', ElasticNet()))\nregressors.append(('LARS', LarsCV()))\nregressors.append(('Bayes', BayesianRidge()))\nregressors.append(('KNeighbor', KNeighborsRegressor()))\nregressors.append(('DTree', DecisionTreeRegressor()))\nregressors.append(('LSVR', LinearSVR()))\nregressors.append(('SVR', SVR()))\nregressors.append(('AdaBoost', AdaBoostRegressor()))\nregressors.append(('Bagging', BaggingRegressor()))\nregressors.append(('ExtraTree', ExtraTreesRegressor()))\nregressors.append(('GBoost', GradientBoostingRegressor()))\nregressors.append(('RForest', RandomForestRegressor()))\nregressors.append(('LGBM', LGBMRegressor()))\nregressors.append(('XGB', XGBRegressor()))\nregressors.append(('CatBoost', CatBoostRegressor(silent=True)))","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-03-10T08:07:32.881993Z","iopub.execute_input":"2022-03-10T08:07:32.882405Z","iopub.status.idle":"2022-03-10T08:07:32.900704Z","shell.execute_reply.started":"2022-03-10T08:07:32.882363Z","shell.execute_reply":"2022-03-10T08:07:32.899594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = load_data()\nX, X_test = create_features(df_train, df_test)\nX = X[important_features]\nX_test = X_test[important_features]\ny = df_train.loc[:, target]\n\nstrange = ['BsmtFinSF2', 'BsmtUnfSF', 'Condition2']\nX = X.drop(strange, axis=1)\nX_test = X_test.drop(strange, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:32.902832Z","iopub.execute_input":"2022-03-10T08:07:32.903661Z","iopub.status.idle":"2022-03-10T08:07:36.271048Z","shell.execute_reply.started":"2022-03-10T08:07:32.903593Z","shell.execute_reply":"2022-03-10T08:07:36.270011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:36.272664Z","iopub.execute_input":"2022-03-10T08:07:36.273096Z","iopub.status.idle":"2022-03-10T08:07:36.279134Z","shell.execute_reply.started":"2022-03-10T08:07:36.273052Z","shell.execute_reply":"2022-03-10T08:07:36.278013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\nresults = []\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\nkfold = KFold(n_splits=5, random_state=7, shuffle=True)\n\nfor name, regressor in regressors:\n    print('scoring', name, end='.'*(10-len(name)))\n\n    mean_score, scores = score_dataset(X, y, regressor, cv=kfold)\n    for score in scores:\n        if score < 0.25:\n            results.append({'model': name, 'score': score})\n    print(f'{mean_score:.5f}')\n\nresults_df = pd.DataFrame(results)\nfig = plt.figure(figsize=(25,8))\nsns.boxplot(x=results_df.model, y=results_df['score'])\nplt.show()    ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:07:36.280436Z","iopub.execute_input":"2022-03-10T08:07:36.280745Z","iopub.status.idle":"2022-03-10T08:08:19.704823Z","shell.execute_reply.started":"2022-03-10T08:07:36.280714Z","shell.execute_reply":"2022-03-10T08:08:19.703747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHAP","metadata":{}},{"cell_type":"code","source":"import shap  # package used to calculate Shap values\n\npars = {'max_depth': 6,\n 'learning_rate': 0.002483868626800697,\n 'n_estimators': 7989,\n 'min_child_weight': 1,\n 'colsample_bytree': 0.5030185650975951,\n 'subsample': 0.44705436353703526,\n 'reg_alpha': 0.007053643198184307,\n 'reg_lambda': 0.03677328533642659}\n\ndf_train, df_test = load_data()\nX, X_test = create_features(df_train, df_test)\ny = df_train.loc[:, \"SalePrice\"]\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n\nregressor = XGBRegressor(**pars)\nregressor.fit(X_train, y_train)\nprediction = regressor.predict(X_valid)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:08:19.706149Z","iopub.execute_input":"2022-03-10T08:08:19.706449Z","iopub.status.idle":"2022-03-10T08:08:47.983037Z","shell.execute_reply.started":"2022-03-10T08:08:19.706421Z","shell.execute_reply":"2022-03-10T08:08:47.982032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(2):\n    data_for_prediction = X_valid.iloc[[i]]  \n    explainer = shap.TreeExplainer(regressor)\n    shap_values = explainer.shap_values(data_for_prediction)\n    shap.initjs()\n    plt = shap.force_plot(explainer.expected_value, shap_values[0], data_for_prediction)\n    display(plt)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:08:47.98432Z","iopub.execute_input":"2022-03-10T08:08:47.984651Z","iopub.status.idle":"2022-03-10T08:09:28.651765Z","shell.execute_reply.started":"2022-03-10T08:08:47.984602Z","shell.execute_reply":"2022-03-10T08:09:28.650791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.TreeExplainer(regressor)    \nshap_values = explainer.shap_values(X_valid)\nprint(X_valid.shape, shap_values.shape)\nplt = shap.summary_plot(shap_values, X_valid, max_display=X_valid.shape[1])\ndisplay(plt)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:09:28.652916Z","iopub.execute_input":"2022-03-10T08:09:28.653181Z","iopub.status.idle":"2022-03-10T08:10:03.595634Z","shell.execute_reply.started":"2022-03-10T08:09:28.653155Z","shell.execute_reply":"2022-03-10T08:10:03.594879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`BsmtFinSF2`, `BsmtUnfSF` and `Condition2` have strange outliers, I'm to drop them","metadata":{}},{"cell_type":"code","source":"df_train, df_test = load_data()\nX, X_test = create_features(df_train, df_test)\ny = df_train.loc[:, target]\nstrange = ['BsmtFinSF2', 'BsmtUnfSF', 'Condition2']\nX = X.drop(strange, axis=1)\nX_test = X_test.drop(strange, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:03.596715Z","iopub.execute_input":"2022-03-10T08:10:03.597142Z","iopub.status.idle":"2022-03-10T08:10:06.869227Z","shell.execute_reply.started":"2022-03-10T08:10:03.597102Z","shell.execute_reply":"2022-03-10T08:10:06.868065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OPTUNA","metadata":{}},{"cell_type":"code","source":"import optuna","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:06.870887Z","iopub.execute_input":"2022-03-10T08:10:06.871314Z","iopub.status.idle":"2022-03-10T08:10:07.357975Z","shell.execute_reply.started":"2022-03-10T08:10:06.871267Z","shell.execute_reply":"2022-03-10T08:10:07.356895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tune XGB regressor","metadata":{"execution":{"iopub.status.busy":"2021-08-10T19:36:14.744146Z","iopub.status.idle":"2021-08-10T19:36:14.744724Z"}}},{"cell_type":"code","source":"# XGB = {\n#     'tree_method': 'hist',\n#     'booster': 'gbtree',\n#     'random_state': 228,\n#     'use_label_encoder': False,\n#     'eval_metric': 'rmse'\n# }\n\n# def objective(trial):\n#     params = dict(\n#         max_depth=trial.suggest_int(\"max_depth\", 2, 20),\n#         learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n#         n_estimators=trial.suggest_int(\"n_estimators\", 1000, 25000),\n#         min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 300),\n#         colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n#         subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n#         reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n#         reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n#         gamma=trial.suggest_float(\"gamma\", 1e-4, 1e2, log=True),\n#     )\n#     regressor = XGBRegressor(**params, **XGB)\n#     return score_dataset(X, y, regressor, cv=5)[0]\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=30)\n# params = study.best_params\n\n# display(params)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:07.359213Z","iopub.execute_input":"2022-03-10T08:10:07.35949Z","iopub.status.idle":"2022-03-10T08:10:07.367212Z","shell.execute_reply.started":"2022-03-10T08:10:07.359457Z","shell.execute_reply":"2022-03-10T08:10:07.365725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tune CAT regressor","metadata":{}},{"cell_type":"code","source":"# CB = {\n#     'grow_policy': 'Depthwise', \n#     'leaf_estimation_method': 'Newton',\n#     'random_seed': 228,\n#     'loss_function': 'RMSE',\n#     'eval_metric': 'RMSE',\n#     'bootstrap_type': 'Bernoulli',\n#     'silent': True,\n# }\n\n# def objective(trial):\n#     params = dict(\n#         depth=trial.suggest_int(\"depth\", 2, 10),\n#         learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n#         iterations=trial.suggest_int(\"iterations\", 300, 25000),\n#         max_bin=trial.suggest_int(\"max_bin\", 10, 300),\n#         min_data_in_leaf=trial.suggest_int(\"min_data_in_leaf\", 10, 500),\n#         l2_leaf_reg=trial.suggest_float(\"l2_leaf_reg\", 0.2, 1.0),\n#         subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n#     )\n#     regressor = CatBoostRegressor(**params, **CB)\n#     return score_dataset(X, y, regressor, cv=5)[0]\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=30)\n# params = study.best_params\n\n# display(params)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:07.368498Z","iopub.execute_input":"2022-03-10T08:10:07.368939Z","iopub.status.idle":"2022-03-10T08:10:07.382377Z","shell.execute_reply.started":"2022-03-10T08:10:07.368907Z","shell.execute_reply":"2022-03-10T08:10:07.381314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune LGBM","metadata":{}},{"cell_type":"code","source":"# lgbm_def = LGBMRegressor(\n#     boosting_type='gbdt', \n#     num_leaves=31,\n#     max_depth=- 1, \n#     learning_rate=0.1, \n#     n_estimators=100, \n#     subsample_for_bin=200000, \n#     objective=None, \n#     class_weight=None, \n#     min_split_gain=0.0, \n#     min_child_weight=0.001, \n#     min_child_samples=20, \n#     subsample=1.0, \n#     subsample_freq=0, \n#     colsample_bytree=1.0, \n#     reg_alpha=0.0, \n#     reg_lambda=0.0, \n#     random_state=None, \n#     n_jobs=- 1, \n#     silent=True, \n#     importance_type='split'\n# )\n# # {   \n# #  'learning_rate': 0.09039083345568485,\n# #  'reg_alpha': 0.0001190115814442082,\n# #  'reg_lambda': 1.5174576281379848,\n# #  'cat_l2': 13.530516606143303\n# # }\n# LGBM = {\n#     'n_estimators': 14522,\n#     'max_depth': 8,\n#     'min_data_in_leaf': 31,\n#     'random_state': 228,\n#     'metric': 'rmse'\n# }\n\n# def objective(trial):\n#     params = dict(\n# #         max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n#         learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n# #         n_estimators=trial.suggest_int(\"n_estimators\", 300, 25000),\n#         reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e-2, log=True),\n#         reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-1, 1e2, log=True),\n#         num_leaves=trial.suggest_int(\"num_leaves\", 10, 300),\n# #         min_data_in_leaf=trial.suggest_int(\"min_data_in_leaf\", 10, 500),\n#         cat_l2=trial.suggest_float(\"cat_l2\", 1, 20),\n# #         min_child_samples=trial.suggest_float(\"min_child_samples\", 2, 50),\n#     )\n#     regressor = LGBMRegressor(**params, **LGBM)\n#     return score_dataset(X, y, regressor, cv=5)[0]\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=50)\n# params = study.best_params\n\n# display(params)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:07.384072Z","iopub.execute_input":"2022-03-10T08:10:07.384736Z","iopub.status.idle":"2022-03-10T08:10:07.401108Z","shell.execute_reply.started":"2022-03-10T08:10:07.384683Z","shell.execute_reply":"2022-03-10T08:10:07.399969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting Regressor","metadata":{}},{"cell_type":"code","source":"xgb_pars = {'max_depth': 6,\n 'learning_rate': 0.002483868626800697,\n 'n_estimators': 7989,\n 'min_child_weight': 1,\n 'colsample_bytree': 0.5030185650975951,\n 'subsample': 0.44705436353703526,\n 'reg_alpha': 0.007053643198184307,\n 'reg_lambda': 0.03677328533642659}\n\nxgb = XGBRegressor(**xgb_pars)\n\nCB = {\n    'grow_policy': 'Depthwise', \n    'leaf_estimation_method': 'Newton',\n    'random_seed': 228,\n    'loss_function': 'RMSE',\n    'eval_metric': 'RMSE',\n    'bootstrap_type': 'Bernoulli',\n    'silent': True,\n}\n\ncat_pars = {'depth': 5,\n 'learning_rate': 0.002058251099330786,\n 'iterations': 10294,\n 'max_bin': 207,\n 'min_data_in_leaf': 14,\n 'l2_leaf_reg': 0.36181081978772367,\n 'subsample': 0.5798334683744184}\n\ncat = CatBoostRegressor(**cat_pars, **CB)\n\nlgbm_pars = {'learning_rate': 0.001816775252684838, 'reg_alpha': 0.0015734456737639636, 'reg_lambda': 0.10747950720829248, 'num_leaves': 67, 'cat_l2': 8.38470951659679}\n\nLGBM = {\n    'n_estimators': 14522,\n    'max_depth': 8,\n    'min_data_in_leaf': 31,\n    'random_state': 228,\n    'metric': 'rmse'\n}\n\nlgbm = LGBMRegressor(**lgbm_pars, **LGBM)\n\nlgbm2 = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=5000,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n                                       )\n\nkfolds = KFold(n_splits=10, shuffle=True, random_state=42)\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, \n                                              alphas=alphas2, \n                                              random_state=42, \n                                              cv=kfolds))\nelasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \nsvr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n\n\nall_estimators=[('CAT', cat), ('XGB', xgb), ('LR', LinearRegression()), ('Ridge', ridge), ('Lasso', lasso), ('Elastic', elasticnet), ('SVR', svr), ('LGBM', lgbm), ('LGBM2', lgbm2)]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:07.403911Z","iopub.execute_input":"2022-03-10T08:10:07.40451Z","iopub.status.idle":"2022-03-10T08:10:07.426752Z","shell.execute_reply.started":"2022-03-10T08:10:07.404462Z","shell.execute_reply":"2022-03-10T08:10:07.42592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scores = []\n# results = []\n\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n# kfold = KFold(n_splits=5, random_state=7, shuffle=True)\n\n# for name, estimator in all_estimators:\n#     print('scoring', name, end='.'*(10-len(name)))\n\n#     mean_score, scores = score_dataset(X, y, estimator, cv=kfold)\n#     for score in scores:\n#         if score < 0.25:\n#             results.append({'estimator': name, 'score': score})\n#     print(f'{mean_score:.5f}')\n\n# results_df = pd.DataFrame(results)\n# fig = plt.figure(figsize=(25,8))\n# sns.boxplot(x=results_df.estimator, y=results_df['score'])\n# plt.show()   ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:07.428773Z","iopub.execute_input":"2022-03-10T08:10:07.429217Z","iopub.status.idle":"2022-03-10T08:10:07.438303Z","shell.execute_reply.started":"2022-03-10T08:10:07.429172Z","shell.execute_reply":"2022-03-10T08:10:07.437447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators=[('cat', cat), ('xgb', xgb), ('Linear', LinearRegression()), ('Ridge', Ridge()), ('lgbm', lgbm2)]\n\n# weights = [0.40, 0.48, 0.05, 0.07]\n# weights = [0.38, 0.50, 0.04, 0.08] # 0.11851\nweights = [0.38, 0.48, 0.04, 0.08, 0.02] # 0.011848\n# weights = [0.38, 0.47, 0.04, 0.04, 0.07]\n\nmodel = VotingRegressor(estimators=estimators, weights=weights, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:07.439648Z","iopub.execute_input":"2022-03-10T08:10:07.440175Z","iopub.status.idle":"2022-03-10T08:10:07.450031Z","shell.execute_reply.started":"2022-03-10T08:10:07.440143Z","shell.execute_reply":"2022-03-10T08:10:07.44921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submition","metadata":{}},{"cell_type":"code","source":"model.fit(X, np.log(y))\npredictions = 1.009 * np.exp(model.predict(X_test)) \noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T08:10:07.451316Z","iopub.execute_input":"2022-03-10T08:10:07.451744Z","iopub.status.idle":"2022-03-10T08:12:20.355293Z","shell.execute_reply.started":"2022-03-10T08:10:07.451714Z","shell.execute_reply":"2022-03-10T08:12:20.354127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# THE END","metadata":{}}]}