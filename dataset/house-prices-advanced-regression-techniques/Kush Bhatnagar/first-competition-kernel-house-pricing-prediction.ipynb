{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About the Kernel"},{"metadata":{},"cell_type":"markdown","source":"This notebook consist of Exploratory Data Analysis(EDA) and Sales Price prediction with different Regression Models for House Price prediction competition .\n\nThis kernel is easily understandable to the beginner(like me). I tried to explain everything as simple and straightforward to my best wisdom.\n\nI have tried different model and submitted score based of all models , in this way we can see different models/approach and how to fine tune them. With the latest model score is **0.16303**\n\nPlease provide comment if you have any kind of suggestions ao that I can improve this kernel and if you like in someway then please upvote the kernel.\n\n**Note** : *This is Work In Progress Notebook , will be updating on regular basis till the time will get good model and satisfactory scores.*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"# 1. Getting the Data"},{"metadata":{},"cell_type":"markdown","source":"Let's import the data and check columns data type and total records"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries and data set\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndataset=pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking total number records\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking all columns\ndataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Selecting independent variables(features)"},{"metadata":{},"cell_type":"markdown","source":"From the provided columns we have to select few columns as independent variables or features on which we can train our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking columns data types\n#String data type\nlen(dataset.select_dtypes(include=['O']).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Integer data type\nlen(dataset.select_dtypes(include=['int64']).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Float data type\nlen(dataset.select_dtypes(include=['float64']).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting Correlation Coefficient of sale price with other numerical data\nsaleprice_corr=dataset.corr()['SalePrice']\nsaleprice_corr\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have done detailed data analysis for this data set and it's present in this [link](https://docs.google.com/spreadsheets/d/1IyfMnTl4g8JUpI6N_l8QlPB42uwygR9-m-i1z5KciJ8/edit?usp=sharing), if anyone intrested can take a look\n\nI took some help from this Kaggle [Kernel](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) for data analysis.\n\nI have created the spreadsheet with the following columns:\n\nVariable - Variable name\n    \nType - Identification of the variables' type. There are two possible values for this field: 'numerical' or 'categorical'. By 'numerical' we mean variables for which the values are numbers, and by 'categorical' we mean variables for which the values are categories\n\nCategory - Identification of the variables category . We can define three possible segments: building, space or location. When we say 'building', we mean a variable that relates to the physical characteristics of the building (e.g. 'OverallQual'). When we say 'space', we mean a variable that reports space properties of the house (e.g. 'TotalBsmtSF'). Finally, when we say a 'location', we mean a variable that gives information about the place where the house is located (e.g. 'Neighborhood')\n\nExpected Effect on Sale Price - Our expectation about the variable influence in 'SalePrice'. We can use a categorical scale with 'High', 'Medium' and 'Low' as possible values. We can look at each variable and try to understand their meaning and relevance\n\nCorrelation Coefficient - Consist of correlation cofficient value for numerical variable\n\nConclusion - Our conclusions about the importance of the variable, after we give a quick look at the data and cofficenent\n\nNote - Any general comments realted to variables"},{"metadata":{},"cell_type":"markdown","source":"Based on above analysis I have come up with following variables as a posisble independent variables (features)\n'Neighborhood','OverallQual','YearBuilt','ExterCond','TotalBsmtSF','GrLivArea'.\nI have selected these variables from all of the segments (building, space and location) with 'High' expected effect on Sales Price.\nNow , I will check the relation bewtween all these variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating independent variables data frame X\nX=dataset[['Neighborhood','OverallQual','YearBuilt','ExterCond','TotalBsmtSF','GrLivArea','SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the relation between GrLivArea and SalePrice\nplt.scatter(X['GrLivArea'],X['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the relation between TotalBsmtSF and SalePrice\nplt.scatter(X['TotalBsmtSF'],X['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the relation between OverallQual and SalePrice\nplt.scatter(X['OverallQual'],X['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the relation between YearBuilt and SalePrice\nplt.scatter(X['YearBuilt'],X['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating pair plot along with categorical variable 'ExterCond' to get relation with Sale Price and other variables\nsns.pairplot(X,hue='ExterCond')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating pair plot along with categorical variable 'Neighborhood' to get relation with Sale Price and other variables\nsns.pairplot(X,hue='Neighborhood')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With above scatter plots and pair plots we can say that numerical variables have linear relationship with Sale Price and Categorical variables also have some relationship with Sale Price , will dig more on Categorical variables\n\nNote: If we observe graph between 'OverallQual' and 'SalePrice' we can see that though it's a numerical variable it's actually a  categorical variable and on checking the variable description it's pretty evident that 'OverallQual' is a categorical variable only\n\nLet's analyze relationship between Categorical variables and Sale price with the help of box plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot between 'OverallQuality' and 'Sales Price'\nsns.boxplot(x=X['OverallQual'],y=X['SalePrice'],palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot between 'ExterCond' and 'Sales Price'\nsns.boxplot(x=X['ExterCond'],y=X['SalePrice'],palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot between 'Neighborhood' and 'Sales Price'\nplt.figure(figsize=(20,10))\nsns.boxplot(y=X['Neighborhood'],x=X['SalePrice'],palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With these plots we can see that out of three categorical variables only 'OverallQual' is having linear relationship with 'SalePrice'(When Quality increase Sales Price also increase) and other two variables i.e. 'Neighborhood' and 'ExtCond' does not show any linear relationship. Based on this we can skip these two variables from our feature list\n\nNow, we have independent variables (features) 'OverallQual','YearBuilt','TotalBsmtSF','GrLivArea' and from above analysis we know that 'OverallQual','TotalBsmtSF','GrLivArea' are linearly related to our dependent variable('SalePrice') for 'YearBuilt' let's create box plot graph with 'SalePrice' to see the relation ship more clearly between these two"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot between 'Year built' and 'Sales Price' to check sales price across years\nplt.figure(figsize=(20, 10))\nsns.boxplot(x=X['YearBuilt'],y=X['SalePrice'],palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we can see that 'YearBuilt' and 'SalePrice' are kind of linearly related as Sales price increases over the years.From scatter and box plots for 'OverallQual' and 'YearBuilt' we can say that they are kind of linearly related with Sales Price\n\nNow , lets consider other numerical variable with high correlation cofficent which I have skipped during my initial data analysis because these variables does not look relevant to me. But due to high correlation cofficent numbers let's consider them now , and these variables are\n'FullBath','1stFlrSF',\n'YearRemodAdd','GarageCars','GarageArea'\n\nOn checking data description and correlation coffecient it looks like that 'YearRemodAdd'//'YearBuilt' , 'TotalBsmtSF' //'1stFlrSF' ,'GarageCars'//'GarageArea' variables are kind of identical variables only .If we practially think about these variables, we can conclude that they give almost the same information so multicollinearity can occurs\nSo we can consider only 'FullBath','GarageCars' in new list and ignore the remaining of them"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding new independent Variables in X\nX=dataset[['FullBath','OverallQual','YearBuilt','TotalBsmtSF','GrLivArea','GarageCars','SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the relation between FullBath and SalePrice\nplt.scatter(X['FullBath'],X['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the relation between FullBath and SalePrice\nplt.scatter(X['GarageCars'],X['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With above two graphs we can say that 'FullBath' and 'GarageCars' have linear relationship with Sale Price. 'GarageCars' have an exception(last value '4') which can be outliner value\n\nWith this updated list of dependent variables let's create a new pair plot graph to see relationship between all variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create pairplot with new list\nsns.pairplot(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we see last row of Sale Price with each independent variables we will find out that all dependent are somewhat linearly related to Sale Price(dependent variable) and all these variables have high correlation coefficient with dependent variable\n"},{"metadata":{},"cell_type":"markdown","source":"# 3. Missing Values"},{"metadata":{},"cell_type":"markdown","source":"Let's check missing values in our independent and dependent variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking missing values \ntotal_missing_values_X=X.isnull().sum().sort_values(ascending=False)\ntotal_missing_values_X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no missing values in our independent and dependent variables so we are good for model fitting , but before that let's look into Outliers"},{"metadata":{},"cell_type":"markdown","source":"# 4. Outliers"},{"metadata":{},"cell_type":"markdown","source":"If we see our graph between 'GirLivArea' ,'TotalBsmtSF' and 'GarageCars' with 'SalePrice' we can see that there are few points which are out of the crowd (not following the trend of regression) and we can consider them as outliers .There can be logical reason behind these outliers , like for 'GirLivArea' there are two observation where Sale price decreased with high above ground living area so posisble reason can be that these properties are located in outskirts or agriculture area or can be anything and we are not sure about these so we will treat them as outliers and delete them"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking first two values in 'GirLivArea' for outliers\nX.sort_values(by='GrLivArea',ascending=False)[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop outliers rows from the data set\nX=X.drop(1298)\nX=X.drop(523)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For 'TotalBsmtSF' only one outlier was there which was at index '1298' and same got deleted with 'GrLivArea'.\n\nNow For 'GarageCars' on looking at graph we can say when 'GarageCars' value is 4 then sale price is dropped and does not follow the trend , so we will drop the rows where Garage car value is 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get index for records with GarageCars as 4\nindexNames=X[X['GarageCars'] == 4].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the records for GarageCars as 4\nX=X.drop(indexNames)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will create pair plot one more time to check outliers are coming or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create pairplot with new list\nsns.pairplot(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now there is not much outliers coming in our data . We can see few point in 'TotalBsmtSF' but they are pretty much following the trend so we will leave them and we can start modelling our data"},{"metadata":{},"cell_type":"markdown","source":"# 5. Data Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split independent and dependent variables\nX=dataset[['FullBath','OverallQual','YearBuilt','TotalBsmtSF','GrLivArea','GarageCars']]\ny=dataset[['SalePrice']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Multiple linear regression to the data set\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting the train set results\ny_pred=regressor.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting y from series to array , to generate a graph for comparision with y_pred\ny=y.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rounding off the y_pred \ny_pred=y_pred.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting 2 dimensional y and y_pred array into single dimension \ny=y.ravel()\ny_pred=y_pred.ravel()\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating data frame for y and y_pred to create line plot\ndf=pd.DataFrame({\"y\":y,\"y_pred\":y_pred})\nsns.lineplot(data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph it's evident that our predicted Sale value is matching with actual sale value  but with few mismatch values . It means there is a scope of remodelling here.\nLet's get some statistics related to this model"},{"metadata":{},"cell_type":"markdown","source":"On calculating 'P' values for every variable we can say that for 'FullBath' it's pretty high (0.418 which is > significant value of .05) so we can drop this feature and remodel our model Note: Removing feature/independent varaible based on 'P' value is called process of Backward Elimination"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing 'FullBath' from list of independent variables\n#X=dataset[['OverallQual','YearBuilt','GrLivArea','TotalBsmtSF','GarageCars']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Commneting above line of code as after removing 'FullBath' also there is no difference in prediction so we decided to keep it as it is highly corelated "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating new regressor object and fitting the model\nregressor_new=LinearRegression()\nregressor_new.fit(X,y)\ny_pred_new=regressor_new.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rounding off the y_pred_new\ny_pred_new=y_pred_new.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting 2 dimensional y and y_pred array into single dimension \ny_pred_new=y_pred_new.ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating data frame for y ,y_pred,y_pred_new to create line plot\ndf=pd.DataFrame({\"y\":y,\"y_pred\":y_pred,\"y_pred_new\":y_pred_new})\nsns.lineplot(data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Green and Blue lines are almost overlapping each other (only very few exception , need to zoom for that) , but this is on train data set. We need to make our prediction on test set, so will repeat these steps on test set and verify our findings\n\nAs mentioned earlier , removing 'FullBath' is not making much differnce in prediction so we will keep it in our feature list\n"},{"metadata":{},"cell_type":"markdown","source":"# 6. Prediction from Test Data"},{"metadata":{},"cell_type":"markdown","source":"Let's summarize what we have done till now\n    1. Data import\n    2. Data analysis\n    3. Selection of independent variables\n    4. Verifying any missing values\n    5. Removal of Outliers\n    6. Data modeling\n    7. Prediction\n\nTo get prediction from test data we have to perform step 4 and 5 and fit our model on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get test data \ndataset_test=pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create X_test and fetching id in different frame\nX_test=dataset_test[['FullBath','OverallQual','YearBuilt','TotalBsmtSF','GrLivArea','GarageCars']]\ny_test_id=dataset_test[['Id']]\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking missing value in test data set\ntotal_missing_values_X_test=X_test.isnull().sum().sort_values(ascending=False)\ntotal_missing_values_X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the missing Garage Cars record\nX_test[X_test['GarageCars'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #Checking the missing Total Bsmt SF record\nX_test[X_test['TotalBsmtSF'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can use Imputer library to take care of missing value but in this scenario only one value is missing in both columns so we will update that with most frequent value and mean value in 'Garage Cars' and 'TotalBsmtSF' respectively.\n\nFor 'Garage Cars' we  can say that value '2' is most common in test data so we will replace the missing with this value"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Updating Garage Cars to 2 at missing value index\nX_test.at[1116,'GarageCars'] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the missing value in Garage Cars\nX_test[X_test['GarageCars'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will check 'TotalBsmtSF' mean and update the same to missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fetching 'TotalBsmtSF' information\nX_test['TotalBsmtSF'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Updating the missing value to mean value\nX_test.at[660,'TotalBsmtSF'] = 1046.12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying the missing value in TotalBsmtSF\nX_test[X_test['TotalBsmtSF'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking missing value in test data set again\ntotal_missing_values_X_test=X_test.isnull().sum().sort_values(ascending=False)\ntotal_missing_values_X_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see there is no missing value in test data set , let's deal with outliers now."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize test data\nsns.pairplot(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on our train set data and above pairplot, we will check top values in 'GirLivArea' and 'TotalBsmtSF'"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sort_values(by='GrLivArea',ascending=False)[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sort_values(by='TotalBsmtSF',ascending=False)[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can drop the outliers but our submission csv needs 1459 records \n#X_test=X_test.drop(1089)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating predictions based on X_test\ny_test_pred=regressor_new.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting 2 dimensional y_test_pred into single dimension \ny_test_pred=y_test_pred.ravel()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rounding off the values\ny_test_pred=y_test_pred.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting Id into array\ny_test_id=y_test_id.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting 2 dimensional y_test_id into single dimension \ny_test_id=y_test_id.ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Submission dataframe from id and predecited Sale price\nsubmission_df=pd.DataFrame({\"Id\":y_test_id,\"SalePrice\":y_test_pred})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting index as Id Column\nsubmission_df.set_index(\"Id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting into CSV file for submission\nsubmission_df.to_csv(\"submission_1.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. K-Fold Techniques"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply K-fold in current model to check model accuracy\nfrom sklearn.model_selection import cross_val_score\naccuracies_linreg_model = cross_val_score(estimator = regressor, X = X, y = y, cv = 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking accuracies for 10 fold in linear regression model\naccuracies_linreg_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Mean and Standard Deviation between accuracies\naccuracies_linreg_model.mean()\naccuracies_linreg_model.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Accuracy is coming close to 76% and standard Devaition is also not that much (~8.4%) , but our score with this model is ~ 0.50 we need to improve this\nWe need to try another mode  , let's try with Random Forest Regression Model"},{"metadata":{},"cell_type":"markdown","source":"# 8. Random Forest Regression\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating new Regressor model for Random forest regression\nfrom sklearn.ensemble import RandomForestRegressor\nrf_regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nrf_regressor.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting from test set with this new model\ny_test_rf_pred=rf_regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting 2 dimensional y_test_pred into single dimension \ny_test_rf_pred=y_test_rf_pred.ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rounding off the values\ny_test_rf_pred=y_test_rf_pred.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Submission dataframe from id and predecited Sale price\nsubmission_rf_df=pd.DataFrame({\"Id\":y_test_id,\"SalePrice\":y_test_rf_pred})\n#Setting index as Id Column\nsubmission_rf_df.set_index(\"Id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting into CSV file for submission\nsubmission_rf_df.to_csv(\"submission_2.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score is improved with this submission , with linear regression model score(RMSE) was 0.51 and with this Random Forest regressor model it is 0.16955.\nLet's fine tune this model with Hyperparameter tuning"},{"metadata":{},"cell_type":"markdown","source":"# 7. Hyperparameter Tuning"},{"metadata":{},"cell_type":"markdown","source":"For implementing Grid Search in Random Forest Regressor model I have refered this [blog](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Best params\nrf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting from test set with this new model\ny_test_rf_random_pred=rf_random.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting 2 dimensional y_test_pred into single dimension \ny_test_rf_random_pred=y_test_rf_random_pred.ravel()\n#Rounding off the values\ny_test_rf_random_pred=y_test_rf_random_pred.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Submission dataframe from id and predecited Sale price\nsubmission_rf_random_df=pd.DataFrame({\"Id\":y_test_id,\"SalePrice\":y_test_rf_random_pred})\n#Setting index as Id Column\nsubmission_rf_random_df.set_index(\"Id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting into CSV file for submission\nsubmission_rf_random_df.to_csv(\"submission_3.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" *Score is improved with this submission , before hyper tuning of parameters it was **0.16955** and now it is **0.16379***"},{"metadata":{},"cell_type":"markdown","source":"# 8. XGBoost Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing required library and creating XGboost Regressor model\nfrom xgboost import XGBRegressor\nxgboost_regressor=XGBRegressor(learning_rate=0.01,n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.00006)\nxgboost_regressor.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting from test set with this new model\ny_test_xgb_pred=xgboost_regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting 2 dimensional y_test_pred into single dimension \ny_test_xgb_pred=y_test_xgb_pred.ravel()\n#Rounding off the values\ny_test_xgb_pred=y_test_xgb_pred.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Submission dataframe from id and predecited Sale price\nsubmission_xgb_df=pd.DataFrame({\"Id\":y_test_id,\"SalePrice\":y_test_xgb_pred})\n#Setting index as Id Column\nsubmission_xgb_df.set_index(\"Id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting into CSV file for submission\nsubmission_xgb_df.to_csv(\"submission_4.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":" *Score is improved with this submission , before XGBoost it was **0.16379** and now it is **0.16303***"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}