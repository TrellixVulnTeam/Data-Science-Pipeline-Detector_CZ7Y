{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3f0655588e38283eb9563d8264f5e8e568763346"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline\n\nfrom math import sqrt\nimport os\nfrom pathlib import Path\n\nfrom IPython.display import display, FileLink\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split, cross_val_score","execution_count":265,"outputs":[]},{"metadata":{"_uuid":"13dc0cf9240abf368b7b3fa6ccdcd8bb9d2fa664"},"cell_type":"markdown","source":"# House price predictions: simple linear model"},{"metadata":{"_uuid":"697091bc92083f7ab498b0a026067c9749c01669"},"cell_type":"markdown","source":"This notebook attempts to solve the Housing Prices predictions Kaggle competition using the simplest possible model, with lots of room to improve. A lot the ideas for feature engineering were taken from other Kaggle notebooks including: \n\n  * [Stacked Regressions : Top 4% on LeaderBoard](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard)\n  * [A study on Regression applied to the Ames dataset](https://www.kaggle.com/juliencs/a-study-on-regression-applied-to-the-ames-dataset)\n\nThe notebook is broken down into 4 short parts:\n\n  1. Load dataset.\n  2. Feature engineering.\n  3. Model training.\n  4. Submission."},{"metadata":{"_uuid":"7f484d4f329fd058ceff7d20f29ac0936fc03c81"},"cell_type":"markdown","source":"## Load dataset"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0b08bd0c4d9314f8b1911278108446df39a3ff80"},"cell_type":"code","source":"PATH = Path(\"../input/\")","execution_count":266,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b583bd25bd8f739fc3b38c4f3cc96c7267aa4ea","collapsed":true},"cell_type":"code","source":"list(PATH.iterdir())","execution_count":267,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d548136a9ba107e1998230a4225294c29dee7df0"},"cell_type":"code","source":"df_raw = pd.read_csv(PATH / 'train.csv')","execution_count":268,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fc374d4dc397ece8b02adbaef69fa2bc512c60e","collapsed":true},"cell_type":"code","source":"df_raw.head().transpose()","execution_count":269,"outputs":[]},{"metadata":{"_uuid":"ce772e62c8e415de9e00b8ca6c277b5bd34d3570"},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"_uuid":"961aeebb2fbaac6598d401052c1b6fa46302158a"},"cell_type":"markdown","source":"### Find and remove outliers"},{"metadata":{"_uuid":"2164cb2351c4d87ce109e3ef23d768bf2e6dce56"},"cell_type":"markdown","source":"The [documentation](http://https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt) for the dataset says *\"there are 5 observations that an instructor may wish to remove from the dataset\"*. It also says: *\"a plot of SALE PRICE versus GR LIV AREA will indicate them quickly\"*, so let's do that."},{"metadata":{"trusted":true,"_uuid":"f70c142c131804d98b7627477ee3b16bee8d9407","collapsed":true},"cell_type":"code","source":"plt.scatter(x=df_raw['GrLivArea'], y=df_raw['SalePrice'])\nplt.title('SALE PRICE vs GR LIV AREA')\nplt.show()","execution_count":270,"outputs":[]},{"metadata":{"_uuid":"538e81aaee47be427e7ee3b6cde56e91ac7a7a11"},"cell_type":"markdown","source":"The author also says: *\"I would recommend removing any houses with more than 4000 square feet from the data set (which eliminates these 5 unusual observations)*\" so let's do that too."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d02856c386cae19dea310ca716553665297ff7d2"},"cell_type":"code","source":"idx_to_drop = df_raw[(df_raw['GrLivArea']>4000)].index\ndf_raw.drop(idx_to_drop, inplace=True)","execution_count":271,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"981787fdf06bc826a6499f5ea84970306ab3ba1f","collapsed":true},"cell_type":"code","source":"plt.scatter(x=df_raw['GrLivArea'], y=df_raw['SalePrice'])\nplt.title('SALE PRICE vs GR LIV AREA (without outliers)')\nplt.show()","execution_count":272,"outputs":[]},{"metadata":{"_uuid":"8e79ac0119a131263375fd5752e33fd8d7fe8477"},"cell_type":"markdown","source":"### Add features\n\nAdd the house's total square feet because it helps a bit. I tried a few other features but nothing helped much."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cef3c1cc02eb3b931d6a6613b2f0169a975c3ff5"},"cell_type":"code","source":"df_raw['TotalSF'] = (\n    df_raw['BsmtFinSF1'].fillna(0) +\n    df_raw['BsmtFinSF2'].fillna(0) +\n    df_raw['1stFlrSF'].fillna(0) +\n    df_raw['2ndFlrSF'].fillna(0)\n)","execution_count":273,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f64765e9911c021c13e2f60a1cf05d6475c7adc9","collapsed":true},"cell_type":"code","source":"df_raw.TotalSF.head()","execution_count":274,"outputs":[]},{"metadata":{"_uuid":"2c5a7a019f4a3fb82418d628665f8d48398238e9"},"cell_type":"markdown","source":"### Extract target variable\n\nWe know the target variable is going to be SalePrice, so I'll pop that off the DataFrame. Kaggle says: *\"Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price\"* so I'll calculate the log of the sale price."},{"metadata":{"trusted":true,"_uuid":"331300d08ce2e29e011faa4a403b4e84a4041e32","collapsed":true},"cell_type":"code","source":"sale_price = df_raw.pop('SalePrice')\nsale_price_log = np.log(sale_price)\n\n# We also don't need this.\nhouse_ids = df_raw.pop('Id')","execution_count":275,"outputs":[]},{"metadata":{"_uuid":"ccb68771dfe9e787e24d4ad580a1f406a6a735f7"},"cell_type":"markdown","source":"### Prepare columns\n\nContinuous columns are columns with numbers that can be any size. Categorical columns have a limited number of choices. For example, `LotArea` can be any size whereas `LandSlope` has to be either `['Sev', 'Mod', 'Gtl']` (or `None`).\n\nWe'll need to process each type separately, so I've defined those by examing each column."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"26b821583ab7994bc8741e635e55e51b1214fc85"},"cell_type":"code","source":"continuous_columns = [\n    'BsmtUnfSF',\n    'FullBath',\n    'LotFrontage',\n    'BsmtFullBath',\n    '3SsnPorch',\n    'BedroomAbvGr',\n    'LowQualFinSF',\n    'BsmtFinSF1',\n    'WoodDeckSF',\n    'GarageArea',\n    'MiscVal',\n    'BsmtHalfBath',\n    'HalfBath',\n    'EnclosedPorch',\n    'ScreenPorch',\n    'TotRmsAbvGrd',\n    'Fireplaces',\n    'KitchenAbvGr',\n    'GarageCars',\n    '1stFlrSF',\n    'BsmtFinSF2',\n    'PoolArea',\n    '2ndFlrSF',\n    'TotalBsmtSF',\n    'TotalSF',\n    'GrLivArea',\n    'LotArea',\n    'OpenPorchSF',\n    'MasVnrArea'\n]\n\ncategorical_columns = [col for col in df_raw.columns if col not in continuous_columns]","execution_count":276,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bfcf787b930cb78735327fe61223f69a9f888ad","collapsed":true},"cell_type":"code","source":"categorical_columns","execution_count":277,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"47591e56907044f7800949dcda05893c29984226"},"cell_type":"code","source":"assert len(df_raw.columns) == len(categorical_columns + continuous_columns)","execution_count":278,"outputs":[]},{"metadata":{"_uuid":"8d0b0b4146cddc977cb6f45118359a4a395822cc"},"cell_type":"markdown","source":"#### Prepare categorical\n\nPandas has a categorical datatype that makes life rather easy when dealing with categorical columns. I'll convert all categorical columns as follows:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6bec01e9a911463deca747ea32ca77c323cbc8ed"},"cell_type":"code","source":"for col_name, col in df_raw[categorical_columns].items():\n    df_raw[col_name] = col.astype('category').cat.as_ordered()","execution_count":279,"outputs":[]},{"metadata":{"_uuid":"bbb2a0290080ad1956b982f84fd8774137dee96f"},"cell_type":"markdown","source":"For some categories, the order is quite important like `OverallQual` (10 is best, 1 is worst). Those values are called \"ordinal\". I'll ensure the ordinal columns are ordered."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5e282f0adaf481ccd4f94420455cc8ed75cf2f4e"},"cell_type":"code","source":"ordinal_column_data = [\n    ('ExterQual', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('ExterCond', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('BsmtQual', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('BsmtExposure', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('BsmtFinType1', ['Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']),\n    ('BsmtFinType2', ['Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']),\n    ('HeatingQC', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('KitchenQual', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('FireplaceQu', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('GarageFinish', ['Unf', 'Rfn', 'Fin']),\n    ('GarageQual', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('GarageCond', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('PoolQC', ['Fa', 'TA', 'Gd', 'Ex']),\n    ('OverallQual', list(range(1, 11))),\n    ('OverallCond', list(range(1, 11))),\n    ('LandSlope', ['Sev', 'Mod', 'Gtl']),  # Assume less slope is better\n    ('Functional', ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ']),\n    ('YearBuilt', list(range(1800, 2018))),\n    ('YrSold', list(range(2006, 2018))),\n    ('GarageYrBlt', list(range(1900, 2018))),\n    ('YearRemodAdd', list(range(1900, 2018)))\n]\n\nordinal_columns = [o[0] for o in ordinal_column_data]\n\nfor col, categories in ordinal_column_data:\n    df_raw[col].cat.set_categories(categories, ordered=True, inplace=True)","execution_count":280,"outputs":[]},{"metadata":{"_uuid":"7b88be7254f123d4e3242bd184749b31d87c08e4"},"cell_type":"markdown","source":"For columns with no ordinal relationship, we'll do some special processing later."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d8ec08881bd3f363b7c4eec653207a0901658a12"},"cell_type":"code","source":"other_cat_columns = [col for col in categorical_columns if col not in ordinal_columns]","execution_count":281,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3ba17339847a256b71b55a781da2aeb2e1ff926b"},"cell_type":"code","source":"assert len(categorical_columns) == len(ordinal_columns + other_cat_columns)","execution_count":282,"outputs":[]},{"metadata":{"_uuid":"a2c037a22721d13c41ef0b43a2ff365eaa968abc"},"cell_type":"markdown","source":"#### Prepare continuous\n\n##### Replace missing"},{"metadata":{"_uuid":"0d03ddd9cfe20e22e7712d3bd6837a70b7ccb345"},"cell_type":"markdown","source":"The first thing we'll want to do is replace all missing values with some value. For some columns, a missing value is equivalent to 0. For others, we'll use the column's median. We can also add a column `<column_name>_is_na` that will tell the model whether the value was originally missing or not. I got this idea from the [Fast.ai library](https://github.com/fastai/fastai).\n\nWe'll also want to save the median values to be used to replace missing values in the test set."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f8fc72c475a7be806bab1e9219d955504ce6f428"},"cell_type":"code","source":"NAs = {}","execution_count":283,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e1f471a7501b126c975ee1e7d71bb79fb8665e6","collapsed":true},"cell_type":"code","source":"for col in (\n    'GarageArea', 'GarageCars', 'BsmtFinSF1',\n    'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\n    'MasVnrArea'\n):\n    NAs[col] = 0\n    df_raw[col] = df_raw[col].fillna(0)\n    df_raw[f'{col}_na'] = pd.isna(df_raw[col])","execution_count":284,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"67f5898a377b8f235cef908a213416a7f69339dc"},"cell_type":"code","source":"for col in continuous_columns:\n    if not len(df_raw[df_raw[col].isna()]):\n        continue\n        \n    median = df_raw[col].median()\n        \n    df_raw[f'{col}_na'] = pd.isna(df_raw[col])\n    df_raw[col] = df_raw[col].fillna(median)\n    \n    NAs[col] = median","execution_count":285,"outputs":[]},{"metadata":{"_uuid":"a3d4a601574c00dff1829fccdddfc4deb69882a3"},"cell_type":"markdown","source":"##### Unskew data"},{"metadata":{"_uuid":"cef055f23a35524407bf3701be96404282c0edf2"},"cell_type":"markdown","source":"Machine learning models generally want data to be normally distributed. We can examine the skew of our features using the skew function in Scikit-learn."},{"metadata":{"trusted":true,"_uuid":"dbfae23babba5f435d4ae85a9c4f0c0389ec6a6d","collapsed":true},"cell_type":"code","source":"skew_feats = df_raw[continuous_columns].apply(skew).sort_values(ascending=False)\nskew_feats.head(10)","execution_count":286,"outputs":[]},{"metadata":{"_uuid":"48b54afc09a8aa812d5e028e7a5a42f05f117faf"},"cell_type":"markdown","source":"For the most skewed column, let's look at the distribution."},{"metadata":{"trusted":true,"_uuid":"35ede1c1985f9847edc6151470649558274ef9f4","collapsed":true},"cell_type":"code","source":"sns.distplot(df_raw[df_raw['MiscVal'] != 0]['MiscVal'])","execution_count":287,"outputs":[]},{"metadata":{"_uuid":"045ebd57dbe50766a5ac98df5a4d4319afbcd33f"},"cell_type":"markdown","source":"We can take the log of the most skewed variables, which seems to help a lot."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fcd0c5f976b077ecd818cce02a5983980f6da449"},"cell_type":"code","source":"skew_feats = skew_feats[abs(skew_feats) > 0.75]\n\nfor feat in skew_feats.index:\n    df_raw[feat] = np.log1p(df_raw[feat])","execution_count":288,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4da67d398b45943216e80ad84c77ea987f7a634c","collapsed":true},"cell_type":"code","source":"sns.distplot(df_raw[df_raw['MiscVal'] != 0]['MiscVal'])","execution_count":289,"outputs":[]},{"metadata":{"_uuid":"a182109adadd6370029072ce8a1a5fcab81450b1"},"cell_type":"markdown","source":"#### Numericalise\n\nLastly, we want to convert all categories to their numeric representation.\n\nWe also want to add \"dummies\" to the dataframe which deals with the unordered categorical variables by replacing the category: `LandSlope` with `LandSlope_Sev`, `LandSlope_Mod` and `LandSlope_Gtl`. ' We generate the dummies, then drop the original columns from the table before concatenating the dummies."},{"metadata":{"trusted":true,"_uuid":"d78f0a85d6ab9b8fbb13a97b2cd01e522b6a8868","collapsed":true},"cell_type":"code","source":"df_numeric = df_raw.copy()\ndummies = pd.get_dummies(df_numeric[other_cat_columns], dummy_na=True)\nfor col_name in categorical_columns:\n    # Use +1 to push the -1 NaN value to 0\n    df_numeric[col_name] = df_numeric[col_name].cat.codes + 1","execution_count":290,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"944a08718ec5c2090d9f023e127191e45a78a7d9"},"cell_type":"code","source":"df_numeric.drop(other_cat_columns, axis=1, inplace=True)\ndf_numeric = pd.concat([df_numeric, dummies], axis=1)","execution_count":291,"outputs":[]},{"metadata":{"_uuid":"8b11f0a4e894c61ba36ceead829ea6d1c717686e"},"cell_type":"markdown","source":"## Model training"},{"metadata":{"_uuid":"a13b8120f95070fd7750a09bb2ccc6d7b3dd497d"},"cell_type":"markdown","source":"Instead of separating the data into a validation set, we'll use KFolds cross-validation. It basically breaks the model into n train / val splits and trains a model then evaluates the results. It ensures that a particular train / val split is unlikely to bias the outcomes.\n\nI'm using the `Lasso` model which is just Linear Regression with L1 regularization. Straight Linear Regression tends to overfit a lot on this dataset."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6007530a19242d6566def6d22dbc5f72985fadaf"},"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=42)\nmodel = Lasso(alpha=0.0004)\nscores = np.sqrt(\n    -cross_val_score(model, df_numeric, sale_price_log, cv=kf, scoring='neg_mean_squared_error'))","execution_count":292,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2fb6cde04b87d6e5b2a0881fac826215bbd6d52","collapsed":true},"cell_type":"code","source":"scores.mean()","execution_count":293,"outputs":[]},{"metadata":{"_uuid":"a417062909dfd495ab7ca3c9d38af2162ed782a1"},"cell_type":"markdown","source":"I could actually get that result on the leaderboard, I'd be around 8th. This model translates to about 0.11898 on the test set, which puts me around 800th.\n\nI'll train a model on the full set before submitting my predictions."},{"metadata":{"trusted":true,"_uuid":"885bf2af0ad5f89ca5e8e1faca8e85c309231c8c","collapsed":true},"cell_type":"code","source":"final_model  = Lasso(alpha=0.0004)\nfinal_model.fit(df_numeric, sale_price_log)","execution_count":294,"outputs":[]},{"metadata":{"_uuid":"7703c7768e4ee4fe50ade9dd3f37c286c5ee9cd9"},"cell_type":"markdown","source":"## Submission\n\nNeed to ensure we do all the same preprocessing on the test set as training set before generating predictions."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8b9a78f33195e35898969b76c54d89ec2f3ce22a"},"cell_type":"code","source":"df_test_raw = pd.read_csv(PATH / 'test.csv')","execution_count":295,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"51eb5c31a4fbc9d834218ff6b873ff23d9eb327f"},"cell_type":"code","source":"house_ids = df_test_raw.pop('Id')","execution_count":296,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"48bb1984fe84e02c66a914ded2b087555dec2560"},"cell_type":"code","source":"df_test_raw['TotalSF'] = (\n    df_test_raw['BsmtFinSF1'].fillna(0) +\n    df_test_raw['BsmtFinSF2'].fillna(0) +\n    df_test_raw['1stFlrSF'].fillna(0) +\n    df_test_raw['2ndFlrSF'].fillna(0)\n)","execution_count":297,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7df99dfcd6710ddf3c8cc097bce2b9aae0cafdaa","collapsed":true},"cell_type":"code","source":"for col_name in categorical_columns:\n    df_test_raw[col_name] = (\n        pd.Categorical(\n            df_test_raw[col_name],\n            categories=df_raw[col_name].cat.categories,\n            ordered=True))","execution_count":298,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"829b8ba85313c8531978d0677aeed1c77c7a42e4","collapsed":true},"cell_type":"code","source":"for col in continuous_columns:\n    if col not in NAs:\n        continue\n\n    df_test_raw[f'{col}_na'] = pd.isna(df_test_raw[col])\n    df_test_raw[col] = df_test_raw[col].fillna(NAs[col])","execution_count":299,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e1ba6617f57743d9971d5d7f2ef27d38499a08b6"},"cell_type":"code","source":"# Handle any other NAs\ndf_test_raw[continuous_columns] = df_test_raw[continuous_columns].fillna(\n    df_test_raw[continuous_columns].median()\n)","execution_count":300,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e0e2909df3bcd92264372028456ffd16e79e8472"},"cell_type":"code","source":"for feat in skew_feats.index:\n    df_test_raw[feat] = np.log1p(df_test_raw[feat])","execution_count":301,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"21d127eed349bd0fadfcd6582cddccdb7a9952e0"},"cell_type":"code","source":"df_test = df_test_raw.copy()","execution_count":302,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db023df2ebe8910cb8bda707b7ec88d90bcea697","collapsed":true},"cell_type":"code","source":"test_dummies = pd.get_dummies(df_test[other_cat_columns], dummy_na=True)\nfor col_name in categorical_columns:\n    # Use +1 to push the -1 NaN value to 0\n    df_test[col_name] = df_test[col_name].cat.codes + 1\ndf_test.drop(other_cat_columns, axis=1, inplace=True)\ndf_test = pd.concat([df_test, test_dummies], axis=1)","execution_count":303,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2695d3371fd3456d6fc6f67a18fad0f8ecbacd73","collapsed":true},"cell_type":"code","source":"test_preds = final_model.predict(df_test)","execution_count":304,"outputs":[]},{"metadata":{"_uuid":"1751202f9fb26f8b8d526485e05c493776308cc0"},"cell_type":"markdown","source":"Generate CSV. Note that I have to use `np.exp` to reverse the log of the predictions before submitting."},{"metadata":{"trusted":true,"_uuid":"a1ed0cf923e95fe7c7df570672aca0262d683002","collapsed":true},"cell_type":"code","source":"pd.DataFrame(\n    {'Id': house_ids, 'SalePrice': np.exp(test_preds)}\n).to_csv('output.csv')","execution_count":305,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7b0c0f2c47d16002f9ab0e4dfb267714bd1bf741"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}