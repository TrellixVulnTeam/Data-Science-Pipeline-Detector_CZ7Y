{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Analysis and Feature engineering for House Price modelling\n\nIn this notebook I mix exploratory data analysis, to understand the nature of the data with feature engineering and feature selection. I make heavy use of the open source Python library [Feature-engine](https://feature-engine.readthedocs.io/en/latest/), because it removes quite a lot of coding from my hands and also.\n\n[Feature-engine](https://feature-engine.readthedocs.io/en/latest/)'s transformers come along with fit and transform funcionality, to learn the necessary parameters from the data, and then transform the data accordinly. So it is very easy to learn and use. And it can also detect automatically the nature of the variables, or engineer a selected group of variables if we so desire.\n\n\n## Table of contents\n\n**0. Feature Creation**\n\n    0.1 Binary indicators\n    \n    0.2 Variable Aggregations    \n    \n\n**1. Categorical variables**\n\n    1.1 Missing data\n\n    1.2 Cardinality\n    \n    1.3 Rare Labels\n    \n    1.4 Label grouping\n    \n    1.5 Variable selection\n    \n    1.6 Encoding\n    \n    \n**2. Time variables**\n\n    2.1 Time elapsed calculation\n    \n    2.2 Missing Data\n    \n    \n**3. Discrete variables**\n\n    3.1 Exploratory data analysis\n    \n    3.2 Missing Data\n    \n    \n**4. Numerical variables**\n\n    4.1 Distributions\n    \n    4.2 Relation with house sale price\n    \n    4.3 Missing Data\n    \n    \n**5. End to end pipeline with cross validation**\n\n\nThis notebook is based on the following resources:\n\n- [Feature Engineering for Machine Learning](https://www.courses.trainindata.com/p/feature-engineering-for-machine-learning), online course.\n- [Feature Selection for Machine Learning](https://www.courses.trainindata.com/p/feature-selection-for-machine-learning), online course.\n- [Packt Feature Engineering Cookbook](https://www.packtpub.com/data/python-feature-engineering-cookbook)\n- [Feature-engine](https://feature-engine.readthedocs.io/en/latest/), Python open source library\n\n## If you find this notebook useful, I will appreciate if you could upvote it :)","metadata":{}},{"cell_type":"code","source":"# let's install Feature-engine\n\n!pip install feature_engine","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:13:10.622726Z","iopub.execute_input":"2022-03-06T08:13:10.623127Z","iopub.status.idle":"2022-03-06T08:13:21.269206Z","shell.execute_reply.started":"2022-03-06T08:13:10.623094Z","shell.execute_reply":"2022-03-06T08:13:21.267924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom lightgbm import LGBMRegressor\n\n# Feature-engine's modules for feature egineering\nfrom feature_engine import creation\nfrom feature_engine import discretisation as disc\nfrom feature_engine import encoding as enc\nfrom feature_engine import imputation as imp\nfrom feature_engine import selection as sel","metadata":{"papermill":{"duration":1.331629,"end_time":"2021-01-05T18:54:08.546399","exception":false,"start_time":"2021-01-05T18:54:07.21477","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-06T08:13:21.273193Z","iopub.execute_input":"2022-03-06T08:13:21.273607Z","iopub.status.idle":"2022-03-06T08:13:22.720858Z","shell.execute_reply.started":"2022-03-06T08:13:21.273568Z","shell.execute_reply":"2022-03-06T08:13:22.719864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load training data\ndata = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n\n# load data for competition submission\n# this data does not have the target\nsubmission = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"papermill":{"duration":0.161779,"end_time":"2021-01-05T18:54:08.725737","exception":false,"start_time":"2021-01-05T18:54:08.563958","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-06T08:13:22.722406Z","iopub.execute_input":"2022-03-06T08:13:22.722776Z","iopub.status.idle":"2022-03-06T08:13:22.819253Z","shell.execute_reply.started":"2022-03-06T08:13:22.72274Z","shell.execute_reply":"2022-03-06T08:13:22.818352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split training data into train and test\n\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\n    ['Id', 'SalePrice'], axis=1),\n    data['SalePrice'],\n    test_size=0.05,\n    random_state=0)\n\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:13:22.820621Z","iopub.execute_input":"2022-03-06T08:13:22.820962Z","iopub.status.idle":"2022-03-06T08:13:22.848636Z","shell.execute_reply.started":"2022-03-06T08:13:22.820924Z","shell.execute_reply":"2022-03-06T08:13:22.847827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop id\nid_ = submission['Id']\n\nsubmission.drop('Id', axis=1, inplace=True)\n\nsubmission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:13:22.850849Z","iopub.execute_input":"2022-03-06T08:13:22.851145Z","iopub.status.idle":"2022-03-06T08:13:22.860274Z","shell.execute_reply.started":"2022-03-06T08:13:22.851115Z","shell.execute_reply":"2022-03-06T08:13:22.859189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to create a dataset with all the train, test and subimssion, \n# so I can easily compare the variable distributions\n\ndef create_master_data(train, test, submission, y_train, y_test):\n    \n    train = train.copy()\n    test = test.copy()\n    submission = submission.copy()\n    \n    train['target'] = y_train\n    train['data'] = 'train'\n    train.reset_index(drop=True, inplace=True)\n    \n    test['target'] = y_test\n    test['data'] = 'test'\n    test.reset_index(drop=True, inplace=True)\n    \n    submission['target'] = np.nan\n    submission['data'] = 'submission'\n    submission.reset_index(drop=True, inplace=True)\n    \n    master_data = pd.concat([train, test, submission], axis=0)\n    master_data.reset_index(drop=True, inplace=True)\n    \n    return master_data","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:13:22.862126Z","iopub.execute_input":"2022-03-06T08:13:22.862441Z","iopub.status.idle":"2022-03-06T08:13:22.873235Z","shell.execute_reply.started":"2022-03-06T08:13:22.862411Z","shell.execute_reply":"2022-03-06T08:13:22.872046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target\n\nLet's explore the target variable.","metadata":{}},{"cell_type":"code","source":"# histogran to evaluate target distribution\n\ny_train.hist(bins=50, density=True)\ny_test.hist(bins=50, density=True)\n\nplt.legend([\"Train\", \"Test\"])\nplt.ylabel('Number of houses')\nplt.xlabel('Sale Price')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:00.74944Z","iopub.execute_input":"2022-03-06T08:14:00.749872Z","iopub.status.idle":"2022-03-06T08:14:01.219548Z","shell.execute_reply.started":"2022-03-06T08:14:00.749838Z","shell.execute_reply":"2022-03-06T08:14:01.218644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, the 2 distributions are very similar, because the datasets come from a random division of the original data.","metadata":{}},{"cell_type":"code","source":"# let's transform the target, we are optimising for the log \n# of the target as per competition rules\n\nnp.log(y_train).hist(bins=50, density=True)\nnp.log(y_test).hist(bins=50, density=True)\n\nplt.ylabel('Number of houses')\nplt.xlabel('Log of Sale Price')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:04.605921Z","iopub.execute_input":"2022-03-06T08:14:04.606299Z","iopub.status.idle":"2022-03-06T08:14:05.056188Z","shell.execute_reply.started":"2022-03-06T08:14:04.606267Z","shell.execute_reply":"2022-03-06T08:14:05.055394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# density plot instead of histogram\nnp.log(y_train).plot.density()\nnp.log(y_test).plot.density()\n\nplt.xlabel('Log of Sale Price')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:05.271896Z","iopub.execute_input":"2022-03-06T08:14:05.272312Z","iopub.status.idle":"2022-03-06T08:14:05.531475Z","shell.execute_reply.started":"2022-03-06T08:14:05.272275Z","shell.execute_reply":"2022-03-06T08:14:05.530173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's transform the target with the log\n\ny_train = np.log(y_train)\n\ny_test = np.log(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:06.07586Z","iopub.execute_input":"2022-03-06T08:14:06.076255Z","iopub.status.idle":"2022-03-06T08:14:06.081677Z","shell.execute_reply.started":"2022-03-06T08:14:06.076218Z","shell.execute_reply":"2022-03-06T08:14:06.080715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Creation\n\nIn this section, I create new variables, from those already in the dataset.","metadata":{}},{"cell_type":"code","source":"# if the house has a pool\n\nX_train['HasPool'] = np.where(X_train['PoolArea']>0,1,0)\nX_test['HasPool'] = np.where(X_test['PoolArea']>0,1,0)\nsubmission['HasPool'] = np.where(submission['PoolArea']>0,1,0)\n\n\n# if the house has an Alley\n\nX_train['HasAlley'] = np.where(X_train['Alley'].isnull(), 0, 1)\nX_test['HasAlley'] = np.where(X_test['Alley'].isnull(), 0, 1)\nsubmission['HasAlley'] = np.where(submission['Alley'].isnull(), 0, 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:08.755971Z","iopub.execute_input":"2022-03-06T08:14:08.756521Z","iopub.status.idle":"2022-03-06T08:14:08.787642Z","shell.execute_reply.started":"2022-03-06T08:14:08.756487Z","shell.execute_reply":"2022-03-06T08:14:08.78679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create function to plot the median sale price vs a list of variables\n\ndef plot_median_price(variables, limits):\n    \n    tmp = pd.concat([X_train[variables].reset_index(drop=True),\n                 y_train.reset_index(drop=True)], axis=1)\n\n    # plot mean sale price per null value or otherwise\n    g = sns.PairGrid(tmp, x_vars=variables, y_vars=['SalePrice'])\n    g.map(sns.barplot)\n    plt.ylim(limits)   \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:09.245998Z","iopub.execute_input":"2022-03-06T08:14:09.246694Z","iopub.status.idle":"2022-03-06T08:14:09.254622Z","shell.execute_reply.started":"2022-03-06T08:14:09.246633Z","shell.execute_reply":"2022-03-06T08:14:09.253149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the mean house sale price for the created variables\n# to see if they add some value\n\nplot_median_price(['HasAlley', 'HasPool'], (11.5,12.5))","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:10.017898Z","iopub.execute_input":"2022-03-06T08:14:10.018422Z","iopub.status.idle":"2022-03-06T08:14:10.427459Z","shell.execute_reply.started":"2022-03-06T08:14:10.018388Z","shell.execute_reply":"2022-03-06T08:14:10.426183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not clear if these variables add a lot of value. The difference in price is small, but then the price is in log scale.","metadata":{}},{"cell_type":"code","source":"# The variables Condition1 and Condition2 indicate Proximity to various conditions. \n\n# Create a variable that aggregates both to indicate if the house is\n# close to more than 1 ammenity. If the house is close to more than 1\n# ammenity, the conditions take different values.\n\nX_train['Condition_total'] = np.where(X_train['Condition2'] == X_train['Condition1'], 0, 1)\nX_test['Condition_total'] = np.where(X_test['Condition2'] == X_test['Condition1'], 0, 1)\nsubmission['Condition_total'] = np.where(submission['Condition2'] == submission['Condition1'], 0, 1)\n\n# inspect the variable\nX_train['Condition_total'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:13.284643Z","iopub.execute_input":"2022-03-06T08:14:13.285102Z","iopub.status.idle":"2022-03-06T08:14:13.301819Z","shell.execute_reply.started":"2022-03-06T08:14:13.285064Z","shell.execute_reply":"2022-03-06T08:14:13.300703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Roughly 10% of the houses are proximal to 2 different ammenities.","metadata":{}},{"cell_type":"code","source":"# Exterior 1s and 2nd indicate the Exterior material covering on house:\n# Create a variable that aggregates both, like we did for contition\n\nX_train['Exterior_total'] = np.where(X_train['Exterior1st'] == X_train['Exterior2nd'], 0, 1)\nX_test['Exterior_total'] = np.where(X_test['Exterior1st'] == X_test['Exterior2nd'], 0, 1)\nsubmission['Exterior_total'] = np.where(submission['Exterior1st'] == submission['Exterior2nd'], 0, 1)\n\n# inspect the variable\nX_train['Exterior_total'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:14.122996Z","iopub.execute_input":"2022-03-06T08:14:14.123646Z","iopub.status.idle":"2022-03-06T08:14:14.14057Z","shell.execute_reply.started":"2022-03-06T08:14:14.123593Z","shell.execute_reply":"2022-03-06T08:14:14.139476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Roughly 20% of the houses ashow 2 materials in the exterior.","metadata":{}},{"cell_type":"code","source":"# plot the mean house sale price for the created variables\n\nplot_median_price(['Condition_total', 'Exterior_total'], (11.5,12.5))","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:17.252036Z","iopub.execute_input":"2022-03-06T08:14:17.252704Z","iopub.status.idle":"2022-03-06T08:14:17.646945Z","shell.execute_reply.started":"2022-03-06T08:14:17.252635Z","shell.execute_reply":"2022-03-06T08:14:17.645818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, it is unclear if these new variables add a lot of value. The difference in price seems minimal.","metadata":{}},{"cell_type":"markdown","source":"## Categorical Variables","metadata":{}},{"cell_type":"code","source":"# let's identify the categorical variables\n\ncategorical = [var for var in data.columns if data[var].dtype == 'O']\n\n# MSSubClass is also categorical by definition, despite its numeric values\ncategorical = categorical + ['MSSubClass']\n\n# number of categorical variables\nlen(categorical)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:21.242145Z","iopub.execute_input":"2022-03-06T08:14:21.242865Z","iopub.status.idle":"2022-03-06T08:14:21.255322Z","shell.execute_reply.started":"2022-03-06T08:14:21.242808Z","shell.execute_reply":"2022-03-06T08:14:21.254278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cast all variables as categorical\n\nX_train[categorical] = X_train[categorical].astype('O')\nX_test[categorical] = X_test[categorical].astype('O')\nsubmission[categorical] = submission[categorical].astype('O')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:21.794188Z","iopub.execute_input":"2022-03-06T08:14:21.794573Z","iopub.status.idle":"2022-03-06T08:14:21.826719Z","shell.execute_reply.started":"2022-03-06T08:14:21.794539Z","shell.execute_reply":"2022-03-06T08:14:21.825801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Missing Data","metadata":{}},{"cell_type":"code","source":"# which categorical variables have missing data?\n\n# capture categorical variables with NA in a dictionary\nnull_cat = {var: data[var].isnull().mean() for var in categorical if data[var].isnull().mean()>0}\n\n# plot\npd.Series(null_cat).sort_values().plot.bar(figsize=(10,4))\nplt.ylabel('Percentage of missing data')\nplt.axhline(y = 0.90, color = 'r', linestyle = '-') \nplt.axhline(y = 0.80, color = 'g', linestyle = '-') \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:24.682682Z","iopub.execute_input":"2022-03-06T08:14:24.683075Z","iopub.status.idle":"2022-03-06T08:14:24.925485Z","shell.execute_reply.started":"2022-03-06T08:14:24.683042Z","shell.execute_reply":"2022-03-06T08:14:24.924562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a few variables with a lot of data missing, and a few variables with few missing data. In particular, there are 3 variables for which > 90% of the values are missing (above red line)\n\nLet's examine if the variables with NA are somewhat informative of the house sale price.","metadata":{}},{"cell_type":"code","source":"# create a temporary dataset with the interest variables\n\ntmp = pd.concat([X_train[['Alley', 'MiscFeature', 'PoolQC']].reset_index(drop=True),\n                 y_train.reset_index(drop=True)], axis=1)\n\n# replace null values by 1, or 0 otherwise\nfor var in ['Alley', 'MiscFeature', 'PoolQC']:\n    tmp[var] = np.where(tmp[var].isnull(),1,0)\n\n\n# plot mean sale price per null value or otherwise\ng = sns.PairGrid(tmp, x_vars=['Alley', 'MiscFeature', 'PoolQC'], y_vars=['SalePrice'])\ng.map(sns.barplot)\nplt.ylim(10,13)   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:25.263821Z","iopub.execute_input":"2022-03-06T08:14:25.264197Z","iopub.status.idle":"2022-03-06T08:14:25.858431Z","shell.execute_reply.started":"2022-03-06T08:14:25.264165Z","shell.execute_reply":"2022-03-06T08:14:25.857589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"They don't seem to be hughly predictive so I will drop them (I already captured 2 of them in a binary feature anyways, at the beginning of the notebook).\n\n[DropFeatures](https://feature-engine.readthedocs.io/en/latest/selection/DropFeatures.html)","metadata":{}},{"cell_type":"code","source":"# DropFeatures allows me to drop selected feature groups from data\n\ndrop_features = sel.DropFeatures(features_to_drop = ['Alley', 'MiscFeature', 'PoolQC'])\n\nX_train = drop_features.fit_transform(X_train)\nX_test = drop_features.transform(X_test)\nsubmission = drop_features.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:27.978476Z","iopub.execute_input":"2022-03-06T08:14:27.97889Z","iopub.status.idle":"2022-03-06T08:14:27.999572Z","shell.execute_reply.started":"2022-03-06T08:14:27.978854Z","shell.execute_reply":"2022-03-06T08:14:27.998467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's impute the missing data in categorical variables.\n\n[CategoricalImputer](https://feature-engine.readthedocs.io/en/latest/imputation/CategoricalImputer.html)","metadata":{}},{"cell_type":"code","source":"# impute missing data, categorical variables are detected automatically\n# the imputer replaces missing data with the string 'Missing'\n\ncat_imputer = imp.CategoricalImputer(return_object=True)\n\ncat_imputer.fit(X_train)\n\n# the variables to impute are stored in the variables attribute\ncat_imputer.variables_[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:44.529109Z","iopub.execute_input":"2022-03-06T08:14:44.529653Z","iopub.status.idle":"2022-03-06T08:14:44.617723Z","shell.execute_reply.started":"2022-03-06T08:14:44.529617Z","shell.execute_reply":"2022-03-06T08:14:44.616776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the number of categorical variables detected by Feature-engine\n\nlen(cat_imputer.variables_)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:50.407517Z","iopub.execute_input":"2022-03-06T08:14:50.408049Z","iopub.status.idle":"2022-03-06T08:14:50.413171Z","shell.execute_reply.started":"2022-03-06T08:14:50.408016Z","shell.execute_reply":"2022-03-06T08:14:50.412389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the imputer will add a string 'Missing' to each categorical variable\n\ncat_imputer.imputer_dict_","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:52.458926Z","iopub.execute_input":"2022-03-06T08:14:52.459336Z","iopub.status.idle":"2022-03-06T08:14:52.466957Z","shell.execute_reply.started":"2022-03-06T08:14:52.459302Z","shell.execute_reply":"2022-03-06T08:14:52.466058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove missing data\n\nX_train = cat_imputer.transform(X_train)\nX_test = cat_imputer.transform(X_test)\nsubmission = cat_imputer.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:52.932712Z","iopub.execute_input":"2022-03-06T08:14:52.933107Z","iopub.status.idle":"2022-03-06T08:14:53.023987Z","shell.execute_reply.started":"2022-03-06T08:14:52.933069Z","shell.execute_reply":"2022-03-06T08:14:53.023042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check that we do not have more missing data in categorical variables\n# if we do, the list should not be empty\n\n[c for c in cat_imputer.variables_ if X_train[c].isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:14:58.909286Z","iopub.execute_input":"2022-03-06T08:14:58.909938Z","iopub.status.idle":"2022-03-06T08:14:58.93377Z","shell.execute_reply.started":"2022-03-06T08:14:58.909878Z","shell.execute_reply":"2022-03-06T08:14:58.93249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quasi-constant variables\n\nLet's inspect if there are some variables that show predominantly 1 value  in all observations. We can find them automatically with the folliwing class from Feature-engine:\n\n[DropConstantFeatures](https://feature-engine.readthedocs.io/en/latest/selection/DropConstantFeatures.html)","metadata":{}},{"cell_type":"code","source":"# assign the categorical variable list to the categorical variable name\n\ncategorical = cat_imputer.variables_\n\n# we still have 41 categorical variables in the dataset\nlen(categorical)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:04.009533Z","iopub.execute_input":"2022-03-06T08:15:04.009945Z","iopub.status.idle":"2022-03-06T08:15:04.015706Z","shell.execute_reply.started":"2022-03-06T08:15:04.009907Z","shell.execute_reply":"2022-03-06T08:15:04.014824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I ask the transformer to remove all variables that show the same value in more than\n# 94% of the observations (tol=0.94)\nconstant = sel.DropConstantFeatures(tol=0.94, variables=categorical)\n\n# find constant features\nconstant.fit(X_train)\n\n# the quasi-constant features are stored in this attribute\nconstant.features_to_drop_","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:07.977163Z","iopub.execute_input":"2022-03-06T08:15:07.977535Z","iopub.status.idle":"2022-03-06T08:15:08.062652Z","shell.execute_reply.started":"2022-03-06T08:15:07.977504Z","shell.execute_reply":"2022-03-06T08:15:08.061476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# put data together for analysis\n\ndata = create_master_data(X_train, X_test, submission, y_train, y_test)\n\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:08.639081Z","iopub.execute_input":"2022-03-06T08:15:08.639465Z","iopub.status.idle":"2022-03-06T08:15:08.681696Z","shell.execute_reply.started":"2022-03-06T08:15:08.639431Z","shell.execute_reply":"2022-03-06T08:15:08.680855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot number of observations per category, per variable\n# so that we see that these variables show mostly 1 value in most of the \n# observations\n\nfor variable in constant.features_to_drop_:\n    \n    data.groupby(variable)['data'].value_counts().unstack().plot.bar(figsize=(10,5))\n    plt.title(variable)\n    plt.ylabel('Number of houses')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:11.805466Z","iopub.execute_input":"2022-03-06T08:15:11.805997Z","iopub.status.idle":"2022-03-06T08:15:13.117887Z","shell.execute_reply.started":"2022-03-06T08:15:11.805963Z","shell.execute_reply":"2022-03-06T08:15:13.116758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that in most of these variables, most observations show the same value. I will re-map these variables to group all the categories that are less frequent into a new category called 'Other'.","metadata":{}},{"cell_type":"code","source":"# I will re-group these variables into either the majoritarian category\n# or \"Other\"\n\n# if a category is present in less than 10% of the observations, we group it with other\n# infrequent categories (tol param)\n\nrare_enc = enc.RareLabelEncoder(tol = 0.1,\n                                n_categories=1, # number of minimum categories per variable for the grouping to proceed\n                                variables=constant.features_to_drop_, # the variables to pre-process\n                                replace_with='Other', # the label to use to replace the original category\n                               )\n\nrare_enc.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:18.40557Z","iopub.execute_input":"2022-03-06T08:15:18.405955Z","iopub.status.idle":"2022-03-06T08:15:18.432965Z","shell.execute_reply.started":"2022-03-06T08:15:18.40592Z","shell.execute_reply":"2022-03-06T08:15:18.43215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make the grouping\n\nX_train = rare_enc.transform(X_train)\nX_test = rare_enc.transform(X_test)\nsubmission = rare_enc.transform(submission)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:18.891441Z","iopub.execute_input":"2022-03-06T08:15:18.892033Z","iopub.status.idle":"2022-03-06T08:15:18.914989Z","shell.execute_reply.started":"2022-03-06T08:15:18.89198Z","shell.execute_reply":"2022-03-06T08:15:18.913946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, when I plot the data again, I should see only 2 categories in each variable\n\n# put data together for analysis\ndata = create_master_data(X_train, X_test, submission, y_train, y_test)\n\nfor variable in constant.features_to_drop_:\n    \n    data.groupby(variable)['data'].value_counts().unstack().plot.bar(figsize=(10,5))\n    plt.title(variable)\n    plt.ylabel('Number of houses')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:19.381563Z","iopub.execute_input":"2022-03-06T08:15:19.381992Z","iopub.status.idle":"2022-03-06T08:15:20.434701Z","shell.execute_reply.started":"2022-03-06T08:15:19.381947Z","shell.execute_reply":"2022-03-06T08:15:20.433803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quality variables\n\nThere are a number of variables that refer to the quality of some aspect of the house, for example the garage, or the fence, or the kitchen. I will replace these categories by numbers increasing with the quality of the place or room.\n\n- Ex = Excellent\n- Gd = Good\n- TA = Average/Typical\n- Fa =\tFair\n- Po = Poor","metadata":{}},{"cell_type":"code","source":"qual_mappings = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'Missing': 0, 'NA': 0}\n\nqual_vars = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n             'HeatingQC', 'KitchenQual', 'FireplaceQu',\n             'GarageQual', 'GarageCond',\n            ]\n\nfor var in qual_vars:\n    X_train[var] = X_train[var].map(qual_mappings)\n    X_test[var] = X_test[var].map(qual_mappings)\n    submission[var] = submission[var].map(qual_mappings)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:23.493463Z","iopub.execute_input":"2022-03-06T08:15:23.494102Z","iopub.status.idle":"2022-03-06T08:15:23.539494Z","shell.execute_reply.started":"2022-03-06T08:15:23.494052Z","shell.execute_reply":"2022-03-06T08:15:23.538437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exposure_mappings = {'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4, 'Missing': 0, 'NA': 0}\n\nvar = 'BsmtExposure'\n\nX_train[var] = X_train[var].map(exposure_mappings)\nX_test[var] = X_test[var].map(exposure_mappings)\nsubmission[var] = submission[var].map(exposure_mappings)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:23.805933Z","iopub.execute_input":"2022-03-06T08:15:23.80657Z","iopub.status.idle":"2022-03-06T08:15:23.819166Z","shell.execute_reply.started":"2022-03-06T08:15:23.806517Z","shell.execute_reply":"2022-03-06T08:15:23.818123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finish_mappings = {'Missing': 0, 'NA': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n\nfinish_vars = ['BsmtFinType1', 'BsmtFinType2']\n\nfor var in finish_vars:\n    X_train[var] = X_train[var].map(finish_mappings)\n    X_test[var] = X_test[var].map(finish_mappings)\n    submission[var] = submission[var].map(finish_mappings)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:24.207681Z","iopub.execute_input":"2022-03-06T08:15:24.208235Z","iopub.status.idle":"2022-03-06T08:15:24.225432Z","shell.execute_reply.started":"2022-03-06T08:15:24.208196Z","shell.execute_reply":"2022-03-06T08:15:24.22444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"garage_mappings = {'Missing': 0, 'NA': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n\nvar = 'GarageFinish'\n\nX_train[var] = X_train[var].map(garage_mappings)\nX_test[var] = X_test[var].map(garage_mappings)\nsubmission[var] = submission[var].map(garage_mappings)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:24.719632Z","iopub.execute_input":"2022-03-06T08:15:24.720176Z","iopub.status.idle":"2022-03-06T08:15:24.733818Z","shell.execute_reply.started":"2022-03-06T08:15:24.720141Z","shell.execute_reply":"2022-03-06T08:15:24.732453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fence_mappings = {'Missing': 0, 'NA': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n\nvar = 'Fence'\n\nX_train[var] = X_train[var].map(fence_mappings)\nX_test[var] = X_test[var].map(fence_mappings)\nsubmission[var] = submission[var].map(fence_mappings)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:27.261522Z","iopub.execute_input":"2022-03-06T08:15:27.261905Z","iopub.status.idle":"2022-03-06T08:15:27.273191Z","shell.execute_reply.started":"2022-03-06T08:15:27.261871Z","shell.execute_reply":"2022-03-06T08:15:27.272431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# capture all quality variables\n\nqual_vars  = qual_vars + finish_vars + ['BsmtExposure','GarageFinish','Fence']","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:27.563703Z","iopub.execute_input":"2022-03-06T08:15:27.564122Z","iopub.status.idle":"2022-03-06T08:15:27.569244Z","shell.execute_reply.started":"2022-03-06T08:15:27.564085Z","shell.execute_reply":"2022-03-06T08:15:27.568348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now let's plot the house mean sale price based on the quality of the \n# various attributes\n\n# put data together for analysis\ndata = create_master_data(X_train, X_test, submission, y_train, y_test)\n\nfor var in qual_vars:\n    # make boxplot with Catplot\n    sns.catplot(x=var, y='target', data=data[data['data']=='train'], kind=\"box\", height=4, aspect=1.5)\n    # add data points to boxplot with stripplot\n    sns.stripplot(x=var, y='target', data=data[data['data']=='train'], jitter=0.1, alpha=0.3, color='k')\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:27.898694Z","iopub.execute_input":"2022-03-06T08:15:27.899358Z","iopub.status.idle":"2022-03-06T08:15:32.138412Z","shell.execute_reply.started":"2022-03-06T08:15:27.899317Z","shell.execute_reply":"2022-03-06T08:15:32.137443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For many quality variables, we see an increase in the house price, with the quality.\n\n### Cardinality\n\nCardinality indicates the number of unique values or categories per variable. The highest the cardinality, the more difficult the variable is to handle. Although it could provide more information.","metadata":{}},{"cell_type":"code","source":"# let's collect the remaining categorical variables\n\ncategorical = [c for c in categorical if c not in constant.features_to_drop_]\n\ncategorical = [c for c in categorical if c not in qual_vars]\n\nlen(categorical)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:39.312694Z","iopub.execute_input":"2022-03-06T08:15:39.313072Z","iopub.status.idle":"2022-03-06T08:15:39.321402Z","shell.execute_reply.started":"2022-03-06T08:15:39.313041Z","shell.execute_reply":"2022-03-06T08:15:39.320328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with nunique from pandas we count the number of unique categories per variable\n\ndata[categorical].nunique().sort_values().plot.bar(figsize=(15,5))\nplt.ylabel('Number of categories per variable')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:40.123898Z","iopub.execute_input":"2022-03-06T08:15:40.124272Z","iopub.status.idle":"2022-03-06T08:15:40.525147Z","shell.execute_reply.started":"2022-03-06T08:15:40.124241Z","shell.execute_reply":"2022-03-06T08:15:40.524219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some variables have few categories (low cardinality), others have a lot of categories (high cardinality). \n\nIn addition to the number of unique categories, it is important to know how many observations in the dataset show each category. Rare categories tend to bring problems when building the models, with little reliable information, precisely, because there are not a lot of observations to learn from.","metadata":{}},{"cell_type":"code","source":"# plot number of observations / houses per category, per variable\n\nfor variable in categorical:\n    data.groupby(variable)['data'].value_counts().unstack().plot.bar(figsize=(10,5))\n    plt.title(variable)\n    plt.ylabel('Number of houses')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:41.618027Z","iopub.execute_input":"2022-03-06T08:15:41.618406Z","iopub.status.idle":"2022-03-06T08:15:46.665815Z","shell.execute_reply.started":"2022-03-06T08:15:41.618374Z","shell.execute_reply":"2022-03-06T08:15:46.664854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that pretty much for every variable, some categories are shared by many houses, and some are shown only by very few houses. Then, we wouldn't know if we should trust the Sale Price of houses with these few categories, because we have few houses to learn from.\n\nAnother problem that comes up with rare categories, is that they may appear only in the train set, or only in the test set, or maybe even only in the submission. So if it appears only in the train set, they may cause over-fitting. But if it appears only on the test set, then the model does not know what to make of that category, and it may crash.\n\n**I will group infrequent labels together into 1 umbrella category called 'Rare'**. But before that, let's have a look at the mean sale price per category, to see if we find some value in any of these variables that we can capitalize.","metadata":{}},{"cell_type":"code","source":"# the following function calculates:\n\n# 1) the percentage of houses per category\n# 2) the mean SalePrice per category\n\n# and returns a dataframe with those 2 variables\n\ndef calculate_mean_target_per_category(df, var):\n    \n    df = pd.concat([df, y_train], axis=1)\n    \n    # total number of houses\n    total_houses = len(df)\n\n    # percentage of houses per category\n    temp_df = pd.Series(df[var].value_counts() / total_houses).reset_index()\n    temp_df.columns = [var, 'perc_houses']\n\n    # add the mean SalePrice\n    temp_df = temp_df.merge(df.groupby([var])['SalePrice'].mean().reset_index(),\n                            on=var,\n                            how='left')\n\n    return temp_df","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:46.667902Z","iopub.execute_input":"2022-03-06T08:15:46.668197Z","iopub.status.idle":"2022-03-06T08:15:46.675787Z","shell.execute_reply.started":"2022-03-06T08:15:46.668168Z","shell.execute_reply":"2022-03-06T08:15:46.674733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we use the function for the variable 'Neighborhood'\ntemp_df = calculate_mean_target_per_category(X_train, 'Neighborhood')\n\ntemp_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:46.677044Z","iopub.execute_input":"2022-03-06T08:15:46.677344Z","iopub.status.idle":"2022-03-06T08:15:46.722465Z","shell.execute_reply.started":"2022-03-06T08:15:46.677318Z","shell.execute_reply":"2022-03-06T08:15:46.721744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now I create a function to plot of the\n# category frequency and mean SalePrice.\n\n# This will help us visualise the relationship between the\n# target and the labels of the  categorical variable\n\ndef plot_categories(df, var):\n    \n    fig, ax = plt.subplots(figsize=(8, 4))\n    plt.xticks(df.index, df[var], rotation=90)\n\n    ax2 = ax.twinx()\n    ax.bar(df.index, df[\"perc_houses\"], color='lightgrey')\n    ax2.plot(df.index, df[\"SalePrice\"], color='green', label='Seconds')\n    ax.axhline(y=0.05, color='red')\n    ax.set_ylabel('percentage of houses per category')\n    ax.set_xlabel(var)\n    ax2.set_ylabel('Average Sale Price per category')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:46.954321Z","iopub.execute_input":"2022-03-06T08:15:46.954939Z","iopub.status.idle":"2022-03-06T08:15:46.964682Z","shell.execute_reply.started":"2022-03-06T08:15:46.954894Z","shell.execute_reply":"2022-03-06T08:15:46.963398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot house count and sale price for Neighbourhood.\n\nplot_categories(temp_df, 'Neighborhood')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:47.782757Z","iopub.execute_input":"2022-03-06T08:15:47.783136Z","iopub.status.idle":"2022-03-06T08:15:48.161444Z","shell.execute_reply.started":"2022-03-06T08:15:47.783105Z","shell.execute_reply":"2022-03-06T08:15:48.160498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, we can see that there are expensive neighbourhoods and cheap neighbourhoods.","metadata":{}},{"cell_type":"code","source":"temp_df['SalePrice'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:51.476087Z","iopub.execute_input":"2022-03-06T08:15:51.476462Z","iopub.status.idle":"2022-03-06T08:15:51.487178Z","shell.execute_reply.started":"2022-03-06T08:15:51.476431Z","shell.execute_reply":"2022-03-06T08:15:51.486162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make a list of the least expensive neighbourhoods\n\ncheap_neighbourhoods = temp_df[temp_df['SalePrice']<11.85]['Neighborhood'].unique()\n\ncheap_neighbourhoods","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:51.825656Z","iopub.execute_input":"2022-03-06T08:15:51.8262Z","iopub.status.idle":"2022-03-06T08:15:51.840862Z","shell.execute_reply.started":"2022-03-06T08:15:51.826153Z","shell.execute_reply":"2022-03-06T08:15:51.839499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make a list of the most expensive neighbourhoods\n\nexpensive_neighbourhoods = temp_df[temp_df['SalePrice']>12.2]['Neighborhood'].unique()\n\nexpensive_neighbourhoods","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:52.146021Z","iopub.execute_input":"2022-03-06T08:15:52.146386Z","iopub.status.idle":"2022-03-06T08:15:52.154739Z","shell.execute_reply.started":"2022-03-06T08:15:52.146346Z","shell.execute_reply":"2022-03-06T08:15:52.153805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new variable that segregates neigbourhoods as per the previous lists\n\nX_train['Neigh_Price'] = np.where(X_train['Neighborhood'].isin(cheap_neighbourhoods),\n                                  0, np.where(X_train['Neighborhood'].isin(expensive_neighbourhoods),\n                                              2, 1))\n\nX_test['Neigh_Price'] = np.where(X_test['Neighborhood'].isin(cheap_neighbourhoods),\n                                  0, np.where(X_test['Neighborhood'].isin(expensive_neighbourhoods),\n                                              2, 1))\n\nsubmission['Neigh_Price'] = np.where(submission['Neighborhood'].isin(cheap_neighbourhoods),\n                                  0, np.where(submission['Neighborhood'].isin(expensive_neighbourhoods),\n                                              2, 1))\n\n# let's inspect the new variable\nX_train['Neigh_Price'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:53.014465Z","iopub.execute_input":"2022-03-06T08:15:53.015274Z","iopub.status.idle":"2022-03-06T08:15:53.033979Z","shell.execute_reply.started":"2022-03-06T08:15:53.015221Z","shell.execute_reply":"2022-03-06T08:15:53.032823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's inspect the value of our new variable\n\n# put data together for analysis\ndata = create_master_data(X_train, X_test, submission, y_train, y_test)\n\nsns.catplot(x='Neigh_Price', y='target', data=data[data['data']=='train'], kind=\"box\", height=4, aspect=1.5)\n# add data points to boxplot with stripplot\nsns.stripplot(x='Neigh_Price', y='target', data=data[data['data']=='train'], jitter=0.1, alpha=0.3, color='k')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:55.494255Z","iopub.execute_input":"2022-03-06T08:15:55.494836Z","iopub.status.idle":"2022-03-06T08:15:55.768378Z","shell.execute_reply.started":"2022-03-06T08:15:55.494789Z","shell.execute_reply":"2022-03-06T08:15:55.767492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks good to me.","metadata":{}},{"cell_type":"code","source":"# let's plot for the remaining categorical variables\n# the count of houses per category and the mean sale price\n\nfor col in categorical:\n    \n    # we plotted this variable already\n    if col !='Neighborhood':\n        \n        # re using the functions I created\n        temp_df = calculate_mean_target_per_category(data, col)\n        plot_categories(temp_df, col)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:15:56.026262Z","iopub.execute_input":"2022-03-06T08:15:56.026856Z","iopub.status.idle":"2022-03-06T08:16:01.502771Z","shell.execute_reply.started":"2022-03-06T08:15:56.026815Z","shell.execute_reply":"2022-03-06T08:16:01.501634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The other variables, don't show a clear increase in house for certain categories. So I will not derive new features from them.","metadata":{}},{"cell_type":"code","source":"# Now I will group infrequent labels together:\n\n# if a category is present in less than 5% of the observations, we group it with other\n# infrequent categories (tol param)\n\nrare_enc = enc.RareLabelEncoder(tol = 0.05,\n                                n_categories=4, # number of minimum categories per variable for the grouping to proceed\n                                variables=categorical\n                               )\n\nrare_enc.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:01.504396Z","iopub.execute_input":"2022-03-06T08:16:01.50475Z","iopub.status.idle":"2022-03-06T08:16:01.553204Z","shell.execute_reply.started":"2022-03-06T08:16:01.504718Z","shell.execute_reply":"2022-03-06T08:16:01.552279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The warnings tell me that there are a few categorical variables that I indicated to the variables parameter, that have less than 4 unique categories. So the transformer will not pre-process those.","metadata":{}},{"cell_type":"code","source":"X_train = rare_enc.transform(X_train)\nX_test = rare_enc.transform(X_test)\nsubmission = rare_enc.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:01.55475Z","iopub.execute_input":"2022-03-06T08:16:01.555209Z","iopub.status.idle":"2022-03-06T08:16:01.599425Z","shell.execute_reply.started":"2022-03-06T08:16:01.555176Z","shell.execute_reply":"2022-03-06T08:16:01.598563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# put data together for analysis\n\ndata = create_master_data(X_train, X_test, submission, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:01.93225Z","iopub.execute_input":"2022-03-06T08:16:01.932627Z","iopub.status.idle":"2022-03-06T08:16:01.966225Z","shell.execute_reply.started":"2022-03-06T08:16:01.932594Z","shell.execute_reply":"2022-03-06T08:16:01.965047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we can plot the variables with grouped categories\n\nfor variable in categorical:\n    data.groupby(variable)['data'].value_counts().unstack().plot.bar(figsize=(10,5))\n    plt.title(variable)\n    plt.ylabel('Number of houses')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:02.342271Z","iopub.execute_input":"2022-03-06T08:16:02.342636Z","iopub.status.idle":"2022-03-06T08:16:06.37368Z","shell.execute_reply.started":"2022-03-06T08:16:02.342605Z","shell.execute_reply":"2022-03-06T08:16:06.372654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that after grouping the variables, the categories appear in all the 3 datasets, train, test and submission. And also, they are shared by at least more than 5% of the observations in the datasets.\n\n### Categorical variable importance\n\nLet's plot the House Sale Price distribution per category per variable to understand if there is a difference.\n\n**Boxplot**: indicates the median value of the house, and the interquantal range distance, which contains most of the houses. The rombos above and below are outliers for that distribution.\n\n**Jitter**: on top of the box plot I plot the houses individually as dots, this gives us an idea of how many houses show that category. More dots, more houses.\n\nIf the box plots are at the same height, then the categories or the variable do not show predictive power. But if the show different heights for the different categories, then they might.","metadata":{}},{"cell_type":"code","source":"for variable in categorical:\n    # make boxplot with Catplot\n    sns.catplot(x=variable, y='target', data=data[data['data']=='train'], kind=\"box\", height=4, aspect=1.5)\n    # add data points to boxplot with stripplot\n    sns.stripplot(x=variable, y='target', data=data[data['data']=='train'], jitter=0.1, alpha=0.3, color='k')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:06.375474Z","iopub.execute_input":"2022-03-06T08:16:06.375938Z","iopub.status.idle":"2022-03-06T08:16:12.084099Z","shell.execute_reply.started":"2022-03-06T08:16:06.375899Z","shell.execute_reply":"2022-03-06T08:16:12.083096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some categories seem to correlate with higher or lower house sale prices. And some, not at all. See for example the plot for the variable **Foundation**. The different foundations seem to correlate with lower sale prices. The same is true for the variable **SaleCondition** and others.\n\nWe can try and determine which of the variables are useful using an approach used in the KDD2009 data science competition. The approach consists in replacing the category by the mean of the target. And then using that replacement as a prediction, and evaluate the performance comparing the prediction to the real value of the house price.\n\nWe can perform all of this, very easily with a class from Feature-engine.\n\nCheck [SelectByTargetMeanPerformance](https://feature-engine.readthedocs.io/en/latest/selection/SelectByTargetMeanPerformance.html) for more details.","metadata":{}},{"cell_type":"code","source":"selector = sel.SelectByTargetMeanPerformance(\n    variables=categorical, # the variables to examine\n    scoring='r2_score', # the metric to use for the performance evaluation\n    threshold=0.1, # the minimum performance threshold for a variable to be selected\n    cv=2, # the cross-validation fold\n    random_state=0)\n\n# find the variables that are important\nselector.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:12.086545Z","iopub.execute_input":"2022-03-06T08:16:12.086899Z","iopub.status.idle":"2022-03-06T08:16:12.234371Z","shell.execute_reply.started":"2022-03-06T08:16:12.086865Z","shell.execute_reply":"2022-03-06T08:16:12.233318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in the attribute feature_performance_ the class stores the performance\n# of each feature\n\npd.Series(selector.feature_performance_).sort_values().plot.bar(figsize=(15,5))\nplt.ylabel('r2')\n\n# the red line is the threshold we selected.\nplt.axhline(y = 0.1, color = 'r', linestyle = '-') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:12.235871Z","iopub.execute_input":"2022-03-06T08:16:12.236188Z","iopub.status.idle":"2022-03-06T08:16:12.488332Z","shell.execute_reply.started":"2022-03-06T08:16:12.236159Z","shell.execute_reply":"2022-03-06T08:16:12.487111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I selected the threshold somewhat arbitrarily. We can play with this a bit to select more or less variables. If we leave the parameter to None, then the class will select those features which performance is above the mean performance of the group. An S2 of 0.1 indicates that the variable explains 10% of the total variability in the data. So it is not too bad.","metadata":{}},{"cell_type":"code","source":"# number of variables to remove\n\nlen(selector.features_to_drop_)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:12.489799Z","iopub.execute_input":"2022-03-06T08:16:12.490214Z","iopub.status.idle":"2022-03-06T08:16:12.496099Z","shell.execute_reply.started":"2022-03-06T08:16:12.490178Z","shell.execute_reply":"2022-03-06T08:16:12.495028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove non predictive categorical variables\n\nX_train = selector.transform(X_train)\nX_test = selector.transform(X_test)\nsubmission = selector.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:12.497523Z","iopub.execute_input":"2022-03-06T08:16:12.497975Z","iopub.status.idle":"2022-03-06T08:16:12.519042Z","shell.execute_reply.started":"2022-03-06T08:16:12.49793Z","shell.execute_reply":"2022-03-06T08:16:12.518033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode categorical variables\n\nTo use categorical variables in machine learning models, we need to encode them into numbers. At least for the Gradient Boosting Classifier from Sklearn.\n\nWe are going to assign numbers to the variables, but these numbers will be assigned from smaller to bigger, based on the mean sale price per category. This way, we create (hopefully) a monotonic relationship between the encoded variable and the target, which may boost the performance of the model.\n\n[OrdinalEncoder](https://feature-engine.readthedocs.io/en/latest/encoding/OrdinalEncoder.html)","metadata":{}},{"cell_type":"code","source":"# let's identify all remaining categorical variables (remember that we encoded\n# some into numbers already)\n\ncategorical = [var for var in X_train.columns if X_train[var].dtype == 'O']\n\n# MSSubClass is also categorical by definition, despite its numeric values\ncategorical = categorical + ['MSSubClass']\n\n# number of categorical variables\nlen(categorical)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:16.478743Z","iopub.execute_input":"2022-03-06T08:16:16.479123Z","iopub.status.idle":"2022-03-06T08:16:16.64081Z","shell.execute_reply.started":"2022-03-06T08:16:16.479092Z","shell.execute_reply":"2022-03-06T08:16:16.639879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cast all variables as categorical\n\nX_train[categorical] = X_train[categorical].astype('O')\nX_test[categorical] = X_test[categorical].astype('O')\nsubmission[categorical] = submission[categorical].astype('O')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:16.778447Z","iopub.execute_input":"2022-03-06T08:16:16.778863Z","iopub.status.idle":"2022-03-06T08:16:16.819338Z","shell.execute_reply.started":"2022-03-06T08:16:16.778825Z","shell.execute_reply":"2022-03-06T08:16:16.818208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up the ordinal encoder from Feature-engine\n\nencoder = enc.OrdinalEncoder(encoding_method='ordered',\n                             variables=categorical)\n\nencoder.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:17.072614Z","iopub.execute_input":"2022-03-06T08:16:17.073009Z","iopub.status.idle":"2022-03-06T08:16:17.12013Z","shell.execute_reply.started":"2022-03-06T08:16:17.072975Z","shell.execute_reply":"2022-03-06T08:16:17.119019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in this attribute we find the numbers that will replace each category in each variable\n\nencoder.encoder_dict_","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:17.324495Z","iopub.execute_input":"2022-03-06T08:16:17.324919Z","iopub.status.idle":"2022-03-06T08:16:17.334104Z","shell.execute_reply.started":"2022-03-06T08:16:17.324881Z","shell.execute_reply":"2022-03-06T08:16:17.333156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode the variables\n\nX_train = encoder.transform(X_train)\nX_test = encoder.transform(X_test)\nsubmission = encoder.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:17.916616Z","iopub.execute_input":"2022-03-06T08:16:17.917197Z","iopub.status.idle":"2022-03-06T08:16:17.999485Z","shell.execute_reply.started":"2022-03-06T08:16:17.91716Z","shell.execute_reply":"2022-03-06T08:16:17.998326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's examine the monotonic relationships\n\nfor var in categorical:\n    plt.scatter(X_train[var], y_train, alpha=0.2)\n    plt.ylabel('Log of Sale Price')\n    plt.xlabel(var)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:19.815208Z","iopub.execute_input":"2022-03-06T08:16:19.815843Z","iopub.status.idle":"2022-03-06T08:16:22.53447Z","shell.execute_reply.started":"2022-03-06T08:16:19.815777Z","shell.execute_reply":"2022-03-06T08:16:22.533453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For some variables, we see an increase in the house price with the encoded variable value. ","metadata":{}},{"cell_type":"code","source":"# check that NAN were not introduced during the encoding\n\n[c for c in categorical if X_train[c].isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:22.53686Z","iopub.execute_input":"2022-03-06T08:16:22.537179Z","iopub.status.idle":"2022-03-06T08:16:22.547408Z","shell.execute_reply.started":"2022-03-06T08:16:22.537149Z","shell.execute_reply":"2022-03-06T08:16:22.546483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check that NAN were not introduced during the encoding\n\n[c for c in categorical if X_test[c].isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:22.549022Z","iopub.execute_input":"2022-03-06T08:16:22.549329Z","iopub.status.idle":"2022-03-06T08:16:22.563821Z","shell.execute_reply.started":"2022-03-06T08:16:22.549289Z","shell.execute_reply":"2022-03-06T08:16:22.562556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[c for c in categorical if submission[c].isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:22.565121Z","iopub.execute_input":"2022-03-06T08:16:22.565563Z","iopub.status.idle":"2022-03-06T08:16:22.582203Z","shell.execute_reply.started":"2022-03-06T08:16:22.565515Z","shell.execute_reply":"2022-03-06T08:16:22.58101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time variables\n\nThere are a few variables that show time, for example the year in which the house was sold, or the garage was built.","metadata":{}},{"cell_type":"code","source":"year_vars = [var for var in data.columns if 'Yr' in var or 'Year' in var]\n\nyear_vars","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:22.584423Z","iopub.execute_input":"2022-03-06T08:16:22.585066Z","iopub.status.idle":"2022-03-06T08:16:22.595354Z","shell.execute_reply.started":"2022-03-06T08:16:22.585015Z","shell.execute_reply":"2022-03-06T08:16:22.594387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's plot the sale price over the years.","metadata":{}},{"cell_type":"code","source":"data = create_master_data(X_train, X_test, submission, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:23.392855Z","iopub.execute_input":"2022-03-06T08:16:23.393393Z","iopub.status.idle":"2022-03-06T08:16:23.412761Z","shell.execute_reply.started":"2022-03-06T08:16:23.39336Z","shell.execute_reply":"2022-03-06T08:16:23.411875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make boxplot with Catplot\nsns.catplot(x='YrSold', y='target', data=data[data['data']=='train'], kind=\"box\", height=4, aspect=1.5)\n# add data points to boxplot with stripplot\nsns.stripplot(x='YrSold', y='target', data=data[data['data']=='train'], jitter=0.1, alpha=0.3, color='k')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:23.660794Z","iopub.execute_input":"2022-03-06T08:16:23.661455Z","iopub.status.idle":"2022-03-06T08:16:23.959803Z","shell.execute_reply.started":"2022-03-06T08:16:23.661416Z","shell.execute_reply":"2022-03-06T08:16:23.958506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the sale price seems stable over the years for which we have data.\n\nNow let's plot the house price vs the last time where something was remodelled in the house. I expect more expensive houses if they were recently remodelled.","metadata":{}},{"cell_type":"code","source":"for variable in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n    plt.scatter(X_train[variable], y_train)\n    plt.ylabel('Log of sale Price')\n    plt.xlabel(variable)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:24.009147Z","iopub.execute_input":"2022-03-06T08:16:24.00951Z","iopub.status.idle":"2022-03-06T08:16:24.651176Z","shell.execute_reply.started":"2022-03-06T08:16:24.009478Z","shell.execute_reply":"2022-03-06T08:16:24.650201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There seems to be a slight linear trend to increase in house prices, for those houses that were remodelled in later years.\n\nLet's capture the difference between the year in which something was remodelled or built and the sale time.\n\n[CombineWithFeatureReference](https://feature-engine.readthedocs.io/en/latest/creation/CombineWithReferenceFeature.html)","metadata":{}},{"cell_type":"code","source":"# this transformer will substract all the variables in the reference list, from YrSold\n# to determine the age of remodelling at point of sale\n\ncreate = creation.CombineWithReferenceFeature(\n    variables_to_combine = ['YrSold'],\n    reference_variables = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt'],\n    operations=['sub'],\n)\n\ncreate.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:26.752963Z","iopub.execute_input":"2022-03-06T08:16:26.753367Z","iopub.status.idle":"2022-03-06T08:16:26.765825Z","shell.execute_reply.started":"2022-03-06T08:16:26.75333Z","shell.execute_reply":"2022-03-06T08:16:26.765091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = create.transform(X_train)\nX_test = create.transform(X_test)\nsubmission = create.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:27.082891Z","iopub.execute_input":"2022-03-06T08:16:27.083543Z","iopub.status.idle":"2022-03-06T08:16:27.109473Z","shell.execute_reply.started":"2022-03-06T08:16:27.083506Z","shell.execute_reply":"2022-03-06T08:16:27.108757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can see the new variables at the right of the dataframe\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:27.26871Z","iopub.execute_input":"2022-03-06T08:16:27.269113Z","iopub.status.idle":"2022-03-06T08:16:27.293736Z","shell.execute_reply.started":"2022-03-06T08:16:27.269083Z","shell.execute_reply":"2022-03-06T08:16:27.292816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if the variable 'YearRemodAdd' shows the same value as the\n# variable 'YearBuilt', that means that the house has not been remodelled\n\n# so let's create a new feature that captures this.\n\nremodelled = creation.CombineWithReferenceFeature(\n    variables_to_combine = ['YearRemodAdd'],\n    reference_variables = ['YearBuilt'],\n    operations=['sub'],\n)\n\nremodelled.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:27.408985Z","iopub.execute_input":"2022-03-06T08:16:27.409747Z","iopub.status.idle":"2022-03-06T08:16:27.423039Z","shell.execute_reply.started":"2022-03-06T08:16:27.409708Z","shell.execute_reply":"2022-03-06T08:16:27.421851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = remodelled.transform(X_train)\nX_test = remodelled.transform(X_test)\nsubmission = remodelled.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:27.594915Z","iopub.execute_input":"2022-03-06T08:16:27.595302Z","iopub.status.idle":"2022-03-06T08:16:27.614998Z","shell.execute_reply.started":"2022-03-06T08:16:27.595265Z","shell.execute_reply":"2022-03-06T08:16:27.613724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can see the new variable at the right of the dataframe\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:29.903052Z","iopub.execute_input":"2022-03-06T08:16:29.90347Z","iopub.status.idle":"2022-03-06T08:16:29.930026Z","shell.execute_reply.started":"2022-03-06T08:16:29.903432Z","shell.execute_reply":"2022-03-06T08:16:29.929025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we need to remove the original time features\n\ndrop_features = sel.DropFeatures(features_to_drop =['YearBuilt', 'YearRemodAdd', 'GarageYrBlt','YrSold'])\n\nX_train = drop_features.fit_transform(X_train)\nX_test = drop_features.transform(X_test)\nsubmission = drop_features.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:30.226813Z","iopub.execute_input":"2022-03-06T08:16:30.227199Z","iopub.status.idle":"2022-03-06T08:16:30.245411Z","shell.execute_reply.started":"2022-03-06T08:16:30.227169Z","shell.execute_reply":"2022-03-06T08:16:30.244044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Missing data","metadata":{}},{"cell_type":"code","source":"# let's check if the variables have missing data\n\nX_train[[\n    'YrSold_sub_YearBuilt', 'YrSold_sub_YearRemodAdd' ,'YrSold_sub_GarageYrBlt', 'YearRemodAdd_sub_YearBuilt']\n].isnull().mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:30.616863Z","iopub.execute_input":"2022-03-06T08:16:30.61745Z","iopub.status.idle":"2022-03-06T08:16:30.629831Z","shell.execute_reply.started":"2022-03-06T08:16:30.617397Z","shell.execute_reply":"2022-03-06T08:16:30.628813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[[\n    'YrSold_sub_YearBuilt', 'YrSold_sub_YearRemodAdd' ,'YrSold_sub_GarageYrBlt', 'YearRemodAdd_sub_YearBuilt']\n].isnull().mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:30.772885Z","iopub.execute_input":"2022-03-06T08:16:30.773492Z","iopub.status.idle":"2022-03-06T08:16:30.783939Z","shell.execute_reply.started":"2022-03-06T08:16:30.773455Z","shell.execute_reply":"2022-03-06T08:16:30.782617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[[\n    'YrSold_sub_YearBuilt', 'YrSold_sub_YearRemodAdd' ,'YrSold_sub_GarageYrBlt', 'YearRemodAdd_sub_YearBuilt']\n].isnull().mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:30.966893Z","iopub.execute_input":"2022-03-06T08:16:30.967476Z","iopub.status.idle":"2022-03-06T08:16:30.978837Z","shell.execute_reply.started":"2022-03-06T08:16:30.967418Z","shell.execute_reply":"2022-03-06T08:16:30.977995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"YrSold_sub_GarageYrBlt shows missing data. I will impute this altogether when I impute numerical variables later on in the notebook.\n\nThe final temporal variable is the month in which the house was sold. Let's check if there is some price change depending on the month of the sale.","metadata":{}},{"cell_type":"code","source":"# make boxplot with Catplot\nsns.catplot(x='MoSold', y='target', data=data[data['data']=='train'], kind=\"box\", height=4, aspect=1.5)\n# add data points to boxplot with stripplot\nsns.stripplot(x='MoSold', y='target', data=data[data['data']=='train'], jitter=0.1, alpha=0.3, color='k')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:31.352949Z","iopub.execute_input":"2022-03-06T08:16:31.353479Z","iopub.status.idle":"2022-03-06T08:16:31.824824Z","shell.execute_reply.started":"2022-03-06T08:16:31.353438Z","shell.execute_reply":"2022-03-06T08:16:31.823802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The mean house sale price seems similar throughout the mosnts, but there is a difference in the number of houses sold, with less houses sold in Jan and Feb, and more houses sold towards the summer months of the northern hemisphere.","metadata":{}},{"cell_type":"markdown","source":"## Discrete variables","metadata":{}},{"cell_type":"code","source":"discrete = [\n    var for var in X_train.columns if X_train[var].dtype != 'O'\n    and var not in year_vars\n    and var not in qual_vars+categorical\n    and len(X_train[var].unique()) < 20 \n]\n\n# number of discrete variables\nlen(discrete)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:31.897035Z","iopub.execute_input":"2022-03-06T08:16:31.897418Z","iopub.status.idle":"2022-03-06T08:16:31.916739Z","shell.execute_reply.started":"2022-03-06T08:16:31.897383Z","shell.execute_reply":"2022-03-06T08:16:31.915801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see if there is a relationship between the values of discrete houses and the mean sale price.","metadata":{}},{"cell_type":"code","source":"for var in discrete:\n    # make boxplot with Catplot\n    sns.catplot(x=var, y='target', data=data[data['data']=='train'], kind=\"box\", height=4, aspect=1.5)\n    # add data points to boxplot with stripplot\n    sns.stripplot(x=var, y='target', data=data[data['data']=='train'], jitter=0.1, alpha=0.3, color='k')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:34.671464Z","iopub.execute_input":"2022-03-06T08:16:34.671844Z","iopub.status.idle":"2022-03-06T08:16:40.430338Z","shell.execute_reply.started":"2022-03-06T08:16:34.671811Z","shell.execute_reply":"2022-03-06T08:16:40.429153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For most of these variables, there is a correlation between the number assigned to the house and the sale price. Particularly for those variables which values are determined by people, for example OverallQual, or OverallCond. But also for variables like number of bathrooms or rooms.\n\nThe only variable that seems to have only 1 value predominantly is PoolArea, so I will remove it from the dataset.","metadata":{}},{"cell_type":"code","source":"# remove original feature\n\ndrop_features = sel.DropFeatures(features_to_drop =['PoolArea'])\n\nX_train = drop_features.fit_transform(X_train)\nX_test = drop_features.transform(X_test)\nsubmission = drop_features.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:40.433437Z","iopub.execute_input":"2022-03-06T08:16:40.43398Z","iopub.status.idle":"2022-03-06T08:16:40.449337Z","shell.execute_reply.started":"2022-03-06T08:16:40.433929Z","shell.execute_reply":"2022-03-06T08:16:40.448112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Missing data\n\n# let's capture the discrete variables with missing data\n\nnull_disc = {var: data[var].isnull().mean() for var in discrete if data[var].isnull().mean()>0}\n\n# plot\npd.Series(null_disc).sort_values().plot.bar(figsize=(10,4))\nplt.ylabel('Percentage of missing data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:40.450949Z","iopub.execute_input":"2022-03-06T08:16:40.451568Z","iopub.status.idle":"2022-03-06T08:16:40.601903Z","shell.execute_reply.started":"2022-03-06T08:16:40.45152Z","shell.execute_reply":"2022-03-06T08:16:40.60097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 3 discrete variables with NA. I will impute these altogether with numerical variables ","metadata":{}},{"cell_type":"code","source":"# get variable names\n\npd.Series(null_disc).sort_values().index","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:40.603716Z","iopub.execute_input":"2022-03-06T08:16:40.604298Z","iopub.status.idle":"2022-03-06T08:16:40.61358Z","shell.execute_reply.started":"2022-03-06T08:16:40.604246Z","shell.execute_reply":"2022-03-06T08:16:40.612391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numerical variables","metadata":{}},{"cell_type":"code","source":"numerical = [\n    var for var in X_train.columns \n    if var not in categorical + qual_vars + discrete + year_vars\n]\n\nlen(numerical)","metadata":{"papermill":{"duration":0.038643,"end_time":"2021-01-05T18:54:08.8858","exception":false,"start_time":"2021-01-05T18:54:08.847157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-06T08:16:40.616853Z","iopub.execute_input":"2022-03-06T08:16:40.617593Z","iopub.status.idle":"2022-03-06T08:16:40.626492Z","shell.execute_reply.started":"2022-03-06T08:16:40.61754Z","shell.execute_reply":"2022-03-06T08:16:40.625577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's examine the distribution of the numerical continuous variables\n\nX_train[numerical].hist(bins=50, figsize=(15,15))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:40.628295Z","iopub.execute_input":"2022-03-06T08:16:40.629038Z","iopub.status.idle":"2022-03-06T08:16:45.699737Z","shell.execute_reply.started":"2022-03-06T08:16:40.628987Z","shell.execute_reply":"2022-03-06T08:16:45.698679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some variables that show predominantly 1 value, like MiscVal, ScreenPorch, LowQualFinSF. I could remove them with the constant features selector. But I could also let the model decide if they are important or not. So I will do this, this time.","metadata":{}},{"cell_type":"code","source":"# let's plot the sale price vs the numerical variables\n\ntmp = pd.concat([X_train, y_train], axis=1)\n\nsns.pairplot(data=tmp,\n             y_vars='SalePrice',\n             x_vars=['LotFrontage',\n                     'LotArea',\n                     'MasVnrArea',\n                     'BsmtFinSF1',\n                     'BsmtFinSF2', ])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:45.701322Z","iopub.execute_input":"2022-03-06T08:16:45.701789Z","iopub.status.idle":"2022-03-06T08:16:46.496828Z","shell.execute_reply.started":"2022-03-06T08:16:45.70175Z","shell.execute_reply":"2022-03-06T08:16:46.49572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We se that the higher the value of the variable, the higher the sale price, for most of these variables.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(data=tmp,\n             y_vars=['SalePrice'],\n             x_vars=['BsmtUnfSF',\n                     'TotalBsmtSF',\n                     '1stFlrSF',\n                     '2ndFlrSF',\n                     'LowQualFinSF', ])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:46.499611Z","iopub.execute_input":"2022-03-06T08:16:46.500291Z","iopub.status.idle":"2022-03-06T08:16:47.336333Z","shell.execute_reply.started":"2022-03-06T08:16:46.500237Z","shell.execute_reply":"2022-03-06T08:16:47.335268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same here, the higher the value of the variable, the higher the sale price, in general.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(data=tmp,\n             y_vars=['SalePrice'],\n             x_vars=['GrLivArea',\n                     'GarageArea',\n                     'WoodDeckSF',\n                     'OpenPorchSF',\n                     'EnclosedPorch', ])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:47.33945Z","iopub.execute_input":"2022-03-06T08:16:47.339974Z","iopub.status.idle":"2022-03-06T08:16:48.401175Z","shell.execute_reply.started":"2022-03-06T08:16:47.339927Z","shell.execute_reply":"2022-03-06T08:16:48.400233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data=tmp,\n             y_vars=['SalePrice'],\n             x_vars=['3SsnPorch',\n                     'ScreenPorch',\n                     'MiscVal'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:48.402523Z","iopub.execute_input":"2022-03-06T08:16:48.403047Z","iopub.status.idle":"2022-03-06T08:16:48.888886Z","shell.execute_reply.started":"2022-03-06T08:16:48.402992Z","shell.execute_reply":"2022-03-06T08:16:48.887976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For these variables, there does not seem to be a clear tendency.","metadata":{}},{"cell_type":"code","source":"# and now the time variables we created before\n\nsns.pairplot(data=tmp,\n             y_vars=['SalePrice'],\n             x_vars=['YrSold_sub_YearBuilt', \n                     'YrSold_sub_YearRemodAdd' ,\n                     'YrSold_sub_GarageYrBlt',\n                     'YearRemodAdd_sub_YearBuilt'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:48.890109Z","iopub.execute_input":"2022-03-06T08:16:48.890399Z","iopub.status.idle":"2022-03-06T08:16:49.522086Z","shell.execute_reply.started":"2022-03-06T08:16:48.890371Z","shell.execute_reply":"2022-03-06T08:16:49.521088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is some promise in these variables\n\n### Missing Data","metadata":{"trusted":true}},{"cell_type":"code","source":"# concatenate data sources\ndata = create_master_data(X_train, X_test, submission, y_train, y_test)\n\n# capture numerical variables with NA\nnull_num = {var: data[var].isnull().mean() for var in numerical if data[var].isnull().mean()>0}\n\n# plot\npd.Series(null_num).sort_values().plot.bar(figsize=(5,4))\nplt.ylabel('Percentage of missing data')\nplt.show()","metadata":{"papermill":{"duration":0.042698,"end_time":"2021-01-05T18:54:08.947435","exception":false,"start_time":"2021-01-05T18:54:08.904737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-06T08:16:49.523471Z","iopub.execute_input":"2022-03-06T08:16:49.523912Z","iopub.status.idle":"2022-03-06T08:16:49.717778Z","shell.execute_reply.started":"2022-03-06T08:16:49.52386Z","shell.execute_reply":"2022-03-06T08:16:49.716873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a few variables that show missing data.\n\nLet's add a missing indicator first and then impute the missing data with the median value of the variable. \n\n[MeanMedianImputer](https://feature-engine.readthedocs.io/en/latest/imputation/MeanMedianImputer.html)\n\n[AddMissingIndicator](https://feature-engine.readthedocs.io/en/1.0.x/imputation/AddMissingIndicator.html)","metadata":{}},{"cell_type":"code","source":"vars_to_impute = [c for c in null_num.keys()]\n\n# add the discrete variables with NA\nvars_to_impute = vars_to_impute + ['GarageCars', 'BsmtFullBath', 'BsmtHalfBath']\n\nindicator = imp.AddMissingIndicator(missing_only = False,\n                                variables = vars_to_impute,\n                               )\n\nindicator.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:49.719169Z","iopub.execute_input":"2022-03-06T08:16:49.719448Z","iopub.status.idle":"2022-03-06T08:16:49.728681Z","shell.execute_reply.started":"2022-03-06T08:16:49.719421Z","shell.execute_reply":"2022-03-06T08:16:49.727813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in this attribute we find the variables for which\n# the missing indicators will be added\n\nindicator.variables_","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:49.729805Z","iopub.execute_input":"2022-03-06T08:16:49.73017Z","iopub.status.idle":"2022-03-06T08:16:49.741536Z","shell.execute_reply.started":"2022-03-06T08:16:49.730135Z","shell.execute_reply":"2022-03-06T08:16:49.740524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = indicator.transform(X_train)\nX_test = indicator.transform(X_test)\nsubmission = indicator.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:49.742838Z","iopub.execute_input":"2022-03-06T08:16:49.743171Z","iopub.status.idle":"2022-03-06T08:16:49.778616Z","shell.execute_reply.started":"2022-03-06T08:16:49.743128Z","shell.execute_reply":"2022-03-06T08:16:49.777797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now replace NA by the median value\n\nnum_imputer = imp.MeanMedianImputer(imputation_method = 'median',\n                                    variables = vars_to_impute,\n                                   )\n\nnum_imputer.fit(X_train)\n\n# the median for imputation for each numerical variable\nnum_imputer.imputer_dict_","metadata":{"papermill":{"duration":0.054805,"end_time":"2021-01-05T18:54:09.235925","exception":false,"start_time":"2021-01-05T18:54:09.18112","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-06T08:16:49.780647Z","iopub.execute_input":"2022-03-06T08:16:49.781136Z","iopub.status.idle":"2022-03-06T08:16:49.795879Z","shell.execute_reply.started":"2022-03-06T08:16:49.781091Z","shell.execute_reply":"2022-03-06T08:16:49.794719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = num_imputer.transform(X_train)\nX_test = num_imputer.transform(X_test)\nsubmission = num_imputer.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"papermill":{"duration":0.035819,"end_time":"2021-01-05T18:54:09.293677","exception":false,"start_time":"2021-01-05T18:54:09.257858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-06T08:16:49.797657Z","iopub.execute_input":"2022-03-06T08:16:49.798342Z","iopub.status.idle":"2022-03-06T08:16:49.816684Z","shell.execute_reply.started":"2022-03-06T08:16:49.79829Z","shell.execute_reply":"2022-03-06T08:16:49.815811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:49.817868Z","iopub.execute_input":"2022-03-06T08:16:49.818392Z","iopub.status.idle":"2022-03-06T08:16:49.845344Z","shell.execute_reply.started":"2022-03-06T08:16:49.818356Z","shell.execute_reply":"2022-03-06T08:16:49.843933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[c for c in X_train.columns if X_train[c].isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:49.847492Z","iopub.execute_input":"2022-03-06T08:16:49.848335Z","iopub.status.idle":"2022-03-06T08:16:49.881003Z","shell.execute_reply.started":"2022-03-06T08:16:49.848283Z","shell.execute_reply":"2022-03-06T08:16:49.879812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[c for c in X_test.columns if X_test[c].isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:49.882951Z","iopub.execute_input":"2022-03-06T08:16:49.883277Z","iopub.status.idle":"2022-03-06T08:16:49.906555Z","shell.execute_reply.started":"2022-03-06T08:16:49.883241Z","shell.execute_reply":"2022-03-06T08:16:49.905321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[c for c in submission.columns if submission[c].isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:50.017504Z","iopub.execute_input":"2022-03-06T08:16:50.018068Z","iopub.status.idle":"2022-03-06T08:16:50.043431Z","shell.execute_reply.started":"2022-03-06T08:16:50.018031Z","shell.execute_reply":"2022-03-06T08:16:50.042451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create some more features\n\n# total number of basement bathrooms\nbath_bsmt = creation.MathematicalCombination(\n    variables_to_combine=['BsmtHalfBath', 'BsmtFullBath'],\n    math_operations=['sum'],\n    new_variables_names=['BsmtBath_total'],\n)\n\n# total number of bathrooms\nbath_ground = creation.MathematicalCombination(\n    variables_to_combine=['FullBath', 'HalfBath'],\n    math_operations=['sum'],\n    new_variables_names=['Bath_total'],\n)\n\nX_train = bath_bsmt.fit_transform(X_train)\nX_test = bath_bsmt.transform(X_test)\nsubmission = bath_bsmt.transform(submission)\n\nX_train = bath_ground.fit_transform(X_train)\nX_test = bath_ground.transform(X_test)\nsubmission = bath_ground.transform(submission)\n\nX_train.shape, X_test.shape, submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:50.263702Z","iopub.execute_input":"2022-03-06T08:16:50.264284Z","iopub.status.idle":"2022-03-06T08:16:50.335995Z","shell.execute_reply.started":"2022-03-06T08:16:50.264247Z","shell.execute_reply":"2022-03-06T08:16:50.335097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model with nested cross-validation","metadata":{}},{"cell_type":"code","source":"X_train.reset_index(drop=True, inplace=True)\ny_train.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:50.583194Z","iopub.execute_input":"2022-03-06T08:16:50.583588Z","iopub.status.idle":"2022-03-06T08:16:50.589298Z","shell.execute_reply.started":"2022-03-06T08:16:50.583551Z","shell.execute_reply":"2022-03-06T08:16:50.588285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nested_cross_val(model, grid):\n    \n    # configure the cross-validation procedure\n    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n\n    # enumerate splits\n    outer_results = list()\n\n    for train_ix, test_ix in cv_outer.split(X_train):\n\n        # split data\n        xtrain, xtest = X_train.loc[train_ix, :], X_train.loc[test_ix, :]\n        ytrain, ytest = y_train[train_ix], y_train[test_ix]\n\n        # configure the cross-validation procedure\n        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n\n        # define search\n        search = GridSearchCV(model, grid, scoring='neg_root_mean_squared_error', cv=cv_inner, refit=True)\n\n        # execute search\n        search.fit(xtrain, ytrain)\n\n        # evaluate model on the hold out dataset\n        yhat = search.predict(xtest)\n\n        # evaluate the model\n        rmse = mean_squared_error(ytest, yhat, squared=False)\n\n        # store the result\n        outer_results.append(rmse)\n\n        # report progress\n        print('>rmse_outer=%.3f, rmse_inner=%.3f, cfg=%s' % (rmse, search.best_score_, search.best_params_))\n\n    # summarize the estimated performance of the model\n    print('rmse_outer: %.3f +- %.3f' % (np.mean(outer_results), np.std(outer_results)))\n    \n    return search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:52.378474Z","iopub.execute_input":"2022-03-06T08:16:52.379207Z","iopub.status.idle":"2022-03-06T08:16:52.392827Z","shell.execute_reply.started":"2022-03-06T08:16:52.379148Z","shell.execute_reply":"2022-03-06T08:16:52.39178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GBM","metadata":{}},{"cell_type":"code","source":"gbm = GradientBoostingRegressor(\n    loss='ls',\n    n_estimators=100,\n    criterion='friedman_mse',\n    min_samples_split=2,\n    max_depth=3,\n    random_state=0,\n    n_iter_no_change=2,\n    tol=0.0001,\n    )\n\nparam_grid = dict(\n    loss=['ls', 'huber'],\n    n_estimators=[10, 20, 50, 100, 200, 500, 1000, 2000],\n    min_samples_split=[0.1, 0.3, 0.5],\n    max_depth=[1,2,3,4,None],\n    )\n\nsearch = nested_cross_val(gbm, param_grid)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:16:52.834201Z","iopub.execute_input":"2022-03-06T08:16:52.8346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(search.cv_results_)\n\nresults.sort_values(by='mean_test_score', ascending=False, inplace=True)\n\nresults.reset_index(drop=True, inplace=True)\n\nresults[['params','mean_test_score', 'std_test_score']]\n\nresults['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n\nplt.ylabel('Mean test score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's get the predictions\n\nX_train_preds = search.predict(X_train)\nX_test_preds = search.predict(X_test)\n\nsubmission_preds = search.predict(submission)\n\nprint('Train rmse: ', mean_squared_error(y_train, X_train_preds, squared=False))\nprint('Test rmse: ', mean_squared_error(y_test, X_test_preds, squared=False))\nprint()\nprint('Train r2: ', r2_score(y_train, X_train_preds))\nprint('Test r2: ', r2_score(y_test, X_test_preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.exp(submission_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# my_submission = pd.DataFrame({'Id': id_, 'SalePrice': np.exp(submission_preds)})\n\n# # you could use any filename. We choose submission here\n# my_submission.to_csv('submission_gbm_full.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Light GBM","metadata":{}},{"cell_type":"code","source":"# Light GBM\n\nlgbm_param = {\n    \"num_leaves\": [6, 8, 20, 30],\n    \"max_depth\": [2, 4, 6, 8, 10],\n    \"n_estimators\": [50, 100, 200, 500],\n    'colsample_bytree': [0.3, 1.0],\n}\n\nlgbm = LGBMRegressor(\n    learning_rate = 0.1, \n    min_child_weight = 0.4,\n    objective='regression', \n    random_state=0)\n\nsearch = nested_cross_val(lgbm, lgbm_param)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(search.cv_results_)\n\nresults.sort_values(by='mean_test_score', ascending=False, inplace=True)\n\nresults.reset_index(drop=True, inplace=True)\n\nresults[['params','mean_test_score', 'std_test_score']]\n\nresults['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n\nplt.ylabel('Mean test score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's get the predictions\n\nX_train_preds = search.predict(X_train)\nX_test_preds = search.predict(X_test)\n\nsubmission_preds = search.predict(submission)\n\nprint('Train rmse: ', mean_squared_error(y_train, X_train_preds, squared=False))\nprint('Test rmse: ', mean_squared_error(y_test, X_test_preds, squared=False))\nprint()\nprint('Train r2: ', r2_score(y_train, X_train_preds))\nprint('Test r2: ', r2_score(y_test, X_test_preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.exp(submission_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': id_, 'SalePrice': np.exp(submission_preds)})\n\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_lgbm_full.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature selection","metadata":{}},{"cell_type":"code","source":"sel_perf = sel.SelectBySingleFeaturePerformance(\n    estimator=DecisionTreeRegressor(random_state=2, max_depth=2),\n    scoring='r2',\n    cv=3,\n    threshold=0.01,\n    variables=None,\n)\n\nsel_perf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in the attribute feature_performance_ the class stores the performance\n# of each feature\n\npd.Series(sel_perf.feature_performance_).sort_values().plot.bar(figsize=(15,5))\nplt.ylabel('r2')\n\n# the red line is the threshold we selected.\nplt.axhline(y = pd.Series(sel_perf.feature_performance_).mean(),\n            color = 'g', linestyle = '-')\n\n# the red line is the threshold we selected.\nplt.axhline(y = pd.Series(sel_perf.threshold).mean(),\n            color = 'r', linestyle = '-') \n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of features to drop\n\nprint('total features: ', X_train.shape[1])\nprint('features to drop: ', len(sel_perf.features_to_drop_))\nprint('remaining features: ', X_train.shape[1] - len(sel_perf.features_to_drop_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's try  different selection method\n\nrfm = RandomForestRegressor(\n    n_estimators=100,\n    random_state=0,\n    max_depth=2,\n    )\n\nrfe = sel.RecursiveFeatureElimination(\n    estimator = rfm,\n    scoring ='neg_root_mean_squared_error',\n    cv=3,\n    threshold=0.001,\n    variables=None,\n)\n\nrfe.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performance of the gbm built using all features\n\nrfe.initial_model_performance_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in the attribute performance_drifts_ the class stores the performance\n# of each feature the drop in performance when the feature was removed\n\npd.Series(rfe.performance_drifts_).sort_values().plot.bar(figsize=(15,5))\nplt.ylabel('neg rmse')\n\n# the red line is the threshold we selected.\nplt.axhline(y = pd.Series(rfe.performance_drifts_).mean(),\n            color = 'g', linestyle = '-')\n\nplt.axhline(y = rfe.threshold,\n            color = 'r', linestyle = '-') \n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in the attribute feature_importances_ the class stores the importance\n# of each feature, derived from the gbm\n\npd.Series(rfe.feature_importances_).sort_values().plot.bar(figsize=(15,5))\nplt.ylabel('neg rmse')\n\n# the red line is the threshold we selected.\nplt.axhline(y = pd.Series(rfe.feature_importances_).mean(),\n            color = 'r', linestyle = '-') \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of features to drop\n\nprint('total features: ', X_train.shape[1])\nprint('features to drop: ', len(rfe.features_to_drop_))\nprint('remaining features: ', X_train.shape[1] - len(rfe.features_to_drop_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = sel_perf.transform(X_train) \nX_test = sel_perf.transform(X_test) \nsubmission = sel_perf.transform(submission) \n\nX_train.shape, X_test.shape, submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model with cross-validation, searching for best parameters\n\nIn the rest of the notebook, I will perform a Random Search with cross-validation for the best parameters of a GradientBoostingClassifier.","metadata":{}},{"cell_type":"code","source":"gbm = GradientBoostingRegressor(\n    loss='ls',\n    n_estimators=100,\n    criterion='friedman_mse',\n    min_samples_split=2,\n    max_depth=3,\n    random_state=0,\n    n_iter_no_change=2,\n    tol=0.0001,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = dict(\n    loss=['ls', 'huber'],\n    n_estimators=[10, 20, 50, 100, 200, 500, 1000, 2000],\n    min_samples_split=[0.1, 0.3, 0.5],\n    max_depth=[1,2,3,4,None],\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search = nested_cross_val(gbm, param_grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reg = GridSearchCV(gbm, param_grid, scoring='neg_mean_squared_error')\n\n# search = reg.fit(X_train, y_train)\n\n# search.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(search.cv_results_)\n\nresults.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n\nresults.reset_index(drop=True, inplace=True)\n\nresults[['params','mean_test_score', 'std_test_score']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results['params'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n\nplt.ylabel('Mean test score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's get the predictions\n\nX_train_preds = search.predict(X_train)\nX_test_preds = search.predict(X_test)\n\nsubmission_preds = search.predict(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train rmse: ', mean_squared_error(y_train, X_train_preds, squared=False))\nprint('Test rmse: ', mean_squared_error(y_test, X_test_preds, squared=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train r2: ', r2_score(y_train, X_train_preds))\nprint('Test r2: ', r2_score(y_test, X_test_preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.exp(submission_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': id_, 'SalePrice': np.exp(submission_preds)})\n\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_gbm_small.csv', index=False)","metadata":{"papermill":{"duration":0.043089,"end_time":"2021-01-05T18:54:28.472585","exception":false,"start_time":"2021-01-05T18:54:28.429496","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Light GBM","metadata":{"papermill":{"duration":0.023339,"end_time":"2021-01-05T18:54:28.519267","exception":false,"start_time":"2021-01-05T18:54:28.495928","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"# Light GBM\n\nlgbm_param = {\n    \"num_leaves\": [6, 8, 20, 30],\n    \"max_depth\": [2, 4, 6, 8, 10],\n    \"n_estimators\": [50, 100, 200, 500],\n    'colsample_bytree': [0.3, 1.0],\n}\n\nlgbm = LGBMRegressor(\n    learning_rate = 0.1, \n    min_child_weight = 0.4,\n    objective='regression', \n    random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search = nested_cross_val(lgbm, lgbm_param)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reg = GridSearchCV(lgbm, lgbm_param, scoring='neg_mean_squared_error')\n\n# search = reg.fit(X_train, y_train)\n\n# search.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n\nresults.reset_index(drop=True, inplace=True)\n\nresults['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n\nplt.ylabel('Mean test score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's get the predictions\nX_train_preds = search.predict(X_train)\nX_test_preds = search.predict(X_test)\n\nsubmission_preds = search.predict(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train rmse: ', mean_squared_error(y_train, X_train_preds,squared=False))\nprint('Test rmse: ', mean_squared_error(y_test, X_test_preds,squared=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train r2: ', r2_score(y_train, X_train_preds))\nprint('Test r2: ', r2_score(y_test, X_test_preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.exp(submission_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': id_, 'SalePrice': np.exp(submission_preds)})\n\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_lgbm_small.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}