{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  <font color='red'> House Prices : Data cleaning, visualization and modeling  </font>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nimport sklearn.metrics as metrics\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='red'>  Importing **train** and **test** datasets </font>","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\ntest = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\ntrain = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\n#Creating a copy of the train and test datasets\nc_test  = test.copy()\nc_train  = train.copy()\n","metadata":{"_cell_guid":"","_uuid":"","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'>  **Getting information about train dataset** </font>","metadata":{}},{"cell_type":"code","source":"c_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'>  **Getting information about test dataset** </font>\n","metadata":{}},{"cell_type":"code","source":"c_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <font color='black'> 1. **We have 81 columns.**\n2. **Our target variable is SalePrice.**\n3. **Id is just an index that we can drop but we will need it in the final submission.**\n1. **We have many missing values** </font>\n\n\n <font color='red'>   *** * * * we have 79 features in our dataset.** </font>\n\n","metadata":{}},{"cell_type":"markdown","source":"\n* <font color='black'>  **Concat Train and Test datasets** </font>\n","metadata":{}},{"cell_type":"code","source":"c_train['train']  = 1\nc_test['train']  = 0\ndf = pd.concat([c_train, c_test], axis=0,sort=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  <font color='red'> Data preprocessing </font>","metadata":{}},{"cell_type":"markdown","source":"\n* <font color='black'>  **Calculating the percentage of missing values of each feature** </font>\n","metadata":{}},{"cell_type":"code","source":"#Percentage of NAN Values \nNAN = [(c, df[c].isna().mean()*100) for c in df]\nNAN = pd.DataFrame(NAN, columns=[\"column_name\", \"percentage\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'>  **Features with more than 50% of missing values.** </font>","metadata":{}},{"cell_type":"code","source":"NAN = NAN[NAN.percentage > 50]\nNAN.sort_values(\"percentage\", ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'>  **We can drop PoolQC, MiscFeature, Alley and Fence features because they have more than 80% of missing values.** <font>","metadata":{}},{"cell_type":"code","source":"#Drop PoolQC, MiscFeature, Alley and Fence features\ndf = df.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'>  **Now we will select numerical and categorical features**  <font>","metadata":{}},{"cell_type":"code","source":"object_columns_df = df.select_dtypes(include=['object'])\nnumerical_columns_df =df.select_dtypes(exclude=['object'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'>  **Categorical Features** :  <font>","metadata":{}},{"cell_type":"code","source":"object_columns_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'>  **Numerical Features** :  <font>","metadata":{}},{"cell_type":"code","source":"numerical_columns_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'>  Deeling with **categorical** feature  <font>","metadata":{}},{"cell_type":"code","source":"#Number of null values in each feature\nnull_counts = object_columns_df.isnull().sum()\nprint(\"Number of null values in each column:\\n{}\".format(null_counts))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'>   We will fill -- **BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, GarageType, GarageFinish, GarageQual, FireplaceQu, GarageCond** -- with \"None\" (Take a look in the data description). </font>\n* <font color='black'>    We will fill the rest of features with th most frequent value (using its own most frequent value). </font>","metadata":{}},{"cell_type":"code","source":"columns_None = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageFinish','GarageQual','FireplaceQu','GarageCond']\nobject_columns_df[columns_None]= object_columns_df[columns_None].fillna('None')","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_with_lowNA = ['MSZoning','Utilities','Exterior1st','Exterior2nd','MasVnrType','Electrical','KitchenQual','Functional','SaleType']\n#fill missing values for each column (using its own most frequent value)\nobject_columns_df[columns_with_lowNA] = object_columns_df[columns_with_lowNA].fillna(object_columns_df.mode().iloc[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'>  ** Now we have a clean categorical features** </font>\n* <font color='black'>   In the next step we will deal with the **numerical** features </font>black","metadata":{}},{"cell_type":"code","source":"#Number of null values in each feature\nnull_counts = numerical_columns_df.isnull().sum()\nprint(\"Number of null values in each column:\\n{}\".format(null_counts))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. <font color='black'>  **Fill GarageYrBlt and LotFrontage** </font>\n1. <font color='black'>  **Fill the rest of columns with 0** </font>","metadata":{}},{"cell_type":"code","source":"print((numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt']).median())\nprint(numerical_columns_df[\"LotFrontage\"].median())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <font color='black'>  **So we will fill the year with 1979 and the Lot frontage with 68** </font>\n","metadata":{}},{"cell_type":"code","source":"numerical_columns_df['GarageYrBlt'] = numerical_columns_df['GarageYrBlt'].fillna(numerical_columns_df['YrSold']-35)\nnumerical_columns_df['LotFrontage'] = numerical_columns_df['LotFrontage'].fillna(68)\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <font color='black'> **Fill the rest of columns with 0**  <font>\n","metadata":{}},{"cell_type":"code","source":"numerical_columns_df= numerical_columns_df.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'>  **We finally end up with a clean dataset**  <font>","metadata":{}},{"cell_type":"markdown","source":"\n* <font color='black'> **After making some plots we found that we have some colums with low variance so we decide to delete them**  <font>\n","metadata":{}},{"cell_type":"code","source":"object_columns_df['Utilities'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Utilities'].value_counts() \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columns_df['Street'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Street'].value_counts() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columns_df['Condition2'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Condition2'].value_counts() \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columns_df['RoofMatl'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['RoofMatl'].value_counts() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columns_df['Heating'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Heating'].value_counts() #======> Drop feature one Type\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columns_df = object_columns_df.drop(['Heating','RoofMatl','Condition2','Street','Utilities'],axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <font color='black'> **Now we will create some new features**  <font>","metadata":{}},{"cell_type":"code","source":"numerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Negatif = numerical_columns_df[numerical_columns_df['Age_House'] < 0]\nNegatif\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'> **Like we see here tha the minimun is -1 ???** <font>\n* <font color='black'>**It is strange to find that the house was sold in 2007 before the YearRemodAdd 2009.**\n\n    **So we decide to change the year of sold to 2009** <font>","metadata":{}},{"cell_type":"code","source":"numerical_columns_df.loc[numerical_columns_df['YrSold'] < numerical_columns_df['YearBuilt'],'YrSold' ] = 2009\nnumerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <font color='black'> \n*** TotalBsmtBath : Sum of :\nBsmtFullBath and  1/2 BsmtHalfBath**\n\n*** TotalBath : Sum of :\nFullBath and 1/2 HalfBath**\n\n*** TotalSA : Sum of : \n1stFlrSF and 2ndFlrSF and basement area**\n</font>\n\n\n\n","metadata":{}},{"cell_type":"code","source":"numerical_columns_df['TotalBsmtBath'] = numerical_columns_df['BsmtFullBath'] + numerical_columns_df['BsmtFullBath']*0.5\nnumerical_columns_df['TotalBath'] = numerical_columns_df['FullBath'] + numerical_columns_df['HalfBath']*0.5 \nnumerical_columns_df['TotalSA']=numerical_columns_df['TotalBsmtSF'] + numerical_columns_df['1stFlrSF'] + numerical_columns_df['2ndFlrSF']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_columns_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'> **Now the next step is to encode categorical features**  <font>\n","metadata":{}},{"cell_type":"markdown","source":"\n* <font color='black'>  **Ordinal categories features** - Mapping from 0 to N  <font>","metadata":{}},{"cell_type":"code","source":"bin_map  = {'TA':2,'Gd':3, 'Fa':1,'Ex':4,'Po':1,'None':0,'Y':1,'N':0,'Reg':3,'IR1':2,'IR2':1,'IR3':0,\"None\" : 0,\n            \"No\" : 2, \"Mn\" : 2, \"Av\": 3,\"Gd\" : 4,\"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3,\"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6\n            }\nobject_columns_df['ExterQual'] = object_columns_df['ExterQual'].map(bin_map)\nobject_columns_df['ExterCond'] = object_columns_df['ExterCond'].map(bin_map)\nobject_columns_df['BsmtCond'] = object_columns_df['BsmtCond'].map(bin_map)\nobject_columns_df['BsmtQual'] = object_columns_df['BsmtQual'].map(bin_map)\nobject_columns_df['HeatingQC'] = object_columns_df['HeatingQC'].map(bin_map)\nobject_columns_df['KitchenQual'] = object_columns_df['KitchenQual'].map(bin_map)\nobject_columns_df['FireplaceQu'] = object_columns_df['FireplaceQu'].map(bin_map)\nobject_columns_df['GarageQual'] = object_columns_df['GarageQual'].map(bin_map)\nobject_columns_df['GarageCond'] = object_columns_df['GarageCond'].map(bin_map)\nobject_columns_df['CentralAir'] = object_columns_df['CentralAir'].map(bin_map)\nobject_columns_df['LotShape'] = object_columns_df['LotShape'].map(bin_map)\nobject_columns_df['BsmtExposure'] = object_columns_df['BsmtExposure'].map(bin_map)\nobject_columns_df['BsmtFinType1'] = object_columns_df['BsmtFinType1'].map(bin_map)\nobject_columns_df['BsmtFinType2'] = object_columns_df['BsmtFinType2'].map(bin_map)\n\nPavedDrive =   {\"N\" : 0, \"P\" : 1, \"Y\" : 2}\nobject_columns_df['PavedDrive'] = object_columns_df['PavedDrive'].map(PavedDrive)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'>  **Will we use One hot encoder to encode the rest of categorical features**  <font>","metadata":{}},{"cell_type":"code","source":"#Select categorical features\nrest_object_columns = object_columns_df.select_dtypes(include=['object'])\n#Using One hot encoder\nobject_columns_df = pd.get_dummies(object_columns_df, columns=rest_object_columns.columns) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_columns_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'>  **Concat Categorical (after encoding) and numerical features**  <font>\n","metadata":{}},{"cell_type":"code","source":"df_final = pd.concat([object_columns_df, numerical_columns_df], axis=1,sort=False)\ndf_final.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop(['Id',],axis=1)\n\ndf_train = df_final[df_final['train'] == 1]\ndf_train = df_train.drop(['train',],axis=1)\n\n\ndf_test = df_final[df_final['train'] == 0]\ndf_test = df_test.drop(['SalePrice'],axis=1)\ndf_test = df_test.drop(['train',],axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'>  **Separate Train and Targets**  <font>","metadata":{}},{"cell_type":"code","source":"target= df_train['SalePrice']\ndf_train = df_train.drop(['SalePrice'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  <font color='red'> Modeling  </font>","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(df_train,target,test_size=0.33,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nxgb =XGBRegressor( booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=4, min_child_weight=1.5, n_estimators=2400,\n             n_jobs=1, nthread=None, objective='reg:linear',\n             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n             silent=None, subsample=0.8, verbosity=1)\n\n\nlgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=12000, \n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.4, \n                                       )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting\nxgb.fit(x_train, y_train)\nlgbm.fit(x_train, y_train,eval_metric='rmse')\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict1 = xgb.predict(x_test)\npredict = lgbm.predict(x_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict1))))\nprint('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict))))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* <font color='black'> **Fitting With all the dataset** <font>","metadata":{}},{"cell_type":"code","source":"xgb.fit(df_train, target)\nlgbm.fit(df_train, target,eval_metric='rmse')\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict4 = lgbm.predict(df_test)\npredict3 = xgb.predict(df_test)\npredict_y = ( predict3*0.45 + predict4 * 0.55)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n        \"Id\": test[\"Id\"],\n        \"SalePrice\": predict_y\n    })\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}