{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Welcome to my kernel, I hope you'll find it useful as a brief tutorial. It has two steps: data preprocessing, where I modify the datasets to achieve the best performance of the model, and building the model itself. ","metadata":{}},{"cell_type":"markdown","source":"![Photo from Pixabay](https://cdn.pixabay.com/photo/2016/01/19/17/08/vintage-1149558_1280.jpg)","metadata":{}},{"cell_type":"markdown","source":"# 1-Data preprocessing üõ†","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nrouteTrain='../input/house-prices-advanced-regression-techniques/train.csv'\nrouteTest='../input/house-prices-advanced-regression-techniques/test.csv'\n\n\ndatasetTrain=pd.read_csv(routeTrain)\ndatasetTest=pd.read_csv(routeTest)  \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasetTrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasetTest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Drop the columns with a lot of NaN values **in both datasets**. These colums are MiscFeature, PoolQC, Fence, FireplaceQu,Alley.","metadata":{}},{"cell_type":"code","source":"datasetTrain=datasetTrain.drop(['MiscFeature','PoolQC','Fence','FireplaceQu','Alley'],axis=1)\ndatasetTest=datasetTest.drop(['MiscFeature','PoolQC','Fence','FireplaceQu','Alley'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Build a heatmap to check which variables are more correlated to SalePrice, the variable that you want to predict. The heatmap will show only the numerical variables. To study the correlation between the target variable and a categorical variable, you can do the ANOVA test. ","metadata":{}},{"cell_type":"code","source":"corr=datasetTrain.corr()\nplt.figure(figsize = (40,40))\nsns.heatmap(corr,annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cor_target = abs(corr[\"SalePrice\"])#Selecting highly correlated features\nimportant_numerical_features = cor_target[cor_target>0.5]\nimportant_numerical_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numerical variables that are correlated to SalePrice (correlation >=0.5) are:\n\n* OverallQual: positive correlation, which means that SalePrice is bigger when the OverallQual is bigger.\n* YearBuilt: positive correlation.\n* YearRemodAdd: positive correlation.\n* TotalBsmtSF: positive correlation.\n* 1stFlrSF: positive correlation.\n* GrLivArea: positive correlation.\n* FullBath: positive correlation.\n* TotRmsAbvGrd: positive correlation.\n* GarageCars: positive correlation.\n* GarageArea: positive correlation.\n","metadata":{}},{"cell_type":"code","source":"#if you want to check the correlation between categorical variables and target variable\n#Example-MSZoning\nfrom scipy import stats\nF, p = stats.f_oneway(datasetTrain[datasetTrain.MSZoning=='RL'].SalePrice,datasetTrain[datasetTrain.MSZoning=='RM'].SalePrice,datasetTrain[datasetTrain.MSZoning=='C (all)'].SalePrice,\n                     datasetTrain[datasetTrain.MSZoning=='FV'].SalePrice,datasetTrain[datasetTrain.MSZoning=='RH'].SalePrice)\nprint(F)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next step is to check if any of the numerical variables are right or left skewed. You can do this with the function skew(). In a normal distribution, the value of skewness is zero. When a distribution is asymmetrical the tail of the distribution is skewed to one side-to the right (value of the skewness is positive) or to the left (skewness is negative). To fix skewed variables, use log transformation.","metadata":{}},{"cell_type":"code","source":"numerical_columns=['OverallQual','YearBuilt','YearRemodAdd','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','GarageCars','GarageArea','SalePrice']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasetTrain[numerical_columns].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(datasetTrain, x=\"GrLivArea\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can clearly see that GrLivArea is right skewed. ","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(datasetTrain, x=\"TotalBsmtSF\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(datasetTrain, x=\"GarageArea\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, with the variables TotalBsmtSF and GarageArea there is a problem: when the house has not basement or garage, the value for these column in that specific row is 0. So if you apply log transformation to these two, you'll get a weird result. \n\nThe solution I came up with was to throw away these rows.","metadata":{}},{"cell_type":"code","source":"housesWithNoBasement=datasetTrain[datasetTrain.TotalBsmtSF==0]\nhousesWithNoBasement.shape #rows,columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housesWithNoGarage=datasetTrain[datasetTrain.GarageArea==0]\nhousesWithNoGarage.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There were 1460 not null values in TotalBsmtSF and GarageArea columns so it's not big deal deleting 81 and 37 rows.","metadata":{}},{"cell_type":"code","source":"datasetTrain=datasetTrain[datasetTrain.TotalBsmtSF>0]\ndatasetTrain=datasetTrain[datasetTrain.GarageArea>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's select now the columns that had a significant correlation with the target variable, and SalePrice itself, and let's apply log transformation to them. ","metadata":{}},{"cell_type":"code","source":"finalDatasetTrain=datasetTrain[numerical_columns]\nfinalDatasetTrain=np.log1p(finalDatasetTrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalDatasetTrain.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalDatasetTrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's prepare the test dataset.","metadata":{}},{"cell_type":"code","source":"nun_columns=['OverallQual','YearBuilt','YearRemodAdd','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','GarageCars','GarageArea']\nfinalTestDataset=datasetTest[nun_columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalTestDataset.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalTestDataset.GarageArea.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalTestDataset.GarageCars.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalTestDataset.update(finalTestDataset['GarageCars'].fillna(value=finalTestDataset['GarageCars'].mean(), inplace=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalTestDataset.update(finalTestDataset['GarageArea'].fillna(value=finalTestDataset['GarageArea'].mean(), inplace=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalTestDataset.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalTestDataset=np.log1p(finalTestDataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2-Building the model üèõ","metadata":{}},{"cell_type":"code","source":"#build a basic model for the tutorial\nimport xgboost as xgb\nmodel=xgb.XGBRegressor(max_depth=3,eta=0.05,min_child_weight=4)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=finalDatasetTrain.drop('SalePrice',axis=1)\ny=finalDatasetTrain['SalePrice']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(features,y)\npredictions=model.predict(finalTestDataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalPred=np.expm1(predictions)#you need to reverse log transformation\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission=pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')\nsubmission = pd.DataFrame({'Id':sample_submission['Id'],'SalePrice':finalPred})\nsubmission\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'Submission.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}