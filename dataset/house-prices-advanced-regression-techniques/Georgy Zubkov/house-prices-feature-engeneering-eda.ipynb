{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import of necessary libraries and data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport scipy.stats as st\nfrom sklearn import ensemble, tree, linear_model\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, ElasticNet\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_house=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\nTest_house=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_house.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_house.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"House=pd.concat([Train_house.drop(['SalePrice'],axis=1),Test_house]).set_index('Id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=Train_house.SalePrice","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's do a mini-EDA","metadata":{}},{"cell_type":"code","source":"numeric_features = Train_house.select_dtypes(include=[np.number])\nnumeric_features.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"year_feature = [feature for feature in numeric_features if 'Yr' in feature or 'Year' in feature]\nyear_feature","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in year_feature:\n    if feature!='YrSold':\n        data=Train_house.copy()\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the relationship between numeric variables and the target variable","metadata":{}},{"cell_type":"code","source":"numeric_features = Train_house.select_dtypes(include=[np.number])\nnumeric_features.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discrete_feature=[feature for feature in numeric_features if len(Train_house[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in discrete_feature:\n    data=Train_house.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('Target')\n    plt.title(feature)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"continuous_feature=[feature for feature in numeric_features if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous Feature Count {}\".format(len(continuous_feature)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in continuous_feature:\n    data=Train_house.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Estimate the distribution of the target variable","metadata":{}},{"cell_type":"code","source":"y = Train_house['SalePrice']\nplt.figure(1); plt.title('Johnson SU')\nsns.distplot(y, kde=False, fit=st.johnsonsu)\nplt.figure(2); plt.title('Normal')\nsns.distplot(y, kde=False, fit=st.norm)\nplt.figure(3); plt.title('Log Normal')\nsns.distplot(y, kde=False, fit=st.lognorm)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = np.log(Train_house['SalePrice'])\ntarget.skew()\nplt.hist(target,color='blue')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's build a heat map of correlations between numerical variables in the training dataset","metadata":{}},{"cell_type":"code","source":"correlation = Train_house.corr()\nprint(correlation['SalePrice'].sort_values(ascending = False),'\\n')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k= 11\ncols = correlation.nlargest(k,'SalePrice')['SalePrice'].index\nprint(cols)\ncm = np.corrcoef(Train_house[cols].values.T)\nf , ax = plt.subplots(figsize = (14,12))\nsns.heatmap(cm, vmax=.8, linewidths=0.01,square=True,annot=True,cmap='viridis',\n            linecolor=\"white\",xticklabels = cols.values ,annot_kws = {'size':12},yticklabels = cols.values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us estimate the pairwise correlation of numerical variables","metadata":{}},{"cell_type":"code","source":"sns.set()\ncolumns = ['SalePrice','OverallQual','TotalBsmtSF','GrLivArea','GarageArea','FullBath','YearBuilt','YearRemodAdd']\nsns.pairplot(Train_house[columns],size = 2 ,kind ='scatter',diag_kind='kde')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Execute Future Engineering","metadata":{}},{"cell_type":"markdown","source":"Divide the total data into categorical and numerical variables to fill in information gaps","metadata":{}},{"cell_type":"code","source":"numeric_features = House.select_dtypes(include=[np.number])\nnumeric_features.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = House.select_dtypes(include=[np.object])\ncategorical_features.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's start with simple categorical variables. It is necessary to estimate the number of missing information, as well as the number of unique values in each variable.","metadata":{}},{"cell_type":"code","source":"cat_features_with_na=[features for features in categorical_features.columns if categorical_features[features].isnull().sum()>0]\nfor feature in cat_features_with_na:\n    print(feature, np.round(100*categorical_features[feature].isnull().sum()/2919, 4),  ' % of Missing Values')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's estimate the number of unique values in each variable of categorical features","metadata":{}},{"cell_type":"code","source":"for column_name in categorical_features.columns:\n    unique_category = len(categorical_features[column_name].unique())\n    print(\"Feature '{column_name}' has '{unique_category}' unique categories\".format(column_name = column_name,\n                                                                                         unique_category=unique_category))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove 'MiscFeature','Fence','PoolQC','Alley','FireplaceQu' from categorical variables.","metadata":{}},{"cell_type":"code","source":"categorical_features=categorical_features.drop(['MiscFeature','Fence','PoolQC','Alley','FireplaceQu'],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Because the number of missing values for most of the variables is small, let's fill them with the mode. When filling variables with a mod using a loop, an error occurs. I decided to fill everything in manually.","metadata":{}},{"cell_type":"code","source":"categorical_features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features.MSZoning.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features['MSZoning'].fillna('RL',inplace=True)\ncategorical_features['Utilities'].fillna('AllPub',inplace=True)\ncategorical_features['MasVnrType'].fillna('None',inplace=True)\ncategorical_features['BsmtQual'].fillna('TA',inplace=True)\ncategorical_features['BsmtCond'].fillna('TA',inplace=True)\ncategorical_features['BsmtExposure'].fillna('No',inplace=True)\ncategorical_features['BsmtFinType1'].fillna('Unf',inplace=True)\ncategorical_features['BsmtFinType2'].fillna('Unf',inplace=True)\ncategorical_features['Functional'].fillna('Typ',inplace=True)\ncategorical_features['GarageType'].fillna('Attchd',inplace=True)\ncategorical_features['GarageFinish'].fillna('Unf',inplace=True)\ncategorical_features['GarageQual'].fillna('TA',inplace=True)\ncategorical_features['GarageCond'].fillna('TA',inplace=True)\ncategorical_features['Exterior1st'].fillna('VinylSd',inplace=True)\ncategorical_features['Exterior2nd'].fillna('VinylSd',inplace=True)\ncategorical_features['Electrical'].fillna('SBrkr',inplace=True)\ncategorical_features['KitchenQual'].fillna('TA',inplace=True)\ncategorical_features['SaleType'].fillna('WD',inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's estimate the gaps in information and the number of unique values in numeric variables. Because we have categorical variables and in numerical ones, then we will fill in the gaps of information in a different way.","metadata":{}},{"cell_type":"code","source":"num_features_with_na=[features for features in numeric_features.columns if numeric_features[features].isnull().sum()>0]\nfor feature in num_features_with_na:\n    print(feature, np.round(100*numeric_features[feature].isnull().sum()/2919, 4),  ' % of Missing Values')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column_name in numeric_features.columns:\n    unique_values = len(numeric_features[column_name].unique())\n    print(\"Feature '{column_name}' has '{unique_values}' unique values\".format(column_name = column_name,\n                                                                                         unique_values=unique_values))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variables 'BsmtFullBath' and 'BsmtHalfBath', 'GarageCars' mod, rest medium","metadata":{}},{"cell_type":"code","source":"numeric_features['LotFrontage'].fillna(69.30579531442663,inplace=True)\nnumeric_features['MasVnrArea'].fillna(102.20131215469613,inplace=True)\nnumeric_features['GarageYrBlt'].fillna(1978,inplace=True)\nnumeric_features['BsmtFullBath'].fillna(0,inplace=True)\nnumeric_features['BsmtHalfBath'].fillna(0,inplace=True)\nnumeric_features['GarageCars'].fillna(2,inplace=True)\nnumeric_features['BsmtFinSF1'].fillna(441.4232350925291,inplace=True)\nnumeric_features['BsmtFinSF2'].fillna(49.58224811514736,inplace=True)\nnumeric_features['BsmtUnfSF'].fillna(560.7721041809458,inplace=True)\nnumeric_features['TotalBsmtSF'].fillna(1051.7775873886224,inplace=True)\nnumeric_features['GarageArea'].fillna(0,inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We observe a strong cross-correlation between some variables, remove duplicates from the data","metadata":{}},{"cell_type":"code","source":"numeric_features=numeric_features.drop(['GarageArea','1stFlrSF'],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Merge Tables and Encode Categorical Variables One Hot Encoding","metadata":{}},{"cell_type":"code","source":"House_data=numeric_features.merge(categorical_features,on='Id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features=['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n       'PavedDrive', 'SaleType', 'SaleCondition']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name in cat_features:\n    Dummies=pd.get_dummies(House_data[name]).add_prefix(name)\n    House_data=House_data.merge(Dummies,on='Id')\n    House_data=House_data.drop([name],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train=House_data[:1460]\nValid=House_data[1460:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tr=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\").set_index('Id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(Train,\n                                                    Tr.SalePrice,\n                                                    test_size=0.33,\n                                                    random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Search for the best model and predict the target variable","metadata":{}},{"cell_type":"markdown","source":"Let's build model pipelines","metadata":{}},{"cell_type":"code","source":"models = [RandomForestRegressor(), LinearRegression(),ElasticNet(), KNeighborsRegressor(),xgb.XGBRegressor()]\nscores = dict()\n\nfor m in models:\n    m.fit(X_train, y_train)\n    y_pred = m.predict(X_test)\n\n    print(f'model: {str(m)}')\n    print(f'RMSE: {round(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred))), 3)}')\n    print(f'MAE: {round(mean_absolute_error(y_test, y_pred), 3)}')\n    print('-'*30, '\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's start improving the XGBRegressor and RandomForestRegressor hyperparameters. Then we average the values of the final forecast","metadata":{}},{"cell_type":"code","source":"clf = xgb.XGBRegressor()\nparametres={'base_score':[0.1],\n            'learning_rate':[0.1],\n           'max_depth':[5,6,7],\n           'n_estimators':[100,90,110]}\ngrid_search_cv_clf=GridSearchCV(clf,parametres,cv=5)\ngrid_search_cv_clf.fit(X_train,y_train)\nbest_clf1=grid_search_cv_clf.best_estimator_\ny_pred1=best_clf1.predict(X_test)\nprint(f'RMSE: {round(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred))), 3)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf1 = RandomForestRegressor()\nparametres={'max_depth':[1,2,4,8],\n           'min_samples_split':[2,4,8],\n           'n_estimators':[10,20,40,80],\n           'n_jobs':[-1]}\ngrid_search_cv_clf=GridSearchCV(clf1,parametres,cv=5)\ngrid_search_cv_clf.fit(X_train,y_train)\nbest_clf2=grid_search_cv_clf.best_estimator_\ny_pred2=best_clf2.predict(X_test)\nprint(f'RMSE: {round(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred))), 3)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted_prob1=best_clf1.predict(Valid)\ny_predicted_prob2=best_clf2.predict(Valid)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summ=(y_predicted_prob1+y_predicted_prob2)/2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tit=pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions = pd.concat([Tit.Id,pd.Series(summ)],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions=submissions.rename(columns={0:'SalePrice'})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions.to_csv('submissionhouse.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]}]}