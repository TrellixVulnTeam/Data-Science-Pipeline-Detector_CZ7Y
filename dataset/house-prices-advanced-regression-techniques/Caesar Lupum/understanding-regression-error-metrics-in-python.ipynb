{"cells":[{"metadata":{},"cell_type":"markdown","source":"Style of the data"},{"metadata":{"trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"%%HTML\n<style type=\"text/css\">\ndiv.h1 { background-color:#b300b3;\n        color: white; padding: 8px; padding-right: 300px;font-size: 35px; max-width: 1500px; margin: auto; margin-top: 50px; }\ndiv.h2 {background-color:#b300b3;\n        color: white; padding: 8px; padding-right: 300px; font-size: 25px; max-width: 1500px; margin: auto; margin-top: 50px; }\ndiv.h3 { color:#b300b3;\n        font-size: 16px; margin-top: 20px; margin-bottom:4px; }\nhr {display: block; color: gray; height: 1px; border: 0; border-top: 1px solid; }\nhr.light {display: block; color: lightgray; height: 1px; border: 0; border-top: 1px solid; }\n</style>","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Crisl√¢nio Mac√™do](https://medium.com/sapere-aude-tech) -  March, 13th, 2020\n\n<div class=\"h1\">Understanding Regression Error Metrics in Pythonüêç</div>\n\n- [**Github**](https://github.com/crislanio)\n- [**Linkedin**](https://www.linkedin.com/in/crislanio/)\n- [**Medium**](https://medium.com/sapere-aude-tech)\n- [**Quora**](https://www.quora.com/profile/Crislanio)\n- [**Hackerrank**](https://www.hackerrank.com/crislanio_ufc?hr_r=1)\n- [**Blog**](https://medium.com/@crislanio.ufc)\n- [**Personal Page**](https://crislanio.wordpress.com/about)\n- [**Twitter**](https://twitter.com/crs_macedo)\n"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"top\"></a>\n<a id='dsf4'></a>\n# <div class=\"h2\">  Table of contents</div>\n1. [Imports](#IMPORT)\n2. [Regression metrics summary ](#M)\n   -  <a href='#m1'>MAE</a>\n   -  <a href='#m2'>MSE</a>\n   -  <a href='#m3'>RMSE</a>\n   -  <a href='#m4'>MAPE</a>\n   -  <a href='#m5'>RMLSE</a>\n   -  <a href='#m6'>R-Square</a>   \n   -  <a href='#m6'>Ajusted R-Square</a>\n   -  <a href='#m7'>Residual Sum of Squares (RSS)</a>\n   \n  <hr>"},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h1\">Imports </div>\n<a id=\"IMPORT\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)\n\nWe are using a stack: ``numpy``, ``pandas``, ``sklearn``, ``matplotlib``."},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom scipy.stats import boxcox_normmax\nfrom scipy.special import boxcox1p\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Read the data\ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"y = train.SalePrice.reset_index(drop=True)\nfeatures = train\nend_features = ['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath','TotRmsAbvGrd','MSSubClass','MSZoning']\nfeatures = features[end_features]\nfeatures['MSSubClass'] = features['MSSubClass'].apply(str)\nfeatures['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\nobjects = [col for col in features.columns if features[col].dtype == \"object\"]\nfeatures.update(features[objects].fillna('None'))\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = [col for col in features.columns if features[col].dtype in numeric_dtypes]\nfeatures.update(features[numerics].fillna(0))\n\nfor i in numerics:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))\nX = pd.get_dummies(features).reset_index(drop=True)\n#----------------- The model\nreg = LinearRegression().fit(X, y)\ny_pred = reg.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"The model"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"reg = LinearRegression().fit(X, y)\ny_pred = reg.predict(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h1\">Regression metrics summary </div>\n<a id=\"M\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)\n\n![](https://miro.medium.com/max/1308/1*lke9jk2uY-ppHO0h0xytQw.png)"},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h3\">MAE: Mean absolute error</div>\n<a id=\"m1\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1189/0*sA9a9MlNiZ1dI7so.jpg)\n\n> MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It‚Äôs the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def MAE(predict,target):\n    return (abs(predict-target)).mean()\n\nfrom sklearn.metrics import mean_absolute_error\nprint ('MAE: ' + str(mean_absolute_error(y,y_pred)) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h3\">MSE: Mean squared error</div>\n<a id=\"m2\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/978/0*7RxO773DPeY8IYeD.png)\nsource: https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/\n\n> MSE is a risk function, corresponding to the expected value of the squared error loss. The fact that MSE is almost always strictly positive (and not zero) is because of randomness or because the estimator does not account for information that could produce a more accurate estimate. The MSE is a measure of the quality of an estimator ‚Äî it is always non-negative, and values closer to zero are better"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nprint ('MSE: ' + str(mean_squared_error(y,y_pred)) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h3\">RMSE: Root mean square error</div>\n<a id=\"m3\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)"},{"metadata":{},"cell_type":"markdown","source":"\n![](https://miro.medium.com/max/650/0*at-j68ROeSmiruDE.png)\nsource: https://www.includehelp.com/ml-ai/root-mean-square%20error-rmse.aspx\n> RMSE is a quadratic scoring rule that also measures the average magnitude of the error. It‚Äôs the square root of the average of squared differences between prediction and actual observation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(predict, target):\n    return np.sqrt(((predict - target) ** 2).mean())\nprint ('RMSE: ' + str(rmsle(y_pred,y)) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h3\">MAPE: Mean absolute percentage error</div>\n<a id=\"m4\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1063/0*N8USfmlDmXq7YuNy.png)\n> Measure of prediction accuracy of a forecasting method in statistics, for example in trend estimation, also used as a loss function for regression problems in machine learning. It usually expresses accuracy as a percentage."},{"metadata":{"trusted":true},"cell_type":"code","source":"def MAPE(predict,target):\n    return ( abs((target - predict) / target).mean()) * 100\nprint ('MAPE: ' + str(MAPE(y_pred,y)) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h3\">R¬≤ and R-Squared: Coefficient of determination</div>\n\n<a id=\"m5\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)\n\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/888/0*-lBX506Imc6Hjqpu)\n\n> R¬≤ and R-Squared help us to know how good our regression model as compared to a very simple model that just predicts the mean value of target from the train set as predictions.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def R2(predict, target):\n    return 1 - (MAE(predict,target) / MAE(target.mean(),target))\ndef R_SQR(predict, target):\n    r2 = R2(predict,target)\n    return np.sqrt(r2)\nprint ('R2         : ' + str(R2(y_pred,y)) )\nprint ('R          : ' + str(R_SQR(y_pred,y)) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h3\">Adjusted R¬≤</div>\n<a id=\"m5\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/955/0*1jxDmwoJF8R4tOVq.png)\nsource: http://www.haghish.com/statistics/stata-blog/stata-programming/adjusted_R_squared.php\n\n> A model performing equal to baseline would give R-Squared as 0. Better the model, higher the r2 value. The best model with all correct predictions would give R-Squared as 1. However, on adding new features to the model, the R-Squared value either increases or remains the same. R-Squared does not penalize for adding features that add no value to the model. So an improved version over the R-Squared is the adjusted R-Squared.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def R2_ADJ(predict, target, k):\n    r2 = R2(predict,target)\n    n = len(target)\n    return (1 -  ( (1-r2) *  ( (n-1) / (n-(k+1)) ) ) )\n\nk= len(features.columns)\nprint ('R2 adjusted: ' + str(R2_ADJ(y_pred,y,k)) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h3\">Residual Sum of Squares (RSS)</div>\n<a id=\"m6\"></a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)"},{"metadata":{},"cell_type":"markdown","source":"The residual sum of squares is the top term in the  R2  metric (albeit adjusted by 1 to account for degrees of freedom). It takes the distance between observed and predicted values (the residuals), squares them, and sums them all together. Ordinary least squares regression is designed to minimize exactly this value.\n\nRSS=‚àë0n‚àí1(yi‚àíy^i)2\n \nRSS is not very interpretable on its own, because it is the sum of many (potentially very large) residuals. For this reason it is rarely used as a metric, but because it is so important to regression, it's often included in statistical fit assays."},{"metadata":{"trusted":true},"cell_type":"code","source":"def rss_score(y, y_pred):\n    return np.sum((y - y_pred)**2)\nrss = rss_score(y, y_pred) \nprint ('Residual Sum of Squares (RSS): ' + str( rss ) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Refer: \n- [Metrics and Python](https://towardsdatascience.com/metrics-and-python-850b60710e0c)\n- [Understanding Regression Error Metrics](https://www.dataquest.io/blog/understanding-regression-error-metrics/)\n- [The Absolute Best Way to Measure Forecast Accuracy](https://www.axsiumgroup.com/the-absolute-best-way-to-measure-forecast-accuracy-2/)\n"},{"metadata":{},"cell_type":"markdown","source":"[Back to Table of Contents](#top)\n\n<a class=\"anchor\" id=\"theend\"></a>\n# Final"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}