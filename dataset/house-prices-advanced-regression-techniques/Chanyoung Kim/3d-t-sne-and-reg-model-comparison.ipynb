{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-19T07:24:33.663972Z","iopub.execute_input":"2022-03-19T07:24:33.664497Z","iopub.status.idle":"2022-03-19T07:24:33.695514Z","shell.execute_reply.started":"2022-03-19T07:24:33.664392Z","shell.execute_reply":"2022-03-19T07:24:33.694671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nHouse Prices - Advanced Regression Techniques\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/5407/media/housesbanner.png\">","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npd_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\npd_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:33.697119Z","iopub.execute_input":"2022-03-19T07:24:33.697377Z","iopub.status.idle":"2022-03-19T07:24:33.768137Z","shell.execute_reply.started":"2022-03-19T07:24:33.697349Z","shell.execute_reply":"2022-03-19T07:24:33.767377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nPreprocessing NaN Data\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"#### Checking NaN data","metadata":{}},{"cell_type":"code","source":"print('training data+++++++++++++++++++++total train length: ',len(pd_train))\nfor i in np.arange(pd_train.shape[1]):\n    n = pd_train.iloc[:,i].isnull().sum() \n    if n > 0:\n        print(list(pd_train.columns.values)[i] + ': ' + str(n) + ' nans')\n\nprint('testing data++++++++++++++++++++++total test length: ',len(pd_test))\nfor i in np.arange(pd_test.shape[1]):\n    n = pd_test.iloc[:,i].isnull().sum() \n    if n > 0:\n        print(list(pd_test.columns.values)[i] + ': ' + str(n) + ' nans')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:33.769879Z","iopub.execute_input":"2022-03-19T07:24:33.770398Z","iopub.status.idle":"2022-03-19T07:24:33.859456Z","shell.execute_reply.started":"2022-03-19T07:24:33.77035Z","shell.execute_reply":"2022-03-19T07:24:33.858608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd_train['SalePrice']\nx_train = pd_train.drop(['Id','SalePrice'], axis=1)\nx_test = pd_test.drop('Id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:33.860617Z","iopub.execute_input":"2022-03-19T07:24:33.86084Z","iopub.status.idle":"2022-03-19T07:24:33.878008Z","shell.execute_reply.started":"2022-03-19T07:24:33.860811Z","shell.execute_reply":"2022-03-19T07:24:33.877235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Fill NaN data with ffill method","metadata":{}},{"cell_type":"code","source":"def fill_nan_values(pd):\n    pd = pd.drop(['Alley','PoolQC','Fence','MiscFeature','LotFrontage','MasVnrArea','GarageYrBlt'], axis=1)\n    pd = pd.fillna(method=\"ffill\")\n    return pd\n    \nx_train = fill_nan_values(x_train)\nx_test = fill_nan_values(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:33.88176Z","iopub.execute_input":"2022-03-19T07:24:33.881973Z","iopub.status.idle":"2022-03-19T07:24:33.917605Z","shell.execute_reply.started":"2022-03-19T07:24:33.881948Z","shell.execute_reply":"2022-03-19T07:24:33.916832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualization of remaining NaN\nSeems like every NaN has gone!","metadata":{}},{"cell_type":"code","source":"import missingno as msno\ndf = pd.concat([x_train, x_test])\nmsno.matrix(df=df, figsize=(20,7), color=(0,0,0))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:33.919401Z","iopub.execute_input":"2022-03-19T07:24:33.919722Z","iopub.status.idle":"2022-03-19T07:24:35.495375Z","shell.execute_reply.started":"2022-03-19T07:24:33.91968Z","shell.execute_reply":"2022-03-19T07:24:35.494464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nCategorical Data Transformation\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"We will use LabelEncoder to transform categorical data into numerical data.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndef encoder(df_train, df_test):\n    En = LabelEncoder()\n    df_train = En.fit_transform(df_train)\n    df_test = En.transform(df_test)\n    return df_train, df_test\n\nfor col in x_train:\n    if x_train[col].dtypes == object:\n        x_train[col],x_test[col] = encoder(x_train[col],x_test[col])","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:35.496736Z","iopub.execute_input":"2022-03-19T07:24:35.496985Z","iopub.status.idle":"2022-03-19T07:24:35.690522Z","shell.execute_reply.started":"2022-03-19T07:24:35.496953Z","shell.execute_reply":"2022-03-19T07:24:35.689731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nPlotting Regplot\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nim = pd.concat([x_train, y_train], axis=1)\nfig, axs = plt.subplots(figsize=(40,35), ncols=8, nrows=9)\ncol = [i for i in x_train ]\nfor i, features in enumerate(col):\n    row = int(i/8)\n    col = i%8\n    sns.regplot(x=features, y='SalePrice', data=im, ax=axs[row][col])","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:24:35.691861Z","iopub.execute_input":"2022-03-19T07:24:35.692255Z","iopub.status.idle":"2022-03-19T07:25:00.658039Z","shell.execute_reply.started":"2022-03-19T07:24:35.692203Z","shell.execute_reply":"2022-03-19T07:25:00.657362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nConsidering Correlations\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"corr = im.corr()\nplt.subplots(figsize=(15,10))\nax = sns.heatmap(corr, cmap=\"BuPu\", vmax=0.7, square=True)\nax.set_title(\"Correlations\", fontsize = 18)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:00.658968Z","iopub.execute_input":"2022-03-19T07:25:00.659221Z","iopub.status.idle":"2022-03-19T07:25:01.728939Z","shell.execute_reply.started":"2022-03-19T07:25:00.659171Z","shell.execute_reply":"2022-03-19T07:25:01.728241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Remove columns whose correlation coefficient is less than or equal to an absolute value of 0.2 ","metadata":{}},{"cell_type":"code","source":"cor = pd.DataFrame(corr.iloc[-1,:]).T\nrm_col = []\nfor col in cor:\n    if abs(cor[col][0])<=0.2:\n        rm_col.append(col)\nprint(rm_col)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:01.729874Z","iopub.execute_input":"2022-03-19T07:25:01.730206Z","iopub.status.idle":"2022-03-19T07:25:01.741581Z","shell.execute_reply.started":"2022-03-19T07:25:01.730166Z","shell.execute_reply":"2022-03-19T07:25:01.740549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.drop(rm_col, axis=1)\nx_test = x_test.drop(rm_col, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:01.743063Z","iopub.execute_input":"2022-03-19T07:25:01.743629Z","iopub.status.idle":"2022-03-19T07:25:01.756924Z","shell.execute_reply.started":"2022-03-19T07:25:01.743582Z","shell.execute_reply":"2022-03-19T07:25:01.756304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nVisualizing t-SNE\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"#### t-distributed stochastic neighbor embedding (t-SNE) is a statistical method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://gaussian37.github.io/assets/img/ml/concept/t-sne/0.png\">","metadata":{}},{"cell_type":"markdown","source":"#### t-SNE is effective for representing the distribution of class-divided data like MNIST as shown in the figure above, but it can be used sufficiently for regression problems like this dataset.  \n#### In this notebook, we are going to plot in 3D for more visualization effects, using Plotly.","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata = np.array(x_train)\n\nn_components = 3\nmodel = TSNE(n_components=n_components)\ntransformed = model.fit_transform(data.data)\n\nfig = px.scatter_3d(\n    transformed, x=0, y=1, z=2,\n    color=y_train\n)\nfig.update_traces(marker_size=3)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:01.758148Z","iopub.execute_input":"2022-03-19T07:25:01.758775Z","iopub.status.idle":"2022-03-19T07:25:19.431694Z","shell.execute_reply.started":"2022-03-19T07:25:01.758727Z","shell.execute_reply":"2022-03-19T07:25:19.431061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nData Normalization and Data Split\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"code","source":"x_train = np.log1p(x_train)\nx_test = np.log1p(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:19.432655Z","iopub.execute_input":"2022-03-19T07:25:19.433222Z","iopub.status.idle":"2022-03-19T07:25:19.43956Z","shell.execute_reply.started":"2022-03-19T07:25:19.433191Z","shell.execute_reply":"2022-03-19T07:25:19.43848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:19.442527Z","iopub.execute_input":"2022-03-19T07:25:19.44279Z","iopub.status.idle":"2022-03-19T07:25:19.45234Z","shell.execute_reply.started":"2022-03-19T07:25:19.442759Z","shell.execute_reply":"2022-03-19T07:25:19.45156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:blue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nTraining Three Models with GridSearchCV\n</h1>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"#### We are going to compare three diffenent models XGBRegressor, Lasso Regression, ElasticNet using GridSearchCV","metadata":{}},{"cell_type":"code","source":"import xgboost\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Lasso, ElasticNet\n\ndef train(method, x_train, y_train):\n    \n    xgb_reg = xgboost.XGBRegressor()\n    lasso_reg = Lasso()\n    elastic_reg = ElasticNet()\n    \n    model = [xgb_reg, lasso_reg, elastic_reg]\n    \n    if method == 'XGBRegressor':\n        reg = model[0]\n        param_grid = [{'booster':['gbtree', 'dart'], 'max_depth':[1,2,5,10,20,50,100]}]\n        \n    elif method == 'Lasso':\n        reg = model[1]\n        param_grid = [{'alpha':[0.01,0.1,1.0,2.0], 'max_iter':[1,10,50,100,500]}]\n    \n    elif method == 'ElasticNet':\n        reg = model[2]\n        param_grid = [{'alpha':[0.01,0.1,1.0,2.0], 'max_iter':[1,10,50,100,500], 'l1_ratio':[0.01,0.1,1.0,2.0]}]\n    else:\n        print(\"Choose one from XGBRegressor, Lasso, ElasticNet\")\n    \n    grid_search = GridSearchCV(reg, param_grid, cv=5, scoring = 'neg_mean_squared_error', verbose=1)\n    grid_search.fit(x_train, y_train)\n    \n    best_model = grid_search.best_estimator_\n    print('GridSearchCV {} Best Params:'.format(method), grid_search.best_params_)\n    \n    return best_model","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:19.453605Z","iopub.execute_input":"2022-03-19T07:25:19.453866Z","iopub.status.idle":"2022-03-19T07:25:19.56174Z","shell.execute_reply.started":"2022-03-19T07:25:19.453836Z","shell.execute_reply":"2022-03-19T07:25:19.561049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(method, RMSE, y_pred, y_val):\n    ax, fig = plt.subplots(figsize=(10,8))\n    plt.plot(y_pred, 'b.', marker='*')\n    plt.plot(y_val.reset_index(drop=True), 'r.')\n    x = np.linspace(0,len(y_pred),num=len(y_pred))\n    m, b = np.polyfit(x, y_pred, 1)\n    plt.plot(x, m*x+b, 'g')\n    m, b = np.polyfit(x, y_val, 1)\n    plt.plot(x, m*x+b, 'm--')\n    plt.legend(['Prediction', 'Ground Truth', 'Prediction Line', 'GT Line'])\n    plt.title('Model : {}, RMSE : {}'.format(method, RMSE))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:19.563013Z","iopub.execute_input":"2022-03-19T07:25:19.563354Z","iopub.status.idle":"2022-03-19T07:25:19.570949Z","shell.execute_reply.started":"2022-03-19T07:25:19.563326Z","shell.execute_reply":"2022-03-19T07:25:19.570157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm\n\nmodels = ['XGBRegressor', 'Lasso', 'ElasticNet']\n\nfor method in tqdm(models):\n    best_model = train(method,x_train, y_train)\n    y_pred = best_model.predict(x_val)\n    RMSE = mean_squared_error(y_val, y_pred)**0.5\n    visualize(method, RMSE, y_pred, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:25:19.57211Z","iopub.execute_input":"2022-03-19T07:25:19.572563Z","iopub.status.idle":"2022-03-19T07:26:31.533326Z","shell.execute_reply.started":"2022-03-19T07:25:19.572529Z","shell.execute_reply":"2022-03-19T07:26:31.53241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Seems like XGBRegressor works the best!👍","metadata":{}}]}