{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np \nimport pandas as pd \nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, ElasticNet, ElasticNetCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, VotingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, OrdinalEncoder, PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\nfrom sklearn.feature_selection import chi2\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom category_encoders import TargetEncoder\nimport scipy.stats\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-03T20:45:21.215115Z","iopub.execute_input":"2022-03-03T20:45:21.215857Z","iopub.status.idle":"2022-03-03T20:45:21.23083Z","shell.execute_reply.started":"2022-03-03T20:45:21.215804Z","shell.execute_reply":"2022-03-03T20:45:21.229741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:21.233014Z","iopub.execute_input":"2022-03-03T20:45:21.233955Z","iopub.status.idle":"2022-03-03T20:45:21.304116Z","shell.execute_reply.started":"2022-03-03T20:45:21.233888Z","shell.execute_reply":"2022-03-03T20:45:21.303347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:21.305615Z","iopub.execute_input":"2022-03-03T20:45:21.306594Z","iopub.status.idle":"2022-03-03T20:45:21.334435Z","shell.execute_reply.started":"2022-03-03T20:45:21.30655Z","shell.execute_reply":"2022-03-03T20:45:21.333562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe(exclude = ['int', 'float'])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:21.336563Z","iopub.execute_input":"2022-03-03T20:45:21.336804Z","iopub.status.idle":"2022-03-03T20:45:21.441758Z","shell.execute_reply.started":"2022-03-03T20:45:21.336773Z","shell.execute_reply":"2022-03-03T20:45:21.440645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe(exclude = ['object'])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:21.443678Z","iopub.execute_input":"2022-03-03T20:45:21.444382Z","iopub.status.idle":"2022-03-03T20:45:21.56689Z","shell.execute_reply.started":"2022-03-03T20:45:21.444323Z","shell.execute_reply":"2022-03-03T20:45:21.565931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 6))\nmissings = train_df.isnull().sum() / len(train_df)\nmissings.plot.bar()\nplt.axhline(0.5, color = 'r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:21.568233Z","iopub.execute_input":"2022-03-03T20:45:21.568543Z","iopub.status.idle":"2022-03-03T20:45:22.856401Z","shell.execute_reply.started":"2022-03-03T20:45:21.56851Z","shell.execute_reply":"2022-03-03T20:45:22.855169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p> More than 80% of the data is missing in Alley, PoolQC, Fence, MiscFeature</p>","metadata":{}},{"cell_type":"markdown","source":"<ul>\n    <li> Alley column has three features Grave, Pval and NA(No alley access), so we can consider that all of the missing values are NA</li>\n    <li> also in PoolQC there is a category NA so all of the missings are NA</li>\n    <li> Fence all of the missings are NA also</li>\n    <li> NA also all of the missings in MiscFeature </li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"<p> other missing values in columns below 50% </p>\n<ul>\n    <li> Lot Frontage (numerical Column)</li>\n    <li> MasVnrType (Categorical Column) replace missings with (None)</li>\n    <li> MasVnrType (numerical Column)</li>\n    <li> BsmtQual (categorical Column) NA</li>\n    <li> BsmtCond (categorical Column) NA</li>\n    <li> BsmtExposure (categorical Column) NA</li>\n    <li> BsmtFinType1 (categorical Column) NA</li>\n    <li> BsmtFinType2 (categorical Column) NA</li>\n    <li> FireplaceQu (categorical Column) NA</li>\n    <li> GarageType (categorical Column) NA</li>\n    <li> GarageFinish (categorical Column) NA</li>\n    <li> GarageQual (categorical Column) NA</li>\n    <li> GarageCond (categorical Column) NA</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"# let's first split our data into Categorical features and numberical ones\n# and start explore thier behavoiur with the target variable\nnumerical_features = [col for col in train_df.columns if train_df[col].dtype != 'object']\ncategorical_features = [col for col in train_df.columns if train_df[col].dtype == 'object']","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:22.857986Z","iopub.execute_input":"2022-03-03T20:45:22.858251Z","iopub.status.idle":"2022-03-03T20:45:22.865751Z","shell.execute_reply.started":"2022-03-03T20:45:22.858222Z","shell.execute_reply":"2022-03-03T20:45:22.864624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's check the normality of SalesPrice (shapiro-wilk test)\nfrom scipy.stats import shapiro\ndef check_normality(data):\n    stat, p = shapiro(data)\n    print(\"stat = %.2f, P-Value = %.2f\" % (stat, p))\n    if p > 0.05:\n        print(\"Normal Distribution\")\n    else:\n        print(\"Not Normal.\")\ncheck_normality(train_df[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:22.867952Z","iopub.execute_input":"2022-03-03T20:45:22.868213Z","iopub.status.idle":"2022-03-03T20:45:22.882757Z","shell.execute_reply.started":"2022-03-03T20:45:22.868183Z","shell.execute_reply":"2022-03-03T20:45:22.881281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# so SalePrice doesn't follow normal Distribution\nsns.distplot(train_df['SalePrice'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:22.886249Z","iopub.execute_input":"2022-03-03T20:45:22.88657Z","iopub.status.idle":"2022-03-03T20:45:23.210861Z","shell.execute_reply.started":"2022-03-03T20:45:22.88654Z","shell.execute_reply":"2022-03-03T20:45:23.210048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I think it is so obovious that SalePrice is positively skewed.\n# let's apply log transformation and see\nsns.distplot(np.log1p(train_df['SalePrice']))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:23.212552Z","iopub.execute_input":"2022-03-03T20:45:23.213104Z","iopub.status.idle":"2022-03-03T20:45:23.486972Z","shell.execute_reply.started":"2022-03-03T20:45:23.21306Z","shell.execute_reply":"2022-03-03T20:45:23.486316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# also let's check the normality for each numerical Variable..\nfor col in train_df[numerical_features].columns:\n    print(f\"shapiro-wilk test for {col}\")\n    check_normality(train_df[col])\n    print(\"=============================\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:23.488031Z","iopub.execute_input":"2022-03-03T20:45:23.488377Z","iopub.status.idle":"2022-03-03T20:45:23.519141Z","shell.execute_reply.started":"2022-03-03T20:45:23.488347Z","shell.execute_reply":"2022-03-03T20:45:23.518374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (25, 25))\nsns.heatmap(train_df[numerical_features].corr(), annot = True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:23.520502Z","iopub.execute_input":"2022-03-03T20:45:23.52072Z","iopub.status.idle":"2022-03-03T20:45:29.682942Z","shell.execute_reply.started":"2022-03-03T20:45:23.520694Z","shell.execute_reply":"2022-03-03T20:45:29.682218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now also let's check correlation between features and Target variables..\ntarget_corr = train_df[numerical_features].corr()['SalePrice'].sort_values(ascending = False)\ntarget_corr","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:29.684003Z","iopub.execute_input":"2022-03-03T20:45:29.684822Z","iopub.status.idle":"2022-03-03T20:45:29.700877Z","shell.execute_reply.started":"2022-03-03T20:45:29.684781Z","shell.execute_reply":"2022-03-03T20:45:29.700306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now let's remove some correlated and transform some numerical fatures....\n# let's remove Id, GarageYrBlt, GarageArea, 1stFlrSF\ntrain_df.drop(['Id', 'GarageYrBlt', 'GarageArea', '1stFlrSF'], axis = 1, inplace = True)\ntest_df.drop(['Id', 'GarageYrBlt', 'GarageArea', '1stFlrSF'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:29.701888Z","iopub.execute_input":"2022-03-03T20:45:29.702509Z","iopub.status.idle":"2022-03-03T20:45:29.711557Z","shell.execute_reply.started":"2022-03-03T20:45:29.702467Z","shell.execute_reply":"2022-03-03T20:45:29.71036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_target = pd.melt(train_df, id_vars = 'SalePrice', value_vars = categorical_features)\ng = sns.FacetGrid(cat_target, col='variable',  col_wrap=2, sharex=False, sharey=False, size=5, palette = 'tab10')\ng = g.map(sns.boxplot, 'value', 'SalePrice')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:29.713663Z","iopub.execute_input":"2022-03-03T20:45:29.713895Z","iopub.status.idle":"2022-03-03T20:45:42.567437Z","shell.execute_reply.started":"2022-03-03T20:45:29.713869Z","shell.execute_reply":"2022-03-03T20:45:42.566632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p> Most of the the categorical features distribution varies with the Sale Price of the houses except for Utilites that contain no variability (1459 AllPub, 1 NoSaWa)","metadata":{}},{"cell_type":"code","source":"test_df['Utilities'].value_counts().plot.bar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.568657Z","iopub.execute_input":"2022-03-03T20:45:42.568869Z","iopub.status.idle":"2022-03-03T20:45:42.73278Z","shell.execute_reply.started":"2022-03-03T20:45:42.568842Z","shell.execute_reply":"2022-03-03T20:45:42.732098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p> again test data contain one category of utilities, so we can remove it</p>","metadata":{}},{"cell_type":"code","source":"train_df.drop('Utilities', axis = 1, inplace = True)\ntest_df.drop('Utilities', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.73396Z","iopub.execute_input":"2022-03-03T20:45:42.734169Z","iopub.status.idle":"2022-03-03T20:45:42.741531Z","shell.execute_reply.started":"2022-03-03T20:45:42.734143Z","shell.execute_reply":"2022-03-03T20:45:42.740734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now let's handle missing categorical variables with 'None'\ncategorical_features.remove('Utilities')\ntrain_df[categorical_features] = train_df[categorical_features].fillna(\"NoNe\")\ntest_df[categorical_features] = test_df[categorical_features].fillna(\"NoNe\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.742571Z","iopub.execute_input":"2022-03-03T20:45:42.743172Z","iopub.status.idle":"2022-03-03T20:45:42.783441Z","shell.execute_reply.started":"2022-03-03T20:45:42.743136Z","shell.execute_reply":"2022-03-03T20:45:42.782486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's now handle the numerical columns with median if it's data outside the range of 0.05 and 0.95\n# mean if it in the range of 0.05 and 0.95\n# LotFrontage, MasVnrArea\ndef outlier_detector(data, col_name):\n    upper_lim = data[col_name].quantile(.95)\n    lower_lim = data[col_name].quantile(.05)\n    data = data[(data[col_name] < lower_lim) & (data[col_name] > upper_lim)][col_name]\n    if len(data) > 0:\n        return True\n    return False\ndef handle_numerical(data, col_name):\n    if outlier_detector(data, col_name):\n        data[col_name].fillna(data[col_name].mean(), inplace = True)\n    else:\n        data[col_name].fillna(data[col_name].median(), inplace = True)\nhandle_numerical(train_df, 'LotFrontage')\nhandle_numerical(train_df, 'MasVnrArea')\nhandle_numerical(test_df, 'LotFrontage')\nhandle_numerical(test_df, 'MasVnrArea')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.784995Z","iopub.execute_input":"2022-03-03T20:45:42.785324Z","iopub.status.idle":"2022-03-03T20:45:42.810316Z","shell.execute_reply.started":"2022-03-03T20:45:42.78528Z","shell.execute_reply":"2022-03-03T20:45:42.808754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generete some features from the old ones..\ntrain_df['AboveGr'] = (train_df['FullBath'] + train_df['BedroomAbvGr'] + train_df['KitchenAbvGr'] + train_df['HalfBath']) / train_df['GrLivArea']\ntest_df['AboveGr'] = (test_df['FullBath'] + test_df['BedroomAbvGr'] + test_df['KitchenAbvGr'] + test_df['HalfBath']) / test_df['GrLivArea']\ntrain_df[\"TotalBath\"] = train_df[\"BsmtFullBath\"] + (0.5 * train_df[\"BsmtHalfBath\"]) + train_df[\"FullBath\"] + (0.5 * train_df[\"HalfBath\"])\ntest_df[\"TotalBath\"] = test_df[\"BsmtFullBath\"] + (0.5 * test_df[\"BsmtHalfBath\"]) + test_df[\"FullBath\"] + (0.5 * test_df[\"HalfBath\"])\ntrain_df[\"AllSF\"] = train_df[\"GrLivArea\"] + train_df[\"TotalBsmtSF\"]\ntest_df[\"AllSF\"] = test_df[\"GrLivArea\"] + test_df[\"TotalBsmtSF\"]\n# add some ploynomials for the uncorrelated features ^2, ^1/2, ^3....\ntrain_df['PoolArea^2'] = train_df['PoolArea']**2\ntrain_df['PoolArea^3'] = train_df['PoolArea']**3\ntrain_df['PoolArea^1/2'] = np.sqrt(train_df['PoolArea'])\ntest_df['PoolArea^2'] = test_df['PoolArea']**2\ntest_df['PoolArea^3'] = test_df['PoolArea']**3\ntest_df['PoolArea^1/2'] = np.sqrt(test_df['PoolArea'])\n#########\ntrain_df['MoSold^2'] = train_df['MoSold']**2\ntrain_df['MoSold^3'] = train_df['MoSold']**3\ntrain_df['MoSold^1/2'] = np.sqrt(train_df['MoSold'])\ntest_df['MoSold^2'] = test_df['MoSold']**2\ntest_df['MoSold^3'] = test_df['MoSold']**3\ntest_df['MoSold^1/2'] = np.sqrt(test_df['MoSold'])\n#########\ntrain_df['3SsnPorch^2'] = train_df['3SsnPorch']**2\ntrain_df['3SsnPorch^3'] = train_df['3SsnPorch']**3\ntrain_df['3SsnPorch^1/2'] = np.sqrt(train_df['3SsnPorch'])\ntest_df['3SsnPorch^2'] = test_df['3SsnPorch']**2\ntest_df['3SsnPorch^3'] = test_df['3SsnPorch']**3\ntest_df['3SsnPorch^1/2'] = np.sqrt(test_df['3SsnPorch'])\n#########\ntrain_df['BsmtFinSF2^2'] = train_df['BsmtFinSF2']**2\ntrain_df['BsmtFinSF2^3'] = train_df['BsmtFinSF2']**3\ntrain_df['BsmtFinSF2^1/2'] = np.sqrt(train_df['BsmtFinSF2'])\ntest_df['BsmtFinSF2^2'] = test_df['BsmtFinSF2']**2\ntest_df['BsmtFinSF2^3'] = test_df['BsmtFinSF2']**3\ntest_df['BsmtFinSF2^1/2'] = np.sqrt(test_df['BsmtFinSF2'])\n#########\ntrain_df['BsmtHalfBath^2'] = train_df['BsmtHalfBath']**2\ntrain_df['BsmtHalfBath^3'] = train_df['BsmtHalfBath']**3\ntrain_df['BsmtHalfBath^1/2'] = np.sqrt(train_df['BsmtHalfBath'])\ntest_df['BsmtHalfBath^2'] = test_df['BsmtHalfBath']**2\ntest_df['BsmtHalfBath^3'] = test_df['BsmtHalfBath']**3\ntest_df['BsmtHalfBath^1/2'] = np.sqrt(test_df['BsmtHalfBath'])\n#########\ntrain_df['MiscVal^2'] = train_df['MiscVal']**2\ntrain_df['MiscVal^3'] = train_df['MiscVal']**3\ntrain_df['MiscVal^1/2'] = np.sqrt(train_df['MiscVal'])\ntest_df['MiscVal^2'] = test_df['MiscVal']**2\ntest_df['MiscVal^3'] = test_df['MiscVal']**3\ntest_df['MiscVal^1/2'] = np.sqrt(test_df['MiscVal'])\n#########\ntrain_df['LowQualFinSF^2'] = train_df['LowQualFinSF']**2\ntrain_df['LowQualFinSF^3'] = train_df['LowQualFinSF']**3\ntrain_df['LowQualFinSF^1/2'] = np.sqrt(train_df['LowQualFinSF'])\ntest_df['LowQualFinSF^2'] = test_df['LowQualFinSF']**2\ntest_df['LowQualFinSF^3'] = test_df['LowQualFinSF']**3\ntest_df['LowQualFinSF^1/2'] = np.sqrt(test_df['LowQualFinSF'])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.812132Z","iopub.execute_input":"2022-03-03T20:45:42.81266Z","iopub.status.idle":"2022-03-03T20:45:42.868638Z","shell.execute_reply.started":"2022-03-03T20:45:42.812618Z","shell.execute_reply":"2022-03-03T20:45:42.868008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def house_remodel(df):\n    lst = []\n    for val in df['YearRemodAdd'] - df['YearBuilt']:\n        if val > 0:\n            lst.append('Yes')\n        else:\n            lst.append('No')\n    return lst\ntrain_df['HouseRemodeled'] = house_remodel(train_df)\ntest_df['HouseRemodeled'] = house_remodel(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.870028Z","iopub.execute_input":"2022-03-03T20:45:42.870716Z","iopub.status.idle":"2022-03-03T20:45:42.879755Z","shell.execute_reply.started":"2022-03-03T20:45:42.870676Z","shell.execute_reply":"2022-03-03T20:45:42.878655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's check the skewness of the numeric features to see which features needs log transformation\nnumerical_features = [col for col in train_df.columns if train_df[col].dtype != 'object']\nnumerical_features.remove('SalePrice')\ncategorical_features = [col for col in train_df.columns if train_df[col].dtype == 'object']\nskewed_features = [col for col in train_df[numerical_features].columns if abs(train_df[col].skew()) > 0.5]\nprint(len(skewed_features))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.881455Z","iopub.execute_input":"2022-03-03T20:45:42.882294Z","iopub.status.idle":"2022-03-03T20:45:42.91229Z","shell.execute_reply.started":"2022-03-03T20:45:42.882243Z","shell.execute_reply":"2022-03-03T20:45:42.911342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in test_df[numerical_features].columns:\n    handle_numerical(test_df, col)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:42.913868Z","iopub.execute_input":"2022-03-03T20:45:42.914177Z","iopub.status.idle":"2022-03-03T20:45:43.065889Z","shell.execute_reply.started":"2022-03-03T20:45:42.914135Z","shell.execute_reply":"2022-03-03T20:45:43.065284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_df['SalePrice']\nX = train_df.drop('SalePrice', axis = 1)\ny = y.apply(lambda x: np.log1p(x))\nX[skewed_features] = X[skewed_features].apply(lambda x: np.log1p(x))\ntest_df[skewed_features] = test_df[skewed_features].apply(lambda x: np.log1p(x))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.070456Z","iopub.execute_input":"2022-03-03T20:45:43.070717Z","iopub.status.idle":"2022-03-03T20:45:43.130228Z","shell.execute_reply.started":"2022-03-03T20:45:43.070688Z","shell.execute_reply":"2022-03-03T20:45:43.129285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_num_data = pd.concat([X[numerical_features], test_df[numerical_features]])\nss=StandardScaler()\nss.fit(all_num_data)\nnormalized_X=pd.DataFrame(ss.transform(X[numerical_features]))\nnormalized_test=pd.DataFrame(ss.transform(test_df[numerical_features]))\nnormalized_X.index = X.index\nnormalized_test.index = test_df.index","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.131342Z","iopub.execute_input":"2022-03-03T20:45:43.131544Z","iopub.status.idle":"2022-03-03T20:45:43.160797Z","shell.execute_reply.started":"2022-03-03T20:45:43.13152Z","shell.execute_reply":"2022-03-03T20:45:43.159939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check high and low cardinality columns\ngood_label_cols=[i for i in categorical_features if set(X[i])==set(test_df[i])]\nbad_label_cols = list(set(categorical_features)-set(good_label_cols))\nprint('good label cols \\n', good_label_cols)\nprint('bad label cols \\n', bad_label_cols)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.16216Z","iopub.execute_input":"2022-03-03T20:45:43.162525Z","iopub.status.idle":"2022-03-03T20:45:43.191916Z","shell.execute_reply.started":"2022-03-03T20:45:43.162489Z","shell.execute_reply":"2022-03-03T20:45:43.190825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"good_cat_x=X[good_label_cols]\nbad_cat_x=X[bad_label_cols]\ngood_cat_test=test_df[good_label_cols]\nbad_cat_test=test_df[bad_label_cols]","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.193078Z","iopub.execute_input":"2022-03-03T20:45:43.193305Z","iopub.status.idle":"2022-03-03T20:45:43.203631Z","shell.execute_reply.started":"2022-03-03T20:45:43.193278Z","shell.execute_reply":"2022-03-03T20:45:43.202825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cat_data = pd.concat([X[categorical_features], test_df[categorical_features]])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.205189Z","iopub.execute_input":"2022-03-03T20:45:43.206247Z","iopub.status.idle":"2022-03-03T20:45:43.216988Z","shell.execute_reply.started":"2022-03-03T20:45:43.206198Z","shell.execute_reply":"2022-03-03T20:45:43.216155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ohe=OneHotEncoder(handle_unknown='ignore', sparse=False)\nohe.fit(all_cat_data)\noh_cat_x=pd.DataFrame(ohe.transform(train_df[categorical_features]))\noh_cat_test=pd.DataFrame(ohe.transform(test_df[categorical_features]))\noh_cat_x.index = bad_cat_x.index\noh_cat_test.index = bad_cat_test.index","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.217991Z","iopub.execute_input":"2022-03-03T20:45:43.218912Z","iopub.status.idle":"2022-03-03T20:45:43.578707Z","shell.execute_reply.started":"2022-03-03T20:45:43.218862Z","shell.execute_reply":"2022-03-03T20:45:43.577765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=pd.concat([normalized_X, oh_cat_x], axis=1)\ntest_df=pd.concat([normalized_test, oh_cat_test], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.580184Z","iopub.execute_input":"2022-03-03T20:45:43.58054Z","iopub.status.idle":"2022-03-03T20:45:43.593282Z","shell.execute_reply.started":"2022-03-03T20:45:43.580492Z","shell.execute_reply":"2022-03-03T20:45:43.592387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=[\n    {\n        'name': 'linear regression',\n        'estimator':LinearRegression(),\n        'hyperparameters':{}\n    },\n    {\n        'name':'ridge regression',\n        'estimator':Ridge(),\n        'hyperparameters':{\n            'alpha':np.arange(0.01, 1, 0.02)\n        }\n    },\n    {\n        'name':'lasso regression',\n        'estimator':Lasso(),\n        'hyperparameters':{\n            'alpha':np.arange(0.01, 1, 0.02)\n        }\n    },\n    {\n        'name': 'ElasticNet',\n        'estimator': ElasticNet(),\n        'hyperparameters':{\n            'alpha':np.arange(0.01, 1, 0.02),\n            'l1_ratio': [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1] \n        }\n    },\n    {\n        'name':'decision Tree',\n        'estimator':DecisionTreeRegressor(),\n        'hyperparameters':{\n            'max_depth':[2,3,4,5,6,7],\n            'criterion':['mse', 'friedman_mse', 'mae'],\n            'splitter':['best', 'random'],\n            'max_features':['auto', 'sqrt', 'log2']\n        }\n    }\n]\nfor i in model:\n    print(i['name'])\n    gs=GridSearchCV(i['estimator'], param_grid=i['hyperparameters'], cv=5, n_jobs=-1, scoring='neg_root_mean_squared_error')\n    gs.fit(X.values, y.values)\n    print('best score: ', gs.best_score_)\n    print('best parameters ; ', gs.best_params_)\n    print('best model: ', gs.best_estimator_)\n    print('---------------------------------\\n')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:45:43.59461Z","iopub.execute_input":"2022-03-03T20:45:43.595249Z","iopub.status.idle":"2022-03-03T20:46:19.807243Z","shell.execute_reply.started":"2022-03-03T20:45:43.59521Z","shell.execute_reply":"2022-03-03T20:46:19.806333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = ElasticNet(alpha=0.01, l1_ratio=0.1)\nfinal_model.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:46:19.808932Z","iopub.execute_input":"2022-03-03T20:46:19.809171Z","iopub.status.idle":"2022-03-03T20:46:19.913161Z","shell.execute_reply.started":"2022-03-03T20:46:19.809143Z","shell.execute_reply":"2022-03-03T20:46:19.912045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model2 = LinearRegression()\nfinal_model2.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:46:19.915572Z","iopub.execute_input":"2022-03-03T20:46:19.916404Z","iopub.status.idle":"2022-03-03T20:46:19.990693Z","shell.execute_reply.started":"2022-03-03T20:46:19.916344Z","shell.execute_reply":"2022-03-03T20:46:19.989694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model3 = VotingRegressor([('en', ElasticNet(alpha=0.01, l1_ratio=0.1)),\n                                ('xgb', XGBRegressor(n_estimators = 1000, learning_rate = 0.05))])\nscore = cross_validate(final_model3, X.values, y.values, cv = 5, scoring = ['neg_root_mean_squared_error'])\nscore['test_neg_root_mean_squared_error'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:53:52.905722Z","iopub.execute_input":"2022-03-03T20:53:52.906094Z","iopub.status.idle":"2022-03-03T20:54:58.121017Z","shell.execute_reply.started":"2022-03-03T20:53:52.906056Z","shell.execute_reply":"2022-03-03T20:54:58.119912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model3.fit(X.values, y.values)\ny_hat = np.expm1(final_model3.predict(test_df))\ny_hat","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:56:15.904895Z","iopub.execute_input":"2022-03-03T20:56:15.906122Z","iopub.status.idle":"2022-03-03T20:56:31.599734Z","shell.execute_reply.started":"2022-03-03T20:56:15.906053Z","shell.execute_reply":"2022-03-03T20:56:31.598689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.DataFrame({'Id':range(1461, 1461+len(test_df)),'SalePrice':y_hat})","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:56:36.594186Z","iopub.execute_input":"2022-03-03T20:56:36.59449Z","iopub.status.idle":"2022-03-03T20:56:36.60203Z","shell.execute_reply.started":"2022-03-03T20:56:36.594462Z","shell.execute_reply":"2022-03-03T20:56:36.600202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:56:39.055542Z","iopub.execute_input":"2022-03-03T20:56:39.056447Z","iopub.status.idle":"2022-03-03T20:56:39.069674Z","shell.execute_reply.started":"2022-03-03T20:56:39.056398Z","shell.execute_reply":"2022-03-03T20:56:39.06861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}