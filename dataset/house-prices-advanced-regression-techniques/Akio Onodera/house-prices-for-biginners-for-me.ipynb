{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Import data","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')\nf = open('/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt', 'r')\ndata_description = f.read()\ntrain = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame(train)\ndf_test = pd.DataFrame(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preprocessing","metadata":{}},{"cell_type":"code","source":"df_all = pd.concat([df_train.drop(columns='SalePrice'),df_test],ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Search for missing data\nimport missingno as msno\nmsno.matrix(df=df_all, figsize=(20,14), color=(0,.3,.3))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# String label to categorical values\nfrom sklearn.preprocessing import LabelEncoder\n\nfor i in range(df_all.shape[1]):\n    if df_all.iloc[:,i].dtypes == object:\n        lbl = LabelEncoder()\n        lbl.fit(list(df_all.iloc[:,i].values))\n        df_all.iloc[:,i] = lbl.transform(list(df_all.iloc[:,i].values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing data (type = int or float) fill in 0\nfor column in df_all.columns:\n    df_all[column] = df_all[column].fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add new columns\ndef add_new_columns(df):\n    # 建物内の総面積 = 1階の面積 + 2階の面積 + 地下の面積\n    df[\"TotalSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"] + df[\"TotalBsmtSF\"]\n\n    # 一部屋あたりの平均面積 = 建物の総面積 / 部屋数\n    df['AreaPerRoom'] = df['TotalSF']/df['TotRmsAbvGrd']\n\n    # 築年数 + 最新リフォーム年 : この値が大きいほど値段が高くなりそう\n    df['YearBuiltPlusRemod']=df['YearBuilt']+df['YearRemodAdd']\n\n    # お風呂の総面積\n    # Full bath : 浴槽、シャワー、洗面台、便器全てが備わったバスルーム\n    # Half bath : 洗面台、便器が備わった部屋)(シャワールームがある場合もある)\n    # シャワーがない場合を想定してHalf Bathには0.5の係数をつける\n    df['TotalBathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))\n\n    # 合計の屋根付きの玄関の総面積 \n    df['TotalPorchSF'] = (df['OpenPorchSF'] + df['3SsnPorch'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF'])\n\n    # プールの有無\n    df['HasPool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n\n    # 2階の有無\n    df['Has2ndFloor'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n\n    # ガレージの有無\n    df['HasGarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n\n    # 地下室の有無\n    df['HasBsmt'] = df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n\n    # 暖炉の有無\n    df['HasFireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n\nadd_new_columns(df_all)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df=df_all, figsize=(20,14), color=(0,.3,.3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.merge(df_all.iloc[df_train.index[0]:df_train.index[-1]+1],df_train['SalePrice'],left_index=True,right_index=True)\ndf_test = df_all.iloc[df_train.index[-1]+1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Histogram","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.histplot(df_train['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Truncate outliers\ndf_train = df_train[(df_train['SalePrice'] < 510000)]\nsns.histplot(df_train['SalePrice'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Check the correlation for each item","metadata":{}},{"cell_type":"code","source":"df_train_corr = df_train.corr()\ndf_train_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(df_train_corr, vmax=.8, square=True, cmap='Blues');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Extract items with high correlation coefficient","metadata":{}},{"cell_type":"code","source":"predictor_cols = []\nfor i in df_train_corr:\n    if df_train_corr[i]['SalePrice'] > 0.05 or df_train_corr[i]['SalePrice'] < -0.05:\n        innerName = df_train_corr[i].name\n        if innerName != 'SalePrice':\n            predictor_cols.append(innerName)\npredictor_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor as RFR\nfrom sklearn.model_selection import GridSearchCV\n\ntrain_x = df_train[predictor_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling\n#scale_train_x = preprocessing.minmax_scale(train_x[:, :])\n\ntrain_y = df_train.SalePrice\n\n# Tune parameters\nsearch_params = {\n    'n_estimators'      : [600],\n    'max_features'      : [24],\n    'random_state'      : [0],\n    'n_jobs'            : [-1],\n    'min_samples_split' : [3],\n    'max_depth'         : [17]\n}\n\nmodel = GridSearchCV(\n    RFR(),\n    search_params,\n    cv = 3,\n    verbose=True\n)\n\nmodel.fit(train_x, train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.metrics import r2_score\n\n# Check score\nt_true = np.array(df_train['SalePrice'])\nx_forScore = df_train[predictor_cols]\nnp_x_forScore = np.array(x_forScore)\nfloat_x_forScore = np_x_forScore.astype('float32')\n# Scaling\n#scale_float_x_forScore = preprocessing.minmax_scale(float_x_forScore[:, :])\n\npredict = model.predict(float_x_forScore)\nprint(t_true)\nprint(predict)\nr2_score = r2_score(t_true, predict)\nr2_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Predict","metadata":{}},{"cell_type":"code","source":"test_x = df_test[predictor_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling\n#scale_test_x = preprocessing.minmax_scale(test_x[:, :])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = model.predict(test_x)\ntest_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Prepare upload data","metadata":{}},{"cell_type":"code","source":"if r2_score > 0.95:\n    my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': test_y})\n    my_submission.to_csv('submission.csv', index=False)\n    print('Succeeded : r2 = {:.5f}'.format(r2_score))\nelse:\n    print('Low Score : r2 = {:.5f}'.format(r2_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}