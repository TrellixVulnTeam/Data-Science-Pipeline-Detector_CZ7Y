{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.cluster import KMeans \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\n\n\n#matplolib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T05:49:47.231086Z","iopub.execute_input":"2022-04-26T05:49:47.231697Z","iopub.status.idle":"2022-04-26T05:49:48.682993Z","shell.execute_reply.started":"2022-04-26T05:49:47.231604Z","shell.execute_reply":"2022-04-26T05:49:48.682315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:48.684245Z","iopub.execute_input":"2022-04-26T05:49:48.684594Z","iopub.status.idle":"2022-04-26T05:49:48.757295Z","shell.execute_reply.started":"2022-04-26T05:49:48.684566Z","shell.execute_reply":"2022-04-26T05:49:48.756396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:48.758337Z","iopub.execute_input":"2022-04-26T05:49:48.758942Z","iopub.status.idle":"2022-04-26T05:49:48.786013Z","shell.execute_reply.started":"2022-04-26T05:49:48.758909Z","shell.execute_reply":"2022-04-26T05:49:48.785071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total number of cells with missing values\nprint(\"Number of cells with the missing values are {}\".format((df.isnull().sum()).sum()))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:48.787951Z","iopub.execute_input":"2022-04-26T05:49:48.788168Z","iopub.status.idle":"2022-04-26T05:49:48.802284Z","shell.execute_reply.started":"2022-04-26T05:49:48.788143Z","shell.execute_reply":"2022-04-26T05:49:48.801616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seperating numerical and categorical variabled for EDA and feature engineering\n\nnum_cols = [col for col in df.columns if df[col].dtype in ['int64','float64']]\n\ncat_cols = [col for col in df.columns if df[col].dtype == 'object']\n\ny = df['SalePrice']\n\n# numerical and categorical dataframe\n\nnum_df = df[num_cols]\ncat_df = df[cat_cols]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:48.803677Z","iopub.execute_input":"2022-04-26T05:49:48.804265Z","iopub.status.idle":"2022-04-26T05:49:48.813066Z","shell.execute_reply.started":"2022-04-26T05:49:48.804229Z","shell.execute_reply":"2022-04-26T05:49:48.812317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA and feature engineering on numerical cols\n\nnum_df.dropna(axis=1, inplace=True)\n\nnum_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:48.814668Z","iopub.execute_input":"2022-04-26T05:49:48.815123Z","iopub.status.idle":"2022-04-26T05:49:48.833986Z","shell.execute_reply.started":"2022-04-26T05:49:48.815084Z","shell.execute_reply":"2022-04-26T05:49:48.8331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [col for col in num_df.columns if num_df[col].nunique() > 15 ] \n\ncols.remove('SalePrice')\n\nconti_fea = num_df[cols]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:48.835215Z","iopub.execute_input":"2022-04-26T05:49:48.835462Z","iopub.status.idle":"2022-04-26T05:49:48.846211Z","shell.execute_reply.started":"2022-04-26T05:49:48.835436Z","shell.execute_reply":"2022-04-26T05:49:48.845526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Numerical columns data analysis","metadata":{}},{"cell_type":"markdown","source":"> Below code will give us bivariate analysis of continous features and its releationship with our target\n\n> we can see that some features are more likely to co-relate than others and we will cross check with mutual info regressor as well","metadata":{}},{"cell_type":"code","source":"for idx, col in enumerate(conti_fea.columns):\n    plt.figure(idx, figsize=(5,5))\n    sns.relplot(x=col, y=y, kind=\"scatter\", data=conti_fea)\n    plt.show","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:48.847307Z","iopub.execute_input":"2022-04-26T05:49:48.847954Z","iopub.status.idle":"2022-04-26T05:49:55.128181Z","shell.execute_reply.started":"2022-04-26T05:49:48.847922Z","shell.execute_reply":"2022-04-26T05:49:55.127301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From above plots we can see that 'Yearbuilt', 'YearRemodadd', 'GrLivArea', 'GarageArea' highly co-relate with our target 'SalePrice'","metadata":{}},{"cell_type":"code","source":"cols = [col for col in num_df.columns if num_df[col].nunique() <= 15 ] \n\ndist_feature = num_df[cols]\ndist_feature.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:55.129336Z","iopub.execute_input":"2022-04-26T05:49:55.129536Z","iopub.status.idle":"2022-04-26T05:49:55.148124Z","shell.execute_reply.started":"2022-04-26T05:49:55.129511Z","shell.execute_reply":"2022-04-26T05:49:55.147582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, col in enumerate(dist_feature.columns):\n    plt.figure(idx, figsize=(5,5))\n    sns.stripplot(x=col , y=y , data=dist_feature)\n    plt.show","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T05:49:55.150972Z","iopub.execute_input":"2022-04-26T05:49:55.151194Z","iopub.status.idle":"2022-04-26T05:49:59.942031Z","shell.execute_reply.started":"2022-04-26T05:49:55.151168Z","shell.execute_reply":"2022-04-26T05:49:59.94146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From above plots we can clearly see that 'MSSubclass', 'YrSold', 'MoSold', 'PoolArea' are not informative features and will examine them in mutual info regressor","metadata":{}},{"cell_type":"code","source":"# MI score on num_df dataframe\n#nti_fea = num_df[cols]\n#ist_feature = num_df[cols]\n\nX = num_df.drop('SalePrice', axis=1)\n\ny = df['SalePrice']\n\n#iscrete_features = dist_feature\n\ndef mi_score(X,y):\n    mi_score = mutual_info_regression(X,y, discrete_features=False, random_state=0)\n    mi_score = pd.Series(mi_score, name=\"MI_SCORE\", index=X.columns)\n    mi_score = mi_score.sort_values(ascending=False)\n    return mi_score\n\nmi_series = mi_score(X,y)\n\n#i_df = pd.DataFrame(mi_series, columns=\"MI_SCORE\", index = mi_series.index)\n\npd.DataFrame(mi_series)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:49:59.943138Z","iopub.execute_input":"2022-04-26T05:49:59.943478Z","iopub.status.idle":"2022-04-26T05:50:00.908996Z","shell.execute_reply.started":"2022-04-26T05:49:59.943441Z","shell.execute_reply":"2022-04-26T05:50:00.908321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From above plots and MI_score we will consider features having score above **0.15** to keep most informative features in our model training dataset.\n\n> We will do feature engineering and outliers handling on these features","metadata":{}},{"cell_type":"code","source":"# plootting MI scores of numrical data analysis\ndata=pd.DataFrame(mi_series)\n\nfig, ax = plt.subplots(figsize=(6,15))\n\nax.set_title(\"MI SCORES OF NUMERICAL FEATURES\")\nsns.barplot(data=data, y=data.index, x='MI_SCORE', ax=ax)\nax.set_ylabel(\"Numrerical features\")\n\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:00.910058Z","iopub.execute_input":"2022-04-26T05:50:00.910251Z","iopub.status.idle":"2022-04-26T05:50:01.451082Z","shell.execute_reply.started":"2022-04-26T05:50:00.910229Z","shell.execute_reply":"2022-04-26T05:50:01.450278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Categorical columns data analysis","metadata":{}},{"cell_type":"markdown","source":"> We will do bivariate analysis of categorical features to see how they explains our target variable","metadata":{}},{"cell_type":"code","source":"cat_df = df[cat_cols]\ncat_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:01.452599Z","iopub.execute_input":"2022-04-26T05:50:01.453758Z","iopub.status.idle":"2022-04-26T05:50:01.479132Z","shell.execute_reply.started":"2022-04-26T05:50:01.453711Z","shell.execute_reply":"2022-04-26T05:50:01.478533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cat_df.isnull().sum()\n\n# remove features wiht most number of data missing\n\nfeatures_rem = [col for col in cat_df.columns if cat_df[col].isnull().sum() > 500]\n\ncat_df = cat_df.drop(features_rem, axis=1)\n\ncat_df.fillna(method='bfill', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:01.480037Z","iopub.execute_input":"2022-04-26T05:50:01.480722Z","iopub.status.idle":"2022-04-26T05:50:01.516111Z","shell.execute_reply.started":"2022-04-26T05:50:01.480675Z","shell.execute_reply":"2022-04-26T05:50:01.515485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting categorical features to find releationship with our target variable\n\ny = df['SalePrice']\n\ncol_15 = [col for col in cat_df.columns if cat_df[col].nunique() >= 15]\n\nfor idx, col in enumerate(col_15):\n    plt.figure(idx, figsize=(8,8))\n    sns.stripplot(x=col, y=y, data=cat_df[col_15])\n    plt.xticks(rotation=60)\n    plt.show","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T05:50:01.517274Z","iopub.execute_input":"2022-04-26T05:50:01.517521Z","iopub.status.idle":"2022-04-26T05:50:03.132754Z","shell.execute_reply.started":"2022-04-26T05:50:01.517493Z","shell.execute_reply":"2022-04-26T05:50:03.131819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From these plots we can say that above features contains no information to explain our target variable as we have more uncertainity ","metadata":{}},{"cell_type":"code","source":"y = df['SalePrice']\n\ncols_ = [col for col in cat_df.columns if cat_df[col].nunique() < 15]\n\nfor idx, col in enumerate(cols_):\n    plt.figure(idx, figsize=(5,5))\n    sns.stripplot(x=col, y=y, data=cat_df[cols_])\n    plt.xticks(rotation=60)\n    plt.show","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T05:50:03.134046Z","iopub.execute_input":"2022-04-26T05:50:03.134332Z","iopub.status.idle":"2022-04-26T05:50:13.618068Z","shell.execute_reply.started":"2022-04-26T05:50:03.134294Z","shell.execute_reply":"2022-04-26T05:50:13.617233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Some of the features like 'Street', 'BldgType', 'PavedDrive', 'Garagecond', 'HeatingQC' are more informative and explains target variable with less antropy than others","metadata":{}},{"cell_type":"code","source":"# Mutual info regressio on categorical features\ny = df['SalePrice']\nX1 = cat_df[cols_]\n\nfor colname in X1.select_dtypes('object'):\n    X1[colname],_= X1[colname].factorize()\n\nmiscore = mutual_info_regression(X1, y, random_state=0)\nmiscore = pd.Series(miscore, name=\"MISCORE\", index = X1.columns)\nmiscore = miscore.sort_values(ascending=False)\n\npd.DataFrame(miscore)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:13.619227Z","iopub.execute_input":"2022-04-26T05:50:13.619439Z","iopub.status.idle":"2022-04-26T05:50:14.752266Z","shell.execute_reply.started":"2022-04-26T05:50:13.619413Z","shell.execute_reply":"2022-04-26T05:50:14.751336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plootting MI scores of numrical data analysis\ndata = pd.DataFrame(miscore)\n\nfig, ax = plt.subplots(figsize=(6,15))\n\nax.set_title(\"MI SCORES OF CATEGORICAL FEATURES\")\nsns.barplot(data=data, y=data.index, x='MISCORE', ax=ax)\nax.set_ylabel(\"Categorical features\")\nax.set_xlim(0,0.5)\n\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:14.753934Z","iopub.execute_input":"2022-04-26T05:50:14.754235Z","iopub.status.idle":"2022-04-26T05:50:15.415313Z","shell.execute_reply.started":"2022-04-26T05:50:14.754195Z","shell.execute_reply":"2022-04-26T05:50:15.41451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We will keep features having MI score of **0.15** and above in our model training ","metadata":{}},{"cell_type":"code","source":"# corelation matrix for numerical continues features\nplt.figure(figsize=(10,10))\nsns.heatmap(data=conti_fea.corr(), annot=True, vmin=-1, vmax=1)\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:15.416497Z","iopub.execute_input":"2022-04-26T05:50:15.41676Z","iopub.status.idle":"2022-04-26T05:50:18.271042Z","shell.execute_reply.started":"2022-04-26T05:50:15.416731Z","shell.execute_reply":"2022-04-26T05:50:18.270247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features transformations and  new features addition\n\n# ratio of ground live area and frist floor area\n\nnum_df['grlivperfirstflr'] = num_df['GrLivArea']/num_df['1stFlrSF']\n\n# total number of porch types\n\nnum_df['Porchtypes'] = num_df[['ScreenPorch','3SsnPorch',\n                               'EnclosedPorch','OpenPorchSF','WoodDeckSF']].gt(0).sum(axis=1)\n\n# we can see from above numerical plots that houses with 2nd floor highly correlate with price of the house\n# but are not having all house with 2nd floor so will tell model that what houses are having 2nd floor\n\nnum_df['2nd_flr'] = np.where(num_df['2ndFlrSF'].map(lambda x: x>0), 1 ,0) \n\n# total number of bathrooms \n\nnum_df['Totalbath'] = (num_df['HalfBath'] + \n                       num_df['FullBath'] + \n                       num_df['BsmtHalfBath'] +   \n                       num_df['BsmtFullBath'])\n\n# mean saleprice surrounded by each Neighborhood \n\nnum_df['MeanpriceNBH'] = df.groupby('Neighborhood').SalePrice.transform('mean')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.272313Z","iopub.execute_input":"2022-04-26T05:50:18.273717Z","iopub.status.idle":"2022-04-26T05:50:18.290406Z","shell.execute_reply.started":"2022-04-26T05:50:18.27367Z","shell.execute_reply":"2022-04-26T05:50:18.289303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#num_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.291851Z","iopub.execute_input":"2022-04-26T05:50:18.292413Z","iopub.status.idle":"2022-04-26T05:50:18.307337Z","shell.execute_reply.started":"2022-04-26T05:50:18.292378Z","shell.execute_reply":"2022-04-26T05:50:18.306651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.DataFrame(mi_series)\narr = np.array(data.index)\n\nfeature1 = []\n\nfor fea in arr:\n    if data.loc[fea,'MI_SCORE'] > 0.15:\n        feature1.append(fea)\n    else:\n        pass\n\nfeature1","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.3085Z","iopub.execute_input":"2022-04-26T05:50:18.308897Z","iopub.status.idle":"2022-04-26T05:50:18.322149Z","shell.execute_reply.started":"2022-04-26T05:50:18.308853Z","shell.execute_reply":"2022-04-26T05:50:18.321593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X1.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.323248Z","iopub.execute_input":"2022-04-26T05:50:18.323645Z","iopub.status.idle":"2022-04-26T05:50:18.328168Z","shell.execute_reply.started":"2022-04-26T05:50:18.323614Z","shell.execute_reply":"2022-04-26T05:50:18.327436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2 = pd.DataFrame(miscore)\narr2 = np.array(data2.index)\n\nfeature2 = []\n\nfor fea in arr2:\n    if data2.loc[fea,'MISCORE'] > 0.15:\n        feature2.append(fea)\n    else:\n        pass\n    \nfeature2","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.329425Z","iopub.execute_input":"2022-04-26T05:50:18.329785Z","iopub.status.idle":"2022-04-26T05:50:18.341746Z","shell.execute_reply.started":"2022-04-26T05:50:18.329753Z","shell.execute_reply":"2022-04-26T05:50:18.341172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combining all transformd data and creating one single dataframe for model traning","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.342637Z","iopub.execute_input":"2022-04-26T05:50:18.343302Z","iopub.status.idle":"2022-04-26T05:50:18.350484Z","shell.execute_reply.started":"2022-04-26T05:50:18.343259Z","shell.execute_reply":"2022-04-26T05:50:18.349844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature3 = ['grlivperfirstflr','Porchtypes','2nd_flr','Totalbath','MeanpriceNBH']","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.351532Z","iopub.execute_input":"2022-04-26T05:50:18.35178Z","iopub.status.idle":"2022-04-26T05:50:18.362058Z","shell.execute_reply.started":"2022-04-26T05:50:18.351747Z","shell.execute_reply":"2022-04-26T05:50:18.360951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. K-means clustering","metadata":{}},{"cell_type":"code","source":"# we will cluster houses based on area ocuupied by various floors and basement\n\nfeat = ['GrLivArea','GarageArea','TotalBsmtSF','1stFlrSF','2ndFlrSF']\n\ndef clusters(df):\n    X = df.copy()\n    X_scaled = (X - X.mean(axis=0))/X.std(axis=0)\n    kmeans = KMeans(n_clusters=15, n_init=10, max_iter=400, random_state=0)\n    kmeans = kmeans.fit_predict(X_scaled)\n    X['clusters'] = np.array(kmeans)\n    return X\n\nclustering_df = clusters(num_df[feat])\n\nclustering_df","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.363125Z","iopub.execute_input":"2022-04-26T05:50:18.36366Z","iopub.status.idle":"2022-04-26T05:50:18.606099Z","shell.execute_reply.started":"2022-04-26T05:50:18.363629Z","shell.execute_reply":"2022-04-26T05:50:18.605405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df['SalePrice']\nfeat = ['GrLivArea','GarageArea','TotalBsmtSF','1stFlrSF','2ndFlrSF']\n# plotting clusters and its significance on our target\n\nfor idx,col in enumerate(feat):\n    plt.figure(idx, figsize=(6,6))\n    sns.relplot(x=col,\n            y=y, \n            hue='clusters',\n            kind='scatter',\n            palette='deep',\n            data=clustering_df)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:18.612302Z","iopub.execute_input":"2022-04-26T05:50:18.612632Z","iopub.status.idle":"2022-04-26T05:50:23.715298Z","shell.execute_reply.started":"2022-04-26T05:50:18.6126Z","shell.execute_reply":"2022-04-26T05:50:23.71449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2 = clustering_df.copy()\ndata2['Neighbor'] = df['Neighborhood']\ndata2['Salep'] = df['SalePrice']\n\n# plotting using facet grid categorising via neighborhood\n\ng = sns.FacetGrid(data2, col='Neighbor',height= 5,\n                aspect= 1,\n                col_wrap=3,\n                palette='deep')\ng.map_dataframe(sns.scatterplot,\n                x='GrLivArea', \n                y='Salep', \n                hue='clusters')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:23.716595Z","iopub.execute_input":"2022-04-26T05:50:23.716897Z","iopub.status.idle":"2022-04-26T05:50:32.289196Z","shell.execute_reply.started":"2022-04-26T05:50:23.716857Z","shell.execute_reply":"2022-04-26T05:50:32.288199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training dataset preparation","metadata":{}},{"cell_type":"code","source":"# ccategorical dataframe and numerical dataframe\n\nd1 = X1[feature2]\nd = num_df[feature1+feature3]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:32.290459Z","iopub.execute_input":"2022-04-26T05:50:32.290797Z","iopub.status.idle":"2022-04-26T05:50:32.297905Z","shell.execute_reply.started":"2022-04-26T05:50:32.290757Z","shell.execute_reply":"2022-04-26T05:50:32.297092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalising data frame\nd2 = d - d.mean(axis=0)/d.std(axis=0)\n\n# concating dataframes d1 and d2\n\nX = d2.join(d1, how='left')\nX = round(X,1)\nX = X.astype('int')\ny = df['SalePrice']\n\n# splitting train and validation dataset\n\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, train_size=0.8, \n                                                      test_size=0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:32.299179Z","iopub.execute_input":"2022-04-26T05:50:32.299913Z","iopub.status.idle":"2022-04-26T05:50:32.324877Z","shell.execute_reply.started":"2022-04-26T05:50:32.299867Z","shell.execute_reply":"2022-04-26T05:50:32.324085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Hyperparamters tuning and models training","metadata":{}},{"cell_type":"code","source":"def results(results):\n    print('Best Params {}\\n'.format(results.best_params_))\n    print('Best Estimator {}\\n'.format(results.best_estimator_))\n    \n    meanscore = results.cv_results_['mean_test_score']\n    stdscore  = results.cv_results_['std_test_score']\n    params = results.cv_results_['params']\n    for mean, std, param in zip(meanscore,stdscore,params):\n        print('{} (+/-{}) for {}'.format(round(mean),round(std),param))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:32.326022Z","iopub.execute_input":"2022-04-26T05:50:32.326251Z","iopub.status.idle":"2022-04-26T05:50:32.332516Z","shell.execute_reply.started":"2022-04-26T05:50:32.326225Z","shell.execute_reply":"2022-04-26T05:50:32.331607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mlp = MLPRegressor()\n\n#params = {'hidden_layer_sizes':[(100,),(150,2)],\n#          'activation':['identity','tanh','relu'],\n #         'solver':['lbfgs','sgd','adam'],\n #         'learning_rate':['constant','invscaling','adaptive'],\n  #        'max_iter':[500,1000]\n  #        }\n\n#cv1 = GridSearchCV(mlp, params, cv=5, scoring='neg_mean_absolute_error')\n#cv1.fit(X_train,y_train)\n\n#results(cv1)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:32.333716Z","iopub.execute_input":"2022-04-26T05:50:32.333976Z","iopub.status.idle":"2022-04-26T05:50:32.346785Z","shell.execute_reply.started":"2022-04-26T05:50:32.333949Z","shell.execute_reply":"2022-04-26T05:50:32.345942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will train first model via stochastic gradient descent regressor\n\nsgd = SGDRegressor()\nparams = {'loss': ['squared_loss','huber'],\n          'max_iter': [500,1000,1500],\n          'learning_rate': ['constant', 'optimal', 'invscaling'],\n          'penalty': ['l2','l1','elasticnet']\n          }\n\ncv = GridSearchCV(sgd, params, cv=5, scoring='neg_mean_absolute_error')\ncv.fit(X_train, y_train)\n\nresults(cv)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:32.348472Z","iopub.execute_input":"2022-04-26T05:50:32.348787Z","iopub.status.idle":"2022-04-26T05:50:46.30013Z","shell.execute_reply.started":"2022-04-26T05:50:32.348755Z","shell.execute_reply":"2022-04-26T05:50:46.299345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using random forest regressor\n\nrfr = RandomForestRegressor()\n\nparams = {'n_estimators':[100,200,500],\n          'max_depth':[5,8,10,15,20],\n          'max_leaf_nodes':[50,100,150]\n         }\n\ncv1 = GridSearchCV(rfr, params, cv=5, scoring = 'neg_mean_absolute_error')\ncv1.fit(X_train,y_train)\n\nresults(cv1)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:50:46.301229Z","iopub.execute_input":"2022-04-26T05:50:46.30144Z","iopub.status.idle":"2022-04-26T05:55:43.291712Z","shell.execute_reply.started":"2022-04-26T05:50:46.301415Z","shell.execute_reply":"2022-04-26T05:55:43.290833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using XGB algoritham\n\nxgb = XGBRegressor()\n\nparams = {'n_estimators':[50,100,500,1000],\n          'max_depth':[3,4,5],\n          'learning_rate':[0.01,0.5,0.8]}\n\ncv2 = GridSearchCV(xgb, params, cv=5, scoring='neg_mean_absolute_error')\ncv2.fit(X_train,y_train)\n\nresults(cv2)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:55:43.292918Z","iopub.execute_input":"2022-04-26T05:55:43.293154Z","iopub.status.idle":"2022-04-26T05:59:50.103562Z","shell.execute_reply.started":"2022-04-26T05:55:43.293125Z","shell.execute_reply":"2022-04-26T05:59:50.102782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using svr algoritham \n\n#svr = SVR()\n\n#params = {'kernel':['rbf','poly','linear'],\n#          'degree':[3,4,5],\n #         'C':[0.5,1,5]}\n\n#cv3 = GridSearchCV(svr, params, cv=5, scoring='neg_mean_absolute_error')\n#cv3.fit(X_train,y_train)\n\n#results(cv3)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:59:50.104944Z","iopub.execute_input":"2022-04-26T05:59:50.10525Z","iopub.status.idle":"2022-04-26T05:59:50.110304Z","shell.execute_reply.started":"2022-04-26T05:59:50.105212Z","shell.execute_reply":"2022-04-26T05:59:50.10935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using linear regression\n\nlr = LinearRegression()\n\nlr.fit(X_train,y_train)\n\npreds = lr.predict(X_valid)\n\nmae = mean_absolute_error(y_valid,preds)\n\nprint(\"Mean absolute error: \", mae)\nprint(lr.coef_)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:59:50.111825Z","iopub.execute_input":"2022-04-26T05:59:50.112125Z","iopub.status.idle":"2022-04-26T05:59:50.13894Z","shell.execute_reply.started":"2022-04-26T05:59:50.112086Z","shell.execute_reply":"2022-04-26T05:59:50.138392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ridge regression with l2 regularization\n\nrdg = Ridge()\n\nparams = {'alpha': [0.0001,0.001,0.01,0.5,1,1.5]}\n\ncv3 = GridSearchCV(rdg, params, cv=5, scoring='neg_mean_absolute_error')\ncv3.fit(X_train,y_train)\n\nresults(cv3)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:59:50.139736Z","iopub.execute_input":"2022-04-26T05:59:50.139931Z","iopub.status.idle":"2022-04-26T05:59:50.400803Z","shell.execute_reply.started":"2022-04-26T05:59:50.139907Z","shell.execute_reply":"2022-04-26T05:59:50.399842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From above models our best models turn out to be randomforest and xtreame gradient boosting.\n\n> We will test our models on validation dataset.\n\n> We can notice that our tree based models are performing better than linear models. this is because our dataset contains lot of outliars that we haven't removed, instead we tried to normalize and cluster data.\n\n> Due to cluatering dataset, and having multiple categorical features our dataset is prepared for tree based model than linear models.","metadata":{}},{"cell_type":"markdown","source":"# 6. Evaluting results on validation dataset","metadata":{}},{"cell_type":"code","source":"# evaluting validation model\n\npre1 = cv1.predict(X_valid)\npre2 = cv2.predict(X_valid)\n\n# mae\nmae1 = mean_absolute_error(y_valid,pre1)\nmae2 = mean_absolute_error(y_valid,pre2)\n\nprint(\"MAE of RandomForest model:\",mae1)\n\nprint(\"MAE of XGB model: \",mae2)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T05:59:50.406697Z","iopub.execute_input":"2022-04-26T05:59:50.409388Z","iopub.status.idle":"2022-04-26T05:59:50.509611Z","shell.execute_reply.started":"2022-04-26T05:59:50.409331Z","shell.execute_reply":"2022-04-26T05:59:50.508669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> As you can see mean absolute error of XGB model is less than the randomforest model.\n\n> we can learn here that Xgboost is far more accurate and reliable than any other models that we have used in this project.\n\n> so the conclusion is use Xgboost model as your frindly companion than any other model. Ps. cheers","metadata":{}}]}