{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Before Proceeding into the depth of notebook ,have a look at the given fastAI useful Links.These are useful because in this house price data we are dealing with Categorical Dataset and categorical embeddings\n### http://docs.fast.ai/tabular.html\n### https://www.fast.ai/2018/04/29/categorical-embeddings/\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv' ,usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n    print(\"Column names {} and Unique Values are {}\".format(i,len(df[i].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\ndatetime.datetime.now().year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will create Derived Feature i.e Total Years ,we dont want YearBuilt \ndf['Total Years']=datetime.datetime.now().year-df['YearBuilt']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('YearBuilt',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Creating Categorical Variables\ncat_feat=[\"MSSubClass\",\"MSZoning\",\"Street\",\"LotShape\"]\nout_feat=\"SalePrice\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Unique Values of MSSubClass now we will conert in categorical variable and label encoding\n\nfrom sklearn.preprocessing import LabelEncoder\nlbl_encoders={}\nlbl_encoders[\"MSSubClass\"]=LabelEncoder()\nlbl_encoders[\"MSSubClass\"].fit_transform(df[\"MSSubClass\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl_encoders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlbl_encoders={}\nfor feature in cat_feat:\n    lbl_encoders[feature]=LabelEncoder()\n    df[feature]=lbl_encoders[feature].fit_transform(df[feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Stacking and converting into Tensors\ncat_feat=np.stack([df[\"MSSubClass\"],df[\"MSZoning\"],df[\"Street\"],df[\"LotShape\"]],1)\ncat_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert numpy to Tensors\n# Categorical Features cannot be converted to Float\nimport torch\ncat_feat= torch.tensor(cat_feat, dtype=torch.int64)\ncat_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### create continuous Variable\ncont_feat=[]\nfor i in df.columns:\n    if i in [\"MSSubClass\",\"MSZoning\",\"Street\",\"LotShape\",\"SalePrice\"]:\n        pass\n    else:\n        cont_feat.append(i)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Stacking continuous variable to a tensor\ncont_values=np.stack([df[i].values for i in cont_feat],axis=1)\ncont_values=torch.tensor(cont_values,dtype=torch.float)\ncont_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_values.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### dependent Feature\ny=torch.tensor(df['SalePrice'].values,dtype=torch.float).reshape(-1,1)   ##converting to 2D feature\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feat.shape,cont_values.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['MSSubClass'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Embedding Size For Categorical columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_dims=[len(df[col].unique()) for col in [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]]\ncat_dims","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thumb Rule says--Output dimension ahould be set based on the input variable \n#The formula is (min(50,featur_dimension/2))\nembedding_dims=[(x,min(50,(x+1)//2)) for x in cat_dims]\nembedding_dims","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nembed_representation=nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dims])\nembed_representation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_featz=cat_feat[:4]\ncat_featz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows',500)\nembedding_val=[]\nfor i,e in enumerate(embed_representation):               ## e is responsible for converting value to Vector\n    \n    embedding_val.append(e(cat_feat[:,i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stacking should be Column Wise So we will be using Concatination Operation using Embedding Value\n\nz=torch.cat(embedding_val,1)            # So now all are stacked in one row\nz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will apply Dropout layer which will help in avoiding Overfitting \n#After executing Some of the values become 0.So I am dropping 40% values\ndropout=nn.Dropout(.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_embed=dropout(z)\nfinal_embed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Create a Feed Forward Neural network\n\nimport torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nclass FeedForwardNN(nn.Module):\n    \n    def __init__(self,embedding_dims,n_cont,out_sz,layers,p=0.5):\n        super().__init__()\n        self.embeds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dims])\n        self.emb_drop = nn.Dropout(p)\n        self.bn_cont = nn.BatchNorm1d(n_cont)\n        \n        layerlist=[]\n        n_emb= sum(out for inp,out in embedding_dims)                    ### calculate the total dimension of embedding layer\n        n_in= n_emb + n_cont\n        \n        for i in layers:\n            layerlist.append(nn.Linear(n_in,i))\n            layerlist.append(nn.ReLU(inplace=True))\n            layerlist.append(nn.BatchNorm1d(i))\n            layerlist.append(nn.Dropout(p))\n            n_in=i\n       \n        layerlist.append(nn.Linear(layers[-1],out_sz))\n        \n        self.layers=nn.Sequential(*layerlist)\n     \n    def forward(self,x_cat,x_cont):\n        embeddings=[]\n        for i,e in enumerate(self.embeds):\n            embeddings.append(e(x_cat[:,i]))\n        x= torch.cat(embeddings,1)                      ## concatinating the embeddings and applying Dropout\n        x= self.emb_drop(x)\n    \n        x_cont= self.bn_cont(x_cont)\n        x= torch.cat([x,x_cont], 1)\n        x= self.layers(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(100)\nmodel=FeedForwardNN(embedding_dims, len(cont_feat),1,[100,50],p=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define Loss and Optimizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_func= nn.MSELoss()       ## Convert into RMSE later\noptimizer= torch.optim.Adam(model.parameters(),lr=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_values.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train test split\n\nbatch_size=1200\ntest_size= int(batch_size*0.15)\ntrain_categorical=  cat_feat[:batch_size-test_size]\ntest_categorical= cat_feat[batch_size-test_size:batch_size]\ntrain_cont= cont_values[:batch_size-test_size]\ntest_cont= cont_values[batch_size-test_size:batch_size]\ny_train= y[:batch_size-test_size]\ny_test= y[batch_size-test_size:batch_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_categorical),len(test_categorical),len(train_cont),len(test_cont),len(y_train),len(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nepochs=5000\nfinal_losses=[]\nfor i in range(epochs):\n    i=i+1\n    y_pred= model(train_categorical,train_cont)\n    loss= torch.sqrt(loss_func(y_pred,y_train))     ## RMSE\n    final_losses.append(loss)\n    if i%10==1:\n        print(\"Epoch number: {} and the Loss: {}\".format(i,loss.item()))\n    optimizer.zero_grad()\n    loss.backward()         ##back propogation\n    optimizer.step()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.plot(range(epochs),final_losses)\nplt.ylabel('RMSE loss')\nplt.xlabel('Epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Validate the test data\ny_pred=\"\"\nwith torch.no_grad():\n    y_pred= model(test_categorical,test_cont)\n    loss=torch.sqrt(loss_func(y_pred,y_test))\n    \nprint(\"RMSE: {}\" .format(loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_verify= pd.DataFrame(y_test.tolist(),columns=[\"test\"])\ndata_predicted=pd.DataFrame(y_pred.tolist(),columns=[\"Prediction\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_output=pd.concat([data_verify,data_predicted],axis=1)\nfinal_output[\"Difference\"]= final_output['test']-final_output['Prediction']\nfinal_output.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Svaing the model\n## Save the model\ntorch.save(model,'HousePrice.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict,'HouseWeights.pt')           ## state_dict helps in saving Weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Loading the saved Model\nemb_size=[(15,8),(5,3),(2,1),(4,2)]\nmodel1= FeedForwardNN(emb_size,5,1,[100,50],p=0.4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.eval","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Thankyou for visiting the kernel. I will be happy if you find this useful .Please leave an upvote which is a kind of motivation.**\n\n### I have tried to make the useful codes understandable by marking the comments still anything to learn or add .please feel free to do so in comments.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}