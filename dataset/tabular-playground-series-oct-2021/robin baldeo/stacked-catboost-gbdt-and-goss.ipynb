{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn.model_selection as ms\nimport warnings\nwarnings.simplefilter(\"ignore\", UserWarning)\nfrom sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom collections import namedtuple\nimport sys\nnp.set_printoptions(threshold=sys.maxsize)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:49:15.347733Z","iopub.execute_input":"2021-10-14T23:49:15.347988Z","iopub.status.idle":"2021-10-14T23:49:15.354131Z","shell.execute_reply.started":"2021-10-14T23:49:15.347961Z","shell.execute_reply":"2021-10-14T23:49:15.353079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Introduction\nMy approach to this monthâ€™s challenge was to use 3 algorithms. I used the GBDT, GOSS, and CatBoost and stack them together. There were 10 folds used where each fold was weighted by the validation AUC score. This output was collected along with the prediction on the test data. This information was then passed into a secondary model ","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation\nThe method below is the primary data preparation step used to compress the original dataset read by pandas. ","metadata":{}},{"cell_type":"code","source":"\ndef reduce_df(df):\n\n    print(f\"orginal dataset :{df.memory_usage().sum() / 1024 ** 2} mb\")\n    for i in df.columns:\n        col_type = df[i].dtypes\n\n        if str(col_type)[0:1] in [\"i\", \"f\"]:\n            col_min, col_max = np.min(df[i]), np.max(df[i])\n            if str(col_type)[0:1] == \"i\":\n                for j in [np.int8,np.int16,np.int32, np.int64]:\n                    if col_min > np.iinfo(j).min and col_max < np.iinfo(j).max:\n                        df[i] = df[i].astype(j)\n                        break\n            else:\n                for j in [np.float16,np.float32,np.float64]:\n                    if col_min > np.finfo(j).min and col_max < np.finfo(j).max:\n                        df[i] = df[i].astype(j)\n                        break\n\n    print(f\"dataset reduced to :{df.memory_usage().sum() / 1024 ** 2} mb\")\n    print()\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:49:20.815739Z","iopub.execute_input":"2021-10-14T23:49:20.816444Z","iopub.status.idle":"2021-10-14T23:49:20.825468Z","shell.execute_reply.started":"2021-10-14T23:49:20.816404Z","shell.execute_reply":"2021-10-14T23:49:20.82453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_df(pd.read_csv(\"../input/tabular-playground-series-oct-2021/train.csv\").set_index(\"id\"))\ntest_o = reduce_df(pd.read_csv(\"../input/tabular-playground-series-oct-2021/test.csv\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T23:49:27.280667Z","iopub.execute_input":"2021-10-14T23:49:27.281145Z","iopub.status.idle":"2021-10-14T23:51:59.472547Z","shell.execute_reply.started":"2021-10-14T23:49:27.281105Z","shell.execute_reply":"2021-10-14T23:51:59.471086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train[\"target\"]\nx = train.drop(columns = [\"target\"])\ntest = test_o.drop(columns=[\"id\"])\n\n\nfolds = 10\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters\nAll hyperparameters were derived using Optuna. I removed the execution because this hyperparameter search took some time to run. ","metadata":{}},{"cell_type":"code","source":"\n\ngbdt_para = {'n_jobs':-1, 'n_estimators': 847, 'max_depth': 7, 'learning_rate': 0.04617423130344099, 'lambda_l1': 1.6029632425074436, 'lambda_l2': 0.0010928490115681689, 'num_leaves': 124, 'min_child_samples': 93, 'feature_fraction': 0.7917548593828119, 'bagging_fraction': 0.96375720421119, 'bagging_freq': 3}\ngoss_para = {\"boosting_type\": 'goss','n_jobs':-1,'n_estimators': 888, 'max_depth': 3, 'lambda_l1': 0.045547053858182196, 'lambda_l2': 1.290891976923166, 'num_leaves': 614, 'min_child_samples': 261, 'min_child_weight': 15.811750102552908}\ncat_para = {'colsample_bylevel': 0.05606508594613661, 'depth': 4, 'learning_rate': 0.3840012528742531, 'bootstrap_type': 'Bernoulli', 'subsample': 0.645075461245303}\n\ngbdt_ = LGBMClassifier(**gbdt_para)\ngoss_ = LGBMClassifier(**goss_para)\ncat_ = CatBoostClassifier(**cat_para)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1\n\nIn this step meta model was generated. Using the 3 algorithms outlined in the introduction. Ten folds were used, and for each fold there was a AUC score recorded. These scores were used after the last fold as weighted averages for each fold. This process was repeated for all 3 models. The meta data was stored into a NumPy array. Also, the prediction for each model was also stored into a NumPy array. \n","metadata":{}},{"cell_type":"code","source":"models_lst = []\nmodels = namedtuple(\"models\", \"ind type fit_\")\nmodels_lst.append(models(ind = 0, type= \"gbdt\", fit_ = gbdt_))\nmodels_lst.append(models(ind = 1, type=\"goss\", fit_=goss_))\nmodels_lst.append(models(ind = 2, type=\"cat\", fit_=cat_))\n\n\ndf_split = ms.StratifiedKFold(n_splits=folds, shuffle=True, random_state=0)\ntrain_meta_x = np.zeros((len(train.index), 3))\ntrain_meta_y = np.zeros((len(train.index), 3))\nweights = np.zeros((folds, 3))\nfold_score = np.zeros((folds, 3))\n\n\nfold_pred_cv = np.zeros((len(test.index) , folds))\nfold_pred = np.zeros((len(test.index), 3))\n\nfor m in models_lst:\n\n    start = 0\n    end = 0\n\n    for counter, (trn, val) in enumerate(df_split.split(x, y)):\n\n        end += len(val)\n        mod_ = m.fit_.fit(x.iloc[trn, :].values, y.iloc[trn])\n        meta_pred = mod_.predict_proba(x.iloc[val, :])[:, 1]\n        fold_pred_cv[:, counter] = mod_.predict_proba(test.values)[:, 1]\n        train_meta_x[start:end, m.ind] = meta_pred\n        train_meta_y[start:end, m.ind] = y.iloc[val]\n\n        weights[counter, m.ind] = roc_auc_score(y.iloc[val], meta_pred)\n        fold_score[counter, m.ind] = weights[counter, m.ind]\n        print(counter)\n\n        if counter == folds -1:\n\n            weights[:, m.ind] = weights[:, m.ind]/np.sum(weights[:, m.ind], axis=0)\n            fold_pred[:,m.ind] = np.dot(fold_pred_cv,weights[:, m.ind])\n        start += len(val)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(fold_score)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2\n\nBelow is the final step. Below the meta data is used with 10 folds to create a weighted array so the folds with a low AUC with have a lower effect than the folds with a higher AUC score.\n","metadata":{}},{"cell_type":"code","source":"score_weight = np.zeros((folds, 1))\nmeta_pred = np.zeros((len(fold_pred), folds))\nfinal_data = np.zeros((len(fold_pred), 1))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndf_split = ms.StratifiedKFold(n_splits=folds, shuffle=True, random_state=45)\nfor counter, (trn, val) in enumerate(df_split.split(train_meta_x, train_meta_y[:,0])):\n    model = SGDClassifier(max_iter=10000, loss='log')\n    model.fit(train_meta_x[trn, :], train_meta_y[trn, 0])\n    meta_pred[:,counter] = model.predict_proba(fold_pred)[:, 1]\n    pred = model.predict_proba(train_meta_x[val, :])[:, 1]\n    score_weight[counter] = roc_auc_score(train_meta_y[val, 0], pred)\n    if counter == folds - 1:\n        score_weight = score_weight / np.sum(score_weight, axis=0)\n        final_data = np.dot(meta_pred, score_weight)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Output","metadata":{}},{"cell_type":"code","source":"\nfinal = pd.DataFrame(test_o[\"id\"])\nfinal = final.merge(pd.DataFrame(final_data), right_index=True, left_index=True)\n\nfinal.columns = [\"id\", \"target\"]\nfinal.to_csv(\"sub.csv\", index=False)\n","metadata":{},"execution_count":null,"outputs":[]}]}