{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VotingClassifier + Power Averaging - TPS Oct 2021","metadata":{}},{"cell_type":"markdown","source":"## What is Power Averaging?","metadata":{}},{"cell_type":"markdown","source":"The main idea behind Power Averaging is that we want **highly correlated** submissions to combine to get a better AUC.\n\nBut why does Power Averaging work?\n1. AUC judges score based on ranking only. Example: (0,1,2) has the same AUC as (0,50,100)\n2. Power Averaging **amplifies** the distance between probabilities.\n3. This makes the order of ranks clearer = better AUC.\n\nIn case you want more explanation on Power Averaging, check out my previous notebooks:\n* [Simple Power Averaging](https://www.kaggle.com/edrickkesuma/power-averaging-is-your-friend)\n* [In depth Power Averaging](https://www.kaggle.com/edrickkesuma/in-depth-power-averaging-0-81848)","metadata":{}},{"cell_type":"markdown","source":"## What is VotingClassifier?","metadata":{}},{"cell_type":"markdown","source":"VotingClassifier takes a group of classifiers/models and **averages** out their predictions.\n\nRemember that we need **highly correlated** submissions to get a good AUC. \n\nThe easiest way to get them is to just change the **random_state** when creating each model. This way, the model makes predictions differently but they are still close to each other = high correlation.\n\nYou create several of these models with different random states and put them in VotingClassifier. ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datatable as dt\n\nfrom xgboost import XGBClassifier\nimport time\nfrom sklearn.ensemble import VotingClassifier\n\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-16T04:36:11.269586Z","iopub.execute_input":"2021-10-16T04:36:11.269903Z","iopub.status.idle":"2021-10-16T04:36:11.363242Z","shell.execute_reply.started":"2021-10-16T04:36:11.269823Z","shell.execute_reply":"2021-10-16T04:36:11.362572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read in the data","metadata":{}},{"cell_type":"code","source":"%%time\n\ntrain_data = dt.fread('../input/tabular-playground-series-oct-2021/train.csv')\ntest_data = dt.fread('../input/tabular-playground-series-oct-2021/test.csv')\n\nprint(train_data.shape, test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:11.429853Z","iopub.execute_input":"2021-10-16T04:36:11.43037Z","iopub.status.idle":"2021-10-16T04:36:41.722728Z","shell.execute_reply.started":"2021-10-16T04:36:11.43033Z","shell.execute_reply":"2021-10-16T04:36:41.721947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Credit: https://www.kaggle.com/hardyxu52/tps-oct-2021-reduce-memory-usage-but-faster\nfor i, col in enumerate(train_data):\n    if col.type.name == 'float64':\n        train_data[:,i] = dt.as_type(col, 'float32')\n\nfor i, col in enumerate(test_data):\n    if col.type.name == 'float64':\n        test_data[:,i] = dt.as_type(col, 'float32')\n\ntrain_data = train_data.to_pandas()\ntest_data = test_data.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:41.724922Z","iopub.execute_input":"2021-10-16T04:36:41.725441Z","iopub.status.idle":"2021-10-16T04:36:45.198372Z","shell.execute_reply.started":"2021-10-16T04:36:41.725401Z","shell.execute_reply":"2021-10-16T04:36:45.196715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.set_index('id', drop=True)\ntest_data = test_data.set_index('id', drop=True)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:45.199791Z","iopub.execute_input":"2021-10-16T04:36:45.200039Z","iopub.status.idle":"2021-10-16T04:36:45.840244Z","shell.execute_reply.started":"2021-10-16T04:36:45.200005Z","shell.execute_reply":"2021-10-16T04:36:45.839501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# Turn True/False into 0s and 1s\nbool_cols_train = []\nfor i, col in enumerate(train_data.columns):\n    if train_data[col].dtypes == bool:\n        bool_cols_train.append(i)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:45.841719Z","iopub.execute_input":"2021-10-16T04:36:45.841956Z","iopub.status.idle":"2021-10-16T04:36:45.859715Z","shell.execute_reply.started":"2021-10-16T04:36:45.841924Z","shell.execute_reply":"2021-10-16T04:36:45.859002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bool_cols_test = []\nfor i, col in enumerate(test_data.columns):\n    if test_data[col].dtypes == bool:\n        bool_cols_test.append(i)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:45.860815Z","iopub.execute_input":"2021-10-16T04:36:45.861076Z","iopub.status.idle":"2021-10-16T04:36:45.877635Z","shell.execute_reply.started":"2021-10-16T04:36:45.861042Z","shell.execute_reply":"2021-10-16T04:36:45.876814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[:, bool_cols_train] = train_data.iloc[:, bool_cols_train].astype(int)\ntest_data.iloc[:, bool_cols_test] = test_data.iloc[:, bool_cols_test].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:45.88061Z","iopub.execute_input":"2021-10-16T04:36:45.880812Z","iopub.status.idle":"2021-10-16T04:36:46.592349Z","shell.execute_reply.started":"2021-10-16T04:36:45.88079Z","shell.execute_reply":"2021-10-16T04:36:46.591599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train_data.drop('target', axis=1).columns\nlabel = 'target'","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:46.593473Z","iopub.execute_input":"2021-10-16T04:36:46.593886Z","iopub.status.idle":"2021-10-16T04:36:47.188512Z","shell.execute_reply.started":"2021-10-16T04:36:46.59385Z","shell.execute_reply":"2021-10-16T04:36:47.187679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_data[features].copy()\ny = train_data[label].copy()\nX_test = test_data.copy()\n\ndel train_data, test_data\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:47.191718Z","iopub.execute_input":"2021-10-16T04:36:47.191924Z","iopub.status.idle":"2021-10-16T04:36:48.537727Z","shell.execute_reply.started":"2021-10-16T04:36:47.191898Z","shell.execute_reply":"2021-10-16T04:36:48.537087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['std'] = X.std(axis=1)\nX['min'] = X.min(axis=1)\nX['max'] = X.max(axis=1)\nX['var'] = X.var(axis=1)\n\nX_test['std'] = X_test.std(axis=1)\nX_test['min'] = X_test.min(axis=1)\nX_test['max'] = X_test.max(axis=1)\nX_test['var'] = X_test.var(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:48.538889Z","iopub.execute_input":"2021-10-16T04:36:48.539291Z","iopub.status.idle":"2021-10-16T04:36:58.218781Z","shell.execute_reply.started":"2021-10-16T04:36:48.539253Z","shell.execute_reply":"2021-10-16T04:36:58.218058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create models + VotingClassifier","metadata":{}},{"cell_type":"markdown","source":"In an ideal situation, you could run each batch on a different kernel for for **parallel** training and predicting.","metadata":{}},{"cell_type":"code","source":"# Credit: https://www.kaggle.com/shenurisumanasekara/tabular-october-xgbclassifier-stepbystep\n# Set optimal hyperparameters\nparams = {\n    'max_depth': 6,\n    'n_estimators': 5500,\n    'subsample': 0.6000000000000001,\n    'colsample_bytree': 0.2,\n    'colsample_bylevel': 0.4,\n    'min_child_weight': 0.0475667709098205,\n    'reg_lambda': 50.33144833870577,\n    'reg_alpha': 0.01634917276171278,\n    'gamma': 5.507875585868313,\n    'booster': 'gbtree',\n    'eval_metric': 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'use_label_encoder': False\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batch 1\n\nxgb_clf1 = XGBClassifier(**params, random_state=1)\nxgb_clf2 = XGBClassifier(**params, random_state=2)\nxgb_clf3 = XGBClassifier(**params, random_state=3)\nxgb_clf4 = XGBClassifier(**params, random_state=4)\nxgb_clf5 = XGBClassifier(**params, random_state=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:58.238587Z","iopub.execute_input":"2021-10-16T04:36:58.238866Z","iopub.status.idle":"2021-10-16T04:36:59.064914Z","shell.execute_reply.started":"2021-10-16T04:36:58.238834Z","shell.execute_reply":"2021-10-16T04:36:59.064095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators=[('xgb1', xgb_clf1), \n            ('xgb2', xgb_clf2), \n            ('xgb3', xgb_clf3), \n            ('xgb4', xgb_clf4),\n            ('xgb5', xgb_clf5)\n           ]\n\nstart = time.time()\nprint(f'fitting ...')\nmodel = VotingClassifier(estimators=estimators, voting='soft', verbose=True)\nmodel.fit(X, y)\n\nprint('predicting ...')\nmodel_preds1 = model.predict_proba(X_test)[:, -1]\n\nelapsed = time.time() - start\nprint(f'elapsed time: {elapsed:.2f}sec\\n')\nprint('model_preds1 ready!')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:38:29.278693Z","iopub.execute_input":"2021-10-16T04:38:29.278949Z","iopub.status.idle":"2021-10-16T04:58:38.940281Z","shell.execute_reply.started":"2021-10-16T04:38:29.27892Z","shell.execute_reply":"2021-10-16T04:58:38.939058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batch 2\n\nxgb_clf6 = XGBClassifier(**params, random_state=6)\nxgb_clf7 = XGBClassifier(**params, random_state=7)\nxgb_clf8 = XGBClassifier(**params, random_state=8)\nxgb_clf9 = XGBClassifier(**params, random_state=9)\nxgb_clf10 = XGBClassifier(**params, random_state=10)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:59.166131Z","iopub.status.idle":"2021-10-16T04:36:59.166539Z","shell.execute_reply.started":"2021-10-16T04:36:59.16632Z","shell.execute_reply":"2021-10-16T04:36:59.16634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators=[('xgb6', xgb_clf6), \n            ('xgb7', xgb_clf7), \n            ('xgb8', xgb_clf8), \n            ('xgb9', xgb_clf9),\n            ('xgb10', xgb_clf10)\n           ]\n\nstart = time.time()\nprint(f'fitting ...')\nmodel = VotingClassifier(estimators=estimators, voting='soft', verbose=True)\nmodel.fit(X, y)\n\nprint('predicting ...')\nmodel_preds2 = model.predict_proba(X_test)[:, -1]\n\nelapsed = time.time() - start\nprint(f'elapsed time: {elapsed:.2f}sec\\n')\nprint('model_preds2 ready!')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:36:59.167953Z","iopub.status.idle":"2021-10-16T04:36:59.168373Z","shell.execute_reply.started":"2021-10-16T04:36:59.168153Z","shell.execute_reply":"2021-10-16T04:36:59.168173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batch 3\n\nxgb_clf11 = XGBClassifier(**params, random_state=11)\nxgb_clf12 = XGBClassifier(**params, random_state=12)\nxgb_clf13 = XGBClassifier(**params, random_state=13)\nxgb_clf14 = XGBClassifier(**params, random_state=14)\nxgb_clf15 = XGBClassifier(**params, random_state=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators=[('xgb11', xgb_clf11), \n            ('xgb12', xgb_clf12), \n            ('xgb13', xgb_clf13), \n            ('xgb14', xgb_clf14),\n            ('xgb15', xgb_clf15)\n           ]\n\nstart = time.time()\nprint(f'fitting ...')\nmodel = VotingClassifier(estimators=estimators, voting='soft', verbose=True)\nmodel.fit(X, y)\n\nprint('predicting ...')\nmodel_preds3 = model.predict_proba(X_test)[:, -1]\n\nelapsed = time.time() - start\nprint(f'elapsed time: {elapsed:.2f}sec\\n')\nprint('model_preds3 ready!')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check for correlation","metadata":{}},{"cell_type":"code","source":"import matplotlib as plt\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\ngroup_labels = ['batch1', 'batch2', 'batch3']\n\ndata = np.corrcoef([model_preds1, model_preds2, model_preds3])\nfig=px.imshow(data,x=group_labels, y=group_labels)\n\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Power averaging","metadata":{}},{"cell_type":"markdown","source":"The formula is **Final Predictions = (Predictions1^Power + Predictions2^Power + Predictions3^Power) / n_predictions**","metadata":{}},{"cell_type":"code","source":"sample_sub = pd.read_csv('../input/tabular-playground-series-oct-2021/sample_submission.csv')\nensemble = sample_sub.copy()\n\npower = 4\n\nensemble.loc[:,'target'] = (model_preds1**power + model_preds2**power + model_preds3**power)/3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Closing thoughts","metadata":{}},{"cell_type":"markdown","source":"This strategy carried me to 20th place last TPS. Though, it seems that it doesn't work that well on this dataset. Particularly because the correlations aren't as high.. \n\nThere might be potential for this to work if the model is trained differently. Eg. Changing learning rates and stacking from what I've seen.\n\nOpen to any suggestions.","metadata":{}}]}