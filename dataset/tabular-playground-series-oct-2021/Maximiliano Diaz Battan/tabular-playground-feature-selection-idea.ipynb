{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# <b> <span style='color:#808080'>- |</span> Explanation </b>\n\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">   \nThis is an idea on how to deal with so many features of this dataset. First we tried some feature selection method, to reduce the number of features, and keep only the best ones. I've try mutual information and Shap, I think Shap it's better. Then to stablish a baseline score, we train a model with the features selected, this score it's gonna be low in comparassion, but we're using only 20 features. After that you train another model with the features selected by Shap and the non selected features one by one, to see if anyone can add some \"info\" to predict the target value. And finaly we train a model with the features selected by Shap, and the other ones selected by the second model. </p>\n","metadata":{}},{"cell_type":"markdown","source":"# <b> <span style='color:#808080'>- |</span> Table of Contents</b>\n\n* [1-Libraries and data loading](#section-one)\n* [2-Feature management](#section-two)\n* [3-Baseline](#section-three)\n* [4-Comparison](#section-four)\n* [5-Final AUC with the selected features](#section-five)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# <b>1 <span style='color:#808080'>|</span> Libraries and Data loading</b>","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn import metrics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-19T18:33:13.253531Z","iopub.execute_input":"2021-11-19T18:33:13.253853Z","iopub.status.idle":"2021-11-19T18:33:13.614505Z","shell.execute_reply.started":"2021-11-19T18:33:13.253771Z","shell.execute_reply":"2021-11-19T18:33:13.613746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_parquet('../input/playgroundkfold/train_kfold_play_oct_orig.parquet')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:33:15.061297Z","iopub.execute_input":"2021-11-19T18:33:15.061565Z","iopub.status.idle":"2021-11-19T18:33:18.491224Z","shell.execute_reply.started":"2021-11-19T18:33:15.061535Z","shell.execute_reply":"2021-11-19T18:33:18.490415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# <b>2 <span style='color:#808080'>|</span> Feature management</b>\n\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\nThe process begins by separating the set of features to use in the analysis.\n</p>","metadata":{}},{"cell_type":"code","source":"features = [feature for feature in train.columns if feature not in ('id', 'kfold','target')]","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:33:20.671151Z","iopub.execute_input":"2021-11-19T18:33:20.671681Z","iopub.status.idle":"2021-11-19T18:33:20.677716Z","shell.execute_reply.started":"2021-11-19T18:33:20.671643Z","shell.execute_reply":"2021-11-19T18:33:20.676858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Starting feature len =  {len(features)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:33:21.577704Z","iopub.execute_input":"2021-11-19T18:33:21.578237Z","iopub.status.idle":"2021-11-19T18:33:21.584122Z","shell.execute_reply.started":"2021-11-19T18:33:21.578192Z","shell.execute_reply":"2021-11-19T18:33:21.583424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\nThe features down below were selected with the Shap study.\n</p>","metadata":{}},{"cell_type":"code","source":"shaped_features = ['f22','f179','f69','f58','f214','f78','f136','f156','f8','f3',\n                   'f77','f92','f19','f200','f18','f247','f12','f211','f43','f201']","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:35:37.623762Z","iopub.execute_input":"2021-11-19T18:35:37.624571Z","iopub.status.idle":"2021-11-19T18:35:37.629269Z","shell.execute_reply.started":"2021-11-19T18:35:37.624514Z","shell.execute_reply":"2021-11-19T18:35:37.628523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_to_comp = [feature for feature in features if feature not in shaped_features]","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:35:40.483158Z","iopub.execute_input":"2021-11-19T18:35:40.483851Z","iopub.status.idle":"2021-11-19T18:35:40.488448Z","shell.execute_reply.started":"2021-11-19T18:35:40.483813Z","shell.execute_reply":"2021-11-19T18:35:40.487299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Length of features to compare = {len(features_to_comp)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:56:16.481498Z","iopub.execute_input":"2021-11-19T18:56:16.481794Z","iopub.status.idle":"2021-11-19T18:56:16.487346Z","shell.execute_reply.started":"2021-11-19T18:56:16.481763Z","shell.execute_reply":"2021-11-19T18:56:16.486424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# <b>3 <span style='color:#808080'>|</span> Baseline</b>\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\nTo stablish a baseline I've calculate the AUC for a given fold. </p>","metadata":{}},{"cell_type":"code","source":"fold = 0 \n    \nX_train = train[train.kfold != fold].reset_index(drop=True)\nX_valid = train[train.kfold == fold].reset_index(drop=True)\n\ny_train = X_train['target'].values\ny_valid = X_valid['target'].values\n    \nX_train = X_train[shaped_features].values\nX_valid = X_valid[shaped_features].values\n\n# Model \nmodel = xgb.XGBClassifier(n_estimators = 20000, random_state=0, objective = 'binary:logistic',use_label_encoder=False,\n                          tree_method='gpu_hist', gpu_id=0,predictor=\"gpu_predictor\"\n                             )\nmodel.fit(X_train, y_train, early_stopping_rounds=20, eval_set=[(X_valid, y_valid)], eval_metric=['auc'],verbose=False) \n\npreds_valid = model.predict_proba(X_valid)[:,1]\nauc_baseline = metrics.roc_auc_score (y_valid, preds_valid)\n    \nprint(f'fold {fold} auc = {auc_baseline}')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:50:11.984325Z","iopub.execute_input":"2021-11-19T18:50:11.984852Z","iopub.status.idle":"2021-11-19T18:50:14.069402Z","shell.execute_reply.started":"2021-11-19T18:50:11.984815Z","shell.execute_reply":"2021-11-19T18:50:14.068652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# <b>4 <span style='color:#808080'>|</span> Comparison</b>\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\nNow in the comparison I'm going to do a loop over the non selected features to see at the end if anyone of them can add some value to improve the prediction. </p>","metadata":{}},{"cell_type":"code","source":"scores = dict()\n\n# Loop over all the non selected features\nfor feature in features_to_comp:\n    fold = 0 \n    \n    X_train = train[train.kfold != fold].reset_index(drop=True)\n    X_valid = train[train.kfold == fold].reset_index(drop=True)\n\n    y_train = X_train['target'].values\n    y_valid = X_valid['target'].values\n    \n    # Adding the non selected feature to train and valid \n    X_train = X_train[shaped_features+[feature]].values\n    X_valid = X_valid[shaped_features+[feature]].values\n\n    # Model \n    model = xgb.XGBClassifier(n_estimators = 20000, random_state=0, objective = 'binary:logistic',use_label_encoder=False,\n                             tree_method='gpu_hist', gpu_id=0,predictor=\"gpu_predictor\"\n                             )\n    model.fit(X_train, y_train, early_stopping_rounds=20, eval_set=[(X_valid, y_valid)], eval_metric=['auc'],verbose=False) \n\n    preds_valid = model.predict_proba(X_valid)[:,1]\n    auc = metrics.roc_auc_score (y_valid, preds_valid)\n    \n    scores[feature] = np.round(auc, 10)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:37:33.479334Z","iopub.execute_input":"2021-11-19T18:37:33.479597Z","iopub.status.idle":"2021-11-19T18:47:14.917547Z","shell.execute_reply.started":"2021-11-19T18:37:33.479568Z","shell.execute_reply":"2021-11-19T18:47:14.916792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\nConverting the dict with all the AUC features values to a dataframe\n</p>","metadata":{}},{"cell_type":"code","source":"scores_features_df = pd.DataFrame.from_dict(scores, orient='index').reset_index().rename(columns = {'index':'Feature', 0:f'AUC'})","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:48:16.555606Z","iopub.execute_input":"2021-11-19T18:48:16.555897Z","iopub.status.idle":"2021-11-19T18:48:16.564022Z","shell.execute_reply.started":"2021-11-19T18:48:16.555868Z","shell.execute_reply":"2021-11-19T18:48:16.56323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_features_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:48:19.771114Z","iopub.execute_input":"2021-11-19T18:48:19.771692Z","iopub.status.idle":"2021-11-19T18:48:19.787753Z","shell.execute_reply.started":"2021-11-19T18:48:19.771656Z","shell.execute_reply":"2021-11-19T18:48:19.787017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\nAdding the baseline score to perform the difference \n</p>","metadata":{}},{"cell_type":"code","source":"scores_features_df['Baseline AUC'] = auc_baseline","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:50:32.948743Z","iopub.execute_input":"2021-11-19T18:50:32.949384Z","iopub.status.idle":"2021-11-19T18:50:32.955187Z","shell.execute_reply.started":"2021-11-19T18:50:32.949346Z","shell.execute_reply":"2021-11-19T18:50:32.953754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_features_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:50:37.00329Z","iopub.execute_input":"2021-11-19T18:50:37.00372Z","iopub.status.idle":"2021-11-19T18:50:37.016461Z","shell.execute_reply.started":"2021-11-19T18:50:37.003688Z","shell.execute_reply":"2021-11-19T18:50:37.015561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\nFinally we compute the diffence between the baseline score and the feature added score, also we can set a thershold value to keep those features.</p>","metadata":{}},{"cell_type":"code","source":"scores_features_df['Difference'] =  scores_features_df['AUC'] - scores_features_df['Baseline AUC']","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:50:43.114247Z","iopub.execute_input":"2021-11-19T18:50:43.114525Z","iopub.status.idle":"2021-11-19T18:50:43.119948Z","shell.execute_reply.started":"2021-11-19T18:50:43.114493Z","shell.execute_reply":"2021-11-19T18:50:43.118962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.float_format', lambda x: '%.10f' % x) # Set standard notation instead scientific","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:50:43.186572Z","iopub.execute_input":"2021-11-19T18:50:43.18686Z","iopub.status.idle":"2021-11-19T18:50:43.190481Z","shell.execute_reply.started":"2021-11-19T18:50:43.186832Z","shell.execute_reply":"2021-11-19T18:50:43.189801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_features_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:50:45.23898Z","iopub.execute_input":"2021-11-19T18:50:45.239531Z","iopub.status.idle":"2021-11-19T18:50:45.249505Z","shell.execute_reply.started":"2021-11-19T18:50:45.239494Z","shell.execute_reply":"2021-11-19T18:50:45.248834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_features_df.to_csv('features_selected.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T11:07:42.42701Z","iopub.execute_input":"2021-11-18T11:07:42.427581Z","iopub.status.idle":"2021-11-18T11:07:42.438734Z","shell.execute_reply.started":"2021-11-18T11:07:42.427542Z","shell.execute_reply":"2021-11-18T11:07:42.4379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selec_features = list(scores_features_df[scores_features_df['Difference'] > 0.0001].Feature.values)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:51:04.373176Z","iopub.execute_input":"2021-11-19T18:51:04.373688Z","iopub.status.idle":"2021-11-19T18:51:04.380446Z","shell.execute_reply.started":"2021-11-19T18:51:04.373652Z","shell.execute_reply":"2021-11-19T18:51:04.379639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Length of the final set of features = {len(shaped_features+selec_features)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:52:20.909793Z","iopub.execute_input":"2021-11-19T18:52:20.910587Z","iopub.status.idle":"2021-11-19T18:52:20.915078Z","shell.execute_reply.started":"2021-11-19T18:52:20.910546Z","shell.execute_reply":"2021-11-19T18:52:20.914314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# <b>5 <span style='color:#808080'>|</span> Final AUC with the selected features</b>","metadata":{}},{"cell_type":"code","source":"fold = 0 \n    \nX_train = train[train.kfold != fold].reset_index(drop=True)\nX_valid = train[train.kfold == fold].reset_index(drop=True)\n\ny_train = X_train['target'].values\ny_valid = X_valid['target'].values\n    \nX_train = X_train[shaped_features+selec_features].values\nX_valid = X_valid[shaped_features+selec_features].values\n\n# Model \nmodel = xgb.XGBClassifier(n_estimators = 20000, random_state=0, objective = 'binary:logistic',use_label_encoder=False,\n                          tree_method='gpu_hist', gpu_id=0,predictor=\"gpu_predictor\"\n                             )\nmodel.fit(X_train, y_train, early_stopping_rounds=20, eval_set=[(X_valid, y_valid)], eval_metric=['auc'],verbose=False) \n\npreds_valid = model.predict_proba(X_valid)[:,1]\nauc_final = metrics.roc_auc_score (y_valid, preds_valid)\n    \nprint(f'fold {fold}, final auc = {auc_final}')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:51:22.922834Z","iopub.execute_input":"2021-11-19T18:51:22.923316Z","iopub.status.idle":"2021-11-19T18:51:29.452537Z","shell.execute_reply.started":"2021-11-19T18:51:22.923269Z","shell.execute_reply":"2021-11-19T18:51:29.451791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n<b> Insights:</b> By filtering all the features greater than 0.0001 (for example), we reduce the continuous feature size from 285 to 105, and the score increase from 0.8399 (with only the Shap features), to 0.8503. Also by selecting a reduce number of features, we shortening the training time, the overfitting, and we make a better model for unseen data.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">\n<b>I hope you found this interesting, if you have a question, suggestion, please let me know in the comments. Greetings to all!\n</b></p>","metadata":{}}]}