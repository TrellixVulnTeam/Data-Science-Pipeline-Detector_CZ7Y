{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =======================================================\n# TPS October 2021 - Baseline\n# =======================================================\n# Name: BÃ¡rbara Sulpis\n# Date: 01-oct-2021\n# Description: I want to run a basic model to see what is the base ROC value without doing any angineering\n# Python 3 - kaggle/python Docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nfrom sklearn.model_selection import train_test_split\n\n#Lgbm\nimport lightgbm as lgb\n\n# roc\nimport sklearn.metrics as metrics   # Para la curva ROC\nimport matplotlib.pyplot as plt     # Para la curva ROC\n\n\n# ---------------------------\n# Input data:\n# Go to file -> add or upload data -> \"Competition\" data tab and select the commpetition which you want to add the csv data data \"\n# files are available in the read-only \"../input/\" directory\n# ---------------------------\n#list =  os. getcwd()\n#print(list)\n#os. chdir(\"kaggle\") \n\nlist =  os. getcwd()\nprint(list) # shoud be in \"kaggle\" directory\n\n# I left this commented if you want to check that the files are there\n# i = 0\n# for subdir, dirs, files in os.walk('./'):\n#     for file in files:\n#         print(file)\n#         i+= 1\n#         if i>20: \n#             break\n\n\ndata = pd.read_csv(\"../input/tabular-playground-series-oct-2021/train.csv\")        \nsubm = pd.read_csv(\"../input/tabular-playground-series-oct-2021/test.csv\")        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-07T22:48:36.108404Z","iopub.execute_input":"2021-10-07T22:48:36.108712Z","iopub.status.idle":"2021-10-07T22:49:57.54071Z","shell.execute_reply.started":"2021-10-07T22:48:36.108635Z","shell.execute_reply":"2021-10-07T22:49:57.539557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Draw_ROC(y_test, preds, base_name):\n    fpr, tpr, threshold = metrics.roc_curve(y_test , preds)\n    roc_auc = metrics.auc(fpr, tpr)\n\n    plt.title('Receiver Operating Characteristic ('+ base_name+ ')')\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.6f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-07T22:58:55.790298Z","iopub.execute_input":"2021-10-07T22:58:55.790565Z","iopub.status.idle":"2021-10-07T22:58:55.797497Z","shell.execute_reply.started":"2021-10-07T22:58:55.79054Z","shell.execute_reply":"2021-10-07T22:58:55.796467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-10-07T22:59:02.182263Z","iopub.execute_input":"2021-10-07T22:59:02.182517Z","iopub.status.idle":"2021-10-07T22:59:02.283749Z","shell.execute_reply.started":"2021-10-07T22:59:02.182492Z","shell.execute_reply":"2021-10-07T22:59:02.283188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --------------------------------------------------------------------\n#     SPLIT IN TARGET AND DATA\n# --------------------------------------------------------------------\ny = data['target']\nX = data.drop(['id', 'target'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T22:59:07.657583Z","iopub.execute_input":"2021-10-07T22:59:07.659045Z","iopub.status.idle":"2021-10-07T22:59:08.006783Z","shell.execute_reply.started":"2021-10-07T22:59:07.658925Z","shell.execute_reply":"2021-10-07T22:59:08.006071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --------------------------------------------------------------------\n#     SPLIT TRAIN - TEST - VALIDATION  70%-15%-15%\n# --------------------------------------------------------------------\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T23:02:31.079183Z","iopub.execute_input":"2021-10-07T23:02:31.081329Z","iopub.status.idle":"2021-10-07T23:02:36.081804Z","shell.execute_reply.started":"2021-10-07T23:02:31.081256Z","shell.execute_reply":"2021-10-07T23:02:36.080352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------------------------------\n# LGBM Classification\n# -----------------------------------------\n\n# Use a parametrization that worked fine in some projects\nparams = {'colsample_bytree': 0.541999392404749, \n          'min_child_samples': 430, \n          'min_child_weight': 10.0, \n          'num_leaves': 44,\n          'reg_alpha': 1, \n          'reg_lambda': 100, \n          'subsample': 0.7653033041096617}\n\n#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\nclf = lgb.LGBMClassifier(max_depth=-1, silent=True, metric='None', n_jobs=-1, n_estimators=5000, random_state=314)\n\n# This allows us to avoid overtraining and we do not need to optimise the number of trees\nfit_params={\"early_stopping_rounds\":30, \n            \"eval_metric\" : 'auc', \n            \"eval_set\" : [(X_test, y_test)],\n            'eval_names': ['valid'],\n            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n            'verbose': 100,\n            'categorical_feature': 'auto'}\n\n# opt_parameters = {\n#     'colsample_bytree': params['colsample_bytree'], \n#     'min_child_samples': params['min_child_samples'], \n#     'min_child_weight': params['min_child_weight'], \n#     'num_leaves': params['num_leaves'], \n#     'reg_alpha': params['reg_alpha'], \n#     'reg_lambda': params['reg_lambda'], \n#     'subsample': params['subsample']\n# }\n\n#Configure from the HP optimisation\n#clf_final = lgb.LGBMClassifier(**gs.best_estimator_.get_params())\n\n#Configure locally from hardcoded values\nclf_final = lgb.LGBMClassifier(**clf.get_params())\n\n#set optimal parameters\nclf_final.set_params(**params)\n\n#Train the final model with learning rate decay\nclf_final.fit(X_train, y_train, **fit_params )  #, callbacks=[lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_0995)])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T23:02:41.525715Z","iopub.execute_input":"2021-10-07T23:02:41.526825Z","iopub.status.idle":"2021-10-07T23:06:06.358116Z","shell.execute_reply.started":"2021-10-07T23:02:41.526797Z","shell.execute_reply":"2021-10-07T23:06:06.357107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------------\n#  ROC : TRAIN\n# ---------------------------------------\n\n# calculate the fpr and tpr for all thresholds of the classification\ny_predict_xgr = clf_final.predict_proba(X_train)\npreds = y_predict_xgr  [:,1]   # CLF_pred es la variable con las predicciones de probabilidad\nbase_name = 'TRAIN'\nDraw_ROC(y_train, preds, base_name)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T23:16:22.512987Z","iopub.execute_input":"2021-10-07T23:16:22.513316Z","iopub.status.idle":"2021-10-07T23:16:33.574339Z","shell.execute_reply.started":"2021-10-07T23:16:22.513291Z","shell.execute_reply":"2021-10-07T23:16:33.573094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------------\n#  ROC : TEST\n# ---------------------------------------\n\n# calculate the fpr and tpr for all thresholds of the classification\ny_predict_xgr = clf_final.predict_proba(X_test)\npreds = y_predict_xgr  [:,1]   # CLF_pred es la variable con las predicciones de probabilidad\nbase_name = 'TEST'\nDraw_ROC(y_test, preds, base_name)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T23:16:53.334651Z","iopub.execute_input":"2021-10-07T23:16:53.334913Z","iopub.status.idle":"2021-10-07T23:16:55.534245Z","shell.execute_reply.started":"2021-10-07T23:16:53.334889Z","shell.execute_reply":"2021-10-07T23:16:55.533288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------------\n#  ROC : VALIDATION\n# ---------------------------------------\n\n# calculate the fpr and tpr for all thresholds of the classification\ny_predict_xgr = clf_final.predict_proba(X_val)\npreds = y_predict_xgr  [:,1]   # CLF_pred es la variable con las predicciones de probabilidad\nbase_name = 'VALIDATION'\nDraw_ROC(y_val, preds, base_name)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T23:16:58.691887Z","iopub.execute_input":"2021-10-07T23:16:58.692141Z","iopub.status.idle":"2021-10-07T23:17:00.876712Z","shell.execute_reply.started":"2021-10-07T23:16:58.692118Z","shell.execute_reply":"2021-10-07T23:17:00.875808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------------\n#  SUBMISSION FILE \n# ---------------------------------------\nX_subm = subm.drop(['id'], axis=1)\ny_preds_subm = clf_final.predict_proba(X_subm)\n\nsubmit = pd.read_csv(\"../input/tabular-playground-series-oct-2021/sample_submission.csv\")\nsubmit['target'] = y_preds_subm  [:,1]\n#submit.to_csv(\"LGBM_Baseline.csv\", index=False)\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T23:17:26.182359Z","iopub.execute_input":"2021-10-07T23:17:26.183948Z","iopub.status.idle":"2021-10-07T23:17:33.621055Z","shell.execute_reply.started":"2021-10-07T23:17:26.183889Z","shell.execute_reply":"2021-10-07T23:17:33.619994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv(\"LGBM_Baseline.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-07T23:17:39.665571Z","iopub.execute_input":"2021-10-07T23:17:39.665815Z","iopub.status.idle":"2021-10-07T23:17:40.756433Z","shell.execute_reply.started":"2021-10-07T23:17:39.665791Z","shell.execute_reply":"2021-10-07T23:17:40.755431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}