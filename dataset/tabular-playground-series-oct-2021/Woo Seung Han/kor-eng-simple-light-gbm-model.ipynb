{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 개요 (Introduction)\n\n##### 모델링의 경우 train, test data를 나누고,\n##### 그것을 fit(학습) 시켜서 0.5이상의 값에 대하여 1,0으로 구분하여 predict을 진행합니다.\n\n##### 이 validation set data를 활용하여 threshold값을 조정하여 우리가 원하는 AUROC나 Accuracy에 맞는 최종 값 사용하는 모델을 구현 하였습니다. \n\n##### 굳이 Grid-Search나 bayesian optimization같은 기법을 사용하여 Hyper parameter tuning에 시간을 소요하는 것을 최소화하는\n##### 목적으로 모델링 진행하였습니다.\n\n## \n\n##### In the case of modeling, train and test data are divided,\n##### By fitting (learning) it, we proceed to predict by classifying 1, 0 for values over 0.5.\n\n##### By adjusting this threshold value, we implemented a model that uses the final value that fits the desired AUROC or Accuracy.\n##### To minimize the time required for hyper parameter tuning by using techniques such as Grid-Search or Bayesian optimization.\n##### Modeling was done for this purpose.","metadata":{}},{"cell_type":"code","source":"\nimport datetime\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import QuantileTransformer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-29T13:06:07.33543Z","iopub.execute_input":"2021-10-29T13:06:07.335755Z","iopub.status.idle":"2021-10-29T13:06:09.526098Z","shell.execute_reply.started":"2021-10-29T13:06:07.335675Z","shell.execute_reply":"2021-10-29T13:06:09.525206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Memory Reduction\n#### This memory reduction part taken from https://www.kaggle.com/azzamradman/tps-10-single-xgboost/notebook amazing notebook. Please upvote it if you like this part.","metadata":{}},{"cell_type":"code","source":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) / start_mem\n            )\n        )\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:06:09.529564Z","iopub.execute_input":"2021-10-29T13:06:09.52993Z","iopub.status.idle":"2021-10-29T13:06:09.54254Z","shell.execute_reply.started":"2021-10-29T13:06:09.5299Z","shell.execute_reply":"2021-10-29T13:06:09.541534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-oct-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:06:09.543818Z","iopub.execute_input":"2021-10-29T13:06:09.544069Z","iopub.status.idle":"2021-10-29T13:07:32.1677Z","shell.execute_reply.started":"2021-10-29T13:06:09.54404Z","shell.execute_reply":"2021-10-29T13:07:32.166826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7:3으로 제공된 train data를 train과 validation data로 구분\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.05\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:07:32.170129Z","iopub.execute_input":"2021-10-29T13:07:32.170446Z","iopub.status.idle":"2021-10-29T13:07:35.084704Z","shell.execute_reply.started":"2021-10-29T13:07:32.170406Z","shell.execute_reply":"2021-10-29T13:07:35.083853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_nm = 'target'\n\ndf_train_x = train.drop(y_nm, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(y_nm, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:07:35.08594Z","iopub.execute_input":"2021-10-29T13:07:35.086354Z","iopub.status.idle":"2021-10-29T13:07:35.799904Z","shell.execute_reply.started":"2021-10-29T13:07:35.086318Z","shell.execute_reply":"2021-10-29T13:07:35.799037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = QuantileTransformer()\nscaler.fit(df_train_x)\ndf_train_x = pd.DataFrame(scaler.transform(df_train_x))\ndf_val_x = pd.DataFrame(scaler.transform(df_val_x))\ndf_test_x = pd.DataFrame(scaler.transform(df_test_x))","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:07:35.801196Z","iopub.execute_input":"2021-10-29T13:07:35.801505Z","iopub.status.idle":"2021-10-29T13:09:00.854319Z","shell.execute_reply.started":"2021-10-29T13:07:35.801467Z","shell.execute_reply":"2021-10-29T13:09:00.853392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:09:00.855673Z","iopub.execute_input":"2021-10-29T13:09:00.856308Z","iopub.status.idle":"2021-10-29T13:09:00.860519Z","shell.execute_reply.started":"2021-10-29T13:09:00.856271Z","shell.execute_reply":"2021-10-29T13:09:00.859972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:09:00.861428Z","iopub.execute_input":"2021-10-29T13:09:00.862131Z","iopub.status.idle":"2021-10-29T13:29:06.80231Z","shell.execute_reply.started":"2021-10-29T13:09:00.862096Z","shell.execute_reply":"2021-10-29T13:29:06.80103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:29:06.80443Z","iopub.execute_input":"2021-10-29T13:29:06.804788Z","iopub.status.idle":"2021-10-29T13:29:11.241071Z","shell.execute_reply.started":"2021-10-29T13:29:06.804736Z","shell.execute_reply":"2021-10-29T13:29:11.240231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, _ = roc_curve(df_val_y, lgbm.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_roc_auc =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,50):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_roc_auc <= roc_auc:\n        max_roc_auc = roc_auc\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max roc_auc =%f, optimized_threshold=%f'%(max_roc_auc, opt_threshold))\nprint('Complete')","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:29:11.243779Z","iopub.execute_input":"2021-10-29T13:29:11.244454Z","iopub.status.idle":"2021-10-29T13:33:21.982748Z","shell.execute_reply.started":"2021-10-29T13:29:11.244411Z","shell.execute_reply":"2021-10-29T13:33:21.981726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:33:21.984287Z","iopub.execute_input":"2021-10-29T13:33:21.985058Z","iopub.status.idle":"2021-10-29T13:36:36.051166Z","shell.execute_reply.started":"2021-10-29T13:33:21.985015Z","shell.execute_reply":"2021-10-29T13:36:36.050177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:36:36.052485Z","iopub.execute_input":"2021-10-29T13:36:36.05274Z","iopub.status.idle":"2021-10-29T13:36:36.487327Z","shell.execute_reply.started":"2021-10-29T13:36:36.05271Z","shell.execute_reply":"2021-10-29T13:36:36.486372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Accuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:36:36.488772Z","iopub.execute_input":"2021-10-29T13:36:36.489108Z","iopub.status.idle":"2021-10-29T13:36:36.497636Z","shell.execute_reply.started":"2021-10-29T13:36:36.489067Z","shell.execute_reply":"2021-10-29T13:36:36.496786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')\n\npredict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntest_result= pd.DataFrame(pred_test)\ntest_result.columns = ['target']\npredict = test_result['target']\nId_No = df_test['id']\nsubmission = pd.DataFrame({'id': Id_No, 'target': predict})\nsubmission['target'] = submission['target'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T13:36:36.499379Z","iopub.execute_input":"2021-10-29T13:36:36.499736Z","iopub.status.idle":"2021-10-29T13:39:16.54902Z","shell.execute_reply.started":"2021-10-29T13:36:36.499708Z","shell.execute_reply":"2021-10-29T13:39:16.548064Z"},"trusted":true},"execution_count":null,"outputs":[]}]}