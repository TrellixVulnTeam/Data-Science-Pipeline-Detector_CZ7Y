{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import auc\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-08T08:26:48.376547Z","iopub.execute_input":"2021-10-08T08:26:48.377547Z","iopub.status.idle":"2021-10-08T08:26:51.678965Z","shell.execute_reply.started":"2021-10-08T08:26:48.377428Z","shell.execute_reply":"2021-10-08T08:26:51.677563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:26:52.033449Z","iopub.execute_input":"2021-10-08T08:26:52.033673Z","iopub.status.idle":"2021-10-08T08:26:52.049982Z","shell.execute_reply.started":"2021-10-08T08:26:52.033646Z","shell.execute_reply":"2021-10-08T08:26:52.049247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_ogi = import_data(\"../input/tabular-playground-series-oct-2021/train.csv\")\ndf_test_ogi = import_data(\"../input/tabular-playground-series-oct-2021/test.csv\")   ","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:26:54.372506Z","iopub.execute_input":"2021-10-08T08:26:54.372772Z","iopub.status.idle":"2021-10-08T08:29:55.656953Z","shell.execute_reply.started":"2021-10-08T08:26:54.372744Z","shell.execute_reply":"2021-10-08T08:29:55.656212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = import_data(\"../input/tabular-playground-series-oct-2021/sample_submission.csv\")       ","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:29:55.658584Z","iopub.execute_input":"2021-10-08T08:29:55.659006Z","iopub.status.idle":"2021-10-08T08:29:55.814824Z","shell.execute_reply.started":"2021-10-08T08:29:55.658969Z","shell.execute_reply":"2021-10-08T08:29:55.813976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train_ogi.copy()\ndf_test = df_test_ogi.copy()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:29:55.816362Z","iopub.execute_input":"2021-10-08T08:29:55.816676Z","iopub.status.idle":"2021-10-08T08:29:55.997049Z","shell.execute_reply.started":"2021-10-08T08:29:55.816639Z","shell.execute_reply":"2021-10-08T08:29:55.996205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [x for x in df_train.columns if 'f' in x]","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:22:10.955048Z","iopub.execute_input":"2021-10-02T14:22:10.955387Z","iopub.status.idle":"2021-10-02T14:22:10.960261Z","shell.execute_reply.started":"2021-10-02T14:22:10.95535Z","shell.execute_reply":"2021-10-02T14:22:10.959298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['mean'] = df_train[features].mean()\ndf_train['var'] = df_train[features].var()\ndf_train['std'] = df_train[features].std()\n\ndf_test['mean'] = df_test[features].mean()\ndf_test['var'] = df_test[features].var()\ndf_test['std'] = df_test[features].std()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:23:17.75139Z","iopub.execute_input":"2021-10-02T14:23:17.751661Z","iopub.status.idle":"2021-10-02T14:24:00.468424Z","shell.execute_reply.started":"2021-10-02T14:23:17.751633Z","shell.execute_reply":"2021-10-02T14:24:00.467623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.drop(['id','target'], axis = 1)\ny = df_train['target']\ndf_test = df_test.drop('id', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T09:12:31.056663Z","iopub.execute_input":"2021-10-08T09:12:31.056923Z","iopub.status.idle":"2021-10-08T09:12:31.518912Z","shell.execute_reply.started":"2021-10-08T09:12:31.056896Z","shell.execute_reply":"2021-10-08T09:12:31.518193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xtrain ,xtest ,  ytrain , ytest = train_test_split(X , y , random_state = 0, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T09:12:32.89259Z","iopub.execute_input":"2021-10-08T09:12:32.893296Z","iopub.status.idle":"2021-10-08T09:12:34.856593Z","shell.execute_reply.started":"2021-10-08T09:12:32.893239Z","shell.execute_reply":"2021-10-08T09:12:34.855811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def objective(trial,data=xtrain,target=ytrain):\n    \n#     param = {\n\n#         'lambda': trial.suggest_uniform('lambda',0.001,0.1),\n#         'alpha': trial.suggest_uniform('alpha',0.1,0.5),\n#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1,1.0),\n#         'subsample': trial.suggest_uniform('subsample', 0.5,0.9),\n#         'learning_rate': trial.suggest_uniform('learning_rate', 0.05,0.10),\n#         'n_estimators': trial.suggest_int('n_estimators', 10000,30000),\n#         'max_depth': trial.suggest_int('max_depth', 3,8),\n#         'min_child_weight': trial.suggest_int('min_child_weight', 10,100),        \n#         'objective': trial.suggest_categorical('objective',['binary:logistic']), \n#         'tree_method': trial.suggest_categorical('tree_method',['gpu_hist']),  # 'gpu_hist','hist'\n#         'eval_metric' : 'logloss'\n#     }\n#     model = xgb.XGBClassifier(**param)      \n#     model.fit(xtrain,ytrain,eval_set=[(xtest,ytest)],early_stopping_rounds=100,verbose=False)\n#     preds = model.predict(xtest)\n#     auc = roc_auc_score(ytest, preds)\n    \n#     return auc","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:24:16.845027Z","iopub.execute_input":"2021-10-02T14:24:16.845709Z","iopub.status.idle":"2021-10-02T14:24:16.85411Z","shell.execute_reply.started":"2021-10-02T14:24:16.845674Z","shell.execute_reply":"2021-10-02T14:24:16.853274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\n# from optuna.samplers import TPESampler\n# import sklearn\n# sampler = TPESampler()\n# study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n# study.optimize(objective, n_trials=20)\n# params = study.best_params #getting best params from study\n# print('Number of finished trials:', len(study.trials))\n# print('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:24:18.517274Z","iopub.execute_input":"2021-10-02T14:24:18.517934Z","iopub.status.idle":"2021-10-02T15:00:30.2722Z","shell.execute_reply.started":"2021-10-02T14:24:18.517899Z","shell.execute_reply":"2021-10-02T15:00:30.271506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_train_ogi\ndel df_test_ogi","metadata":{"execution":{"iopub.status.busy":"2021-10-02T15:00:47.184706Z","iopub.execute_input":"2021-10-02T15:00:47.184977Z","iopub.status.idle":"2021-10-02T15:00:47.1923Z","shell.execute_reply.started":"2021-10-02T15:00:47.184931Z","shell.execute_reply":"2021-10-02T15:00:47.191615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn import model_selection\n# from sklearn import metrics \n# params = {\n#         \"grow_policy\": \"lossguide\",\n#         'lambda': 0.022724869921522506, \n#         'alpha': 0.3985407522030936, \n#         'colsample_bytree': 0.5511604708167909, \n#         'subsample': 0.8133327192612618, \n#         'learning_rate': 0.05035773098806651, \n#         'n_estimators': 19522, \n#         'max_depth': 4, \n#         'min_child_weight': 69, \n#         'objective': 'binary:logistic', \n#         'tree_method': 'gpu_hist'\n#         }\n\n\n# # KFold\n# n_splits=3\n# skf = model_selection.StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n# scores_train = []\n# scores_valid = []\n# preds_valid_array = np.zeros((X.shape[0], ))\n# print(preds_valid_array)\n\n# preds_test_array = np.zeros((df_test.shape[0], ))\n# print(preds_test_array)\n\n# for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n\n#     print(f\"Fold {fold+1} -------------->\")\n#     x_train, y_train = X[train_idx], y[train_idx]\n#     x_valid, y_valid = X[valid_idx], y[valid_idx]\n\n#     y_train_log = y_train\n#     y_valid_log = y_valid\n\n#     model= xgb.XGBClassifier(\n#                                **params,\n#                                eval_metric='auc'\n#                                 )\n#     model.fit(\n#             x_train, y=y_train,\n#             eval_set=[(x_valid, y_valid)],\n#             early_stopping_rounds=50,\n#             verbose=100\n#             )\n\n#     preds_train = model.predict_proba(x_train)[:, 1]\n#     preds_valid = model.predict_proba(x_valid)[:, 1]\n#     preds_test = model.predict_proba(df_test)[:, 1]\n    \n#     preds_valid_array[valid_idx] += preds_valid\n#     preds_test_array += preds_test / n_splits\n    \n#     score_train = metrics.roc_auc_score(y_train, preds_train)\n#     score_valid = metrics.roc_auc_score(y_valid, preds_valid)\n#     print(score_valid)\n#     scores_train.append(score_train)\n#     scores_valid.append(score_valid)\n        \n# print('Mean train score =', np.mean(scores_train), 'STD train =', np.std(scores_train, ddof=1))\n# print('Mean valid score =', np.mean(scores_valid), 'STD valid =', np.std(scores_valid, ddof=1))\n\n# #pd.DataFrame({'target': preds_valid_array}).to_csv('xgb_valid.csv', index=False)\n# sample.iloc[:, 1] = preds_test_array\n# sample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T15:02:06.03484Z","iopub.execute_input":"2021-10-02T15:02:06.035298Z","iopub.status.idle":"2021-10-02T15:09:46.349819Z","shell.execute_reply.started":"2021-10-02T15:02:06.035263Z","shell.execute_reply":"2021-10-02T15:09:46.349047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gc\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:16:37.365893Z","iopub.execute_input":"2021-10-02T14:16:37.366157Z","iopub.status.idle":"2021-10-02T14:16:37.506858Z","shell.execute_reply.started":"2021-10-02T14:16:37.366129Z","shell.execute_reply":"2021-10-02T14:16:37.506128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = {\n#         \"objective\": \"binary\",\n#         \"metric\": \"auc\",\n#         \"verbosity\": -1,\n#         \"boosting_type\": \"gbdt\",\n#         \"device\" : \"gpu\"\n#     }","metadata":{"execution":{"iopub.status.busy":"2021-10-08T09:12:39.92112Z","iopub.execute_input":"2021-10-08T09:12:39.921847Z","iopub.status.idle":"2021-10-08T09:12:39.926158Z","shell.execute_reply.started":"2021-10-08T09:12:39.92181Z","shell.execute_reply":"2021-10-08T09:12:39.925456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# traindata = lgb.Dataset(xtrain , label = ytrain)\n# valdata = lgb.Dataset(xtest , label = ytest)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T09:12:40.892221Z","iopub.execute_input":"2021-10-08T09:12:40.892739Z","iopub.status.idle":"2021-10-08T09:12:40.898207Z","shell.execute_reply.started":"2021-10-08T09:12:40.892699Z","shell.execute_reply":"2021-10-08T09:12:40.897337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\n# import optuna.integration.lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2021-10-08T09:12:44.426054Z","iopub.execute_input":"2021-10-08T09:12:44.426892Z","iopub.status.idle":"2021-10-08T09:12:44.440942Z","shell.execute_reply.started":"2021-10-08T09:12:44.426844Z","shell.execute_reply":"2021-10-08T09:12:44.44021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = lgb.train(params, train_set = traindata , valid_sets = [traindata , valdata] , verbose_eval=100, early_stopping_rounds=100)\n# best_params = model.params\n# print(\"Best params:\", best_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T09:13:34.911086Z","iopub.execute_input":"2021-10-08T09:13:34.911822Z","iopub.status.idle":"2021-10-08T13:29:32.221932Z","shell.execute_reply.started":"2021-10-08T09:13:34.911791Z","shell.execute_reply":"2021-10-08T13:29:32.22127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample['target'] = model.predict_proba(df_test_ogi)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T13:29:32.223452Z","iopub.execute_input":"2021-10-08T13:29:32.224075Z","iopub.status.idle":"2021-10-08T13:29:47.048305Z","shell.execute_reply.started":"2021-10-08T13:29:32.224045Z","shell.execute_reply":"2021-10-08T13:29:47.047745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"  Params: \")\n# for key, value in best_params.items():\n#     print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2021-10-08T13:29:47.051293Z","iopub.execute_input":"2021-10-08T13:29:47.052739Z","iopub.status.idle":"2021-10-08T13:29:47.060971Z","shell.execute_reply.started":"2021-10-08T13:29:47.052707Z","shell.execute_reply":"2021-10-08T13:29:47.060239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'verbosity': -1,\n    'boosting_type': 'gbdt',\n    'device': 'gpu',\n    'feature_pre_filter': 'False',\n    'lambda_l1': 7.630344575773596,\n    'lambda_l2': 0.20806251221905683,\n    'num_leaves': 10,\n    'feature_fraction': 0.48000000000000004,\n    'bagging_fraction': 0.8196480879728116,\n    'bagging_freq': 3,\n    'min_child_samples': 10,\n    'num_iterations': 1000,\n    'early_stopping_round': 100 }","metadata":{"execution":{"iopub.status.busy":"2021-10-08T13:35:38.729816Z","iopub.execute_input":"2021-10-08T13:35:38.730073Z","iopub.status.idle":"2021-10-08T13:35:38.735827Z","shell.execute_reply.started":"2021-10-08T13:35:38.730045Z","shell.execute_reply":"2021-10-08T13:35:38.735142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nsplits = 5\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n\n# Creating an array of zeros for storing \"out of fold\" predictions\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_auc = 0\npreds_test_array = np.zeros((df_test.shape[0], ))\n\n# Generating folds and making training and prediction for each of 10 folds\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n    X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n    \n    model = lgb.LGBMClassifier(**lgbm_params)\n    model.fit(X_train, y_train,\n              verbose=False,\n              # These three parameters will stop training before a model starts overfitting \n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=300,\n              )\n    \n    # Getting mean test data predictions (i.e. devided by number of splits)\n    preds += model.predict_proba(df_test)[:, 1] / splits\n    preds_test_array += preds / splits\n    \n    # Getting mean feature importances (i.e. devided by number of splits)\n    model_fi += model.feature_importances_ / splits\n    \n    # Getting validation data predictions. Each fold model makes predictions on an unseen data.\n    # So in the end it will be completely filled with unseen data predictions.\n    # It will be used to evaluate hyperparameters performance only.\n    oof_preds[valid_idx] = model.predict_proba(X_valid)[:, 1]\n    # Getting score for a fold model\n    fold_auc = roc_auc_score(y_valid, oof_preds[valid_idx])\n    print(f\"Fold {num} ROC AUC: {fold_auc}\")\n\n    # Getting mean score of all fold models (i.e. devided by number of splits)\n    total_mean_auc += fold_auc / splits\n    \nprint(f\"\\nOverall ROC AUC: {total_mean_auc}\")\nsample.iloc[:, 1] = preds_test_array\nsample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T13:51:46.713355Z","iopub.execute_input":"2021-10-08T13:51:46.713655Z","iopub.status.idle":"2021-10-08T14:15:08.363214Z","shell.execute_reply.started":"2021-10-08T13:51:46.713605Z","shell.execute_reply":"2021-10-08T14:15:08.36248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampledf = pd.read_csv(\"submission.csv\")\nsampledf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T13:51:29.92052Z","iopub.execute_input":"2021-10-08T13:51:29.92136Z","iopub.status.idle":"2021-10-08T13:51:30.319423Z","shell.execute_reply.started":"2021-10-08T13:51:29.921309Z","shell.execute_reply":"2021-10-08T13:51:30.318685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}