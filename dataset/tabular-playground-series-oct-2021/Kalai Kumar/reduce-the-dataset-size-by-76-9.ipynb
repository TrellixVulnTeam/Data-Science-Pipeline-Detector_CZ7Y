{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reduce the Dataset size by 76.9%\n\n\nThe first of your worries start when loading the data - the time it takes to read the dataset into your working environment can be as long as you train a model. At this stage, don't use pandas - there are much faster alternatives available.Its one of the datatable package which can read data up to 10 times faster.\n\nAs an example, we will load 1000000 rows Kaggle TPS OCT 2021 dataset with both datatable and pandas and compare the speeds:","metadata":{}},{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"import datatable as dt  # pip install datatable\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-01T10:41:10.309535Z","iopub.execute_input":"2021-10-01T10:41:10.309891Z","iopub.status.idle":"2021-10-01T10:41:11.414634Z","shell.execute_reply.started":"2021-10-01T10:41:10.309802Z","shell.execute_reply":"2021-10-01T10:41:11.413817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading data using datatable","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_dt = dt.fread(\"../input/tabular-playground-series-oct-2021/train.csv\").to_pandas()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:41:11.416166Z","iopub.execute_input":"2021-10-01T10:41:11.416387Z","iopub.status.idle":"2021-10-01T10:41:25.53554Z","shell.execute_reply.started":"2021-10-01T10:41:11.416363Z","shell.execute_reply":"2021-10-01T10:41:25.534667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest_dt = dt.fread(\"../input/tabular-playground-series-oct-2021/test.csv\").to_pandas()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:41:25.536641Z","iopub.execute_input":"2021-10-01T10:41:25.536903Z","iopub.status.idle":"2021-10-01T10:41:32.107056Z","shell.execute_reply.started":"2021-10-01T10:41:25.536873Z","shell.execute_reply":"2021-10-01T10:41:32.106407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading data using pandas","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_pd = pd.read_csv(\"../input/tabular-playground-series-oct-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:41:32.108837Z","iopub.execute_input":"2021-10-01T10:41:32.109279Z","iopub.status.idle":"2021-10-01T10:42:21.720994Z","shell.execute_reply.started":"2021-10-01T10:41:32.109234Z","shell.execute_reply":"2021-10-01T10:42:21.720423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest_pd = pd.read_csv(\"../input/tabular-playground-series-oct-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:42:21.722194Z","iopub.execute_input":"2021-10-01T10:42:21.722622Z","iopub.status.idle":"2021-10-01T10:42:51.934204Z","shell.execute_reply.started":"2021-10-01T10:42:21.722559Z","shell.execute_reply":"2021-10-01T10:42:51.933138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load time comparision","metadata":{}},{"cell_type":"markdown","source":"|            | Datatable  | Pandas   |\n|------------| -----------| ---------|\n| Train data | 19.1s      | 49.6s    |\n| Test data  | 8.91s      | 23.4s    |\n","metadata":{}},{"cell_type":"markdown","source":"### Memory usage of train and test data","metadata":{}},{"cell_type":"code","source":"memory_usage_train = train_pd.memory_usage(deep=True) / 1024 ** 2\nmemory_usage_test = test_pd.memory_usage(deep=True) / 1024 ** 2\n\nmemory_usage_train.head(7)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:44:07.793516Z","iopub.execute_input":"2021-10-01T10:44:07.793832Z","iopub.status.idle":"2021-10-01T10:44:07.817744Z","shell.execute_reply.started":"2021-10-01T10:44:07.793798Z","shell.execute_reply":"2021-10-01T10:44:07.816834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"memory_usage_train.sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:44:18.583917Z","iopub.execute_input":"2021-10-01T10:44:18.584218Z","iopub.status.idle":"2021-10-01T10:44:18.590895Z","shell.execute_reply.started":"2021-10-01T10:44:18.584188Z","shell.execute_reply":"2021-10-01T10:44:18.590311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reduce the memory of train and test data which is loaded using pandas","metadata":{}},{"cell_type":"code","source":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) / start_mem\n            )\n        )\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:44:19.498521Z","iopub.execute_input":"2021-10-01T10:44:19.499262Z","iopub.status.idle":"2021-10-01T10:44:19.514906Z","shell.execute_reply.started":"2021-10-01T10:44:19.499224Z","shell.execute_reply":"2021-10-01T10:44:19.514044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_train_pd = reduce_memory_usage(train_pd, verbose=True)\nreduced_test_pd = reduce_memory_usage(test_pd, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:44:22.238064Z","iopub.execute_input":"2021-10-01T10:44:22.238336Z","iopub.status.idle":"2021-10-01T10:46:11.257786Z","shell.execute_reply.started":"2021-10-01T10:44:22.23831Z","shell.execute_reply":"2021-10-01T10:46:11.256811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><img src=\"http://ift.tt/2lRnGIX\" alt=\"centered image\"> </center>\n <h1 style=' border:0; color:#FFA500 '><center> If you find this notebook usefull support me with giving ⬆️!</left></h1> ","metadata":{}},{"cell_type":"markdown","source":"Reference : https://www.kaggle.com/bextuychiev/how-to-work-w-million-row-datasets-like-a-pro","metadata":{}}]}