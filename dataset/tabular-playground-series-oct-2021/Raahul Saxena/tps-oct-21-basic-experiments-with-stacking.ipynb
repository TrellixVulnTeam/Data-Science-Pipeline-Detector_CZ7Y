{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:rgba(108, 29, 21, 0.5);\">\n    <h1><center>Importing Libraries and Data</center></h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"This is a sandpit of sorts, where I explore different methods of stacking which came to my mind.\nI am aware of the fact that adding more levels to stacking may improve accuracy further.\n\nAfter getting weights for my simple ensemble, I am trying **different methods of stacking**-\n1. Taking the predictions as separate and using them for training my meta-classifier\n2. Aggregating the two predictions (mean) and using that for my meta.\n3. Adding the predictions to whole training data.\n4. Adding the predictions to a subset of the whole data, which has most 'important' features.\n\nI have calculated total average AUCs for these 4 methods.\n\nI hae compared the results as well and I hope it gives you an idea for trying out a different method of stacking as well. Note that **I have used only 10000 rows of the data**, to demonstrate, for speed and memory.\n\n**Do upvote if you find this notebook useful :)**","metadata":{}},{"cell_type":"code","source":"import random\nrandom.seed(123)\n\nimport pandas as pd\nimport numpy as np\nimport datatable as dt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# importing feature selection and processing packages\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,PowerTransformer\nfrom sklearn.decomposition import PCA\n\n# importing modelling packages\n\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:29:22.635586Z","iopub.execute_input":"2021-10-24T07:29:22.635896Z","iopub.status.idle":"2021-10-24T07:29:25.943449Z","shell.execute_reply.started":"2021-10-24T07:29:22.635821Z","shell.execute_reply":"2021-10-24T07:29:25.94267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using datatable for faster loading\n\ntrain = pd.read_csv(r'../input/tabular-playground-series-oct-2021/train.csv',nrows=10000)\ntest = pd.read_csv(r'../input/tabular-playground-series-oct-2021/test.csv',nrows=10000)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:29:30.679971Z","iopub.execute_input":"2021-10-24T07:29:30.680559Z","iopub.status.idle":"2021-10-24T07:29:32.191988Z","shell.execute_reply.started":"2021-10-24T07:29:30.680521Z","shell.execute_reply":"2021-10-24T07:29:32.191197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(108, 29, 21, 0.5);\">\n    <h1><center>Memory Reduction</center></h1>\n</div>","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64','float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                else:\n                    df[col] = df[col].astype(np.float32)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:29:39.633622Z","iopub.execute_input":"2021-10-24T07:29:39.634461Z","iopub.status.idle":"2021-10-24T07:29:39.64655Z","shell.execute_reply.started":"2021-10-24T07:29:39.634407Z","shell.execute_reply":"2021-10-24T07:29:39.645687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest  = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:29:44.127494Z","iopub.execute_input":"2021-10-24T07:29:44.128193Z","iopub.status.idle":"2021-10-24T07:29:44.912349Z","shell.execute_reply.started":"2021-10-24T07:29:44.128152Z","shell.execute_reply":"2021-10-24T07:29:44.911598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(108, 29, 21, 0.5);\">\n    <h1><center>Data Splitting</center></h1>\n</div>","metadata":{}},{"cell_type":"code","source":"X = train.drop(columns=[\"id\", \"target\"]).copy()\ny = train[\"target\"].copy()\ntest_for_model = test.drop(columns=[\"id\"]).copy()\n\n# freeing up some memory\n\ndel train\ndel test","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:29:48.635629Z","iopub.execute_input":"2021-10-24T07:29:48.636185Z","iopub.status.idle":"2021-10-24T07:29:48.665297Z","shell.execute_reply.started":"2021-10-24T07:29:48.636148Z","shell.execute_reply":"2021-10-24T07:29:48.664546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(108, 29, 21, 0.5);\">\n    <h1><center>Initialising Baseline Models</center></h1>\n</div>","metadata":{}},{"cell_type":"code","source":"# using baseline xgb and catboost models - on gpu\n\ncat_params = {\"task_type\": \"GPU\"}\nxgb_params = {'tree_method': 'gpu_hist','predictor': 'gpu_predictor'}","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:29:52.850782Z","iopub.execute_input":"2021-10-24T07:29:52.851083Z","iopub.status.idle":"2021-10-24T07:29:52.855881Z","shell.execute_reply.started":"2021-10-24T07:29:52.851053Z","shell.execute_reply":"2021-10-24T07:29:52.85489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Ensembling","metadata":{}},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 10, random_state = 2021, shuffle = True)\n\npredictions_cb = np.zeros(len(test_for_model))\npredictions_xgb = np.zeros(len(test_for_model))\n\ncat_oof = np.zeros(X.shape[0])\nxgb_oof = np.zeros(X.shape[0])\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X,y)):\n    print(f\"Fold: {fold+1}\")\n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model_cb =  CatBoostClassifier(**cat_params,verbose=0,random_state=2021)\n    model_xgb = XGBClassifier(**xgb_params,random_state=2021)\n    \n    model_cb.fit(X_train, y_train)\n    pred_cb = model_cb.predict_proba(X_val)[:,1]\n    cat_oof[val_idx] = pred_cb\n    print('ROC of CB: ',roc_auc_score(y_val,pred_cb))\n    \n    model_xgb.fit(X_train, y_train)\n    pred_xgb = model_xgb.predict_proba(X_val)[:,1]\n    xgb_oof[val_idx] = pred_xgb\n    print('ROC of XGB: ',roc_auc_score(y_val,pred_xgb))\n    \n    print(\"-\"*50)\n    \n    predictions_cb += model_cb.predict_proba(test_for_model)[:,1] / folds.n_splits\n    predictions_xgb += model_xgb.predict_proba(test_for_model)[:,1] / folds.n_splits","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:29:56.566945Z","iopub.execute_input":"2021-10-24T07:29:56.567665Z","iopub.status.idle":"2021-10-24T07:38:48.929304Z","shell.execute_reply.started":"2021-10-24T07:29:56.567627Z","shell.execute_reply":"2021-10-24T07:38:48.928518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating appropriate weights for ensemble\n\nimport scipy\ndef class_optimizer(X, a0, a1):\n    oof = X[0]*a0 + (1-X[0])*a1\n    return (1-roc_auc_score(y, oof))\n\nres = scipy.optimize.minimize(\n    fun=class_optimizer,\n    x0=[0.5],\n    args=tuple([cat_oof, xgb_oof]),\n    method='BFGS',\n    options={'maxiter': 1000})\n\nprint(res)\nprint(f\"coef0 {res.x[0]}, coef1 {1-res.x[0]}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:39:02.055729Z","iopub.execute_input":"2021-10-24T07:39:02.056011Z","iopub.status.idle":"2021-10-24T07:39:02.073706Z","shell.execute_reply.started":"2021-10-24T07:39:02.055963Z","shell.execute_reply":"2021-10-24T07:39:02.07295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_pred = res.x[0] * predictions_cb  + (1-res.x[0]) * predictions_xgb\nsub['target'] = ensemble_pred\nsub.to_csv('submission_simple_ensemble.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:06:19.433703Z","iopub.execute_input":"2021-10-24T07:06:19.434443Z","iopub.status.idle":"2021-10-24T07:06:21.009697Z","shell.execute_reply.started":"2021-10-24T07:06:19.434385Z","shell.execute_reply":"2021-10-24T07:06:21.008928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking using the 2 predictions separately","metadata":{}},{"cell_type":"code","source":"# creating stack datasets for our meta-classifier\n\ncat_train = pd.DataFrame(cat_oof,columns=['CAT_train'])\nxgb_train = pd.DataFrame(xgb_oof,columns=['XGB_train'])\ncat_test = pd.DataFrame(predictions_cb,columns=['CAT_train'])\nxgb_test = pd.DataFrame(predictions_xgb,columns=['XGB_train'])\n\nstack_x_train = pd.concat((cat_train,xgb_train), axis = 1)\nstack_x_test = pd.concat((cat_test,xgb_test), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:39:07.828489Z","iopub.execute_input":"2021-10-24T07:39:07.829119Z","iopub.status.idle":"2021-10-24T07:39:07.837005Z","shell.execute_reply.started":"2021-10-24T07:39:07.82908Z","shell.execute_reply":"2021-10-24T07:39:07.836092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stk = StratifiedKFold(n_splits = 10, random_state = 42)\n\ntest_pred = 0\nfold = 1\ntotal_auc = 0\n\nfor train_index, valid_index in stk.split(stack_x_train, y):\n    x_train, y_train = stack_x_train.iloc[train_index], y[train_index]\n    x_valid, y_valid = stack_x_train.iloc[valid_index], y[valid_index]\n    \n    lr = LogisticRegression(n_jobs = -1, random_state = 42, C = 1000, max_iter = 1000)\n    lr.fit(x_train, y_train)\n    \n    valid_pred = lr.predict_proba(x_valid)[:,1]\n    test_pred += lr.predict_proba(stack_x_test)[:,1]\n    auc = roc_auc_score(y_valid, valid_pred)\n    total_auc += auc / 10\n    print('Fold', fold, 'AUC :', auc)\n    fold += 1\n    \nprint('Total AUC score :', total_auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:39:11.368245Z","iopub.execute_input":"2021-10-24T07:39:11.36912Z","iopub.status.idle":"2021-10-24T07:39:14.135225Z","shell.execute_reply.started":"2021-10-24T07:39:11.369081Z","shell.execute_reply":"2021-10-24T07:39:14.134247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking using average of the 2 predictions","metadata":{}},{"cell_type":"code","source":"# creating stack datasets for our meta-classifier\n\nstack_x_train['pred'] = stack_x_train.mean(axis=1)\nstack_x_test['pred'] = stack_x_test.mean(axis=1)\nstack_x_train = pd.DataFrame(stack_x_train['pred'])\nstack_x_test = pd.DataFrame(stack_x_test['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:39:19.348027Z","iopub.execute_input":"2021-10-24T07:39:19.348675Z","iopub.status.idle":"2021-10-24T07:39:19.35721Z","shell.execute_reply.started":"2021-10-24T07:39:19.348634Z","shell.execute_reply":"2021-10-24T07:39:19.356523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stk = StratifiedKFold(n_splits = 10, random_state = 42)\n\ntest_pred = 0\nfold = 1\ntotal_auc = 0\n\nfor train_index, valid_index in stk.split(stack_x_train, y):\n    x_train, y_train = stack_x_train.iloc[train_index], y[train_index]\n    x_valid, y_valid = stack_x_train.iloc[valid_index], y[valid_index]\n    \n    lr = LogisticRegression(n_jobs = -1, random_state = 42, C = 1000, max_iter = 1000)\n    lr.fit(x_train, y_train)\n    \n    valid_pred = lr.predict_proba(x_valid)[:, 1]\n    test_pred += lr.predict_proba(stack_x_test)[:, 1]\n    auc = roc_auc_score(y_valid, valid_pred)\n    total_auc += auc / 10\n    print('Fold', fold, 'AUC :', auc)\n    fold += 1\n    \nprint('Total AUC score :', total_auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:39:22.807842Z","iopub.execute_input":"2021-10-24T07:39:22.808408Z","iopub.status.idle":"2021-10-24T07:39:23.080343Z","shell.execute_reply.started":"2021-10-24T07:39:22.808368Z","shell.execute_reply":"2021-10-24T07:39:23.078141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking using whole data+predictions separately","metadata":{}},{"cell_type":"code","source":"# adding whole data to the predictions\n\nstack_x_train = pd.concat((X,cat_train, xgb_train), axis = 1)\nstack_x_test = pd.concat((test_for_model,cat_test, xgb_test), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:39:28.696607Z","iopub.execute_input":"2021-10-24T07:39:28.697522Z","iopub.status.idle":"2021-10-24T07:39:28.714594Z","shell.execute_reply.started":"2021-10-24T07:39:28.697483Z","shell.execute_reply":"2021-10-24T07:39:28.713653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stk = StratifiedKFold(n_splits = 10, random_state = 42)\n\ntest_pred = 0\nfold = 1\ntotal_auc = 0\n\nfor train_index, valid_index in stk.split(stack_x_train, y):\n    x_train, y_train = stack_x_train.iloc[train_index], y[train_index]\n    x_valid, y_valid = stack_x_train.iloc[valid_index], y[valid_index]\n    \n    lr = LogisticRegression(n_jobs = -1, random_state = 42, C = 1000, max_iter = 1000)\n    lr.fit(x_train, y_train)\n    \n    valid_pred = lr.predict_proba(x_valid)[:, 1]\n    test_pred += lr.predict_proba(stack_x_test)[:, 1]\n    auc = roc_auc_score(y_valid, valid_pred)\n    total_auc += auc / 10\n    print('Fold', fold, 'AUC :', auc)\n    fold += 1\n    \nprint('Total AUC score :', total_auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:39:32.241508Z","iopub.execute_input":"2021-10-24T07:39:32.242289Z","iopub.status.idle":"2021-10-24T07:40:51.617362Z","shell.execute_reply.started":"2021-10-24T07:39:32.242251Z","shell.execute_reply":"2021-10-24T07:40:51.616587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking using important features+predictions separately","metadata":{}},{"cell_type":"code","source":"imp_features= [\"f22\", \"f179\", \"f69\", \"f58\", \"f214\", \"f78\", \"f136\", \"f156\",\n               \"f8\", \"f3\", \"f77\", \"f200\", \"f92\", \"f185\", \"f142\", \"f115\", \"f284\"]\nX_new = X[imp_features]\ntest_for_model_new = test_for_model[imp_features]\n\nstack_x_train = pd.concat((X_new,cat_train, xgb_train), axis = 1)\nstack_x_test = pd.concat((test_for_model_new,cat_test, xgb_test), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:40:58.296477Z","iopub.execute_input":"2021-10-24T07:40:58.296746Z","iopub.status.idle":"2021-10-24T07:40:58.308881Z","shell.execute_reply.started":"2021-10-24T07:40:58.296718Z","shell.execute_reply":"2021-10-24T07:40:58.307916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stk = StratifiedKFold(n_splits = 10, random_state = 42)\n\ntest_pred = 0\nfold = 1\ntotal_auc = 0\n\nfor train_index, valid_index in stk.split(stack_x_train, y):\n    x_train, y_train = stack_x_train.iloc[train_index], y[train_index]\n    x_valid, y_valid = stack_x_train.iloc[valid_index], y[valid_index]\n    \n    lr = LogisticRegression(n_jobs = -1, random_state = 42, C = 1000, max_iter = 1000)\n    lr.fit(x_train, y_train)\n    \n    valid_pred = lr.predict_proba(x_valid)[:, 1]\n    test_pred += lr.predict_proba(stack_x_test)[:, 1]\n    auc = roc_auc_score(y_valid, valid_pred)\n    total_auc += auc / 10\n    print('Fold', fold, 'AUC :', auc)\n    fold += 1\n    \nprint('Total AUC score :', total_auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T07:41:02.367011Z","iopub.execute_input":"2021-10-24T07:41:02.367365Z","iopub.status.idle":"2021-10-24T07:41:09.448641Z","shell.execute_reply.started":"2021-10-24T07:41:02.367323Z","shell.execute_reply":"2021-10-24T07:41:09.446482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\n\n1. Taking the predictions as separate and using them for training my meta-classifier - 0.8394 - BEST\n2. Aggregating the two predictions (mean) and using that for my meta - 0.8345\n3. Adding the predictions to whole training data. - 0.8301 - WORST (Weird)\n4. Adding the predictions to a subset of the whole data, which has most 'important' features - 0.8384","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(108, 29, 21, 0.5);\">\n    <h1><center>Use for your own experiments and do upvote. Thanks :)</center></h1>\n</div>","metadata":{}}]}