{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-14T18:50:36.80558Z","iopub.execute_input":"2021-10-14T18:50:36.805955Z","iopub.status.idle":"2021-10-14T18:50:36.817047Z","shell.execute_reply.started":"2021-10-14T18:50:36.805915Z","shell.execute_reply":"2021-10-14T18:50:36.816116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '/kaggle/input/tabular-playground-series-oct-2021/'\ntrain = pd.read_csv(f'{PATH}train.csv')\ntest = pd.read_csv(f'{PATH}test.csv')\nsub = pd.read_csv(f'{PATH}sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:50:36.819601Z","iopub.execute_input":"2021-10-14T18:50:36.820122Z","iopub.status.idle":"2021-10-14T18:51:44.723645Z","shell.execute_reply.started":"2021-10-14T18:50:36.820086Z","shell.execute_reply":"2021-10-14T18:51:44.722837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of missing values in training data: {train.isna().sum().sum()}')\nprint(f'Number of missing values in testing data: {test.isna().sum().sum()}')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:51:44.725074Z","iopub.execute_input":"2021-10-14T18:51:44.7255Z","iopub.status.idle":"2021-10-14T18:51:45.548935Z","shell.execute_reply.started":"2021-10-14T18:51:44.725465Z","shell.execute_reply":"2021-10-14T18:51:45.54766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info(memory_usage=\"deep\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:51:45.550287Z","iopub.execute_input":"2021-10-14T18:51:45.550631Z","iopub.status.idle":"2021-10-14T18:51:45.578265Z","shell.execute_reply.started":"2021-10-14T18:51:45.550593Z","shell.execute_reply":"2021-10-14T18:51:45.577186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Garbage Collector\nimport gc\n#This is a function that downcast the integer columns\ndef downcast_df_int_columns(df):\n    list_of_columns = list(df.select_dtypes(include=[\"int32\", \"int64\"]).columns)\n        \n    if len(list_of_columns)>=1:\n        max_string_length = max([len(col) for col in list_of_columns]) # finds max string length for better status printing\n        print(\"downcasting integers for:\", list_of_columns, \"\\n\")\n        \n        for col in list_of_columns:\n            print(\"reduced memory usage for:  \", col.ljust(max_string_length+2)[:max_string_length+2],\n                  \"from\", str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8), \"to\", end=\" \")\n            df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n            print(str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8))\n    else:\n        print(\"no columns to downcast\")\n    \n    gc.collect()\n    \n    print(\"done\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:51:45.581449Z","iopub.execute_input":"2021-10-14T18:51:45.581732Z","iopub.status.idle":"2021-10-14T18:51:45.590854Z","shell.execute_reply.started":"2021-10-14T18:51:45.581698Z","shell.execute_reply":"2021-10-14T18:51:45.589747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is a function that downcast the float columns, if you have too many columns to adjust and do not want to see to many messages proceesing, you could comment our the print() columns\ndef downcast_df_float_columns(df):\n    list_of_columns = list(df.select_dtypes(include=[\"float64\"]).columns)\n        \n    if len(list_of_columns)>=1:\n        max_string_length = max([len(col) for col in list_of_columns]) # finds max string length for better status printing\n        print(\"downcasting float for:\", list_of_columns, \"\\n\")\n        \n        for col in list_of_columns:\n            print(\"reduced memory usage for:  \", col.ljust(max_string_length+2)[:max_string_length+2],\n                  \"from\", str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8), \"to\", end=\" \")\n            df[col] = pd.to_numeric(df[col], downcast=\"float\")\n            print(str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8))\n    else:\n        print(\"no columns to downcast\")\n    \n    gc.collect()\n    \n    print(\"done\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:51:45.592427Z","iopub.execute_input":"2021-10-14T18:51:45.593333Z","iopub.status.idle":"2021-10-14T18:51:45.604675Z","shell.execute_reply.started":"2021-10-14T18:51:45.593145Z","shell.execute_reply":"2021-10-14T18:51:45.603855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"downcast_df_int_columns(train)\ndowncast_df_float_columns(train)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:51:45.605966Z","iopub.execute_input":"2021-10-14T18:51:45.606272Z","iopub.status.idle":"2021-10-14T18:52:54.676271Z","shell.execute_reply.started":"2021-10-14T18:51:45.60624Z","shell.execute_reply":"2021-10-14T18:52:54.675502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info(memory_usage=\"deep\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:54.677565Z","iopub.execute_input":"2021-10-14T18:52:54.677836Z","iopub.status.idle":"2021-10-14T18:52:54.699705Z","shell.execute_reply.started":"2021-10-14T18:52:54.677801Z","shell.execute_reply":"2021-10-14T18:52:54.698833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info(memory_usage=\"deep\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:54.701838Z","iopub.execute_input":"2021-10-14T18:52:54.7022Z","iopub.status.idle":"2021-10-14T18:52:54.727064Z","shell.execute_reply.started":"2021-10-14T18:52:54.702164Z","shell.execute_reply":"2021-10-14T18:52:54.72639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"downcast_df_int_columns(train)\ndowncast_df_float_columns(train)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:54.72815Z","iopub.execute_input":"2021-10-14T18:52:54.728517Z","iopub.status.idle":"2021-10-14T18:52:55.534995Z","shell.execute_reply.started":"2021-10-14T18:52:54.728455Z","shell.execute_reply":"2021-10-14T18:52:55.534325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info(memory_usage=\"deep\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:55.537756Z","iopub.execute_input":"2021-10-14T18:52:55.53797Z","iopub.status.idle":"2021-10-14T18:52:55.550148Z","shell.execute_reply.started":"2021-10-14T18:52:55.537947Z","shell.execute_reply":"2021-10-14T18:52:55.549119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [col for col in train.columns if 'f' in col]\nfeatures.append('id')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:55.551322Z","iopub.execute_input":"2021-10-14T18:52:55.552419Z","iopub.status.idle":"2021-10-14T18:52:55.560806Z","shell.execute_reply.started":"2021-10-14T18:52:55.552383Z","shell.execute_reply":"2021-10-14T18:52:55.560043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(features)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:55.56204Z","iopub.execute_input":"2021-10-14T18:52:55.56241Z","iopub.status.idle":"2021-10-14T18:52:55.572763Z","shell.execute_reply.started":"2021-10-14T18:52:55.562297Z","shell.execute_reply":"2021-10-14T18:52:55.571952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:55.577263Z","iopub.execute_input":"2021-10-14T18:52:55.577454Z","iopub.status.idle":"2021-10-14T18:52:55.582429Z","shell.execute_reply.started":"2021-10-14T18:52:55.577432Z","shell.execute_reply":"2021-10-14T18:52:55.581441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_frac = train.sample(frac = 1).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:55.584228Z","iopub.execute_input":"2021-10-14T18:52:55.584801Z","iopub.status.idle":"2021-10-14T18:52:55.893408Z","shell.execute_reply.started":"2021-10-14T18:52:55.584696Z","shell.execute_reply":"2021-10-14T18:52:55.892579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_frac = test.sample(frac = 1).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:55.894915Z","iopub.execute_input":"2021-10-14T18:52:55.895186Z","iopub.status.idle":"2021-10-14T18:52:56.102752Z","shell.execute_reply.started":"2021-10-14T18:52:55.895153Z","shell.execute_reply":"2021-10-14T18:52:56.102007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the first 5 features \n# i = 1\n# plt.figure()\n# fig, ax = plt.subplots(285, 5,figsize=(30, 285))\n# for feature in features:\n#     plt.subplot(285, 5,i)\n#     sns.histplot(train_frac[feature],color=\"blue\", kde=True,bins=100, label='train_'+feature)\n#     sns.histplot(test_frac[feature],color=\"olive\", kde=True,bins=100, label='test_'+feature)\n#     plt.xlabel(feature, fontsize=9); plt.legend()\n#     i += 1\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:56.104246Z","iopub.execute_input":"2021-10-14T18:52:56.104647Z","iopub.status.idle":"2021-10-14T18:52:56.108964Z","shell.execute_reply.started":"2021-10-14T18:52:56.10461Z","shell.execute_reply":"2021-10-14T18:52:56.107949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas_profiling as pp\n# pp.ProfileReport(train_frac)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:56.110481Z","iopub.execute_input":"2021-10-14T18:52:56.110783Z","iopub.status.idle":"2021-10-14T18:52:56.118642Z","shell.execute_reply.started":"2021-10-14T18:52:56.110738Z","shell.execute_reply":"2021-10-14T18:52:56.117636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train['std'] = train[features].std(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:56.120078Z","iopub.execute_input":"2021-10-14T18:52:56.12038Z","iopub.status.idle":"2021-10-14T18:52:56.126482Z","shell.execute_reply.started":"2021-10-14T18:52:56.120346Z","shell.execute_reply":"2021-10-14T18:52:56.125483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check scale\ntrain_frac.describe().T.style.bar(subset=['mean'], color='#FF595E')\\\n                           .background_gradient(subset=['50%'], cmap='PiYG')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:56.127931Z","iopub.execute_input":"2021-10-14T18:52:56.128308Z","iopub.status.idle":"2021-10-14T18:52:57.670518Z","shell.execute_reply.started":"2021-10-14T18:52:56.128272Z","shell.execute_reply":"2021-10-14T18:52:57.669865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n# scaler = RobustScaler()\n# X_train[features] = scaler.fit_transform(X_train[features])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:57.671917Z","iopub.execute_input":"2021-10-14T18:52:57.672361Z","iopub.status.idle":"2021-10-14T18:52:57.676686Z","shell.execute_reply.started":"2021-10-14T18:52:57.672325Z","shell.execute_reply":"2021-10-14T18:52:57.67566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Library\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgbm\n\n# train_X, val_X, train_y, val_y = train_test_split(X_train, y, train_size=0.8, test_size=0.2,\n#                                                                 random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:57.67811Z","iopub.execute_input":"2021-10-14T18:52:57.67838Z","iopub.status.idle":"2021-10-14T18:52:57.685322Z","shell.execute_reply.started":"2021-10-14T18:52:57.678346Z","shell.execute_reply":"2021-10-14T18:52:57.68469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:57.686101Z","iopub.execute_input":"2021-10-14T18:52:57.686321Z","iopub.status.idle":"2021-10-14T18:52:57.693603Z","shell.execute_reply.started":"2021-10-14T18:52:57.686283Z","shell.execute_reply":"2021-10-14T18:52:57.69303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = lgbm.LGBMClassifier()\n# model.fit(\n#         train_X, \n#         train_y,\n#         eval_set=[(val_X, val_y)],\n#         eval_metric='auc',\n#         early_stopping_rounds=200,\n#         verbose=1000,\n#     )\n\n# lgb_oof = model.predict_proba(val_X)[:,-1]\n\n# print(roc_auc_score(val_y, lgb_oof))\n\n# tmp = pd.DataFrame()\n# tmp['imp'] = model.feature_importances_\n# tmp['feature'] = model.feature_name_\n# tmp_or = tmp\n# tmp = tmp[tmp.imp > 0]\n# order = list(tmp.groupby('feature').mean().sort_values('imp', ascending=False).index)\n# fig = plt.figure(figsize=(16, 16), tight_layout=True)\n# sns.barplot(x=\"imp\", y=\"feature\", data=tmp.groupby('feature').mean().reset_index(), order=order)\n# plt.title(\"LightGBM feature importances\")\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:57.694389Z","iopub.execute_input":"2021-10-14T18:52:57.694598Z","iopub.status.idle":"2021-10-14T18:52:57.702854Z","shell.execute_reply.started":"2021-10-14T18:52:57.694571Z","shell.execute_reply":"2021-10-14T18:52:57.70223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_or = train\ntest_or = test\ntrain = train_frac\ntest = test_frac\ntarget = train.target","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:57.703733Z","iopub.execute_input":"2021-10-14T18:52:57.704001Z","iopub.status.idle":"2021-10-14T18:52:57.721344Z","shell.execute_reply.started":"2021-10-14T18:52:57.703969Z","shell.execute_reply":"2021-10-14T18:52:57.720463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[features].set_index('id')\ntest = test[features].set_index('id')\n\nfeatures.remove('id')\n\ntrain['std'] = train[features].std(axis=1)\ntrain['min'] = train[features].min(axis=1)\ntrain['median'] = train[features].median(axis=1)\ntrain['max'] = train[features].max(axis=1)\ntrain['mean'] = train[features].mean(axis=1)\n\ntest['std'] = test[features].std(axis=1)\ntest['min'] = test[features].min(axis=1)\ntest['median'] = test[features].median(axis=1)\ntest['max'] = test[features].max(axis=1)\ntest['mean'] = test[features].mean(axis=1)\n\nfeatures.extend(['std','min','median','max','mean'])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:57.722523Z","iopub.execute_input":"2021-10-14T18:52:57.722803Z","iopub.status.idle":"2021-10-14T18:52:59.58174Z","shell.execute_reply.started":"2021-10-14T18:52:57.722758Z","shell.execute_reply":"2021-10-14T18:52:59.581006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = RobustScaler()\ntrain[features] = scaler.fit_transform(train[features])\n\ntest[features] = scaler.transform(test[features])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:52:59.583372Z","iopub.execute_input":"2021-10-14T18:52:59.583663Z","iopub.status.idle":"2021-10-14T18:53:13.331591Z","shell.execute_reply.started":"2021-10-14T18:52:59.583628Z","shell.execute_reply":"2021-10-14T18:53:13.330847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna Training","metadata":{"execution":{"iopub.status.busy":"2021-10-04T12:55:25.070821Z","iopub.execute_input":"2021-10-04T12:55:25.071147Z","iopub.status.idle":"2021-10-04T12:55:25.087166Z","shell.execute_reply.started":"2021-10-04T12:55:25.071059Z","shell.execute_reply":"2021-10-04T12:55:25.086525Z"}}},{"cell_type":"code","source":"N_SPLITS = 5\nN_ESTIMATORS = 20000\nEARLY_STOPPING_ROUNDS = 200\nVERBOSE = 1000\nSEED = 2021\n\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nimport os\nimport gc\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:53:13.332722Z","iopub.execute_input":"2021-10-14T18:53:13.333889Z","iopub.status.idle":"2021-10-14T18:53:13.342194Z","shell.execute_reply.started":"2021-10-14T18:53:13.333858Z","shell.execute_reply":"2021-10-14T18:53:13.340083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom optuna.integration import LightGBMPruningCallback\nimport optuna  # pip install optuna\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\ndef objective(trial, train, target):\n    param_grid = {\n        \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-4, 0.5),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n        \"bagging_fraction\": trial.suggest_float(\n            \"bagging_fraction\", 0.2, 0.95, step=0.1\n        ),\n        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n        \"feature_fraction\": trial.suggest_float(\n            \"feature_fraction\", 0.2, 0.95, step=0.1\n        ),\n        'subsample': trial.suggest_float(\n            \"subsample\", 0.1, 1, step=0.1\n        ),\n        'subsample_freq': trial.suggest_int('subsample_freq',0,1),\n        'colsample_bytree':trial.suggest_float(\n            \"colsample_bytree\", 0, 10),\n        'reg_alpha': trial.suggest_float(\n            \"reg_alpha\", 1.0, 20),\n        'reg_lambda': trial.suggest_float(\n            \"reg_lambda\", 1e-2, 5),\n        'min_child_weight': trial.suggest_int(\"min_child_weight\", 0, 500),\n        'min_child_samples': trial.suggest_int(\"min_child_samples\", 20, 1000)\n    }\n\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n\n    cv_scores = np.empty(5)\n    for idx, (train_idx, test_idx) in enumerate(cv.split(train, target)):\n        X_train, X_test = train.iloc[train_idx], train.iloc[test_idx]\n        y_train, y_test = target[train_idx], target[test_idx]\n\n        model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n        model.fit(\n            X_train,\n            y_train,\n            eval_set=[(X_test, y_test)],\n            eval_metric=\"auc\",\n            early_stopping_rounds=100\n        )\n        preds = model.predict_proba(X_test)[:,1]\n        cv_scores[idx] = roc_auc_score(y_test, preds)\n\n    return np.mean(cv_scores)\n    \nstudy = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\nfunc = lambda trial: objective(trial, train, target)\nstudy.optimize(func, n_trials=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:53:13.343825Z","iopub.execute_input":"2021-10-14T18:53:13.344212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\tBest value (auc): {study.best_value:.5f}\") \n\n\nprint(f\"\\tBest params:\")\n\nbest_params = study.best_params\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_params = {'device_type': 'gpu',\n#  'n_estimators': 10000,\n#  'learning_rate': 0.005561317553182468,\n#  'num_leaves': 20,\n#  'max_depth': 5,\n#  'min_data_in_leaf': 9400,\n#  'lambda_l1': 0,\n#  'lambda_l2': 95,\n#  'min_gain_to_split': 4.175935643818434,\n#  'bagging_fraction': 0.9,\n#  'bagging_freq': 1,\n#  'feature_fraction': 0.30000000000000004,\n#  'subsample': 0.6,\n#  'subsample_freq': 1,\n#  'colsample_bytree': 9.959598465442731,\n#  'reg_alpha': 11.705140163646389,\n#  'reg_lambda': 3.897135186715671,\n#  'min_child_weight': 266,\n#  'min_child_samples': 985}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_oof = np.zeros(train.shape[0])\nlgb_pred = np.zeros(test.shape[0])\nlgb_importances = pd.DataFrame()\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X=train, y=target)):\n    print(f\"===== fold {fold} =====\")\n    X_train = train[features].iloc[trn_idx]\n    y_train = target.iloc[trn_idx]\n    X_valid = train[features].iloc[val_idx]\n    y_valid = target.iloc[val_idx]\n    X_test = test[features]\n    \n    start = time.time()\n    model = lgbm.LGBMClassifier(**best_params)\n    model.fit(\n        X_train, \n        y_train,\n        eval_set=[(X_valid, y_valid)],\n        eval_metric='auc',\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        verbose=VERBOSE,\n    )\n    \n    fi_tmp = pd.DataFrame()\n    fi_tmp['feature'] = model.feature_name_\n    fi_tmp['importance'] = model.feature_importances_\n    fi_tmp['fold'] = fold\n    fi_tmp['seed'] = SEED\n    lgb_importances = lgb_importances.append(fi_tmp)\n\n    lgb_oof[val_idx] = model.predict_proba(X_valid)[:, -1]\n    lgb_pred += model.predict_proba(X_test)[:, -1] / N_SPLITS\n\n    elapsed = time.time() - start\n    auc = roc_auc_score(y_valid, lgb_oof[val_idx])\n    print(f\"fold {fold} - lgb auc: {auc:.6f}, elapsed time: {elapsed:.2f}sec\\n\")\n\nprint(f\"oof lgb roc = {roc_auc_score(target, lgb_oof)}\")\n\nnp.save(\"lgb_oof.npy\", lgb_oof)\nnp.save(\"lgb_pred.npy\", lgb_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order = list(lgb_importances.groupby('feature').mean().sort_values('importance', ascending=False).index)\n\nfig = plt.figure(figsize=(16, 120), tight_layout=True)\nsns.barplot(x=\"importance\", y=\"feature\", data=lgb_importances.groupby('feature').mean().reset_index(), order=order)\nplt.title(\"LightGBM feature importances\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_params['learning_rate'] = 5e-3\n# Didn't do any good","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb_oof = np.zeros(train.shape[0])\n# lgb_pred = np.zeros(test.shape[0])\n# lgb_importances = pd.DataFrame()\n\n# for fold, (trn_idx, val_idx) in enumerate(skf.split(X=train, y=target)):\n#     print(f\"===== fold {fold} =====\")\n#     X_train = train[features].iloc[trn_idx]\n#     y_train = target.iloc[trn_idx]\n#     X_valid = train[features].iloc[val_idx]\n#     y_valid = target.iloc[val_idx]\n#     X_test = test[features]\n    \n#     start = time.time()\n#     model = lgbm.LGBMClassifier(**best_params)\n#     model.fit(\n#         X_train, \n#         y_train,\n#         eval_set=[(X_valid, y_valid)],\n#         eval_metric='auc',\n#         early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n#         verbose=VERBOSE,\n#     )\n    \n#     fi_tmp = pd.DataFrame()\n#     fi_tmp['feature'] = model.feature_name_\n#     fi_tmp['importance'] = model.feature_importances_\n#     fi_tmp['fold'] = fold\n#     fi_tmp['seed'] = SEED\n#     lgb_importances = lgb_importances.append(fi_tmp)\n\n#     lgb_oof[val_idx] = model.predict_proba(X_valid)[:, -1]\n#     lgb_pred += model.predict_proba(X_test)[:, -1] / N_SPLITS\n\n#     elapsed = time.time() - start\n#     auc = roc_auc_score(y_valid, lgb_oof[val_idx])\n#     print(f\"fold {fold} - lgb auc: {auc:.6f}, elapsed time: {elapsed:.2f}sec\\n\")\n\n# print(f\"oof lgb roc = {roc_auc_score(target, lgb_oof)}\")\n\n# np.save(\"lgb_oof.npy\", lgb_oof)\n# np.save(\"lgb_pred.npy\", lgb_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb_pred = model.predict_proba(test)[:,-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub['target'] = lgb_pred\n# sub.to_csv(\"submission.csv\", index=False)\n# sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}