{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# source : https://catboost.ai/en/docs/\n","metadata":{}},{"cell_type":"markdown","source":"# # some of the columns have binary data and some have continuous (float values ) in it , we are going to categorise them in binary and continuous","metadata":{}},{"cell_type":"code","source":"# binary_feature = []\n# continuous_feature = [] \n# for feature in features:\n#     if \"int\" in str(train_df[feature].dtype):   \n#         binary_feature.append(feature)\n#     else:\n#         continuous_feature.append(feature)\n# print('binary features' , binary_feature , '\\n')\n# print('continuous_feature' , continuous_feature) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check count of conti feature col and binary features col\n#len(binary_feature) , len(continuous_feature )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# #new code","metadata":{"execution":{"iopub.status.busy":"2021-10-16T15:54:37.781001Z","iopub.execute_input":"2021-10-16T15:54:37.781357Z","iopub.status.idle":"2021-10-16T15:54:37.798165Z","shell.execute_reply.started":"2021-10-16T15:54:37.78127Z","shell.execute_reply":"2021-10-16T15:54:37.797238Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/tabular-playground-series-oct-2021/train.csv' )\ntestset = pd.read_csv('/kaggle/input/tabular-playground-series-oct-2021/test.csv' )  # we can reduce the size of \n                                                                                     #data by selecting 1000- rows only by adding parameter as\n                                                                                    # nrows=10000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# kde plot\n# displot","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:15:04.064637Z","iopub.execute_input":"2021-10-21T05:15:04.064893Z","iopub.status.idle":"2021-10-21T05:15:04.06934Z","shell.execute_reply.started":"2021-10-21T05:15:04.064866Z","shell.execute_reply":"2021-10-21T05:15:04.067499Z"}}},{"cell_type":"code","source":"X1 = dataset.drop('target', axis=1)\ncols = ['f10', 'f30', 'f50','f70' , 'f90', 'f110', 'f130', 'f150', 'f170' , 'f190','f210' ,'f230' ,'f250','f270','f280']\nX1 = X1[cols]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"lets check how the feature value is deviating ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport random\nimport os\nimport plotly.figure_factory as ff","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_data = [X1.f10,  X1.f30,  X1.f50,  X1.f70,  X1.f90,  X1.f110,  X1.f130,  X1.f150, X1.f170 ,  X1.f190 , X1.f210,  X1.f230,  X1.f250,  X1.f270, X1.f280 ]\nlabel = X1.columns.to_list()\nfig = ff.create_distplot(X_data, label, bin_size=0.3, show_hist=False, show_rug=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# kde conclusion : features are not in a same proportion there is so much variation in it, so we have to select all the features in terms of geting high accuracy","metadata":{"execution":{"iopub.status.busy":"2021-10-21T04:21:49.853487Z","iopub.execute_input":"2021-10-21T04:21:49.854126Z","iopub.status.idle":"2021-10-21T04:21:49.858839Z","shell.execute_reply.started":"2021-10-21T04:21:49.854084Z","shell.execute_reply":"2021-10-21T04:21:49.858153Z"}}},{"cell_type":"code","source":"pip install catboost\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\nimport catboost as cb\nfrom catboost import CatBoostClassifier\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape #, target.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = dataset['target']\nfeature = dataset.drop(columns=['id','target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(feature,target, test_size = 0.3, random_state = 60,shuffle=True)\nprint(len(X_train))\nprint(len(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_params = {\n    'iterations': 15585, \n    'objective': 'CrossEntropy', \n    'bootstrap_type': 'Bernoulli',\n    'learning_rate': 0.023575206684596582, \n    'reg_lambda': 36.30433203563295, \n    'random_strength': 43.75597655616195, \n    'depth': 8, \n    'min_data_in_leaf': 11, \n    'leaf_estimation_iterations': 1, \n    'subsample': 0.8227911142845009,\n    #'task_type' : 'GPU',\n    'eval_metric' : 'AUC',\n    'verbose' : 1000,\n    'early_stopping_rounds' : 500,\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat = CatBoostClassifier(**cat_params )\n\ncat.fit(X_train, Y_train)\n\ntest_predict = cat.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('hello')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# graph\nres = cat.calc_feature_statistics(feature,\n                                    target,\n                                    feature=2,\n                                    plot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as sm\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_proba = cat.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(Y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(Y_test, y_pred_proba)\nprint(auc)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testid = testset['id']\ntestset= testset.drop(columns=['id']) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prdict =cat.predict_proba(testset)[:, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(list(zip(testid, y_prdict)),\n               columns =['id', 'target'])\nsubmission.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\" , index=False )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}