{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\nThis notebook experiments with the TabTransformer, which learns contextual embeddings to achieve higher prediction accuracy.  \nIn a supervised-only setting, the architectures performs on par with GBDTs from benchmarks.  \n  \nImprovements so far, include:\n - Discretising continuous features to pass to transformer blocks\n - Training with a flat learning rate\n - This version experiments with feeding only column embeddings to the transformer \n \nSo far the best local CV is ~*85* AUROC, using 242 continuous columns, and 242 (cont) + 42 (cat) categorical features.    \nThanks for reading\n ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\nfrom tqdm import tqdm\nfrom torchmetrics import AUROC\nimport matplotlib.pyplot as plt\nimport gc, sys, random, warnings\ngc.enable()\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:38:00.669245Z","iopub.execute_input":"2021-10-05T00:38:00.669511Z","iopub.status.idle":"2021-10-05T00:38:05.851732Z","shell.execute_reply.started":"2021-10-05T00:38:00.669482Z","shell.execute_reply":"2021-10-05T00:38:05.850956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tab-transformer-pytorch\nfrom tab_transformer_pytorch import TabTransformer","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:38:05.85329Z","iopub.execute_input":"2021-10-05T00:38:05.853542Z","iopub.status.idle":"2021-10-05T00:38:14.488205Z","shell.execute_reply.started":"2021-10-05T00:38:05.853509Z","shell.execute_reply":"2021-10-05T00:38:14.487274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_all(seed_value):\n    random.seed(seed_value) # Python\n    np.random.seed(seed_value) # cpu vars\n    torch.manual_seed(seed_value) # cpu  vars\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value) # gpu vars\n        torch.backends.cudnn.deterministic = True  #needed\nseed_all(123)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:38:14.489836Z","iopub.execute_input":"2021-10-05T00:38:14.490157Z","iopub.status.idle":"2021-10-05T00:38:14.556427Z","shell.execute_reply.started":"2021-10-05T00:38:14.490114Z","shell.execute_reply":"2021-10-05T00:38:14.555663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-oct-2021/train.csv', nrows = 500000) # memory issues on kaggle cpu\ntest_df =  pd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')\n\ntrain_df.drop('id',1, inplace=True)\ntest_df.drop('id',1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:38:14.558467Z","iopub.execute_input":"2021-10-05T00:38:14.55897Z","iopub.status.idle":"2021-10-05T00:39:11.640243Z","shell.execute_reply.started":"2021-10-05T00:38:14.558932Z","shell.execute_reply":"2021-10-05T00:39:11.63942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploration and Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"`train_df` has a mix of continuous and potentially one-hot encoded categorical features.  \nInteger features start at index 242. We'll save the columns for preprocessing/splitting later","metadata":{}},{"cell_type":"code","source":"cont_cols = train_df.columns[:242]\ncat_cols = train_df.columns[242:-1]","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:39:11.64135Z","iopub.execute_input":"2021-10-05T00:39:11.641595Z","iopub.status.idle":"2021-10-05T00:39:11.645469Z","shell.execute_reply.started":"2021-10-05T00:39:11.641563Z","shell.execute_reply":"2021-10-05T00:39:11.644815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll scale the data here with a Gauss Rank transform, with code originally from the MOA competition:  \n  https://www.kaggle.com/kushal1506/moa-pytorch-0-01859-rankgauss-pca-nn","metadata":{}},{"cell_type":"code","source":"train_scaled, test_scaled = train_df.copy(), test_df.copy()\nfor col in cont_cols:\n    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n    vec_len = len(train_scaled[col].values)\n    vec_len_test = len(test_scaled[col].values)\n    raw_vec = train_scaled[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n\n    train_scaled[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_scaled[col] = transformer.transform(test_scaled[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:39:11.646577Z","iopub.execute_input":"2021-10-05T00:39:11.647292Z","iopub.status.idle":"2021-10-05T00:39:57.562385Z","shell.execute_reply.started":"2021-10-05T00:39:11.647255Z","shell.execute_reply":"2021-10-05T00:39:57.561538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2)\naxs[0].title.set_text('F0 dist before Gauss Rank')\naxs[0].hist(train_df.f0, bins = 100)\n\naxs[1].title.set_text('F0 dist after Gauss Rank')\naxs[1].hist(train_scaled.f0, bins = 100)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:39:57.563602Z","iopub.execute_input":"2021-10-05T00:39:57.563857Z","iopub.status.idle":"2021-10-05T00:39:58.288849Z","shell.execute_reply.started":"2021-10-05T00:39:57.563823Z","shell.execute_reply":"2021-10-05T00:39:58.288148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del(train_df); del (test_df); gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:39:58.290225Z","iopub.execute_input":"2021-10-05T00:39:58.290495Z","iopub.status.idle":"2021-10-05T00:39:58.419704Z","shell.execute_reply.started":"2021-10-05T00:39:58.290461Z","shell.execute_reply":"2021-10-05T00:39:58.418842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Discretising Continuous Features \nHere we discretise the scaled features using a `KBinsDiscretizer`  \nFor this version we'll replace continuous features inplace","metadata":{}},{"cell_type":"code","source":"disc = KBinsDiscretizer(n_bins=50, encode='ordinal',strategy='uniform')\ntrain_scaled[cont_cols] = disc.fit_transform(train_scaled[cont_cols])\ntest_scaled[cont_cols] = disc.transform(test_scaled[cont_cols])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:39:58.421146Z","iopub.execute_input":"2021-10-05T00:39:58.421683Z","iopub.status.idle":"2021-10-05T00:41:10.164971Z","shell.execute_reply.started":"2021-10-05T00:39:58.421645Z","shell.execute_reply":"2021-10-05T00:41:10.164206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train_scaled.target.values\ntrain_scaled = train_scaled.drop('target', 1).values\ntest_scaled = test_scaled.values","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:41:10.167535Z","iopub.execute_input":"2021-10-05T00:41:10.167804Z","iopub.status.idle":"2021-10-05T00:41:11.293363Z","shell.execute_reply.started":"2021-10-05T00:41:10.16777Z","shell.execute_reply":"2021-10-05T00:41:11.292642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"class AverageMeter:\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:41:11.29474Z","iopub.execute_input":"2021-10-05T00:41:11.295031Z","iopub.status.idle":"2021-10-05T00:41:11.300558Z","shell.execute_reply.started":"2021-10-05T00:41:11.294997Z","shell.execute_reply":"2021-10-05T00:41:11.299837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=7, mode=\"max\", delta=0.001, verbose = None):\n        self.patience = patience\n        self.counter = 0\n        self.mode = mode\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n        self.verbose = verbose\n        if self.mode == \"min\":\n            self.val_score = np.Inf\n        else:\n            self.val_score = -np.Inf\n\n    def __call__(self, epoch_score, model, model_path):\n\n        if self.mode == \"min\":\n            score = -1.0 * epoch_score\n        else:\n            score = np.copy(epoch_score)\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model, model_path)\n        elif score < self.best_score: #  + self.delta\n            self.counter += 1\n            if self.verbose:\n                print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model, model_path)\n            self.counter = 0\n\n    def save_checkpoint(self, epoch_score, model, model_path):\n        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n            if self.verbose:\n                print('Validation score improved ({:.4f} --> {:.4f}). Saving model!'.format(self.val_score, epoch_score))\n                \n            torch.save(model.state_dict(), model_path)\n        self.val_score = epoch_score","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:41:11.301914Z","iopub.execute_input":"2021-10-05T00:41:11.302343Z","iopub.status.idle":"2021-10-05T00:41:11.314651Z","shell.execute_reply.started":"2021-10-05T00:41:11.302308Z","shell.execute_reply":"2021-10-05T00:41:11.313996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def split_df(df):\n#     _cont = df.filter(cont_cols).values\n#     _cat = df.filter(cat_cols).values\n#     return _cont, _cat\n\n# train_cont, train_cat = split_df(train_scaled)\n# test_cont, test_cat = split_df(test_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:41:11.315898Z","iopub.execute_input":"2021-10-05T00:41:11.316172Z","iopub.status.idle":"2021-10-05T00:41:11.325036Z","shell.execute_reply.started":"2021-10-05T00:41:11.316123Z","shell.execute_reply":"2021-10-05T00:41:11.32431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"# Updated to pass a contant cont value in this version\nclass TabDataset(Dataset):\n    def __init__(self, cat, target = None):\n        super().__init__()\n        self.cat = cat\n        self.target = target\n        \n    def __len__(self):\n        return len(self.cat)\n    \n    def __getitem__(self, idx):\n        cat = self.cat[idx]\n        \n        _dict = {'cont': torch.ones(1),\n                 'cat': torch.LongTensor(cat)}\n        \n        if self.target is not None:\n            target = self.target[idx].item()\n            _dict.update({'target': torch.tensor(target, dtype = torch.float)})\n        \n        return _dict","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:41:11.326359Z","iopub.execute_input":"2021-10-05T00:41:11.326735Z","iopub.status.idle":"2021-10-05T00:41:11.334509Z","shell.execute_reply.started":"2021-10-05T00:41:11.326701Z","shell.execute_reply":"2021-10-05T00:41:11.333567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainer\nThe Trainer manages context and training for single epochs  \n  \nA `metric` object is created in evaluation to compute AUROC, which is used for saving weights/early stopping  ","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, device, loss_fn, opt, scheduler = None):\n        self.model = model\n        self.device = device\n        self.loss_fn = loss_fn\n        self.opt = opt\n        self.scheduler = scheduler\n        \n    def fit_one_epoch(self, dl):\n        self.model.train()\n        losses = AverageMeter()\n        prog_bar = tqdm(enumerate(dl), total = len(dl), file=sys.stdout, leave = False)\n        \n        for bi, d in prog_bar:\n            cont = d[\"cont\"].to(self.device)\n            cat = d['cat'].to(self.device)\n            target = d['target'].to(self.device)\n            \n            out = self.model(cat, cont)\n            loss = self.loss_fn(out.squeeze(-1), target)\n            prog_bar.set_description('loss: {:.2f}'.format(loss.item()))\n            losses.update(loss.item(), cont.size(0))\n            loss.backward()\n            self.opt.step()\n            \n            if self.scheduler: \n                self.scheduler.step()\n                    \n            self.opt.zero_grad()\n            \n    def eval_one_epoch(self, dl, **kwargs):\n        self.model.eval()\n        losses = AverageMeter()\n        metric = AUROC()\n        prog_bar = tqdm(enumerate(dl), total = len(dl), file=sys.stdout, leave = False)\n        \n        for bi, d in prog_bar:  \n            cont = d[\"cont\"].to(self.device)\n            cat = d['cat'].to(self.device)\n            target = d['target'].to(self.device)\n            \n            with torch.no_grad():\n                out = self.model(cat, cont)\n                loss = self.loss_fn(out.squeeze(-1), target)\n                if metric:\n                    auroc = metric(out.squeeze(-1), target.int())\n                \n                losses.update(loss.item(), cont.size(0))\n        auroc = metric.compute()\n        print(f\"F{kwargs['fold']} E{str(kwargs['epoch']):2s}\"\\\n              f\"  Valid Loss: {losses.avg:.4f}  AUROC Score: {auroc:.4f}\")\n        return auroc.cpu() if metric else losses.avg","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:42:39.638254Z","iopub.execute_input":"2021-10-05T00:42:39.63851Z","iopub.status.idle":"2021-10-05T00:42:39.657659Z","shell.execute_reply.started":"2021-10-05T00:42:39.638482Z","shell.execute_reply":"2021-10-05T00:42:39.656815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"markdown","source":"<img align=\"left\" src=https://raw.githubusercontent.com/lucidrains/tab-transformer-pytorch/main/tab.png>","metadata":{}},{"cell_type":"markdown","source":"The TabTransformer uses both categorical and continuous features to model tabular data.  \nOnly the categorical features/column embeddings are passed to the self-attention layers with this architecture.   \n  \nIn our case, only features $F242 ... F284$ are passed to the transformer blocks.  \n  It could be interesting to experiment with discretising the continuous features and passing them to the transformer as well","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"class cfg:\n    bs = 400\n    n_splits = 5\n    seed = 2021\n    epochs = 3\n    lr = 2e-5\n    checkpoint = lambda fold: f'full_cat_{fold}.pt'\n    \nkfold = StratifiedKFold(n_splits = cfg.n_splits, \n                        random_state = cfg.seed, \n                        shuffle = True)\nsplits = [*kfold.split(X = train_scaled, y = y_train)]","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:42:41.343425Z","iopub.execute_input":"2021-10-05T00:42:41.343942Z","iopub.status.idle":"2021-10-05T00:42:41.431788Z","shell.execute_reply.started":"2021-10-05T00:42:41.343908Z","shell.execute_reply":"2021-10-05T00:42:41.431005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_cfg = {\n    'categories' : [50]*242 + [2]*43,           # iterable with the number of unique values for categoric feature\n    'num_continuous' : 1,                       # continuous dimensions in data\n    'dim' : 32,                                 # hidden dim, paper set at 32\n    'dim_out' : 1,                              # binary prediction\n    'depth' : 3,                                # depth, paper recommended 6\n    'heads' : 6,                                # heads, paper recommends 8\n    'attn_dropout' : 0.1,                       # post-attention dropout\n    'ff_dropout' : 0.1,                         # feed forward dropout\n    'mlp_hidden_mults' : (4, 2),                # relative multiples of each hidden dimension of the last mlp to logits\n    'mlp_act' : nn.GELU(),                      # activation for final mlp, defaults to relu\n    'continuous_mean_std' : torch.randn(1, 2)   # normalize the continuous values before layer norm (optional)\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:42:42.083242Z","iopub.execute_input":"2021-10-05T00:42:42.083968Z","iopub.status.idle":"2021-10-05T00:42:42.11099Z","shell.execute_reply.started":"2021-10-05T00:42:42.08393Z","shell.execute_reply":"2021-10-05T00:42:42.110106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:42:44.018049Z","iopub.execute_input":"2021-10-05T00:42:44.018815Z","iopub.status.idle":"2021-10-05T00:42:44.023508Z","shell.execute_reply.started":"2021-10-05T00:42:44.018767Z","shell.execute_reply":"2021-10-05T00:42:44.022412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataloaders(fold):\n    train_idx, valid_idx = splits[fold]\n    \n    _xtr, _ytr = train_scaled[train_idx], y_train[train_idx]\n    _xval, _yval = train_scaled[valid_idx], y_train[valid_idx]\n    \n    train_ds = TabDataset(cat = _xtr, target = _ytr)\n    valid_ds = TabDataset(cat = _xval, target = _yval)\n                          \n    train_dl = DataLoader(train_ds, batch_size = cfg.bs, shuffle = True)\n    valid_dl = DataLoader(valid_ds, batch_size = cfg.bs, shuffle = False)\n    \n    return train_dl, valid_dl","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:42:44.608169Z","iopub.execute_input":"2021-10-05T00:42:44.608725Z","iopub.status.idle":"2021-10-05T00:42:44.61665Z","shell.execute_reply.started":"2021-10-05T00:42:44.608687Z","shell.execute_reply":"2021-10-05T00:42:44.615684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fold(fold, epochs = 20):\n    train_dl, valid_dl = create_dataloaders(fold)\n    es = EarlyStopping(patience = 7, mode=\"max\", verbose = False)\n    \n    model = TabTransformer(**transformer_cfg).to(device)\n    \n    opt = torch.optim.AdamW(model.parameters(), lr = cfg.lr)\n\n    trainer = Trainer(model, \n                      device, \n                      loss_fn=nn.BCEWithLogitsLoss(),\n                      opt = opt,\n                      scheduler = None,\n                     )\n    \n    for epoch in range(epochs):\n        trainer.fit_one_epoch(train_dl)\n        valid_loss = trainer.eval_one_epoch(valid_dl, fold = fold, epoch = epoch)\n        \n        es(valid_loss, trainer.model, model_path = cfg.checkpoint(fold))\n        \n        if es.early_stop:\n            break","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:42:45.974567Z","iopub.execute_input":"2021-10-05T00:42:45.9751Z","iopub.status.idle":"2021-10-05T00:42:45.983438Z","shell.execute_reply.started":"2021-10-05T00:42:45.975062Z","shell.execute_reply":"2021-10-05T00:42:45.981658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(cfg.n_splits):\n    train_fold(fold, cfg.epochs)\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T22:31:04.394257Z","iopub.execute_input":"2021-10-04T22:31:04.394498Z","iopub.status.idle":"2021-10-04T22:32:33.129774Z","shell.execute_reply.started":"2021-10-04T22:31:04.394472Z","shell.execute_reply":"2021-10-04T22:32:33.128601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"y_pred = torch.zeros(len(test_scaled), 1).to(device)\ntest_ds = TabDataset(cat = test_scaled)\ntest_dl = DataLoader(test_ds, batch_size = cfg.bs, shuffle = False)\n\nwith torch.no_grad():\n    for fold in range(cfg.n_splits):\n        preds = []\n        model = TabTransformer(**transformer_cfg).to(device)\n        state_dict = cfg.checkpoint(fold)\n        model.load_state_dict(torch.load(state_dict))\n        model.eval()\n        \n        for d in test_dl:\n            cont = d[\"cont\"].to(device)\n            cat = d['cat'].to(device)\n            out = model(cat, cont)\n            preds.append(out)\n            \n        preds = torch.vstack(preds)\n        y_pred += preds / cfg.n_splits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-oct-2021/sample_submission.csv')\nsub.iloc[:,1] = y_pred.cpu()\nsub = sub.set_index('id')\nsub.to_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]}]}