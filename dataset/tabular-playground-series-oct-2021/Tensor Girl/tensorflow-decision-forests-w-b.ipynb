{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"                             \n\n![](https://drive.google.com/uc?id=13IkWjxQcDEX8UMYP4U8YN6O6zc7TVRQD)\n\n","metadata":{}},{"cell_type":"markdown","source":"For Tabular Playground Series - October 2021 , we have a synthetic dataset generated using CTGAN and  the original dataset deals with predicting the biological response of molecules given various chemical properties.. Although the features are anonymized, they have properties relating to real-world features.\n\n# **<span style=\"color:#e76f51;\">Goal</span>**\n \nThe goal is to a binary target based on a number of feature columns given in the data. The columns are a mix of scaled continuous features and binary features.The data is synthetically generated by a GAN that was trained on real-world molecular response data.\n\n# **<span style=\"color:#e76f51;\">Data</span>**\n\n**Training Data**\n\n> - ```train.csv``` -  the training data with the target column\n> - ```test.csv``` - the test set; you will be predicting the target for each row in this file (the probability of the binary target)\n> - ```sample_submission.csv``` - a sample submission file in the correct format\n\n# **<span style=\"color:#e76f51;\">Metric</span>**\n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://camo.githubusercontent.com/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">\n\n> I will be integrating W&B for visualizations and logging artifacts!\n> \n> [TPS October Project on W&B Dashboard]\n(https://wandb.ai/usharengaraju/TPSOctober)\n> \n> - To get the API key, create an account in the [website](https://wandb.ai/site) .\n> - Use secrets to use API Keys more securely ","metadata":{}},{"cell_type":"code","source":"!pip3 install tensorflow_decision_forests --upgrade\n\nimport os\nimport wandb\nimport logging\nimport datetime\nimport warnings\nimport gc\n\nimport numpy as np\nimport pandas as pd\n\n\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')\n\nimport tensorflow_decision_forests as tfdf\n\nsns.set_style('whitegrid')\nsns_params = {\"palette\": sns.color_palette([\"#2a9d8f\", \"#e9c46a\"])}","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-04T16:23:39.192781Z","iopub.execute_input":"2021-10-04T16:23:39.193151Z","iopub.status.idle":"2021-10-04T16:24:56.901429Z","shell.execute_reply.started":"2021-10-04T16:23:39.193062Z","shell.execute_reply":"2021-10-04T16:24:56.900573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"api_key\")\n    wandb.login(key=secret_value_0)\n    anony=None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n    \nCONFIG = dict(competition = 'TPSOctober',_wandb_kernel = 'tensorgirl')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:38:48.171879Z","iopub.execute_input":"2021-10-04T16:38:48.17269Z","iopub.status.idle":"2021-10-04T16:38:48.754962Z","shell.execute_reply.started":"2021-10-04T16:38:48.172638Z","shell.execute_reply":"2021-10-04T16:38:48.754161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-oct-2021/train.csv\",nrows = 1000)\ntest = pd.read_csv(\"../input/tabular-playground-series-oct-2021/test.csv\",nrows = 1000)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:24:57.107816Z","iopub.execute_input":"2021-10-04T16:24:57.108176Z","iopub.status.idle":"2021-10-04T16:24:57.308727Z","shell.execute_reply.started":"2021-10-04T16:24:57.108148Z","shell.execute_reply":"2021-10-04T16:24:57.308103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">Observations</span>**\n\nThere are no missing values in both train ans test dataset.\nThe train consists of 1000000 data, and the test consists of 500000 data.\nThe binary features are from f22, f43, f242~f284 and rest of the features are continuous .\n\n\nSource : https://www.kaggle.com/subinium/tps-oct-simple-eda","metadata":{}},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">Basic Statistics of Features</span>**","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'f0':'f284'].describe().style.background_gradient(cmap='Pastel1')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:24:57.310357Z","iopub.execute_input":"2021-10-04T16:24:57.310693Z","iopub.status.idle":"2021-10-04T16:24:58.419482Z","shell.execute_reply.started":"2021-10-04T16:24:57.310666Z","shell.execute_reply":"2021-10-04T16:24:58.418922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">Target Variable Distribution</span>**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nsns.kdeplot(train[\"target\"] ,fill=True, color = \"#2a9d8f\")\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:24:58.420489Z","iopub.execute_input":"2021-10-04T16:24:58.420805Z","iopub.status.idle":"2021-10-04T16:24:58.78947Z","shell.execute_reply.started":"2021-10-04T16:24:58.42078Z","shell.execute_reply":"2021-10-04T16:24:58.788583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">Target Class Balance</span>**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nplt.pie([508,492], labels = [\"0\" , \"1\"],autopct='%1.1f%%',colors = [\"#2a9d8f\", \"#e9c46a\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:24:58.790933Z","iopub.execute_input":"2021-10-04T16:24:58.79114Z","iopub.status.idle":"2021-10-04T16:24:58.894724Z","shell.execute_reply.started":"2021-10-04T16:24:58.791116Z","shell.execute_reply":"2021-10-04T16:24:58.89389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">Distribution of features Vs Target</span>**","metadata":{}},{"cell_type":"code","source":"#code copied from https://www.kaggle.com/subinium/tps-oct-simple-eda\n\nfig, axes = plt.subplots(11,11,figsize=(12, 12))\naxes = axes.flatten()\nsns.set_palette(sns.color_palette([\"#2a9d8f\", \"#e9c46a\"]))\n\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=train, x=f'f{idx}',ax=ax,palette = [\"#2a9d8f\"])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    ax.set_title(f'f{idx}', loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average by class (by feature f0-f120)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:24:58.896014Z","iopub.execute_input":"2021-10-04T16:24:58.896313Z","iopub.status.idle":"2021-10-04T16:25:07.129483Z","shell.execute_reply.started":"2021-10-04T16:24:58.89627Z","shell.execute_reply":"2021-10-04T16:25:07.128889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#code copied from https://www.kaggle.com/craigmthomas/tps-oct-2021-eda\n\ncat_features = [\"f22\", \"f43\"]\ncat_features.extend([\"f{}\".format(x) for x in range(242, 285)])\n\nfig, axs = plt.subplots(11, 4, figsize=(4*4, 11*3), squeeze=False, sharey=True)\n\nptr = 0\nfor row in range(11):\n    for col in range(4):  \n        x = train[[cat_features[ptr], \"target\"]].value_counts().sort_index().to_frame().rename({0: \"# of Samples\"}, axis=\"columns\").reset_index()\n        sns.barplot(x=cat_features[ptr], y=\"# of Samples\", hue=\"target\", data=x, ax=axs[row][col], **sns_params)\n        plt.xlabel(cat_features[ptr])\n        ptr += 1\n        del(x)\nplt.tight_layout()    \nplt.show()\n\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:25:07.130424Z","iopub.execute_input":"2021-10-04T16:25:07.131121Z","iopub.status.idle":"2021-10-04T16:25:15.021169Z","shell.execute_reply.started":"2021-10-04T16:25:07.131088Z","shell.execute_reply":"2021-10-04T16:25:15.020368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">W & B Artifacts</span>**\n\nAn artifact as a versioned folder of data.Entire datasets can be directly stored as artifacts .\n\nW&B Artifacts are used for dataset versioning, model versioning . They are also used for tracking dependencies and results across machine learning pipelines.Artifact references can be used to point to data in other systems like S3, GCP, or your own system.\n\nYou can learn more about W&B artifacts [here](https://docs.wandb.ai/guides/artifacts)\n\n![](https://drive.google.com/uc?id=1JYSaIMXuEVBheP15xxuaex-32yzxgglV)","metadata":{}},{"cell_type":"code","source":"# Save train data to W&B Artifacts\nrun = wandb.init(project='TPSOctober', name='training_data', anonymous=anony,config=CONFIG) \nartifact = wandb.Artifact(name='training_data',type='dataset')\nartifact.add_file(\"../input/tabular-playground-series-oct-2021/train.csv\")\n\nwandb.log_artifact(artifact)\nwandb.finish()","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-04T16:39:15.609495Z","iopub.execute_input":"2021-10-04T16:39:15.609957Z","iopub.status.idle":"2021-10-04T16:40:02.839212Z","shell.execute_reply.started":"2021-10-04T16:39:15.609911Z","shell.execute_reply":"2021-10-04T16:40:02.83837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Snapshot of the artifacts created  \n\n![](https://drive.google.com/uc?id=1w8g5VUO34Wy6Mi3y2M6-Yu6yOdz7qXqA)","metadata":{}},{"cell_type":"markdown","source":"\n# **<span style=\"color:#e76f51;\">Logging to W & B environment</span>**","metadata":{}},{"cell_type":"code","source":"# Log Plots to W&B environment\ntitle = \"Distribution of Target Feature\"\nrun = wandb.init(project='TPSOctober', name=title,anonymous=anony,config=CONFIG)\nfig = sns.kdeplot(train[\"target\"] , color = \"#E4916C\")\nwandb.log({\"Distribution of Target Feature\": fig})\nwandb.finish()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-04T16:32:31.065272Z","iopub.execute_input":"2021-10-04T16:32:31.066006Z","iopub.status.idle":"2021-10-04T16:32:42.533751Z","shell.execute_reply.started":"2021-10-04T16:32:31.065964Z","shell.execute_reply":"2021-10-04T16:32:42.532879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">Tensorflow Decision Forests</span>**\n\nSource : https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\n\n![](https://drive.google.com/uc?id=1u8C0iutX50ajnYPdvnoTyCrtNNECvI_R)\n\nDecision forests are a family of machine learning algorithms with quality and speed competitive with (and often favorable to) neural networks, especially when you’re working with tabular data. They’re built from many decision trees, which makes them easy to use and understand - and you can take advantage of a plethora of interpretability tools and techniques that already exist today.\n\nTF-DF brings this class of models along with a suite of tailored tools to TensorFlow users:\n\nBeginners will find it easier to develop and explain decision forest models. There is no need to explicitly list or pre-process input features (as decision forests can naturally handle numeric and categorical attributes), specify an architecture (for example, by trying different combinations of layers like you would in a neural network), or worry about models diverging. Once your model is trained, you can plot it directly or analyse it with easy to interpret statistics.\nAdvanced users will benefit from models with very fast inference time (sub-microseconds per example in many cases). And, this library offers a great deal of composability for model experimentation and research. In particular, it is easy to combine neural networks and decision forests.\nIf you’re already using decision forests outside of TensorFlow, here’s a little of what TF-DF offers:\n\nIt provides a slew of state-of-the-art Decision Forest training and serving algorithms such as random forests, gradient-boosted trees, CART, (Lambda)MART, DART, Extra Trees, greedy global growth, oblique trees, one-side-sampling, categorical-set learning, random categorical learning, out-of-bag evaluation and feature importance, and structural feature importance.\nThis library can serve as a bridge to the rich TensorFlow ecosystem by making it easier for you to integrate tree-based models with various TensorFlow tools, libraries, and platforms such as TFX.\nAnd for users new to neural networks, you can use decision forests as an easy way to get started with TensorFlow, and continue to explore neural networks from there.\n","metadata":{}},{"cell_type":"code","source":"\n\n# Convert the dataset into a TensorFlow dataset.\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"target\")\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test)\n\n# Train the model\nmodel = tfdf.keras.RandomForestModel()\nmodel.fit(train_ds)\n\n# Look at the model.\n#model.summary()\n\n# Evaluate the model.\noutput = model.predict(test_ds)\n\n# Export to a TensorFlow SavedModel.\n# Note: the model is compatible with Yggdrasil Decision Forests.\n# **<span style=\"color:#AB51E9;\">References</span>**model.save(\"project/model\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-04T16:26:45.470726Z","iopub.execute_input":"2021-10-04T16:26:45.471275Z","iopub.status.idle":"2021-10-04T16:27:05.432296Z","shell.execute_reply.started":"2021-10-04T16:26:45.471241Z","shell.execute_reply":"2021-10-04T16:27:05.431419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">Visualize the Output</span>**","metadata":{}},{"cell_type":"code","source":"sns.histplot(pd.DataFrame(output),legend = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:27:05.43365Z","iopub.execute_input":"2021-10-04T16:27:05.434007Z","iopub.status.idle":"2021-10-04T16:27:05.784313Z","shell.execute_reply.started":"2021-10-04T16:27:05.433965Z","shell.execute_reply":"2021-10-04T16:27:05.783554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#e76f51;\">References</span>**\n\nhttps://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\n\nhttps://www.kaggle.com/subinium/tps-oct-simple-eda\n\nhttps://www.kaggle.com/craigmthomas/tps-oct-2021-eda\n\n","metadata":{}},{"cell_type":"markdown","source":"# Work in progress 🚧","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}