{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-06T15:03:49.859678Z","iopub.execute_input":"2021-10-06T15:03:49.859934Z","iopub.status.idle":"2021-10-06T15:03:49.958237Z","shell.execute_reply.started":"2021-10-06T15:03:49.859863Z","shell.execute_reply":"2021-10-06T15:03:49.957559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/tabular-playground-series-oct-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:03:49.959954Z","iopub.execute_input":"2021-10-06T15:03:49.960244Z","iopub.status.idle":"2021-10-06T15:04:46.772574Z","shell.execute_reply.started":"2021-10-06T15:03:49.96021Z","shell.execute_reply":"2021-10-06T15:04:46.771806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:04:46.77382Z","iopub.execute_input":"2021-10-06T15:04:46.774166Z","iopub.status.idle":"2021-10-06T15:04:47.466274Z","shell.execute_reply.started":"2021-10-06T15:04:46.774128Z","shell.execute_reply":"2021-10-06T15:04:47.465553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn import model_selection\n\ndef create_folds(data):\n # we create a new column called kfold and fill it with -1\n data[\"kfold\"] = -1\n \n # the next step is to randomize the rows of the data\n data = data.sample(frac=1).reset_index(drop=True)\n # calculate the number of bins by Sturge's rule\n # I take the floor of the value, you can also\n # just round it\n#  num_bins = int(np.floor(1 + np.log2(len(data))))\n#  # bin targets\n#  data.loc[:, \"bins\"] = pd.cut(\n#  data[\"target\"], bins=num_bins, labels=False\n#  )\n \n # initiate the kfold class from model_selection module\n kf = model_selection.StratifiedKFold(n_splits=5)\n \n # fill the new kfold column\n # note that, instead of targets, we use bins!\n for f, (t_, v_) in enumerate(kf.split(X=data, y=data.target)):\n     data.loc[v_, 'kfold'] = f\n \n # drop the bins column\n#  data = data.drop(\"bins\", axis=1)\n # return dataframe with folds\n return data","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:04:47.468828Z","iopub.execute_input":"2021-10-06T15:04:47.469112Z","iopub.status.idle":"2021-10-06T15:04:47.597066Z","shell.execute_reply.started":"2021-10-06T15:04:47.469079Z","shell.execute_reply":"2021-10-06T15:04:47.596372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=create_folds(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:04:47.598098Z","iopub.execute_input":"2021-10-06T15:04:47.598371Z","iopub.status.idle":"2021-10-06T15:04:50.926695Z","shell.execute_reply.started":"2021-10-06T15:04:47.598341Z","shell.execute_reply":"2021-10-06T15:04:50.925991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xg\nimport joblib\nimport lightgbm as lgb ","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:04:50.928145Z","iopub.execute_input":"2021-10-06T15:04:50.928446Z","iopub.status.idle":"2021-10-06T15:04:53.275129Z","shell.execute_reply.started":"2021-10-06T15:04:50.928411Z","shell.execute_reply":"2021-10-06T15:04:53.274236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    \n    param = {\n        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': 4000,\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n        'use_label_encoder':False\n    }\n    \n    \n    roc_auc_score=0\n    clf = xg.XGBClassifier(**param)\n    for fold in range(5):\n        \n        df_train=df[df.kfold!=fold]\n        df_test=df[df.kfold==fold]\n\n        x_train=df_train.drop(['target','id','kfold'],axis=1).values\n        y_train=df_train.target.values\n\n        x_test=df_test.drop(['target','id','kfold'],axis=1).values\n        y_test=df_test.target.values\n\n    #     clf=RandomForestClassifier()\n        clf.fit(x_train,y_train)\n\n        y_pred = clf.predict_proba(x_test)[:,1]\n        roc_auc_score = roc_auc_score+sklearn.metrics.roc_auc_score(y_test,y_pred)\n    \n    return roc_auc_score/5\n#     return sklearn.model_selection.cross_val_score(clf, x, y, \n#        n_jobs=-1, cv=5).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\n# optimization_function=partial(objective,x=x,y=y)\nstudy.optimize(objective, n_trials=12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i didnot run this here because i have done it already in my local ","metadata":{}},{"cell_type":"code","source":"def run_folds(df,fold):\n    df_train=df[df.kfold!=fold]\n    df_test=df[df.kfold==fold]\n    \n    x_train=df_train.drop(['target','id','kfold'],axis=1).values\n    y_train=df_train.target.values\n    \n    x_test=df_test.drop(['target','id','kfold'],axis=1).values\n    y_test=df_test.target.values\n    #xgboost\n    param={'tree_method':'gpu_hist','lambda': 0.5033009770384954, 'alpha': 0.5585785710700676, 'colsample_bytree': 0.8, \n           'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 263,\n          'use_label_encoder':False,'n_estimators': 4000}\n\n    \n    clf= xg.XGBClassifier(**param)\n    clf.fit(x_train,y_train)\n    \n    y_pred = clf.predict_proba(x_test)[:,1]\n    roc_auc_score = sklearn.metrics.roc_auc_score(y_test,y_pred)\n    print(f\"Fold={fold}, roc_auc_score={roc_auc_score}\")\n    \n    File_name = 'model_lgbmclf' + str(fold)\n    joblib.dump(\n    clf,File_name)\n    \n    \nfor i in range(5):\n    run_folds(df,i)    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i didnot run the aboe code cell also just to save time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param={'tree_method':'gpu_hist','lambda': 0.5033009770384954, 'alpha': 0.5585785710700676, 'colsample_bytree': 0.8, \n           'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 263,\n          'use_label_encoder':False,'n_estimators': 4000}\nxgclf=xg.XGBClassifier(**param)\nxgclf.fit(df.iloc[:,1:-2],df.target)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:04:53.276327Z","iopub.execute_input":"2021-10-06T15:04:53.276651Z","iopub.status.idle":"2021-10-06T15:13:14.531518Z","shell.execute_reply.started":"2021-10-06T15:04:53.276616Z","shell.execute_reply":"2021-10-06T15:13:14.530826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-oct-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:13:14.532936Z","iopub.execute_input":"2021-10-06T15:13:14.533223Z","iopub.status.idle":"2021-10-06T15:13:14.682853Z","shell.execute_reply.started":"2021-10-06T15:13:14.533189Z","shell.execute_reply":"2021-10-06T15:13:14.68206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')\ndf_test = df_test.drop(columns = 'id')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:13:14.684271Z","iopub.execute_input":"2021-10-06T15:13:14.684539Z","iopub.status.idle":"2021-10-06T15:13:43.172894Z","shell.execute_reply.started":"2021-10-06T15:13:14.684505Z","shell.execute_reply":"2021-10-06T15:13:43.172044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_final_avg=xgclf.predict_proba(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:23:14.410912Z","iopub.execute_input":"2021-10-06T15:23:14.411762Z","iopub.status.idle":"2021-10-06T15:24:57.892171Z","shell.execute_reply.started":"2021-10-06T15:23:14.411703Z","shell.execute_reply":"2021-10-06T15:24:57.891387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = y_final_avg","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:24:57.893783Z","iopub.execute_input":"2021-10-06T15:24:57.894038Z","iopub.status.idle":"2021-10-06T15:24:57.903859Z","shell.execute_reply.started":"2021-10-06T15:24:57.894006Z","shell.execute_reply":"2021-10-06T15:24:57.903125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('pred_csv_xg_optuna_tuned2.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T15:24:57.905603Z","iopub.execute_input":"2021-10-06T15:24:57.905929Z","iopub.status.idle":"2021-10-06T15:24:59.166472Z","shell.execute_reply.started":"2021-10-06T15:24:57.905889Z","shell.execute_reply":"2021-10-06T15:24:59.165726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}