{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-07T06:00:05.893691Z","iopub.execute_input":"2021-10-07T06:00:05.894883Z","iopub.status.idle":"2021-10-07T06:00:05.923776Z","shell.execute_reply.started":"2021-10-07T06:00:05.894777Z","shell.execute_reply":"2021-10-07T06:00:05.923183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/tabular-playground-series-oct-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:02:15.934089Z","iopub.execute_input":"2021-10-07T06:02:15.934409Z","iopub.status.idle":"2021-10-07T06:03:24.363551Z","shell.execute_reply.started":"2021-10-07T06:02:15.93437Z","shell.execute_reply":"2021-10-07T06:03:24.362659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:03:24.365254Z","iopub.execute_input":"2021-10-07T06:03:24.365516Z","iopub.status.idle":"2021-10-07T06:03:25.266967Z","shell.execute_reply.started":"2021-10-07T06:03:24.365484Z","shell.execute_reply":"2021-10-07T06:03:25.266089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn import model_selection\n\ndef create_folds(data):\n # we create a new column called kfold and fill it with -1\n data[\"kfold\"] = -1\n \n # the next step is to randomize the rows of the data\n data = data.sample(frac=1).reset_index(drop=True)\n # calculate the number of bins by Sturge's rule\n # I take the floor of the value, you can also\n # just round it\n#  num_bins = int(np.floor(1 + np.log2(len(data))))\n#  # bin targets\n#  data.loc[:, \"bins\"] = pd.cut(\n#  data[\"target\"], bins=num_bins, labels=False\n#  )\n \n # initiate the kfold class from model_selection module\n kf = model_selection.StratifiedKFold(n_splits=5)\n \n # fill the new kfold column\n # note that, instead of targets, we use bins!\n for f, (t_, v_) in enumerate(kf.split(X=data, y=data.target)):\n     data.loc[v_, 'kfold'] = f\n \n # drop the bins column\n#  data = data.drop(\"bins\", axis=1)\n # return dataframe with folds\n return data","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:03:25.268065Z","iopub.execute_input":"2021-10-07T06:03:25.268299Z","iopub.status.idle":"2021-10-07T06:03:25.428354Z","shell.execute_reply.started":"2021-10-07T06:03:25.268273Z","shell.execute_reply":"2021-10-07T06:03:25.427564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=create_folds(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:03:25.430381Z","iopub.execute_input":"2021-10-07T06:03:25.430688Z","iopub.status.idle":"2021-10-07T06:03:29.569624Z","shell.execute_reply.started":"2021-10-07T06:03:25.430658Z","shell.execute_reply":"2021-10-07T06:03:29.568783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nimport xgboost as xg\nimport joblib\nimport lightgbm as lgb ","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:03:29.570894Z","iopub.execute_input":"2021-10-07T06:03:29.571109Z","iopub.status.idle":"2021-10-07T06:03:31.136939Z","shell.execute_reply.started":"2021-10-07T06:03:29.571084Z","shell.execute_reply":"2021-10-07T06:03:31.136262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n#       iris = sklearn.datasets.load_iris()\n#     criterion= trial.suggest_categorical('criterion',['gini','entropy'])\n#     eta=trial.suggest_uniform('eta',0.01,0.1)\n#     lambdaa = trial.suggest_loguniform('lambda', 1e-3, 10.0)\n#     alpha= trial.suggest_loguniform('alpha', 1e-3, 10.0)\n#     colsample_bytree= trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0])\n#     subsample=trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0])\n#     learning_rate = trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02])\n#     n_estimators = 4000\n#     max_depth=trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20])\n#     random_state=trial.suggest_categorical('random_state', [24, 48,2020])\n#     min_child_weight= trial.suggest_int('min_child_weight', 1, 300)\n    \n#     param = {\n#         'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n#         'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n#         'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n#         'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n#         'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n#         'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n#         'n_estimators': 4000,\n#         'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n#         'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n#         'use_label_encoder':False\n#     }\n    \n    param = {\n        \"objective\": \"binary\",\n        \"metric\": \"binary_logloss\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    \n#     eta\n#     n_estimators = trial.suggest_int('n_estimators', 100, 1500)\n#     max_depth = int(trial.suggest_int('max_depth', 5, 30))\n#     min_samples_split=trial.suggest_int('min_samples_split', 1,100)\n#     min_samples_leaf=trial.suggest_int('min_samples_leaf', 1,10)\n#     criterion= trial.suggest_categorical('criterion',['gini','entropy'])\n    roc_auc_score=0\n    clf = lgb.LGBMClassifier(**param)  #xg.XGBClassifier(**param)\n    for fold in range(1):\n        \n        df_train=df[df.kfold!=1]\n        df_test=df[df.kfold==1]\n\n        x_train=df_train.drop(['target','id','kfold'],axis=1).values\n        y_train=df_train.target.values\n\n        x_test=df_test.drop(['target','id','kfold'],axis=1).values\n        y_test=df_test.target.values\n\n    #     clf=RandomForestClassifier()\n        clf.fit(x_train,y_train)\n\n        y_pred = clf.predict_proba(x_test)[:,1]\n        roc_auc_score = roc_auc_score+sklearn.metrics.roc_auc_score(y_test,y_pred)\n    \n    return roc_auc_score\n#     return sklearn.model_selection.cross_val_score(clf, x, y, \n#        n_jobs=-1, cv=5).mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\n# optimization_function=partial(objective,x=x,y=y)\nstudy.optimize(objective, n_trials=12)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_folds(df,fold):\n    df_train=df[df.kfold!=fold]\n    df_test=df[df.kfold==fold]\n    \n    x_train=df_train.drop(['target','id','kfold'],axis=1).values\n    y_train=df_train.target.values\n    \n    x_test=df_test.drop(['target','id','kfold'],axis=1).values\n    y_test=df_test.target.values\n    #xgboost\n#     param={'tree_method':'gpu_hist','lambda': 0.5033009770384954, 'alpha': 0.5585785710700676, 'colsample_bytree': 0.8, \n#            'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 263,\n#           'use_label_encoder':False,'n_estimators': 4000}\n\n    #lgbm\n    \n    param={\"objective\": \"binary\",\n        \"metric\": \"binary_logloss\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n           'lambda_l1': 1.4536206738653063e-07, 'lambda_l2': 6.458971864500743e-08, 'num_leaves': 131, \n           'feature_fraction': 0.5474311915512885,\n           'bagging_fraction': 0.9388678532827928,\n           'bagging_freq': 6, 'min_child_samples': 13}\n    \n    clf= lgb.LGBMClassifier(**param)#xg.XGBClassifier(**param)\n    clf.fit(x_train,y_train)\n    \n    y_pred = clf.predict_proba(x_test)[:,1]\n    roc_auc_score = sklearn.metrics.roc_auc_score(y_test,y_pred)\n    print(f\"Fold={fold}, roc_auc_score={roc_auc_score}\")\n    \n    File_name = 'model_lgbmclf' + str(fold)\n    joblib.dump(\n    clf,File_name)\n    \n    \nfor i in range(5):\n    run_folds(df,i)    ","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:03:42.478877Z","iopub.execute_input":"2021-10-07T06:03:42.47939Z","iopub.status.idle":"2021-10-07T06:11:15.381476Z","shell.execute_reply.started":"2021-10-07T06:03:42.479354Z","shell.execute_reply":"2021-10-07T06:11:15.379292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_0_xgb= joblib.load('./model_lgbmclf0')\nmodel_1_xgb =joblib.load('./model_lgbmclf1')\nmodel_2_xgb= joblib.load('./model_lgbmclf2')\nmodel_3_xgb= joblib.load('./model_lgbmclf3')\nmodel_4_xgb= joblib.load('./model_lgbmclf4')","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:11:15.384067Z","iopub.execute_input":"2021-10-07T06:11:15.384321Z","iopub.status.idle":"2021-10-07T06:11:15.445543Z","shell.execute_reply.started":"2021-10-07T06:11:15.384293Z","shell.execute_reply":"2021-10-07T06:11:15.444696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')\ndf_test = df_test.drop(columns = 'id')","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:11:15.446908Z","iopub.execute_input":"2021-10-07T06:11:15.447686Z","iopub.status.idle":"2021-10-07T06:11:47.258142Z","shell.execute_reply.started":"2021-10-07T06:11:15.447648Z","shell.execute_reply":"2021-10-07T06:11:47.257504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_final_3 = model_3_xgb.predict_proba(df_test)[:,1]\ny_final_0 = model_0_xgb.predict_proba(df_test)[:,1]\ny_final_1 = model_1_xgb.predict_proba(df_test)[:,1]\ny_final_2 = model_2_xgb.predict_proba(df_test)[:,1]\ny_final_4 = model_4_xgb.predict_proba(df_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:11:47.260459Z","iopub.execute_input":"2021-10-07T06:11:47.260969Z","iopub.status.idle":"2021-10-07T06:12:05.157635Z","shell.execute_reply.started":"2021-10-07T06:11:47.260925Z","shell.execute_reply":"2021-10-07T06:12:05.15693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_final_avg = (y_final_0 + y_final_1 +y_final_2 + y_final_3 + y_final_4)/5","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:12:05.158838Z","iopub.execute_input":"2021-10-07T06:12:05.159234Z","iopub.status.idle":"2021-10-07T06:12:05.166159Z","shell.execute_reply.started":"2021-10-07T06:12:05.159189Z","shell.execute_reply":"2021-10-07T06:12:05.165589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-oct-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:12:05.167052Z","iopub.execute_input":"2021-10-07T06:12:05.167723Z","iopub.status.idle":"2021-10-07T06:12:05.347549Z","shell.execute_reply.started":"2021-10-07T06:12:05.167694Z","shell.execute_reply":"2021-10-07T06:12:05.346685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_final_avg=clf.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:12:05.348871Z","iopub.execute_input":"2021-10-07T06:12:05.349108Z","iopub.status.idle":"2021-10-07T06:12:05.484883Z","shell.execute_reply.started":"2021-10-07T06:12:05.349079Z","shell.execute_reply":"2021-10-07T06:12:05.483796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = y_final_avg ","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:13:20.251846Z","iopub.execute_input":"2021-10-07T06:13:20.252232Z","iopub.status.idle":"2021-10-07T06:13:20.262063Z","shell.execute_reply.started":"2021-10-07T06:13:20.252177Z","shell.execute_reply":"2021-10-07T06:13:20.260787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('pred_csv_lgbm_optuna2.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T06:13:21.589456Z","iopub.execute_input":"2021-10-07T06:13:21.590037Z","iopub.status.idle":"2021-10-07T06:13:23.441941Z","shell.execute_reply.started":"2021-10-07T06:13:21.589989Z","shell.execute_reply":"2021-10-07T06:13:23.441066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}