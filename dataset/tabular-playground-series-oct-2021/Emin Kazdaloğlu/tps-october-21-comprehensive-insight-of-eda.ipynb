{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <p style=\"background-color:#3a2c57; font-family:newtimeroman; margin-bottom:2px; font-size:32px; color: white; text-align:center\">Table of Content</p>  \n\n<a id=\"table-of-contents\"></a>\n1. [Preperation](#preperation)\n    * 1.1. [Loading Packages and Importing Libraries](#load_packages_import_libraries)\n    * 1.2. [Data Description](#data_description)\n2. [Exploratory Data Analysis (EDA)](#eda)\n    * 2.1. [Categorical Variables](#categorical_variables)\n        * 2.1.1. [Number of Categorical Variables](#no_cat_features)\n        * 2.1.2. [Correlation Matrix of Categorical Variables](#corr_categorical_variables)\n    * 2.2. [Numerical Variables](#numerical_variables)\n        * 2.2.1. [Box Plot of Numerical Variables](#box_numerical_variables)\n        * 2.2.2. [KDE Plot of Numerical Variables](#kde_numerical_variables)\n        * 2.2.3. [Correlation Matrix of Numerical Variables](#corr_numerical_variables)\n        * 2.2.4. [Histogram Plot of Numerical Variables](#hist_numerical_variables)\n        * 2.2.5. [Q-Q Plot of Numerical Variables](#qq_numerical_variables)\n    * 2.3. [Normality Check and Outlier Detection](#norm_check_outlier_detect)\n       * 2.3.1. [Mild and Extreme Outlier Detection](#mild_extreme_outlier)","metadata":{}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"preperation\"></a>\n# <p style=\"background-color:#3a2c57; font-family:newtimeroman; font-size:150%; text-align:center\">1. Preperation</p>\n\n\n<a id=\"load_packages_import_libraries\"></a>\n## <p style=\"background-color:#664e99; font-family:newtimeroman; font-size:120%; text-align:center\">1.1. Loading Packages and Importing Libraries</p>\n\n* **Loading packages and importing some helpful libraries.**","metadata":{}},{"cell_type":"code","source":"!pip install simple-colors","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:17:31.077912Z","iopub.execute_input":"2021-10-06T07:17:31.078923Z","iopub.status.idle":"2021-10-06T07:17:39.201568Z","shell.execute_reply.started":"2021-10-06T07:17:31.0787Z","shell.execute_reply":"2021-10-06T07:17:39.200408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom simple_colors import *\nfrom termcolor import colored\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nfrom scipy.stats import normaltest\nfrom scipy import stats\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-06T07:17:39.203659Z","iopub.execute_input":"2021-10-06T07:17:39.203948Z","iopub.status.idle":"2021-10-06T07:17:40.054085Z","shell.execute_reply.started":"2021-10-06T07:17:39.203914Z","shell.execute_reply":"2021-10-06T07:17:40.053193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data_description\"></a>\n## <p style=\"background-color:#664e99; font-family:newtimeroman; font-size:120%; text-align:center\">1.2. Data Description</p>\n\n* **First of all, some setting up options were made. It is aimed to show all rows and columns in order to improve the general view of data sets. Next, I will load the train and test data sets and display train and test data sets as well.**","metadata":{}},{"cell_type":"code","source":"#Setting up options\n\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.options.display.float_format = \"{:,.3f}\".format","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:17:40.0555Z","iopub.execute_input":"2021-10-06T07:17:40.055744Z","iopub.status.idle":"2021-10-06T07:17:40.061891Z","shell.execute_reply.started":"2021-10-06T07:17:40.055715Z","shell.execute_reply":"2021-10-06T07:17:40.060688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\n\ntrain = pd.read_csv('../input/tabular-playground-series-oct-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:17:40.064279Z","iopub.execute_input":"2021-10-06T07:17:40.064499Z","iopub.status.idle":"2021-10-06T07:19:04.340388Z","shell.execute_reply.started":"2021-10-06T07:17:40.064473Z","shell.execute_reply":"2021-10-06T07:19:04.339531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_desc(df):\n    \n    \"\"\"\n    This function helps us with simple data analysis.\n    We may explore the common information about the dataset, missing values, features distribution and duplicated rows\n    \"\"\"\n    \n    # applying info() method\n    print('*******************')\n    print(cyan('General information of this dataset', 'bold'))\n    print('*******************\\n')\n    print(df.info())\n    \n    print('\\n*******************')\n    print(cyan('Number of rows and columns', 'bold'))\n    print('*******************\\n')\n    print(\"Number of rows:\", colored(df.shape[0], 'green', attrs=['bold']))\n    print(\"Number of columns:\", colored(df.shape[1], 'green', attrs=['bold']))\n    \n    # missing values\n    print('\\n*******************')\n    print(cyan('Missing value checking', 'bold'))\n    print('*******************\\n')\n    if df.isna().sum().sum() == 0:\n        print(colored('There are no missing values', 'green'))\n        print('*******************')\n    else:\n        print(colored('Missing value detected!', 'green', attrs=['bold']))\n        print(\"\\nTotal number of missing values:\", colored(sum(df.isna().sum()), 'green', attrs=['bold']))\n        \n        print('\\n*******************')\n        print(cyan('Missing values of features', 'bold'))\n        print('*******************\\n')\n        display(df.isna().sum().sort_values(ascending = False).to_frame().rename({0:'Counts'}, axis = 1).T.style.background_gradient('Purples', axis = None))\n        print('\\n*******************')\n        print(cyan('Percentage of missing values of features', 'bold'))\n        print('*******************\\n')\n        display(round((df.isnull().sum() / (len(df.index)) * 100) , 3).sort_values(ascending = False).to_frame().rename({0:'%'}, axis = 1).T.style.background_gradient('PuBuGn', axis = None))\n\n        \n    # applying describe() method for categorical features\n    cat_feats = [col for col in df.columns if 'int' in str(df[col].dtype) and col not in ('id', 'target')]\n    print('\\n*******************')\n    print(cyan('Categorical columns', 'bold'))\n    print('*******************\\n')\n    print(\"Total categorical (binary) features:\", colored(len(cat_feats), 'green', attrs=['bold']))\n    display(df.describe())\n        \n        \n    # describe() for numerical features\n    cont_feats = [col for col in df.columns if 'float' in str(df[col].dtype) and col not in ('id', 'target')]\n    print('\\n*******************')\n    print(cyan('Numerical columns', 'bold'))\n    print('*******************\\n')\n    print(\"Total numerical features:\", colored(len(cont_feats), 'green', attrs=['bold']))\n    df = df[df.columns.difference(['id', 'claim'], sort = False)]\n    display(df.describe())\n    \n    # Checking for duplicated rows -if any-\n    if df.duplicated().sum() == 0:\n        print('\\n*******************')\n        print(colored('There are no duplicates!', 'green', attrs=['bold']))\n        print('*******************')\n    else:\n        print('\\n*******************')\n        print(colored('Duplicates found!', 'green', attrs=['bold']))\n        print('*******************')\n        display(df[df.duplicated()])\n\n    print('\\n*******************')\n    print(cyan('Preview of the data - Top 10 rows', 'bold'))\n    print('*******************\\n')\n    display(df.head(10))\n    print('*******************\\n')\n    \n    print('\\n*******************')\n    print(cyan('End of the report', 'bold'))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:19:04.342123Z","iopub.execute_input":"2021-10-06T07:19:04.342553Z","iopub.status.idle":"2021-10-06T07:19:04.364736Z","shell.execute_reply.started":"2021-10-06T07:19:04.342512Z","shell.execute_reply":"2021-10-06T07:19:04.36387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_desc(train)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:19:04.366138Z","iopub.execute_input":"2021-10-06T07:19:04.366414Z","iopub.status.idle":"2021-10-06T07:20:02.105443Z","shell.execute_reply.started":"2021-10-06T07:19:04.366374Z","shell.execute_reply":"2021-10-06T07:20:02.10438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_desc(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:02.106783Z","iopub.execute_input":"2021-10-06T07:20:02.107021Z","iopub.status.idle":"2021-10-06T07:20:29.879085Z","shell.execute_reply.started":"2021-10-06T07:20:02.106993Z","shell.execute_reply":"2021-10-06T07:20:29.87843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"eda\"></a>\n# <p style=\"background-color:#3a2c57; font-family:newtimeroman; font-size:150%; text-align:center\">2. Exploratory Data Analysis (EDA)</p>\n\n* **All numerical and categorical variables will be explored in this section.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nax = sns.countplot(y=train[\"target\"], palette='muted', zorder=3, linewidth=5, orient='h', saturation=1, alpha=1)\nax.set_title('Distribution of Target', fontname = 'Times New Roman', fontsize = 30, color = '#8c49e7', x = 0.5, y = 1.05)\nbackground_color = \"#8c49e7\"\nsns.set_palette(['#ffd514']*120)\n\nfor a in ax.patches:\n    value = f'Amount and percentage of values: {a.get_width():,.0f} | {(a.get_width()/train.shape[0]):,.3%}'\n    x = a.get_x() + a.get_width() / 2 - 230000\n    y = a.get_y() + a.get_height() / 2 \n    ax.text(x, y, value, ha='left', va='center', fontsize=18, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round4', linewidth=0.7))\n\n\n# ax.margins(-0.12, -0.12)\nax.grid(axis=\"x\")\n\nsns.despine(right=True)\nsns.despine(offset=15, trim=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:40:06.464094Z","iopub.execute_input":"2021-10-06T07:40:06.464394Z","iopub.status.idle":"2021-10-06T07:40:06.717114Z","shell.execute_reply.started":"2021-10-06T07:40:06.464364Z","shell.execute_reply":"2021-10-06T07:40:06.71617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features =[]\nnumerical_features =[]\n\nfor col in train.columns:\n    if train[col].dtype == 'int64' and col not in ('id', 'target'):\n        categorical_features.append(col)\n    elif train[col].dtype != 'int64' and col not in ('id', 'target'):\n        numerical_features.append(col)\nprint('Catagoric features: ', categorical_features)\nprint()\nprint('Numerical features: ', numerical_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:30.209488Z","iopub.execute_input":"2021-10-06T07:20:30.209777Z","iopub.status.idle":"2021-10-06T07:20:30.219727Z","shell.execute_reply.started":"2021-10-06T07:20:30.209743Z","shell.execute_reply":"2021-10-06T07:20:30.219032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cardinality check\n\nprint(colored(\"In Train Dataset\", 'cyan', attrs=['bold', 'underline']))\nfor col in categorical_features:\n    print('{} unique values in {}'.format(train[col].nunique(), col))\n\nprint()\nprint(colored(\"In Test Dataset\", 'cyan', attrs=['bold', 'underline']))\nfor col in categorical_features:\n    print('{} unique values in {}'.format(test[col].nunique(), col))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:30.222245Z","iopub.execute_input":"2021-10-06T07:20:30.222499Z","iopub.status.idle":"2021-10-06T07:20:30.666357Z","shell.execute_reply.started":"2021-10-06T07:20:30.222469Z","shell.execute_reply":"2021-10-06T07:20:30.66527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cardinality(data):\n    for k in categorical_features:\n        print(f'{k}\\n{(np.round((data[k].value_counts() / len(data[k]))*100,3))}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:30.668226Z","iopub.execute_input":"2021-10-06T07:20:30.66847Z","iopub.status.idle":"2021-10-06T07:20:30.673765Z","shell.execute_reply.started":"2021-10-06T07:20:30.668439Z","shell.execute_reply":"2021-10-06T07:20:30.672801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cardinality(train)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:30.675017Z","iopub.execute_input":"2021-10-06T07:20:30.675267Z","iopub.status.idle":"2021-10-06T07:20:31.006996Z","shell.execute_reply.started":"2021-10-06T07:20:30.67523Z","shell.execute_reply":"2021-10-06T07:20:31.006169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cardinality(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:31.008023Z","iopub.execute_input":"2021-10-06T07:20:31.008263Z","iopub.status.idle":"2021-10-06T07:20:31.191479Z","shell.execute_reply.started":"2021-10-06T07:20:31.008235Z","shell.execute_reply":"2021-10-06T07:20:31.190433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"categorical_variables\"></a>\n## <p style=\"background-color:#664e99; font-family:newtimeroman; font-size:120%; text-align:center\">2.1. Categorical Variables</p>","metadata":{}},{"cell_type":"code","source":"fig = go.Figure([go.Bar(x = train[categorical_features].nunique().index, y = train[categorical_features].nunique().values, marker_color='rgb(100, 14, 175)')])\n#fig.show()\n\nfig.update_traces(marker_line_color='rgb(120, 15, 155)', marker_line_width=1, opacity=0.7)\n\nfig.update_layout(\n    title=\"<b>Number of unique values of categorical features<b>\",\n    width=1600,\n    height=900,\n    \n    xaxis = dict(showline=True,\n    title = '<b>Categorical Variables<b>',\n    tickangle = -30,\n    tickfont = dict(family='Times New Roman', color='black', size=16),\n    titlefont_size = 16,\n    ),\n\n    yaxis = dict(showline=True,\n    ticks = \"outside\", tickwidth=2, tickcolor='red', ticklen=7.5,\n    title = '<b># of unique values<b>',\n    tickfont = dict(family = 'Times New Roman', color='black', size=16),\n    titlefont_size = 16,\n    title_standoff = 5,\n    ),\n    bargap = 0.50, # gap between bars of adjacent location coordinates.   \n)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:31.193069Z","iopub.execute_input":"2021-10-06T07:20:31.193484Z","iopub.status.idle":"2021-10-06T07:20:32.230138Z","shell.execute_reply.started":"2021-10-06T07:20:31.193404Z","shell.execute_reply":"2021-10-06T07:20:32.229308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"no_cat_features\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.1.1. Number of Categorical Variables</p>","metadata":{}},{"cell_type":"code","source":"def count_plot(data, features, titleText, hue=None):\n\n    L = len(features)\n    nrow = int(np.ceil(L/4))\n    ncol = 5\n    remove_last = (nrow * ncol) - L\n\n    fig, axs = plt.subplots(nrow, ncol, figsize=(30, 80))\n    fig.tight_layout()\n    fig.set_facecolor('#e4e4e4')\n\n    while remove_last > 0:\n      axs.flat[-remove_last].set_visible(False)\n      remove_last -= 1\n\n    fig.subplots_adjust(top = 0.97)\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.01, \n                    right=0.9,  \n                    wspace=0.4, \n                    hspace=0.4)\n\n    i = 1\n    for feature in features:\n        plt.subplot(nrow, ncol, i)\n        ax = sns.countplot(x = feature, palette='rocket_r', data=data, hue=None)\n        plt.xlabel(feature, fontsize=14, fontweight = 'bold')\n        plt.ylabel('#', fontsize=14, fontweight = 'bold')\n        for p in ax.patches:\n            height = p.get_height()\n            value = f'{p.get_height():,.0f} | {(p.get_height()/data[feature].shape[0]):,.3%}'\n            ax.text(p.get_x()+p.get_width()/2., height+5000, value, ha=\"center\", fontsize = 12, fontweight = 'bold')     \n        i += 1\n    \n    plt.suptitle(titleText, fontsize = 28, fontweight = 'bold', color = 'darkorange')\n    plt.show()    ","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:48.844993Z","iopub.execute_input":"2021-10-06T07:20:48.846065Z","iopub.status.idle":"2021-10-06T07:20:48.858976Z","shell.execute_reply.started":"2021-10-06T07:20:48.846015Z","shell.execute_reply":"2021-10-06T07:20:48.857833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_plot(train, categorical_features, 'Categorical features of train dataset', hue=None)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:20:54.837747Z","iopub.execute_input":"2021-10-06T07:20:54.838067Z","iopub.status.idle":"2021-10-06T07:21:05.169866Z","shell.execute_reply.started":"2021-10-06T07:20:54.838037Z","shell.execute_reply":"2021-10-06T07:21:05.168996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_plot(test, categorical_features, 'Categorical features of train dataset', hue=None)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:21:24.773674Z","iopub.execute_input":"2021-10-06T07:21:24.774402Z","iopub.status.idle":"2021-10-06T07:21:33.618472Z","shell.execute_reply.started":"2021-10-06T07:21:24.774355Z","shell.execute_reply":"2021-10-06T07:21:33.617401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_plot_testtrain(data1, data2, features, titleText):\n  \n    L = len(features)\n    nrow= int(np.ceil(L/4))\n    ncol= 5\n    remove_last= (nrow * ncol) - L\n\n    fig, axs = plt.subplots(nrow, ncol, figsize=(30, 80))\n    fig.tight_layout()\n    fig.set_facecolor('#e4e4e4')\n\n    while remove_last > 0:\n      axs.flat[-remove_last].set_visible(False)\n      remove_last = remove_last - 1\n\n    fig.subplots_adjust(top = 0.97)\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.01, \n                    right=0.9,  \n                    wspace=0.4, \n                    hspace=0.4)\n    \n    i = 1\n    for feature in features:\n        plt.subplot(nrow, ncol, i)\n        ax = sns.countplot(x=feature, color='#61057c', data=data1, label='train')         \n        ax = sns.countplot(x=feature, color='#b7f035', data=data2, label='test')\n        plt.xlabel(feature, fontsize=14, fontweight = 'bold')\n        plt.ylabel('#', fontsize=14, fontweight = 'bold')\n        ax = ax.legend(loc = \"best\", fontsize = 12)\n        i += 1\n\n    plt.suptitle(titleText, fontsize = 28, fontweight = 'bold', color = 'indigo')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:21:33.620477Z","iopub.execute_input":"2021-10-06T07:21:33.621219Z","iopub.status.idle":"2021-10-06T07:21:33.635969Z","shell.execute_reply.started":"2021-10-06T07:21:33.621163Z","shell.execute_reply":"2021-10-06T07:21:33.635147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_plot_testtrain(train, test, categorical_features, titleText = 'Categorical features of train & test datasets')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:21:38.796812Z","iopub.execute_input":"2021-10-06T07:21:38.797899Z","iopub.status.idle":"2021-10-06T07:21:51.221172Z","shell.execute_reply.started":"2021-10-06T07:21:38.797833Z","shell.execute_reply":"2021-10-06T07:21:51.22029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"corr_categorical_variables\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.1.2. Correlation Matrix of Categorical Variables</p>","metadata":{}},{"cell_type":"code","source":"def correlation_matrix(data, features):\n    \n    fig, ax = plt.subplots(1, 1, figsize = (20, 20))\n    plt.title('Pearson Correlation Matrix', fontweight='bold', fontsize=25)\n    fig.set_facecolor('#d0d0d0') \n    corr = data[features].corr()\n\n    # Mask to hide upper-right part of plot as it is a duplicate\n    mask = np.triu(np.ones_like(corr, dtype = bool))\n    sns.heatmap(corr, annot = False, center = 0, cmap = 'jet', mask = mask, linewidths = .5, square = True, cbar_kws = {\"shrink\": .70})\n    ax.set_xticklabels(ax.get_xticklabels(), fontfamily = 'sans', rotation = 90, fontsize = 12)\n    ax.set_yticklabels(ax.get_yticklabels(), fontfamily = 'sans', rotation = 0, fontsize = 12)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T08:31:15.868979Z","iopub.execute_input":"2021-10-06T08:31:15.869344Z","iopub.status.idle":"2021-10-06T08:31:15.879613Z","shell.execute_reply.started":"2021-10-06T08:31:15.869315Z","shell.execute_reply":"2021-10-06T08:31:15.87833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix(train, categorical_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T08:31:17.364235Z","iopub.execute_input":"2021-10-06T08:31:17.364579Z","iopub.status.idle":"2021-10-06T08:31:25.005318Z","shell.execute_reply.started":"2021-10-06T08:31:17.364535Z","shell.execute_reply":"2021-10-06T08:31:25.004242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix(test, categorical_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T08:31:25.007372Z","iopub.execute_input":"2021-10-06T08:31:25.007721Z","iopub.status.idle":"2021-10-06T08:31:29.25695Z","shell.execute_reply.started":"2021-10-06T08:31:25.007677Z","shell.execute_reply":"2021-10-06T08:31:29.255994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **There is no significant correlation between categorical variables in both train and test dataset. No correlation between variables is even greater than 0.01. Additionally, the relationships between the variables are similar in both data sets.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"numerical_variables\"></a>\n## <p style=\"background-color:#664e99; font-family:newtimeroman; font-size:120%; text-align:center\">2.2. Numerical Variables</p>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"box_numerical_variables\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.2.1. Box Plot of Numerical Variables</p>","metadata":{}},{"cell_type":"code","source":"def box_plot(data, features, titleText, hue=None):\n\n    L = len(features)\n    nrow = int(np.ceil(L/4))\n    ncol = 5\n    remove_last = (nrow * ncol) - L\n\n    fig, axs = plt.subplots(nrow, ncol, figsize=(30, 150))\n    fig.tight_layout()\n    fig.set_facecolor('#e4e4e4')\n\n    while remove_last > 0:\n      axs.flat[-remove_last].set_visible(False)\n      remove_last = remove_last - 1\n\n    fig.subplots_adjust(top = 0.97)\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.01, \n                    right=0.9,  \n                    wspace=0.4, \n                    hspace=0.4)\n    \n    i = 1\n    for feature in features:\n        plt.subplot(nrow, ncol, i)\n        v0 = sns.color_palette(palette = \"pastel\").as_hex()[2]\n        ax = sns.boxplot(x = data[feature], color=v0, saturation=.75)  \n        ax = ax.legend(loc = \"best\")    \n        plt.xlabel(feature, fontsize=14, fontweight = 'bold')\n        plt.ylabel('Values', fontsize=14, fontweight = 'bold')\n        i += 1\n\n    plt.suptitle(titleText, fontsize = 28, fontweight = 'bold', color = 'navy')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:39:22.776744Z","iopub.execute_input":"2021-10-04T11:39:22.777032Z","iopub.status.idle":"2021-10-04T11:39:22.789394Z","shell.execute_reply.started":"2021-10-04T11:39:22.777004Z","shell.execute_reply":"2021-10-04T11:39:22.788622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"box_plot(train, numerical_features, 'Box Plot of Numerical Columns of Train Dataset')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:39:25.751506Z","iopub.execute_input":"2021-10-04T11:39:25.752562Z","iopub.status.idle":"2021-10-04T11:40:54.878949Z","shell.execute_reply.started":"2021-10-04T11:39:25.752516Z","shell.execute_reply":"2021-10-04T11:40:54.878336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"box_plot(test, numerical_features, 'Box Plot of Numerical Columns of Train Dataset')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T11:40:54.880235Z","iopub.execute_input":"2021-10-04T11:40:54.88101Z","iopub.status.idle":"2021-10-04T11:41:57.029403Z","shell.execute_reply.started":"2021-10-04T11:40:54.880974Z","shell.execute_reply":"2021-10-04T11:41:57.028318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **It is very obvious that some features contain significant amount of outlier value in both data sets. This has to be handled.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"kde_numerical_variables\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.2.2. KDE Plot of Numerical Variables</p>","metadata":{}},{"cell_type":"code","source":"def kde_plot(data, features, titleText, hue=None):\n\n    L = len(features)\n    nrow = int(np.ceil(L/4))\n    ncol = 5\n    remove_last = (nrow * ncol) - L\n\n    fig, axs = plt.subplots(nrow, ncol, figsize=(30, 150))\n    fig.tight_layout()\n    fig.set_facecolor('#e4e4e4')\n\n    while remove_last > 0:\n      axs.flat[-remove_last].set_visible(False)\n      remove_last -= 1\n\n    fig.subplots_adjust(top = 0.97)\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9,  \n                    wspace=0.4, \n                    hspace=0.4)\n    i = 1\n    for feature in features:\n        plt.subplot(nrow, ncol, i)\n        ax = sns.kdeplot(data[feature], color=\"m\", shade=True, label=\"%.3f\"%(data[feature].skew()))  \n        ax = ax.legend(loc = \"best\")    \n        plt.xlabel(feature, fontsize=14, fontweight = 'bold')\n        plt.ylabel('Density', fontsize=14, fontweight = 'bold')\n        i += 1\n\n    plt.suptitle(titleText, fontsize = 28, fontweight = 'bold', color = 'navy')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:22:51.987997Z","iopub.execute_input":"2021-10-06T07:22:51.989186Z","iopub.status.idle":"2021-10-06T07:22:52.000369Z","shell.execute_reply.started":"2021-10-06T07:22:51.989121Z","shell.execute_reply":"2021-10-06T07:22:51.999304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Since there is a large amount of data, it may make sense to randomly take some of the data and create the plots.**","metadata":{}},{"cell_type":"code","source":"train_frac = train.sample(frac = 0.01).reset_index(drop = True)\n\nkde_plot(train_frac, numerical_features, titleText = 'KDE Plot of Numerical Features of Train Dataset', hue = None)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T07:22:55.428404Z","iopub.execute_input":"2021-10-06T07:22:55.428723Z","iopub.status.idle":"2021-10-06T07:23:39.344205Z","shell.execute_reply.started":"2021-10-06T07:22:55.428692Z","shell.execute_reply":"2021-10-06T07:23:39.343479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_frac = test.sample(frac = 0.01).reset_index(drop = True)\n\nkde_plot(test_frac, numerical_features, titleText = 'KDE Plot of Numerical Features of Test Dataset', hue = None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Since KDE plots are processed in a long time, plots were created on 1% of the data sets. Supporting the box chart, it can be seen from this chart that there are various outliers.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"corr_numerical_variables\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.2.3. Correlation Matrix of Numerical Variables</p>","metadata":{}},{"cell_type":"code","source":"def correlation_matrix(data, features):\n    \n    fig, ax = plt.subplots(1, 1, figsize = (20, 20))\n    plt.title('Pearson Correlation Matrix', fontweight='bold', fontsize=25)\n    fig.set_facecolor('#d0d0d0') \n    corr = data[features].corr()\n\n    # Mask to hide upper-right part of plot as it is a duplicate\n    mask = np.triu(np.ones_like(corr, dtype = bool))\n    sns.heatmap(corr, annot = False, center = 0, cmap = 'jet', mask = mask, linewidths = .5, square = True, cbar_kws = {\"shrink\": .70})\n    ax.set_xticklabels(ax.get_xticklabels(), fontfamily = 'sans', rotation = 90, fontsize = 12)\n    ax.set_yticklabels(ax.get_yticklabels(), fontfamily = 'sans', rotation = 0, fontsize = 12)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T08:20:59.151443Z","iopub.execute_input":"2021-10-06T08:20:59.152752Z","iopub.status.idle":"2021-10-06T08:20:59.160797Z","shell.execute_reply.started":"2021-10-06T08:20:59.152695Z","shell.execute_reply":"2021-10-06T08:20:59.160159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix(train, numerical_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T08:26:53.312899Z","iopub.execute_input":"2021-10-06T08:26:53.3132Z","iopub.status.idle":"2021-10-06T08:26:57.97595Z","shell.execute_reply.started":"2021-10-06T08:26:53.313171Z","shell.execute_reply":"2021-10-06T08:26:57.974937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix(test, numerical_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T08:24:47.429882Z","iopub.execute_input":"2021-10-06T08:24:47.43022Z","iopub.status.idle":"2021-10-06T08:26:07.767951Z","shell.execute_reply.started":"2021-10-06T08:24:47.43017Z","shell.execute_reply":"2021-10-06T08:26:07.766635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **There is no significant correlation between numerical variables in both train and test dataset.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"hist_numerical_variables\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.2.4. Histogram Plot of Numerical Variables</p>","metadata":{}},{"cell_type":"code","source":"def hist_plot(data, features, titleText, hue=None):\n\n    L = len(features)\n    nrow = int(np.ceil(L/4))\n    ncol = 5\n    remove_last = (nrow * ncol) - L\n\n    fig, axs = plt.subplots(nrow, ncol, figsize=(30, 150))\n    fig.tight_layout()\n    fig.set_facecolor('#e4e4e4')\n\n    while remove_last > 0:\n      axs.flat[-remove_last].set_visible(False)\n      remove_last -= 1\n\n    fig.subplots_adjust(top = 0.97)\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9,  \n                    wspace=0.4, \n                    hspace=0.4)\n    \n    i = 1\n    for feature in features:\n        plt.subplot(nrow, ncol, i)\n        ax = sns.histplot(data[feature], edgecolor=\"black\", color=\"darkseagreen\", alpha=0.7)  \n        ax = ax.legend(loc = \"best\")    \n        plt.xlabel(feature, fontsize=18, fontweight = 'bold')\n        plt.ylabel('Frequency', fontsize=18, fontweight = 'bold')\n        i += 1\n\n    plt.suptitle(titleText, fontsize = 32, fontweight = 'bold', color = 'navy')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_plot(train_frac, numerical_features, titleText = 'Histogram of Numerical Features of Train Dataset', hue = None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_plot(test_frac, numerical_features, titleText = 'Histogram of Numerical Features of Test Dataset', hue = None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **The logic in the KDE plots is also executed in the histogram plots.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"qq_numerical_variables\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.2.5. Q-Q Plot of Numerical Variables</p>","metadata":{}},{"cell_type":"code","source":"def qqplot(data, features, titleText, hue=None):\n\n    L = len(features)\n    nrow = int(np.ceil(L/4))\n    ncol = 5\n    remove_last = (nrow * ncol) - L\n\n    fig, axs = plt.subplots(nrow, ncol, figsize=(30, 150))\n    fig.tight_layout()\n    fig.set_facecolor('#e4e4e4')\n\n    while remove_last > 0:\n      axs.flat[-remove_last].set_visible(False)\n      remove_last -= 1\n\n    fig.subplots_adjust(top = 0.97)\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9,  \n                    wspace=0.4, \n                    hspace=0.4)\n        \n    i = 1\n    for feature in features:\n        plt.subplot(nrow, ncol, i)   \n        stats.probplot(data[feature],plot=plt)\n        plt.title('\\nQ-Q Plot')\n        plt.xlabel(feature, fontsize=18, fontweight = 'bold')\n        plt.ylabel('Sample Quantile', fontsize=18, fontweight = 'bold')\n        i += 1\n\n    plt.suptitle(titleText, fontsize = 32, fontweight = 'bold', color = 'navy')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qqplot(train_frac, numerical_features, 'Q-Q Plot of Numerical Features of Train Dataset', hue=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qqplot(test_frac, numerical_features, 'Q-Q Plot of Numerical Features of Train Dataset', hue=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **The Q-Q plot with clues to the normal distribution also shows tremendously that the data is not normally distributed.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"norm_check_outlier_detect\"></a>\n## <p style=\"background-color:#664e99; font-family:newtimeroman; font-size:120%; text-align:center\">2.3. Normality Check and Outlier Detection</p>","metadata":{}},{"cell_type":"code","source":"# D'Agostino and Pearson's Test\n\ndef normality_check(data):\n  for i in numerical_features:\n    # normality test\n    stat, p = normaltest(data[[i]])\n    print('Statistics=%.3f, p=%.3f' % (stat, p))\n    # interpret results\n    alpha = 1e-2\n    if p > alpha:\n        print(f'{i} looks Gaussian (fail to reject H0)\\n')\n    else:\n        print(f'{i} does not look Gaussian (reject H0)\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normality_check(train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normality_check(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_outliers(x, c = 1.5):\n    \"\"\"\n    Function to detect outliers.\n    \"\"\"\n    q1, q3 = np.percentile(x, [25,75])\n    iqr = (q3 - q1)\n    lob = q1 - (iqr * c)\n    uob = q3 + (iqr * c)\n\n    # Generate outliers\n\n    indicies = np.where((x > uob) | (x < lob))\n\n    return indicies","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect all Outliers \noutliers = detect_outliers(train['target'])\nprint(\"Total Outliers count for claim : \", len(outliers[0]))\n\nprint(\"\\nShape before removing outliers : \",train.shape)\n\n# Remove outliers\n#train.drop(outliers[0],inplace=True, errors = 'ignore')\nprint(\"Shape after removing outliers : \",train.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Obviously, since the target variable is 0-1 (binary), there is no outlier value for this variable. There are many outliers for other features, but no direct data dropping is done in order not to lose an enormous number of rows.** ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"mild_extreme_outlier\"></a>\n## <p style=\"background-color:#9370db; font-family:newtimeroman; font-size:100%; text-align:center\">2.3.1. Mild and Extreme Outlier Detection</p>","metadata":{}},{"cell_type":"code","source":"train_iqr = pd.DataFrame()\ntrain_iqr.reindex(columns=[*train_iqr.columns.tolist(), \"-3 IQR\", \"-1.5 IQR\", \"1.5 IQR\", \"3 IQR\"], fill_value = 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import iqr\n\ndata = []\n\nk = 0\ncolumns = [\"-3 IQR\", \"-1.5 IQR\", \"1.5 IQR\", \"3 IQR\"]\n\nfor i in numerical_features:\n\n    q1 = train[i].quantile(0.25)\n    q3 = train[i].quantile(0.75)\n    \n    iqr = (q3 - q1)\n    lob_1 = q1 - (iqr * 1.5)\n    uob_1 = q3 + (iqr * 1.5)\n    lob_3 = q1 - (iqr * 3)\n    uob_3 = q3 + (iqr * 3)\n    \n    number_uob_1 = f'{round(sum(train[numerical_features[k]] > uob_1) / len(train[numerical_features[k]]), 5):,.3%}'\n    number_lob_1 = f'{round(sum(train[numerical_features[k]] < lob_1) / len(train[numerical_features[k]]), 5):,.3%}'\n    number_uob_3 = f'{round(sum(train[numerical_features[k]] > uob_3) / len(train[numerical_features[k]]), 5):,.3%}'\n    number_lob_3 = f'{round(sum(train[numerical_features[k]] < lob_3) / len(train[numerical_features[k]]), 5):,.3%}'\n\n    values = [number_lob_3, number_lob_1, number_uob_1, number_uob_3]\n    zipped = zip(columns, values)\n    a_dictionary = dict(zipped)\n    print(a_dictionary)\n    data.append(a_dictionary)\n    \n    k = k + 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_iqr = train_iqr.append(data, True)\ntrain_iqr.set_axis([numerical_features], axis='index')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def colour(value):\n\n    if float(value.strip('%')) > 10:\n      color = 'red'\n    elif float(value.strip('%')) > 5:\n        color = 'darkorange'   \n    else:\n      color = 'green'\n\n    return 'color: %s' % color\n\n# train_iqr = train_iqr.set_axis([numerical_features], axis='index')\ntrain_iqr = train_iqr.style.applymap(colour)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_iqr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **This dataframe about how to manage outlier values during the feature engineering section while developing the model will be very helpful.** ","metadata":{}}]}