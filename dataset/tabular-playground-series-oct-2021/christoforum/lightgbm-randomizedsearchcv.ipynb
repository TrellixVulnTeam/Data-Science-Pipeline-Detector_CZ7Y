{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Loading libraries","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\n\nimport lightgbm as lgb\n\nfrom scipy.stats import uniform\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, plot_roc_curve","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INT8_MIN = np.iinfo(np.int8).min\nINT8_MAX = np.iinfo(np.int8).max\nINT16_MIN = np.iinfo(np.int16).min\nINT16_MAX = np.iinfo(np.int16).max\nINT32_MIN = np.iinfo(np.int32).min\nINT32_MAX = np.iinfo(np.int32).max\n\nFLOAT16_MIN = np.finfo(np.float16).min\nFLOAT16_MAX = np.finfo(np.float16).max\nFLOAT32_MIN = np.finfo(np.float32).min\nFLOAT32_MAX = np.finfo(np.float32).max\n\n\ndef memory_usage(data, detail = 1):\n    if detail:\n        display(data.memory_usage())\n    memory = data.memory_usage().sum() / (1024 * 1024)\n    print('Memory usage : {0:.2f}MB'.format(memory))\n    return memory\n\n\ndef compress_dataset(data):\n    memory_before_compress = memory_usage(data, 0)\n    print()\n    print('=' * 50)\n    for col in data.columns:\n        col_dtype = data[col][:100].dtype\n\n        if col_dtype != 'object':\n            print('Name: {0:24s} Type: {1}'.format(col, col_dtype))\n            col_series = data[col]\n            col_min = col_series.min()\n            col_max = col_series.max()\n\n            if col_dtype == 'float64':\n                print(' variable min: {0:15s} max: {1:15s}'.format(str(np.round(col_min, 4)), str(np.round(col_max, 4))))\n                if (col_min > FLOAT16_MIN) and (col_max < FLOAT16_MAX):\n                    data[col] = data[col].astype(np.float16)\n                    print('  float16 min: {0:15s} max: {1:15s}'.format(str(FLOAT16_MIN), str(FLOAT16_MAX)))\n                    print('compress float64 --> float16')\n                elif (col_min > FLOAT32_MIN) and (col_max < FLOAT32_MAX):\n                    data[col] = data[col].astype(np.float32)\n                    print('  float32 min: {0:15s} max: {1:15s}'.format(str(FLOAT32_MIN), str(FLOAT32_MAX)))\n                    print('compress float64 --> float32')\n                else:\n                    pass\n                memory_after_compress = memory_usage(data, 0)\n                print('Compress Rate: [{0:.2%}]'.format((memory_before_compress-memory_after_compress) / memory_before_compress))\n                print('=' * 50)\n\n            if col_dtype == 'int64':\n                print(' variable min: {0:15s} max: {1:15s}'.format(str(col_min), str(col_max)))\n                type_flag = 64\n                if (col_min > INT8_MIN / 2) and (col_max < INT8_MAX / 2):\n                    type_flag = 8\n                    data[col] = data[col].astype(np.int8)\n                    print('     int8 min: {0:15s} max: {1:15s}'.format(str(INT8_MIN), str(INT8_MAX)))\n                elif (col_min > INT16_MIN) and (col_max < INT16_MAX):\n                    type_flag = 16\n                    data[col] = data[col].astype(np.int16)\n                    print('    int16 min: {0:15s} max: {1:15s}'.format(str(INT16_MIN), str(INT16_MAX)))\n                elif (col_min > INT32_MIN) and (col_max < INT32_MAX):\n                    type_flag = 32\n                    data[col] = data[col].astype(np.int32)\n                    print('    int32 min: {0:15s} max: {1:15s}'.format(str(INT32_MIN), str(INT32_MAX)))\n                    type_flag = 1\n                else:\n                    pass\n                memory_after_compress = memory_usage(data, 0)\n                print('Compress Rate: [{0:.2%}]'.format((memory_before_compress-memory_after_compress) / memory_before_compress))\n                if type_flag == 32:\n                    print('compress (int64) ==> (int32)')\n                elif type_flag == 16:\n                    print('compress (int64) ==> (int16)')\n                else:\n                    print('compress (int64) ==> (int8)')\n                print('=' * 50)\n\n    print()\n    memory_after_compress = memory_usage(data, 0)\n    print('Compress Rate: [{0:.2%}]'.format((memory_before_compress-memory_after_compress) / memory_before_compress))\n    \n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading previously prepared datasets","metadata":{}},{"cell_type":"markdown","source":"**Click to check my notebook and see how I prepared datasets ;)** \nhttps://www.kaggle.com/christoforum/preparing-datasets/notebook","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/preparing-datasets/train_prepared.csv')\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop('Unnamed: 0', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/preparing-datasets/test_prepared.csv')\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = df_test.drop('Unnamed: 0', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Releasing memory","metadata":{}},{"cell_type":"code","source":"df_train = compress_dataset(df_train)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = compress_dataset(df_test)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBM + RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"feats = df_test.columns\n\nX = df_train[feats]\ny = df_train['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.3, \n                                                                random_state = 10, stratify = y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfit_params = dict(early_stopping_rounds = 200, eval_set = [(X_train, y_train), (X_validation, y_validation)], \n                  eval_metric = 'auc', verbose = 200)\n\nrs_params = dict(learning_rate = uniform(loc = 0.05, scale = 0.1), reg_lambda = [0, 20],\n                 n_estimators = [5000], max_depth = [3, 5], num_leaves = [5, 7], subsample = [0.5, 0.6],\n                 colsample_bytree = [0.3, 0.5], reg_alpha = [0, 20])\n\n\nlgb = lgb.LGBMClassifier(random_state = 8, device = 'gpu')\nrs_lgb = RandomizedSearchCV(estimator = lgb, param_distributions = rs_params, scoring = 'roc_auc', \n                            cv = 5, n_iter = 15, random_state = 12)\nrs_lgb.fit(X_train, y_train, **fit_params)\npreds = rs_lgb.predict_proba(X_validation)[:, -1]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_lgb.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = rs_lgb.best_estimator_\nmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_roc_curve(model, X_validation, y_validation)\nplt.plot([0, 1], '--y')\nplt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_model(model, n_splits = 5):\n    \n    scores= []\n    cv = KFold(n_splits = n_splits, shuffle = True)\n    \n    for train_idx, test_idx in cv.split(X):\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n        model.fit(X_train, y_train, early_stopping_rounds = 200, verbose = 200, \n                  eval_set = [(X_train, y_train), (X_test, y_test)], eval_metric = 'auc')\n        preds = model.predict_proba(X_test)[:, -1]\n        score = roc_auc_score(y_test, preds)\n        scores.append(score)\n        \n    print('************************************')    \n    print(f'Mean AUCROC score:       {np.mean(scores)}')\n    print(f'Std AUCROC:              {np.std(scores)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ncheck_model(model)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict_proba(df_test)[:, -1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-oct-2021/sample_submission.csv')\nsub['target'] = preds\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('lgbm_ver2.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}