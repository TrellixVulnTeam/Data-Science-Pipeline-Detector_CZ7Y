{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport datatable as dt\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\n\nimport optuna\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T06:31:25.526732Z","iopub.execute_input":"2021-11-30T06:31:25.527156Z","iopub.status.idle":"2021-11-30T06:31:34.573926Z","shell.execute_reply.started":"2021-11-30T06:31:25.52705Z","shell.execute_reply":"2021-11-30T06:31:34.57299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/tabular-playground-series-oct-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-oct-2021/sample_submission.csv')\n\nmemory_usage = train.memory_usage(deep=True) / 2 ** 11\nstart_memory = memory_usage.sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T06:31:34.575761Z","iopub.execute_input":"2021-11-30T06:31:34.576022Z","iopub.status.idle":"2021-11-30T06:33:26.45322Z","shell.execute_reply.started":"2021-11-30T06:31:34.575994Z","shell.execute_reply":"2021-11-30T06:33:26.452386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = train.columns.tolist()[1:-1]\ncon_features = train.select_dtypes(include = 'float64').columns.tolist()\ncat_features = train.select_dtypes(include = 'int64').columns.tolist()[1:-1]\n\ntrain[con_features] = train[con_features].astype('float32')\ntrain[cat_features] = train[cat_features].astype('uint8')\n\ntest[con_features] = test[con_features].astype('float32')\ntest[cat_features] = test[cat_features].astype('uint8')\n\nmemory_usage = train.memory_usage(deep=True) / 2 ** 11\nend_memory = memory_usage.sum()\n\nprint('Memory usage decreased from {:.2f} MB to {:2f} MB ({:.2f} % reduction)'.format(start_memory, end_memory, 100 * (start_memory - end_memory) / start_memory))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T06:33:26.454383Z","iopub.execute_input":"2021-11-30T06:33:26.454594Z","iopub.status.idle":"2021-11-30T06:35:17.405594Z","shell.execute_reply.started":"2021-11-30T06:33:26.454569Z","shell.execute_reply":"2021-11-30T06:35:17.404633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nX = train.drop(columns=[\"id\", \"target\"]).copy()\ny = train[\"target\"].copy()\nX_test = test.drop(columns=[\"id\"]).copy()\n\nscaler = StandardScaler()\nX = pd.DataFrame (data=scaler.fit_transform(X), columns=X.columns)\nX_test = pd.DataFrame (data=scaler.transform(X_test), columns=X_test.columns)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T06:35:17.40779Z","iopub.execute_input":"2021-11-30T06:35:17.408231Z","iopub.status.idle":"2021-11-30T06:35:25.36819Z","shell.execute_reply.started":"2021-11-30T06:35:17.408183Z","shell.execute_reply":"2021-11-30T06:35:25.367081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'boosting_type':'gbdt', \n    'num_leaves': 31, \n    'max_depth': 8, \n    'n_estimators':1000, \n    'subsample_for_bin':2000, \n    'min_split_gain':0.0, \n    'min_child_weight':1e-3, \n    'min_child_samples':20, \n    'subsample':1.0, \n    'subsample_freq':0, \n    'colsample_bytree':1, \n    'reg_alpha':0, \n    'reg_lambda':0, \n}","metadata":{"execution":{"iopub.status.busy":"2021-11-30T06:35:25.370475Z","iopub.execute_input":"2021-11-30T06:35:25.370815Z","iopub.status.idle":"2021-11-30T06:35:25.376435Z","shell.execute_reply.started":"2021-11-30T06:35:25.37078Z","shell.execute_reply":"2021-11-30T06:35:25.375768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def objective(trial):\n    \n#     kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=786)\n\n#     scores = []\n    \n#     params = {\n#         'device_type':'gpu',\n#         'boosting_type':'dart', # 'dart' accuracy, 'gbdt' speed\n#         'num_leaves':trial.suggest_int(\"num_leaves\", 20, 3000, step=20), # overfitting, accuracy\n#         'max_depth': trial.suggest_int(\"max_depth\", 3, 12), # overfitting\n#         'n_estimators':trial.suggest_int(\"n_estimators\", 100, 10000), \n# #         'subsample_for_bin':200000, \n# #         \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n# #         \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300), # accuracy\n# #         \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5), # overfitting\n# #         \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5), # overfitting\n# #         \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15), # regularization\n# #         \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 0.95, step=0.1),\n# #         \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n# #         \"feature_fraction\": trial.suggest_float(\n# #             \"feature_fraction\", 0.2, 0.95, step=0.1\n# #         ),\n#         'min_split_gain':0.0, \n#         'min_child_weight':trial.suggest_int('min_child_weight', 1, 100), \n#         'min_child_samples':20, \n#         'subsample':1.0, \n#         'subsample_freq':0, \n#         'colsample_bytree':trial.suggest_float(\"colsample_bytree\", 1e-8, 1), \n#         'reg_alpha':trial.suggest_float(\"reg_alpha\", 1e-8, 1, log=True), \n#         'reg_lambda':trial.suggest_int(\"reg_lambda\", 1, 100), \n# #         'random_state':2021, \n# #         'n_jobs':- 1, \n# #         'silent':'warn'\n\n# #         'max_depth': trial.suggest_int(\"max_depth\", 1, 20),\n# #         'n_estimators': trial.suggest_int(\"n_estimators\", 200, 10000),\n# #         'subsample': trial.suggest_float(\"subsample\", 0.2, 1),\n# #         'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 1e-8, 1),\n# #         'colsample_bylevel': trial.suggest_float(\"colsample_bylevel\", 1e-8, 1),\n# #         'min_child_weight': trial.suggest_int('min_child_weight', 1, 100),\n# #         'reg_lambda': trial.suggest_int(\"reg_lambda\", 1, 100),\n# #         'reg_alpha': trial.suggest_float(\"reg_alpha\", 1e-8, 1, log=True),\n# #         'gamma': trial.suggest_float(\"gamma\", 0, 1),\n# #         'booster': 'gbtree',\n# #         'eval_metric': 'auc',\n# #         'tree_method': 'gpu_hist',\n# #         'predictor': 'gpu_predictor',\n# #         'use_label_encoder': False\n#     }\n    \n    \n#     for fold, (idx_train, idx_valid) in enumerate(kf.split(X.iloc[:10000], y[:10000])):\n        \n        \n#         X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n#         X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n\n#         params['learning_rate']=trial.suggest_categorical(\n#             'learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02])\n#         model1 = LGBMClassifier(objective=\"binary\", **params)\n\n#         model1.fit(X_train,y_train,\n#                   eval_set=[(X_train, y_train),(X_valid,y_valid)],\n# #                   early_stopping_rounds=200,\n#                   verbose=False)\n\n# #         params['learning_rate']=trial.suggest_categorical(\n# #             'learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02])\n# #         model2 = LGBMClassifier(objective='binary', **params)\n\n# #         model2.fit(X_train,y_train,\n# #                   eval_set=[(X_train, y_train),(X_valid,y_valid)],\n# #                   early_stopping_rounds=200,\n# #                   verbose=False,\n# #                   init_model=model1)\n\n# #         params['learning_rate']=trial.suggest_categorical(\n# #             'learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02])\n# #         model3 = LGBMClassifier(objective='binary', **params)\n\n# #         model3.fit(X_train,y_train,\n# #                   eval_set=[(X_train, y_train),(X_valid,y_valid)],\n# #                   early_stopping_rounds=200,\n# #                   verbose=False,\n# #                   init_model=model2)\n\n# #         params['learning_rate']=trial.suggest_categorical(\n# #             'learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02])\n# #         model4 = LGBMClassifier(objective='binary', **params)\n\n# #         model4.fit(X_train,y_train,\n# #                   eval_set=[(X_train, y_train),(X_valid,y_valid)],\n# #                   early_stopping_rounds=200,\n# #                   verbose=False,\n# #                   init_model=model3)\n\n#         pred_valid = model1.predict_proba(X_valid)[:,1]\n#         fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n#         score = auc(fpr, tpr)\n#         scores.append(score)\n\n#         print(f\"Fold: {fold + 1} Score: {score}\")\n\n#     print(f\"Overall Validation Score: {np.mean(scores)}\")\n#     return np.mean(scores)\n    \n    \n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=100)\n\n# print('Number of finished trials: {}'.format(len(study.trials)))\n\n# print('Best trial:')\n# trial = study.best_trial\n\n# print('  Value: {}'.format(trial.value))\n\n# print('  Params: ')\n# for key, value in trial.params.items():\n#     print('     {}: {}'.format(key, value))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-11-30T06:35:25.377954Z","iopub.execute_input":"2021-11-30T06:35:25.378404Z","iopub.status.idle":"2021-11-30T06:35:25.396284Z","shell.execute_reply.started":"2021-11-30T06:35:25.378358Z","shell.execute_reply":"2021-11-30T06:35:25.395483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n    print(\"Running on TPU:\", tpu.master())\n    print(f\"Batch Size: {BATCH_SIZE}\")\n    \nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n    BATCH_SIZE = 512\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    print(f\"Batch Size: {BATCH_SIZE}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T06:35:25.397769Z","iopub.execute_input":"2021-11-30T06:35:25.398329Z","iopub.status.idle":"2021-11-30T06:35:31.574954Z","shell.execute_reply.started":"2021-11-30T06:35:25.398282Z","shell.execute_reply":"2021-11-30T06:35:31.5739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n        \n    kf = StratifiedKFold(n_splits=7, shuffle=True, random_state=786)\n\n    test_preds = []\n    scores = []\n\n    for fold, (idx_train, idx_valid) in enumerate(kf.split(X.iloc[:10000], y[:10000])):\n\n        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n        X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n\n        params['learning_rate']=0.05\n        model1 = LGBMClassifier(**params)\n\n        print('Processing Model1 ...')\n        model1.fit(X_train,y_train,\n                   eval_set=[(X_valid,y_valid)],\n                   eval_metric='auc',\n                   verbose=False)\n\n        params['learning_rate']=0.01\n        model2 = LGBMClassifier(**params)\n\n        print('Processing Model2 ...')\n        model2.fit(X_train,y_train,\n                   eval_set=[(X_valid,y_valid)],\n                   eval_metric='auc',\n                   verbose=False,\n                   init_model=model1)\n\n        params['learning_rate']=0.007\n        model3 = LGBMClassifier(**params)\n\n        print('Processing Model3 ...')\n        model3.fit(X_train,y_train,\n                   eval_set=[(X_valid,y_valid)],\n                   eval_metric='auc',\n                   verbose=False,\n                   init_model=model2)\n\n        params['learning_rate']=0.001\n        model4 = LGBMClassifier(**params)\n\n        print('Processing Model4 ...')\n        model4.fit(X_train,y_train,\n                   eval_set=[(X_valid,y_valid)],\n                   eval_metric='auc',\n                   verbose=False,\n                   init_model=model3)\n\n        pred_valid = model4.predict_proba(X_valid)[:,1]\n        fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n        score = auc(fpr, tpr)\n        scores.append(score)\n\n        print(f\"Fold: {fold + 1} Score: {score}\")\n        print('Predicting test data ...')\n\n        test_preds.append(model3.predict_proba(X_test)[:,1])\n\n    print(f\"Overall Validation Score: {np.mean(scores)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T06:35:31.576318Z","iopub.execute_input":"2021-11-30T06:35:31.576551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.mean(np.column_stack(test_preds),axis=1)\n\nsample_submission['target'] = predictions\nsample_submission.to_csv('lgbm_sub_mean.csv', index=False)\nsample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.median(np.vstack(test_preds),axis=0)\n\nsample_submission['target'] = predictions\nsample_submission.to_csv('lgbm_sub_median.csv', index=False)\nsample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}