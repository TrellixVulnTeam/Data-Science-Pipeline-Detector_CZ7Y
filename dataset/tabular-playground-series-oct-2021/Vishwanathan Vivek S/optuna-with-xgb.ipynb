{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-07T07:27:22.474734Z","iopub.execute_input":"2021-10-07T07:27:22.47508Z","iopub.status.idle":"2021-10-07T07:27:22.571984Z","shell.execute_reply.started":"2021-10-07T07:27:22.474992Z","shell.execute_reply":"2021-10-07T07:27:22.570993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport gc\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:27:22.573732Z","iopub.execute_input":"2021-10-07T07:27:22.574138Z","iopub.status.idle":"2021-10-07T07:27:23.426637Z","shell.execute_reply.started":"2021-10-07T07:27:22.574101Z","shell.execute_reply":"2021-10-07T07:27:23.425947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# credits -- https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file)\n    df = reduce_mem_usage(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:27:23.428083Z","iopub.execute_input":"2021-10-07T07:27:23.428336Z","iopub.status.idle":"2021-10-07T07:27:23.445314Z","shell.execute_reply.started":"2021-10-07T07:27:23.428304Z","shell.execute_reply":"2021-10-07T07:27:23.444654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = import_data('../input/tabular-playground-series-oct-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:27:23.447431Z","iopub.execute_input":"2021-10-07T07:27:23.447946Z","iopub.status.idle":"2021-10-07T07:29:35.840653Z","shell.execute_reply.started":"2021-10-07T07:27:23.447911Z","shell.execute_reply":"2021-10-07T07:29:35.839948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"continous_cols= ['f'+str(i) for i in range(242)]\ncontinous_cols.remove('f22')\ncontinous_cols.remove('f43')\n\ncategorical_cols = ['f'+str(i) for i in range(242,285)]+['f22','f43']\n\ncols = continous_cols + categorical_cols","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:29:35.84177Z","iopub.execute_input":"2021-10-07T07:29:35.842415Z","iopub.status.idle":"2021-10-07T07:29:35.848594Z","shell.execute_reply.started":"2021-10-07T07:29:35.842378Z","shell.execute_reply":"2021-10-07T07:29:35.847825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing the features\nscaler = StandardScaler()\n\ntrain[categorical_cols] = scaler.fit_transform(train[categorical_cols])","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:29:35.849689Z","iopub.execute_input":"2021-10-07T07:29:35.850022Z","iopub.status.idle":"2021-10-07T07:29:35.888017Z","shell.execute_reply.started":"2021-10-07T07:29:35.849988Z","shell.execute_reply":"2021-10-07T07:29:35.887317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\n\ndef objective(trial):\n    # prameter grid \n    # search about suggest_int, suggest_uniform and all.. it is easy to understand\n    param_grid = {\n        'lambda': trial.suggest_loguniform(\n            'lambda', 1e-3, 10.0\n        ),\n        'alpha': trial.suggest_loguniform(\n            'alpha', 1e-3, 10.0\n        ),\n        'colsample_bytree': trial.suggest_categorical(\n            'colsample_bytree', [0.5,0.6,0.7,0.8,0.9,1.0]\n        ),\n        'subsample': trial.suggest_categorical(\n            'subsample', [0.6,0.7,0.8,1.0]\n        ),\n        'learning_rate': trial.suggest_categorical(\n            'learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]\n        ),\n        'n_estimators': trial.suggest_categorical(\n            \"n_estimators\", [150, 200, 300, 3000]\n        ),\n        'max_depth': trial.suggest_categorical(\n            'max_depth', [4,5,7,9,11,13,15,17]\n        ),\n        'random_state': 42,\n        'min_child_weight': trial.suggest_int(\n            'min_child_weight', 1, 300\n        ),\n    }\n    \n    # Simple kfold implementation\n    kf = StratifiedKFold(n_splits=5,random_state=48,shuffle=True)\n    auc = np.empty(5)\n    \n    for n, (train_index, test_index) in enumerate(kf.split(train[cols],train['target'])):\n        X_train, X_valid = train[cols].iloc[train_index], train[cols].iloc[test_index]\n        y_train, y_valid = train['target'].iloc[train_index], train['target'].iloc[test_index]\n        \n        model = XGBClassifier(tree_method='gpu_hist', gpu_id=0, predictor = 'gpu_predictor', **param_grid)\n        model.fit(X_train, y_train, eval_set=[(X_valid,y_valid)], early_stopping_rounds=100, eval_metric=\"auc\", verbose=False)\n        \n        auc[n] = roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])\n        gc.collect()\n        \n    return np.mean(auc)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:29:35.889285Z","iopub.execute_input":"2021-10-07T07:29:35.889787Z","iopub.status.idle":"2021-10-07T07:29:36.551994Z","shell.execute_reply.started":"2021-10-07T07:29:35.88975Z","shell.execute_reply":"2021-10-07T07:29:36.551231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nstudy = optuna.create_study(direction=\"maximize\", study_name=\"XGB Classifier\")\nstudy.optimize(objective, n_trials=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:29:36.553164Z","iopub.execute_input":"2021-10-07T07:29:36.554205Z","iopub.status.idle":"2021-10-07T07:29:47.172704Z","shell.execute_reply.started":"2021-10-07T07:29:36.554174Z","shell.execute_reply":"2021-10-07T07:29:47.171952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:31:01.543875Z","iopub.execute_input":"2021-10-07T07:31:01.544179Z","iopub.status.idle":"2021-10-07T07:31:01.554384Z","shell.execute_reply.started":"2021-10-07T07:31:01.544146Z","shell.execute_reply":"2021-10-07T07:31:01.55355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\tBest value (auc): {study.best_value:.5f}\")\nprint(f\"\\tBest params:\")\n\nfor key, value in study.best_params.items():\n    print(f\"\\t\\t{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:31:40.903114Z","iopub.execute_input":"2021-10-07T07:31:40.903828Z","iopub.status.idle":"2021-10-07T07:31:40.913559Z","shell.execute_reply.started":"2021-10-07T07:31:40.903786Z","shell.execute_reply":"2021-10-07T07:31:40.912723Z"},"trusted":true},"execution_count":null,"outputs":[]}]}