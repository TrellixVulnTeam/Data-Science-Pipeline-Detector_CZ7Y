{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" <font size = 1000px color = 'royalblue'><center><b>Blending<b></center></font>\n ","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.094767,"end_time":"2021-08-03T10:37:53.678704","exception":false,"start_time":"2021-08-03T10:37:53.583937","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<font color = \"#191970\" size=6px><center><b>Import Required Libraries</b></font>","metadata":{"papermill":{"duration":0.128736,"end_time":"2021-08-03T10:37:54.350568","exception":false,"start_time":"2021-08-03T10:37:54.221832","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Data Wrangling and Data Analysis\n\nimport pandas as pd , numpy as np\nimport gc\n\n# Visualization\n\nfrom matplotlib import pyplot as plt, style\nimport seaborn as sns\n\n# Feature Engineering / Feature Selection\nimport optuna \nfrom optuna.integration import XGBoostPruningCallback\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\n\n\n# Model Building\n#import lightgbm as lgbm\n#from lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n#from catboost import CatBoostClassifier, Pool\nfrom sklearn import metrics\n\n\n# Ignore Warings\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"papermill":{"duration":2.064384,"end_time":"2021-08-03T10:37:56.506193","exception":false,"start_time":"2021-08-03T10:37:54.441809","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-24T03:15:38.567848Z","iopub.execute_input":"2021-10-24T03:15:38.568528Z","iopub.status.idle":"2021-10-24T03:15:38.576742Z","shell.execute_reply.started":"2021-10-24T03:15:38.568486Z","shell.execute_reply":"2021-10-24T03:15:38.575951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color = \"#191970\" size=6px><center><b>Data Collection</b></font>","metadata":{"execution":{"iopub.execute_input":"2021-05-27T12:54:22.548171Z","iopub.status.busy":"2021-05-27T12:54:22.547671Z","iopub.status.idle":"2021-05-27T12:54:22.556604Z","shell.execute_reply":"2021-05-27T12:54:22.555285Z","shell.execute_reply.started":"2021-05-27T12:54:22.548064Z"},"papermill":{"duration":0.092726,"end_time":"2021-08-03T10:37:56.691002","exception":false,"start_time":"2021-08-03T10:37:56.598276","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<font color = \"maroon\" size=5px><b>1.1 Reducing Data Size</b></font>","metadata":{}},{"cell_type":"markdown","source":"<font color = \"maroon\" size=4px><b>Since the dataset is vert large(1 million rows) . lest use below function to convert each column to the best fitting datatype for its range.</b></font>","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:15:38.578651Z","iopub.execute_input":"2021-10-24T03:15:38.579061Z","iopub.status.idle":"2021-10-24T03:15:38.60667Z","shell.execute_reply.started":"2021-10-24T03:15:38.579027Z","shell.execute_reply":"2021-10-24T03:15:38.605895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before working with the data, we reduce the use of memory, so we can improve performance\n\ndef import_data(file):\n    # Reading File\n    df = pd.read_csv(file)\n    \n    # Reducing Size by Optimizing Dtypes of columns\n    df = reduce_mem_usage(df)\n    \n    # Converting Bool cols into integer\n    bool_cols = []\n    for i, col in enumerate(df.columns):\n        if df[col].dtypes == bool:\n            bool_cols.append(i)\n    df.iloc[:, bool_cols] = df.iloc[:, bool_cols].astype(int)  \n    \n    return df\n\n# Train Data\ntrain = import_data('../input/tpsoct2021-5-folds/Train_tps_oct_2021_kfold.csv')\n\n#Test Data\ntest = import_data('../input/tabular-playground-series-oct-2021/test.csv')\n\n\n# Submission\n\nsubmission = import_data('../input/tabular-playground-series-oct-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:15:38.608048Z","iopub.execute_input":"2021-10-24T03:15:38.60836Z","iopub.status.idle":"2021-10-24T03:15:54.296632Z","shell.execute_reply.started":"2021-10-24T03:15:38.608326Z","shell.execute_reply":"2021-10-24T03:15:54.295378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color = \"maroon\" size=5px><b>2.3 Analysing Different Column Types</b></font>","metadata":{}},{"cell_type":"code","source":"# categorical Columns :- \n\nCat_cols = [col for col in train.columns if train[col].nunique() < 5]\nCat_cols.remove('target')\n#Cat_cols_indices = [train.columns.get_loc(col) for col in Cat_cols]\n\n# Continous Columns : -\n\nCon_cols = [col for col in train.columns if train[col].nunique() > 5]\n\n\n\n# Number of each respective column types\n\nprint(\"Number of Categorical Columns :\", len(Cat_cols))\nprint(\"Number of Continous Columns   :\", len(Con_cols))\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:15:54.297644Z","iopub.status.idle":"2021-10-24T03:15:54.299178Z","shell.execute_reply.started":"2021-10-24T03:15:54.298922Z","shell.execute_reply":"2021-10-24T03:15:54.298948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color = \"blue\" size=4px> <b>Interpretation : </b></font>\n\n* <font color = \"red\" size=4px>Most features Are Left Skewed, so We use Algorithms That Doesnt Expect Normality ,i.e any **tree based ensemble techniques** </font>\n\n<hr>","metadata":{}},{"cell_type":"markdown","source":"<font color = \"maroon\" size=5px><b>2.4 Feature Engineering</b></font>","metadata":{}},{"cell_type":"code","source":"Con_cols_test = [cols for cols in Con_cols if cols not in [\"mean\", \"std\", \"min\", \"max\", \"abs_sum\", \"sem\"]]\ntest[\"mean\"] = test[Con_cols_test].mean(axis=1)\ntest[\"std\"] = test[Con_cols_test].std(axis=1)\ntest[\"min\"] = test[Con_cols_test].min(axis=1)\ntest[\"max\"] = test[Con_cols_test].max(axis=1)\ntest['abs_sum'] = test[Con_cols_test].abs().sum(axis=1)\ntest['sem'] = test[Con_cols_test].sem(axis=1)\ndel Con_cols_test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:15:54.3005Z","iopub.status.idle":"2021-10-24T03:15:54.301167Z","shell.execute_reply.started":"2021-10-24T03:15:54.300923Z","shell.execute_reply":"2021-10-24T03:15:54.300947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color = \"#191970\" size=6px><center><b>XGB Model</b></font>","metadata":{}},{"cell_type":"markdown","source":"<font color = \"maroon\" size=5px><b>3.1 Best Params From HyperParameter Tuning Notebook :- [HyperParameter Tuning TPS OCT-2021](https://www.kaggle.com/jaysrivastav/blending-tps-oct-21?scriptVersionId=77672359) </b></font>","metadata":{}},{"cell_type":"code","source":"XGB_params = {'learning_rate': 0.014679233453195013, 'reg_lamba':75.56651890088857, 'reg_alpha': 0.11766857055687065,\n              'gamma': 0.6407823221122686, 'subsample': 0.4640789338167099,\n              'subsample': 0.7,'colsample_bytree': 0.2,'colsample_bylevel': 0.6000000000000001,\n              'min_child_weight': 56.41980735551558,'max_depth': 6,\n              'verbosity' : 0, 'eval_metric' : 'auc','objective':\"binary:logistic\",\n              'use_label_encoder': False,'tree_method': 'gpu_hist',\n              \"seed\": 42, 'n_jobs': -1, 'n_estimators': 20000, 'predictor': 'gpu_predictor',\n              'learning_rate': 0.013474548048574765}\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:16:12.396726Z","iopub.execute_input":"2021-10-24T03:16:12.397013Z","iopub.status.idle":"2021-10-24T03:16:12.402124Z","shell.execute_reply.started":"2021-10-24T03:16:12.396982Z","shell.execute_reply":"2021-10-24T03:16:12.401438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features and Target \n\ntrain.reset_index(inplace=True)\ntest.reset_index(inplace=True)\nFeatures = [c for c in train.columns if c not in ('id','index','target','kfold')]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:15:54.304356Z","iopub.status.idle":"2021-10-24T03:15:54.305Z","shell.execute_reply.started":"2021-10-24T03:15:54.304739Z","shell.execute_reply":"2021-10-24T03:15:54.304762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kfold Loop\n\ndef XGB():\n    final_test_predictions = []\n    final_valid_predictions = {}\n    scores = []\n    for fold in range(5):\n    \n        x_train = train[train.kfold != fold].reset_index(drop=True)\n        x_valid = train[train.kfold == fold].reset_index(drop=True)\n        x_test = test[Features].copy()\n    \n        valid_ids = x_valid.index.values.tolist()\n   \n        y_train = x_train.target\n        y_valid = x_valid.target\n    \n        x_train = x_train[Features]\n        x_valid = x_valid[Features]\n    \n   \n    \n        gc.collect()\n\n        # Model Training\n        model = XGBClassifier(**XGB_params, n_threads=4)\n        model.fit(x_train, y_train,\n                  eval_set=[(x_valid,y_valid)],\n                  early_stopping_rounds=200,\n                  verbose = False)\n        gc.collect()\n    \n        # Predictions\n        valid_preds = model.predict_proba(x_valid)[:,1]\n        test_preds = model.predict_proba(x_test)[:,1]\n    \n        final_test_predictions.append(test_preds)\n        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n\n        # Score\n        auc = metrics.roc_auc_score(y_valid, valid_preds)\n        scores.append(auc)\n        print(f\"Fold: {fold + 1} Score: {auc}\")\n        print('||'*40)\n        gc.collect()\n    print(\"Overall Auc : - \", np.mean(scores))\n    return final_test_predictions, final_valid_predictions\n    \nfinal_test_predictions, final_valid_predictions = XGB()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:21:54.134219Z","iopub.execute_input":"2021-10-24T03:21:54.134493Z","iopub.status.idle":"2021-10-24T03:48:11.979469Z","shell.execute_reply.started":"2021-10-24T03:21:54.134462Z","shell.execute_reply":"2021-10-24T03:48:11.978704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient = \"index\")\n# final_valid_predictions.columns = ['id', 'pred_1']\n\n# final_valid_predictions.to_csv(\"train_pred_1.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:51:19.38836Z","iopub.execute_input":"2021-10-24T03:51:19.388628Z","iopub.status.idle":"2021-10-24T03:51:19.39462Z","shell.execute_reply.started":"2021-10-24T03:51:19.388598Z","shell.execute_reply":"2021-10-24T03:51:19.393936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target = np.mean(np.column_stack(final_test_predictions), axis = 1)\n\n#submission.columns = ['id', 'pred_1']\nsubmission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:52:30.988669Z","iopub.execute_input":"2021-10-24T03:52:30.989212Z","iopub.status.idle":"2021-10-24T03:52:31.009854Z","shell.execute_reply.started":"2021-10-24T03:52:30.989172Z","shell.execute_reply":"2021-10-24T03:52:31.009143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T03:52:33.487276Z","iopub.execute_input":"2021-10-24T03:52:33.48781Z","iopub.status.idle":"2021-10-24T03:52:33.49685Z","shell.execute_reply.started":"2021-10-24T03:52:33.487773Z","shell.execute_reply":"2021-10-24T03:52:33.496032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color = \"#191970\" size=6px><center><b>LGBM HyperParameter Tuning</b></font>","metadata":{}},{"cell_type":"code","source":"# lgb_params = {\n#      'objective': 'binary',\n#      'n_estimators':N_ESTIMATORS,\n#      'importance_type': 'gain',\n#      'metric':'auc',\n#      'boosting_type': 'gbdt',\n#      'n_jobs' : -1, \n#     'learning_rate': 0.0038511441056118664, \n#     'subsample': 0.5827550088149794, \n#     'subsample_freq': 1, \n#     'colsample_bytree': 0.19599597755538956, \n#     'reg_lambda': 0.011685550612519125, \n#     'reg_alpha': 0.04502045156737212, \n#     'min_child_weight': 16.843316711276092, \n#     'min_child_samples': 412, \n#     'num_leaves': 546, \n#     'max_depth': 5, \n#     'cat_smooth': 36.40200359200525, \n#     'cat_l2': 12.979520035205597\n#     }","metadata":{"execution":{"iopub.status.busy":"2021-10-21T10:05:10.012045Z","iopub.execute_input":"2021-10-21T10:05:10.012496Z","iopub.status.idle":"2021-10-21T10:05:10.023069Z","shell.execute_reply.started":"2021-10-21T10:05:10.012458Z","shell.execute_reply":"2021-10-21T10:05:10.022306Z"},"trusted":true},"execution_count":null,"outputs":[]}]}