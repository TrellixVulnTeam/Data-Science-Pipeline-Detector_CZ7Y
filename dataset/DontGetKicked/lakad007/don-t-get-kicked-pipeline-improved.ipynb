{"cells":[{"metadata":{},"cell_type":"markdown","source":"Ref Articles \n- https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n- https://discuss.analyticsvidhya.com/t/what-is-the-difference-between-predict-and-predict-proba/67376\n- https://github.com/AnilBetta/AV-Janata-Hack-healh-Care-2/blob/master/av-jh-hca2-cat.ipynb\n- https://github.com/gcspkmdr/HA-Hackathon"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport itertools as it\nimport numpy as np\nimport math\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n\n\n# solution to https://www.kaggle.com/c/DontGetKicked\nVER = '01'\n\n\n### Load data: \ntr = pd.read_csv('../input/DontGetKicked/training.csv')\n\ntarget_name = 'IsBadBuy'\ntarget = tr[target_name].copy(deep=True)\ntr = tr.drop([target_name], axis=1)\ntr_length = len(tr)\n\nte = pd.read_csv('../input/DontGetKicked/test.csv')\n\n\n### Concat train and test:\ndf = pd.concat([tr, te])\ndf = df.reset_index(drop=True)\n\n\n### drop RefId and WheelTypeID' (because == 'WheelType):\ndf = df.drop(['RefId', 'WheelTypeID'], axis=1)\n\n\n\n\n### Date features:\ndf['PurchDate'] = pd.to_datetime(df['PurchDate'])\ndf['Purch_Year'] = df['PurchDate'].dt.year\ndf['Purch_Month'] = df['PurchDate'].dt.month\ndf['Purch_Day'] = df['PurchDate'].dt.day\ndf['Purch_DayOfWeek'] = df['PurchDate'].dt.dayofweek\ndf['Purch_DayOfYear'] = df['PurchDate'].dt.dayofyear\ndf['Age_At_Purchase'] = df['Purch_Year'] - df['VehYear']\ndf['VehOdo'] = df['VehOdo'].apply(lambda x: int(math.ceil(x / 1000.0)) * 1000)\n\n\n### Holidays:\ndef holidays():\n    cal = calendar()\n    dr = pd.date_range(start='2000-07-01', end='2019-07-31')\n    holidays = cal.holidays(start=dr.min(), end=dr.max())\n    return holidays\n\ndf['Holiday'] = df['PurchDate'].isin(holidays())\n\n\n### Ratio features:\ndef ratio(col1:str, col2:str, df):\n    return (df[col1] - df[col2]) / df[col1]\n\nPrice_List = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice',\t\n              'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\t\n              'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\t\n              'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice'\n             ]\n\nfor i in Price_List:\n    df[i] = df[i].apply(lambda p: np.nan if p==0 else p)\n\nfor combination in it.combinations(Price_List, 2):\n    df[str(combination)] = ratio(*combination, df)\n\nfor i in Price_List:\n    df['VehBCost_R_' + i] = ratio(i, 'VehBCost', df)\n\n\n### Fractional features:\ndef frac(col1:str, col2:str, df):\n    return df[col1] / df[col2]\n\ndf['Age_At_Purchase_f_VehicleAge'] = frac('Age_At_Purchase', 'VehicleAge', df)\ndf['Age_At_Purchase_f_VehOdo'] = frac('Age_At_Purchase', 'VehOdo', df) \ndf['WarrantyCost_f_VehBCost'] = frac('WarrantyCost', 'VehBCost', df)\ndf['VehBCost_f_VehOdo'] = frac('VehBCost', 'VehOdo', df)\ndf['VehBCost_f_VehicleAge'] = frac('VehBCost', 'VehicleAge', df)\n\n\n### Submodel features:\ndef string_detector(str_to_check:str):\n    return df['SubModel'].apply(lambda s: 1 if str_to_check in str(s) else 0)\n\n# Manually defined list:\nstrings_to_check = ['4D', '2D', 'CAB', 'WAGON', 'CONVERTIBLE',\n                    'HATCHBACK', 'CREW', 'SEDAN', 'SUV', 'MINIVAN',\n                    'PASSENGER', 'REG', 'QUAD', 'UTILITY', 'CARGO', \n                    'EXT', 'SPORT', 'COUPE', 'CUV', 'DOUBLE',\n                   ]\nfor i in strings_to_check:\n    df[i] = string_detector(i)\n\ndf['BYRNO'] = df['BYRNO'].astype(str)\n\n\n### Split back to train & test, saving:\ntr = df.iloc[:tr_length, :].copy(deep=True)\ntr[target_name] = target\ntr.to_csv('Carv_train_'+VER+'.csv', index=False)\n\nte = df.iloc[tr_length:, :].copy(deep=True)\nte.to_csv('Carv_test_'+VER+'.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n#from catboost import CatBoostClassifier\n#from sklearn.model_selection import StratifiedKFold,KFold,GroupKFold\n#from sklearn.metrics import accuracy_score\n\n#Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\n#For Missing Value and Feature Engineering\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif, VarianceThreshold\nfrom sklearn.impute import SimpleImputer, KNNImputer, MissingIndicator\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n\nimport time\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"./Carv_train_01.csv\")\ntest = pd.read_csv(\"./Carv_test_01.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"#insert code","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feat Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Date\n#PurchDate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['mean_MMRAcquisitionAuctionAveragePrice_Make']=train.groupby(['Make'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Model']=train.groupby(['Model'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Trim']=train.groupby(['Trim'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_SubModel']=train.groupby(['SubModel'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Color']=train.groupby(['Color'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Transmission']=train.groupby(['Transmission'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['mean_MMRAcquisitionAuctionAveragePrice_Make']=test.groupby(['Make'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Model']=test.groupby(['Model'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Trim']=test.groupby(['Trim'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_SubModel']=test.groupby(['SubModel'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Color']=test.groupby(['Color'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Transmission']=test.groupby(['Transmission'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Divide Dataset into X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create X and y datasets for splitting \nX = train.drop(['IsBadBuy'], axis=1)\ny = train['IsBadBuy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = all_features.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind in ['i','f'] and c !='PassengerId']\ncategorical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind not in ['i','f']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.get_dummies(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import train_test_split library\nfrom sklearn.model_selection import train_test_split\n\n# create train test split\nX_train, X_test, y_train, y_test = train_test_split( X,  y, test_size=0.3, random_state=0)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup Pipeline "},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor = make_column_transformer(\n    \n    (make_pipeline(\n    #SimpleImputer(strategy = 'median'),\n    KNNImputer(n_neighbors=2, weights=\"uniform\"),\n    MinMaxScaler()), numerical_features),\n    \n    (make_pipeline(\n    SimpleImputer(strategy = 'constant', fill_value = 'missing'),\n    OneHotEncoder(categories = 'auto', handle_unknown = 'ignore')), categorical_features),\n    \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor_best = make_pipeline(preprocessor, \n                                  VarianceThreshold(), \n                                  SelectKBest(f_classif, k = 50)\n                                 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nRF_Model = make_pipeline(preprocessor_best, LGBMClassifier(n_estimators = 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 50)]\n# Number of features to consider at every split\n#max_features = ['auto', 'sqrt']\n#Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n\n# Minimum number of samples required to split a node\n#min_samples_split = [2, 5]\n# Minimum number of samples required at each leaf node\n#min_samples_leaf = [1, 2]\n# Method of selecting samples for training each tree\n#bootstrap = [True, False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_Model.get_params().keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the param grid\nparam_grid = {'lgbmclassifier__n_estimators': n_estimators,\n               'lgbmclassifier__max_depth': max_depth\n               #'randomforestclassifier__min_samples_split': min_samples_split,\n               #'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n               #'randomforestclassifier__bootstrap': bootstrap\n             }\nprint(param_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nrf_RandomGrid = RandomizedSearchCV(estimator = RF_Model, param_distributions = param_grid, cv = 3, verbose=1, n_jobs = -1, n_iter = 5, scoring = 'f1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndef clean_dataset(df):\n    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    df.dropna(inplace=True)\n    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n    return df[indices_to_keep].astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_RandomGrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_RandomGrid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train : {rf_RandomGrid.score(X_train, y_train):.3f}')\nprint(f'Test : {rf_RandomGrid.score(X_test, y_test):.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gini Index"},{"metadata":{"trusted":true},"cell_type":"code","source":"def gini(actual, pred):\n    assert (len(actual) == len(pred))\n    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n    totalLosses = all[:, 0].sum()\n    giniSum = all[:, 0].cumsum().sum() / totalLosses\n\n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n\n\ndef gini_normalized(actual, pred):\n    return gini(actual, pred) / gini(actual, actual)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"actual_train = y_train\npred_train = rf_RandomGrid.predict(X_train)\nactual_test = y_test\npred_test = rf_RandomGrid.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Gini Train : {gini(actual_train,pred_train):.3f}')\nprint(f'Gini Test : {gini(actual_test,pred_test):.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = rf_RandomGrid.predict_proba(test[X.columns])[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AllSub = pd.DataFrame({ 'RefId': test['RefId'],\n                       'IsBadBuy' : test_pred\n    \n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AllSub['IsBadBuy'] = AllSub['IsBadBuy'].apply(lambda x: 1 if x > 0.09 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AllSub.to_csv('DGK_RF_Pipe_BetterPipe1.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE # Recursive Feature Selection\nfrom sklearn.feature_selection import RFECV # Recursive Feature Selection with Cross Validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing Random Forest Classifier\n# Initializing the RFE object, one of the most important arguments is the estimator, in this case is RandomForest\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}