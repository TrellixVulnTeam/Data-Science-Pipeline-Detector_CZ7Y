{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Forest Cover Data Exploration","metadata":{}},{"cell_type":"markdown","source":"## Motivation\n\nThe purpose of this project is to provide a simple overview of how Python data visualization tools can be used to understand a complex, large dataset.\nThe dataset in question contains information about features of forested areas. The data includes numerical variables (distance to XXX feature) as well as categorical variables (soil type, tree cover type).   \n\nThrough 7 data visualization tenchniques, we will drive understanding of this data and the trends that underlie it.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Setup  \n1. Import necessary packages\n2. Gain a high level understanding of data  \n3. Set up data for manipulation","metadata":{}},{"cell_type":"code","source":"# Supress unnecessary warnings so that presentation looks clean\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import packages\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import data\ntraining = pd.read_csv('/kaggle/input/forest-cover-type-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/forest-cover-type-prediction/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Look at training data - 56 populated columns\ntraining.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %matplotlib inline embeds a static image of what we are trying to show in our notebook\n#.columns shows the columns we are using\n%matplotlib inline\ntraining.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Plan\n\n**1. Explore by:**    \n\n    1. Making histograms to understand distributions for all numeric variables   \n    \n    2. Creating and visualize correlation matrix to understand correlations between variables  \n    \n    3. Creating a pivot table to view average values numerically\n    \n    4. Vizualizing average numerical values using barplots   \n    \n    5. Using violin plots to see the relationship between categorical variables (cover type) and other forest attributes.    \n    \n    6. Making scatterplots to visualize horizontal distance to hydrology by elevation by cover type    \n    \n    7. Creating countplots relate categorical variables:    \n        a. Cover type by wilderness area  \n        b. Cover type by soil type","metadata":{}},{"cell_type":"markdown","source":"## Histograms  \nUnderstand distributions for all numeric variables   ","metadata":{}},{"cell_type":"code","source":"# .describe() shows us the measures of central tendency for our data\n#Help us think about the data differntly and help us make associations\ntraining.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look at numeric values separately \ndf_num = training [['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways', \n                    'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm','Horizontal_Distance_To_Fire_Points']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for loop runs through all of the numeric variables and displays histograms for them all\n\nfor i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation Matrices  \nUnderstand correlations between variables  ","metadata":{}},{"cell_type":"code","source":"# Prints a correlation matrix that shows how variables correlate with each other.\nprint(df_num.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print a heatmap representation of the above correlation matrix\nsns.heatmap(df_num.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Interpretation of degrees of correlation:**\n\nPerfect: If the value is near ± 1, then it said to be a perfect correlation: as one variable increases, the other variable tends to also increase (if positive) or decrease (if negative).\n\nHigh degree: If the coefficient value lies between ± 0.50 and ± 1, then it is said to be a strong correlation.\n\nModerate degree: If the value lies between ± 0.30 and ± 0.49, then it is said to be a medium correlation.\n\nLow degree: When the value lies below + .29, then it is said to be a small correlation.\n\nNo correlation: When the value is zero.","metadata":{}},{"cell_type":"markdown","source":"## Pivot Table  \nView average values numerically","metadata":{}},{"cell_type":"code","source":"#Get the average numerical attributes of the cover types\npd.pivot_table(training, index = 'Cover_Type', values = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways',\n                                                         'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm','Horizontal_Distance_To_Fire_Points'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Barplots  \nVizualize average numerical values ","metadata":{}},{"cell_type":"code","source":"# Visualize the interesting numerical attributes based on their average value\n    # We will visualize all the attributes using Bar plots\n        # Black tips on bars are error bars- show variability of data (standard devation)\n\n#names of all the attributes \ncols = training.columns\n\n#number of attributes (exclude target)\nsize = len(cols)-1\n\n#x-axis has target attribute to distinguish between classes\nx = cols[size]\n\n#y-axis shows values of an attribute\ny = cols[0:size]\n\n#Plot violin for all attributes\nfor i in range(0,size):\n    sns.barplot(x=x, y=y[i], data=training)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Violin Plots  \nSee the relationship between categorical variables (cover type) and other forest attributes. ","metadata":{}},{"cell_type":"code","source":"# We will visualize all the attributes using Violin Plot - a combination of box and density plots\n\n#names of all the attributes \ncols = training.columns\n\n#number of attributes (exclude target)\nsize = len(cols)-1\n\n#x-axis has target attribute to distinguish between classes\nx = cols[size]\n\n#y-axis shows values of an attribute\ny = cols[0:size]\n\n#Plot violin for all attributes\nfor i in range(0,size):\n    sns.violinplot(data=training,x=x,y=y[i])  \n    plt.show()\n\n# Elevation is strongly correlated with Cover_Type\n#Aspect contains a couple of normal distribution for several classes\n#Horizontal distance to road, fire points hydrology have similar distribution\n#Hillshade 9am and 12pm display left skew\n#Hillshade 3pm is normal\n#Lots of 0s in vertical distance to hydrology\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatterplots  \nVisualize horizontal distance to hydrology by elevation by cover type    ","metadata":{}},{"cell_type":"code","source":"# Make array 'plot_features' with Horizontal Distance columns\n\nplot_features = ['Horizontal_Distance_To_Hydrology', \n                 'Horizontal_Distance_To_Roadways', \n                 'Horizontal_Distance_To_Fire_Points']\n\n# pick a Seaborn color pallete\ncolors = sns.color_palette('deep')\n\n# Make a copy of the training data\nsample = training.copy()\n\n#Set up a for loop\n\n#Loop through Cover values 1-6\nfor cover in [1,2,3,4,5,6,7]:\n    \n    # Rest = every element in the list except for the current cover element\n    rest = list(set([1,2,3,4,5,6,7]) - set([cover]))\n    \n    # Copy Cover_Type from training set\n    sample['Cover_Type'] = training['Cover_Type'].copy()\n    \n    # Set every value from the \"rest\" list to 0\n    sample['Cover_Type'] = sample['Cover_Type'].replace(rest, 0)\n    \n    # create a figure object\n    fig = plt.figure(figsize=(16, 12))\n    #Choose colors\n    palette = ['lavender', colors[cover]]\n    \n    # For loop to create scatterplots\n    \n    #Loops 1-3 because we are trying to show 3 Horizontal distances\n    for i in range(3):\n        \n        # The first (3,3) defines the setup of the subpl0t\n        # i+1 loops through all of the i values, which will loop through the 3 elements in plot_features(Horizontal Distances)\n        fig.add_subplot(3, 3, i+1)\n        \n        # X axis = elevation\n        # Y axis is a loop through the Horizontal distances\n        # data= our new sample\n        # Hue = the Cover type for this given loop\n        # Marker = what is on the scatterplot (+ is a little + on it)\n        # palette = the colors we picked above\n        \n        ax = sns.scatterplot(x='Elevation', \n                             y=plot_features[i], \n                             data=sample, \n                             hue='Cover_Type',\n                             marker='+',\n                             palette=palette)\n    #tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area. \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Countplots  \nRelate categorical variables:    \n            a. Cover type by wilderness area  \n            b. Cover type by soil type","metadata":{}},{"cell_type":"code","source":"# Quick for loop to get numbered list of columns for use below\nfor col in training.columns:\n    print(training.columns.get_loc(col),col)     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group one-hot encoded variables of a category into one single variable\n    # One hot encoded variables are representations of categorical variables as binary vectors\n        # For example, Wilderness_Area is represented as a binary vector in 4 columns for each of the 4 wilderness areas\n\n\n#names of all the columns\ncols = training.columns\n\n# Training.shape returns an array of number of rows, number of columns\n    # So number of rows=r , number of columns=c\nr,c = training.shape\n\n#Create a new dataframe with r rows, one column for each encoded category, and target in the end\n\ndata = pd.DataFrame(index=np.arange(0, r),columns=['Wilderness_Area','Soil_Type','Cover_Type'])\n\n# We now have an empty dataframe with rows= number of rows in Training and a column for each of our \ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make an entry in 'data' for each r as category_id, target value\n\n# For loop in range (0 up to the number of rows in 'Data'- which is 15,120)\n    # Range (0,15120) is actually 0-15119\n\nfor i in range(0,r):\n    w=0;\n    s=0;\n    \n    # Category1 range - FInd Wilderness area\n        # 10-13 Is the column of the first wilderness area through the column of the first soil type \n            # Range (10,14) is actually the numbers 10-13 \n            \n    for j in range(10,14):\n        \n        # (training.iloc[row,column] returns the value at the row, column location. \n            #So if there is a 1 at this location that means this row has a binary \"yes\" identifying it as being from that wilderness location\n            # For example, training.iloc[i,j] will evaluate to 1 if i= 5 and j=10, and at that \"cell (5,10)\" the binary identifier is yes\n                # column 10 is Wilderness area 1\n            # So once we evaluate to yes, we move onto the steps below the if statements\n            \n        if (training.iloc[i,j] == 1):\n            \n            # W is going to be our wilderness location when we input below \n                # So, using the above example (i=5, j=10), wilderness area would be set to 10-9 =1. \n                # w =1\n                     # If the area in row 5 had been of Wilderness Area 2, it would have looped through once more. \n                        # So J would have equaled 11.\n                            # W would have equaled (11-9)=2\n                        \n            w=j-9  # Wilderness Area input. 10-9=1\n            \n            # now we have a W value, so we stop the loop for finding wilderness area for this given row and move on to find soil type\n            break\n            \n    # Category2 range   \n        # 14-54 is the column of the first soil type through the column of the last soil type \n              # Range (14,54) is actually the numbers 14-53\n                # If you look above to the numbered for loop column list, 53 is the last soil column\n            \n    for k in range(14,54):\n        \n         # (training.iloc[row,column] returns the value at the row, column location. \n            #So if there is a 1 at this location that means this row has a binary \"yes\" identifying it as being of that soil\n            # For example, training.iloc[i,k] will evaluate to 1 if i= 5 and k=43, and at that \"cell (5,43)\" the binary identifier is yes\n                # column 43 is soil type 30\n            # So once we evaluate to yes, we move onto the steps below the if statements\n            \n        if (training.iloc[i,k] == 1):\n            \n                # S is going to be our wilderness location when we input below \n                # So, using the above example (i=5, k=43), wilderness area would be set to 43-13 =30. \n                # s = 30\n                     # If the area in row 5 had been of Soil Type 31, it would have looped through once more. \n                        # So k would have equaled 44.\n                            # S would have equaled (44-13)=31\n            \n            s=k-13 # Soil Type input. 43-13=30\n            \n            # now we have a S value, so we stop the loop for finding Soil Type for this given row and move on to input the values\n            break\n    \n    \n    # Make an entry in 'data' for each r\n    \n        # Set the row i = 5 to a 3 element array that fills in the 3 empty columns in the 'data' table.\n            # 3 elements are wilderness area, soil type, and Cover type\n        \n        # i is the row in question - 5 in this example\n        # w is the wilderness area - (10-9)=1 in this example \n        #S is the soil type - (43-13) = 30 in this example \n        #training.iloc[i,c-1] is the cover type\n            #Cover type is not broken out into one hot encoded variables so we can just index it by using training.iloc\n                # i = the row in question, 5 in this example\n                # c - 1 gets us the last row of the training set\n                \n          \n    data.iloc[i]=[w,s,training.iloc[i,c-1]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now our data table is populated\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot for Wilderness Area  \nsns.countplot(x=\"Wilderness_Area\", hue=\"Cover_Type\", data=data)\nplt.show()\n\n#Plot for Soil Type\nplt.rc(\"figure\", figsize=(25, 10))\nsns.countplot(x=\"Soil_Type\", hue=\"Cover_Type\", data=data)\nplt.show()\n\n# right-click and open the image in a new window for larger size ","metadata":{"execution":{"iopub.status.busy":"2021-09-24T19:41:56.380696Z","iopub.execute_input":"2021-09-24T19:41:56.381845Z","iopub.status.idle":"2021-09-24T19:41:56.471433Z","shell.execute_reply.started":"2021-09-24T19:41:56.381635Z","shell.execute_reply":"2021-09-24T19:41:56.469958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WildernessArea_4 has a lot of presence for cover_type 4. Good class distinction  \n\nWildernessArea_3 has very litte class distinction  \n\nSoil Types **1-6, 10-14, 17, 22-23, 29-33, 35, and 38-40** offer significant class distinction as counts for some are very high","metadata":{}},{"cell_type":"markdown","source":"## Review and Future Work  \n\nIn this notebook, we used data visualization to gain an understanding of a large dataset of information about forests.   \nIn the future, we could leverage this understanding to build a classification model that predicts forest cover type by using the other columns of the dataset.  \n\nThank you for reading!","metadata":{}}]}