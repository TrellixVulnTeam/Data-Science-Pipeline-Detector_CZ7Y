{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T01:09:53.045745Z","iopub.execute_input":"2021-11-22T01:09:53.046516Z","iopub.status.idle":"2021-11-22T01:09:54.43049Z","shell.execute_reply.started":"2021-11-22T01:09:53.046408Z","shell.execute_reply":"2021-11-22T01:09:54.429032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/forest-cover-type-prediction/train.csv')\n\n# display train data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:09:57.510442Z","iopub.execute_input":"2021-11-22T01:09:57.51076Z","iopub.status.idle":"2021-11-22T01:09:57.643398Z","shell.execute_reply.started":"2021-11-22T01:09:57.510724Z","shell.execute_reply":"2021-11-22T01:09:57.642744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop ID column\ntrain = train.iloc[:,1:]\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:09:59.926583Z","iopub.execute_input":"2021-11-22T01:09:59.927429Z","iopub.status.idle":"2021-11-22T01:09:59.946586Z","shell.execute_reply.started":"2021-11-22T01:09:59.927385Z","shell.execute_reply":"2021-11-22T01:09:59.945704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:10:04.200715Z","iopub.execute_input":"2021-11-22T01:10:04.201197Z","iopub.status.idle":"2021-11-22T01:10:04.366731Z","shell.execute_reply.started":"2021-11-22T01:10:04.201133Z","shell.execute_reply":"2021-11-22T01:10:04.365835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"def outlier_function(df, col_name):\n    first_quartile = np.percentile(np.array(df[col_name].tolist()), 25)\n    third_quartile = np.percentile(np.array(df[col_name].tolist()), 75)\n    IQR = third_quartile - first_quartile\n    \n    upper_limit = third_quartile+(3*IQR)\n    lower_limit = first_quartile-(3*IQR)\n    outlier_count = 0\n    \n    for value in df[col_name].tolist():\n        if (value < lower_limit) | (value > upper_limit):\n            outlier_count += 1\n    return lower_limit, upper_limit, outlier_count","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:10:20.410303Z","iopub.execute_input":"2021-11-22T01:10:20.411046Z","iopub.status.idle":"2021-11-22T01:10:20.419015Z","shell.execute_reply.started":"2021-11-22T01:10:20.411002Z","shell.execute_reply":"2021-11-22T01:10:20.417808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: As `Wilderness_Area` and `Soil_Type` are one-hot encoded, we can focus on the following:\n\n\n- There are 53 outliers in Horizontal_Distance_To_Hydrology\n- There are 49 outliers in Vertical_Distance_To_Hydrology\n- There are 3 outliers in Horizontal_Distance_To_Roadways\n- There are 7 outliers in Hillshade_9am\n- There are 20 outliers in Hillshade_Noon\n- There are 132 outliers in Horizontal_Distance_To_Fire_Points","metadata":{}},{"cell_type":"code","source":"for column in train.columns:\n    if outlier_function(train, column)[2] > 0:\n        print(\"There are {} outliers in {}\".format(outlier_function(train, column)[2], column))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:10:23.946942Z","iopub.execute_input":"2021-11-22T01:10:23.947735Z","iopub.status.idle":"2021-11-22T01:10:26.36666Z","shell.execute_reply.started":"2021-11-22T01:10:23.947683Z","shell.execute_reply":"2021-11-22T01:10:26.365697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove outliers from Fire Points with highest range of outliers\ntrain = train[(train['Horizontal_Distance_To_Fire_Points'] > \n               outlier_function(train, 'Horizontal_Distance_To_Fire_Points')[0]) &\n            (train['Horizontal_Distance_To_Fire_Points'] <\n            outlier_function(train, 'Horizontal_Distance_To_Fire_Points')[1])]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:10:37.926142Z","iopub.execute_input":"2021-11-22T01:10:37.926463Z","iopub.status.idle":"2021-11-22T01:10:37.987266Z","shell.execute_reply.started":"2021-11-22T01:10:37.926428Z","shell.execute_reply":"2021-11-22T01:10:37.986138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:10:39.193296Z","iopub.execute_input":"2021-11-22T01:10:39.193571Z","iopub.status.idle":"2021-11-22T01:10:39.343737Z","shell.execute_reply.started":"2021-11-22T01:10:39.193542Z","shell.execute_reply":"2021-11-22T01:10:39.342836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering & Selection","metadata":{}},{"cell_type":"markdown","source":"There are horizontal and vertical distance to hydrology features, which blinks for adding the euclidian distance of the two.","metadata":{}},{"cell_type":"code","source":"train['Euclidian_Distance_To_Hydrology'] = (train['Horizontal_Distance_To_Hydrology']**2 + train['Vertical_Distance_To_Hydrology']**2)**0.5\ntrain['Mean_Elevation_Vertical_Distance_Hydrology'] = (train['Elevation'] + train['Vertical_Distance_To_Hydrology'])/2\ntrain['Mean_Distance_Hydrology_Firepoints'] = (train['Horizontal_Distance_To_Hydrology'] + train['Horizontal_Distance_To_Fire_Points'])/2\ntrain['Mean_Distance_Hydrology_Roadways'] = (train['Horizontal_Distance_To_Hydrology'] + train['Horizontal_Distance_To_Roadways'])/2\ntrain['Mean_Distance_Firepoints_Roadways'] = (train['Horizontal_Distance_To_Fire_Points'] + train['Horizontal_Distance_To_Roadways'])/2\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:19:02.025061Z","iopub.execute_input":"2021-11-22T01:19:02.025421Z","iopub.status.idle":"2021-11-22T01:19:02.073422Z","shell.execute_reply.started":"2021-11-22T01:19:02.02539Z","shell.execute_reply":"2021-11-22T01:19:02.072474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:10:27.679041Z","iopub.execute_input":"2021-11-22T02:10:27.679455Z","iopub.status.idle":"2021-11-22T02:10:27.688275Z","shell.execute_reply.started":"2021-11-22T02:10:27.679425Z","shell.execute_reply":"2021-11-22T02:10:27.687693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# create cat, num and y\n# create categorical features\nX_cat = train.iloc[:,10:54].values\n\n# numerical features\n# X_num_ori = train.iloc[:,0:10].values\n# X_num_new = train.iloc[:,56:60].values\nX_num = train.iloc[:, np.r_[0:10, 55:60]].values\n\n# create y\ny = train.iloc[:,-54].values","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:17:26.567595Z","iopub.execute_input":"2021-11-22T02:17:26.568086Z","iopub.status.idle":"2021-11-22T02:17:26.578199Z","shell.execute_reply.started":"2021-11-22T02:17:26.568041Z","shell.execute_reply":"2021-11-22T02:17:26.577103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale/standardize numerical columns\nscaler = StandardScaler() # scaler object\nscaler.fit(X_num) # fit training data\nX_num = scaler.transform(X_num) # scale num columns\n\n# shape\nprint(f'Categorical Shape: {X_cat.shape}')\nprint(f'Numerical Shape: {X_num.shape}')\nprint(f'Label Shape: {y.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:17:28.433318Z","iopub.execute_input":"2021-11-22T02:17:28.43366Z","iopub.status.idle":"2021-11-22T02:17:28.445957Z","shell.execute_reply.started":"2021-11-22T02:17:28.433601Z","shell.execute_reply":"2021-11-22T02:17:28.445129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine num and cat\nX = np.hstack((X_num, X_cat))\nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:17:30.523452Z","iopub.execute_input":"2021-11-22T02:17:30.524196Z","iopub.status.idle":"2021-11-22T02:17:30.531149Z","shell.execute_reply.started":"2021-11-22T02:17:30.52415Z","shell.execute_reply":"2021-11-22T02:17:30.530277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA().fit(X)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.title('PCA Number of Compoenents for Cumulative Variance')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:17:32.708675Z","iopub.execute_input":"2021-11-22T02:17:32.708949Z","iopub.status.idle":"2021-11-22T02:17:33.034161Z","shell.execute_reply.started":"2021-11-22T02:17:32.708921Z","shell.execute_reply":"2021-11-22T02:17:33.032258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dimensionality Reduction","metadata":{}},{"cell_type":"markdown","source":"## Extra-Trees Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\netc_model = ExtraTreesClassifier(random_state = 53) # pass the model\nX = train.iloc[:,:-54] # feed features to var X\ny = train['Cover_Type'] # feed target variable to y\n\netc_model.fit(X,y) # train the ETC model\n\n# extract feature importances\netc_feature_importances = pd.DataFrame(etc_model.feature_importances_, index=X.columns,\n                                      columns=['ETC']).sort_values('ETC', ascending=False)\n\netc_model = None # remove trace of this ETC model\netc_feature_importances.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:18:10.343104Z","iopub.execute_input":"2021-11-22T02:18:10.343393Z","iopub.status.idle":"2021-11-22T02:18:11.840849Z","shell.execute_reply.started":"2021-11-22T02:18:10.343363Z","shell.execute_reply":"2021-11-22T02:18:11.84002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc_model = RandomForestClassifier(random_state = 53) # pass the model\nrfc_model.fit(X,y) # train the model\n\n# extract feature importances\nrfc_feature_importances = pd.DataFrame(rfc_model.feature_importances_, index=X.columns, \n                                       columns=['RFC']).sort_values('RFC', ascending=False)\n\nrfc_model = None # remove trace of this RFC model\nrfc_feature_importances.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:03:26.815168Z","iopub.execute_input":"2021-11-22T02:03:26.815442Z","iopub.status.idle":"2021-11-22T02:03:29.543106Z","shell.execute_reply.started":"2021-11-22T02:03:26.815415Z","shell.execute_reply":"2021-11-22T02:03:29.542259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AdaBoost Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nadb_model = AdaBoostClassifier(random_state = 53) # pass the model\nadb_model.fit(X,y) # train the model\n\n# extract feature importances\nadb_feature_importances = pd.DataFrame(adb_model.feature_importances_, index=X.columns,\n                                      columns=['ADB']).sort_values('ADB', ascending=False)\n\nadb_model = None # remove trace of this ADB model\nadb_feature_importances.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:05:18.214309Z","iopub.execute_input":"2021-11-22T02:05:18.214643Z","iopub.status.idle":"2021-11-22T02:05:18.96842Z","shell.execute_reply.started":"2021-11-22T02:05:18.214576Z","shell.execute_reply":"2021-11-22T02:05:18.967667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc_model = GradientBoostingClassifier(random_state = 53) # pass the model\ngbc_model.fit(X,y) # train the model\n\n# extract feature importances\ngbc_feature_importances = pd.DataFrame(gbc_model.feature_importances_, index=X.columns,\n                                      columns=['GBC']).sort_values('GBC', ascending=False)\n\ngbc_model = None # remove trace of GBC model\ngbc_feature_importances.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:06:17.275509Z","iopub.execute_input":"2021-11-22T02:06:17.275811Z","iopub.status.idle":"2021-11-22T02:06:35.012503Z","shell.execute_reply.started":"2021-11-22T02:06:17.275779Z","shell.execute_reply":"2021-11-22T02:06:35.011477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features Selection\n\nWe will add the features we found important, plus the new features we engineered.","metadata":{}},{"cell_type":"code","source":"sample = train[[\n    'Elevation','Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Hydrology',\n    'Vertical_Distance_To_Hydrology','Aspect','Slope','Euclidian_Distance_To_Hydrology',\n    'Mean_Elevation_Vertical_Distance_Hydrology','Mean_Distance_Hydrology_Firepoints',\n    'Mean_Distance_Hydrology_Roadways','Mean_Distance_Firepoints_Roadways','Cover_Type'\n]]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:23:55.740242Z","iopub.execute_input":"2021-11-22T02:23:55.740529Z","iopub.status.idle":"2021-11-22T02:23:55.747417Z","shell.execute_reply.started":"2021-11-22T02:23:55.7405Z","shell.execute_reply":"2021-11-22T02:23:55.746376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# pass range to the function and then save it\nscaler = MinMaxScaler(feature_range = (0,1))\n\nX = sample.iloc[:,:-1] # feed sample features to X\ny = sample['Cover_Type'] # feed target variable to y\n\nX_scaled = scaler.fit_transform(X) # apply feature scaling to all features","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:26:46.877079Z","iopub.execute_input":"2021-11-22T02:26:46.877725Z","iopub.status.idle":"2021-11-22T02:26:46.889663Z","shell.execute_reply.started":"2021-11-22T02:26:46.877669Z","shell.execute_reply":"2021-11-22T02:26:46.889009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:26:55.102711Z","iopub.execute_input":"2021-11-22T02:26:55.103151Z","iopub.status.idle":"2021-11-22T02:26:55.10846Z","shell.execute_reply.started":"2021-11-22T02:26:55.103104Z","shell.execute_reply":"2021-11-22T02:26:55.107911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nimport time\n\n# function\ndef model_evaluation(clf):\n    clf = clf # pass classifier to variable\n    \n    t_start = time.time() # record time\n    clf = clf.fit(X_scaled, y) # classifier learning model\n    t_end = time.time() # record time\n    \n    c_start = time.time() # record time\n    accuracy = cross_val_score(clf, X_scaled, y, cv=10, scoring='accuracy')\n    f1_score = cross_val_score(clf, X_scaled, y, cv=10, scoring='f1_macro')\n    c_end = time.time() # record time\n    \n    # calculate mean of all 10 obs' accuracy and f1 as percent\n    acc_mean = np.round(accuracy.mean() * 100, 2)\n    f1_mean = np.round(f1_score.mean() * 100, 2)\n    \n    t_time = np.round((t_end - t_start) / 60, 3) # time for training\n    c_time = np.round((c_end - c_start) / 60, 3) # time for evaluating scores\n    \n    clf = None # remove traces of classifier\n    \n    print(f'The accuracy score of this classifier is: {acc_mean}%.')\n    print(f'The f1 score of this classifier is: {f1_mean}%.')\n    print(f'This classifier took {t_time} minutes to train and {c_time} minutes to evaluate CV and metric scores.')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:27:00.512921Z","iopub.execute_input":"2021-11-22T02:27:00.513553Z","iopub.status.idle":"2021-11-22T02:27:00.526148Z","shell.execute_reply.started":"2021-11-22T02:27:00.513501Z","shell.execute_reply":"2021-11-22T02:27:00.525144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Benchmark Model: `MultinomialNB Classifier`\nWe will not see how the performance of `MultinomialNB Classifier` on given training data. This performs quite quickly, but has poor **precision** and **recall**.","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nmodel_evaluation(MultinomialNB())","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:27:05.059096Z","iopub.execute_input":"2021-11-22T02:27:05.059781Z","iopub.status.idle":"2021-11-22T02:27:05.292953Z","shell.execute_reply.started":"2021-11-22T02:27:05.059719Z","shell.execute_reply":"2021-11-22T02:27:05.292026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"markdown","source":"## 1. K-Nearest Neighbors","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel_evaluation(KNeighborsClassifier(n_jobs=-1))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:27:40.655536Z","iopub.execute_input":"2021-11-22T02:27:40.655808Z","iopub.status.idle":"2021-11-22T02:27:46.831419Z","shell.execute_reply.started":"2021-11-22T02:27:40.65578Z","shell.execute_reply":"2021-11-22T02:27:46.830356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel_evaluation(RandomForestClassifier(n_jobs=-1, random_state=53))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:27:59.593719Z","iopub.execute_input":"2021-11-22T02:27:59.594046Z","iopub.status.idle":"2021-11-22T02:28:32.891509Z","shell.execute_reply.started":"2021-11-22T02:27:59.594009Z","shell.execute_reply":"2021-11-22T02:28:32.890359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Stochastic Gradient Descent Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nmodel_evaluation(SGDClassifier(n_jobs=-1, random_state=53))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:29:08.113865Z","iopub.execute_input":"2021-11-22T02:29:08.11427Z","iopub.status.idle":"2021-11-22T02:29:10.56162Z","shell.execute_reply.started":"2021-11-22T02:29:08.114241Z","shell.execute_reply":"2021-11-22T02:29:10.560662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Extra Trees Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nmodel_evaluation(ExtraTreesClassifier(n_jobs=-1, random_state=53))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:28:38.275514Z","iopub.execute_input":"2021-11-22T02:28:38.275827Z","iopub.status.idle":"2021-11-22T02:28:56.980888Z","shell.execute_reply.started":"2021-11-22T02:28:38.275794Z","shell.execute_reply":"2021-11-22T02:28:56.979958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Logisitic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel_evaluation(LogisticRegression(n_jobs=-1, random_state=53, solver='saga', max_iter = 500))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:28:56.982581Z","iopub.execute_input":"2021-11-22T02:28:56.983292Z","iopub.status.idle":"2021-11-22T02:29:04.514249Z","shell.execute_reply.started":"2021-11-22T02:28:56.983236Z","shell.execute_reply":"2021-11-22T02:29:04.513536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# number of trees in the forest algorithm\nn_estimators = [50, 100, 300, 500, 1000]\n\n# minimum number of samples required to split an internal node\nmin_samples_split = [2, 3, 5, 7, 9]\n\n# minimum number of samples required to be at a leaf node\nmin_samples_leaf = [1, 2, 4, 6, 8]\n\n# number of features to consider when looking for the best split\nmax_features = ['auto','sqrt','log2',None]\n\n# define the grid of hyperparameters to search\nhyperparameter_grid = {'n_estimators': n_estimators,\n                       'min_samples_leaf': min_samples_leaf,\n                       'min_samples_split': min_samples_split,\n                       'max_features': max_features}\n\n# create model\nbest_model = ExtraTreesClassifier(random_state=42)\n\n# create randomized search object\nrandom_cv = RandomizedSearchCV(estimator=best_model, param_distributions=hyperparameter_grid, cv=10,\n                               n_iter=20, scoring='accuracy', n_jobs=-1, verbose=1, return_train_score=True, random_state=0)\n\n# fit on all training data using random search object\nrandom_cv.fit(X_scaled, y)\nrandom_cv.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:32:00.195017Z","iopub.execute_input":"2021-11-22T02:32:00.195348Z","iopub.status.idle":"2021-11-22T02:40:48.63715Z","shell.execute_reply.started":"2021-11-22T02:32:00.195312Z","shell.execute_reply":"2021-11-22T02:40:48.636233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Final Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\nclf = ExtraTreesClassifier(n_estimators=1000, random_state=42, max_features='log2') # best classifier\nclf = clf.fit(X, y) # train model\npredict = clf.predict(X) # predict unseen data\naccuracy = accuracy_score(y, predict) # calculate accuracy\nf1_score = f1_score(y, predict, average='macro') # calculate f1 score\n\naccuracy = np.round(accuracy * 100, 3)\nf1_score = np.round(f1_score * 100, 3)\n\nclf = None # clean traces\n\nprint(f'The accuracy score of our final model ETC on our testing set is {accuracy}%.')\nprint(f'The f1 score of our final model ETC on our testing set is {f1_score}%.')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:45:46.232648Z","iopub.execute_input":"2021-11-22T02:45:46.233108Z","iopub.status.idle":"2021-11-22T02:46:05.573868Z","shell.execute_reply.started":"2021-11-22T02:45:46.233046Z","shell.execute_reply":"2021-11-22T02:46:05.572995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}