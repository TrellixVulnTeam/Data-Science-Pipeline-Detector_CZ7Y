{"cells":[{"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","cell_type":"code","metadata":{"_uuid":"6b651f1a78af74000abf7ac50ced0d92f5d61c70","collapsed":true,"_cell_guid":"9850d212-a1b0-48ca-b75a-fb4df9d84d57"},"execution_count":2},{"outputs":[],"source":"df_train = pd.read_csv('../input/train.csv')\ndf_train.drop('Id',axis=1,inplace = True)\nprint(df_train.info())\n\nX_train, X_cv, Y_train, Y_cv = train_test_split(df_train.drop('Cover_Type',axis=1),\n                                                df_train['Cover_Type'], test_size=0.2)\nX_test = pd.read_csv('../input/test.csv')\ntest_ids = X_test['Id']\nX_test.drop('Id',inplace=True,axis=1)\n","cell_type":"code","metadata":{"_uuid":"008354ba50a6142c89c1c718e68a0f966a48529e","_cell_guid":"fdd7595b-1f58-40e5-88a6-0d3fe5db8220"},"execution_count":3},{"outputs":[],"source":"\n# Let's plot the correlation of all features but Soil_Type's. \ncol_list = df_train.columns\ncol_list = [col for col in col_list if not col[0:4]=='Soil']\nfig, ax = plt.subplots(figsize=(10,10))  \nsns.heatmap(df_train[col_list].corr(),square=True,linewidths=1)\nplt.title('Correlation of Variables')\n\nplt.figure(figsize=(10,10))\nsns.boxplot(y='Elevation',x='Cover_Type', data= df_train )\nplt.title('Elevation vs. Cover_Type')\n\n\nsns.pairplot( df_train, hue='Cover_Type',vars=['Elevation','Aspect','Slope','Hillshade_9am','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Fire_Points'],diag_kind=\"kde\")\nplt.show()\n","cell_type":"code","metadata":{"_uuid":"e6959edbe9f1fd4997d62690ae837264ec400dad","_cell_guid":"2b228570-e123-458e-b906-897d40f37759"},"execution_count":4},{"outputs":[],"source":"## Starting the learning phase...\n\n## Let's try random forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators = 300, max_depth=15,min_samples_leaf=2)\nclf.fit(X_train, Y_train)\n\nprint('Random Forest train score =', clf.score(X=X_train,y=Y_train))\nprint('Random Forest test score =', clf.score(X=X_cv,y=Y_cv))\nprint('----------------------')\n\nrandForPrediction = clf.predict(X_test)\n\n","cell_type":"code","metadata":{"_uuid":"7431b3fa66f920aaeee3ec2aa1b44c178a18caf1","_cell_guid":"a4f5da2c-17e0-4a4a-858a-a5273504c9d0"},"execution_count":5},{"outputs":[],"source":"# Let's get the feature importances as well.\nfeatureImp = [(i, clf.feature_importances_[i]) for i in range(len(clf.feature_importances_))]\nfeatureImp =sorted(featureImp,key=lambda x: x[1],reverse=True)\nindList= [x[0] for x in featureImp]\nplt.figure(figsize=(20,10))\nplt.title('Feature Importance')\nplt.bar(range(len(clf.feature_importances_)), [x[1] for x in featureImp])\nplt.xticks(range(len(clf.feature_importances_)),\n           df_train.drop('Cover_Type',axis=1).columns[indList],rotation=90)\nplt.show()\n","cell_type":"code","metadata":{"_uuid":"c67de0a1a1c3b1e48c548b00c297088052cbadc9","_cell_guid":"75f08f5f-8828-43f3-9bb6-34cbe86ae356"},"execution_count":6},{"outputs":[],"source":"# # Let's try XGBOOST\nfrom xgboost import XGBClassifier\nclf = XGBClassifier(n_estimators=300,max_depth=5)\nclf.fit(X_train, Y_train)  \nprint('XGB train score =', clf.score(X=X_train,y=Y_train))\nprint('XGB test score =', clf.score(X=X_cv,y=Y_cv))\nprint('----------------------')\n\nXGBPrediction = clf.predict(X_test)","cell_type":"code","metadata":{"_uuid":"a791483a62bcaa7d5b1c74d0a7068e903a89bbcf","_cell_guid":"14a19134-29a7-4bf5-900b-edada1abb12a"},"execution_count":7},{"outputs":[],"source":"# Finally, let's try SVM.\nfrom sklearn import svm\n\n\nclf = svm.SVC(C=10,gamma=0.0000001)\nclf.fit(X_train, Y_train)  \n\nprint('SVM train score =', clf.score(X=X_train,y=Y_train))\nprint('SVM test score =', clf.score(X=X_cv,y=Y_cv)) \nprint('SVM number of support vectors =', len(clf.support_))\nprint('----------------------')\n\nSVMPrediction = clf.predict(X_test)","cell_type":"code","metadata":{"_uuid":"9b383c5e701aca1b2dddfc47a8b7112a7f092550","_cell_guid":"7b45e3cc-aa9c-4567-8797-c22d6c8bfa43"},"execution_count":null},{"outputs":[],"source":"from subprocess import check_output\n\nfinalPrediction = SVMPrediction\nloc_submission = \"submission.csv\"   \n\nwith open(loc_submission, \"w\") as outfile:\n    outfile.write(\"Id,Cover_Type\\n\")\n    for e, val in enumerate(finalPrediction):\n      outfile.write(\"%s,%s\\n\"%(test_ids[e],val))","cell_type":"code","metadata":{"_uuid":"6eed643688bc424fb6ec485568b02cf9c2003d53","collapsed":true,"_cell_guid":"0b22c3b9-838b-4528-a27e-9eda82873ac9"},"execution_count":null}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1}