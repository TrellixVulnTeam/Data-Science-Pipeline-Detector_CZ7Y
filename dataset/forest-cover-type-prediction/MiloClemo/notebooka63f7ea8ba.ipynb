{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d0dbc540-fa25-3bd9-44ee-33ca8ac9963e"},"source":"First attempt at classifying tree types"},{"cell_type":"markdown","metadata":{"_cell_guid":"42627d04-9f06-f939-afb7-d687ff2b5e34"},"source":"**Data Input**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5545da07-b154-453f-1c50-ae287bcd4471"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/train.csv\"]).decode(\"utf8\"))\n\n## Load in train dataset\n## Columns should all be int64\ntrain = pd.read_csv(\"../input/train.csv\")\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"c86d1cbf-6d00-f02b-c51a-d604290695fe"},"source":"**QC of input data** \n\n - Confirm number of rows/columns\n - Confirm data types (int64)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c905c5af-b1af-249d-40a5-d09014592a5c"},"outputs":[],"source":"print(train.shape)\nprint(train.dtypes)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca502ba6-4c56-7d3c-39a6-ce6954f8acb9"},"source":"**Statistical Exploration** \n\n - Count\n - Mean\n - Std\n - Min\n - 25%\n - 50%\n - 75%\n - Max"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d5d59a79-2f53-d4f2-8951-bf304a9c85e3"},"outputs":[],"source":"## Set option so that all columns are displayed\npd.set_option('display.max_columns', None)\nprint(train.describe())"},{"cell_type":"markdown","metadata":{"_cell_guid":"2cc072c8-6d48-a595-c15b-ae0ad1784419"},"source":"**Soil Type 7 and 15 have no values, and can be removed**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5410c661-7935-1f8d-90c3-7ef2747d2f4e"},"outputs":[],"source":"train = train.drop('Id', 1)\ntrain = train.drop('Soil_Type7', 1)\ntrain = train.drop('Soil_Type15', 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b60ccf64-f39b-50d3-07a2-aa27c6ceedae"},"outputs":[],"source":"print(train.shape)\nprint(list(train))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f306e2b2-a909-efdc-ab97-1e37e5a3fdba"},"source":"**Basic Statistics 2**\n\n - Correlation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"acf06abe-b6b0-6f77-b351-c5b359b649ee"},"outputs":[],"source":"#sets the number of features considered\nsize = 10 \n#create a dataframe with only 'size' features\ndata=train.iloc[:,:size] \n#get the names of all the columns\ncols=data.columns \n# Calculates pearson co-efficient for all combinations\ndata_corr = data.corr()\n# Set the threshold to select only only highly correlated attributes\nthreshold = 0.5\n# List of pairs along with correlation above threshold\ncorr_list = []\n#Search for the highly correlated pairs\nfor i in range(0,size): #for 'size' features\n    for j in range(i+1,size): #avoid repetition\n        if (data_corr.iloc[i,j] >= threshold and data_corr.iloc[i,j] < 1) or (data_corr.iloc[i,j] < 0 and data_corr.iloc[i,j] <= -threshold):\n            corr_list.append([data_corr.iloc[i,j],i,j]) #store correlation and columns index\n#Sort to show higher ones first            \ns_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n#Print correlations and column names\nfor v,i,j in s_corr_list:\n    print (\"%s and %s = %.2f\" % (cols[i],cols[j],v))"},{"cell_type":"markdown","metadata":{"_cell_guid":"641c5f21-67b0-c235-4d73-bc0f1ecc8d77"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9f64d55-abff-3fdb-5528-c7d4a7354331"},"outputs":[],"source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Scatter plot of only the highly correlated pairs\nfor v,i,j in s_corr_list:\n    sns.pairplot(train, hue=\"Cover_Type\", size=5, x_vars=cols[i],y_vars=cols[j] )\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"5559f837-0b43-26d0-de81-0ef69c94e829"},"source":"**Box/Density Plot Examples**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4889227b-9848-fb5d-237e-e6485830fc94"},"outputs":[],"source":"cols = train.columns\n#number of attributes (exclude target)\nsize = len(cols)-1\n#x-axis has target attribute to distinguish between classes\nx = cols[size]\n#y-axis shows values of an attribute\ny = cols[0:size]\n#Plot violin for all attributes\nfor i in range(0,size):\n    sns.violinplot(data=train,x=x,y=y[i])  \n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"33806c6c-c987-4780-eea1-bf4917f3ca7a"},"source":"Elevation shows some variance between land cover types. \nSoil_Type, 1,5,8,9,12,14,18-22, 25-30 and 35-40 offer class distinction as values are not present for many classes"},{"cell_type":"markdown","metadata":{"_cell_guid":"badf0a73-a99c-7448-1073-1c57f9dd445d"},"source":"**Data Prep**\n - StandardScaler \n - MinMaxScaler \n - Normalizer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ff36d9b-fab5-a861-ecd8-3b2bda0c9f55"},"outputs":[],"source":"import warnings\nwarnings.filterwarnings('ignore')\n#get the number of rows and columns\nr, c = train.shape\n#get the list of columns\ncols = train.columns\n#create an array which has indexes of columns\ni_cols = []\nfor i in range(0,c-1):\n    i_cols.append(i)\n#array of importance rank of all features  \nranks = []\n#Extract only the values\narray = train.values\n#Y is the target column, X has the rest\nX = array[:,0:(c-1)]\nY = array[:,(c-1)]\n#Validation chunk size\nval_size = 0.1\n#Use a common seed in all experiments so that same chunk is used for validation\nseed = 0\n#Split the data into chunks\nfrom sklearn import cross_validation\nX_train, X_val, Y_train, Y_val = cross_validation.train_test_split(X, Y, test_size=val_size, random_state=seed)\n#Import libraries for data transformations\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import Normalizer\n#All features\nX_all = []\n#Additionally we will make a list of subsets\nX_all_add =[]\n#columns to be dropped\nrem = []\n#indexes of columns to be dropped\ni_rem = []\n#List of combinations\ncomb = []\ncomb.append(\"All+1.0\")\n#Add this version of X to the list \nX_all.append(['Orig','All', X_train,X_val,1.0,cols[:c-1],rem,ranks,i_cols,i_rem])\n#point where categorical data begins\nsize=10\n#Standardized\n#Apply transform only for non-categorical data\nX_temp = StandardScaler().fit_transform(X_train[:,0:size])\nX_val_temp = StandardScaler().fit_transform(X_val[:,0:size])\n#Concatenate non-categorical data and categorical\nX_con = numpy.concatenate((X_temp,X_train[:,size:]),axis=1)\nX_val_con = numpy.concatenate((X_val_temp,X_val[:,size:]),axis=1)\n#Add this version of X to the list \nX_all.append(['StdSca','All', X_con,X_val_con,1.0,cols,rem,ranks,i_cols,i_rem])\n#MinMax\n#Apply transform only for non-categorical data\nX_temp = MinMaxScaler().fit_transform(X_train[:,0:size])\nX_val_temp = MinMaxScaler().fit_transform(X_val[:,0:size])\n#Concatenate non-categorical data and categorical\nX_con = numpy.concatenate((X_temp,X_train[:,size:]),axis=1)\nX_val_con = numpy.concatenate((X_val_temp,X_val[:,size:]),axis=1)\n#Add this version of X to the list \nX_all.append(['MinMax', 'All', X_con,X_val_con,1.0,cols,rem,ranks,i_cols,i_rem])\n#Normalize\n#Apply transform only for non-categorical data\nX_temp = Normalizer().fit_transform(X_train[:,0:size])\nX_val_temp = Normalizer().fit_transform(X_val[:,0:size])\n#Concatenate non-categorical data and categorical\nX_con = numpy.concatenate((X_temp,X_train[:,size:]),axis=1)\nX_val_con = numpy.concatenate((X_val_temp,X_val[:,size:]),axis=1)\n#Add this version of X to the list \nX_all.append(['Norm', 'All', X_con,X_val_con,1.0,cols,rem,ranks,i_cols,i_rem])\n#Impute\n#Imputer is not used as no data is missing\n#List of transformations\ntrans_list = []\nfor trans,name,X,X_val,v,cols_list,rem_list,rank_list,i_cols_list,i_rem_list in X_all:\n    trans_list.append(trans)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c305a09-3c2d-144a-9f10-15757c177fe7"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}