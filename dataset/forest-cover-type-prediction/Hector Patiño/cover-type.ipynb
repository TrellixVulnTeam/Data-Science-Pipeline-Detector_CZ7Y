{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install feature-engine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lazypredict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/forest-cover-type-prediction/train.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Custom Transformers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nclass DistanceTransformer(BaseEstimator, TransformerMixin):\n    # TODO create a tranformer that do its for any numeric variables in a pandas dataframe\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X['EuclideanDistanceHidroloy'] = np.around(\n            np.sqrt(X['Horizontal_Distance_To_Hydrology'] **2 +\n                    X['Vertical_Distance_To_Hydrology'] **2), \n            4)\n        X['Elevation_Vertical_Hydro_Minus'] = X['Elevation'] - X['Vertical_Distance_To_Hydrology']\n        X['Elevation_Vertical_Hydro_Plus'] = X['Elevation'] + X['Vertical_Distance_To_Hydrology']\n        X['Elevation_Vertical_Hydro_Prod'] = X['Elevation'] * X['Vertical_Distance_To_Hydrology']\n        \n        X['Elevation_Horizontal_Hydro_Minus'] = X['Elevation'] - X['Horizontal_Distance_To_Hydrology']\n        X['Elevation_Horizontal_Hydro_Plus'] = X['Elevation'] + X['Horizontal_Distance_To_Hydrology']\n        X['Elevation_Horizontal_Hydro_Prod'] = X['Elevation'] * X['Horizontal_Distance_To_Hydrology']\n        \n        X['Elevation_Horizontal_Fire_Minus'] = X['Elevation'] - X['Horizontal_Distance_To_Fire_Points']\n        X['Elevation_Horizontal_Fire_Plus'] = X['Elevation'] + X['Horizontal_Distance_To_Fire_Points']\n        X['Elevation_Horizontal_Fire_Prod'] = X['Elevation'] * X['Horizontal_Distance_To_Fire_Points']\n        \n        X['Elevation_Horizontal_Roadways_Minus'] = X['Elevation'] - X['Horizontal_Distance_To_Roadways']\n        X['Elevation_Horizontal_Roadways_Plus'] = X['Elevation'] + X['Horizontal_Distance_To_Roadways']\n        X['Elevation_Horizontal_Roadways_Prod'] = X['Elevation'] * X['Horizontal_Distance_To_Roadways']\n                \n        X['Hidrology_Horizonal_Fire_Minus'] = X['Horizontal_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Horizonal_Fire_Plus'] = X['Horizontal_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Horizonal_Fire_Prod'] = X['Horizontal_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Fire_Points']\n        \n        X['Hidrology_Horizonal_Roadways_Minus'] = X['Horizontal_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Horizonal_Roadways_Plus'] = X['Horizontal_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Horizonal_Roadways_Prod'] = X['Horizontal_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Roadways']\n        \n        X['Hidrology_Horizonal_Vertical_Minus'] = X['Horizontal_Distance_To_Hydrology'] - X['Vertical_Distance_To_Hydrology']\n        X['Hidrology_Horizonal_Vertical_Plus'] = X['Horizontal_Distance_To_Hydrology'] + X['Vertical_Distance_To_Hydrology']\n        X['Hidrology_Horizonal_Vertical_Prod'] = X['Horizontal_Distance_To_Hydrology'] * X['Vertical_Distance_To_Hydrology']\n        \n        X['Hidrology_Vertical_Fire_Minus'] = X['Vertical_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Vertical_Fire_Plus'] = X['Vertical_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Vertical_Fire_Prod'] = X['Vertical_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Fire_Points']\n        \n        X['Hidrology_Vertical_Fire_Minus'] = X['Vertical_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Vertical_Fire_Plus'] = X['Vertical_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Vertical_Fire_Prod'] = X['Vertical_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Roadways']\n        \n        X.drop(['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points'], axis=1, inplace=True)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DropIdentifierFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X.drop('Id', axis=1, inplace=True)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.validation import check_is_fitted\n\nclass FromDummiesToCategories(BaseEstimator, TransformerMixin):\n    def __init__(self, cols_to_operate, new_column_name):\n        self.cols_to_operate = cols_to_operate\n        self.new_column_name = new_column_name\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X1 = pd.DataFrame(X[self.cols_to_operate])\n        serie = X1.columns[np.where(X1!=0)[1]]\n        X[self.new_column_name] = serie\n        X.drop(self.cols_to_operate, axis=1, inplace=True)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AspectTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, column, new_name):\n        self.column = column\n        self.new_name = new_name\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X[self.new_name] = X[self.column].copy().apply(self._reclassify_aspect)\n        X.drop(self.column, axis=1, inplace=True)\n        return X\n        \n    def _reclassify_aspect(self, x):\n        if x<0:\n            return 'Flat'\n        if  0 >= x < 45:\n            return 'North'\n        if 45 >= x < 90:\n            return 'North_East'\n        if 90 >= x < 135:\n            return 'East'\n        if 135 >= x < 180:\n            return 'South_East'\n        if 180 >= x < 225:\n            return 'South'\n        if 225 >= x < 270:\n            return 'South_West'\n        if 270 >= x < 315:\n            return 'West'\n        if 315 >= x <360:\n            return 'North_West'\n        if 360 >= x :\n            return 'North_West'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\nX = data.drop('Cover_Type', axis=1).copy()\ny = data['Cover_Type'].copy()\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"soil_columns = [x for x in X.columns if x.startswith('Soil_Type')]\nwilder_columns = [x for x in X.columns if x.startswith('Wilder')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"from feature_engine.discretisation import EqualWidthDiscretiser, EqualFrequencyDiscretiser\nfrom feature_engine.selection  import DropConstantFeatures, DropDuplicateFeatures, DropCorrelatedFeatures, SelectBySingleFeaturePerformance, RecursiveFeatureElimination, SmartCorrelatedSelection, DropFeatures \nfrom feature_engine.encoding import RareLabelEncoder, OneHotEncoder, OrdinalEncoder\nfrom feature_engine.outliers import Winsorizer\nfrom feature_engine.creation import MathematicalCombination\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_list_1 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dd', DropDuplicateFeatures()),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness', 'Orientation'])),\n    ('dteq', EqualFrequencyDiscretiser(q=10, variables=['EuclideanDistanceHidroloy',                                                   \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),\n    ('dcf', DropCorrelatedFeatures(variables=None, method='pearson', threshold=0.80)),    \n]   \npipeline_1 = Pipeline(pipeline_list_1)\nX_train_pipe_1 = pipeline_1.fit_transform(X_train)\nX_train_pipe_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pipe_1 = pipeline_1.transform(X_test)\nX_test_pipe_1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Pipeline 2\nIn this pipeline I will change some transformers as :\n\n* Outliers in Elevation will be windorized\n* EuclidianDiscanteHidrology will not be Discretized, its outliers willbe windorized.\n* Hillshade_9am will not be Discretized, its outliers will be windorized.\n* Hillshade_Noon will not be Discretized, its outliers will be windorized.\n* Hillshade_3pm will not be Discretized, its outliers will be windorized"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_list_2 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dd', DropDuplicateFeatures()),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness', 'Orientation'])),\n    ('winds', Winsorizer(variables=['EuclideanDistanceHidroloy',  'Elevation',                                                 \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dcf', DropCorrelatedFeatures(variables=None, method='pearson', threshold=0.80)),    \n]   \npipeline_2 = Pipeline(pipeline_list_2)\nX_train_pipe_2 = pipeline_2.fit_transform(X_train)\nX_train_pipe_2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline 3\nThis pipeline is similar to pipeline2 except it uses SmartcorrelatedSelection."},{"metadata":{"trusted":true},"cell_type":"code","source":"\npipeline_list_3 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness', 'Orientation'])),\n    ('winds', Winsorizer(variables=['EuclideanDistanceHidroloy',  'Elevation',                                                 \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dd', SmartCorrelatedSelection()),  \n]   \npipeline_3 = Pipeline(pipeline_list_3)\nX_train_pipe_3 = pipeline_3.fit_transform(X_train)\nX_train_pipe_3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline 4\nThis pipeline will drop Soil and wilderness columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_list_4 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('dropwild_soil',DropFeatures(soil_columns + wilder_columns)),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dt', DistanceTransformer()),\n    ('one_hot',OneHotEncoder(variables=['Orientation'])),\n    ('winds', Winsorizer(variables=[\n        'EuclideanDistanceHidroloy',  'Elevation', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dd', SmartCorrelatedSelection()),  \n]   \npipeline_4 = Pipeline(pipeline_list_4)\nX_train_pipe_4 = pipeline_4.fit_transform(X_train)\nX_train_pipe_4.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline 5\nThis pipeline will use again the coluns of wilderness and soiltype, but will not make the aspect transformation."},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_list_5 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness'])),\n    ('winds', Winsorizer(variables=['EuclideanDistanceHidroloy',  'Elevation',                                                 \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dd', SmartCorrelatedSelection()),  \n]   \npipeline_5 = Pipeline(pipeline_list_5)\nX_train_pipe_5 = pipeline_5.fit_transform(X_train)\nX_train_pipe_5.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation Pipeline 1\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\npipe_list_1_rf = [('rf', RandomForestClassifier(random_state=42))]\npipe_1_rf = Pipeline(pipeline_list_1 + pipe_list_1_rf)\nrfpg1 ={\n    'rf__n_estimators': [100, 150, 200],\n    'rf__max_depth': [60,80, None],\n    'rf__min_samples_split': [2, 3, 4],\n}\ngrid1_pipe_1 = GridSearchCV(pipe_1_rf, param_grid=rfpg1, cv=sss, n_jobs=-1, verbose=3)\ngrid1_pipe_1.fit(X_train, y_train)\nprint(\"Best cross-validation accuracy: {:.2f}\".format(grid1_pipe_1.best_score_)) \nprint(\"Test set score: {:.2f}\".format(grid1_pipe_1.score(X_test, y_test))) \nprint(\"Best parameters: {}\".format(grid1_pipe_1.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ny_predict_pipe_1 = grid1_pipe_1.predict(X_test)\npd.DataFrame(metrics.confusion_matrix(y_test, y_predict_pipe_1, labels=y_test.unique().tolist()), columns =y_test.unique().tolist(), index = y_test.unique().tolist() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(metrics.classification_report(y_test, y_predict_pipe_1, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # # # Analysis of classifier\nThis classifier has problems with cover type 2 as it miss classify a large portion of the samples, specially it gets confusse class 2 with class 1"},{"metadata":{},"cell_type":"markdown","source":"# Evaluation pipeline 2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_list_2_rf = [('rf', RandomForestClassifier(random_state=42))]\npipe_2_rf = Pipeline(pipeline_list_2 + pipe_list_2_rf)\nrfpg2 ={\n    'rf__n_estimators': [100, 150, 200],\n    'rf__max_depth': [60,80, None],\n    'rf__min_samples_split': [2, 3, 4],\n}\ngrid1_pipe_2 = GridSearchCV(pipe_2_rf, param_grid=rfpg2, cv=sss, n_jobs=-1, verbose=3)\ngrid1_pipe_2.fit(X_train, y_train)\nprint(\"Best cross-validation accuracy: {:.2f}\".format(grid1_pipe_2.best_score_)) \nprint(\"Test set score: {:.2f}\".format(grid1_pipe_2.score(X_test, y_test))) \nprint(\"Best parameters: {}\".format(grid1_pipe_2.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_pipe_2 = grid1_pipe_2.predict(X_test)\npd.DataFrame(metrics.confusion_matrix(y_test, y_predict_pipe_2, labels=y_test.unique().tolist()), columns =y_test.unique().tolist(), index = y_test.unique().tolist() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(y_test, y_predict_pipe_2, digits=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nIm not happy with the results in this one, but im gonna stay with pipeline number 1, if in the future I have a better idea or if in my study I see somthing that is worth to try on Data Analysis I will do it in this dataset as i Really enjoy working on it."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/forest-cover-type-prediction/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest['Cover_Type'] = grid1_pipe_1.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nto_kaggle = test[['Id', 'Cover_Type']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nto_kaggle.to_csv('grid1_pipe_1', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\ny_predict_pipe_1 = grid1_pipe_1.predict(X_test)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}