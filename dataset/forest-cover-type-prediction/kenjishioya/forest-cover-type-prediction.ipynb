{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import make_union\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is visualized [here](https://www.kaggle.com/kenjishioya/draft-for-forest-cover-type-prediction)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import data\ntrain_df = pd.read_csv('../input/forest-cover-type-prediction/train.csv')\ntest_df = pd.read_csv('../input/forest-cover-type-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data info\nprint(train_df.info())\nprint(train_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values\nprint(train_df.columns[train_df.isnull().sum() > 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# outliers\nclass OutlierDetector():\n    def __init__(self, threshhold=3):\n        self.all_index_ = set()\n        self.columns_ = {}\n        self.threshhold_ = threshhold\n    \n    def fit(self, df, target_columns):\n        self.df_ = df.copy()\n        self.target_columns_ = target_columns\n        for column in self.target_columns_:\n            upper_limit, lower_limit, outliers = self.detect_outlier(self.df_[column])\n            self.all_index_ |= set(outliers.index.tolist())\n            self.columns_[column] = {'index': outliers.index.tolist(), 'upper_limit': upper_limit, 'lower_limit': lower_limit}\n        return self\n    \n    def detect_outlier(self, series):\n        first_q = np.percentile(np.array(series.tolist()), 25)\n        third_q = np.percentile(np.array(series.tolist()), 75)\n        IQR = third_q - first_q\n        \n        upper_limit = third_q+(self.threshhold_*IQR)\n        lower_limit = first_q-(self.threshhold_*IQR)\n        \n        outliers = series[(series > upper_limit) | (series < lower_limit)]\n        return upper_limit, lower_limit, outliers\n    \n    def get_df_without_outlier(self):\n        outlier_index = self.df_.index.isin(self.all_index_)\n        return self.df_.loc[~outlier_index]\n    \n    def get_ouliers_info(self):\n        return self.columns_\n    \n    def show_outliers_label_distribution(self, target_column, label_column):\n        outlier_index = self.df_.index.isin(self.columns_[target_column]['index'])\n        sns.histplot(self.df_.loc[outlier_index][label_column])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_detector = OutlierDetector()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = ['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_detector.fit(train_df, target_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_without_outliers = outlier_detector.get_df_without_outlier()\ntrain_df_without_outliers.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HeatMap for numeric features\nnumeric_features = ['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points']\ncorr = train_df_without_outliers[numeric_features].corr()\nplt.figure(figsize=(14,12))\ncolormap = plt.cm.RdBu\nsns.heatmap(corr,linewidths=0.1, \n            square=False, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomPreprocessor(BaseEstimator, TransformerMixin):\n        \n    def transform(self, X, y=None):\n        # feature generation\n        new_X = X.copy()\n        new_X['Ele_minus_VDtHyd'] = new_X['Elevation']-new_X['Vertical_Distance_To_Hydrology']\n        new_X['Ele_plus_VDtHyd'] = new_X['Elevation']+new_X['Vertical_Distance_To_Hydrology']\n        new_X['Distanse_to_Hydrolody'] = (new_X['Horizontal_Distance_To_Hydrology']**2+new_X['Vertical_Distance_To_Hydrology']**2)**0.5\n        new_X['Hydro_plus_Fire'] = new_X['Horizontal_Distance_To_Hydrology']+new_X['Horizontal_Distance_To_Fire_Points']\n        new_X['Hydro_minus_Fire'] = new_X['Horizontal_Distance_To_Hydrology']-new_X['Horizontal_Distance_To_Fire_Points']\n        new_X['Hydro_plus_Road'] = new_X['Horizontal_Distance_To_Hydrology']+new_X['Horizontal_Distance_To_Roadways']\n        new_X['Hydro_minus_Road'] = new_X['Horizontal_Distance_To_Hydrology']-new_X['Horizontal_Distance_To_Roadways']\n        new_X['Fire_plus_Road'] = new_X['Horizontal_Distance_To_Fire_Points']+new_X['Horizontal_Distance_To_Roadways']\n        new_X['Fire_minus_Road'] = new_X['Horizontal_Distance_To_Fire_Points']-new_X['Horizontal_Distance_To_Roadways']\n        # feature selection\n        columns_to_remove = ['Soil_Type1', 'Soil_Type2', 'Soil_Type5', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37']\n        new_X = new_X.drop(columns_to_remove, axis='columns')\n        return new_X\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train_df_without_outliers.Cover_Type\ntrain_X = train_df_without_outliers.drop(['Id','Cover_Type'], axis='columns')\ntest_id = test_df.Id\ntest_X = test_df.drop(['Id'], axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxg_model = XGBClassifier(\n    #learning_rate = 0.02,\n n_estimators= 500,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'multi:softprob',\n nthread= -1,\n scale_pos_weight=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nex_model = ExtraTreesClassifier(max_features=0.3, n_estimators=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ex_pipe = Pipeline([\n    (\"preprocess\", CustomPreprocessor()),\n    (\"model\", ex_model)\n])\nscores = cross_val_score(ex_pipe,train_X,train_y,cv=5,scoring='accuracy')\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_pipe = Pipeline([\n    (\"preprocess\", CustomPreprocessor()),\n    (\"model\", xg_model)\n])\nscores = cross_val_score(xg_pipe,train_X,train_y,cv=5,scoring='accuracy')\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ex_pipe.fit(train_X, train_y)\npredict = ex_pipe.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(test_id))\nprint(len(predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'Id': test_id, 'Cover_Type': predict})\nprint(submission.head())\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"reference:  \n[Forest_Prediction_Final](https://www.kaggle.com/nehabhandari1/forest-prediction-final)  \n[my_first_submission](https://www.kaggle.com/jianyu/my-first-submission)  "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}