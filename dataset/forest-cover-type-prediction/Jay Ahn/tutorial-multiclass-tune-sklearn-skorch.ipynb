{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Before begins\n\nThis notebook is written in google colab.\n\nTo see some interactive plots, please enter the colab link Below.\n\n<a href=\"https://colab.research.google.com/drive/1Kgd6OOrRE7rXrl62HTu4PHtAED2d2zWJ?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n\nThere are many notebooks similar to this for various competitions, so check the github address below\n\n<img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=50 align='left' alt=\"Open in Colab\" /></a>\n&nbsp; <font size=\"5\">[Github: Kaggle-Notebook](https://github.com/JayAhn0104/Kaggle-Notebook)</font>","metadata":{"id":"Zp1kQPbW1Dtg"}},{"cell_type":"markdown","source":"# Overview\n\n<br>\n\n## Competition Description\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3936/logos/thumb76_76.png\" width=50 align='left' alt=\"Open in Colab\"/></a>\n&nbsp; \n<font size=\"5\">[Forest Cover Type Prediction](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)</font>\n\n<br>\n\n- Problem type: (Multi-class) classification\n  - Predict the forest categories by using cartographic variables \n- Evaluation metric: Accuracy\n\n<br>\n\n## Notebook Description\n\nThis notebook provides the '**proper workflow**' for kaggle submission.\n\nThe workflow is divided into three main steps.\n1. Data preprocessing\n2. Model selection (hyper parameter tuning, model combination, model comparison)\n3. Training final model & Prediction on Test-set\n\nAt each stage, detailed descriptions of the work and an appropriate procedure will be provided.\n\nThrough this notebook, readers can learn the 'proper workflow' to be done for kaggle submission, \nand using this as a basic structure, someone will be able to apply this to other competitions easily with some adjustments\n\n**Warnings**:\n- The purpose of this notebook\n  - This notebook focuses on the 'procedure' rather than the 'result'. \n  - Thus this notebook does not guide you on how to achieve the top score. Since I personally think that any result can only have a meaning through an appropriate procedure.\n  - But since this is a competition, it cannot be avoided that the score is important. Following this notebook, you will get the top 15% (score: 0.12519) result in this competition\n\n- The readers this notebook is intended for\n  - Who are aware of the basic usage of data processing tools (e.g., numpy, pandas)\n  - Who are aware of the basic concepts of machine learning models \n","metadata":{"id":"-SwjGFuM1KH-"}},{"cell_type":"markdown","source":"# 0. Preliminaries","metadata":{"id":"3pWVGPoI3F8F"}},{"cell_type":"markdown","source":"### > Set Configurations \n\n- Set the configurations for this notebook","metadata":{"id":"1iXf0FYdV6lR"}},{"cell_type":"code","source":"config = {\n    'data_name': 'forest-cover-type-prediction',\n    'random_state': 2022\n}","metadata":{"id":"cqAZuca43Hsr","execution":{"iopub.status.busy":"2022-03-12T03:15:55.766917Z","iopub.execute_input":"2022-03-12T03:15:55.76721Z","iopub.status.idle":"2022-03-12T03:15:55.772399Z","shell.execute_reply.started":"2022-03-12T03:15:55.767178Z","shell.execute_reply":"2022-03-12T03:15:55.770825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Install Libraries","metadata":{"id":"M7Cdi76nV9ci"}},{"cell_type":"code","source":"!pip install tune_sklearn skorch","metadata":{"id":"YHF5wP1-V-Fg","execution":{"iopub.status.busy":"2022-03-12T03:16:05.951573Z","iopub.execute_input":"2022-03-12T03:16:05.951872Z","iopub.status.idle":"2022-03-12T03:16:19.571242Z","shell.execute_reply.started":"2022-03-12T03:16:05.95184Z","shell.execute_reply":"2022-03-12T03:16:19.570068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data preprocessing\n\nThe data preprocessing works are divided into 9 steps here.\n\nSome of these steps are mandatory and some are optional.\n\nOptional steps are marked separately.\n\nIt is important to go through each step in order.\nBe careful not to reverse the order.","metadata":{"id":"gH2oJD3ezQD6"}},{"cell_type":"markdown","source":"## 1-1. Load Dataset\n\nLoad train-set and test-set on working environment\n","metadata":{"id":"VtX2Kc_03TGR"}},{"cell_type":"markdown","source":"### > Load Data-set","metadata":{"id":"9Mt5zqAKUSUV"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\ntrain = pd.read_csv('/kaggle/input/{}/train.csv'.format(config['data_name']))\ntest = pd.read_csv('/kaggle/input/{}/test.csv'.format(config['data_name']))","metadata":{"id":"OmHiIN8l4HrR","execution":{"iopub.status.busy":"2022-03-12T03:16:19.578152Z","iopub.execute_input":"2022-03-12T03:16:19.580912Z","iopub.status.idle":"2022-03-12T03:16:22.392529Z","shell.execute_reply.started":"2022-03-12T03:16:19.580855Z","shell.execute_reply":"2022-03-12T03:16:22.391495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Concatenate the 'train' and 'test' data for preprocessing\n\nData preprocessing work should be applied equally for train-set and test-set.\n\nIn order to work at once, exclude the response variable 'Cover_Type' from 'train' and combine it with 'test'.","metadata":{"id":"Kev0Dvdf3WTW"}},{"cell_type":"code","source":"all_features = pd.concat((train.drop(['Id','Cover_Type'], axis=1), test.drop(['Id'], axis=1)), axis=0)","metadata":{"id":"0TDFp6vD3VJI","execution":{"iopub.status.busy":"2022-03-12T03:16:22.393937Z","iopub.execute_input":"2022-03-12T03:16:22.395705Z","iopub.status.idle":"2022-03-12T03:16:22.606704Z","shell.execute_reply.started":"2022-03-12T03:16:22.395655Z","shell.execute_reply":"2022-03-12T03:16:22.605721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-2. Missing Value Treatment\n\nMissing (NA) values in Data must be treated properly before model training.\n\nThere are three main treatment methods:\n1. Remove the variables which have NA values\n2. Remove the rows (observations) which have NA values\n3. Impute the NA values with other values\n\nWhich of the above methods is chosen is at the analyst's discretion.\nIt is important to choose the appropriate method for the situation.","metadata":{"id":"Fia79Yb4YfnR"}},{"cell_type":"markdown","source":"### > Check missing values in each variable\n\nThere is no missing values in the data-set","metadata":{"id":"lE7irare3a4q"}},{"cell_type":"code","source":"all_features.isnull().sum().values","metadata":{"id":"BRVmI9DA8pfA","outputId":"7cd204dd-0d8b-4272-8aee-d6ef15f9570e","execution":{"iopub.status.busy":"2022-03-12T03:16:22.609314Z","iopub.execute_input":"2022-03-12T03:16:22.609552Z","iopub.status.idle":"2022-03-12T03:16:22.667974Z","shell.execute_reply.started":"2022-03-12T03:16:22.609521Z","shell.execute_reply":"2022-03-12T03:16:22.666998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-3. Adding new features (*optional*)\n\nNew variables can be created using the given data.\nThese variables are called 'derived variables'.\n\nNew informations can be added by creating appropriate derived variables.\n\nThis can have a positive effect on model performance. (Not always)\n","metadata":{"id":"IivbeIZeoVzE"}},{"cell_type":"markdown","source":"### > Get Euclidean distance by using horizontal distance and vertical distance \n\nThere are 'Horizontal_Distance_To_Hydrology' and 'Vertical_Distance_To_Hydrology'. \n\nBy using Pythagorean theorem, we can calculate the Euclidean distance to hydrology","metadata":{"id":"9VrJv57mX49t"}},{"cell_type":"code","source":"all_features['Euclidean_Distance_To_Hydrology'] = np.sqrt(np.power(all_features['Horizontal_Distance_To_Hydrology'],2) + np.power(all_features['Vertical_Distance_To_Hydrology'],2))","metadata":{"id":"USRz3Gy90BJf","execution":{"iopub.status.busy":"2022-03-12T03:16:22.669395Z","iopub.execute_input":"2022-03-12T03:16:22.670412Z","iopub.status.idle":"2022-03-12T03:16:22.695346Z","shell.execute_reply.started":"2022-03-12T03:16:22.670362Z","shell.execute_reply":"2022-03-12T03:16:22.694394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-4. Variable modification\n\n### > Aspect\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Brosen_windrose.svg/600px-Brosen_windrose.svg.png\" width=180 align='left' alt=\"Open in Colab\"/></a>\n\nAccording to the data description, 'Aspect' indicates the Aspect in degrees azimuth. \nIn the cartographic data, the azimuth is the angular direction of the sun, measured from the north in clockwise degrees from 0 to 360. \nFor example, An azimuth of 90 degrees is east.\n\nSince the values of 'Aspect' vary from 0 to 360, this variable's actual information, which is the azimuth angle, can not be obtained in modeling.\n\nThus we need to convert these values ​​appropriately to represent the azimuth angle.\n\n<br>\n\nProcedure:\n- Bin values into discrete intervals based on the cardinal direction \n- Label the binned discrete intervals based on the cardinal direction\n\n","metadata":{"id":"RETuULj8Wwjs"}},{"cell_type":"code","source":"aspect_label_list = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\naspect_interval = np.linspace(11.25, 371.25, 17)\naspect_interval[0] = 0\nall_features['Aspect_direction'] = pd.cut(all_features['Aspect']+11.25, aspect_interval, right=True, labels=aspect_label_list, ordered=False)\nall_features.drop('Aspect', inplace=True, axis=1)","metadata":{"id":"bXa-D51f1VGh","execution":{"iopub.status.busy":"2022-03-12T03:16:22.697111Z","iopub.execute_input":"2022-03-12T03:16:22.697464Z","iopub.status.idle":"2022-03-12T03:16:22.821427Z","shell.execute_reply.started":"2022-03-12T03:16:22.697417Z","shell.execute_reply":"2022-03-12T03:16:22.820408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-5. Dummify categorical variables\n\nIn the case of linear modeling without regularization, the first or last column should be dropped (to prevent linear dependency), but here, for the convenience of using the factorization model, one-hot encoding method is used that does not drop any columns.","metadata":{"id":"hJayzx_-Nzck"}},{"cell_type":"code","source":"data_set = pd.get_dummies(all_features, drop_first=False)","metadata":{"id":"CsctjSYSQClH","execution":{"iopub.status.busy":"2022-03-12T03:16:22.823484Z","iopub.execute_input":"2022-03-12T03:16:22.824123Z","iopub.status.idle":"2022-03-12T03:16:23.073017Z","shell.execute_reply.started":"2022-03-12T03:16:22.824076Z","shell.execute_reply":"2022-03-12T03:16:23.072055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-6. Scaling continuous variables\n\nMinMaxScaling maps all variables from 0 to 1 in order to consider only relative information, not absolute magnitudes of the values.\n\nBesides, it is known that scaling is often more stable in parameter optimization when training a model.","metadata":{"id":"Yo_M-blKP1pP"}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata_set = scaler.fit_transform(data_set)","metadata":{"id":"W-F7cdreP1ZV","execution":{"iopub.status.busy":"2022-03-12T03:16:23.075558Z","iopub.execute_input":"2022-03-12T03:16:23.076245Z","iopub.status.idle":"2022-03-12T03:16:23.684338Z","shell.execute_reply.started":"2022-03-12T03:16:23.076176Z","shell.execute_reply":"2022-03-12T03:16:23.683298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-7. Split Train & Test set","metadata":{"id":"3Bds2C0rQb_c"}},{"cell_type":"code","source":"n_train = train.shape[0]\nX_train = data_set[:n_train].astype(np.float32)\nX_test = data_set[n_train:].astype(np.float32)\ny_train = train['Cover_Type'].values.astype(np.int64)","metadata":{"id":"AZj86aMgaBrp","execution":{"iopub.status.busy":"2022-03-12T03:16:23.686141Z","iopub.execute_input":"2022-03-12T03:16:23.68652Z","iopub.status.idle":"2022-03-12T03:16:23.771096Z","shell.execute_reply.started":"2022-03-12T03:16:23.686471Z","shell.execute_reply":"2022-03-12T03:16:23.770109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-8. Outlier Detection on Training data (*optional*)\n\nDetect and remove outlier observations that exist in the train-set.\n\n- Methodology: [Isolation Forest](https://ieeexplore.ieee.org/abstract/document/4781136/?casa_token=V7U3M1UIykoAAAAA:kww9pojtMeJtXaBcNmw0eVlJaXEGGICi1ogmeHUFMpgJ2h_XCbSd2yBU5mRgd7zEJrXZ01z2)\n  - How it works\n    - Isolation Forest applies a decision tree that repeats splits based on the 'random criterion' for the given data unitl only one observation remains in every terminal node (this is defined as 'isolation').\n    - Based on the number of splits used for isolation, 'normality' is defined. A smaller value means a higher degree of outlierness.\n    - By applying this decision tree several times, the average of the measured 'normality' values ​​is derived as the final 'normality' value.\n  - Assumptions\n    - Outliers require relatively few splits to be isolated.\n    - For normal data, the number of splits required to be isolated is relatively large.\n  - Outlier determination\n    - Determines whether it is an outlier or not based on the measured 'normality' value.\n      - sklearn's IsolationForest package determines based on '0' \n      - I, personally, think it is better to set the discriminant criterion by considering the 'distribution' of the 'normality' values.\n      - The details of the method is given below.","metadata":{"id":"xXpd4YS_Rooe"}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nclf = IsolationForest(\n    n_estimators=100,\n    max_samples='auto',\n    n_jobs=-1,\n    random_state=config['random_state'])\n\nclf.fit(X_train)\nnormality_df = pd.DataFrame(clf.decision_function(X_train), columns=['normality'])","metadata":{"id":"CT4-2FOcRnkM","execution":{"iopub.status.busy":"2022-03-12T03:16:23.77469Z","iopub.execute_input":"2022-03-12T03:16:23.775047Z","iopub.status.idle":"2022-03-12T03:16:24.803615Z","shell.execute_reply.started":"2022-03-12T03:16:23.774999Z","shell.execute_reply":"2022-03-12T03:16:24.802633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The dicriminant value \n  - The discriminant value (threshold) is defined by calculating the 1st quartile ($q_1$) and 3rd quartile ($q_3$) on the distribution of the measured normality values.\n    - with $k=1.5$\n\n$$threshold = q_1 - k*(q_3 - q_1)$$\n\n\n- Motivation\n  - This discriminant method is adapted from Tukey's boxplot idea.\nIn the distribution of any continuous variable, Tukey designates observations smaller than that value or larger than q_3 + k*(q_3 - q_1) as outliers.\n\n- How we do \n  - Our methodology does not apply the above method to a specific variable, but applies the method to the obtained normality.\n\n  - That is, it is based on the assumption that an outlier will be far left from the other observations in the measured normality distribution.","metadata":{"id":"hdaIv79s73kV"}},{"cell_type":"code","source":"def outlier_threshold(normality, k=1.5):\n  q1 = np.quantile(normality, 0.25)\n  q3 = np.quantile(normality, 0.75)  \n  threshold = q1 - k*(q3-q1)\n  return threshold\n\nthreshold = outlier_threshold(normality_df['normality'].values, k=1.5)\n\nimport plotly.express as px\nfig = px.histogram(normality_df, x='normality', width=400, height=400)\nfig.add_vline(x=threshold, line_width=3, line_dash=\"dash\", line_color=\"red\")\nfig.show()","metadata":{"id":"fnuzws26Sm_7","outputId":"ca9aa335-8487-4fb5-eabf-b0c4b5c1338e","execution":{"iopub.status.busy":"2022-03-12T03:16:24.805186Z","iopub.execute_input":"2022-03-12T03:16:24.805532Z","iopub.status.idle":"2022-03-12T03:16:28.565972Z","shell.execute_reply.started":"2022-03-12T03:16:24.805489Z","shell.execute_reply":"2022-03-12T03:16:28.564059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\npx.box(normality_df, x='normality', orientation='h', width=400, height=400)","metadata":{"id":"HFc_y-fSUp4Y","outputId":"e9537299-5697-43bf-b3d1-6ce551cb59f8","execution":{"iopub.status.busy":"2022-03-12T03:16:28.567587Z","iopub.execute_input":"2022-03-12T03:16:28.567913Z","iopub.status.idle":"2022-03-12T03:16:28.713295Z","shell.execute_reply.started":"2022-03-12T03:16:28.56786Z","shell.execute_reply":"2022-03-12T03:16:28.712125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train[normality_df['normality'].values>=threshold]\ny_train = y_train[normality_df['normality'].values>=threshold]\n\nprint('{} observations are removed from train_set'.format(train.shape[0] - X_train.shape[0]))","metadata":{"id":"sTVOUiyma73J","outputId":"c3f0de73-78c0-4cec-b827-b1e3ced2a812","execution":{"iopub.status.busy":"2022-03-12T03:16:28.715021Z","iopub.execute_input":"2022-03-12T03:16:28.715449Z","iopub.status.idle":"2022-03-12T03:16:28.732568Z","shell.execute_reply.started":"2022-03-12T03:16:28.715404Z","shell.execute_reply":"2022-03-12T03:16:28.73132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-9. Output variable transformation\n\nPyTorch module supports labels starting from 0.\n\nSince our output variable values vary from 1 to 7, we convert these to 0 to 7.","metadata":{"id":"uvVfaWVqaTNH"}},{"cell_type":"code","source":"np.unique(y_train)","metadata":{"id":"Wh05gyyTevsE","outputId":"f2ab0168-ca06-4372-dce9-13d5f6e6e989","execution":{"iopub.status.busy":"2022-03-12T03:16:28.734409Z","iopub.execute_input":"2022-03-12T03:16:28.734748Z","iopub.status.idle":"2022-03-12T03:16:28.744784Z","shell.execute_reply.started":"2022-03-12T03:16:28.7347Z","shell.execute_reply":"2022-03-12T03:16:28.743318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_trans = y_train - 1","metadata":{"id":"ScxFpT5baT5q","execution":{"iopub.status.busy":"2022-03-12T03:16:28.746496Z","iopub.execute_input":"2022-03-12T03:16:28.74691Z","iopub.status.idle":"2022-03-12T03:16:28.752649Z","shell.execute_reply.started":"2022-03-12T03:16:28.746865Z","shell.execute_reply":"2022-03-12T03:16:28.751354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# 2. Model Selection\n\nOur goal is to build a model that predicts the forest cover type given the cartographic informations of the forest. The formula can be expressed as:\n\n$\\hat{y} = \\underset{k \\in \\{1,\\cdots,K\\}}{\\operatorname{argmax}}f_{k}(x)$\n\nwhere,\n  - $y \\in \\{1,\\cdots,K\\} $: labels \n  - $x$: an input observation\n  - $f_{k}(x)$: a function of $x$ that outputs predicted value for each $k$\n\nThis is a typical multiclass classification problem, and various machine learning models can be obtained. This notebook uses the following models.\n- Logistic regression\n- Support vector machine\n- Random forest\n- Xgboost\n- Multi-layer perceptron\n- Factorization\n\nHowever, we have to \"choose\" one final methodology to make predictions on the test set.\nTo do this, a “fair evaluation” of the models is essential. \"Fair evaluation\" must satisfy the following two conditions.\n\n1. Select optimal hyperparameters for each model\n  - If hyperparameter search is not performed, the difference in model performance may occur due to incorrect hyperparameter values.\n2. same evaluation method\n  - If the same evaluation method is not applied, comparison between models itself is impossible.\n\nWhen comparing models through an evaluation method that satisfies the above two conditions,\nOnly then can the final model be selected.\n\n\n","metadata":{"id":"3UbJJrv6i3kM"}},{"cell_type":"markdown","source":"## 2-1. Hyper parameter tuning by using Tune_SKlearn (Ray Tune)\n\n- Package: tune_sklearn\n  - This package makes it easy to apply [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) to sklearn models.\n  - Ray Tune is a python package that provides various hyperparameter tuning algorithms (HyperOpt, BayesianOptimization, ...).\n- Tuning procedure\n  - Define an appropriate search space for each model's hyperparameters.\n  - 5-fold CV (Cross Validation) is performed for each specific hyper-parameter value combination of the search space by using the hyper-parameter tuning algorithm (HyperOpt)\n    - Training: Training by using Scikit-Learn and Skorch packages\n    - Validation: Evaluate the model using an appropriate evaluation metric\n  - The hyperparameter with the highest average score of the CV result is designated as the optimal hyperparameter of the model.\n    - Save this CV result and use for model comparison\n\n","metadata":{"id":"TpffTJyuKCip"}},{"cell_type":"markdown","source":"### > Make a dataframe for containing CV results","metadata":{"id":"9W6seW1C6Lwa"}},{"cell_type":"code","source":"model_list = []\nfor name in ['linear', 'svm', 'rf', 'xgb', 'mlp', 'fm']:\n  model_list.append(np.full(5, name))\n  \nbest_cv_df = pd.DataFrame({'model': np.hstack((model_list)), 'log_loss':None, 'accuracy':None, 'best_hyper_param':None})","metadata":{"id":"yecAASyT5ljV","execution":{"iopub.status.busy":"2022-03-12T03:16:32.447212Z","iopub.execute_input":"2022-03-12T03:16:32.447542Z","iopub.status.idle":"2022-03-12T03:16:32.454352Z","shell.execute_reply.started":"2022-03-12T03:16:32.447508Z","shell.execute_reply":"2022-03-12T03:16:32.453352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Logistic regression","metadata":{"id":"2MZsMccOKY2B"}},{"cell_type":"code","source":"from tune_sklearn import TuneSearchCV\nfrom sklearn.linear_model import SGDClassifier\n\n# Define a search space\nparameters = {\n    'max_iter': [1000],\n    'loss': ['log'],\n    'penalty': ['l2'],\n    'random_state': [config['random_state']],\n    'alpha': list(np.geomspace(1e-6, 1e-3, 4)),\n    'tol': list(np.geomspace(1e-4, 1e-1, 4))\n}\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    SGDClassifier(),\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=10,\n    n_jobs=-1,\n    scoring=['neg_log_loss', 'accuracy'],\n    cv=5,\n    refit='accuracy', # target metric of competition\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n# Run hyper parameter tuning\nX = X_train\ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'linear'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'log_loss'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[5:10]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_accuracy')\nfig.show()","metadata":{"id":"2o4dQv1oreS4","outputId":"705a7ee2-ac38-4b8b-dd4c-5faea34f6dad","execution":{"iopub.status.busy":"2022-03-12T03:16:32.621751Z","iopub.execute_input":"2022-03-12T03:16:32.622076Z","iopub.status.idle":"2022-03-12T03:18:02.544261Z","shell.execute_reply.started":"2022-03-12T03:16:32.622032Z","shell.execute_reply":"2022-03-12T03:18:02.543152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Support vector machine","metadata":{"id":"db18WC2yKc9p"}},{"cell_type":"code","source":"from tune_sklearn import TuneSearchCV\nfrom sklearn.linear_model import SGDClassifier\n\n# Define a search space\nparameters = {\n    'alpha': list(np.geomspace(1e-7, 1e-3, 3)),\n    'epsilon': list(np.geomspace(1e-5, 1e-1, 3)),\n    'loss': ['hinge'],\n    'tol': list(np.geomspace(1e-7, 1e-1, 4)),\n    'max_iter': [1000],\n    'penalty': ['l2'],\n    'random_state': [config['random_state']]\n}\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    SGDClassifier(),\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=10,\n    n_jobs=-1,\n    scoring=['accuracy'],\n    cv=5,\n    refit='accuracy', # target metric of competition\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n# Run hyper parameter tuning\nX = X_train \ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'svm'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[:5]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_accuracy')\nfig.show()","metadata":{"id":"VsI-OMilwGxb","outputId":"f5032a81-0882-43e1-ea7c-ea89aa8b5c8f","execution":{"iopub.status.busy":"2022-03-12T03:18:02.547254Z","iopub.execute_input":"2022-03-12T03:18:02.547615Z","iopub.status.idle":"2022-03-12T03:19:07.799527Z","shell.execute_reply.started":"2022-03-12T03:18:02.547563Z","shell.execute_reply":"2022-03-12T03:19:07.798464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Random forest","metadata":{"id":"TZV1XLbAKffy"}},{"cell_type":"code","source":"from tune_sklearn import TuneSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Define a search space\nparameters = {\n    'n_estimators': [100, 500, 1000],\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [20, 25, 30],\n    'max_features': ['auto'],\n    'random_state': [config['random_state']]\n}\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    RandomForestClassifier(),\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=10,\n    n_jobs=-1,\n    scoring=['neg_log_loss', 'accuracy'],\n    cv=5,\n    refit='accuracy',\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n\n# Run hyper parameter tuning\nX = X_train \ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'rf'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'log_loss'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[5:10]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_accuracy')\nfig.show()","metadata":{"id":"10x4_Hh9hqMN","outputId":"5a80582d-09b8-4591-d066-07618db77318","execution":{"iopub.status.busy":"2022-03-12T03:19:07.801357Z","iopub.execute_input":"2022-03-12T03:19:07.803448Z","iopub.status.idle":"2022-03-12T03:27:42.473065Z","shell.execute_reply.started":"2022-03-12T03:19:07.803387Z","shell.execute_reply":"2022-03-12T03:27:42.472022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > XGBoost","metadata":{"id":"NGiWtM5NKhA-"}},{"cell_type":"code","source":"from tune_sklearn import TuneSearchCV\nfrom xgboost import XGBClassifier\n\n# Define a search space\nparameters = {\n    'n_estimators': [50, 100, 200],\n    'learning_rate': list(np.geomspace(1e-2, 1, 3)),\n    'min_child_weight': [10, 15, 20],\n    'gamma': [0.5, 2],\n    'subsample': [0.6, 1.0],\n    'colsample_bytree': [0.6, 1.0],\n    'max_depth': [5, 10, 15],\n    'objective': ['multi:softmax'],\n    'random_state': [config['random_state']]\n}\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    XGBClassifier(),\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=10,\n    n_jobs=-1,\n    scoring=['neg_log_loss', 'accuracy'],\n    cv=5,\n    refit='accuracy',\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n\n# Run hyper parameter tuning\nX = X_train \ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'xgb'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'log_loss'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[5:10]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_accuracy')\nfig.show()","metadata":{"id":"YtJ5wlpu9j21","outputId":"ee40a335-eb45-4e13-d8e3-c687122ed7be","execution":{"iopub.status.busy":"2022-03-12T03:27:42.476539Z","iopub.execute_input":"2022-03-12T03:27:42.476907Z","iopub.status.idle":"2022-03-12T04:40:56.509774Z","shell.execute_reply.started":"2022-03-12T03:27:42.476849Z","shell.execute_reply":"2022-03-12T04:40:56.508685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Multi-layer perceptron","metadata":{"id":"eMEkfLDXKmtD"}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom skorch import NeuralNetClassifier\nfrom skorch.callbacks import EarlyStopping\nfrom skorch.callbacks import Checkpoint\nfrom tune_sklearn import TuneSearchCV\n\n# Define a model structure\nclass MLP(nn.Module):\n    def __init__(self, num_inputs=X_train.shape[1], num_outputs=len(np.unique(y_train)), layer1=512, layer2=256, dropout1=0, dropout2=0):\n        super(MLP, self).__init__()\n\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(num_inputs, layer1),\n            nn.LeakyReLU(),\n            nn.Dropout(dropout1),\n            nn.Linear(layer1, layer2),\n            nn.LeakyReLU(),\n            nn.Dropout(dropout2),\n            nn.Linear(layer2, num_outputs)\n            )\n    def forward(self, x):\n        x = self.linear_relu_stack(x)\n        return x  \n\ndef try_gpu(i=0): \n    return f'cuda:{i}' if torch.cuda.device_count() >= i + 1 else 'cpu'\n\n# Set model configurations\nmlp = NeuralNetClassifier(\n    MLP(num_inputs=X_train.shape[1], num_outputs=len(np.unique(y_train))),\n    optimizer=torch.optim.Adam,\n    criterion=nn.CrossEntropyLoss(),\n    iterator_train__shuffle=True,\n    device=try_gpu(),\n    verbose=0,\n    callbacks=[EarlyStopping(monitor='valid_loss', patience=5,\n                             threshold=1e-4, lower_is_better=True),\n               Checkpoint(monitor='valid_loss_best')]\n                          )\n\n# Define a search space\nparameters = {\n    'lr': list(np.geomspace(1e-4, 1e-1, 4)),\n    'module__layer1': [128, 256, 512],\n    'module__layer2': [128, 256, 512],\n    'module__dropout1': [0, 0.1],\n    'module__dropout2': [0, 0.1],\n    'optimizer__weight_decay': list(np.append(0, np.geomspace(1e-5, 1e-3, 3))),\n    'max_epochs': [1000],\n    'batch_size': [32, 128],\n    'callbacks__EarlyStopping__threshold': list(np.geomspace(1e-4, 1e-2, 3))\n    }\n\ndef use_gpu(device):\n    return True if not device == 'cpu' else False \n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    mlp,\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=10,\n    n_jobs=-1,\n    scoring=['neg_log_loss', 'accuracy'],\n    cv=5,\n    refit='accuracy',\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n# Run hyper parameter tuning\nX = X_train \ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'mlp'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'log_loss'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[5:10]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\ntune_result_df.rename({\n    'callbacks__EarlyStopping__threshold':'Earlystoping_threshold',\n    'optimizer__weight_decay': 'weight_decay'\n    }, axis=1, inplace=True)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_accuracy')\nfig.show()","metadata":{"id":"1CCNhjAwPGK-","outputId":"d82cf30d-7937-4c67-c937-5dc61181abaa","execution":{"iopub.status.busy":"2022-03-12T04:40:56.511774Z","iopub.execute_input":"2022-03-12T04:40:56.51203Z","iopub.status.idle":"2022-03-12T04:52:35.996116Z","shell.execute_reply.started":"2022-03-12T04:40:56.511997Z","shell.execute_reply":"2022-03-12T04:52:35.995153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Factorization Machine\n\n[Factorization Machines](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694074&casa_token=WNncod4Fzy0AAAAA:06BUH6Q3Mh-HhboU-WV9p4h5AykMCWcYedWlcFDLtNw4tIkNWZg9oadIz32UuMx9rFDyqOTGY1w&tag=1), proposed by Steffen Rendle in 2010, is a supervised algorithm that can be used for classification, regression, and ranking tasks. \nIt quickly took notice and became a popular and impactful method for making predictions and recommendations.\n\n\n#### >> Preprocessing Data for implementing Factorization Machine\n\nSince the factorization machine uses an embedding layer, it requires that the data type of all input variables be 'int'.\n\nTo take this into account, 'float' type variables are divided into several sections according to their values, and values ​​belonging to a specific section are transformed into interger values ​​of the section.","metadata":{"id":"J72KPFkkkL3J"}},{"cell_type":"code","source":"def prepro_for_fm(X_train, X_test, bin_method='sturges'):\n  n_train = X_train.shape[0]\n  all = np.vstack((X_train, X_test))\n\n  col_num_uniq = np.apply_along_axis(lambda x: len(np.unique(x)), 0,  all)\n  remain_iidx = (col_num_uniq<=2)\n  to_bin_iidx = (col_num_uniq>2)\n\n  all_remain = all[:,remain_iidx]\n  all_to_bin = all[:,to_bin_iidx]\n  \n  for iter in range(all_to_bin.shape[1]):\n    bin_size = len(np.histogram(all_to_bin[:,iter], bins=bin_method)[0])\n    all_to_bin[:,iter] = pd.cut(all_to_bin[:,iter], bins=bin_size, labels=False)\n\n  all_to_bin_df = pd.DataFrame(all_to_bin).astype('object')\n  all_to_bin_array = pd.get_dummies(all_to_bin_df, drop_first=False).to_numpy()\n\n  all_array = np.hstack((all_to_bin_array, all_remain)).astype(np.int64)\n  field_dims = all_array.shape[1]\n  all_fm = np.vstack((np.apply_along_axis(lambda x: np.where(x==1), 1, all_array)))\n\n  return all_fm[:n_train], all_fm[n_train:], field_dims\n\n\nX_train_fm, X_test_fm, field_dims = prepro_for_fm(X_train, X_test, bin_method='sturges')","metadata":{"id":"-OylMhdCj-Aw","execution":{"iopub.status.busy":"2022-03-12T04:52:35.998014Z","iopub.execute_input":"2022-03-12T04:52:35.998281Z","iopub.status.idle":"2022-03-12T04:52:48.847067Z","shell.execute_reply.started":"2022-03-12T04:52:35.998248Z","shell.execute_reply":"2022-03-12T04:52:48.84604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom skorch import NeuralNetClassifier\nfrom skorch.callbacks import EarlyStopping\nfrom skorch.callbacks import Checkpoint\nfrom tune_sklearn import TuneSearchCV\n\n# Define a model structure\nclass FM(nn.Module):\n    def __init__(self, num_inputs=field_dims, num_factors=20, output_dim=7):\n        super(FM, self).__init__()\n        self.output_dim = output_dim\n        for i in range(output_dim):\n          setattr(self, f'embedding_{i}', nn.Embedding(num_inputs, num_factors))\n        self.fc = nn.Embedding(num_inputs, output_dim)\n        self.bias = nn.Parameter(torch.zeros((output_dim,)))\n\n    def forward(self, x):\n        square_of_sum_list = []\n        sum_of_square_list = []\n        for i in range(self.output_dim):\n          square_of_sum_list.append(torch.sum(getattr(self, f'embedding_{i}')(x), dim=1)**2)\n          sum_of_square_list.append(torch.sum(getattr(self, f'embedding_{i}')(x)**2, dim=1))\n        square_of_sum = torch.stack(square_of_sum_list, dim=1)\n        sum_of_square = torch.stack(sum_of_square_list, dim=1)\n        x = self.bias + self.fc(x).sum(dim=1) + 0.5 * (square_of_sum - sum_of_square).sum(dim=2)\n        return x\n\ndef try_gpu(i=0): \n    return f'cuda:{i}' if torch.cuda.device_count() >= i + 1 else 'cpu'\n\n# Set model configurations\nfm = NeuralNetClassifier(\n    FM(num_inputs=field_dims, output_dim=len(np.unique(y_train_trans))),\n    optimizer=torch.optim.Adam,\n    criterion=nn.CrossEntropyLoss(),\n    iterator_train__shuffle=True,\n    device=try_gpu(),\n    verbose=0,\n    callbacks=[EarlyStopping(monitor='valid_loss', patience=5,\n                             threshold=1e-4, lower_is_better=True),\n               Checkpoint(monitor='valid_loss_best')]\n                          )\n\n# Define a search space\nparameters = {\n    'lr': list(np.geomspace(1e-4, 1e-2, 3)),\n    'module__num_factors': [50, 100, 150],\n    'optimizer__weight_decay': [1e-5, 1e-4, 1e-1],\n    'max_epochs': [1000],\n    'batch_size': [16, 32]\n    }\n\ndef use_gpu(device):\n    return True if not device == 'cpu' else False \n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    fm, \n    parameters, \n    search_optimization='hyperopt',\n    n_trials=10,\n    n_jobs=-1,\n    scoring=['neg_log_loss', 'accuracy'],\n    cv=5,\n    refit='accuracy',\n    mode='max',   \n    use_gpu = use_gpu(try_gpu()),\n    random_state=config['random_state'],\n    verbose=1,\n    )\n\n# Run hyper parameter tuning\nX = X_train_fm\ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'fm'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'log_loss'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[5:10]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\ntune_result_df.rename({\n    'callbacks__EarlyStopping__threshold':'Earlystoping_threshold',\n    'optimizer__weight_decay': 'weight_decay'\n    }, axis=1, inplace=True)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_accuracy')\nfig.show()","metadata":{"id":"1CKvuBazj6pD","outputId":"dcef9e3a-2edb-4332-e340-b9417ee1f37b","execution":{"iopub.status.busy":"2022-03-12T04:52:48.849031Z","iopub.execute_input":"2022-03-12T04:52:48.84929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-2. Model Comparison based on CV results\n\nCompare the CV results (measured using the best hyper parameter values) \\\\\nThe figure below shows that \\\\\nrf > xgb >> fm > mlp >> linear > svm\n\n","metadata":{"id":"v4BlrQ6XK0ol"}},{"cell_type":"code","source":"fig = px.box(best_cv_df, x='model', y='accuracy', color='model', width=600)\nfig.show()","metadata":{"id":"r0-GxErzmJ0T","outputId":"1cc847f4-101a-46c0-9b20-d3db8416efdb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-3. Model Combination\n\nAlthough it is possible to select a final model based on the above results, it has been observed that in many cases the combination of predicted values ​​from multiple models leads to improve prediction performance. ([Can multi-model combination really enhance the prediction skill of probabilistic ensemble forecasts?](https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.210?casa_token=OwyF2RbEywAAAAAA:gahpwGRdOWzLXyafYQQt_voHOF8MedTBLd1SBv4vkdT3ZTLVoKZQj3zl-KbrhSkX5x8CndeCxwBoL_-S))\n\nFor classification problems, the final probabilities are derived by combining the predicted 'probabilities' for each class in a 'proper way'.\n\nThis notebook uses following two model combination methods.\n\n1. Simple Average\n2. Stacked Generalization (Stacking)\n\n\nModel comparison needs to be done with single models (e.g., rf, xgb,...).\nSo model performance are measured by applying the same CV method as above.\n\nBased on the CV results, we select (rf, xgb, mlp) as the base estimators for model combination. (Although fm performs slightly better than mlp in terms of CV results, mlp was chosen because mlp has a shorter learning time.","metadata":{"id":"4n8Ah9ahKDDZ"}},{"cell_type":"markdown","source":"### > Simple Average\n\nThe simple average method derives the final probability value by 'averaging' the predicted probability values ​​for each class of multiple models.\n\nFor example,\n- Base Estimations\n  - $P_{rf}(Y=1|X=x)$ = 0.75\n  - $P_{xgb}(Y=1|X=x)$ = 0.80\n  - $P_{mlp}(Y=1|X=x)$ = 0.80\n- Final Estimation\n  - $P_{average}(Y=1|X=x)$  = 0.8 (= 0.75 + 0.80 + 0.85 + 0.80 / 4)\n","metadata":{"id":"Sf4wsWU4EHW-"}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom tqdm import notebook\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\ndef CV_ensemble(ensemble_name, ensemble_func, estimators, X_train, y_train, n_folds=5, shuffle=True, random_state=2022):\n  kf = KFold(n_splits=5, random_state=random_state, shuffle=True)\n\n  res_list = []\n  for train_idx, valid_idx in notebook.tqdm(kf.split(X_train), total=kf.get_n_splits(), desc='Eval_CV'):\n    X_train_train, X_valid = X_train[train_idx], X_train[valid_idx]\n    y_train_train, y_valid = y_train[train_idx], y_train[valid_idx]\n\n    ensemble_pred_proba = ensemble_func(estimators, X_train_train, y_train_train, X_valid)\n    neg_log_loss = np.negative(log_loss(y_valid, ensemble_pred_proba))\n    accuracy = accuracy_score(y_valid, ensemble_pred_proba.argmax(axis=1))\n\n    res_list.append([ensemble_name, neg_log_loss, accuracy])\n  res_df = pd.DataFrame(np.vstack((res_list)))\n  res_df.columns = ['model', 'log_loss', 'accuracy']\n  return res_df\n\ndef ensemble_average(estimators, X_train, y_train, X_test):\n  preds = []\n  num_estimators = len(estimators)\n  num_class = len(np.unique(y_train))\n  for iter in range(num_estimators):\n    try:\n      estimators[iter].module__num_factors\n    except: # for other models\n      estimators[iter].fit(X_train, y_train)\n      preds.append(estimators[iter].predict_proba(X_test))\n    else: # for factorization machine\n      X_train_fm, X_test_fm, _ = prepro_for_fm(X_train, X_test)\n      estimators[iter].fit(X_train_fm, y_train)\n      preds.append(estimators[iter].predict_proba(X_test_fm))\n  \n  preds_stack = np.hstack((preds))\n  preds_mean = []\n  for iter in range(num_class):\n    col_idx = np.arange(iter, num_estimators * num_class, num_class)\n    preds_mean.append(np.mean(preds_stack[:,col_idx], axis=1))\n\n  return np.vstack((preds_mean)).transpose()","metadata":{"id":"BJ6YHo9Bfl2Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nlinear = SGDClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='linear', 'best_hyper_param'].values[0]))\nsvm = SGDClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='svm', 'best_hyper_param'].values[0]))\nrf = RandomForestClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='rf', 'best_hyper_param'].values[0]))\nxgb = XGBClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='xgb', 'best_hyper_param'].values[0]))\nmlp = mlp.set_params(**eval(best_cv_df.loc[best_cv_df['model']=='mlp', 'best_hyper_param'].values[0]))\nfm = fm.set_params(**eval(best_cv_df.loc[best_cv_df['model']=='fm', 'best_hyper_param'].values[0]))\n\nestimators = [rf, xgb, mlp]\nestimators_name = 'rf_xgb_mlp'\nensemble_name = 'average' + '_by_' + estimators_name\n\nX = X_train\ny = y_train_trans\n\nres_df = CV_ensemble(ensemble_name, ensemble_average, estimators, X, y, n_folds=5, shuffle=True, random_state=config['random_state'])\nbest_cv_df = best_cv_df.append(res_df).reset_index(drop=True)","metadata":{"id":"JEDSzMQTX48i","outputId":"044de500-3e54-4141-b636-125ffc7cf04f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.box(best_cv_df, x='model', y='accuracy', color='model', width=800)\nfig.show()","metadata":{"id":"-UHM0yHIk7Q7","outputId":"23a2d37d-0bcb-4cd0-9f59-5390a9d4ce59","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Stacked generalization (Stacking)\n\nIn the [Stacked generalization](https://www.jair.org/index.php/jair/article/view/10228), the predicted probabilities of base estimators are treated as the 'input data', and y (Cover_Type) of each row is treated as the 'output variable'. \nThe 'Meta Learner' is learned with these data and the predicted probablities of this model are derived as the final prediction probabilities.\n\n- The 'Meta Learner' can be optained among any of the classification models. However, this notebook uses a ridge model (logistic regression with ridge penalty) to prevent overfitting.\n\n- As input data for 'Meta Learner', prediction probabilities for validation data in cv of base estimators are obtained.\n\n- Trained meta-learner predicts the final predicted probabilities for the test-set by using the predicted probabilites of baes estimators for the test-set as input data.\n\nThe total process, in order, is as follows:\n1. (Base estimators) Run CV on Train-set\n2. (Meta Learner) Train on CV predictions (predicted probabilities on validation data of CV) with corresponding y values\n3. (Base estimators) Train on Train-set\n4. (Base estimators) Predict on Test-set\n5. (Meta Learner) Predict on predictions on Test-set\n\n<img align='top' src='https://drive.google.com/uc?export=view&id=1uDxSIIFt8rUJkuIwRYU4lALvOPqlXPG5' width='600' height='400'>\n\n\nFor example,\n- Assume that \n  - $Y \\in \\{0, 1, 2\\}$\n- Base Estimatiors\n  - rf\n    - $P_{rf}(Y=0|X=x)$ = 0.75\n    - $P_{rf}(Y=1|X=x)$ = 0.10\n    - $P_{rf}(Y=2|X=x)$ = 0.15\n  - xgb\n    - $P_{xgb}(Y=0|X=x)$ = 0.80\n    - $P_{xgb}(Y=1|X=x)$ = 0.10\n    - $P_{xgb}(Y=2|X=x)$ = 0.10\n- Meta Learner (logistic regression with ridge (l2) penalty)\n  - when Y=0:\n    - intercept = 0.1\n    - coefficient = [0.8, 0.1, -0.1, 0.9, 0.2, -0.05]\n  - predicted probabilities\n    - $P_{stack}(Y=0|X=x)$ = 0.8069 = sigmoid(0.1 + 0.8*0.75 + 0.1*0.1 -0.1*0.15 + 0.9*0.8 + 0.2*0.1 - 0.05*0.1)$\n\n\n**Warnings**:\n\n- the set of predicted probabilities $[P_{rf}(Y=1|X=x), \\cdots, P_{xgb}(Y=2|X=x)]$ is a **linearly dependent** matrix.\n- Thus, as a final estimator, linear model with penalty or not a linear model is recommended.\n- If you want to apply plain linear model with no penalty, please remove the first or last class probabilities of each base estimators (e.g., remove $P_{rf}(Y=2|X=x)$ and $P_{xgb}(Y=2|X=x)$)\n\n\nThe code provided by sklearn exists ([StackingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html)), but this can not be applied to the skorch models.\n\nSo I provide below code which does the stacking operation.","metadata":{"id":"5eKbDaOmEPVc"}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom tqdm import notebook\n\n\ndef stack_clf(estimators, X_train, y_train, X_test, n_folds=5, shuffle=True, random_state=2022):\n  final_estimator = estimators[-1]\n  num_estimators = len(estimators)-1\n\n  kf = KFold(n_splits=n_folds, random_state=random_state, shuffle=shuffle)\n  preds = []\n  y_valid_list = []\n  for train_idx, valid_idx in notebook.tqdm(kf.split(X_train), total=kf.get_n_splits(), desc='Stack_CV'):\n    X_train_train, X_valid = X_train[train_idx], X_train[valid_idx]\n    y_train_train, y_valid = y_train[train_idx], y_train[valid_idx]\n    \n    valid_preds = []\n    for iter in range(num_estimators):\n      try:\n        estimators[iter].module__num_factors\n      except: # for other models\n        estimators[iter].fit(X_train_train, y_train_train)\n        valid_preds.append(estimators[iter].predict_proba(X_valid))\n      else: # for factorization machine\n        X_train_train_fm, X_valid_fm, _ = prepro_for_fm(X_train_train, X_valid)\n        estimators[iter].fit(X_train_train_fm, y_train_train)\n        valid_preds.append(estimators[iter].predict_proba(X_valid_fm))\n\n    preds.append(np.hstack((valid_preds))) # warning: this matrix is linearly dependent. If you want to ge linearly independent matrix, drop first column\n    y_valid_list.append(y_valid)\n\n  cv_preds = np.vstack((preds))\n  cv_y = np.hstack((y_valid_list))\n  \n  final_estimator.fit(cv_preds, cv_y)\n  print(' Train score: {}'.format(final_estimator.score(cv_preds, cv_y)))\n  print(' Estimated coefficients: {} \\n intercept: {}'.format(final_estimator.coef_, final_estimator.intercept_))\n\n  test_preds =[]\n  for iter in range(num_estimators):\n      try:\n        estimators[iter].module__num_factors\n      except: # for other models\n        estimators[iter].fit(X_train, y_train)\n        test_preds.append(estimators[iter].predict_proba(X_test))\n      else: # for factorization machine\n        X_train_fm, X_test_fm, _ = prepro_for_fm(X_train, X_test)\n        estimators[iter].fit(X_train_fm, y_train)\n        test_preds.append(estimators[iter].predict_proba(X_test_fm))\n\n  test_preds_mat = np.hstack((test_preds)) # warning: this matrix is linearly dependent. If you want to ge linearly independent matrix, drop first column\n  pred_fin = final_estimator.predict_proba(test_preds_mat)\n  return pred_fin","metadata":{"id":"ixki1gq_3Wwk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Base estimators\nlinear = SGDClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='linear', 'best_hyper_param'].values[0]))\nsvm = SGDClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='svm', 'best_hyper_param'].values[0]))\nrf = RandomForestClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='rf', 'best_hyper_param'].values[0]))\nxgb = XGBClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='xgb', 'best_hyper_param'].values[0]))\nmlp = mlp.set_params(**eval(best_cv_df.loc[best_cv_df['model']=='mlp', 'best_hyper_param'].values[0]))\nfm = fm.set_params(**eval(best_cv_df.loc[best_cv_df['model']=='fm', 'best_hyper_param'].values[0]))\n\nestimators = [rf, xgb, mlp]\nestimators_name = 'rf_xgb_mlp'\n\n# Final estimator\nclf = LogisticRegression(penalty='l2', max_iter=1000, random_state=config['random_state'])\n\nestimators.append(clf)\nensemble_func = stack_clf\nensemble_name = 'stack_ridge' + '_by_' + estimators_name\n\n# Run CV \nX = X_train\ny = y_train_trans\n\nres_df = CV_ensemble(ensemble_name, ensemble_func, estimators, X, y, n_folds=5, shuffle=True, random_state=config['random_state'])\nbest_cv_df = best_cv_df.append(res_df)","metadata":{"id":"c0h_Vp91oze7","outputId":"1ef98e4a-0a44-4021-c4f7-8744268111fa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-4. Model Comparison based on CV results including model combination methods\n\nFrom the figure below, we can observe that model combination methods outperform single models in terms of accuracy and its variance. \nIn 5-fold CV model combination methods shows much more stable performance.\n\nAs a result, 'stack_ridge_by_rf_xgb_mlp' model is chosen as the best model.","metadata":{"id":"TCB4E54B7DwA"}},{"cell_type":"code","source":"fig = px.box(best_cv_df, x='model', y='accuracy', color='model', width=800 )\nfig.show()","metadata":{"id":"kcjY4Mh-6c3I","outputId":"f4517af6-8c42-4a0e-aef4-d7d3fc023217","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_cv_df.to_csv('best_cv_results.csv', index=False)","metadata":{"id":"V9AgZesyMdAo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Make a prediction with the best model\n","metadata":{"id":"mqxwLjTU6jWq"}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Base estimators\nlinear = SGDClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='linear', 'best_hyper_param'].values[0]))\nsvm = SGDClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='svm', 'best_hyper_param'].values[0]))\nrf = RandomForestClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='rf', 'best_hyper_param'].values[0]))\nxgb = XGBClassifier(**eval(best_cv_df.loc[best_cv_df['model']=='xgb', 'best_hyper_param'].values[0]))\nmlp = mlp.set_params(**eval(best_cv_df.loc[best_cv_df['model']=='mlp', 'best_hyper_param'].values[0]))\nfm = fm.set_params(**eval(best_cv_df.loc[best_cv_df['model']=='fm', 'best_hyper_param'].values[0]))\n\nestimators = [rf, xgb, mlp]\nestimators_name = 'rf_xgb_mlp'\n\n# Final estimator\nclf = LogisticRegression(penalty='l2', max_iter=1000, random_state=config['random_state'])\n\nestimators.append(clf)\nensemble_func = stack_clf\nensemble_name = 'stack_ridge' + '_by_' + estimators_name\n\n# Run CV \nX = X_train\ny = y_train_trans\n\npred_proba = stack_clf(estimators, X, y,  X_test, n_folds=5, shuffle=True, random_state=config['random_state'])\npred = pred_proba.argmax(axis=1)\npred_trans = pred + 1\n\nres_df = pd.DataFrame({'Id': test['Id'], 'Cover_Type': pred_trans})\nres_df.to_csv('subission.csv', index=False)\nprint(ensemble_name)","metadata":{"id":"_fnE-46Q6ix1","outputId":"70f64aa5-b578-406e-9261-c465159ac3ba","trusted":true},"execution_count":null,"outputs":[]}]}