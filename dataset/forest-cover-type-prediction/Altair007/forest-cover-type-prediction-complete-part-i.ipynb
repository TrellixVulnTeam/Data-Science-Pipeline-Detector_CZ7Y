{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d86ac6e4-d4f7-abb5-db65-4e192715afd9"},"source":"## PART I (Being a newbie would love to have your suggestions on improving it)\nLink to PART II <https://www.kaggle.com/nitin007/forest-cover-type-prediction/forest-cover-type-prediction-complete-part-ii/>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"87d4f359-510c-fb86-eab9-a53e1df7a871"},"outputs":[],"source":"# Common libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Restrict minor warnings\nimport warnings\nwarnings.filterwarnings('ignore')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe1ed031-2129-ba67-c87d-18aeae0e07a5"},"outputs":[],"source":"# Import test and train data\ndf_train = pd.read_csv('../input/train.csv')\ndf_Test = pd.read_csv('../input/test.csv')\ndf_test = df_Test"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9cc30d5e-3f97-e960-5047-340c98023f9c"},"outputs":[],"source":"# First 5 data points\ndf_train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4ada6ac-a17a-cd8d-3a5c-5de355fce1ca"},"outputs":[],"source":"# Datatypes of the attributes\ndf_train.dtypes"},{"cell_type":"markdown","metadata":{"_cell_guid":"01675a33-828a-9fab-cb33-4ef1c65db196"},"source":"No categorical data. All are numerical"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0637d36-b0ee-3a59-c449-af2da49e8eb9"},"outputs":[],"source":"pd.set_option('display.max_columns', None) # we need to see all the columns\ndf_train.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"69630232-3913-c4b1-ecbf-7d9f744f3955"},"source":"## Inferences\n- Count is 15120 for each column, so no data point is missing.\n- Soil type 7 and 15 are constant(each value is zero), so they can be removed.\n- Wilderness_Area and Soil_Type are one hot encoded. Hence, they could be converted back for some analysis.\n- Scales are not the same for all. Hence, rescaling and standardisation may be necessary for some algos."},{"cell_type":"markdown","metadata":{"_cell_guid":"50a87854-6f54-6b8c-6934-55ffc772eb86"},"source":"## Removing Soil_type 7 & 15"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c8db535-2b3c-04ae-09fe-19c3ccbd9f7d"},"outputs":[],"source":"# From both train and test data\ndf_train = df_train.drop(['Soil_Type7', 'Soil_Type15'], axis = 1)\ndf_test = df_test.drop(['Soil_Type7', 'Soil_Type15'], axis = 1)\n\n# Also drop 'Id'\ndf_train = df_train.iloc[:,1:]\ndf_test = df_test.iloc[:,1:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"0d8ba39a-7e1a-438b-15f7-148169569731"},"source":"## Correlation matrix (heatmap)\nCorrelation requires continuous data. Hence, ignore Wilderness_Area and Soil_Type as they are binary values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"891d4c31-6075-e0c1-c9c4-934b34d020f9"},"outputs":[],"source":"size = 10\ncorrmat = df_train.iloc[:,:size].corr()\nf, ax = plt.subplots(figsize = (10,8))\nsns.heatmap(corrmat,vmax=0.8,square=True);"},{"cell_type":"markdown","metadata":{"_cell_guid":"5ddcd266-2898-5123-6d3a-3447ac2ebc34"},"source":"## Correlation values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e876b122-95ff-b590-771e-7ae0a9461301"},"outputs":[],"source":"data = df_train.iloc[:,:size]\n\n# Get name of the columns\ncols = data.columns\n\n# Calculate the pearson correlation coefficients for all combinations\ndata_corr = data.corr()\n\n# Threshold ( only highly correlated ones matter)\nthreshold = 0.5\ncorr_list = []"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cca29c7-7e3d-23e8-e003-2ce4ca8818be"},"outputs":[],"source":"data_corr"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84547fc3-16b9-eee6-27ef-0cca89dfcc11"},"outputs":[],"source":"# Sorting out the highly correlated values\nfor i in range(0, size):\n    for j in range(i+1, size):\n        if data_corr.iloc[i,j]>= threshold and data_corr.iloc[i,j]<1\\\n        or data_corr.iloc[i,j] <0 and data_corr.iloc[i,j]<=-threshold:\n            corr_list.append([data_corr.iloc[i,j],i,j])\n        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a518a84-4767-65fb-b929-a28364ede96c"},"outputs":[],"source":"# Sorting the values\ns_corr_list = sorted(corr_list,key= lambda x: -abs(x[0]))\n\n# print the higher values\nfor v,i,j in s_corr_list:\n    print(\"%s and %s = %.2f\" % (cols[i], cols[j], v))"},{"cell_type":"markdown","metadata":{"_cell_guid":"179356d5-60d7-456b-9f74-4055e22784b7"},"source":"## Skewness"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"527eabd0-1eec-d87f-57d2-8ef78aa6545c"},"outputs":[],"source":"df_train.iloc[:,:10].skew()"},{"cell_type":"markdown","metadata":{"_cell_guid":"c37b42c0-38be-fce8-6b51-1750d18e4abf"},"source":"Presence of skewness can easily be noticed"},{"cell_type":"markdown","metadata":{"_cell_guid":"9e6d1db4-7ca4-d8a5-ea3c-8f2cf953c2e0"},"source":"## Data Visualisation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d85e90e2-4749-7f84-3c2b-c52e20e4a9a6"},"outputs":[],"source":"# Pair wise scatter plot with hue being 'Cover_Type'\nfor v,i,j in s_corr_list:\n    sns.pairplot(data = df_train, hue='Cover_Type', size= 6, x_vars=cols[i], y_vars=cols[j])\n    plt.show()\n    "},{"cell_type":"markdown","metadata":{"_cell_guid":"7e7e91a2-a9b1-b6f1-7238-d36ca191b588"},"source":"- Horizontal and vertical distance to hydrology seems to have a linear relation\n- Hillside and Aspect seems to have a sigmoid relation given by: $$\\frac { 1 }{ 1\\quad +\\quad { e }^{ -x } } $$"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55299531-61a8-96a2-b68e-2844c0b0e085"},"outputs":[],"source":"# A violin plot is a hybrid of a box plot and a kernel density plot, which shows peaks in the data.\ncols = df_train.columns\nsize = len(cols) - 1 # We don't need the target attribute\n# x-axis has target attributes to distinguish between classes\nx = cols[size]\ny = cols[0:size]\n\nfor i in range(0, size):\n    sns.violinplot(data=df_train, x=x, y=y[i])\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"51dc7e86-fce3-d96e-b49b-3b3d9f5ec807"},"source":"- Elevation has a seperate distribution for each class, hence an important attribute for prediction\n- Aspect plot contains couple of normal distribution for several classes\n- Horizontal distance to hydrology and roadways is quite similar\n- Hillshade 9am and 12pm displays left skew (long tail towards left)\n- Wilderness_Area3 gives no class distinction. As values are not present, others give some scope to distinguish\n- Soil_Type, 1,5,8,9,12,14,18-22, 25-30 and 35-40 offer class distinction as values are not present for many classes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bbec4a77-651c-a09a-6f82-4a3a202b0df1"},"outputs":[],"source":"df_train.Wilderness_Area2.value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"3be0978d-9e17-d449-a6b7-6cbe9988e34c"},"source":"Too many zero values means attributes like it shows class distinction"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"140da0e7-2cbf-bace-fa3c-012eba5a4f26"},"outputs":[],"source":"### Group one-hot encoded variables of a category into one single variable\ncols = df_train.columns\nr,c = df_train.shape\n\n# Create a new dataframe with r rows, one column for each encoded category, and target in the end\nnew_data = pd.DataFrame(index= np.arange(0,r), columns=['Wilderness_Area', 'Soil_Type', 'Cover_Type'])\n\n# Make an entry in data for each r for category_id, target_value\nfor i in range(0,r):\n    p = 0;\n    q = 0;\n    # Category1_range\n    for j in range(10,14):\n        if (df_train.iloc[i,j] == 1):\n            p = j-9 # category_class\n            break\n    # Category2_range\n    for k in range(14,54):\n        if (df_train.iloc[i,k] == 1):\n            q = k-13 # category_class\n            break\n    # Make an entry in data for each r\n    new_data.iloc[i] = [p,q,df_train.iloc[i, c-1]]\n    \n# plot for category1\nsns.countplot(x = 'Wilderness_Area', hue = 'Cover_Type', data = new_data)\nplt.show()\n\n# Plot for category2\nplt.rc(\"figure\", figsize = (25,10))\nsns.countplot(x='Soil_Type', hue = 'Cover_Type', data= new_data)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b233403-41ee-85c4-2277-016d61a7670f"},"source":"- Wilderness_Area4 has lot of presence of cover_type 4, good class distinction\n- SoilType 1-6,9-13,15, 20-22, 27-31,35,36-38 offer lot of class distinction as counts for some are very high"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b3fa9db-6fe7-8164-ba53-671df9a60037"},"source":"## Data Preparation\n## Delete rows or impute values in case of missing\n## Check for data transformation\n## Some of the soil_types is present in very few Cover_Types"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31ba100a-d18d-41ae-db7b-0f12e12ee3f8"},"outputs":[],"source":"# Checking the value count for different soil_types\nfor i in range(10, df_train.shape[1]-1):\n    j = df_train.columns[i]\n    print (df_train[j].value_counts())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eaea3937-f2f1-5b2d-aafd-8ca5e2012b6f"},"outputs":[],"source":"# Let's drop them\ndf_train = df_train.drop(['Soil_Type8', 'Soil_Type25'], axis=1)\ndf_test = df_test.drop(['Soil_Type8', 'Soil_Type25'], axis=1)\ndf_train1 = df_train # To be used for algos like SVM where we need normalization and StandardScaler\ndf_test1 = df_test # To be used under normalization and StandardScaler"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b3042f4-06ad-369a-4b3e-3a3f47b73e06"},"source":"## Normality\n(Needed only for few ML algorithms like SVM)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6cf7c727-0d60-b2e2-6b65-3426d60709cc"},"outputs":[],"source":"# Checking for data transformation (take only non-categorical values)\ndf_train.iloc[:,:10].skew()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b95d2c51-238b-0ff8-ba89-11f2d008db47"},"source":"Data transformation needed in: 'Horizontal n vertical distance', 'Hillshade_9am & noon'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abd0aa2a-1e15-523b-8faa-0941f52a22c3"},"outputs":[],"source":"#Horizontal_Distance_To_Hydrology\nfrom scipy import stats\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Horizontal_Distance_To_Hydrology'], fit = stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Horizontal_Distance_To_Hydrology'], plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"13121d60-dde5-2d2e-1c98-598ee8ec0d2b"},"source":"It shows positive skewness (log or squared transformations will be a good option)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"733db818-5abb-34c9-f202-2e78f88d5646"},"outputs":[],"source":"df_train1['Horizontal_Distance_To_Hydrology'] = np.sqrt(df_train1['Horizontal_Distance_To_Hydrology'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb6b6154-0ea5-df81-c74f-b083ba194334"},"outputs":[],"source":"# Plot again after sqrt transformation\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Horizontal_Distance_To_Hydrology'], fit = stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Horizontal_Distance_To_Hydrology'], plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4cd80929-f3ec-6b38-8882-d53543aa9827"},"source":"I also performed log transformation but squared one gives better result"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a9019ff-04f0-f758-5c81-fa4bbd1439ae"},"outputs":[],"source":"#Vertical_Distance_To_Hydrology\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Vertical_Distance_To_Hydrology'], fit = stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Vertical_Distance_To_Hydrology'], plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"17f81c8f-d123-d2bd-2d5e-48dde817bf9b"},"source":"Shows positive skewness"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"080f8e3a-f377-6b21-a17c-80dc14b4e8d8"},"outputs":[],"source":"#Horizontal_Distance_To_Roadways\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Horizontal_Distance_To_Roadways'], fit=stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Horizontal_Distance_To_Roadways'], plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"666a13a9-ce03-c664-6008-4eaaf258f2fd"},"source":"Shows positive skewness"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"032194a5-5ff5-38e3-5551-fc696e066871"},"outputs":[],"source":"df_train1['Horizontal_Distance_To_Roadways'] = np.sqrt(df_train1['Horizontal_Distance_To_Roadways'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a008ce4-76da-8858-595c-9e154c15f547"},"outputs":[],"source":"# Plot again after sqrt transformation\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Horizontal_Distance_To_Roadways'], fit = stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Horizontal_Distance_To_Roadways'], plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"dd4d05e6-81b4-8679-5aff-b400e529ebff"},"source":"Reasonable improvement noticed"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60ccff99-3ed0-38a8-7ec2-435c440a3f8e"},"outputs":[],"source":"#Hillshade_9am\nfig = plt.figure(figsize=(8,6))\nsns.distplot(df_train1['Hillshade_9am'],fit=stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Hillshade_9am'],plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"94df6024-81d8-7a29-e482-e78b388b5731"},"source":"Shows negative skewness"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba18e18d-ab82-73a4-a870-8dfdf93c5c05"},"outputs":[],"source":"df_train1['Hillshade_9am'] = np.square(df_train1['Hillshade_9am'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"020b2693-ff10-32d7-ffeb-c1a8cf103653"},"outputs":[],"source":"# Plot again after square transformation\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Hillshade_9am'], fit = stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Hillshade_9am'], plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9fd314aa-b828-80a3-a17c-e774128679b6"},"source":"Reasonable improvement seen"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2415baf9-1b37-c894-4d1f-ac93b8589ef6"},"outputs":[],"source":"# Hillshade_Noon\nfig = plt.figure(figsize=(8,6))\nsns.distplot(df_train1['Hillshade_Noon'],fit=stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Hillshade_Noon'],plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"68314f39-a2c3-229d-cc48-557c229a20c1"},"source":"Negative skewness present"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0712f9b3-249a-b27d-532b-80121df6b069"},"outputs":[],"source":"df_train1['Hillshade_Noon'] = np.square(df_train1['Hillshade_Noon'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"485b404d-0125-ae2b-d153-fba6a3da6bde"},"outputs":[],"source":"# Plot again after square transformation\nfig = plt.figure(figsize=(8,6))\nsns.distplot(df_train1['Hillshade_Noon'],fit=stats.norm)\nfig = plt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Hillshade_Noon'],plot=plt)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fca75590-3b7b-c1a7-0c1c-07a2be5350c3"},"outputs":[],"source":"# Horizontal_Distance_To_Fire_Points\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Horizontal_Distance_To_Fire_Points'], fit=stats.norm)\nplt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Horizontal_Distance_To_Fire_Points'],plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"614cf59f-6078-0d24-e7dd-8c72db934783"},"source":"Shows positive skewness"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e2619a35-70c3-58e8-797f-81a22e92556b"},"outputs":[],"source":"df_train1['Horizontal_Distance_To_Fire_Points'] = np.sqrt(df_train1['Horizontal_Distance_To_Fire_Points'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c084cea9-59a4-50b2-db72-a77f5db0d129"},"outputs":[],"source":"# Plot again after sqrt transformation\nplt.figure(figsize=(8,6))\nsns.distplot(df_train1['Horizontal_Distance_To_Fire_Points'], fit=stats.norm)\nplt.figure(figsize=(8,6))\nres = stats.probplot(df_train1['Horizontal_Distance_To_Fire_Points'],plot=plt)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ec185ce6-a88c-eacf-4cac-4174e6a9077f"},"source":"Improvement clearly visible"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95bee30f-19ff-7520-c1be-19848ec970a9"},"outputs":[],"source":"# To be used in case of algorithms like SVM\ndf_test1[['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Fire_Points'\\\n        ,'Horizontal_Distance_To_Roadways']] = np.sqrt(df_test1[['Horizontal_Distance_To_Hydrology',\\\n        'Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Roadways']])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c2ff032-b55b-1d0d-b2ee-18ae04e6a46e"},"outputs":[],"source":"# To be used in case of algorithms like SVM\ndf_test1[['Hillshade_9am','Hillshade_Noon']] = np.square(df_test1[['Hillshade_9am','Hillshade_Noon']])"},{"cell_type":"markdown","metadata":{"_cell_guid":"d416d7ee-5fc2-6dc5-362d-b319c0366cda"},"source":"## Train & Test Data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8ced7b2d-c3a9-7726-0625-8d37563fc480"},"outputs":[],"source":"from sklearn.preprocessing import StandardScaler"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cff0d233-82c7-b0b9-62f6-8e990095d7c6"},"outputs":[],"source":"# Taking only non-categorical values\nSize = 10\nX_temp = df_train.iloc[:,:Size]\nX_test_temp = df_test.iloc[:,:Size]\nX_temp1 = df_train1.iloc[:,:Size]\nX_test_temp1 = df_test1.iloc[:,:Size]\n\nX_temp1 = StandardScaler().fit_transform(X_temp1)\nX_test_temp1 = StandardScaler().fit_transform(X_test_temp1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf133b40-46b8-f74a-5fd3-8dc9871d7818"},"outputs":[],"source":"r,c = df_train.shape\nX_train = np.concatenate((X_temp,df_train.iloc[:,Size:c-1]),axis=1)\nX_train1 = np.concatenate((X_temp1, df_train1.iloc[:,Size:c-1]), axis=1) # to be used for SVM\ny_train = df_train.Cover_Type.values"},{"cell_type":"markdown","metadata":{"_cell_guid":"132a98c0-d9db-2fbe-cb4e-2c9c564a5234"},"source":"## ML algorithms"},{"cell_type":"markdown","metadata":{"_cell_guid":"c05900bd-a46a-9651-bd96-50ac574cd90f"},"source":"## Support vector Machines"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa353025-fe67-1119-02e9-cc2ee7c50e9a"},"outputs":[],"source":"from sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.grid_search import GridSearchCV, RandomizedSearchCV"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44f97fe6-efde-26eb-a55f-a867fbf85ea7"},"outputs":[],"source":"# Setting parameters\nx_data, x_test_data, y_data, y_test_data = train_test_split(X_train1,y_train,test_size=0.2, random_state=123)\nsvm_para = [{'kernel':['rbf'],'C': [1,10,100,100]}]"},{"cell_type":"markdown","metadata":{"_cell_guid":"229627ef-6073-97ca-dfd3-6cbacb86a8ed"},"source":"'rbf' or radial basis function is the Gaussian kernel"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91c82eb3-26ee-de86-1bdc-973ebbc2b675"},"outputs":[],"source":"#classifier = GridSearchCV(svm.SVC(),svm_para,cv=3,verbose=2)\n#classifier.fit(x_data,y_data)\n#classifier.best_params_\n#classifier.grid_scores_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e71ede37-eaa6-e420-171b-14f8399b2c23"},"outputs":[],"source":"# Parameters optimized using the code in above cell\nC_opt = 10 # reasonable option\nclf = svm.SVC(C=C_opt,kernel='rbf')\nclf.fit(X_train1,y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"001c4e60-b30e-2482-079e-dc014ffea4d8"},"outputs":[],"source":"clf.score(X_train1,y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0ea8815-6588-4553-c41c-9d98bedc8767"},"outputs":[],"source":"# y_pred = clf.predict(X_test1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"18532a60-a05f-d28f-5f91-cca3a9498ce0"},"source":"## ExtraTreesClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2209f0a7-d506-5c11-811d-2ed7ecd0b402"},"outputs":[],"source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import classification_report\n\n# setting parameters\nx_data, x_test_data, y_data, y_test_data = train_test_split(X_train,y_train,test_size= 0.3, random_state=0)\netc_para = [{'n_estimators':[20,30,100], 'max_depth':[5,10,15], 'max_features':[0.1,0.2,0.3]}] \n# Default number of features is sqrt(n)\n# Default number of min_samples_leaf is 1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4269f6ca-b5af-2b93-ddb4-060385ad4138"},"outputs":[],"source":"ETC = GridSearchCV(ExtraTreesClassifier(),param_grid=etc_para, cv=10, n_jobs=-1)\nETC.fit(x_data, y_data)\nETC.best_params_\nETC.grid_scores_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea09c6af-76de-373c-81f9-dd6b118dbfcd"},"outputs":[],"source":"print ('Best accuracy obtained: {}'.format(ETC.best_score_))\nprint ('Parameters:')\nfor key, value in ETC.best_params_.items():\n    print('\\t{}:{}'.format(key,value))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60a38979-e138-1dd1-4017-c9e467ffed58"},"outputs":[],"source":"# Classification Report\nY_pred = ETC.predict(x_test_data)\ntarget = ['class1', 'class2','class3','class4','class5','class6','class7' ]\nprint (classification_report(y_test_data, Y_pred, target_names=target))"},{"cell_type":"markdown","metadata":{"_cell_guid":"4f58bc5b-f645-1669-8842-3e52ce15d736"},"source":"It shows Cover_Type 1 and 2 are difficult to predict"},{"cell_type":"markdown","metadata":{"_cell_guid":"e2b41fc8-b396-884e-3f24-6a90fc76e22b"},"source":"## Learning Curve\nExtraTreesClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e31f199-c553-45fb-dd5e-bf6c874b8454"},"outputs":[],"source":"from sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\ndef plot_learning_curve(model,title, X, y,n_jobs = 1, ylim = None, cv = None,train_sizes = np.linspace(0.1, 1, 5)):\n    \n    # Figrue parameters\n    plt.figure(figsize=(10,8))\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel('Training Examples')\n    plt.ylabel('Score')\n    \n    train_sizes, train_score, test_score = learning_curve(model, X, y, cv = cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    \n    # Calculate mean and std\n    train_score_mean = np.mean(train_score, axis=1)\n    train_score_std = np.std(train_score, axis=1)\n    test_score_mean = np.mean(test_score, axis=1)\n    test_score_std = np.std(test_score, axis=1)\n    \n    plt.grid()\n    plt.fill_between(train_sizes, train_score_mean - train_score_std, train_score_mean + train_score_std,\\\n                    alpha = 0.1, color = 'r')\n    plt.fill_between(train_sizes, test_score_mean - test_score_std, test_score_mean + test_score_std,\\\n                    alpha = 0.1, color = 'g')\n    \n    plt.plot(train_sizes, train_score_mean, 'o-', color=\"r\", label=\"Training score\")\n    plt.plot(train_sizes, test_score_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n    \n    plt.legend(loc = \"best\")\n    return plt"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a7eeaa7-9b13-757a-22bb-07931f90cbd0"},"outputs":[],"source":"# 'max_features': 0.3, 'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf: 1'\netc = ExtraTreesClassifier(bootstrap=True, oob_score=True, n_estimators=100, max_depth=10, max_features=0.3, \\\n                           min_samples_leaf=1)\n\netc.fit(X_train, y_train)\n# yy_pred = etc.predict(X_test)\netc.score(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2720362d-885a-ec26-2a99-ec5a388298a8"},"outputs":[],"source":"# Plotting learning curve\ntitle = 'Learning Curve (ExtraTreeClassifier)'\n# cross validation with 50 iterations to have a smoother curve\ncv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\nmodel = etc\nplot_learning_curve(model,title,X_train, y_train, n_jobs=-1,ylim=None,cv=cv)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"54ccbdf1-65c9-73d2-be03-2a1514e7d66d"},"source":"##PART II\n<https://www.kaggle.com/nitin007/forest-cover-type-prediction/forest-cover-type-prediction-complete-part-ii/> "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}