{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"0d72d46a-96ff-6f85-59e7-c73a7d284339"},"source":"## Contents\n+ Objective: Use cartographic variables to classify forest categories\n+ Loading, preparing, and exploring the data\n+ k-Nearest Neighbors (kNN)\n+ Naive Bayes (NB)\n+ Decision Trees\n+ Random Forests\n+ Extra Trees Classifier\n+ AdaBoost\n+ Gradient Boosting Classifier\n+ Support Vector Machines\n+ Logistic Regression\n+ Stochastic Gradient Descent (SGD)\n+ Gaussian Mixture Model\n+ Ensemble\n+ Results\n+ Annex 1: Plotting the training dataset\n+ Annex 2: Feature analysis"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2480f446-91ad-ec31-d00c-b0e3a11d6108"},"outputs":[],"source":"# This tells matplotlib not to try opening a new window for each plot.\n%matplotlib inline\n\n# General libraries.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# SK-learn libraries for learning.\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import ensemble\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.grid_search import RandomizedSearchCV\nfrom sklearn.mixture import GMM\nfrom sklearn import linear_model\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# SK-learn libraries for evaluation.\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\n# SK-learn libraries for feature preprocessing.\nfrom sklearn import preprocessing\n\n# SK-learn libraries for dimensionality reduction.\nfrom sklearn.decomposition import PCA\n\n# Data analysis and plotting \nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac7689a1-3ca0-0168-6bb0-36be222c14a5"},"outputs":[],"source":"Next we load the training and test data sets."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2894350-2945-e01f-b99b-c9a45524e782"},"outputs":[],"source":"ff = \"../input/train.csv\"\nf = open(ff)\ncolumn_names = f.readline()\n\ndata = np.loadtxt(f, delimiter=\",\")\n\ny, X = data[:, -1].astype('u1'), data[:, :-1]\n\nff_test = \"../input/test.csv\" # you will need to edit this directory\nf_test = open(ff_test)\ncolumn_names_test = f_test.readline() # you'd needs this ordinarily\n\ndata_test = np.loadtxt(f_test, delimiter=\",\")\n\n# note there are no labels here!\nX_test = data_test\n\nprint('The test dataset contains {0} observations with {1} features each.'.\\\n    format(X_test.shape[0], X_test.shape[1]))\nprint('\\t(The 1st one is not really a feature but an observation ID.)')\nprint('The training dataset contains {0} observations with the same {1} features each.'.\\\n    format(X.shape[0], X.shape[1]))\nprint('For this training set we know the corresponding category (forest cover type) of the ' \\\n      '{0} observations.'.format(y.shape[0]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99aaf8d1-af27-bd3c-d518-61e1fddfdc59"},"outputs":[],"source":"Let's take a look at the distribution of values, for the continuous features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9c65a59-b2f9-c2f0-401f-4b911eec0b19"},"outputs":[],"source":"Train_panda = pd.read_csv('../input/train.csv')\nTrain_panda.ix[:,1:11].hist(figsize=(16,12),bins=50)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b950f68-a531-9c61-bf77-ddaac128f08e"},"outputs":[],"source":"Test_panda = pd.read_csv('../input/test.csv')\nTest_panda.ix[:,1:11].hist(figsize=(16,12),bins=50)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b95b2a15-ae00-3615-30eb-f5839a7c7002"},"source":"The histograms of each feature, for both the training and test sets, look quite similar (with the exception of Elevation and Slope). We noticed that the histogram of Hillshade_3pm contains several 0's, especially in the training set, which might make us think of missing values coded with 0, but according to the dataset description that feature can take this value, so we shall accept those values as valid. There may be due to measurement error or rounding (in the same way that the histogram of Hillshade_9am for the training set contains more 255's than the distribution suggests), but in the absence of more information, we can't substitute those 0's by some other value like the median or the mean.\n\n(We did that, anyway (substitute 0's by the median, as seen below), and the accuracy for the dev set increased slightly (by about 0.5%) in most of the models that we tried.)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27fac90f-6ca6-f57a-167e-d5aef30fe9b0"},"outputs":[],"source":"# X[:,9] = np.where(X[:,9]==0, np.median(X[X[:,9]!=0,9]), X[:,9])\n# X_test[:,9] = np.where(X_test[:,9]==0, np.median(X_test[X_test[:,9]!=0,9]), X_test[:,9])"},{"cell_type":"markdown","metadata":{"_cell_guid":"c66ba813-74dd-8a54-60bc-2bcdca49c9e8"},"source":"To evaluate our performance, we'll split the training set into 2 subsets: training data (90%) plus development (aka validation) data (10%). Test data must not be used to validate our models, otherwise we might introduce bias: the more times we look at the error rate on the test set, the more we know about the test data, and the more we include our knowledge (that's very specific to that test data set) in the way we solve the problem.\n\nNonetheless, in most cases we used cross-validation in many cases, to assess how the results of one model generalize to another data set: with this model validation technique, the training data are partitioned into complementary subsets, multiple rounds of cross-validation are performed using different partitions, and the results are averaged.\n\nWe also discard the 1st variable (ID), which does not provide any information about the forest cover type."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e246f29a-78ab-781d-cae1-1646de0c65d9"},"outputs":[],"source":"# Shuffle the data, but make sure that the features and accompanying labels stay in sync.\nnp.random.seed(0)\nshuffle = np.random.permutation(np.arange(X.shape[0]))\nX, y = X[shuffle], y[shuffle]\n\n# Split into train (90%) and dev (10%)\ntrain_size = int(X.shape[0] * 0.9)\n# Also discard 1st feature (ID number that doesn't provide info about the label)\ny_train, X_train = y[:train_size], X[:train_size, 1:]\ny_dev, X_dev = y[train_size:], X[train_size:, 1:]\nX_test = X_test[:, 1:]\nprint(X_dev.shape, X_train.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a03fd55-067d-d84c-9410-37eee94d82d6"},"outputs":[],"source":"As previously mentioned, the first 10 features of each observation (Elevation to Horizontal_Distance_To_Fire_Points) are continuous, with different ranges, while the remaining 44 are all binary. 4 of those 44 binary features correspond to Wilderness Area (i.e., there are 4 possible types), so any observation will have one 1 and three 0's in those columns. The last 40 features correspond to Soil Type (i.e., there are 40 possible types), so any observation will have one 1 and thirty-nine 0's in those columns."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06ed795d-e935-7da3-a927-326fab10064e"},"outputs":[],"source":"prop_wilderness = 100*X_train[:,10:14].sum(axis=0)/X_train[:,10:14].sum()\nprop_soil = 100*X_train[:,14:54].sum(axis=0)/X_train[:,14:54].sum()\n\nplt.figure(figsize=(8, 4))\nplt.bar(np.arange(4), prop_wilderness, align=\"center\")\nplt.title(\"Percentage of Wilderness Area cases in the training dataset\")\nplt.xticks(np.arange(4), np.array([str(i) for i in np.arange(1,5)]))\n\nplt.figure(figsize=(12, 4))\nplt.bar(np.arange(40), prop_soil, align=\"center\")\nplt.title(\"Percentage of Soil Type cases in the training dataset\")\nplt.xticks(np.arange(40), np.array([str(i) for i in np.arange(1,41)]))\n\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"54eb2d74-119b-c953-6f1a-4fada3b5c82b"},"source":"The type of Wilderness Area is roughly uniformly distributed among the observations in the training set, with the exception of the 2nd type (only 3.3%).\n\nSoil Type is not uniformly distributed at all: many types are quite uncommon, while others account for up to 14.1% of the cases."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7dead86-cfb1-3e7d-e513-605751c764b8"},"outputs":[],"source":"prop_wilderness = 100*X_test[:,10:14].sum(axis=0)/X_test[:,10:14].sum()\nprop_soil = 100*X_test[:,14:54].sum(axis=0)/X_test[:,14:54].sum()\n\nplt.figure(figsize=(8, 4))\nplt.bar(np.arange(4), prop_wilderness, align=\"center\")\nplt.title(\"Percentage of Wilderness Area cases in the test dataset\")\nplt.xticks(np.arange(4), np.array([str(i) for i in np.arange(1,5)]))\n\nplt.figure(figsize=(12, 4))\nplt.bar(np.arange(40), prop_soil, align=\"center\")\nplt.title(\"Percentage of Soil Type cases in the test dataset\")\nplt.xticks(np.arange(40), np.array([str(i) for i in np.arange(1,41)]))\n\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"068b614a-f2f0-dcde-8a3b-d5a5875549e8"},"source":"\nThe distribution of the binary features differs quite much from the training to the test set.\n\nFor the 10 continuous features, we sometimes used preprocessing.StandardScaler (to standardize them by removing the mean and scaling to unit variance), as well as preprocessing.MinMaxScaler (to standardize them by scaling each feature to a given range; [0,1] in our case, to make it comparable to the binâ€‹ary features). That did not always improve the results, but scaled features are mandatory for some models.\n\nhttp://scikit-learn.org/stable/modules/preprocessing.html"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37c1ef6b-a7b1-85ec-66ab-ddddf571ab46"},"outputs":[],"source":"# Scale to range [0,1]\n    # Only the continuous features\nmin_max_scaler = preprocessing.MinMaxScaler()\nX_train_minmax = np.copy(X_train)\nX_dev_minmax = np.copy(X_dev)\nX_test_minmax = np.copy(X_test)\nX_train_minmax[:, :10] = min_max_scaler.fit_transform(X_train[:, :10])\nX_dev_minmax[:, :10]  = min_max_scaler.transform(X_dev[:, :10])\nX_test_minmax[:, :10] = min_max_scaler.transform(X_test[:, :10])\n\n# Scale to mean = 0, sd = 1\nstd_scaler = preprocessing.StandardScaler()\n# X_train_std = std_scaler.fit_transform(X_train)\n# X_dev_std = std_scaler.transform(X_dev)\n# X_test_std = std_scaler.transform(X_test)\n    # Only the continuous features\nX_train_std = np.copy(X_train)\nX_dev_std = np.copy(X_dev)\nX_test_std = np.copy(X_test)\nX_train_std[:, :10] = std_scaler.fit_transform(X_train[:, :10])\nX_dev_std[:, :10] = std_scaler.transform(X_dev[:, :10])\nX_test_std[:, :10] = std_scaler.transform(X_test[:, :10])"},{"cell_type":"markdown","metadata":{"_cell_guid":"2d313289-dfd0-5cc7-2dfc-4d72d709296d"},"source":"## k-Nearest Neighbors (kNN)\n\nBecause of the different nature of the 54 features (some continuous, some binary and mutually exclusive), we started creating our own distance metric that accounts for these differences to give similar weight to all the features. This new metric combined Euclidean and a variant of Hamming distance, and used the re-scaled version of the continuous variables, as explained in the code below.\n\nBut the results were slightly worse than using the standard Euclidean distance, and after several tests, we discovered that the 44 binary features do not add too much information about the Cover Type. Using that standard Euclidean distance with unscaled data, with all features or just the 10 continuous ones, yields the best results.\n\nThe code below just shows some of the results we found."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"42ad7f87-a447-59a3-9b28-1a79ab491521"},"outputs":[],"source":"# Create a mixed distance metric that accounts for the different characteristic of the features\n    # to give a similar weight to all of them\n# First 10 features are continuous. The square of differences is applied to the values scaled \n    # to [0,1] (maximum value of the sum = 10)\n# Last 44 features correspond to 2 features (wilderness area and soil type), with 4 and 40\n    # categories each. A variant of Hamming distance is applied to them, so the maximum value\n    # is 2 if two observations differ in both features\n# The total distance is the square of the sum of those 12 values, divided by the square of 12,\n    # so the maximum distance between any two observations will be 1\n# The ranges of the first 10 features may vary in the dev and test datasets, so the distances\n    # might be slightly greater than 1\ndef mixed_distance(x, y):\n    return np.sqrt(np.sum((x[:10]-y[:10])**2) + 0.5*np.sum(x[10:14]!=y[10:14]) +\n                          0.5*np.sum(x[14:54]!=y[14:54])) / np.sqrt(12)\n\nk = 1 # We also tried many other values of k\n# Try our own metric\nkNN_mixed = KNeighborsClassifier(n_neighbors=k, metric=mixed_distance)\nkNN_mixed.fit(X_train_minmax, y_train)\nprint(kNN_mixed.score(X_dev_minmax, y_dev))\n# Try euclidean distance with unscaled data\nkNN = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\nkNN.fit(X_train, y_train)\nprint(kNN.score(X_dev, y_dev))\n# Try euclidean distance with scaled data\nkNN = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\nkNN.fit(X_train, y_train)\nprint(kNN.score(X_dev, y_dev))\n# Try euclidean distance with unscaled data and only continuous features\nkNN.fit(X_train[:,:10], y_train)\nprint(kNN.score(X_dev[:,:10], y_dev))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a6387a8-f36a-5bed-28ee-e48ce656ba7a"},"outputs":[],"source":"# Estimate by cross-validation the optimal number of neighbors (k)\n# Try between 1 and the number of features (54)\nk = {'n_neighbors': np.concatenate([np.arange(1, X_train.shape[1]+1)]).tolist()}\n# The optimal value is low, so let's narrow the search from 1 to 11\nk = {'n_neighbors': np.concatenate([np.arange(1, 10+1)]).tolist()}\nbest_param_kNN = GridSearchCV(KNeighborsClassifier(), k, scoring='accuracy')\nbest_param_kNN.fit(X_train, y_train)\noptimal_k = best_param_kNN.best_params_['n_neighbors']\nprint('The optimal value for k is {0}'.format(optimal_k))\n\n# Plot results\nf1_vector = np.array([best_param_kNN.grid_scores_[x][1] for x in \n                      range(len(k['n_neighbors']))])\nplt.figure(figsize=(8, 8))\nplt.plot(k['n_neighbors'], f1_vector, marker='x')\nplt.axvline(x=optimal_k, linewidth=1, linestyle='--', color='red')\nplt.axhline(y=best_param_kNN.best_score_, linewidth=1, linestyle='--', color='red')\nplt.xlabel(\"k (Nearest Neighbors)\")\nplt.ylabel(\"F1 score\")\nplt.title('F1 score per value of k')\nplt.ylim([0, (np.ceil(best_param_kNN.best_score_*20)+1)/20])\nplt.xlim([0, len(k['n_neighbors'])+1])"},{"cell_type":"markdown","metadata":{"_cell_guid":"047fd23b-2512-37c1-b1c6-6edc9e844620"},"source":"How well does our first model perform on the development data?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c765624d-6662-ecab-11fc-3985cbcc6380"},"outputs":[],"source":"kNN = KNeighborsClassifier(n_neighbors=optimal_k)\n\nkNN.fit(X_train, y_train)\nprint('Accuracy using non-scaled data:      {0:.4f}'.\\\n    format(kNN.score(X_dev, y_dev)))\n\nkNN.fit(X_train_std, y_train)\nprint('Accuracy using standardized data:    {0:.4f}'.\\\n    format(kNN.score(X_dev_std, y_dev)))\n\nkNN.fit(X_train_minmax, y_train)\nprint('Accuracy using scaled-to-range data: {0:.4f}'.\\\n    format(kNN.score(X_dev_minmax, y_dev)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9c5e4ed-1022-4810-e8a4-17f125967fd1"},"outputs":[],"source":"The model performs better with non-scaled data (it could be argued that we searched for the optimal value for k using those data, but we did the same -out of this notebook- with standardized and scaled-to-range data).\nWhich are the cover types most commonly misclassified?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df5a16f9-7b08-3b8d-5c94-235f089023e6"},"outputs":[],"source":"kNN = KNeighborsClassifier(n_neighbors=optimal_k)\nkNN.fit(X_train[:, :10], y_train)\npredicted_y_dev = kNN.predict(X_dev[:, :10])\nprint(classification_report(y_dev, predicted_y_dev))\n# Confusion Matrix\nCM = metrics.confusion_matrix(y_dev, predicted_y_dev)\nCM_percentage = np.around(100*CM.astype('f2') / CM.sum(axis=1)[:, np.newaxis], 1)\n\n# plt.figure(figsize=(12, 12))\n# ax = plt.gca()\n# ax.axes.get_xaxis().set_visible(False)\n# ax.axes.get_yaxis().set_visible(False)\n# ax.axis('off')\n# table2 = plt.table(cellText=CM_percentage,rowLabels=np.arange(1,8),\n#                            colLabels=np.arange(1,8),loc='center')\n# plt.show()\n\n# Print a table with the confusion matrix (percentages of row, so each row correspond to the\n    # true cover type, and the diagonal values correspond to the Recall / 100\ncover_type = [c.rjust(5) for c in map(str, np.unique(y_dev))]\nprint(\"|    |{}|{}|{}|{}|{}|{}|{}|\".format(*cover_type))\nprint('------------------------------------------------')\ntable = []\nfor i,j in enumerate(np.unique(y_dev)):\n    table.append([j, CM_percentage[i,0], CM_percentage[i,1], CM_percentage[i,2],\n                  CM_percentage[i,3], CM_percentage[i,4], CM_percentage[i,5],\n                  CM_percentage[i,6]])\nfor i in table:\n    print(\"|{:4}|{:5.1f}|{:5.1f}|{:5.1f}|{:5.1f}|{:5.1f}|{:5.1f}|{:5.1f}|\".format(*i))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1189651-2e05-bff3-7bbc-c10ef0645a42"},"outputs":[],"source":"The cover types most typically misclassified are 1 and 2 (confused with each other).\n\nKeep record of the predictions in the dev set, as well as the accuracy, to ensemble all the models in a later step:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a0c45e8-8ea6-4762-6f29-7dc77d7382d2"},"outputs":[],"source":"kNN = KNeighborsClassifier(n_neighbors=optimal_k)\nkNN.fit(X_train, y_train)\npred_y_dev_kNN = kNN.predict(X_dev)\nacc_kNN = metrics.accuracy_score(y_dev, pred_y_dev_kNN)\nprint(acc_kNN)\n\nCM = metrics.confusion_matrix(y_dev, pred_y_dev_kNN)\nacc = CM.astype('f8') / CM.sum(axis=1)[:, np.newaxis]\nacc_kNN_perType = np.diag(acc)\nprint(acc_kNN_perType)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fa7d4f2-b216-803e-f517-914af6fba2b3"},"outputs":[],"source":"Predict the test set:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b5b444c-8efb-2524-80f9-140e8274487e"},"outputs":[],"source":"pred_y_test_kNN = kNN.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd50a3e7-fe93-737c-d0b4-c8b5d7c6afa8"},"outputs":[],"source":"## Naive Bayes (NB)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a3d655e-b5cb-4977-43bd-ae19bcf3ee2f"},"outputs":[],"source":"NB_model = GaussianNB()\nNB_model.fit(X_train_std[:,:10], y_train)\ndev_predicted_labels = NB_model.predict(X_dev_std[:,:10])\nprint(metrics.accuracy_score(y_true=y_dev, y_pred=dev_predicted_labels))\nprint(metrics.classification_report(y_dev, dev_predicted_labels))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a3fce90-b4e1-c025-6716-93700b81419f"},"outputs":[],"source":"Keep record of the predictions in the dev set, as well as the accuracy, to ensemble all the models in a later step:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c777f4b-f21c-7ba9-7b4c-dbb05a3e1043"},"outputs":[],"source":"NB = GaussianNB()\nNB.fit(X_train_std[:,:10], y_train)\npred_y_dev_NB = NB.predict(X_dev_std[:,:10])\nacc_NB = metrics.accuracy_score(y_dev, pred_y_dev_NB)\nprint(acc_NB)\n\nCM = metrics.confusion_matrix(y_dev, pred_y_dev_NB)\nacc = CM.astype('f8') / CM.sum(axis=1)[:, np.newaxis]\nacc_NB_perType = np.diag(acc)\nprint(acc_NB_perType)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec8bb6ec-9163-5cb1-7bb5-a0cc14e0ee67"},"outputs":[],"source":"Predict the test set:\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0f1e987-c971-6a54-463a-b5483264a33f"},"outputs":[],"source":"pred_y_test_NB = NB.predict(X_test_std[:,:10])"},{"cell_type":"markdown","metadata":{"_cell_guid":"e24bc900-592c-8be7-cd50-f6a77e777594"},"source":"## Decision Trees\n\nDecision Trees (DTs) are a non-parametric supervised learning method used for classification and regression.\n\nMotivation for using the decision trees for our dataset:\n+ The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.\n+ Able to handle both numerical and categorical data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce466010-bc58-bfd2-908c-40052dde309a"},"outputs":[],"source":"param_grid = {'criterion': ['gini', 'entropy'], 'max_features': [2, 5, 10, 20, 54], \n              'max_depth': [5, 10, 20, 25, 30, 40]}\nbest_param_DT = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring='accuracy')\nbest_param_DT.fit(X_train, y_train)\noptimal_criterion_DT = best_param_DT.best_params_['criterion']\nprint('The optimal criterion is {0}'.format(optimal_criterion_DT))\noptimal_max_features_DT = best_param_DT.best_params_['max_features']\nprint('The optimal maximum number of features is {0}'.format(optimal_max_features_DT))\noptimal_max_depth_DT = best_param_DT.best_params_['max_depth']\nprint('The optimal maximum depth of the tree is {0}'.format(optimal_max_depth_DT))\n\nDT = DecisionTreeClassifier(criterion=optimal_criterion_DT, max_features=optimal_max_features_DT, \n                            max_depth=optimal_max_depth_DT, random_state=0)\nDT.fit(X_train, y_train)\n\ny_dev_dec = DT.predict(X_dev)\nprint(metrics.classification_report(y_dev, y_dev_dec))\nprint(metrics.accuracy_score(y_dev, y_dev_dec))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1e8607f8-00fd-4cb8-8ccd-54c442d8c43c"},"source":"Keep record of the predictions in the dev set, as well as the accuracy, to ensemble all the models in a later step:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8584a6a0-42dc-45a6-e435-9883db62c18f"},"outputs":[],"source":"DT = DecisionTreeClassifier(criterion='entropy', max_features=54, \n                            max_depth=25, random_state=0)\nDT.fit(X_train, y_train)\npred_y_dev_DT = DT.predict(X_dev)\nacc_DT = metrics.accuracy_score(y_dev, pred_y_dev_DT)\nprint(acc_DT)\n\nCM = metrics.confusion_matrix(y_dev, pred_y_dev_DT)\nacc = CM.astype('f8') / CM.sum(axis=1)[:, np.newaxis]\nacc_DT_perType = np.diag(acc)\nprint(acc_DT_perType)"},{"cell_type":"markdown","metadata":{"_cell_guid":"067023ee-2981-99db-c8df-8958f3834b54"},"source":"Predict the test set:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73ac825d-0d30-c77b-0c3e-55d5e77b9de1"},"outputs":[],"source":"pred_y_test_DT = DT.predict(X_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6c05c322-bc94-37f4-e290-467c5fb87afa"},"source":"## Random Forests\n\nGiven how closely decision trees can fit themselves to their training data, they have a tendency to overfit. One way of avoiding this is a technique called random forests, in which we build multiple decision trees and let them vote on how to classify inputs:\n\n**Random forests** are ensembles of decision trees. Multiple decision trees are trained and aggregated to form a model that is more performant than any of the individual trees. This general idea is the purpose of ensemble learning."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"226e92d3-cf11-06b9-dae3-bb1a5da22dc5"},"outputs":[],"source":"# Train and predict with the random forest classifier\nparam_grid = {'criterion': ['gini', 'entropy'], 'n_estimators': [10, 50, 150], \n              'min_samples_split': [2, 4], 'max_features': [2, 5, 10, 20, 54], \n              'max_depth': [10, 20, 25, 30, 40]}\nbest_param_RF = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, scoring='accuracy')\nbest_param_RF.fit(X_train, y_train)\noptimal_criterion_RF = best_param_RF.best_params_['criterion']\nprint('The optimal criterion is {0}'.format(optimal_criterion_RF))\noptimal_n_estimators_RF = best_param_RF.best_params_['n_estimators']\nprint('The optimal number of trees in the forest is {0}'.format(optimal_n_estimators_RF))\noptimal_min_samples_split_RF = best_param_RF.best_params_['min_samples_split']\nprint('The optimal minimum number of samples required to split an internal node is {0}'.\\\n    format(optimal_min_samples_split_RF))\noptimal_max_features_RF = best_param_RF.best_params_['max_features']\nprint('The optimal maximum number of features is {0}'.format(optimal_max_features_RF))\noptimal_max_depth_RF = best_param_DT.best_params_['max_depth']\nprint('The optimal maximum depth of the tree is {0}'.format(optimal_max_depth_RF))\n\nRF = ensemble.RandomForestClassifier(criterion=optimal_criterion_RF, \n                                     n_estimators=optimal_n_estimators_RF, \n                                     min_samples_split=optimal_min_samples_split_RF, \n                                     max_features=optimal_max_features_RF, \n                                     max_depth=optimal_max_depth_RF, random_state=0)\nRF.fit(X_train,y_train)\ny_dev_RF = RF.predict(X_dev)\nprint(metrics.classification_report(y_dev, y_dev_RF))\nprint(metrics.accuracy_score(y_dev, y_dev_RF))"},{"cell_type":"markdown","metadata":{"_cell_guid":"b0c38cfe-7b03-916e-dbd3-849b0a83cb55"},"source":"Keep record of the predictions in the dev set, as well as the accuracy, to ensemble all the models in a later step:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c5ec246c-acee-aa1b-f146-3592bd4b2f1c"},"outputs":[],"source":"RF = ensemble.RandomForestClassifier(criterion='entropy', n_estimators=150, \n                                     min_samples_split=2, max_features=20, \n                                     max_depth=25, random_state=0)\nRF.fit(X_train,y_train)\npred_y_dev_RF = RF.predict(X_dev)\nacc_RF = metrics.accuracy_score(y_dev, pred_y_dev_RF)\nprint(acc_RF)\n\nCM = metrics.confusion_matrix(y_dev, pred_y_dev_RF)\nacc = CM.astype('f8') / CM.sum(axis=1)[:, np.newaxis]\nacc_RF_perType = np.diag(acc)\nprint(acc_RF_perType)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fba46b4b-f91a-450b-46c7-13aa4529656d"},"outputs":[],"source":"Predict the test set:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"421c3e2c-6f69-213e-183c-0f3f820f68fc"},"outputs":[],"source":"pred_y_test_RF = RF.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f9ead36-498b-1306-b2e0-4e31548976c7"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}