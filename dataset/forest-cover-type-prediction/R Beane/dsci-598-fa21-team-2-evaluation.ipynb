{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Final Model Evaluation Notebook\n\nThis notebook consists of an evaluation of our best model for the Forest Cover Type Prediction competition. Our best model is an Extra Trees model, which outperformed our ensemble. ","metadata":{}},{"cell_type":"markdown","source":"# Import Statements","metadata":{}},{"cell_type":"markdown","source":"First, we will import the necessary packages for data manipulation and analysis.","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd, matplotlib.pyplot as plt\nimport joblib\nimport sklearn \n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom keras.metrics import top_k_categorical_accuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.489181Z","iopub.execute_input":"2021-12-12T04:14:34.489577Z","iopub.status.idle":"2021-12-12T04:14:34.49656Z","shell.execute_reply.started":"2021-12-12T04:14:34.489538Z","shell.execute_reply":"2021-12-12T04:14:34.495589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ntrain = pd.read_csv('../input/forest-cover-type-prediction/train.csv')\n# view data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.541331Z","iopub.execute_input":"2021-12-12T04:14:34.542278Z","iopub.status.idle":"2021-12-12T04:14:34.618736Z","shell.execute_reply.started":"2021-12-12T04:14:34.542212Z","shell.execute_reply":"2021-12-12T04:14:34.617849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Next, we will preprocess the data to remove the ID column from the set, add new features from our feature engineering and PCA analysis, split the data into training and validation sets, and scale the data. ","metadata":{}},{"cell_type":"code","source":"# remove ID column from set\ntrain = train.iloc[:, 1:]\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.620309Z","iopub.execute_input":"2021-12-12T04:14:34.62055Z","iopub.status.idle":"2021-12-12T04:14:34.638777Z","shell.execute_reply.started":"2021-12-12T04:14:34.620522Z","shell.execute_reply":"2021-12-12T04:14:34.637978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add new features from feature engineering\ntrain['Elev_to_Horizontal_Hyd'] = train.Elevation - 0.2 * train.Horizontal_Distance_To_Hydrology \ntrain['Elev_to_Horizontal_Road'] = train.Elevation - 0.05 * train.Horizontal_Distance_To_Roadways  \ntrain['Elev_to_Verticle_Hyd'] = train.Elevation - train.Vertical_Distance_To_Hydrology \ntrain['Mean_Horizontal_Dist'] = (train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology + \n                                 train.Horizontal_Distance_To_Roadways)/3 \ntrain['Mean_Fire_Hydro'] = (train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology)/2","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.640113Z","iopub.execute_input":"2021-12-12T04:14:34.640367Z","iopub.status.idle":"2021-12-12T04:14:34.657159Z","shell.execute_reply.started":"2021-12-12T04:14:34.640338Z","shell.execute_reply":"2021-12-12T04:14:34.656415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# move target to first column\nfirst_column = train.pop('Cover_Type')\n  \n# insert column using insert(position,column_name,first_column) function\ntrain.insert(0, 'Cover_Type', first_column)\n  \n# view\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.658407Z","iopub.execute_input":"2021-12-12T04:14:34.658693Z","iopub.status.idle":"2021-12-12T04:14:34.92303Z","shell.execute_reply.started":"2021-12-12T04:14:34.658661Z","shell.execute_reply":"2021-12-12T04:14:34.922153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create cat, num, and y\nX_cat = train.iloc[:, 11:55].values\nB = train.iloc[:, 55:60]\nA = train.iloc[:, 1:11]\nX_num = pd.concat([A, B], axis = 1).values\ny = train.iloc[:, 0].values","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.925747Z","iopub.execute_input":"2021-12-12T04:14:34.92616Z","iopub.status.idle":"2021-12-12T04:14:34.939001Z","shell.execute_reply.started":"2021-12-12T04:14:34.926113Z","shell.execute_reply":"2021-12-12T04:14:34.938146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale/standardizing numerical columns\n# scaler object\nscaler = StandardScaler()\n# fit to training data\nscaler.fit(X_num)\n# scale num columns\nX_num = scaler.transform(X_num)\n\n# shape\nprint(f'Categorical Shape: {X_cat.shape}')\nprint(f'Numerical Shape: {X_num.shape}')\nprint(f'Label Shape: {y.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.940596Z","iopub.execute_input":"2021-12-12T04:14:34.9409Z","iopub.status.idle":"2021-12-12T04:14:34.954101Z","shell.execute_reply.started":"2021-12-12T04:14:34.940859Z","shell.execute_reply":"2021-12-12T04:14:34.953243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine num and cat\nX = np.hstack((X_num, X_cat))\nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.955187Z","iopub.execute_input":"2021-12-12T04:14:34.956636Z","iopub.status.idle":"2021-12-12T04:14:34.965053Z","shell.execute_reply.started":"2021-12-12T04:14:34.956586Z","shell.execute_reply":"2021-12-12T04:14:34.964222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train/validate split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = .20, random_state = 1)\nprint(X_train.shape)\nprint(X_valid.shape)\nprint(y_train.shape)\nprint(y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.966251Z","iopub.execute_input":"2021-12-12T04:14:34.967043Z","iopub.status.idle":"2021-12-12T04:14:34.982349Z","shell.execute_reply.started":"2021-12-12T04:14:34.967012Z","shell.execute_reply":"2021-12-12T04:14:34.98152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"markdown","source":"Below, we will load in the best model from our Training Model Notebook and fit it to the training set. Normally, we would not refit the model, but we are interested in exploring the strength of the model by splitting the training set into a training and validation set, so we need to refit it to the training portion of the data.","metadata":{}},{"cell_type":"code","source":"# load final model\nfinal_model = joblib.load('../input/dsci-598-fa21/Team_2/tree_model_final.joblib')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:34.9837Z","iopub.execute_input":"2021-12-12T04:14:34.983938Z","iopub.status.idle":"2021-12-12T04:14:37.208431Z","shell.execute_reply.started":"2021-12-12T04:14:34.983909Z","shell.execute_reply":"2021-12-12T04:14:37.207544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit model to training set \nfinal_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:37.211348Z","iopub.execute_input":"2021-12-12T04:14:37.21184Z","iopub.status.idle":"2021-12-12T04:14:52.14979Z","shell.execute_reply.started":"2021-12-12T04:14:37.211801Z","shell.execute_reply":"2021-12-12T04:14:52.148957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy\nAs we do not have access to the labels for the test set for the Forest Cover Type competition, we are going to examine the accuracy of the model with a validation set. ","metadata":{}},{"cell_type":"code","source":"# score for training set\ntrain_acc = final_model.score(X_train, y_train)\n# score for validation set\nvalid_acc = final_model.score(X_valid, y_valid)\n\nprint('Training Accuracy for Final Model', {round(train_acc, 4)})\nprint('Validation Accuracy for Final Model', {round(valid_acc, 4)})","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:52.151054Z","iopub.execute_input":"2021-12-12T04:14:52.151296Z","iopub.status.idle":"2021-12-12T04:14:56.641663Z","shell.execute_reply.started":"2021-12-12T04:14:52.151264Z","shell.execute_reply":"2021-12-12T04:14:56.640756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training accuracy for the model is 1.0, with the validation accuracy at .8932. This means that the model is overfitting the training set. \nThe validation score is .8932 and the test score accuracy is .7962. This means that the model is fitting the validation set better than the test set. ","metadata":{}},{"cell_type":"code","source":"# predictions\nvalid_pred = final_model.predict(X_valid)\n# prob predictions\nvalid_proba = final_model.predict_proba(X_valid)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:56.643019Z","iopub.execute_input":"2021-12-12T04:14:56.643299Z","iopub.status.idle":"2021-12-12T04:14:58.871247Z","shell.execute_reply.started":"2021-12-12T04:14:56.643268Z","shell.execute_reply":"2021-12-12T04:14:58.870444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Top K-Accuracy","metadata":{}},{"cell_type":"markdown","source":"We will now explore the accuracy of the final model by calculating the top number of successes of finding the actual label in the top 2 and 3 predicted labels.","metadata":{}},{"cell_type":"code","source":"def top_k_accuracy(y_true, pred_prob, K):\n    count = 0\n    for i in range(len(y_true)):\n        p = pred_prob[i, :]          # Get predictions for current observation\n        rank = np.argsort(p) + 1     # Rank classes in increasing order; add 1 to get from 0-6 to 1-7 for label\n        correct = y_true[i]          # Get correct class.\n        if correct in rank[-K:]:     # See if correct class is in top k\n            count += 1               # Increment count if so.\n\n    return count / len(y_true)       # Return score","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:58.872383Z","iopub.execute_input":"2021-12-12T04:14:58.872667Z","iopub.status.idle":"2021-12-12T04:14:58.87943Z","shell.execute_reply.started":"2021-12-12T04:14:58.872627Z","shell.execute_reply":"2021-12-12T04:14:58.878594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate accuracy for top 2 predictions\ntop_2_accuracy = top_k_accuracy(y_valid, valid_proba, 2)\nprint(round(top_2_accuracy, 4))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:58.883515Z","iopub.execute_input":"2021-12-12T04:14:58.88392Z","iopub.status.idle":"2021-12-12T04:14:58.947742Z","shell.execute_reply.started":"2021-12-12T04:14:58.883874Z","shell.execute_reply":"2021-12-12T04:14:58.946829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate accuracy for top 3 predictions\ntop_3_accuracy = top_k_accuracy(y_valid, valid_proba, 3)\nprint(round(top_3_accuracy, 4))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:58.949031Z","iopub.execute_input":"2021-12-12T04:14:58.949361Z","iopub.status.idle":"2021-12-12T04:14:59.012441Z","shell.execute_reply.started":"2021-12-12T04:14:58.949315Z","shell.execute_reply":"2021-12-12T04:14:59.01153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While the model is 89.32% accurate on the validation set for predicting the correct label, the model is 97.98% accurate at predicting the label that is in the top 2 for each cover type and 99.54% accurate at predicting the label that is within the top 3 for each cover type. If selecting a model where predicting within the top 2 classifications were acceptable, then this model would be very strong. ","metadata":{}},{"cell_type":"markdown","source":"# Classification Report\n\nOne of the ways to assess the accuracy of our model is through examining precision and recall. The classification report below includes the precision and recall for each cover type. ","metadata":{}},{"cell_type":"code","source":"# classification report\nc_report = classification_report(y_valid, valid_pred)\nprint(c_report)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:59.013945Z","iopub.execute_input":"2021-12-12T04:14:59.014232Z","iopub.status.idle":"2021-12-12T04:14:59.03109Z","shell.execute_reply.started":"2021-12-12T04:14:59.01419Z","shell.execute_reply":"2021-12-12T04:14:59.029904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Precision = TP/TP + FP\n\nRecall = TP/TP + FN\n\n- The model precision was highest for Cover Type 4. \n- The model recall was highest for Cover Type 4 as well. \n- The model also yielded the highest f1-score for Cover Type 4. \n\nThis makes sense as the support for Cover Type 4 was among the top 2 most common cover types in the data set. \n","metadata":{}},{"cell_type":"markdown","source":"# Confusion Matrix\n\nWe will now examine the accuracy of the model via a confusion matrix. The confusion matrix displays the number of times the cover type was classified correctly and how many times it was misclassified as another cover type. ","metadata":{}},{"cell_type":"code","source":"# confusion matrix\ncm = confusion_matrix(y_valid, valid_pred)\ncm_df = pd.DataFrame(cm)\n# Change the column names\ncm_df.columns =[1, 2, 3, 4, 5, 6, 7]\ncm_df.index = [1, 2, 3, 4, 5, 6, 7]\n# display\ncm_df","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:59.032327Z","iopub.execute_input":"2021-12-12T04:14:59.032564Z","iopub.status.idle":"2021-12-12T04:14:59.0545Z","shell.execute_reply.started":"2021-12-12T04:14:59.032531Z","shell.execute_reply":"2021-12-12T04:14:59.053442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of Class Probability Predictions","metadata":{}},{"cell_type":"markdown","source":"In this section, we provide some histograms displaying the distributions of probability estimates generated for each label.","metadata":{}},{"cell_type":"code","source":"# validation predictions data frame\ndf_prob = pd.DataFrame(valid_proba)\ndf_prob.columns = [1, 2, 3, 4, 5, 6, 7]\ndf_prob","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:59.055476Z","iopub.execute_input":"2021-12-12T04:14:59.055982Z","iopub.status.idle":"2021-12-12T04:14:59.077576Z","shell.execute_reply.started":"2021-12-12T04:14:59.055951Z","shell.execute_reply":"2021-12-12T04:14:59.076649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# histogram chart for probabilities by cover type\nplt.figure(figsize = [12,9])\nplt.hist(df_prob)\nplt.title('Histogram for Probabilities for Each Cover Type')\nplt.ylabel('Count')\nplt.xlabel('Probability')\nplt.legend([1, 2, 3, 4, 5, 6, 7], title = 'Cover Type')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:59.079386Z","iopub.execute_input":"2021-12-12T04:14:59.07971Z","iopub.status.idle":"2021-12-12T04:14:59.519301Z","shell.execute_reply.started":"2021-12-12T04:14:59.079666Z","shell.execute_reply":"2021-12-12T04:14:59.518432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These visualizations provide us with information about the labels that our model is more likely to predict, or if there are labels that it tends to be more or less confident about.","metadata":{}},{"cell_type":"code","source":"df_prob.plot(kind = 'hist',\n        alpha = 0.7,\n        bins = 30,\n        title = 'Histogram of Probabilities by Cover Type',\n        rot = 45,\n        grid = False,\n        figsize = (12,8),\n        fontsize = 15, \n        color = ['purple', 'orange', 'gold', 'pink', 'forestgreen', 'lightblue', 'navy'])\nplt.xlabel('Probability')\nplt.ylabel(\"Count\");","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:59.520479Z","iopub.execute_input":"2021-12-12T04:14:59.520764Z","iopub.status.idle":"2021-12-12T04:15:00.462381Z","shell.execute_reply.started":"2021-12-12T04:14:59.520732Z","shell.execute_reply":"2021-12-12T04:15:00.461537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxValueIndex = df_prob.idxmax(axis=1)\nmaxValues = df_prob.max(axis=1)\npred_prob = pd.concat([maxValueIndex, maxValues], axis=1)\ndf_1 = pred_prob.loc[lambda x: x[0] == 1]\ndf_2 = pred_prob.loc[lambda x: x[0] == 2]\ndf_3 = pred_prob.loc[lambda x: x[0] == 3]\ndf_4 = pred_prob.loc[lambda x: x[0] == 4]\ndf_5 = pred_prob.loc[lambda x: x[0] == 5]\ndf_6 = pred_prob.loc[lambda x: x[0] == 6]\ndf_7 = pred_prob.loc[lambda x: x[0] == 7]","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:15:00.46354Z","iopub.execute_input":"2021-12-12T04:15:00.463831Z","iopub.status.idle":"2021-12-12T04:15:00.491997Z","shell.execute_reply.started":"2021-12-12T04:15:00.463799Z","shell.execute_reply":"2021-12-12T04:15:00.490962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# histograms of probability estimates generated for each label\nc_label = [1, 2, 3, 4, 5, 6, 7]\npalette = ['purple', 'orange', 'gold', 'pink', 'forestgreen', 'lightblue', 'navy']\ndflist = [df_1, df_2, df_3, df_4, df_5, df_6, df_7]\nplt.figure(figsize = [18, 9])\n\nfor c in c_label:\n    plt.figure(figsize = [18, 9])\n    plt.subplot(2, 4, c)\n    plt.hist(dflist[c-1][1], color = palette[c-1])\n    plt.title(f'Probability Distribution for Cover Type {c_label[c-1]}')\n    plt.ylabel('Count')\n    plt.ylim(0, 300)\n    plt.xlabel('Probability')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:15:00.493329Z","iopub.execute_input":"2021-12-12T04:15:00.493911Z","iopub.status.idle":"2021-12-12T04:15:02.171154Z","shell.execute_reply.started":"2021-12-12T04:15:00.493881Z","shell.execute_reply":"2021-12-12T04:15:02.169869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From these visualizations, we can see that our model is most confident about Cover Types 7, 4, and 5. This corresponds with the classification report data explored earlier. ","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:14:11.111635Z","iopub.execute_input":"2021-12-12T04:14:11.111998Z","iopub.status.idle":"2021-12-12T04:14:11.118964Z","shell.execute_reply.started":"2021-12-12T04:14:11.11195Z","shell.execute_reply":"2021-12-12T04:14:11.117996Z"}}}]}