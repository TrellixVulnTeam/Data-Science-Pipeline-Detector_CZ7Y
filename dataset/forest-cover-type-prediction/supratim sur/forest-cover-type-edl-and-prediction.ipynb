{"cells":[{"metadata":{},"cell_type":"markdown","source":"<table style= 'width:100%'>\n    <tr style=\"background-color:#186b6b;color:#ffffff;\">\n        <th><img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3936/logos/front_page.png\"></th>\n        <th><p style=\"color:white;text-align: center; font-size:300%\">Forest cover type prediction</p></th>\n    </tr>\n    </table>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Please upvote my kernel if you like it :) his will motivate me. also please point out my mistakes so i can rectify.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style= \"color:blue; font-size:200%; text-decoration: underline\">Problem Definition:</p>\n\n\n<p style= 'color:gray'>\n    In this competition you are asked to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form (not scaled) and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.</p>\n<p style= 'color:gray'>\nThis study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Importing necessary libraries:</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\npy.init_notebook_mode()\nimport plotly\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>loading the csv data in the dataframe:</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/forest-cover-type-prediction/train.csv',low_memory=False)\ndf_test = pd.read_csv('../input/forest-cover-type-prediction/test.csv', low_memory=False)\ncombine = [df_train, df_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style= \"color:blue; font-size:200%; text-align:center;text-decoration: underline\">Data Definition:</p><br><br>\n\n\n\n\n<h2 style= \"color:gray\">\nThe study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. Each observation is a 30m x 30m patch. You are asked to predict an integer classification for the forest cover type. The seven types are:</h2><br><br>\n<b>\n1 - Spruce/Fir<br>\n    \n2 - Lodgepole Pine\n    \n3 - Ponderosa Pine\n    \n4 - Cottonwood/Willow\n    \n5 - Aspen\n    \n6 - Douglas-fir\n    \n7 - Krummholz<br><br>\n</b>\n<h2 style= \"color:gray\">\nThe training set (15120 observations) contains both features and the Cover_Type. The test set contains only the features. You must predict the Cover_Type for every row in the test set (565892 observations).</h2><br><br>\n\n<h1 style= \"color:teal; font-size:200%; text-decoration: underline\">Data Field:</h1><br>\n\n\n<b>\nElevation - Elevation in meters<br>\n\nAspect - Aspect in degrees azimuth\n\nSlope - Slope in degrees\n\nHorizontal_Distance_To_Hydrology - Horz Dist to nearest surface water features\n\nVertical_Distance_To_Hydrology - Vert Dist to nearest surface water features\n\nHorizontal_Distance_To_Roadways - Horz Dist to nearest roadway\n\nHillshade_9am (0 to 255 index) - Hillshade index at 9am, summer solstice\n\nHillshade_Noon (0 to 255 index) - Hillshade index at noon, summer solstice\n\nHillshade_3pm (0 to 255 index) - Hillshade index at 3pm, summer solstice\n\nHorizontal_Distance_To_Fire_Points - Horz Dist to nearest wildfire ignition points\n\nWilderness_Area (4 binary columns, 0 = absence or 1 = presence) - Wilderness area designation\n\nSoil_Type (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation\n\nCover_Type (7 types, integers 1 to 7) - Forest Cover Type designation\n</b>\n\n<h2 style= \"color:gray\">\nThe wilderness areas are:<br><br>\n</h2>\n\n\n<b>\n1 - Rawah Wilderness Area<br>\n\n2 - Neota Wilderness Area\n\n3 - Comanche Peak Wilderness Area\n\n4 - Cache la Poudre Wilderness Area</b>\n\n\n<h2 style= \"color:gray\">\nThe soil types are:<br><br>\n</h2>\n\n<b>\n1 Cathedral family - Rock outcrop complex, extremely stony.<br>\n\n2 Vanet - Ratake families complex, very stony.\n\n3 Haploborolis - Rock outcrop complex, rubbly.\n\n4 Ratake family - Rock outcrop complex, rubbly.\n\n5 Vanet family - Rock outcrop complex complex, rubbly.\n\n6 Vanet - Wetmore families - Rock outcrop complex, stony.\n\n7 Gothic family.\n\n8 Supervisor - Limber families complex.\n\n9 Troutville family, very stony.\n\n10 Bullwark - Catamount families - Rock outcrop complex, rubbly.\n\n11 Bullwark - Catamount families - Rock land complex, rubbly.\n\n12 Legault family - Rock land complex, stony.\n\n13 Catamount family - Rock land - Bullwark family complex, rubbly.\n\n14 Pachic Argiborolis - Aquolis complex.\n\n15 unspecified in the USFS Soil and ELU Survey.\n\n16 Cryaquolis - Cryoborolis complex.\n\n17 Gateview family - Cryaquolis complex.\n\n18 Rogert family, very stony.\n\n19 Typic Cryaquolis - Borohemists complex.\n\n20 Typic Cryaquepts - Typic Cryaquolls complex.\n\n21 Typic Cryaquolls - Leighcan family, till substratum complex.\n\n22 Leighcan family, till substratum, extremely bouldery.\n\n23 Leighcan family, till substratum - Typic Cryaquolls complex.\n\n24 Leighcan family, extremely stony.\n\n25 Leighcan family, warm, extremely stony.\n\n26 Granile - Catamount families complex, very stony.\n\n27 Leighcan family, warm - Rock outcrop complex, extremely stony.\n\n28 Leighcan family - Rock outcrop complex, extremely stony.\n\n29 Como - Legault families complex, extremely stony.\n\n30 Como family - Rock land - Legault family complex, extremely stony.\n\n31 Leighcan - Catamount families complex, extremely stony.\n\n32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.\n\n33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.\n\n34 Cryorthents - Rock land complex, extremely stony.\n\n35 Cryumbrepts - Rock outcrop - Cryaquepts complex.\n\n36 Bross family - Rock land - Cryumbrepts complex, extremely stony.\n\n37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.\n\n38 Leighcan - Moran families - Cryaquolls complex, extremely stony.\n\n39 Moran family - Cryorthents - Leighcan family complex, extremely stony.\n\n40 Moran family - Cryorthents - Rock land complex, extremely stony.</b>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>checking the dataframes</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"training datasets contains {} nos of rows and {} nos of columns\".format(df_train.shape[0],df_train.shape[1]))\nprint('*'*68)\nprint(\"test datasets contains {} nos of rows and {} nos of columns\".format(df_test.shape[0],df_test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"inception : \n\ntest dataset having one column less that training datasets which is okay and must be the cover type feature which we need to predict lets confirm by comparing the two datsets for missing columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"set(df_train) - set(df_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(df_train.info())\nprint('-'*70)\nprint(df_test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference :\n\n\nall the feature and predict variables are int64 type and there is no missing values lets confirm the missing values below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference Drawn:\n\nThere is no missing value in the datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# view data statistics\ndf_train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"inference drawn :\n\nsoil_type7 and soil_type15 can be removed from the dataframe later as its standard deviation and all other aspects are 0\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Data Correleation</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = df_train[['Elevation', 'Aspect', 'Slope',                  # did not consider the soiltype and wilderness area\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', # as it is a hotencoded columns.\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Cover_Type']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation.iloc[10,10]\ncorrelation.columns[10]\ncorrelation.index[10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(correlation.columns)\ntest = pd.DataFrame()\nvalues=[]\ncols=[]\nindx =[]\nplot = []\n\nfor i in range(0,11):\n    for j in range (i+1,11): # avoid repition\n        if (1> correlation.iloc[i,j] >= 0.5) or (correlation.iloc[i,j] <= -0.5):\n            test = test.append(pd.DataFrame(correlation.iloc[i,j], columns=[correlation.columns[i]],index=[correlation.index[j]]))\n            print (f\"{correlation.columns[j]} and {correlation.index[i]} are highly correlated ({correlation.iloc[i,j]:.2f})\")\n            values.append(correlation.iloc[i,j])\n            indx.append([correlation.index[i]])\n            cols.append(correlation.columns[j])\n            plot.append([correlation.iloc[i,j],correlation.index[i],correlation.columns[j]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.heatmap(correlation,annot = True, cmap ='YlGnBu');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"inference drawn :\n\nValues close to 0 show less skew\n\nSeveral attributes in Soil_Type show a large skew. Hence, some algos may benefit if skew is corrected","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Data Statistics : class distrubution</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.groupby('Cover_Type').size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"inference Drawn:\n\n    We see that all classes have an equal presence. No class re-balancing is necessary\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Data visualization : Scatter plot</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.iloc[:,1:] #remove the first id column which is of no use now","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.set(style='darkgrid')\nfor v,i,c, in plot:\n    sns.pairplot(data=df_train, hue=\"Cover_Type\", x_vars=i, y_vars =c, height=5)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference Drawn :\n\nThe plots show to which class does a point belong to. The class distribution overlaps in the plots.    \n\nHillshade patterns give a nice ellipsoid patterns with each other\n\nAspect and Hillshades attributes form a sigmoid pattern\n\nHorizontal and vertical distance to hydrology give an almost linear pattern.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Data visualization : Box and density plot</p>","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for i in range(len(df_train.columns)-1):\n    plt.figure(figsize=(12,6))\n    sns.violinplot(x= df_train.Cover_Type, y = df_train.columns[i], data = df_train, pallet = 'deep')\n    plt.show()\n    \n    \n    \n#Elevation is has a separate distribution for most classes. Highly correlated with the target and hence an important attribute\n#Aspect contains a couple of normal distribution for several classes\n#Horizontal distance to road and hydrology have similar distribution\n#Hillshade 9am and 12pm display left skew\n#Hillshade 3pm is normal\n#Lots of 0s in vertical distance to hydrology\n#Wilderness_Area3 gives no class distinction. As values are not present, others gives some scope to distinguish\n#Soil_Type, 1,5,8,9,12,14,18-22, 25-30 and 35-40 offer class distinction as values are not present for many classes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Data Cleaning</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# rem = []\n# for i in df_train.columns:\n#     if df_train[i].std()==0:\n#         rem.append(i)\n# rem\nrem = [i for i in df_train if df_train[i].std()==0]\nrem # list of columns we need to remove as it contains zero or its standard deviations are zero","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(rem,axis=1,inplace=True) # dropping the unnecessary column from the training data sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Data Preparation</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Original\n\nDelete rows or impute values in case of missing\n\nStandardScaler\n\nMinMaxScaler\n\nNormalizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns[:10] # point from where ctegorical data begins#\ndf_train.iloc[:,:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard = StandardScaler()\nminmax = MinMaxScaler()\nnormalizer = Normalizer()\n\nX = df_train.drop('Cover_Type',axis=1)\ny = df_train['Cover_Type']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply standardscaler to only non categorical data\n\nstn_x_train = standard.fit_transform(X_train.iloc[:,:10])\nstn_x_valid = standard.fit_transform(X_test.iloc[:,:10])\n\n# apply MinMaxScaler to only non categorical data\n\nminmax_x_train = minmax.fit_transform(stn_x_train)\nminmax_x_valid = minmax.transform(stn_x_valid)\n\n# apply normalizer to only non categroical data\nnormal_x_train = normalizer.fit_transform(minmax_x_train)\nnormal_x_valid = normalizer.fit_transform(minmax_x_valid)\n\n\nX_train_scaled = pd.DataFrame(data = normal_x_train,columns=df_train.columns[:10])\nX_valid_scaled = pd.DataFrame(data = normal_x_valid,columns=df_train.columns[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_cat = X_train.iloc[:,10:]\nx_valid_cat = X_test.iloc[:,10:] # dataframe of categorical colums already hotencoded\nx_train_cat.reset_index(inplace=True,drop=True)\nx_valid_cat.reset_index(inplace=True,drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_valid_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = X_train_scaled.join(x_train_cat) # joined non categorical and categorical dataframe together after scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = X_valid_scaled.join(x_valid_cat)  # joined non categorical and categorical dataframe together after scaling","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Model selection and accuracy test</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBRFClassifier,XGBClassifier\n\n\nsvc = LinearSVC(max_iter=10000,dual=False)\nknc = KNeighborsClassifier()\nclf = RandomForestClassifier()\nxgbrf = XGBRFClassifier()\nxgb = XGBClassifier()\n\ndef model_score(model):\n    score=[]\n    model_name = type(model).__name__\n    a = model.fit(x_train,y_train)\n    a.score(x_test,y_test)\n    y_pred = a.predict(x_test)\n    acc = accuracy_score(y_test,y_pred)  \n    return model_name,acc     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [svc,knc,clf,xgbrf,xgb]\nscore =[]\nfor name in models:\n    a,b = model_score(name)\n    score.append([a,round(b*100,2)])\ndf = pd.DataFrame(data=score,columns=['name','accuracy_score'])\nc = df[df.accuracy_score==df.accuracy_score.max()]\nprint (df)\nprint ('_'*50)\nprint (f'the best model is {c.name.values[0]} and its score is {df.accuracy_score.max()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Hyper parameter tuning</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# as we see the best  model is RandomForestClassifier lets tune its hyperparamter\nclf.get_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Hyper parameter tuning</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\n\n 'max_features': ['auto','sqrt', 'log2'],\n 'min_samples_leaf': np.arange(1,10,2),\n 'min_samples_split': np.arange(2,10,2),\n 'n_estimators': np.arange(100,200,50),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score,GridSearchCV\n\ncvs = cross_val_score(clf,X=x_train,y=y_train,n_jobs=-1,cv=10)\ncvs.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gridsearch = GridSearchCV(clf,param_grid = grid, n_jobs=-1, verbose=2, cv = 5)\ngrid_clf = gridsearch.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_pred = grid_clf.predict(x_test)\naccuracy_score(y_pred,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting best parameter into the model\n\nideal_model = RandomForestClassifier(max_features= 'auto',\n min_samples_leaf= 1,\n min_samples_split= 2,\n n_estimators= 100,\n n_jobs= -1,\n random_state= 0,\n verbose= 2)\nideal_model.fit(x_train,y_train)\ny_pred = ideal_model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Classification report</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Multiclass ROC AUC score</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiclass ROC AUC score\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_auc_score\n\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multiclass_roc_auc_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Confusion Matrix</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_roc_curve,confusion_matrix\n\nconfusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting confusion matrix\nplt.figure(figsize = (12,6))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = True, cmap ='YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>Feature Importance</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importance\n\nimportances = ideal_model.feature_importances_\n\ndf_tmp = pd.DataFrame(data = {'score': importances,'name':x_train.columns})\n\ndf_tmp.sort_values(by='score',ascending = False,inplace=True)\n\ng = sns.barplot(x='name',y='score',data= df_tmp.head(10))\nplt.xticks(rotation=90)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:maroon; font-size:150%; font-weight:bold'>loading test dataframe and predicting values and submission</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.columns #checking the columns of the test dataframe\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rem = [i for i in df_test if df_test[i].std()==0] # removing the zero deviation columns if present\nrem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we need to remove only id column as of now\ndf_tmp = df_test.drop('Id',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets predict with the dataframe after normalizer and minmax and standard scaling\n\n# apply standardscaler to only non categorical data\n\n\nstn_x_test = standard.fit_transform(df_tmp.iloc[:,:10])\n\n# apply MinMaxScaler to only non categorical data\n\n\nminmax_x_valid = minmax.transform(stn_x_test)\n\n# apply normalizer to only non categroical data\n\nnormal_x_valid = normalizer.fit_transform(minmax_x_valid)\n\n\n\nX_valid_scaled = pd.DataFrame(data = normal_x_valid,columns=df_train.columns[:10])\n\n\nx_valid_cat = df_tmp.iloc[:,10:] # dataframe of categorical colums already hotencoded\n\nx_valid_cat.reset_index(inplace=True,drop=True)\n\nx_test = X_valid_scaled.join(x_valid_cat)  # joined non categorical and categorical dataframe together after scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Cover_Type = clf.predict(x_test.drop(['Soil_Type7','Soil_Type15'],axis =1)) # predicting the values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(data={'Id': df_test.Id,'Cover_Type': Cover_Type}) # creating dataframe with prediction and id","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False) # creating the csv for submission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}