{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#%% Importing required packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport pickle\n\n#%%\nTrain_set = pd.read_csv(\"train.csv\")\nTest_set = pd.read_csv(\"test.csv\")\n#Ori_Train = Train_set\n#Ori_Test = Test_set\npd.set_option('display.max_columns', None)\nTrain_set.head(8)\nTrain_set = Train_set.drop(['Id'], axis = 1)\n\n#Train_set.describe()\nTrain_set.isnull().sum() #check for missing values\n\"\"\"\nThats great no missing values and all values belong \nto integer data type.Also the data contains \nbinary columns of data for qualitative independent \nvariables such as wilderness areas and soil type.\n\"\"\"\n\nTrain_set['Cover_Type'].value_counts()\nsns.countplot(data=Train_set,x=Train_set['Cover_Type'])\n\"\"\"\nSo we see that all the cover types are equal in number\ni.e, 2160\n\"\"\"\nfor i in range(10,54):\n    print (Train_set.iloc[:,i].value_counts())\n\"\"\"\nSoil_Type7 and Soil_type25 are constant with '0' \nbinary value.\nWe can drop those.\n\"\"\"\nTrain_set = Train_set.drop(['Soil_Type7', 'Soil_Type15'], axis = 1)\nTest_set = Test_set.drop(['Soil_Type7', 'Soil_Type15'], axis = 1)\n\n#%% Visualizations\ncolnames = Train_set.columns\n\n\n\"\"\"\nWe can actually plot for [0:52] columns but the wilderness areas \nand soil type data points are in binary data form.Later we will be \ngrouping them into single variable  \n\"\"\"\nfor i in colnames[0:10]:\n    plt.figure()\n    sns.violinplot(data=Train_set,x=Train_set['Cover_Type'],y=Train_set[i])\n    plt.show()\n    \n\"\"\"\nFrom Visualizations we observe that:\n1.Elevation seems to be an important factor for prediction as \n  each Cover_Type has different type of distribution\n2.Aspect and slope plots shows normal distribution for most of the \n  classes\n3.Horizontal distance to hydrology and roadways plots are quite similar\n4.Hillshade 9am and 12pm plots are left skewed\n\"\"\"\n\n#%% Correlation\ncorrdata = Train_set.iloc[:,:10]\ndata_corr = corrdata.corr()\nlevel = 0.6\n#print(data_corr) # Are the highly correlated ones\n\ncorrmat = Train_set.iloc[:,:10].corr()\nsns.heatmap(corrmat,vmax=0.8,square=True) #for better visualization\n\nhigh_corr = [] #to get highly correlated ones\nfor i in range(0, 10):\n    for j in range(i+1, 10):\n        if data_corr.iloc[i,j]>= level and data_corr.iloc[i,j]<1\\\n        or data_corr.iloc[i,j] <0 and data_corr.iloc[i,j]<=-level:\n            high_corr.append([i,j,data_corr.iloc[i,j]])\nsorted_high_corr = sorted(high_corr,key= lambda x: abs(x[2]),reverse = True)\n\ncols = corrdata.columns\nfor i,j,corr in sorted_high_corr:\n    print(\"%s and %s = %.2f\" % (cols[i], cols[j], corr))\n    \n#visualization\nfor i,j,corr in sorted_high_corr:\n    sns.pairplot(data = Train_set, hue='Cover_Type', x_vars=cols[i], y_vars=cols[j])\n    plt.show()\n\n  \n#%% Combining the One-Hot Encoded Variables\n\"\"\"\nNow we are going to group the one-hot encoded variables of a \nWilderness_Area', 'Soil_Type into one single variable\n\"\"\"\nrow,column = Train_set.shape\ngrp_data = pd.DataFrame(index= np.arange(0,row), columns=['Wilderness_Area', 'Soil_Type', 'Cover_Type'])\nfor i in range(0,row):\n    area_class = 0;\n    soil_class = 0;\n    for j in range(10,14):\n        if (Train_set.iloc[i,j] == 1):\n            area_class = j-9\n            break\n    for k in range(14,54):\n        if (Train_set.iloc[i,k] == 1):\n            soil_class = k-13\n            break\n    grp_data.iloc[i] = [area_class,soil_class,Train_set.iloc[i, column-1]]\n\nplt.figure()    \nsns.countplot(x = 'Wilderness_Area', hue = 'Cover_Type', data = grp_data)\nplt.show()\n\nplt.figure(figsize=(20,10))\nsns.countplot(x='Soil_Type', hue = 'Cover_Type', data= grp_data)\nplt.show()\n\n\"\"\"\n1.Wilderness_Area 1,3,4 show presence of class distinction\n2.Few Soil_Types does not show much class distinction\n\"\"\"\n\n#%%\nId=Test_set['Id']\ny=Train_set['Cover_Type']\nTrain_set=Train_set.drop(['Cover_Type'],1)\nTest_set=Test_set.drop(['Id'],1)\n\n\n#Train-Test split for Cross-validation\n\nx_train, x_test, y_train, y_test = train_test_split(Train_set, y, test_size=0.3, random_state=42)\n\n#%% Using RandomForestClassifier \n\n\"\"\"\nWe are using the Random Forest Classifier to predict because:\n1.The overfitting problem will never come when we use the \n  random forest algorithm.\n2.The random forest algorithm can be used for feature engineering.\n  As we see there is a strong correlation between different features.\n  The RandomForest algorithm does the feature engineering and choose\n  the best features for prediction\n\nand of course Random Forest is known for its accuracy and missing value\ntreatment (We do not have any missing values here)\nwe will also perform feature selection and build another model\nand compare the accuracies \n\"\"\"\n\nrf=RandomForestClassifier(n_estimators=150,class_weight='balanced',n_jobs=2,random_state=42)\nrf.fit(x_train,y_train)\npred=rf.predict(x_test)\nconfusion_matrix(pred,y_test)\nacc=rf.score(x_test,y_test)\nprint(acc)\n\n\n#rf.fit(Train_set,y)\n#res=rf.predict(Test_set)\n#res\n\n#Result=pd.DataFrame(Id)\n#Result['Cover_Type']=res\n#Result.head()\n\n\n\"\"\"\nSo our model is about 86% accurate and in the next step feature \nselection is done by taking top 20 important features.\n\nWe will be creating test and train data sets using those features\nand test our model accuracy\n\n\"\"\"\n#%% Feature selection\n\n#Please remove the comment quotes, in case if u need to run the feature selection model\n\n\"\"\"\nfrom sklearn.feature_selection import SelectFromModel\n\ncolnames = Train_set.columns\nimp_fea = []\nfor feature in zip(colnames, rf.feature_importances_):\n    imp_fea.append(feature)\n    imp_fea = sorted(imp_fea , key = lambda x:x[1], reverse = True)\n    \nimp_fea[0:20] #Top 20 important features\n\nsfm = SelectFromModel(rf, threshold=0.008) #Selecting those top 20 features\nsfm.fit(x_train, y_train)\nfor i in sfm.get_support(indices=True):\n    print(colnames[i])\n\n#Creating Test and Train Data sets using those TOP FEATURES\n    \nX_important_train = sfm.transform(x_train)\nX_important_test = sfm.transform(x_test)\nrf_important = RandomForestClassifier(n_estimators=150,class_weight='balanced', random_state=42, n_jobs=2)\nrf_important.fit(X_important_train, y_train)\ny_important_pred = rf_important.predict(X_important_test)\nconfusion_matrix(y_important_pred,y_test)\nrf_important.score(X_important_test,y_test)\n\n\"\"\"\n\"\"\"\nAs can be seen by the accuracy scores, our original model which \ncontained all the features is 86.1% accurate while the our \ntop features model which contained only the top 20 features is 85.1% \naccurate. Thus, for a 1% cost in accuracy we reduced the \nnumber of features in the model but I didnt find any appreciable\ntraining time difference between the two models\n\"\"\"\n\"\"\"\nrf_important.fit(Train_set,y)\nres=rf_important.predict(Test_set)\nres\n\n\"\"\"\n#%% Into the pickle file\nwith open(r\"model.pkl\",\"wb\") as output_file:\n    pickle.dump(rf,output_file,-1)\n#rf2 = pickle.load(open('model.pkl','rb'))\n#rf2.predict(Test_set[0:8]) #pickle file is working properly\n\nmodel_columns = list(Train_set.columns)\npickle.dump(model_columns, open('model_columns.pkl','wb'))\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}