{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"770ac7b7-190f-a01d-f2f4-926d165f9e9e"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27bc7c54-622b-a00e-6498-8c6cc60e28b8"},"outputs":[],"source":"# Read raw data from the file\n\nimport pandas #provides data structures to quickly analyze data\n#Since this code runs on Kaggle server, train data can be accessed directly in the 'input' folder\ndataset = pandas.read_csv(\"../input/train.csv\")\n\n# Size of the dataframe\n\nprint(\"Size of the dataframe: \", dataset.shape)\nprint(\"\")\n# We can see that there are 15120 instances having 55 attributes\n\n#Learning : Data is loaded successfully as dimensions match the data description\n\n#Drop the first column 'Id' since it just has serial numbers. Not useful in the prediction process.\ndataset = dataset.iloc[:,1:]\nprint(dataset)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6276e638-ccc1-0b52-8c7a-3735029ebe13"},"outputs":[],"source":"# Datatypes of the attributes\n\nprint(\"Datatypes of the attributes: \", dataset.dtypes)\n\n# Learning : Data types of all attributes has been inferred as int64"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"39b6a93e-e293-38ea-21be-8a4663ec046e"},"outputs":[],"source":"# Statistical description\n\npandas.set_option('display.max_columns', None)\nprint(dataset.describe())\n\n# Learning :\n# No attribute is missing as count is 15120 for all attributes. Hence, all rows can be used\n# Negative value(s) present in Vertical_Distance_To_Hydrology. Hence, some tests such as chi-sq cant be used.\n# Wilderness_Area and Soil_Type are one hot encoded. Hence, they could be converted back for some analysis\n# Attributes Soil_Type7 and Soil_Type15 can be removed as they are constant\n# Scales are not the same for all. Hence, rescaling and standardization may be necessary for some algos"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"efe3d3b5-e694-fa31-6146-517f9760c0ac"},"outputs":[],"source":"# Skewness of the distribution\nprint(\"Skewness of the distribution\")\nprint(\"----------------------------\")\nprint(\"\")\nprint(dataset.skew())\n\n# Values close to 0 show less skew\n# Several attributes in Soil_Type show a large skew. Hence, some algos may benefit if skew is corrected"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a13d2e86-f051-dd4a-b813-cbabb253fd98"},"outputs":[],"source":"#Class distribution\nprint(\"Class distribution\")\nprint(\"-----------\")\nprint(\"\")\n\n# Number of instances belonging to each class\n\ndataset.groupby('Cover_Type').size()\n\n# We see that all classes have an equal presence. No class re-balancing is necessary"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0b3c768-331e-7881-fe8a-d61274393874"},"outputs":[],"source":"#Data interaction // Correlation\nprint(\"Correlation\")\nprint(\"-----------\")\nprint(\"\")"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}