{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Statements","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd, matplotlib.pyplot as plt\nimport joblib\nimport optuna\nimport sklearn \n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:42.695593Z","iopub.execute_input":"2021-11-22T04:38:42.696802Z","iopub.status.idle":"2021-11-22T04:38:43.566737Z","shell.execute_reply.started":"2021-11-22T04:38:42.696634Z","shell.execute_reply":"2021-11-22T04:38:43.565564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# load data\ntrain = pd.read_csv('../input/forest-cover-type-prediction/train.csv')\n# view data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.569219Z","iopub.execute_input":"2021-11-22T04:38:43.569542Z","iopub.status.idle":"2021-11-22T04:38:43.684845Z","shell.execute_reply.started":"2021-11-22T04:38:43.569495Z","shell.execute_reply":"2021-11-22T04:38:43.683955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove ID column from set\ntrain = train.iloc[:, 1:]\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.686221Z","iopub.execute_input":"2021-11-22T04:38:43.68644Z","iopub.status.idle":"2021-11-22T04:38:43.705772Z","shell.execute_reply.started":"2021-11-22T04:38:43.686413Z","shell.execute_reply":"2021-11-22T04:38:43.704877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# check for missing values\ntrain.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.707007Z","iopub.execute_input":"2021-11-22T04:38:43.707252Z","iopub.status.idle":"2021-11-22T04:38:43.721009Z","shell.execute_reply.started":"2021-11-22T04:38:43.707222Z","shell.execute_reply":"2021-11-22T04:38:43.720118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.72516Z","iopub.execute_input":"2021-11-22T04:38:43.726244Z","iopub.status.idle":"2021-11-22T04:38:43.886523Z","shell.execute_reply.started":"2021-11-22T04:38:43.726187Z","shell.execute_reply":"2021-11-22T04:38:43.885369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dimensions of data set \nprint(train.shape) # 55 columns\n# column names\nprint(train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.887787Z","iopub.execute_input":"2021-11-22T04:38:43.888001Z","iopub.status.idle":"2021-11-22T04:38:43.894291Z","shell.execute_reply.started":"2021-11-22T04:38:43.887974Z","shell.execute_reply":"2021-11-22T04:38:43.893505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# create cat, num, and y\nX_cat = train.iloc[:, 10:54].values\nX_num = train.iloc[:, 0:10].values\ny = train.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.895481Z","iopub.execute_input":"2021-11-22T04:38:43.89589Z","iopub.status.idle":"2021-11-22T04:38:43.910698Z","shell.execute_reply.started":"2021-11-22T04:38:43.895855Z","shell.execute_reply":"2021-11-22T04:38:43.909614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale/standardizing numerical columns\n# scaler object\nscaler = StandardScaler()\n# fit to training data\nscaler.fit(X_num)\n# scale num columns\nX_num = scaler.transform(X_num)\n\n# shape\nprint(f'Categorical Shape: {X_cat.shape}')\nprint(f'Numerical Shape: {X_num.shape}')\nprint(f'Label Shape: {y.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.912789Z","iopub.execute_input":"2021-11-22T04:38:43.913124Z","iopub.status.idle":"2021-11-22T04:38:43.930075Z","shell.execute_reply.started":"2021-11-22T04:38:43.913079Z","shell.execute_reply":"2021-11-22T04:38:43.92888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine num and cat\nX = np.hstack((X_num, X_cat))\nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.931556Z","iopub.execute_input":"2021-11-22T04:38:43.931785Z","iopub.status.idle":"2021-11-22T04:38:43.945287Z","shell.execute_reply.started":"2021-11-22T04:38:43.931755Z","shell.execute_reply":"2021-11-22T04:38:43.944603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA","metadata":{}},{"cell_type":"code","source":"# PCA to find the number of components\npca = PCA().fit(X)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.title('PCA Number of Components for Cumulative Variance')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:43.946759Z","iopub.execute_input":"2021-11-22T04:38:43.946998Z","iopub.status.idle":"2021-11-22T04:38:44.286382Z","shell.execute_reply.started":"2021-11-22T04:38:43.946968Z","shell.execute_reply":"2021-11-22T04:38:44.285598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PCA\npca = PCA(n_components = 10)\npca.fit(X)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:44.287872Z","iopub.execute_input":"2021-11-22T04:38:44.288141Z","iopub.status.idle":"2021-11-22T04:38:44.401508Z","shell.execute_reply.started":"2021-11-22T04:38:44.28811Z","shell.execute_reply":"2021-11-22T04:38:44.400307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print components\nprint(pca.components_)\n\n# print variances\nprint(pca.explained_variance_)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:44.403824Z","iopub.execute_input":"2021-11-22T04:38:44.404832Z","iopub.status.idle":"2021-11-22T04:38:44.426081Z","shell.execute_reply.started":"2021-11-22T04:38:44.404775Z","shell.execute_reply":"2021-11-22T04:38:44.425132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"%%time\n\n# optuna hyperparameter tuning\ndef objective(trial):\n      solver = trial.suggest_categorical('solver', ['saga', 'lbfgs'])\n      lr_clf = LogisticRegression(random_state = 1, penalty = 'none', max_iter = 500, solver = solver)\n      return sklearn.model_selection.cross_val_score(lr_clf, X, y, n_jobs = -1, cv = 10).mean()\n    \nlr_study = optuna.create_study(direction='maximize')\nlr_study.optimize(objective, n_trials=3)\nlr = lr_study.best_trial\nprint('Accuracy: {}'.format(lr.value))\nprint(\"Best hyperparameters: {}\".format(lr.params))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:43:48.005941Z","iopub.execute_input":"2021-11-22T01:43:48.006482Z","iopub.status.idle":"2021-11-22T01:46:00.436786Z","shell.execute_reply.started":"2021-11-22T01:43:48.006437Z","shell.execute_reply":"2021-11-22T01:46:00.435886Z"}}},{"cell_type":"code","source":"# best model \n\nlr_model = LogisticRegression(random_state = 1, \n                              penalty = 'none', \n                              max_iter = 500, \n                              solver = 'saga')\nlr_model.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T04:38:44.428085Z","iopub.execute_input":"2021-11-22T04:38:44.428637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"%%time\n\n# optuna hyperparameter tuning\ndef objective(trial):\n    max_depth = trial.suggest_int('max_depth', 2, 50)\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 32)\n    dt_clf = DecisionTreeClassifier(random_state = 1, max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n    return sklearn.model_selection.cross_val_score(dt_clf, X, y, n_jobs = -1, cv = 10).mean()\n    \ndt_study = optuna.create_study(direction='maximize')\ndt_study.optimize(objective, n_trials=100)\ndt = dt_study.best_trial\nprint('Accuracy: {}'.format(dt.value))\nprint(\"Best hyperparameters: {}\".format(dt.params))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dt best model\ndt_model = DecisionTreeClassifier(random_state = 1, \n                                  max_depth = dt_study.best_trial.params['max_depth'], \n                                  min_samples_leaf = dt_study.best_trial.params['min_samples_leaf'])\ndt_model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"%%time\n\n# optuna hyperparameter tuning\ndef objective(trial):\n    n_estimators = trial.suggest_int('n_estimators', 100, 150)\n    max_depth = trial.suggest_int('max_depth', 20, 50)\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n    rf_clf = RandomForestClassifier(random_state = 1, n_estimators = n_estimators, max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n    return sklearn.model_selection.cross_val_score(rf_clf, X, y, n_jobs = -1, cv = 10).mean()\n    \nrf_study = optuna.create_study(direction='maximize')\nrf_study.optimize(objective, n_trials=20)\nrf = rf_study.best_trial\nprint('Accuracy: {}'.format(rf.value))\nprint(\"Best hyperparameters: {}\".format(rf.params))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best model\nrf_model = RandomForestClassifier(random_state = 1, \n                                  n_estimators = rf_study.best_trial.params['n_estimators'], \n                                  max_depth = rf_study.best_trial.params['max_depth'], \n                                  min_samples_leaf = rf_study.best_trial.params['min_samples_leaf'])\n\nrf_model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extra Tree Classifier","metadata":{}},{"cell_type":"code","source":"%%time\n\n# optuna hyperparameter tuning\ndef objective(trial):\n    max_depth = trial.suggest_int('max_depth', 30, 50)\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n    tree_clf = ExtraTreesClassifier(random_state = 0, n_estimators = 200, max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n    return sklearn.model_selection.cross_val_score(tree_clf, X, y, n_jobs = -1, cv = 10).mean()\n    \ntree_study = optuna.create_study(direction='maximize')\ntree_study.optimize(objective, n_trials=20)\ntree = tree_study.best_trial\nprint('Accuracy: {}'.format(tree.value))\nprint(\"Best hyperparameters: {}\".format(tree.params))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best model\ntree_model = ExtraTreesClassifier(random_state = 1, \n                                  n_estimators = 200, \n                                  max_depth = tree_study.best_trial.params['max_depth'], \n                                  min_samples_leaf = tree_study.best_trial.params['min_samples_leaf'])\n\ntree_model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"%%time\n\n# optuna hyperparameter tuning\ndef objective(trial):\n    max_depth = trial.suggest_int('max_depth', 10, 20)\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 15, 20)\n    gradb_clf = GradientBoostingClassifier(random_state = 0, max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n    return sklearn.model_selection.cross_val_score(gradb_clf, X, y, n_jobs = -1, cv = 10).mean()\n    \ngradb_study = optuna.create_study(direction='maximize')\ngradb_study.optimize(objective, n_trials = 5)\ngradb = gradb_study.best_trial\nprint('Accuracy: {}'.format(gradb.value))\nprint(\"Best hyperparameters: {}\".format(gradb.params))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# best model\ngradb_model = GradientBoostingClassifier(random_state = 0,\n                                         max_depth = gradb_study.best_trial.params['max_depth'], \n                                         min_samples_leaf = gradb_study.best_trial.params['min_samples_leaf'])\n\ngradb_model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extreme Gradient Boosting","metadata":{}},{"cell_type":"code","source":"%%time\n# xgb classifier\nxgb_clf = XGBClassifier(random_state = 0, max_depth = 10)\nxgb_model = xgb_clf.fit(X, y)\nxgb_model.score(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AdaBoost ","metadata":{}},{"cell_type":"code","source":"%%time\n\n# optuna hyperparameter tuning\ndef objective(trial):\n    n_estimators = trial.suggest_int('n_estimators', 1, 15)\n    adab_clf = AdaBoostClassifier(random_state = 0, n_estimators = n_estimators)\n    return sklearn.model_selection.cross_val_score(adab_clf, X, y, n_jobs = -1, cv = 10).mean()\n    \nadab_study = optuna.create_study(direction='maximize')\nadab_study.optimize(objective, n_trials = 10)\nadab = adab_study.best_trial\nprint('Accuracy: {}'.format(adab.value))\nprint(\"Best hyperparameters: {}\".format(adab.params))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best model\nadab_model = AdaBoostClassifier(random_state = 0, \n                                n_estimators = adab_study.best_trial.params['n_estimators'])\n\nadab_model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection","metadata":{}},{"cell_type":"code","source":"%%time \n# create ensemble classifier \nensemble_model = VotingClassifier(\n    estimators = [('tree', tree_model), \n                  ('rf', rf_model), \n                  ('gradb', gradb_model), \n                  ('xgb', xgb_model)],\n    voting = 'hard'\n)\n\n# fit\nensemble_model.fit(X, y)\n\n# print training accuracy\nprint('Logistic Regression Accuracy', lr_model.score(X, y))\nprint('Decision Tree Accuracy', dt_model.score(X, y))\nprint('Random Forest Accuracy', rf_model.score(X, y))\nprint('Extra Trees Accuracy', tree_model.score(X, y))\nprint('Gradient Boosting Accuracy', gradb_model.score(X, y))\nprint('Extra Gradient Boosting Accuracy', xgb_model.score(X, y))\nprint('AdaBoost Accuracy', adab_model.score(X, y))\nprint('Ensemble Accuracy:', ensemble_model.score(X, y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Preprocessor and Models","metadata":{}},{"cell_type":"code","source":"# save scaler\njoblib.dump(scaler, 'forest_cover_scaler.joblib')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joblib.dump(rf_model, 'rf_model_2.joblib')\njoblib.dump(tree_model, 'tree_model_2.joblib')\njoblib.dump(gradb_model, 'gradb_model_2.joblib')\njoblib.dump(xgb_model, 'xgb_model_2.joblib')\njoblib.dump(adab_model, 'adab_model_2.joblib')\njoblib.dump(ensemble_model, 'ensemble_model_2.joblib')\nprint('Model written to file.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}