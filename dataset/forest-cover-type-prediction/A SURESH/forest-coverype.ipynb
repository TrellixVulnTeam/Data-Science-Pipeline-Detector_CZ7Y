{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:blue\" align=\"left\"> 1. Import necessary Libraries </h2>","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read Data\nimport numpy as np                     # Linear Algebra (calculate the mean and standard deviation)\nimport pandas as pd                    # manipulate data, data processing, load csv file I/O (e.g. pd.read_csv)\n\n# Visualization\nimport seaborn as sns                  # Visualization using seaborn\nimport matplotlib.pyplot as plt        # Visualization using matplotlib\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\n# style\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nplt.style.use(\"fivethirtyeight\")       # Set Graphs Background style using matplotlib\nsns.set_style(\"darkgrid\")              # Set Graphs Background style using seaborn\n\n# ML model building; Pre Processing & Evaluation\nfrom sklearn.model_selection import train_test_split                     # split  data into training and testing sets\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge          # Linear Regression, Lasso and Ridge\nfrom sklearn.linear_model import LogisticRegression                      # Logistic Regression\nfrom sklearn.tree import DecisionTreeRegressor                           # Decision tree Regression\nfrom sklearn.ensemble import RandomForestClassifier                      # this will make a Random Forest Classifier\nfrom sklearn import svm                                                  # this will make a SVM classificaiton\nfrom sklearn.svm import SVC                                              # import SVC from SVM\nimport xgboost\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report      # this creates a confusion matrix\nfrom sklearn.metrics import roc_curve,auc                                # ROC\nfrom sklearn.preprocessing import StandardScaler                         # Standard Scalar\nfrom sklearn.model_selection import GridSearchCV                         # this will do cross validation\n\nimport warnings                        # Ignore Warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:blue\" align=\"left\"> 2. Load data </h2>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import first 5 rows\ncover = pd.read_csv(\"/kaggle/input/forest-cover-type-prediction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/forest-cover-type-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(cover.head())\ndisplay(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking dimension (num of rows and columns) of dataset\nprint(\"Training data shape (Rows, Columns):\",cover.shape)\nprint(\"Training data shape (Rows, Columns):\",test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cover['Cover_Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for Numerical and Categorical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check dataframe structure like columns and its counts, datatypes & Null Values\ncover.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cover.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Our dataset features consists of only integers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gives number of data points in each variable\ncover.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:blue\" align=\"left\"> 3. EDA (Exploratory Data Analysis) </h2>\n\n- EDA is a way of **Visualizing, Summarizing and interpreting** the information that is **hidden in rows and column** format.\n\n### Steps involved in EDA:\n1. Find Unwanted Columns\n- Find Missing Values\n- Find Features with one value\n- Explore the Categorical Features\n- Find Categorical Feature Distribution\n- Relationship between Categorical Features and Label\n- Explore the Numerical Features\n- Find Discrete Numerical Features\n- Relation between Discrete numerical Features and Labels\n- Find Continous Numerical Features\n- Distribution of Continous Numerical Features\n- Relation between Continous numerical Features and Labels\n- Find Outliers in numerical features\n- Explore the Correlation between numerical features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 1. Find Unwanted Columns\n\n- There is no unwanted column present in given dataset to remove.\n\n     EX: ID","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2. Find Missing Values\n\n- Checking missing values by below methods:\n\n     1. df.isnull().sum()\n        - It returns null values for each column\n          \n     2. isnull().any()\n        - It returns True if column have NULL Values\n        - It returns False if column don't have NULL Values\n          \n     3. Heatmap()\n        - Missing value representation using heatmap.\n          \n     4. Percentage of Missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Listing Number of missing values by feature column wise\ncover.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# any() check null values by columns\ncover.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,10))\nsns.heatmap(cover.isnull(), yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There is no missing values in dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 3. Find Features with one value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in cover.columns:\n    print(column,cover[column].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Since there is no Categorical Features, we can skip steps from 4 to 6.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 7. Explore the Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features = cover.select_dtypes(exclude='object')\nnumerical_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8. Find Discrete Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_feature=[feature for feature in numerical_features if len(cover[feature].unique())<25]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 9. Find Continous Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_features=[feature for feature in numerical_features if feature not in discrete_feature+['Cover_Type']]\nprint(\"Continuous feature Count {}\".format(len(continuous_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 10. Distribution of Continous Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,4, figsize=(14,9))\nsns.distplot(cover.Elevation, bins = 20, ax=ax[0,0]) \nsns.distplot(cover.Aspect, bins = 20, ax=ax[0,1]) \nsns.distplot(cover.Slope, bins = 20, ax=ax[0,2]) \nsns.distplot(cover.Horizontal_Distance_To_Hydrology, bins = 20, ax=ax[0,3])\nsns.distplot(cover.Vertical_Distance_To_Hydrology, bins = 20, ax=ax[1,0]) \nsns.distplot(cover.Horizontal_Distance_To_Roadways, bins = 20, ax=ax[1,1]) \nsns.distplot(cover.Hillshade_9am, bins = 20, ax=ax[1,2]) \nsns.distplot(cover.Hillshade_Noon, bins = 20, ax=ax[1,3])\nsns.distplot(cover.Hillshade_3pm, bins = 20, ax=ax[2,0])\nsns.distplot(cover.Horizontal_Distance_To_Fire_Points, bins = 20, ax=ax[2,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- it seems all continuous features are not normally distributed\n\n- **Slope, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Horizontal_Distance_To_Fire_Points** are **right skewed**\n\n- **Elevation, Hillshade_9am, Hillshade_3pm** is **left skewed**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 11. Relation between Continous numerical Features and Labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor feature in continuous_features:\n    data=cover.copy()\n    ax = plt.subplot(12,3,plotnumber)\n    plt.scatter(cover[feature], cover['Cover_Type'])\n    plt.xlabel(feature)\n    plt.ylabel('Cover_Type')\n    plt.title(feature)\n    plotnumber+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 12. Find Outliers in numerical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxplot on numerical features to find outliers\nplt.figure(figsize=(18,15), facecolor='white')\nplotnumber =1\nfor numerical_feature in numerical_features:\n    ax = plt.subplot(19,3,plotnumber)\n    sns.boxplot(cover[numerical_feature])\n    plt.xlabel(numerical_feature)\n    plotnumber+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- all features have outliers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 13. Explore the Correlation between numerical features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Correlation Heat Map","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,12))\nplt.title('Correlation of Numeric Features with Sale Price', y=1, size=16)\nsns.heatmap(cover.corr(), square = True, vmax=0.8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Selected HeatMap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = cover.drop('Cover_Type', axis=1).corr()\nplt.figure(figsize=(17, 14))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Correlation requires continuous data. Hence, ignore Wilderness_Area and Soil_Type as they are binary values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = cover.iloc[:,:10].corr()\nf, ax = plt.subplots(figsize = (12,8))\nsns.heatmap(corrmat, cmap='viridis', vmax=0.8, annot=True, square=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 14. Descriptive statistics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# descriptive statistics (numerical columns)\npd.set_option('display.max_columns', None)\ncover.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Count is 581012 for each column, so no data point is missing.\n- Wilderness_Area and Soil_Type are one hot encoded. Hence, they could be converted back for some analysis.\n- Scales are not the same for all. Hence, rescaling and standardisation may be necessary for some algos.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:green\" align=\"left\"> 5. Data Visualization </h2>\n\n- Used below **visualisation libraries**\n\n     1. Matplotlib\n     2. Seaborn (statistical data visualization)\n     \n### 1. Categorical\n\n- Categorical data :\n\n     1. Numerical Summaries\n     2. Histograms\n     3. Pie Charts\n\n\n### 2. Univariate Analysis\n\n- Univariate Analysis : data consists of **only one variable (only x value)**.\n\n     1. Line Plots / Bar Charts\n     2. Histograms\n     3. Box Plots \n     4. Count Plots\n     5. Descriptive Statistics techniques\n     6. Violin Plot","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Histogram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram for \"Elevation\"\nplt.figure(figsize=(5,4))\nsns.distplot(cover.Elevation,rug=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(cover.Aspect)\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram for \"Elevation\"\nsns.boxplot(cover['Elevation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(cover.Vertical_Distance_To_Hydrology)\nplt.title('Vertical_Distance_To_Hydrology')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram for \"All Features\"\ncover.hist(figsize=(16, 20), bins=50, xlabelsize=7, ylabelsize=7);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Bivariate Analysis\n\n- **Bivariate Analysis** : data involves **two different variables**.\n\n     1. Bar Charts\n     2. Scatter Plots\n     3. FacetGrid\n     \n\n-  There are **three** types of bivariate analysis\n\n     1. Numerical & Numerical\n     2. Categorical & Categorical\n     3. Numerical & Categorical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x=cover['Cover_Type'],y=cover['Elevation'])\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x=cover['Cover_Type'],y=cover['Aspect'])\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vertical distance to the hydrology column\nsns.violinplot(x=cover.Cover_Type, y=cover.Vertical_Distance_To_Hydrology)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Line Plot","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Aspect Vs Cover_Type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Line Plot between \"Aspect\" and \"Cover_Type\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=cover['Aspect'], y=cover['Cover_Type'])\n\nplt.xlabel('Aspect', fontsize=15, fontweight='bold')\nplt.ylabel('Cover_Type', fontsize=15, fontweight='bold')\n\nplt.title('Aspect Vs Cover_Type', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Slope Vs Cover_Type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Line Plot between \"Slope\" and \"Cover_Type\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=cover['Slope'], y=cover['Cover_Type'])\n\nplt.xlabel('Slope', fontsize=15, fontweight='bold')\nplt.ylabel('Cover_Type', fontsize=15, fontweight='bold')\n\nplt.title('Slope Vs Cover_Type', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Scatter Plot","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Elevation Vs HD Roadways","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(cover, x='Elevation', y= 'Horizontal_Distance_To_Roadways', color='Cover_Type', width=800, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see a positive correlation between Elevation and Distance to Roadways.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Aspect  Vs Hillshade_3pm","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot between \"GrLivArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(cover.Aspect, cover.Hillshade_3pm)\n\nplt.xlabel('Aspect', fontsize=15, fontweight='bold')\nplt.ylabel('Hillshade_3pm', fontsize=15, fontweight='bold')\n\nplt.title('Aspect Vs Hillshade_3pm', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Horizontal_Distance_To_Hydrology Vs Vertical_Distance_To_Hydrology","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot between \"Horizontal_Distance_To_Hydrology\" and \"Vertical_Distance_To_Hydrology\" variable\nplt.figure(figsize=(7,6))\nsns.scatterplot(cover['Horizontal_Distance_To_Hydrology'], cover['Vertical_Distance_To_Hydrology'])\n\nplt.xlabel('Horizontal_Distance_To_Hydrology', fontsize=15, fontweight='bold')\nplt.ylabel('Vertical_Distance_To_Hydrology', fontsize=15, fontweight='bold')\n\nplt.title('Horizontal_Distance_To_Hydrology Vs Vertical_Distance_To_Hydrology', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Hillshade_Noon Vs Hillshade_3pm","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot between \"Hillshade_Noon\" and \"Hillshade_3pm\"\nfig = px.scatter(cover,x='Hillshade_Noon',y= 'Hillshade_3pm',color='Cover_Type',width=800,height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Aspect Vs Hillshade_9am","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot between \"Aspect\" and \"Hillshade_9am\"\nfig = px.scatter(cover,x='Aspect',y= 'Hillshade_9am',color='Cover_Type',width=800,height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Hillshade_9am vs Hillshade_3pm","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot between \"Hillshade_9am\" and \"Hillshade_3pm\"\nfig = px.scatter(cover,x='Hillshade_9am',y= 'Hillshade_3pm',color='Cover_Type',width=800,height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Slope Vs Hillshade_Noon","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot between \"Slope\" and \"Hillshade_Noon\"\nfig = px.scatter(cover,x='Slope',y= 'Hillshade_Noon',color='Cover_Type',width=800,height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Count Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count Plot for \"Cover_Type\"\nplt.figure(figsize = (15, 9))\nsns.countplot(x = 'Cover_Type', data = cover)\nxt = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Violin Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# A violin plot is a hybrid of a box plot and a kernel density plot, which shows peaks in the data.\ncols = cover.columns\nsize = len(cols) - 1 # We don't need the target attribute\n# x-axis has target attributes to distinguish between classes\nx = cols[size]\ny = cols[0:size]\n\nfor i in range(0, size):\n    sns.violinplot(data=cover, x=x, y=y[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Aspect plot contains couple of normal distribution for several classes\n- Hillshade 9am and 12pm displays left skew (long tail towards left)\n- Wilderness_Area3 gives no class distinction.\n- Soil_Type, 1,5,8,9,12,14,18-22, 25-30 and 35-40 offer class distinction as values are not present for many classes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3. Multivariate Analysis\n\n- 1. Pair Plot","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Pair Plot between 'SalePrice' and correlated variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\ncolumns = cover.iloc[:,:10]\nsns.pairplot(columns, kind ='scatter', diag_kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Features have more missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the value count for different soil_types\nfor i in range(10, cover.shape[1]-1):\n    j = cover.columns[i]\n    print (cover[j].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:blue\" align=\"left\"> 7. Check & Reduce Skewness </h2>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Skewness tells us about the symmetry in a distribution.\n\n* If the **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.\n  \n* If the **skewness** is **between -1 to -0.5 or 0.5 to 1** then data is **moderately skewed**.\n  \n* If the **skewness** is **less than -1 and greater than +1** then our data is **heavily skewed**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cover.iloc[:,:10].skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- \"Aspect\" & \"Hillshade_3pm\" are in between -0.5 and +0.5. Fairly skewed.\n- In our above data,\n    1. Slope\n    2. Horizontal_Distance_To_Hydrology\n    3. Vertical_Distance_To_Hydrology\n\n- Are highly positively, right skewed.\n\n    1. Elevation\n    2. Hillshade_9am\n    3. Hillshade_Noon\n    \n- Are highly negitively, left skewed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### a. Checking Skewness for feature \"Horizontal_Distance_To_Hydrology\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the skewness of \"LotArea\" attributes\nsns.distplot(cover['Horizontal_Distance_To_Hydrology'])\nSkew_Horizontal_Distance_To_Hydrology = cover['Horizontal_Distance_To_Hydrology'].skew()\nplt.title(\"Skew:\"+str(Skew_Horizontal_Distance_To_Hydrology))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculating the square for the column df['LotArea'] column\nsns.distplot(np.sqrt(cover['Horizontal_Distance_To_Hydrology']))\nSkew_Horizontal_Distance_To_Hydrology_sqrt = np.sqrt(cover['Horizontal_Distance_To_Hydrology']+1).skew()\nplt.title(\"Skew:\"+str(Skew_Horizontal_Distance_To_Hydrology_sqrt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- skewness is close to zero means normally distributed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### b. Checking Skewness for feature \"Vertical_Distance_To_Hydrology\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the skewness of \"Vertical_Distance_To_Hydrology\" attributes\nsns.distplot(cover['Vertical_Distance_To_Hydrology'])\nSkew_Vertical_Distance_To_Hydrology = cover['Vertical_Distance_To_Hydrology'].skew()\nplt.title(\"Skew:\"+str(Skew_Vertical_Distance_To_Hydrology))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### c. Checking Skewness for feature \"Horizontal_Distance_To_Roadways\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the skewness of \"Horizontal_Distance_To_Roadways\" attributes\nsns.distplot(cover['Horizontal_Distance_To_Roadways'])\nSkew_Horizontal_Distance_To_Roadways = cover['Horizontal_Distance_To_Roadways'].skew()\nplt.title(\"Skew:\"+str(Skew_Horizontal_Distance_To_Roadways))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculating the square for the column df['Horizontal_Distance_To_Roadways'] column\nsns.distplot(np.sqrt(cover['Horizontal_Distance_To_Roadways']))\nSkew_Horizontal_Distance_To_Roadways_sqrt = np.sqrt(cover['Horizontal_Distance_To_Roadways']).skew()\nplt.title(\"Skew:\"+str(Skew_Horizontal_Distance_To_Roadways_sqrt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### d. Checking Skewness for feature \"Hillshade_9am\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the skewness of \"Hillshade_9am\" attributes\nsns.distplot(cover['Hillshade_9am'])\nSkew_Hillshade_9am = cover['Hillshade_9am'].skew()\nplt.title(\"Skew:\"+str(Skew_Hillshade_9am))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculating the square for the column df['Hillshade_9am'] column\nsns.distplot(np.power(cover['Hillshade_9am'],5))\nSkew_Hillshade_9am_power = np.power(cover['Hillshade_9am'],5).skew()\nplt.title(\"Skew:\"+str(Skew_Hillshade_9am_power))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### e. Checking Skewness for feature \"Hillshade_Noon\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the skewness of \"Hillshade_Noon\" attributes\nsns.distplot(cover['Hillshade_Noon'])\nSkew_Hillshade_Noon = cover['Hillshade_Noon'].skew()\nplt.title(\"Skew:\"+str(Skew_Hillshade_Noon))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculating the square for the column df['Hillshade_9am'] column\nsns.distplot(np.power(cover['Hillshade_Noon'],5))\nSkew_Hillshade_Noon_power = np.power(cover['Hillshade_Noon'],5).skew()\nplt.title(\"Skew:\"+str(Skew_Hillshade_Noon_power))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### f. Checking Skewness for feature \"Horizontal_Distance_To_Fire_Points\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the skewness of \"Horizontal_Distance_To_Fire_Points\" attributes\nsns.distplot(cover['Horizontal_Distance_To_Fire_Points'])\nSkew_Horizontal_Distance_To_Fire_Points = cover['Horizontal_Distance_To_Fire_Points'].skew()\nplt.title(\"Skew:\"+str(Skew_Horizontal_Distance_To_Fire_Points))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculating the square for the column df['Horizontal_Distance_To_Fire_Points'] column\nsns.distplot(np.cbrt(cover['Horizontal_Distance_To_Fire_Points']))\nSkew_Horizontal_Distance_To_Fire_Points_cube = np.cbrt(cover['Horizontal_Distance_To_Fire_Points']).skew()\nplt.title(\"Skew:\"+str(Skew_Horizontal_Distance_To_Fire_Points_cube))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### g. Checking Skewness for feature \"Slope\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the skewness of \"Slope\" attributes\nsns.distplot(cover['Slope'])\nSkew_Slope = cover['Slope'].skew()\nplt.title(\"Skew:\"+str(Skew_Slope))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculating the square for the column df['Slope'] column\nsns.distplot(np.sqrt(cover['Slope']))\nSkew_Slope_sqrt = np.sqrt(cover['Slope']).skew()\nplt.title(\"Skew:\"+str(Skew_Slope_sqrt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cover['dist_hydr'] = np.sqrt(cover['Vertical_Distance_To_Hydrology']**2 + cover['Horizontal_Distance_To_Hydrology']**2)\ntest['dist_hydr'] = np.sqrt(cover['Vertical_Distance_To_Hydrology']**2 + cover['Horizontal_Distance_To_Hydrology']**2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(cover['dist_hydr'], color='green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:blue\" align=\"left\"> 7. Model building and Evaluation </h2>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cover.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# standardizing the columns except \"soil type and wilderness_area\" since they are binary  \n\ncover_new = cover.iloc[:,:11]\ncover_new['dist_hydr'] = cover['dist_hydr']\ncover_new.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scaling\n- Standardizing the data i.e. to rescale the features to have a **mean of zero** and **standard deviation of 1.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nsc.fit(cover_new)\ncover_new = sc.transform(cover_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cover_new[:10,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cover.iloc[:,1:11] = cover_new[:,0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cover['dist_hydr'] = cover_new[:,10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation of \"independant features\" with \"target\" feature\n# Drop least correlated features; since we have hign dimmensional data \ncover_corr = cover.corr()\ncover_corr['Cover_Type'].abs().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Independant variable\nX = cover.drop(columns='Cover_Type',axis=1)\n# Dependant variable\ny = cover['Cover_Type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split  data into training and testing sets of 70:30 ratio\n# 20% of test size selected\n# random_state is random seed\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape of X & Y test / train\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_accuracy=[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LogReg = LogisticRegression(max_iter=1000)\nLogReg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_LogReg = LogReg.predict(X_test)\nclf_accuracy.append(accuracy_score(y_test, y_pred_LogReg))\nprint(accuracy_score(y_test, y_pred_LogReg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(LogReg.score(X_train, y_train), LogReg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Logistic Regression \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_LogReg)),\n            mean_squared_error(y_test, y_pred_LogReg),\n            mean_absolute_error(y_test, y_pred_LogReg),\n            r2_score(y_test, y_pred_LogReg)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"DTR = DecisionTreeRegressor()\nDTR.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_DTR = DTR.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_accuracy.append(accuracy_score(y_test, y_pred_DTR))\nprint(accuracy_score(y_test, y_pred_DTR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(DTR.score(X_train, y_train), DTR.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model\\t\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Decision Tree Regressor \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_DTR)),\n            mean_squared_error(y_test, y_pred_DTR),\n            mean_absolute_error(y_test, y_pred_DTR),\n            r2_score(y_test, y_pred_DTR)))\n\nplt.scatter(y_test, y_pred_DTR)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.title(\"Decision Tree Regressor\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rf = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_accuracy.append(accuracy_score(y_test, pred_rf ))\nprint(accuracy_score(y_test, pred_rf ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(rf.score(X_train, y_train), rf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Random Forest \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, pred_rf )),\n            mean_squared_error(y_test, pred_rf ),\n            mean_absolute_error(y_test, pred_rf ),\n            r2_score(y_test, pred_rf )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. KNN (K Nearest Neighbors)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN = KNeighborsClassifier()\n\nl=[i for i in range(1,11)]\naccuracy=[]\n\nfor i in l:\n    KNN = KNeighborsClassifier(n_neighbors=i, weights='distance')\n    KNN.fit(X_train, y_train)\n    pred_knn = KNN.predict(X_test)\n    accuracy.append(accuracy_score(y_test, pred_knn))\n\nplt.plot(l,accuracy)\nplt.title('knn_accuracy plot')\nplt.xlabel('neighbors')\nplt.ylabel('accuracy')\nplt.grid()\n\nprint(max(accuracy))\n\nclf_accuracy.append(max(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Random Forest \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, pred_rf )),\n            mean_squared_error(y_test, pred_rf ),\n            mean_absolute_error(y_test, pred_rf ),\n            r2_score(y_test, pred_rf )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nreg_xgb = xgboost.XGBClassifier(max_depth=7)\nreg_xgb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting X_test\ny_pred_xgb = reg_xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_xgb.score(X_train,y_train),reg_xgb.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_accuracy.append(accuracy_score(y_test, y_pred_xgb))\nprint(accuracy_score(y_test, y_pred_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"XGBClassifier \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, pred_rf )),\n            mean_squared_error(y_test, pred_rf ),\n            mean_absolute_error(y_test, pred_rf ),\n            r2_score(y_test, pred_rf )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Naive Bayes Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = GaussianNB()\nnb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_nb = nb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_accuracy.append(accuracy_score(y_test, pred_nb))\nprint(accuracy_score(y_test, pred_nb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(nb.score(X_train,y_train),nb.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Model\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Naive Bayes Classifier \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, pred_nb )),\n            mean_squared_error(y_test, pred_nb ),\n            mean_absolute_error(y_test, pred_nb ),\n            r2_score(y_test, pred_nb )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### classification Report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification Report\nprint(classification_report(y_test, pred_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\ncf_matrix = confusion_matrix(y_test, pred_rf)\nprint('Confusion Matrix \\n',cf_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix Heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,6))\nsns.heatmap(cf_matrix, cmap='coolwarm', annot=True, linewidth=1, fmt=\"d\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Score Summary :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_list=['Logistic Regression','Decision Tree','Random Forest','KNN','xgboost','nbayes']\nclf_accuracy1 = [0.6488095238095238,0.781415343915344,0.8621031746031746,0.6458333333333334,0.8753306878306878,0.6504629629629629]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,6))\nsns.barplot(x=clf_accuracy1, y=classifier_list)\nplt.grid()\nplt.xlabel('accuracy')\nplt.ylabel('classifier')\nplt.title('classifier vs accuracy plot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [LogReg, DTR, rf, KNN, reg_xgb, nb]\nnames = ['Logistic Regression','Decision Tree','Random Forest','KNN','xgboost','nbayes']\nrmses = []\n\nfor model in models:\n    rmses.append(np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n\nx = np.arange(len(names)) \nwidth = 0.3\n\nfig, ax = plt.subplots(figsize=(10,7))\nrects = ax.bar(x, rmses, width)\nax.set_ylabel('RMSE')\nax.set_xlabel('Models')\n\nax.set_title('RMSE with Different Algorithms')\n\nax.set_xticks(x)\nax.set_xticklabels(names, rotation=45)\n\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression\n- Accuracy on Test Data Set with Logistic Regression : 64%\n\n#### Decision Tree\n- Accuracy on Test Data Set with DecisionTree Regression : 78%\n\n#### Random Forest\n- Accuracy on Test Data Set with Random Forest Classifier : 86%\n\n#### KNN\n- Accuracy on Test Data Set with K Nearest Neighbours : 64%\n\n#### XGBoost Model\n- Accuracy on Test Data Set with XGBoost Classifier : 87%\n\n#### Naive Bayes Classifier\n- Accuracy on Test Data Set with Naive Bayes Classifier : 65%\n\n\n- So far **GBoost Model** proved to be the best performing model with **87% accuracy**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = reg_xgb.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'Id': test['Id'], 'Cover_Type': y_pred_test})\nsubmission.to_csv('Forest Covetype.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"color:green\" align=\"left\"> Hypothesis Testing </h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import f_oneway\nfrom scipy.stats import ttest_ind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.ttest_1samp(cover['Elevation'],0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Chi-Square Test-\n- The test is applied when you have two categorical variables from a single population. It is used to determine whether there is a significant association between the two variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"street_table = pd.crosstab(cover['Elevation'], cover['Cover_Type'])\nprint(street_table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"street_table.values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Observed Values\nObserved_Values = street_table.values \nprint(\"Observed Values :-\\n\",Observed_Values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = stats.chi2_contingency(street_table)\nval","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Expected_Values = val[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_rows = len(street_table.iloc[0:2,0])\nno_of_columns = len(street_table.iloc[0,0:2])\nddof = (no_of_rows-1)*(no_of_columns-1)\nprint(\"Degree of Freedom:-\",ddof)\nalpha = 0.05","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import chi2\nchi_square = sum([(o-e)**2./e for o,e in zip(Observed_Values, Expected_Values)])\nchi_square_statistic = chi_square[0]+chi_square[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"chi-square statistic:-\",chi_square_statistic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"critical_value = chi2.ppf(q=1-alpha,df=ddof)\nprint('critical_value:',critical_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# p-value\np_value = 1-chi2.cdf(x=chi_square_statistic, df=ddof)\nprint('p-value:', p_value)\nprint('Significance level: ',alpha)\nprint('Degree of Freedom: ',ddof)\nprint('p-value:', p_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if chi_square_statistic>=critical_value:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")\n    \nif p_value<=alpha:\n    print(\"Reject H0,There is a relationship between 2 categorical variables\")\nelse:\n    print(\"Retain H0,There is no relationship between 2 categorical variables\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sms\nmodel = sms.OLS(y,X).fit()\nmodel.summary()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}